2024-07-14 04:21:52,888 [INFO    ] __main__: jax.local_devices(): [cuda(id=0)]
2024-07-14 04:21:52,888 [INFO    ] __main__: selecting devices: [cuda(id=0)]
2024-07-14 04:21:52,888 [INFO    ] __main__: JAX found 1 devices
2024-07-14 04:21:54,704 [DEBUG   ] __main__: 

                                                                AlphaZeroNet Summary                                                                
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ path                         ┃ module         ┃ inputs              ┃ outputs           ┃ flops ┃ params                     ┃ batch_stats       ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│                              │ AlphaZeroNet   │ - float32[1,6,7,2]  │ - float32[1,7]    │ 0     │                            │                   │
│                              │                │ - train: False      │ - float32[1]      │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ConvBlock_0                 │ _ConvBlock     │ - float32[1,6,7,2]  │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ConvBlock_0/Conv_0          │ Conv           │ float32[1,6,7,2]    │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,2,64]  │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 1,216 (4.9 KB)             │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ConvBlock_0/BatchNorm_0     │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0                │ _PolicyHead    │ - float32[1,6,7,64] │ float32[1,7]      │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0/Conv_0         │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[1,1,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 4,160 (16.6 KB)            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0/BatchNorm_0    │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0/Dense_0        │ Dense          │ float32[1,2688]     │ float32[1,7]      │ 0     │ bias: float32[7]           │                   │
│                              │                │                     │                   │       │ kernel: float32[2688,7]    │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 18,823 (75.3 KB)           │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0                 │ _ValueHead     │ - float32[1,6,7,64] │ float32[1]        │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/Conv_0          │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,1]  │ 0     │ bias: float32[1]           │                   │
│                              │                │                     │                   │       │ kernel: float32[1,1,64,1]  │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 65 (260 B)                 │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/BatchNorm_0     │ BatchNorm      │ float32[1,6,7,1]    │ float32[1,6,7,1]  │ 0     │ bias: float32[1]           │ mean: float32[1]  │
│                              │                │                     │                   │       │ scale: float32[1]          │ var: float32[1]   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 2 (8 B)                    │ 2 (8 B)           │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/Dense_0         │ Dense          │ float32[1,42]       │ float32[1,64]     │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[42,64]     │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 2,752 (11.0 KB)            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/BatchNorm_1     │ BatchNorm      │ float32[1,64]       │ float32[1,64]     │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/Dense_1         │ Dense          │ float32[1,64]       │ float32[1,1]      │ 0     │ bias: float32[1]           │                   │
│                              │                │                     │                   │       │ kernel: float32[64,1]      │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 65 (260 B)                 │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│                              │                │                     │                   │ Total │ 398,027 (1.6 MB)           │ 1,666 (6.7 KB)    │
└──────────────────────────────┴────────────────┴─────────────────────┴───────────────────┴───────┴────────────────────────────┴───────────────────┘
                                                                                                                                                    
                                                         Total Parameters: 399,693 (1.6 MB)                                                         


2024-07-14 04:21:58,332 [INFO    ] __main__: jax.local_devices(): [cuda(id=0)]
2024-07-14 04:21:58,332 [INFO    ] __main__: selecting devices: [cuda(id=0)]
2024-07-14 04:21:58,332 [INFO    ] __main__: JAX found 1 devices
2024-07-14 04:22:06,741 [WARNING ] __main__: no checkpoint found in '/root/connect_four_clean/checkpoints/run2_armageddon'
2024-07-14 04:22:14,414 [INFO    ] __main__: replay_buffer size = 512
2024-07-14 04:22:14,418 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:22:15,876 [INFO    ] __main__: replay_buffer size = 1024
2024-07-14 04:22:15,887 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:22:17,328 [INFO    ] __main__: replay_buffer size = 1536
2024-07-14 04:22:17,345 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:22:18,811 [INFO    ] __main__: replay_buffer size = 2048
2024-07-14 04:22:18,830 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:22:20,251 [INFO    ] __main__: replay_buffer size = 2560
2024-07-14 04:22:20,276 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:22:21,732 [INFO    ] __main__: replay_buffer size = 3072
2024-07-14 04:22:21,765 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:22:23,183 [INFO    ] __main__: replay_buffer size = 3584
2024-07-14 04:22:23,217 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:22:24,702 [INFO    ] __main__: replay_buffer size = 4096
2024-07-14 04:22:24,739 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:22:34,517 [INFO    ] __main__: train step 0: loss: 0.3127, policy_loss: 2.1493, value_loss: 1.2968
2024-07-14 04:22:34,778 [INFO    ] __main__: train step 1: loss: 0.3009, policy_loss: 2.1332, value_loss: 1.2894
2024-07-14 04:22:35,041 [INFO    ] __main__: train step 2: loss: 0.3045, policy_loss: 2.1238, value_loss: 1.2927
2024-07-14 04:22:35,302 [INFO    ] __main__: train step 3: loss: 0.2948, policy_loss: 2.1178, value_loss: 1.2871
2024-07-14 04:22:35,561 [INFO    ] __main__: train step 4: loss: 0.2925, policy_loss: 2.1095, value_loss: 1.2879
2024-07-14 04:22:35,842 [INFO    ] __main__: train step 5: loss: 0.2897, policy_loss: 2.1018, value_loss: 1.2859
2024-07-14 04:22:36,325 [INFO    ] __main__: train step 6: loss: 0.2855, policy_loss: 2.0951, value_loss: 1.2792
2024-07-14 04:22:36,611 [INFO    ] __main__: train step 7: loss: 0.2808, policy_loss: 2.0913, value_loss: 1.2706
2024-07-14 04:22:36,884 [INFO    ] __main__: train step 8: loss: 0.2765, policy_loss: 2.0895, value_loss: 1.2658
2024-07-14 04:22:37,171 [INFO    ] __main__: train step 9: loss: 0.2753, policy_loss: 2.0889, value_loss: 1.2576
2024-07-14 04:22:37,442 [INFO    ] __main__: train step 10: loss: 0.2716, policy_loss: 2.0875, value_loss: 1.2503
2024-07-14 04:22:37,693 [INFO    ] __main__: train step 11: loss: 0.2684, policy_loss: 2.0858, value_loss: 1.2463
2024-07-14 04:22:37,938 [INFO    ] __main__: train step 12: loss: 0.2654, policy_loss: 2.0825, value_loss: 1.2448
2024-07-14 04:22:38,207 [INFO    ] __main__: train step 13: loss: 0.2623, policy_loss: 2.0781, value_loss: 1.2432
2024-07-14 04:22:38,475 [INFO    ] __main__: train step 14: loss: 0.2600, policy_loss: 2.0755, value_loss: 1.2417
2024-07-14 04:22:38,764 [INFO    ] __main__: train step 15: loss: 0.2576, policy_loss: 2.0736, value_loss: 1.2395
2024-07-14 04:22:39,041 [INFO    ] __main__: train step 16: loss: 0.2560, policy_loss: 2.0717, value_loss: 1.2367
2024-07-14 04:22:40,728 [INFO    ] __main__: replay_buffer size = 4608
2024-07-14 04:22:40,771 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:22:43,101 [INFO    ] __main__: train step 17: loss: 0.2534, policy_loss: 2.0708, value_loss: 1.2359
2024-07-14 04:22:43,606 [INFO    ] __main__: train step 18: loss: 0.2516, policy_loss: 2.0700, value_loss: 1.2339
2024-07-14 04:22:43,883 [INFO    ] __main__: train step 19: loss: 0.2504, policy_loss: 2.0682, value_loss: 1.2342
2024-07-14 04:22:44,151 [INFO    ] __main__: train step 20: loss: 0.2493, policy_loss: 2.0667, value_loss: 1.2339
2024-07-14 04:22:44,436 [INFO    ] __main__: train step 21: loss: 0.2478, policy_loss: 2.0650, value_loss: 1.2341
2024-07-14 04:22:44,712 [INFO    ] __main__: train step 22: loss: 0.2464, policy_loss: 2.0636, value_loss: 1.2350
2024-07-14 04:22:44,988 [INFO    ] __main__: train step 23: loss: 0.2448, policy_loss: 2.0618, value_loss: 1.2349
2024-07-14 04:22:45,260 [INFO    ] __main__: train step 24: loss: 0.2441, policy_loss: 2.0600, value_loss: 1.2354
2024-07-14 04:22:45,542 [INFO    ] __main__: train step 25: loss: 0.2425, policy_loss: 2.0583, value_loss: 1.2361
2024-07-14 04:22:45,808 [INFO    ] __main__: train step 26: loss: 0.2416, policy_loss: 2.0569, value_loss: 1.2365
2024-07-14 04:22:46,098 [INFO    ] __main__: train step 27: loss: 0.2408, policy_loss: 2.0557, value_loss: 1.2356
2024-07-14 04:22:46,381 [INFO    ] __main__: train step 28: loss: 0.2401, policy_loss: 2.0546, value_loss: 1.2347
2024-07-14 04:22:46,664 [INFO    ] __main__: train step 29: loss: 0.2393, policy_loss: 2.0535, value_loss: 1.2335
2024-07-14 04:22:46,929 [INFO    ] __main__: train step 30: loss: 0.2386, policy_loss: 2.0524, value_loss: 1.2330
2024-07-14 04:22:47,436 [INFO    ] __main__: train step 31: loss: 0.2377, policy_loss: 2.0512, value_loss: 1.2314
2024-07-14 04:22:47,705 [INFO    ] __main__: train step 32: loss: 0.2369, policy_loss: 2.0500, value_loss: 1.2305
2024-07-14 04:22:47,981 [INFO    ] __main__: train step 33: loss: 0.2363, policy_loss: 2.0490, value_loss: 1.2302
2024-07-14 04:22:49,626 [INFO    ] __main__: replay_buffer size = 5120
2024-07-14 04:22:49,671 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:22:51,885 [INFO    ] __main__: train step 34: loss: 0.2359, policy_loss: 2.0481, value_loss: 1.2279
2024-07-14 04:22:52,164 [INFO    ] __main__: train step 35: loss: 0.2351, policy_loss: 2.0471, value_loss: 1.2259
2024-07-14 04:22:52,428 [INFO    ] __main__: train step 36: loss: 0.2345, policy_loss: 2.0461, value_loss: 1.2242
2024-07-14 04:22:52,694 [INFO    ] __main__: train step 37: loss: 0.2340, policy_loss: 2.0451, value_loss: 1.2226
2024-07-14 04:22:52,965 [INFO    ] __main__: train step 38: loss: 0.2338, policy_loss: 2.0442, value_loss: 1.2209
2024-07-14 04:22:53,232 [INFO    ] __main__: train step 39: loss: 0.2335, policy_loss: 2.0432, value_loss: 1.2187
2024-07-14 04:22:53,506 [INFO    ] __main__: train step 40: loss: 0.2333, policy_loss: 2.0423, value_loss: 1.2173
2024-07-14 04:22:53,794 [INFO    ] __main__: train step 41: loss: 0.2330, policy_loss: 2.0413, value_loss: 1.2150
2024-07-14 04:22:54,065 [INFO    ] __main__: train step 42: loss: 0.2326, policy_loss: 2.0404, value_loss: 1.2126
2024-07-14 04:22:54,555 [INFO    ] __main__: train step 43: loss: 0.2319, policy_loss: 2.0394, value_loss: 1.2099
2024-07-14 04:22:54,831 [INFO    ] __main__: train step 44: loss: 0.2316, policy_loss: 2.0384, value_loss: 1.2076
2024-07-14 04:22:55,096 [INFO    ] __main__: train step 45: loss: 0.2314, policy_loss: 2.0376, value_loss: 1.2061
2024-07-14 04:22:55,365 [INFO    ] __main__: train step 46: loss: 0.2310, policy_loss: 2.0368, value_loss: 1.2034
2024-07-14 04:22:55,641 [INFO    ] __main__: train step 47: loss: 0.2306, policy_loss: 2.0360, value_loss: 1.2010
2024-07-14 04:22:55,924 [INFO    ] __main__: train step 48: loss: 0.2304, policy_loss: 2.0352, value_loss: 1.1987
2024-07-14 04:22:56,202 [INFO    ] __main__: train step 49: loss: 0.2299, policy_loss: 2.0345, value_loss: 1.1965
2024-07-14 04:22:56,476 [INFO    ] __main__: train step 50: loss: 0.2293, policy_loss: 2.0338, value_loss: 1.1947
2024-07-14 04:22:58,091 [INFO    ] __main__: replay_buffer size = 5632
2024-07-14 04:22:58,144 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:23:00,414 [INFO    ] __main__: train step 51: loss: 0.2289, policy_loss: 2.0329, value_loss: 1.1930
2024-07-14 04:23:00,691 [INFO    ] __main__: train step 52: loss: 0.2286, policy_loss: 2.0320, value_loss: 1.1911
2024-07-14 04:23:00,959 [INFO    ] __main__: train step 53: loss: 0.2283, policy_loss: 2.0313, value_loss: 1.1888
2024-07-14 04:23:01,249 [INFO    ] __main__: train step 54: loss: 0.2280, policy_loss: 2.0307, value_loss: 1.1868
2024-07-14 04:23:01,920 [INFO    ] __main__: train step 55: loss: 0.2276, policy_loss: 2.0301, value_loss: 1.1851
2024-07-14 04:23:02,192 [INFO    ] __main__: train step 56: loss: 0.2273, policy_loss: 2.0295, value_loss: 1.1836
2024-07-14 04:23:02,465 [INFO    ] __main__: train step 57: loss: 0.2271, policy_loss: 2.0288, value_loss: 1.1815
2024-07-14 04:23:02,745 [INFO    ] __main__: train step 58: loss: 0.2266, policy_loss: 2.0281, value_loss: 1.1800
2024-07-14 04:23:03,019 [INFO    ] __main__: train step 59: loss: 0.2264, policy_loss: 2.0274, value_loss: 1.1780
2024-07-14 04:23:03,293 [INFO    ] __main__: train step 60: loss: 0.2263, policy_loss: 2.0267, value_loss: 1.1761
2024-07-14 04:23:03,564 [INFO    ] __main__: train step 61: loss: 0.2260, policy_loss: 2.0258, value_loss: 1.1745
2024-07-14 04:23:03,841 [INFO    ] __main__: train step 62: loss: 0.2259, policy_loss: 2.0251, value_loss: 1.1727
2024-07-14 04:23:04,120 [INFO    ] __main__: train step 63: loss: 0.2258, policy_loss: 2.0243, value_loss: 1.1711
2024-07-14 04:23:04,385 [INFO    ] __main__: train step 64: loss: 0.2254, policy_loss: 2.0235, value_loss: 1.1693
2024-07-14 04:23:04,651 [INFO    ] __main__: train step 65: loss: 0.2253, policy_loss: 2.0229, value_loss: 1.1675
2024-07-14 04:23:04,927 [INFO    ] __main__: train step 66: loss: 0.2252, policy_loss: 2.0222, value_loss: 1.1661
2024-07-14 04:23:05,406 [INFO    ] __main__: train step 67: loss: 0.2249, policy_loss: 2.0215, value_loss: 1.1640
2024-07-14 04:23:07,042 [INFO    ] __main__: replay_buffer size = 6144
2024-07-14 04:23:07,101 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:23:08,986 [INFO    ] __main__: train step 68: loss: 0.2249, policy_loss: 2.0209, value_loss: 1.1625
2024-07-14 04:23:09,255 [INFO    ] __main__: train step 69: loss: 0.2249, policy_loss: 2.0203, value_loss: 1.1610
2024-07-14 04:23:09,526 [INFO    ] __main__: train step 70: loss: 0.2248, policy_loss: 2.0196, value_loss: 1.1593
2024-07-14 04:23:09,798 [INFO    ] __main__: train step 71: loss: 0.2246, policy_loss: 2.0190, value_loss: 1.1581
2024-07-14 04:23:10,061 [INFO    ] __main__: train step 72: loss: 0.2245, policy_loss: 2.0184, value_loss: 1.1567
2024-07-14 04:23:10,332 [INFO    ] __main__: train step 73: loss: 0.2243, policy_loss: 2.0179, value_loss: 1.1554
2024-07-14 04:23:10,615 [INFO    ] __main__: train step 74: loss: 0.2242, policy_loss: 2.0173, value_loss: 1.1538
2024-07-14 04:23:10,892 [INFO    ] __main__: train step 75: loss: 0.2240, policy_loss: 2.0168, value_loss: 1.1527
2024-07-14 04:23:11,172 [INFO    ] __main__: train step 76: loss: 0.2239, policy_loss: 2.0163, value_loss: 1.1511
2024-07-14 04:23:11,445 [INFO    ] __main__: train step 77: loss: 0.2237, policy_loss: 2.0158, value_loss: 1.1497
2024-07-14 04:23:11,731 [INFO    ] __main__: train step 78: loss: 0.2236, policy_loss: 2.0151, value_loss: 1.1483
2024-07-14 04:23:12,414 [INFO    ] __main__: train step 79: loss: 0.2234, policy_loss: 2.0146, value_loss: 1.1472
2024-07-14 04:23:12,692 [INFO    ] __main__: train step 80: loss: 0.2233, policy_loss: 2.0140, value_loss: 1.1458
2024-07-14 04:23:12,964 [INFO    ] __main__: train step 81: loss: 0.2232, policy_loss: 2.0135, value_loss: 1.1445
2024-07-14 04:23:13,244 [INFO    ] __main__: train step 82: loss: 0.2231, policy_loss: 2.0130, value_loss: 1.1433
2024-07-14 04:23:13,526 [INFO    ] __main__: train step 83: loss: 0.2229, policy_loss: 2.0125, value_loss: 1.1421
2024-07-14 04:23:13,813 [INFO    ] __main__: train step 84: loss: 0.2227, policy_loss: 2.0121, value_loss: 1.1407
2024-07-14 04:23:15,568 [INFO    ] __main__: replay_buffer size = 6656
2024-07-14 04:23:15,629 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:23:17,875 [INFO    ] __main__: train step 85: loss: 0.2227, policy_loss: 2.0116, value_loss: 1.1393
2024-07-14 04:23:18,154 [INFO    ] __main__: train step 86: loss: 0.2227, policy_loss: 2.0112, value_loss: 1.1380
2024-07-14 04:23:18,437 [INFO    ] __main__: train step 87: loss: 0.2225, policy_loss: 2.0108, value_loss: 1.1369
2024-07-14 04:23:18,719 [INFO    ] __main__: train step 88: loss: 0.2225, policy_loss: 2.0104, value_loss: 1.1358
2024-07-14 04:23:18,991 [INFO    ] __main__: train step 89: loss: 0.2224, policy_loss: 2.0099, value_loss: 1.1345
2024-07-14 04:23:19,260 [INFO    ] __main__: train step 90: loss: 0.2223, policy_loss: 2.0095, value_loss: 1.1336
2024-07-14 04:23:19,515 [INFO    ] __main__: train step 91: loss: 0.2224, policy_loss: 2.0091, value_loss: 1.1323
2024-07-14 04:23:19,786 [INFO    ] __main__: train step 92: loss: 0.2224, policy_loss: 2.0087, value_loss: 1.1313
2024-07-14 04:23:20,294 [INFO    ] __main__: train step 93: loss: 0.2222, policy_loss: 2.0083, value_loss: 1.1303
2024-07-14 04:23:20,554 [INFO    ] __main__: train step 94: loss: 0.2222, policy_loss: 2.0080, value_loss: 1.1293
2024-07-14 04:23:20,833 [INFO    ] __main__: train step 95: loss: 0.2221, policy_loss: 2.0075, value_loss: 1.1285
2024-07-14 04:23:21,096 [INFO    ] __main__: train step 96: loss: 0.2223, policy_loss: 2.0072, value_loss: 1.1276
2024-07-14 04:23:21,378 [INFO    ] __main__: train step 97: loss: 0.2221, policy_loss: 2.0068, value_loss: 1.1269
2024-07-14 04:23:21,646 [INFO    ] __main__: train step 98: loss: 0.2222, policy_loss: 2.0064, value_loss: 1.1258
2024-07-14 04:23:21,919 [INFO    ] __main__: train step 99: loss: 0.2222, policy_loss: 2.0061, value_loss: 1.1249
2024-07-14 04:23:22,188 [INFO    ] __main__: train step 100: loss: 0.2221, policy_loss: 2.0057, value_loss: 1.1238
2024-07-14 04:23:22,453 [INFO    ] __main__: train step 101: loss: 0.2222, policy_loss: 2.0053, value_loss: 1.1227
2024-07-14 04:23:24,062 [INFO    ] __main__: replay_buffer size = 7168
2024-07-14 04:23:24,132 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:23:26,437 [INFO    ] __main__: train step 102: loss: 0.2221, policy_loss: 2.0049, value_loss: 1.1220
2024-07-14 04:23:26,710 [INFO    ] __main__: train step 103: loss: 0.2220, policy_loss: 2.0045, value_loss: 1.1210
2024-07-14 04:23:27,385 [INFO    ] __main__: train step 104: loss: 0.2221, policy_loss: 2.0041, value_loss: 1.1201
2024-07-14 04:23:27,647 [INFO    ] __main__: train step 105: loss: 0.2221, policy_loss: 2.0036, value_loss: 1.1193
2024-07-14 04:23:27,921 [INFO    ] __main__: train step 106: loss: 0.2221, policy_loss: 2.0032, value_loss: 1.1187
2024-07-14 04:23:28,194 [INFO    ] __main__: train step 107: loss: 0.2221, policy_loss: 2.0029, value_loss: 1.1180
2024-07-14 04:23:28,470 [INFO    ] __main__: train step 108: loss: 0.2220, policy_loss: 2.0025, value_loss: 1.1171
2024-07-14 04:23:28,734 [INFO    ] __main__: train step 109: loss: 0.2221, policy_loss: 2.0022, value_loss: 1.1163
2024-07-14 04:23:28,988 [INFO    ] __main__: train step 110: loss: 0.2220, policy_loss: 2.0018, value_loss: 1.1152
2024-07-14 04:23:29,266 [INFO    ] __main__: train step 111: loss: 0.2219, policy_loss: 2.0015, value_loss: 1.1145
2024-07-14 04:23:29,548 [INFO    ] __main__: train step 112: loss: 0.2218, policy_loss: 2.0011, value_loss: 1.1139
2024-07-14 04:23:29,814 [INFO    ] __main__: train step 113: loss: 0.2219, policy_loss: 2.0007, value_loss: 1.1131
2024-07-14 04:23:30,088 [INFO    ] __main__: train step 114: loss: 0.2220, policy_loss: 2.0004, value_loss: 1.1125
2024-07-14 04:23:30,370 [INFO    ] __main__: train step 115: loss: 0.2220, policy_loss: 2.0000, value_loss: 1.1116
2024-07-14 04:23:30,640 [INFO    ] __main__: train step 116: loss: 0.2220, policy_loss: 1.9997, value_loss: 1.1110
2024-07-14 04:23:30,914 [INFO    ] __main__: train step 117: loss: 0.2220, policy_loss: 1.9993, value_loss: 1.1102
2024-07-14 04:23:31,637 [INFO    ] __main__: train step 118: loss: 0.2220, policy_loss: 1.9990, value_loss: 1.1095
2024-07-14 04:23:33,331 [INFO    ] __main__: replay_buffer size = 7680
2024-07-14 04:23:33,403 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:23:35,633 [INFO    ] __main__: train step 119: loss: 0.2220, policy_loss: 1.9986, value_loss: 1.1089
2024-07-14 04:23:35,905 [INFO    ] __main__: train step 120: loss: 0.2220, policy_loss: 1.9983, value_loss: 1.1083
2024-07-14 04:23:36,172 [INFO    ] __main__: train step 121: loss: 0.2221, policy_loss: 1.9980, value_loss: 1.1077
2024-07-14 04:23:36,433 [INFO    ] __main__: train step 122: loss: 0.2220, policy_loss: 1.9977, value_loss: 1.1072
2024-07-14 04:23:36,687 [INFO    ] __main__: train step 123: loss: 0.2221, policy_loss: 1.9973, value_loss: 1.1066
2024-07-14 04:23:36,962 [INFO    ] __main__: train step 124: loss: 0.2221, policy_loss: 1.9969, value_loss: 1.1060
2024-07-14 04:23:37,234 [INFO    ] __main__: train step 125: loss: 0.2222, policy_loss: 1.9966, value_loss: 1.1055
2024-07-14 04:23:37,501 [INFO    ] __main__: train step 126: loss: 0.2223, policy_loss: 1.9963, value_loss: 1.1048
2024-07-14 04:23:37,767 [INFO    ] __main__: train step 127: loss: 0.2223, policy_loss: 1.9960, value_loss: 1.1044
2024-07-14 04:23:38,037 [INFO    ] __main__: train step 128: loss: 0.2223, policy_loss: 1.9956, value_loss: 1.1038
2024-07-14 04:23:38,302 [INFO    ] __main__: train step 129: loss: 0.2224, policy_loss: 1.9953, value_loss: 1.1034
2024-07-14 04:23:38,557 [INFO    ] __main__: train step 130: loss: 0.2223, policy_loss: 1.9949, value_loss: 1.1029
2024-07-14 04:23:39,234 [INFO    ] __main__: train step 131: loss: 0.2223, policy_loss: 1.9946, value_loss: 1.1021
2024-07-14 04:23:39,508 [INFO    ] __main__: train step 132: loss: 0.2222, policy_loss: 1.9943, value_loss: 1.1014
2024-07-14 04:23:39,781 [INFO    ] __main__: train step 133: loss: 0.2222, policy_loss: 1.9940, value_loss: 1.1008
2024-07-14 04:23:40,055 [INFO    ] __main__: train step 134: loss: 0.2222, policy_loss: 1.9937, value_loss: 1.1004
2024-07-14 04:23:40,336 [INFO    ] __main__: train step 135: loss: 0.2222, policy_loss: 1.9934, value_loss: 1.0998
2024-07-14 04:23:41,970 [INFO    ] __main__: replay_buffer size = 8192
2024-07-14 04:23:42,041 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:23:43,779 [INFO    ] __main__: train step 136: loss: 0.2223, policy_loss: 1.9932, value_loss: 1.0993
2024-07-14 04:23:44,062 [INFO    ] __main__: train step 137: loss: 0.2223, policy_loss: 1.9929, value_loss: 1.0989
2024-07-14 04:23:44,327 [INFO    ] __main__: train step 138: loss: 0.2224, policy_loss: 1.9926, value_loss: 1.0983
2024-07-14 04:23:44,610 [INFO    ] __main__: train step 139: loss: 0.2225, policy_loss: 1.9923, value_loss: 1.0977
2024-07-14 04:23:44,881 [INFO    ] __main__: train step 140: loss: 0.2225, policy_loss: 1.9921, value_loss: 1.0972
2024-07-14 04:23:45,150 [INFO    ] __main__: train step 141: loss: 0.2226, policy_loss: 1.9919, value_loss: 1.0969
2024-07-14 04:23:45,410 [INFO    ] __main__: train step 142: loss: 0.2226, policy_loss: 1.9916, value_loss: 1.0965
2024-07-14 04:23:45,678 [INFO    ] __main__: train step 143: loss: 0.2227, policy_loss: 1.9913, value_loss: 1.0959
2024-07-14 04:23:46,349 [INFO    ] __main__: train step 144: loss: 0.2227, policy_loss: 1.9911, value_loss: 1.0954
2024-07-14 04:23:46,616 [INFO    ] __main__: train step 145: loss: 0.2228, policy_loss: 1.9907, value_loss: 1.0949
2024-07-14 04:23:46,887 [INFO    ] __main__: train step 146: loss: 0.2229, policy_loss: 1.9905, value_loss: 1.0943
2024-07-14 04:23:47,169 [INFO    ] __main__: train step 147: loss: 0.2228, policy_loss: 1.9902, value_loss: 1.0939
2024-07-14 04:23:47,438 [INFO    ] __main__: train step 148: loss: 0.2228, policy_loss: 1.9900, value_loss: 1.0934
2024-07-14 04:23:47,705 [INFO    ] __main__: train step 149: loss: 0.2228, policy_loss: 1.9897, value_loss: 1.0929
2024-07-14 04:23:47,975 [INFO    ] __main__: train step 150: loss: 0.2228, policy_loss: 1.9895, value_loss: 1.0926
2024-07-14 04:23:48,254 [INFO    ] __main__: train step 151: loss: 0.2230, policy_loss: 1.9892, value_loss: 1.0919
2024-07-14 04:23:48,518 [INFO    ] __main__: train step 152: loss: 0.2231, policy_loss: 1.9890, value_loss: 1.0913
2024-07-14 04:23:50,111 [INFO    ] __main__: replay_buffer size = 8704
2024-07-14 04:23:50,186 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:23:52,475 [INFO    ] __main__: train step 153: loss: 0.2231, policy_loss: 1.9887, value_loss: 1.0909
2024-07-14 04:23:52,759 [INFO    ] __main__: train step 154: loss: 0.2232, policy_loss: 1.9885, value_loss: 1.0905
2024-07-14 04:23:53,029 [INFO    ] __main__: train step 155: loss: 0.2233, policy_loss: 1.9882, value_loss: 1.0901
2024-07-14 04:23:53,523 [INFO    ] __main__: train step 156: loss: 0.2233, policy_loss: 1.9880, value_loss: 1.0897
2024-07-14 04:23:53,793 [INFO    ] __main__: train step 157: loss: 0.2234, policy_loss: 1.9877, value_loss: 1.0893
2024-07-14 04:23:54,068 [INFO    ] __main__: train step 158: loss: 0.2235, policy_loss: 1.9874, value_loss: 1.0888
2024-07-14 04:23:54,337 [INFO    ] __main__: train step 159: loss: 0.2235, policy_loss: 1.9871, value_loss: 1.0884
2024-07-14 04:23:54,614 [INFO    ] __main__: train step 160: loss: 0.2236, policy_loss: 1.9868, value_loss: 1.0880
2024-07-14 04:23:54,885 [INFO    ] __main__: train step 161: loss: 0.2235, policy_loss: 1.9866, value_loss: 1.0875
2024-07-14 04:23:55,157 [INFO    ] __main__: train step 162: loss: 0.2236, policy_loss: 1.9864, value_loss: 1.0869
2024-07-14 04:23:55,437 [INFO    ] __main__: train step 163: loss: 0.2236, policy_loss: 1.9861, value_loss: 1.0864
2024-07-14 04:23:55,704 [INFO    ] __main__: train step 164: loss: 0.2237, policy_loss: 1.9859, value_loss: 1.0860
2024-07-14 04:23:55,971 [INFO    ] __main__: train step 165: loss: 0.2237, policy_loss: 1.9857, value_loss: 1.0856
2024-07-14 04:23:56,260 [INFO    ] __main__: train step 166: loss: 0.2238, policy_loss: 1.9855, value_loss: 1.0852
2024-07-14 04:23:56,523 [INFO    ] __main__: train step 167: loss: 0.2238, policy_loss: 1.9853, value_loss: 1.0849
2024-07-14 04:23:56,806 [INFO    ] __main__: train step 168: loss: 0.2238, policy_loss: 1.9850, value_loss: 1.0845
2024-07-14 04:23:57,336 [INFO    ] __main__: train step 169: loss: 0.2238, policy_loss: 1.9848, value_loss: 1.0842
2024-07-14 04:23:59,004 [INFO    ] __main__: replay_buffer size = 9216
2024-07-14 04:23:59,084 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:24:01,389 [INFO    ] __main__: train step 170: loss: 0.2239, policy_loss: 1.9846, value_loss: 1.0838
2024-07-14 04:24:01,663 [INFO    ] __main__: train step 171: loss: 0.2240, policy_loss: 1.9843, value_loss: 1.0834
2024-07-14 04:24:01,927 [INFO    ] __main__: train step 172: loss: 0.2240, policy_loss: 1.9841, value_loss: 1.0831
2024-07-14 04:24:02,192 [INFO    ] __main__: train step 173: loss: 0.2240, policy_loss: 1.9838, value_loss: 1.0828
2024-07-14 04:24:02,467 [INFO    ] __main__: train step 174: loss: 0.2240, policy_loss: 1.9836, value_loss: 1.0824
2024-07-14 04:24:02,740 [INFO    ] __main__: train step 175: loss: 0.2240, policy_loss: 1.9834, value_loss: 1.0821
2024-07-14 04:24:03,011 [INFO    ] __main__: train step 176: loss: 0.2241, policy_loss: 1.9832, value_loss: 1.0819
2024-07-14 04:24:03,278 [INFO    ] __main__: train step 177: loss: 0.2241, policy_loss: 1.9829, value_loss: 1.0814
2024-07-14 04:24:03,554 [INFO    ] __main__: train step 178: loss: 0.2242, policy_loss: 1.9827, value_loss: 1.0810
2024-07-14 04:24:03,837 [INFO    ] __main__: train step 179: loss: 0.2243, policy_loss: 1.9825, value_loss: 1.0808
2024-07-14 04:24:04,108 [INFO    ] __main__: train step 180: loss: 0.2244, policy_loss: 1.9822, value_loss: 1.0805
2024-07-14 04:24:04,367 [INFO    ] __main__: train step 181: loss: 0.2244, policy_loss: 1.9820, value_loss: 1.0803
2024-07-14 04:24:05,039 [INFO    ] __main__: train step 182: loss: 0.2245, policy_loss: 1.9817, value_loss: 1.0798
2024-07-14 04:24:05,316 [INFO    ] __main__: train step 183: loss: 0.2245, policy_loss: 1.9815, value_loss: 1.0794
2024-07-14 04:24:05,587 [INFO    ] __main__: train step 184: loss: 0.2246, policy_loss: 1.9813, value_loss: 1.0790
2024-07-14 04:24:05,858 [INFO    ] __main__: train step 185: loss: 0.2248, policy_loss: 1.9811, value_loss: 1.0785
2024-07-14 04:24:06,130 [INFO    ] __main__: train step 186: loss: 0.2248, policy_loss: 1.9809, value_loss: 1.0781
2024-07-14 04:24:07,743 [INFO    ] __main__: replay_buffer size = 9728
2024-07-14 04:24:07,824 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:24:10,206 [INFO    ] __main__: train step 187: loss: 0.2249, policy_loss: 1.9806, value_loss: 1.0778
2024-07-14 04:24:10,467 [INFO    ] __main__: train step 188: loss: 0.2250, policy_loss: 1.9804, value_loss: 1.0775
2024-07-14 04:24:10,748 [INFO    ] __main__: train step 189: loss: 0.2251, policy_loss: 1.9802, value_loss: 1.0772
2024-07-14 04:24:11,018 [INFO    ] __main__: train step 190: loss: 0.2252, policy_loss: 1.9799, value_loss: 1.0768
2024-07-14 04:24:11,265 [INFO    ] __main__: train step 191: loss: 0.2253, policy_loss: 1.9797, value_loss: 1.0765
2024-07-14 04:24:11,516 [INFO    ] __main__: train step 192: loss: 0.2253, policy_loss: 1.9795, value_loss: 1.0762
2024-07-14 04:24:11,766 [INFO    ] __main__: train step 193: loss: 0.2254, policy_loss: 1.9793, value_loss: 1.0759
2024-07-14 04:24:12,407 [INFO    ] __main__: train step 194: loss: 0.2255, policy_loss: 1.9791, value_loss: 1.0756
2024-07-14 04:24:12,676 [INFO    ] __main__: train step 195: loss: 0.2255, policy_loss: 1.9789, value_loss: 1.0754
2024-07-14 04:24:12,949 [INFO    ] __main__: train step 196: loss: 0.2256, policy_loss: 1.9786, value_loss: 1.0750
2024-07-14 04:24:13,190 [INFO    ] __main__: train step 197: loss: 0.2256, policy_loss: 1.9784, value_loss: 1.0746
2024-07-14 04:24:13,453 [INFO    ] __main__: train step 198: loss: 0.2257, policy_loss: 1.9782, value_loss: 1.0742
2024-07-14 04:24:13,741 [INFO    ] __main__: train step 199: loss: 0.2257, policy_loss: 1.9780, value_loss: 1.0739
2024-07-14 04:24:14,025 [INFO    ] __main__: train step 200: loss: 0.2259, policy_loss: 1.9779, value_loss: 1.0735
2024-07-14 04:24:14,297 [INFO    ] __main__: train step 201: loss: 0.2260, policy_loss: 1.9777, value_loss: 1.0730
2024-07-14 04:24:14,575 [INFO    ] __main__: train step 202: loss: 0.2261, policy_loss: 1.9775, value_loss: 1.0729
2024-07-14 04:24:14,852 [INFO    ] __main__: train step 203: loss: 0.2261, policy_loss: 1.9773, value_loss: 1.0725
2024-07-14 04:24:16,495 [INFO    ] __main__: replay_buffer size = 10240
2024-07-14 04:24:16,578 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:24:18,365 [INFO    ] __main__: train step 204: loss: 0.2262, policy_loss: 1.9770, value_loss: 1.0721
2024-07-14 04:24:18,645 [INFO    ] __main__: train step 205: loss: 0.2262, policy_loss: 1.9768, value_loss: 1.0718
2024-07-14 04:24:19,172 [INFO    ] __main__: train step 206: loss: 0.2263, policy_loss: 1.9766, value_loss: 1.0714
2024-07-14 04:24:19,442 [INFO    ] __main__: train step 207: loss: 0.2264, policy_loss: 1.9764, value_loss: 1.0711
2024-07-14 04:24:19,701 [INFO    ] __main__: train step 208: loss: 0.2265, policy_loss: 1.9762, value_loss: 1.0708
2024-07-14 04:24:19,981 [INFO    ] __main__: train step 209: loss: 0.2265, policy_loss: 1.9760, value_loss: 1.0705
2024-07-14 04:24:20,257 [INFO    ] __main__: train step 210: loss: 0.2266, policy_loss: 1.9757, value_loss: 1.0701
2024-07-14 04:24:20,541 [INFO    ] __main__: train step 211: loss: 0.2267, policy_loss: 1.9756, value_loss: 1.0697
2024-07-14 04:24:20,814 [INFO    ] __main__: train step 212: loss: 0.2268, policy_loss: 1.9754, value_loss: 1.0695
2024-07-14 04:24:21,081 [INFO    ] __main__: train step 213: loss: 0.2268, policy_loss: 1.9751, value_loss: 1.0692
2024-07-14 04:24:21,358 [INFO    ] __main__: train step 214: loss: 0.2270, policy_loss: 1.9749, value_loss: 1.0687
2024-07-14 04:24:21,627 [INFO    ] __main__: train step 215: loss: 0.2271, policy_loss: 1.9747, value_loss: 1.0684
2024-07-14 04:24:21,902 [INFO    ] __main__: train step 216: loss: 0.2272, policy_loss: 1.9746, value_loss: 1.0681
2024-07-14 04:24:22,181 [INFO    ] __main__: train step 217: loss: 0.2272, policy_loss: 1.9744, value_loss: 1.0678
2024-07-14 04:24:22,456 [INFO    ] __main__: train step 218: loss: 0.2273, policy_loss: 1.9742, value_loss: 1.0676
2024-07-14 04:24:22,728 [INFO    ] __main__: train step 219: loss: 0.2273, policy_loss: 1.9740, value_loss: 1.0673
2024-07-14 04:24:23,253 [INFO    ] __main__: train step 220: loss: 0.2275, policy_loss: 1.9738, value_loss: 1.0669
2024-07-14 04:24:24,855 [INFO    ] __main__: replay_buffer size = 10752
2024-07-14 04:24:24,946 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:24:27,187 [INFO    ] __main__: train step 221: loss: 0.2275, policy_loss: 1.9735, value_loss: 1.0667
2024-07-14 04:24:27,430 [INFO    ] __main__: train step 222: loss: 0.2276, policy_loss: 1.9733, value_loss: 1.0663
2024-07-14 04:24:27,682 [INFO    ] __main__: train step 223: loss: 0.2277, policy_loss: 1.9731, value_loss: 1.0661
2024-07-14 04:24:27,954 [INFO    ] __main__: train step 224: loss: 0.2278, policy_loss: 1.9729, value_loss: 1.0658
2024-07-14 04:24:28,234 [INFO    ] __main__: train step 225: loss: 0.2279, policy_loss: 1.9727, value_loss: 1.0655
2024-07-14 04:24:28,507 [INFO    ] __main__: train step 226: loss: 0.2280, policy_loss: 1.9726, value_loss: 1.0652
2024-07-14 04:24:28,790 [INFO    ] __main__: train step 227: loss: 0.2280, policy_loss: 1.9724, value_loss: 1.0650
2024-07-14 04:24:29,070 [INFO    ] __main__: train step 228: loss: 0.2281, policy_loss: 1.9722, value_loss: 1.0648
2024-07-14 04:24:29,342 [INFO    ] __main__: train step 229: loss: 0.2282, policy_loss: 1.9720, value_loss: 1.0645
2024-07-14 04:24:29,606 [INFO    ] __main__: train step 230: loss: 0.2283, policy_loss: 1.9718, value_loss: 1.0642
2024-07-14 04:24:29,885 [INFO    ] __main__: train step 231: loss: 0.2284, policy_loss: 1.9716, value_loss: 1.0640
2024-07-14 04:24:30,403 [INFO    ] __main__: train step 232: loss: 0.2285, policy_loss: 1.9714, value_loss: 1.0636
2024-07-14 04:24:30,678 [INFO    ] __main__: train step 233: loss: 0.2286, policy_loss: 1.9712, value_loss: 1.0635
2024-07-14 04:24:30,945 [INFO    ] __main__: train step 234: loss: 0.2286, policy_loss: 1.9710, value_loss: 1.0632
2024-07-14 04:24:31,222 [INFO    ] __main__: train step 235: loss: 0.2287, policy_loss: 1.9708, value_loss: 1.0629
2024-07-14 04:24:31,495 [INFO    ] __main__: train step 236: loss: 0.2288, policy_loss: 1.9706, value_loss: 1.0625
2024-07-14 04:24:31,765 [INFO    ] __main__: train step 237: loss: 0.2289, policy_loss: 1.9704, value_loss: 1.0623
2024-07-14 04:24:33,487 [INFO    ] __main__: replay_buffer size = 11264
2024-07-14 04:24:33,577 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:24:35,915 [INFO    ] __main__: train step 238: loss: 0.2290, policy_loss: 1.9703, value_loss: 1.0620
2024-07-14 04:24:36,193 [INFO    ] __main__: train step 239: loss: 0.2291, policy_loss: 1.9700, value_loss: 1.0616
2024-07-14 04:24:36,457 [INFO    ] __main__: train step 240: loss: 0.2292, policy_loss: 1.9699, value_loss: 1.0613
2024-07-14 04:24:36,737 [INFO    ] __main__: train step 241: loss: 0.2292, policy_loss: 1.9697, value_loss: 1.0611
2024-07-14 04:24:37,010 [INFO    ] __main__: train step 242: loss: 0.2293, policy_loss: 1.9695, value_loss: 1.0607
2024-07-14 04:24:37,283 [INFO    ] __main__: train step 243: loss: 0.2294, policy_loss: 1.9693, value_loss: 1.0604
2024-07-14 04:24:37,554 [INFO    ] __main__: train step 244: loss: 0.2295, policy_loss: 1.9692, value_loss: 1.0601
2024-07-14 04:24:38,065 [INFO    ] __main__: train step 245: loss: 0.2295, policy_loss: 1.9690, value_loss: 1.0599
2024-07-14 04:24:38,362 [INFO    ] __main__: train step 246: loss: 0.2296, policy_loss: 1.9688, value_loss: 1.0596
2024-07-14 04:24:38,632 [INFO    ] __main__: train step 247: loss: 0.2297, policy_loss: 1.9687, value_loss: 1.0593
2024-07-14 04:24:38,916 [INFO    ] __main__: train step 248: loss: 0.2298, policy_loss: 1.9685, value_loss: 1.0591
2024-07-14 04:24:39,209 [INFO    ] __main__: train step 249: loss: 0.2298, policy_loss: 1.9683, value_loss: 1.0589
2024-07-14 04:24:39,484 [INFO    ] __main__: train step 250: loss: 0.2299, policy_loss: 1.9681, value_loss: 1.0587
2024-07-14 04:24:39,763 [INFO    ] __main__: train step 251: loss: 0.2300, policy_loss: 1.9679, value_loss: 1.0585
2024-07-14 04:24:40,044 [INFO    ] __main__: train step 252: loss: 0.2300, policy_loss: 1.9677, value_loss: 1.0582
2024-07-14 04:24:40,315 [INFO    ] __main__: train step 253: loss: 0.2302, policy_loss: 1.9675, value_loss: 1.0579
2024-07-14 04:24:40,581 [INFO    ] __main__: train step 254: loss: 0.2303, policy_loss: 1.9674, value_loss: 1.0577
2024-07-14 04:24:42,213 [INFO    ] __main__: replay_buffer size = 11776
2024-07-14 04:24:42,309 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:24:44,657 [INFO    ] __main__: train step 255: loss: 0.2304, policy_loss: 1.9672, value_loss: 1.0576
2024-07-14 04:24:44,925 [INFO    ] __main__: train step 256: loss: 0.2305, policy_loss: 1.9670, value_loss: 1.0572
2024-07-14 04:24:45,195 [INFO    ] __main__: train step 257: loss: 0.2306, policy_loss: 1.9668, value_loss: 1.0571
2024-07-14 04:24:45,470 [INFO    ] __main__: train step 258: loss: 0.2306, policy_loss: 1.9666, value_loss: 1.0568
2024-07-14 04:24:46,189 [INFO    ] __main__: train step 259: loss: 0.2307, policy_loss: 1.9665, value_loss: 1.0567
2024-07-14 04:24:46,462 [INFO    ] __main__: train step 260: loss: 0.2308, policy_loss: 1.9663, value_loss: 1.0564
2024-07-14 04:24:46,741 [INFO    ] __main__: train step 261: loss: 0.2309, policy_loss: 1.9661, value_loss: 1.0561
2024-07-14 04:24:47,014 [INFO    ] __main__: train step 262: loss: 0.2309, policy_loss: 1.9659, value_loss: 1.0559
2024-07-14 04:24:47,289 [INFO    ] __main__: train step 263: loss: 0.2310, policy_loss: 1.9657, value_loss: 1.0556
2024-07-14 04:24:47,569 [INFO    ] __main__: train step 264: loss: 0.2311, policy_loss: 1.9656, value_loss: 1.0554
2024-07-14 04:24:47,849 [INFO    ] __main__: train step 265: loss: 0.2312, policy_loss: 1.9654, value_loss: 1.0550
2024-07-14 04:24:48,124 [INFO    ] __main__: train step 266: loss: 0.2313, policy_loss: 1.9652, value_loss: 1.0548
2024-07-14 04:24:48,405 [INFO    ] __main__: train step 267: loss: 0.2313, policy_loss: 1.9650, value_loss: 1.0545
2024-07-14 04:24:48,682 [INFO    ] __main__: train step 268: loss: 0.2314, policy_loss: 1.9649, value_loss: 1.0544
2024-07-14 04:24:48,952 [INFO    ] __main__: train step 269: loss: 0.2315, policy_loss: 1.9647, value_loss: 1.0542
2024-07-14 04:24:49,224 [INFO    ] __main__: train step 270: loss: 0.2316, policy_loss: 1.9645, value_loss: 1.0540
2024-07-14 04:24:49,499 [INFO    ] __main__: train step 271: loss: 0.2317, policy_loss: 1.9643, value_loss: 1.0536
2024-07-14 04:24:51,137 [INFO    ] __main__: replay_buffer size = 12288
2024-07-14 04:24:51,238 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:24:53,445 [INFO    ] __main__: train step 272: loss: 0.2319, policy_loss: 1.9642, value_loss: 1.0534
2024-07-14 04:24:53,723 [INFO    ] __main__: train step 273: loss: 0.2320, policy_loss: 1.9640, value_loss: 1.0531
2024-07-14 04:24:53,995 [INFO    ] __main__: train step 274: loss: 0.2321, policy_loss: 1.9638, value_loss: 1.0528
2024-07-14 04:24:54,261 [INFO    ] __main__: train step 275: loss: 0.2322, policy_loss: 1.9636, value_loss: 1.0525
2024-07-14 04:24:54,530 [INFO    ] __main__: train step 276: loss: 0.2323, policy_loss: 1.9634, value_loss: 1.0523
2024-07-14 04:24:54,809 [INFO    ] __main__: train step 277: loss: 0.2324, policy_loss: 1.9633, value_loss: 1.0521
2024-07-14 04:24:55,083 [INFO    ] __main__: train step 278: loss: 0.2325, policy_loss: 1.9631, value_loss: 1.0519
2024-07-14 04:24:55,353 [INFO    ] __main__: train step 279: loss: 0.2326, policy_loss: 1.9630, value_loss: 1.0516
2024-07-14 04:24:55,622 [INFO    ] __main__: train step 280: loss: 0.2327, policy_loss: 1.9628, value_loss: 1.0514
2024-07-14 04:24:55,892 [INFO    ] __main__: train step 281: loss: 0.2329, policy_loss: 1.9626, value_loss: 1.0510
2024-07-14 04:24:56,174 [INFO    ] __main__: train step 282: loss: 0.2330, policy_loss: 1.9625, value_loss: 1.0508
2024-07-14 04:24:56,450 [INFO    ] __main__: train step 283: loss: 0.2331, policy_loss: 1.9623, value_loss: 1.0505
2024-07-14 04:24:56,728 [INFO    ] __main__: train step 284: loss: 0.2332, policy_loss: 1.9621, value_loss: 1.0502
2024-07-14 04:24:56,990 [INFO    ] __main__: train step 285: loss: 0.2333, policy_loss: 1.9620, value_loss: 1.0500
2024-07-14 04:24:57,608 [INFO    ] __main__: train step 286: loss: 0.2333, policy_loss: 1.9618, value_loss: 1.0497
2024-07-14 04:24:57,886 [INFO    ] __main__: train step 287: loss: 0.2334, policy_loss: 1.9617, value_loss: 1.0496
2024-07-14 04:24:58,154 [INFO    ] __main__: train step 288: loss: 0.2335, policy_loss: 1.9615, value_loss: 1.0494
2024-07-14 04:24:59,788 [INFO    ] __main__: replay_buffer size = 12800
2024-07-14 04:24:59,892 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:25:02,149 [INFO    ] __main__: train step 289: loss: 0.2335, policy_loss: 1.9613, value_loss: 1.0491
2024-07-14 04:25:02,424 [INFO    ] __main__: train step 290: loss: 0.2336, policy_loss: 1.9612, value_loss: 1.0489
2024-07-14 04:25:02,697 [INFO    ] __main__: train step 291: loss: 0.2337, policy_loss: 1.9610, value_loss: 1.0487
2024-07-14 04:25:02,969 [INFO    ] __main__: train step 292: loss: 0.2338, policy_loss: 1.9609, value_loss: 1.0484
2024-07-14 04:25:03,262 [INFO    ] __main__: train step 293: loss: 0.2338, policy_loss: 1.9608, value_loss: 1.0481
2024-07-14 04:25:03,537 [INFO    ] __main__: train step 294: loss: 0.2339, policy_loss: 1.9606, value_loss: 1.0479
2024-07-14 04:25:03,812 [INFO    ] __main__: train step 295: loss: 0.2340, policy_loss: 1.9604, value_loss: 1.0476
2024-07-14 04:25:04,094 [INFO    ] __main__: train step 296: loss: 0.2341, policy_loss: 1.9603, value_loss: 1.0474
2024-07-14 04:25:04,362 [INFO    ] __main__: train step 297: loss: 0.2341, policy_loss: 1.9601, value_loss: 1.0472
2024-07-14 04:25:05,098 [INFO    ] __main__: train step 298: loss: 0.2342, policy_loss: 1.9600, value_loss: 1.0469
2024-07-14 04:25:05,376 [INFO    ] __main__: train step 299: loss: 0.2343, policy_loss: 1.9598, value_loss: 1.0467
2024-07-14 04:25:05,647 [INFO    ] __main__: train step 300: loss: 0.2344, policy_loss: 1.9597, value_loss: 1.0465
2024-07-14 04:25:05,931 [INFO    ] __main__: train step 301: loss: 0.2345, policy_loss: 1.9595, value_loss: 1.0463
2024-07-14 04:25:06,212 [INFO    ] __main__: train step 302: loss: 0.2346, policy_loss: 1.9593, value_loss: 1.0460
2024-07-14 04:25:06,476 [INFO    ] __main__: train step 303: loss: 0.2347, policy_loss: 1.9592, value_loss: 1.0458
2024-07-14 04:25:06,751 [INFO    ] __main__: train step 304: loss: 0.2347, policy_loss: 1.9590, value_loss: 1.0456
2024-07-14 04:25:07,041 [INFO    ] __main__: train step 305: loss: 0.2348, policy_loss: 1.9589, value_loss: 1.0453
2024-07-14 04:25:08,713 [INFO    ] __main__: replay_buffer size = 13312
2024-07-14 04:25:08,823 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:25:11,105 [INFO    ] __main__: train step 306: loss: 0.2349, policy_loss: 1.9587, value_loss: 1.0451
2024-07-14 04:25:11,378 [INFO    ] __main__: train step 307: loss: 0.2350, policy_loss: 1.9586, value_loss: 1.0449
2024-07-14 04:25:11,663 [INFO    ] __main__: train step 308: loss: 0.2352, policy_loss: 1.9584, value_loss: 1.0446
2024-07-14 04:25:11,939 [INFO    ] __main__: train step 309: loss: 0.2352, policy_loss: 1.9583, value_loss: 1.0444
2024-07-14 04:25:12,212 [INFO    ] __main__: train step 310: loss: 0.2353, policy_loss: 1.9581, value_loss: 1.0442
2024-07-14 04:25:12,723 [INFO    ] __main__: train step 311: loss: 0.2354, policy_loss: 1.9580, value_loss: 1.0439
2024-07-14 04:25:13,000 [INFO    ] __main__: train step 312: loss: 0.2355, policy_loss: 1.9578, value_loss: 1.0437
2024-07-14 04:25:13,284 [INFO    ] __main__: train step 313: loss: 0.2356, policy_loss: 1.9576, value_loss: 1.0436
2024-07-14 04:25:13,562 [INFO    ] __main__: train step 314: loss: 0.2356, policy_loss: 1.9575, value_loss: 1.0433
2024-07-14 04:25:13,827 [INFO    ] __main__: train step 315: loss: 0.2357, policy_loss: 1.9573, value_loss: 1.0431
2024-07-14 04:25:14,103 [INFO    ] __main__: train step 316: loss: 0.2358, policy_loss: 1.9572, value_loss: 1.0429
2024-07-14 04:25:14,377 [INFO    ] __main__: train step 317: loss: 0.2359, policy_loss: 1.9570, value_loss: 1.0426
2024-07-14 04:25:14,649 [INFO    ] __main__: train step 318: loss: 0.2360, policy_loss: 1.9569, value_loss: 1.0424
2024-07-14 04:25:14,928 [INFO    ] __main__: train step 319: loss: 0.2361, policy_loss: 1.9568, value_loss: 1.0422
2024-07-14 04:25:15,189 [INFO    ] __main__: train step 320: loss: 0.2362, policy_loss: 1.9566, value_loss: 1.0419
2024-07-14 04:25:15,455 [INFO    ] __main__: train step 321: loss: 0.2363, policy_loss: 1.9564, value_loss: 1.0417
2024-07-14 04:25:15,719 [INFO    ] __main__: train step 322: loss: 0.2364, policy_loss: 1.9563, value_loss: 1.0415
2024-07-14 04:25:17,325 [INFO    ] __main__: replay_buffer size = 13824
2024-07-14 04:25:17,432 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:25:19,689 [INFO    ] __main__: train step 323: loss: 0.2364, policy_loss: 1.9561, value_loss: 1.0413
2024-07-14 04:25:19,970 [INFO    ] __main__: train step 324: loss: 0.2365, policy_loss: 1.9560, value_loss: 1.0410
2024-07-14 04:25:20,473 [INFO    ] __main__: train step 325: loss: 0.2366, policy_loss: 1.9558, value_loss: 1.0408
2024-07-14 04:25:20,741 [INFO    ] __main__: train step 326: loss: 0.2367, policy_loss: 1.9557, value_loss: 1.0407
2024-07-14 04:25:21,016 [INFO    ] __main__: train step 327: loss: 0.2368, policy_loss: 1.9556, value_loss: 1.0404
2024-07-14 04:25:21,299 [INFO    ] __main__: train step 328: loss: 0.2369, policy_loss: 1.9554, value_loss: 1.0403
2024-07-14 04:25:21,570 [INFO    ] __main__: train step 329: loss: 0.2370, policy_loss: 1.9553, value_loss: 1.0400
2024-07-14 04:25:21,845 [INFO    ] __main__: train step 330: loss: 0.2370, policy_loss: 1.9551, value_loss: 1.0398
2024-07-14 04:25:22,121 [INFO    ] __main__: train step 331: loss: 0.2372, policy_loss: 1.9550, value_loss: 1.0396
2024-07-14 04:25:22,401 [INFO    ] __main__: train step 332: loss: 0.2372, policy_loss: 1.9548, value_loss: 1.0394
2024-07-14 04:25:22,677 [INFO    ] __main__: train step 333: loss: 0.2373, policy_loss: 1.9547, value_loss: 1.0392
2024-07-14 04:25:22,962 [INFO    ] __main__: train step 334: loss: 0.2374, policy_loss: 1.9545, value_loss: 1.0390
2024-07-14 04:25:23,271 [INFO    ] __main__: train step 335: loss: 0.2375, policy_loss: 1.9544, value_loss: 1.0388
2024-07-14 04:25:23,560 [INFO    ] __main__: train step 336: loss: 0.2376, policy_loss: 1.9543, value_loss: 1.0386
2024-07-14 04:25:23,837 [INFO    ] __main__: train step 337: loss: 0.2377, policy_loss: 1.9541, value_loss: 1.0385
2024-07-14 04:25:24,113 [INFO    ] __main__: train step 338: loss: 0.2378, policy_loss: 1.9540, value_loss: 1.0383
2024-07-14 04:25:24,631 [INFO    ] __main__: train step 339: loss: 0.2378, policy_loss: 1.9539, value_loss: 1.0381
2024-07-14 04:25:26,238 [INFO    ] __main__: replay_buffer size = 14336
2024-07-14 04:25:26,344 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:25:28,088 [INFO    ] __main__: train step 340: loss: 0.2379, policy_loss: 1.9537, value_loss: 1.0379
2024-07-14 04:25:28,365 [INFO    ] __main__: train step 341: loss: 0.2380, policy_loss: 1.9536, value_loss: 1.0378
2024-07-14 04:25:28,645 [INFO    ] __main__: train step 342: loss: 0.2381, policy_loss: 1.9535, value_loss: 1.0376
2024-07-14 04:25:28,925 [INFO    ] __main__: train step 343: loss: 0.2382, policy_loss: 1.9534, value_loss: 1.0374
2024-07-14 04:25:29,202 [INFO    ] __main__: train step 344: loss: 0.2382, policy_loss: 1.9532, value_loss: 1.0372
2024-07-14 04:25:29,496 [INFO    ] __main__: train step 345: loss: 0.2383, policy_loss: 1.9531, value_loss: 1.0371
2024-07-14 04:25:29,786 [INFO    ] __main__: train step 346: loss: 0.2384, policy_loss: 1.9529, value_loss: 1.0369
2024-07-14 04:25:30,059 [INFO    ] __main__: train step 347: loss: 0.2385, policy_loss: 1.9528, value_loss: 1.0367
2024-07-14 04:25:30,333 [INFO    ] __main__: train step 348: loss: 0.2387, policy_loss: 1.9527, value_loss: 1.0365
2024-07-14 04:25:30,606 [INFO    ] __main__: train step 349: loss: 0.2387, policy_loss: 1.9525, value_loss: 1.0364
2024-07-14 04:25:30,881 [INFO    ] __main__: train step 350: loss: 0.2388, policy_loss: 1.9524, value_loss: 1.0363
2024-07-14 04:25:31,166 [INFO    ] __main__: train step 351: loss: 0.2389, policy_loss: 1.9523, value_loss: 1.0361
2024-07-14 04:25:31,824 [INFO    ] __main__: train step 352: loss: 0.2389, policy_loss: 1.9521, value_loss: 1.0359
2024-07-14 04:25:32,113 [INFO    ] __main__: train step 353: loss: 0.2390, policy_loss: 1.9520, value_loss: 1.0357
2024-07-14 04:25:32,390 [INFO    ] __main__: train step 354: loss: 0.2391, policy_loss: 1.9518, value_loss: 1.0355
2024-07-14 04:25:32,666 [INFO    ] __main__: train step 355: loss: 0.2392, policy_loss: 1.9517, value_loss: 1.0353
2024-07-14 04:25:32,914 [INFO    ] __main__: train step 356: loss: 0.2393, policy_loss: 1.9516, value_loss: 1.0351
2024-07-14 04:25:34,557 [INFO    ] __main__: replay_buffer size = 14848
2024-07-14 04:25:34,663 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:25:36,954 [INFO    ] __main__: train step 357: loss: 0.2394, policy_loss: 1.9514, value_loss: 1.0349
2024-07-14 04:25:37,225 [INFO    ] __main__: train step 358: loss: 0.2395, policy_loss: 1.9513, value_loss: 1.0347
2024-07-14 04:25:37,505 [INFO    ] __main__: train step 359: loss: 0.2396, policy_loss: 1.9512, value_loss: 1.0346
2024-07-14 04:25:37,779 [INFO    ] __main__: train step 360: loss: 0.2397, policy_loss: 1.9511, value_loss: 1.0344
2024-07-14 04:25:38,064 [INFO    ] __main__: train step 361: loss: 0.2399, policy_loss: 1.9509, value_loss: 1.0341
2024-07-14 04:25:38,347 [INFO    ] __main__: train step 362: loss: 0.2400, policy_loss: 1.9508, value_loss: 1.0339
2024-07-14 04:25:38,619 [INFO    ] __main__: train step 363: loss: 0.2401, policy_loss: 1.9507, value_loss: 1.0338
2024-07-14 04:25:38,894 [INFO    ] __main__: train step 364: loss: 0.2402, policy_loss: 1.9505, value_loss: 1.0336
2024-07-14 04:25:39,173 [INFO    ] __main__: train step 365: loss: 0.2403, policy_loss: 1.9504, value_loss: 1.0335
2024-07-14 04:25:39,885 [INFO    ] __main__: train step 366: loss: 0.2404, policy_loss: 1.9503, value_loss: 1.0333
2024-07-14 04:25:40,164 [INFO    ] __main__: train step 367: loss: 0.2405, policy_loss: 1.9501, value_loss: 1.0331
2024-07-14 04:25:40,442 [INFO    ] __main__: train step 368: loss: 0.2406, policy_loss: 1.9500, value_loss: 1.0329
2024-07-14 04:25:40,729 [INFO    ] __main__: train step 369: loss: 0.2407, policy_loss: 1.9499, value_loss: 1.0327
2024-07-14 04:25:41,004 [INFO    ] __main__: train step 370: loss: 0.2408, policy_loss: 1.9498, value_loss: 1.0325
2024-07-14 04:25:41,291 [INFO    ] __main__: train step 371: loss: 0.2409, policy_loss: 1.9496, value_loss: 1.0323
2024-07-14 04:25:41,563 [INFO    ] __main__: train step 372: loss: 0.2410, policy_loss: 1.9495, value_loss: 1.0322
2024-07-14 04:25:41,835 [INFO    ] __main__: train step 373: loss: 0.2411, policy_loss: 1.9494, value_loss: 1.0320
2024-07-14 04:25:43,496 [INFO    ] __main__: replay_buffer size = 15360
2024-07-14 04:25:43,619 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:25:45,851 [INFO    ] __main__: train step 374: loss: 0.2412, policy_loss: 1.9492, value_loss: 1.0318
2024-07-14 04:25:46,119 [INFO    ] __main__: train step 375: loss: 0.2413, policy_loss: 1.9491, value_loss: 1.0318
2024-07-14 04:25:46,385 [INFO    ] __main__: train step 376: loss: 0.2414, policy_loss: 1.9490, value_loss: 1.0316
2024-07-14 04:25:46,645 [INFO    ] __main__: train step 377: loss: 0.2415, policy_loss: 1.9489, value_loss: 1.0314
2024-07-14 04:25:46,903 [INFO    ] __main__: train step 378: loss: 0.2417, policy_loss: 1.9487, value_loss: 1.0311
2024-07-14 04:25:47,422 [INFO    ] __main__: train step 379: loss: 0.2417, policy_loss: 1.9486, value_loss: 1.0310
2024-07-14 04:25:47,690 [INFO    ] __main__: train step 380: loss: 0.2418, policy_loss: 1.9485, value_loss: 1.0307
2024-07-14 04:25:47,968 [INFO    ] __main__: train step 381: loss: 0.2419, policy_loss: 1.9483, value_loss: 1.0306
2024-07-14 04:25:48,242 [INFO    ] __main__: train step 382: loss: 0.2421, policy_loss: 1.9482, value_loss: 1.0305
2024-07-14 04:25:48,518 [INFO    ] __main__: train step 383: loss: 0.2422, policy_loss: 1.9481, value_loss: 1.0303
2024-07-14 04:25:48,795 [INFO    ] __main__: train step 384: loss: 0.2423, policy_loss: 1.9480, value_loss: 1.0301
2024-07-14 04:25:49,063 [INFO    ] __main__: train step 385: loss: 0.2424, policy_loss: 1.9478, value_loss: 1.0298
2024-07-14 04:25:49,340 [INFO    ] __main__: train step 386: loss: 0.2425, policy_loss: 1.9477, value_loss: 1.0296
2024-07-14 04:25:49,624 [INFO    ] __main__: train step 387: loss: 0.2425, policy_loss: 1.9476, value_loss: 1.0294
2024-07-14 04:25:49,899 [INFO    ] __main__: train step 388: loss: 0.2427, policy_loss: 1.9474, value_loss: 1.0292
2024-07-14 04:25:50,171 [INFO    ] __main__: train step 389: loss: 0.2427, policy_loss: 1.9473, value_loss: 1.0291
2024-07-14 04:25:50,447 [INFO    ] __main__: train step 390: loss: 0.2428, policy_loss: 1.9472, value_loss: 1.0290
2024-07-14 04:25:52,124 [INFO    ] __main__: replay_buffer size = 15872
2024-07-14 04:25:52,252 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:25:54,466 [INFO    ] __main__: train step 391: loss: 0.2429, policy_loss: 1.9471, value_loss: 1.0288
2024-07-14 04:25:54,991 [INFO    ] __main__: train step 392: loss: 0.2430, policy_loss: 1.9470, value_loss: 1.0287
2024-07-14 04:25:55,260 [INFO    ] __main__: train step 393: loss: 0.2432, policy_loss: 1.9468, value_loss: 1.0286
2024-07-14 04:25:55,529 [INFO    ] __main__: train step 394: loss: 0.2432, policy_loss: 1.9467, value_loss: 1.0284
2024-07-14 04:25:55,806 [INFO    ] __main__: train step 395: loss: 0.2433, policy_loss: 1.9465, value_loss: 1.0282
2024-07-14 04:25:56,088 [INFO    ] __main__: train step 396: loss: 0.2434, policy_loss: 1.9464, value_loss: 1.0280
2024-07-14 04:25:56,372 [INFO    ] __main__: train step 397: loss: 0.2435, policy_loss: 1.9463, value_loss: 1.0279
2024-07-14 04:25:56,650 [INFO    ] __main__: train step 398: loss: 0.2437, policy_loss: 1.9462, value_loss: 1.0277
2024-07-14 04:25:56,909 [INFO    ] __main__: train step 399: loss: 0.2438, policy_loss: 1.9460, value_loss: 1.0275
2024-07-14 04:25:57,170 [INFO    ] __main__: train step 400: loss: 0.2439, policy_loss: 1.9459, value_loss: 1.0275
2024-07-14 04:25:57,416 [INFO    ] __main__: train step 401: loss: 0.2440, policy_loss: 1.9458, value_loss: 1.0274
2024-07-14 04:25:57,686 [INFO    ] __main__: train step 402: loss: 0.2441, policy_loss: 1.9457, value_loss: 1.0273
2024-07-14 04:25:57,965 [INFO    ] __main__: train step 403: loss: 0.2442, policy_loss: 1.9455, value_loss: 1.0271
2024-07-14 04:25:58,235 [INFO    ] __main__: train step 404: loss: 0.2443, policy_loss: 1.9454, value_loss: 1.0270
2024-07-14 04:25:58,494 [INFO    ] __main__: train step 405: loss: 0.2444, policy_loss: 1.9453, value_loss: 1.0268
2024-07-14 04:25:59,064 [INFO    ] __main__: train step 406: loss: 0.2445, policy_loss: 1.9452, value_loss: 1.0267
2024-07-14 04:25:59,341 [INFO    ] __main__: train step 407: loss: 0.2446, policy_loss: 1.9451, value_loss: 1.0265
2024-07-14 04:26:01,007 [INFO    ] __main__: replay_buffer size = 16384
2024-07-14 04:26:01,139 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:26:02,880 [INFO    ] __main__: train step 408: loss: 0.2447, policy_loss: 1.9449, value_loss: 1.0264
2024-07-14 04:26:03,166 [INFO    ] __main__: train step 409: loss: 0.2448, policy_loss: 1.9448, value_loss: 1.0262
2024-07-14 04:26:03,449 [INFO    ] __main__: train step 410: loss: 0.2448, policy_loss: 1.9447, value_loss: 1.0261
2024-07-14 04:26:03,730 [INFO    ] __main__: train step 411: loss: 0.2450, policy_loss: 1.9446, value_loss: 1.0260
2024-07-14 04:26:03,996 [INFO    ] __main__: train step 412: loss: 0.2451, policy_loss: 1.9445, value_loss: 1.0258
2024-07-14 04:26:04,268 [INFO    ] __main__: train step 413: loss: 0.2452, policy_loss: 1.9444, value_loss: 1.0256
2024-07-14 04:26:04,535 [INFO    ] __main__: train step 414: loss: 0.2453, policy_loss: 1.9443, value_loss: 1.0255
2024-07-14 04:26:04,810 [INFO    ] __main__: train step 415: loss: 0.2454, policy_loss: 1.9442, value_loss: 1.0254
2024-07-14 04:26:05,078 [INFO    ] __main__: train step 416: loss: 0.2455, policy_loss: 1.9440, value_loss: 1.0252
2024-07-14 04:26:05,380 [INFO    ] __main__: train step 417: loss: 0.2457, policy_loss: 1.9439, value_loss: 1.0251
2024-07-14 04:26:06,085 [INFO    ] __main__: train step 418: loss: 0.2458, policy_loss: 1.9438, value_loss: 1.0249
2024-07-14 04:26:06,352 [INFO    ] __main__: train step 419: loss: 0.2459, policy_loss: 1.9437, value_loss: 1.0248
2024-07-14 04:26:06,609 [INFO    ] __main__: train step 420: loss: 0.2461, policy_loss: 1.9436, value_loss: 1.0246
2024-07-14 04:26:06,868 [INFO    ] __main__: train step 421: loss: 0.2461, policy_loss: 1.9435, value_loss: 1.0245
2024-07-14 04:26:07,131 [INFO    ] __main__: train step 422: loss: 0.2463, policy_loss: 1.9434, value_loss: 1.0244
2024-07-14 04:26:07,401 [INFO    ] __main__: train step 423: loss: 0.2464, policy_loss: 1.9433, value_loss: 1.0242
2024-07-14 04:26:07,656 [INFO    ] __main__: train step 424: loss: 0.2465, policy_loss: 1.9432, value_loss: 1.0241
2024-07-14 04:26:09,263 [INFO    ] __main__: replay_buffer size = 16896
2024-07-14 04:26:09,385 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:26:11,679 [INFO    ] __main__: train step 425: loss: 0.2466, policy_loss: 1.9431, value_loss: 1.0239
2024-07-14 04:26:11,969 [INFO    ] __main__: train step 426: loss: 0.2467, policy_loss: 1.9430, value_loss: 1.0238
2024-07-14 04:26:12,233 [INFO    ] __main__: train step 427: loss: 0.2468, policy_loss: 1.9428, value_loss: 1.0236
2024-07-14 04:26:12,503 [INFO    ] __main__: train step 428: loss: 0.2469, policy_loss: 1.9427, value_loss: 1.0235
2024-07-14 04:26:12,786 [INFO    ] __main__: train step 429: loss: 0.2470, policy_loss: 1.9426, value_loss: 1.0234
2024-07-14 04:26:13,064 [INFO    ] __main__: train step 430: loss: 0.2472, policy_loss: 1.9425, value_loss: 1.0233
2024-07-14 04:26:13,335 [INFO    ] __main__: train step 431: loss: 0.2473, policy_loss: 1.9424, value_loss: 1.0232
2024-07-14 04:26:13,865 [INFO    ] __main__: train step 432: loss: 0.2474, policy_loss: 1.9423, value_loss: 1.0231
2024-07-14 04:26:14,131 [INFO    ] __main__: train step 433: loss: 0.2475, policy_loss: 1.9422, value_loss: 1.0229
2024-07-14 04:26:14,405 [INFO    ] __main__: train step 434: loss: 0.2476, policy_loss: 1.9421, value_loss: 1.0227
2024-07-14 04:26:14,681 [INFO    ] __main__: train step 435: loss: 0.2477, policy_loss: 1.9419, value_loss: 1.0225
2024-07-14 04:26:14,957 [INFO    ] __main__: train step 436: loss: 0.2478, policy_loss: 1.9418, value_loss: 1.0223
2024-07-14 04:26:15,231 [INFO    ] __main__: train step 437: loss: 0.2480, policy_loss: 1.9417, value_loss: 1.0222
2024-07-14 04:26:15,502 [INFO    ] __main__: train step 438: loss: 0.2481, policy_loss: 1.9416, value_loss: 1.0221
2024-07-14 04:26:15,774 [INFO    ] __main__: train step 439: loss: 0.2482, policy_loss: 1.9415, value_loss: 1.0219
2024-07-14 04:26:16,046 [INFO    ] __main__: train step 440: loss: 0.2483, policy_loss: 1.9414, value_loss: 1.0218
2024-07-14 04:26:16,321 [INFO    ] __main__: train step 441: loss: 0.2484, policy_loss: 1.9412, value_loss: 1.0216
2024-07-14 04:26:18,025 [INFO    ] __main__: replay_buffer size = 17408
2024-07-14 04:26:18,150 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:26:20,466 [INFO    ] __main__: train step 442: loss: 0.2485, policy_loss: 1.9411, value_loss: 1.0215
2024-07-14 04:26:20,741 [INFO    ] __main__: train step 443: loss: 0.2486, policy_loss: 1.9410, value_loss: 1.0214
2024-07-14 04:26:21,017 [INFO    ] __main__: train step 444: loss: 0.2487, policy_loss: 1.9409, value_loss: 1.0212
2024-07-14 04:26:21,296 [INFO    ] __main__: train step 445: loss: 0.2488, policy_loss: 1.9408, value_loss: 1.0211
2024-07-14 04:26:22,015 [INFO    ] __main__: train step 446: loss: 0.2489, policy_loss: 1.9407, value_loss: 1.0210
2024-07-14 04:26:22,292 [INFO    ] __main__: train step 447: loss: 0.2490, policy_loss: 1.9406, value_loss: 1.0209
2024-07-14 04:26:22,564 [INFO    ] __main__: train step 448: loss: 0.2491, policy_loss: 1.9405, value_loss: 1.0208
2024-07-14 04:26:22,847 [INFO    ] __main__: train step 449: loss: 0.2492, policy_loss: 1.9404, value_loss: 1.0207
2024-07-14 04:26:23,121 [INFO    ] __main__: train step 450: loss: 0.2493, policy_loss: 1.9403, value_loss: 1.0205
2024-07-14 04:26:23,390 [INFO    ] __main__: train step 451: loss: 0.2494, policy_loss: 1.9402, value_loss: 1.0204
2024-07-14 04:26:23,672 [INFO    ] __main__: train step 452: loss: 0.2495, policy_loss: 1.9400, value_loss: 1.0203
2024-07-14 04:26:23,941 [INFO    ] __main__: train step 453: loss: 0.2496, policy_loss: 1.9399, value_loss: 1.0201
2024-07-14 04:26:24,215 [INFO    ] __main__: train step 454: loss: 0.2497, policy_loss: 1.9398, value_loss: 1.0199
2024-07-14 04:26:24,488 [INFO    ] __main__: train step 455: loss: 0.2499, policy_loss: 1.9397, value_loss: 1.0198
2024-07-14 04:26:24,755 [INFO    ] __main__: train step 456: loss: 0.2500, policy_loss: 1.9396, value_loss: 1.0196
2024-07-14 04:26:25,020 [INFO    ] __main__: train step 457: loss: 0.2501, policy_loss: 1.9395, value_loss: 1.0195
2024-07-14 04:26:25,294 [INFO    ] __main__: train step 458: loss: 0.2503, policy_loss: 1.9394, value_loss: 1.0193
2024-07-14 04:26:26,911 [INFO    ] __main__: replay_buffer size = 17920
2024-07-14 04:26:27,050 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:26:29,407 [INFO    ] __main__: train step 459: loss: 0.2504, policy_loss: 1.9393, value_loss: 1.0192
2024-07-14 04:26:30,133 [INFO    ] __main__: train step 460: loss: 0.2505, policy_loss: 1.9392, value_loss: 1.0190
2024-07-14 04:26:30,411 [INFO    ] __main__: train step 461: loss: 0.2506, policy_loss: 1.9391, value_loss: 1.0189
2024-07-14 04:26:30,697 [INFO    ] __main__: train step 462: loss: 0.2507, policy_loss: 1.9390, value_loss: 1.0188
2024-07-14 04:26:30,968 [INFO    ] __main__: train step 463: loss: 0.2509, policy_loss: 1.9389, value_loss: 1.0187
2024-07-14 04:26:31,242 [INFO    ] __main__: train step 464: loss: 0.2510, policy_loss: 1.9388, value_loss: 1.0186
2024-07-14 04:26:31,516 [INFO    ] __main__: train step 465: loss: 0.2511, policy_loss: 1.9387, value_loss: 1.0184
2024-07-14 04:26:31,789 [INFO    ] __main__: train step 466: loss: 0.2512, policy_loss: 1.9386, value_loss: 1.0183
2024-07-14 04:26:32,077 [INFO    ] __main__: train step 467: loss: 0.2513, policy_loss: 1.9385, value_loss: 1.0182
2024-07-14 04:26:32,342 [INFO    ] __main__: train step 468: loss: 0.2514, policy_loss: 1.9384, value_loss: 1.0181
2024-07-14 04:26:32,618 [INFO    ] __main__: train step 469: loss: 0.2515, policy_loss: 1.9383, value_loss: 1.0179
2024-07-14 04:26:32,886 [INFO    ] __main__: train step 470: loss: 0.2516, policy_loss: 1.9382, value_loss: 1.0178
2024-07-14 04:26:33,148 [INFO    ] __main__: train step 471: loss: 0.2517, policy_loss: 1.9380, value_loss: 1.0177
2024-07-14 04:26:33,443 [INFO    ] __main__: train step 472: loss: 0.2518, policy_loss: 1.9380, value_loss: 1.0176
2024-07-14 04:26:33,710 [INFO    ] __main__: train step 473: loss: 0.2519, policy_loss: 1.9378, value_loss: 1.0175
2024-07-14 04:26:34,451 [INFO    ] __main__: train step 474: loss: 0.2520, policy_loss: 1.9377, value_loss: 1.0173
2024-07-14 04:26:34,731 [INFO    ] __main__: train step 475: loss: 0.2521, policy_loss: 1.9376, value_loss: 1.0172
2024-07-14 04:26:36,404 [INFO    ] __main__: replay_buffer size = 18432
2024-07-14 04:26:36,531 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:26:38,318 [INFO    ] __main__: train step 476: loss: 0.2523, policy_loss: 1.9375, value_loss: 1.0171
2024-07-14 04:26:38,598 [INFO    ] __main__: train step 477: loss: 0.2524, policy_loss: 1.9375, value_loss: 1.0169
2024-07-14 04:26:38,879 [INFO    ] __main__: train step 478: loss: 0.2525, policy_loss: 1.9373, value_loss: 1.0168
2024-07-14 04:26:39,151 [INFO    ] __main__: train step 479: loss: 0.2527, policy_loss: 1.9372, value_loss: 1.0167
2024-07-14 04:26:39,414 [INFO    ] __main__: train step 480: loss: 0.2528, policy_loss: 1.9371, value_loss: 1.0166
2024-07-14 04:26:39,689 [INFO    ] __main__: train step 481: loss: 0.2529, policy_loss: 1.9370, value_loss: 1.0165
2024-07-14 04:26:39,969 [INFO    ] __main__: train step 482: loss: 0.2530, policy_loss: 1.9369, value_loss: 1.0163
2024-07-14 04:26:40,248 [INFO    ] __main__: train step 483: loss: 0.2531, policy_loss: 1.9368, value_loss: 1.0162
2024-07-14 04:26:40,529 [INFO    ] __main__: train step 484: loss: 0.2532, policy_loss: 1.9367, value_loss: 1.0160
2024-07-14 04:26:40,791 [INFO    ] __main__: train step 485: loss: 0.2533, policy_loss: 1.9366, value_loss: 1.0159
2024-07-14 04:26:41,068 [INFO    ] __main__: train step 486: loss: 0.2535, policy_loss: 1.9365, value_loss: 1.0157
2024-07-14 04:26:41,342 [INFO    ] __main__: train step 487: loss: 0.2536, policy_loss: 1.9364, value_loss: 1.0155
2024-07-14 04:26:41,893 [INFO    ] __main__: train step 488: loss: 0.2537, policy_loss: 1.9363, value_loss: 1.0154
2024-07-14 04:26:42,170 [INFO    ] __main__: train step 489: loss: 0.2539, policy_loss: 1.9362, value_loss: 1.0153
2024-07-14 04:26:42,434 [INFO    ] __main__: train step 490: loss: 0.2540, policy_loss: 1.9361, value_loss: 1.0152
2024-07-14 04:26:42,695 [INFO    ] __main__: train step 491: loss: 0.2541, policy_loss: 1.9360, value_loss: 1.0152
2024-07-14 04:26:42,976 [INFO    ] __main__: train step 492: loss: 0.2542, policy_loss: 1.9359, value_loss: 1.0150
2024-07-14 04:26:44,680 [INFO    ] __main__: replay_buffer size = 18944
2024-07-14 04:26:44,835 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:26:47,172 [INFO    ] __main__: train step 493: loss: 0.2543, policy_loss: 1.9358, value_loss: 1.0150
2024-07-14 04:26:47,437 [INFO    ] __main__: train step 494: loss: 0.2544, policy_loss: 1.9357, value_loss: 1.0148
2024-07-14 04:26:47,699 [INFO    ] __main__: train step 495: loss: 0.2545, policy_loss: 1.9356, value_loss: 1.0147
2024-07-14 04:26:47,974 [INFO    ] __main__: train step 496: loss: 0.2546, policy_loss: 1.9355, value_loss: 1.0146
2024-07-14 04:26:48,244 [INFO    ] __main__: train step 497: loss: 0.2547, policy_loss: 1.9354, value_loss: 1.0145
2024-07-14 04:26:48,505 [INFO    ] __main__: train step 498: loss: 0.2549, policy_loss: 1.9353, value_loss: 1.0144
2024-07-14 04:26:48,775 [INFO    ] __main__: train step 499: loss: 0.2550, policy_loss: 1.9352, value_loss: 1.0143
2024-07-14 04:26:49,364 [INFO    ] __main__: train step 500: loss: 0.2551, policy_loss: 1.9351, value_loss: 1.0142
2024-07-14 04:26:49,622 [INFO    ] __main__: train step 501: loss: 0.2553, policy_loss: 1.9350, value_loss: 1.0140
2024-07-14 04:26:49,886 [INFO    ] __main__: train step 502: loss: 0.2554, policy_loss: 1.9349, value_loss: 1.0139
2024-07-14 04:26:50,149 [INFO    ] __main__: train step 503: loss: 0.2555, policy_loss: 1.9348, value_loss: 1.0138
2024-07-14 04:26:50,423 [INFO    ] __main__: train step 504: loss: 0.2556, policy_loss: 1.9348, value_loss: 1.0137
2024-07-14 04:26:50,680 [INFO    ] __main__: train step 505: loss: 0.2557, policy_loss: 1.9347, value_loss: 1.0136
2024-07-14 04:26:50,974 [INFO    ] __main__: train step 506: loss: 0.2558, policy_loss: 1.9346, value_loss: 1.0135
2024-07-14 04:26:51,257 [INFO    ] __main__: train step 507: loss: 0.2560, policy_loss: 1.9345, value_loss: 1.0133
2024-07-14 04:26:51,544 [INFO    ] __main__: train step 508: loss: 0.2562, policy_loss: 1.9344, value_loss: 1.0132
2024-07-14 04:26:51,823 [INFO    ] __main__: train step 509: loss: 0.2562, policy_loss: 1.9342, value_loss: 1.0132
2024-07-14 04:26:53,454 [INFO    ] __main__: replay_buffer size = 19456
2024-07-14 04:26:53,596 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:26:55,940 [INFO    ] __main__: train step 510: loss: 0.2564, policy_loss: 1.9342, value_loss: 1.0131
2024-07-14 04:26:56,218 [INFO    ] __main__: train step 511: loss: 0.2565, policy_loss: 1.9340, value_loss: 1.0129
2024-07-14 04:26:56,499 [INFO    ] __main__: train step 512: loss: 0.2566, policy_loss: 1.9339, value_loss: 1.0128
2024-07-14 04:26:56,777 [INFO    ] __main__: train step 513: loss: 0.2567, policy_loss: 1.9338, value_loss: 1.0127
2024-07-14 04:26:57,498 [INFO    ] __main__: train step 514: loss: 0.2568, policy_loss: 1.9337, value_loss: 1.0127
2024-07-14 04:26:57,781 [INFO    ] __main__: train step 515: loss: 0.2570, policy_loss: 1.9336, value_loss: 1.0125
2024-07-14 04:26:58,057 [INFO    ] __main__: train step 516: loss: 0.2571, policy_loss: 1.9335, value_loss: 1.0125
2024-07-14 04:26:58,328 [INFO    ] __main__: train step 517: loss: 0.2572, policy_loss: 1.9334, value_loss: 1.0124
2024-07-14 04:26:58,603 [INFO    ] __main__: train step 518: loss: 0.2573, policy_loss: 1.9333, value_loss: 1.0123
2024-07-14 04:26:58,880 [INFO    ] __main__: train step 519: loss: 0.2574, policy_loss: 1.9332, value_loss: 1.0122
2024-07-14 04:26:59,162 [INFO    ] __main__: train step 520: loss: 0.2575, policy_loss: 1.9331, value_loss: 1.0121
2024-07-14 04:26:59,430 [INFO    ] __main__: train step 521: loss: 0.2576, policy_loss: 1.9330, value_loss: 1.0120
2024-07-14 04:26:59,700 [INFO    ] __main__: train step 522: loss: 0.2577, policy_loss: 1.9329, value_loss: 1.0120
2024-07-14 04:26:59,980 [INFO    ] __main__: train step 523: loss: 0.2578, policy_loss: 1.9329, value_loss: 1.0119
2024-07-14 04:27:00,249 [INFO    ] __main__: train step 524: loss: 0.2579, policy_loss: 1.9328, value_loss: 1.0118
2024-07-14 04:27:00,514 [INFO    ] __main__: train step 525: loss: 0.2581, policy_loss: 1.9327, value_loss: 1.0117
2024-07-14 04:27:00,788 [INFO    ] __main__: train step 526: loss: 0.2582, policy_loss: 1.9326, value_loss: 1.0116
2024-07-14 04:27:02,541 [INFO    ] __main__: replay_buffer size = 19968
2024-07-14 04:27:02,695 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:27:05,015 [INFO    ] __main__: train step 527: loss: 0.2584, policy_loss: 1.9325, value_loss: 1.0115
2024-07-14 04:27:05,687 [INFO    ] __main__: train step 528: loss: 0.2585, policy_loss: 1.9324, value_loss: 1.0114
2024-07-14 04:27:05,980 [INFO    ] __main__: train step 529: loss: 0.2586, policy_loss: 1.9323, value_loss: 1.0112
2024-07-14 04:27:06,247 [INFO    ] __main__: train step 530: loss: 0.2588, policy_loss: 1.9322, value_loss: 1.0111
2024-07-14 04:27:06,529 [INFO    ] __main__: train step 531: loss: 0.2589, policy_loss: 1.9322, value_loss: 1.0109
2024-07-14 04:27:06,801 [INFO    ] __main__: train step 532: loss: 0.2590, policy_loss: 1.9321, value_loss: 1.0107
2024-07-14 04:27:07,100 [INFO    ] __main__: train step 533: loss: 0.2591, policy_loss: 1.9320, value_loss: 1.0106
2024-07-14 04:27:07,399 [INFO    ] __main__: train step 534: loss: 0.2592, policy_loss: 1.9319, value_loss: 1.0105
2024-07-14 04:27:07,672 [INFO    ] __main__: train step 535: loss: 0.2593, policy_loss: 1.9318, value_loss: 1.0104
2024-07-14 04:27:07,953 [INFO    ] __main__: train step 536: loss: 0.2595, policy_loss: 1.9317, value_loss: 1.0102
2024-07-14 04:27:08,227 [INFO    ] __main__: train step 537: loss: 0.2596, policy_loss: 1.9316, value_loss: 1.0101
2024-07-14 04:27:08,504 [INFO    ] __main__: train step 538: loss: 0.2597, policy_loss: 1.9315, value_loss: 1.0099
2024-07-14 04:27:08,802 [INFO    ] __main__: train step 539: loss: 0.2599, policy_loss: 1.9314, value_loss: 1.0098
2024-07-14 04:27:09,077 [INFO    ] __main__: train step 540: loss: 0.2600, policy_loss: 1.9313, value_loss: 1.0097
2024-07-14 04:27:09,358 [INFO    ] __main__: train step 541: loss: 0.2601, policy_loss: 1.9312, value_loss: 1.0096
2024-07-14 04:27:09,941 [INFO    ] __main__: train step 542: loss: 0.2602, policy_loss: 1.9311, value_loss: 1.0095
2024-07-14 04:27:10,221 [INFO    ] __main__: train step 543: loss: 0.2604, policy_loss: 1.9310, value_loss: 1.0094
2024-07-14 04:27:11,913 [INFO    ] __main__: replay_buffer size = 20480
2024-07-14 04:27:12,078 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:27:13,785 [INFO    ] __main__: train step 544: loss: 0.2605, policy_loss: 1.9309, value_loss: 1.0094
2024-07-14 04:27:14,062 [INFO    ] __main__: train step 545: loss: 0.2606, policy_loss: 1.9309, value_loss: 1.0093
2024-07-14 04:27:14,342 [INFO    ] __main__: train step 546: loss: 0.2607, policy_loss: 1.9308, value_loss: 1.0092
2024-07-14 04:27:14,649 [INFO    ] __main__: train step 547: loss: 0.2609, policy_loss: 1.9307, value_loss: 1.0091
2024-07-14 04:27:14,923 [INFO    ] __main__: train step 548: loss: 0.2610, policy_loss: 1.9306, value_loss: 1.0090
2024-07-14 04:27:15,207 [INFO    ] __main__: train step 549: loss: 0.2611, policy_loss: 1.9305, value_loss: 1.0089
2024-07-14 04:27:15,488 [INFO    ] __main__: train step 550: loss: 0.2612, policy_loss: 1.9304, value_loss: 1.0088
2024-07-14 04:27:15,749 [INFO    ] __main__: train step 551: loss: 0.2614, policy_loss: 1.9303, value_loss: 1.0087
2024-07-14 04:27:16,035 [INFO    ] __main__: train step 552: loss: 0.2615, policy_loss: 1.9302, value_loss: 1.0085
2024-07-14 04:27:16,303 [INFO    ] __main__: train step 553: loss: 0.2616, policy_loss: 1.9301, value_loss: 1.0084
2024-07-14 04:27:16,566 [INFO    ] __main__: train step 554: loss: 0.2618, policy_loss: 1.9300, value_loss: 1.0083
2024-07-14 04:27:17,257 [INFO    ] __main__: train step 555: loss: 0.2619, policy_loss: 1.9300, value_loss: 1.0082
2024-07-14 04:27:17,529 [INFO    ] __main__: train step 556: loss: 0.2621, policy_loss: 1.9299, value_loss: 1.0081
2024-07-14 04:27:17,797 [INFO    ] __main__: train step 557: loss: 0.2622, policy_loss: 1.9298, value_loss: 1.0079
2024-07-14 04:27:18,078 [INFO    ] __main__: train step 558: loss: 0.2623, policy_loss: 1.9297, value_loss: 1.0078
2024-07-14 04:27:18,355 [INFO    ] __main__: train step 559: loss: 0.2625, policy_loss: 1.9296, value_loss: 1.0077
2024-07-14 04:27:18,642 [INFO    ] __main__: train step 560: loss: 0.2626, policy_loss: 1.9295, value_loss: 1.0076
2024-07-14 04:27:20,397 [INFO    ] __main__: replay_buffer size = 20992
2024-07-14 04:27:20,552 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:27:22,869 [INFO    ] __main__: train step 561: loss: 0.2627, policy_loss: 1.9294, value_loss: 1.0075
2024-07-14 04:27:23,145 [INFO    ] __main__: train step 562: loss: 0.2628, policy_loss: 1.9293, value_loss: 1.0074
2024-07-14 04:27:23,424 [INFO    ] __main__: train step 563: loss: 0.2630, policy_loss: 1.9292, value_loss: 1.0074
2024-07-14 04:27:23,694 [INFO    ] __main__: train step 564: loss: 0.2631, policy_loss: 1.9291, value_loss: 1.0073
2024-07-14 04:27:23,992 [INFO    ] __main__: train step 565: loss: 0.2632, policy_loss: 1.9290, value_loss: 1.0072
2024-07-14 04:27:24,266 [INFO    ] __main__: train step 566: loss: 0.2634, policy_loss: 1.9289, value_loss: 1.0071
2024-07-14 04:27:24,537 [INFO    ] __main__: train step 567: loss: 0.2635, policy_loss: 1.9289, value_loss: 1.0070
2024-07-14 04:27:24,809 [INFO    ] __main__: train step 568: loss: 0.2636, policy_loss: 1.9288, value_loss: 1.0069
2024-07-14 04:27:25,345 [INFO    ] __main__: train step 569: loss: 0.2637, policy_loss: 1.9287, value_loss: 1.0069
2024-07-14 04:27:25,630 [INFO    ] __main__: train step 570: loss: 0.2639, policy_loss: 1.9286, value_loss: 1.0068
2024-07-14 04:27:25,905 [INFO    ] __main__: train step 571: loss: 0.2640, policy_loss: 1.9285, value_loss: 1.0067
2024-07-14 04:27:26,205 [INFO    ] __main__: train step 572: loss: 0.2642, policy_loss: 1.9284, value_loss: 1.0066
2024-07-14 04:27:26,485 [INFO    ] __main__: train step 573: loss: 0.2643, policy_loss: 1.9283, value_loss: 1.0066
2024-07-14 04:27:26,763 [INFO    ] __main__: train step 574: loss: 0.2644, policy_loss: 1.9282, value_loss: 1.0065
2024-07-14 04:27:27,041 [INFO    ] __main__: train step 575: loss: 0.2645, policy_loss: 1.9281, value_loss: 1.0064
2024-07-14 04:27:27,332 [INFO    ] __main__: train step 576: loss: 0.2647, policy_loss: 1.9280, value_loss: 1.0063
2024-07-14 04:27:27,611 [INFO    ] __main__: train step 577: loss: 0.2648, policy_loss: 1.9279, value_loss: 1.0061
2024-07-14 04:27:29,272 [INFO    ] __main__: replay_buffer size = 21504
2024-07-14 04:27:29,428 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:27:31,809 [INFO    ] __main__: train step 578: loss: 0.2649, policy_loss: 1.9279, value_loss: 1.0060
2024-07-14 04:27:32,097 [INFO    ] __main__: train step 579: loss: 0.2651, policy_loss: 1.9278, value_loss: 1.0059
2024-07-14 04:27:32,376 [INFO    ] __main__: train step 580: loss: 0.2652, policy_loss: 1.9277, value_loss: 1.0058
2024-07-14 04:27:32,659 [INFO    ] __main__: train step 581: loss: 0.2654, policy_loss: 1.9276, value_loss: 1.0057
2024-07-14 04:27:32,934 [INFO    ] __main__: train step 582: loss: 0.2655, policy_loss: 1.9275, value_loss: 1.0056
2024-07-14 04:27:33,502 [INFO    ] __main__: train step 583: loss: 0.2656, policy_loss: 1.9274, value_loss: 1.0056
2024-07-14 04:27:33,791 [INFO    ] __main__: train step 584: loss: 0.2657, policy_loss: 1.9274, value_loss: 1.0055
2024-07-14 04:27:34,065 [INFO    ] __main__: train step 585: loss: 0.2659, policy_loss: 1.9273, value_loss: 1.0054
2024-07-14 04:27:34,336 [INFO    ] __main__: train step 586: loss: 0.2660, policy_loss: 1.9272, value_loss: 1.0052
2024-07-14 04:27:34,599 [INFO    ] __main__: train step 587: loss: 0.2662, policy_loss: 1.9271, value_loss: 1.0051
2024-07-14 04:27:34,868 [INFO    ] __main__: train step 588: loss: 0.2663, policy_loss: 1.9270, value_loss: 1.0050
2024-07-14 04:27:35,174 [INFO    ] __main__: train step 589: loss: 0.2664, policy_loss: 1.9270, value_loss: 1.0049
2024-07-14 04:27:35,463 [INFO    ] __main__: train step 590: loss: 0.2666, policy_loss: 1.9269, value_loss: 1.0048
2024-07-14 04:27:35,738 [INFO    ] __main__: train step 591: loss: 0.2667, policy_loss: 1.9268, value_loss: 1.0047
2024-07-14 04:27:35,997 [INFO    ] __main__: train step 592: loss: 0.2668, policy_loss: 1.9267, value_loss: 1.0046
2024-07-14 04:27:36,261 [INFO    ] __main__: train step 593: loss: 0.2669, policy_loss: 1.9267, value_loss: 1.0045
2024-07-14 04:27:36,534 [INFO    ] __main__: train step 594: loss: 0.2670, policy_loss: 1.9266, value_loss: 1.0044
2024-07-14 04:27:38,186 [INFO    ] __main__: replay_buffer size = 22016
2024-07-14 04:27:38,352 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:27:40,763 [INFO    ] __main__: train step 595: loss: 0.2672, policy_loss: 1.9265, value_loss: 1.0042
2024-07-14 04:27:41,033 [INFO    ] __main__: train step 596: loss: 0.2673, policy_loss: 1.9264, value_loss: 1.0041
2024-07-14 04:27:41,585 [INFO    ] __main__: train step 597: loss: 0.2675, policy_loss: 1.9263, value_loss: 1.0040
2024-07-14 04:27:41,852 [INFO    ] __main__: train step 598: loss: 0.2676, policy_loss: 1.9262, value_loss: 1.0040
2024-07-14 04:27:42,143 [INFO    ] __main__: train step 599: loss: 0.2677, policy_loss: 1.9261, value_loss: 1.0039
2024-07-14 04:27:42,422 [INFO    ] __main__: train step 600: loss: 0.2679, policy_loss: 1.9261, value_loss: 1.0037
2024-07-14 04:27:42,703 [INFO    ] __main__: train step 601: loss: 0.2680, policy_loss: 1.9260, value_loss: 1.0036
2024-07-14 04:27:42,983 [INFO    ] __main__: train step 602: loss: 0.2682, policy_loss: 1.9259, value_loss: 1.0035
2024-07-14 04:27:43,265 [INFO    ] __main__: train step 603: loss: 0.2683, policy_loss: 1.9258, value_loss: 1.0034
2024-07-14 04:27:43,546 [INFO    ] __main__: train step 604: loss: 0.2684, policy_loss: 1.9257, value_loss: 1.0034
2024-07-14 04:27:43,819 [INFO    ] __main__: train step 605: loss: 0.2685, policy_loss: 1.9256, value_loss: 1.0032
2024-07-14 04:27:44,103 [INFO    ] __main__: train step 606: loss: 0.2686, policy_loss: 1.9256, value_loss: 1.0031
2024-07-14 04:27:44,374 [INFO    ] __main__: train step 607: loss: 0.2688, policy_loss: 1.9255, value_loss: 1.0030
2024-07-14 04:27:44,650 [INFO    ] __main__: train step 608: loss: 0.2688, policy_loss: 1.9254, value_loss: 1.0029
2024-07-14 04:27:44,937 [INFO    ] __main__: train step 609: loss: 0.2689, policy_loss: 1.9253, value_loss: 1.0028
2024-07-14 04:27:45,212 [INFO    ] __main__: train step 610: loss: 0.2691, policy_loss: 1.9252, value_loss: 1.0027
2024-07-14 04:27:45,963 [INFO    ] __main__: train step 611: loss: 0.2692, policy_loss: 1.9252, value_loss: 1.0027
2024-07-14 04:27:47,681 [INFO    ] __main__: replay_buffer size = 22528
2024-07-14 04:27:47,859 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:27:49,649 [INFO    ] __main__: train step 612: loss: 0.2693, policy_loss: 1.9251, value_loss: 1.0025
2024-07-14 04:27:49,927 [INFO    ] __main__: train step 613: loss: 0.2695, policy_loss: 1.9250, value_loss: 1.0025
2024-07-14 04:27:50,213 [INFO    ] __main__: train step 614: loss: 0.2696, policy_loss: 1.9249, value_loss: 1.0024
2024-07-14 04:27:50,495 [INFO    ] __main__: train step 615: loss: 0.2697, policy_loss: 1.9249, value_loss: 1.0024
2024-07-14 04:27:50,764 [INFO    ] __main__: train step 616: loss: 0.2699, policy_loss: 1.9248, value_loss: 1.0022
2024-07-14 04:27:51,074 [INFO    ] __main__: train step 617: loss: 0.2701, policy_loss: 1.9247, value_loss: 1.0021
2024-07-14 04:27:51,360 [INFO    ] __main__: train step 618: loss: 0.2702, policy_loss: 1.9247, value_loss: 1.0021
2024-07-14 04:27:51,637 [INFO    ] __main__: train step 619: loss: 0.2703, policy_loss: 1.9246, value_loss: 1.0020
2024-07-14 04:27:51,917 [INFO    ] __main__: train step 620: loss: 0.2705, policy_loss: 1.9245, value_loss: 1.0019
2024-07-14 04:27:52,185 [INFO    ] __main__: train step 621: loss: 0.2706, policy_loss: 1.9244, value_loss: 1.0018
2024-07-14 04:27:52,465 [INFO    ] __main__: train step 622: loss: 0.2708, policy_loss: 1.9244, value_loss: 1.0018
2024-07-14 04:27:52,708 [INFO    ] __main__: train step 623: loss: 0.2709, policy_loss: 1.9243, value_loss: 1.0016
2024-07-14 04:27:52,976 [INFO    ] __main__: train step 624: loss: 0.2710, policy_loss: 1.9242, value_loss: 1.0016
2024-07-14 04:27:53,255 [INFO    ] __main__: train step 625: loss: 0.2712, policy_loss: 1.9241, value_loss: 1.0015
2024-07-14 04:27:53,969 [INFO    ] __main__: train step 626: loss: 0.2713, policy_loss: 1.9240, value_loss: 1.0014
2024-07-14 04:27:54,249 [INFO    ] __main__: train step 627: loss: 0.2714, policy_loss: 1.9239, value_loss: 1.0013
2024-07-14 04:27:54,527 [INFO    ] __main__: train step 628: loss: 0.2715, policy_loss: 1.9239, value_loss: 1.0013
2024-07-14 04:27:56,245 [INFO    ] __main__: replay_buffer size = 23040
2024-07-14 04:27:56,425 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:27:58,714 [INFO    ] __main__: train step 629: loss: 0.2717, policy_loss: 1.9238, value_loss: 1.0012
2024-07-14 04:27:59,012 [INFO    ] __main__: train step 630: loss: 0.2718, policy_loss: 1.9237, value_loss: 1.0012
2024-07-14 04:27:59,285 [INFO    ] __main__: train step 631: loss: 0.2719, policy_loss: 1.9236, value_loss: 1.0011
2024-07-14 04:27:59,555 [INFO    ] __main__: train step 632: loss: 0.2721, policy_loss: 1.9236, value_loss: 1.0010
2024-07-14 04:27:59,835 [INFO    ] __main__: train step 633: loss: 0.2722, policy_loss: 1.9235, value_loss: 1.0010
2024-07-14 04:28:00,123 [INFO    ] __main__: train step 634: loss: 0.2724, policy_loss: 1.9234, value_loss: 1.0009
2024-07-14 04:28:00,391 [INFO    ] __main__: train step 635: loss: 0.2726, policy_loss: 1.9233, value_loss: 1.0009
2024-07-14 04:28:00,656 [INFO    ] __main__: train step 636: loss: 0.2727, policy_loss: 1.9233, value_loss: 1.0008
2024-07-14 04:28:00,945 [INFO    ] __main__: train step 637: loss: 0.2728, policy_loss: 1.9232, value_loss: 1.0008
2024-07-14 04:28:01,214 [INFO    ] __main__: train step 638: loss: 0.2729, policy_loss: 1.9231, value_loss: 1.0007
2024-07-14 04:28:01,491 [INFO    ] __main__: train step 639: loss: 0.2730, policy_loss: 1.9230, value_loss: 1.0007
2024-07-14 04:28:01,758 [INFO    ] __main__: train step 640: loss: 0.2732, policy_loss: 1.9229, value_loss: 1.0006
2024-07-14 04:28:02,334 [INFO    ] __main__: train step 641: loss: 0.2733, policy_loss: 1.9229, value_loss: 1.0005
2024-07-14 04:28:02,607 [INFO    ] __main__: train step 642: loss: 0.2734, policy_loss: 1.9228, value_loss: 1.0005
2024-07-14 04:28:02,885 [INFO    ] __main__: train step 643: loss: 0.2736, policy_loss: 1.9227, value_loss: 1.0004
2024-07-14 04:28:03,164 [INFO    ] __main__: train step 644: loss: 0.2737, policy_loss: 1.9226, value_loss: 1.0003
2024-07-14 04:28:03,462 [INFO    ] __main__: train step 645: loss: 0.2739, policy_loss: 1.9226, value_loss: 1.0003
2024-07-14 04:28:05,149 [INFO    ] __main__: replay_buffer size = 23552
2024-07-14 04:28:05,323 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:28:07,641 [INFO    ] __main__: train step 646: loss: 0.2740, policy_loss: 1.9225, value_loss: 1.0002
2024-07-14 04:28:07,916 [INFO    ] __main__: train step 647: loss: 0.2741, policy_loss: 1.9224, value_loss: 1.0002
2024-07-14 04:28:08,195 [INFO    ] __main__: train step 648: loss: 0.2743, policy_loss: 1.9223, value_loss: 1.0001
2024-07-14 04:28:08,469 [INFO    ] __main__: train step 649: loss: 0.2744, policy_loss: 1.9223, value_loss: 1.0000
2024-07-14 04:28:08,739 [INFO    ] __main__: train step 650: loss: 0.2746, policy_loss: 1.9222, value_loss: 1.0000
2024-07-14 04:28:09,001 [INFO    ] __main__: train step 651: loss: 0.2747, policy_loss: 1.9221, value_loss: 0.9999
2024-07-14 04:28:09,265 [INFO    ] __main__: train step 652: loss: 0.2748, policy_loss: 1.9221, value_loss: 0.9998
2024-07-14 04:28:09,540 [INFO    ] __main__: train step 653: loss: 0.2750, policy_loss: 1.9220, value_loss: 0.9998
2024-07-14 04:28:09,809 [INFO    ] __main__: train step 654: loss: 0.2751, policy_loss: 1.9219, value_loss: 0.9997
2024-07-14 04:28:10,097 [INFO    ] __main__: train step 655: loss: 0.2753, policy_loss: 1.9218, value_loss: 0.9997
2024-07-14 04:28:10,753 [INFO    ] __main__: train step 656: loss: 0.2754, policy_loss: 1.9218, value_loss: 0.9996
2024-07-14 04:28:11,003 [INFO    ] __main__: train step 657: loss: 0.2756, policy_loss: 1.9217, value_loss: 0.9996
2024-07-14 04:28:11,276 [INFO    ] __main__: train step 658: loss: 0.2757, policy_loss: 1.9216, value_loss: 0.9995
2024-07-14 04:28:11,558 [INFO    ] __main__: train step 659: loss: 0.2758, policy_loss: 1.9216, value_loss: 0.9994
2024-07-14 04:28:11,838 [INFO    ] __main__: train step 660: loss: 0.2760, policy_loss: 1.9215, value_loss: 0.9993
2024-07-14 04:28:12,121 [INFO    ] __main__: train step 661: loss: 0.2761, policy_loss: 1.9214, value_loss: 0.9993
2024-07-14 04:28:12,399 [INFO    ] __main__: train step 662: loss: 0.2763, policy_loss: 1.9214, value_loss: 0.9991
2024-07-14 04:28:14,152 [INFO    ] __main__: replay_buffer size = 24064
2024-07-14 04:28:14,339 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:28:16,684 [INFO    ] __main__: train step 663: loss: 0.2764, policy_loss: 1.9213, value_loss: 0.9991
2024-07-14 04:28:16,965 [INFO    ] __main__: train step 664: loss: 0.2766, policy_loss: 1.9212, value_loss: 0.9990
2024-07-14 04:28:17,272 [INFO    ] __main__: train step 665: loss: 0.2767, policy_loss: 1.9212, value_loss: 0.9989
2024-07-14 04:28:17,546 [INFO    ] __main__: train step 666: loss: 0.2769, policy_loss: 1.9211, value_loss: 0.9988
2024-07-14 04:28:17,826 [INFO    ] __main__: train step 667: loss: 0.2770, policy_loss: 1.9210, value_loss: 0.9987
2024-07-14 04:28:18,112 [INFO    ] __main__: train step 668: loss: 0.2772, policy_loss: 1.9210, value_loss: 0.9986
2024-07-14 04:28:18,388 [INFO    ] __main__: train step 669: loss: 0.2773, policy_loss: 1.9209, value_loss: 0.9985
2024-07-14 04:28:19,054 [INFO    ] __main__: train step 670: loss: 0.2774, policy_loss: 1.9208, value_loss: 0.9984
2024-07-14 04:28:19,339 [INFO    ] __main__: train step 671: loss: 0.2775, policy_loss: 1.9208, value_loss: 0.9983
2024-07-14 04:28:19,622 [INFO    ] __main__: train step 672: loss: 0.2777, policy_loss: 1.9207, value_loss: 0.9983
2024-07-14 04:28:19,893 [INFO    ] __main__: train step 673: loss: 0.2778, policy_loss: 1.9206, value_loss: 0.9982
2024-07-14 04:28:20,173 [INFO    ] __main__: train step 674: loss: 0.2780, policy_loss: 1.9205, value_loss: 0.9981
2024-07-14 04:28:20,500 [INFO    ] __main__: train step 675: loss: 0.2781, policy_loss: 1.9205, value_loss: 0.9981
2024-07-14 04:28:20,787 [INFO    ] __main__: train step 676: loss: 0.2783, policy_loss: 1.9204, value_loss: 0.9980
2024-07-14 04:28:21,067 [INFO    ] __main__: train step 677: loss: 0.2784, policy_loss: 1.9203, value_loss: 0.9979
2024-07-14 04:28:21,363 [INFO    ] __main__: train step 678: loss: 0.2785, policy_loss: 1.9202, value_loss: 0.9979
2024-07-14 04:28:21,646 [INFO    ] __main__: train step 679: loss: 0.2786, policy_loss: 1.9202, value_loss: 0.9978
2024-07-14 04:28:23,432 [INFO    ] __main__: replay_buffer size = 24576
2024-07-14 04:28:23,625 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:28:25,275 [INFO    ] __main__: train step 680: loss: 0.2787, policy_loss: 1.9201, value_loss: 0.9978
2024-07-14 04:28:25,526 [INFO    ] __main__: train step 681: loss: 0.2789, policy_loss: 1.9200, value_loss: 0.9977
2024-07-14 04:28:25,767 [INFO    ] __main__: train step 682: loss: 0.2790, policy_loss: 1.9200, value_loss: 0.9976
2024-07-14 04:28:26,048 [INFO    ] __main__: train step 683: loss: 0.2792, policy_loss: 1.9199, value_loss: 0.9975
2024-07-14 04:28:26,323 [INFO    ] __main__: train step 684: loss: 0.2793, policy_loss: 1.9198, value_loss: 0.9974
2024-07-14 04:28:27,091 [INFO    ] __main__: train step 685: loss: 0.2794, policy_loss: 1.9198, value_loss: 0.9973
2024-07-14 04:28:27,364 [INFO    ] __main__: train step 686: loss: 0.2796, policy_loss: 1.9197, value_loss: 0.9972
2024-07-14 04:28:27,648 [INFO    ] __main__: train step 687: loss: 0.2797, policy_loss: 1.9196, value_loss: 0.9971
2024-07-14 04:28:27,922 [INFO    ] __main__: train step 688: loss: 0.2799, policy_loss: 1.9196, value_loss: 0.9971
2024-07-14 04:28:28,201 [INFO    ] __main__: train step 689: loss: 0.2800, policy_loss: 1.9195, value_loss: 0.9970
2024-07-14 04:28:28,480 [INFO    ] __main__: train step 690: loss: 0.2801, policy_loss: 1.9194, value_loss: 0.9969
2024-07-14 04:28:28,760 [INFO    ] __main__: train step 691: loss: 0.2803, policy_loss: 1.9194, value_loss: 0.9969
2024-07-14 04:28:29,040 [INFO    ] __main__: train step 692: loss: 0.2804, policy_loss: 1.9193, value_loss: 0.9968
2024-07-14 04:28:29,318 [INFO    ] __main__: train step 693: loss: 0.2805, policy_loss: 1.9192, value_loss: 0.9968
2024-07-14 04:28:29,601 [INFO    ] __main__: train step 694: loss: 0.2807, policy_loss: 1.9191, value_loss: 0.9968
2024-07-14 04:28:29,879 [INFO    ] __main__: train step 695: loss: 0.2808, policy_loss: 1.9191, value_loss: 0.9967
2024-07-14 04:28:30,152 [INFO    ] __main__: train step 696: loss: 0.2809, policy_loss: 1.9190, value_loss: 0.9966
2024-07-14 04:28:31,794 [INFO    ] __main__: replay_buffer size = 25088
2024-07-14 04:28:31,986 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:28:34,303 [INFO    ] __main__: train step 697: loss: 0.2811, policy_loss: 1.9189, value_loss: 0.9966
2024-07-14 04:28:34,570 [INFO    ] __main__: train step 698: loss: 0.2812, policy_loss: 1.9188, value_loss: 0.9965
2024-07-14 04:28:35,149 [INFO    ] __main__: train step 699: loss: 0.2813, policy_loss: 1.9188, value_loss: 0.9964
2024-07-14 04:28:35,420 [INFO    ] __main__: train step 700: loss: 0.2815, policy_loss: 1.9187, value_loss: 0.9964
2024-07-14 04:28:35,688 [INFO    ] __main__: train step 701: loss: 0.2816, policy_loss: 1.9187, value_loss: 0.9963
2024-07-14 04:28:35,975 [INFO    ] __main__: train step 702: loss: 0.2818, policy_loss: 1.9186, value_loss: 0.9962
2024-07-14 04:28:36,255 [INFO    ] __main__: train step 703: loss: 0.2819, policy_loss: 1.9185, value_loss: 0.9961
2024-07-14 04:28:36,529 [INFO    ] __main__: train step 704: loss: 0.2821, policy_loss: 1.9185, value_loss: 0.9960
2024-07-14 04:28:36,810 [INFO    ] __main__: train step 705: loss: 0.2822, policy_loss: 1.9184, value_loss: 0.9960
2024-07-14 04:28:37,111 [INFO    ] __main__: train step 706: loss: 0.2823, policy_loss: 1.9183, value_loss: 0.9959
2024-07-14 04:28:37,382 [INFO    ] __main__: train step 707: loss: 0.2825, policy_loss: 1.9183, value_loss: 0.9958
2024-07-14 04:28:37,657 [INFO    ] __main__: train step 708: loss: 0.2826, policy_loss: 1.9182, value_loss: 0.9957
2024-07-14 04:28:37,934 [INFO    ] __main__: train step 709: loss: 0.2827, policy_loss: 1.9181, value_loss: 0.9957
2024-07-14 04:28:38,212 [INFO    ] __main__: train step 710: loss: 0.2829, policy_loss: 1.9180, value_loss: 0.9956
2024-07-14 04:28:38,499 [INFO    ] __main__: train step 711: loss: 0.2830, policy_loss: 1.9180, value_loss: 0.9955
2024-07-14 04:28:38,761 [INFO    ] __main__: train step 712: loss: 0.2831, policy_loss: 1.9179, value_loss: 0.9955
2024-07-14 04:28:39,049 [INFO    ] __main__: train step 713: loss: 0.2833, policy_loss: 1.9178, value_loss: 0.9954
2024-07-14 04:28:41,170 [INFO    ] __main__: replay_buffer size = 25600
2024-07-14 04:28:41,355 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:28:43,703 [INFO    ] __main__: train step 714: loss: 0.2834, policy_loss: 1.9178, value_loss: 0.9954
2024-07-14 04:28:43,963 [INFO    ] __main__: train step 715: loss: 0.2836, policy_loss: 1.9177, value_loss: 0.9953
2024-07-14 04:28:44,222 [INFO    ] __main__: train step 716: loss: 0.2837, policy_loss: 1.9176, value_loss: 0.9952
2024-07-14 04:28:44,486 [INFO    ] __main__: train step 717: loss: 0.2839, policy_loss: 1.9176, value_loss: 0.9951
2024-07-14 04:28:44,767 [INFO    ] __main__: train step 718: loss: 0.2840, policy_loss: 1.9175, value_loss: 0.9951
2024-07-14 04:28:45,050 [INFO    ] __main__: train step 719: loss: 0.2842, policy_loss: 1.9174, value_loss: 0.9950
2024-07-14 04:28:45,336 [INFO    ] __main__: train step 720: loss: 0.2843, policy_loss: 1.9174, value_loss: 0.9950
2024-07-14 04:28:45,616 [INFO    ] __main__: train step 721: loss: 0.2845, policy_loss: 1.9173, value_loss: 0.9949
2024-07-14 04:28:45,891 [INFO    ] __main__: train step 722: loss: 0.2846, policy_loss: 1.9172, value_loss: 0.9948
2024-07-14 04:28:46,173 [INFO    ] __main__: train step 723: loss: 0.2848, policy_loss: 1.9172, value_loss: 0.9948
2024-07-14 04:28:46,439 [INFO    ] __main__: train step 724: loss: 0.2849, policy_loss: 1.9171, value_loss: 0.9947
2024-07-14 04:28:46,713 [INFO    ] __main__: train step 725: loss: 0.2850, policy_loss: 1.9170, value_loss: 0.9946
2024-07-14 04:28:46,988 [INFO    ] __main__: train step 726: loss: 0.2852, policy_loss: 1.9170, value_loss: 0.9946
2024-07-14 04:28:47,255 [INFO    ] __main__: train step 727: loss: 0.2853, policy_loss: 1.9169, value_loss: 0.9946
2024-07-14 04:28:47,519 [INFO    ] __main__: train step 728: loss: 0.2855, policy_loss: 1.9168, value_loss: 0.9945
2024-07-14 04:28:48,073 [INFO    ] __main__: train step 729: loss: 0.2856, policy_loss: 1.9168, value_loss: 0.9945
2024-07-14 04:28:48,365 [INFO    ] __main__: train step 730: loss: 0.2858, policy_loss: 1.9167, value_loss: 0.9944
2024-07-14 04:28:50,084 [INFO    ] __main__: replay_buffer size = 26112
2024-07-14 04:28:50,289 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:28:52,687 [INFO    ] __main__: train step 731: loss: 0.2859, policy_loss: 1.9166, value_loss: 0.9944
2024-07-14 04:28:52,974 [INFO    ] __main__: train step 732: loss: 0.2861, policy_loss: 1.9166, value_loss: 0.9944
2024-07-14 04:28:53,237 [INFO    ] __main__: train step 733: loss: 0.2862, policy_loss: 1.9165, value_loss: 0.9943
2024-07-14 04:28:53,522 [INFO    ] __main__: train step 734: loss: 0.2864, policy_loss: 1.9165, value_loss: 0.9943
2024-07-14 04:28:53,804 [INFO    ] __main__: train step 735: loss: 0.2865, policy_loss: 1.9164, value_loss: 0.9943
2024-07-14 04:28:54,077 [INFO    ] __main__: train step 736: loss: 0.2867, policy_loss: 1.9163, value_loss: 0.9942
2024-07-14 04:28:54,352 [INFO    ] __main__: train step 737: loss: 0.2868, policy_loss: 1.9163, value_loss: 0.9941
2024-07-14 04:28:54,624 [INFO    ] __main__: train step 738: loss: 0.2870, policy_loss: 1.9162, value_loss: 0.9941
2024-07-14 04:28:54,900 [INFO    ] __main__: train step 739: loss: 0.2871, policy_loss: 1.9162, value_loss: 0.9940
2024-07-14 04:28:55,170 [INFO    ] __main__: train step 740: loss: 0.2873, policy_loss: 1.9161, value_loss: 0.9940
2024-07-14 04:28:55,444 [INFO    ] __main__: train step 741: loss: 0.2874, policy_loss: 1.9160, value_loss: 0.9939
2024-07-14 04:28:55,738 [INFO    ] __main__: train step 742: loss: 0.2876, policy_loss: 1.9160, value_loss: 0.9939
2024-07-14 04:28:56,012 [INFO    ] __main__: train step 743: loss: 0.2877, policy_loss: 1.9159, value_loss: 0.9938
2024-07-14 04:28:56,751 [INFO    ] __main__: train step 744: loss: 0.2878, policy_loss: 1.9159, value_loss: 0.9938
2024-07-14 04:28:57,028 [INFO    ] __main__: train step 745: loss: 0.2880, policy_loss: 1.9158, value_loss: 0.9937
2024-07-14 04:28:57,296 [INFO    ] __main__: train step 746: loss: 0.2881, policy_loss: 1.9157, value_loss: 0.9936
2024-07-14 04:28:57,586 [INFO    ] __main__: train step 747: loss: 0.2883, policy_loss: 1.9157, value_loss: 0.9935
2024-07-14 04:28:59,376 [INFO    ] __main__: replay_buffer size = 26624
2024-07-14 04:28:59,573 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:29:01,367 [INFO    ] __main__: train step 748: loss: 0.2884, policy_loss: 1.9156, value_loss: 0.9934
2024-07-14 04:29:01,648 [INFO    ] __main__: train step 749: loss: 0.2886, policy_loss: 1.9155, value_loss: 0.9934
2024-07-14 04:29:01,920 [INFO    ] __main__: train step 750: loss: 0.2887, policy_loss: 1.9155, value_loss: 0.9933
2024-07-14 04:29:02,203 [INFO    ] __main__: train step 751: loss: 0.2889, policy_loss: 1.9154, value_loss: 0.9932
2024-07-14 04:29:02,473 [INFO    ] __main__: train step 752: loss: 0.2890, policy_loss: 1.9154, value_loss: 0.9931
2024-07-14 04:29:02,758 [INFO    ] __main__: train step 753: loss: 0.2892, policy_loss: 1.9153, value_loss: 0.9931
2024-07-14 04:29:03,045 [INFO    ] __main__: train step 754: loss: 0.2893, policy_loss: 1.9152, value_loss: 0.9930
2024-07-14 04:29:03,324 [INFO    ] __main__: train step 755: loss: 0.2894, policy_loss: 1.9152, value_loss: 0.9930
2024-07-14 04:29:03,602 [INFO    ] __main__: train step 756: loss: 0.2896, policy_loss: 1.9151, value_loss: 0.9929
2024-07-14 04:29:03,870 [INFO    ] __main__: train step 757: loss: 0.2897, policy_loss: 1.9150, value_loss: 0.9929
2024-07-14 04:29:04,152 [INFO    ] __main__: train step 758: loss: 0.2898, policy_loss: 1.9149, value_loss: 0.9928
2024-07-14 04:29:05,160 [INFO    ] __main__: train step 759: loss: 0.2900, policy_loss: 1.9149, value_loss: 0.9928
2024-07-14 04:29:05,467 [INFO    ] __main__: train step 760: loss: 0.2901, policy_loss: 1.9148, value_loss: 0.9927
2024-07-14 04:29:05,774 [INFO    ] __main__: train step 761: loss: 0.2902, policy_loss: 1.9147, value_loss: 0.9926
2024-07-14 04:29:06,086 [INFO    ] __main__: train step 762: loss: 0.2904, policy_loss: 1.9147, value_loss: 0.9926
2024-07-14 04:29:06,386 [INFO    ] __main__: train step 763: loss: 0.2905, policy_loss: 1.9146, value_loss: 0.9925
2024-07-14 04:29:06,680 [INFO    ] __main__: train step 764: loss: 0.2906, policy_loss: 1.9145, value_loss: 0.9925
2024-07-14 04:29:08,423 [INFO    ] __main__: replay_buffer size = 27136
2024-07-14 04:29:08,647 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:29:10,992 [INFO    ] __main__: train step 765: loss: 0.2908, policy_loss: 1.9145, value_loss: 0.9924
2024-07-14 04:29:11,269 [INFO    ] __main__: train step 766: loss: 0.2909, policy_loss: 1.9144, value_loss: 0.9924
2024-07-14 04:29:11,552 [INFO    ] __main__: train step 767: loss: 0.2911, policy_loss: 1.9143, value_loss: 0.9923
2024-07-14 04:29:11,819 [INFO    ] __main__: train step 768: loss: 0.2912, policy_loss: 1.9143, value_loss: 0.9923
2024-07-14 04:29:12,092 [INFO    ] __main__: train step 769: loss: 0.2914, policy_loss: 1.9142, value_loss: 0.9922
2024-07-14 04:29:12,379 [INFO    ] __main__: train step 770: loss: 0.2915, policy_loss: 1.9142, value_loss: 0.9922
2024-07-14 04:29:12,650 [INFO    ] __main__: train step 771: loss: 0.2916, policy_loss: 1.9141, value_loss: 0.9922
2024-07-14 04:29:12,931 [INFO    ] __main__: train step 772: loss: 0.2918, policy_loss: 1.9141, value_loss: 0.9921
2024-07-14 04:29:13,200 [INFO    ] __main__: train step 773: loss: 0.2919, policy_loss: 1.9140, value_loss: 0.9921
2024-07-14 04:29:13,788 [INFO    ] __main__: train step 774: loss: 0.2921, policy_loss: 1.9140, value_loss: 0.9921
2024-07-14 04:29:14,066 [INFO    ] __main__: train step 775: loss: 0.2922, policy_loss: 1.9139, value_loss: 0.9920
2024-07-14 04:29:14,336 [INFO    ] __main__: train step 776: loss: 0.2923, policy_loss: 1.9138, value_loss: 0.9920
2024-07-14 04:29:14,606 [INFO    ] __main__: train step 777: loss: 0.2925, policy_loss: 1.9138, value_loss: 0.9919
2024-07-14 04:29:14,883 [INFO    ] __main__: train step 778: loss: 0.2926, policy_loss: 1.9137, value_loss: 0.9918
2024-07-14 04:29:15,157 [INFO    ] __main__: train step 779: loss: 0.2928, policy_loss: 1.9137, value_loss: 0.9918
2024-07-14 04:29:15,445 [INFO    ] __main__: train step 780: loss: 0.2929, policy_loss: 1.9136, value_loss: 0.9918
2024-07-14 04:29:15,716 [INFO    ] __main__: train step 781: loss: 0.2931, policy_loss: 1.9135, value_loss: 0.9917
2024-07-14 04:29:17,484 [INFO    ] __main__: replay_buffer size = 27648
2024-07-14 04:29:17,687 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:29:20,045 [INFO    ] __main__: train step 782: loss: 0.2932, policy_loss: 1.9135, value_loss: 0.9916
2024-07-14 04:29:20,332 [INFO    ] __main__: train step 783: loss: 0.2934, policy_loss: 1.9134, value_loss: 0.9916
2024-07-14 04:29:20,622 [INFO    ] __main__: train step 784: loss: 0.2935, policy_loss: 1.9133, value_loss: 0.9915
2024-07-14 04:29:20,925 [INFO    ] __main__: train step 785: loss: 0.2937, policy_loss: 1.9133, value_loss: 0.9915
2024-07-14 04:29:21,195 [INFO    ] __main__: train step 786: loss: 0.2938, policy_loss: 1.9132, value_loss: 0.9915
2024-07-14 04:29:21,497 [INFO    ] __main__: train step 787: loss: 0.2940, policy_loss: 1.9132, value_loss: 0.9915
2024-07-14 04:29:21,771 [INFO    ] __main__: train step 788: loss: 0.2941, policy_loss: 1.9131, value_loss: 0.9914
2024-07-14 04:29:22,330 [INFO    ] __main__: train step 789: loss: 0.2943, policy_loss: 1.9130, value_loss: 0.9914
2024-07-14 04:29:22,597 [INFO    ] __main__: train step 790: loss: 0.2944, policy_loss: 1.9130, value_loss: 0.9913
2024-07-14 04:29:22,877 [INFO    ] __main__: train step 791: loss: 0.2946, policy_loss: 1.9129, value_loss: 0.9912
2024-07-14 04:29:23,144 [INFO    ] __main__: train step 792: loss: 0.2947, policy_loss: 1.9129, value_loss: 0.9912
2024-07-14 04:29:23,418 [INFO    ] __main__: train step 793: loss: 0.2949, policy_loss: 1.9128, value_loss: 0.9911
2024-07-14 04:29:23,686 [INFO    ] __main__: train step 794: loss: 0.2951, policy_loss: 1.9127, value_loss: 0.9910
2024-07-14 04:29:23,960 [INFO    ] __main__: train step 795: loss: 0.2952, policy_loss: 1.9127, value_loss: 0.9910
2024-07-14 04:29:24,239 [INFO    ] __main__: train step 796: loss: 0.2953, policy_loss: 1.9126, value_loss: 0.9909
2024-07-14 04:29:24,505 [INFO    ] __main__: train step 797: loss: 0.2955, policy_loss: 1.9125, value_loss: 0.9908
2024-07-14 04:29:24,772 [INFO    ] __main__: train step 798: loss: 0.2956, policy_loss: 1.9125, value_loss: 0.9907
2024-07-14 04:29:26,558 [INFO    ] __main__: replay_buffer size = 28160
2024-07-14 04:29:26,794 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:29:29,173 [INFO    ] __main__: train step 799: loss: 0.2958, policy_loss: 1.9124, value_loss: 0.9907
2024-07-14 04:29:29,455 [INFO    ] __main__: train step 800: loss: 0.2959, policy_loss: 1.9124, value_loss: 0.9907
2024-07-14 04:29:29,728 [INFO    ] __main__: train step 801: loss: 0.2960, policy_loss: 1.9123, value_loss: 0.9906
2024-07-14 04:29:30,006 [INFO    ] __main__: train step 802: loss: 0.2962, policy_loss: 1.9123, value_loss: 0.9905
2024-07-14 04:29:30,285 [INFO    ] __main__: train step 803: loss: 0.2963, policy_loss: 1.9122, value_loss: 0.9905
2024-07-14 04:29:31,044 [INFO    ] __main__: train step 804: loss: 0.2965, policy_loss: 1.9121, value_loss: 0.9904
2024-07-14 04:29:31,306 [INFO    ] __main__: train step 805: loss: 0.2966, policy_loss: 1.9120, value_loss: 0.9904
2024-07-14 04:29:31,577 [INFO    ] __main__: train step 806: loss: 0.2968, policy_loss: 1.9120, value_loss: 0.9903
2024-07-14 04:29:31,846 [INFO    ] __main__: train step 807: loss: 0.2969, policy_loss: 1.9119, value_loss: 0.9903
2024-07-14 04:29:32,129 [INFO    ] __main__: train step 808: loss: 0.2970, policy_loss: 1.9118, value_loss: 0.9902
2024-07-14 04:29:32,409 [INFO    ] __main__: train step 809: loss: 0.2972, policy_loss: 1.9118, value_loss: 0.9901
2024-07-14 04:29:32,675 [INFO    ] __main__: train step 810: loss: 0.2973, policy_loss: 1.9117, value_loss: 0.9900
2024-07-14 04:29:32,954 [INFO    ] __main__: train step 811: loss: 0.2974, policy_loss: 1.9116, value_loss: 0.9899
2024-07-14 04:29:33,230 [INFO    ] __main__: train step 812: loss: 0.2975, policy_loss: 1.9115, value_loss: 0.9899
2024-07-14 04:29:33,513 [INFO    ] __main__: train step 813: loss: 0.2977, policy_loss: 1.9115, value_loss: 0.9898
2024-07-14 04:29:33,775 [INFO    ] __main__: train step 814: loss: 0.2978, policy_loss: 1.9114, value_loss: 0.9898
2024-07-14 04:29:34,053 [INFO    ] __main__: train step 815: loss: 0.2980, policy_loss: 1.9113, value_loss: 0.9897
2024-07-14 04:29:35,808 [INFO    ] __main__: replay_buffer size = 28672
2024-07-14 04:29:36,030 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:29:37,785 [INFO    ] __main__: train step 816: loss: 0.2981, policy_loss: 1.9113, value_loss: 0.9897
2024-07-14 04:29:38,070 [INFO    ] __main__: train step 817: loss: 0.2983, policy_loss: 1.9112, value_loss: 0.9896
2024-07-14 04:29:38,704 [INFO    ] __main__: train step 818: loss: 0.2984, policy_loss: 1.9112, value_loss: 0.9896
2024-07-14 04:29:38,990 [INFO    ] __main__: train step 819: loss: 0.2986, policy_loss: 1.9111, value_loss: 0.9896
2024-07-14 04:29:39,271 [INFO    ] __main__: train step 820: loss: 0.2987, policy_loss: 1.9110, value_loss: 0.9895
2024-07-14 04:29:39,551 [INFO    ] __main__: train step 821: loss: 0.2988, policy_loss: 1.9110, value_loss: 0.9895
2024-07-14 04:29:39,824 [INFO    ] __main__: train step 822: loss: 0.2990, policy_loss: 1.9109, value_loss: 0.9894
2024-07-14 04:29:40,101 [INFO    ] __main__: train step 823: loss: 0.2992, policy_loss: 1.9108, value_loss: 0.9894
2024-07-14 04:29:40,383 [INFO    ] __main__: train step 824: loss: 0.2993, policy_loss: 1.9108, value_loss: 0.9893
2024-07-14 04:29:40,656 [INFO    ] __main__: train step 825: loss: 0.2995, policy_loss: 1.9107, value_loss: 0.9893
2024-07-14 04:29:40,935 [INFO    ] __main__: train step 826: loss: 0.2996, policy_loss: 1.9106, value_loss: 0.9893
2024-07-14 04:29:41,206 [INFO    ] __main__: train step 827: loss: 0.2998, policy_loss: 1.9106, value_loss: 0.9893
2024-07-14 04:29:41,476 [INFO    ] __main__: train step 828: loss: 0.2999, policy_loss: 1.9105, value_loss: 0.9891
2024-07-14 04:29:41,747 [INFO    ] __main__: train step 829: loss: 0.3001, policy_loss: 1.9104, value_loss: 0.9891
2024-07-14 04:29:42,029 [INFO    ] __main__: train step 830: loss: 0.3003, policy_loss: 1.9104, value_loss: 0.9890
2024-07-14 04:29:42,309 [INFO    ] __main__: train step 831: loss: 0.3004, policy_loss: 1.9103, value_loss: 0.9890
2024-07-14 04:29:42,584 [INFO    ] __main__: train step 832: loss: 0.3006, policy_loss: 1.9102, value_loss: 0.9890
2024-07-14 04:29:44,620 [INFO    ] __main__: replay_buffer size = 29184
2024-07-14 04:29:44,854 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:29:47,207 [INFO    ] __main__: train step 833: loss: 0.3007, policy_loss: 1.9101, value_loss: 0.9889
2024-07-14 04:29:47,485 [INFO    ] __main__: train step 834: loss: 0.3009, policy_loss: 1.9101, value_loss: 0.9889
2024-07-14 04:29:47,757 [INFO    ] __main__: train step 835: loss: 0.3011, policy_loss: 1.9100, value_loss: 0.9889
2024-07-14 04:29:48,035 [INFO    ] __main__: train step 836: loss: 0.3012, policy_loss: 1.9100, value_loss: 0.9888
2024-07-14 04:29:48,336 [INFO    ] __main__: train step 837: loss: 0.3013, policy_loss: 1.9099, value_loss: 0.9888
2024-07-14 04:29:48,596 [INFO    ] __main__: train step 838: loss: 0.3015, policy_loss: 1.9098, value_loss: 0.9888
2024-07-14 04:29:48,866 [INFO    ] __main__: train step 839: loss: 0.3017, policy_loss: 1.9098, value_loss: 0.9887
2024-07-14 04:29:49,149 [INFO    ] __main__: train step 840: loss: 0.3018, policy_loss: 1.9097, value_loss: 0.9887
2024-07-14 04:29:49,425 [INFO    ] __main__: train step 841: loss: 0.3020, policy_loss: 1.9096, value_loss: 0.9886
2024-07-14 04:29:49,691 [INFO    ] __main__: train step 842: loss: 0.3021, policy_loss: 1.9095, value_loss: 0.9886
2024-07-14 04:29:49,992 [INFO    ] __main__: train step 843: loss: 0.3023, policy_loss: 1.9095, value_loss: 0.9885
2024-07-14 04:29:50,267 [INFO    ] __main__: train step 844: loss: 0.3024, policy_loss: 1.9094, value_loss: 0.9885
2024-07-14 04:29:50,556 [INFO    ] __main__: train step 845: loss: 0.3026, policy_loss: 1.9094, value_loss: 0.9884
2024-07-14 04:29:50,835 [INFO    ] __main__: train step 846: loss: 0.3027, policy_loss: 1.9093, value_loss: 0.9884
2024-07-14 04:29:51,119 [INFO    ] __main__: train step 847: loss: 0.3028, policy_loss: 1.9092, value_loss: 0.9884
2024-07-14 04:29:51,890 [INFO    ] __main__: train step 848: loss: 0.3030, policy_loss: 1.9092, value_loss: 0.9883
2024-07-14 04:29:52,162 [INFO    ] __main__: train step 849: loss: 0.3031, policy_loss: 1.9091, value_loss: 0.9883
2024-07-14 04:29:53,872 [INFO    ] __main__: replay_buffer size = 29696
2024-07-14 04:29:54,105 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:29:56,429 [INFO    ] __main__: train step 850: loss: 0.3033, policy_loss: 1.9090, value_loss: 0.9883
2024-07-14 04:29:56,708 [INFO    ] __main__: train step 851: loss: 0.3034, policy_loss: 1.9089, value_loss: 0.9882
2024-07-14 04:29:56,992 [INFO    ] __main__: train step 852: loss: 0.3036, policy_loss: 1.9089, value_loss: 0.9881
2024-07-14 04:29:57,275 [INFO    ] __main__: train step 853: loss: 0.3037, policy_loss: 1.9088, value_loss: 0.9881
2024-07-14 04:29:57,554 [INFO    ] __main__: train step 854: loss: 0.3038, policy_loss: 1.9088, value_loss: 0.9881
2024-07-14 04:29:57,834 [INFO    ] __main__: train step 855: loss: 0.3040, policy_loss: 1.9087, value_loss: 0.9881
2024-07-14 04:29:58,096 [INFO    ] __main__: train step 856: loss: 0.3042, policy_loss: 1.9086, value_loss: 0.9880
2024-07-14 04:29:58,366 [INFO    ] __main__: train step 857: loss: 0.3043, policy_loss: 1.9086, value_loss: 0.9880
2024-07-14 04:29:58,639 [INFO    ] __main__: train step 858: loss: 0.3044, policy_loss: 1.9085, value_loss: 0.9879
2024-07-14 04:29:58,922 [INFO    ] __main__: train step 859: loss: 0.3046, policy_loss: 1.9084, value_loss: 0.9879
2024-07-14 04:29:59,216 [INFO    ] __main__: train step 860: loss: 0.3047, policy_loss: 1.9084, value_loss: 0.9879
2024-07-14 04:29:59,458 [INFO    ] __main__: train step 861: loss: 0.3049, policy_loss: 1.9083, value_loss: 0.9879
2024-07-14 04:29:59,711 [INFO    ] __main__: train step 862: loss: 0.3050, policy_loss: 1.9082, value_loss: 0.9878
2024-07-14 04:29:59,973 [INFO    ] __main__: train step 863: loss: 0.3052, policy_loss: 1.9081, value_loss: 0.9878
2024-07-14 04:30:00,682 [INFO    ] __main__: train step 864: loss: 0.3053, policy_loss: 1.9081, value_loss: 0.9878
2024-07-14 04:30:00,951 [INFO    ] __main__: train step 865: loss: 0.3054, policy_loss: 1.9080, value_loss: 0.9877
2024-07-14 04:30:01,224 [INFO    ] __main__: train step 866: loss: 0.3056, policy_loss: 1.9079, value_loss: 0.9876
2024-07-14 04:30:02,986 [INFO    ] __main__: replay_buffer size = 30208
2024-07-14 04:30:03,233 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:30:05,640 [INFO    ] __main__: train step 867: loss: 0.3058, policy_loss: 1.9079, value_loss: 0.9876
2024-07-14 04:30:05,915 [INFO    ] __main__: train step 868: loss: 0.3059, policy_loss: 1.9078, value_loss: 0.9875
2024-07-14 04:30:06,201 [INFO    ] __main__: train step 869: loss: 0.3061, policy_loss: 1.9077, value_loss: 0.9875
2024-07-14 04:30:06,470 [INFO    ] __main__: train step 870: loss: 0.3062, policy_loss: 1.9076, value_loss: 0.9875
2024-07-14 04:30:06,749 [INFO    ] __main__: train step 871: loss: 0.3064, policy_loss: 1.9076, value_loss: 0.9874
2024-07-14 04:30:07,040 [INFO    ] __main__: train step 872: loss: 0.3065, policy_loss: 1.9075, value_loss: 0.9874
2024-07-14 04:30:07,325 [INFO    ] __main__: train step 873: loss: 0.3067, policy_loss: 1.9074, value_loss: 0.9874
2024-07-14 04:30:07,603 [INFO    ] __main__: train step 874: loss: 0.3068, policy_loss: 1.9074, value_loss: 0.9873
2024-07-14 04:30:07,883 [INFO    ] __main__: train step 875: loss: 0.3070, policy_loss: 1.9073, value_loss: 0.9873
2024-07-14 04:30:08,148 [INFO    ] __main__: train step 876: loss: 0.3071, policy_loss: 1.9072, value_loss: 0.9873
2024-07-14 04:30:08,419 [INFO    ] __main__: train step 877: loss: 0.3073, policy_loss: 1.9072, value_loss: 0.9872
2024-07-14 04:30:08,689 [INFO    ] __main__: train step 878: loss: 0.3074, policy_loss: 1.9071, value_loss: 0.9872
2024-07-14 04:30:09,459 [INFO    ] __main__: train step 879: loss: 0.3076, policy_loss: 1.9070, value_loss: 0.9872
2024-07-14 04:30:09,720 [INFO    ] __main__: train step 880: loss: 0.3077, policy_loss: 1.9070, value_loss: 0.9871
2024-07-14 04:30:09,991 [INFO    ] __main__: train step 881: loss: 0.3079, policy_loss: 1.9069, value_loss: 0.9871
2024-07-14 04:30:10,257 [INFO    ] __main__: train step 882: loss: 0.3080, policy_loss: 1.9068, value_loss: 0.9871
2024-07-14 04:30:10,521 [INFO    ] __main__: train step 883: loss: 0.3082, policy_loss: 1.9068, value_loss: 0.9870
2024-07-14 04:30:12,298 [INFO    ] __main__: replay_buffer size = 30720
2024-07-14 04:30:12,543 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:30:14,291 [INFO    ] __main__: train step 884: loss: 0.3083, policy_loss: 1.9067, value_loss: 0.9870
2024-07-14 04:30:14,566 [INFO    ] __main__: train step 885: loss: 0.3085, policy_loss: 1.9066, value_loss: 0.9869
2024-07-14 04:30:14,848 [INFO    ] __main__: train step 886: loss: 0.3086, policy_loss: 1.9066, value_loss: 0.9869
2024-07-14 04:30:15,129 [INFO    ] __main__: train step 887: loss: 0.3088, policy_loss: 1.9065, value_loss: 0.9868
2024-07-14 04:30:15,404 [INFO    ] __main__: train step 888: loss: 0.3089, policy_loss: 1.9064, value_loss: 0.9868
2024-07-14 04:30:15,683 [INFO    ] __main__: train step 889: loss: 0.3091, policy_loss: 1.9064, value_loss: 0.9868
2024-07-14 04:30:15,949 [INFO    ] __main__: train step 890: loss: 0.3092, policy_loss: 1.9063, value_loss: 0.9867
2024-07-14 04:30:16,217 [INFO    ] __main__: train step 891: loss: 0.3093, policy_loss: 1.9063, value_loss: 0.9867
2024-07-14 04:30:16,482 [INFO    ] __main__: train step 892: loss: 0.3095, policy_loss: 1.9062, value_loss: 0.9867
2024-07-14 04:30:16,759 [INFO    ] __main__: train step 893: loss: 0.3097, policy_loss: 1.9061, value_loss: 0.9867
2024-07-14 04:30:17,312 [INFO    ] __main__: train step 894: loss: 0.3098, policy_loss: 1.9061, value_loss: 0.9867
2024-07-14 04:30:17,588 [INFO    ] __main__: train step 895: loss: 0.3099, policy_loss: 1.9060, value_loss: 0.9866
2024-07-14 04:30:17,867 [INFO    ] __main__: train step 896: loss: 0.3101, policy_loss: 1.9060, value_loss: 0.9866
2024-07-14 04:30:18,146 [INFO    ] __main__: train step 897: loss: 0.3102, policy_loss: 1.9059, value_loss: 0.9865
2024-07-14 04:30:18,457 [INFO    ] __main__: train step 898: loss: 0.3104, policy_loss: 1.9058, value_loss: 0.9865
2024-07-14 04:30:18,743 [INFO    ] __main__: train step 899: loss: 0.3105, policy_loss: 1.9058, value_loss: 0.9864
2024-07-14 04:30:19,017 [INFO    ] __main__: train step 900: loss: 0.3107, policy_loss: 1.9057, value_loss: 0.9864
2024-07-14 04:30:20,761 [INFO    ] __main__: replay_buffer size = 31232
2024-07-14 04:30:21,011 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:30:23,330 [INFO    ] __main__: train step 901: loss: 0.3108, policy_loss: 1.9057, value_loss: 0.9863
2024-07-14 04:30:23,609 [INFO    ] __main__: train step 902: loss: 0.3109, policy_loss: 1.9056, value_loss: 0.9863
2024-07-14 04:30:23,875 [INFO    ] __main__: train step 903: loss: 0.3111, policy_loss: 1.9055, value_loss: 0.9863
2024-07-14 04:30:24,143 [INFO    ] __main__: train step 904: loss: 0.3112, policy_loss: 1.9055, value_loss: 0.9863
2024-07-14 04:30:24,416 [INFO    ] __main__: train step 905: loss: 0.3114, policy_loss: 1.9054, value_loss: 0.9863
2024-07-14 04:30:24,693 [INFO    ] __main__: train step 906: loss: 0.3116, policy_loss: 1.9053, value_loss: 0.9863
2024-07-14 04:30:24,973 [INFO    ] __main__: train step 907: loss: 0.3117, policy_loss: 1.9053, value_loss: 0.9863
2024-07-14 04:30:25,245 [INFO    ] __main__: train step 908: loss: 0.3119, policy_loss: 1.9052, value_loss: 0.9862
2024-07-14 04:30:25,933 [INFO    ] __main__: train step 909: loss: 0.3121, policy_loss: 1.9051, value_loss: 0.9862
2024-07-14 04:30:26,198 [INFO    ] __main__: train step 910: loss: 0.3122, policy_loss: 1.9050, value_loss: 0.9862
2024-07-14 04:30:26,472 [INFO    ] __main__: train step 911: loss: 0.3124, policy_loss: 1.9050, value_loss: 0.9861
2024-07-14 04:30:26,747 [INFO    ] __main__: train step 912: loss: 0.3125, policy_loss: 1.9049, value_loss: 0.9861
2024-07-14 04:30:27,015 [INFO    ] __main__: train step 913: loss: 0.3127, policy_loss: 1.9048, value_loss: 0.9861
2024-07-14 04:30:27,288 [INFO    ] __main__: train step 914: loss: 0.3128, policy_loss: 1.9048, value_loss: 0.9860
2024-07-14 04:30:27,584 [INFO    ] __main__: train step 915: loss: 0.3130, policy_loss: 1.9047, value_loss: 0.9860
2024-07-14 04:30:27,855 [INFO    ] __main__: train step 916: loss: 0.3131, policy_loss: 1.9046, value_loss: 0.9859
2024-07-14 04:30:28,120 [INFO    ] __main__: train step 917: loss: 0.3132, policy_loss: 1.9045, value_loss: 0.9859
2024-07-14 04:30:29,834 [INFO    ] __main__: replay_buffer size = 31744
2024-07-14 04:30:30,089 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:30:32,442 [INFO    ] __main__: train step 918: loss: 0.3134, policy_loss: 1.9045, value_loss: 0.9859
2024-07-14 04:30:32,721 [INFO    ] __main__: train step 919: loss: 0.3135, policy_loss: 1.9044, value_loss: 0.9859
2024-07-14 04:30:32,999 [INFO    ] __main__: train step 920: loss: 0.3137, policy_loss: 1.9043, value_loss: 0.9858
2024-07-14 04:30:33,285 [INFO    ] __main__: train step 921: loss: 0.3138, policy_loss: 1.9043, value_loss: 0.9858
2024-07-14 04:30:33,562 [INFO    ] __main__: train step 922: loss: 0.3140, policy_loss: 1.9042, value_loss: 0.9858
2024-07-14 04:30:33,843 [INFO    ] __main__: train step 923: loss: 0.3142, policy_loss: 1.9041, value_loss: 0.9857
2024-07-14 04:30:34,433 [INFO    ] __main__: train step 924: loss: 0.3143, policy_loss: 1.9041, value_loss: 0.9857
2024-07-14 04:30:34,699 [INFO    ] __main__: train step 925: loss: 0.3145, policy_loss: 1.9040, value_loss: 0.9857
2024-07-14 04:30:34,978 [INFO    ] __main__: train step 926: loss: 0.3146, policy_loss: 1.9039, value_loss: 0.9857
2024-07-14 04:30:35,265 [INFO    ] __main__: train step 927: loss: 0.3148, policy_loss: 1.9039, value_loss: 0.9856
2024-07-14 04:30:35,539 [INFO    ] __main__: train step 928: loss: 0.3149, policy_loss: 1.9038, value_loss: 0.9856
2024-07-14 04:30:35,816 [INFO    ] __main__: train step 929: loss: 0.3151, policy_loss: 1.9037, value_loss: 0.9855
2024-07-14 04:30:36,117 [INFO    ] __main__: train step 930: loss: 0.3152, policy_loss: 1.9036, value_loss: 0.9855
2024-07-14 04:30:36,401 [INFO    ] __main__: train step 931: loss: 0.3154, policy_loss: 1.9036, value_loss: 0.9854
2024-07-14 04:30:36,672 [INFO    ] __main__: train step 932: loss: 0.3155, policy_loss: 1.9035, value_loss: 0.9854
2024-07-14 04:30:36,947 [INFO    ] __main__: train step 933: loss: 0.3157, policy_loss: 1.9034, value_loss: 0.9854
2024-07-14 04:30:37,223 [INFO    ] __main__: train step 934: loss: 0.3158, policy_loss: 1.9033, value_loss: 0.9854
2024-07-14 04:30:38,999 [INFO    ] __main__: replay_buffer size = 32256
2024-07-14 04:30:39,251 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:30:41,598 [INFO    ] __main__: train step 935: loss: 0.3160, policy_loss: 1.9033, value_loss: 0.9853
2024-07-14 04:30:41,880 [INFO    ] __main__: train step 936: loss: 0.3162, policy_loss: 1.9032, value_loss: 0.9853
2024-07-14 04:30:42,158 [INFO    ] __main__: train step 937: loss: 0.3163, policy_loss: 1.9031, value_loss: 0.9853
2024-07-14 04:30:42,438 [INFO    ] __main__: train step 938: loss: 0.3165, policy_loss: 1.9030, value_loss: 0.9853
2024-07-14 04:30:42,697 [INFO    ] __main__: train step 939: loss: 0.3166, policy_loss: 1.9029, value_loss: 0.9853
2024-07-14 04:30:43,450 [INFO    ] __main__: train step 940: loss: 0.3168, policy_loss: 1.9029, value_loss: 0.9853
2024-07-14 04:30:43,680 [INFO    ] __main__: train step 941: loss: 0.3170, policy_loss: 1.9028, value_loss: 0.9853
2024-07-14 04:30:43,931 [INFO    ] __main__: train step 942: loss: 0.3171, policy_loss: 1.9028, value_loss: 0.9852
2024-07-14 04:30:44,205 [INFO    ] __main__: train step 943: loss: 0.3173, policy_loss: 1.9027, value_loss: 0.9852
2024-07-14 04:30:44,462 [INFO    ] __main__: train step 944: loss: 0.3174, policy_loss: 1.9026, value_loss: 0.9852
2024-07-14 04:30:44,726 [INFO    ] __main__: train step 945: loss: 0.3176, policy_loss: 1.9026, value_loss: 0.9852
2024-07-14 04:30:44,991 [INFO    ] __main__: train step 946: loss: 0.3177, policy_loss: 1.9025, value_loss: 0.9851
2024-07-14 04:30:45,270 [INFO    ] __main__: train step 947: loss: 0.3179, policy_loss: 1.9024, value_loss: 0.9851
2024-07-14 04:30:45,545 [INFO    ] __main__: train step 948: loss: 0.3180, policy_loss: 1.9024, value_loss: 0.9851
2024-07-14 04:30:45,825 [INFO    ] __main__: train step 949: loss: 0.3182, policy_loss: 1.9023, value_loss: 0.9851
2024-07-14 04:30:46,098 [INFO    ] __main__: train step 950: loss: 0.3183, policy_loss: 1.9022, value_loss: 0.9851
2024-07-14 04:30:46,364 [INFO    ] __main__: train step 951: loss: 0.3185, policy_loss: 1.9021, value_loss: 0.9851
2024-07-14 04:30:48,151 [INFO    ] __main__: replay_buffer size = 32768
2024-07-14 04:30:48,409 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:30:50,144 [INFO    ] __main__: train step 952: loss: 0.3187, policy_loss: 1.9021, value_loss: 0.9850
2024-07-14 04:30:50,422 [INFO    ] __main__: train step 953: loss: 0.3188, policy_loss: 1.9020, value_loss: 0.9850
2024-07-14 04:30:50,699 [INFO    ] __main__: train step 954: loss: 0.3190, policy_loss: 1.9019, value_loss: 0.9850
2024-07-14 04:30:50,972 [INFO    ] __main__: train step 955: loss: 0.3191, policy_loss: 1.9018, value_loss: 0.9850
2024-07-14 04:30:51,551 [INFO    ] __main__: train step 956: loss: 0.3193, policy_loss: 1.9018, value_loss: 0.9849
2024-07-14 04:30:51,836 [INFO    ] __main__: train step 957: loss: 0.3194, policy_loss: 1.9017, value_loss: 0.9849
2024-07-14 04:30:52,106 [INFO    ] __main__: train step 958: loss: 0.3196, policy_loss: 1.9016, value_loss: 0.9849
2024-07-14 04:30:52,382 [INFO    ] __main__: train step 959: loss: 0.3198, policy_loss: 1.9015, value_loss: 0.9849
2024-07-14 04:30:52,651 [INFO    ] __main__: train step 960: loss: 0.3199, policy_loss: 1.9015, value_loss: 0.9848
2024-07-14 04:30:52,913 [INFO    ] __main__: train step 961: loss: 0.3201, policy_loss: 1.9014, value_loss: 0.9849
2024-07-14 04:30:53,187 [INFO    ] __main__: train step 962: loss: 0.3202, policy_loss: 1.9013, value_loss: 0.9848
2024-07-14 04:30:53,465 [INFO    ] __main__: train step 963: loss: 0.3204, policy_loss: 1.9012, value_loss: 0.9848
2024-07-14 04:30:53,734 [INFO    ] __main__: train step 964: loss: 0.3205, policy_loss: 1.9012, value_loss: 0.9848
2024-07-14 04:30:53,993 [INFO    ] __main__: train step 965: loss: 0.3207, policy_loss: 1.9011, value_loss: 0.9847
2024-07-14 04:30:54,263 [INFO    ] __main__: train step 966: loss: 0.3208, policy_loss: 1.9010, value_loss: 0.9847
2024-07-14 04:30:54,533 [INFO    ] __main__: train step 967: loss: 0.3210, policy_loss: 1.9010, value_loss: 0.9847
2024-07-14 04:30:54,808 [INFO    ] __main__: train step 968: loss: 0.3212, policy_loss: 1.9009, value_loss: 0.9847
2024-07-14 04:30:56,584 [INFO    ] __main__: replay_buffer size = 33280
2024-07-14 04:30:56,841 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:30:59,671 [INFO    ] __main__: train step 969: loss: 0.3214, policy_loss: 1.9008, value_loss: 0.9847
2024-07-14 04:30:59,964 [INFO    ] __main__: train step 970: loss: 0.3215, policy_loss: 1.9007, value_loss: 0.9847
2024-07-14 04:31:00,650 [INFO    ] __main__: train step 971: loss: 0.3217, policy_loss: 1.9007, value_loss: 0.9847
2024-07-14 04:31:00,930 [INFO    ] __main__: train step 972: loss: 0.3218, policy_loss: 1.9006, value_loss: 0.9847
2024-07-14 04:31:01,197 [INFO    ] __main__: train step 973: loss: 0.3220, policy_loss: 1.9005, value_loss: 0.9846
2024-07-14 04:31:01,511 [INFO    ] __main__: train step 974: loss: 0.3221, policy_loss: 1.9004, value_loss: 0.9846
2024-07-14 04:31:01,785 [INFO    ] __main__: train step 975: loss: 0.3223, policy_loss: 1.9004, value_loss: 0.9846
2024-07-14 04:31:02,056 [INFO    ] __main__: train step 976: loss: 0.3225, policy_loss: 1.9003, value_loss: 0.9845
2024-07-14 04:31:02,335 [INFO    ] __main__: train step 977: loss: 0.3226, policy_loss: 1.9002, value_loss: 0.9845
2024-07-14 04:31:02,610 [INFO    ] __main__: train step 978: loss: 0.3228, policy_loss: 1.9001, value_loss: 0.9845
2024-07-14 04:31:02,894 [INFO    ] __main__: train step 979: loss: 0.3229, policy_loss: 1.9001, value_loss: 0.9845
2024-07-14 04:31:03,164 [INFO    ] __main__: train step 980: loss: 0.3231, policy_loss: 1.9000, value_loss: 0.9844
2024-07-14 04:31:03,429 [INFO    ] __main__: train step 981: loss: 0.3233, policy_loss: 1.8999, value_loss: 0.9844
2024-07-14 04:31:03,701 [INFO    ] __main__: train step 982: loss: 0.3234, policy_loss: 1.8999, value_loss: 0.9844
2024-07-14 04:31:03,984 [INFO    ] __main__: train step 983: loss: 0.3235, policy_loss: 1.8998, value_loss: 0.9844
2024-07-14 04:31:04,265 [INFO    ] __main__: train step 984: loss: 0.3237, policy_loss: 1.8997, value_loss: 0.9844
2024-07-14 04:31:04,543 [INFO    ] __main__: train step 985: loss: 0.3238, policy_loss: 1.8997, value_loss: 0.9843
2024-07-14 04:31:06,333 [INFO    ] __main__: replay_buffer size = 33792
2024-07-14 04:31:06,605 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:31:09,180 [INFO    ] __main__: train step 986: loss: 0.3240, policy_loss: 1.8996, value_loss: 0.9843
2024-07-14 04:31:09,930 [INFO    ] __main__: train step 987: loss: 0.3242, policy_loss: 1.8995, value_loss: 0.9843
2024-07-14 04:31:10,197 [INFO    ] __main__: train step 988: loss: 0.3243, policy_loss: 1.8994, value_loss: 0.9842
2024-07-14 04:31:10,478 [INFO    ] __main__: train step 989: loss: 0.3245, policy_loss: 1.8994, value_loss: 0.9842
2024-07-14 04:31:10,746 [INFO    ] __main__: train step 990: loss: 0.3246, policy_loss: 1.8993, value_loss: 0.9842
2024-07-14 04:31:11,018 [INFO    ] __main__: train step 991: loss: 0.3248, policy_loss: 1.8993, value_loss: 0.9842
2024-07-14 04:31:11,299 [INFO    ] __main__: train step 992: loss: 0.3249, policy_loss: 1.8992, value_loss: 0.9842
2024-07-14 04:31:11,575 [INFO    ] __main__: train step 993: loss: 0.3251, policy_loss: 1.8991, value_loss: 0.9842
2024-07-14 04:31:11,854 [INFO    ] __main__: train step 994: loss: 0.3253, policy_loss: 1.8991, value_loss: 0.9841
2024-07-14 04:31:12,106 [INFO    ] __main__: train step 995: loss: 0.3254, policy_loss: 1.8990, value_loss: 0.9841
2024-07-14 04:31:12,384 [INFO    ] __main__: train step 996: loss: 0.3256, policy_loss: 1.8989, value_loss: 0.9841
2024-07-14 04:31:12,697 [INFO    ] __main__: train step 997: loss: 0.3257, policy_loss: 1.8989, value_loss: 0.9840
2024-07-14 04:31:12,967 [INFO    ] __main__: train step 998: loss: 0.3259, policy_loss: 1.8988, value_loss: 0.9840
2024-07-14 04:31:13,247 [INFO    ] __main__: train step 999: loss: 0.3260, policy_loss: 1.8988, value_loss: 0.9840
2024-07-14 04:31:13,533 [INFO    ] __main__: train step 1000: loss: 0.3262, policy_loss: 1.8987, value_loss: 0.9840
2024-07-14 04:31:13,707 [INFO    ] __main__: restored step 0 for evaluation
2024-07-14 04:47:50,859 [INFO    ] __main__: jax.local_devices(): [cuda(id=0)]
2024-07-14 04:47:50,860 [INFO    ] __main__: selecting devices: [cuda(id=0)]
2024-07-14 04:47:50,860 [INFO    ] __main__: JAX found 1 devices
2024-07-14 04:47:52,636 [DEBUG   ] __main__: 

                                                                AlphaZeroNet Summary                                                                
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ path                         ┃ module         ┃ inputs              ┃ outputs           ┃ flops ┃ params                     ┃ batch_stats       ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│                              │ AlphaZeroNet   │ - float32[1,6,7,2]  │ - float32[1,7]    │ 0     │                            │                   │
│                              │                │ - train: False      │ - float32[1]      │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ConvBlock_0                 │ _ConvBlock     │ - float32[1,6,7,2]  │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ConvBlock_0/Conv_0          │ Conv           │ float32[1,6,7,2]    │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,2,64]  │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 1,216 (4.9 KB)             │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ConvBlock_0/BatchNorm_0     │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0                │ _PolicyHead    │ - float32[1,6,7,64] │ float32[1,7]      │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0/Conv_0         │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[1,1,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 4,160 (16.6 KB)            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0/BatchNorm_0    │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0/Dense_0        │ Dense          │ float32[1,2688]     │ float32[1,7]      │ 0     │ bias: float32[7]           │                   │
│                              │                │                     │                   │       │ kernel: float32[2688,7]    │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 18,823 (75.3 KB)           │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0                 │ _ValueHead     │ - float32[1,6,7,64] │ float32[1]        │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/Conv_0          │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,1]  │ 0     │ bias: float32[1]           │                   │
│                              │                │                     │                   │       │ kernel: float32[1,1,64,1]  │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 65 (260 B)                 │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/BatchNorm_0     │ BatchNorm      │ float32[1,6,7,1]    │ float32[1,6,7,1]  │ 0     │ bias: float32[1]           │ mean: float32[1]  │
│                              │                │                     │                   │       │ scale: float32[1]          │ var: float32[1]   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 2 (8 B)                    │ 2 (8 B)           │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/Dense_0         │ Dense          │ float32[1,42]       │ float32[1,64]     │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[42,64]     │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 2,752 (11.0 KB)            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/BatchNorm_1     │ BatchNorm      │ float32[1,64]       │ float32[1,64]     │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/Dense_1         │ Dense          │ float32[1,64]       │ float32[1,1]      │ 0     │ bias: float32[1]           │                   │
│                              │                │                     │                   │       │ kernel: float32[64,1]      │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 65 (260 B)                 │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│                              │                │                     │                   │ Total │ 398,027 (1.6 MB)           │ 1,666 (6.7 KB)    │
└──────────────────────────────┴────────────────┴─────────────────────┴───────────────────┴───────┴────────────────────────────┴───────────────────┘
                                                                                                                                                    
                                                         Total Parameters: 399,693 (1.6 MB)                                                         


2024-07-14 04:47:56,484 [INFO    ] __main__: jax.local_devices(): [cuda(id=0)]
2024-07-14 04:47:56,485 [INFO    ] __main__: selecting devices: [cuda(id=0)]
2024-07-14 04:47:56,485 [INFO    ] __main__: JAX found 1 devices
2024-07-14 04:48:05,008 [INFO    ] __main__: restored training checkpoint at step 999
2024-07-14 04:48:05,270 [INFO    ] __main__: loaded replay_buffer from storage
2024-07-14 04:48:13,128 [INFO    ] __main__: replay_buffer size = 34304
2024-07-14 04:48:13,375 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:48:23,861 [INFO    ] __main__: train step 1000: loss: 0.3262, policy_loss: 1.8987, value_loss: 0.9839
2024-07-14 04:48:24,000 [INFO    ] __main__: restored step 0 for evaluation
2024-07-14 04:49:48,142 [INFO    ] __main__: jax.local_devices(): [cuda(id=0)]
2024-07-14 04:49:48,143 [INFO    ] __main__: selecting devices: [cuda(id=0)]
2024-07-14 04:49:48,143 [INFO    ] __main__: JAX found 1 devices
2024-07-14 04:49:49,993 [DEBUG   ] __main__: 

                                                                AlphaZeroNet Summary                                                                
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ path                         ┃ module         ┃ inputs              ┃ outputs           ┃ flops ┃ params                     ┃ batch_stats       ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│                              │ AlphaZeroNet   │ - float32[1,6,7,2]  │ - float32[1,7]    │ 0     │                            │                   │
│                              │                │ - train: False      │ - float32[1]      │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ConvBlock_0                 │ _ConvBlock     │ - float32[1,6,7,2]  │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ConvBlock_0/Conv_0          │ Conv           │ float32[1,6,7,2]    │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,2,64]  │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 1,216 (4.9 KB)             │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ConvBlock_0/BatchNorm_0     │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0                │ _PolicyHead    │ - float32[1,6,7,64] │ float32[1,7]      │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0/Conv_0         │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[1,1,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 4,160 (16.6 KB)            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0/BatchNorm_0    │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0/Dense_0        │ Dense          │ float32[1,2688]     │ float32[1,7]      │ 0     │ bias: float32[7]           │                   │
│                              │                │                     │                   │       │ kernel: float32[2688,7]    │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 18,823 (75.3 KB)           │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0                 │ _ValueHead     │ - float32[1,6,7,64] │ float32[1]        │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/Conv_0          │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,1]  │ 0     │ bias: float32[1]           │                   │
│                              │                │                     │                   │       │ kernel: float32[1,1,64,1]  │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 65 (260 B)                 │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/BatchNorm_0     │ BatchNorm      │ float32[1,6,7,1]    │ float32[1,6,7,1]  │ 0     │ bias: float32[1]           │ mean: float32[1]  │
│                              │                │                     │                   │       │ scale: float32[1]          │ var: float32[1]   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 2 (8 B)                    │ 2 (8 B)           │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/Dense_0         │ Dense          │ float32[1,42]       │ float32[1,64]     │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[42,64]     │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 2,752 (11.0 KB)            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/BatchNorm_1     │ BatchNorm      │ float32[1,64]       │ float32[1,64]     │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/Dense_1         │ Dense          │ float32[1,64]       │ float32[1,1]      │ 0     │ bias: float32[1]           │                   │
│                              │                │                     │                   │       │ kernel: float32[64,1]      │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 65 (260 B)                 │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│                              │                │                     │                   │ Total │ 398,027 (1.6 MB)           │ 1,666 (6.7 KB)    │
└──────────────────────────────┴────────────────┴─────────────────────┴───────────────────┴───────┴────────────────────────────┴───────────────────┘
                                                                                                                                                    
                                                         Total Parameters: 399,693 (1.6 MB)                                                         


2024-07-14 04:49:54,061 [INFO    ] __main__: jax.local_devices(): [cuda(id=0)]
2024-07-14 04:49:54,061 [INFO    ] __main__: selecting devices: [cuda(id=0)]
2024-07-14 04:49:54,061 [INFO    ] __main__: JAX found 1 devices
2024-07-14 04:50:03,367 [INFO    ] __main__: restored training checkpoint at step 999
2024-07-14 04:50:03,643 [INFO    ] __main__: loaded replay_buffer from storage
2024-07-14 04:50:11,985 [INFO    ] __main__: replay_buffer size = 34816
2024-07-14 04:50:12,288 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:50:22,791 [INFO    ] __main__: train step 1000: loss: 0.3262, policy_loss: 1.8987, value_loss: 0.9840
2024-07-14 04:50:22,941 [INFO    ] __main__: restored step 0 for evaluation
2024-07-14 04:53:55,623 [INFO    ] __main__: jax.local_devices(): [cuda(id=0)]
2024-07-14 04:53:55,623 [INFO    ] __main__: selecting devices: [cuda(id=0)]
2024-07-14 04:53:55,623 [INFO    ] __main__: JAX found 1 devices
2024-07-14 04:53:57,426 [DEBUG   ] __main__: 

                                                                AlphaZeroNet Summary                                                                
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ path                         ┃ module         ┃ inputs              ┃ outputs           ┃ flops ┃ params                     ┃ batch_stats       ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│                              │ AlphaZeroNet   │ - float32[1,6,7,2]  │ - float32[1,7]    │ 0     │                            │                   │
│                              │                │ - train: False      │ - float32[1]      │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ConvBlock_0                 │ _ConvBlock     │ - float32[1,6,7,2]  │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ConvBlock_0/Conv_0          │ Conv           │ float32[1,6,7,2]    │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,2,64]  │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 1,216 (4.9 KB)             │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ConvBlock_0/BatchNorm_0     │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_0/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_1/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_2/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_3/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[3,3,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 36,928 (147.7 KB)          │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ResidualBlock_4/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0                │ _PolicyHead    │ - float32[1,6,7,64] │ float32[1,7]      │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0/Conv_0         │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[1,1,64,64] │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 4,160 (16.6 KB)            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0/BatchNorm_0    │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _PolicyHead_0/Dense_0        │ Dense          │ float32[1,2688]     │ float32[1,7]      │ 0     │ bias: float32[7]           │                   │
│                              │                │                     │                   │       │ kernel: float32[2688,7]    │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 18,823 (75.3 KB)           │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0                 │ _ValueHead     │ - float32[1,6,7,64] │ float32[1]        │ 0     │                            │                   │
│                              │                │ - False             │                   │       │                            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/Conv_0          │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,1]  │ 0     │ bias: float32[1]           │                   │
│                              │                │                     │                   │       │ kernel: float32[1,1,64,1]  │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 65 (260 B)                 │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/BatchNorm_0     │ BatchNorm      │ float32[1,6,7,1]    │ float32[1,6,7,1]  │ 0     │ bias: float32[1]           │ mean: float32[1]  │
│                              │                │                     │                   │       │ scale: float32[1]          │ var: float32[1]   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 2 (8 B)                    │ 2 (8 B)           │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/Dense_0         │ Dense          │ float32[1,42]       │ float32[1,64]     │ 0     │ bias: float32[64]          │                   │
│                              │                │                     │                   │       │ kernel: float32[42,64]     │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 2,752 (11.0 KB)            │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/BatchNorm_1     │ BatchNorm      │ float32[1,64]       │ float32[1,64]     │ 0     │ bias: float32[64]          │ mean: float32[64] │
│                              │                │                     │                   │       │ scale: float32[64]         │ var: float32[64]  │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 128 (512 B)                │ 128 (512 B)       │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│ _ValueHead_0/Dense_1         │ Dense          │ float32[1,64]       │ float32[1,1]      │ 0     │ bias: float32[1]           │                   │
│                              │                │                     │                   │       │ kernel: float32[64,1]      │                   │
│                              │                │                     │                   │       │                            │                   │
│                              │                │                     │                   │       │ 65 (260 B)                 │                   │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼────────────────────────────┼───────────────────┤
│                              │                │                     │                   │ Total │ 398,027 (1.6 MB)           │ 1,666 (6.7 KB)    │
└──────────────────────────────┴────────────────┴─────────────────────┴───────────────────┴───────┴────────────────────────────┴───────────────────┘
                                                                                                                                                    
                                                         Total Parameters: 399,693 (1.6 MB)                                                         


2024-07-14 04:54:01,267 [INFO    ] __main__: jax.local_devices(): [cuda(id=0)]
2024-07-14 04:54:01,267 [INFO    ] __main__: selecting devices: [cuda(id=0)]
2024-07-14 04:54:01,267 [INFO    ] __main__: JAX found 1 devices
2024-07-14 04:54:09,926 [INFO    ] __main__: restored training checkpoint at step 999
2024-07-14 04:54:10,190 [INFO    ] __main__: loaded replay_buffer from storage
2024-07-14 04:54:18,086 [INFO    ] __main__: replay_buffer size = 35328
2024-07-14 04:54:18,375 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:54:29,017 [INFO    ] __main__: train step 1000: loss: 0.3262, policy_loss: 1.8987, value_loss: 0.9840
2024-07-14 04:54:29,158 [INFO    ] __main__: restored step 0 for evaluation
2024-07-14 04:54:48,908 [INFO    ] __main__: test network ELO difference from baseline network: +424 (+12/-12) ELO from 32000 self-played games
2024-07-14 04:54:48,912 [INFO    ] __main__: game outcomes: W: 28652, D: 0, L: 3348
2024-07-14 04:54:48,916 [INFO    ] __main__: validation_elo_delta: 424, validation_elo: 424
2024-07-14 04:54:50,870 [INFO    ] __main__: train step 1001: loss: 0.3263, policy_loss: 1.8986, value_loss: 0.9840
2024-07-14 04:54:51,132 [INFO    ] __main__: train step 1002: loss: 0.3265, policy_loss: 1.8986, value_loss: 0.9839
2024-07-14 04:54:51,400 [INFO    ] __main__: train step 1003: loss: 0.3266, policy_loss: 1.8985, value_loss: 0.9839
2024-07-14 04:54:51,665 [INFO    ] __main__: train step 1004: loss: 0.3268, policy_loss: 1.8985, value_loss: 0.9839
2024-07-14 04:54:51,935 [INFO    ] __main__: train step 1005: loss: 0.3269, policy_loss: 1.8984, value_loss: 0.9838
2024-07-14 04:54:52,202 [INFO    ] __main__: train step 1006: loss: 0.3271, policy_loss: 1.8984, value_loss: 0.9838
2024-07-14 04:54:52,476 [INFO    ] __main__: train step 1007: loss: 0.3273, policy_loss: 1.8983, value_loss: 0.9838
2024-07-14 04:54:52,747 [INFO    ] __main__: train step 1008: loss: 0.3274, policy_loss: 1.8982, value_loss: 0.9838
2024-07-14 04:54:53,312 [INFO    ] __main__: train step 1009: loss: 0.3276, policy_loss: 1.8982, value_loss: 0.9837
2024-07-14 04:54:53,579 [INFO    ] __main__: train step 1010: loss: 0.3277, policy_loss: 1.8981, value_loss: 0.9837
2024-07-14 04:54:53,853 [INFO    ] __main__: train step 1011: loss: 0.3279, policy_loss: 1.8981, value_loss: 0.9837
2024-07-14 04:54:54,133 [INFO    ] __main__: train step 1012: loss: 0.3280, policy_loss: 1.8980, value_loss: 0.9836
2024-07-14 04:54:54,407 [INFO    ] __main__: train step 1013: loss: 0.3282, policy_loss: 1.8979, value_loss: 0.9836
2024-07-14 04:54:54,671 [INFO    ] __main__: train step 1014: loss: 0.3283, policy_loss: 1.8979, value_loss: 0.9836
2024-07-14 04:54:54,931 [INFO    ] __main__: train step 1015: loss: 0.3285, policy_loss: 1.8978, value_loss: 0.9836
2024-07-14 04:54:55,196 [INFO    ] __main__: train step 1016: loss: 0.3286, policy_loss: 1.8977, value_loss: 0.9836
2024-07-14 04:54:56,930 [INFO    ] __main__: replay_buffer size = 35840
2024-07-14 04:54:57,212 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:54:59,730 [INFO    ] __main__: train step 1017: loss: 0.3288, policy_loss: 1.8977, value_loss: 0.9835
2024-07-14 04:54:59,994 [INFO    ] __main__: train step 1018: loss: 0.3290, policy_loss: 1.8976, value_loss: 0.9836
2024-07-14 04:55:00,271 [INFO    ] __main__: train step 1019: loss: 0.3291, policy_loss: 1.8975, value_loss: 0.9836
2024-07-14 04:55:00,548 [INFO    ] __main__: train step 1020: loss: 0.3292, policy_loss: 1.8975, value_loss: 0.9836
2024-07-14 04:55:00,821 [INFO    ] __main__: train step 1021: loss: 0.3294, policy_loss: 1.8974, value_loss: 0.9835
2024-07-14 04:55:01,093 [INFO    ] __main__: train step 1022: loss: 0.3296, policy_loss: 1.8973, value_loss: 0.9835
2024-07-14 04:55:01,362 [INFO    ] __main__: train step 1023: loss: 0.3297, policy_loss: 1.8973, value_loss: 0.9835
2024-07-14 04:55:01,637 [INFO    ] __main__: train step 1024: loss: 0.3299, policy_loss: 1.8972, value_loss: 0.9835
2024-07-14 04:55:02,205 [INFO    ] __main__: train step 1025: loss: 0.3300, policy_loss: 1.8971, value_loss: 0.9835
2024-07-14 04:55:02,486 [INFO    ] __main__: train step 1026: loss: 0.3302, policy_loss: 1.8970, value_loss: 0.9834
2024-07-14 04:55:02,762 [INFO    ] __main__: train step 1027: loss: 0.3303, policy_loss: 1.8970, value_loss: 0.9834
2024-07-14 04:55:03,029 [INFO    ] __main__: train step 1028: loss: 0.3305, policy_loss: 1.8969, value_loss: 0.9834
2024-07-14 04:55:03,295 [INFO    ] __main__: train step 1029: loss: 0.3307, policy_loss: 1.8968, value_loss: 0.9834
2024-07-14 04:55:03,583 [INFO    ] __main__: train step 1030: loss: 0.3308, policy_loss: 1.8967, value_loss: 0.9834
2024-07-14 04:55:03,863 [INFO    ] __main__: train step 1031: loss: 0.3310, policy_loss: 1.8967, value_loss: 0.9834
2024-07-14 04:55:04,136 [INFO    ] __main__: train step 1032: loss: 0.3311, policy_loss: 1.8966, value_loss: 0.9833
2024-07-14 04:55:04,405 [INFO    ] __main__: train step 1033: loss: 0.3313, policy_loss: 1.8965, value_loss: 0.9833
2024-07-14 04:55:06,170 [INFO    ] __main__: replay_buffer size = 36352
2024-07-14 04:55:06,450 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:55:09,095 [INFO    ] __main__: train step 1034: loss: 0.3315, policy_loss: 1.8965, value_loss: 0.9833
2024-07-14 04:55:09,374 [INFO    ] __main__: train step 1035: loss: 0.3316, policy_loss: 1.8964, value_loss: 0.9832
2024-07-14 04:55:09,651 [INFO    ] __main__: train step 1036: loss: 0.3318, policy_loss: 1.8963, value_loss: 0.9832
2024-07-14 04:55:09,930 [INFO    ] __main__: train step 1037: loss: 0.3319, policy_loss: 1.8963, value_loss: 0.9832
2024-07-14 04:55:10,211 [INFO    ] __main__: train step 1038: loss: 0.3321, policy_loss: 1.8962, value_loss: 0.9832
2024-07-14 04:55:10,473 [INFO    ] __main__: train step 1039: loss: 0.3322, policy_loss: 1.8961, value_loss: 0.9832
2024-07-14 04:55:10,733 [INFO    ] __main__: train step 1040: loss: 0.3324, policy_loss: 1.8961, value_loss: 0.9832
2024-07-14 04:55:11,265 [INFO    ] __main__: train step 1041: loss: 0.3325, policy_loss: 1.8960, value_loss: 0.9832
2024-07-14 04:55:11,506 [INFO    ] __main__: train step 1042: loss: 0.3327, policy_loss: 1.8959, value_loss: 0.9832
2024-07-14 04:55:11,747 [INFO    ] __main__: train step 1043: loss: 0.3328, policy_loss: 1.8959, value_loss: 0.9832
2024-07-14 04:55:12,005 [INFO    ] __main__: train step 1044: loss: 0.3330, policy_loss: 1.8958, value_loss: 0.9832
2024-07-14 04:55:12,272 [INFO    ] __main__: train step 1045: loss: 0.3332, policy_loss: 1.8957, value_loss: 0.9832
2024-07-14 04:55:12,554 [INFO    ] __main__: train step 1046: loss: 0.3333, policy_loss: 1.8957, value_loss: 0.9832
2024-07-14 04:55:12,833 [INFO    ] __main__: train step 1047: loss: 0.3335, policy_loss: 1.8956, value_loss: 0.9832
2024-07-14 04:55:13,114 [INFO    ] __main__: train step 1048: loss: 0.3336, policy_loss: 1.8955, value_loss: 0.9831
2024-07-14 04:55:13,392 [INFO    ] __main__: train step 1049: loss: 0.3338, policy_loss: 1.8955, value_loss: 0.9831
2024-07-14 04:55:13,665 [INFO    ] __main__: train step 1050: loss: 0.3339, policy_loss: 1.8954, value_loss: 0.9831
2024-07-14 04:55:15,413 [INFO    ] __main__: replay_buffer size = 36864
2024-07-14 04:55:15,700 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:55:17,559 [INFO    ] __main__: train step 1051: loss: 0.3341, policy_loss: 1.8953, value_loss: 0.9831
2024-07-14 04:55:17,836 [INFO    ] __main__: train step 1052: loss: 0.3343, policy_loss: 1.8953, value_loss: 0.9831
2024-07-14 04:55:18,105 [INFO    ] __main__: train step 1053: loss: 0.3345, policy_loss: 1.8952, value_loss: 0.9831
2024-07-14 04:55:18,383 [INFO    ] __main__: train step 1054: loss: 0.3346, policy_loss: 1.8951, value_loss: 0.9831
2024-07-14 04:55:18,650 [INFO    ] __main__: train step 1055: loss: 0.3347, policy_loss: 1.8951, value_loss: 0.9831
2024-07-14 04:55:18,926 [INFO    ] __main__: train step 1056: loss: 0.3349, policy_loss: 1.8950, value_loss: 0.9831
2024-07-14 04:55:19,200 [INFO    ] __main__: train step 1057: loss: 0.3351, policy_loss: 1.8949, value_loss: 0.9831
2024-07-14 04:55:19,749 [INFO    ] __main__: train step 1058: loss: 0.3352, policy_loss: 1.8949, value_loss: 0.9830
2024-07-14 04:55:20,038 [INFO    ] __main__: train step 1059: loss: 0.3354, policy_loss: 1.8948, value_loss: 0.9830
2024-07-14 04:55:20,315 [INFO    ] __main__: train step 1060: loss: 0.3355, policy_loss: 1.8947, value_loss: 0.9830
2024-07-14 04:55:20,586 [INFO    ] __main__: train step 1061: loss: 0.3357, policy_loss: 1.8947, value_loss: 0.9830
2024-07-14 04:55:20,858 [INFO    ] __main__: train step 1062: loss: 0.3359, policy_loss: 1.8946, value_loss: 0.9830
2024-07-14 04:55:21,132 [INFO    ] __main__: train step 1063: loss: 0.3360, policy_loss: 1.8946, value_loss: 0.9830
2024-07-14 04:55:21,398 [INFO    ] __main__: train step 1064: loss: 0.3362, policy_loss: 1.8945, value_loss: 0.9830
2024-07-14 04:55:21,679 [INFO    ] __main__: train step 1065: loss: 0.3364, policy_loss: 1.8944, value_loss: 0.9830
2024-07-14 04:55:21,951 [INFO    ] __main__: train step 1066: loss: 0.3365, policy_loss: 1.8944, value_loss: 0.9830
2024-07-14 04:55:22,225 [INFO    ] __main__: train step 1067: loss: 0.3367, policy_loss: 1.8943, value_loss: 0.9830
2024-07-14 04:55:23,948 [INFO    ] __main__: replay_buffer size = 37376
2024-07-14 04:55:24,238 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:55:26,782 [INFO    ] __main__: train step 1068: loss: 0.3368, policy_loss: 1.8943, value_loss: 0.9830
2024-07-14 04:55:27,057 [INFO    ] __main__: train step 1069: loss: 0.3370, policy_loss: 1.8942, value_loss: 0.9830
2024-07-14 04:55:27,330 [INFO    ] __main__: train step 1070: loss: 0.3372, policy_loss: 1.8941, value_loss: 0.9829
2024-07-14 04:55:27,607 [INFO    ] __main__: train step 1071: loss: 0.3373, policy_loss: 1.8941, value_loss: 0.9829
2024-07-14 04:55:27,879 [INFO    ] __main__: train step 1072: loss: 0.3375, policy_loss: 1.8940, value_loss: 0.9829
2024-07-14 04:55:28,152 [INFO    ] __main__: train step 1073: loss: 0.3377, policy_loss: 1.8940, value_loss: 0.9829
2024-07-14 04:55:28,718 [INFO    ] __main__: train step 1074: loss: 0.3378, policy_loss: 1.8939, value_loss: 0.9829
2024-07-14 04:55:29,000 [INFO    ] __main__: train step 1075: loss: 0.3380, policy_loss: 1.8938, value_loss: 0.9829
2024-07-14 04:55:29,270 [INFO    ] __main__: train step 1076: loss: 0.3382, policy_loss: 1.8937, value_loss: 0.9829
2024-07-14 04:55:29,526 [INFO    ] __main__: train step 1077: loss: 0.3384, policy_loss: 1.8937, value_loss: 0.9828
2024-07-14 04:55:29,798 [INFO    ] __main__: train step 1078: loss: 0.3385, policy_loss: 1.8936, value_loss: 0.9828
2024-07-14 04:55:30,083 [INFO    ] __main__: train step 1079: loss: 0.3387, policy_loss: 1.8935, value_loss: 0.9828
2024-07-14 04:55:30,361 [INFO    ] __main__: train step 1080: loss: 0.3388, policy_loss: 1.8935, value_loss: 0.9828
2024-07-14 04:55:30,632 [INFO    ] __main__: train step 1081: loss: 0.3390, policy_loss: 1.8934, value_loss: 0.9827
2024-07-14 04:55:30,893 [INFO    ] __main__: train step 1082: loss: 0.3392, policy_loss: 1.8933, value_loss: 0.9827
2024-07-14 04:55:31,178 [INFO    ] __main__: train step 1083: loss: 0.3393, policy_loss: 1.8932, value_loss: 0.9827
2024-07-14 04:55:31,437 [INFO    ] __main__: train step 1084: loss: 0.3395, policy_loss: 1.8932, value_loss: 0.9827
2024-07-14 04:55:33,192 [INFO    ] __main__: replay_buffer size = 37888
2024-07-14 04:55:33,459 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:55:35,944 [INFO    ] __main__: train step 1085: loss: 0.3396, policy_loss: 1.8931, value_loss: 0.9827
2024-07-14 04:55:36,222 [INFO    ] __main__: train step 1086: loss: 0.3398, policy_loss: 1.8930, value_loss: 0.9827
2024-07-14 04:55:36,491 [INFO    ] __main__: train step 1087: loss: 0.3400, policy_loss: 1.8930, value_loss: 0.9827
2024-07-14 04:55:36,767 [INFO    ] __main__: train step 1088: loss: 0.3401, policy_loss: 1.8929, value_loss: 0.9827
2024-07-14 04:55:37,037 [INFO    ] __main__: train step 1089: loss: 0.3403, policy_loss: 1.8928, value_loss: 0.9827
2024-07-14 04:55:37,302 [INFO    ] __main__: train step 1090: loss: 0.3405, policy_loss: 1.8928, value_loss: 0.9827
2024-07-14 04:55:37,860 [INFO    ] __main__: train step 1091: loss: 0.3406, policy_loss: 1.8927, value_loss: 0.9827
2024-07-14 04:55:38,133 [INFO    ] __main__: train step 1092: loss: 0.3408, policy_loss: 1.8927, value_loss: 0.9827
2024-07-14 04:55:38,384 [INFO    ] __main__: train step 1093: loss: 0.3409, policy_loss: 1.8926, value_loss: 0.9826
2024-07-14 04:55:38,651 [INFO    ] __main__: train step 1094: loss: 0.3411, policy_loss: 1.8925, value_loss: 0.9826
2024-07-14 04:55:38,940 [INFO    ] __main__: train step 1095: loss: 0.3412, policy_loss: 1.8925, value_loss: 0.9826
2024-07-14 04:55:39,216 [INFO    ] __main__: train step 1096: loss: 0.3414, policy_loss: 1.8924, value_loss: 0.9826
2024-07-14 04:55:39,490 [INFO    ] __main__: train step 1097: loss: 0.3416, policy_loss: 1.8924, value_loss: 0.9825
2024-07-14 04:55:39,761 [INFO    ] __main__: train step 1098: loss: 0.3417, policy_loss: 1.8923, value_loss: 0.9825
2024-07-14 04:55:40,040 [INFO    ] __main__: train step 1099: loss: 0.3419, policy_loss: 1.8922, value_loss: 0.9825
2024-07-14 04:55:40,349 [INFO    ] __main__: train step 1100: loss: 0.3420, policy_loss: 1.8922, value_loss: 0.9824
2024-07-14 04:55:40,612 [INFO    ] __main__: train step 1101: loss: 0.3422, policy_loss: 1.8921, value_loss: 0.9824
2024-07-14 04:55:42,402 [INFO    ] __main__: replay_buffer size = 38400
2024-07-14 04:55:42,699 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:55:45,289 [INFO    ] __main__: train step 1102: loss: 0.3423, policy_loss: 1.8920, value_loss: 0.9824
2024-07-14 04:55:45,552 [INFO    ] __main__: train step 1103: loss: 0.3425, policy_loss: 1.8920, value_loss: 0.9825
2024-07-14 04:55:45,815 [INFO    ] __main__: train step 1104: loss: 0.3426, policy_loss: 1.8919, value_loss: 0.9825
2024-07-14 04:55:46,085 [INFO    ] __main__: train step 1105: loss: 0.3428, policy_loss: 1.8918, value_loss: 0.9825
2024-07-14 04:55:46,357 [INFO    ] __main__: train step 1106: loss: 0.3429, policy_loss: 1.8918, value_loss: 0.9824
2024-07-14 04:55:46,934 [INFO    ] __main__: train step 1107: loss: 0.3431, policy_loss: 1.8917, value_loss: 0.9824
2024-07-14 04:55:47,204 [INFO    ] __main__: train step 1108: loss: 0.3432, policy_loss: 1.8916, value_loss: 0.9824
2024-07-14 04:55:47,478 [INFO    ] __main__: train step 1109: loss: 0.3434, policy_loss: 1.8916, value_loss: 0.9824
2024-07-14 04:55:47,766 [INFO    ] __main__: train step 1110: loss: 0.3436, policy_loss: 1.8915, value_loss: 0.9824
2024-07-14 04:55:48,034 [INFO    ] __main__: train step 1111: loss: 0.3437, policy_loss: 1.8914, value_loss: 0.9824
2024-07-14 04:55:48,314 [INFO    ] __main__: train step 1112: loss: 0.3439, policy_loss: 1.8913, value_loss: 0.9824
2024-07-14 04:55:48,609 [INFO    ] __main__: train step 1113: loss: 0.3441, policy_loss: 1.8913, value_loss: 0.9823
2024-07-14 04:55:48,880 [INFO    ] __main__: train step 1114: loss: 0.3442, policy_loss: 1.8912, value_loss: 0.9823
2024-07-14 04:55:49,154 [INFO    ] __main__: train step 1115: loss: 0.3444, policy_loss: 1.8911, value_loss: 0.9823
2024-07-14 04:55:49,413 [INFO    ] __main__: train step 1116: loss: 0.3445, policy_loss: 1.8911, value_loss: 0.9823
2024-07-14 04:55:49,678 [INFO    ] __main__: train step 1117: loss: 0.3447, policy_loss: 1.8910, value_loss: 0.9823
2024-07-14 04:55:49,949 [INFO    ] __main__: train step 1118: loss: 0.3449, policy_loss: 1.8910, value_loss: 0.9823
2024-07-14 04:55:51,717 [INFO    ] __main__: replay_buffer size = 38912
2024-07-14 04:55:52,027 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:55:53,909 [INFO    ] __main__: train step 1119: loss: 0.3450, policy_loss: 1.8909, value_loss: 0.9823
2024-07-14 04:55:54,185 [INFO    ] __main__: train step 1120: loss: 0.3452, policy_loss: 1.8908, value_loss: 0.9823
2024-07-14 04:55:54,451 [INFO    ] __main__: train step 1121: loss: 0.3453, policy_loss: 1.8907, value_loss: 0.9823
2024-07-14 04:55:54,729 [INFO    ] __main__: train step 1122: loss: 0.3455, policy_loss: 1.8907, value_loss: 0.9823
2024-07-14 04:55:55,005 [INFO    ] __main__: train step 1123: loss: 0.3456, policy_loss: 1.8906, value_loss: 0.9822
2024-07-14 04:55:55,746 [INFO    ] __main__: train step 1124: loss: 0.3458, policy_loss: 1.8905, value_loss: 0.9822
2024-07-14 04:55:56,027 [INFO    ] __main__: train step 1125: loss: 0.3460, policy_loss: 1.8905, value_loss: 0.9822
2024-07-14 04:55:56,298 [INFO    ] __main__: train step 1126: loss: 0.3461, policy_loss: 1.8904, value_loss: 0.9822
2024-07-14 04:55:56,570 [INFO    ] __main__: train step 1127: loss: 0.3463, policy_loss: 1.8903, value_loss: 0.9822
2024-07-14 04:55:56,868 [INFO    ] __main__: train step 1128: loss: 0.3464, policy_loss: 1.8903, value_loss: 0.9822
2024-07-14 04:55:57,143 [INFO    ] __main__: train step 1129: loss: 0.3466, policy_loss: 1.8902, value_loss: 0.9822
2024-07-14 04:55:57,410 [INFO    ] __main__: train step 1130: loss: 0.3468, policy_loss: 1.8901, value_loss: 0.9822
2024-07-14 04:55:57,682 [INFO    ] __main__: train step 1131: loss: 0.3470, policy_loss: 1.8900, value_loss: 0.9822
2024-07-14 04:55:57,944 [INFO    ] __main__: train step 1132: loss: 0.3471, policy_loss: 1.8900, value_loss: 0.9822
2024-07-14 04:55:58,220 [INFO    ] __main__: train step 1133: loss: 0.3473, policy_loss: 1.8899, value_loss: 0.9822
2024-07-14 04:55:58,492 [INFO    ] __main__: train step 1134: loss: 0.3474, policy_loss: 1.8898, value_loss: 0.9822
2024-07-14 04:55:58,768 [INFO    ] __main__: train step 1135: loss: 0.3476, policy_loss: 1.8898, value_loss: 0.9822
2024-07-14 04:56:00,520 [INFO    ] __main__: replay_buffer size = 39424
2024-07-14 04:56:00,832 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:56:03,316 [INFO    ] __main__: train step 1136: loss: 0.3478, policy_loss: 1.8897, value_loss: 0.9822
2024-07-14 04:56:03,605 [INFO    ] __main__: train step 1137: loss: 0.3480, policy_loss: 1.8897, value_loss: 0.9821
2024-07-14 04:56:03,908 [INFO    ] __main__: train step 1138: loss: 0.3481, policy_loss: 1.8896, value_loss: 0.9821
2024-07-14 04:56:04,201 [INFO    ] __main__: train step 1139: loss: 0.3483, policy_loss: 1.8895, value_loss: 0.9822
2024-07-14 04:56:04,963 [INFO    ] __main__: train step 1140: loss: 0.3485, policy_loss: 1.8894, value_loss: 0.9821
2024-07-14 04:56:05,248 [INFO    ] __main__: train step 1141: loss: 0.3486, policy_loss: 1.8894, value_loss: 0.9821
2024-07-14 04:56:05,530 [INFO    ] __main__: train step 1142: loss: 0.3488, policy_loss: 1.8893, value_loss: 0.9821
2024-07-14 04:56:05,798 [INFO    ] __main__: train step 1143: loss: 0.3489, policy_loss: 1.8892, value_loss: 0.9821
2024-07-14 04:56:06,071 [INFO    ] __main__: train step 1144: loss: 0.3491, policy_loss: 1.8892, value_loss: 0.9821
2024-07-14 04:56:06,350 [INFO    ] __main__: train step 1145: loss: 0.3493, policy_loss: 1.8891, value_loss: 0.9821
2024-07-14 04:56:06,624 [INFO    ] __main__: train step 1146: loss: 0.3494, policy_loss: 1.8890, value_loss: 0.9821
2024-07-14 04:56:06,893 [INFO    ] __main__: train step 1147: loss: 0.3496, policy_loss: 1.8890, value_loss: 0.9821
2024-07-14 04:56:07,176 [INFO    ] __main__: train step 1148: loss: 0.3498, policy_loss: 1.8889, value_loss: 0.9821
2024-07-14 04:56:07,454 [INFO    ] __main__: train step 1149: loss: 0.3499, policy_loss: 1.8888, value_loss: 0.9820
2024-07-14 04:56:07,733 [INFO    ] __main__: train step 1150: loss: 0.3501, policy_loss: 1.8888, value_loss: 0.9820
2024-07-14 04:56:08,008 [INFO    ] __main__: train step 1151: loss: 0.3502, policy_loss: 1.8887, value_loss: 0.9820
2024-07-14 04:56:08,277 [INFO    ] __main__: train step 1152: loss: 0.3504, policy_loss: 1.8886, value_loss: 0.9820
2024-07-14 04:56:10,068 [INFO    ] __main__: replay_buffer size = 39936
2024-07-14 04:56:10,392 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:56:12,965 [INFO    ] __main__: train step 1153: loss: 0.3505, policy_loss: 1.8885, value_loss: 0.9820
2024-07-14 04:56:13,240 [INFO    ] __main__: train step 1154: loss: 0.3507, policy_loss: 1.8885, value_loss: 0.9820
2024-07-14 04:56:13,502 [INFO    ] __main__: train step 1155: loss: 0.3508, policy_loss: 1.8884, value_loss: 0.9820
2024-07-14 04:56:13,769 [INFO    ] __main__: train step 1156: loss: 0.3510, policy_loss: 1.8883, value_loss: 0.9820
2024-07-14 04:56:14,559 [INFO    ] __main__: train step 1157: loss: 0.3512, policy_loss: 1.8882, value_loss: 0.9820
2024-07-14 04:56:14,829 [INFO    ] __main__: train step 1158: loss: 0.3514, policy_loss: 1.8882, value_loss: 0.9820
2024-07-14 04:56:15,100 [INFO    ] __main__: train step 1159: loss: 0.3515, policy_loss: 1.8881, value_loss: 0.9820
2024-07-14 04:56:15,371 [INFO    ] __main__: train step 1160: loss: 0.3517, policy_loss: 1.8880, value_loss: 0.9820
2024-07-14 04:56:15,635 [INFO    ] __main__: train step 1161: loss: 0.3519, policy_loss: 1.8880, value_loss: 0.9820
2024-07-14 04:56:15,918 [INFO    ] __main__: train step 1162: loss: 0.3520, policy_loss: 1.8879, value_loss: 0.9820
2024-07-14 04:56:16,189 [INFO    ] __main__: train step 1163: loss: 0.3522, policy_loss: 1.8879, value_loss: 0.9820
2024-07-14 04:56:16,463 [INFO    ] __main__: train step 1164: loss: 0.3524, policy_loss: 1.8878, value_loss: 0.9820
2024-07-14 04:56:16,727 [INFO    ] __main__: train step 1165: loss: 0.3525, policy_loss: 1.8877, value_loss: 0.9820
2024-07-14 04:56:16,990 [INFO    ] __main__: train step 1166: loss: 0.3527, policy_loss: 1.8876, value_loss: 0.9820
2024-07-14 04:56:17,262 [INFO    ] __main__: train step 1167: loss: 0.3528, policy_loss: 1.8876, value_loss: 0.9820
2024-07-14 04:56:17,540 [INFO    ] __main__: train step 1168: loss: 0.3530, policy_loss: 1.8875, value_loss: 0.9820
2024-07-14 04:56:17,812 [INFO    ] __main__: train step 1169: loss: 0.3531, policy_loss: 1.8874, value_loss: 0.9820
2024-07-14 04:56:19,547 [INFO    ] __main__: replay_buffer size = 40448
2024-07-14 04:56:19,867 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:56:22,409 [INFO    ] __main__: train step 1170: loss: 0.3533, policy_loss: 1.8873, value_loss: 0.9820
2024-07-14 04:56:22,682 [INFO    ] __main__: train step 1171: loss: 0.3534, policy_loss: 1.8873, value_loss: 0.9820
2024-07-14 04:56:22,945 [INFO    ] __main__: train step 1172: loss: 0.3536, policy_loss: 1.8872, value_loss: 0.9820
2024-07-14 04:56:23,505 [INFO    ] __main__: train step 1173: loss: 0.3538, policy_loss: 1.8871, value_loss: 0.9820
2024-07-14 04:56:23,779 [INFO    ] __main__: train step 1174: loss: 0.3539, policy_loss: 1.8870, value_loss: 0.9819
2024-07-14 04:56:24,048 [INFO    ] __main__: train step 1175: loss: 0.3541, policy_loss: 1.8870, value_loss: 0.9819
2024-07-14 04:56:24,312 [INFO    ] __main__: train step 1176: loss: 0.3543, policy_loss: 1.8869, value_loss: 0.9819
2024-07-14 04:56:24,572 [INFO    ] __main__: train step 1177: loss: 0.3544, policy_loss: 1.8868, value_loss: 0.9819
2024-07-14 04:56:24,841 [INFO    ] __main__: train step 1178: loss: 0.3546, policy_loss: 1.8868, value_loss: 0.9819
2024-07-14 04:56:25,114 [INFO    ] __main__: train step 1179: loss: 0.3547, policy_loss: 1.8867, value_loss: 0.9819
2024-07-14 04:56:25,397 [INFO    ] __main__: train step 1180: loss: 0.3549, policy_loss: 1.8866, value_loss: 0.9819
2024-07-14 04:56:25,670 [INFO    ] __main__: train step 1181: loss: 0.3551, policy_loss: 1.8866, value_loss: 0.9819
2024-07-14 04:56:25,960 [INFO    ] __main__: train step 1182: loss: 0.3552, policy_loss: 1.8865, value_loss: 0.9819
2024-07-14 04:56:26,225 [INFO    ] __main__: train step 1183: loss: 0.3554, policy_loss: 1.8864, value_loss: 0.9819
2024-07-14 04:56:26,482 [INFO    ] __main__: train step 1184: loss: 0.3556, policy_loss: 1.8863, value_loss: 0.9819
2024-07-14 04:56:26,748 [INFO    ] __main__: train step 1185: loss: 0.3557, policy_loss: 1.8863, value_loss: 0.9819
2024-07-14 04:56:27,024 [INFO    ] __main__: train step 1186: loss: 0.3559, policy_loss: 1.8862, value_loss: 0.9818
2024-07-14 04:56:28,813 [INFO    ] __main__: replay_buffer size = 40960
2024-07-14 04:56:29,138 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:56:30,973 [INFO    ] __main__: train step 1187: loss: 0.3561, policy_loss: 1.8861, value_loss: 0.9819
2024-07-14 04:56:31,243 [INFO    ] __main__: train step 1188: loss: 0.3562, policy_loss: 1.8861, value_loss: 0.9818
2024-07-14 04:56:32,043 [INFO    ] __main__: train step 1189: loss: 0.3564, policy_loss: 1.8860, value_loss: 0.9819
2024-07-14 04:56:32,306 [INFO    ] __main__: train step 1190: loss: 0.3565, policy_loss: 1.8859, value_loss: 0.9819
2024-07-14 04:56:32,575 [INFO    ] __main__: train step 1191: loss: 0.3567, policy_loss: 1.8859, value_loss: 0.9818
2024-07-14 04:56:32,847 [INFO    ] __main__: train step 1192: loss: 0.3569, policy_loss: 1.8858, value_loss: 0.9818
2024-07-14 04:56:33,127 [INFO    ] __main__: train step 1193: loss: 0.3571, policy_loss: 1.8857, value_loss: 0.9818
2024-07-14 04:56:33,397 [INFO    ] __main__: train step 1194: loss: 0.3572, policy_loss: 1.8856, value_loss: 0.9818
2024-07-14 04:56:33,670 [INFO    ] __main__: train step 1195: loss: 0.3574, policy_loss: 1.8856, value_loss: 0.9818
2024-07-14 04:56:33,948 [INFO    ] __main__: train step 1196: loss: 0.3575, policy_loss: 1.8855, value_loss: 0.9817
2024-07-14 04:56:34,221 [INFO    ] __main__: train step 1197: loss: 0.3577, policy_loss: 1.8854, value_loss: 0.9817
2024-07-14 04:56:34,489 [INFO    ] __main__: train step 1198: loss: 0.3579, policy_loss: 1.8854, value_loss: 0.9817
2024-07-14 04:56:34,777 [INFO    ] __main__: train step 1199: loss: 0.3580, policy_loss: 1.8853, value_loss: 0.9817
2024-07-14 04:56:35,042 [INFO    ] __main__: train step 1200: loss: 0.3582, policy_loss: 1.8852, value_loss: 0.9817
2024-07-14 04:56:35,319 [INFO    ] __main__: train step 1201: loss: 0.3583, policy_loss: 1.8852, value_loss: 0.9817
2024-07-14 04:56:35,599 [INFO    ] __main__: train step 1202: loss: 0.3585, policy_loss: 1.8851, value_loss: 0.9817
2024-07-14 04:56:35,872 [INFO    ] __main__: train step 1203: loss: 0.3586, policy_loss: 1.8850, value_loss: 0.9817
2024-07-14 04:56:37,660 [INFO    ] __main__: replay_buffer size = 41472
2024-07-14 04:56:37,985 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:56:40,488 [INFO    ] __main__: train step 1204: loss: 0.3588, policy_loss: 1.8850, value_loss: 0.9817
2024-07-14 04:56:40,765 [INFO    ] __main__: train step 1205: loss: 0.3590, policy_loss: 1.8849, value_loss: 0.9817
2024-07-14 04:56:41,329 [INFO    ] __main__: train step 1206: loss: 0.3592, policy_loss: 1.8848, value_loss: 0.9817
2024-07-14 04:56:41,604 [INFO    ] __main__: train step 1207: loss: 0.3593, policy_loss: 1.8848, value_loss: 0.9817
2024-07-14 04:56:41,871 [INFO    ] __main__: train step 1208: loss: 0.3595, policy_loss: 1.8847, value_loss: 0.9817
2024-07-14 04:56:42,146 [INFO    ] __main__: train step 1209: loss: 0.3596, policy_loss: 1.8846, value_loss: 0.9817
2024-07-14 04:56:42,420 [INFO    ] __main__: train step 1210: loss: 0.3598, policy_loss: 1.8846, value_loss: 0.9817
2024-07-14 04:56:42,701 [INFO    ] __main__: train step 1211: loss: 0.3599, policy_loss: 1.8845, value_loss: 0.9817
2024-07-14 04:56:42,969 [INFO    ] __main__: train step 1212: loss: 0.3601, policy_loss: 1.8844, value_loss: 0.9817
2024-07-14 04:56:43,240 [INFO    ] __main__: train step 1213: loss: 0.3602, policy_loss: 1.8844, value_loss: 0.9817
2024-07-14 04:56:43,506 [INFO    ] __main__: train step 1214: loss: 0.3604, policy_loss: 1.8843, value_loss: 0.9817
2024-07-14 04:56:43,769 [INFO    ] __main__: train step 1215: loss: 0.3606, policy_loss: 1.8842, value_loss: 0.9817
2024-07-14 04:56:44,036 [INFO    ] __main__: train step 1216: loss: 0.3608, policy_loss: 1.8842, value_loss: 0.9817
2024-07-14 04:56:44,308 [INFO    ] __main__: train step 1217: loss: 0.3609, policy_loss: 1.8841, value_loss: 0.9816
2024-07-14 04:56:44,572 [INFO    ] __main__: train step 1218: loss: 0.3611, policy_loss: 1.8840, value_loss: 0.9816
2024-07-14 04:56:44,829 [INFO    ] __main__: train step 1219: loss: 0.3613, policy_loss: 1.8839, value_loss: 0.9816
2024-07-14 04:56:45,094 [INFO    ] __main__: train step 1220: loss: 0.3614, policy_loss: 1.8838, value_loss: 0.9816
2024-07-14 04:56:46,857 [INFO    ] __main__: replay_buffer size = 41984
2024-07-14 04:56:47,177 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:56:49,671 [INFO    ] __main__: train step 1221: loss: 0.3616, policy_loss: 1.8838, value_loss: 0.9816
2024-07-14 04:56:49,940 [INFO    ] __main__: train step 1222: loss: 0.3618, policy_loss: 1.8837, value_loss: 0.9816
2024-07-14 04:56:50,504 [INFO    ] __main__: train step 1223: loss: 0.3620, policy_loss: 1.8836, value_loss: 0.9816
2024-07-14 04:56:50,806 [INFO    ] __main__: train step 1224: loss: 0.3621, policy_loss: 1.8835, value_loss: 0.9816
2024-07-14 04:56:51,077 [INFO    ] __main__: train step 1225: loss: 0.3623, policy_loss: 1.8835, value_loss: 0.9816
2024-07-14 04:56:51,340 [INFO    ] __main__: train step 1226: loss: 0.3624, policy_loss: 1.8834, value_loss: 0.9816
2024-07-14 04:56:51,610 [INFO    ] __main__: train step 1227: loss: 0.3626, policy_loss: 1.8833, value_loss: 0.9816
2024-07-14 04:56:51,876 [INFO    ] __main__: train step 1228: loss: 0.3627, policy_loss: 1.8833, value_loss: 0.9816
2024-07-14 04:56:52,148 [INFO    ] __main__: train step 1229: loss: 0.3629, policy_loss: 1.8832, value_loss: 0.9816
2024-07-14 04:56:52,419 [INFO    ] __main__: train step 1230: loss: 0.3631, policy_loss: 1.8831, value_loss: 0.9816
2024-07-14 04:56:52,690 [INFO    ] __main__: train step 1231: loss: 0.3632, policy_loss: 1.8830, value_loss: 0.9815
2024-07-14 04:56:52,949 [INFO    ] __main__: train step 1232: loss: 0.3633, policy_loss: 1.8830, value_loss: 0.9816
2024-07-14 04:56:53,226 [INFO    ] __main__: train step 1233: loss: 0.3635, policy_loss: 1.8829, value_loss: 0.9816
2024-07-14 04:56:53,496 [INFO    ] __main__: train step 1234: loss: 0.3636, policy_loss: 1.8828, value_loss: 0.9816
2024-07-14 04:56:53,763 [INFO    ] __main__: train step 1235: loss: 0.3638, policy_loss: 1.8828, value_loss: 0.9816
2024-07-14 04:56:54,028 [INFO    ] __main__: train step 1236: loss: 0.3640, policy_loss: 1.8827, value_loss: 0.9816
2024-07-14 04:56:54,303 [INFO    ] __main__: train step 1237: loss: 0.3641, policy_loss: 1.8826, value_loss: 0.9816
2024-07-14 04:56:56,067 [INFO    ] __main__: replay_buffer size = 42496
2024-07-14 04:56:56,377 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:56:58,881 [INFO    ] __main__: train step 1238: loss: 0.3643, policy_loss: 1.8825, value_loss: 0.9816
2024-07-14 04:56:59,154 [INFO    ] __main__: train step 1239: loss: 0.3644, policy_loss: 1.8825, value_loss: 0.9816
2024-07-14 04:56:59,954 [INFO    ] __main__: train step 1240: loss: 0.3646, policy_loss: 1.8824, value_loss: 0.9816
2024-07-14 04:57:00,211 [INFO    ] __main__: train step 1241: loss: 0.3647, policy_loss: 1.8823, value_loss: 0.9816
2024-07-14 04:57:00,486 [INFO    ] __main__: train step 1242: loss: 0.3649, policy_loss: 1.8823, value_loss: 0.9816
2024-07-14 04:57:00,753 [INFO    ] __main__: train step 1243: loss: 0.3651, policy_loss: 1.8822, value_loss: 0.9816
2024-07-14 04:57:01,028 [INFO    ] __main__: train step 1244: loss: 0.3653, policy_loss: 1.8822, value_loss: 0.9816
2024-07-14 04:57:01,304 [INFO    ] __main__: train step 1245: loss: 0.3654, policy_loss: 1.8821, value_loss: 0.9815
2024-07-14 04:57:01,582 [INFO    ] __main__: train step 1246: loss: 0.3656, policy_loss: 1.8820, value_loss: 0.9815
2024-07-14 04:57:01,883 [INFO    ] __main__: train step 1247: loss: 0.3657, policy_loss: 1.8819, value_loss: 0.9815
2024-07-14 04:57:02,154 [INFO    ] __main__: train step 1248: loss: 0.3659, policy_loss: 1.8819, value_loss: 0.9815
2024-07-14 04:57:02,436 [INFO    ] __main__: train step 1249: loss: 0.3660, policy_loss: 1.8818, value_loss: 0.9815
2024-07-14 04:57:02,725 [INFO    ] __main__: train step 1250: loss: 0.3662, policy_loss: 1.8817, value_loss: 0.9815
2024-07-14 04:57:02,996 [INFO    ] __main__: train step 1251: loss: 0.3664, policy_loss: 1.8817, value_loss: 0.9815
2024-07-14 04:57:03,270 [INFO    ] __main__: train step 1252: loss: 0.3665, policy_loss: 1.8816, value_loss: 0.9815
2024-07-14 04:57:03,533 [INFO    ] __main__: train step 1253: loss: 0.3667, policy_loss: 1.8815, value_loss: 0.9815
2024-07-14 04:57:03,800 [INFO    ] __main__: train step 1254: loss: 0.3668, policy_loss: 1.8815, value_loss: 0.9815
2024-07-14 04:57:05,575 [INFO    ] __main__: replay_buffer size = 43008
2024-07-14 04:57:05,923 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:57:07,783 [INFO    ] __main__: train step 1255: loss: 0.3670, policy_loss: 1.8814, value_loss: 0.9815
2024-07-14 04:57:08,055 [INFO    ] __main__: train step 1256: loss: 0.3672, policy_loss: 1.8813, value_loss: 0.9815
2024-07-14 04:57:08,819 [INFO    ] __main__: train step 1257: loss: 0.3673, policy_loss: 1.8812, value_loss: 0.9815
2024-07-14 04:57:09,102 [INFO    ] __main__: train step 1258: loss: 0.3675, policy_loss: 1.8811, value_loss: 0.9815
2024-07-14 04:57:09,393 [INFO    ] __main__: train step 1259: loss: 0.3677, policy_loss: 1.8810, value_loss: 0.9815
2024-07-14 04:57:09,648 [INFO    ] __main__: train step 1260: loss: 0.3679, policy_loss: 1.8810, value_loss: 0.9814
2024-07-14 04:57:09,925 [INFO    ] __main__: train step 1261: loss: 0.3680, policy_loss: 1.8809, value_loss: 0.9814
2024-07-14 04:57:10,187 [INFO    ] __main__: train step 1262: loss: 0.3682, policy_loss: 1.8808, value_loss: 0.9814
2024-07-14 04:57:10,456 [INFO    ] __main__: train step 1263: loss: 0.3683, policy_loss: 1.8807, value_loss: 0.9814
2024-07-14 04:57:10,734 [INFO    ] __main__: train step 1264: loss: 0.3685, policy_loss: 1.8806, value_loss: 0.9814
2024-07-14 04:57:11,001 [INFO    ] __main__: train step 1265: loss: 0.3686, policy_loss: 1.8806, value_loss: 0.9814
2024-07-14 04:57:11,280 [INFO    ] __main__: train step 1266: loss: 0.3688, policy_loss: 1.8805, value_loss: 0.9814
2024-07-14 04:57:11,553 [INFO    ] __main__: train step 1267: loss: 0.3690, policy_loss: 1.8804, value_loss: 0.9814
2024-07-14 04:57:11,817 [INFO    ] __main__: train step 1268: loss: 0.3691, policy_loss: 1.8803, value_loss: 0.9814
2024-07-14 04:57:12,087 [INFO    ] __main__: train step 1269: loss: 0.3693, policy_loss: 1.8802, value_loss: 0.9814
2024-07-14 04:57:12,362 [INFO    ] __main__: train step 1270: loss: 0.3695, policy_loss: 1.8802, value_loss: 0.9814
2024-07-14 04:57:12,631 [INFO    ] __main__: train step 1271: loss: 0.3696, policy_loss: 1.8801, value_loss: 0.9814
2024-07-14 04:57:14,373 [INFO    ] __main__: replay_buffer size = 43520
2024-07-14 04:57:14,672 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:57:17,167 [INFO    ] __main__: train step 1272: loss: 0.3698, policy_loss: 1.8800, value_loss: 0.9814
2024-07-14 04:57:17,456 [INFO    ] __main__: train step 1273: loss: 0.3700, policy_loss: 1.8799, value_loss: 0.9814
2024-07-14 04:57:17,725 [INFO    ] __main__: train step 1274: loss: 0.3701, policy_loss: 1.8798, value_loss: 0.9814
2024-07-14 04:57:18,287 [INFO    ] __main__: train step 1275: loss: 0.3703, policy_loss: 1.8797, value_loss: 0.9814
2024-07-14 04:57:18,561 [INFO    ] __main__: train step 1276: loss: 0.3704, policy_loss: 1.8797, value_loss: 0.9814
2024-07-14 04:57:18,831 [INFO    ] __main__: train step 1277: loss: 0.3706, policy_loss: 1.8796, value_loss: 0.9815
2024-07-14 04:57:19,099 [INFO    ] __main__: train step 1278: loss: 0.3707, policy_loss: 1.8795, value_loss: 0.9815
2024-07-14 04:57:19,376 [INFO    ] __main__: train step 1279: loss: 0.3709, policy_loss: 1.8794, value_loss: 0.9815
2024-07-14 04:57:19,648 [INFO    ] __main__: train step 1280: loss: 0.3711, policy_loss: 1.8794, value_loss: 0.9815
2024-07-14 04:57:19,922 [INFO    ] __main__: train step 1281: loss: 0.3712, policy_loss: 1.8793, value_loss: 0.9815
2024-07-14 04:57:20,185 [INFO    ] __main__: train step 1282: loss: 0.3714, policy_loss: 1.8792, value_loss: 0.9815
2024-07-14 04:57:20,473 [INFO    ] __main__: train step 1283: loss: 0.3715, policy_loss: 1.8791, value_loss: 0.9815
2024-07-14 04:57:20,747 [INFO    ] __main__: train step 1284: loss: 0.3717, policy_loss: 1.8790, value_loss: 0.9815
2024-07-14 04:57:21,023 [INFO    ] __main__: train step 1285: loss: 0.3719, policy_loss: 1.8789, value_loss: 0.9815
2024-07-14 04:57:21,288 [INFO    ] __main__: train step 1286: loss: 0.3720, policy_loss: 1.8789, value_loss: 0.9815
2024-07-14 04:57:21,557 [INFO    ] __main__: train step 1287: loss: 0.3722, policy_loss: 1.8788, value_loss: 0.9815
2024-07-14 04:57:21,824 [INFO    ] __main__: train step 1288: loss: 0.3724, policy_loss: 1.8787, value_loss: 0.9814
2024-07-14 04:57:23,612 [INFO    ] __main__: replay_buffer size = 44032
2024-07-14 04:57:23,953 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:57:26,448 [INFO    ] __main__: train step 1289: loss: 0.3726, policy_loss: 1.8786, value_loss: 0.9814
2024-07-14 04:57:26,727 [INFO    ] __main__: train step 1290: loss: 0.3727, policy_loss: 1.8785, value_loss: 0.9814
2024-07-14 04:57:26,985 [INFO    ] __main__: train step 1291: loss: 0.3729, policy_loss: 1.8785, value_loss: 0.9814
2024-07-14 04:57:27,678 [INFO    ] __main__: train step 1292: loss: 0.3730, policy_loss: 1.8784, value_loss: 0.9814
2024-07-14 04:57:27,946 [INFO    ] __main__: train step 1293: loss: 0.3732, policy_loss: 1.8783, value_loss: 0.9814
2024-07-14 04:57:28,209 [INFO    ] __main__: train step 1294: loss: 0.3734, policy_loss: 1.8782, value_loss: 0.9814
2024-07-14 04:57:28,477 [INFO    ] __main__: train step 1295: loss: 0.3735, policy_loss: 1.8782, value_loss: 0.9814
2024-07-14 04:57:28,736 [INFO    ] __main__: train step 1296: loss: 0.3737, policy_loss: 1.8781, value_loss: 0.9814
2024-07-14 04:57:29,016 [INFO    ] __main__: train step 1297: loss: 0.3739, policy_loss: 1.8780, value_loss: 0.9814
2024-07-14 04:57:29,292 [INFO    ] __main__: train step 1298: loss: 0.3741, policy_loss: 1.8780, value_loss: 0.9814
2024-07-14 04:57:29,564 [INFO    ] __main__: train step 1299: loss: 0.3742, policy_loss: 1.8779, value_loss: 0.9814
2024-07-14 04:57:29,834 [INFO    ] __main__: train step 1300: loss: 0.3744, policy_loss: 1.8778, value_loss: 0.9814
2024-07-14 04:57:30,114 [INFO    ] __main__: train step 1301: loss: 0.3745, policy_loss: 1.8777, value_loss: 0.9814
2024-07-14 04:57:30,375 [INFO    ] __main__: train step 1302: loss: 0.3747, policy_loss: 1.8777, value_loss: 0.9814
2024-07-14 04:57:30,662 [INFO    ] __main__: train step 1303: loss: 0.3749, policy_loss: 1.8776, value_loss: 0.9814
2024-07-14 04:57:30,922 [INFO    ] __main__: train step 1304: loss: 0.3750, policy_loss: 1.8775, value_loss: 0.9813
2024-07-14 04:57:31,201 [INFO    ] __main__: train step 1305: loss: 0.3752, policy_loss: 1.8774, value_loss: 0.9813
2024-07-14 04:57:32,956 [INFO    ] __main__: replay_buffer size = 44544
2024-07-14 04:57:33,265 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:57:35,979 [INFO    ] __main__: train step 1306: loss: 0.3754, policy_loss: 1.8774, value_loss: 0.9813
2024-07-14 04:57:36,251 [INFO    ] __main__: train step 1307: loss: 0.3755, policy_loss: 1.8773, value_loss: 0.9813
2024-07-14 04:57:36,520 [INFO    ] __main__: train step 1308: loss: 0.3757, policy_loss: 1.8772, value_loss: 0.9813
2024-07-14 04:57:36,811 [INFO    ] __main__: train step 1309: loss: 0.3758, policy_loss: 1.8772, value_loss: 0.9813
2024-07-14 04:57:37,482 [INFO    ] __main__: train step 1310: loss: 0.3760, policy_loss: 1.8771, value_loss: 0.9813
2024-07-14 04:57:37,758 [INFO    ] __main__: train step 1311: loss: 0.3762, policy_loss: 1.8770, value_loss: 0.9812
2024-07-14 04:57:38,030 [INFO    ] __main__: train step 1312: loss: 0.3764, policy_loss: 1.8770, value_loss: 0.9812
2024-07-14 04:57:38,293 [INFO    ] __main__: train step 1313: loss: 0.3765, policy_loss: 1.8769, value_loss: 0.9812
2024-07-14 04:57:38,554 [INFO    ] __main__: train step 1314: loss: 0.3767, policy_loss: 1.8768, value_loss: 0.9812
2024-07-14 04:57:38,843 [INFO    ] __main__: train step 1315: loss: 0.3768, policy_loss: 1.8767, value_loss: 0.9812
2024-07-14 04:57:39,126 [INFO    ] __main__: train step 1316: loss: 0.3770, policy_loss: 1.8767, value_loss: 0.9812
2024-07-14 04:57:39,416 [INFO    ] __main__: train step 1317: loss: 0.3772, policy_loss: 1.8766, value_loss: 0.9811
2024-07-14 04:57:39,707 [INFO    ] __main__: train step 1318: loss: 0.3773, policy_loss: 1.8765, value_loss: 0.9811
2024-07-14 04:57:39,987 [INFO    ] __main__: train step 1319: loss: 0.3775, policy_loss: 1.8764, value_loss: 0.9811
2024-07-14 04:57:40,248 [INFO    ] __main__: train step 1320: loss: 0.3776, policy_loss: 1.8764, value_loss: 0.9811
2024-07-14 04:57:40,526 [INFO    ] __main__: train step 1321: loss: 0.3778, policy_loss: 1.8763, value_loss: 0.9811
2024-07-14 04:57:40,805 [INFO    ] __main__: train step 1322: loss: 0.3780, policy_loss: 1.8762, value_loss: 0.9811
2024-07-14 04:57:42,580 [INFO    ] __main__: replay_buffer size = 45056
2024-07-14 04:57:42,875 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:57:44,833 [INFO    ] __main__: train step 1323: loss: 0.3781, policy_loss: 1.8761, value_loss: 0.9811
2024-07-14 04:57:45,186 [INFO    ] __main__: train step 1324: loss: 0.3783, policy_loss: 1.8761, value_loss: 0.9811
2024-07-14 04:57:45,447 [INFO    ] __main__: train step 1325: loss: 0.3784, policy_loss: 1.8760, value_loss: 0.9810
2024-07-14 04:57:45,711 [INFO    ] __main__: train step 1326: loss: 0.3786, policy_loss: 1.8759, value_loss: 0.9810
2024-07-14 04:57:46,277 [INFO    ] __main__: train step 1327: loss: 0.3788, policy_loss: 1.8758, value_loss: 0.9810
2024-07-14 04:57:46,543 [INFO    ] __main__: train step 1328: loss: 0.3790, policy_loss: 1.8758, value_loss: 0.9810
2024-07-14 04:57:46,809 [INFO    ] __main__: train step 1329: loss: 0.3791, policy_loss: 1.8757, value_loss: 0.9811
2024-07-14 04:57:47,072 [INFO    ] __main__: train step 1330: loss: 0.3793, policy_loss: 1.8756, value_loss: 0.9810
2024-07-14 04:57:47,337 [INFO    ] __main__: train step 1331: loss: 0.3795, policy_loss: 1.8756, value_loss: 0.9810
2024-07-14 04:57:47,605 [INFO    ] __main__: train step 1332: loss: 0.3797, policy_loss: 1.8755, value_loss: 0.9810
2024-07-14 04:57:47,934 [INFO    ] __main__: train step 1333: loss: 0.3798, policy_loss: 1.8754, value_loss: 0.9810
2024-07-14 04:57:48,213 [INFO    ] __main__: train step 1334: loss: 0.3800, policy_loss: 1.8753, value_loss: 0.9810
2024-07-14 04:57:48,484 [INFO    ] __main__: train step 1335: loss: 0.3802, policy_loss: 1.8753, value_loss: 0.9810
2024-07-14 04:57:48,743 [INFO    ] __main__: train step 1336: loss: 0.3803, policy_loss: 1.8752, value_loss: 0.9810
2024-07-14 04:57:49,073 [INFO    ] __main__: train step 1337: loss: 0.3805, policy_loss: 1.8751, value_loss: 0.9810
2024-07-14 04:57:49,343 [INFO    ] __main__: train step 1338: loss: 0.3806, policy_loss: 1.8750, value_loss: 0.9810
2024-07-14 04:57:49,629 [INFO    ] __main__: train step 1339: loss: 0.3808, policy_loss: 1.8749, value_loss: 0.9810
2024-07-14 04:57:51,435 [INFO    ] __main__: replay_buffer size = 45568
2024-07-14 04:57:51,720 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:57:54,236 [INFO    ] __main__: train step 1340: loss: 0.3809, policy_loss: 1.8749, value_loss: 0.9810
2024-07-14 04:57:54,495 [INFO    ] __main__: train step 1341: loss: 0.3811, policy_loss: 1.8748, value_loss: 0.9810
2024-07-14 04:57:54,760 [INFO    ] __main__: train step 1342: loss: 0.3812, policy_loss: 1.8747, value_loss: 0.9810
2024-07-14 04:57:55,022 [INFO    ] __main__: train step 1343: loss: 0.3814, policy_loss: 1.8746, value_loss: 0.9810
2024-07-14 04:57:55,291 [INFO    ] __main__: train step 1344: loss: 0.3815, policy_loss: 1.8745, value_loss: 0.9810
2024-07-14 04:57:55,853 [INFO    ] __main__: train step 1345: loss: 0.3817, policy_loss: 1.8745, value_loss: 0.9810
2024-07-14 04:57:56,115 [INFO    ] __main__: train step 1346: loss: 0.3819, policy_loss: 1.8744, value_loss: 0.9810
2024-07-14 04:57:56,372 [INFO    ] __main__: train step 1347: loss: 0.3821, policy_loss: 1.8743, value_loss: 0.9810
2024-07-14 04:57:56,634 [INFO    ] __main__: train step 1348: loss: 0.3822, policy_loss: 1.8743, value_loss: 0.9810
2024-07-14 04:57:56,905 [INFO    ] __main__: train step 1349: loss: 0.3824, policy_loss: 1.8742, value_loss: 0.9810
2024-07-14 04:57:57,181 [INFO    ] __main__: train step 1350: loss: 0.3825, policy_loss: 1.8741, value_loss: 0.9810
2024-07-14 04:57:57,441 [INFO    ] __main__: train step 1351: loss: 0.3827, policy_loss: 1.8740, value_loss: 0.9810
2024-07-14 04:57:57,711 [INFO    ] __main__: train step 1352: loss: 0.3828, policy_loss: 1.8739, value_loss: 0.9810
2024-07-14 04:57:57,986 [INFO    ] __main__: train step 1353: loss: 0.3830, policy_loss: 1.8739, value_loss: 0.9810
2024-07-14 04:57:58,248 [INFO    ] __main__: train step 1354: loss: 0.3832, policy_loss: 1.8738, value_loss: 0.9809
2024-07-14 04:57:58,518 [INFO    ] __main__: train step 1355: loss: 0.3834, policy_loss: 1.8737, value_loss: 0.9810
2024-07-14 04:57:58,790 [INFO    ] __main__: train step 1356: loss: 0.3835, policy_loss: 1.8736, value_loss: 0.9810
2024-07-14 04:58:00,680 [INFO    ] __main__: replay_buffer size = 46080
2024-07-14 04:58:01,072 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:58:04,385 [INFO    ] __main__: train step 1357: loss: 0.3837, policy_loss: 1.8736, value_loss: 0.9810
2024-07-14 04:58:04,647 [INFO    ] __main__: train step 1358: loss: 0.3839, policy_loss: 1.8735, value_loss: 0.9810
2024-07-14 04:58:04,943 [INFO    ] __main__: train step 1359: loss: 0.3840, policy_loss: 1.8734, value_loss: 0.9810
2024-07-14 04:58:05,223 [INFO    ] __main__: train step 1360: loss: 0.3842, policy_loss: 1.8733, value_loss: 0.9810
2024-07-14 04:58:05,513 [INFO    ] __main__: train step 1361: loss: 0.3844, policy_loss: 1.8733, value_loss: 0.9810
2024-07-14 04:58:05,780 [INFO    ] __main__: train step 1362: loss: 0.3845, policy_loss: 1.8732, value_loss: 0.9809
2024-07-14 04:58:06,587 [INFO    ] __main__: train step 1363: loss: 0.3847, policy_loss: 1.8731, value_loss: 0.9809
2024-07-14 04:58:06,858 [INFO    ] __main__: train step 1364: loss: 0.3849, policy_loss: 1.8730, value_loss: 0.9809
2024-07-14 04:58:07,125 [INFO    ] __main__: train step 1365: loss: 0.3850, policy_loss: 1.8729, value_loss: 0.9809
2024-07-14 04:58:07,389 [INFO    ] __main__: train step 1366: loss: 0.3852, policy_loss: 1.8729, value_loss: 0.9809
2024-07-14 04:58:07,650 [INFO    ] __main__: train step 1367: loss: 0.3853, policy_loss: 1.8728, value_loss: 0.9809
2024-07-14 04:58:07,923 [INFO    ] __main__: train step 1368: loss: 0.3855, policy_loss: 1.8727, value_loss: 0.9809
2024-07-14 04:58:08,189 [INFO    ] __main__: train step 1369: loss: 0.3857, policy_loss: 1.8727, value_loss: 0.9809
2024-07-14 04:58:08,455 [INFO    ] __main__: train step 1370: loss: 0.3858, policy_loss: 1.8726, value_loss: 0.9810
2024-07-14 04:58:08,732 [INFO    ] __main__: train step 1371: loss: 0.3860, policy_loss: 1.8725, value_loss: 0.9809
2024-07-14 04:58:08,992 [INFO    ] __main__: train step 1372: loss: 0.3861, policy_loss: 1.8724, value_loss: 0.9810
2024-07-14 04:58:09,265 [INFO    ] __main__: train step 1373: loss: 0.3863, policy_loss: 1.8724, value_loss: 0.9810
2024-07-14 04:58:11,051 [INFO    ] __main__: replay_buffer size = 46592
2024-07-14 04:58:11,373 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:58:13,960 [INFO    ] __main__: train step 1374: loss: 0.3865, policy_loss: 1.8723, value_loss: 0.9810
2024-07-14 04:58:14,256 [INFO    ] __main__: train step 1375: loss: 0.3867, policy_loss: 1.8722, value_loss: 0.9809
2024-07-14 04:58:14,537 [INFO    ] __main__: train step 1376: loss: 0.3868, policy_loss: 1.8721, value_loss: 0.9809
2024-07-14 04:58:14,814 [INFO    ] __main__: train step 1377: loss: 0.3870, policy_loss: 1.8720, value_loss: 0.9809
2024-07-14 04:58:15,090 [INFO    ] __main__: train step 1378: loss: 0.3871, policy_loss: 1.8720, value_loss: 0.9809
2024-07-14 04:58:15,357 [INFO    ] __main__: train step 1379: loss: 0.3873, policy_loss: 1.8719, value_loss: 0.9809
2024-07-14 04:58:16,200 [INFO    ] __main__: train step 1380: loss: 0.3875, policy_loss: 1.8718, value_loss: 0.9809
2024-07-14 04:58:16,475 [INFO    ] __main__: train step 1381: loss: 0.3876, policy_loss: 1.8717, value_loss: 0.9809
2024-07-14 04:58:16,750 [INFO    ] __main__: train step 1382: loss: 0.3878, policy_loss: 1.8717, value_loss: 0.9809
2024-07-14 04:58:17,035 [INFO    ] __main__: train step 1383: loss: 0.3880, policy_loss: 1.8716, value_loss: 0.9809
2024-07-14 04:58:17,309 [INFO    ] __main__: train step 1384: loss: 0.3881, policy_loss: 1.8715, value_loss: 0.9809
2024-07-14 04:58:17,584 [INFO    ] __main__: train step 1385: loss: 0.3883, policy_loss: 1.8714, value_loss: 0.9809
2024-07-14 04:58:17,860 [INFO    ] __main__: train step 1386: loss: 0.3884, policy_loss: 1.8714, value_loss: 0.9810
2024-07-14 04:58:18,141 [INFO    ] __main__: train step 1387: loss: 0.3886, policy_loss: 1.8713, value_loss: 0.9810
2024-07-14 04:58:18,418 [INFO    ] __main__: train step 1388: loss: 0.3888, policy_loss: 1.8712, value_loss: 0.9809
2024-07-14 04:58:18,684 [INFO    ] __main__: train step 1389: loss: 0.3889, policy_loss: 1.8712, value_loss: 0.9810
2024-07-14 04:58:18,963 [INFO    ] __main__: train step 1390: loss: 0.3891, policy_loss: 1.8711, value_loss: 0.9809
2024-07-14 04:58:20,725 [INFO    ] __main__: replay_buffer size = 47104
2024-07-14 04:58:21,036 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:58:22,873 [INFO    ] __main__: train step 1391: loss: 0.3893, policy_loss: 1.8710, value_loss: 0.9809
2024-07-14 04:58:23,164 [INFO    ] __main__: train step 1392: loss: 0.3894, policy_loss: 1.8709, value_loss: 0.9809
2024-07-14 04:58:23,441 [INFO    ] __main__: train step 1393: loss: 0.3896, policy_loss: 1.8709, value_loss: 0.9809
2024-07-14 04:58:23,694 [INFO    ] __main__: train step 1394: loss: 0.3898, policy_loss: 1.8708, value_loss: 0.9809
2024-07-14 04:58:23,969 [INFO    ] __main__: train step 1395: loss: 0.3899, policy_loss: 1.8707, value_loss: 0.9809
2024-07-14 04:58:24,236 [INFO    ] __main__: train step 1396: loss: 0.3901, policy_loss: 1.8707, value_loss: 0.9809
2024-07-14 04:58:24,507 [INFO    ] __main__: train step 1397: loss: 0.3903, policy_loss: 1.8706, value_loss: 0.9809
2024-07-14 04:58:25,296 [INFO    ] __main__: train step 1398: loss: 0.3904, policy_loss: 1.8705, value_loss: 0.9809
2024-07-14 04:58:25,556 [INFO    ] __main__: train step 1399: loss: 0.3906, policy_loss: 1.8705, value_loss: 0.9809
2024-07-14 04:58:25,829 [INFO    ] __main__: train step 1400: loss: 0.3908, policy_loss: 1.8704, value_loss: 0.9809
2024-07-14 04:58:26,095 [INFO    ] __main__: train step 1401: loss: 0.3909, policy_loss: 1.8703, value_loss: 0.9809
2024-07-14 04:58:26,356 [INFO    ] __main__: train step 1402: loss: 0.3911, policy_loss: 1.8702, value_loss: 0.9809
2024-07-14 04:58:26,626 [INFO    ] __main__: train step 1403: loss: 0.3913, policy_loss: 1.8701, value_loss: 0.9809
2024-07-14 04:58:26,894 [INFO    ] __main__: train step 1404: loss: 0.3914, policy_loss: 1.8701, value_loss: 0.9810
2024-07-14 04:58:27,161 [INFO    ] __main__: train step 1405: loss: 0.3916, policy_loss: 1.8700, value_loss: 0.9810
2024-07-14 04:58:27,433 [INFO    ] __main__: train step 1406: loss: 0.3918, policy_loss: 1.8699, value_loss: 0.9810
2024-07-14 04:58:27,694 [INFO    ] __main__: train step 1407: loss: 0.3920, policy_loss: 1.8699, value_loss: 0.9809
2024-07-14 04:58:29,469 [INFO    ] __main__: replay_buffer size = 47616
2024-07-14 04:58:29,786 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:58:32,297 [INFO    ] __main__: train step 1408: loss: 0.3922, policy_loss: 1.8698, value_loss: 0.9809
2024-07-14 04:58:32,572 [INFO    ] __main__: train step 1409: loss: 0.3923, policy_loss: 1.8697, value_loss: 0.9809
2024-07-14 04:58:32,846 [INFO    ] __main__: train step 1410: loss: 0.3925, policy_loss: 1.8697, value_loss: 0.9809
2024-07-14 04:58:33,131 [INFO    ] __main__: train step 1411: loss: 0.3926, policy_loss: 1.8696, value_loss: 0.9809
2024-07-14 04:58:33,404 [INFO    ] __main__: train step 1412: loss: 0.3928, policy_loss: 1.8695, value_loss: 0.9809
2024-07-14 04:58:33,674 [INFO    ] __main__: train step 1413: loss: 0.3929, policy_loss: 1.8694, value_loss: 0.9809
2024-07-14 04:58:33,947 [INFO    ] __main__: train step 1414: loss: 0.3931, policy_loss: 1.8693, value_loss: 0.9809
2024-07-14 04:58:34,228 [INFO    ] __main__: train step 1415: loss: 0.3932, policy_loss: 1.8693, value_loss: 0.9809
2024-07-14 04:58:35,074 [INFO    ] __main__: train step 1416: loss: 0.3934, policy_loss: 1.8692, value_loss: 0.9809
2024-07-14 04:58:35,351 [INFO    ] __main__: train step 1417: loss: 0.3936, policy_loss: 1.8691, value_loss: 0.9809
2024-07-14 04:58:35,630 [INFO    ] __main__: train step 1418: loss: 0.3938, policy_loss: 1.8690, value_loss: 0.9809
2024-07-14 04:58:35,897 [INFO    ] __main__: train step 1419: loss: 0.3939, policy_loss: 1.8690, value_loss: 0.9809
2024-07-14 04:58:36,175 [INFO    ] __main__: train step 1420: loss: 0.3941, policy_loss: 1.8689, value_loss: 0.9809
2024-07-14 04:58:36,456 [INFO    ] __main__: train step 1421: loss: 0.3942, policy_loss: 1.8688, value_loss: 0.9808
2024-07-14 04:58:36,733 [INFO    ] __main__: train step 1422: loss: 0.3944, policy_loss: 1.8688, value_loss: 0.9809
2024-07-14 04:58:37,009 [INFO    ] __main__: train step 1423: loss: 0.3946, policy_loss: 1.8687, value_loss: 0.9809
2024-07-14 04:58:37,289 [INFO    ] __main__: train step 1424: loss: 0.3947, policy_loss: 1.8686, value_loss: 0.9809
2024-07-14 04:58:39,063 [INFO    ] __main__: replay_buffer size = 48128
2024-07-14 04:58:39,359 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:58:41,786 [INFO    ] __main__: train step 1425: loss: 0.3949, policy_loss: 1.8685, value_loss: 0.9809
2024-07-14 04:58:42,058 [INFO    ] __main__: train step 1426: loss: 0.3951, policy_loss: 1.8685, value_loss: 0.9809
2024-07-14 04:58:42,324 [INFO    ] __main__: train step 1427: loss: 0.3953, policy_loss: 1.8684, value_loss: 0.9808
2024-07-14 04:58:42,588 [INFO    ] __main__: train step 1428: loss: 0.3954, policy_loss: 1.8683, value_loss: 0.9808
2024-07-14 04:58:42,859 [INFO    ] __main__: train step 1429: loss: 0.3956, policy_loss: 1.8683, value_loss: 0.9808
2024-07-14 04:58:43,120 [INFO    ] __main__: train step 1430: loss: 0.3958, policy_loss: 1.8682, value_loss: 0.9808
2024-07-14 04:58:43,387 [INFO    ] __main__: train step 1431: loss: 0.3960, policy_loss: 1.8681, value_loss: 0.9808
2024-07-14 04:58:43,652 [INFO    ] __main__: train step 1432: loss: 0.3962, policy_loss: 1.8680, value_loss: 0.9808
2024-07-14 04:58:44,244 [INFO    ] __main__: train step 1433: loss: 0.3963, policy_loss: 1.8680, value_loss: 0.9808
2024-07-14 04:58:44,515 [INFO    ] __main__: train step 1434: loss: 0.3965, policy_loss: 1.8679, value_loss: 0.9808
2024-07-14 04:58:44,785 [INFO    ] __main__: train step 1435: loss: 0.3967, policy_loss: 1.8678, value_loss: 0.9808
2024-07-14 04:58:45,052 [INFO    ] __main__: train step 1436: loss: 0.3968, policy_loss: 1.8677, value_loss: 0.9808
2024-07-14 04:58:45,311 [INFO    ] __main__: train step 1437: loss: 0.3970, policy_loss: 1.8677, value_loss: 0.9808
2024-07-14 04:58:45,574 [INFO    ] __main__: train step 1438: loss: 0.3972, policy_loss: 1.8676, value_loss: 0.9808
2024-07-14 04:58:45,843 [INFO    ] __main__: train step 1439: loss: 0.3973, policy_loss: 1.8675, value_loss: 0.9808
2024-07-14 04:58:46,096 [INFO    ] __main__: train step 1440: loss: 0.3975, policy_loss: 1.8675, value_loss: 0.9808
2024-07-14 04:58:46,349 [INFO    ] __main__: train step 1441: loss: 0.3977, policy_loss: 1.8674, value_loss: 0.9808
2024-07-14 04:58:48,104 [INFO    ] __main__: replay_buffer size = 48640
2024-07-14 04:58:48,425 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:58:50,934 [INFO    ] __main__: train step 1442: loss: 0.3979, policy_loss: 1.8673, value_loss: 0.9808
2024-07-14 04:58:51,199 [INFO    ] __main__: train step 1443: loss: 0.3980, policy_loss: 1.8672, value_loss: 0.9808
2024-07-14 04:58:51,456 [INFO    ] __main__: train step 1444: loss: 0.3982, policy_loss: 1.8672, value_loss: 0.9808
2024-07-14 04:58:51,726 [INFO    ] __main__: train step 1445: loss: 0.3984, policy_loss: 1.8671, value_loss: 0.9808
2024-07-14 04:58:51,998 [INFO    ] __main__: train step 1446: loss: 0.3985, policy_loss: 1.8670, value_loss: 0.9808
2024-07-14 04:58:52,264 [INFO    ] __main__: train step 1447: loss: 0.3987, policy_loss: 1.8670, value_loss: 0.9808
2024-07-14 04:58:52,523 [INFO    ] __main__: train step 1448: loss: 0.3989, policy_loss: 1.8669, value_loss: 0.9808
2024-07-14 04:58:52,797 [INFO    ] __main__: train step 1449: loss: 0.3990, policy_loss: 1.8668, value_loss: 0.9808
2024-07-14 04:58:53,067 [INFO    ] __main__: train step 1450: loss: 0.3992, policy_loss: 1.8668, value_loss: 0.9808
2024-07-14 04:58:53,876 [INFO    ] __main__: train step 1451: loss: 0.3993, policy_loss: 1.8667, value_loss: 0.9808
2024-07-14 04:58:54,154 [INFO    ] __main__: train step 1452: loss: 0.3995, policy_loss: 1.8666, value_loss: 0.9808
2024-07-14 04:58:54,408 [INFO    ] __main__: train step 1453: loss: 0.3997, policy_loss: 1.8665, value_loss: 0.9808
2024-07-14 04:58:54,677 [INFO    ] __main__: train step 1454: loss: 0.3998, policy_loss: 1.8665, value_loss: 0.9808
2024-07-14 04:58:54,939 [INFO    ] __main__: train step 1455: loss: 0.4000, policy_loss: 1.8664, value_loss: 0.9808
2024-07-14 04:58:55,191 [INFO    ] __main__: train step 1456: loss: 0.4001, policy_loss: 1.8663, value_loss: 0.9808
2024-07-14 04:58:55,465 [INFO    ] __main__: train step 1457: loss: 0.4003, policy_loss: 1.8663, value_loss: 0.9808
2024-07-14 04:58:55,731 [INFO    ] __main__: train step 1458: loss: 0.4005, policy_loss: 1.8662, value_loss: 0.9808
2024-07-14 04:58:57,456 [INFO    ] __main__: replay_buffer size = 49152
2024-07-14 04:58:57,763 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:58:59,563 [INFO    ] __main__: train step 1459: loss: 0.4006, policy_loss: 1.8661, value_loss: 0.9808
2024-07-14 04:58:59,838 [INFO    ] __main__: train step 1460: loss: 0.4008, policy_loss: 1.8660, value_loss: 0.9808
2024-07-14 04:59:00,102 [INFO    ] __main__: train step 1461: loss: 0.4010, policy_loss: 1.8659, value_loss: 0.9808
2024-07-14 04:59:00,373 [INFO    ] __main__: train step 1462: loss: 0.4011, policy_loss: 1.8658, value_loss: 0.9808
2024-07-14 04:59:00,639 [INFO    ] __main__: train step 1463: loss: 0.4013, policy_loss: 1.8658, value_loss: 0.9808
2024-07-14 04:59:00,908 [INFO    ] __main__: train step 1464: loss: 0.4015, policy_loss: 1.8657, value_loss: 0.9808
2024-07-14 04:59:01,179 [INFO    ] __main__: train step 1465: loss: 0.4017, policy_loss: 1.8656, value_loss: 0.9808
2024-07-14 04:59:01,441 [INFO    ] __main__: train step 1466: loss: 0.4018, policy_loss: 1.8655, value_loss: 0.9808
2024-07-14 04:59:01,697 [INFO    ] __main__: train step 1467: loss: 0.4020, policy_loss: 1.8655, value_loss: 0.9807
2024-07-14 04:59:01,964 [INFO    ] __main__: train step 1468: loss: 0.4021, policy_loss: 1.8654, value_loss: 0.9807
2024-07-14 04:59:02,718 [INFO    ] __main__: train step 1469: loss: 0.4023, policy_loss: 1.8653, value_loss: 0.9808
2024-07-14 04:59:02,989 [INFO    ] __main__: train step 1470: loss: 0.4025, policy_loss: 1.8652, value_loss: 0.9808
2024-07-14 04:59:03,267 [INFO    ] __main__: train step 1471: loss: 0.4027, policy_loss: 1.8651, value_loss: 0.9808
2024-07-14 04:59:03,528 [INFO    ] __main__: train step 1472: loss: 0.4028, policy_loss: 1.8651, value_loss: 0.9808
2024-07-14 04:59:03,803 [INFO    ] __main__: train step 1473: loss: 0.4030, policy_loss: 1.8650, value_loss: 0.9808
2024-07-14 04:59:04,076 [INFO    ] __main__: train step 1474: loss: 0.4032, policy_loss: 1.8649, value_loss: 0.9808
2024-07-14 04:59:04,342 [INFO    ] __main__: train step 1475: loss: 0.4033, policy_loss: 1.8649, value_loss: 0.9808
2024-07-14 04:59:06,100 [INFO    ] __main__: replay_buffer size = 49664
2024-07-14 04:59:06,427 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:59:08,928 [INFO    ] __main__: train step 1476: loss: 0.4035, policy_loss: 1.8648, value_loss: 0.9808
2024-07-14 04:59:09,204 [INFO    ] __main__: train step 1477: loss: 0.4037, policy_loss: 1.8647, value_loss: 0.9808
2024-07-14 04:59:09,467 [INFO    ] __main__: train step 1478: loss: 0.4038, policy_loss: 1.8646, value_loss: 0.9808
2024-07-14 04:59:09,743 [INFO    ] __main__: train step 1479: loss: 0.4040, policy_loss: 1.8646, value_loss: 0.9808
2024-07-14 04:59:10,009 [INFO    ] __main__: train step 1480: loss: 0.4041, policy_loss: 1.8645, value_loss: 0.9808
2024-07-14 04:59:10,278 [INFO    ] __main__: train step 1481: loss: 0.4043, policy_loss: 1.8644, value_loss: 0.9808
2024-07-14 04:59:10,544 [INFO    ] __main__: train step 1482: loss: 0.4045, policy_loss: 1.8643, value_loss: 0.9808
2024-07-14 04:59:10,814 [INFO    ] __main__: train step 1483: loss: 0.4046, policy_loss: 1.8643, value_loss: 0.9808
2024-07-14 04:59:11,077 [INFO    ] __main__: train step 1484: loss: 0.4048, policy_loss: 1.8642, value_loss: 0.9808
2024-07-14 04:59:11,339 [INFO    ] __main__: train step 1485: loss: 0.4050, policy_loss: 1.8641, value_loss: 0.9808
2024-07-14 04:59:12,127 [INFO    ] __main__: train step 1486: loss: 0.4051, policy_loss: 1.8640, value_loss: 0.9808
2024-07-14 04:59:12,404 [INFO    ] __main__: train step 1487: loss: 0.4053, policy_loss: 1.8639, value_loss: 0.9808
2024-07-14 04:59:12,635 [INFO    ] __main__: train step 1488: loss: 0.4054, policy_loss: 1.8639, value_loss: 0.9808
2024-07-14 04:59:12,871 [INFO    ] __main__: train step 1489: loss: 0.4056, policy_loss: 1.8638, value_loss: 0.9808
2024-07-14 04:59:13,118 [INFO    ] __main__: train step 1490: loss: 0.4058, policy_loss: 1.8637, value_loss: 0.9808
2024-07-14 04:59:13,377 [INFO    ] __main__: train step 1491: loss: 0.4060, policy_loss: 1.8637, value_loss: 0.9808
2024-07-14 04:59:13,635 [INFO    ] __main__: train step 1492: loss: 0.4061, policy_loss: 1.8636, value_loss: 0.9808
2024-07-14 04:59:15,424 [INFO    ] __main__: replay_buffer size = 50176
2024-07-14 04:59:15,736 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:59:18,228 [INFO    ] __main__: train step 1493: loss: 0.4063, policy_loss: 1.8635, value_loss: 0.9808
2024-07-14 04:59:18,502 [INFO    ] __main__: train step 1494: loss: 0.4065, policy_loss: 1.8634, value_loss: 0.9808
2024-07-14 04:59:18,770 [INFO    ] __main__: train step 1495: loss: 0.4067, policy_loss: 1.8634, value_loss: 0.9808
2024-07-14 04:59:19,040 [INFO    ] __main__: train step 1496: loss: 0.4068, policy_loss: 1.8633, value_loss: 0.9808
2024-07-14 04:59:19,308 [INFO    ] __main__: train step 1497: loss: 0.4070, policy_loss: 1.8632, value_loss: 0.9808
2024-07-14 04:59:19,575 [INFO    ] __main__: train step 1498: loss: 0.4072, policy_loss: 1.8632, value_loss: 0.9808
2024-07-14 04:59:19,848 [INFO    ] __main__: train step 1499: loss: 0.4073, policy_loss: 1.8631, value_loss: 0.9808
2024-07-14 04:59:20,115 [INFO    ] __main__: train step 1500: loss: 0.4075, policy_loss: 1.8630, value_loss: 0.9808
2024-07-14 04:59:20,377 [INFO    ] __main__: train step 1501: loss: 0.4077, policy_loss: 1.8630, value_loss: 0.9808
2024-07-14 04:59:20,653 [INFO    ] __main__: train step 1502: loss: 0.4078, policy_loss: 1.8629, value_loss: 0.9808
2024-07-14 04:59:21,453 [INFO    ] __main__: train step 1503: loss: 0.4080, policy_loss: 1.8628, value_loss: 0.9808
2024-07-14 04:59:21,731 [INFO    ] __main__: train step 1504: loss: 0.4082, policy_loss: 1.8627, value_loss: 0.9808
2024-07-14 04:59:21,997 [INFO    ] __main__: train step 1505: loss: 0.4084, policy_loss: 1.8627, value_loss: 0.9808
2024-07-14 04:59:22,270 [INFO    ] __main__: train step 1506: loss: 0.4085, policy_loss: 1.8626, value_loss: 0.9808
2024-07-14 04:59:22,549 [INFO    ] __main__: train step 1507: loss: 0.4087, policy_loss: 1.8625, value_loss: 0.9808
2024-07-14 04:59:22,811 [INFO    ] __main__: train step 1508: loss: 0.4089, policy_loss: 1.8625, value_loss: 0.9808
2024-07-14 04:59:23,078 [INFO    ] __main__: train step 1509: loss: 0.4090, policy_loss: 1.8624, value_loss: 0.9809
2024-07-14 04:59:24,852 [INFO    ] __main__: replay_buffer size = 50688
2024-07-14 04:59:25,195 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:59:27,653 [INFO    ] __main__: train step 1510: loss: 0.4092, policy_loss: 1.8623, value_loss: 0.9809
2024-07-14 04:59:27,929 [INFO    ] __main__: train step 1511: loss: 0.4093, policy_loss: 1.8622, value_loss: 0.9809
2024-07-14 04:59:28,185 [INFO    ] __main__: train step 1512: loss: 0.4095, policy_loss: 1.8622, value_loss: 0.9809
2024-07-14 04:59:28,458 [INFO    ] __main__: train step 1513: loss: 0.4097, policy_loss: 1.8621, value_loss: 0.9809
2024-07-14 04:59:28,730 [INFO    ] __main__: train step 1514: loss: 0.4098, policy_loss: 1.8620, value_loss: 0.9809
2024-07-14 04:59:29,004 [INFO    ] __main__: train step 1515: loss: 0.4100, policy_loss: 1.8620, value_loss: 0.9809
2024-07-14 04:59:29,270 [INFO    ] __main__: train step 1516: loss: 0.4102, policy_loss: 1.8619, value_loss: 0.9809
2024-07-14 04:59:29,546 [INFO    ] __main__: train step 1517: loss: 0.4103, policy_loss: 1.8618, value_loss: 0.9809
2024-07-14 04:59:29,821 [INFO    ] __main__: train step 1518: loss: 0.4105, policy_loss: 1.8617, value_loss: 0.9809
2024-07-14 04:59:30,078 [INFO    ] __main__: train step 1519: loss: 0.4107, policy_loss: 1.8616, value_loss: 0.9810
2024-07-14 04:59:30,342 [INFO    ] __main__: train step 1520: loss: 0.4108, policy_loss: 1.8616, value_loss: 0.9810
2024-07-14 04:59:31,115 [INFO    ] __main__: train step 1521: loss: 0.4110, policy_loss: 1.8615, value_loss: 0.9810
2024-07-14 04:59:31,395 [INFO    ] __main__: train step 1522: loss: 0.4112, policy_loss: 1.8614, value_loss: 0.9810
2024-07-14 04:59:31,671 [INFO    ] __main__: train step 1523: loss: 0.4113, policy_loss: 1.8614, value_loss: 0.9810
2024-07-14 04:59:31,943 [INFO    ] __main__: train step 1524: loss: 0.4115, policy_loss: 1.8613, value_loss: 0.9810
2024-07-14 04:59:32,221 [INFO    ] __main__: train step 1525: loss: 0.4116, policy_loss: 1.8612, value_loss: 0.9810
2024-07-14 04:59:32,514 [INFO    ] __main__: train step 1526: loss: 0.4118, policy_loss: 1.8611, value_loss: 0.9810
2024-07-14 04:59:34,276 [INFO    ] __main__: replay_buffer size = 51200
2024-07-14 04:59:34,605 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:59:36,478 [INFO    ] __main__: train step 1527: loss: 0.4120, policy_loss: 1.8611, value_loss: 0.9810
2024-07-14 04:59:36,751 [INFO    ] __main__: train step 1528: loss: 0.4122, policy_loss: 1.8610, value_loss: 0.9811
2024-07-14 04:59:37,016 [INFO    ] __main__: train step 1529: loss: 0.4123, policy_loss: 1.8609, value_loss: 0.9811
2024-07-14 04:59:37,281 [INFO    ] __main__: train step 1530: loss: 0.4125, policy_loss: 1.8608, value_loss: 0.9811
2024-07-14 04:59:37,542 [INFO    ] __main__: train step 1531: loss: 0.4127, policy_loss: 1.8608, value_loss: 0.9811
2024-07-14 04:59:37,802 [INFO    ] __main__: train step 1532: loss: 0.4128, policy_loss: 1.8607, value_loss: 0.9811
2024-07-14 04:59:38,054 [INFO    ] __main__: train step 1533: loss: 0.4130, policy_loss: 1.8606, value_loss: 0.9811
2024-07-14 04:59:38,323 [INFO    ] __main__: train step 1534: loss: 0.4132, policy_loss: 1.8606, value_loss: 0.9811
2024-07-14 04:59:38,592 [INFO    ] __main__: train step 1535: loss: 0.4133, policy_loss: 1.8605, value_loss: 0.9811
2024-07-14 04:59:38,859 [INFO    ] __main__: train step 1536: loss: 0.4135, policy_loss: 1.8604, value_loss: 0.9810
2024-07-14 04:59:39,133 [INFO    ] __main__: train step 1537: loss: 0.4136, policy_loss: 1.8603, value_loss: 0.9811
2024-07-14 04:59:39,400 [INFO    ] __main__: train step 1538: loss: 0.4138, policy_loss: 1.8603, value_loss: 0.9811
2024-07-14 04:59:39,985 [INFO    ] __main__: train step 1539: loss: 0.4140, policy_loss: 1.8602, value_loss: 0.9810
2024-07-14 04:59:40,261 [INFO    ] __main__: train step 1540: loss: 0.4141, policy_loss: 1.8601, value_loss: 0.9810
2024-07-14 04:59:40,530 [INFO    ] __main__: train step 1541: loss: 0.4143, policy_loss: 1.8601, value_loss: 0.9810
2024-07-14 04:59:40,797 [INFO    ] __main__: train step 1542: loss: 0.4145, policy_loss: 1.8600, value_loss: 0.9810
2024-07-14 04:59:41,074 [INFO    ] __main__: train step 1543: loss: 0.4146, policy_loss: 1.8599, value_loss: 0.9810
2024-07-14 04:59:42,852 [INFO    ] __main__: replay_buffer size = 51712
2024-07-14 04:59:43,193 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:59:45,668 [INFO    ] __main__: train step 1544: loss: 0.4148, policy_loss: 1.8598, value_loss: 0.9810
2024-07-14 04:59:45,945 [INFO    ] __main__: train step 1545: loss: 0.4149, policy_loss: 1.8598, value_loss: 0.9810
2024-07-14 04:59:46,203 [INFO    ] __main__: train step 1546: loss: 0.4151, policy_loss: 1.8597, value_loss: 0.9810
2024-07-14 04:59:46,481 [INFO    ] __main__: train step 1547: loss: 0.4153, policy_loss: 1.8596, value_loss: 0.9810
2024-07-14 04:59:46,749 [INFO    ] __main__: train step 1548: loss: 0.4154, policy_loss: 1.8596, value_loss: 0.9810
2024-07-14 04:59:47,016 [INFO    ] __main__: train step 1549: loss: 0.4156, policy_loss: 1.8595, value_loss: 0.9810
2024-07-14 04:59:47,295 [INFO    ] __main__: train step 1550: loss: 0.4157, policy_loss: 1.8595, value_loss: 0.9810
2024-07-14 04:59:47,565 [INFO    ] __main__: train step 1551: loss: 0.4159, policy_loss: 1.8594, value_loss: 0.9810
2024-07-14 04:59:47,817 [INFO    ] __main__: train step 1552: loss: 0.4161, policy_loss: 1.8593, value_loss: 0.9810
2024-07-14 04:59:48,089 [INFO    ] __main__: train step 1553: loss: 0.4163, policy_loss: 1.8593, value_loss: 0.9810
2024-07-14 04:59:48,357 [INFO    ] __main__: train step 1554: loss: 0.4164, policy_loss: 1.8592, value_loss: 0.9810
2024-07-14 04:59:48,625 [INFO    ] __main__: train step 1555: loss: 0.4166, policy_loss: 1.8591, value_loss: 0.9810
2024-07-14 04:59:48,889 [INFO    ] __main__: train step 1556: loss: 0.4167, policy_loss: 1.8591, value_loss: 0.9810
2024-07-14 04:59:49,488 [INFO    ] __main__: train step 1557: loss: 0.4169, policy_loss: 1.8590, value_loss: 0.9810
2024-07-14 04:59:49,757 [INFO    ] __main__: train step 1558: loss: 0.4171, policy_loss: 1.8589, value_loss: 0.9810
2024-07-14 04:59:50,026 [INFO    ] __main__: train step 1559: loss: 0.4173, policy_loss: 1.8589, value_loss: 0.9810
2024-07-14 04:59:50,301 [INFO    ] __main__: train step 1560: loss: 0.4174, policy_loss: 1.8588, value_loss: 0.9810
2024-07-14 04:59:52,094 [INFO    ] __main__: replay_buffer size = 52224
2024-07-14 04:59:52,423 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 04:59:54,934 [INFO    ] __main__: train step 1561: loss: 0.4176, policy_loss: 1.8587, value_loss: 0.9810
2024-07-14 04:59:55,191 [INFO    ] __main__: train step 1562: loss: 0.4178, policy_loss: 1.8587, value_loss: 0.9810
2024-07-14 04:59:55,466 [INFO    ] __main__: train step 1563: loss: 0.4179, policy_loss: 1.8586, value_loss: 0.9810
2024-07-14 04:59:55,740 [INFO    ] __main__: train step 1564: loss: 0.4181, policy_loss: 1.8585, value_loss: 0.9810
2024-07-14 04:59:56,012 [INFO    ] __main__: train step 1565: loss: 0.4182, policy_loss: 1.8584, value_loss: 0.9810
2024-07-14 04:59:56,267 [INFO    ] __main__: train step 1566: loss: 0.4184, policy_loss: 1.8584, value_loss: 0.9810
2024-07-14 04:59:56,534 [INFO    ] __main__: train step 1567: loss: 0.4186, policy_loss: 1.8583, value_loss: 0.9810
2024-07-14 04:59:56,795 [INFO    ] __main__: train step 1568: loss: 0.4188, policy_loss: 1.8582, value_loss: 0.9810
2024-07-14 04:59:57,063 [INFO    ] __main__: train step 1569: loss: 0.4189, policy_loss: 1.8582, value_loss: 0.9810
2024-07-14 04:59:57,330 [INFO    ] __main__: train step 1570: loss: 0.4191, policy_loss: 1.8581, value_loss: 0.9810
2024-07-14 04:59:57,606 [INFO    ] __main__: train step 1571: loss: 0.4192, policy_loss: 1.8580, value_loss: 0.9810
2024-07-14 04:59:57,875 [INFO    ] __main__: train step 1572: loss: 0.4194, policy_loss: 1.8580, value_loss: 0.9811
2024-07-14 04:59:58,144 [INFO    ] __main__: train step 1573: loss: 0.4196, policy_loss: 1.8579, value_loss: 0.9810
2024-07-14 04:59:58,405 [INFO    ] __main__: train step 1574: loss: 0.4197, policy_loss: 1.8578, value_loss: 0.9811
2024-07-14 04:59:59,259 [INFO    ] __main__: train step 1575: loss: 0.4199, policy_loss: 1.8578, value_loss: 0.9811
2024-07-14 04:59:59,542 [INFO    ] __main__: train step 1576: loss: 0.4201, policy_loss: 1.8577, value_loss: 0.9811
2024-07-14 04:59:59,825 [INFO    ] __main__: train step 1577: loss: 0.4202, policy_loss: 1.8576, value_loss: 0.9810
2024-07-14 05:00:01,581 [INFO    ] __main__: replay_buffer size = 52736
2024-07-14 05:00:01,934 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:00:04,458 [INFO    ] __main__: train step 1578: loss: 0.4204, policy_loss: 1.8576, value_loss: 0.9810
2024-07-14 05:00:04,725 [INFO    ] __main__: train step 1579: loss: 0.4205, policy_loss: 1.8575, value_loss: 0.9810
2024-07-14 05:00:04,993 [INFO    ] __main__: train step 1580: loss: 0.4207, policy_loss: 1.8574, value_loss: 0.9810
2024-07-14 05:00:05,258 [INFO    ] __main__: train step 1581: loss: 0.4209, policy_loss: 1.8573, value_loss: 0.9810
2024-07-14 05:00:05,531 [INFO    ] __main__: train step 1582: loss: 0.4210, policy_loss: 1.8573, value_loss: 0.9810
2024-07-14 05:00:05,806 [INFO    ] __main__: train step 1583: loss: 0.4212, policy_loss: 1.8572, value_loss: 0.9810
2024-07-14 05:00:06,087 [INFO    ] __main__: train step 1584: loss: 0.4213, policy_loss: 1.8571, value_loss: 0.9810
2024-07-14 05:00:06,360 [INFO    ] __main__: train step 1585: loss: 0.4215, policy_loss: 1.8571, value_loss: 0.9810
2024-07-14 05:00:06,641 [INFO    ] __main__: train step 1586: loss: 0.4217, policy_loss: 1.8570, value_loss: 0.9810
2024-07-14 05:00:06,911 [INFO    ] __main__: train step 1587: loss: 0.4219, policy_loss: 1.8570, value_loss: 0.9810
2024-07-14 05:00:07,171 [INFO    ] __main__: train step 1588: loss: 0.4220, policy_loss: 1.8569, value_loss: 0.9810
2024-07-14 05:00:07,446 [INFO    ] __main__: train step 1589: loss: 0.4222, policy_loss: 1.8568, value_loss: 0.9810
2024-07-14 05:00:07,712 [INFO    ] __main__: train step 1590: loss: 0.4224, policy_loss: 1.8568, value_loss: 0.9809
2024-07-14 05:00:07,976 [INFO    ] __main__: train step 1591: loss: 0.4225, policy_loss: 1.8567, value_loss: 0.9809
2024-07-14 05:00:08,247 [INFO    ] __main__: train step 1592: loss: 0.4227, policy_loss: 1.8566, value_loss: 0.9809
2024-07-14 05:00:09,030 [INFO    ] __main__: train step 1593: loss: 0.4229, policy_loss: 1.8566, value_loss: 0.9809
2024-07-14 05:00:09,315 [INFO    ] __main__: train step 1594: loss: 0.4230, policy_loss: 1.8565, value_loss: 0.9809
2024-07-14 05:00:11,067 [INFO    ] __main__: replay_buffer size = 53248
2024-07-14 05:00:11,407 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:00:13,238 [INFO    ] __main__: train step 1595: loss: 0.4232, policy_loss: 1.8564, value_loss: 0.9809
2024-07-14 05:00:13,506 [INFO    ] __main__: train step 1596: loss: 0.4234, policy_loss: 1.8564, value_loss: 0.9809
2024-07-14 05:00:13,776 [INFO    ] __main__: train step 1597: loss: 0.4235, policy_loss: 1.8563, value_loss: 0.9809
2024-07-14 05:00:14,044 [INFO    ] __main__: train step 1598: loss: 0.4237, policy_loss: 1.8562, value_loss: 0.9809
2024-07-14 05:00:14,311 [INFO    ] __main__: train step 1599: loss: 0.4239, policy_loss: 1.8562, value_loss: 0.9809
2024-07-14 05:00:14,591 [INFO    ] __main__: train step 1600: loss: 0.4240, policy_loss: 1.8561, value_loss: 0.9809
2024-07-14 05:00:14,862 [INFO    ] __main__: train step 1601: loss: 0.4242, policy_loss: 1.8560, value_loss: 0.9809
2024-07-14 05:00:15,130 [INFO    ] __main__: train step 1602: loss: 0.4244, policy_loss: 1.8559, value_loss: 0.9809
2024-07-14 05:00:15,393 [INFO    ] __main__: train step 1603: loss: 0.4245, policy_loss: 1.8558, value_loss: 0.9809
2024-07-14 05:00:15,660 [INFO    ] __main__: train step 1604: loss: 0.4247, policy_loss: 1.8558, value_loss: 0.9809
2024-07-14 05:00:15,926 [INFO    ] __main__: train step 1605: loss: 0.4249, policy_loss: 1.8557, value_loss: 0.9809
2024-07-14 05:00:16,176 [INFO    ] __main__: train step 1606: loss: 0.4250, policy_loss: 1.8556, value_loss: 0.9809
2024-07-14 05:00:16,444 [INFO    ] __main__: train step 1607: loss: 0.4252, policy_loss: 1.8555, value_loss: 0.9809
2024-07-14 05:00:16,715 [INFO    ] __main__: train step 1608: loss: 0.4253, policy_loss: 1.8555, value_loss: 0.9809
2024-07-14 05:00:16,988 [INFO    ] __main__: train step 1609: loss: 0.4255, policy_loss: 1.8554, value_loss: 0.9809
2024-07-14 05:00:17,255 [INFO    ] __main__: train step 1610: loss: 0.4257, policy_loss: 1.8553, value_loss: 0.9809
2024-07-14 05:00:17,503 [INFO    ] __main__: train step 1611: loss: 0.4258, policy_loss: 1.8552, value_loss: 0.9809
2024-07-14 05:00:19,824 [INFO    ] __main__: replay_buffer size = 53760
2024-07-14 05:00:20,175 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:00:22,689 [INFO    ] __main__: train step 1612: loss: 0.4260, policy_loss: 1.8552, value_loss: 0.9809
2024-07-14 05:00:22,961 [INFO    ] __main__: train step 1613: loss: 0.4261, policy_loss: 1.8551, value_loss: 0.9809
2024-07-14 05:00:23,225 [INFO    ] __main__: train step 1614: loss: 0.4263, policy_loss: 1.8550, value_loss: 0.9809
2024-07-14 05:00:23,500 [INFO    ] __main__: train step 1615: loss: 0.4265, policy_loss: 1.8550, value_loss: 0.9809
2024-07-14 05:00:23,769 [INFO    ] __main__: train step 1616: loss: 0.4267, policy_loss: 1.8549, value_loss: 0.9809
2024-07-14 05:00:24,044 [INFO    ] __main__: train step 1617: loss: 0.4268, policy_loss: 1.8548, value_loss: 0.9809
2024-07-14 05:00:24,319 [INFO    ] __main__: train step 1618: loss: 0.4270, policy_loss: 1.8547, value_loss: 0.9809
2024-07-14 05:00:24,584 [INFO    ] __main__: train step 1619: loss: 0.4272, policy_loss: 1.8547, value_loss: 0.9809
2024-07-14 05:00:24,842 [INFO    ] __main__: train step 1620: loss: 0.4274, policy_loss: 1.8546, value_loss: 0.9809
2024-07-14 05:00:25,099 [INFO    ] __main__: train step 1621: loss: 0.4275, policy_loss: 1.8546, value_loss: 0.9809
2024-07-14 05:00:25,381 [INFO    ] __main__: train step 1622: loss: 0.4277, policy_loss: 1.8545, value_loss: 0.9809
2024-07-14 05:00:25,659 [INFO    ] __main__: train step 1623: loss: 0.4278, policy_loss: 1.8544, value_loss: 0.9809
2024-07-14 05:00:25,941 [INFO    ] __main__: train step 1624: loss: 0.4280, policy_loss: 1.8544, value_loss: 0.9809
2024-07-14 05:00:26,216 [INFO    ] __main__: train step 1625: loss: 0.4282, policy_loss: 1.8543, value_loss: 0.9809
2024-07-14 05:00:26,490 [INFO    ] __main__: train step 1626: loss: 0.4284, policy_loss: 1.8542, value_loss: 0.9809
2024-07-14 05:00:26,779 [INFO    ] __main__: train step 1627: loss: 0.4285, policy_loss: 1.8542, value_loss: 0.9809
2024-07-14 05:00:27,060 [INFO    ] __main__: train step 1628: loss: 0.4287, policy_loss: 1.8541, value_loss: 0.9809
2024-07-14 05:00:28,851 [INFO    ] __main__: replay_buffer size = 54272
2024-07-14 05:00:29,203 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:00:31,689 [INFO    ] __main__: train step 1629: loss: 0.4289, policy_loss: 1.8540, value_loss: 0.9808
2024-07-14 05:00:32,285 [INFO    ] __main__: train step 1630: loss: 0.4290, policy_loss: 1.8540, value_loss: 0.9808
2024-07-14 05:00:32,546 [INFO    ] __main__: train step 1631: loss: 0.4292, policy_loss: 1.8539, value_loss: 0.9808
2024-07-14 05:00:32,822 [INFO    ] __main__: train step 1632: loss: 0.4294, policy_loss: 1.8538, value_loss: 0.9808
2024-07-14 05:00:33,100 [INFO    ] __main__: train step 1633: loss: 0.4295, policy_loss: 1.8538, value_loss: 0.9808
2024-07-14 05:00:33,344 [INFO    ] __main__: train step 1634: loss: 0.4297, policy_loss: 1.8537, value_loss: 0.9808
2024-07-14 05:00:33,633 [INFO    ] __main__: train step 1635: loss: 0.4299, policy_loss: 1.8536, value_loss: 0.9808
2024-07-14 05:00:33,901 [INFO    ] __main__: train step 1636: loss: 0.4300, policy_loss: 1.8535, value_loss: 0.9808
2024-07-14 05:00:34,195 [INFO    ] __main__: train step 1637: loss: 0.4302, policy_loss: 1.8535, value_loss: 0.9807
2024-07-14 05:00:34,465 [INFO    ] __main__: train step 1638: loss: 0.4303, policy_loss: 1.8534, value_loss: 0.9807
2024-07-14 05:00:34,735 [INFO    ] __main__: train step 1639: loss: 0.4305, policy_loss: 1.8533, value_loss: 0.9807
2024-07-14 05:00:34,998 [INFO    ] __main__: train step 1640: loss: 0.4307, policy_loss: 1.8532, value_loss: 0.9807
2024-07-14 05:00:35,277 [INFO    ] __main__: train step 1641: loss: 0.4308, policy_loss: 1.8532, value_loss: 0.9807
2024-07-14 05:00:35,560 [INFO    ] __main__: train step 1642: loss: 0.4310, policy_loss: 1.8531, value_loss: 0.9807
2024-07-14 05:00:35,832 [INFO    ] __main__: train step 1643: loss: 0.4312, policy_loss: 1.8530, value_loss: 0.9807
2024-07-14 05:00:36,109 [INFO    ] __main__: train step 1644: loss: 0.4313, policy_loss: 1.8530, value_loss: 0.9807
2024-07-14 05:00:36,387 [INFO    ] __main__: train step 1645: loss: 0.4315, policy_loss: 1.8529, value_loss: 0.9807
2024-07-14 05:00:38,131 [INFO    ] __main__: replay_buffer size = 54784
2024-07-14 05:00:38,490 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:00:41,012 [INFO    ] __main__: train step 1646: loss: 0.4317, policy_loss: 1.8528, value_loss: 0.9807
2024-07-14 05:00:41,292 [INFO    ] __main__: train step 1647: loss: 0.4318, policy_loss: 1.8527, value_loss: 0.9807
2024-07-14 05:00:42,125 [INFO    ] __main__: train step 1648: loss: 0.4320, policy_loss: 1.8527, value_loss: 0.9807
2024-07-14 05:00:42,395 [INFO    ] __main__: train step 1649: loss: 0.4322, policy_loss: 1.8526, value_loss: 0.9807
2024-07-14 05:00:42,661 [INFO    ] __main__: train step 1650: loss: 0.4323, policy_loss: 1.8525, value_loss: 0.9806
2024-07-14 05:00:42,931 [INFO    ] __main__: train step 1651: loss: 0.4325, policy_loss: 1.8524, value_loss: 0.9807
2024-07-14 05:00:43,199 [INFO    ] __main__: train step 1652: loss: 0.4327, policy_loss: 1.8524, value_loss: 0.9806
2024-07-14 05:00:43,468 [INFO    ] __main__: train step 1653: loss: 0.4328, policy_loss: 1.8523, value_loss: 0.9806
2024-07-14 05:00:43,741 [INFO    ] __main__: train step 1654: loss: 0.4330, policy_loss: 1.8522, value_loss: 0.9806
2024-07-14 05:00:44,007 [INFO    ] __main__: train step 1655: loss: 0.4331, policy_loss: 1.8522, value_loss: 0.9806
2024-07-14 05:00:44,273 [INFO    ] __main__: train step 1656: loss: 0.4333, policy_loss: 1.8521, value_loss: 0.9806
2024-07-14 05:00:44,527 [INFO    ] __main__: train step 1657: loss: 0.4335, policy_loss: 1.8520, value_loss: 0.9806
2024-07-14 05:00:44,797 [INFO    ] __main__: train step 1658: loss: 0.4336, policy_loss: 1.8519, value_loss: 0.9806
2024-07-14 05:00:45,054 [INFO    ] __main__: train step 1659: loss: 0.4338, policy_loss: 1.8519, value_loss: 0.9806
2024-07-14 05:00:45,325 [INFO    ] __main__: train step 1660: loss: 0.4340, policy_loss: 1.8518, value_loss: 0.9806
2024-07-14 05:00:45,605 [INFO    ] __main__: train step 1661: loss: 0.4341, policy_loss: 1.8517, value_loss: 0.9806
2024-07-14 05:00:45,866 [INFO    ] __main__: train step 1662: loss: 0.4343, policy_loss: 1.8517, value_loss: 0.9806
2024-07-14 05:00:47,589 [INFO    ] __main__: replay_buffer size = 55296
2024-07-14 05:00:47,938 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:00:49,752 [INFO    ] __main__: train step 1663: loss: 0.4345, policy_loss: 1.8516, value_loss: 0.9806
2024-07-14 05:00:50,020 [INFO    ] __main__: train step 1664: loss: 0.4346, policy_loss: 1.8515, value_loss: 0.9806
2024-07-14 05:00:50,283 [INFO    ] __main__: train step 1665: loss: 0.4348, policy_loss: 1.8515, value_loss: 0.9806
2024-07-14 05:00:51,109 [INFO    ] __main__: train step 1666: loss: 0.4350, policy_loss: 1.8514, value_loss: 0.9806
2024-07-14 05:00:51,377 [INFO    ] __main__: train step 1667: loss: 0.4351, policy_loss: 1.8513, value_loss: 0.9806
2024-07-14 05:00:51,648 [INFO    ] __main__: train step 1668: loss: 0.4353, policy_loss: 1.8512, value_loss: 0.9806
2024-07-14 05:00:51,919 [INFO    ] __main__: train step 1669: loss: 0.4354, policy_loss: 1.8511, value_loss: 0.9806
2024-07-14 05:00:52,186 [INFO    ] __main__: train step 1670: loss: 0.4356, policy_loss: 1.8511, value_loss: 0.9806
2024-07-14 05:00:52,454 [INFO    ] __main__: train step 1671: loss: 0.4357, policy_loss: 1.8510, value_loss: 0.9806
2024-07-14 05:00:52,719 [INFO    ] __main__: train step 1672: loss: 0.4359, policy_loss: 1.8509, value_loss: 0.9806
2024-07-14 05:00:52,985 [INFO    ] __main__: train step 1673: loss: 0.4361, policy_loss: 1.8508, value_loss: 0.9805
2024-07-14 05:00:53,246 [INFO    ] __main__: train step 1674: loss: 0.4362, policy_loss: 1.8508, value_loss: 0.9805
2024-07-14 05:00:53,511 [INFO    ] __main__: train step 1675: loss: 0.4364, policy_loss: 1.8507, value_loss: 0.9805
2024-07-14 05:00:53,785 [INFO    ] __main__: train step 1676: loss: 0.4366, policy_loss: 1.8506, value_loss: 0.9805
2024-07-14 05:00:54,061 [INFO    ] __main__: train step 1677: loss: 0.4367, policy_loss: 1.8506, value_loss: 0.9805
2024-07-14 05:00:54,328 [INFO    ] __main__: train step 1678: loss: 0.4369, policy_loss: 1.8505, value_loss: 0.9805
2024-07-14 05:00:54,595 [INFO    ] __main__: train step 1679: loss: 0.4371, policy_loss: 1.8504, value_loss: 0.9805
2024-07-14 05:00:56,358 [INFO    ] __main__: replay_buffer size = 55808
2024-07-14 05:00:56,718 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:00:59,191 [INFO    ] __main__: train step 1680: loss: 0.4373, policy_loss: 1.8503, value_loss: 0.9805
2024-07-14 05:00:59,457 [INFO    ] __main__: train step 1681: loss: 0.4374, policy_loss: 1.8502, value_loss: 0.9805
2024-07-14 05:00:59,738 [INFO    ] __main__: train step 1682: loss: 0.4376, policy_loss: 1.8502, value_loss: 0.9805
2024-07-14 05:01:00,025 [INFO    ] __main__: train step 1683: loss: 0.4378, policy_loss: 1.8501, value_loss: 0.9805
2024-07-14 05:01:00,297 [INFO    ] __main__: train step 1684: loss: 0.4379, policy_loss: 1.8500, value_loss: 0.9805
2024-07-14 05:01:00,889 [INFO    ] __main__: train step 1685: loss: 0.4381, policy_loss: 1.8499, value_loss: 0.9805
2024-07-14 05:01:01,156 [INFO    ] __main__: train step 1686: loss: 0.4383, policy_loss: 1.8498, value_loss: 0.9805
2024-07-14 05:01:01,430 [INFO    ] __main__: train step 1687: loss: 0.4384, policy_loss: 1.8498, value_loss: 0.9805
2024-07-14 05:01:01,695 [INFO    ] __main__: train step 1688: loss: 0.4386, policy_loss: 1.8497, value_loss: 0.9805
2024-07-14 05:01:01,972 [INFO    ] __main__: train step 1689: loss: 0.4388, policy_loss: 1.8496, value_loss: 0.9805
2024-07-14 05:01:02,251 [INFO    ] __main__: train step 1690: loss: 0.4390, policy_loss: 1.8495, value_loss: 0.9805
2024-07-14 05:01:02,516 [INFO    ] __main__: train step 1691: loss: 0.4391, policy_loss: 1.8495, value_loss: 0.9804
2024-07-14 05:01:02,796 [INFO    ] __main__: train step 1692: loss: 0.4393, policy_loss: 1.8494, value_loss: 0.9804
2024-07-14 05:01:03,056 [INFO    ] __main__: train step 1693: loss: 0.4395, policy_loss: 1.8493, value_loss: 0.9804
2024-07-14 05:01:03,336 [INFO    ] __main__: train step 1694: loss: 0.4396, policy_loss: 1.8493, value_loss: 0.9804
2024-07-14 05:01:03,608 [INFO    ] __main__: train step 1695: loss: 0.4398, policy_loss: 1.8492, value_loss: 0.9804
2024-07-14 05:01:03,866 [INFO    ] __main__: train step 1696: loss: 0.4400, policy_loss: 1.8491, value_loss: 0.9804
2024-07-14 05:01:05,632 [INFO    ] __main__: replay_buffer size = 56320
2024-07-14 05:01:05,996 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:01:08,449 [INFO    ] __main__: train step 1697: loss: 0.4401, policy_loss: 1.8490, value_loss: 0.9804
2024-07-14 05:01:08,736 [INFO    ] __main__: train step 1698: loss: 0.4403, policy_loss: 1.8490, value_loss: 0.9804
2024-07-14 05:01:08,998 [INFO    ] __main__: train step 1699: loss: 0.4405, policy_loss: 1.8489, value_loss: 0.9804
2024-07-14 05:01:09,265 [INFO    ] __main__: train step 1700: loss: 0.4406, policy_loss: 1.8488, value_loss: 0.9804
2024-07-14 05:01:09,538 [INFO    ] __main__: train step 1701: loss: 0.4408, policy_loss: 1.8488, value_loss: 0.9804
2024-07-14 05:01:09,815 [INFO    ] __main__: train step 1702: loss: 0.4410, policy_loss: 1.8487, value_loss: 0.9803
2024-07-14 05:01:10,399 [INFO    ] __main__: train step 1703: loss: 0.4411, policy_loss: 1.8486, value_loss: 0.9803
2024-07-14 05:01:10,672 [INFO    ] __main__: train step 1704: loss: 0.4413, policy_loss: 1.8485, value_loss: 0.9803
2024-07-14 05:01:10,944 [INFO    ] __main__: train step 1705: loss: 0.4415, policy_loss: 1.8484, value_loss: 0.9803
2024-07-14 05:01:11,222 [INFO    ] __main__: train step 1706: loss: 0.4416, policy_loss: 1.8484, value_loss: 0.9803
2024-07-14 05:01:11,489 [INFO    ] __main__: train step 1707: loss: 0.4418, policy_loss: 1.8483, value_loss: 0.9802
2024-07-14 05:01:11,762 [INFO    ] __main__: train step 1708: loss: 0.4420, policy_loss: 1.8482, value_loss: 0.9802
2024-07-14 05:01:12,025 [INFO    ] __main__: train step 1709: loss: 0.4422, policy_loss: 1.8481, value_loss: 0.9803
2024-07-14 05:01:12,285 [INFO    ] __main__: train step 1710: loss: 0.4423, policy_loss: 1.8480, value_loss: 0.9803
2024-07-14 05:01:12,569 [INFO    ] __main__: train step 1711: loss: 0.4425, policy_loss: 1.8480, value_loss: 0.9802
2024-07-14 05:01:12,832 [INFO    ] __main__: train step 1712: loss: 0.4427, policy_loss: 1.8479, value_loss: 0.9802
2024-07-14 05:01:13,093 [INFO    ] __main__: train step 1713: loss: 0.4428, policy_loss: 1.8478, value_loss: 0.9802
2024-07-14 05:01:14,847 [INFO    ] __main__: replay_buffer size = 56832
2024-07-14 05:01:15,190 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:01:17,783 [INFO    ] __main__: train step 1714: loss: 0.4430, policy_loss: 1.8478, value_loss: 0.9802
2024-07-14 05:01:18,051 [INFO    ] __main__: train step 1715: loss: 0.4431, policy_loss: 1.8477, value_loss: 0.9802
2024-07-14 05:01:18,300 [INFO    ] __main__: train step 1716: loss: 0.4433, policy_loss: 1.8476, value_loss: 0.9802
2024-07-14 05:01:18,567 [INFO    ] __main__: train step 1717: loss: 0.4435, policy_loss: 1.8475, value_loss: 0.9802
2024-07-14 05:01:18,826 [INFO    ] __main__: train step 1718: loss: 0.4436, policy_loss: 1.8475, value_loss: 0.9802
2024-07-14 05:01:19,083 [INFO    ] __main__: train step 1719: loss: 0.4438, policy_loss: 1.8474, value_loss: 0.9802
2024-07-14 05:01:19,343 [INFO    ] __main__: train step 1720: loss: 0.4440, policy_loss: 1.8473, value_loss: 0.9802
2024-07-14 05:01:19,598 [INFO    ] __main__: train step 1721: loss: 0.4442, policy_loss: 1.8473, value_loss: 0.9802
2024-07-14 05:01:19,862 [INFO    ] __main__: train step 1722: loss: 0.4443, policy_loss: 1.8472, value_loss: 0.9801
2024-07-14 05:01:20,544 [INFO    ] __main__: train step 1723: loss: 0.4445, policy_loss: 1.8471, value_loss: 0.9801
2024-07-14 05:01:20,803 [INFO    ] __main__: train step 1724: loss: 0.4446, policy_loss: 1.8471, value_loss: 0.9802
2024-07-14 05:01:21,075 [INFO    ] __main__: train step 1725: loss: 0.4448, policy_loss: 1.8470, value_loss: 0.9801
2024-07-14 05:01:21,345 [INFO    ] __main__: train step 1726: loss: 0.4450, policy_loss: 1.8469, value_loss: 0.9801
2024-07-14 05:01:21,606 [INFO    ] __main__: train step 1727: loss: 0.4452, policy_loss: 1.8468, value_loss: 0.9801
2024-07-14 05:01:21,887 [INFO    ] __main__: train step 1728: loss: 0.4453, policy_loss: 1.8468, value_loss: 0.9801
2024-07-14 05:01:22,165 [INFO    ] __main__: train step 1729: loss: 0.4455, policy_loss: 1.8467, value_loss: 0.9801
2024-07-14 05:01:22,419 [INFO    ] __main__: train step 1730: loss: 0.4457, policy_loss: 1.8467, value_loss: 0.9801
2024-07-14 05:01:24,159 [INFO    ] __main__: replay_buffer size = 57344
2024-07-14 05:01:24,527 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:01:26,383 [INFO    ] __main__: train step 1731: loss: 0.4459, policy_loss: 1.8466, value_loss: 0.9801
2024-07-14 05:01:26,655 [INFO    ] __main__: train step 1732: loss: 0.4460, policy_loss: 1.8465, value_loss: 0.9800
2024-07-14 05:01:26,903 [INFO    ] __main__: train step 1733: loss: 0.4462, policy_loss: 1.8465, value_loss: 0.9800
2024-07-14 05:01:27,150 [INFO    ] __main__: train step 1734: loss: 0.4464, policy_loss: 1.8464, value_loss: 0.9800
2024-07-14 05:01:27,401 [INFO    ] __main__: train step 1735: loss: 0.4465, policy_loss: 1.8463, value_loss: 0.9800
2024-07-14 05:01:27,657 [INFO    ] __main__: train step 1736: loss: 0.4467, policy_loss: 1.8462, value_loss: 0.9800
2024-07-14 05:01:27,909 [INFO    ] __main__: train step 1737: loss: 0.4469, policy_loss: 1.8462, value_loss: 0.9799
2024-07-14 05:01:28,164 [INFO    ] __main__: train step 1738: loss: 0.4470, policy_loss: 1.8461, value_loss: 0.9799
2024-07-14 05:01:28,418 [INFO    ] __main__: train step 1739: loss: 0.4472, policy_loss: 1.8460, value_loss: 0.9799
2024-07-14 05:01:28,672 [INFO    ] __main__: train step 1740: loss: 0.4474, policy_loss: 1.8460, value_loss: 0.9799
2024-07-14 05:01:29,300 [INFO    ] __main__: train step 1741: loss: 0.4476, policy_loss: 1.8459, value_loss: 0.9799
2024-07-14 05:01:29,569 [INFO    ] __main__: train step 1742: loss: 0.4477, policy_loss: 1.8459, value_loss: 0.9799
2024-07-14 05:01:29,835 [INFO    ] __main__: train step 1743: loss: 0.4479, policy_loss: 1.8458, value_loss: 0.9798
2024-07-14 05:01:30,089 [INFO    ] __main__: train step 1744: loss: 0.4481, policy_loss: 1.8457, value_loss: 0.9798
2024-07-14 05:01:30,345 [INFO    ] __main__: train step 1745: loss: 0.4482, policy_loss: 1.8457, value_loss: 0.9798
2024-07-14 05:01:30,601 [INFO    ] __main__: train step 1746: loss: 0.4484, policy_loss: 1.8456, value_loss: 0.9798
2024-07-14 05:01:30,860 [INFO    ] __main__: train step 1747: loss: 0.4486, policy_loss: 1.8455, value_loss: 0.9798
2024-07-14 05:01:32,586 [INFO    ] __main__: replay_buffer size = 57856
2024-07-14 05:01:32,960 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:01:35,410 [INFO    ] __main__: train step 1748: loss: 0.4487, policy_loss: 1.8455, value_loss: 0.9798
2024-07-14 05:01:35,688 [INFO    ] __main__: train step 1749: loss: 0.4489, policy_loss: 1.8454, value_loss: 0.9797
2024-07-14 05:01:35,937 [INFO    ] __main__: train step 1750: loss: 0.4491, policy_loss: 1.8453, value_loss: 0.9797
2024-07-14 05:01:36,195 [INFO    ] __main__: train step 1751: loss: 0.4492, policy_loss: 1.8453, value_loss: 0.9797
2024-07-14 05:01:36,448 [INFO    ] __main__: train step 1752: loss: 0.4494, policy_loss: 1.8452, value_loss: 0.9797
2024-07-14 05:01:36,714 [INFO    ] __main__: train step 1753: loss: 0.4495, policy_loss: 1.8451, value_loss: 0.9797
2024-07-14 05:01:36,962 [INFO    ] __main__: train step 1754: loss: 0.4497, policy_loss: 1.8451, value_loss: 0.9797
2024-07-14 05:01:37,221 [INFO    ] __main__: train step 1755: loss: 0.4499, policy_loss: 1.8450, value_loss: 0.9797
2024-07-14 05:01:37,474 [INFO    ] __main__: train step 1756: loss: 0.4501, policy_loss: 1.8449, value_loss: 0.9797
2024-07-14 05:01:37,732 [INFO    ] __main__: train step 1757: loss: 0.4502, policy_loss: 1.8449, value_loss: 0.9797
2024-07-14 05:01:37,988 [INFO    ] __main__: train step 1758: loss: 0.4504, policy_loss: 1.8448, value_loss: 0.9797
2024-07-14 05:01:38,641 [INFO    ] __main__: train step 1759: loss: 0.4506, policy_loss: 1.8447, value_loss: 0.9797
2024-07-14 05:01:38,910 [INFO    ] __main__: train step 1760: loss: 0.4507, policy_loss: 1.8447, value_loss: 0.9797
2024-07-14 05:01:39,169 [INFO    ] __main__: train step 1761: loss: 0.4509, policy_loss: 1.8446, value_loss: 0.9797
2024-07-14 05:01:39,429 [INFO    ] __main__: train step 1762: loss: 0.4510, policy_loss: 1.8445, value_loss: 0.9796
2024-07-14 05:01:39,685 [INFO    ] __main__: train step 1763: loss: 0.4512, policy_loss: 1.8444, value_loss: 0.9796
2024-07-14 05:01:39,943 [INFO    ] __main__: train step 1764: loss: 0.4514, policy_loss: 1.8444, value_loss: 0.9796
2024-07-14 05:01:41,646 [INFO    ] __main__: replay_buffer size = 58368
2024-07-14 05:01:42,007 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:01:44,434 [INFO    ] __main__: train step 1765: loss: 0.4515, policy_loss: 1.8443, value_loss: 0.9796
2024-07-14 05:01:44,715 [INFO    ] __main__: train step 1766: loss: 0.4517, policy_loss: 1.8442, value_loss: 0.9796
2024-07-14 05:01:44,992 [INFO    ] __main__: train step 1767: loss: 0.4519, policy_loss: 1.8441, value_loss: 0.9795
2024-07-14 05:01:45,262 [INFO    ] __main__: train step 1768: loss: 0.4520, policy_loss: 1.8441, value_loss: 0.9795
2024-07-14 05:01:45,515 [INFO    ] __main__: train step 1769: loss: 0.4522, policy_loss: 1.8440, value_loss: 0.9795
2024-07-14 05:01:45,777 [INFO    ] __main__: train step 1770: loss: 0.4524, policy_loss: 1.8440, value_loss: 0.9795
2024-07-14 05:01:46,030 [INFO    ] __main__: train step 1771: loss: 0.4525, policy_loss: 1.8439, value_loss: 0.9795
2024-07-14 05:01:46,314 [INFO    ] __main__: train step 1772: loss: 0.4527, policy_loss: 1.8438, value_loss: 0.9795
2024-07-14 05:01:46,556 [INFO    ] __main__: train step 1773: loss: 0.4529, policy_loss: 1.8438, value_loss: 0.9795
2024-07-14 05:01:46,959 [INFO    ] __main__: train step 1774: loss: 0.4531, policy_loss: 1.8437, value_loss: 0.9795
2024-07-14 05:01:47,271 [INFO    ] __main__: train step 1775: loss: 0.4532, policy_loss: 1.8436, value_loss: 0.9794
2024-07-14 05:01:47,527 [INFO    ] __main__: train step 1776: loss: 0.4534, policy_loss: 1.8435, value_loss: 0.9794
2024-07-14 05:01:47,797 [INFO    ] __main__: train step 1777: loss: 0.4536, policy_loss: 1.8435, value_loss: 0.9794
2024-07-14 05:01:48,497 [INFO    ] __main__: train step 1778: loss: 0.4537, policy_loss: 1.8434, value_loss: 0.9794
2024-07-14 05:01:48,750 [INFO    ] __main__: train step 1779: loss: 0.4539, policy_loss: 1.8433, value_loss: 0.9794
2024-07-14 05:01:48,999 [INFO    ] __main__: train step 1780: loss: 0.4541, policy_loss: 1.8433, value_loss: 0.9794
2024-07-14 05:01:49,249 [INFO    ] __main__: train step 1781: loss: 0.4542, policy_loss: 1.8432, value_loss: 0.9794
2024-07-14 05:01:50,977 [INFO    ] __main__: replay_buffer size = 58880
2024-07-14 05:01:51,356 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:01:53,902 [INFO    ] __main__: train step 1782: loss: 0.4544, policy_loss: 1.8431, value_loss: 0.9794
2024-07-14 05:01:54,163 [INFO    ] __main__: train step 1783: loss: 0.4546, policy_loss: 1.8431, value_loss: 0.9794
2024-07-14 05:01:54,426 [INFO    ] __main__: train step 1784: loss: 0.4547, policy_loss: 1.8430, value_loss: 0.9794
2024-07-14 05:01:54,686 [INFO    ] __main__: train step 1785: loss: 0.4549, policy_loss: 1.8429, value_loss: 0.9794
2024-07-14 05:01:54,952 [INFO    ] __main__: train step 1786: loss: 0.4551, policy_loss: 1.8428, value_loss: 0.9794
2024-07-14 05:01:55,214 [INFO    ] __main__: train step 1787: loss: 0.4552, policy_loss: 1.8428, value_loss: 0.9794
2024-07-14 05:01:55,470 [INFO    ] __main__: train step 1788: loss: 0.4554, policy_loss: 1.8427, value_loss: 0.9794
2024-07-14 05:01:55,727 [INFO    ] __main__: train step 1789: loss: 0.4555, policy_loss: 1.8426, value_loss: 0.9793
2024-07-14 05:01:55,994 [INFO    ] __main__: train step 1790: loss: 0.4557, policy_loss: 1.8426, value_loss: 0.9793
2024-07-14 05:01:56,257 [INFO    ] __main__: train step 1791: loss: 0.4559, policy_loss: 1.8425, value_loss: 0.9793
2024-07-14 05:01:56,511 [INFO    ] __main__: train step 1792: loss: 0.4560, policy_loss: 1.8424, value_loss: 0.9793
2024-07-14 05:01:56,782 [INFO    ] __main__: train step 1793: loss: 0.4562, policy_loss: 1.8424, value_loss: 0.9793
2024-07-14 05:01:57,043 [INFO    ] __main__: train step 1794: loss: 0.4564, policy_loss: 1.8423, value_loss: 0.9793
2024-07-14 05:01:57,311 [INFO    ] __main__: train step 1795: loss: 0.4565, policy_loss: 1.8422, value_loss: 0.9793
2024-07-14 05:01:58,142 [INFO    ] __main__: train step 1796: loss: 0.4567, policy_loss: 1.8421, value_loss: 0.9793
2024-07-14 05:01:58,492 [INFO    ] __main__: train step 1797: loss: 0.4569, policy_loss: 1.8421, value_loss: 0.9793
2024-07-14 05:01:58,781 [INFO    ] __main__: train step 1798: loss: 0.4570, policy_loss: 1.8420, value_loss: 0.9793
2024-07-14 05:02:00,544 [INFO    ] __main__: replay_buffer size = 59392
2024-07-14 05:02:00,956 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:02:02,831 [INFO    ] __main__: train step 1799: loss: 0.4572, policy_loss: 1.8419, value_loss: 0.9793
2024-07-14 05:02:03,098 [INFO    ] __main__: train step 1800: loss: 0.4574, policy_loss: 1.8419, value_loss: 0.9793
2024-07-14 05:02:03,360 [INFO    ] __main__: train step 1801: loss: 0.4575, policy_loss: 1.8418, value_loss: 0.9792
2024-07-14 05:02:03,628 [INFO    ] __main__: train step 1802: loss: 0.4577, policy_loss: 1.8417, value_loss: 0.9792
2024-07-14 05:02:03,883 [INFO    ] __main__: train step 1803: loss: 0.4579, policy_loss: 1.8417, value_loss: 0.9792
2024-07-14 05:02:04,142 [INFO    ] __main__: train step 1804: loss: 0.4580, policy_loss: 1.8416, value_loss: 0.9792
2024-07-14 05:02:04,429 [INFO    ] __main__: train step 1805: loss: 0.4582, policy_loss: 1.8415, value_loss: 0.9792
2024-07-14 05:02:04,690 [INFO    ] __main__: train step 1806: loss: 0.4584, policy_loss: 1.8415, value_loss: 0.9792
2024-07-14 05:02:04,953 [INFO    ] __main__: train step 1807: loss: 0.4586, policy_loss: 1.8414, value_loss: 0.9792
2024-07-14 05:02:05,218 [INFO    ] __main__: train step 1808: loss: 0.4587, policy_loss: 1.8414, value_loss: 0.9792
2024-07-14 05:02:05,473 [INFO    ] __main__: train step 1809: loss: 0.4589, policy_loss: 1.8413, value_loss: 0.9792
2024-07-14 05:02:05,740 [INFO    ] __main__: train step 1810: loss: 0.4591, policy_loss: 1.8412, value_loss: 0.9792
2024-07-14 05:02:05,996 [INFO    ] __main__: train step 1811: loss: 0.4592, policy_loss: 1.8412, value_loss: 0.9792
2024-07-14 05:02:06,257 [INFO    ] __main__: train step 1812: loss: 0.4594, policy_loss: 1.8411, value_loss: 0.9791
2024-07-14 05:02:06,528 [INFO    ] __main__: train step 1813: loss: 0.4596, policy_loss: 1.8410, value_loss: 0.9791
2024-07-14 05:02:06,804 [INFO    ] __main__: train step 1814: loss: 0.4597, policy_loss: 1.8410, value_loss: 0.9791
2024-07-14 05:02:07,669 [INFO    ] __main__: train step 1815: loss: 0.4599, policy_loss: 1.8409, value_loss: 0.9791
2024-07-14 05:02:09,396 [INFO    ] __main__: replay_buffer size = 59904
2024-07-14 05:02:09,889 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:02:12,221 [INFO    ] __main__: train step 1816: loss: 0.4600, policy_loss: 1.8409, value_loss: 0.9791
2024-07-14 05:02:12,495 [INFO    ] __main__: train step 1817: loss: 0.4602, policy_loss: 1.8408, value_loss: 0.9791
2024-07-14 05:02:12,768 [INFO    ] __main__: train step 1818: loss: 0.4604, policy_loss: 1.8407, value_loss: 0.9791
2024-07-14 05:02:13,044 [INFO    ] __main__: train step 1819: loss: 0.4605, policy_loss: 1.8407, value_loss: 0.9791
2024-07-14 05:02:13,307 [INFO    ] __main__: train step 1820: loss: 0.4607, policy_loss: 1.8406, value_loss: 0.9791
2024-07-14 05:02:13,573 [INFO    ] __main__: train step 1821: loss: 0.4609, policy_loss: 1.8405, value_loss: 0.9791
2024-07-14 05:02:13,827 [INFO    ] __main__: train step 1822: loss: 0.4610, policy_loss: 1.8405, value_loss: 0.9791
2024-07-14 05:02:14,093 [INFO    ] __main__: train step 1823: loss: 0.4612, policy_loss: 1.8404, value_loss: 0.9791
2024-07-14 05:02:14,361 [INFO    ] __main__: train step 1824: loss: 0.4614, policy_loss: 1.8403, value_loss: 0.9791
2024-07-14 05:02:14,628 [INFO    ] __main__: train step 1825: loss: 0.4615, policy_loss: 1.8403, value_loss: 0.9790
2024-07-14 05:02:14,908 [INFO    ] __main__: train step 1826: loss: 0.4617, policy_loss: 1.8402, value_loss: 0.9790
2024-07-14 05:02:15,205 [INFO    ] __main__: train step 1827: loss: 0.4619, policy_loss: 1.8401, value_loss: 0.9790
2024-07-14 05:02:15,466 [INFO    ] __main__: train step 1828: loss: 0.4620, policy_loss: 1.8401, value_loss: 0.9790
2024-07-14 05:02:15,733 [INFO    ] __main__: train step 1829: loss: 0.4622, policy_loss: 1.8400, value_loss: 0.9790
2024-07-14 05:02:16,010 [INFO    ] __main__: train step 1830: loss: 0.4623, policy_loss: 1.8399, value_loss: 0.9790
2024-07-14 05:02:16,273 [INFO    ] __main__: train step 1831: loss: 0.4625, policy_loss: 1.8399, value_loss: 0.9790
2024-07-14 05:02:16,537 [INFO    ] __main__: train step 1832: loss: 0.4627, policy_loss: 1.8398, value_loss: 0.9790
2024-07-14 05:02:18,784 [INFO    ] __main__: replay_buffer size = 60416
2024-07-14 05:02:19,209 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:02:21,654 [INFO    ] __main__: train step 1833: loss: 0.4629, policy_loss: 1.8398, value_loss: 0.9789
2024-07-14 05:02:21,902 [INFO    ] __main__: train step 1834: loss: 0.4630, policy_loss: 1.8397, value_loss: 0.9789
2024-07-14 05:02:22,151 [INFO    ] __main__: train step 1835: loss: 0.4632, policy_loss: 1.8396, value_loss: 0.9789
2024-07-14 05:02:22,420 [INFO    ] __main__: train step 1836: loss: 0.4634, policy_loss: 1.8395, value_loss: 0.9789
2024-07-14 05:02:22,676 [INFO    ] __main__: train step 1837: loss: 0.4635, policy_loss: 1.8395, value_loss: 0.9789
2024-07-14 05:02:22,943 [INFO    ] __main__: train step 1838: loss: 0.4637, policy_loss: 1.8394, value_loss: 0.9789
2024-07-14 05:02:23,213 [INFO    ] __main__: train step 1839: loss: 0.4638, policy_loss: 1.8393, value_loss: 0.9789
2024-07-14 05:02:23,485 [INFO    ] __main__: train step 1840: loss: 0.4640, policy_loss: 1.8393, value_loss: 0.9789
2024-07-14 05:02:23,765 [INFO    ] __main__: train step 1841: loss: 0.4642, policy_loss: 1.8392, value_loss: 0.9789
2024-07-14 05:02:24,040 [INFO    ] __main__: train step 1842: loss: 0.4643, policy_loss: 1.8391, value_loss: 0.9788
2024-07-14 05:02:24,302 [INFO    ] __main__: train step 1843: loss: 0.4645, policy_loss: 1.8390, value_loss: 0.9788
2024-07-14 05:02:24,578 [INFO    ] __main__: train step 1844: loss: 0.4646, policy_loss: 1.8390, value_loss: 0.9788
2024-07-14 05:02:24,853 [INFO    ] __main__: train step 1845: loss: 0.4648, policy_loss: 1.8389, value_loss: 0.9788
2024-07-14 05:02:25,122 [INFO    ] __main__: train step 1846: loss: 0.4650, policy_loss: 1.8388, value_loss: 0.9788
2024-07-14 05:02:25,395 [INFO    ] __main__: train step 1847: loss: 0.4652, policy_loss: 1.8387, value_loss: 0.9788
2024-07-14 05:02:25,660 [INFO    ] __main__: train step 1848: loss: 0.4653, policy_loss: 1.8387, value_loss: 0.9788
2024-07-14 05:02:25,941 [INFO    ] __main__: train step 1849: loss: 0.4655, policy_loss: 1.8386, value_loss: 0.9788
2024-07-14 05:02:27,676 [INFO    ] __main__: replay_buffer size = 60928
2024-07-14 05:02:28,073 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:02:30,604 [INFO    ] __main__: train step 1850: loss: 0.4657, policy_loss: 1.8385, value_loss: 0.9788
2024-07-14 05:02:30,882 [INFO    ] __main__: train step 1851: loss: 0.4658, policy_loss: 1.8385, value_loss: 0.9788
2024-07-14 05:02:31,741 [INFO    ] __main__: train step 1852: loss: 0.4660, policy_loss: 1.8384, value_loss: 0.9787
2024-07-14 05:02:32,019 [INFO    ] __main__: train step 1853: loss: 0.4661, policy_loss: 1.8383, value_loss: 0.9787
2024-07-14 05:02:32,293 [INFO    ] __main__: train step 1854: loss: 0.4663, policy_loss: 1.8383, value_loss: 0.9787
2024-07-14 05:02:32,561 [INFO    ] __main__: train step 1855: loss: 0.4665, policy_loss: 1.8382, value_loss: 0.9787
2024-07-14 05:02:32,804 [INFO    ] __main__: train step 1856: loss: 0.4666, policy_loss: 1.8381, value_loss: 0.9787
2024-07-14 05:02:33,052 [INFO    ] __main__: train step 1857: loss: 0.4668, policy_loss: 1.8381, value_loss: 0.9787
2024-07-14 05:02:33,299 [INFO    ] __main__: train step 1858: loss: 0.4670, policy_loss: 1.8380, value_loss: 0.9787
2024-07-14 05:02:33,549 [INFO    ] __main__: train step 1859: loss: 0.4672, policy_loss: 1.8379, value_loss: 0.9787
2024-07-14 05:02:33,812 [INFO    ] __main__: train step 1860: loss: 0.4673, policy_loss: 1.8379, value_loss: 0.9786
2024-07-14 05:02:34,085 [INFO    ] __main__: train step 1861: loss: 0.4675, policy_loss: 1.8378, value_loss: 0.9786
2024-07-14 05:02:34,355 [INFO    ] __main__: train step 1862: loss: 0.4676, policy_loss: 1.8377, value_loss: 0.9786
2024-07-14 05:02:34,627 [INFO    ] __main__: train step 1863: loss: 0.4678, policy_loss: 1.8377, value_loss: 0.9786
2024-07-14 05:02:34,908 [INFO    ] __main__: train step 1864: loss: 0.4680, policy_loss: 1.8376, value_loss: 0.9785
2024-07-14 05:02:35,178 [INFO    ] __main__: train step 1865: loss: 0.4681, policy_loss: 1.8376, value_loss: 0.9785
2024-07-14 05:02:35,451 [INFO    ] __main__: train step 1866: loss: 0.4683, policy_loss: 1.8375, value_loss: 0.9785
2024-07-14 05:02:37,209 [INFO    ] __main__: replay_buffer size = 61440
2024-07-14 05:02:37,608 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:02:39,440 [INFO    ] __main__: train step 1867: loss: 0.4684, policy_loss: 1.8374, value_loss: 0.9785
2024-07-14 05:02:39,710 [INFO    ] __main__: train step 1868: loss: 0.4686, policy_loss: 1.8374, value_loss: 0.9785
2024-07-14 05:02:39,985 [INFO    ] __main__: train step 1869: loss: 0.4688, policy_loss: 1.8373, value_loss: 0.9785
2024-07-14 05:02:40,243 [INFO    ] __main__: train step 1870: loss: 0.4690, policy_loss: 1.8372, value_loss: 0.9784
2024-07-14 05:02:40,873 [INFO    ] __main__: train step 1871: loss: 0.4691, policy_loss: 1.8371, value_loss: 0.9784
2024-07-14 05:02:41,145 [INFO    ] __main__: train step 1872: loss: 0.4693, policy_loss: 1.8371, value_loss: 0.9784
2024-07-14 05:02:41,413 [INFO    ] __main__: train step 1873: loss: 0.4694, policy_loss: 1.8370, value_loss: 0.9784
2024-07-14 05:02:41,682 [INFO    ] __main__: train step 1874: loss: 0.4696, policy_loss: 1.8370, value_loss: 0.9784
2024-07-14 05:02:41,957 [INFO    ] __main__: train step 1875: loss: 0.4698, policy_loss: 1.8369, value_loss: 0.9783
2024-07-14 05:02:42,224 [INFO    ] __main__: train step 1876: loss: 0.4699, policy_loss: 1.8368, value_loss: 0.9783
2024-07-14 05:02:42,500 [INFO    ] __main__: train step 1877: loss: 0.4701, policy_loss: 1.8367, value_loss: 0.9783
2024-07-14 05:02:42,761 [INFO    ] __main__: train step 1878: loss: 0.4703, policy_loss: 1.8367, value_loss: 0.9783
2024-07-14 05:02:43,031 [INFO    ] __main__: train step 1879: loss: 0.4705, policy_loss: 1.8366, value_loss: 0.9783
2024-07-14 05:02:43,302 [INFO    ] __main__: train step 1880: loss: 0.4706, policy_loss: 1.8365, value_loss: 0.9783
2024-07-14 05:02:43,576 [INFO    ] __main__: train step 1881: loss: 0.4708, policy_loss: 1.8364, value_loss: 0.9782
2024-07-14 05:02:43,842 [INFO    ] __main__: train step 1882: loss: 0.4709, policy_loss: 1.8364, value_loss: 0.9782
2024-07-14 05:02:44,126 [INFO    ] __main__: train step 1883: loss: 0.4711, policy_loss: 1.8363, value_loss: 0.9782
2024-07-14 05:02:45,919 [INFO    ] __main__: replay_buffer size = 61952
2024-07-14 05:02:46,335 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:02:48,813 [INFO    ] __main__: train step 1884: loss: 0.4713, policy_loss: 1.8362, value_loss: 0.9782
2024-07-14 05:02:49,073 [INFO    ] __main__: train step 1885: loss: 0.4714, policy_loss: 1.8361, value_loss: 0.9782
2024-07-14 05:02:49,343 [INFO    ] __main__: train step 1886: loss: 0.4716, policy_loss: 1.8361, value_loss: 0.9782
2024-07-14 05:02:49,613 [INFO    ] __main__: train step 1887: loss: 0.4718, policy_loss: 1.8360, value_loss: 0.9782
2024-07-14 05:02:49,889 [INFO    ] __main__: train step 1888: loss: 0.4719, policy_loss: 1.8359, value_loss: 0.9781
2024-07-14 05:02:50,743 [INFO    ] __main__: train step 1889: loss: 0.4721, policy_loss: 1.8359, value_loss: 0.9781
2024-07-14 05:02:51,018 [INFO    ] __main__: train step 1890: loss: 0.4723, policy_loss: 1.8358, value_loss: 0.9781
2024-07-14 05:02:51,283 [INFO    ] __main__: train step 1891: loss: 0.4724, policy_loss: 1.8357, value_loss: 0.9781
2024-07-14 05:02:51,565 [INFO    ] __main__: train step 1892: loss: 0.4726, policy_loss: 1.8356, value_loss: 0.9781
2024-07-14 05:02:51,827 [INFO    ] __main__: train step 1893: loss: 0.4728, policy_loss: 1.8356, value_loss: 0.9781
2024-07-14 05:02:52,092 [INFO    ] __main__: train step 1894: loss: 0.4729, policy_loss: 1.8355, value_loss: 0.9781
2024-07-14 05:02:52,356 [INFO    ] __main__: train step 1895: loss: 0.4731, policy_loss: 1.8354, value_loss: 0.9781
2024-07-14 05:02:52,651 [INFO    ] __main__: train step 1896: loss: 0.4733, policy_loss: 1.8354, value_loss: 0.9781
2024-07-14 05:02:52,926 [INFO    ] __main__: train step 1897: loss: 0.4734, policy_loss: 1.8353, value_loss: 0.9781
2024-07-14 05:02:53,188 [INFO    ] __main__: train step 1898: loss: 0.4736, policy_loss: 1.8352, value_loss: 0.9781
2024-07-14 05:02:53,452 [INFO    ] __main__: train step 1899: loss: 0.4738, policy_loss: 1.8352, value_loss: 0.9780
2024-07-14 05:02:53,773 [INFO    ] __main__: train step 1900: loss: 0.4740, policy_loss: 1.8351, value_loss: 0.9780
2024-07-14 05:02:55,553 [INFO    ] __main__: replay_buffer size = 62464
2024-07-14 05:02:55,990 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:02:58,424 [INFO    ] __main__: train step 1901: loss: 0.4741, policy_loss: 1.8350, value_loss: 0.9780
2024-07-14 05:02:58,703 [INFO    ] __main__: train step 1902: loss: 0.4743, policy_loss: 1.8350, value_loss: 0.9780
2024-07-14 05:02:58,972 [INFO    ] __main__: train step 1903: loss: 0.4745, policy_loss: 1.8349, value_loss: 0.9780
2024-07-14 05:02:59,249 [INFO    ] __main__: train step 1904: loss: 0.4746, policy_loss: 1.8348, value_loss: 0.9779
2024-07-14 05:02:59,518 [INFO    ] __main__: train step 1905: loss: 0.4748, policy_loss: 1.8348, value_loss: 0.9779
2024-07-14 05:02:59,789 [INFO    ] __main__: train step 1906: loss: 0.4750, policy_loss: 1.8347, value_loss: 0.9779
2024-07-14 05:03:00,058 [INFO    ] __main__: train step 1907: loss: 0.4751, policy_loss: 1.8346, value_loss: 0.9779
2024-07-14 05:03:00,693 [INFO    ] __main__: train step 1908: loss: 0.4753, policy_loss: 1.8346, value_loss: 0.9779
2024-07-14 05:03:00,962 [INFO    ] __main__: train step 1909: loss: 0.4754, policy_loss: 1.8345, value_loss: 0.9779
2024-07-14 05:03:01,234 [INFO    ] __main__: train step 1910: loss: 0.4756, policy_loss: 1.8344, value_loss: 0.9779
2024-07-14 05:03:01,507 [INFO    ] __main__: train step 1911: loss: 0.4758, policy_loss: 1.8343, value_loss: 0.9779
2024-07-14 05:03:01,784 [INFO    ] __main__: train step 1912: loss: 0.4759, policy_loss: 1.8343, value_loss: 0.9778
2024-07-14 05:03:02,050 [INFO    ] __main__: train step 1913: loss: 0.4761, policy_loss: 1.8342, value_loss: 0.9778
2024-07-14 05:03:02,308 [INFO    ] __main__: train step 1914: loss: 0.4763, policy_loss: 1.8341, value_loss: 0.9778
2024-07-14 05:03:02,576 [INFO    ] __main__: train step 1915: loss: 0.4764, policy_loss: 1.8341, value_loss: 0.9778
2024-07-14 05:03:02,846 [INFO    ] __main__: train step 1916: loss: 0.4766, policy_loss: 1.8340, value_loss: 0.9778
2024-07-14 05:03:03,103 [INFO    ] __main__: train step 1917: loss: 0.4767, policy_loss: 1.8339, value_loss: 0.9777
2024-07-14 05:03:05,060 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:03:05,489 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:03:07,990 [INFO    ] __main__: train step 1918: loss: 0.4769, policy_loss: 1.8339, value_loss: 0.9777
2024-07-14 05:03:08,270 [INFO    ] __main__: train step 1919: loss: 0.4771, policy_loss: 1.8338, value_loss: 0.9777
2024-07-14 05:03:08,541 [INFO    ] __main__: train step 1920: loss: 0.4772, policy_loss: 1.8337, value_loss: 0.9777
2024-07-14 05:03:08,817 [INFO    ] __main__: train step 1921: loss: 0.4774, policy_loss: 1.8336, value_loss: 0.9777
2024-07-14 05:03:09,098 [INFO    ] __main__: train step 1922: loss: 0.4775, policy_loss: 1.8335, value_loss: 0.9777
2024-07-14 05:03:09,377 [INFO    ] __main__: train step 1923: loss: 0.4777, policy_loss: 1.8335, value_loss: 0.9777
2024-07-14 05:03:09,629 [INFO    ] __main__: train step 1924: loss: 0.4779, policy_loss: 1.8334, value_loss: 0.9777
2024-07-14 05:03:09,929 [INFO    ] __main__: train step 1925: loss: 0.4780, policy_loss: 1.8333, value_loss: 0.9776
2024-07-14 05:03:10,256 [INFO    ] __main__: train step 1926: loss: 0.4782, policy_loss: 1.8333, value_loss: 0.9776
2024-07-14 05:03:11,128 [INFO    ] __main__: train step 1927: loss: 0.4784, policy_loss: 1.8332, value_loss: 0.9776
2024-07-14 05:03:11,399 [INFO    ] __main__: train step 1928: loss: 0.4785, policy_loss: 1.8331, value_loss: 0.9776
2024-07-14 05:03:11,672 [INFO    ] __main__: train step 1929: loss: 0.4787, policy_loss: 1.8330, value_loss: 0.9776
2024-07-14 05:03:11,937 [INFO    ] __main__: train step 1930: loss: 0.4789, policy_loss: 1.8329, value_loss: 0.9776
2024-07-14 05:03:12,214 [INFO    ] __main__: train step 1931: loss: 0.4790, policy_loss: 1.8329, value_loss: 0.9775
2024-07-14 05:03:12,486 [INFO    ] __main__: train step 1932: loss: 0.4792, policy_loss: 1.8328, value_loss: 0.9775
2024-07-14 05:03:12,763 [INFO    ] __main__: train step 1933: loss: 0.4794, policy_loss: 1.8327, value_loss: 0.9775
2024-07-14 05:03:13,037 [INFO    ] __main__: train step 1934: loss: 0.4795, policy_loss: 1.8326, value_loss: 0.9775
2024-07-14 05:03:15,001 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:03:15,417 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:03:15,489 [INFO    ] __main__: train step 1935: loss: 0.4797, policy_loss: 1.8325, value_loss: 0.9775
2024-07-14 05:03:15,760 [INFO    ] __main__: train step 1936: loss: 0.4799, policy_loss: 1.8325, value_loss: 0.9775
2024-07-14 05:03:16,027 [INFO    ] __main__: train step 1937: loss: 0.4800, policy_loss: 1.8324, value_loss: 0.9775
2024-07-14 05:03:16,306 [INFO    ] __main__: train step 1938: loss: 0.4802, policy_loss: 1.8323, value_loss: 0.9775
2024-07-14 05:03:16,588 [INFO    ] __main__: train step 1939: loss: 0.4804, policy_loss: 1.8322, value_loss: 0.9775
2024-07-14 05:03:16,856 [INFO    ] __main__: train step 1940: loss: 0.4806, policy_loss: 1.8321, value_loss: 0.9774
2024-07-14 05:03:17,128 [INFO    ] __main__: train step 1941: loss: 0.4807, policy_loss: 1.8320, value_loss: 0.9774
2024-07-14 05:03:17,398 [INFO    ] __main__: train step 1942: loss: 0.4809, policy_loss: 1.8320, value_loss: 0.9774
2024-07-14 05:03:17,660 [INFO    ] __main__: train step 1943: loss: 0.4811, policy_loss: 1.8319, value_loss: 0.9774
2024-07-14 05:03:17,930 [INFO    ] __main__: train step 1944: loss: 0.4812, policy_loss: 1.8318, value_loss: 0.9774
2024-07-14 05:03:18,197 [INFO    ] __main__: train step 1945: loss: 0.4814, policy_loss: 1.8317, value_loss: 0.9774
2024-07-14 05:03:19,030 [INFO    ] __main__: train step 1946: loss: 0.4816, policy_loss: 1.8316, value_loss: 0.9774
2024-07-14 05:03:19,302 [INFO    ] __main__: train step 1947: loss: 0.4817, policy_loss: 1.8316, value_loss: 0.9774
2024-07-14 05:03:19,570 [INFO    ] __main__: train step 1948: loss: 0.4819, policy_loss: 1.8315, value_loss: 0.9774
2024-07-14 05:03:19,848 [INFO    ] __main__: train step 1949: loss: 0.4821, policy_loss: 1.8314, value_loss: 0.9773
2024-07-14 05:03:20,124 [INFO    ] __main__: train step 1950: loss: 0.4822, policy_loss: 1.8313, value_loss: 0.9773
2024-07-14 05:03:20,391 [INFO    ] __main__: train step 1951: loss: 0.4824, policy_loss: 1.8313, value_loss: 0.9773
2024-07-14 05:03:21,980 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:03:22,380 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:03:22,451 [INFO    ] __main__: train step 1952: loss: 0.4826, policy_loss: 1.8312, value_loss: 0.9773
2024-07-14 05:03:22,726 [INFO    ] __main__: train step 1953: loss: 0.4827, policy_loss: 1.8311, value_loss: 0.9773
2024-07-14 05:03:22,993 [INFO    ] __main__: train step 1954: loss: 0.4829, policy_loss: 1.8311, value_loss: 0.9773
2024-07-14 05:03:23,259 [INFO    ] __main__: train step 1955: loss: 0.4831, policy_loss: 1.8310, value_loss: 0.9772
2024-07-14 05:03:23,533 [INFO    ] __main__: train step 1956: loss: 0.4832, policy_loss: 1.8309, value_loss: 0.9772
2024-07-14 05:03:23,805 [INFO    ] __main__: train step 1957: loss: 0.4834, policy_loss: 1.8308, value_loss: 0.9772
2024-07-14 05:03:24,085 [INFO    ] __main__: train step 1958: loss: 0.4836, policy_loss: 1.8308, value_loss: 0.9772
2024-07-14 05:03:24,347 [INFO    ] __main__: train step 1959: loss: 0.4837, policy_loss: 1.8307, value_loss: 0.9772
2024-07-14 05:03:24,618 [INFO    ] __main__: train step 1960: loss: 0.4839, policy_loss: 1.8306, value_loss: 0.9772
2024-07-14 05:03:24,889 [INFO    ] __main__: train step 1961: loss: 0.4841, policy_loss: 1.8305, value_loss: 0.9772
2024-07-14 05:03:25,161 [INFO    ] __main__: train step 1962: loss: 0.4842, policy_loss: 1.8305, value_loss: 0.9772
2024-07-14 05:03:25,438 [INFO    ] __main__: train step 1963: loss: 0.4844, policy_loss: 1.8304, value_loss: 0.9771
2024-07-14 05:03:25,689 [INFO    ] __main__: train step 1964: loss: 0.4846, policy_loss: 1.8303, value_loss: 0.9771
2024-07-14 05:03:26,525 [INFO    ] __main__: train step 1965: loss: 0.4848, policy_loss: 1.8302, value_loss: 0.9771
2024-07-14 05:03:26,797 [INFO    ] __main__: train step 1966: loss: 0.4849, policy_loss: 1.8302, value_loss: 0.9771
2024-07-14 05:03:27,069 [INFO    ] __main__: train step 1967: loss: 0.4851, policy_loss: 1.8301, value_loss: 0.9771
2024-07-14 05:03:27,350 [INFO    ] __main__: train step 1968: loss: 0.4853, policy_loss: 1.8300, value_loss: 0.9771
2024-07-14 05:03:28,941 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:03:29,334 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:03:29,402 [INFO    ] __main__: train step 1969: loss: 0.4854, policy_loss: 1.8299, value_loss: 0.9771
2024-07-14 05:03:29,661 [INFO    ] __main__: train step 1970: loss: 0.4856, policy_loss: 1.8299, value_loss: 0.9770
2024-07-14 05:03:29,932 [INFO    ] __main__: train step 1971: loss: 0.4857, policy_loss: 1.8298, value_loss: 0.9770
2024-07-14 05:03:30,203 [INFO    ] __main__: train step 1972: loss: 0.4859, policy_loss: 1.8297, value_loss: 0.9770
2024-07-14 05:03:30,466 [INFO    ] __main__: train step 1973: loss: 0.4861, policy_loss: 1.8296, value_loss: 0.9770
2024-07-14 05:03:30,737 [INFO    ] __main__: train step 1974: loss: 0.4862, policy_loss: 1.8295, value_loss: 0.9770
2024-07-14 05:03:31,016 [INFO    ] __main__: train step 1975: loss: 0.4864, policy_loss: 1.8295, value_loss: 0.9770
2024-07-14 05:03:31,283 [INFO    ] __main__: train step 1976: loss: 0.4866, policy_loss: 1.8294, value_loss: 0.9770
2024-07-14 05:03:31,559 [INFO    ] __main__: train step 1977: loss: 0.4867, policy_loss: 1.8293, value_loss: 0.9770
2024-07-14 05:03:31,810 [INFO    ] __main__: train step 1978: loss: 0.4869, policy_loss: 1.8292, value_loss: 0.9770
2024-07-14 05:03:32,062 [INFO    ] __main__: train step 1979: loss: 0.4871, policy_loss: 1.8292, value_loss: 0.9769
2024-07-14 05:03:32,334 [INFO    ] __main__: train step 1980: loss: 0.4872, policy_loss: 1.8291, value_loss: 0.9769
2024-07-14 05:03:32,607 [INFO    ] __main__: train step 1981: loss: 0.4874, policy_loss: 1.8290, value_loss: 0.9769
2024-07-14 05:03:32,876 [INFO    ] __main__: train step 1982: loss: 0.4876, policy_loss: 1.8289, value_loss: 0.9769
2024-07-14 05:03:33,145 [INFO    ] __main__: train step 1983: loss: 0.4878, policy_loss: 1.8289, value_loss: 0.9769
2024-07-14 05:03:33,419 [INFO    ] __main__: train step 1984: loss: 0.4879, policy_loss: 1.8288, value_loss: 0.9769
2024-07-14 05:03:33,687 [INFO    ] __main__: train step 1985: loss: 0.4881, policy_loss: 1.8287, value_loss: 0.9769
2024-07-14 05:03:35,629 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:03:36,023 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:03:36,093 [INFO    ] __main__: train step 1986: loss: 0.4882, policy_loss: 1.8286, value_loss: 0.9768
2024-07-14 05:03:36,363 [INFO    ] __main__: train step 1987: loss: 0.4884, policy_loss: 1.8286, value_loss: 0.9768
2024-07-14 05:03:36,627 [INFO    ] __main__: train step 1988: loss: 0.4886, policy_loss: 1.8285, value_loss: 0.9768
2024-07-14 05:03:36,901 [INFO    ] __main__: train step 1989: loss: 0.4887, policy_loss: 1.8284, value_loss: 0.9768
2024-07-14 05:03:37,166 [INFO    ] __main__: train step 1990: loss: 0.4889, policy_loss: 1.8283, value_loss: 0.9767
2024-07-14 05:03:37,432 [INFO    ] __main__: train step 1991: loss: 0.4891, policy_loss: 1.8282, value_loss: 0.9767
2024-07-14 05:03:37,708 [INFO    ] __main__: train step 1992: loss: 0.4892, policy_loss: 1.8281, value_loss: 0.9767
2024-07-14 05:03:37,980 [INFO    ] __main__: train step 1993: loss: 0.4894, policy_loss: 1.8280, value_loss: 0.9767
2024-07-14 05:03:38,267 [INFO    ] __main__: train step 1994: loss: 0.4896, policy_loss: 1.8280, value_loss: 0.9767
2024-07-14 05:03:38,542 [INFO    ] __main__: train step 1995: loss: 0.4897, policy_loss: 1.8279, value_loss: 0.9767
2024-07-14 05:03:38,818 [INFO    ] __main__: train step 1996: loss: 0.4899, policy_loss: 1.8278, value_loss: 0.9767
2024-07-14 05:03:39,091 [INFO    ] __main__: train step 1997: loss: 0.4900, policy_loss: 1.8277, value_loss: 0.9766
2024-07-14 05:03:39,367 [INFO    ] __main__: train step 1998: loss: 0.4902, policy_loss: 1.8276, value_loss: 0.9766
2024-07-14 05:03:39,634 [INFO    ] __main__: train step 1999: loss: 0.4904, policy_loss: 1.8276, value_loss: 0.9766
2024-07-14 05:03:39,909 [INFO    ] __main__: train step 2000: loss: 0.4905, policy_loss: 1.8275, value_loss: 0.9766
2024-07-14 05:03:40,057 [INFO    ] __main__: restored step 1000 for evaluation
2024-07-14 05:03:45,308 [INFO    ] __main__: test network ELO difference from baseline network: +148 (+8/-8) ELO from 32000 self-played games
2024-07-14 05:03:45,311 [INFO    ] __main__: game outcomes: W: 21279, D: 23, L: 10698
2024-07-14 05:03:45,313 [INFO    ] __main__: validation_elo_delta: 148, validation_elo: 572
2024-07-14 05:03:46,017 [INFO    ] __main__: train step 2001: loss: 0.4907, policy_loss: 1.8274, value_loss: 0.9766
2024-07-14 05:03:53,097 [INFO    ] __main__: train step 2002: loss: 0.4909, policy_loss: 1.8273, value_loss: 0.9766
2024-07-14 05:03:55,008 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:03:55,485 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:03:55,555 [INFO    ] __main__: train step 2003: loss: 0.4910, policy_loss: 1.8273, value_loss: 0.9766
2024-07-14 05:03:56,163 [INFO    ] __main__: train step 2004: loss: 0.4912, policy_loss: 1.8272, value_loss: 0.9766
2024-07-14 05:03:56,423 [INFO    ] __main__: train step 2005: loss: 0.4913, policy_loss: 1.8271, value_loss: 0.9766
2024-07-14 05:03:56,682 [INFO    ] __main__: train step 2006: loss: 0.4915, policy_loss: 1.8270, value_loss: 0.9765
2024-07-14 05:03:56,949 [INFO    ] __main__: train step 2007: loss: 0.4917, policy_loss: 1.8270, value_loss: 0.9765
2024-07-14 05:03:57,223 [INFO    ] __main__: train step 2008: loss: 0.4918, policy_loss: 1.8269, value_loss: 0.9765
2024-07-14 05:03:57,491 [INFO    ] __main__: train step 2009: loss: 0.4920, policy_loss: 1.8268, value_loss: 0.9765
2024-07-14 05:03:57,755 [INFO    ] __main__: train step 2010: loss: 0.4922, policy_loss: 1.8267, value_loss: 0.9765
2024-07-14 05:03:58,029 [INFO    ] __main__: train step 2011: loss: 0.4923, policy_loss: 1.8267, value_loss: 0.9765
2024-07-14 05:03:58,295 [INFO    ] __main__: train step 2012: loss: 0.4925, policy_loss: 1.8266, value_loss: 0.9765
2024-07-14 05:03:58,564 [INFO    ] __main__: train step 2013: loss: 0.4927, policy_loss: 1.8265, value_loss: 0.9765
2024-07-14 05:03:58,831 [INFO    ] __main__: train step 2014: loss: 0.4928, policy_loss: 1.8264, value_loss: 0.9764
2024-07-14 05:03:59,090 [INFO    ] __main__: train step 2015: loss: 0.4930, policy_loss: 1.8264, value_loss: 0.9765
2024-07-14 05:03:59,371 [INFO    ] __main__: train step 2016: loss: 0.4932, policy_loss: 1.8263, value_loss: 0.9764
2024-07-14 05:03:59,632 [INFO    ] __main__: train step 2017: loss: 0.4933, policy_loss: 1.8262, value_loss: 0.9764
2024-07-14 05:03:59,895 [INFO    ] __main__: train step 2018: loss: 0.4935, policy_loss: 1.8261, value_loss: 0.9764
2024-07-14 05:04:00,157 [INFO    ] __main__: train step 2019: loss: 0.4937, policy_loss: 1.8261, value_loss: 0.9764
2024-07-14 05:04:01,752 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:04:02,227 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:04:02,294 [INFO    ] __main__: train step 2020: loss: 0.4938, policy_loss: 1.8260, value_loss: 0.9764
2024-07-14 05:04:02,552 [INFO    ] __main__: train step 2021: loss: 0.4940, policy_loss: 1.8259, value_loss: 0.9764
2024-07-14 05:04:02,819 [INFO    ] __main__: train step 2022: loss: 0.4942, policy_loss: 1.8258, value_loss: 0.9764
2024-07-14 05:04:03,698 [INFO    ] __main__: train step 2023: loss: 0.4943, policy_loss: 1.8257, value_loss: 0.9764
2024-07-14 05:04:03,963 [INFO    ] __main__: train step 2024: loss: 0.4945, policy_loss: 1.8257, value_loss: 0.9763
2024-07-14 05:04:04,232 [INFO    ] __main__: train step 2025: loss: 0.4947, policy_loss: 1.8256, value_loss: 0.9763
2024-07-14 05:04:04,504 [INFO    ] __main__: train step 2026: loss: 0.4948, policy_loss: 1.8255, value_loss: 0.9763
2024-07-14 05:04:04,773 [INFO    ] __main__: train step 2027: loss: 0.4950, policy_loss: 1.8254, value_loss: 0.9763
2024-07-14 05:04:05,039 [INFO    ] __main__: train step 2028: loss: 0.4952, policy_loss: 1.8253, value_loss: 0.9763
2024-07-14 05:04:05,305 [INFO    ] __main__: train step 2029: loss: 0.4953, policy_loss: 1.8252, value_loss: 0.9763
2024-07-14 05:04:05,580 [INFO    ] __main__: train step 2030: loss: 0.4955, policy_loss: 1.8252, value_loss: 0.9763
2024-07-14 05:04:05,842 [INFO    ] __main__: train step 2031: loss: 0.4957, policy_loss: 1.8251, value_loss: 0.9762
2024-07-14 05:04:06,115 [INFO    ] __main__: train step 2032: loss: 0.4958, policy_loss: 1.8250, value_loss: 0.9762
2024-07-14 05:04:06,390 [INFO    ] __main__: train step 2033: loss: 0.4960, policy_loss: 1.8249, value_loss: 0.9762
2024-07-14 05:04:06,652 [INFO    ] __main__: train step 2034: loss: 0.4962, policy_loss: 1.8248, value_loss: 0.9762
2024-07-14 05:04:06,923 [INFO    ] __main__: train step 2035: loss: 0.4963, policy_loss: 1.8248, value_loss: 0.9762
2024-07-14 05:04:07,211 [INFO    ] __main__: train step 2036: loss: 0.4965, policy_loss: 1.8247, value_loss: 0.9762
2024-07-14 05:04:08,824 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:04:09,330 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:04:09,400 [INFO    ] __main__: train step 2037: loss: 0.4967, policy_loss: 1.8246, value_loss: 0.9762
2024-07-14 05:04:09,694 [INFO    ] __main__: train step 2038: loss: 0.4969, policy_loss: 1.8245, value_loss: 0.9762
2024-07-14 05:04:09,973 [INFO    ] __main__: train step 2039: loss: 0.4970, policy_loss: 1.8244, value_loss: 0.9762
2024-07-14 05:04:10,269 [INFO    ] __main__: train step 2040: loss: 0.4972, policy_loss: 1.8243, value_loss: 0.9761
2024-07-14 05:04:10,527 [INFO    ] __main__: train step 2041: loss: 0.4973, policy_loss: 1.8242, value_loss: 0.9761
2024-07-14 05:04:10,805 [INFO    ] __main__: train step 2042: loss: 0.4975, policy_loss: 1.8241, value_loss: 0.9761
2024-07-14 05:04:11,617 [INFO    ] __main__: train step 2043: loss: 0.4977, policy_loss: 1.8241, value_loss: 0.9761
2024-07-14 05:04:11,918 [INFO    ] __main__: train step 2044: loss: 0.4979, policy_loss: 1.8240, value_loss: 0.9761
2024-07-14 05:04:12,210 [INFO    ] __main__: train step 2045: loss: 0.4980, policy_loss: 1.8239, value_loss: 0.9761
2024-07-14 05:04:12,495 [INFO    ] __main__: train step 2046: loss: 0.4982, policy_loss: 1.8238, value_loss: 0.9761
2024-07-14 05:04:12,780 [INFO    ] __main__: train step 2047: loss: 0.4984, policy_loss: 1.8238, value_loss: 0.9761
2024-07-14 05:04:13,071 [INFO    ] __main__: train step 2048: loss: 0.4985, policy_loss: 1.8237, value_loss: 0.9761
2024-07-14 05:04:13,349 [INFO    ] __main__: train step 2049: loss: 0.4987, policy_loss: 1.8236, value_loss: 0.9760
2024-07-14 05:04:13,619 [INFO    ] __main__: train step 2050: loss: 0.4989, policy_loss: 1.8235, value_loss: 0.9760
2024-07-14 05:04:13,908 [INFO    ] __main__: train step 2051: loss: 0.4990, policy_loss: 1.8234, value_loss: 0.9760
2024-07-14 05:04:14,185 [INFO    ] __main__: train step 2052: loss: 0.4992, policy_loss: 1.8234, value_loss: 0.9760
2024-07-14 05:04:14,478 [INFO    ] __main__: train step 2053: loss: 0.4994, policy_loss: 1.8233, value_loss: 0.9760
2024-07-14 05:04:16,104 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:04:16,634 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:04:16,709 [INFO    ] __main__: train step 2054: loss: 0.4995, policy_loss: 1.8232, value_loss: 0.9760
2024-07-14 05:04:17,000 [INFO    ] __main__: train step 2055: loss: 0.4997, policy_loss: 1.8231, value_loss: 0.9760
2024-07-14 05:04:17,296 [INFO    ] __main__: train step 2056: loss: 0.4998, policy_loss: 1.8230, value_loss: 0.9759
2024-07-14 05:04:17,583 [INFO    ] __main__: train step 2057: loss: 0.5000, policy_loss: 1.8229, value_loss: 0.9759
2024-07-14 05:04:17,874 [INFO    ] __main__: train step 2058: loss: 0.5002, policy_loss: 1.8228, value_loss: 0.9759
2024-07-14 05:04:18,165 [INFO    ] __main__: train step 2059: loss: 0.5003, policy_loss: 1.8227, value_loss: 0.9759
2024-07-14 05:04:18,467 [INFO    ] __main__: train step 2060: loss: 0.5005, policy_loss: 1.8226, value_loss: 0.9759
2024-07-14 05:04:18,747 [INFO    ] __main__: train step 2061: loss: 0.5007, policy_loss: 1.8226, value_loss: 0.9758
2024-07-14 05:04:19,043 [INFO    ] __main__: train step 2062: loss: 0.5008, policy_loss: 1.8225, value_loss: 0.9758
2024-07-14 05:04:20,355 [INFO    ] __main__: train step 2063: loss: 0.5010, policy_loss: 1.8224, value_loss: 0.9758
2024-07-14 05:04:20,653 [INFO    ] __main__: train step 2064: loss: 0.5012, policy_loss: 1.8223, value_loss: 0.9758
2024-07-14 05:04:20,958 [INFO    ] __main__: train step 2065: loss: 0.5013, policy_loss: 1.8222, value_loss: 0.9758
2024-07-14 05:04:21,257 [INFO    ] __main__: train step 2066: loss: 0.5015, policy_loss: 1.8222, value_loss: 0.9757
2024-07-14 05:04:21,544 [INFO    ] __main__: train step 2067: loss: 0.5017, policy_loss: 1.8221, value_loss: 0.9757
2024-07-14 05:04:21,834 [INFO    ] __main__: train step 2068: loss: 0.5018, policy_loss: 1.8220, value_loss: 0.9757
2024-07-14 05:04:22,134 [INFO    ] __main__: train step 2069: loss: 0.5020, policy_loss: 1.8219, value_loss: 0.9757
2024-07-14 05:04:22,431 [INFO    ] __main__: train step 2070: loss: 0.5022, policy_loss: 1.8218, value_loss: 0.9757
2024-07-14 05:04:24,053 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:04:24,557 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:04:24,633 [INFO    ] __main__: train step 2071: loss: 0.5024, policy_loss: 1.8217, value_loss: 0.9756
2024-07-14 05:04:24,923 [INFO    ] __main__: train step 2072: loss: 0.5025, policy_loss: 1.8217, value_loss: 0.9756
2024-07-14 05:04:25,204 [INFO    ] __main__: train step 2073: loss: 0.5027, policy_loss: 1.8216, value_loss: 0.9756
2024-07-14 05:04:25,493 [INFO    ] __main__: train step 2074: loss: 0.5029, policy_loss: 1.8215, value_loss: 0.9756
2024-07-14 05:04:25,780 [INFO    ] __main__: train step 2075: loss: 0.5030, policy_loss: 1.8214, value_loss: 0.9756
2024-07-14 05:04:26,064 [INFO    ] __main__: train step 2076: loss: 0.5032, policy_loss: 1.8213, value_loss: 0.9756
2024-07-14 05:04:26,327 [INFO    ] __main__: train step 2077: loss: 0.5034, policy_loss: 1.8213, value_loss: 0.9755
2024-07-14 05:04:26,583 [INFO    ] __main__: train step 2078: loss: 0.5035, policy_loss: 1.8212, value_loss: 0.9755
2024-07-14 05:04:26,879 [INFO    ] __main__: train step 2079: loss: 0.5037, policy_loss: 1.8211, value_loss: 0.9755
2024-07-14 05:04:27,159 [INFO    ] __main__: train step 2080: loss: 0.5039, policy_loss: 1.8210, value_loss: 0.9755
2024-07-14 05:04:27,451 [INFO    ] __main__: train step 2081: loss: 0.5040, policy_loss: 1.8209, value_loss: 0.9755
2024-07-14 05:04:28,402 [INFO    ] __main__: train step 2082: loss: 0.5042, policy_loss: 1.8208, value_loss: 0.9755
2024-07-14 05:04:28,676 [INFO    ] __main__: train step 2083: loss: 0.5044, policy_loss: 1.8207, value_loss: 0.9755
2024-07-14 05:04:28,961 [INFO    ] __main__: train step 2084: loss: 0.5045, policy_loss: 1.8207, value_loss: 0.9755
2024-07-14 05:04:29,230 [INFO    ] __main__: train step 2085: loss: 0.5047, policy_loss: 1.8206, value_loss: 0.9754
2024-07-14 05:04:29,502 [INFO    ] __main__: train step 2086: loss: 0.5048, policy_loss: 1.8205, value_loss: 0.9754
2024-07-14 05:04:29,778 [INFO    ] __main__: train step 2087: loss: 0.5050, policy_loss: 1.8204, value_loss: 0.9754
2024-07-14 05:04:31,368 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:04:31,846 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:04:31,912 [INFO    ] __main__: train step 2088: loss: 0.5052, policy_loss: 1.8203, value_loss: 0.9754
2024-07-14 05:04:32,174 [INFO    ] __main__: train step 2089: loss: 0.5053, policy_loss: 1.8202, value_loss: 0.9754
2024-07-14 05:04:35,804 [INFO    ] __main__: train step 2090: loss: 0.5055, policy_loss: 1.8201, value_loss: 0.9754
2024-07-14 05:04:36,087 [INFO    ] __main__: train step 2091: loss: 0.5057, policy_loss: 1.8200, value_loss: 0.9754
2024-07-14 05:04:36,359 [INFO    ] __main__: train step 2092: loss: 0.5058, policy_loss: 1.8199, value_loss: 0.9753
2024-07-14 05:04:36,629 [INFO    ] __main__: train step 2093: loss: 0.5060, policy_loss: 1.8199, value_loss: 0.9753
2024-07-14 05:04:36,907 [INFO    ] __main__: train step 2094: loss: 0.5061, policy_loss: 1.8198, value_loss: 0.9753
2024-07-14 05:04:37,186 [INFO    ] __main__: train step 2095: loss: 0.5063, policy_loss: 1.8197, value_loss: 0.9753
2024-07-14 05:04:37,462 [INFO    ] __main__: train step 2096: loss: 0.5065, policy_loss: 1.8196, value_loss: 0.9753
2024-07-14 05:04:37,745 [INFO    ] __main__: train step 2097: loss: 0.5067, policy_loss: 1.8195, value_loss: 0.9753
2024-07-14 05:04:38,022 [INFO    ] __main__: train step 2098: loss: 0.5068, policy_loss: 1.8194, value_loss: 0.9753
2024-07-14 05:04:38,299 [INFO    ] __main__: train step 2099: loss: 0.5070, policy_loss: 1.8193, value_loss: 0.9752
2024-07-14 05:04:38,577 [INFO    ] __main__: train step 2100: loss: 0.5072, policy_loss: 1.8192, value_loss: 0.9752
2024-07-14 05:04:38,863 [INFO    ] __main__: train step 2101: loss: 0.5073, policy_loss: 1.8191, value_loss: 0.9752
2024-07-14 05:04:39,795 [INFO    ] __main__: train step 2102: loss: 0.5075, policy_loss: 1.8190, value_loss: 0.9752
2024-07-14 05:04:40,073 [INFO    ] __main__: train step 2103: loss: 0.5077, policy_loss: 1.8189, value_loss: 0.9752
2024-07-14 05:04:40,343 [INFO    ] __main__: train step 2104: loss: 0.5078, policy_loss: 1.8188, value_loss: 0.9751
2024-07-14 05:04:41,937 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:04:42,420 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:04:42,485 [INFO    ] __main__: train step 2105: loss: 0.5080, policy_loss: 1.8187, value_loss: 0.9751
2024-07-14 05:04:42,761 [INFO    ] __main__: train step 2106: loss: 0.5082, policy_loss: 1.8186, value_loss: 0.9751
2024-07-14 05:04:43,023 [INFO    ] __main__: train step 2107: loss: 0.5084, policy_loss: 1.8185, value_loss: 0.9751
2024-07-14 05:04:43,296 [INFO    ] __main__: train step 2108: loss: 0.5085, policy_loss: 1.8184, value_loss: 0.9750
2024-07-14 05:04:43,562 [INFO    ] __main__: train step 2109: loss: 0.5087, policy_loss: 1.8183, value_loss: 0.9750
2024-07-14 05:04:43,830 [INFO    ] __main__: train step 2110: loss: 0.5089, policy_loss: 1.8182, value_loss: 0.9750
2024-07-14 05:04:44,104 [INFO    ] __main__: train step 2111: loss: 0.5090, policy_loss: 1.8181, value_loss: 0.9750
2024-07-14 05:04:44,388 [INFO    ] __main__: train step 2112: loss: 0.5092, policy_loss: 1.8180, value_loss: 0.9749
2024-07-14 05:04:44,663 [INFO    ] __main__: train step 2113: loss: 0.5093, policy_loss: 1.8179, value_loss: 0.9749
2024-07-14 05:04:44,945 [INFO    ] __main__: train step 2114: loss: 0.5095, policy_loss: 1.8178, value_loss: 0.9749
2024-07-14 05:04:45,213 [INFO    ] __main__: train step 2115: loss: 0.5097, policy_loss: 1.8177, value_loss: 0.9749
2024-07-14 05:04:45,490 [INFO    ] __main__: train step 2116: loss: 0.5098, policy_loss: 1.8176, value_loss: 0.9749
2024-07-14 05:04:45,769 [INFO    ] __main__: train step 2117: loss: 0.5100, policy_loss: 1.8175, value_loss: 0.9749
2024-07-14 05:04:46,048 [INFO    ] __main__: train step 2118: loss: 0.5102, policy_loss: 1.8174, value_loss: 0.9748
2024-07-14 05:04:46,321 [INFO    ] __main__: train step 2119: loss: 0.5103, policy_loss: 1.8173, value_loss: 0.9748
2024-07-14 05:04:46,610 [INFO    ] __main__: train step 2120: loss: 0.5105, policy_loss: 1.8172, value_loss: 0.9748
2024-07-14 05:04:46,886 [INFO    ] __main__: train step 2121: loss: 0.5106, policy_loss: 1.8171, value_loss: 0.9748
2024-07-14 05:04:49,132 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:04:49,620 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:04:49,692 [INFO    ] __main__: train step 2122: loss: 0.5108, policy_loss: 1.8170, value_loss: 0.9748
2024-07-14 05:04:49,951 [INFO    ] __main__: train step 2123: loss: 0.5110, policy_loss: 1.8169, value_loss: 0.9747
2024-07-14 05:04:50,207 [INFO    ] __main__: train step 2124: loss: 0.5111, policy_loss: 1.8169, value_loss: 0.9747
2024-07-14 05:04:50,478 [INFO    ] __main__: train step 2125: loss: 0.5113, policy_loss: 1.8168, value_loss: 0.9747
2024-07-14 05:04:50,759 [INFO    ] __main__: train step 2126: loss: 0.5115, policy_loss: 1.8167, value_loss: 0.9747
2024-07-14 05:04:51,034 [INFO    ] __main__: train step 2127: loss: 0.5116, policy_loss: 1.8166, value_loss: 0.9747
2024-07-14 05:04:51,293 [INFO    ] __main__: train step 2128: loss: 0.5118, policy_loss: 1.8165, value_loss: 0.9747
2024-07-14 05:04:51,566 [INFO    ] __main__: train step 2129: loss: 0.5119, policy_loss: 1.8164, value_loss: 0.9747
2024-07-14 05:04:51,857 [INFO    ] __main__: train step 2130: loss: 0.5121, policy_loss: 1.8163, value_loss: 0.9746
2024-07-14 05:04:52,132 [INFO    ] __main__: train step 2131: loss: 0.5123, policy_loss: 1.8162, value_loss: 0.9746
2024-07-14 05:04:52,407 [INFO    ] __main__: train step 2132: loss: 0.5124, policy_loss: 1.8161, value_loss: 0.9746
2024-07-14 05:04:52,675 [INFO    ] __main__: train step 2133: loss: 0.5126, policy_loss: 1.8160, value_loss: 0.9746
2024-07-14 05:04:52,939 [INFO    ] __main__: train step 2134: loss: 0.5128, policy_loss: 1.8159, value_loss: 0.9746
2024-07-14 05:04:53,178 [INFO    ] __main__: train step 2135: loss: 0.5129, policy_loss: 1.8158, value_loss: 0.9746
2024-07-14 05:04:53,434 [INFO    ] __main__: train step 2136: loss: 0.5131, policy_loss: 1.8157, value_loss: 0.9746
2024-07-14 05:04:53,708 [INFO    ] __main__: train step 2137: loss: 0.5132, policy_loss: 1.8156, value_loss: 0.9745
2024-07-14 05:04:53,979 [INFO    ] __main__: train step 2138: loss: 0.5134, policy_loss: 1.8155, value_loss: 0.9745
2024-07-14 05:04:55,570 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:04:56,046 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:04:56,116 [INFO    ] __main__: train step 2139: loss: 0.5136, policy_loss: 1.8154, value_loss: 0.9745
2024-07-14 05:04:56,405 [INFO    ] __main__: train step 2140: loss: 0.5137, policy_loss: 1.8153, value_loss: 0.9745
2024-07-14 05:04:56,677 [INFO    ] __main__: train step 2141: loss: 0.5139, policy_loss: 1.8152, value_loss: 0.9745
2024-07-14 05:04:57,602 [INFO    ] __main__: train step 2142: loss: 0.5140, policy_loss: 1.8151, value_loss: 0.9745
2024-07-14 05:04:57,879 [INFO    ] __main__: train step 2143: loss: 0.5142, policy_loss: 1.8150, value_loss: 0.9744
2024-07-14 05:04:58,166 [INFO    ] __main__: train step 2144: loss: 0.5143, policy_loss: 1.8149, value_loss: 0.9744
2024-07-14 05:04:58,447 [INFO    ] __main__: train step 2145: loss: 0.5145, policy_loss: 1.8147, value_loss: 0.9744
2024-07-14 05:04:58,735 [INFO    ] __main__: train step 2146: loss: 0.5147, policy_loss: 1.8146, value_loss: 0.9744
2024-07-14 05:04:59,016 [INFO    ] __main__: train step 2147: loss: 0.5148, policy_loss: 1.8145, value_loss: 0.9744
2024-07-14 05:04:59,294 [INFO    ] __main__: train step 2148: loss: 0.5150, policy_loss: 1.8144, value_loss: 0.9744
2024-07-14 05:04:59,574 [INFO    ] __main__: train step 2149: loss: 0.5152, policy_loss: 1.8143, value_loss: 0.9744
2024-07-14 05:04:59,854 [INFO    ] __main__: train step 2150: loss: 0.5153, policy_loss: 1.8142, value_loss: 0.9744
2024-07-14 05:05:00,123 [INFO    ] __main__: train step 2151: loss: 0.5155, policy_loss: 1.8141, value_loss: 0.9743
2024-07-14 05:05:00,395 [INFO    ] __main__: train step 2152: loss: 0.5157, policy_loss: 1.8141, value_loss: 0.9743
2024-07-14 05:05:00,659 [INFO    ] __main__: train step 2153: loss: 0.5158, policy_loss: 1.8140, value_loss: 0.9743
2024-07-14 05:05:00,939 [INFO    ] __main__: train step 2154: loss: 0.5160, policy_loss: 1.8139, value_loss: 0.9743
2024-07-14 05:05:01,222 [INFO    ] __main__: train step 2155: loss: 0.5162, policy_loss: 1.8138, value_loss: 0.9743
2024-07-14 05:05:02,827 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:05:03,300 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:05:03,365 [INFO    ] __main__: train step 2156: loss: 0.5163, policy_loss: 1.8137, value_loss: 0.9743
2024-07-14 05:05:03,633 [INFO    ] __main__: train step 2157: loss: 0.5165, policy_loss: 1.8135, value_loss: 0.9743
2024-07-14 05:05:03,904 [INFO    ] __main__: train step 2158: loss: 0.5167, policy_loss: 1.8134, value_loss: 0.9742
2024-07-14 05:05:04,181 [INFO    ] __main__: train step 2159: loss: 0.5168, policy_loss: 1.8134, value_loss: 0.9742
2024-07-14 05:05:04,461 [INFO    ] __main__: train step 2160: loss: 0.5170, policy_loss: 1.8133, value_loss: 0.9742
2024-07-14 05:05:05,350 [INFO    ] __main__: train step 2161: loss: 0.5171, policy_loss: 1.8132, value_loss: 0.9742
2024-07-14 05:05:05,624 [INFO    ] __main__: train step 2162: loss: 0.5173, policy_loss: 1.8131, value_loss: 0.9742
2024-07-14 05:05:05,912 [INFO    ] __main__: train step 2163: loss: 0.5174, policy_loss: 1.8130, value_loss: 0.9742
2024-07-14 05:05:06,195 [INFO    ] __main__: train step 2164: loss: 0.5176, policy_loss: 1.8128, value_loss: 0.9742
2024-07-14 05:05:06,469 [INFO    ] __main__: train step 2165: loss: 0.5178, policy_loss: 1.8127, value_loss: 0.9742
2024-07-14 05:05:06,746 [INFO    ] __main__: train step 2166: loss: 0.5179, policy_loss: 1.8126, value_loss: 0.9742
2024-07-14 05:05:07,023 [INFO    ] __main__: train step 2167: loss: 0.5181, policy_loss: 1.8125, value_loss: 0.9741
2024-07-14 05:05:07,319 [INFO    ] __main__: train step 2168: loss: 0.5182, policy_loss: 1.8124, value_loss: 0.9741
2024-07-14 05:05:07,607 [INFO    ] __main__: train step 2169: loss: 0.5184, policy_loss: 1.8123, value_loss: 0.9741
2024-07-14 05:05:07,880 [INFO    ] __main__: train step 2170: loss: 0.5186, policy_loss: 1.8122, value_loss: 0.9741
2024-07-14 05:05:08,156 [INFO    ] __main__: train step 2171: loss: 0.5188, policy_loss: 1.8121, value_loss: 0.9741
2024-07-14 05:05:08,429 [INFO    ] __main__: train step 2172: loss: 0.5189, policy_loss: 1.8120, value_loss: 0.9741
2024-07-14 05:05:10,018 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:05:10,499 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:05:10,571 [INFO    ] __main__: train step 2173: loss: 0.5191, policy_loss: 1.8119, value_loss: 0.9741
2024-07-14 05:05:10,846 [INFO    ] __main__: train step 2174: loss: 0.5192, policy_loss: 1.8118, value_loss: 0.9741
2024-07-14 05:05:11,130 [INFO    ] __main__: train step 2175: loss: 0.5194, policy_loss: 1.8117, value_loss: 0.9740
2024-07-14 05:05:11,398 [INFO    ] __main__: train step 2176: loss: 0.5196, policy_loss: 1.8116, value_loss: 0.9740
2024-07-14 05:05:11,685 [INFO    ] __main__: train step 2177: loss: 0.5197, policy_loss: 1.8115, value_loss: 0.9740
2024-07-14 05:05:11,952 [INFO    ] __main__: train step 2178: loss: 0.5199, policy_loss: 1.8114, value_loss: 0.9740
2024-07-14 05:05:12,222 [INFO    ] __main__: train step 2179: loss: 0.5200, policy_loss: 1.8113, value_loss: 0.9739
2024-07-14 05:05:12,503 [INFO    ] __main__: train step 2180: loss: 0.5202, policy_loss: 1.8112, value_loss: 0.9739
2024-07-14 05:05:13,133 [INFO    ] __main__: train step 2181: loss: 0.5204, policy_loss: 1.8111, value_loss: 0.9739
2024-07-14 05:05:13,398 [INFO    ] __main__: train step 2182: loss: 0.5205, policy_loss: 1.8109, value_loss: 0.9739
2024-07-14 05:05:13,674 [INFO    ] __main__: train step 2183: loss: 0.5207, policy_loss: 1.8108, value_loss: 0.9738
2024-07-14 05:05:13,946 [INFO    ] __main__: train step 2184: loss: 0.5209, policy_loss: 1.8107, value_loss: 0.9738
2024-07-14 05:05:14,219 [INFO    ] __main__: train step 2185: loss: 0.5210, policy_loss: 1.8106, value_loss: 0.9738
2024-07-14 05:05:14,492 [INFO    ] __main__: train step 2186: loss: 0.5212, policy_loss: 1.8105, value_loss: 0.9738
2024-07-14 05:05:14,775 [INFO    ] __main__: train step 2187: loss: 0.5213, policy_loss: 1.8104, value_loss: 0.9738
2024-07-14 05:05:15,055 [INFO    ] __main__: train step 2188: loss: 0.5215, policy_loss: 1.8103, value_loss: 0.9737
2024-07-14 05:05:15,345 [INFO    ] __main__: train step 2189: loss: 0.5217, policy_loss: 1.8102, value_loss: 0.9737
2024-07-14 05:05:16,937 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:05:17,427 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:05:17,495 [INFO    ] __main__: train step 2190: loss: 0.5219, policy_loss: 1.8101, value_loss: 0.9737
2024-07-14 05:05:17,779 [INFO    ] __main__: train step 2191: loss: 0.5220, policy_loss: 1.8100, value_loss: 0.9737
2024-07-14 05:05:18,058 [INFO    ] __main__: train step 2192: loss: 0.5222, policy_loss: 1.8099, value_loss: 0.9737
2024-07-14 05:05:18,337 [INFO    ] __main__: train step 2193: loss: 0.5223, policy_loss: 1.8098, value_loss: 0.9736
2024-07-14 05:05:18,607 [INFO    ] __main__: train step 2194: loss: 0.5225, policy_loss: 1.8097, value_loss: 0.9736
2024-07-14 05:05:18,884 [INFO    ] __main__: train step 2195: loss: 0.5227, policy_loss: 1.8096, value_loss: 0.9736
2024-07-14 05:05:19,155 [INFO    ] __main__: train step 2196: loss: 0.5228, policy_loss: 1.8095, value_loss: 0.9736
2024-07-14 05:05:19,419 [INFO    ] __main__: train step 2197: loss: 0.5230, policy_loss: 1.8093, value_loss: 0.9736
2024-07-14 05:05:19,688 [INFO    ] __main__: train step 2198: loss: 0.5231, policy_loss: 1.8092, value_loss: 0.9735
2024-07-14 05:05:19,957 [INFO    ] __main__: train step 2199: loss: 0.5233, policy_loss: 1.8091, value_loss: 0.9736
2024-07-14 05:05:20,228 [INFO    ] __main__: train step 2200: loss: 0.5235, policy_loss: 1.8090, value_loss: 0.9735
2024-07-14 05:05:20,850 [INFO    ] __main__: train step 2201: loss: 0.5236, policy_loss: 1.8089, value_loss: 0.9735
2024-07-14 05:05:21,120 [INFO    ] __main__: train step 2202: loss: 0.5238, policy_loss: 1.8088, value_loss: 0.9735
2024-07-14 05:05:21,396 [INFO    ] __main__: train step 2203: loss: 0.5239, policy_loss: 1.8087, value_loss: 0.9735
2024-07-14 05:05:21,671 [INFO    ] __main__: train step 2204: loss: 0.5241, policy_loss: 1.8086, value_loss: 0.9735
2024-07-14 05:05:21,952 [INFO    ] __main__: train step 2205: loss: 0.5242, policy_loss: 1.8085, value_loss: 0.9734
2024-07-14 05:05:22,227 [INFO    ] __main__: train step 2206: loss: 0.5244, policy_loss: 1.8084, value_loss: 0.9734
2024-07-14 05:05:23,810 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:05:24,296 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:05:24,364 [INFO    ] __main__: train step 2207: loss: 0.5246, policy_loss: 1.8083, value_loss: 0.9734
2024-07-14 05:05:24,635 [INFO    ] __main__: train step 2208: loss: 0.5247, policy_loss: 1.8082, value_loss: 0.9734
2024-07-14 05:05:24,909 [INFO    ] __main__: train step 2209: loss: 0.5249, policy_loss: 1.8081, value_loss: 0.9734
2024-07-14 05:05:25,187 [INFO    ] __main__: train step 2210: loss: 0.5250, policy_loss: 1.8080, value_loss: 0.9733
2024-07-14 05:05:25,460 [INFO    ] __main__: train step 2211: loss: 0.5252, policy_loss: 1.8079, value_loss: 0.9733
2024-07-14 05:05:25,739 [INFO    ] __main__: train step 2212: loss: 0.5253, policy_loss: 1.8078, value_loss: 0.9733
2024-07-14 05:05:26,010 [INFO    ] __main__: train step 2213: loss: 0.5255, policy_loss: 1.8077, value_loss: 0.9733
2024-07-14 05:05:26,288 [INFO    ] __main__: train step 2214: loss: 0.5257, policy_loss: 1.8076, value_loss: 0.9733
2024-07-14 05:05:26,572 [INFO    ] __main__: train step 2215: loss: 0.5258, policy_loss: 1.8075, value_loss: 0.9733
2024-07-14 05:05:26,845 [INFO    ] __main__: train step 2216: loss: 0.5260, policy_loss: 1.8074, value_loss: 0.9732
2024-07-14 05:05:27,110 [INFO    ] __main__: train step 2217: loss: 0.5261, policy_loss: 1.8073, value_loss: 0.9732
2024-07-14 05:05:27,384 [INFO    ] __main__: train step 2218: loss: 0.5263, policy_loss: 1.8072, value_loss: 0.9732
2024-07-14 05:05:27,658 [INFO    ] __main__: train step 2219: loss: 0.5265, policy_loss: 1.8071, value_loss: 0.9732
2024-07-14 05:05:27,941 [INFO    ] __main__: train step 2220: loss: 0.5266, policy_loss: 1.8070, value_loss: 0.9732
2024-07-14 05:05:28,799 [INFO    ] __main__: train step 2221: loss: 0.5268, policy_loss: 1.8069, value_loss: 0.9731
2024-07-14 05:05:29,076 [INFO    ] __main__: train step 2222: loss: 0.5269, policy_loss: 1.8068, value_loss: 0.9731
2024-07-14 05:05:29,348 [INFO    ] __main__: train step 2223: loss: 0.5271, policy_loss: 1.8067, value_loss: 0.9731
2024-07-14 05:05:30,956 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:05:31,428 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:05:31,500 [INFO    ] __main__: train step 2224: loss: 0.5272, policy_loss: 1.8066, value_loss: 0.9731
2024-07-14 05:05:31,778 [INFO    ] __main__: train step 2225: loss: 0.5274, policy_loss: 1.8065, value_loss: 0.9731
2024-07-14 05:05:32,048 [INFO    ] __main__: train step 2226: loss: 0.5276, policy_loss: 1.8064, value_loss: 0.9731
2024-07-14 05:05:32,325 [INFO    ] __main__: train step 2227: loss: 0.5277, policy_loss: 1.8063, value_loss: 0.9731
2024-07-14 05:05:32,601 [INFO    ] __main__: train step 2228: loss: 0.5279, policy_loss: 1.8062, value_loss: 0.9731
2024-07-14 05:05:32,872 [INFO    ] __main__: train step 2229: loss: 0.5280, policy_loss: 1.8061, value_loss: 0.9730
2024-07-14 05:05:33,158 [INFO    ] __main__: train step 2230: loss: 0.5282, policy_loss: 1.8060, value_loss: 0.9730
2024-07-14 05:05:33,426 [INFO    ] __main__: train step 2231: loss: 0.5284, policy_loss: 1.8059, value_loss: 0.9730
2024-07-14 05:05:33,698 [INFO    ] __main__: train step 2232: loss: 0.5285, policy_loss: 1.8058, value_loss: 0.9730
2024-07-14 05:05:33,968 [INFO    ] __main__: train step 2233: loss: 0.5287, policy_loss: 1.8057, value_loss: 0.9730
2024-07-14 05:05:34,248 [INFO    ] __main__: train step 2234: loss: 0.5288, policy_loss: 1.8056, value_loss: 0.9729
2024-07-14 05:05:34,516 [INFO    ] __main__: train step 2235: loss: 0.5290, policy_loss: 1.8055, value_loss: 0.9729
2024-07-14 05:05:34,792 [INFO    ] __main__: train step 2236: loss: 0.5292, policy_loss: 1.8054, value_loss: 0.9729
2024-07-14 05:05:35,080 [INFO    ] __main__: train step 2237: loss: 0.5293, policy_loss: 1.8053, value_loss: 0.9729
2024-07-14 05:05:35,347 [INFO    ] __main__: train step 2238: loss: 0.5295, policy_loss: 1.8052, value_loss: 0.9729
2024-07-14 05:05:35,616 [INFO    ] __main__: train step 2239: loss: 0.5297, policy_loss: 1.8051, value_loss: 0.9729
2024-07-14 05:05:35,890 [INFO    ] __main__: train step 2240: loss: 0.5298, policy_loss: 1.8050, value_loss: 0.9729
2024-07-14 05:05:37,995 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:05:38,470 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:05:38,540 [INFO    ] __main__: train step 2241: loss: 0.5300, policy_loss: 1.8049, value_loss: 0.9728
2024-07-14 05:05:38,820 [INFO    ] __main__: train step 2242: loss: 0.5302, policy_loss: 1.8048, value_loss: 0.9728
2024-07-14 05:05:39,091 [INFO    ] __main__: train step 2243: loss: 0.5303, policy_loss: 1.8047, value_loss: 0.9728
2024-07-14 05:05:39,368 [INFO    ] __main__: train step 2244: loss: 0.5305, policy_loss: 1.8046, value_loss: 0.9728
2024-07-14 05:05:39,637 [INFO    ] __main__: train step 2245: loss: 0.5306, policy_loss: 1.8045, value_loss: 0.9728
2024-07-14 05:05:39,906 [INFO    ] __main__: train step 2246: loss: 0.5308, policy_loss: 1.8044, value_loss: 0.9727
2024-07-14 05:05:40,187 [INFO    ] __main__: train step 2247: loss: 0.5309, policy_loss: 1.8043, value_loss: 0.9727
2024-07-14 05:05:40,469 [INFO    ] __main__: train step 2248: loss: 0.5311, policy_loss: 1.8041, value_loss: 0.9727
2024-07-14 05:05:40,737 [INFO    ] __main__: train step 2249: loss: 0.5313, policy_loss: 1.8040, value_loss: 0.9727
2024-07-14 05:05:41,010 [INFO    ] __main__: train step 2250: loss: 0.5314, policy_loss: 1.8039, value_loss: 0.9727
2024-07-14 05:05:41,295 [INFO    ] __main__: train step 2251: loss: 0.5316, policy_loss: 1.8038, value_loss: 0.9727
2024-07-14 05:05:41,575 [INFO    ] __main__: train step 2252: loss: 0.5318, policy_loss: 1.8037, value_loss: 0.9727
2024-07-14 05:05:41,853 [INFO    ] __main__: train step 2253: loss: 0.5319, policy_loss: 1.8036, value_loss: 0.9727
2024-07-14 05:05:42,128 [INFO    ] __main__: train step 2254: loss: 0.5321, policy_loss: 1.8035, value_loss: 0.9726
2024-07-14 05:05:42,409 [INFO    ] __main__: train step 2255: loss: 0.5322, policy_loss: 1.8034, value_loss: 0.9726
2024-07-14 05:05:42,668 [INFO    ] __main__: train step 2256: loss: 0.5324, policy_loss: 1.8033, value_loss: 0.9726
2024-07-14 05:05:42,940 [INFO    ] __main__: train step 2257: loss: 0.5326, policy_loss: 1.8032, value_loss: 0.9726
2024-07-14 05:05:44,548 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:05:44,967 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:05:45,035 [INFO    ] __main__: train step 2258: loss: 0.5327, policy_loss: 1.8031, value_loss: 0.9726
2024-07-14 05:05:45,320 [INFO    ] __main__: train step 2259: loss: 0.5329, policy_loss: 1.8029, value_loss: 0.9726
2024-07-14 05:05:45,591 [INFO    ] __main__: train step 2260: loss: 0.5330, policy_loss: 1.8028, value_loss: 0.9726
2024-07-14 05:05:46,514 [INFO    ] __main__: train step 2261: loss: 0.5332, policy_loss: 1.8027, value_loss: 0.9725
2024-07-14 05:05:46,792 [INFO    ] __main__: train step 2262: loss: 0.5333, policy_loss: 1.8026, value_loss: 0.9725
2024-07-14 05:05:47,060 [INFO    ] __main__: train step 2263: loss: 0.5335, policy_loss: 1.8025, value_loss: 0.9725
2024-07-14 05:05:47,331 [INFO    ] __main__: train step 2264: loss: 0.5337, policy_loss: 1.8024, value_loss: 0.9725
2024-07-14 05:05:47,607 [INFO    ] __main__: train step 2265: loss: 0.5338, policy_loss: 1.8023, value_loss: 0.9724
2024-07-14 05:05:47,879 [INFO    ] __main__: train step 2266: loss: 0.5340, policy_loss: 1.8022, value_loss: 0.9724
2024-07-14 05:05:48,161 [INFO    ] __main__: train step 2267: loss: 0.5341, policy_loss: 1.8021, value_loss: 0.9724
2024-07-14 05:05:48,439 [INFO    ] __main__: train step 2268: loss: 0.5343, policy_loss: 1.8020, value_loss: 0.9724
2024-07-14 05:05:48,711 [INFO    ] __main__: train step 2269: loss: 0.5345, policy_loss: 1.8018, value_loss: 0.9724
2024-07-14 05:05:48,999 [INFO    ] __main__: train step 2270: loss: 0.5346, policy_loss: 1.8017, value_loss: 0.9723
2024-07-14 05:05:49,269 [INFO    ] __main__: train step 2271: loss: 0.5348, policy_loss: 1.8016, value_loss: 0.9723
2024-07-14 05:05:49,541 [INFO    ] __main__: train step 2272: loss: 0.5349, policy_loss: 1.8015, value_loss: 0.9723
2024-07-14 05:05:49,831 [INFO    ] __main__: train step 2273: loss: 0.5351, policy_loss: 1.8014, value_loss: 0.9723
2024-07-14 05:05:50,126 [INFO    ] __main__: train step 2274: loss: 0.5353, policy_loss: 1.8013, value_loss: 0.9723
2024-07-14 05:05:51,745 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:05:52,243 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:05:52,315 [INFO    ] __main__: train step 2275: loss: 0.5354, policy_loss: 1.8012, value_loss: 0.9722
2024-07-14 05:05:52,591 [INFO    ] __main__: train step 2276: loss: 0.5356, policy_loss: 1.8011, value_loss: 0.9722
2024-07-14 05:05:52,878 [INFO    ] __main__: train step 2277: loss: 0.5358, policy_loss: 1.8009, value_loss: 0.9722
2024-07-14 05:05:53,154 [INFO    ] __main__: train step 2278: loss: 0.5359, policy_loss: 1.8008, value_loss: 0.9722
2024-07-14 05:05:53,419 [INFO    ] __main__: train step 2279: loss: 0.5361, policy_loss: 1.8007, value_loss: 0.9722
2024-07-14 05:05:54,286 [INFO    ] __main__: train step 2280: loss: 0.5362, policy_loss: 1.8006, value_loss: 0.9721
2024-07-14 05:05:54,561 [INFO    ] __main__: train step 2281: loss: 0.5364, policy_loss: 1.8005, value_loss: 0.9721
2024-07-14 05:05:54,844 [INFO    ] __main__: train step 2282: loss: 0.5366, policy_loss: 1.8004, value_loss: 0.9721
2024-07-14 05:05:55,120 [INFO    ] __main__: train step 2283: loss: 0.5367, policy_loss: 1.8003, value_loss: 0.9721
2024-07-14 05:05:55,397 [INFO    ] __main__: train step 2284: loss: 0.5369, policy_loss: 1.8002, value_loss: 0.9721
2024-07-14 05:05:55,693 [INFO    ] __main__: train step 2285: loss: 0.5371, policy_loss: 1.8001, value_loss: 0.9721
2024-07-14 05:05:55,965 [INFO    ] __main__: train step 2286: loss: 0.5372, policy_loss: 1.8000, value_loss: 0.9721
2024-07-14 05:05:56,243 [INFO    ] __main__: train step 2287: loss: 0.5374, policy_loss: 1.7999, value_loss: 0.9720
2024-07-14 05:05:56,522 [INFO    ] __main__: train step 2288: loss: 0.5375, policy_loss: 1.7997, value_loss: 0.9720
2024-07-14 05:05:56,797 [INFO    ] __main__: train step 2289: loss: 0.5377, policy_loss: 1.7996, value_loss: 0.9720
2024-07-14 05:05:57,077 [INFO    ] __main__: train step 2290: loss: 0.5379, policy_loss: 1.7995, value_loss: 0.9720
2024-07-14 05:05:57,347 [INFO    ] __main__: train step 2291: loss: 0.5380, policy_loss: 1.7994, value_loss: 0.9720
2024-07-14 05:05:58,947 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:05:59,428 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:05:59,492 [INFO    ] __main__: train step 2292: loss: 0.5382, policy_loss: 1.7993, value_loss: 0.9720
2024-07-14 05:05:59,769 [INFO    ] __main__: train step 2293: loss: 0.5383, policy_loss: 1.7992, value_loss: 0.9719
2024-07-14 05:06:00,045 [INFO    ] __main__: train step 2294: loss: 0.5385, policy_loss: 1.7991, value_loss: 0.9719
2024-07-14 05:06:00,324 [INFO    ] __main__: train step 2295: loss: 0.5387, policy_loss: 1.7990, value_loss: 0.9719
2024-07-14 05:06:00,596 [INFO    ] __main__: train step 2296: loss: 0.5388, policy_loss: 1.7989, value_loss: 0.9719
2024-07-14 05:06:00,863 [INFO    ] __main__: train step 2297: loss: 0.5390, policy_loss: 1.7988, value_loss: 0.9718
2024-07-14 05:06:01,135 [INFO    ] __main__: train step 2298: loss: 0.5391, policy_loss: 1.7987, value_loss: 0.9718
2024-07-14 05:06:01,408 [INFO    ] __main__: train step 2299: loss: 0.5393, policy_loss: 1.7985, value_loss: 0.9718
2024-07-14 05:06:02,297 [INFO    ] __main__: train step 2300: loss: 0.5395, policy_loss: 1.7984, value_loss: 0.9718
2024-07-14 05:06:02,570 [INFO    ] __main__: train step 2301: loss: 0.5396, policy_loss: 1.7983, value_loss: 0.9718
2024-07-14 05:06:02,852 [INFO    ] __main__: train step 2302: loss: 0.5398, policy_loss: 1.7982, value_loss: 0.9717
2024-07-14 05:06:03,128 [INFO    ] __main__: train step 2303: loss: 0.5399, policy_loss: 1.7981, value_loss: 0.9717
2024-07-14 05:06:03,403 [INFO    ] __main__: train step 2304: loss: 0.5401, policy_loss: 1.7980, value_loss: 0.9717
2024-07-14 05:06:03,680 [INFO    ] __main__: train step 2305: loss: 0.5402, policy_loss: 1.7978, value_loss: 0.9717
2024-07-14 05:06:03,951 [INFO    ] __main__: train step 2306: loss: 0.5404, policy_loss: 1.7977, value_loss: 0.9717
2024-07-14 05:06:04,227 [INFO    ] __main__: train step 2307: loss: 0.5406, policy_loss: 1.7976, value_loss: 0.9717
2024-07-14 05:06:04,499 [INFO    ] __main__: train step 2308: loss: 0.5407, policy_loss: 1.7975, value_loss: 0.9717
2024-07-14 05:06:06,098 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:06:06,582 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:06:06,649 [INFO    ] __main__: train step 2309: loss: 0.5409, policy_loss: 1.7974, value_loss: 0.9716
2024-07-14 05:06:06,923 [INFO    ] __main__: train step 2310: loss: 0.5411, policy_loss: 1.7973, value_loss: 0.9716
2024-07-14 05:06:07,208 [INFO    ] __main__: train step 2311: loss: 0.5412, policy_loss: 1.7972, value_loss: 0.9716
2024-07-14 05:06:07,486 [INFO    ] __main__: train step 2312: loss: 0.5414, policy_loss: 1.7971, value_loss: 0.9716
2024-07-14 05:06:07,774 [INFO    ] __main__: train step 2313: loss: 0.5415, policy_loss: 1.7970, value_loss: 0.9715
2024-07-14 05:06:08,049 [INFO    ] __main__: train step 2314: loss: 0.5417, policy_loss: 1.7968, value_loss: 0.9715
2024-07-14 05:06:08,330 [INFO    ] __main__: train step 2315: loss: 0.5419, policy_loss: 1.7967, value_loss: 0.9715
2024-07-14 05:06:08,608 [INFO    ] __main__: train step 2316: loss: 0.5420, policy_loss: 1.7966, value_loss: 0.9715
2024-07-14 05:06:08,891 [INFO    ] __main__: train step 2317: loss: 0.5422, policy_loss: 1.7965, value_loss: 0.9715
2024-07-14 05:06:09,170 [INFO    ] __main__: train step 2318: loss: 0.5423, policy_loss: 1.7964, value_loss: 0.9714
2024-07-14 05:06:09,445 [INFO    ] __main__: train step 2319: loss: 0.5425, policy_loss: 1.7963, value_loss: 0.9714
2024-07-14 05:06:10,069 [INFO    ] __main__: train step 2320: loss: 0.5426, policy_loss: 1.7962, value_loss: 0.9714
2024-07-14 05:06:10,357 [INFO    ] __main__: train step 2321: loss: 0.5428, policy_loss: 1.7961, value_loss: 0.9714
2024-07-14 05:06:10,634 [INFO    ] __main__: train step 2322: loss: 0.5429, policy_loss: 1.7960, value_loss: 0.9714
2024-07-14 05:06:10,918 [INFO    ] __main__: train step 2323: loss: 0.5431, policy_loss: 1.7959, value_loss: 0.9713
2024-07-14 05:06:11,199 [INFO    ] __main__: train step 2324: loss: 0.5433, policy_loss: 1.7957, value_loss: 0.9713
2024-07-14 05:06:11,475 [INFO    ] __main__: train step 2325: loss: 0.5434, policy_loss: 1.7956, value_loss: 0.9713
2024-07-14 05:06:13,086 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:06:13,583 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:06:13,652 [INFO    ] __main__: train step 2326: loss: 0.5436, policy_loss: 1.7955, value_loss: 0.9713
2024-07-14 05:06:13,933 [INFO    ] __main__: train step 2327: loss: 0.5437, policy_loss: 1.7954, value_loss: 0.9713
2024-07-14 05:06:14,206 [INFO    ] __main__: train step 2328: loss: 0.5439, policy_loss: 1.7953, value_loss: 0.9713
2024-07-14 05:06:14,471 [INFO    ] __main__: train step 2329: loss: 0.5441, policy_loss: 1.7952, value_loss: 0.9713
2024-07-14 05:06:14,743 [INFO    ] __main__: train step 2330: loss: 0.5442, policy_loss: 1.7951, value_loss: 0.9713
2024-07-14 05:06:15,022 [INFO    ] __main__: train step 2331: loss: 0.5444, policy_loss: 1.7950, value_loss: 0.9712
2024-07-14 05:06:15,305 [INFO    ] __main__: train step 2332: loss: 0.5446, policy_loss: 1.7948, value_loss: 0.9712
2024-07-14 05:06:15,592 [INFO    ] __main__: train step 2333: loss: 0.5447, policy_loss: 1.7947, value_loss: 0.9712
2024-07-14 05:06:15,865 [INFO    ] __main__: train step 2334: loss: 0.5449, policy_loss: 1.7946, value_loss: 0.9712
2024-07-14 05:06:16,145 [INFO    ] __main__: train step 2335: loss: 0.5450, policy_loss: 1.7945, value_loss: 0.9712
2024-07-14 05:06:16,423 [INFO    ] __main__: train step 2336: loss: 0.5452, policy_loss: 1.7944, value_loss: 0.9712
2024-07-14 05:06:16,705 [INFO    ] __main__: train step 2337: loss: 0.5453, policy_loss: 1.7943, value_loss: 0.9711
2024-07-14 05:06:16,980 [INFO    ] __main__: train step 2338: loss: 0.5455, policy_loss: 1.7942, value_loss: 0.9711
2024-07-14 05:06:17,608 [INFO    ] __main__: train step 2339: loss: 0.5457, policy_loss: 1.7941, value_loss: 0.9711
2024-07-14 05:06:17,881 [INFO    ] __main__: train step 2340: loss: 0.5458, policy_loss: 1.7940, value_loss: 0.9711
2024-07-14 05:06:18,154 [INFO    ] __main__: train step 2341: loss: 0.5460, policy_loss: 1.7939, value_loss: 0.9711
2024-07-14 05:06:18,446 [INFO    ] __main__: train step 2342: loss: 0.5461, policy_loss: 1.7937, value_loss: 0.9711
2024-07-14 05:06:20,044 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:06:20,534 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:06:20,605 [INFO    ] __main__: train step 2343: loss: 0.5463, policy_loss: 1.7936, value_loss: 0.9711
2024-07-14 05:06:20,888 [INFO    ] __main__: train step 2344: loss: 0.5465, policy_loss: 1.7935, value_loss: 0.9710
2024-07-14 05:06:21,168 [INFO    ] __main__: train step 2345: loss: 0.5466, policy_loss: 1.7934, value_loss: 0.9710
2024-07-14 05:06:21,442 [INFO    ] __main__: train step 2346: loss: 0.5468, policy_loss: 1.7933, value_loss: 0.9710
2024-07-14 05:06:21,708 [INFO    ] __main__: train step 2347: loss: 0.5469, policy_loss: 1.7932, value_loss: 0.9710
2024-07-14 05:06:21,996 [INFO    ] __main__: train step 2348: loss: 0.5471, policy_loss: 1.7931, value_loss: 0.9710
2024-07-14 05:06:22,258 [INFO    ] __main__: train step 2349: loss: 0.5472, policy_loss: 1.7929, value_loss: 0.9710
2024-07-14 05:06:22,539 [INFO    ] __main__: train step 2350: loss: 0.5474, policy_loss: 1.7928, value_loss: 0.9709
2024-07-14 05:06:22,815 [INFO    ] __main__: train step 2351: loss: 0.5476, policy_loss: 1.7927, value_loss: 0.9709
2024-07-14 05:06:23,092 [INFO    ] __main__: train step 2352: loss: 0.5477, policy_loss: 1.7926, value_loss: 0.9709
2024-07-14 05:06:23,373 [INFO    ] __main__: train step 2353: loss: 0.5479, policy_loss: 1.7925, value_loss: 0.9709
2024-07-14 05:06:23,654 [INFO    ] __main__: train step 2354: loss: 0.5481, policy_loss: 1.7924, value_loss: 0.9709
2024-07-14 05:06:23,932 [INFO    ] __main__: train step 2355: loss: 0.5482, policy_loss: 1.7923, value_loss: 0.9709
2024-07-14 05:06:24,200 [INFO    ] __main__: train step 2356: loss: 0.5484, policy_loss: 1.7921, value_loss: 0.9708
2024-07-14 05:06:24,476 [INFO    ] __main__: train step 2357: loss: 0.5485, policy_loss: 1.7920, value_loss: 0.9708
2024-07-14 05:06:25,361 [INFO    ] __main__: train step 2358: loss: 0.5487, policy_loss: 1.7919, value_loss: 0.9708
2024-07-14 05:06:25,629 [INFO    ] __main__: train step 2359: loss: 0.5488, policy_loss: 1.7918, value_loss: 0.9708
2024-07-14 05:06:27,255 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:06:27,736 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:06:27,806 [INFO    ] __main__: train step 2360: loss: 0.5490, policy_loss: 1.7917, value_loss: 0.9708
2024-07-14 05:06:28,080 [INFO    ] __main__: train step 2361: loss: 0.5492, policy_loss: 1.7916, value_loss: 0.9708
2024-07-14 05:06:28,366 [INFO    ] __main__: train step 2362: loss: 0.5493, policy_loss: 1.7915, value_loss: 0.9708
2024-07-14 05:06:28,638 [INFO    ] __main__: train step 2363: loss: 0.5495, policy_loss: 1.7914, value_loss: 0.9707
2024-07-14 05:06:28,917 [INFO    ] __main__: train step 2364: loss: 0.5496, policy_loss: 1.7912, value_loss: 0.9707
2024-07-14 05:06:29,202 [INFO    ] __main__: train step 2365: loss: 0.5498, policy_loss: 1.7911, value_loss: 0.9707
2024-07-14 05:06:29,503 [INFO    ] __main__: train step 2366: loss: 0.5499, policy_loss: 1.7910, value_loss: 0.9707
2024-07-14 05:06:29,783 [INFO    ] __main__: train step 2367: loss: 0.5501, policy_loss: 1.7909, value_loss: 0.9707
2024-07-14 05:06:30,068 [INFO    ] __main__: train step 2368: loss: 0.5503, policy_loss: 1.7908, value_loss: 0.9706
2024-07-14 05:06:30,349 [INFO    ] __main__: train step 2369: loss: 0.5504, policy_loss: 1.7907, value_loss: 0.9706
2024-07-14 05:06:30,638 [INFO    ] __main__: train step 2370: loss: 0.5506, policy_loss: 1.7906, value_loss: 0.9706
2024-07-14 05:06:30,957 [INFO    ] __main__: train step 2371: loss: 0.5507, policy_loss: 1.7904, value_loss: 0.9706
2024-07-14 05:06:31,242 [INFO    ] __main__: train step 2372: loss: 0.5509, policy_loss: 1.7903, value_loss: 0.9706
2024-07-14 05:06:31,525 [INFO    ] __main__: train step 2373: loss: 0.5511, policy_loss: 1.7902, value_loss: 0.9706
2024-07-14 05:06:31,811 [INFO    ] __main__: train step 2374: loss: 0.5513, policy_loss: 1.7901, value_loss: 0.9705
2024-07-14 05:06:32,086 [INFO    ] __main__: train step 2375: loss: 0.5514, policy_loss: 1.7900, value_loss: 0.9705
2024-07-14 05:06:32,357 [INFO    ] __main__: train step 2376: loss: 0.5516, policy_loss: 1.7899, value_loss: 0.9705
2024-07-14 05:06:33,950 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:06:34,426 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:06:34,498 [INFO    ] __main__: train step 2377: loss: 0.5517, policy_loss: 1.7898, value_loss: 0.9704
2024-07-14 05:06:35,358 [INFO    ] __main__: train step 2378: loss: 0.5519, policy_loss: 1.7896, value_loss: 0.9704
2024-07-14 05:06:35,642 [INFO    ] __main__: train step 2379: loss: 0.5521, policy_loss: 1.7895, value_loss: 0.9704
2024-07-14 05:06:35,913 [INFO    ] __main__: train step 2380: loss: 0.5522, policy_loss: 1.7894, value_loss: 0.9704
2024-07-14 05:06:36,190 [INFO    ] __main__: train step 2381: loss: 0.5524, policy_loss: 1.7893, value_loss: 0.9704
2024-07-14 05:06:36,512 [INFO    ] __main__: train step 2382: loss: 0.5525, policy_loss: 1.7892, value_loss: 0.9703
2024-07-14 05:06:36,786 [INFO    ] __main__: train step 2383: loss: 0.5527, policy_loss: 1.7890, value_loss: 0.9703
2024-07-14 05:06:37,060 [INFO    ] __main__: train step 2384: loss: 0.5529, policy_loss: 1.7889, value_loss: 0.9703
2024-07-14 05:06:37,331 [INFO    ] __main__: train step 2385: loss: 0.5530, policy_loss: 1.7888, value_loss: 0.9703
2024-07-14 05:06:37,606 [INFO    ] __main__: train step 2386: loss: 0.5532, policy_loss: 1.7887, value_loss: 0.9703
2024-07-14 05:06:37,886 [INFO    ] __main__: train step 2387: loss: 0.5534, policy_loss: 1.7886, value_loss: 0.9703
2024-07-14 05:06:38,151 [INFO    ] __main__: train step 2388: loss: 0.5535, policy_loss: 1.7885, value_loss: 0.9702
2024-07-14 05:06:38,414 [INFO    ] __main__: train step 2389: loss: 0.5537, policy_loss: 1.7884, value_loss: 0.9702
2024-07-14 05:06:38,692 [INFO    ] __main__: train step 2390: loss: 0.5538, policy_loss: 1.7883, value_loss: 0.9702
2024-07-14 05:06:38,962 [INFO    ] __main__: train step 2391: loss: 0.5540, policy_loss: 1.7881, value_loss: 0.9702
2024-07-14 05:06:39,214 [INFO    ] __main__: train step 2392: loss: 0.5542, policy_loss: 1.7880, value_loss: 0.9702
2024-07-14 05:06:39,468 [INFO    ] __main__: train step 2393: loss: 0.5543, policy_loss: 1.7879, value_loss: 0.9701
2024-07-14 05:06:41,060 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:06:41,532 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:06:41,600 [INFO    ] __main__: train step 2394: loss: 0.5545, policy_loss: 1.7878, value_loss: 0.9701
2024-07-14 05:06:41,867 [INFO    ] __main__: train step 2395: loss: 0.5546, policy_loss: 1.7877, value_loss: 0.9701
2024-07-14 05:06:42,147 [INFO    ] __main__: train step 2396: loss: 0.5548, policy_loss: 1.7876, value_loss: 0.9701
2024-07-14 05:06:43,022 [INFO    ] __main__: train step 2397: loss: 0.5550, policy_loss: 1.7874, value_loss: 0.9701
2024-07-14 05:06:43,294 [INFO    ] __main__: train step 2398: loss: 0.5551, policy_loss: 1.7873, value_loss: 0.9700
2024-07-14 05:06:43,575 [INFO    ] __main__: train step 2399: loss: 0.5553, policy_loss: 1.7872, value_loss: 0.9700
2024-07-14 05:06:43,852 [INFO    ] __main__: train step 2400: loss: 0.5554, policy_loss: 1.7871, value_loss: 0.9700
2024-07-14 05:06:44,124 [INFO    ] __main__: train step 2401: loss: 0.5556, policy_loss: 1.7870, value_loss: 0.9700
2024-07-14 05:06:44,393 [INFO    ] __main__: train step 2402: loss: 0.5558, policy_loss: 1.7869, value_loss: 0.9700
2024-07-14 05:06:44,673 [INFO    ] __main__: train step 2403: loss: 0.5559, policy_loss: 1.7867, value_loss: 0.9700
2024-07-14 05:06:44,970 [INFO    ] __main__: train step 2404: loss: 0.5561, policy_loss: 1.7866, value_loss: 0.9699
2024-07-14 05:06:45,233 [INFO    ] __main__: train step 2405: loss: 0.5562, policy_loss: 1.7865, value_loss: 0.9699
2024-07-14 05:06:45,506 [INFO    ] __main__: train step 2406: loss: 0.5564, policy_loss: 1.7864, value_loss: 0.9699
2024-07-14 05:06:45,778 [INFO    ] __main__: train step 2407: loss: 0.5566, policy_loss: 1.7863, value_loss: 0.9699
2024-07-14 05:06:46,066 [INFO    ] __main__: train step 2408: loss: 0.5567, policy_loss: 1.7862, value_loss: 0.9699
2024-07-14 05:06:46,349 [INFO    ] __main__: train step 2409: loss: 0.5569, policy_loss: 1.7860, value_loss: 0.9699
2024-07-14 05:06:46,608 [INFO    ] __main__: train step 2410: loss: 0.5571, policy_loss: 1.7859, value_loss: 0.9698
2024-07-14 05:06:48,187 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:06:48,667 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:06:48,732 [INFO    ] __main__: train step 2411: loss: 0.5572, policy_loss: 1.7858, value_loss: 0.9698
2024-07-14 05:06:48,997 [INFO    ] __main__: train step 2412: loss: 0.5574, policy_loss: 1.7857, value_loss: 0.9698
2024-07-14 05:06:49,273 [INFO    ] __main__: train step 2413: loss: 0.5576, policy_loss: 1.7856, value_loss: 0.9698
2024-07-14 05:06:49,542 [INFO    ] __main__: train step 2414: loss: 0.5577, policy_loss: 1.7854, value_loss: 0.9697
2024-07-14 05:06:49,842 [INFO    ] __main__: train step 2415: loss: 0.5579, policy_loss: 1.7853, value_loss: 0.9697
2024-07-14 05:06:50,623 [INFO    ] __main__: train step 2416: loss: 0.5580, policy_loss: 1.7852, value_loss: 0.9697
2024-07-14 05:06:50,919 [INFO    ] __main__: train step 2417: loss: 0.5582, policy_loss: 1.7851, value_loss: 0.9697
2024-07-14 05:06:51,212 [INFO    ] __main__: train step 2418: loss: 0.5583, policy_loss: 1.7850, value_loss: 0.9696
2024-07-14 05:06:51,495 [INFO    ] __main__: train step 2419: loss: 0.5585, policy_loss: 1.7848, value_loss: 0.9696
2024-07-14 05:06:51,790 [INFO    ] __main__: train step 2420: loss: 0.5586, policy_loss: 1.7847, value_loss: 0.9696
2024-07-14 05:06:52,083 [INFO    ] __main__: train step 2421: loss: 0.5588, policy_loss: 1.7846, value_loss: 0.9696
2024-07-14 05:06:52,386 [INFO    ] __main__: train step 2422: loss: 0.5590, policy_loss: 1.7845, value_loss: 0.9696
2024-07-14 05:06:52,709 [INFO    ] __main__: train step 2423: loss: 0.5591, policy_loss: 1.7844, value_loss: 0.9696
2024-07-14 05:06:53,012 [INFO    ] __main__: train step 2424: loss: 0.5593, policy_loss: 1.7842, value_loss: 0.9696
2024-07-14 05:06:53,312 [INFO    ] __main__: train step 2425: loss: 0.5594, policy_loss: 1.7841, value_loss: 0.9695
2024-07-14 05:06:53,605 [INFO    ] __main__: train step 2426: loss: 0.5596, policy_loss: 1.7840, value_loss: 0.9695
2024-07-14 05:06:53,883 [INFO    ] __main__: train step 2427: loss: 0.5598, policy_loss: 1.7839, value_loss: 0.9695
2024-07-14 05:06:55,481 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:06:55,967 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:06:56,035 [INFO    ] __main__: train step 2428: loss: 0.5599, policy_loss: 1.7838, value_loss: 0.9695
2024-07-14 05:06:56,308 [INFO    ] __main__: train step 2429: loss: 0.5601, policy_loss: 1.7837, value_loss: 0.9695
2024-07-14 05:06:56,582 [INFO    ] __main__: train step 2430: loss: 0.5602, policy_loss: 1.7836, value_loss: 0.9695
2024-07-14 05:06:56,859 [INFO    ] __main__: train step 2431: loss: 0.5604, policy_loss: 1.7834, value_loss: 0.9694
2024-07-14 05:06:57,134 [INFO    ] __main__: train step 2432: loss: 0.5605, policy_loss: 1.7833, value_loss: 0.9694
2024-07-14 05:06:57,411 [INFO    ] __main__: train step 2433: loss: 0.5607, policy_loss: 1.7832, value_loss: 0.9694
2024-07-14 05:06:57,694 [INFO    ] __main__: train step 2434: loss: 0.5609, policy_loss: 1.7831, value_loss: 0.9694
2024-07-14 05:06:58,350 [INFO    ] __main__: train step 2435: loss: 0.5610, policy_loss: 1.7830, value_loss: 0.9694
2024-07-14 05:06:58,636 [INFO    ] __main__: train step 2436: loss: 0.5612, policy_loss: 1.7829, value_loss: 0.9693
2024-07-14 05:06:58,925 [INFO    ] __main__: train step 2437: loss: 0.5613, policy_loss: 1.7828, value_loss: 0.9693
2024-07-14 05:06:59,200 [INFO    ] __main__: train step 2438: loss: 0.5615, policy_loss: 1.7827, value_loss: 0.9693
2024-07-14 05:06:59,473 [INFO    ] __main__: train step 2439: loss: 0.5616, policy_loss: 1.7826, value_loss: 0.9693
2024-07-14 05:06:59,754 [INFO    ] __main__: train step 2440: loss: 0.5618, policy_loss: 1.7825, value_loss: 0.9693
2024-07-14 05:07:00,036 [INFO    ] __main__: train step 2441: loss: 0.5619, policy_loss: 1.7824, value_loss: 0.9693
2024-07-14 05:07:00,306 [INFO    ] __main__: train step 2442: loss: 0.5621, policy_loss: 1.7823, value_loss: 0.9692
2024-07-14 05:07:00,574 [INFO    ] __main__: train step 2443: loss: 0.5623, policy_loss: 1.7821, value_loss: 0.9692
2024-07-14 05:07:00,844 [INFO    ] __main__: train step 2444: loss: 0.5624, policy_loss: 1.7820, value_loss: 0.9692
2024-07-14 05:07:02,429 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:07:02,908 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:07:02,976 [INFO    ] __main__: train step 2445: loss: 0.5626, policy_loss: 1.7819, value_loss: 0.9692
2024-07-14 05:07:03,238 [INFO    ] __main__: train step 2446: loss: 0.5627, policy_loss: 1.7818, value_loss: 0.9692
2024-07-14 05:07:03,500 [INFO    ] __main__: train step 2447: loss: 0.5629, policy_loss: 1.7816, value_loss: 0.9692
2024-07-14 05:07:03,766 [INFO    ] __main__: train step 2448: loss: 0.5631, policy_loss: 1.7815, value_loss: 0.9692
2024-07-14 05:07:04,038 [INFO    ] __main__: train step 2449: loss: 0.5632, policy_loss: 1.7814, value_loss: 0.9691
2024-07-14 05:07:04,311 [INFO    ] __main__: train step 2450: loss: 0.5634, policy_loss: 1.7813, value_loss: 0.9691
2024-07-14 05:07:04,580 [INFO    ] __main__: train step 2451: loss: 0.5635, policy_loss: 1.7811, value_loss: 0.9691
2024-07-14 05:07:04,861 [INFO    ] __main__: train step 2452: loss: 0.5637, policy_loss: 1.7810, value_loss: 0.9691
2024-07-14 05:07:05,121 [INFO    ] __main__: train step 2453: loss: 0.5639, policy_loss: 1.7809, value_loss: 0.9691
2024-07-14 05:07:05,395 [INFO    ] __main__: train step 2454: loss: 0.5640, policy_loss: 1.7808, value_loss: 0.9691
2024-07-14 05:07:06,227 [INFO    ] __main__: train step 2455: loss: 0.5642, policy_loss: 1.7806, value_loss: 0.9690
2024-07-14 05:07:06,478 [INFO    ] __main__: train step 2456: loss: 0.5643, policy_loss: 1.7805, value_loss: 0.9690
2024-07-14 05:07:06,744 [INFO    ] __main__: train step 2457: loss: 0.5645, policy_loss: 1.7804, value_loss: 0.9690
2024-07-14 05:07:07,020 [INFO    ] __main__: train step 2458: loss: 0.5646, policy_loss: 1.7803, value_loss: 0.9690
2024-07-14 05:07:07,298 [INFO    ] __main__: train step 2459: loss: 0.5648, policy_loss: 1.7802, value_loss: 0.9690
2024-07-14 05:07:07,565 [INFO    ] __main__: train step 2460: loss: 0.5650, policy_loss: 1.7800, value_loss: 0.9689
2024-07-14 05:07:07,832 [INFO    ] __main__: train step 2461: loss: 0.5651, policy_loss: 1.7799, value_loss: 0.9689
2024-07-14 05:07:09,439 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:07:09,913 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:07:09,980 [INFO    ] __main__: train step 2462: loss: 0.5653, policy_loss: 1.7798, value_loss: 0.9689
2024-07-14 05:07:10,258 [INFO    ] __main__: train step 2463: loss: 0.5654, policy_loss: 1.7797, value_loss: 0.9689
2024-07-14 05:07:10,523 [INFO    ] __main__: train step 2464: loss: 0.5656, policy_loss: 1.7795, value_loss: 0.9689
2024-07-14 05:07:10,797 [INFO    ] __main__: train step 2465: loss: 0.5657, policy_loss: 1.7794, value_loss: 0.9689
2024-07-14 05:07:11,068 [INFO    ] __main__: train step 2466: loss: 0.5659, policy_loss: 1.7793, value_loss: 0.9688
2024-07-14 05:07:11,357 [INFO    ] __main__: train step 2467: loss: 0.5661, policy_loss: 1.7792, value_loss: 0.9688
2024-07-14 05:07:11,629 [INFO    ] __main__: train step 2468: loss: 0.5662, policy_loss: 1.7790, value_loss: 0.9688
2024-07-14 05:07:11,910 [INFO    ] __main__: train step 2469: loss: 0.5664, policy_loss: 1.7789, value_loss: 0.9688
2024-07-14 05:07:12,181 [INFO    ] __main__: train step 2470: loss: 0.5665, policy_loss: 1.7788, value_loss: 0.9687
2024-07-14 05:07:12,446 [INFO    ] __main__: train step 2471: loss: 0.5667, policy_loss: 1.7787, value_loss: 0.9687
2024-07-14 05:07:12,728 [INFO    ] __main__: train step 2472: loss: 0.5668, policy_loss: 1.7786, value_loss: 0.9687
2024-07-14 05:07:12,995 [INFO    ] __main__: train step 2473: loss: 0.5670, policy_loss: 1.7784, value_loss: 0.9687
2024-07-14 05:07:13,622 [INFO    ] __main__: train step 2474: loss: 0.5671, policy_loss: 1.7783, value_loss: 0.9687
2024-07-14 05:07:13,902 [INFO    ] __main__: train step 2475: loss: 0.5673, policy_loss: 1.7782, value_loss: 0.9686
2024-07-14 05:07:14,187 [INFO    ] __main__: train step 2476: loss: 0.5674, policy_loss: 1.7781, value_loss: 0.9686
2024-07-14 05:07:14,458 [INFO    ] __main__: train step 2477: loss: 0.5676, policy_loss: 1.7779, value_loss: 0.9686
2024-07-14 05:07:14,735 [INFO    ] __main__: train step 2478: loss: 0.5678, policy_loss: 1.7778, value_loss: 0.9686
2024-07-14 05:07:16,334 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:07:16,809 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:07:16,877 [INFO    ] __main__: train step 2479: loss: 0.5679, policy_loss: 1.7777, value_loss: 0.9686
2024-07-14 05:07:17,149 [INFO    ] __main__: train step 2480: loss: 0.5681, policy_loss: 1.7776, value_loss: 0.9686
2024-07-14 05:07:17,419 [INFO    ] __main__: train step 2481: loss: 0.5682, policy_loss: 1.7775, value_loss: 0.9686
2024-07-14 05:07:17,704 [INFO    ] __main__: train step 2482: loss: 0.5684, policy_loss: 1.7773, value_loss: 0.9686
2024-07-14 05:07:17,981 [INFO    ] __main__: train step 2483: loss: 0.5686, policy_loss: 1.7772, value_loss: 0.9685
2024-07-14 05:07:18,267 [INFO    ] __main__: train step 2484: loss: 0.5687, policy_loss: 1.7771, value_loss: 0.9685
2024-07-14 05:07:18,534 [INFO    ] __main__: train step 2485: loss: 0.5688, policy_loss: 1.7770, value_loss: 0.9685
2024-07-14 05:07:18,811 [INFO    ] __main__: train step 2486: loss: 0.5690, policy_loss: 1.7769, value_loss: 0.9685
2024-07-14 05:07:19,090 [INFO    ] __main__: train step 2487: loss: 0.5692, policy_loss: 1.7767, value_loss: 0.9685
2024-07-14 05:07:19,377 [INFO    ] __main__: train step 2488: loss: 0.5693, policy_loss: 1.7766, value_loss: 0.9684
2024-07-14 05:07:19,653 [INFO    ] __main__: train step 2489: loss: 0.5695, policy_loss: 1.7765, value_loss: 0.9684
2024-07-14 05:07:19,925 [INFO    ] __main__: train step 2490: loss: 0.5696, policy_loss: 1.7764, value_loss: 0.9684
2024-07-14 05:07:20,195 [INFO    ] __main__: train step 2491: loss: 0.5698, policy_loss: 1.7763, value_loss: 0.9684
2024-07-14 05:07:20,452 [INFO    ] __main__: train step 2492: loss: 0.5699, policy_loss: 1.7762, value_loss: 0.9684
2024-07-14 05:07:20,711 [INFO    ] __main__: train step 2493: loss: 0.5701, policy_loss: 1.7760, value_loss: 0.9683
2024-07-14 05:07:20,984 [INFO    ] __main__: train step 2494: loss: 0.5703, policy_loss: 1.7759, value_loss: 0.9683
2024-07-14 05:07:21,882 [INFO    ] __main__: train step 2495: loss: 0.5704, policy_loss: 1.7758, value_loss: 0.9683
2024-07-14 05:07:23,500 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:07:23,979 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:07:24,046 [INFO    ] __main__: train step 2496: loss: 0.5706, policy_loss: 1.7757, value_loss: 0.9683
2024-07-14 05:07:24,328 [INFO    ] __main__: train step 2497: loss: 0.5708, policy_loss: 1.7756, value_loss: 0.9683
2024-07-14 05:07:24,603 [INFO    ] __main__: train step 2498: loss: 0.5709, policy_loss: 1.7755, value_loss: 0.9683
2024-07-14 05:07:24,874 [INFO    ] __main__: train step 2499: loss: 0.5711, policy_loss: 1.7753, value_loss: 0.9683
2024-07-14 05:07:25,139 [INFO    ] __main__: train step 2500: loss: 0.5712, policy_loss: 1.7752, value_loss: 0.9682
2024-07-14 05:07:25,412 [INFO    ] __main__: train step 2501: loss: 0.5714, policy_loss: 1.7751, value_loss: 0.9682
2024-07-14 05:07:25,682 [INFO    ] __main__: train step 2502: loss: 0.5716, policy_loss: 1.7750, value_loss: 0.9682
2024-07-14 05:07:25,967 [INFO    ] __main__: train step 2503: loss: 0.5717, policy_loss: 1.7749, value_loss: 0.9682
2024-07-14 05:07:26,249 [INFO    ] __main__: train step 2504: loss: 0.5719, policy_loss: 1.7748, value_loss: 0.9682
2024-07-14 05:07:26,525 [INFO    ] __main__: train step 2505: loss: 0.5720, policy_loss: 1.7746, value_loss: 0.9681
2024-07-14 05:07:26,808 [INFO    ] __main__: train step 2506: loss: 0.5722, policy_loss: 1.7745, value_loss: 0.9681
2024-07-14 05:07:27,083 [INFO    ] __main__: train step 2507: loss: 0.5723, policy_loss: 1.7744, value_loss: 0.9681
2024-07-14 05:07:27,363 [INFO    ] __main__: train step 2508: loss: 0.5725, policy_loss: 1.7743, value_loss: 0.9681
2024-07-14 05:07:27,635 [INFO    ] __main__: train step 2509: loss: 0.5726, policy_loss: 1.7742, value_loss: 0.9681
2024-07-14 05:07:27,916 [INFO    ] __main__: train step 2510: loss: 0.5728, policy_loss: 1.7740, value_loss: 0.9681
2024-07-14 05:07:28,196 [INFO    ] __main__: train step 2511: loss: 0.5730, policy_loss: 1.7739, value_loss: 0.9681
2024-07-14 05:07:28,465 [INFO    ] __main__: train step 2512: loss: 0.5731, policy_loss: 1.7738, value_loss: 0.9681
2024-07-14 05:07:30,092 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:07:30,567 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:07:30,638 [INFO    ] __main__: train step 2513: loss: 0.5733, policy_loss: 1.7737, value_loss: 0.9680
2024-07-14 05:07:30,918 [INFO    ] __main__: train step 2514: loss: 0.5734, policy_loss: 1.7735, value_loss: 0.9680
2024-07-14 05:07:31,801 [INFO    ] __main__: train step 2515: loss: 0.5736, policy_loss: 1.7734, value_loss: 0.9680
2024-07-14 05:07:32,079 [INFO    ] __main__: train step 2516: loss: 0.5737, policy_loss: 1.7733, value_loss: 0.9680
2024-07-14 05:07:32,358 [INFO    ] __main__: train step 2517: loss: 0.5739, policy_loss: 1.7732, value_loss: 0.9680
2024-07-14 05:07:32,629 [INFO    ] __main__: train step 2518: loss: 0.5741, policy_loss: 1.7731, value_loss: 0.9679
2024-07-14 05:07:32,909 [INFO    ] __main__: train step 2519: loss: 0.5742, policy_loss: 1.7729, value_loss: 0.9679
2024-07-14 05:07:33,173 [INFO    ] __main__: train step 2520: loss: 0.5744, policy_loss: 1.7728, value_loss: 0.9679
2024-07-14 05:07:33,448 [INFO    ] __main__: train step 2521: loss: 0.5745, policy_loss: 1.7727, value_loss: 0.9679
2024-07-14 05:07:33,734 [INFO    ] __main__: train step 2522: loss: 0.5747, policy_loss: 1.7726, value_loss: 0.9679
2024-07-14 05:07:34,003 [INFO    ] __main__: train step 2523: loss: 0.5748, policy_loss: 1.7725, value_loss: 0.9679
2024-07-14 05:07:34,279 [INFO    ] __main__: train step 2524: loss: 0.5750, policy_loss: 1.7723, value_loss: 0.9678
2024-07-14 05:07:34,567 [INFO    ] __main__: train step 2525: loss: 0.5752, policy_loss: 1.7722, value_loss: 0.9678
2024-07-14 05:07:34,835 [INFO    ] __main__: train step 2526: loss: 0.5753, policy_loss: 1.7721, value_loss: 0.9678
2024-07-14 05:07:35,114 [INFO    ] __main__: train step 2527: loss: 0.5755, policy_loss: 1.7720, value_loss: 0.9678
2024-07-14 05:07:35,378 [INFO    ] __main__: train step 2528: loss: 0.5756, policy_loss: 1.7719, value_loss: 0.9678
2024-07-14 05:07:35,639 [INFO    ] __main__: train step 2529: loss: 0.5758, policy_loss: 1.7717, value_loss: 0.9678
2024-07-14 05:07:37,206 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:07:37,663 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:07:37,727 [INFO    ] __main__: train step 2530: loss: 0.5759, policy_loss: 1.7716, value_loss: 0.9677
2024-07-14 05:07:37,982 [INFO    ] __main__: train step 2531: loss: 0.5761, policy_loss: 1.7715, value_loss: 0.9677
2024-07-14 05:07:38,230 [INFO    ] __main__: train step 2532: loss: 0.5763, policy_loss: 1.7714, value_loss: 0.9677
2024-07-14 05:07:38,489 [INFO    ] __main__: train step 2533: loss: 0.5764, policy_loss: 1.7712, value_loss: 0.9677
2024-07-14 05:07:39,370 [INFO    ] __main__: train step 2534: loss: 0.5766, policy_loss: 1.7711, value_loss: 0.9676
2024-07-14 05:07:39,648 [INFO    ] __main__: train step 2535: loss: 0.5767, policy_loss: 1.7710, value_loss: 0.9676
2024-07-14 05:07:39,934 [INFO    ] __main__: train step 2536: loss: 0.5769, policy_loss: 1.7709, value_loss: 0.9676
2024-07-14 05:07:40,215 [INFO    ] __main__: train step 2537: loss: 0.5770, policy_loss: 1.7708, value_loss: 0.9676
2024-07-14 05:07:40,489 [INFO    ] __main__: train step 2538: loss: 0.5772, policy_loss: 1.7706, value_loss: 0.9676
2024-07-14 05:07:40,777 [INFO    ] __main__: train step 2539: loss: 0.5773, policy_loss: 1.7705, value_loss: 0.9676
2024-07-14 05:07:41,096 [INFO    ] __main__: train step 2540: loss: 0.5775, policy_loss: 1.7704, value_loss: 0.9676
2024-07-14 05:07:41,419 [INFO    ] __main__: train step 2541: loss: 0.5776, policy_loss: 1.7703, value_loss: 0.9675
2024-07-14 05:07:41,724 [INFO    ] __main__: train step 2542: loss: 0.5778, policy_loss: 1.7702, value_loss: 0.9675
2024-07-14 05:07:42,020 [INFO    ] __main__: train step 2543: loss: 0.5779, policy_loss: 1.7700, value_loss: 0.9675
2024-07-14 05:07:42,340 [INFO    ] __main__: train step 2544: loss: 0.5781, policy_loss: 1.7699, value_loss: 0.9675
2024-07-14 05:07:42,638 [INFO    ] __main__: train step 2545: loss: 0.5783, policy_loss: 1.7698, value_loss: 0.9675
2024-07-14 05:07:42,938 [INFO    ] __main__: train step 2546: loss: 0.5784, policy_loss: 1.7697, value_loss: 0.9674
2024-07-14 05:07:44,564 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:07:45,070 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:07:45,144 [INFO    ] __main__: train step 2547: loss: 0.5786, policy_loss: 1.7696, value_loss: 0.9674
2024-07-14 05:07:45,456 [INFO    ] __main__: train step 2548: loss: 0.5787, policy_loss: 1.7694, value_loss: 0.9674
2024-07-14 05:07:45,753 [INFO    ] __main__: train step 2549: loss: 0.5789, policy_loss: 1.7693, value_loss: 0.9674
2024-07-14 05:07:46,047 [INFO    ] __main__: train step 2550: loss: 0.5790, policy_loss: 1.7692, value_loss: 0.9674
2024-07-14 05:07:46,357 [INFO    ] __main__: train step 2551: loss: 0.5792, policy_loss: 1.7691, value_loss: 0.9674
2024-07-14 05:07:46,655 [INFO    ] __main__: train step 2552: loss: 0.5794, policy_loss: 1.7689, value_loss: 0.9673
2024-07-14 05:07:46,950 [INFO    ] __main__: train step 2553: loss: 0.5795, policy_loss: 1.7688, value_loss: 0.9673
2024-07-14 05:07:48,235 [INFO    ] __main__: train step 2554: loss: 0.5797, policy_loss: 1.7687, value_loss: 0.9673
2024-07-14 05:07:48,531 [INFO    ] __main__: train step 2555: loss: 0.5798, policy_loss: 1.7686, value_loss: 0.9673
2024-07-14 05:07:48,813 [INFO    ] __main__: train step 2556: loss: 0.5800, policy_loss: 1.7684, value_loss: 0.9672
2024-07-14 05:07:49,085 [INFO    ] __main__: train step 2557: loss: 0.5801, policy_loss: 1.7683, value_loss: 0.9672
2024-07-14 05:07:49,367 [INFO    ] __main__: train step 2558: loss: 0.5803, policy_loss: 1.7682, value_loss: 0.9672
2024-07-14 05:07:49,641 [INFO    ] __main__: train step 2559: loss: 0.5805, policy_loss: 1.7681, value_loss: 0.9672
2024-07-14 05:07:49,914 [INFO    ] __main__: train step 2560: loss: 0.5806, policy_loss: 1.7679, value_loss: 0.9672
2024-07-14 05:07:50,187 [INFO    ] __main__: train step 2561: loss: 0.5808, policy_loss: 1.7678, value_loss: 0.9671
2024-07-14 05:07:50,465 [INFO    ] __main__: train step 2562: loss: 0.5809, policy_loss: 1.7677, value_loss: 0.9671
2024-07-14 05:07:50,732 [INFO    ] __main__: train step 2563: loss: 0.5811, policy_loss: 1.7676, value_loss: 0.9671
2024-07-14 05:07:52,323 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:07:52,801 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:07:52,867 [INFO    ] __main__: train step 2564: loss: 0.5813, policy_loss: 1.7674, value_loss: 0.9671
2024-07-14 05:07:53,143 [INFO    ] __main__: train step 2565: loss: 0.5814, policy_loss: 1.7673, value_loss: 0.9671
2024-07-14 05:07:53,400 [INFO    ] __main__: train step 2566: loss: 0.5816, policy_loss: 1.7672, value_loss: 0.9670
2024-07-14 05:07:53,678 [INFO    ] __main__: train step 2567: loss: 0.5817, policy_loss: 1.7670, value_loss: 0.9670
2024-07-14 05:07:53,950 [INFO    ] __main__: train step 2568: loss: 0.5819, policy_loss: 1.7669, value_loss: 0.9670
2024-07-14 05:07:54,219 [INFO    ] __main__: train step 2569: loss: 0.5821, policy_loss: 1.7668, value_loss: 0.9670
2024-07-14 05:07:54,495 [INFO    ] __main__: train step 2570: loss: 0.5822, policy_loss: 1.7667, value_loss: 0.9670
2024-07-14 05:07:54,775 [INFO    ] __main__: train step 2571: loss: 0.5823, policy_loss: 1.7665, value_loss: 0.9670
2024-07-14 05:07:55,044 [INFO    ] __main__: train step 2572: loss: 0.5825, policy_loss: 1.7664, value_loss: 0.9669
2024-07-14 05:07:55,671 [INFO    ] __main__: train step 2573: loss: 0.5827, policy_loss: 1.7663, value_loss: 0.9669
2024-07-14 05:07:55,944 [INFO    ] __main__: train step 2574: loss: 0.5828, policy_loss: 1.7662, value_loss: 0.9669
2024-07-14 05:07:56,217 [INFO    ] __main__: train step 2575: loss: 0.5830, policy_loss: 1.7660, value_loss: 0.9669
2024-07-14 05:07:56,488 [INFO    ] __main__: train step 2576: loss: 0.5831, policy_loss: 1.7659, value_loss: 0.9669
2024-07-14 05:07:56,766 [INFO    ] __main__: train step 2577: loss: 0.5833, policy_loss: 1.7658, value_loss: 0.9668
2024-07-14 05:07:57,037 [INFO    ] __main__: train step 2578: loss: 0.5835, policy_loss: 1.7657, value_loss: 0.9668
2024-07-14 05:07:57,311 [INFO    ] __main__: train step 2579: loss: 0.5836, policy_loss: 1.7656, value_loss: 0.9668
2024-07-14 05:07:57,599 [INFO    ] __main__: train step 2580: loss: 0.5838, policy_loss: 1.7655, value_loss: 0.9668
2024-07-14 05:07:59,186 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:07:59,657 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:07:59,721 [INFO    ] __main__: train step 2581: loss: 0.5839, policy_loss: 1.7653, value_loss: 0.9668
2024-07-14 05:08:00,001 [INFO    ] __main__: train step 2582: loss: 0.5841, policy_loss: 1.7652, value_loss: 0.9667
2024-07-14 05:08:00,270 [INFO    ] __main__: train step 2583: loss: 0.5842, policy_loss: 1.7651, value_loss: 0.9667
2024-07-14 05:08:00,552 [INFO    ] __main__: train step 2584: loss: 0.5844, policy_loss: 1.7650, value_loss: 0.9667
2024-07-14 05:08:00,858 [INFO    ] __main__: train step 2585: loss: 0.5846, policy_loss: 1.7648, value_loss: 0.9667
2024-07-14 05:08:01,137 [INFO    ] __main__: train step 2586: loss: 0.5847, policy_loss: 1.7647, value_loss: 0.9666
2024-07-14 05:08:01,402 [INFO    ] __main__: train step 2587: loss: 0.5849, policy_loss: 1.7646, value_loss: 0.9666
2024-07-14 05:08:01,667 [INFO    ] __main__: train step 2588: loss: 0.5850, policy_loss: 1.7645, value_loss: 0.9666
2024-07-14 05:08:01,944 [INFO    ] __main__: train step 2589: loss: 0.5852, policy_loss: 1.7643, value_loss: 0.9666
2024-07-14 05:08:02,225 [INFO    ] __main__: train step 2590: loss: 0.5853, policy_loss: 1.7642, value_loss: 0.9665
2024-07-14 05:08:02,491 [INFO    ] __main__: train step 2591: loss: 0.5855, policy_loss: 1.7641, value_loss: 0.9665
2024-07-14 05:08:03,119 [INFO    ] __main__: train step 2592: loss: 0.5856, policy_loss: 1.7640, value_loss: 0.9665
2024-07-14 05:08:03,393 [INFO    ] __main__: train step 2593: loss: 0.5858, policy_loss: 1.7638, value_loss: 0.9665
2024-07-14 05:08:03,670 [INFO    ] __main__: train step 2594: loss: 0.5859, policy_loss: 1.7637, value_loss: 0.9664
2024-07-14 05:08:03,932 [INFO    ] __main__: train step 2595: loss: 0.5861, policy_loss: 1.7636, value_loss: 0.9664
2024-07-14 05:08:04,205 [INFO    ] __main__: train step 2596: loss: 0.5862, policy_loss: 1.7635, value_loss: 0.9664
2024-07-14 05:08:04,477 [INFO    ] __main__: train step 2597: loss: 0.5864, policy_loss: 1.7634, value_loss: 0.9664
2024-07-14 05:08:06,079 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:08:06,548 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:08:06,624 [INFO    ] __main__: train step 2598: loss: 0.5866, policy_loss: 1.7632, value_loss: 0.9663
2024-07-14 05:08:06,922 [INFO    ] __main__: train step 2599: loss: 0.5867, policy_loss: 1.7631, value_loss: 0.9663
2024-07-14 05:08:07,191 [INFO    ] __main__: train step 2600: loss: 0.5869, policy_loss: 1.7630, value_loss: 0.9663
2024-07-14 05:08:07,462 [INFO    ] __main__: train step 2601: loss: 0.5870, policy_loss: 1.7628, value_loss: 0.9663
2024-07-14 05:08:07,725 [INFO    ] __main__: train step 2602: loss: 0.5872, policy_loss: 1.7627, value_loss: 0.9663
2024-07-14 05:08:07,991 [INFO    ] __main__: train step 2603: loss: 0.5874, policy_loss: 1.7626, value_loss: 0.9662
2024-07-14 05:08:08,263 [INFO    ] __main__: train step 2604: loss: 0.5875, policy_loss: 1.7625, value_loss: 0.9662
2024-07-14 05:08:08,534 [INFO    ] __main__: train step 2605: loss: 0.5877, policy_loss: 1.7623, value_loss: 0.9662
2024-07-14 05:08:08,808 [INFO    ] __main__: train step 2606: loss: 0.5878, policy_loss: 1.7622, value_loss: 0.9662
2024-07-14 05:08:09,083 [INFO    ] __main__: train step 2607: loss: 0.5880, policy_loss: 1.7621, value_loss: 0.9661
2024-07-14 05:08:09,368 [INFO    ] __main__: train step 2608: loss: 0.5881, policy_loss: 1.7620, value_loss: 0.9661
2024-07-14 05:08:09,641 [INFO    ] __main__: train step 2609: loss: 0.5883, policy_loss: 1.7618, value_loss: 0.9661
2024-07-14 05:08:09,949 [INFO    ] __main__: train step 2610: loss: 0.5884, policy_loss: 1.7617, value_loss: 0.9661
2024-07-14 05:08:10,225 [INFO    ] __main__: train step 2611: loss: 0.5886, policy_loss: 1.7616, value_loss: 0.9661
2024-07-14 05:08:11,071 [INFO    ] __main__: train step 2612: loss: 0.5888, policy_loss: 1.7615, value_loss: 0.9660
2024-07-14 05:08:11,350 [INFO    ] __main__: train step 2613: loss: 0.5889, policy_loss: 1.7613, value_loss: 0.9660
2024-07-14 05:08:11,623 [INFO    ] __main__: train step 2614: loss: 0.5891, policy_loss: 1.7612, value_loss: 0.9660
2024-07-14 05:08:13,208 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:08:13,689 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:08:13,754 [INFO    ] __main__: train step 2615: loss: 0.5892, policy_loss: 1.7611, value_loss: 0.9660
2024-07-14 05:08:14,006 [INFO    ] __main__: train step 2616: loss: 0.5894, policy_loss: 1.7610, value_loss: 0.9659
2024-07-14 05:08:14,273 [INFO    ] __main__: train step 2617: loss: 0.5895, policy_loss: 1.7608, value_loss: 0.9659
2024-07-14 05:08:14,542 [INFO    ] __main__: train step 2618: loss: 0.5897, policy_loss: 1.7607, value_loss: 0.9659
2024-07-14 05:08:14,794 [INFO    ] __main__: train step 2619: loss: 0.5898, policy_loss: 1.7606, value_loss: 0.9659
2024-07-14 05:08:15,071 [INFO    ] __main__: train step 2620: loss: 0.5900, policy_loss: 1.7604, value_loss: 0.9659
2024-07-14 05:08:15,351 [INFO    ] __main__: train step 2621: loss: 0.5901, policy_loss: 1.7603, value_loss: 0.9658
2024-07-14 05:08:15,621 [INFO    ] __main__: train step 2622: loss: 0.5903, policy_loss: 1.7602, value_loss: 0.9658
2024-07-14 05:08:15,900 [INFO    ] __main__: train step 2623: loss: 0.5904, policy_loss: 1.7601, value_loss: 0.9658
2024-07-14 05:08:16,179 [INFO    ] __main__: train step 2624: loss: 0.5906, policy_loss: 1.7599, value_loss: 0.9658
2024-07-14 05:08:16,449 [INFO    ] __main__: train step 2625: loss: 0.5907, policy_loss: 1.7598, value_loss: 0.9658
2024-07-14 05:08:16,727 [INFO    ] __main__: train step 2626: loss: 0.5909, policy_loss: 1.7597, value_loss: 0.9657
2024-07-14 05:08:17,001 [INFO    ] __main__: train step 2627: loss: 0.5910, policy_loss: 1.7595, value_loss: 0.9657
2024-07-14 05:08:17,269 [INFO    ] __main__: train step 2628: loss: 0.5912, policy_loss: 1.7594, value_loss: 0.9657
2024-07-14 05:08:17,545 [INFO    ] __main__: train step 2629: loss: 0.5913, policy_loss: 1.7593, value_loss: 0.9657
2024-07-14 05:08:17,820 [INFO    ] __main__: train step 2630: loss: 0.5915, policy_loss: 1.7592, value_loss: 0.9657
2024-07-14 05:08:18,097 [INFO    ] __main__: train step 2631: loss: 0.5916, policy_loss: 1.7590, value_loss: 0.9656
2024-07-14 05:08:20,059 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:08:20,532 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:08:20,599 [INFO    ] __main__: train step 2632: loss: 0.5918, policy_loss: 1.7589, value_loss: 0.9656
2024-07-14 05:08:20,899 [INFO    ] __main__: train step 2633: loss: 0.5920, policy_loss: 1.7588, value_loss: 0.9656
2024-07-14 05:08:21,175 [INFO    ] __main__: train step 2634: loss: 0.5921, policy_loss: 1.7587, value_loss: 0.9655
2024-07-14 05:08:21,440 [INFO    ] __main__: train step 2635: loss: 0.5923, policy_loss: 1.7586, value_loss: 0.9655
2024-07-14 05:08:21,703 [INFO    ] __main__: train step 2636: loss: 0.5924, policy_loss: 1.7584, value_loss: 0.9655
2024-07-14 05:08:21,977 [INFO    ] __main__: train step 2637: loss: 0.5926, policy_loss: 1.7583, value_loss: 0.9655
2024-07-14 05:08:22,250 [INFO    ] __main__: train step 2638: loss: 0.5927, policy_loss: 1.7582, value_loss: 0.9655
2024-07-14 05:08:22,524 [INFO    ] __main__: train step 2639: loss: 0.5929, policy_loss: 1.7580, value_loss: 0.9654
2024-07-14 05:08:22,789 [INFO    ] __main__: train step 2640: loss: 0.5930, policy_loss: 1.7579, value_loss: 0.9654
2024-07-14 05:08:23,061 [INFO    ] __main__: train step 2641: loss: 0.5932, policy_loss: 1.7578, value_loss: 0.9654
2024-07-14 05:08:23,339 [INFO    ] __main__: train step 2642: loss: 0.5934, policy_loss: 1.7577, value_loss: 0.9654
2024-07-14 05:08:23,617 [INFO    ] __main__: train step 2643: loss: 0.5935, policy_loss: 1.7575, value_loss: 0.9653
2024-07-14 05:08:23,883 [INFO    ] __main__: train step 2644: loss: 0.5936, policy_loss: 1.7574, value_loss: 0.9653
2024-07-14 05:08:24,163 [INFO    ] __main__: train step 2645: loss: 0.5938, policy_loss: 1.7573, value_loss: 0.9653
2024-07-14 05:08:24,438 [INFO    ] __main__: train step 2646: loss: 0.5940, policy_loss: 1.7572, value_loss: 0.9653
2024-07-14 05:08:24,728 [INFO    ] __main__: train step 2647: loss: 0.5941, policy_loss: 1.7571, value_loss: 0.9653
2024-07-14 05:08:25,026 [INFO    ] __main__: train step 2648: loss: 0.5943, policy_loss: 1.7569, value_loss: 0.9652
2024-07-14 05:08:26,613 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:08:27,087 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:08:27,155 [INFO    ] __main__: train step 2649: loss: 0.5944, policy_loss: 1.7568, value_loss: 0.9652
2024-07-14 05:08:27,425 [INFO    ] __main__: train step 2650: loss: 0.5946, policy_loss: 1.7567, value_loss: 0.9652
2024-07-14 05:08:28,079 [INFO    ] __main__: train step 2651: loss: 0.5947, policy_loss: 1.7566, value_loss: 0.9652
2024-07-14 05:08:28,351 [INFO    ] __main__: train step 2652: loss: 0.5949, policy_loss: 1.7564, value_loss: 0.9651
2024-07-14 05:08:28,621 [INFO    ] __main__: train step 2653: loss: 0.5950, policy_loss: 1.7563, value_loss: 0.9651
2024-07-14 05:08:28,900 [INFO    ] __main__: train step 2654: loss: 0.5952, policy_loss: 1.7562, value_loss: 0.9651
2024-07-14 05:08:29,169 [INFO    ] __main__: train step 2655: loss: 0.5953, policy_loss: 1.7560, value_loss: 0.9651
2024-07-14 05:08:29,440 [INFO    ] __main__: train step 2656: loss: 0.5955, policy_loss: 1.7559, value_loss: 0.9651
2024-07-14 05:08:29,713 [INFO    ] __main__: train step 2657: loss: 0.5956, policy_loss: 1.7558, value_loss: 0.9650
2024-07-14 05:08:29,993 [INFO    ] __main__: train step 2658: loss: 0.5958, policy_loss: 1.7557, value_loss: 0.9650
2024-07-14 05:08:30,274 [INFO    ] __main__: train step 2659: loss: 0.5960, policy_loss: 1.7556, value_loss: 0.9650
2024-07-14 05:08:30,559 [INFO    ] __main__: train step 2660: loss: 0.5961, policy_loss: 1.7554, value_loss: 0.9650
2024-07-14 05:08:30,831 [INFO    ] __main__: train step 2661: loss: 0.5963, policy_loss: 1.7553, value_loss: 0.9649
2024-07-14 05:08:31,120 [INFO    ] __main__: train step 2662: loss: 0.5964, policy_loss: 1.7552, value_loss: 0.9649
2024-07-14 05:08:31,390 [INFO    ] __main__: train step 2663: loss: 0.5966, policy_loss: 1.7551, value_loss: 0.9649
2024-07-14 05:08:31,659 [INFO    ] __main__: train step 2664: loss: 0.5967, policy_loss: 1.7550, value_loss: 0.9648
2024-07-14 05:08:31,936 [INFO    ] __main__: train step 2665: loss: 0.5969, policy_loss: 1.7548, value_loss: 0.9648
2024-07-14 05:08:33,515 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:08:33,984 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:08:34,052 [INFO    ] __main__: train step 2666: loss: 0.5970, policy_loss: 1.7547, value_loss: 0.9648
2024-07-14 05:08:34,302 [INFO    ] __main__: train step 2667: loss: 0.5972, policy_loss: 1.7546, value_loss: 0.9648
2024-07-14 05:08:34,556 [INFO    ] __main__: train step 2668: loss: 0.5974, policy_loss: 1.7545, value_loss: 0.9647
2024-07-14 05:08:34,824 [INFO    ] __main__: train step 2669: loss: 0.5975, policy_loss: 1.7544, value_loss: 0.9647
2024-07-14 05:08:35,090 [INFO    ] __main__: train step 2670: loss: 0.5977, policy_loss: 1.7542, value_loss: 0.9647
2024-07-14 05:08:35,739 [INFO    ] __main__: train step 2671: loss: 0.5978, policy_loss: 1.7541, value_loss: 0.9646
2024-07-14 05:08:36,016 [INFO    ] __main__: train step 2672: loss: 0.5980, policy_loss: 1.7540, value_loss: 0.9646
2024-07-14 05:08:36,302 [INFO    ] __main__: train step 2673: loss: 0.5981, policy_loss: 1.7539, value_loss: 0.9646
2024-07-14 05:08:36,590 [INFO    ] __main__: train step 2674: loss: 0.5983, policy_loss: 1.7538, value_loss: 0.9646
2024-07-14 05:08:36,881 [INFO    ] __main__: train step 2675: loss: 0.5984, policy_loss: 1.7536, value_loss: 0.9645
2024-07-14 05:08:37,163 [INFO    ] __main__: train step 2676: loss: 0.5986, policy_loss: 1.7535, value_loss: 0.9645
2024-07-14 05:08:37,460 [INFO    ] __main__: train step 2677: loss: 0.5987, policy_loss: 1.7534, value_loss: 0.9645
2024-07-14 05:08:37,746 [INFO    ] __main__: train step 2678: loss: 0.5989, policy_loss: 1.7533, value_loss: 0.9645
2024-07-14 05:08:38,023 [INFO    ] __main__: train step 2679: loss: 0.5990, policy_loss: 1.7531, value_loss: 0.9645
2024-07-14 05:08:38,306 [INFO    ] __main__: train step 2680: loss: 0.5992, policy_loss: 1.7530, value_loss: 0.9644
2024-07-14 05:08:38,603 [INFO    ] __main__: train step 2681: loss: 0.5993, policy_loss: 1.7529, value_loss: 0.9644
2024-07-14 05:08:38,896 [INFO    ] __main__: train step 2682: loss: 0.5995, policy_loss: 1.7528, value_loss: 0.9644
2024-07-14 05:08:40,502 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:08:41,002 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:08:41,070 [INFO    ] __main__: train step 2683: loss: 0.5996, policy_loss: 1.7526, value_loss: 0.9643
2024-07-14 05:08:41,352 [INFO    ] __main__: train step 2684: loss: 0.5998, policy_loss: 1.7525, value_loss: 0.9643
2024-07-14 05:08:41,639 [INFO    ] __main__: train step 2685: loss: 0.5999, policy_loss: 1.7524, value_loss: 0.9643
2024-07-14 05:08:41,928 [INFO    ] __main__: train step 2686: loss: 0.6001, policy_loss: 1.7523, value_loss: 0.9642
2024-07-14 05:08:42,209 [INFO    ] __main__: train step 2687: loss: 0.6002, policy_loss: 1.7521, value_loss: 0.9642
2024-07-14 05:08:42,494 [INFO    ] __main__: train step 2688: loss: 0.6004, policy_loss: 1.7520, value_loss: 0.9642
2024-07-14 05:08:42,778 [INFO    ] __main__: train step 2689: loss: 0.6005, policy_loss: 1.7519, value_loss: 0.9642
2024-07-14 05:08:43,526 [INFO    ] __main__: train step 2690: loss: 0.6007, policy_loss: 1.7518, value_loss: 0.9641
2024-07-14 05:08:43,811 [INFO    ] __main__: train step 2691: loss: 0.6008, policy_loss: 1.7516, value_loss: 0.9641
2024-07-14 05:08:44,088 [INFO    ] __main__: train step 2692: loss: 0.6010, policy_loss: 1.7515, value_loss: 0.9641
2024-07-14 05:08:44,369 [INFO    ] __main__: train step 2693: loss: 0.6011, policy_loss: 1.7514, value_loss: 0.9641
2024-07-14 05:08:44,640 [INFO    ] __main__: train step 2694: loss: 0.6013, policy_loss: 1.7513, value_loss: 0.9641
2024-07-14 05:08:44,904 [INFO    ] __main__: train step 2695: loss: 0.6014, policy_loss: 1.7511, value_loss: 0.9640
2024-07-14 05:08:45,187 [INFO    ] __main__: train step 2696: loss: 0.6016, policy_loss: 1.7510, value_loss: 0.9640
2024-07-14 05:08:45,467 [INFO    ] __main__: train step 2697: loss: 0.6018, policy_loss: 1.7509, value_loss: 0.9640
2024-07-14 05:08:45,752 [INFO    ] __main__: train step 2698: loss: 0.6019, policy_loss: 1.7508, value_loss: 0.9640
2024-07-14 05:08:46,036 [INFO    ] __main__: train step 2699: loss: 0.6021, policy_loss: 1.7506, value_loss: 0.9639
2024-07-14 05:08:47,622 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:08:48,108 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:08:48,182 [INFO    ] __main__: train step 2700: loss: 0.6022, policy_loss: 1.7505, value_loss: 0.9639
2024-07-14 05:08:48,473 [INFO    ] __main__: train step 2701: loss: 0.6024, policy_loss: 1.7504, value_loss: 0.9639
2024-07-14 05:08:48,756 [INFO    ] __main__: train step 2702: loss: 0.6025, policy_loss: 1.7502, value_loss: 0.9638
2024-07-14 05:08:49,029 [INFO    ] __main__: train step 2703: loss: 0.6027, policy_loss: 1.7501, value_loss: 0.9638
2024-07-14 05:08:49,310 [INFO    ] __main__: train step 2704: loss: 0.6028, policy_loss: 1.7500, value_loss: 0.9638
2024-07-14 05:08:49,590 [INFO    ] __main__: train step 2705: loss: 0.6030, policy_loss: 1.7499, value_loss: 0.9638
2024-07-14 05:08:49,863 [INFO    ] __main__: train step 2706: loss: 0.6031, policy_loss: 1.7497, value_loss: 0.9638
2024-07-14 05:08:50,146 [INFO    ] __main__: train step 2707: loss: 0.6033, policy_loss: 1.7496, value_loss: 0.9637
2024-07-14 05:08:50,423 [INFO    ] __main__: train step 2708: loss: 0.6034, policy_loss: 1.7495, value_loss: 0.9637
2024-07-14 05:08:50,691 [INFO    ] __main__: train step 2709: loss: 0.6036, policy_loss: 1.7494, value_loss: 0.9637
2024-07-14 05:08:51,329 [INFO    ] __main__: train step 2710: loss: 0.6037, policy_loss: 1.7492, value_loss: 0.9637
2024-07-14 05:08:51,609 [INFO    ] __main__: train step 2711: loss: 0.6039, policy_loss: 1.7491, value_loss: 0.9636
2024-07-14 05:08:51,882 [INFO    ] __main__: train step 2712: loss: 0.6040, policy_loss: 1.7490, value_loss: 0.9636
2024-07-14 05:08:52,157 [INFO    ] __main__: train step 2713: loss: 0.6042, policy_loss: 1.7489, value_loss: 0.9636
2024-07-14 05:08:52,435 [INFO    ] __main__: train step 2714: loss: 0.6043, policy_loss: 1.7487, value_loss: 0.9636
2024-07-14 05:08:52,703 [INFO    ] __main__: train step 2715: loss: 0.6045, policy_loss: 1.7486, value_loss: 0.9635
2024-07-14 05:08:52,981 [INFO    ] __main__: train step 2716: loss: 0.6046, policy_loss: 1.7485, value_loss: 0.9635
2024-07-14 05:08:54,577 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:08:55,034 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:08:55,098 [INFO    ] __main__: train step 2717: loss: 0.6048, policy_loss: 1.7483, value_loss: 0.9635
2024-07-14 05:08:55,363 [INFO    ] __main__: train step 2718: loss: 0.6049, policy_loss: 1.7482, value_loss: 0.9635
2024-07-14 05:08:55,632 [INFO    ] __main__: train step 2719: loss: 0.6051, policy_loss: 1.7481, value_loss: 0.9634
2024-07-14 05:08:55,925 [INFO    ] __main__: train step 2720: loss: 0.6052, policy_loss: 1.7480, value_loss: 0.9634
2024-07-14 05:08:56,194 [INFO    ] __main__: train step 2721: loss: 0.6054, policy_loss: 1.7478, value_loss: 0.9634
2024-07-14 05:08:56,474 [INFO    ] __main__: train step 2722: loss: 0.6055, policy_loss: 1.7477, value_loss: 0.9634
2024-07-14 05:08:56,747 [INFO    ] __main__: train step 2723: loss: 0.6057, policy_loss: 1.7476, value_loss: 0.9633
2024-07-14 05:08:57,020 [INFO    ] __main__: train step 2724: loss: 0.6058, policy_loss: 1.7475, value_loss: 0.9633
2024-07-14 05:08:57,294 [INFO    ] __main__: train step 2725: loss: 0.6060, policy_loss: 1.7473, value_loss: 0.9633
2024-07-14 05:08:57,562 [INFO    ] __main__: train step 2726: loss: 0.6061, policy_loss: 1.7472, value_loss: 0.9632
2024-07-14 05:08:57,837 [INFO    ] __main__: train step 2727: loss: 0.6063, policy_loss: 1.7471, value_loss: 0.9632
2024-07-14 05:08:58,110 [INFO    ] __main__: train step 2728: loss: 0.6064, policy_loss: 1.7470, value_loss: 0.9632
2024-07-14 05:08:58,387 [INFO    ] __main__: train step 2729: loss: 0.6065, policy_loss: 1.7468, value_loss: 0.9632
2024-07-14 05:08:59,003 [INFO    ] __main__: train step 2730: loss: 0.6067, policy_loss: 1.7467, value_loss: 0.9632
2024-07-14 05:08:59,277 [INFO    ] __main__: train step 2731: loss: 0.6068, policy_loss: 1.7466, value_loss: 0.9631
2024-07-14 05:08:59,558 [INFO    ] __main__: train step 2732: loss: 0.6070, policy_loss: 1.7465, value_loss: 0.9631
2024-07-14 05:08:59,836 [INFO    ] __main__: train step 2733: loss: 0.6071, policy_loss: 1.7464, value_loss: 0.9631
2024-07-14 05:09:01,435 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:09:01,922 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:09:01,986 [INFO    ] __main__: train step 2734: loss: 0.6073, policy_loss: 1.7462, value_loss: 0.9631
2024-07-14 05:09:02,259 [INFO    ] __main__: train step 2735: loss: 0.6074, policy_loss: 1.7461, value_loss: 0.9630
2024-07-14 05:09:02,537 [INFO    ] __main__: train step 2736: loss: 0.6076, policy_loss: 1.7460, value_loss: 0.9630
2024-07-14 05:09:02,809 [INFO    ] __main__: train step 2737: loss: 0.6077, policy_loss: 1.7459, value_loss: 0.9630
2024-07-14 05:09:03,080 [INFO    ] __main__: train step 2738: loss: 0.6079, policy_loss: 1.7457, value_loss: 0.9629
2024-07-14 05:09:03,369 [INFO    ] __main__: train step 2739: loss: 0.6080, policy_loss: 1.7456, value_loss: 0.9629
2024-07-14 05:09:03,651 [INFO    ] __main__: train step 2740: loss: 0.6082, policy_loss: 1.7455, value_loss: 0.9629
2024-07-14 05:09:03,943 [INFO    ] __main__: train step 2741: loss: 0.6083, policy_loss: 1.7454, value_loss: 0.9629
2024-07-14 05:09:04,233 [INFO    ] __main__: train step 2742: loss: 0.6085, policy_loss: 1.7452, value_loss: 0.9628
2024-07-14 05:09:04,510 [INFO    ] __main__: train step 2743: loss: 0.6086, policy_loss: 1.7451, value_loss: 0.9628
2024-07-14 05:09:04,782 [INFO    ] __main__: train step 2744: loss: 0.6088, policy_loss: 1.7450, value_loss: 0.9628
2024-07-14 05:09:05,068 [INFO    ] __main__: train step 2745: loss: 0.6089, policy_loss: 1.7449, value_loss: 0.9628
2024-07-14 05:09:05,343 [INFO    ] __main__: train step 2746: loss: 0.6091, policy_loss: 1.7448, value_loss: 0.9627
2024-07-14 05:09:05,615 [INFO    ] __main__: train step 2747: loss: 0.6092, policy_loss: 1.7446, value_loss: 0.9627
2024-07-14 05:09:05,889 [INFO    ] __main__: train step 2748: loss: 0.6094, policy_loss: 1.7445, value_loss: 0.9627
2024-07-14 05:09:06,160 [INFO    ] __main__: train step 2749: loss: 0.6095, policy_loss: 1.7444, value_loss: 0.9627
2024-07-14 05:09:06,797 [INFO    ] __main__: train step 2750: loss: 0.6097, policy_loss: 1.7442, value_loss: 0.9626
2024-07-14 05:09:08,395 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:09:08,875 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:09:08,947 [INFO    ] __main__: train step 2751: loss: 0.6098, policy_loss: 1.7441, value_loss: 0.9626
2024-07-14 05:09:09,223 [INFO    ] __main__: train step 2752: loss: 0.6100, policy_loss: 1.7440, value_loss: 0.9626
2024-07-14 05:09:09,503 [INFO    ] __main__: train step 2753: loss: 0.6101, policy_loss: 1.7439, value_loss: 0.9626
2024-07-14 05:09:09,771 [INFO    ] __main__: train step 2754: loss: 0.6103, policy_loss: 1.7438, value_loss: 0.9625
2024-07-14 05:09:10,055 [INFO    ] __main__: train step 2755: loss: 0.6104, policy_loss: 1.7436, value_loss: 0.9625
2024-07-14 05:09:10,338 [INFO    ] __main__: train step 2756: loss: 0.6106, policy_loss: 1.7435, value_loss: 0.9625
2024-07-14 05:09:10,616 [INFO    ] __main__: train step 2757: loss: 0.6107, policy_loss: 1.7434, value_loss: 0.9625
2024-07-14 05:09:10,905 [INFO    ] __main__: train step 2758: loss: 0.6109, policy_loss: 1.7433, value_loss: 0.9624
2024-07-14 05:09:11,171 [INFO    ] __main__: train step 2759: loss: 0.6110, policy_loss: 1.7432, value_loss: 0.9624
2024-07-14 05:09:11,450 [INFO    ] __main__: train step 2760: loss: 0.6112, policy_loss: 1.7430, value_loss: 0.9624
2024-07-14 05:09:11,738 [INFO    ] __main__: train step 2761: loss: 0.6113, policy_loss: 1.7429, value_loss: 0.9624
2024-07-14 05:09:12,024 [INFO    ] __main__: train step 2762: loss: 0.6115, policy_loss: 1.7428, value_loss: 0.9623
2024-07-14 05:09:12,304 [INFO    ] __main__: train step 2763: loss: 0.6116, policy_loss: 1.7427, value_loss: 0.9623
2024-07-14 05:09:12,578 [INFO    ] __main__: train step 2764: loss: 0.6118, policy_loss: 1.7425, value_loss: 0.9623
2024-07-14 05:09:12,861 [INFO    ] __main__: train step 2765: loss: 0.6119, policy_loss: 1.7424, value_loss: 0.9623
2024-07-14 05:09:13,145 [INFO    ] __main__: train step 2766: loss: 0.6121, policy_loss: 1.7423, value_loss: 0.9622
2024-07-14 05:09:13,422 [INFO    ] __main__: train step 2767: loss: 0.6122, policy_loss: 1.7422, value_loss: 0.9622
2024-07-14 05:09:15,013 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:09:15,490 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:09:15,557 [INFO    ] __main__: train step 2768: loss: 0.6124, policy_loss: 1.7420, value_loss: 0.9622
2024-07-14 05:09:16,190 [INFO    ] __main__: train step 2769: loss: 0.6125, policy_loss: 1.7419, value_loss: 0.9622
2024-07-14 05:09:16,464 [INFO    ] __main__: train step 2770: loss: 0.6127, policy_loss: 1.7418, value_loss: 0.9621
2024-07-14 05:09:16,740 [INFO    ] __main__: train step 2771: loss: 0.6128, policy_loss: 1.7417, value_loss: 0.9621
2024-07-14 05:09:17,008 [INFO    ] __main__: train step 2772: loss: 0.6130, policy_loss: 1.7416, value_loss: 0.9621
2024-07-14 05:09:17,294 [INFO    ] __main__: train step 2773: loss: 0.6131, policy_loss: 1.7414, value_loss: 0.9620
2024-07-14 05:09:17,560 [INFO    ] __main__: train step 2774: loss: 0.6133, policy_loss: 1.7413, value_loss: 0.9620
2024-07-14 05:09:17,840 [INFO    ] __main__: train step 2775: loss: 0.6134, policy_loss: 1.7412, value_loss: 0.9620
2024-07-14 05:09:18,126 [INFO    ] __main__: train step 2776: loss: 0.6136, policy_loss: 1.7411, value_loss: 0.9620
2024-07-14 05:09:18,442 [INFO    ] __main__: train step 2777: loss: 0.6137, policy_loss: 1.7410, value_loss: 0.9619
2024-07-14 05:09:18,719 [INFO    ] __main__: train step 2778: loss: 0.6139, policy_loss: 1.7408, value_loss: 0.9619
2024-07-14 05:09:18,998 [INFO    ] __main__: train step 2779: loss: 0.6140, policy_loss: 1.7407, value_loss: 0.9619
2024-07-14 05:09:19,261 [INFO    ] __main__: train step 2780: loss: 0.6141, policy_loss: 1.7406, value_loss: 0.9619
2024-07-14 05:09:19,528 [INFO    ] __main__: train step 2781: loss: 0.6143, policy_loss: 1.7405, value_loss: 0.9618
2024-07-14 05:09:19,803 [INFO    ] __main__: train step 2782: loss: 0.6144, policy_loss: 1.7403, value_loss: 0.9618
2024-07-14 05:09:20,085 [INFO    ] __main__: train step 2783: loss: 0.6146, policy_loss: 1.7402, value_loss: 0.9618
2024-07-14 05:09:20,357 [INFO    ] __main__: train step 2784: loss: 0.6147, policy_loss: 1.7401, value_loss: 0.9617
2024-07-14 05:09:21,946 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:09:22,419 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:09:22,485 [INFO    ] __main__: train step 2785: loss: 0.6149, policy_loss: 1.7399, value_loss: 0.9617
2024-07-14 05:09:22,765 [INFO    ] __main__: train step 2786: loss: 0.6150, policy_loss: 1.7398, value_loss: 0.9617
2024-07-14 05:09:23,024 [INFO    ] __main__: train step 2787: loss: 0.6152, policy_loss: 1.7397, value_loss: 0.9617
2024-07-14 05:09:23,295 [INFO    ] __main__: train step 2788: loss: 0.6153, policy_loss: 1.7396, value_loss: 0.9616
2024-07-14 05:09:23,959 [INFO    ] __main__: train step 2789: loss: 0.6155, policy_loss: 1.7395, value_loss: 0.9616
2024-07-14 05:09:24,236 [INFO    ] __main__: train step 2790: loss: 0.6156, policy_loss: 1.7393, value_loss: 0.9616
2024-07-14 05:09:24,501 [INFO    ] __main__: train step 2791: loss: 0.6158, policy_loss: 1.7392, value_loss: 0.9615
2024-07-14 05:09:24,784 [INFO    ] __main__: train step 2792: loss: 0.6159, policy_loss: 1.7391, value_loss: 0.9615
2024-07-14 05:09:25,072 [INFO    ] __main__: train step 2793: loss: 0.6161, policy_loss: 1.7390, value_loss: 0.9615
2024-07-14 05:09:25,356 [INFO    ] __main__: train step 2794: loss: 0.6162, policy_loss: 1.7388, value_loss: 0.9615
2024-07-14 05:09:25,626 [INFO    ] __main__: train step 2795: loss: 0.6164, policy_loss: 1.7387, value_loss: 0.9615
2024-07-14 05:09:25,899 [INFO    ] __main__: train step 2796: loss: 0.6165, policy_loss: 1.7386, value_loss: 0.9614
2024-07-14 05:09:26,171 [INFO    ] __main__: train step 2797: loss: 0.6167, policy_loss: 1.7385, value_loss: 0.9614
2024-07-14 05:09:26,444 [INFO    ] __main__: train step 2798: loss: 0.6168, policy_loss: 1.7383, value_loss: 0.9614
2024-07-14 05:09:26,723 [INFO    ] __main__: train step 2799: loss: 0.6170, policy_loss: 1.7382, value_loss: 0.9614
2024-07-14 05:09:27,002 [INFO    ] __main__: train step 2800: loss: 0.6171, policy_loss: 1.7381, value_loss: 0.9613
2024-07-14 05:09:27,277 [INFO    ] __main__: train step 2801: loss: 0.6173, policy_loss: 1.7380, value_loss: 0.9613
2024-07-14 05:09:28,858 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:09:29,328 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:09:29,391 [INFO    ] __main__: train step 2802: loss: 0.6174, policy_loss: 1.7379, value_loss: 0.9613
2024-07-14 05:09:29,670 [INFO    ] __main__: train step 2803: loss: 0.6176, policy_loss: 1.7377, value_loss: 0.9613
2024-07-14 05:09:29,947 [INFO    ] __main__: train step 2804: loss: 0.6177, policy_loss: 1.7376, value_loss: 0.9612
2024-07-14 05:09:30,224 [INFO    ] __main__: train step 2805: loss: 0.6179, policy_loss: 1.7375, value_loss: 0.9612
2024-07-14 05:09:30,501 [INFO    ] __main__: train step 2806: loss: 0.6180, policy_loss: 1.7374, value_loss: 0.9612
2024-07-14 05:09:30,773 [INFO    ] __main__: train step 2807: loss: 0.6182, policy_loss: 1.7372, value_loss: 0.9611
2024-07-14 05:09:31,047 [INFO    ] __main__: train step 2808: loss: 0.6183, policy_loss: 1.7371, value_loss: 0.9611
2024-07-14 05:09:31,698 [INFO    ] __main__: train step 2809: loss: 0.6185, policy_loss: 1.7370, value_loss: 0.9611
2024-07-14 05:09:31,966 [INFO    ] __main__: train step 2810: loss: 0.6186, policy_loss: 1.7369, value_loss: 0.9610
2024-07-14 05:09:32,233 [INFO    ] __main__: train step 2811: loss: 0.6188, policy_loss: 1.7367, value_loss: 0.9610
2024-07-14 05:09:32,511 [INFO    ] __main__: train step 2812: loss: 0.6189, policy_loss: 1.7366, value_loss: 0.9610
2024-07-14 05:09:32,785 [INFO    ] __main__: train step 2813: loss: 0.6190, policy_loss: 1.7365, value_loss: 0.9610
2024-07-14 05:09:33,059 [INFO    ] __main__: train step 2814: loss: 0.6192, policy_loss: 1.7364, value_loss: 0.9609
2024-07-14 05:09:33,337 [INFO    ] __main__: train step 2815: loss: 0.6193, policy_loss: 1.7362, value_loss: 0.9609
2024-07-14 05:09:33,608 [INFO    ] __main__: train step 2816: loss: 0.6195, policy_loss: 1.7361, value_loss: 0.9609
2024-07-14 05:09:33,887 [INFO    ] __main__: train step 2817: loss: 0.6196, policy_loss: 1.7360, value_loss: 0.9608
2024-07-14 05:09:34,158 [INFO    ] __main__: train step 2818: loss: 0.6198, policy_loss: 1.7359, value_loss: 0.9608
2024-07-14 05:09:35,733 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:09:36,208 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:09:36,277 [INFO    ] __main__: train step 2819: loss: 0.6199, policy_loss: 1.7357, value_loss: 0.9608
2024-07-14 05:09:36,555 [INFO    ] __main__: train step 2820: loss: 0.6201, policy_loss: 1.7356, value_loss: 0.9608
2024-07-14 05:09:36,822 [INFO    ] __main__: train step 2821: loss: 0.6202, policy_loss: 1.7355, value_loss: 0.9608
2024-07-14 05:09:37,089 [INFO    ] __main__: train step 2822: loss: 0.6204, policy_loss: 1.7354, value_loss: 0.9607
2024-07-14 05:09:37,356 [INFO    ] __main__: train step 2823: loss: 0.6205, policy_loss: 1.7353, value_loss: 0.9607
2024-07-14 05:09:37,624 [INFO    ] __main__: train step 2824: loss: 0.6207, policy_loss: 1.7351, value_loss: 0.9607
2024-07-14 05:09:37,891 [INFO    ] __main__: train step 2825: loss: 0.6208, policy_loss: 1.7350, value_loss: 0.9606
2024-07-14 05:09:38,166 [INFO    ] __main__: train step 2826: loss: 0.6210, policy_loss: 1.7349, value_loss: 0.9606
2024-07-14 05:09:38,441 [INFO    ] __main__: train step 2827: loss: 0.6211, policy_loss: 1.7348, value_loss: 0.9606
2024-07-14 05:09:39,071 [INFO    ] __main__: train step 2828: loss: 0.6212, policy_loss: 1.7346, value_loss: 0.9606
2024-07-14 05:09:39,339 [INFO    ] __main__: train step 2829: loss: 0.6214, policy_loss: 1.7345, value_loss: 0.9605
2024-07-14 05:09:39,617 [INFO    ] __main__: train step 2830: loss: 0.6215, policy_loss: 1.7344, value_loss: 0.9605
2024-07-14 05:09:39,896 [INFO    ] __main__: train step 2831: loss: 0.6217, policy_loss: 1.7343, value_loss: 0.9605
2024-07-14 05:09:40,165 [INFO    ] __main__: train step 2832: loss: 0.6218, policy_loss: 1.7341, value_loss: 0.9604
2024-07-14 05:09:40,438 [INFO    ] __main__: train step 2833: loss: 0.6220, policy_loss: 1.7340, value_loss: 0.9604
2024-07-14 05:09:40,701 [INFO    ] __main__: train step 2834: loss: 0.6221, policy_loss: 1.7339, value_loss: 0.9604
2024-07-14 05:09:40,971 [INFO    ] __main__: train step 2835: loss: 0.6223, policy_loss: 1.7338, value_loss: 0.9604
2024-07-14 05:09:42,546 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:09:43,005 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:09:43,074 [INFO    ] __main__: train step 2836: loss: 0.6224, policy_loss: 1.7336, value_loss: 0.9603
2024-07-14 05:09:43,340 [INFO    ] __main__: train step 2837: loss: 0.6226, policy_loss: 1.7335, value_loss: 0.9603
2024-07-14 05:09:43,621 [INFO    ] __main__: train step 2838: loss: 0.6228, policy_loss: 1.7334, value_loss: 0.9603
2024-07-14 05:09:43,894 [INFO    ] __main__: train step 2839: loss: 0.6229, policy_loss: 1.7333, value_loss: 0.9602
2024-07-14 05:09:44,167 [INFO    ] __main__: train step 2840: loss: 0.6230, policy_loss: 1.7331, value_loss: 0.9602
2024-07-14 05:09:44,446 [INFO    ] __main__: train step 2841: loss: 0.6232, policy_loss: 1.7330, value_loss: 0.9602
2024-07-14 05:09:44,713 [INFO    ] __main__: train step 2842: loss: 0.6233, policy_loss: 1.7329, value_loss: 0.9602
2024-07-14 05:09:44,978 [INFO    ] __main__: train step 2843: loss: 0.6235, policy_loss: 1.7328, value_loss: 0.9601
2024-07-14 05:09:45,251 [INFO    ] __main__: train step 2844: loss: 0.6236, policy_loss: 1.7326, value_loss: 0.9601
2024-07-14 05:09:45,529 [INFO    ] __main__: train step 2845: loss: 0.6238, policy_loss: 1.7325, value_loss: 0.9601
2024-07-14 05:09:45,807 [INFO    ] __main__: train step 2846: loss: 0.6239, policy_loss: 1.7324, value_loss: 0.9601
2024-07-14 05:09:46,077 [INFO    ] __main__: train step 2847: loss: 0.6241, policy_loss: 1.7323, value_loss: 0.9600
2024-07-14 05:09:46,853 [INFO    ] __main__: train step 2848: loss: 0.6242, policy_loss: 1.7321, value_loss: 0.9600
2024-07-14 05:09:47,117 [INFO    ] __main__: train step 2849: loss: 0.6244, policy_loss: 1.7320, value_loss: 0.9600
2024-07-14 05:09:47,391 [INFO    ] __main__: train step 2850: loss: 0.6245, policy_loss: 1.7319, value_loss: 0.9599
2024-07-14 05:09:47,681 [INFO    ] __main__: train step 2851: loss: 0.6247, policy_loss: 1.7318, value_loss: 0.9599
2024-07-14 05:09:47,957 [INFO    ] __main__: train step 2852: loss: 0.6248, policy_loss: 1.7316, value_loss: 0.9599
2024-07-14 05:09:49,546 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:09:50,024 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:09:50,088 [INFO    ] __main__: train step 2853: loss: 0.6250, policy_loss: 1.7315, value_loss: 0.9599
2024-07-14 05:09:50,358 [INFO    ] __main__: train step 2854: loss: 0.6251, policy_loss: 1.7314, value_loss: 0.9598
2024-07-14 05:09:50,640 [INFO    ] __main__: train step 2855: loss: 0.6253, policy_loss: 1.7313, value_loss: 0.9598
2024-07-14 05:09:50,905 [INFO    ] __main__: train step 2856: loss: 0.6254, policy_loss: 1.7312, value_loss: 0.9598
2024-07-14 05:09:51,174 [INFO    ] __main__: train step 2857: loss: 0.6256, policy_loss: 1.7310, value_loss: 0.9598
2024-07-14 05:09:51,440 [INFO    ] __main__: train step 2858: loss: 0.6257, policy_loss: 1.7309, value_loss: 0.9597
2024-07-14 05:09:51,709 [INFO    ] __main__: train step 2859: loss: 0.6259, policy_loss: 1.7308, value_loss: 0.9597
2024-07-14 05:09:51,994 [INFO    ] __main__: train step 2860: loss: 0.6260, policy_loss: 1.7307, value_loss: 0.9597
2024-07-14 05:09:52,264 [INFO    ] __main__: train step 2861: loss: 0.6262, policy_loss: 1.7305, value_loss: 0.9596
2024-07-14 05:09:52,544 [INFO    ] __main__: train step 2862: loss: 0.6263, policy_loss: 1.7304, value_loss: 0.9596
2024-07-14 05:09:52,833 [INFO    ] __main__: train step 2863: loss: 0.6265, policy_loss: 1.7303, value_loss: 0.9596
2024-07-14 05:09:53,111 [INFO    ] __main__: train step 2864: loss: 0.6266, policy_loss: 1.7302, value_loss: 0.9596
2024-07-14 05:09:53,386 [INFO    ] __main__: train step 2865: loss: 0.6267, policy_loss: 1.7300, value_loss: 0.9595
2024-07-14 05:09:53,657 [INFO    ] __main__: train step 2866: loss: 0.6269, policy_loss: 1.7299, value_loss: 0.9595
2024-07-14 05:09:54,521 [INFO    ] __main__: train step 2867: loss: 0.6270, policy_loss: 1.7298, value_loss: 0.9595
2024-07-14 05:09:54,802 [INFO    ] __main__: train step 2868: loss: 0.6272, policy_loss: 1.7297, value_loss: 0.9595
2024-07-14 05:09:55,092 [INFO    ] __main__: train step 2869: loss: 0.6273, policy_loss: 1.7295, value_loss: 0.9594
2024-07-14 05:09:56,679 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:09:57,137 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:09:57,204 [INFO    ] __main__: train step 2870: loss: 0.6275, policy_loss: 1.7294, value_loss: 0.9594
2024-07-14 05:09:57,457 [INFO    ] __main__: train step 2871: loss: 0.6276, policy_loss: 1.7293, value_loss: 0.9594
2024-07-14 05:09:57,715 [INFO    ] __main__: train step 2872: loss: 0.6278, policy_loss: 1.7292, value_loss: 0.9594
2024-07-14 05:09:57,992 [INFO    ] __main__: train step 2873: loss: 0.6279, policy_loss: 1.7290, value_loss: 0.9593
2024-07-14 05:09:58,264 [INFO    ] __main__: train step 2874: loss: 0.6281, policy_loss: 1.7289, value_loss: 0.9593
2024-07-14 05:09:58,542 [INFO    ] __main__: train step 2875: loss: 0.6282, policy_loss: 1.7288, value_loss: 0.9593
2024-07-14 05:09:58,819 [INFO    ] __main__: train step 2876: loss: 0.6284, policy_loss: 1.7287, value_loss: 0.9593
2024-07-14 05:09:59,091 [INFO    ] __main__: train step 2877: loss: 0.6285, policy_loss: 1.7285, value_loss: 0.9592
2024-07-14 05:09:59,369 [INFO    ] __main__: train step 2878: loss: 0.6287, policy_loss: 1.7284, value_loss: 0.9592
2024-07-14 05:09:59,650 [INFO    ] __main__: train step 2879: loss: 0.6288, policy_loss: 1.7283, value_loss: 0.9592
2024-07-14 05:09:59,923 [INFO    ] __main__: train step 2880: loss: 0.6290, policy_loss: 1.7282, value_loss: 0.9592
2024-07-14 05:10:00,204 [INFO    ] __main__: train step 2881: loss: 0.6291, policy_loss: 1.7281, value_loss: 0.9591
2024-07-14 05:10:00,470 [INFO    ] __main__: train step 2882: loss: 0.6293, policy_loss: 1.7279, value_loss: 0.9591
2024-07-14 05:10:00,739 [INFO    ] __main__: train step 2883: loss: 0.6294, policy_loss: 1.7278, value_loss: 0.9591
2024-07-14 05:10:01,019 [INFO    ] __main__: train step 2884: loss: 0.6296, policy_loss: 1.7277, value_loss: 0.9591
2024-07-14 05:10:01,277 [INFO    ] __main__: train step 2885: loss: 0.6297, policy_loss: 1.7276, value_loss: 0.9590
2024-07-14 05:10:01,517 [INFO    ] __main__: train step 2886: loss: 0.6298, policy_loss: 1.7274, value_loss: 0.9590
2024-07-14 05:10:03,628 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:10:04,090 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:10:04,160 [INFO    ] __main__: train step 2887: loss: 0.6300, policy_loss: 1.7273, value_loss: 0.9590
2024-07-14 05:10:04,450 [INFO    ] __main__: train step 2888: loss: 0.6301, policy_loss: 1.7272, value_loss: 0.9589
2024-07-14 05:10:04,719 [INFO    ] __main__: train step 2889: loss: 0.6303, policy_loss: 1.7271, value_loss: 0.9589
2024-07-14 05:10:04,983 [INFO    ] __main__: train step 2890: loss: 0.6304, policy_loss: 1.7269, value_loss: 0.9589
2024-07-14 05:10:05,251 [INFO    ] __main__: train step 2891: loss: 0.6306, policy_loss: 1.7268, value_loss: 0.9589
2024-07-14 05:10:05,526 [INFO    ] __main__: train step 2892: loss: 0.6307, policy_loss: 1.7267, value_loss: 0.9588
2024-07-14 05:10:05,804 [INFO    ] __main__: train step 2893: loss: 0.6309, policy_loss: 1.7266, value_loss: 0.9588
2024-07-14 05:10:06,076 [INFO    ] __main__: train step 2894: loss: 0.6310, policy_loss: 1.7264, value_loss: 0.9588
2024-07-14 05:10:06,358 [INFO    ] __main__: train step 2895: loss: 0.6312, policy_loss: 1.7263, value_loss: 0.9587
2024-07-14 05:10:06,635 [INFO    ] __main__: train step 2896: loss: 0.6313, policy_loss: 1.7262, value_loss: 0.9587
2024-07-14 05:10:06,921 [INFO    ] __main__: train step 2897: loss: 0.6315, policy_loss: 1.7261, value_loss: 0.9587
2024-07-14 05:10:07,210 [INFO    ] __main__: train step 2898: loss: 0.6316, policy_loss: 1.7259, value_loss: 0.9586
2024-07-14 05:10:07,481 [INFO    ] __main__: train step 2899: loss: 0.6318, policy_loss: 1.7258, value_loss: 0.9586
2024-07-14 05:10:07,775 [INFO    ] __main__: train step 2900: loss: 0.6319, policy_loss: 1.7257, value_loss: 0.9586
2024-07-14 05:10:08,073 [INFO    ] __main__: train step 2901: loss: 0.6321, policy_loss: 1.7256, value_loss: 0.9585
2024-07-14 05:10:08,351 [INFO    ] __main__: train step 2902: loss: 0.6322, policy_loss: 1.7254, value_loss: 0.9585
2024-07-14 05:10:08,626 [INFO    ] __main__: train step 2903: loss: 0.6323, policy_loss: 1.7253, value_loss: 0.9585
2024-07-14 05:10:10,237 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:10:10,718 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:10:10,783 [INFO    ] __main__: train step 2904: loss: 0.6325, policy_loss: 1.7252, value_loss: 0.9584
2024-07-14 05:10:11,060 [INFO    ] __main__: train step 2905: loss: 0.6326, policy_loss: 1.7251, value_loss: 0.9584
2024-07-14 05:10:11,326 [INFO    ] __main__: train step 2906: loss: 0.6328, policy_loss: 1.7249, value_loss: 0.9584
2024-07-14 05:10:11,941 [INFO    ] __main__: train step 2907: loss: 0.6329, policy_loss: 1.7248, value_loss: 0.9584
2024-07-14 05:10:12,231 [INFO    ] __main__: train step 2908: loss: 0.6331, policy_loss: 1.7247, value_loss: 0.9583
2024-07-14 05:10:12,506 [INFO    ] __main__: train step 2909: loss: 0.6332, policy_loss: 1.7246, value_loss: 0.9583
2024-07-14 05:10:12,785 [INFO    ] __main__: train step 2910: loss: 0.6334, policy_loss: 1.7244, value_loss: 0.9583
2024-07-14 05:10:13,066 [INFO    ] __main__: train step 2911: loss: 0.6335, policy_loss: 1.7243, value_loss: 0.9583
2024-07-14 05:10:13,337 [INFO    ] __main__: train step 2912: loss: 0.6336, policy_loss: 1.7242, value_loss: 0.9582
2024-07-14 05:10:13,619 [INFO    ] __main__: train step 2913: loss: 0.6338, policy_loss: 1.7241, value_loss: 0.9582
2024-07-14 05:10:13,901 [INFO    ] __main__: train step 2914: loss: 0.6339, policy_loss: 1.7239, value_loss: 0.9582
2024-07-14 05:10:14,172 [INFO    ] __main__: train step 2915: loss: 0.6341, policy_loss: 1.7238, value_loss: 0.9581
2024-07-14 05:10:14,444 [INFO    ] __main__: train step 2916: loss: 0.6342, policy_loss: 1.7237, value_loss: 0.9581
2024-07-14 05:10:14,728 [INFO    ] __main__: train step 2917: loss: 0.6344, policy_loss: 1.7236, value_loss: 0.9581
2024-07-14 05:10:15,002 [INFO    ] __main__: train step 2918: loss: 0.6345, policy_loss: 1.7234, value_loss: 0.9580
2024-07-14 05:10:15,263 [INFO    ] __main__: train step 2919: loss: 0.6347, policy_loss: 1.7233, value_loss: 0.9580
2024-07-14 05:10:15,536 [INFO    ] __main__: train step 2920: loss: 0.6348, policy_loss: 1.7232, value_loss: 0.9580
2024-07-14 05:10:17,133 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:10:17,602 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:10:17,673 [INFO    ] __main__: train step 2921: loss: 0.6350, policy_loss: 1.7231, value_loss: 0.9580
2024-07-14 05:10:17,946 [INFO    ] __main__: train step 2922: loss: 0.6351, policy_loss: 1.7229, value_loss: 0.9579
2024-07-14 05:10:18,225 [INFO    ] __main__: train step 2923: loss: 0.6353, policy_loss: 1.7228, value_loss: 0.9579
2024-07-14 05:10:18,498 [INFO    ] __main__: train step 2924: loss: 0.6354, policy_loss: 1.7227, value_loss: 0.9579
2024-07-14 05:10:18,770 [INFO    ] __main__: train step 2925: loss: 0.6355, policy_loss: 1.7226, value_loss: 0.9579
2024-07-14 05:10:19,429 [INFO    ] __main__: train step 2926: loss: 0.6357, policy_loss: 1.7225, value_loss: 0.9578
2024-07-14 05:10:19,712 [INFO    ] __main__: train step 2927: loss: 0.6358, policy_loss: 1.7223, value_loss: 0.9578
2024-07-14 05:10:19,982 [INFO    ] __main__: train step 2928: loss: 0.6360, policy_loss: 1.7222, value_loss: 0.9578
2024-07-14 05:10:20,260 [INFO    ] __main__: train step 2929: loss: 0.6361, policy_loss: 1.7221, value_loss: 0.9578
2024-07-14 05:10:20,519 [INFO    ] __main__: train step 2930: loss: 0.6363, policy_loss: 1.7220, value_loss: 0.9577
2024-07-14 05:10:20,799 [INFO    ] __main__: train step 2931: loss: 0.6364, policy_loss: 1.7218, value_loss: 0.9577
2024-07-14 05:10:21,076 [INFO    ] __main__: train step 2932: loss: 0.6366, policy_loss: 1.7217, value_loss: 0.9577
2024-07-14 05:10:21,349 [INFO    ] __main__: train step 2933: loss: 0.6367, policy_loss: 1.7216, value_loss: 0.9577
2024-07-14 05:10:21,632 [INFO    ] __main__: train step 2934: loss: 0.6369, policy_loss: 1.7215, value_loss: 0.9576
2024-07-14 05:10:21,908 [INFO    ] __main__: train step 2935: loss: 0.6370, policy_loss: 1.7213, value_loss: 0.9576
2024-07-14 05:10:22,183 [INFO    ] __main__: train step 2936: loss: 0.6372, policy_loss: 1.7212, value_loss: 0.9576
2024-07-14 05:10:22,444 [INFO    ] __main__: train step 2937: loss: 0.6373, policy_loss: 1.7211, value_loss: 0.9575
2024-07-14 05:10:24,046 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:10:24,515 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:10:24,588 [INFO    ] __main__: train step 2938: loss: 0.6375, policy_loss: 1.7210, value_loss: 0.9575
2024-07-14 05:10:24,872 [INFO    ] __main__: train step 2939: loss: 0.6376, policy_loss: 1.7209, value_loss: 0.9575
2024-07-14 05:10:25,151 [INFO    ] __main__: train step 2940: loss: 0.6377, policy_loss: 1.7207, value_loss: 0.9575
2024-07-14 05:10:25,434 [INFO    ] __main__: train step 2941: loss: 0.6379, policy_loss: 1.7206, value_loss: 0.9574
2024-07-14 05:10:25,706 [INFO    ] __main__: train step 2942: loss: 0.6380, policy_loss: 1.7205, value_loss: 0.9574
2024-07-14 05:10:25,980 [INFO    ] __main__: train step 2943: loss: 0.6382, policy_loss: 1.7204, value_loss: 0.9574
2024-07-14 05:10:26,264 [INFO    ] __main__: train step 2944: loss: 0.6383, policy_loss: 1.7202, value_loss: 0.9574
2024-07-14 05:10:26,885 [INFO    ] __main__: train step 2945: loss: 0.6385, policy_loss: 1.7201, value_loss: 0.9573
2024-07-14 05:10:27,161 [INFO    ] __main__: train step 2946: loss: 0.6386, policy_loss: 1.7200, value_loss: 0.9573
2024-07-14 05:10:27,432 [INFO    ] __main__: train step 2947: loss: 0.6388, policy_loss: 1.7199, value_loss: 0.9573
2024-07-14 05:10:27,701 [INFO    ] __main__: train step 2948: loss: 0.6389, policy_loss: 1.7197, value_loss: 0.9572
2024-07-14 05:10:27,991 [INFO    ] __main__: train step 2949: loss: 0.6390, policy_loss: 1.7196, value_loss: 0.9572
2024-07-14 05:10:28,269 [INFO    ] __main__: train step 2950: loss: 0.6392, policy_loss: 1.7195, value_loss: 0.9572
2024-07-14 05:10:28,541 [INFO    ] __main__: train step 2951: loss: 0.6393, policy_loss: 1.7194, value_loss: 0.9571
2024-07-14 05:10:28,829 [INFO    ] __main__: train step 2952: loss: 0.6395, policy_loss: 1.7192, value_loss: 0.9571
2024-07-14 05:10:29,101 [INFO    ] __main__: train step 2953: loss: 0.6396, policy_loss: 1.7191, value_loss: 0.9571
2024-07-14 05:10:29,380 [INFO    ] __main__: train step 2954: loss: 0.6398, policy_loss: 1.7190, value_loss: 0.9570
2024-07-14 05:10:30,972 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:10:31,454 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:10:31,527 [INFO    ] __main__: train step 2955: loss: 0.6399, policy_loss: 1.7189, value_loss: 0.9570
2024-07-14 05:10:31,812 [INFO    ] __main__: train step 2956: loss: 0.6401, policy_loss: 1.7188, value_loss: 0.9570
2024-07-14 05:10:32,086 [INFO    ] __main__: train step 2957: loss: 0.6402, policy_loss: 1.7186, value_loss: 0.9569
2024-07-14 05:10:32,354 [INFO    ] __main__: train step 2958: loss: 0.6404, policy_loss: 1.7185, value_loss: 0.9569
2024-07-14 05:10:32,650 [INFO    ] __main__: train step 2959: loss: 0.6405, policy_loss: 1.7184, value_loss: 0.9569
2024-07-14 05:10:32,963 [INFO    ] __main__: train step 2960: loss: 0.6406, policy_loss: 1.7183, value_loss: 0.9568
2024-07-14 05:10:33,240 [INFO    ] __main__: train step 2961: loss: 0.6408, policy_loss: 1.7182, value_loss: 0.9568
2024-07-14 05:10:33,559 [INFO    ] __main__: train step 2962: loss: 0.6409, policy_loss: 1.7180, value_loss: 0.9568
2024-07-14 05:10:33,858 [INFO    ] __main__: train step 2963: loss: 0.6411, policy_loss: 1.7179, value_loss: 0.9568
2024-07-14 05:10:35,152 [INFO    ] __main__: train step 2964: loss: 0.6412, policy_loss: 1.7178, value_loss: 0.9567
2024-07-14 05:10:35,462 [INFO    ] __main__: train step 2965: loss: 0.6414, policy_loss: 1.7177, value_loss: 0.9567
2024-07-14 05:10:35,770 [INFO    ] __main__: train step 2966: loss: 0.6415, policy_loss: 1.7175, value_loss: 0.9567
2024-07-14 05:10:36,065 [INFO    ] __main__: train step 2967: loss: 0.6417, policy_loss: 1.7174, value_loss: 0.9566
2024-07-14 05:10:36,372 [INFO    ] __main__: train step 2968: loss: 0.6418, policy_loss: 1.7173, value_loss: 0.9566
2024-07-14 05:10:36,682 [INFO    ] __main__: train step 2969: loss: 0.6420, policy_loss: 1.7172, value_loss: 0.9566
2024-07-14 05:10:36,989 [INFO    ] __main__: train step 2970: loss: 0.6421, policy_loss: 1.7171, value_loss: 0.9565
2024-07-14 05:10:37,298 [INFO    ] __main__: train step 2971: loss: 0.6422, policy_loss: 1.7169, value_loss: 0.9565
2024-07-14 05:10:38,942 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:10:39,443 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:10:39,518 [INFO    ] __main__: train step 2972: loss: 0.6424, policy_loss: 1.7168, value_loss: 0.9565
2024-07-14 05:10:39,807 [INFO    ] __main__: train step 2973: loss: 0.6425, policy_loss: 1.7167, value_loss: 0.9565
2024-07-14 05:10:40,092 [INFO    ] __main__: train step 2974: loss: 0.6427, policy_loss: 1.7166, value_loss: 0.9564
2024-07-14 05:10:40,381 [INFO    ] __main__: train step 2975: loss: 0.6428, policy_loss: 1.7165, value_loss: 0.9564
2024-07-14 05:10:40,661 [INFO    ] __main__: train step 2976: loss: 0.6430, policy_loss: 1.7163, value_loss: 0.9564
2024-07-14 05:10:40,938 [INFO    ] __main__: train step 2977: loss: 0.6431, policy_loss: 1.7162, value_loss: 0.9563
2024-07-14 05:10:41,217 [INFO    ] __main__: train step 2978: loss: 0.6432, policy_loss: 1.7161, value_loss: 0.9563
2024-07-14 05:10:41,520 [INFO    ] __main__: train step 2979: loss: 0.6434, policy_loss: 1.7160, value_loss: 0.9563
2024-07-14 05:10:41,804 [INFO    ] __main__: train step 2980: loss: 0.6435, policy_loss: 1.7159, value_loss: 0.9563
2024-07-14 05:10:42,088 [INFO    ] __main__: train step 2981: loss: 0.6437, policy_loss: 1.7157, value_loss: 0.9562
2024-07-14 05:10:42,370 [INFO    ] __main__: train step 2982: loss: 0.6438, policy_loss: 1.7156, value_loss: 0.9562
2024-07-14 05:10:42,647 [INFO    ] __main__: train step 2983: loss: 0.6439, policy_loss: 1.7155, value_loss: 0.9562
2024-07-14 05:10:43,533 [INFO    ] __main__: train step 2984: loss: 0.6441, policy_loss: 1.7154, value_loss: 0.9561
2024-07-14 05:10:43,817 [INFO    ] __main__: train step 2985: loss: 0.6442, policy_loss: 1.7153, value_loss: 0.9561
2024-07-14 05:10:44,102 [INFO    ] __main__: train step 2986: loss: 0.6444, policy_loss: 1.7151, value_loss: 0.9561
2024-07-14 05:10:44,381 [INFO    ] __main__: train step 2987: loss: 0.6445, policy_loss: 1.7150, value_loss: 0.9560
2024-07-14 05:10:44,652 [INFO    ] __main__: train step 2988: loss: 0.6447, policy_loss: 1.7149, value_loss: 0.9560
2024-07-14 05:10:46,227 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:10:46,704 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:10:46,774 [INFO    ] __main__: train step 2989: loss: 0.6448, policy_loss: 1.7148, value_loss: 0.9560
2024-07-14 05:10:47,045 [INFO    ] __main__: train step 2990: loss: 0.6450, policy_loss: 1.7147, value_loss: 0.9559
2024-07-14 05:10:47,328 [INFO    ] __main__: train step 2991: loss: 0.6451, policy_loss: 1.7145, value_loss: 0.9559
2024-07-14 05:10:47,608 [INFO    ] __main__: train step 2992: loss: 0.6452, policy_loss: 1.7144, value_loss: 0.9559
2024-07-14 05:10:47,892 [INFO    ] __main__: train step 2993: loss: 0.6454, policy_loss: 1.7143, value_loss: 0.9559
2024-07-14 05:10:48,163 [INFO    ] __main__: train step 2994: loss: 0.6455, policy_loss: 1.7142, value_loss: 0.9558
2024-07-14 05:10:48,468 [INFO    ] __main__: train step 2995: loss: 0.6457, policy_loss: 1.7140, value_loss: 0.9558
2024-07-14 05:10:48,742 [INFO    ] __main__: train step 2996: loss: 0.6458, policy_loss: 1.7139, value_loss: 0.9558
2024-07-14 05:10:49,031 [INFO    ] __main__: train step 2997: loss: 0.6460, policy_loss: 1.7138, value_loss: 0.9557
2024-07-14 05:10:49,317 [INFO    ] __main__: train step 2998: loss: 0.6461, policy_loss: 1.7137, value_loss: 0.9557
2024-07-14 05:10:49,593 [INFO    ] __main__: train step 2999: loss: 0.6462, policy_loss: 1.7135, value_loss: 0.9557
2024-07-14 05:10:49,863 [INFO    ] __main__: train step 3000: loss: 0.6464, policy_loss: 1.7134, value_loss: 0.9556
2024-07-14 05:10:50,028 [INFO    ] __main__: restored step 2000 for evaluation
2024-07-14 05:10:55,282 [INFO    ] __main__: test network ELO difference from baseline network: +284 (+8/-8) ELO from 32000 self-played games
2024-07-14 05:10:55,285 [INFO    ] __main__: game outcomes: W: 25460, D: 137, L: 6403
2024-07-14 05:10:55,287 [INFO    ] __main__: validation_elo_delta: 284, validation_elo: 856
2024-07-14 05:10:56,022 [INFO    ] __main__: train step 3001: loss: 0.6465, policy_loss: 1.7133, value_loss: 0.9556
2024-07-14 05:10:56,895 [INFO    ] __main__: train step 3002: loss: 0.6467, policy_loss: 1.7132, value_loss: 0.9556
2024-07-14 05:10:57,172 [INFO    ] __main__: train step 3003: loss: 0.6468, policy_loss: 1.7131, value_loss: 0.9555
2024-07-14 05:10:57,449 [INFO    ] __main__: train step 3004: loss: 0.6469, policy_loss: 1.7129, value_loss: 0.9555
2024-07-14 05:10:57,729 [INFO    ] __main__: train step 3005: loss: 0.6471, policy_loss: 1.7128, value_loss: 0.9555
2024-07-14 05:10:59,316 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:10:59,784 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:10:59,854 [INFO    ] __main__: train step 3006: loss: 0.6472, policy_loss: 1.7127, value_loss: 0.9554
2024-07-14 05:11:00,110 [INFO    ] __main__: train step 3007: loss: 0.6474, policy_loss: 1.7126, value_loss: 0.9554
2024-07-14 05:11:00,365 [INFO    ] __main__: train step 3008: loss: 0.6475, policy_loss: 1.7124, value_loss: 0.9554
2024-07-14 05:11:00,635 [INFO    ] __main__: train step 3009: loss: 0.6476, policy_loss: 1.7123, value_loss: 0.9553
2024-07-14 05:11:00,916 [INFO    ] __main__: train step 3010: loss: 0.6478, policy_loss: 1.7122, value_loss: 0.9553
2024-07-14 05:11:01,192 [INFO    ] __main__: train step 3011: loss: 0.6479, policy_loss: 1.7121, value_loss: 0.9553
2024-07-14 05:11:01,465 [INFO    ] __main__: train step 3012: loss: 0.6481, policy_loss: 1.7120, value_loss: 0.9553
2024-07-14 05:11:01,747 [INFO    ] __main__: train step 3013: loss: 0.6482, policy_loss: 1.7118, value_loss: 0.9552
2024-07-14 05:11:02,023 [INFO    ] __main__: train step 3014: loss: 0.6483, policy_loss: 1.7117, value_loss: 0.9552
2024-07-14 05:11:02,293 [INFO    ] __main__: train step 3015: loss: 0.6485, policy_loss: 1.7116, value_loss: 0.9551
2024-07-14 05:11:02,570 [INFO    ] __main__: train step 3016: loss: 0.6486, policy_loss: 1.7115, value_loss: 0.9551
2024-07-14 05:11:02,840 [INFO    ] __main__: train step 3017: loss: 0.6488, policy_loss: 1.7114, value_loss: 0.9551
2024-07-14 05:11:03,118 [INFO    ] __main__: train step 3018: loss: 0.6489, policy_loss: 1.7112, value_loss: 0.9551
2024-07-14 05:11:03,394 [INFO    ] __main__: train step 3019: loss: 0.6491, policy_loss: 1.7111, value_loss: 0.9550
2024-07-14 05:11:03,655 [INFO    ] __main__: train step 3020: loss: 0.6492, policy_loss: 1.7110, value_loss: 0.9550
2024-07-14 05:11:03,931 [INFO    ] __main__: train step 3021: loss: 0.6494, policy_loss: 1.7109, value_loss: 0.9550
2024-07-14 05:11:04,564 [INFO    ] __main__: train step 3022: loss: 0.6495, policy_loss: 1.7107, value_loss: 0.9549
2024-07-14 05:11:06,161 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:11:06,645 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:11:06,713 [INFO    ] __main__: train step 3023: loss: 0.6496, policy_loss: 1.7106, value_loss: 0.9549
2024-07-14 05:11:06,970 [INFO    ] __main__: train step 3024: loss: 0.6498, policy_loss: 1.7105, value_loss: 0.9549
2024-07-14 05:11:07,241 [INFO    ] __main__: train step 3025: loss: 0.6499, policy_loss: 1.7104, value_loss: 0.9548
2024-07-14 05:11:07,518 [INFO    ] __main__: train step 3026: loss: 0.6500, policy_loss: 1.7103, value_loss: 0.9548
2024-07-14 05:11:07,798 [INFO    ] __main__: train step 3027: loss: 0.6502, policy_loss: 1.7101, value_loss: 0.9548
2024-07-14 05:11:08,079 [INFO    ] __main__: train step 3028: loss: 0.6503, policy_loss: 1.7100, value_loss: 0.9547
2024-07-14 05:11:08,357 [INFO    ] __main__: train step 3029: loss: 0.6505, policy_loss: 1.7099, value_loss: 0.9547
2024-07-14 05:11:08,609 [INFO    ] __main__: train step 3030: loss: 0.6506, policy_loss: 1.7098, value_loss: 0.9547
2024-07-14 05:11:08,873 [INFO    ] __main__: train step 3031: loss: 0.6508, policy_loss: 1.7096, value_loss: 0.9546
2024-07-14 05:11:09,163 [INFO    ] __main__: train step 3032: loss: 0.6509, policy_loss: 1.7095, value_loss: 0.9546
2024-07-14 05:11:09,439 [INFO    ] __main__: train step 3033: loss: 0.6511, policy_loss: 1.7094, value_loss: 0.9546
2024-07-14 05:11:09,707 [INFO    ] __main__: train step 3034: loss: 0.6512, policy_loss: 1.7093, value_loss: 0.9545
2024-07-14 05:11:09,988 [INFO    ] __main__: train step 3035: loss: 0.6513, policy_loss: 1.7092, value_loss: 0.9545
2024-07-14 05:11:10,264 [INFO    ] __main__: train step 3036: loss: 0.6515, policy_loss: 1.7090, value_loss: 0.9545
2024-07-14 05:11:10,547 [INFO    ] __main__: train step 3037: loss: 0.6516, policy_loss: 1.7089, value_loss: 0.9544
2024-07-14 05:11:10,824 [INFO    ] __main__: train step 3038: loss: 0.6518, policy_loss: 1.7088, value_loss: 0.9544
2024-07-14 05:11:11,119 [INFO    ] __main__: train step 3039: loss: 0.6519, policy_loss: 1.7087, value_loss: 0.9544
2024-07-14 05:11:12,720 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:11:13,201 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:11:13,275 [INFO    ] __main__: train step 3040: loss: 0.6520, policy_loss: 1.7085, value_loss: 0.9544
2024-07-14 05:11:14,118 [INFO    ] __main__: train step 3041: loss: 0.6522, policy_loss: 1.7084, value_loss: 0.9543
2024-07-14 05:11:14,395 [INFO    ] __main__: train step 3042: loss: 0.6523, policy_loss: 1.7083, value_loss: 0.9543
2024-07-14 05:11:14,667 [INFO    ] __main__: train step 3043: loss: 0.6525, policy_loss: 1.7082, value_loss: 0.9543
2024-07-14 05:11:14,948 [INFO    ] __main__: train step 3044: loss: 0.6526, policy_loss: 1.7081, value_loss: 0.9542
2024-07-14 05:11:15,229 [INFO    ] __main__: train step 3045: loss: 0.6528, policy_loss: 1.7079, value_loss: 0.9542
2024-07-14 05:11:15,509 [INFO    ] __main__: train step 3046: loss: 0.6529, policy_loss: 1.7078, value_loss: 0.9541
2024-07-14 05:11:15,792 [INFO    ] __main__: train step 3047: loss: 0.6531, policy_loss: 1.7077, value_loss: 0.9541
2024-07-14 05:11:16,076 [INFO    ] __main__: train step 3048: loss: 0.6532, policy_loss: 1.7076, value_loss: 0.9541
2024-07-14 05:11:16,352 [INFO    ] __main__: train step 3049: loss: 0.6534, policy_loss: 1.7075, value_loss: 0.9540
2024-07-14 05:11:16,628 [INFO    ] __main__: train step 3050: loss: 0.6535, policy_loss: 1.7073, value_loss: 0.9540
2024-07-14 05:11:16,924 [INFO    ] __main__: train step 3051: loss: 0.6536, policy_loss: 1.7072, value_loss: 0.9540
2024-07-14 05:11:17,200 [INFO    ] __main__: train step 3052: loss: 0.6538, policy_loss: 1.7071, value_loss: 0.9539
2024-07-14 05:11:17,479 [INFO    ] __main__: train step 3053: loss: 0.6539, policy_loss: 1.7070, value_loss: 0.9539
2024-07-14 05:11:17,766 [INFO    ] __main__: train step 3054: loss: 0.6540, policy_loss: 1.7068, value_loss: 0.9539
2024-07-14 05:11:18,053 [INFO    ] __main__: train step 3055: loss: 0.6542, policy_loss: 1.7067, value_loss: 0.9538
2024-07-14 05:11:18,331 [INFO    ] __main__: train step 3056: loss: 0.6543, policy_loss: 1.7066, value_loss: 0.9538
2024-07-14 05:11:19,923 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:11:20,382 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:11:20,448 [INFO    ] __main__: train step 3057: loss: 0.6545, policy_loss: 1.7065, value_loss: 0.9538
2024-07-14 05:11:20,722 [INFO    ] __main__: train step 3058: loss: 0.6546, policy_loss: 1.7064, value_loss: 0.9538
2024-07-14 05:11:20,986 [INFO    ] __main__: train step 3059: loss: 0.6548, policy_loss: 1.7063, value_loss: 0.9537
2024-07-14 05:11:21,249 [INFO    ] __main__: train step 3060: loss: 0.6549, policy_loss: 1.7061, value_loss: 0.9537
2024-07-14 05:11:22,112 [INFO    ] __main__: train step 3061: loss: 0.6551, policy_loss: 1.7060, value_loss: 0.9537
2024-07-14 05:11:22,409 [INFO    ] __main__: train step 3062: loss: 0.6552, policy_loss: 1.7059, value_loss: 0.9536
2024-07-14 05:11:22,669 [INFO    ] __main__: train step 3063: loss: 0.6553, policy_loss: 1.7058, value_loss: 0.9536
2024-07-14 05:11:22,944 [INFO    ] __main__: train step 3064: loss: 0.6555, policy_loss: 1.7056, value_loss: 0.9536
2024-07-14 05:11:23,217 [INFO    ] __main__: train step 3065: loss: 0.6556, policy_loss: 1.7055, value_loss: 0.9536
2024-07-14 05:11:23,497 [INFO    ] __main__: train step 3066: loss: 0.6557, policy_loss: 1.7054, value_loss: 0.9535
2024-07-14 05:11:23,766 [INFO    ] __main__: train step 3067: loss: 0.6559, policy_loss: 1.7053, value_loss: 0.9535
2024-07-14 05:11:24,041 [INFO    ] __main__: train step 3068: loss: 0.6560, policy_loss: 1.7052, value_loss: 0.9535
2024-07-14 05:11:24,317 [INFO    ] __main__: train step 3069: loss: 0.6562, policy_loss: 1.7050, value_loss: 0.9534
2024-07-14 05:11:24,599 [INFO    ] __main__: train step 3070: loss: 0.6563, policy_loss: 1.7049, value_loss: 0.9534
2024-07-14 05:11:24,873 [INFO    ] __main__: train step 3071: loss: 0.6565, policy_loss: 1.7048, value_loss: 0.9534
2024-07-14 05:11:25,150 [INFO    ] __main__: train step 3072: loss: 0.6566, policy_loss: 1.7047, value_loss: 0.9533
2024-07-14 05:11:25,418 [INFO    ] __main__: train step 3073: loss: 0.6567, policy_loss: 1.7046, value_loss: 0.9533
2024-07-14 05:11:26,997 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:11:27,480 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:11:27,548 [INFO    ] __main__: train step 3074: loss: 0.6569, policy_loss: 1.7044, value_loss: 0.9533
2024-07-14 05:11:27,809 [INFO    ] __main__: train step 3075: loss: 0.6570, policy_loss: 1.7043, value_loss: 0.9532
2024-07-14 05:11:28,074 [INFO    ] __main__: train step 3076: loss: 0.6572, policy_loss: 1.7042, value_loss: 0.9532
2024-07-14 05:11:28,336 [INFO    ] __main__: train step 3077: loss: 0.6573, policy_loss: 1.7041, value_loss: 0.9532
2024-07-14 05:11:28,611 [INFO    ] __main__: train step 3078: loss: 0.6574, policy_loss: 1.7040, value_loss: 0.9531
2024-07-14 05:11:28,898 [INFO    ] __main__: train step 3079: loss: 0.6576, policy_loss: 1.7039, value_loss: 0.9531
2024-07-14 05:11:29,757 [INFO    ] __main__: train step 3080: loss: 0.6577, policy_loss: 1.7037, value_loss: 0.9531
2024-07-14 05:11:30,046 [INFO    ] __main__: train step 3081: loss: 0.6579, policy_loss: 1.7036, value_loss: 0.9531
2024-07-14 05:11:30,316 [INFO    ] __main__: train step 3082: loss: 0.6580, policy_loss: 1.7035, value_loss: 0.9530
2024-07-14 05:11:30,604 [INFO    ] __main__: train step 3083: loss: 0.6582, policy_loss: 1.7034, value_loss: 0.9530
2024-07-14 05:11:30,884 [INFO    ] __main__: train step 3084: loss: 0.6583, policy_loss: 1.7033, value_loss: 0.9530
2024-07-14 05:11:31,157 [INFO    ] __main__: train step 3085: loss: 0.6585, policy_loss: 1.7032, value_loss: 0.9529
2024-07-14 05:11:31,424 [INFO    ] __main__: train step 3086: loss: 0.6586, policy_loss: 1.7030, value_loss: 0.9529
2024-07-14 05:11:31,677 [INFO    ] __main__: train step 3087: loss: 0.6587, policy_loss: 1.7029, value_loss: 0.9529
2024-07-14 05:11:31,946 [INFO    ] __main__: train step 3088: loss: 0.6589, policy_loss: 1.7028, value_loss: 0.9528
2024-07-14 05:11:32,218 [INFO    ] __main__: train step 3089: loss: 0.6590, policy_loss: 1.7027, value_loss: 0.9528
2024-07-14 05:11:32,481 [INFO    ] __main__: train step 3090: loss: 0.6592, policy_loss: 1.7026, value_loss: 0.9528
2024-07-14 05:11:34,069 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:11:34,544 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:11:34,615 [INFO    ] __main__: train step 3091: loss: 0.6593, policy_loss: 1.7025, value_loss: 0.9527
2024-07-14 05:11:34,874 [INFO    ] __main__: train step 3092: loss: 0.6594, policy_loss: 1.7023, value_loss: 0.9527
2024-07-14 05:11:35,154 [INFO    ] __main__: train step 3093: loss: 0.6596, policy_loss: 1.7022, value_loss: 0.9527
2024-07-14 05:11:35,431 [INFO    ] __main__: train step 3094: loss: 0.6597, policy_loss: 1.7021, value_loss: 0.9527
2024-07-14 05:11:35,695 [INFO    ] __main__: train step 3095: loss: 0.6599, policy_loss: 1.7020, value_loss: 0.9526
2024-07-14 05:11:35,975 [INFO    ] __main__: train step 3096: loss: 0.6600, policy_loss: 1.7019, value_loss: 0.9526
2024-07-14 05:11:36,253 [INFO    ] __main__: train step 3097: loss: 0.6602, policy_loss: 1.7017, value_loss: 0.9526
2024-07-14 05:11:36,526 [INFO    ] __main__: train step 3098: loss: 0.6603, policy_loss: 1.7016, value_loss: 0.9525
2024-07-14 05:11:37,372 [INFO    ] __main__: train step 3099: loss: 0.6605, policy_loss: 1.7015, value_loss: 0.9525
2024-07-14 05:11:37,632 [INFO    ] __main__: train step 3100: loss: 0.6606, policy_loss: 1.7014, value_loss: 0.9525
2024-07-14 05:11:37,911 [INFO    ] __main__: train step 3101: loss: 0.6608, policy_loss: 1.7013, value_loss: 0.9524
2024-07-14 05:11:38,187 [INFO    ] __main__: train step 3102: loss: 0.6609, policy_loss: 1.7011, value_loss: 0.9524
2024-07-14 05:11:38,459 [INFO    ] __main__: train step 3103: loss: 0.6610, policy_loss: 1.7010, value_loss: 0.9524
2024-07-14 05:11:38,731 [INFO    ] __main__: train step 3104: loss: 0.6612, policy_loss: 1.7009, value_loss: 0.9523
2024-07-14 05:11:39,003 [INFO    ] __main__: train step 3105: loss: 0.6613, policy_loss: 1.7008, value_loss: 0.9523
2024-07-14 05:11:39,282 [INFO    ] __main__: train step 3106: loss: 0.6615, policy_loss: 1.7007, value_loss: 0.9523
2024-07-14 05:11:39,546 [INFO    ] __main__: train step 3107: loss: 0.6616, policy_loss: 1.7006, value_loss: 0.9523
2024-07-14 05:11:41,135 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:11:41,614 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:11:41,679 [INFO    ] __main__: train step 3108: loss: 0.6617, policy_loss: 1.7004, value_loss: 0.9522
2024-07-14 05:11:41,954 [INFO    ] __main__: train step 3109: loss: 0.6619, policy_loss: 1.7003, value_loss: 0.9522
2024-07-14 05:11:42,221 [INFO    ] __main__: train step 3110: loss: 0.6620, policy_loss: 1.7002, value_loss: 0.9522
2024-07-14 05:11:42,503 [INFO    ] __main__: train step 3111: loss: 0.6622, policy_loss: 1.7001, value_loss: 0.9521
2024-07-14 05:11:42,785 [INFO    ] __main__: train step 3112: loss: 0.6623, policy_loss: 1.7000, value_loss: 0.9521
2024-07-14 05:11:43,054 [INFO    ] __main__: train step 3113: loss: 0.6625, policy_loss: 1.6998, value_loss: 0.9521
2024-07-14 05:11:43,323 [INFO    ] __main__: train step 3114: loss: 0.6626, policy_loss: 1.6997, value_loss: 0.9521
2024-07-14 05:11:43,596 [INFO    ] __main__: train step 3115: loss: 0.6627, policy_loss: 1.6996, value_loss: 0.9520
2024-07-14 05:11:43,876 [INFO    ] __main__: train step 3116: loss: 0.6629, policy_loss: 1.6995, value_loss: 0.9520
2024-07-14 05:11:44,146 [INFO    ] __main__: train step 3117: loss: 0.6630, policy_loss: 1.6994, value_loss: 0.9520
2024-07-14 05:11:44,423 [INFO    ] __main__: train step 3118: loss: 0.6632, policy_loss: 1.6992, value_loss: 0.9519
2024-07-14 05:11:45,057 [INFO    ] __main__: train step 3119: loss: 0.6633, policy_loss: 1.6991, value_loss: 0.9519
2024-07-14 05:11:45,335 [INFO    ] __main__: train step 3120: loss: 0.6635, policy_loss: 1.6990, value_loss: 0.9519
2024-07-14 05:11:45,608 [INFO    ] __main__: train step 3121: loss: 0.6636, policy_loss: 1.6989, value_loss: 0.9518
2024-07-14 05:11:45,890 [INFO    ] __main__: train step 3122: loss: 0.6637, policy_loss: 1.6988, value_loss: 0.9518
2024-07-14 05:11:46,173 [INFO    ] __main__: train step 3123: loss: 0.6639, policy_loss: 1.6987, value_loss: 0.9518
2024-07-14 05:11:46,455 [INFO    ] __main__: train step 3124: loss: 0.6640, policy_loss: 1.6985, value_loss: 0.9517
2024-07-14 05:11:48,059 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:11:48,554 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:11:48,629 [INFO    ] __main__: train step 3125: loss: 0.6642, policy_loss: 1.6984, value_loss: 0.9517
2024-07-14 05:11:48,909 [INFO    ] __main__: train step 3126: loss: 0.6643, policy_loss: 1.6983, value_loss: 0.9517
2024-07-14 05:11:49,178 [INFO    ] __main__: train step 3127: loss: 0.6645, policy_loss: 1.6982, value_loss: 0.9516
2024-07-14 05:11:49,451 [INFO    ] __main__: train step 3128: loss: 0.6646, policy_loss: 1.6981, value_loss: 0.9516
2024-07-14 05:11:49,732 [INFO    ] __main__: train step 3129: loss: 0.6648, policy_loss: 1.6979, value_loss: 0.9516
2024-07-14 05:11:50,004 [INFO    ] __main__: train step 3130: loss: 0.6649, policy_loss: 1.6978, value_loss: 0.9515
2024-07-14 05:11:50,278 [INFO    ] __main__: train step 3131: loss: 0.6650, policy_loss: 1.6977, value_loss: 0.9515
2024-07-14 05:11:50,583 [INFO    ] __main__: train step 3132: loss: 0.6652, policy_loss: 1.6976, value_loss: 0.9515
2024-07-14 05:11:50,869 [INFO    ] __main__: train step 3133: loss: 0.6653, policy_loss: 1.6975, value_loss: 0.9515
2024-07-14 05:11:51,145 [INFO    ] __main__: train step 3134: loss: 0.6655, policy_loss: 1.6974, value_loss: 0.9514
2024-07-14 05:11:51,418 [INFO    ] __main__: train step 3135: loss: 0.6656, policy_loss: 1.6973, value_loss: 0.9514
2024-07-14 05:11:51,690 [INFO    ] __main__: train step 3136: loss: 0.6658, policy_loss: 1.6971, value_loss: 0.9514
2024-07-14 05:11:51,967 [INFO    ] __main__: train step 3137: loss: 0.6659, policy_loss: 1.6970, value_loss: 0.9513
2024-07-14 05:11:52,242 [INFO    ] __main__: train step 3138: loss: 0.6661, policy_loss: 1.6969, value_loss: 0.9513
2024-07-14 05:11:52,866 [INFO    ] __main__: train step 3139: loss: 0.6662, policy_loss: 1.6968, value_loss: 0.9513
2024-07-14 05:11:53,144 [INFO    ] __main__: train step 3140: loss: 0.6663, policy_loss: 1.6967, value_loss: 0.9512
2024-07-14 05:11:53,423 [INFO    ] __main__: train step 3141: loss: 0.6665, policy_loss: 1.6965, value_loss: 0.9512
2024-07-14 05:11:55,026 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:11:55,492 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:11:55,563 [INFO    ] __main__: train step 3142: loss: 0.6666, policy_loss: 1.6964, value_loss: 0.9512
2024-07-14 05:11:55,837 [INFO    ] __main__: train step 3143: loss: 0.6667, policy_loss: 1.6963, value_loss: 0.9511
2024-07-14 05:11:56,111 [INFO    ] __main__: train step 3144: loss: 0.6669, policy_loss: 1.6962, value_loss: 0.9511
2024-07-14 05:11:56,373 [INFO    ] __main__: train step 3145: loss: 0.6670, policy_loss: 1.6961, value_loss: 0.9511
2024-07-14 05:11:56,639 [INFO    ] __main__: train step 3146: loss: 0.6672, policy_loss: 1.6960, value_loss: 0.9510
2024-07-14 05:11:56,916 [INFO    ] __main__: train step 3147: loss: 0.6673, policy_loss: 1.6958, value_loss: 0.9510
2024-07-14 05:11:57,193 [INFO    ] __main__: train step 3148: loss: 0.6674, policy_loss: 1.6957, value_loss: 0.9510
2024-07-14 05:11:57,465 [INFO    ] __main__: train step 3149: loss: 0.6676, policy_loss: 1.6956, value_loss: 0.9509
2024-07-14 05:11:57,735 [INFO    ] __main__: train step 3150: loss: 0.6677, policy_loss: 1.6955, value_loss: 0.9509
2024-07-14 05:11:58,015 [INFO    ] __main__: train step 3151: loss: 0.6678, policy_loss: 1.6954, value_loss: 0.9509
2024-07-14 05:11:58,296 [INFO    ] __main__: train step 3152: loss: 0.6680, policy_loss: 1.6953, value_loss: 0.9508
2024-07-14 05:11:58,595 [INFO    ] __main__: train step 3153: loss: 0.6681, policy_loss: 1.6951, value_loss: 0.9508
2024-07-14 05:11:58,885 [INFO    ] __main__: train step 3154: loss: 0.6683, policy_loss: 1.6950, value_loss: 0.9508
2024-07-14 05:11:59,172 [INFO    ] __main__: train step 3155: loss: 0.6684, policy_loss: 1.6949, value_loss: 0.9507
2024-07-14 05:11:59,464 [INFO    ] __main__: train step 3156: loss: 0.6686, policy_loss: 1.6948, value_loss: 0.9507
2024-07-14 05:11:59,733 [INFO    ] __main__: train step 3157: loss: 0.6687, policy_loss: 1.6947, value_loss: 0.9506
2024-07-14 05:12:00,021 [INFO    ] __main__: train step 3158: loss: 0.6688, policy_loss: 1.6946, value_loss: 0.9506
2024-07-14 05:12:02,291 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:12:02,773 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:12:02,840 [INFO    ] __main__: train step 3159: loss: 0.6690, policy_loss: 1.6944, value_loss: 0.9506
2024-07-14 05:12:03,124 [INFO    ] __main__: train step 3160: loss: 0.6691, policy_loss: 1.6943, value_loss: 0.9505
2024-07-14 05:12:03,368 [INFO    ] __main__: train step 3161: loss: 0.6693, policy_loss: 1.6942, value_loss: 0.9505
2024-07-14 05:12:03,624 [INFO    ] __main__: train step 3162: loss: 0.6694, policy_loss: 1.6941, value_loss: 0.9505
2024-07-14 05:12:03,879 [INFO    ] __main__: train step 3163: loss: 0.6695, policy_loss: 1.6940, value_loss: 0.9504
2024-07-14 05:12:04,141 [INFO    ] __main__: train step 3164: loss: 0.6697, policy_loss: 1.6939, value_loss: 0.9504
2024-07-14 05:12:04,421 [INFO    ] __main__: train step 3165: loss: 0.6698, policy_loss: 1.6937, value_loss: 0.9504
2024-07-14 05:12:04,699 [INFO    ] __main__: train step 3166: loss: 0.6700, policy_loss: 1.6936, value_loss: 0.9503
2024-07-14 05:12:04,982 [INFO    ] __main__: train step 3167: loss: 0.6701, policy_loss: 1.6935, value_loss: 0.9503
2024-07-14 05:12:05,263 [INFO    ] __main__: train step 3168: loss: 0.6703, policy_loss: 1.6934, value_loss: 0.9503
2024-07-14 05:12:05,545 [INFO    ] __main__: train step 3169: loss: 0.6704, policy_loss: 1.6933, value_loss: 0.9502
2024-07-14 05:12:05,837 [INFO    ] __main__: train step 3170: loss: 0.6705, policy_loss: 1.6931, value_loss: 0.9502
2024-07-14 05:12:06,119 [INFO    ] __main__: train step 3171: loss: 0.6706, policy_loss: 1.6930, value_loss: 0.9502
2024-07-14 05:12:06,401 [INFO    ] __main__: train step 3172: loss: 0.6708, policy_loss: 1.6929, value_loss: 0.9501
2024-07-14 05:12:06,690 [INFO    ] __main__: train step 3173: loss: 0.6709, policy_loss: 1.6928, value_loss: 0.9501
2024-07-14 05:12:06,955 [INFO    ] __main__: train step 3174: loss: 0.6711, policy_loss: 1.6927, value_loss: 0.9501
2024-07-14 05:12:07,231 [INFO    ] __main__: train step 3175: loss: 0.6712, policy_loss: 1.6926, value_loss: 0.9500
2024-07-14 05:12:08,848 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:12:09,344 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:12:09,416 [INFO    ] __main__: train step 3176: loss: 0.6714, policy_loss: 1.6924, value_loss: 0.9500
2024-07-14 05:12:09,677 [INFO    ] __main__: train step 3177: loss: 0.6715, policy_loss: 1.6923, value_loss: 0.9500
2024-07-14 05:12:09,951 [INFO    ] __main__: train step 3178: loss: 0.6716, policy_loss: 1.6922, value_loss: 0.9499
2024-07-14 05:12:10,593 [INFO    ] __main__: train step 3179: loss: 0.6718, policy_loss: 1.6921, value_loss: 0.9499
2024-07-14 05:12:10,875 [INFO    ] __main__: train step 3180: loss: 0.6719, policy_loss: 1.6920, value_loss: 0.9499
2024-07-14 05:12:11,150 [INFO    ] __main__: train step 3181: loss: 0.6720, policy_loss: 1.6919, value_loss: 0.9498
2024-07-14 05:12:11,426 [INFO    ] __main__: train step 3182: loss: 0.6722, policy_loss: 1.6918, value_loss: 0.9498
2024-07-14 05:12:11,704 [INFO    ] __main__: train step 3183: loss: 0.6723, policy_loss: 1.6916, value_loss: 0.9498
2024-07-14 05:12:11,991 [INFO    ] __main__: train step 3184: loss: 0.6725, policy_loss: 1.6915, value_loss: 0.9497
2024-07-14 05:12:12,277 [INFO    ] __main__: train step 3185: loss: 0.6726, policy_loss: 1.6914, value_loss: 0.9497
2024-07-14 05:12:12,559 [INFO    ] __main__: train step 3186: loss: 0.6727, policy_loss: 1.6913, value_loss: 0.9497
2024-07-14 05:12:12,846 [INFO    ] __main__: train step 3187: loss: 0.6729, policy_loss: 1.6911, value_loss: 0.9496
2024-07-14 05:12:13,121 [INFO    ] __main__: train step 3188: loss: 0.6730, policy_loss: 1.6910, value_loss: 0.9496
2024-07-14 05:12:13,399 [INFO    ] __main__: train step 3189: loss: 0.6731, policy_loss: 1.6909, value_loss: 0.9496
2024-07-14 05:12:13,679 [INFO    ] __main__: train step 3190: loss: 0.6733, policy_loss: 1.6908, value_loss: 0.9495
2024-07-14 05:12:13,964 [INFO    ] __main__: train step 3191: loss: 0.6734, policy_loss: 1.6907, value_loss: 0.9495
2024-07-14 05:12:14,239 [INFO    ] __main__: train step 3192: loss: 0.6735, policy_loss: 1.6906, value_loss: 0.9495
2024-07-14 05:12:15,841 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:12:16,320 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:12:16,388 [INFO    ] __main__: train step 3193: loss: 0.6737, policy_loss: 1.6904, value_loss: 0.9494
2024-07-14 05:12:16,667 [INFO    ] __main__: train step 3194: loss: 0.6738, policy_loss: 1.6903, value_loss: 0.9494
2024-07-14 05:12:16,963 [INFO    ] __main__: train step 3195: loss: 0.6740, policy_loss: 1.6902, value_loss: 0.9494
2024-07-14 05:12:17,229 [INFO    ] __main__: train step 3196: loss: 0.6741, policy_loss: 1.6901, value_loss: 0.9493
2024-07-14 05:12:17,514 [INFO    ] __main__: train step 3197: loss: 0.6743, policy_loss: 1.6900, value_loss: 0.9493
2024-07-14 05:12:18,422 [INFO    ] __main__: train step 3198: loss: 0.6744, policy_loss: 1.6899, value_loss: 0.9493
2024-07-14 05:12:18,695 [INFO    ] __main__: train step 3199: loss: 0.6746, policy_loss: 1.6897, value_loss: 0.9492
2024-07-14 05:12:18,969 [INFO    ] __main__: train step 3200: loss: 0.6747, policy_loss: 1.6896, value_loss: 0.9492
2024-07-14 05:12:19,252 [INFO    ] __main__: train step 3201: loss: 0.6748, policy_loss: 1.6895, value_loss: 0.9491
2024-07-14 05:12:19,531 [INFO    ] __main__: train step 3202: loss: 0.6750, policy_loss: 1.6894, value_loss: 0.9491
2024-07-14 05:12:19,815 [INFO    ] __main__: train step 3203: loss: 0.6751, policy_loss: 1.6893, value_loss: 0.9491
2024-07-14 05:12:20,099 [INFO    ] __main__: train step 3204: loss: 0.6753, policy_loss: 1.6892, value_loss: 0.9490
2024-07-14 05:12:20,372 [INFO    ] __main__: train step 3205: loss: 0.6754, policy_loss: 1.6890, value_loss: 0.9490
2024-07-14 05:12:20,639 [INFO    ] __main__: train step 3206: loss: 0.6755, policy_loss: 1.6889, value_loss: 0.9490
2024-07-14 05:12:20,914 [INFO    ] __main__: train step 3207: loss: 0.6757, policy_loss: 1.6888, value_loss: 0.9489
2024-07-14 05:12:21,187 [INFO    ] __main__: train step 3208: loss: 0.6758, policy_loss: 1.6887, value_loss: 0.9489
2024-07-14 05:12:21,462 [INFO    ] __main__: train step 3209: loss: 0.6760, policy_loss: 1.6886, value_loss: 0.9489
2024-07-14 05:12:23,066 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:12:23,534 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:12:23,603 [INFO    ] __main__: train step 3210: loss: 0.6761, policy_loss: 1.6885, value_loss: 0.9488
2024-07-14 05:12:23,888 [INFO    ] __main__: train step 3211: loss: 0.6762, policy_loss: 1.6883, value_loss: 0.9488
2024-07-14 05:12:24,166 [INFO    ] __main__: train step 3212: loss: 0.6764, policy_loss: 1.6882, value_loss: 0.9488
2024-07-14 05:12:24,444 [INFO    ] __main__: train step 3213: loss: 0.6765, policy_loss: 1.6881, value_loss: 0.9487
2024-07-14 05:12:24,717 [INFO    ] __main__: train step 3214: loss: 0.6767, policy_loss: 1.6880, value_loss: 0.9487
2024-07-14 05:12:24,997 [INFO    ] __main__: train step 3215: loss: 0.6768, policy_loss: 1.6879, value_loss: 0.9487
2024-07-14 05:12:25,283 [INFO    ] __main__: train step 3216: loss: 0.6769, policy_loss: 1.6877, value_loss: 0.9486
2024-07-14 05:12:25,575 [INFO    ] __main__: train step 3217: loss: 0.6771, policy_loss: 1.6876, value_loss: 0.9486
2024-07-14 05:12:26,206 [INFO    ] __main__: train step 3218: loss: 0.6772, policy_loss: 1.6875, value_loss: 0.9486
2024-07-14 05:12:26,483 [INFO    ] __main__: train step 3219: loss: 0.6773, policy_loss: 1.6874, value_loss: 0.9485
2024-07-14 05:12:26,764 [INFO    ] __main__: train step 3220: loss: 0.6775, policy_loss: 1.6873, value_loss: 0.9485
2024-07-14 05:12:27,062 [INFO    ] __main__: train step 3221: loss: 0.6776, policy_loss: 1.6871, value_loss: 0.9485
2024-07-14 05:12:27,343 [INFO    ] __main__: train step 3222: loss: 0.6777, policy_loss: 1.6870, value_loss: 0.9484
2024-07-14 05:12:27,614 [INFO    ] __main__: train step 3223: loss: 0.6779, policy_loss: 1.6869, value_loss: 0.9484
2024-07-14 05:12:27,883 [INFO    ] __main__: train step 3224: loss: 0.6780, policy_loss: 1.6868, value_loss: 0.9484
2024-07-14 05:12:28,178 [INFO    ] __main__: train step 3225: loss: 0.6782, policy_loss: 1.6867, value_loss: 0.9483
2024-07-14 05:12:28,452 [INFO    ] __main__: train step 3226: loss: 0.6783, policy_loss: 1.6866, value_loss: 0.9483
2024-07-14 05:12:30,049 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:12:30,526 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:12:30,594 [INFO    ] __main__: train step 3227: loss: 0.6784, policy_loss: 1.6865, value_loss: 0.9483
2024-07-14 05:12:30,881 [INFO    ] __main__: train step 3228: loss: 0.6786, policy_loss: 1.6863, value_loss: 0.9483
2024-07-14 05:12:31,156 [INFO    ] __main__: train step 3229: loss: 0.6787, policy_loss: 1.6862, value_loss: 0.9482
2024-07-14 05:12:31,419 [INFO    ] __main__: train step 3230: loss: 0.6789, policy_loss: 1.6861, value_loss: 0.9482
2024-07-14 05:12:31,683 [INFO    ] __main__: train step 3231: loss: 0.6790, policy_loss: 1.6860, value_loss: 0.9482
2024-07-14 05:12:31,978 [INFO    ] __main__: train step 3232: loss: 0.6791, policy_loss: 1.6859, value_loss: 0.9481
2024-07-14 05:12:32,251 [INFO    ] __main__: train step 3233: loss: 0.6793, policy_loss: 1.6858, value_loss: 0.9481
2024-07-14 05:12:32,524 [INFO    ] __main__: train step 3234: loss: 0.6794, policy_loss: 1.6856, value_loss: 0.9481
2024-07-14 05:12:32,802 [INFO    ] __main__: train step 3235: loss: 0.6796, policy_loss: 1.6855, value_loss: 0.9480
2024-07-14 05:12:33,072 [INFO    ] __main__: train step 3236: loss: 0.6797, policy_loss: 1.6854, value_loss: 0.9480
2024-07-14 05:12:33,345 [INFO    ] __main__: train step 3237: loss: 0.6798, policy_loss: 1.6853, value_loss: 0.9480
2024-07-14 05:12:34,190 [INFO    ] __main__: train step 3238: loss: 0.6800, policy_loss: 1.6852, value_loss: 0.9479
2024-07-14 05:12:34,461 [INFO    ] __main__: train step 3239: loss: 0.6801, policy_loss: 1.6851, value_loss: 0.9479
2024-07-14 05:12:34,748 [INFO    ] __main__: train step 3240: loss: 0.6803, policy_loss: 1.6849, value_loss: 0.9479
2024-07-14 05:12:35,029 [INFO    ] __main__: train step 3241: loss: 0.6804, policy_loss: 1.6848, value_loss: 0.9478
2024-07-14 05:12:35,304 [INFO    ] __main__: train step 3242: loss: 0.6805, policy_loss: 1.6847, value_loss: 0.9478
2024-07-14 05:12:35,585 [INFO    ] __main__: train step 3243: loss: 0.6807, policy_loss: 1.6846, value_loss: 0.9477
2024-07-14 05:12:37,185 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:12:37,666 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:12:37,734 [INFO    ] __main__: train step 3244: loss: 0.6808, policy_loss: 1.6845, value_loss: 0.9477
2024-07-14 05:12:38,008 [INFO    ] __main__: train step 3245: loss: 0.6810, policy_loss: 1.6844, value_loss: 0.9477
2024-07-14 05:12:38,281 [INFO    ] __main__: train step 3246: loss: 0.6811, policy_loss: 1.6842, value_loss: 0.9477
2024-07-14 05:12:38,565 [INFO    ] __main__: train step 3247: loss: 0.6812, policy_loss: 1.6841, value_loss: 0.9476
2024-07-14 05:12:38,854 [INFO    ] __main__: train step 3248: loss: 0.6814, policy_loss: 1.6840, value_loss: 0.9476
2024-07-14 05:12:39,154 [INFO    ] __main__: train step 3249: loss: 0.6815, policy_loss: 1.6839, value_loss: 0.9476
2024-07-14 05:12:39,431 [INFO    ] __main__: train step 3250: loss: 0.6817, policy_loss: 1.6838, value_loss: 0.9475
2024-07-14 05:12:39,714 [INFO    ] __main__: train step 3251: loss: 0.6818, policy_loss: 1.6836, value_loss: 0.9475
2024-07-14 05:12:40,004 [INFO    ] __main__: train step 3252: loss: 0.6819, policy_loss: 1.6835, value_loss: 0.9475
2024-07-14 05:12:40,296 [INFO    ] __main__: train step 3253: loss: 0.6821, policy_loss: 1.6834, value_loss: 0.9474
2024-07-14 05:12:40,581 [INFO    ] __main__: train step 3254: loss: 0.6822, policy_loss: 1.6833, value_loss: 0.9474
2024-07-14 05:12:40,865 [INFO    ] __main__: train step 3255: loss: 0.6824, policy_loss: 1.6832, value_loss: 0.9474
2024-07-14 05:12:41,147 [INFO    ] __main__: train step 3256: loss: 0.6825, policy_loss: 1.6831, value_loss: 0.9474
2024-07-14 05:12:41,423 [INFO    ] __main__: train step 3257: loss: 0.6826, policy_loss: 1.6829, value_loss: 0.9473
2024-07-14 05:12:42,340 [INFO    ] __main__: train step 3258: loss: 0.6828, policy_loss: 1.6828, value_loss: 0.9473
2024-07-14 05:12:42,624 [INFO    ] __main__: train step 3259: loss: 0.6829, policy_loss: 1.6827, value_loss: 0.9473
2024-07-14 05:12:42,889 [INFO    ] __main__: train step 3260: loss: 0.6830, policy_loss: 1.6826, value_loss: 0.9472
2024-07-14 05:12:44,490 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:12:44,963 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:12:45,036 [INFO    ] __main__: train step 3261: loss: 0.6832, policy_loss: 1.6825, value_loss: 0.9472
2024-07-14 05:12:45,332 [INFO    ] __main__: train step 3262: loss: 0.6833, policy_loss: 1.6823, value_loss: 0.9472
2024-07-14 05:12:45,609 [INFO    ] __main__: train step 3263: loss: 0.6834, policy_loss: 1.6822, value_loss: 0.9471
2024-07-14 05:12:45,884 [INFO    ] __main__: train step 3264: loss: 0.6836, policy_loss: 1.6821, value_loss: 0.9471
2024-07-14 05:12:46,159 [INFO    ] __main__: train step 3265: loss: 0.6837, policy_loss: 1.6820, value_loss: 0.9471
2024-07-14 05:12:46,435 [INFO    ] __main__: train step 3266: loss: 0.6838, policy_loss: 1.6819, value_loss: 0.9470
2024-07-14 05:12:46,703 [INFO    ] __main__: train step 3267: loss: 0.6840, policy_loss: 1.6818, value_loss: 0.9470
2024-07-14 05:12:46,981 [INFO    ] __main__: train step 3268: loss: 0.6841, policy_loss: 1.6817, value_loss: 0.9470
2024-07-14 05:12:47,256 [INFO    ] __main__: train step 3269: loss: 0.6843, policy_loss: 1.6815, value_loss: 0.9469
2024-07-14 05:12:47,514 [INFO    ] __main__: train step 3270: loss: 0.6844, policy_loss: 1.6814, value_loss: 0.9469
2024-07-14 05:12:47,768 [INFO    ] __main__: train step 3271: loss: 0.6845, policy_loss: 1.6813, value_loss: 0.9469
2024-07-14 05:12:48,015 [INFO    ] __main__: train step 3272: loss: 0.6847, policy_loss: 1.6812, value_loss: 0.9468
2024-07-14 05:12:48,275 [INFO    ] __main__: train step 3273: loss: 0.6848, policy_loss: 1.6811, value_loss: 0.9468
2024-07-14 05:12:48,523 [INFO    ] __main__: train step 3274: loss: 0.6850, policy_loss: 1.6810, value_loss: 0.9468
2024-07-14 05:12:48,772 [INFO    ] __main__: train step 3275: loss: 0.6851, policy_loss: 1.6808, value_loss: 0.9467
2024-07-14 05:12:49,028 [INFO    ] __main__: train step 3276: loss: 0.6852, policy_loss: 1.6807, value_loss: 0.9467
2024-07-14 05:12:49,667 [INFO    ] __main__: train step 3277: loss: 0.6854, policy_loss: 1.6806, value_loss: 0.9467
2024-07-14 05:12:51,268 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:12:51,750 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:12:51,821 [INFO    ] __main__: train step 3278: loss: 0.6855, policy_loss: 1.6805, value_loss: 0.9467
2024-07-14 05:12:52,075 [INFO    ] __main__: train step 3279: loss: 0.6857, policy_loss: 1.6804, value_loss: 0.9466
2024-07-14 05:12:52,345 [INFO    ] __main__: train step 3280: loss: 0.6858, policy_loss: 1.6803, value_loss: 0.9466
2024-07-14 05:12:52,620 [INFO    ] __main__: train step 3281: loss: 0.6859, policy_loss: 1.6802, value_loss: 0.9466
2024-07-14 05:12:52,894 [INFO    ] __main__: train step 3282: loss: 0.6861, policy_loss: 1.6800, value_loss: 0.9465
2024-07-14 05:12:53,173 [INFO    ] __main__: train step 3283: loss: 0.6862, policy_loss: 1.6799, value_loss: 0.9465
2024-07-14 05:12:53,430 [INFO    ] __main__: train step 3284: loss: 0.6863, policy_loss: 1.6798, value_loss: 0.9465
2024-07-14 05:12:53,706 [INFO    ] __main__: train step 3285: loss: 0.6865, policy_loss: 1.6797, value_loss: 0.9464
2024-07-14 05:12:53,983 [INFO    ] __main__: train step 3286: loss: 0.6866, policy_loss: 1.6796, value_loss: 0.9464
2024-07-14 05:12:54,258 [INFO    ] __main__: train step 3287: loss: 0.6868, policy_loss: 1.6794, value_loss: 0.9464
2024-07-14 05:12:54,551 [INFO    ] __main__: train step 3288: loss: 0.6869, policy_loss: 1.6793, value_loss: 0.9463
2024-07-14 05:12:54,835 [INFO    ] __main__: train step 3289: loss: 0.6870, policy_loss: 1.6792, value_loss: 0.9463
2024-07-14 05:12:55,131 [INFO    ] __main__: train step 3290: loss: 0.6872, policy_loss: 1.6791, value_loss: 0.9463
2024-07-14 05:12:55,412 [INFO    ] __main__: train step 3291: loss: 0.6873, policy_loss: 1.6790, value_loss: 0.9462
2024-07-14 05:12:55,695 [INFO    ] __main__: train step 3292: loss: 0.6875, policy_loss: 1.6789, value_loss: 0.9462
2024-07-14 05:12:55,986 [INFO    ] __main__: train step 3293: loss: 0.6876, policy_loss: 1.6788, value_loss: 0.9462
2024-07-14 05:12:56,268 [INFO    ] __main__: train step 3294: loss: 0.6877, policy_loss: 1.6786, value_loss: 0.9461
2024-07-14 05:12:57,878 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:12:58,360 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:12:58,425 [INFO    ] __main__: train step 3295: loss: 0.6879, policy_loss: 1.6785, value_loss: 0.9461
2024-07-14 05:12:58,726 [INFO    ] __main__: train step 3296: loss: 0.6880, policy_loss: 1.6784, value_loss: 0.9461
2024-07-14 05:12:59,672 [INFO    ] __main__: train step 3297: loss: 0.6881, policy_loss: 1.6783, value_loss: 0.9460
2024-07-14 05:12:59,954 [INFO    ] __main__: train step 3298: loss: 0.6883, policy_loss: 1.6782, value_loss: 0.9460
2024-07-14 05:13:00,244 [INFO    ] __main__: train step 3299: loss: 0.6884, policy_loss: 1.6781, value_loss: 0.9460
2024-07-14 05:13:00,524 [INFO    ] __main__: train step 3300: loss: 0.6886, policy_loss: 1.6779, value_loss: 0.9459
2024-07-14 05:13:00,797 [INFO    ] __main__: train step 3301: loss: 0.6887, policy_loss: 1.6778, value_loss: 0.9459
2024-07-14 05:13:01,079 [INFO    ] __main__: train step 3302: loss: 0.6888, policy_loss: 1.6777, value_loss: 0.9459
2024-07-14 05:13:01,364 [INFO    ] __main__: train step 3303: loss: 0.6890, policy_loss: 1.6776, value_loss: 0.9458
2024-07-14 05:13:01,643 [INFO    ] __main__: train step 3304: loss: 0.6891, policy_loss: 1.6775, value_loss: 0.9458
2024-07-14 05:13:01,928 [INFO    ] __main__: train step 3305: loss: 0.6892, policy_loss: 1.6774, value_loss: 0.9458
2024-07-14 05:13:02,210 [INFO    ] __main__: train step 3306: loss: 0.6894, policy_loss: 1.6772, value_loss: 0.9457
2024-07-14 05:13:02,475 [INFO    ] __main__: train step 3307: loss: 0.6895, policy_loss: 1.6771, value_loss: 0.9457
2024-07-14 05:13:02,751 [INFO    ] __main__: train step 3308: loss: 0.6896, policy_loss: 1.6770, value_loss: 0.9457
2024-07-14 05:13:03,030 [INFO    ] __main__: train step 3309: loss: 0.6898, policy_loss: 1.6769, value_loss: 0.9457
2024-07-14 05:13:03,320 [INFO    ] __main__: train step 3310: loss: 0.6899, policy_loss: 1.6768, value_loss: 0.9456
2024-07-14 05:13:03,603 [INFO    ] __main__: train step 3311: loss: 0.6901, policy_loss: 1.6767, value_loss: 0.9456
2024-07-14 05:13:05,212 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:13:05,688 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:13:05,757 [INFO    ] __main__: train step 3312: loss: 0.6902, policy_loss: 1.6765, value_loss: 0.9456
2024-07-14 05:13:06,052 [INFO    ] __main__: train step 3313: loss: 0.6903, policy_loss: 1.6764, value_loss: 0.9455
2024-07-14 05:13:06,324 [INFO    ] __main__: train step 3314: loss: 0.6905, policy_loss: 1.6763, value_loss: 0.9455
2024-07-14 05:13:06,608 [INFO    ] __main__: train step 3315: loss: 0.6906, policy_loss: 1.6762, value_loss: 0.9455
2024-07-14 05:13:07,509 [INFO    ] __main__: train step 3316: loss: 0.6908, policy_loss: 1.6761, value_loss: 0.9454
2024-07-14 05:13:07,797 [INFO    ] __main__: train step 3317: loss: 0.6909, policy_loss: 1.6760, value_loss: 0.9454
2024-07-14 05:13:08,082 [INFO    ] __main__: train step 3318: loss: 0.6910, policy_loss: 1.6758, value_loss: 0.9454
2024-07-14 05:13:08,359 [INFO    ] __main__: train step 3319: loss: 0.6912, policy_loss: 1.6757, value_loss: 0.9453
2024-07-14 05:13:08,618 [INFO    ] __main__: train step 3320: loss: 0.6913, policy_loss: 1.6756, value_loss: 0.9453
2024-07-14 05:13:08,874 [INFO    ] __main__: train step 3321: loss: 0.6914, policy_loss: 1.6755, value_loss: 0.9453
2024-07-14 05:13:09,146 [INFO    ] __main__: train step 3322: loss: 0.6916, policy_loss: 1.6754, value_loss: 0.9452
2024-07-14 05:13:09,437 [INFO    ] __main__: train step 3323: loss: 0.6917, policy_loss: 1.6752, value_loss: 0.9452
2024-07-14 05:13:09,726 [INFO    ] __main__: train step 3324: loss: 0.6919, policy_loss: 1.6751, value_loss: 0.9452
2024-07-14 05:13:09,999 [INFO    ] __main__: train step 3325: loss: 0.6920, policy_loss: 1.6750, value_loss: 0.9451
2024-07-14 05:13:10,280 [INFO    ] __main__: train step 3326: loss: 0.6921, policy_loss: 1.6749, value_loss: 0.9451
2024-07-14 05:13:10,547 [INFO    ] __main__: train step 3327: loss: 0.6923, policy_loss: 1.6748, value_loss: 0.9451
2024-07-14 05:13:10,821 [INFO    ] __main__: train step 3328: loss: 0.6924, policy_loss: 1.6747, value_loss: 0.9450
2024-07-14 05:13:12,431 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:13:12,924 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:13:12,994 [INFO    ] __main__: train step 3329: loss: 0.6925, policy_loss: 1.6746, value_loss: 0.9450
2024-07-14 05:13:13,274 [INFO    ] __main__: train step 3330: loss: 0.6927, policy_loss: 1.6745, value_loss: 0.9450
2024-07-14 05:13:13,550 [INFO    ] __main__: train step 3331: loss: 0.6928, policy_loss: 1.6743, value_loss: 0.9449
2024-07-14 05:13:13,819 [INFO    ] __main__: train step 3332: loss: 0.6930, policy_loss: 1.6742, value_loss: 0.9449
2024-07-14 05:13:14,105 [INFO    ] __main__: train step 3333: loss: 0.6931, policy_loss: 1.6741, value_loss: 0.9449
2024-07-14 05:13:14,391 [INFO    ] __main__: train step 3334: loss: 0.6932, policy_loss: 1.6740, value_loss: 0.9448
2024-07-14 05:13:14,670 [INFO    ] __main__: train step 3335: loss: 0.6934, policy_loss: 1.6739, value_loss: 0.9448
2024-07-14 05:13:15,534 [INFO    ] __main__: train step 3336: loss: 0.6935, policy_loss: 1.6738, value_loss: 0.9448
2024-07-14 05:13:15,819 [INFO    ] __main__: train step 3337: loss: 0.6937, policy_loss: 1.6736, value_loss: 0.9447
2024-07-14 05:13:16,108 [INFO    ] __main__: train step 3338: loss: 0.6938, policy_loss: 1.6735, value_loss: 0.9447
2024-07-14 05:13:16,383 [INFO    ] __main__: train step 3339: loss: 0.6940, policy_loss: 1.6734, value_loss: 0.9447
2024-07-14 05:13:16,655 [INFO    ] __main__: train step 3340: loss: 0.6941, policy_loss: 1.6733, value_loss: 0.9446
2024-07-14 05:13:16,947 [INFO    ] __main__: train step 3341: loss: 0.6942, policy_loss: 1.6732, value_loss: 0.9446
2024-07-14 05:13:17,228 [INFO    ] __main__: train step 3342: loss: 0.6944, policy_loss: 1.6731, value_loss: 0.9446
2024-07-14 05:13:17,494 [INFO    ] __main__: train step 3343: loss: 0.6945, policy_loss: 1.6730, value_loss: 0.9445
2024-07-14 05:13:17,771 [INFO    ] __main__: train step 3344: loss: 0.6946, policy_loss: 1.6728, value_loss: 0.9445
2024-07-14 05:13:18,051 [INFO    ] __main__: train step 3345: loss: 0.6948, policy_loss: 1.6727, value_loss: 0.9445
2024-07-14 05:13:19,649 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:13:20,125 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:13:20,199 [INFO    ] __main__: train step 3346: loss: 0.6949, policy_loss: 1.6726, value_loss: 0.9444
2024-07-14 05:13:20,495 [INFO    ] __main__: train step 3347: loss: 0.6950, policy_loss: 1.6725, value_loss: 0.9444
2024-07-14 05:13:20,795 [INFO    ] __main__: train step 3348: loss: 0.6952, policy_loss: 1.6724, value_loss: 0.9444
2024-07-14 05:13:21,087 [INFO    ] __main__: train step 3349: loss: 0.6953, policy_loss: 1.6722, value_loss: 0.9444
2024-07-14 05:13:21,389 [INFO    ] __main__: train step 3350: loss: 0.6954, policy_loss: 1.6721, value_loss: 0.9443
2024-07-14 05:13:21,693 [INFO    ] __main__: train step 3351: loss: 0.6956, policy_loss: 1.6720, value_loss: 0.9443
2024-07-14 05:13:22,032 [INFO    ] __main__: train step 3352: loss: 0.6957, policy_loss: 1.6719, value_loss: 0.9443
2024-07-14 05:13:22,331 [INFO    ] __main__: train step 3353: loss: 0.6958, policy_loss: 1.6718, value_loss: 0.9442
2024-07-14 05:13:22,631 [INFO    ] __main__: train step 3354: loss: 0.6960, policy_loss: 1.6717, value_loss: 0.9442
2024-07-14 05:13:22,928 [INFO    ] __main__: train step 3355: loss: 0.6961, policy_loss: 1.6716, value_loss: 0.9442
2024-07-14 05:13:23,713 [INFO    ] __main__: train step 3356: loss: 0.6962, policy_loss: 1.6714, value_loss: 0.9441
2024-07-14 05:13:24,012 [INFO    ] __main__: train step 3357: loss: 0.6964, policy_loss: 1.6713, value_loss: 0.9441
2024-07-14 05:13:24,307 [INFO    ] __main__: train step 3358: loss: 0.6965, policy_loss: 1.6712, value_loss: 0.9441
2024-07-14 05:13:24,589 [INFO    ] __main__: train step 3359: loss: 0.6966, policy_loss: 1.6711, value_loss: 0.9440
2024-07-14 05:13:24,894 [INFO    ] __main__: train step 3360: loss: 0.6968, policy_loss: 1.6710, value_loss: 0.9440
2024-07-14 05:13:25,189 [INFO    ] __main__: train step 3361: loss: 0.6969, policy_loss: 1.6709, value_loss: 0.9440
2024-07-14 05:13:25,487 [INFO    ] __main__: train step 3362: loss: 0.6971, policy_loss: 1.6708, value_loss: 0.9439
2024-07-14 05:13:27,088 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:13:27,574 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:13:27,643 [INFO    ] __main__: train step 3363: loss: 0.6972, policy_loss: 1.6707, value_loss: 0.9439
2024-07-14 05:13:27,923 [INFO    ] __main__: train step 3364: loss: 0.6973, policy_loss: 1.6705, value_loss: 0.9439
2024-07-14 05:13:28,201 [INFO    ] __main__: train step 3365: loss: 0.6975, policy_loss: 1.6704, value_loss: 0.9438
2024-07-14 05:13:28,473 [INFO    ] __main__: train step 3366: loss: 0.6976, policy_loss: 1.6703, value_loss: 0.9438
2024-07-14 05:13:28,738 [INFO    ] __main__: train step 3367: loss: 0.6977, policy_loss: 1.6702, value_loss: 0.9438
2024-07-14 05:13:29,017 [INFO    ] __main__: train step 3368: loss: 0.6979, policy_loss: 1.6701, value_loss: 0.9437
2024-07-14 05:13:29,305 [INFO    ] __main__: train step 3369: loss: 0.6980, policy_loss: 1.6700, value_loss: 0.9437
2024-07-14 05:13:29,599 [INFO    ] __main__: train step 3370: loss: 0.6981, policy_loss: 1.6698, value_loss: 0.9437
2024-07-14 05:13:29,885 [INFO    ] __main__: train step 3371: loss: 0.6983, policy_loss: 1.6697, value_loss: 0.9436
2024-07-14 05:13:30,156 [INFO    ] __main__: train step 3372: loss: 0.6984, policy_loss: 1.6696, value_loss: 0.9436
2024-07-14 05:13:30,436 [INFO    ] __main__: train step 3373: loss: 0.6985, policy_loss: 1.6695, value_loss: 0.9436
2024-07-14 05:13:30,714 [INFO    ] __main__: train step 3374: loss: 0.6987, policy_loss: 1.6694, value_loss: 0.9435
2024-07-14 05:13:30,990 [INFO    ] __main__: train step 3375: loss: 0.6988, policy_loss: 1.6693, value_loss: 0.9435
2024-07-14 05:13:31,271 [INFO    ] __main__: train step 3376: loss: 0.6989, policy_loss: 1.6692, value_loss: 0.9435
2024-07-14 05:13:32,228 [INFO    ] __main__: train step 3377: loss: 0.6991, policy_loss: 1.6690, value_loss: 0.9434
2024-07-14 05:13:32,495 [INFO    ] __main__: train step 3378: loss: 0.6992, policy_loss: 1.6689, value_loss: 0.9434
2024-07-14 05:13:32,752 [INFO    ] __main__: train step 3379: loss: 0.6993, policy_loss: 1.6688, value_loss: 0.9434
2024-07-14 05:13:34,346 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:13:34,821 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:13:34,893 [INFO    ] __main__: train step 3380: loss: 0.6995, policy_loss: 1.6687, value_loss: 0.9433
2024-07-14 05:13:35,173 [INFO    ] __main__: train step 3381: loss: 0.6996, policy_loss: 1.6686, value_loss: 0.9433
2024-07-14 05:13:35,459 [INFO    ] __main__: train step 3382: loss: 0.6997, policy_loss: 1.6685, value_loss: 0.9432
2024-07-14 05:13:35,735 [INFO    ] __main__: train step 3383: loss: 0.6999, policy_loss: 1.6683, value_loss: 0.9432
2024-07-14 05:13:36,011 [INFO    ] __main__: train step 3384: loss: 0.7000, policy_loss: 1.6682, value_loss: 0.9432
2024-07-14 05:13:36,276 [INFO    ] __main__: train step 3385: loss: 0.7001, policy_loss: 1.6681, value_loss: 0.9431
2024-07-14 05:13:36,589 [INFO    ] __main__: train step 3386: loss: 0.7003, policy_loss: 1.6680, value_loss: 0.9431
2024-07-14 05:13:36,877 [INFO    ] __main__: train step 3387: loss: 0.7004, policy_loss: 1.6679, value_loss: 0.9431
2024-07-14 05:13:37,158 [INFO    ] __main__: train step 3388: loss: 0.7005, policy_loss: 1.6678, value_loss: 0.9430
2024-07-14 05:13:37,440 [INFO    ] __main__: train step 3389: loss: 0.7007, policy_loss: 1.6676, value_loss: 0.9430
2024-07-14 05:13:37,721 [INFO    ] __main__: train step 3390: loss: 0.7008, policy_loss: 1.6675, value_loss: 0.9430
2024-07-14 05:13:38,003 [INFO    ] __main__: train step 3391: loss: 0.7009, policy_loss: 1.6674, value_loss: 0.9430
2024-07-14 05:13:38,283 [INFO    ] __main__: train step 3392: loss: 0.7011, policy_loss: 1.6673, value_loss: 0.9429
2024-07-14 05:13:38,590 [INFO    ] __main__: train step 3393: loss: 0.7012, policy_loss: 1.6672, value_loss: 0.9429
2024-07-14 05:13:38,896 [INFO    ] __main__: train step 3394: loss: 0.7013, policy_loss: 1.6671, value_loss: 0.9429
2024-07-14 05:13:39,175 [INFO    ] __main__: train step 3395: loss: 0.7015, policy_loss: 1.6670, value_loss: 0.9428
2024-07-14 05:13:40,012 [INFO    ] __main__: train step 3396: loss: 0.7016, policy_loss: 1.6668, value_loss: 0.9428
2024-07-14 05:13:41,631 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:13:42,113 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:13:42,184 [INFO    ] __main__: train step 3397: loss: 0.7018, policy_loss: 1.6667, value_loss: 0.9428
2024-07-14 05:13:42,467 [INFO    ] __main__: train step 3398: loss: 0.7019, policy_loss: 1.6666, value_loss: 0.9427
2024-07-14 05:13:42,752 [INFO    ] __main__: train step 3399: loss: 0.7020, policy_loss: 1.6665, value_loss: 0.9427
2024-07-14 05:13:43,037 [INFO    ] __main__: train step 3400: loss: 0.7022, policy_loss: 1.6664, value_loss: 0.9427
2024-07-14 05:13:43,317 [INFO    ] __main__: train step 3401: loss: 0.7023, policy_loss: 1.6663, value_loss: 0.9426
2024-07-14 05:13:43,598 [INFO    ] __main__: train step 3402: loss: 0.7024, policy_loss: 1.6662, value_loss: 0.9426
2024-07-14 05:13:43,879 [INFO    ] __main__: train step 3403: loss: 0.7026, policy_loss: 1.6660, value_loss: 0.9426
2024-07-14 05:13:44,160 [INFO    ] __main__: train step 3404: loss: 0.7027, policy_loss: 1.6659, value_loss: 0.9425
2024-07-14 05:13:44,451 [INFO    ] __main__: train step 3405: loss: 0.7028, policy_loss: 1.6658, value_loss: 0.9425
2024-07-14 05:13:44,732 [INFO    ] __main__: train step 3406: loss: 0.7030, policy_loss: 1.6657, value_loss: 0.9425
2024-07-14 05:13:45,021 [INFO    ] __main__: train step 3407: loss: 0.7031, policy_loss: 1.6656, value_loss: 0.9424
2024-07-14 05:13:45,307 [INFO    ] __main__: train step 3408: loss: 0.7033, policy_loss: 1.6655, value_loss: 0.9424
2024-07-14 05:13:45,609 [INFO    ] __main__: train step 3409: loss: 0.7034, policy_loss: 1.6653, value_loss: 0.9424
2024-07-14 05:13:45,905 [INFO    ] __main__: train step 3410: loss: 0.7035, policy_loss: 1.6652, value_loss: 0.9423
2024-07-14 05:13:46,185 [INFO    ] __main__: train step 3411: loss: 0.7036, policy_loss: 1.6651, value_loss: 0.9423
2024-07-14 05:13:46,462 [INFO    ] __main__: train step 3412: loss: 0.7038, policy_loss: 1.6650, value_loss: 0.9423
2024-07-14 05:13:46,747 [INFO    ] __main__: train step 3413: loss: 0.7039, policy_loss: 1.6649, value_loss: 0.9422
2024-07-14 05:13:48,381 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:13:48,883 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:13:48,956 [INFO    ] __main__: train step 3414: loss: 0.7040, policy_loss: 1.6648, value_loss: 0.9422
2024-07-14 05:13:49,889 [INFO    ] __main__: train step 3415: loss: 0.7042, policy_loss: 1.6646, value_loss: 0.9422
2024-07-14 05:13:50,177 [INFO    ] __main__: train step 3416: loss: 0.7043, policy_loss: 1.6645, value_loss: 0.9421
2024-07-14 05:13:50,457 [INFO    ] __main__: train step 3417: loss: 0.7044, policy_loss: 1.6644, value_loss: 0.9421
2024-07-14 05:13:50,738 [INFO    ] __main__: train step 3418: loss: 0.7046, policy_loss: 1.6643, value_loss: 0.9421
2024-07-14 05:13:51,013 [INFO    ] __main__: train step 3419: loss: 0.7047, policy_loss: 1.6642, value_loss: 0.9420
2024-07-14 05:13:51,299 [INFO    ] __main__: train step 3420: loss: 0.7049, policy_loss: 1.6641, value_loss: 0.9420
2024-07-14 05:13:51,563 [INFO    ] __main__: train step 3421: loss: 0.7050, policy_loss: 1.6639, value_loss: 0.9420
2024-07-14 05:13:51,847 [INFO    ] __main__: train step 3422: loss: 0.7051, policy_loss: 1.6638, value_loss: 0.9419
2024-07-14 05:13:52,128 [INFO    ] __main__: train step 3423: loss: 0.7053, policy_loss: 1.6637, value_loss: 0.9419
2024-07-14 05:13:52,418 [INFO    ] __main__: train step 3424: loss: 0.7054, policy_loss: 1.6636, value_loss: 0.9419
2024-07-14 05:13:52,693 [INFO    ] __main__: train step 3425: loss: 0.7055, policy_loss: 1.6635, value_loss: 0.9418
2024-07-14 05:13:52,961 [INFO    ] __main__: train step 3426: loss: 0.7057, policy_loss: 1.6634, value_loss: 0.9418
2024-07-14 05:13:53,237 [INFO    ] __main__: train step 3427: loss: 0.7058, policy_loss: 1.6633, value_loss: 0.9418
2024-07-14 05:13:53,509 [INFO    ] __main__: train step 3428: loss: 0.7059, policy_loss: 1.6631, value_loss: 0.9417
2024-07-14 05:13:53,783 [INFO    ] __main__: train step 3429: loss: 0.7061, policy_loss: 1.6630, value_loss: 0.9417
2024-07-14 05:13:54,038 [INFO    ] __main__: train step 3430: loss: 0.7062, policy_loss: 1.6629, value_loss: 0.9417
2024-07-14 05:13:55,612 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:13:56,099 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:13:56,170 [INFO    ] __main__: train step 3431: loss: 0.7063, policy_loss: 1.6628, value_loss: 0.9417
2024-07-14 05:13:56,438 [INFO    ] __main__: train step 3432: loss: 0.7065, policy_loss: 1.6627, value_loss: 0.9416
2024-07-14 05:13:56,711 [INFO    ] __main__: train step 3433: loss: 0.7066, policy_loss: 1.6626, value_loss: 0.9416
2024-07-14 05:13:56,975 [INFO    ] __main__: train step 3434: loss: 0.7068, policy_loss: 1.6624, value_loss: 0.9416
2024-07-14 05:13:57,890 [INFO    ] __main__: train step 3435: loss: 0.7069, policy_loss: 1.6623, value_loss: 0.9415
2024-07-14 05:13:58,172 [INFO    ] __main__: train step 3436: loss: 0.7070, policy_loss: 1.6622, value_loss: 0.9415
2024-07-14 05:13:58,456 [INFO    ] __main__: train step 3437: loss: 0.7072, policy_loss: 1.6621, value_loss: 0.9415
2024-07-14 05:13:58,739 [INFO    ] __main__: train step 3438: loss: 0.7073, policy_loss: 1.6620, value_loss: 0.9414
2024-07-14 05:13:59,016 [INFO    ] __main__: train step 3439: loss: 0.7074, policy_loss: 1.6619, value_loss: 0.9414
2024-07-14 05:13:59,302 [INFO    ] __main__: train step 3440: loss: 0.7076, policy_loss: 1.6617, value_loss: 0.9414
2024-07-14 05:13:59,578 [INFO    ] __main__: train step 3441: loss: 0.7077, policy_loss: 1.6616, value_loss: 0.9413
2024-07-14 05:13:59,862 [INFO    ] __main__: train step 3442: loss: 0.7078, policy_loss: 1.6615, value_loss: 0.9413
2024-07-14 05:14:00,142 [INFO    ] __main__: train step 3443: loss: 0.7080, policy_loss: 1.6614, value_loss: 0.9413
2024-07-14 05:14:00,422 [INFO    ] __main__: train step 3444: loss: 0.7081, policy_loss: 1.6613, value_loss: 0.9412
2024-07-14 05:14:00,702 [INFO    ] __main__: train step 3445: loss: 0.7082, policy_loss: 1.6612, value_loss: 0.9412
2024-07-14 05:14:00,973 [INFO    ] __main__: train step 3446: loss: 0.7083, policy_loss: 1.6611, value_loss: 0.9412
2024-07-14 05:14:01,244 [INFO    ] __main__: train step 3447: loss: 0.7085, policy_loss: 1.6609, value_loss: 0.9412
2024-07-14 05:14:02,829 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:14:03,320 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:14:03,395 [INFO    ] __main__: train step 3448: loss: 0.7086, policy_loss: 1.6608, value_loss: 0.9411
2024-07-14 05:14:03,663 [INFO    ] __main__: train step 3449: loss: 0.7087, policy_loss: 1.6607, value_loss: 0.9411
2024-07-14 05:14:03,936 [INFO    ] __main__: train step 3450: loss: 0.7089, policy_loss: 1.6606, value_loss: 0.9410
2024-07-14 05:14:04,213 [INFO    ] __main__: train step 3451: loss: 0.7090, policy_loss: 1.6605, value_loss: 0.9410
2024-07-14 05:14:04,489 [INFO    ] __main__: train step 3452: loss: 0.7091, policy_loss: 1.6604, value_loss: 0.9410
2024-07-14 05:14:04,771 [INFO    ] __main__: train step 3453: loss: 0.7093, policy_loss: 1.6603, value_loss: 0.9409
2024-07-14 05:14:05,673 [INFO    ] __main__: train step 3454: loss: 0.7094, policy_loss: 1.6601, value_loss: 0.9409
2024-07-14 05:14:05,956 [INFO    ] __main__: train step 3455: loss: 0.7095, policy_loss: 1.6600, value_loss: 0.9409
2024-07-14 05:14:06,233 [INFO    ] __main__: train step 3456: loss: 0.7097, policy_loss: 1.6599, value_loss: 0.9409
2024-07-14 05:14:06,508 [INFO    ] __main__: train step 3457: loss: 0.7098, policy_loss: 1.6598, value_loss: 0.9408
2024-07-14 05:14:06,791 [INFO    ] __main__: train step 3458: loss: 0.7099, policy_loss: 1.6597, value_loss: 0.9408
2024-07-14 05:14:07,071 [INFO    ] __main__: train step 3459: loss: 0.7101, policy_loss: 1.6596, value_loss: 0.9408
2024-07-14 05:14:07,349 [INFO    ] __main__: train step 3460: loss: 0.7102, policy_loss: 1.6594, value_loss: 0.9407
2024-07-14 05:14:07,682 [INFO    ] __main__: train step 3461: loss: 0.7103, policy_loss: 1.6593, value_loss: 0.9407
2024-07-14 05:14:07,958 [INFO    ] __main__: train step 3462: loss: 0.7105, policy_loss: 1.6592, value_loss: 0.9407
2024-07-14 05:14:08,242 [INFO    ] __main__: train step 3463: loss: 0.7106, policy_loss: 1.6591, value_loss: 0.9406
2024-07-14 05:14:08,517 [INFO    ] __main__: train step 3464: loss: 0.7107, policy_loss: 1.6590, value_loss: 0.9406
2024-07-14 05:14:10,099 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:14:10,578 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:14:10,648 [INFO    ] __main__: train step 3465: loss: 0.7109, policy_loss: 1.6589, value_loss: 0.9406
2024-07-14 05:14:10,914 [INFO    ] __main__: train step 3466: loss: 0.7110, policy_loss: 1.6587, value_loss: 0.9405
2024-07-14 05:14:11,192 [INFO    ] __main__: train step 3467: loss: 0.7111, policy_loss: 1.6586, value_loss: 0.9405
2024-07-14 05:14:11,460 [INFO    ] __main__: train step 3468: loss: 0.7113, policy_loss: 1.6585, value_loss: 0.9405
2024-07-14 05:14:11,738 [INFO    ] __main__: train step 3469: loss: 0.7114, policy_loss: 1.6584, value_loss: 0.9405
2024-07-14 05:14:12,018 [INFO    ] __main__: train step 3470: loss: 0.7115, policy_loss: 1.6583, value_loss: 0.9404
2024-07-14 05:14:12,299 [INFO    ] __main__: train step 3471: loss: 0.7117, policy_loss: 1.6582, value_loss: 0.9404
2024-07-14 05:14:12,601 [INFO    ] __main__: train step 3472: loss: 0.7118, policy_loss: 1.6581, value_loss: 0.9403
2024-07-14 05:14:12,865 [INFO    ] __main__: train step 3473: loss: 0.7119, policy_loss: 1.6579, value_loss: 0.9403
2024-07-14 05:14:13,767 [INFO    ] __main__: train step 3474: loss: 0.7121, policy_loss: 1.6578, value_loss: 0.9403
2024-07-14 05:14:14,041 [INFO    ] __main__: train step 3475: loss: 0.7122, policy_loss: 1.6577, value_loss: 0.9403
2024-07-14 05:14:14,332 [INFO    ] __main__: train step 3476: loss: 0.7123, policy_loss: 1.6576, value_loss: 0.9402
2024-07-14 05:14:14,603 [INFO    ] __main__: train step 3477: loss: 0.7125, policy_loss: 1.6575, value_loss: 0.9402
2024-07-14 05:14:14,871 [INFO    ] __main__: train step 3478: loss: 0.7126, policy_loss: 1.6574, value_loss: 0.9402
2024-07-14 05:14:15,139 [INFO    ] __main__: train step 3479: loss: 0.7127, policy_loss: 1.6573, value_loss: 0.9401
2024-07-14 05:14:15,415 [INFO    ] __main__: train step 3480: loss: 0.7129, policy_loss: 1.6571, value_loss: 0.9401
2024-07-14 05:14:15,689 [INFO    ] __main__: train step 3481: loss: 0.7130, policy_loss: 1.6570, value_loss: 0.9401
2024-07-14 05:14:17,282 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:14:17,765 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:14:17,831 [INFO    ] __main__: train step 3482: loss: 0.7131, policy_loss: 1.6569, value_loss: 0.9400
2024-07-14 05:14:18,102 [INFO    ] __main__: train step 3483: loss: 0.7133, policy_loss: 1.6568, value_loss: 0.9400
2024-07-14 05:14:18,378 [INFO    ] __main__: train step 3484: loss: 0.7134, policy_loss: 1.6567, value_loss: 0.9400
2024-07-14 05:14:18,647 [INFO    ] __main__: train step 3485: loss: 0.7135, policy_loss: 1.6566, value_loss: 0.9399
2024-07-14 05:14:18,925 [INFO    ] __main__: train step 3486: loss: 0.7137, policy_loss: 1.6564, value_loss: 0.9399
2024-07-14 05:14:19,194 [INFO    ] __main__: train step 3487: loss: 0.7138, policy_loss: 1.6563, value_loss: 0.9399
2024-07-14 05:14:19,458 [INFO    ] __main__: train step 3488: loss: 0.7139, policy_loss: 1.6562, value_loss: 0.9398
2024-07-14 05:14:19,734 [INFO    ] __main__: train step 3489: loss: 0.7141, policy_loss: 1.6561, value_loss: 0.9398
2024-07-14 05:14:20,014 [INFO    ] __main__: train step 3490: loss: 0.7142, policy_loss: 1.6560, value_loss: 0.9398
2024-07-14 05:14:20,303 [INFO    ] __main__: train step 3491: loss: 0.7143, policy_loss: 1.6559, value_loss: 0.9397
2024-07-14 05:14:20,573 [INFO    ] __main__: train step 3492: loss: 0.7145, policy_loss: 1.6558, value_loss: 0.9397
2024-07-14 05:14:20,855 [INFO    ] __main__: train step 3493: loss: 0.7146, policy_loss: 1.6557, value_loss: 0.9397
2024-07-14 05:14:21,138 [INFO    ] __main__: train step 3494: loss: 0.7147, policy_loss: 1.6555, value_loss: 0.9397
2024-07-14 05:14:21,781 [INFO    ] __main__: train step 3495: loss: 0.7148, policy_loss: 1.6554, value_loss: 0.9396
2024-07-14 05:14:22,054 [INFO    ] __main__: train step 3496: loss: 0.7150, policy_loss: 1.6553, value_loss: 0.9396
2024-07-14 05:14:22,333 [INFO    ] __main__: train step 3497: loss: 0.7151, policy_loss: 1.6552, value_loss: 0.9396
2024-07-14 05:14:22,606 [INFO    ] __main__: train step 3498: loss: 0.7152, policy_loss: 1.6551, value_loss: 0.9395
2024-07-14 05:14:24,225 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:14:24,701 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:14:24,768 [INFO    ] __main__: train step 3499: loss: 0.7154, policy_loss: 1.6550, value_loss: 0.9395
2024-07-14 05:14:25,043 [INFO    ] __main__: train step 3500: loss: 0.7155, policy_loss: 1.6549, value_loss: 0.9395
2024-07-14 05:14:25,354 [INFO    ] __main__: train step 3501: loss: 0.7156, policy_loss: 1.6548, value_loss: 0.9395
2024-07-14 05:14:25,637 [INFO    ] __main__: train step 3502: loss: 0.7158, policy_loss: 1.6546, value_loss: 0.9394
2024-07-14 05:14:25,925 [INFO    ] __main__: train step 3503: loss: 0.7159, policy_loss: 1.6545, value_loss: 0.9394
2024-07-14 05:14:26,210 [INFO    ] __main__: train step 3504: loss: 0.7160, policy_loss: 1.6544, value_loss: 0.9394
2024-07-14 05:14:26,493 [INFO    ] __main__: train step 3505: loss: 0.7162, policy_loss: 1.6543, value_loss: 0.9393
2024-07-14 05:14:26,771 [INFO    ] __main__: train step 3506: loss: 0.7163, policy_loss: 1.6542, value_loss: 0.9393
2024-07-14 05:14:27,047 [INFO    ] __main__: train step 3507: loss: 0.7164, policy_loss: 1.6541, value_loss: 0.9393
2024-07-14 05:14:27,370 [INFO    ] __main__: train step 3508: loss: 0.7166, policy_loss: 1.6540, value_loss: 0.9392
2024-07-14 05:14:27,647 [INFO    ] __main__: train step 3509: loss: 0.7167, policy_loss: 1.6538, value_loss: 0.9392
2024-07-14 05:14:27,937 [INFO    ] __main__: train step 3510: loss: 0.7168, policy_loss: 1.6537, value_loss: 0.9392
2024-07-14 05:14:28,222 [INFO    ] __main__: train step 3511: loss: 0.7170, policy_loss: 1.6536, value_loss: 0.9392
2024-07-14 05:14:28,514 [INFO    ] __main__: train step 3512: loss: 0.7171, policy_loss: 1.6535, value_loss: 0.9391
2024-07-14 05:14:28,791 [INFO    ] __main__: train step 3513: loss: 0.7172, policy_loss: 1.6534, value_loss: 0.9391
2024-07-14 05:14:29,077 [INFO    ] __main__: train step 3514: loss: 0.7174, policy_loss: 1.6533, value_loss: 0.9391
2024-07-14 05:14:30,042 [INFO    ] __main__: train step 3515: loss: 0.7175, policy_loss: 1.6532, value_loss: 0.9390
2024-07-14 05:14:31,659 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:14:32,132 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:14:32,203 [INFO    ] __main__: train step 3516: loss: 0.7176, policy_loss: 1.6530, value_loss: 0.9390
2024-07-14 05:14:32,491 [INFO    ] __main__: train step 3517: loss: 0.7177, policy_loss: 1.6529, value_loss: 0.9389
2024-07-14 05:14:32,814 [INFO    ] __main__: train step 3518: loss: 0.7179, policy_loss: 1.6528, value_loss: 0.9389
2024-07-14 05:14:33,097 [INFO    ] __main__: train step 3519: loss: 0.7180, policy_loss: 1.6527, value_loss: 0.9389
2024-07-14 05:14:33,376 [INFO    ] __main__: train step 3520: loss: 0.7181, policy_loss: 1.6526, value_loss: 0.9389
2024-07-14 05:14:33,660 [INFO    ] __main__: train step 3521: loss: 0.7183, policy_loss: 1.6525, value_loss: 0.9388
2024-07-14 05:14:33,946 [INFO    ] __main__: train step 3522: loss: 0.7184, policy_loss: 1.6524, value_loss: 0.9388
2024-07-14 05:14:34,227 [INFO    ] __main__: train step 3523: loss: 0.7185, policy_loss: 1.6522, value_loss: 0.9388
2024-07-14 05:14:34,502 [INFO    ] __main__: train step 3524: loss: 0.7187, policy_loss: 1.6521, value_loss: 0.9387
2024-07-14 05:14:34,790 [INFO    ] __main__: train step 3525: loss: 0.7188, policy_loss: 1.6520, value_loss: 0.9387
2024-07-14 05:14:35,075 [INFO    ] __main__: train step 3526: loss: 0.7189, policy_loss: 1.6519, value_loss: 0.9387
2024-07-14 05:14:35,359 [INFO    ] __main__: train step 3527: loss: 0.7190, policy_loss: 1.6518, value_loss: 0.9386
2024-07-14 05:14:35,644 [INFO    ] __main__: train step 3528: loss: 0.7192, policy_loss: 1.6517, value_loss: 0.9386
2024-07-14 05:14:35,912 [INFO    ] __main__: train step 3529: loss: 0.7193, policy_loss: 1.6516, value_loss: 0.9386
2024-07-14 05:14:36,191 [INFO    ] __main__: train step 3530: loss: 0.7194, policy_loss: 1.6514, value_loss: 0.9385
2024-07-14 05:14:36,465 [INFO    ] __main__: train step 3531: loss: 0.7196, policy_loss: 1.6513, value_loss: 0.9385
2024-07-14 05:14:36,736 [INFO    ] __main__: train step 3532: loss: 0.7197, policy_loss: 1.6512, value_loss: 0.9385
2024-07-14 05:14:38,346 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:14:38,816 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:14:38,889 [INFO    ] __main__: train step 3533: loss: 0.7198, policy_loss: 1.6511, value_loss: 0.9384
2024-07-14 05:14:39,211 [INFO    ] __main__: train step 3534: loss: 0.7199, policy_loss: 1.6510, value_loss: 0.9384
2024-07-14 05:14:40,034 [INFO    ] __main__: train step 3535: loss: 0.7201, policy_loss: 1.6509, value_loss: 0.9384
2024-07-14 05:14:40,304 [INFO    ] __main__: train step 3536: loss: 0.7202, policy_loss: 1.6508, value_loss: 0.9383
2024-07-14 05:14:40,578 [INFO    ] __main__: train step 3537: loss: 0.7203, policy_loss: 1.6506, value_loss: 0.9383
2024-07-14 05:14:40,857 [INFO    ] __main__: train step 3538: loss: 0.7205, policy_loss: 1.6505, value_loss: 0.9383
2024-07-14 05:14:41,136 [INFO    ] __main__: train step 3539: loss: 0.7206, policy_loss: 1.6504, value_loss: 0.9383
2024-07-14 05:14:41,414 [INFO    ] __main__: train step 3540: loss: 0.7207, policy_loss: 1.6503, value_loss: 0.9382
2024-07-14 05:14:41,692 [INFO    ] __main__: train step 3541: loss: 0.7209, policy_loss: 1.6502, value_loss: 0.9382
2024-07-14 05:14:41,965 [INFO    ] __main__: train step 3542: loss: 0.7210, policy_loss: 1.6501, value_loss: 0.9382
2024-07-14 05:14:42,241 [INFO    ] __main__: train step 3543: loss: 0.7211, policy_loss: 1.6499, value_loss: 0.9382
2024-07-14 05:14:42,529 [INFO    ] __main__: train step 3544: loss: 0.7213, policy_loss: 1.6498, value_loss: 0.9381
2024-07-14 05:14:42,807 [INFO    ] __main__: train step 3545: loss: 0.7214, policy_loss: 1.6497, value_loss: 0.9381
2024-07-14 05:14:43,079 [INFO    ] __main__: train step 3546: loss: 0.7215, policy_loss: 1.6496, value_loss: 0.9381
2024-07-14 05:14:43,354 [INFO    ] __main__: train step 3547: loss: 0.7216, policy_loss: 1.6495, value_loss: 0.9380
2024-07-14 05:14:43,609 [INFO    ] __main__: train step 3548: loss: 0.7218, policy_loss: 1.6494, value_loss: 0.9380
2024-07-14 05:14:43,892 [INFO    ] __main__: train step 3549: loss: 0.7219, policy_loss: 1.6493, value_loss: 0.9380
2024-07-14 05:14:45,493 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:14:45,960 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:14:46,032 [INFO    ] __main__: train step 3550: loss: 0.7220, policy_loss: 1.6491, value_loss: 0.9379
2024-07-14 05:14:46,307 [INFO    ] __main__: train step 3551: loss: 0.7222, policy_loss: 1.6490, value_loss: 0.9379
2024-07-14 05:14:46,576 [INFO    ] __main__: train step 3552: loss: 0.7223, policy_loss: 1.6489, value_loss: 0.9379
2024-07-14 05:14:46,842 [INFO    ] __main__: train step 3553: loss: 0.7224, policy_loss: 1.6488, value_loss: 0.9378
2024-07-14 05:14:47,117 [INFO    ] __main__: train step 3554: loss: 0.7225, policy_loss: 1.6487, value_loss: 0.9378
2024-07-14 05:14:47,748 [INFO    ] __main__: train step 3555: loss: 0.7227, policy_loss: 1.6486, value_loss: 0.9378
2024-07-14 05:14:48,026 [INFO    ] __main__: train step 3556: loss: 0.7228, policy_loss: 1.6485, value_loss: 0.9378
2024-07-14 05:14:48,280 [INFO    ] __main__: train step 3557: loss: 0.7229, policy_loss: 1.6483, value_loss: 0.9377
2024-07-14 05:14:48,550 [INFO    ] __main__: train step 3558: loss: 0.7231, policy_loss: 1.6482, value_loss: 0.9377
2024-07-14 05:14:48,831 [INFO    ] __main__: train step 3559: loss: 0.7232, policy_loss: 1.6481, value_loss: 0.9377
2024-07-14 05:14:49,111 [INFO    ] __main__: train step 3560: loss: 0.7233, policy_loss: 1.6480, value_loss: 0.9376
2024-07-14 05:14:49,382 [INFO    ] __main__: train step 3561: loss: 0.7234, policy_loss: 1.6479, value_loss: 0.9376
2024-07-14 05:14:49,661 [INFO    ] __main__: train step 3562: loss: 0.7236, policy_loss: 1.6478, value_loss: 0.9376
2024-07-14 05:14:49,940 [INFO    ] __main__: train step 3563: loss: 0.7237, policy_loss: 1.6477, value_loss: 0.9375
2024-07-14 05:14:50,213 [INFO    ] __main__: train step 3564: loss: 0.7238, policy_loss: 1.6475, value_loss: 0.9375
2024-07-14 05:14:50,487 [INFO    ] __main__: train step 3565: loss: 0.7240, policy_loss: 1.6474, value_loss: 0.9375
2024-07-14 05:14:50,763 [INFO    ] __main__: train step 3566: loss: 0.7241, policy_loss: 1.6473, value_loss: 0.9375
2024-07-14 05:14:52,371 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:14:52,845 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:14:52,912 [INFO    ] __main__: train step 3567: loss: 0.7242, policy_loss: 1.6472, value_loss: 0.9374
2024-07-14 05:14:53,188 [INFO    ] __main__: train step 3568: loss: 0.7244, policy_loss: 1.6471, value_loss: 0.9374
2024-07-14 05:14:53,464 [INFO    ] __main__: train step 3569: loss: 0.7245, policy_loss: 1.6470, value_loss: 0.9374
2024-07-14 05:14:53,720 [INFO    ] __main__: train step 3570: loss: 0.7246, policy_loss: 1.6469, value_loss: 0.9373
2024-07-14 05:14:53,980 [INFO    ] __main__: train step 3571: loss: 0.7248, policy_loss: 1.6467, value_loss: 0.9373
2024-07-14 05:14:54,233 [INFO    ] __main__: train step 3572: loss: 0.7249, policy_loss: 1.6466, value_loss: 0.9373
2024-07-14 05:14:54,498 [INFO    ] __main__: train step 3573: loss: 0.7250, policy_loss: 1.6465, value_loss: 0.9372
2024-07-14 05:14:54,788 [INFO    ] __main__: train step 3574: loss: 0.7252, policy_loss: 1.6464, value_loss: 0.9372
2024-07-14 05:14:55,701 [INFO    ] __main__: train step 3575: loss: 0.7253, policy_loss: 1.6463, value_loss: 0.9372
2024-07-14 05:14:55,987 [INFO    ] __main__: train step 3576: loss: 0.7254, policy_loss: 1.6462, value_loss: 0.9372
2024-07-14 05:14:56,297 [INFO    ] __main__: train step 3577: loss: 0.7256, policy_loss: 1.6461, value_loss: 0.9371
2024-07-14 05:14:56,580 [INFO    ] __main__: train step 3578: loss: 0.7257, policy_loss: 1.6460, value_loss: 0.9371
2024-07-14 05:14:56,868 [INFO    ] __main__: train step 3579: loss: 0.7258, policy_loss: 1.6458, value_loss: 0.9371
2024-07-14 05:14:57,154 [INFO    ] __main__: train step 3580: loss: 0.7259, policy_loss: 1.6457, value_loss: 0.9370
2024-07-14 05:14:57,420 [INFO    ] __main__: train step 3581: loss: 0.7261, policy_loss: 1.6456, value_loss: 0.9370
2024-07-14 05:14:57,698 [INFO    ] __main__: train step 3582: loss: 0.7262, policy_loss: 1.6455, value_loss: 0.9370
2024-07-14 05:14:57,970 [INFO    ] __main__: train step 3583: loss: 0.7263, policy_loss: 1.6454, value_loss: 0.9369
2024-07-14 05:14:59,568 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:15:00,046 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:15:00,112 [INFO    ] __main__: train step 3584: loss: 0.7265, policy_loss: 1.6453, value_loss: 0.9369
2024-07-14 05:15:00,388 [INFO    ] __main__: train step 3585: loss: 0.7266, policy_loss: 1.6452, value_loss: 0.9369
2024-07-14 05:15:00,668 [INFO    ] __main__: train step 3586: loss: 0.7267, policy_loss: 1.6451, value_loss: 0.9368
2024-07-14 05:15:00,941 [INFO    ] __main__: train step 3587: loss: 0.7269, policy_loss: 1.6450, value_loss: 0.9368
2024-07-14 05:15:01,212 [INFO    ] __main__: train step 3588: loss: 0.7270, policy_loss: 1.6448, value_loss: 0.9368
2024-07-14 05:15:01,495 [INFO    ] __main__: train step 3589: loss: 0.7271, policy_loss: 1.6447, value_loss: 0.9367
2024-07-14 05:15:01,759 [INFO    ] __main__: train step 3590: loss: 0.7273, policy_loss: 1.6446, value_loss: 0.9367
2024-07-14 05:15:02,060 [INFO    ] __main__: train step 3591: loss: 0.7274, policy_loss: 1.6445, value_loss: 0.9367
2024-07-14 05:15:02,336 [INFO    ] __main__: train step 3592: loss: 0.7275, policy_loss: 1.6444, value_loss: 0.9366
2024-07-14 05:15:02,609 [INFO    ] __main__: train step 3593: loss: 0.7277, policy_loss: 1.6443, value_loss: 0.9366
2024-07-14 05:15:03,512 [INFO    ] __main__: train step 3594: loss: 0.7278, policy_loss: 1.6442, value_loss: 0.9366
2024-07-14 05:15:03,815 [INFO    ] __main__: train step 3595: loss: 0.7279, policy_loss: 1.6441, value_loss: 0.9365
2024-07-14 05:15:04,095 [INFO    ] __main__: train step 3596: loss: 0.7280, policy_loss: 1.6439, value_loss: 0.9365
2024-07-14 05:15:04,379 [INFO    ] __main__: train step 3597: loss: 0.7282, policy_loss: 1.6438, value_loss: 0.9365
2024-07-14 05:15:04,659 [INFO    ] __main__: train step 3598: loss: 0.7283, policy_loss: 1.6437, value_loss: 0.9364
2024-07-14 05:15:04,952 [INFO    ] __main__: train step 3599: loss: 0.7284, policy_loss: 1.6436, value_loss: 0.9364
2024-07-14 05:15:05,256 [INFO    ] __main__: train step 3600: loss: 0.7285, policy_loss: 1.6435, value_loss: 0.9364
2024-07-14 05:15:06,865 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:15:07,352 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:15:07,418 [INFO    ] __main__: train step 3601: loss: 0.7287, policy_loss: 1.6434, value_loss: 0.9363
2024-07-14 05:15:07,741 [INFO    ] __main__: train step 3602: loss: 0.7288, policy_loss: 1.6433, value_loss: 0.9363
2024-07-14 05:15:08,023 [INFO    ] __main__: train step 3603: loss: 0.7289, policy_loss: 1.6432, value_loss: 0.9363
2024-07-14 05:15:08,303 [INFO    ] __main__: train step 3604: loss: 0.7291, policy_loss: 1.6430, value_loss: 0.9363
2024-07-14 05:15:08,579 [INFO    ] __main__: train step 3605: loss: 0.7292, policy_loss: 1.6429, value_loss: 0.9362
2024-07-14 05:15:08,870 [INFO    ] __main__: train step 3606: loss: 0.7293, policy_loss: 1.6428, value_loss: 0.9362
2024-07-14 05:15:09,149 [INFO    ] __main__: train step 3607: loss: 0.7295, policy_loss: 1.6427, value_loss: 0.9362
2024-07-14 05:15:09,427 [INFO    ] __main__: train step 3608: loss: 0.7296, policy_loss: 1.6426, value_loss: 0.9361
2024-07-14 05:15:09,707 [INFO    ] __main__: train step 3609: loss: 0.7297, policy_loss: 1.6425, value_loss: 0.9361
2024-07-14 05:15:09,967 [INFO    ] __main__: train step 3610: loss: 0.7299, policy_loss: 1.6424, value_loss: 0.9361
2024-07-14 05:15:10,245 [INFO    ] __main__: train step 3611: loss: 0.7300, policy_loss: 1.6422, value_loss: 0.9360
2024-07-14 05:15:10,535 [INFO    ] __main__: train step 3612: loss: 0.7301, policy_loss: 1.6421, value_loss: 0.9360
2024-07-14 05:15:10,818 [INFO    ] __main__: train step 3613: loss: 0.7303, policy_loss: 1.6420, value_loss: 0.9360
2024-07-14 05:15:11,743 [INFO    ] __main__: train step 3614: loss: 0.7304, policy_loss: 1.6419, value_loss: 0.9360
2024-07-14 05:15:12,033 [INFO    ] __main__: train step 3615: loss: 0.7305, policy_loss: 1.6418, value_loss: 0.9359
2024-07-14 05:15:12,315 [INFO    ] __main__: train step 3616: loss: 0.7307, policy_loss: 1.6417, value_loss: 0.9359
2024-07-14 05:15:12,587 [INFO    ] __main__: train step 3617: loss: 0.7308, policy_loss: 1.6416, value_loss: 0.9359
2024-07-14 05:15:14,174 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:15:14,658 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:15:14,722 [INFO    ] __main__: train step 3618: loss: 0.7309, policy_loss: 1.6415, value_loss: 0.9358
2024-07-14 05:15:14,995 [INFO    ] __main__: train step 3619: loss: 0.7310, policy_loss: 1.6413, value_loss: 0.9358
2024-07-14 05:15:15,271 [INFO    ] __main__: train step 3620: loss: 0.7312, policy_loss: 1.6412, value_loss: 0.9358
2024-07-14 05:15:15,561 [INFO    ] __main__: train step 3621: loss: 0.7313, policy_loss: 1.6411, value_loss: 0.9357
2024-07-14 05:15:15,842 [INFO    ] __main__: train step 3622: loss: 0.7314, policy_loss: 1.6410, value_loss: 0.9357
2024-07-14 05:15:16,120 [INFO    ] __main__: train step 3623: loss: 0.7316, policy_loss: 1.6409, value_loss: 0.9357
2024-07-14 05:15:16,399 [INFO    ] __main__: train step 3624: loss: 0.7317, policy_loss: 1.6408, value_loss: 0.9356
2024-07-14 05:15:16,673 [INFO    ] __main__: train step 3625: loss: 0.7318, policy_loss: 1.6407, value_loss: 0.9356
2024-07-14 05:15:16,959 [INFO    ] __main__: train step 3626: loss: 0.7319, policy_loss: 1.6406, value_loss: 0.9356
2024-07-14 05:15:17,240 [INFO    ] __main__: train step 3627: loss: 0.7321, policy_loss: 1.6404, value_loss: 0.9356
2024-07-14 05:15:17,518 [INFO    ] __main__: train step 3628: loss: 0.7322, policy_loss: 1.6403, value_loss: 0.9355
2024-07-14 05:15:17,799 [INFO    ] __main__: train step 3629: loss: 0.7323, policy_loss: 1.6402, value_loss: 0.9355
2024-07-14 05:15:18,070 [INFO    ] __main__: train step 3630: loss: 0.7325, policy_loss: 1.6401, value_loss: 0.9355
2024-07-14 05:15:18,338 [INFO    ] __main__: train step 3631: loss: 0.7326, policy_loss: 1.6400, value_loss: 0.9354
2024-07-14 05:15:18,625 [INFO    ] __main__: train step 3632: loss: 0.7327, policy_loss: 1.6399, value_loss: 0.9354
2024-07-14 05:15:19,490 [INFO    ] __main__: train step 3633: loss: 0.7328, policy_loss: 1.6397, value_loss: 0.9354
2024-07-14 05:15:19,772 [INFO    ] __main__: train step 3634: loss: 0.7330, policy_loss: 1.6396, value_loss: 0.9353
2024-07-14 05:15:21,362 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:15:21,837 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:15:21,911 [INFO    ] __main__: train step 3635: loss: 0.7331, policy_loss: 1.6395, value_loss: 0.9353
2024-07-14 05:15:22,194 [INFO    ] __main__: train step 3636: loss: 0.7332, policy_loss: 1.6394, value_loss: 0.9352
2024-07-14 05:15:22,472 [INFO    ] __main__: train step 3637: loss: 0.7334, policy_loss: 1.6393, value_loss: 0.9352
2024-07-14 05:15:22,747 [INFO    ] __main__: train step 3638: loss: 0.7335, policy_loss: 1.6392, value_loss: 0.9352
2024-07-14 05:15:23,024 [INFO    ] __main__: train step 3639: loss: 0.7336, policy_loss: 1.6391, value_loss: 0.9352
2024-07-14 05:15:23,298 [INFO    ] __main__: train step 3640: loss: 0.7337, policy_loss: 1.6390, value_loss: 0.9351
2024-07-14 05:15:23,587 [INFO    ] __main__: train step 3641: loss: 0.7339, policy_loss: 1.6389, value_loss: 0.9351
2024-07-14 05:15:23,880 [INFO    ] __main__: train step 3642: loss: 0.7340, policy_loss: 1.6387, value_loss: 0.9351
2024-07-14 05:15:24,162 [INFO    ] __main__: train step 3643: loss: 0.7341, policy_loss: 1.6386, value_loss: 0.9350
2024-07-14 05:15:24,443 [INFO    ] __main__: train step 3644: loss: 0.7342, policy_loss: 1.6385, value_loss: 0.9350
2024-07-14 05:15:24,725 [INFO    ] __main__: train step 3645: loss: 0.7344, policy_loss: 1.6384, value_loss: 0.9350
2024-07-14 05:15:24,989 [INFO    ] __main__: train step 3646: loss: 0.7345, policy_loss: 1.6383, value_loss: 0.9349
2024-07-14 05:15:25,265 [INFO    ] __main__: train step 3647: loss: 0.7346, policy_loss: 1.6382, value_loss: 0.9349
2024-07-14 05:15:25,554 [INFO    ] __main__: train step 3648: loss: 0.7347, policy_loss: 1.6381, value_loss: 0.9349
2024-07-14 05:15:25,838 [INFO    ] __main__: train step 3649: loss: 0.7349, policy_loss: 1.6379, value_loss: 0.9348
2024-07-14 05:15:26,125 [INFO    ] __main__: train step 3650: loss: 0.7350, policy_loss: 1.6378, value_loss: 0.9348
2024-07-14 05:15:26,404 [INFO    ] __main__: train step 3651: loss: 0.7351, policy_loss: 1.6377, value_loss: 0.9348
2024-07-14 05:15:27,998 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:15:28,473 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:15:28,541 [INFO    ] __main__: train step 3652: loss: 0.7352, policy_loss: 1.6376, value_loss: 0.9347
2024-07-14 05:15:29,427 [INFO    ] __main__: train step 3653: loss: 0.7354, policy_loss: 1.6375, value_loss: 0.9347
2024-07-14 05:15:29,698 [INFO    ] __main__: train step 3654: loss: 0.7355, policy_loss: 1.6374, value_loss: 0.9347
2024-07-14 05:15:29,980 [INFO    ] __main__: train step 3655: loss: 0.7356, policy_loss: 1.6373, value_loss: 0.9346
2024-07-14 05:15:30,263 [INFO    ] __main__: train step 3656: loss: 0.7358, policy_loss: 1.6372, value_loss: 0.9346
2024-07-14 05:15:30,543 [INFO    ] __main__: train step 3657: loss: 0.7359, policy_loss: 1.6370, value_loss: 0.9346
2024-07-14 05:15:30,828 [INFO    ] __main__: train step 3658: loss: 0.7360, policy_loss: 1.6369, value_loss: 0.9345
2024-07-14 05:15:31,104 [INFO    ] __main__: train step 3659: loss: 0.7362, policy_loss: 1.6368, value_loss: 0.9345
2024-07-14 05:15:31,390 [INFO    ] __main__: train step 3660: loss: 0.7363, policy_loss: 1.6367, value_loss: 0.9345
2024-07-14 05:15:31,671 [INFO    ] __main__: train step 3661: loss: 0.7364, policy_loss: 1.6366, value_loss: 0.9344
2024-07-14 05:15:31,945 [INFO    ] __main__: train step 3662: loss: 0.7365, policy_loss: 1.6365, value_loss: 0.9344
2024-07-14 05:15:32,220 [INFO    ] __main__: train step 3663: loss: 0.7367, policy_loss: 1.6364, value_loss: 0.9344
2024-07-14 05:15:32,483 [INFO    ] __main__: train step 3664: loss: 0.7368, policy_loss: 1.6363, value_loss: 0.9344
2024-07-14 05:15:32,756 [INFO    ] __main__: train step 3665: loss: 0.7369, policy_loss: 1.6362, value_loss: 0.9343
2024-07-14 05:15:33,050 [INFO    ] __main__: train step 3666: loss: 0.7370, policy_loss: 1.6360, value_loss: 0.9343
2024-07-14 05:15:33,324 [INFO    ] __main__: train step 3667: loss: 0.7372, policy_loss: 1.6359, value_loss: 0.9343
2024-07-14 05:15:33,606 [INFO    ] __main__: train step 3668: loss: 0.7373, policy_loss: 1.6358, value_loss: 0.9342
2024-07-14 05:15:35,208 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:15:35,681 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:15:35,751 [INFO    ] __main__: train step 3669: loss: 0.7374, policy_loss: 1.6357, value_loss: 0.9342
2024-07-14 05:15:36,033 [INFO    ] __main__: train step 3670: loss: 0.7376, policy_loss: 1.6356, value_loss: 0.9342
2024-07-14 05:15:36,299 [INFO    ] __main__: train step 3671: loss: 0.7377, policy_loss: 1.6355, value_loss: 0.9342
2024-07-14 05:15:36,919 [INFO    ] __main__: train step 3672: loss: 0.7378, policy_loss: 1.6354, value_loss: 0.9341
2024-07-14 05:15:37,194 [INFO    ] __main__: train step 3673: loss: 0.7379, policy_loss: 1.6352, value_loss: 0.9341
2024-07-14 05:15:37,471 [INFO    ] __main__: train step 3674: loss: 0.7381, policy_loss: 1.6351, value_loss: 0.9341
2024-07-14 05:15:37,755 [INFO    ] __main__: train step 3675: loss: 0.7382, policy_loss: 1.6350, value_loss: 0.9340
2024-07-14 05:15:38,032 [INFO    ] __main__: train step 3676: loss: 0.7383, policy_loss: 1.6349, value_loss: 0.9340
2024-07-14 05:15:38,300 [INFO    ] __main__: train step 3677: loss: 0.7385, policy_loss: 1.6348, value_loss: 0.9340
2024-07-14 05:15:38,561 [INFO    ] __main__: train step 3678: loss: 0.7386, policy_loss: 1.6347, value_loss: 0.9339
2024-07-14 05:15:38,827 [INFO    ] __main__: train step 3679: loss: 0.7387, policy_loss: 1.6346, value_loss: 0.9339
2024-07-14 05:15:39,102 [INFO    ] __main__: train step 3680: loss: 0.7388, policy_loss: 1.6345, value_loss: 0.9339
2024-07-14 05:15:39,378 [INFO    ] __main__: train step 3681: loss: 0.7390, policy_loss: 1.6344, value_loss: 0.9339
2024-07-14 05:15:39,662 [INFO    ] __main__: train step 3682: loss: 0.7391, policy_loss: 1.6342, value_loss: 0.9338
2024-07-14 05:15:39,941 [INFO    ] __main__: train step 3683: loss: 0.7392, policy_loss: 1.6341, value_loss: 0.9338
2024-07-14 05:15:40,192 [INFO    ] __main__: train step 3684: loss: 0.7394, policy_loss: 1.6340, value_loss: 0.9338
2024-07-14 05:15:40,455 [INFO    ] __main__: train step 3685: loss: 0.7395, policy_loss: 1.6339, value_loss: 0.9337
2024-07-14 05:15:42,059 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:15:42,534 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:15:42,610 [INFO    ] __main__: train step 3686: loss: 0.7396, policy_loss: 1.6338, value_loss: 0.9337
2024-07-14 05:15:42,905 [INFO    ] __main__: train step 3687: loss: 0.7397, policy_loss: 1.6337, value_loss: 0.9337
2024-07-14 05:15:43,178 [INFO    ] __main__: train step 3688: loss: 0.7399, policy_loss: 1.6336, value_loss: 0.9336
2024-07-14 05:15:43,450 [INFO    ] __main__: train step 3689: loss: 0.7400, policy_loss: 1.6335, value_loss: 0.9336
2024-07-14 05:15:43,727 [INFO    ] __main__: train step 3690: loss: 0.7401, policy_loss: 1.6333, value_loss: 0.9336
2024-07-14 05:15:44,364 [INFO    ] __main__: train step 3691: loss: 0.7402, policy_loss: 1.6332, value_loss: 0.9335
2024-07-14 05:15:44,666 [INFO    ] __main__: train step 3692: loss: 0.7404, policy_loss: 1.6331, value_loss: 0.9335
2024-07-14 05:15:44,962 [INFO    ] __main__: train step 3693: loss: 0.7405, policy_loss: 1.6330, value_loss: 0.9335
2024-07-14 05:15:45,250 [INFO    ] __main__: train step 3694: loss: 0.7406, policy_loss: 1.6329, value_loss: 0.9335
2024-07-14 05:15:45,529 [INFO    ] __main__: train step 3695: loss: 0.7408, policy_loss: 1.6328, value_loss: 0.9334
2024-07-14 05:15:45,816 [INFO    ] __main__: train step 3696: loss: 0.7409, policy_loss: 1.6327, value_loss: 0.9334
2024-07-14 05:15:46,098 [INFO    ] __main__: train step 3697: loss: 0.7410, policy_loss: 1.6325, value_loss: 0.9334
2024-07-14 05:15:46,383 [INFO    ] __main__: train step 3698: loss: 0.7411, policy_loss: 1.6324, value_loss: 0.9333
2024-07-14 05:15:46,659 [INFO    ] __main__: train step 3699: loss: 0.7413, policy_loss: 1.6323, value_loss: 0.9333
2024-07-14 05:15:46,935 [INFO    ] __main__: train step 3700: loss: 0.7414, policy_loss: 1.6322, value_loss: 0.9333
2024-07-14 05:15:47,220 [INFO    ] __main__: train step 3701: loss: 0.7415, policy_loss: 1.6321, value_loss: 0.9332
2024-07-14 05:15:47,502 [INFO    ] __main__: train step 3702: loss: 0.7416, policy_loss: 1.6320, value_loss: 0.9332
2024-07-14 05:15:49,107 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:15:49,600 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:15:49,666 [INFO    ] __main__: train step 3703: loss: 0.7418, policy_loss: 1.6319, value_loss: 0.9332
2024-07-14 05:15:49,947 [INFO    ] __main__: train step 3704: loss: 0.7419, policy_loss: 1.6318, value_loss: 0.9331
2024-07-14 05:15:50,230 [INFO    ] __main__: train step 3705: loss: 0.7420, policy_loss: 1.6316, value_loss: 0.9331
2024-07-14 05:15:50,510 [INFO    ] __main__: train step 3706: loss: 0.7422, policy_loss: 1.6315, value_loss: 0.9331
2024-07-14 05:15:50,790 [INFO    ] __main__: train step 3707: loss: 0.7423, policy_loss: 1.6314, value_loss: 0.9330
2024-07-14 05:15:51,048 [INFO    ] __main__: train step 3708: loss: 0.7424, policy_loss: 1.6313, value_loss: 0.9330
2024-07-14 05:15:51,322 [INFO    ] __main__: train step 3709: loss: 0.7425, policy_loss: 1.6312, value_loss: 0.9330
2024-07-14 05:15:51,618 [INFO    ] __main__: train step 3710: loss: 0.7427, policy_loss: 1.6311, value_loss: 0.9330
2024-07-14 05:15:52,523 [INFO    ] __main__: train step 3711: loss: 0.7428, policy_loss: 1.6310, value_loss: 0.9329
2024-07-14 05:15:52,817 [INFO    ] __main__: train step 3712: loss: 0.7429, policy_loss: 1.6309, value_loss: 0.9329
2024-07-14 05:15:53,109 [INFO    ] __main__: train step 3713: loss: 0.7430, policy_loss: 1.6307, value_loss: 0.9329
2024-07-14 05:15:53,399 [INFO    ] __main__: train step 3714: loss: 0.7431, policy_loss: 1.6306, value_loss: 0.9328
2024-07-14 05:15:53,683 [INFO    ] __main__: train step 3715: loss: 0.7433, policy_loss: 1.6305, value_loss: 0.9328
2024-07-14 05:15:53,965 [INFO    ] __main__: train step 3716: loss: 0.7434, policy_loss: 1.6304, value_loss: 0.9328
2024-07-14 05:15:54,248 [INFO    ] __main__: train step 3717: loss: 0.7435, policy_loss: 1.6303, value_loss: 0.9327
2024-07-14 05:15:54,524 [INFO    ] __main__: train step 3718: loss: 0.7436, policy_loss: 1.6302, value_loss: 0.9327
2024-07-14 05:15:54,796 [INFO    ] __main__: train step 3719: loss: 0.7438, policy_loss: 1.6301, value_loss: 0.9327
2024-07-14 05:15:56,397 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:15:56,832 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:15:56,900 [INFO    ] __main__: train step 3720: loss: 0.7439, policy_loss: 1.6300, value_loss: 0.9327
2024-07-14 05:15:57,179 [INFO    ] __main__: train step 3721: loss: 0.7440, policy_loss: 1.6298, value_loss: 0.9326
2024-07-14 05:15:57,447 [INFO    ] __main__: train step 3722: loss: 0.7442, policy_loss: 1.6297, value_loss: 0.9326
2024-07-14 05:15:57,729 [INFO    ] __main__: train step 3723: loss: 0.7443, policy_loss: 1.6296, value_loss: 0.9326
2024-07-14 05:15:57,998 [INFO    ] __main__: train step 3724: loss: 0.7444, policy_loss: 1.6295, value_loss: 0.9325
2024-07-14 05:15:58,283 [INFO    ] __main__: train step 3725: loss: 0.7445, policy_loss: 1.6294, value_loss: 0.9325
2024-07-14 05:15:58,552 [INFO    ] __main__: train step 3726: loss: 0.7447, policy_loss: 1.6293, value_loss: 0.9325
2024-07-14 05:15:58,835 [INFO    ] __main__: train step 3727: loss: 0.7448, policy_loss: 1.6292, value_loss: 0.9324
2024-07-14 05:15:59,108 [INFO    ] __main__: train step 3728: loss: 0.7449, policy_loss: 1.6291, value_loss: 0.9324
2024-07-14 05:15:59,387 [INFO    ] __main__: train step 3729: loss: 0.7450, policy_loss: 1.6289, value_loss: 0.9324
2024-07-14 05:15:59,657 [INFO    ] __main__: train step 3730: loss: 0.7452, policy_loss: 1.6288, value_loss: 0.9323
2024-07-14 05:16:00,552 [INFO    ] __main__: train step 3731: loss: 0.7453, policy_loss: 1.6287, value_loss: 0.9323
2024-07-14 05:16:00,831 [INFO    ] __main__: train step 3732: loss: 0.7454, policy_loss: 1.6286, value_loss: 0.9323
2024-07-14 05:16:01,108 [INFO    ] __main__: train step 3733: loss: 0.7455, policy_loss: 1.6285, value_loss: 0.9322
2024-07-14 05:16:01,392 [INFO    ] __main__: train step 3734: loss: 0.7457, policy_loss: 1.6284, value_loss: 0.9322
2024-07-14 05:16:01,658 [INFO    ] __main__: train step 3735: loss: 0.7458, policy_loss: 1.6283, value_loss: 0.9322
2024-07-14 05:16:01,931 [INFO    ] __main__: train step 3736: loss: 0.7459, policy_loss: 1.6282, value_loss: 0.9321
2024-07-14 05:16:03,527 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:16:04,024 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:16:04,094 [INFO    ] __main__: train step 3737: loss: 0.7460, policy_loss: 1.6280, value_loss: 0.9321
2024-07-14 05:16:04,382 [INFO    ] __main__: train step 3738: loss: 0.7462, policy_loss: 1.6279, value_loss: 0.9321
2024-07-14 05:16:04,654 [INFO    ] __main__: train step 3739: loss: 0.7463, policy_loss: 1.6278, value_loss: 0.9321
2024-07-14 05:16:04,932 [INFO    ] __main__: train step 3740: loss: 0.7464, policy_loss: 1.6277, value_loss: 0.9320
2024-07-14 05:16:05,222 [INFO    ] __main__: train step 3741: loss: 0.7466, policy_loss: 1.6276, value_loss: 0.9320
2024-07-14 05:16:05,504 [INFO    ] __main__: train step 3742: loss: 0.7467, policy_loss: 1.6275, value_loss: 0.9319
2024-07-14 05:16:05,792 [INFO    ] __main__: train step 3743: loss: 0.7468, policy_loss: 1.6274, value_loss: 0.9319
2024-07-14 05:16:06,073 [INFO    ] __main__: train step 3744: loss: 0.7469, policy_loss: 1.6272, value_loss: 0.9319
2024-07-14 05:16:06,353 [INFO    ] __main__: train step 3745: loss: 0.7471, policy_loss: 1.6271, value_loss: 0.9319
2024-07-14 05:16:06,626 [INFO    ] __main__: train step 3746: loss: 0.7472, policy_loss: 1.6270, value_loss: 0.9318
2024-07-14 05:16:06,900 [INFO    ] __main__: train step 3747: loss: 0.7473, policy_loss: 1.6269, value_loss: 0.9318
2024-07-14 05:16:07,176 [INFO    ] __main__: train step 3748: loss: 0.7474, policy_loss: 1.6268, value_loss: 0.9318
2024-07-14 05:16:07,451 [INFO    ] __main__: train step 3749: loss: 0.7476, policy_loss: 1.6267, value_loss: 0.9317
2024-07-14 05:16:07,732 [INFO    ] __main__: train step 3750: loss: 0.7477, policy_loss: 1.6266, value_loss: 0.9317
2024-07-14 05:16:08,359 [INFO    ] __main__: train step 3751: loss: 0.7478, policy_loss: 1.6265, value_loss: 0.9317
2024-07-14 05:16:08,633 [INFO    ] __main__: train step 3752: loss: 0.7479, policy_loss: 1.6264, value_loss: 0.9316
2024-07-14 05:16:08,910 [INFO    ] __main__: train step 3753: loss: 0.7480, policy_loss: 1.6262, value_loss: 0.9316
2024-07-14 05:16:10,494 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:16:10,957 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:16:11,023 [INFO    ] __main__: train step 3754: loss: 0.7482, policy_loss: 1.6261, value_loss: 0.9316
2024-07-14 05:16:11,294 [INFO    ] __main__: train step 3755: loss: 0.7483, policy_loss: 1.6260, value_loss: 0.9315
2024-07-14 05:16:11,568 [INFO    ] __main__: train step 3756: loss: 0.7484, policy_loss: 1.6259, value_loss: 0.9315
2024-07-14 05:16:11,847 [INFO    ] __main__: train step 3757: loss: 0.7485, policy_loss: 1.6258, value_loss: 0.9315
2024-07-14 05:16:12,124 [INFO    ] __main__: train step 3758: loss: 0.7487, policy_loss: 1.6257, value_loss: 0.9315
2024-07-14 05:16:12,406 [INFO    ] __main__: train step 3759: loss: 0.7488, policy_loss: 1.6256, value_loss: 0.9314
2024-07-14 05:16:12,684 [INFO    ] __main__: train step 3760: loss: 0.7489, policy_loss: 1.6254, value_loss: 0.9314
2024-07-14 05:16:12,959 [INFO    ] __main__: train step 3761: loss: 0.7491, policy_loss: 1.6253, value_loss: 0.9314
2024-07-14 05:16:13,247 [INFO    ] __main__: train step 3762: loss: 0.7492, policy_loss: 1.6252, value_loss: 0.9313
2024-07-14 05:16:13,531 [INFO    ] __main__: train step 3763: loss: 0.7493, policy_loss: 1.6251, value_loss: 0.9313
2024-07-14 05:16:13,798 [INFO    ] __main__: train step 3764: loss: 0.7494, policy_loss: 1.6250, value_loss: 0.9313
2024-07-14 05:16:14,075 [INFO    ] __main__: train step 3765: loss: 0.7496, policy_loss: 1.6249, value_loss: 0.9312
2024-07-14 05:16:14,353 [INFO    ] __main__: train step 3766: loss: 0.7497, policy_loss: 1.6248, value_loss: 0.9312
2024-07-14 05:16:14,657 [INFO    ] __main__: train step 3767: loss: 0.7498, policy_loss: 1.6247, value_loss: 0.9312
2024-07-14 05:16:14,946 [INFO    ] __main__: train step 3768: loss: 0.7500, policy_loss: 1.6246, value_loss: 0.9312
2024-07-14 05:16:15,224 [INFO    ] __main__: train step 3769: loss: 0.7501, policy_loss: 1.6245, value_loss: 0.9311
2024-07-14 05:16:15,524 [INFO    ] __main__: train step 3770: loss: 0.7502, policy_loss: 1.6243, value_loss: 0.9311
2024-07-14 05:16:17,785 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:16:18,278 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:16:18,344 [INFO    ] __main__: train step 3771: loss: 0.7503, policy_loss: 1.6242, value_loss: 0.9311
2024-07-14 05:16:18,635 [INFO    ] __main__: train step 3772: loss: 0.7505, policy_loss: 1.6241, value_loss: 0.9310
2024-07-14 05:16:18,917 [INFO    ] __main__: train step 3773: loss: 0.7506, policy_loss: 1.6240, value_loss: 0.9310
2024-07-14 05:16:19,196 [INFO    ] __main__: train step 3774: loss: 0.7507, policy_loss: 1.6239, value_loss: 0.9310
2024-07-14 05:16:19,478 [INFO    ] __main__: train step 3775: loss: 0.7508, policy_loss: 1.6238, value_loss: 0.9310
2024-07-14 05:16:19,771 [INFO    ] __main__: train step 3776: loss: 0.7509, policy_loss: 1.6237, value_loss: 0.9309
2024-07-14 05:16:20,057 [INFO    ] __main__: train step 3777: loss: 0.7511, policy_loss: 1.6236, value_loss: 0.9309
2024-07-14 05:16:20,340 [INFO    ] __main__: train step 3778: loss: 0.7512, policy_loss: 1.6234, value_loss: 0.9309
2024-07-14 05:16:20,626 [INFO    ] __main__: train step 3779: loss: 0.7513, policy_loss: 1.6233, value_loss: 0.9308
2024-07-14 05:16:20,919 [INFO    ] __main__: train step 3780: loss: 0.7515, policy_loss: 1.6232, value_loss: 0.9308
2024-07-14 05:16:21,207 [INFO    ] __main__: train step 3781: loss: 0.7516, policy_loss: 1.6231, value_loss: 0.9308
2024-07-14 05:16:21,498 [INFO    ] __main__: train step 3782: loss: 0.7517, policy_loss: 1.6230, value_loss: 0.9307
2024-07-14 05:16:21,780 [INFO    ] __main__: train step 3783: loss: 0.7518, policy_loss: 1.6229, value_loss: 0.9307
2024-07-14 05:16:22,059 [INFO    ] __main__: train step 3784: loss: 0.7519, policy_loss: 1.6228, value_loss: 0.9307
2024-07-14 05:16:22,338 [INFO    ] __main__: train step 3785: loss: 0.7520, policy_loss: 1.6227, value_loss: 0.9306
2024-07-14 05:16:22,618 [INFO    ] __main__: train step 3786: loss: 0.7522, policy_loss: 1.6225, value_loss: 0.9306
2024-07-14 05:16:22,902 [INFO    ] __main__: train step 3787: loss: 0.7523, policy_loss: 1.6224, value_loss: 0.9306
2024-07-14 05:16:24,508 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:16:24,989 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:16:25,060 [INFO    ] __main__: train step 3788: loss: 0.7524, policy_loss: 1.6223, value_loss: 0.9306
2024-07-14 05:16:25,321 [INFO    ] __main__: train step 3789: loss: 0.7526, policy_loss: 1.6222, value_loss: 0.9305
2024-07-14 05:16:26,213 [INFO    ] __main__: train step 3790: loss: 0.7527, policy_loss: 1.6221, value_loss: 0.9305
2024-07-14 05:16:26,483 [INFO    ] __main__: train step 3791: loss: 0.7528, policy_loss: 1.6220, value_loss: 0.9305
2024-07-14 05:16:26,760 [INFO    ] __main__: train step 3792: loss: 0.7529, policy_loss: 1.6219, value_loss: 0.9304
2024-07-14 05:16:27,052 [INFO    ] __main__: train step 3793: loss: 0.7531, policy_loss: 1.6218, value_loss: 0.9304
2024-07-14 05:16:27,331 [INFO    ] __main__: train step 3794: loss: 0.7532, policy_loss: 1.6216, value_loss: 0.9304
2024-07-14 05:16:27,618 [INFO    ] __main__: train step 3795: loss: 0.7533, policy_loss: 1.6215, value_loss: 0.9303
2024-07-14 05:16:27,895 [INFO    ] __main__: train step 3796: loss: 0.7534, policy_loss: 1.6214, value_loss: 0.9303
2024-07-14 05:16:28,185 [INFO    ] __main__: train step 3797: loss: 0.7536, policy_loss: 1.6213, value_loss: 0.9303
2024-07-14 05:16:28,471 [INFO    ] __main__: train step 3798: loss: 0.7537, policy_loss: 1.6212, value_loss: 0.9303
2024-07-14 05:16:28,746 [INFO    ] __main__: train step 3799: loss: 0.7538, policy_loss: 1.6211, value_loss: 0.9302
2024-07-14 05:16:29,029 [INFO    ] __main__: train step 3800: loss: 0.7539, policy_loss: 1.6210, value_loss: 0.9302
2024-07-14 05:16:29,316 [INFO    ] __main__: train step 3801: loss: 0.7540, policy_loss: 1.6209, value_loss: 0.9302
2024-07-14 05:16:29,598 [INFO    ] __main__: train step 3802: loss: 0.7542, policy_loss: 1.6207, value_loss: 0.9301
2024-07-14 05:16:29,876 [INFO    ] __main__: train step 3803: loss: 0.7543, policy_loss: 1.6206, value_loss: 0.9301
2024-07-14 05:16:30,165 [INFO    ] __main__: train step 3804: loss: 0.7544, policy_loss: 1.6205, value_loss: 0.9301
2024-07-14 05:16:31,770 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:16:32,253 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:16:32,325 [INFO    ] __main__: train step 3805: loss: 0.7545, policy_loss: 1.6204, value_loss: 0.9300
2024-07-14 05:16:32,627 [INFO    ] __main__: train step 3806: loss: 0.7547, policy_loss: 1.6203, value_loss: 0.9300
2024-07-14 05:16:32,914 [INFO    ] __main__: train step 3807: loss: 0.7548, policy_loss: 1.6202, value_loss: 0.9300
2024-07-14 05:16:33,168 [INFO    ] __main__: train step 3808: loss: 0.7549, policy_loss: 1.6201, value_loss: 0.9299
2024-07-14 05:16:33,452 [INFO    ] __main__: train step 3809: loss: 0.7551, policy_loss: 1.6200, value_loss: 0.9299
2024-07-14 05:16:34,388 [INFO    ] __main__: train step 3810: loss: 0.7552, policy_loss: 1.6198, value_loss: 0.9299
2024-07-14 05:16:34,672 [INFO    ] __main__: train step 3811: loss: 0.7553, policy_loss: 1.6197, value_loss: 0.9298
2024-07-14 05:16:34,958 [INFO    ] __main__: train step 3812: loss: 0.7554, policy_loss: 1.6196, value_loss: 0.9298
2024-07-14 05:16:35,239 [INFO    ] __main__: train step 3813: loss: 0.7556, policy_loss: 1.6195, value_loss: 0.9298
2024-07-14 05:16:35,519 [INFO    ] __main__: train step 3814: loss: 0.7557, policy_loss: 1.6194, value_loss: 0.9297
2024-07-14 05:16:35,806 [INFO    ] __main__: train step 3815: loss: 0.7558, policy_loss: 1.6193, value_loss: 0.9297
2024-07-14 05:16:36,097 [INFO    ] __main__: train step 3816: loss: 0.7559, policy_loss: 1.6192, value_loss: 0.9297
2024-07-14 05:16:36,380 [INFO    ] __main__: train step 3817: loss: 0.7561, policy_loss: 1.6191, value_loss: 0.9297
2024-07-14 05:16:36,663 [INFO    ] __main__: train step 3818: loss: 0.7562, policy_loss: 1.6189, value_loss: 0.9296
2024-07-14 05:16:36,942 [INFO    ] __main__: train step 3819: loss: 0.7563, policy_loss: 1.6188, value_loss: 0.9296
2024-07-14 05:16:37,219 [INFO    ] __main__: train step 3820: loss: 0.7564, policy_loss: 1.6187, value_loss: 0.9296
2024-07-14 05:16:37,499 [INFO    ] __main__: train step 3821: loss: 0.7566, policy_loss: 1.6186, value_loss: 0.9295
2024-07-14 05:16:39,119 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:16:39,664 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:16:39,731 [INFO    ] __main__: train step 3822: loss: 0.7567, policy_loss: 1.6185, value_loss: 0.9295
2024-07-14 05:16:40,006 [INFO    ] __main__: train step 3823: loss: 0.7568, policy_loss: 1.6184, value_loss: 0.9295
2024-07-14 05:16:40,275 [INFO    ] __main__: train step 3824: loss: 0.7569, policy_loss: 1.6183, value_loss: 0.9294
2024-07-14 05:16:40,556 [INFO    ] __main__: train step 3825: loss: 0.7570, policy_loss: 1.6182, value_loss: 0.9294
2024-07-14 05:16:40,833 [INFO    ] __main__: train step 3826: loss: 0.7572, policy_loss: 1.6181, value_loss: 0.9294
2024-07-14 05:16:41,123 [INFO    ] __main__: train step 3827: loss: 0.7573, policy_loss: 1.6179, value_loss: 0.9293
2024-07-14 05:16:41,403 [INFO    ] __main__: train step 3828: loss: 0.7574, policy_loss: 1.6178, value_loss: 0.9293
2024-07-14 05:16:41,673 [INFO    ] __main__: train step 3829: loss: 0.7575, policy_loss: 1.6177, value_loss: 0.9293
2024-07-14 05:16:42,577 [INFO    ] __main__: train step 3830: loss: 0.7577, policy_loss: 1.6176, value_loss: 0.9293
2024-07-14 05:16:42,866 [INFO    ] __main__: train step 3831: loss: 0.7578, policy_loss: 1.6175, value_loss: 0.9292
2024-07-14 05:16:43,155 [INFO    ] __main__: train step 3832: loss: 0.7579, policy_loss: 1.6174, value_loss: 0.9292
2024-07-14 05:16:43,443 [INFO    ] __main__: train step 3833: loss: 0.7580, policy_loss: 1.6173, value_loss: 0.9292
2024-07-14 05:16:43,730 [INFO    ] __main__: train step 3834: loss: 0.7582, policy_loss: 1.6172, value_loss: 0.9291
2024-07-14 05:16:44,020 [INFO    ] __main__: train step 3835: loss: 0.7583, policy_loss: 1.6171, value_loss: 0.9291
2024-07-14 05:16:44,300 [INFO    ] __main__: train step 3836: loss: 0.7584, policy_loss: 1.6170, value_loss: 0.9291
2024-07-14 05:16:44,584 [INFO    ] __main__: train step 3837: loss: 0.7585, policy_loss: 1.6168, value_loss: 0.9290
2024-07-14 05:16:44,870 [INFO    ] __main__: train step 3838: loss: 0.7587, policy_loss: 1.6167, value_loss: 0.9290
2024-07-14 05:16:46,471 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:16:46,978 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:16:47,044 [INFO    ] __main__: train step 3839: loss: 0.7588, policy_loss: 1.6166, value_loss: 0.9290
2024-07-14 05:16:47,332 [INFO    ] __main__: train step 3840: loss: 0.7589, policy_loss: 1.6165, value_loss: 0.9289
2024-07-14 05:16:47,619 [INFO    ] __main__: train step 3841: loss: 0.7590, policy_loss: 1.6164, value_loss: 0.9289
2024-07-14 05:16:47,940 [INFO    ] __main__: train step 3842: loss: 0.7592, policy_loss: 1.6163, value_loss: 0.9289
2024-07-14 05:16:48,225 [INFO    ] __main__: train step 3843: loss: 0.7593, policy_loss: 1.6162, value_loss: 0.9289
2024-07-14 05:16:48,508 [INFO    ] __main__: train step 3844: loss: 0.7594, policy_loss: 1.6161, value_loss: 0.9288
2024-07-14 05:16:48,795 [INFO    ] __main__: train step 3845: loss: 0.7595, policy_loss: 1.6159, value_loss: 0.9288
2024-07-14 05:16:49,098 [INFO    ] __main__: train step 3846: loss: 0.7597, policy_loss: 1.6158, value_loss: 0.9288
2024-07-14 05:16:49,364 [INFO    ] __main__: train step 3847: loss: 0.7598, policy_loss: 1.6157, value_loss: 0.9287
2024-07-14 05:16:49,637 [INFO    ] __main__: train step 3848: loss: 0.7599, policy_loss: 1.6156, value_loss: 0.9287
2024-07-14 05:16:50,389 [INFO    ] __main__: train step 3849: loss: 0.7600, policy_loss: 1.6155, value_loss: 0.9287
2024-07-14 05:16:50,680 [INFO    ] __main__: train step 3850: loss: 0.7601, policy_loss: 1.6154, value_loss: 0.9286
2024-07-14 05:16:50,966 [INFO    ] __main__: train step 3851: loss: 0.7603, policy_loss: 1.6153, value_loss: 0.9286
2024-07-14 05:16:51,254 [INFO    ] __main__: train step 3852: loss: 0.7604, policy_loss: 1.6152, value_loss: 0.9286
2024-07-14 05:16:51,539 [INFO    ] __main__: train step 3853: loss: 0.7605, policy_loss: 1.6150, value_loss: 0.9285
2024-07-14 05:16:51,824 [INFO    ] __main__: train step 3854: loss: 0.7606, policy_loss: 1.6149, value_loss: 0.9285
2024-07-14 05:16:52,108 [INFO    ] __main__: train step 3855: loss: 0.7608, policy_loss: 1.6148, value_loss: 0.9285
2024-07-14 05:16:53,709 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:16:54,198 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:16:54,266 [INFO    ] __main__: train step 3856: loss: 0.7609, policy_loss: 1.6147, value_loss: 0.9284
2024-07-14 05:16:54,549 [INFO    ] __main__: train step 3857: loss: 0.7610, policy_loss: 1.6146, value_loss: 0.9284
2024-07-14 05:16:54,873 [INFO    ] __main__: train step 3858: loss: 0.7611, policy_loss: 1.6145, value_loss: 0.9284
2024-07-14 05:16:55,156 [INFO    ] __main__: train step 3859: loss: 0.7613, policy_loss: 1.6144, value_loss: 0.9283
2024-07-14 05:16:55,441 [INFO    ] __main__: train step 3860: loss: 0.7614, policy_loss: 1.6143, value_loss: 0.9283
2024-07-14 05:16:55,719 [INFO    ] __main__: train step 3861: loss: 0.7615, policy_loss: 1.6141, value_loss: 0.9283
2024-07-14 05:16:55,998 [INFO    ] __main__: train step 3862: loss: 0.7616, policy_loss: 1.6140, value_loss: 0.9283
2024-07-14 05:16:56,276 [INFO    ] __main__: train step 3863: loss: 0.7617, policy_loss: 1.6139, value_loss: 0.9282
2024-07-14 05:16:56,555 [INFO    ] __main__: train step 3864: loss: 0.7619, policy_loss: 1.6138, value_loss: 0.9282
2024-07-14 05:16:56,826 [INFO    ] __main__: train step 3865: loss: 0.7620, policy_loss: 1.6137, value_loss: 0.9282
2024-07-14 05:16:57,102 [INFO    ] __main__: train step 3866: loss: 0.7621, policy_loss: 1.6136, value_loss: 0.9281
2024-07-14 05:16:57,383 [INFO    ] __main__: train step 3867: loss: 0.7623, policy_loss: 1.6135, value_loss: 0.9281
2024-07-14 05:16:58,271 [INFO    ] __main__: train step 3868: loss: 0.7624, policy_loss: 1.6134, value_loss: 0.9281
2024-07-14 05:16:58,547 [INFO    ] __main__: train step 3869: loss: 0.7625, policy_loss: 1.6132, value_loss: 0.9280
2024-07-14 05:16:58,844 [INFO    ] __main__: train step 3870: loss: 0.7626, policy_loss: 1.6131, value_loss: 0.9280
2024-07-14 05:16:59,127 [INFO    ] __main__: train step 3871: loss: 0.7627, policy_loss: 1.6130, value_loss: 0.9280
2024-07-14 05:16:59,418 [INFO    ] __main__: train step 3872: loss: 0.7629, policy_loss: 1.6129, value_loss: 0.9280
2024-07-14 05:17:01,031 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:17:01,528 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:17:01,598 [INFO    ] __main__: train step 3873: loss: 0.7630, policy_loss: 1.6128, value_loss: 0.9279
2024-07-14 05:17:01,859 [INFO    ] __main__: train step 3874: loss: 0.7631, policy_loss: 1.6127, value_loss: 0.9279
2024-07-14 05:17:02,112 [INFO    ] __main__: train step 3875: loss: 0.7632, policy_loss: 1.6126, value_loss: 0.9279
2024-07-14 05:17:02,374 [INFO    ] __main__: train step 3876: loss: 0.7634, policy_loss: 1.6125, value_loss: 0.9279
2024-07-14 05:17:02,659 [INFO    ] __main__: train step 3877: loss: 0.7635, policy_loss: 1.6124, value_loss: 0.9278
2024-07-14 05:17:02,950 [INFO    ] __main__: train step 3878: loss: 0.7636, policy_loss: 1.6122, value_loss: 0.9278
2024-07-14 05:17:03,235 [INFO    ] __main__: train step 3879: loss: 0.7637, policy_loss: 1.6121, value_loss: 0.9278
2024-07-14 05:17:03,521 [INFO    ] __main__: train step 3880: loss: 0.7639, policy_loss: 1.6120, value_loss: 0.9277
2024-07-14 05:17:03,805 [INFO    ] __main__: train step 3881: loss: 0.7640, policy_loss: 1.6119, value_loss: 0.9277
2024-07-14 05:17:04,082 [INFO    ] __main__: train step 3882: loss: 0.7641, policy_loss: 1.6118, value_loss: 0.9277
2024-07-14 05:17:04,366 [INFO    ] __main__: train step 3883: loss: 0.7642, policy_loss: 1.6117, value_loss: 0.9276
2024-07-14 05:17:04,655 [INFO    ] __main__: train step 3884: loss: 0.7644, policy_loss: 1.6116, value_loss: 0.9276
2024-07-14 05:17:04,908 [INFO    ] __main__: train step 3885: loss: 0.7645, policy_loss: 1.6115, value_loss: 0.9276
2024-07-14 05:17:05,190 [INFO    ] __main__: train step 3886: loss: 0.7646, policy_loss: 1.6114, value_loss: 0.9276
2024-07-14 05:17:06,091 [INFO    ] __main__: train step 3887: loss: 0.7647, policy_loss: 1.6112, value_loss: 0.9275
2024-07-14 05:17:06,354 [INFO    ] __main__: train step 3888: loss: 0.7649, policy_loss: 1.6111, value_loss: 0.9275
2024-07-14 05:17:06,614 [INFO    ] __main__: train step 3889: loss: 0.7650, policy_loss: 1.6110, value_loss: 0.9275
2024-07-14 05:17:08,192 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:17:08,665 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:17:08,738 [INFO    ] __main__: train step 3890: loss: 0.7651, policy_loss: 1.6109, value_loss: 0.9274
2024-07-14 05:17:09,033 [INFO    ] __main__: train step 3891: loss: 0.7652, policy_loss: 1.6108, value_loss: 0.9274
2024-07-14 05:17:09,322 [INFO    ] __main__: train step 3892: loss: 0.7653, policy_loss: 1.6107, value_loss: 0.9273
2024-07-14 05:17:09,621 [INFO    ] __main__: train step 3893: loss: 0.7655, policy_loss: 1.6106, value_loss: 0.9273
2024-07-14 05:17:09,902 [INFO    ] __main__: train step 3894: loss: 0.7656, policy_loss: 1.6105, value_loss: 0.9273
2024-07-14 05:17:10,178 [INFO    ] __main__: train step 3895: loss: 0.7657, policy_loss: 1.6103, value_loss: 0.9273
2024-07-14 05:17:10,460 [INFO    ] __main__: train step 3896: loss: 0.7658, policy_loss: 1.6102, value_loss: 0.9272
2024-07-14 05:17:10,739 [INFO    ] __main__: train step 3897: loss: 0.7660, policy_loss: 1.6101, value_loss: 0.9272
2024-07-14 05:17:10,998 [INFO    ] __main__: train step 3898: loss: 0.7661, policy_loss: 1.6100, value_loss: 0.9272
2024-07-14 05:17:11,257 [INFO    ] __main__: train step 3899: loss: 0.7662, policy_loss: 1.6099, value_loss: 0.9271
2024-07-14 05:17:11,533 [INFO    ] __main__: train step 3900: loss: 0.7663, policy_loss: 1.6098, value_loss: 0.9271
2024-07-14 05:17:11,807 [INFO    ] __main__: train step 3901: loss: 0.7665, policy_loss: 1.6097, value_loss: 0.9271
2024-07-14 05:17:12,111 [INFO    ] __main__: train step 3902: loss: 0.7666, policy_loss: 1.6096, value_loss: 0.9271
2024-07-14 05:17:12,387 [INFO    ] __main__: train step 3903: loss: 0.7667, policy_loss: 1.6094, value_loss: 0.9270
2024-07-14 05:17:12,652 [INFO    ] __main__: train step 3904: loss: 0.7668, policy_loss: 1.6093, value_loss: 0.9270
2024-07-14 05:17:12,930 [INFO    ] __main__: train step 3905: loss: 0.7670, policy_loss: 1.6092, value_loss: 0.9270
2024-07-14 05:17:13,207 [INFO    ] __main__: train step 3906: loss: 0.7671, policy_loss: 1.6091, value_loss: 0.9269
2024-07-14 05:17:15,407 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:17:15,899 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:17:15,966 [INFO    ] __main__: train step 3907: loss: 0.7672, policy_loss: 1.6090, value_loss: 0.9269
2024-07-14 05:17:16,254 [INFO    ] __main__: train step 3908: loss: 0.7673, policy_loss: 1.6089, value_loss: 0.9269
2024-07-14 05:17:16,535 [INFO    ] __main__: train step 3909: loss: 0.7674, policy_loss: 1.6088, value_loss: 0.9268
2024-07-14 05:17:16,825 [INFO    ] __main__: train step 3910: loss: 0.7676, policy_loss: 1.6087, value_loss: 0.9268
2024-07-14 05:17:17,114 [INFO    ] __main__: train step 3911: loss: 0.7677, policy_loss: 1.6086, value_loss: 0.9268
2024-07-14 05:17:17,395 [INFO    ] __main__: train step 3912: loss: 0.7678, policy_loss: 1.6084, value_loss: 0.9268
2024-07-14 05:17:17,681 [INFO    ] __main__: train step 3913: loss: 0.7679, policy_loss: 1.6083, value_loss: 0.9267
2024-07-14 05:17:17,959 [INFO    ] __main__: train step 3914: loss: 0.7680, policy_loss: 1.6082, value_loss: 0.9267
2024-07-14 05:17:18,245 [INFO    ] __main__: train step 3915: loss: 0.7681, policy_loss: 1.6081, value_loss: 0.9267
2024-07-14 05:17:18,534 [INFO    ] __main__: train step 3916: loss: 0.7683, policy_loss: 1.6080, value_loss: 0.9266
2024-07-14 05:17:18,841 [INFO    ] __main__: train step 3917: loss: 0.7684, policy_loss: 1.6079, value_loss: 0.9266
2024-07-14 05:17:19,149 [INFO    ] __main__: train step 3918: loss: 0.7685, policy_loss: 1.6078, value_loss: 0.9266
2024-07-14 05:17:19,451 [INFO    ] __main__: train step 3919: loss: 0.7686, policy_loss: 1.6077, value_loss: 0.9265
2024-07-14 05:17:19,736 [INFO    ] __main__: train step 3920: loss: 0.7688, policy_loss: 1.6075, value_loss: 0.9265
2024-07-14 05:17:20,032 [INFO    ] __main__: train step 3921: loss: 0.7689, policy_loss: 1.6074, value_loss: 0.9265
2024-07-14 05:17:20,325 [INFO    ] __main__: train step 3922: loss: 0.7690, policy_loss: 1.6073, value_loss: 0.9265
2024-07-14 05:17:20,613 [INFO    ] __main__: train step 3923: loss: 0.7691, policy_loss: 1.6072, value_loss: 0.9264
2024-07-14 05:17:22,207 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:17:22,689 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:17:22,761 [INFO    ] __main__: train step 3924: loss: 0.7693, policy_loss: 1.6071, value_loss: 0.9264
2024-07-14 05:17:23,043 [INFO    ] __main__: train step 3925: loss: 0.7694, policy_loss: 1.6070, value_loss: 0.9264
2024-07-14 05:17:23,967 [INFO    ] __main__: train step 3926: loss: 0.7695, policy_loss: 1.6069, value_loss: 0.9263
2024-07-14 05:17:24,250 [INFO    ] __main__: train step 3927: loss: 0.7696, policy_loss: 1.6068, value_loss: 0.9263
2024-07-14 05:17:24,528 [INFO    ] __main__: train step 3928: loss: 0.7697, policy_loss: 1.6067, value_loss: 0.9263
2024-07-14 05:17:24,807 [INFO    ] __main__: train step 3929: loss: 0.7699, policy_loss: 1.6065, value_loss: 0.9262
2024-07-14 05:17:25,074 [INFO    ] __main__: train step 3930: loss: 0.7700, policy_loss: 1.6064, value_loss: 0.9262
2024-07-14 05:17:25,354 [INFO    ] __main__: train step 3931: loss: 0.7701, policy_loss: 1.6063, value_loss: 0.9262
2024-07-14 05:17:25,634 [INFO    ] __main__: train step 3932: loss: 0.7702, policy_loss: 1.6062, value_loss: 0.9262
2024-07-14 05:17:25,920 [INFO    ] __main__: train step 3933: loss: 0.7703, policy_loss: 1.6061, value_loss: 0.9261
2024-07-14 05:17:26,204 [INFO    ] __main__: train step 3934: loss: 0.7705, policy_loss: 1.6060, value_loss: 0.9261
2024-07-14 05:17:26,488 [INFO    ] __main__: train step 3935: loss: 0.7706, policy_loss: 1.6059, value_loss: 0.9261
2024-07-14 05:17:26,760 [INFO    ] __main__: train step 3936: loss: 0.7707, policy_loss: 1.6058, value_loss: 0.9260
2024-07-14 05:17:27,033 [INFO    ] __main__: train step 3937: loss: 0.7708, policy_loss: 1.6057, value_loss: 0.9260
2024-07-14 05:17:27,302 [INFO    ] __main__: train step 3938: loss: 0.7709, policy_loss: 1.6055, value_loss: 0.9260
2024-07-14 05:17:27,600 [INFO    ] __main__: train step 3939: loss: 0.7711, policy_loss: 1.6054, value_loss: 0.9259
2024-07-14 05:17:27,874 [INFO    ] __main__: train step 3940: loss: 0.7712, policy_loss: 1.6053, value_loss: 0.9259
2024-07-14 05:17:29,492 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:17:29,961 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:17:30,026 [INFO    ] __main__: train step 3941: loss: 0.7713, policy_loss: 1.6052, value_loss: 0.9259
2024-07-14 05:17:30,308 [INFO    ] __main__: train step 3942: loss: 0.7714, policy_loss: 1.6051, value_loss: 0.9258
2024-07-14 05:17:30,609 [INFO    ] __main__: train step 3943: loss: 0.7715, policy_loss: 1.6050, value_loss: 0.9258
2024-07-14 05:17:30,900 [INFO    ] __main__: train step 3944: loss: 0.7717, policy_loss: 1.6049, value_loss: 0.9258
2024-07-14 05:17:31,814 [INFO    ] __main__: train step 3945: loss: 0.7718, policy_loss: 1.6048, value_loss: 0.9257
2024-07-14 05:17:32,093 [INFO    ] __main__: train step 3946: loss: 0.7719, policy_loss: 1.6046, value_loss: 0.9257
2024-07-14 05:17:32,379 [INFO    ] __main__: train step 3947: loss: 0.7720, policy_loss: 1.6045, value_loss: 0.9257
2024-07-14 05:17:32,648 [INFO    ] __main__: train step 3948: loss: 0.7721, policy_loss: 1.6044, value_loss: 0.9256
2024-07-14 05:17:32,928 [INFO    ] __main__: train step 3949: loss: 0.7723, policy_loss: 1.6043, value_loss: 0.9256
2024-07-14 05:17:33,217 [INFO    ] __main__: train step 3950: loss: 0.7724, policy_loss: 1.6042, value_loss: 0.9256
2024-07-14 05:17:33,506 [INFO    ] __main__: train step 3951: loss: 0.7725, policy_loss: 1.6041, value_loss: 0.9255
2024-07-14 05:17:33,789 [INFO    ] __main__: train step 3952: loss: 0.7726, policy_loss: 1.6040, value_loss: 0.9255
2024-07-14 05:17:34,080 [INFO    ] __main__: train step 3953: loss: 0.7728, policy_loss: 1.6039, value_loss: 0.9255
2024-07-14 05:17:34,371 [INFO    ] __main__: train step 3954: loss: 0.7729, policy_loss: 1.6037, value_loss: 0.9255
2024-07-14 05:17:34,655 [INFO    ] __main__: train step 3955: loss: 0.7730, policy_loss: 1.6036, value_loss: 0.9254
2024-07-14 05:17:34,936 [INFO    ] __main__: train step 3956: loss: 0.7731, policy_loss: 1.6035, value_loss: 0.9254
2024-07-14 05:17:35,190 [INFO    ] __main__: train step 3957: loss: 0.7732, policy_loss: 1.6034, value_loss: 0.9254
2024-07-14 05:17:36,776 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:17:37,234 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:17:37,302 [INFO    ] __main__: train step 3958: loss: 0.7734, policy_loss: 1.6033, value_loss: 0.9253
2024-07-14 05:17:37,579 [INFO    ] __main__: train step 3959: loss: 0.7735, policy_loss: 1.6032, value_loss: 0.9253
2024-07-14 05:17:37,861 [INFO    ] __main__: train step 3960: loss: 0.7736, policy_loss: 1.6031, value_loss: 0.9253
2024-07-14 05:17:38,137 [INFO    ] __main__: train step 3961: loss: 0.7737, policy_loss: 1.6029, value_loss: 0.9252
2024-07-14 05:17:38,412 [INFO    ] __main__: train step 3962: loss: 0.7738, policy_loss: 1.6028, value_loss: 0.9252
2024-07-14 05:17:38,697 [INFO    ] __main__: train step 3963: loss: 0.7739, policy_loss: 1.6027, value_loss: 0.9252
2024-07-14 05:17:38,980 [INFO    ] __main__: train step 3964: loss: 0.7741, policy_loss: 1.6026, value_loss: 0.9251
2024-07-14 05:17:39,622 [INFO    ] __main__: train step 3965: loss: 0.7742, policy_loss: 1.6025, value_loss: 0.9251
2024-07-14 05:17:39,910 [INFO    ] __main__: train step 3966: loss: 0.7743, policy_loss: 1.6024, value_loss: 0.9251
2024-07-14 05:17:40,192 [INFO    ] __main__: train step 3967: loss: 0.7744, policy_loss: 1.6023, value_loss: 0.9251
2024-07-14 05:17:40,477 [INFO    ] __main__: train step 3968: loss: 0.7746, policy_loss: 1.6022, value_loss: 0.9250
2024-07-14 05:17:40,771 [INFO    ] __main__: train step 3969: loss: 0.7747, policy_loss: 1.6020, value_loss: 0.9250
2024-07-14 05:17:41,049 [INFO    ] __main__: train step 3970: loss: 0.7748, policy_loss: 1.6019, value_loss: 0.9250
2024-07-14 05:17:41,333 [INFO    ] __main__: train step 3971: loss: 0.7749, policy_loss: 1.6018, value_loss: 0.9249
2024-07-14 05:17:41,616 [INFO    ] __main__: train step 3972: loss: 0.7750, policy_loss: 1.6017, value_loss: 0.9249
2024-07-14 05:17:41,902 [INFO    ] __main__: train step 3973: loss: 0.7752, policy_loss: 1.6016, value_loss: 0.9249
2024-07-14 05:17:42,189 [INFO    ] __main__: train step 3974: loss: 0.7753, policy_loss: 1.6015, value_loss: 0.9249
2024-07-14 05:17:43,801 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:17:44,277 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:17:44,344 [INFO    ] __main__: train step 3975: loss: 0.7754, policy_loss: 1.6014, value_loss: 0.9248
2024-07-14 05:17:44,621 [INFO    ] __main__: train step 3976: loss: 0.7755, policy_loss: 1.6013, value_loss: 0.9248
2024-07-14 05:17:44,897 [INFO    ] __main__: train step 3977: loss: 0.7756, policy_loss: 1.6012, value_loss: 0.9248
2024-07-14 05:17:45,165 [INFO    ] __main__: train step 3978: loss: 0.7758, policy_loss: 1.6010, value_loss: 0.9247
2024-07-14 05:17:45,442 [INFO    ] __main__: train step 3979: loss: 0.7759, policy_loss: 1.6009, value_loss: 0.9247
2024-07-14 05:17:45,720 [INFO    ] __main__: train step 3980: loss: 0.7760, policy_loss: 1.6008, value_loss: 0.9247
2024-07-14 05:17:46,015 [INFO    ] __main__: train step 3981: loss: 0.7761, policy_loss: 1.6007, value_loss: 0.9246
2024-07-14 05:17:46,283 [INFO    ] __main__: train step 3982: loss: 0.7762, policy_loss: 1.6006, value_loss: 0.9246
2024-07-14 05:17:46,564 [INFO    ] __main__: train step 3983: loss: 0.7764, policy_loss: 1.6005, value_loss: 0.9246
2024-07-14 05:17:46,852 [INFO    ] __main__: train step 3984: loss: 0.7765, policy_loss: 1.6004, value_loss: 0.9245
2024-07-14 05:17:47,486 [INFO    ] __main__: train step 3985: loss: 0.7766, policy_loss: 1.6003, value_loss: 0.9245
2024-07-14 05:17:47,765 [INFO    ] __main__: train step 3986: loss: 0.7767, policy_loss: 1.6002, value_loss: 0.9245
2024-07-14 05:17:48,041 [INFO    ] __main__: train step 3987: loss: 0.7768, policy_loss: 1.6000, value_loss: 0.9245
2024-07-14 05:17:48,328 [INFO    ] __main__: train step 3988: loss: 0.7770, policy_loss: 1.5999, value_loss: 0.9244
2024-07-14 05:17:48,606 [INFO    ] __main__: train step 3989: loss: 0.7771, policy_loss: 1.5998, value_loss: 0.9244
2024-07-14 05:17:48,881 [INFO    ] __main__: train step 3990: loss: 0.7772, policy_loss: 1.5997, value_loss: 0.9244
2024-07-14 05:17:49,154 [INFO    ] __main__: train step 3991: loss: 0.7773, policy_loss: 1.5996, value_loss: 0.9243
2024-07-14 05:17:50,750 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:17:51,226 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:17:51,290 [INFO    ] __main__: train step 3992: loss: 0.7774, policy_loss: 1.5995, value_loss: 0.9243
2024-07-14 05:17:51,576 [INFO    ] __main__: train step 3993: loss: 0.7776, policy_loss: 1.5994, value_loss: 0.9243
2024-07-14 05:17:51,855 [INFO    ] __main__: train step 3994: loss: 0.7777, policy_loss: 1.5993, value_loss: 0.9242
2024-07-14 05:17:52,130 [INFO    ] __main__: train step 3995: loss: 0.7778, policy_loss: 1.5991, value_loss: 0.9242
2024-07-14 05:17:52,399 [INFO    ] __main__: train step 3996: loss: 0.7779, policy_loss: 1.5990, value_loss: 0.9242
2024-07-14 05:17:52,671 [INFO    ] __main__: train step 3997: loss: 0.7780, policy_loss: 1.5989, value_loss: 0.9241
2024-07-14 05:17:52,943 [INFO    ] __main__: train step 3998: loss: 0.7781, policy_loss: 1.5988, value_loss: 0.9241
2024-07-14 05:17:53,228 [INFO    ] __main__: train step 3999: loss: 0.7783, policy_loss: 1.5987, value_loss: 0.9241
2024-07-14 05:17:53,502 [INFO    ] __main__: train step 4000: loss: 0.7784, policy_loss: 1.5986, value_loss: 0.9240
2024-07-14 05:17:53,653 [INFO    ] __main__: restored step 3000 for evaluation
2024-07-14 05:17:58,900 [INFO    ] __main__: test network ELO difference from baseline network: +174 (+8/-8) ELO from 32000 self-played games
2024-07-14 05:17:58,903 [INFO    ] __main__: game outcomes: W: 21969, D: 493, L: 9538
2024-07-14 05:17:58,905 [INFO    ] __main__: validation_elo_delta: 174, validation_elo: 1030
2024-07-14 05:17:59,634 [INFO    ] __main__: train step 4001: loss: 0.7785, policy_loss: 1.5985, value_loss: 0.9240
2024-07-14 05:17:59,917 [INFO    ] __main__: train step 4002: loss: 0.7786, policy_loss: 1.5984, value_loss: 0.9240
2024-07-14 05:18:00,199 [INFO    ] __main__: train step 4003: loss: 0.7787, policy_loss: 1.5982, value_loss: 0.9240
2024-07-14 05:18:00,472 [INFO    ] __main__: train step 4004: loss: 0.7789, policy_loss: 1.5981, value_loss: 0.9239
2024-07-14 05:18:01,129 [INFO    ] __main__: train step 4005: loss: 0.7790, policy_loss: 1.5980, value_loss: 0.9239
2024-07-14 05:18:01,400 [INFO    ] __main__: train step 4006: loss: 0.7791, policy_loss: 1.5979, value_loss: 0.9239
2024-07-14 05:18:01,666 [INFO    ] __main__: train step 4007: loss: 0.7792, policy_loss: 1.5978, value_loss: 0.9238
2024-07-14 05:18:01,936 [INFO    ] __main__: train step 4008: loss: 0.7794, policy_loss: 1.5977, value_loss: 0.9238
2024-07-14 05:18:03,522 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:18:03,998 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:18:04,069 [INFO    ] __main__: train step 4009: loss: 0.7795, policy_loss: 1.5976, value_loss: 0.9238
2024-07-14 05:18:04,346 [INFO    ] __main__: train step 4010: loss: 0.7796, policy_loss: 1.5975, value_loss: 0.9237
2024-07-14 05:18:04,622 [INFO    ] __main__: train step 4011: loss: 0.7797, policy_loss: 1.5973, value_loss: 0.9237
2024-07-14 05:18:04,893 [INFO    ] __main__: train step 4012: loss: 0.7798, policy_loss: 1.5972, value_loss: 0.9237
2024-07-14 05:18:05,166 [INFO    ] __main__: train step 4013: loss: 0.7800, policy_loss: 1.5971, value_loss: 0.9237
2024-07-14 05:18:05,443 [INFO    ] __main__: train step 4014: loss: 0.7801, policy_loss: 1.5970, value_loss: 0.9236
2024-07-14 05:18:05,720 [INFO    ] __main__: train step 4015: loss: 0.7802, policy_loss: 1.5969, value_loss: 0.9236
2024-07-14 05:18:05,996 [INFO    ] __main__: train step 4016: loss: 0.7803, policy_loss: 1.5968, value_loss: 0.9236
2024-07-14 05:18:06,286 [INFO    ] __main__: train step 4017: loss: 0.7804, policy_loss: 1.5967, value_loss: 0.9235
2024-07-14 05:18:06,568 [INFO    ] __main__: train step 4018: loss: 0.7806, policy_loss: 1.5966, value_loss: 0.9235
2024-07-14 05:18:06,842 [INFO    ] __main__: train step 4019: loss: 0.7807, policy_loss: 1.5965, value_loss: 0.9235
2024-07-14 05:18:07,121 [INFO    ] __main__: train step 4020: loss: 0.7808, policy_loss: 1.5963, value_loss: 0.9235
2024-07-14 05:18:07,401 [INFO    ] __main__: train step 4021: loss: 0.7809, policy_loss: 1.5962, value_loss: 0.9234
2024-07-14 05:18:07,672 [INFO    ] __main__: train step 4022: loss: 0.7810, policy_loss: 1.5961, value_loss: 0.9234
2024-07-14 05:18:07,948 [INFO    ] __main__: train step 4023: loss: 0.7812, policy_loss: 1.5960, value_loss: 0.9234
2024-07-14 05:18:08,800 [INFO    ] __main__: train step 4024: loss: 0.7813, policy_loss: 1.5959, value_loss: 0.9233
2024-07-14 05:18:09,083 [INFO    ] __main__: train step 4025: loss: 0.7814, policy_loss: 1.5958, value_loss: 0.9233
2024-07-14 05:18:10,690 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:18:11,164 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:18:11,234 [INFO    ] __main__: train step 4026: loss: 0.7815, policy_loss: 1.5957, value_loss: 0.9233
2024-07-14 05:18:11,500 [INFO    ] __main__: train step 4027: loss: 0.7816, policy_loss: 1.5956, value_loss: 0.9232
2024-07-14 05:18:11,779 [INFO    ] __main__: train step 4028: loss: 0.7818, policy_loss: 1.5955, value_loss: 0.9232
2024-07-14 05:18:12,052 [INFO    ] __main__: train step 4029: loss: 0.7819, policy_loss: 1.5954, value_loss: 0.9232
2024-07-14 05:18:12,334 [INFO    ] __main__: train step 4030: loss: 0.7820, policy_loss: 1.5953, value_loss: 0.9231
2024-07-14 05:18:12,615 [INFO    ] __main__: train step 4031: loss: 0.7821, policy_loss: 1.5951, value_loss: 0.9231
2024-07-14 05:18:12,903 [INFO    ] __main__: train step 4032: loss: 0.7822, policy_loss: 1.5950, value_loss: 0.9231
2024-07-14 05:18:13,168 [INFO    ] __main__: train step 4033: loss: 0.7824, policy_loss: 1.5949, value_loss: 0.9231
2024-07-14 05:18:13,440 [INFO    ] __main__: train step 4034: loss: 0.7825, policy_loss: 1.5948, value_loss: 0.9230
2024-07-14 05:18:13,723 [INFO    ] __main__: train step 4035: loss: 0.7826, policy_loss: 1.5947, value_loss: 0.9230
2024-07-14 05:18:14,014 [INFO    ] __main__: train step 4036: loss: 0.7827, policy_loss: 1.5946, value_loss: 0.9230
2024-07-14 05:18:14,288 [INFO    ] __main__: train step 4037: loss: 0.7828, policy_loss: 1.5945, value_loss: 0.9229
2024-07-14 05:18:14,560 [INFO    ] __main__: train step 4038: loss: 0.7830, policy_loss: 1.5944, value_loss: 0.9229
2024-07-14 05:18:14,844 [INFO    ] __main__: train step 4039: loss: 0.7831, policy_loss: 1.5943, value_loss: 0.9229
2024-07-14 05:18:15,122 [INFO    ] __main__: train step 4040: loss: 0.7832, policy_loss: 1.5942, value_loss: 0.9228
2024-07-14 05:18:15,408 [INFO    ] __main__: train step 4041: loss: 0.7833, policy_loss: 1.5940, value_loss: 0.9228
2024-07-14 05:18:15,687 [INFO    ] __main__: train step 4042: loss: 0.7834, policy_loss: 1.5939, value_loss: 0.9228
2024-07-14 05:18:17,294 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:18:17,771 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:18:17,839 [INFO    ] __main__: train step 4043: loss: 0.7835, policy_loss: 1.5938, value_loss: 0.9228
2024-07-14 05:18:18,466 [INFO    ] __main__: train step 4044: loss: 0.7837, policy_loss: 1.5937, value_loss: 0.9227
2024-07-14 05:18:18,740 [INFO    ] __main__: train step 4045: loss: 0.7838, policy_loss: 1.5936, value_loss: 0.9227
2024-07-14 05:18:19,017 [INFO    ] __main__: train step 4046: loss: 0.7839, policy_loss: 1.5935, value_loss: 0.9227
2024-07-14 05:18:19,302 [INFO    ] __main__: train step 4047: loss: 0.7840, policy_loss: 1.5934, value_loss: 0.9226
2024-07-14 05:18:19,580 [INFO    ] __main__: train step 4048: loss: 0.7842, policy_loss: 1.5933, value_loss: 0.9226
2024-07-14 05:18:19,858 [INFO    ] __main__: train step 4049: loss: 0.7843, policy_loss: 1.5932, value_loss: 0.9226
2024-07-14 05:18:20,136 [INFO    ] __main__: train step 4050: loss: 0.7844, policy_loss: 1.5930, value_loss: 0.9226
2024-07-14 05:18:20,421 [INFO    ] __main__: train step 4051: loss: 0.7845, policy_loss: 1.5929, value_loss: 0.9225
2024-07-14 05:18:20,701 [INFO    ] __main__: train step 4052: loss: 0.7846, policy_loss: 1.5928, value_loss: 0.9225
2024-07-14 05:18:20,970 [INFO    ] __main__: train step 4053: loss: 0.7847, policy_loss: 1.5927, value_loss: 0.9225
2024-07-14 05:18:21,245 [INFO    ] __main__: train step 4054: loss: 0.7849, policy_loss: 1.5926, value_loss: 0.9224
2024-07-14 05:18:21,531 [INFO    ] __main__: train step 4055: loss: 0.7850, policy_loss: 1.5925, value_loss: 0.9224
2024-07-14 05:18:21,806 [INFO    ] __main__: train step 4056: loss: 0.7851, policy_loss: 1.5924, value_loss: 0.9224
2024-07-14 05:18:22,097 [INFO    ] __main__: train step 4057: loss: 0.7852, policy_loss: 1.5923, value_loss: 0.9223
2024-07-14 05:18:22,375 [INFO    ] __main__: train step 4058: loss: 0.7853, policy_loss: 1.5921, value_loss: 0.9223
2024-07-14 05:18:22,658 [INFO    ] __main__: train step 4059: loss: 0.7855, policy_loss: 1.5920, value_loss: 0.9223
2024-07-14 05:18:24,264 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:18:24,735 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:18:24,802 [INFO    ] __main__: train step 4060: loss: 0.7856, policy_loss: 1.5919, value_loss: 0.9223
2024-07-14 05:18:25,091 [INFO    ] __main__: train step 4061: loss: 0.7857, policy_loss: 1.5918, value_loss: 0.9222
2024-07-14 05:18:25,367 [INFO    ] __main__: train step 4062: loss: 0.7858, policy_loss: 1.5917, value_loss: 0.9222
2024-07-14 05:18:25,642 [INFO    ] __main__: train step 4063: loss: 0.7859, policy_loss: 1.5916, value_loss: 0.9222
2024-07-14 05:18:26,274 [INFO    ] __main__: train step 4064: loss: 0.7861, policy_loss: 1.5915, value_loss: 0.9222
2024-07-14 05:18:26,560 [INFO    ] __main__: train step 4065: loss: 0.7862, policy_loss: 1.5914, value_loss: 0.9221
2024-07-14 05:18:26,836 [INFO    ] __main__: train step 4066: loss: 0.7863, policy_loss: 1.5913, value_loss: 0.9221
2024-07-14 05:18:27,117 [INFO    ] __main__: train step 4067: loss: 0.7864, policy_loss: 1.5911, value_loss: 0.9221
2024-07-14 05:18:27,406 [INFO    ] __main__: train step 4068: loss: 0.7865, policy_loss: 1.5910, value_loss: 0.9220
2024-07-14 05:18:27,677 [INFO    ] __main__: train step 4069: loss: 0.7867, policy_loss: 1.5909, value_loss: 0.9220
2024-07-14 05:18:27,963 [INFO    ] __main__: train step 4070: loss: 0.7868, policy_loss: 1.5908, value_loss: 0.9220
2024-07-14 05:18:28,250 [INFO    ] __main__: train step 4071: loss: 0.7869, policy_loss: 1.5907, value_loss: 0.9219
2024-07-14 05:18:28,541 [INFO    ] __main__: train step 4072: loss: 0.7870, policy_loss: 1.5906, value_loss: 0.9219
2024-07-14 05:18:28,825 [INFO    ] __main__: train step 4073: loss: 0.7871, policy_loss: 1.5905, value_loss: 0.9219
2024-07-14 05:18:29,103 [INFO    ] __main__: train step 4074: loss: 0.7872, policy_loss: 1.5904, value_loss: 0.9218
2024-07-14 05:18:29,386 [INFO    ] __main__: train step 4075: loss: 0.7874, policy_loss: 1.5903, value_loss: 0.9218
2024-07-14 05:18:29,654 [INFO    ] __main__: train step 4076: loss: 0.7875, policy_loss: 1.5901, value_loss: 0.9218
2024-07-14 05:18:31,269 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:18:31,743 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:18:31,809 [INFO    ] __main__: train step 4077: loss: 0.7876, policy_loss: 1.5900, value_loss: 0.9218
2024-07-14 05:18:32,088 [INFO    ] __main__: train step 4078: loss: 0.7877, policy_loss: 1.5899, value_loss: 0.9217
2024-07-14 05:18:32,362 [INFO    ] __main__: train step 4079: loss: 0.7878, policy_loss: 1.5898, value_loss: 0.9217
2024-07-14 05:18:32,637 [INFO    ] __main__: train step 4080: loss: 0.7879, policy_loss: 1.5897, value_loss: 0.9217
2024-07-14 05:18:32,918 [INFO    ] __main__: train step 4081: loss: 0.7881, policy_loss: 1.5896, value_loss: 0.9216
2024-07-14 05:18:33,187 [INFO    ] __main__: train step 4082: loss: 0.7882, policy_loss: 1.5895, value_loss: 0.9216
2024-07-14 05:18:33,460 [INFO    ] __main__: train step 4083: loss: 0.7883, policy_loss: 1.5894, value_loss: 0.9216
2024-07-14 05:18:34,256 [INFO    ] __main__: train step 4084: loss: 0.7884, policy_loss: 1.5893, value_loss: 0.9215
2024-07-14 05:18:34,520 [INFO    ] __main__: train step 4085: loss: 0.7885, policy_loss: 1.5891, value_loss: 0.9215
2024-07-14 05:18:34,799 [INFO    ] __main__: train step 4086: loss: 0.7887, policy_loss: 1.5890, value_loss: 0.9215
2024-07-14 05:18:35,077 [INFO    ] __main__: train step 4087: loss: 0.7888, policy_loss: 1.5889, value_loss: 0.9215
2024-07-14 05:18:35,350 [INFO    ] __main__: train step 4088: loss: 0.7889, policy_loss: 1.5888, value_loss: 0.9214
2024-07-14 05:18:35,618 [INFO    ] __main__: train step 4089: loss: 0.7890, policy_loss: 1.5887, value_loss: 0.9214
2024-07-14 05:18:35,911 [INFO    ] __main__: train step 4090: loss: 0.7891, policy_loss: 1.5886, value_loss: 0.9214
2024-07-14 05:18:36,179 [INFO    ] __main__: train step 4091: loss: 0.7892, policy_loss: 1.5885, value_loss: 0.9213
2024-07-14 05:18:36,455 [INFO    ] __main__: train step 4092: loss: 0.7894, policy_loss: 1.5884, value_loss: 0.9213
2024-07-14 05:18:36,732 [INFO    ] __main__: train step 4093: loss: 0.7895, policy_loss: 1.5882, value_loss: 0.9213
2024-07-14 05:18:38,341 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:18:38,816 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:18:38,885 [INFO    ] __main__: train step 4094: loss: 0.7896, policy_loss: 1.5881, value_loss: 0.9212
2024-07-14 05:18:39,160 [INFO    ] __main__: train step 4095: loss: 0.7897, policy_loss: 1.5880, value_loss: 0.9212
2024-07-14 05:18:39,424 [INFO    ] __main__: train step 4096: loss: 0.7898, policy_loss: 1.5879, value_loss: 0.9212
2024-07-14 05:18:39,697 [INFO    ] __main__: train step 4097: loss: 0.7900, policy_loss: 1.5878, value_loss: 0.9211
2024-07-14 05:18:39,970 [INFO    ] __main__: train step 4098: loss: 0.7901, policy_loss: 1.5877, value_loss: 0.9211
2024-07-14 05:18:40,255 [INFO    ] __main__: train step 4099: loss: 0.7902, policy_loss: 1.5876, value_loss: 0.9211
2024-07-14 05:18:40,540 [INFO    ] __main__: train step 4100: loss: 0.7903, policy_loss: 1.5875, value_loss: 0.9211
2024-07-14 05:18:40,821 [INFO    ] __main__: train step 4101: loss: 0.7904, policy_loss: 1.5874, value_loss: 0.9210
2024-07-14 05:18:41,092 [INFO    ] __main__: train step 4102: loss: 0.7905, policy_loss: 1.5873, value_loss: 0.9210
2024-07-14 05:18:41,928 [INFO    ] __main__: train step 4103: loss: 0.7907, policy_loss: 1.5871, value_loss: 0.9210
2024-07-14 05:18:42,196 [INFO    ] __main__: train step 4104: loss: 0.7908, policy_loss: 1.5870, value_loss: 0.9209
2024-07-14 05:18:42,465 [INFO    ] __main__: train step 4105: loss: 0.7909, policy_loss: 1.5869, value_loss: 0.9209
2024-07-14 05:18:42,755 [INFO    ] __main__: train step 4106: loss: 0.7910, policy_loss: 1.5868, value_loss: 0.9209
2024-07-14 05:18:43,032 [INFO    ] __main__: train step 4107: loss: 0.7911, policy_loss: 1.5867, value_loss: 0.9209
2024-07-14 05:18:43,307 [INFO    ] __main__: train step 4108: loss: 0.7912, policy_loss: 1.5866, value_loss: 0.9208
2024-07-14 05:18:43,613 [INFO    ] __main__: train step 4109: loss: 0.7914, policy_loss: 1.5865, value_loss: 0.9208
2024-07-14 05:18:43,897 [INFO    ] __main__: train step 4110: loss: 0.7915, policy_loss: 1.5864, value_loss: 0.9208
2024-07-14 05:18:45,501 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:18:45,967 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:18:46,038 [INFO    ] __main__: train step 4111: loss: 0.7916, policy_loss: 1.5863, value_loss: 0.9207
2024-07-14 05:18:46,320 [INFO    ] __main__: train step 4112: loss: 0.7917, policy_loss: 1.5862, value_loss: 0.9207
2024-07-14 05:18:46,602 [INFO    ] __main__: train step 4113: loss: 0.7918, policy_loss: 1.5860, value_loss: 0.9207
2024-07-14 05:18:46,880 [INFO    ] __main__: train step 4114: loss: 0.7919, policy_loss: 1.5859, value_loss: 0.9206
2024-07-14 05:18:47,154 [INFO    ] __main__: train step 4115: loss: 0.7921, policy_loss: 1.5858, value_loss: 0.9206
2024-07-14 05:18:47,430 [INFO    ] __main__: train step 4116: loss: 0.7922, policy_loss: 1.5857, value_loss: 0.9206
2024-07-14 05:18:47,712 [INFO    ] __main__: train step 4117: loss: 0.7923, policy_loss: 1.5856, value_loss: 0.9205
2024-07-14 05:18:47,957 [INFO    ] __main__: train step 4118: loss: 0.7924, policy_loss: 1.5855, value_loss: 0.9205
2024-07-14 05:18:48,240 [INFO    ] __main__: train step 4119: loss: 0.7925, policy_loss: 1.5854, value_loss: 0.9205
2024-07-14 05:18:48,516 [INFO    ] __main__: train step 4120: loss: 0.7926, policy_loss: 1.5853, value_loss: 0.9204
2024-07-14 05:18:48,803 [INFO    ] __main__: train step 4121: loss: 0.7927, policy_loss: 1.5852, value_loss: 0.9204
2024-07-14 05:18:49,076 [INFO    ] __main__: train step 4122: loss: 0.7929, policy_loss: 1.5851, value_loss: 0.9204
2024-07-14 05:18:49,970 [INFO    ] __main__: train step 4123: loss: 0.7930, policy_loss: 1.5849, value_loss: 0.9203
2024-07-14 05:18:50,245 [INFO    ] __main__: train step 4124: loss: 0.7931, policy_loss: 1.5848, value_loss: 0.9203
2024-07-14 05:18:50,523 [INFO    ] __main__: train step 4125: loss: 0.7932, policy_loss: 1.5847, value_loss: 0.9203
2024-07-14 05:18:50,804 [INFO    ] __main__: train step 4126: loss: 0.7933, policy_loss: 1.5846, value_loss: 0.9202
2024-07-14 05:18:51,067 [INFO    ] __main__: train step 4127: loss: 0.7935, policy_loss: 1.5845, value_loss: 0.9202
2024-07-14 05:18:52,676 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:18:53,153 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:18:53,225 [INFO    ] __main__: train step 4128: loss: 0.7936, policy_loss: 1.5844, value_loss: 0.9202
2024-07-14 05:18:53,496 [INFO    ] __main__: train step 4129: loss: 0.7937, policy_loss: 1.5843, value_loss: 0.9202
2024-07-14 05:18:53,763 [INFO    ] __main__: train step 4130: loss: 0.7938, policy_loss: 1.5842, value_loss: 0.9201
2024-07-14 05:18:54,033 [INFO    ] __main__: train step 4131: loss: 0.7939, policy_loss: 1.5841, value_loss: 0.9201
2024-07-14 05:18:54,303 [INFO    ] __main__: train step 4132: loss: 0.7940, policy_loss: 1.5839, value_loss: 0.9201
2024-07-14 05:18:54,578 [INFO    ] __main__: train step 4133: loss: 0.7941, policy_loss: 1.5838, value_loss: 0.9200
2024-07-14 05:18:54,862 [INFO    ] __main__: train step 4134: loss: 0.7943, policy_loss: 1.5837, value_loss: 0.9200
2024-07-14 05:18:55,144 [INFO    ] __main__: train step 4135: loss: 0.7944, policy_loss: 1.5836, value_loss: 0.9200
2024-07-14 05:18:55,424 [INFO    ] __main__: train step 4136: loss: 0.7945, policy_loss: 1.5835, value_loss: 0.9200
2024-07-14 05:18:55,699 [INFO    ] __main__: train step 4137: loss: 0.7946, policy_loss: 1.5834, value_loss: 0.9199
2024-07-14 05:18:55,978 [INFO    ] __main__: train step 4138: loss: 0.7947, policy_loss: 1.5833, value_loss: 0.9199
2024-07-14 05:18:56,259 [INFO    ] __main__: train step 4139: loss: 0.7948, policy_loss: 1.5832, value_loss: 0.9199
2024-07-14 05:18:56,530 [INFO    ] __main__: train step 4140: loss: 0.7950, policy_loss: 1.5831, value_loss: 0.9198
2024-07-14 05:18:56,809 [INFO    ] __main__: train step 4141: loss: 0.7951, policy_loss: 1.5830, value_loss: 0.9198
2024-07-14 05:18:57,084 [INFO    ] __main__: train step 4142: loss: 0.7952, policy_loss: 1.5829, value_loss: 0.9198
2024-07-14 05:18:57,706 [INFO    ] __main__: train step 4143: loss: 0.7953, policy_loss: 1.5827, value_loss: 0.9197
2024-07-14 05:18:57,983 [INFO    ] __main__: train step 4144: loss: 0.7954, policy_loss: 1.5826, value_loss: 0.9197
2024-07-14 05:18:59,593 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:19:00,073 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:19:00,138 [INFO    ] __main__: train step 4145: loss: 0.7955, policy_loss: 1.5825, value_loss: 0.9197
2024-07-14 05:19:00,417 [INFO    ] __main__: train step 4146: loss: 0.7957, policy_loss: 1.5824, value_loss: 0.9197
2024-07-14 05:19:00,696 [INFO    ] __main__: train step 4147: loss: 0.7958, policy_loss: 1.5823, value_loss: 0.9196
2024-07-14 05:19:00,976 [INFO    ] __main__: train step 4148: loss: 0.7959, policy_loss: 1.5822, value_loss: 0.9196
2024-07-14 05:19:01,250 [INFO    ] __main__: train step 4149: loss: 0.7960, policy_loss: 1.5821, value_loss: 0.9196
2024-07-14 05:19:01,524 [INFO    ] __main__: train step 4150: loss: 0.7961, policy_loss: 1.5820, value_loss: 0.9195
2024-07-14 05:19:01,795 [INFO    ] __main__: train step 4151: loss: 0.7962, policy_loss: 1.5819, value_loss: 0.9195
2024-07-14 05:19:02,069 [INFO    ] __main__: train step 4152: loss: 0.7963, policy_loss: 1.5817, value_loss: 0.9195
2024-07-14 05:19:02,339 [INFO    ] __main__: train step 4153: loss: 0.7965, policy_loss: 1.5816, value_loss: 0.9194
2024-07-14 05:19:02,608 [INFO    ] __main__: train step 4154: loss: 0.7966, policy_loss: 1.5815, value_loss: 0.9194
2024-07-14 05:19:02,891 [INFO    ] __main__: train step 4155: loss: 0.7967, policy_loss: 1.5814, value_loss: 0.9194
2024-07-14 05:19:03,165 [INFO    ] __main__: train step 4156: loss: 0.7968, policy_loss: 1.5813, value_loss: 0.9193
2024-07-14 05:19:03,441 [INFO    ] __main__: train step 4157: loss: 0.7969, policy_loss: 1.5812, value_loss: 0.9193
2024-07-14 05:19:03,711 [INFO    ] __main__: train step 4158: loss: 0.7970, policy_loss: 1.5811, value_loss: 0.9193
2024-07-14 05:19:03,982 [INFO    ] __main__: train step 4159: loss: 0.7971, policy_loss: 1.5810, value_loss: 0.9192
2024-07-14 05:19:04,258 [INFO    ] __main__: train step 4160: loss: 0.7972, policy_loss: 1.5809, value_loss: 0.9192
2024-07-14 05:19:04,539 [INFO    ] __main__: train step 4161: loss: 0.7974, policy_loss: 1.5807, value_loss: 0.9192
2024-07-14 05:19:06,562 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:19:07,041 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:19:07,112 [INFO    ] __main__: train step 4162: loss: 0.7975, policy_loss: 1.5806, value_loss: 0.9191
2024-07-14 05:19:07,397 [INFO    ] __main__: train step 4163: loss: 0.7976, policy_loss: 1.5805, value_loss: 0.9191
2024-07-14 05:19:07,667 [INFO    ] __main__: train step 4164: loss: 0.7977, policy_loss: 1.5804, value_loss: 0.9191
2024-07-14 05:19:07,933 [INFO    ] __main__: train step 4165: loss: 0.7978, policy_loss: 1.5803, value_loss: 0.9190
2024-07-14 05:19:08,213 [INFO    ] __main__: train step 4166: loss: 0.7979, policy_loss: 1.5802, value_loss: 0.9190
2024-07-14 05:19:08,483 [INFO    ] __main__: train step 4167: loss: 0.7980, policy_loss: 1.5801, value_loss: 0.9190
2024-07-14 05:19:08,764 [INFO    ] __main__: train step 4168: loss: 0.7981, policy_loss: 1.5800, value_loss: 0.9189
2024-07-14 05:19:09,063 [INFO    ] __main__: train step 4169: loss: 0.7983, policy_loss: 1.5799, value_loss: 0.9189
2024-07-14 05:19:09,337 [INFO    ] __main__: train step 4170: loss: 0.7984, policy_loss: 1.5798, value_loss: 0.9189
2024-07-14 05:19:09,618 [INFO    ] __main__: train step 4171: loss: 0.7985, policy_loss: 1.5796, value_loss: 0.9189
2024-07-14 05:19:09,898 [INFO    ] __main__: train step 4172: loss: 0.7986, policy_loss: 1.5795, value_loss: 0.9188
2024-07-14 05:19:10,183 [INFO    ] __main__: train step 4173: loss: 0.7987, policy_loss: 1.5794, value_loss: 0.9188
2024-07-14 05:19:10,460 [INFO    ] __main__: train step 4174: loss: 0.7988, policy_loss: 1.5793, value_loss: 0.9188
2024-07-14 05:19:10,748 [INFO    ] __main__: train step 4175: loss: 0.7990, policy_loss: 1.5792, value_loss: 0.9187
2024-07-14 05:19:11,028 [INFO    ] __main__: train step 4176: loss: 0.7991, policy_loss: 1.5791, value_loss: 0.9187
2024-07-14 05:19:11,314 [INFO    ] __main__: train step 4177: loss: 0.7992, policy_loss: 1.5790, value_loss: 0.9187
2024-07-14 05:19:11,610 [INFO    ] __main__: train step 4178: loss: 0.7993, policy_loss: 1.5789, value_loss: 0.9186
2024-07-14 05:19:13,205 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:19:13,686 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:19:13,756 [INFO    ] __main__: train step 4179: loss: 0.7994, policy_loss: 1.5788, value_loss: 0.9186
2024-07-14 05:19:14,031 [INFO    ] __main__: train step 4180: loss: 0.7995, policy_loss: 1.5787, value_loss: 0.9186
2024-07-14 05:19:14,316 [INFO    ] __main__: train step 4181: loss: 0.7996, policy_loss: 1.5785, value_loss: 0.9185
2024-07-14 05:19:15,194 [INFO    ] __main__: train step 4182: loss: 0.7998, policy_loss: 1.5784, value_loss: 0.9185
2024-07-14 05:19:15,481 [INFO    ] __main__: train step 4183: loss: 0.7999, policy_loss: 1.5783, value_loss: 0.9185
2024-07-14 05:19:15,765 [INFO    ] __main__: train step 4184: loss: 0.8000, policy_loss: 1.5782, value_loss: 0.9185
2024-07-14 05:19:16,041 [INFO    ] __main__: train step 4185: loss: 0.8001, policy_loss: 1.5781, value_loss: 0.9184
2024-07-14 05:19:16,331 [INFO    ] __main__: train step 4186: loss: 0.8002, policy_loss: 1.5780, value_loss: 0.9184
2024-07-14 05:19:16,608 [INFO    ] __main__: train step 4187: loss: 0.8003, policy_loss: 1.5779, value_loss: 0.9184
2024-07-14 05:19:16,882 [INFO    ] __main__: train step 4188: loss: 0.8004, policy_loss: 1.5778, value_loss: 0.9183
2024-07-14 05:19:17,156 [INFO    ] __main__: train step 4189: loss: 0.8006, policy_loss: 1.5776, value_loss: 0.9183
2024-07-14 05:19:17,433 [INFO    ] __main__: train step 4190: loss: 0.8007, policy_loss: 1.5775, value_loss: 0.9183
2024-07-14 05:19:17,708 [INFO    ] __main__: train step 4191: loss: 0.8008, policy_loss: 1.5774, value_loss: 0.9183
2024-07-14 05:19:17,995 [INFO    ] __main__: train step 4192: loss: 0.8009, policy_loss: 1.5773, value_loss: 0.9182
2024-07-14 05:19:18,283 [INFO    ] __main__: train step 4193: loss: 0.8010, policy_loss: 1.5772, value_loss: 0.9182
2024-07-14 05:19:18,560 [INFO    ] __main__: train step 4194: loss: 0.8011, policy_loss: 1.5771, value_loss: 0.9181
2024-07-14 05:19:18,838 [INFO    ] __main__: train step 4195: loss: 0.8012, policy_loss: 1.5770, value_loss: 0.9181
2024-07-14 05:19:20,444 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:19:20,921 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:19:20,986 [INFO    ] __main__: train step 4196: loss: 0.8014, policy_loss: 1.5769, value_loss: 0.9181
2024-07-14 05:19:21,254 [INFO    ] __main__: train step 4197: loss: 0.8015, policy_loss: 1.5768, value_loss: 0.9181
2024-07-14 05:19:21,524 [INFO    ] __main__: train step 4198: loss: 0.8016, policy_loss: 1.5767, value_loss: 0.9180
2024-07-14 05:19:21,798 [INFO    ] __main__: train step 4199: loss: 0.8017, policy_loss: 1.5766, value_loss: 0.9180
2024-07-14 05:19:22,086 [INFO    ] __main__: train step 4200: loss: 0.8018, policy_loss: 1.5764, value_loss: 0.9180
2024-07-14 05:19:22,922 [INFO    ] __main__: train step 4201: loss: 0.8019, policy_loss: 1.5763, value_loss: 0.9179
2024-07-14 05:19:23,205 [INFO    ] __main__: train step 4202: loss: 0.8021, policy_loss: 1.5762, value_loss: 0.9179
2024-07-14 05:19:23,476 [INFO    ] __main__: train step 4203: loss: 0.8022, policy_loss: 1.5761, value_loss: 0.9179
2024-07-14 05:19:23,751 [INFO    ] __main__: train step 4204: loss: 0.8023, policy_loss: 1.5760, value_loss: 0.9178
2024-07-14 05:19:24,029 [INFO    ] __main__: train step 4205: loss: 0.8024, policy_loss: 1.5759, value_loss: 0.9178
2024-07-14 05:19:24,308 [INFO    ] __main__: train step 4206: loss: 0.8025, policy_loss: 1.5758, value_loss: 0.9178
2024-07-14 05:19:24,582 [INFO    ] __main__: train step 4207: loss: 0.8026, policy_loss: 1.5757, value_loss: 0.9177
2024-07-14 05:19:24,862 [INFO    ] __main__: train step 4208: loss: 0.8027, policy_loss: 1.5756, value_loss: 0.9177
2024-07-14 05:19:25,144 [INFO    ] __main__: train step 4209: loss: 0.8028, policy_loss: 1.5755, value_loss: 0.9177
2024-07-14 05:19:25,422 [INFO    ] __main__: train step 4210: loss: 0.8030, policy_loss: 1.5754, value_loss: 0.9176
2024-07-14 05:19:25,693 [INFO    ] __main__: train step 4211: loss: 0.8031, policy_loss: 1.5752, value_loss: 0.9176
2024-07-14 05:19:25,967 [INFO    ] __main__: train step 4212: loss: 0.8032, policy_loss: 1.5751, value_loss: 0.9176
2024-07-14 05:19:27,565 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:19:28,039 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:19:28,106 [INFO    ] __main__: train step 4213: loss: 0.8033, policy_loss: 1.5750, value_loss: 0.9176
2024-07-14 05:19:28,385 [INFO    ] __main__: train step 4214: loss: 0.8034, policy_loss: 1.5749, value_loss: 0.9175
2024-07-14 05:19:28,671 [INFO    ] __main__: train step 4215: loss: 0.8035, policy_loss: 1.5748, value_loss: 0.9175
2024-07-14 05:19:28,952 [INFO    ] __main__: train step 4216: loss: 0.8037, policy_loss: 1.5747, value_loss: 0.9175
2024-07-14 05:19:29,231 [INFO    ] __main__: train step 4217: loss: 0.8038, policy_loss: 1.5746, value_loss: 0.9174
2024-07-14 05:19:29,507 [INFO    ] __main__: train step 4218: loss: 0.8039, policy_loss: 1.5745, value_loss: 0.9174
2024-07-14 05:19:29,789 [INFO    ] __main__: train step 4219: loss: 0.8040, policy_loss: 1.5744, value_loss: 0.9174
2024-07-14 05:19:30,437 [INFO    ] __main__: train step 4220: loss: 0.8041, policy_loss: 1.5742, value_loss: 0.9173
2024-07-14 05:19:30,713 [INFO    ] __main__: train step 4221: loss: 0.8042, policy_loss: 1.5741, value_loss: 0.9173
2024-07-14 05:19:30,988 [INFO    ] __main__: train step 4222: loss: 0.8043, policy_loss: 1.5740, value_loss: 0.9173
2024-07-14 05:19:31,275 [INFO    ] __main__: train step 4223: loss: 0.8045, policy_loss: 1.5739, value_loss: 0.9173
2024-07-14 05:19:31,548 [INFO    ] __main__: train step 4224: loss: 0.8046, policy_loss: 1.5738, value_loss: 0.9172
2024-07-14 05:19:31,835 [INFO    ] __main__: train step 4225: loss: 0.8047, policy_loss: 1.5737, value_loss: 0.9172
2024-07-14 05:19:32,111 [INFO    ] __main__: train step 4226: loss: 0.8048, policy_loss: 1.5736, value_loss: 0.9172
2024-07-14 05:19:32,391 [INFO    ] __main__: train step 4227: loss: 0.8049, policy_loss: 1.5735, value_loss: 0.9171
2024-07-14 05:19:32,668 [INFO    ] __main__: train step 4228: loss: 0.8050, policy_loss: 1.5734, value_loss: 0.9171
2024-07-14 05:19:32,944 [INFO    ] __main__: train step 4229: loss: 0.8051, policy_loss: 1.5733, value_loss: 0.9171
2024-07-14 05:19:34,544 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:19:35,023 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:19:35,087 [INFO    ] __main__: train step 4230: loss: 0.8052, policy_loss: 1.5731, value_loss: 0.9170
2024-07-14 05:19:35,369 [INFO    ] __main__: train step 4231: loss: 0.8054, policy_loss: 1.5730, value_loss: 0.9170
2024-07-14 05:19:35,638 [INFO    ] __main__: train step 4232: loss: 0.8055, policy_loss: 1.5729, value_loss: 0.9170
2024-07-14 05:19:35,911 [INFO    ] __main__: train step 4233: loss: 0.8056, policy_loss: 1.5728, value_loss: 0.9169
2024-07-14 05:19:36,184 [INFO    ] __main__: train step 4234: loss: 0.8057, policy_loss: 1.5727, value_loss: 0.9169
2024-07-14 05:19:36,461 [INFO    ] __main__: train step 4235: loss: 0.8058, policy_loss: 1.5726, value_loss: 0.9169
2024-07-14 05:19:36,733 [INFO    ] __main__: train step 4236: loss: 0.8059, policy_loss: 1.5725, value_loss: 0.9169
2024-07-14 05:19:37,007 [INFO    ] __main__: train step 4237: loss: 0.8060, policy_loss: 1.5724, value_loss: 0.9168
2024-07-14 05:19:37,307 [INFO    ] __main__: train step 4238: loss: 0.8061, policy_loss: 1.5723, value_loss: 0.9168
2024-07-14 05:19:37,941 [INFO    ] __main__: train step 4239: loss: 0.8063, policy_loss: 1.5722, value_loss: 0.9168
2024-07-14 05:19:38,220 [INFO    ] __main__: train step 4240: loss: 0.8064, policy_loss: 1.5720, value_loss: 0.9167
2024-07-14 05:19:38,490 [INFO    ] __main__: train step 4241: loss: 0.8065, policy_loss: 1.5719, value_loss: 0.9167
2024-07-14 05:19:38,771 [INFO    ] __main__: train step 4242: loss: 0.8066, policy_loss: 1.5718, value_loss: 0.9167
2024-07-14 05:19:39,056 [INFO    ] __main__: train step 4243: loss: 0.8067, policy_loss: 1.5717, value_loss: 0.9167
2024-07-14 05:19:39,312 [INFO    ] __main__: train step 4244: loss: 0.8068, policy_loss: 1.5716, value_loss: 0.9166
2024-07-14 05:19:39,572 [INFO    ] __main__: train step 4245: loss: 0.8069, policy_loss: 1.5715, value_loss: 0.9166
2024-07-14 05:19:39,849 [INFO    ] __main__: train step 4246: loss: 0.8071, policy_loss: 1.5714, value_loss: 0.9166
2024-07-14 05:19:41,447 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:19:41,929 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:19:41,993 [INFO    ] __main__: train step 4247: loss: 0.8072, policy_loss: 1.5713, value_loss: 0.9165
2024-07-14 05:19:42,292 [INFO    ] __main__: train step 4248: loss: 0.8073, policy_loss: 1.5712, value_loss: 0.9165
2024-07-14 05:19:42,574 [INFO    ] __main__: train step 4249: loss: 0.8074, policy_loss: 1.5711, value_loss: 0.9165
2024-07-14 05:19:42,847 [INFO    ] __main__: train step 4250: loss: 0.8075, policy_loss: 1.5709, value_loss: 0.9164
2024-07-14 05:19:43,128 [INFO    ] __main__: train step 4251: loss: 0.8076, policy_loss: 1.5708, value_loss: 0.9164
2024-07-14 05:19:43,411 [INFO    ] __main__: train step 4252: loss: 0.8077, policy_loss: 1.5707, value_loss: 0.9164
2024-07-14 05:19:43,679 [INFO    ] __main__: train step 4253: loss: 0.8079, policy_loss: 1.5706, value_loss: 0.9164
2024-07-14 05:19:43,956 [INFO    ] __main__: train step 4254: loss: 0.8080, policy_loss: 1.5705, value_loss: 0.9163
2024-07-14 05:19:44,236 [INFO    ] __main__: train step 4255: loss: 0.8081, policy_loss: 1.5704, value_loss: 0.9163
2024-07-14 05:19:44,511 [INFO    ] __main__: train step 4256: loss: 0.8082, policy_loss: 1.5703, value_loss: 0.9163
2024-07-14 05:19:44,793 [INFO    ] __main__: train step 4257: loss: 0.8083, policy_loss: 1.5702, value_loss: 0.9162
2024-07-14 05:19:45,064 [INFO    ] __main__: train step 4258: loss: 0.8084, policy_loss: 1.5701, value_loss: 0.9162
2024-07-14 05:19:45,701 [INFO    ] __main__: train step 4259: loss: 0.8085, policy_loss: 1.5700, value_loss: 0.9162
2024-07-14 05:19:45,981 [INFO    ] __main__: train step 4260: loss: 0.8086, policy_loss: 1.5698, value_loss: 0.9161
2024-07-14 05:19:46,257 [INFO    ] __main__: train step 4261: loss: 0.8088, policy_loss: 1.5697, value_loss: 0.9161
2024-07-14 05:19:46,532 [INFO    ] __main__: train step 4262: loss: 0.8089, policy_loss: 1.5696, value_loss: 0.9161
2024-07-14 05:19:46,806 [INFO    ] __main__: train step 4263: loss: 0.8090, policy_loss: 1.5695, value_loss: 0.9160
2024-07-14 05:19:48,383 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:19:48,864 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:19:48,931 [INFO    ] __main__: train step 4264: loss: 0.8091, policy_loss: 1.5694, value_loss: 0.9160
2024-07-14 05:19:49,193 [INFO    ] __main__: train step 4265: loss: 0.8092, policy_loss: 1.5693, value_loss: 0.9160
2024-07-14 05:19:49,452 [INFO    ] __main__: train step 4266: loss: 0.8093, policy_loss: 1.5692, value_loss: 0.9160
2024-07-14 05:19:49,727 [INFO    ] __main__: train step 4267: loss: 0.8094, policy_loss: 1.5691, value_loss: 0.9159
2024-07-14 05:19:49,997 [INFO    ] __main__: train step 4268: loss: 0.8096, policy_loss: 1.5690, value_loss: 0.9159
2024-07-14 05:19:50,276 [INFO    ] __main__: train step 4269: loss: 0.8097, policy_loss: 1.5689, value_loss: 0.9159
2024-07-14 05:19:50,555 [INFO    ] __main__: train step 4270: loss: 0.8098, policy_loss: 1.5688, value_loss: 0.9158
2024-07-14 05:19:50,841 [INFO    ] __main__: train step 4271: loss: 0.8099, policy_loss: 1.5687, value_loss: 0.9158
2024-07-14 05:19:51,106 [INFO    ] __main__: train step 4272: loss: 0.8100, policy_loss: 1.5686, value_loss: 0.9158
2024-07-14 05:19:51,377 [INFO    ] __main__: train step 4273: loss: 0.8101, policy_loss: 1.5685, value_loss: 0.9157
2024-07-14 05:19:51,658 [INFO    ] __main__: train step 4274: loss: 0.8102, policy_loss: 1.5683, value_loss: 0.9157
2024-07-14 05:19:51,929 [INFO    ] __main__: train step 4275: loss: 0.8104, policy_loss: 1.5682, value_loss: 0.9157
2024-07-14 05:19:52,210 [INFO    ] __main__: train step 4276: loss: 0.8105, policy_loss: 1.5681, value_loss: 0.9156
2024-07-14 05:19:52,491 [INFO    ] __main__: train step 4277: loss: 0.8106, policy_loss: 1.5680, value_loss: 0.9156
2024-07-14 05:19:52,749 [INFO    ] __main__: train step 4278: loss: 0.8107, policy_loss: 1.5679, value_loss: 0.9156
2024-07-14 05:19:53,356 [INFO    ] __main__: train step 4279: loss: 0.8108, policy_loss: 1.5678, value_loss: 0.9156
2024-07-14 05:19:53,611 [INFO    ] __main__: train step 4280: loss: 0.8109, policy_loss: 1.5677, value_loss: 0.9155
2024-07-14 05:19:55,187 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:19:55,664 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:19:55,735 [INFO    ] __main__: train step 4281: loss: 0.8110, policy_loss: 1.5676, value_loss: 0.9155
2024-07-14 05:19:56,014 [INFO    ] __main__: train step 4282: loss: 0.8112, policy_loss: 1.5675, value_loss: 0.9155
2024-07-14 05:19:56,288 [INFO    ] __main__: train step 4283: loss: 0.8113, policy_loss: 1.5674, value_loss: 0.9154
2024-07-14 05:19:56,571 [INFO    ] __main__: train step 4284: loss: 0.8114, policy_loss: 1.5673, value_loss: 0.9154
2024-07-14 05:19:56,844 [INFO    ] __main__: train step 4285: loss: 0.8115, policy_loss: 1.5672, value_loss: 0.9154
2024-07-14 05:19:57,120 [INFO    ] __main__: train step 4286: loss: 0.8116, policy_loss: 1.5671, value_loss: 0.9153
2024-07-14 05:19:57,412 [INFO    ] __main__: train step 4287: loss: 0.8117, policy_loss: 1.5669, value_loss: 0.9153
2024-07-14 05:19:57,699 [INFO    ] __main__: train step 4288: loss: 0.8118, policy_loss: 1.5668, value_loss: 0.9153
2024-07-14 05:19:57,989 [INFO    ] __main__: train step 4289: loss: 0.8120, policy_loss: 1.5667, value_loss: 0.9153
2024-07-14 05:19:58,277 [INFO    ] __main__: train step 4290: loss: 0.8121, policy_loss: 1.5666, value_loss: 0.9152
2024-07-14 05:19:58,562 [INFO    ] __main__: train step 4291: loss: 0.8122, policy_loss: 1.5665, value_loss: 0.9152
2024-07-14 05:19:58,841 [INFO    ] __main__: train step 4292: loss: 0.8123, policy_loss: 1.5664, value_loss: 0.9152
2024-07-14 05:19:59,118 [INFO    ] __main__: train step 4293: loss: 0.8124, policy_loss: 1.5663, value_loss: 0.9151
2024-07-14 05:19:59,399 [INFO    ] __main__: train step 4294: loss: 0.8125, policy_loss: 1.5662, value_loss: 0.9151
2024-07-14 05:19:59,681 [INFO    ] __main__: train step 4295: loss: 0.8126, policy_loss: 1.5661, value_loss: 0.9151
2024-07-14 05:19:59,957 [INFO    ] __main__: train step 4296: loss: 0.8128, policy_loss: 1.5660, value_loss: 0.9151
2024-07-14 05:20:00,233 [INFO    ] __main__: train step 4297: loss: 0.8129, policy_loss: 1.5659, value_loss: 0.9150
2024-07-14 05:20:01,829 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:20:02,319 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:20:02,386 [INFO    ] __main__: train step 4298: loss: 0.8130, policy_loss: 1.5658, value_loss: 0.9150
2024-07-14 05:20:03,258 [INFO    ] __main__: train step 4299: loss: 0.8131, policy_loss: 1.5657, value_loss: 0.9150
2024-07-14 05:20:03,537 [INFO    ] __main__: train step 4300: loss: 0.8132, policy_loss: 1.5655, value_loss: 0.9149
2024-07-14 05:20:03,817 [INFO    ] __main__: train step 4301: loss: 0.8133, policy_loss: 1.5654, value_loss: 0.9149
2024-07-14 05:20:04,104 [INFO    ] __main__: train step 4302: loss: 0.8134, policy_loss: 1.5653, value_loss: 0.9149
2024-07-14 05:20:04,387 [INFO    ] __main__: train step 4303: loss: 0.8136, policy_loss: 1.5652, value_loss: 0.9148
2024-07-14 05:20:04,660 [INFO    ] __main__: train step 4304: loss: 0.8137, policy_loss: 1.5651, value_loss: 0.9148
2024-07-14 05:20:04,935 [INFO    ] __main__: train step 4305: loss: 0.8138, policy_loss: 1.5650, value_loss: 0.9148
2024-07-14 05:20:05,223 [INFO    ] __main__: train step 4306: loss: 0.8139, policy_loss: 1.5649, value_loss: 0.9147
2024-07-14 05:20:05,498 [INFO    ] __main__: train step 4307: loss: 0.8140, policy_loss: 1.5648, value_loss: 0.9147
2024-07-14 05:20:05,786 [INFO    ] __main__: train step 4308: loss: 0.8141, policy_loss: 1.5647, value_loss: 0.9147
2024-07-14 05:20:06,058 [INFO    ] __main__: train step 4309: loss: 0.8142, policy_loss: 1.5646, value_loss: 0.9147
2024-07-14 05:20:06,310 [INFO    ] __main__: train step 4310: loss: 0.8144, policy_loss: 1.5645, value_loss: 0.9146
2024-07-14 05:20:06,567 [INFO    ] __main__: train step 4311: loss: 0.8145, policy_loss: 1.5644, value_loss: 0.9146
2024-07-14 05:20:06,844 [INFO    ] __main__: train step 4312: loss: 0.8146, policy_loss: 1.5642, value_loss: 0.9146
2024-07-14 05:20:07,113 [INFO    ] __main__: train step 4313: loss: 0.8147, policy_loss: 1.5641, value_loss: 0.9145
2024-07-14 05:20:07,386 [INFO    ] __main__: train step 4314: loss: 0.8148, policy_loss: 1.5640, value_loss: 0.9145
2024-07-14 05:20:08,960 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:20:09,458 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:20:09,528 [INFO    ] __main__: train step 4315: loss: 0.8149, policy_loss: 1.5639, value_loss: 0.9145
2024-07-14 05:20:09,790 [INFO    ] __main__: train step 4316: loss: 0.8150, policy_loss: 1.5638, value_loss: 0.9145
2024-07-14 05:20:10,067 [INFO    ] __main__: train step 4317: loss: 0.8152, policy_loss: 1.5637, value_loss: 0.9144
2024-07-14 05:20:10,340 [INFO    ] __main__: train step 4318: loss: 0.8153, policy_loss: 1.5636, value_loss: 0.9144
2024-07-14 05:20:10,960 [INFO    ] __main__: train step 4319: loss: 0.8154, policy_loss: 1.5635, value_loss: 0.9144
2024-07-14 05:20:11,237 [INFO    ] __main__: train step 4320: loss: 0.8155, policy_loss: 1.5634, value_loss: 0.9143
2024-07-14 05:20:11,516 [INFO    ] __main__: train step 4321: loss: 0.8156, policy_loss: 1.5633, value_loss: 0.9143
2024-07-14 05:20:11,797 [INFO    ] __main__: train step 4322: loss: 0.8157, policy_loss: 1.5632, value_loss: 0.9143
2024-07-14 05:20:12,069 [INFO    ] __main__: train step 4323: loss: 0.8158, policy_loss: 1.5631, value_loss: 0.9142
2024-07-14 05:20:12,354 [INFO    ] __main__: train step 4324: loss: 0.8159, policy_loss: 1.5630, value_loss: 0.9142
2024-07-14 05:20:12,631 [INFO    ] __main__: train step 4325: loss: 0.8161, policy_loss: 1.5629, value_loss: 0.9142
2024-07-14 05:20:12,913 [INFO    ] __main__: train step 4326: loss: 0.8162, policy_loss: 1.5628, value_loss: 0.9142
2024-07-14 05:20:13,186 [INFO    ] __main__: train step 4327: loss: 0.8163, policy_loss: 1.5626, value_loss: 0.9141
2024-07-14 05:20:13,461 [INFO    ] __main__: train step 4328: loss: 0.8164, policy_loss: 1.5625, value_loss: 0.9141
2024-07-14 05:20:13,741 [INFO    ] __main__: train step 4329: loss: 0.8165, policy_loss: 1.5624, value_loss: 0.9141
2024-07-14 05:20:14,009 [INFO    ] __main__: train step 4330: loss: 0.8166, policy_loss: 1.5623, value_loss: 0.9140
2024-07-14 05:20:14,296 [INFO    ] __main__: train step 4331: loss: 0.8167, policy_loss: 1.5622, value_loss: 0.9140
2024-07-14 05:20:15,887 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:20:16,358 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:20:16,427 [INFO    ] __main__: train step 4332: loss: 0.8169, policy_loss: 1.5621, value_loss: 0.9140
2024-07-14 05:20:16,684 [INFO    ] __main__: train step 4333: loss: 0.8170, policy_loss: 1.5620, value_loss: 0.9140
2024-07-14 05:20:16,960 [INFO    ] __main__: train step 4334: loss: 0.8171, policy_loss: 1.5619, value_loss: 0.9139
2024-07-14 05:20:17,243 [INFO    ] __main__: train step 4335: loss: 0.8172, policy_loss: 1.5618, value_loss: 0.9139
2024-07-14 05:20:17,519 [INFO    ] __main__: train step 4336: loss: 0.8173, policy_loss: 1.5617, value_loss: 0.9139
2024-07-14 05:20:17,794 [INFO    ] __main__: train step 4337: loss: 0.8174, policy_loss: 1.5616, value_loss: 0.9138
2024-07-14 05:20:18,078 [INFO    ] __main__: train step 4338: loss: 0.8175, policy_loss: 1.5615, value_loss: 0.9138
2024-07-14 05:20:18,924 [INFO    ] __main__: train step 4339: loss: 0.8176, policy_loss: 1.5614, value_loss: 0.9138
2024-07-14 05:20:19,208 [INFO    ] __main__: train step 4340: loss: 0.8178, policy_loss: 1.5613, value_loss: 0.9137
2024-07-14 05:20:19,527 [INFO    ] __main__: train step 4341: loss: 0.8179, policy_loss: 1.5612, value_loss: 0.9137
2024-07-14 05:20:19,806 [INFO    ] __main__: train step 4342: loss: 0.8180, policy_loss: 1.5610, value_loss: 0.9137
2024-07-14 05:20:20,089 [INFO    ] __main__: train step 4343: loss: 0.8181, policy_loss: 1.5609, value_loss: 0.9136
2024-07-14 05:20:20,373 [INFO    ] __main__: train step 4344: loss: 0.8182, policy_loss: 1.5608, value_loss: 0.9136
2024-07-14 05:20:20,664 [INFO    ] __main__: train step 4345: loss: 0.8183, policy_loss: 1.5607, value_loss: 0.9136
2024-07-14 05:20:20,945 [INFO    ] __main__: train step 4346: loss: 0.8184, policy_loss: 1.5606, value_loss: 0.9135
2024-07-14 05:20:21,233 [INFO    ] __main__: train step 4347: loss: 0.8186, policy_loss: 1.5605, value_loss: 0.9135
2024-07-14 05:20:21,520 [INFO    ] __main__: train step 4348: loss: 0.8187, policy_loss: 1.5604, value_loss: 0.9135
2024-07-14 05:20:23,116 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:20:23,591 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:20:23,658 [INFO    ] __main__: train step 4349: loss: 0.8188, policy_loss: 1.5603, value_loss: 0.9135
2024-07-14 05:20:23,937 [INFO    ] __main__: train step 4350: loss: 0.8189, policy_loss: 1.5602, value_loss: 0.9134
2024-07-14 05:20:24,209 [INFO    ] __main__: train step 4351: loss: 0.8190, policy_loss: 1.5601, value_loss: 0.9134
2024-07-14 05:20:24,490 [INFO    ] __main__: train step 4352: loss: 0.8191, policy_loss: 1.5600, value_loss: 0.9134
2024-07-14 05:20:24,777 [INFO    ] __main__: train step 4353: loss: 0.8192, policy_loss: 1.5599, value_loss: 0.9133
2024-07-14 05:20:25,062 [INFO    ] __main__: train step 4354: loss: 0.8193, policy_loss: 1.5598, value_loss: 0.9133
2024-07-14 05:20:25,339 [INFO    ] __main__: train step 4355: loss: 0.8195, policy_loss: 1.5597, value_loss: 0.9133
2024-07-14 05:20:25,635 [INFO    ] __main__: train step 4356: loss: 0.8196, policy_loss: 1.5596, value_loss: 0.9132
2024-07-14 05:20:25,918 [INFO    ] __main__: train step 4357: loss: 0.8197, policy_loss: 1.5594, value_loss: 0.9132
2024-07-14 05:20:26,187 [INFO    ] __main__: train step 4358: loss: 0.8198, policy_loss: 1.5593, value_loss: 0.9132
2024-07-14 05:20:27,089 [INFO    ] __main__: train step 4359: loss: 0.8199, policy_loss: 1.5592, value_loss: 0.9131
2024-07-14 05:20:27,369 [INFO    ] __main__: train step 4360: loss: 0.8200, policy_loss: 1.5591, value_loss: 0.9131
2024-07-14 05:20:27,645 [INFO    ] __main__: train step 4361: loss: 0.8201, policy_loss: 1.5590, value_loss: 0.9131
2024-07-14 05:20:27,924 [INFO    ] __main__: train step 4362: loss: 0.8202, policy_loss: 1.5589, value_loss: 0.9131
2024-07-14 05:20:28,191 [INFO    ] __main__: train step 4363: loss: 0.8204, policy_loss: 1.5588, value_loss: 0.9130
2024-07-14 05:20:28,474 [INFO    ] __main__: train step 4364: loss: 0.8205, policy_loss: 1.5587, value_loss: 0.9130
2024-07-14 05:20:28,753 [INFO    ] __main__: train step 4365: loss: 0.8206, policy_loss: 1.5586, value_loss: 0.9130
2024-07-14 05:20:30,350 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:20:30,812 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:20:30,879 [INFO    ] __main__: train step 4366: loss: 0.8207, policy_loss: 1.5585, value_loss: 0.9129
2024-07-14 05:20:31,159 [INFO    ] __main__: train step 4367: loss: 0.8208, policy_loss: 1.5584, value_loss: 0.9129
2024-07-14 05:20:31,431 [INFO    ] __main__: train step 4368: loss: 0.8209, policy_loss: 1.5583, value_loss: 0.9129
2024-07-14 05:20:31,720 [INFO    ] __main__: train step 4369: loss: 0.8210, policy_loss: 1.5582, value_loss: 0.9128
2024-07-14 05:20:31,995 [INFO    ] __main__: train step 4370: loss: 0.8212, policy_loss: 1.5581, value_loss: 0.9128
2024-07-14 05:20:32,286 [INFO    ] __main__: train step 4371: loss: 0.8213, policy_loss: 1.5579, value_loss: 0.9128
2024-07-14 05:20:32,564 [INFO    ] __main__: train step 4372: loss: 0.8214, policy_loss: 1.5578, value_loss: 0.9128
2024-07-14 05:20:32,840 [INFO    ] __main__: train step 4373: loss: 0.8215, policy_loss: 1.5577, value_loss: 0.9127
2024-07-14 05:20:33,111 [INFO    ] __main__: train step 4374: loss: 0.8216, policy_loss: 1.5576, value_loss: 0.9127
2024-07-14 05:20:33,387 [INFO    ] __main__: train step 4375: loss: 0.8217, policy_loss: 1.5575, value_loss: 0.9127
2024-07-14 05:20:33,666 [INFO    ] __main__: train step 4376: loss: 0.8218, policy_loss: 1.5574, value_loss: 0.9126
2024-07-14 05:20:33,954 [INFO    ] __main__: train step 4377: loss: 0.8219, policy_loss: 1.5573, value_loss: 0.9126
2024-07-14 05:20:34,225 [INFO    ] __main__: train step 4378: loss: 0.8220, policy_loss: 1.5572, value_loss: 0.9126
2024-07-14 05:20:34,862 [INFO    ] __main__: train step 4379: loss: 0.8222, policy_loss: 1.5571, value_loss: 0.9125
2024-07-14 05:20:35,139 [INFO    ] __main__: train step 4380: loss: 0.8223, policy_loss: 1.5570, value_loss: 0.9125
2024-07-14 05:20:35,418 [INFO    ] __main__: train step 4381: loss: 0.8224, policy_loss: 1.5569, value_loss: 0.9125
2024-07-14 05:20:35,692 [INFO    ] __main__: train step 4382: loss: 0.8225, policy_loss: 1.5568, value_loss: 0.9124
2024-07-14 05:20:37,283 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:20:37,748 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:20:37,819 [INFO    ] __main__: train step 4383: loss: 0.8226, policy_loss: 1.5567, value_loss: 0.9124
2024-07-14 05:20:38,089 [INFO    ] __main__: train step 4384: loss: 0.8227, policy_loss: 1.5566, value_loss: 0.9124
2024-07-14 05:20:38,360 [INFO    ] __main__: train step 4385: loss: 0.8228, policy_loss: 1.5565, value_loss: 0.9124
2024-07-14 05:20:38,631 [INFO    ] __main__: train step 4386: loss: 0.8229, policy_loss: 1.5564, value_loss: 0.9123
2024-07-14 05:20:38,905 [INFO    ] __main__: train step 4387: loss: 0.8231, policy_loss: 1.5563, value_loss: 0.9123
2024-07-14 05:20:39,189 [INFO    ] __main__: train step 4388: loss: 0.8232, policy_loss: 1.5562, value_loss: 0.9123
2024-07-14 05:20:39,461 [INFO    ] __main__: train step 4389: loss: 0.8233, policy_loss: 1.5561, value_loss: 0.9122
2024-07-14 05:20:39,746 [INFO    ] __main__: train step 4390: loss: 0.8234, policy_loss: 1.5559, value_loss: 0.9122
2024-07-14 05:20:40,024 [INFO    ] __main__: train step 4391: loss: 0.8235, policy_loss: 1.5558, value_loss: 0.9122
2024-07-14 05:20:40,301 [INFO    ] __main__: train step 4392: loss: 0.8236, policy_loss: 1.5557, value_loss: 0.9122
2024-07-14 05:20:40,587 [INFO    ] __main__: train step 4393: loss: 0.8237, policy_loss: 1.5556, value_loss: 0.9121
2024-07-14 05:20:40,862 [INFO    ] __main__: train step 4394: loss: 0.8238, policy_loss: 1.5555, value_loss: 0.9121
2024-07-14 05:20:41,138 [INFO    ] __main__: train step 4395: loss: 0.8239, policy_loss: 1.5554, value_loss: 0.9121
2024-07-14 05:20:41,417 [INFO    ] __main__: train step 4396: loss: 0.8241, policy_loss: 1.5553, value_loss: 0.9120
2024-07-14 05:20:41,690 [INFO    ] __main__: train step 4397: loss: 0.8242, policy_loss: 1.5552, value_loss: 0.9120
2024-07-14 05:20:42,585 [INFO    ] __main__: train step 4398: loss: 0.8243, policy_loss: 1.5551, value_loss: 0.9120
2024-07-14 05:20:42,876 [INFO    ] __main__: train step 4399: loss: 0.8244, policy_loss: 1.5550, value_loss: 0.9119
2024-07-14 05:20:44,481 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:20:44,974 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:20:45,044 [INFO    ] __main__: train step 4400: loss: 0.8245, policy_loss: 1.5549, value_loss: 0.9119
2024-07-14 05:20:45,327 [INFO    ] __main__: train step 4401: loss: 0.8246, policy_loss: 1.5548, value_loss: 0.9119
2024-07-14 05:20:45,604 [INFO    ] __main__: train step 4402: loss: 0.8247, policy_loss: 1.5547, value_loss: 0.9119
2024-07-14 05:20:45,880 [INFO    ] __main__: train step 4403: loss: 0.8248, policy_loss: 1.5546, value_loss: 0.9118
2024-07-14 05:20:46,162 [INFO    ] __main__: train step 4404: loss: 0.8250, policy_loss: 1.5545, value_loss: 0.9118
2024-07-14 05:20:46,443 [INFO    ] __main__: train step 4405: loss: 0.8251, policy_loss: 1.5544, value_loss: 0.9118
2024-07-14 05:20:46,730 [INFO    ] __main__: train step 4406: loss: 0.8252, policy_loss: 1.5542, value_loss: 0.9117
2024-07-14 05:20:47,008 [INFO    ] __main__: train step 4407: loss: 0.8253, policy_loss: 1.5541, value_loss: 0.9117
2024-07-14 05:20:47,295 [INFO    ] __main__: train step 4408: loss: 0.8254, policy_loss: 1.5540, value_loss: 0.9117
2024-07-14 05:20:47,567 [INFO    ] __main__: train step 4409: loss: 0.8255, policy_loss: 1.5539, value_loss: 0.9116
2024-07-14 05:20:47,849 [INFO    ] __main__: train step 4410: loss: 0.8256, policy_loss: 1.5538, value_loss: 0.9116
2024-07-14 05:20:48,129 [INFO    ] __main__: train step 4411: loss: 0.8257, policy_loss: 1.5537, value_loss: 0.9116
2024-07-14 05:20:48,416 [INFO    ] __main__: train step 4412: loss: 0.8259, policy_loss: 1.5536, value_loss: 0.9116
2024-07-14 05:20:48,691 [INFO    ] __main__: train step 4413: loss: 0.8260, policy_loss: 1.5535, value_loss: 0.9115
2024-07-14 05:20:48,973 [INFO    ] __main__: train step 4414: loss: 0.8261, policy_loss: 1.5534, value_loss: 0.9115
2024-07-14 05:20:49,250 [INFO    ] __main__: train step 4415: loss: 0.8262, policy_loss: 1.5533, value_loss: 0.9115
2024-07-14 05:20:49,537 [INFO    ] __main__: train step 4416: loss: 0.8263, policy_loss: 1.5532, value_loss: 0.9114
2024-07-14 05:20:51,153 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:20:51,626 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:20:51,694 [INFO    ] __main__: train step 4417: loss: 0.8264, policy_loss: 1.5531, value_loss: 0.9114
2024-07-14 05:20:52,550 [INFO    ] __main__: train step 4418: loss: 0.8265, policy_loss: 1.5530, value_loss: 0.9114
2024-07-14 05:20:52,825 [INFO    ] __main__: train step 4419: loss: 0.8266, policy_loss: 1.5529, value_loss: 0.9113
2024-07-14 05:20:53,101 [INFO    ] __main__: train step 4420: loss: 0.8268, policy_loss: 1.5528, value_loss: 0.9113
2024-07-14 05:20:53,386 [INFO    ] __main__: train step 4421: loss: 0.8269, policy_loss: 1.5527, value_loss: 0.9113
2024-07-14 05:20:53,659 [INFO    ] __main__: train step 4422: loss: 0.8270, policy_loss: 1.5526, value_loss: 0.9113
2024-07-14 05:20:53,961 [INFO    ] __main__: train step 4423: loss: 0.8271, policy_loss: 1.5525, value_loss: 0.9112
2024-07-14 05:20:54,217 [INFO    ] __main__: train step 4424: loss: 0.8272, policy_loss: 1.5523, value_loss: 0.9112
2024-07-14 05:20:54,497 [INFO    ] __main__: train step 4425: loss: 0.8273, policy_loss: 1.5522, value_loss: 0.9112
2024-07-14 05:20:54,759 [INFO    ] __main__: train step 4426: loss: 0.8274, policy_loss: 1.5521, value_loss: 0.9111
2024-07-14 05:20:55,034 [INFO    ] __main__: train step 4427: loss: 0.8275, policy_loss: 1.5520, value_loss: 0.9111
2024-07-14 05:20:55,311 [INFO    ] __main__: train step 4428: loss: 0.8276, policy_loss: 1.5519, value_loss: 0.9111
2024-07-14 05:20:55,587 [INFO    ] __main__: train step 4429: loss: 0.8277, policy_loss: 1.5518, value_loss: 0.9110
2024-07-14 05:20:55,871 [INFO    ] __main__: train step 4430: loss: 0.8279, policy_loss: 1.5517, value_loss: 0.9110
2024-07-14 05:20:56,157 [INFO    ] __main__: train step 4431: loss: 0.8280, policy_loss: 1.5516, value_loss: 0.9110
2024-07-14 05:20:56,441 [INFO    ] __main__: train step 4432: loss: 0.8281, policy_loss: 1.5515, value_loss: 0.9110
2024-07-14 05:20:56,729 [INFO    ] __main__: train step 4433: loss: 0.8282, policy_loss: 1.5514, value_loss: 0.9109
2024-07-14 05:20:58,317 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:20:58,794 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:20:58,865 [INFO    ] __main__: train step 4434: loss: 0.8283, policy_loss: 1.5513, value_loss: 0.9109
2024-07-14 05:20:59,136 [INFO    ] __main__: train step 4435: loss: 0.8284, policy_loss: 1.5512, value_loss: 0.9109
2024-07-14 05:20:59,412 [INFO    ] __main__: train step 4436: loss: 0.8285, policy_loss: 1.5511, value_loss: 0.9108
2024-07-14 05:20:59,676 [INFO    ] __main__: train step 4437: loss: 0.8286, policy_loss: 1.5510, value_loss: 0.9108
2024-07-14 05:21:00,304 [INFO    ] __main__: train step 4438: loss: 0.8288, policy_loss: 1.5509, value_loss: 0.9108
2024-07-14 05:21:00,578 [INFO    ] __main__: train step 4439: loss: 0.8289, policy_loss: 1.5508, value_loss: 0.9108
2024-07-14 05:21:00,853 [INFO    ] __main__: train step 4440: loss: 0.8290, policy_loss: 1.5507, value_loss: 0.9107
2024-07-14 05:21:01,112 [INFO    ] __main__: train step 4441: loss: 0.8291, policy_loss: 1.5506, value_loss: 0.9107
2024-07-14 05:21:01,381 [INFO    ] __main__: train step 4442: loss: 0.8292, policy_loss: 1.5505, value_loss: 0.9107
2024-07-14 05:21:01,654 [INFO    ] __main__: train step 4443: loss: 0.8293, policy_loss: 1.5504, value_loss: 0.9106
2024-07-14 05:21:01,925 [INFO    ] __main__: train step 4444: loss: 0.8294, policy_loss: 1.5503, value_loss: 0.9106
2024-07-14 05:21:02,201 [INFO    ] __main__: train step 4445: loss: 0.8295, policy_loss: 1.5501, value_loss: 0.9106
2024-07-14 05:21:02,474 [INFO    ] __main__: train step 4446: loss: 0.8297, policy_loss: 1.5500, value_loss: 0.9106
2024-07-14 05:21:02,749 [INFO    ] __main__: train step 4447: loss: 0.8298, policy_loss: 1.5499, value_loss: 0.9105
2024-07-14 05:21:03,024 [INFO    ] __main__: train step 4448: loss: 0.8299, policy_loss: 1.5498, value_loss: 0.9105
2024-07-14 05:21:03,302 [INFO    ] __main__: train step 4449: loss: 0.8300, policy_loss: 1.5497, value_loss: 0.9105
2024-07-14 05:21:03,582 [INFO    ] __main__: train step 4450: loss: 0.8301, policy_loss: 1.5496, value_loss: 0.9104
2024-07-14 05:21:05,172 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:21:05,647 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:21:05,713 [INFO    ] __main__: train step 4451: loss: 0.8302, policy_loss: 1.5495, value_loss: 0.9104
2024-07-14 05:21:05,992 [INFO    ] __main__: train step 4452: loss: 0.8303, policy_loss: 1.5494, value_loss: 0.9104
2024-07-14 05:21:06,269 [INFO    ] __main__: train step 4453: loss: 0.8304, policy_loss: 1.5493, value_loss: 0.9103
2024-07-14 05:21:06,551 [INFO    ] __main__: train step 4454: loss: 0.8305, policy_loss: 1.5492, value_loss: 0.9103
2024-07-14 05:21:06,830 [INFO    ] __main__: train step 4455: loss: 0.8307, policy_loss: 1.5491, value_loss: 0.9103
2024-07-14 05:21:07,105 [INFO    ] __main__: train step 4456: loss: 0.8308, policy_loss: 1.5490, value_loss: 0.9103
2024-07-14 05:21:07,394 [INFO    ] __main__: train step 4457: loss: 0.8309, policy_loss: 1.5489, value_loss: 0.9102
2024-07-14 05:21:08,271 [INFO    ] __main__: train step 4458: loss: 0.8310, policy_loss: 1.5488, value_loss: 0.9102
2024-07-14 05:21:08,547 [INFO    ] __main__: train step 4459: loss: 0.8311, policy_loss: 1.5487, value_loss: 0.9102
2024-07-14 05:21:08,831 [INFO    ] __main__: train step 4460: loss: 0.8312, policy_loss: 1.5486, value_loss: 0.9101
2024-07-14 05:21:09,108 [INFO    ] __main__: train step 4461: loss: 0.8313, policy_loss: 1.5485, value_loss: 0.9101
2024-07-14 05:21:09,388 [INFO    ] __main__: train step 4462: loss: 0.8314, policy_loss: 1.5483, value_loss: 0.9101
2024-07-14 05:21:09,676 [INFO    ] __main__: train step 4463: loss: 0.8315, policy_loss: 1.5482, value_loss: 0.9100
2024-07-14 05:21:09,970 [INFO    ] __main__: train step 4464: loss: 0.8316, policy_loss: 1.5481, value_loss: 0.9100
2024-07-14 05:21:10,266 [INFO    ] __main__: train step 4465: loss: 0.8317, policy_loss: 1.5480, value_loss: 0.9100
2024-07-14 05:21:10,537 [INFO    ] __main__: train step 4466: loss: 0.8319, policy_loss: 1.5479, value_loss: 0.9100
2024-07-14 05:21:10,813 [INFO    ] __main__: train step 4467: loss: 0.8320, policy_loss: 1.5478, value_loss: 0.9099
2024-07-14 05:21:12,422 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:21:12,902 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:21:12,968 [INFO    ] __main__: train step 4468: loss: 0.8321, policy_loss: 1.5477, value_loss: 0.9099
2024-07-14 05:21:13,242 [INFO    ] __main__: train step 4469: loss: 0.8322, policy_loss: 1.5476, value_loss: 0.9099
2024-07-14 05:21:13,530 [INFO    ] __main__: train step 4470: loss: 0.8323, policy_loss: 1.5475, value_loss: 0.9098
2024-07-14 05:21:13,810 [INFO    ] __main__: train step 4471: loss: 0.8324, policy_loss: 1.5474, value_loss: 0.9098
2024-07-14 05:21:14,087 [INFO    ] __main__: train step 4472: loss: 0.8325, policy_loss: 1.5473, value_loss: 0.9098
2024-07-14 05:21:14,352 [INFO    ] __main__: train step 4473: loss: 0.8326, policy_loss: 1.5472, value_loss: 0.9097
2024-07-14 05:21:14,634 [INFO    ] __main__: train step 4474: loss: 0.8327, policy_loss: 1.5471, value_loss: 0.9097
2024-07-14 05:21:14,922 [INFO    ] __main__: train step 4475: loss: 0.8329, policy_loss: 1.5470, value_loss: 0.9097
2024-07-14 05:21:15,206 [INFO    ] __main__: train step 4476: loss: 0.8330, policy_loss: 1.5469, value_loss: 0.9097
2024-07-14 05:21:15,476 [INFO    ] __main__: train step 4477: loss: 0.8331, policy_loss: 1.5468, value_loss: 0.9096
2024-07-14 05:21:16,111 [INFO    ] __main__: train step 4478: loss: 0.8332, policy_loss: 1.5467, value_loss: 0.9096
2024-07-14 05:21:16,396 [INFO    ] __main__: train step 4479: loss: 0.8333, policy_loss: 1.5466, value_loss: 0.9096
2024-07-14 05:21:16,672 [INFO    ] __main__: train step 4480: loss: 0.8334, policy_loss: 1.5465, value_loss: 0.9095
2024-07-14 05:21:16,957 [INFO    ] __main__: train step 4481: loss: 0.8335, policy_loss: 1.5464, value_loss: 0.9095
2024-07-14 05:21:17,243 [INFO    ] __main__: train step 4482: loss: 0.8336, policy_loss: 1.5463, value_loss: 0.9095
2024-07-14 05:21:17,518 [INFO    ] __main__: train step 4483: loss: 0.8337, policy_loss: 1.5462, value_loss: 0.9094
2024-07-14 05:21:17,800 [INFO    ] __main__: train step 4484: loss: 0.8338, policy_loss: 1.5461, value_loss: 0.9094
2024-07-14 05:21:19,412 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:21:19,883 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:21:19,949 [INFO    ] __main__: train step 4485: loss: 0.8339, policy_loss: 1.5460, value_loss: 0.9094
2024-07-14 05:21:20,232 [INFO    ] __main__: train step 4486: loss: 0.8341, policy_loss: 1.5458, value_loss: 0.9093
2024-07-14 05:21:20,513 [INFO    ] __main__: train step 4487: loss: 0.8342, policy_loss: 1.5457, value_loss: 0.9093
2024-07-14 05:21:20,778 [INFO    ] __main__: train step 4488: loss: 0.8343, policy_loss: 1.5456, value_loss: 0.9093
2024-07-14 05:21:21,051 [INFO    ] __main__: train step 4489: loss: 0.8344, policy_loss: 1.5455, value_loss: 0.9092
2024-07-14 05:21:21,361 [INFO    ] __main__: train step 4490: loss: 0.8345, policy_loss: 1.5454, value_loss: 0.9092
2024-07-14 05:21:21,643 [INFO    ] __main__: train step 4491: loss: 0.8346, policy_loss: 1.5453, value_loss: 0.9092
2024-07-14 05:21:21,917 [INFO    ] __main__: train step 4492: loss: 0.8347, policy_loss: 1.5452, value_loss: 0.9092
2024-07-14 05:21:22,204 [INFO    ] __main__: train step 4493: loss: 0.8348, policy_loss: 1.5451, value_loss: 0.9091
2024-07-14 05:21:22,482 [INFO    ] __main__: train step 4494: loss: 0.8350, policy_loss: 1.5450, value_loss: 0.9091
2024-07-14 05:21:22,757 [INFO    ] __main__: train step 4495: loss: 0.8351, policy_loss: 1.5449, value_loss: 0.9091
2024-07-14 05:21:23,041 [INFO    ] __main__: train step 4496: loss: 0.8352, policy_loss: 1.5448, value_loss: 0.9090
2024-07-14 05:21:23,314 [INFO    ] __main__: train step 4497: loss: 0.8353, policy_loss: 1.5447, value_loss: 0.9090
2024-07-14 05:21:23,930 [INFO    ] __main__: train step 4498: loss: 0.8354, policy_loss: 1.5446, value_loss: 0.9090
2024-07-14 05:21:24,197 [INFO    ] __main__: train step 4499: loss: 0.8355, policy_loss: 1.5445, value_loss: 0.9089
2024-07-14 05:21:24,473 [INFO    ] __main__: train step 4500: loss: 0.8356, policy_loss: 1.5444, value_loss: 0.9089
2024-07-14 05:21:24,761 [INFO    ] __main__: train step 4501: loss: 0.8357, policy_loss: 1.5443, value_loss: 0.9089
2024-07-14 05:21:26,318 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:21:26,789 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:21:26,859 [INFO    ] __main__: train step 4502: loss: 0.8358, policy_loss: 1.5442, value_loss: 0.9088
2024-07-14 05:21:27,138 [INFO    ] __main__: train step 4503: loss: 0.8359, policy_loss: 1.5441, value_loss: 0.9088
2024-07-14 05:21:27,401 [INFO    ] __main__: train step 4504: loss: 0.8361, policy_loss: 1.5440, value_loss: 0.9088
2024-07-14 05:21:27,668 [INFO    ] __main__: train step 4505: loss: 0.8362, policy_loss: 1.5439, value_loss: 0.9088
2024-07-14 05:21:27,922 [INFO    ] __main__: train step 4506: loss: 0.8363, policy_loss: 1.5438, value_loss: 0.9087
2024-07-14 05:21:28,188 [INFO    ] __main__: train step 4507: loss: 0.8364, policy_loss: 1.5437, value_loss: 0.9087
2024-07-14 05:21:28,461 [INFO    ] __main__: train step 4508: loss: 0.8365, policy_loss: 1.5436, value_loss: 0.9087
2024-07-14 05:21:28,733 [INFO    ] __main__: train step 4509: loss: 0.8366, policy_loss: 1.5435, value_loss: 0.9086
2024-07-14 05:21:29,004 [INFO    ] __main__: train step 4510: loss: 0.8367, policy_loss: 1.5433, value_loss: 0.9086
2024-07-14 05:21:29,279 [INFO    ] __main__: train step 4511: loss: 0.8368, policy_loss: 1.5432, value_loss: 0.9086
2024-07-14 05:21:29,537 [INFO    ] __main__: train step 4512: loss: 0.8369, policy_loss: 1.5431, value_loss: 0.9086
2024-07-14 05:21:29,816 [INFO    ] __main__: train step 4513: loss: 0.8370, policy_loss: 1.5430, value_loss: 0.9085
2024-07-14 05:21:30,093 [INFO    ] __main__: train step 4514: loss: 0.8371, policy_loss: 1.5429, value_loss: 0.9085
2024-07-14 05:21:30,365 [INFO    ] __main__: train step 4515: loss: 0.8373, policy_loss: 1.5428, value_loss: 0.9085
2024-07-14 05:21:30,609 [INFO    ] __main__: train step 4516: loss: 0.8374, policy_loss: 1.5427, value_loss: 0.9085
2024-07-14 05:21:30,880 [INFO    ] __main__: train step 4517: loss: 0.8375, policy_loss: 1.5426, value_loss: 0.9084
2024-07-14 05:21:31,750 [INFO    ] __main__: train step 4518: loss: 0.8376, policy_loss: 1.5425, value_loss: 0.9084
2024-07-14 05:21:33,345 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:21:33,830 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:21:33,897 [INFO    ] __main__: train step 4519: loss: 0.8377, policy_loss: 1.5424, value_loss: 0.9084
2024-07-14 05:21:34,174 [INFO    ] __main__: train step 4520: loss: 0.8378, policy_loss: 1.5423, value_loss: 0.9083
2024-07-14 05:21:34,446 [INFO    ] __main__: train step 4521: loss: 0.8379, policy_loss: 1.5422, value_loss: 0.9083
2024-07-14 05:21:34,716 [INFO    ] __main__: train step 4522: loss: 0.8380, policy_loss: 1.5421, value_loss: 0.9083
2024-07-14 05:21:34,993 [INFO    ] __main__: train step 4523: loss: 0.8381, policy_loss: 1.5420, value_loss: 0.9082
2024-07-14 05:21:35,269 [INFO    ] __main__: train step 4524: loss: 0.8382, policy_loss: 1.5419, value_loss: 0.9082
2024-07-14 05:21:35,540 [INFO    ] __main__: train step 4525: loss: 0.8384, policy_loss: 1.5418, value_loss: 0.9082
2024-07-14 05:21:35,831 [INFO    ] __main__: train step 4526: loss: 0.8385, policy_loss: 1.5416, value_loss: 0.9081
2024-07-14 05:21:36,113 [INFO    ] __main__: train step 4527: loss: 0.8386, policy_loss: 1.5415, value_loss: 0.9081
2024-07-14 05:21:36,407 [INFO    ] __main__: train step 4528: loss: 0.8387, policy_loss: 1.5414, value_loss: 0.9081
2024-07-14 05:21:36,692 [INFO    ] __main__: train step 4529: loss: 0.8388, policy_loss: 1.5413, value_loss: 0.9081
2024-07-14 05:21:36,971 [INFO    ] __main__: train step 4530: loss: 0.8389, policy_loss: 1.5412, value_loss: 0.9080
2024-07-14 05:21:37,251 [INFO    ] __main__: train step 4531: loss: 0.8390, policy_loss: 1.5411, value_loss: 0.9080
2024-07-14 05:21:37,533 [INFO    ] __main__: train step 4532: loss: 0.8391, policy_loss: 1.5410, value_loss: 0.9080
2024-07-14 05:21:37,809 [INFO    ] __main__: train step 4533: loss: 0.8392, policy_loss: 1.5409, value_loss: 0.9079
2024-07-14 05:21:38,085 [INFO    ] __main__: train step 4534: loss: 0.8393, policy_loss: 1.5408, value_loss: 0.9079
2024-07-14 05:21:38,365 [INFO    ] __main__: train step 4535: loss: 0.8394, policy_loss: 1.5407, value_loss: 0.9079
2024-07-14 05:21:40,006 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:21:40,491 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:21:40,564 [INFO    ] __main__: train step 4536: loss: 0.8395, policy_loss: 1.5406, value_loss: 0.9078
2024-07-14 05:21:41,431 [INFO    ] __main__: train step 4537: loss: 0.8396, policy_loss: 1.5405, value_loss: 0.9078
2024-07-14 05:21:41,704 [INFO    ] __main__: train step 4538: loss: 0.8398, policy_loss: 1.5404, value_loss: 0.9078
2024-07-14 05:21:41,981 [INFO    ] __main__: train step 4539: loss: 0.8399, policy_loss: 1.5403, value_loss: 0.9078
2024-07-14 05:21:42,260 [INFO    ] __main__: train step 4540: loss: 0.8400, policy_loss: 1.5402, value_loss: 0.9077
2024-07-14 05:21:42,539 [INFO    ] __main__: train step 4541: loss: 0.8401, policy_loss: 1.5401, value_loss: 0.9077
2024-07-14 05:21:42,816 [INFO    ] __main__: train step 4542: loss: 0.8402, policy_loss: 1.5400, value_loss: 0.9077
2024-07-14 05:21:43,096 [INFO    ] __main__: train step 4543: loss: 0.8403, policy_loss: 1.5399, value_loss: 0.9076
2024-07-14 05:21:43,378 [INFO    ] __main__: train step 4544: loss: 0.8404, policy_loss: 1.5398, value_loss: 0.9076
2024-07-14 05:21:43,645 [INFO    ] __main__: train step 4545: loss: 0.8405, policy_loss: 1.5396, value_loss: 0.9076
2024-07-14 05:21:43,923 [INFO    ] __main__: train step 4546: loss: 0.8406, policy_loss: 1.5395, value_loss: 0.9075
2024-07-14 05:21:44,210 [INFO    ] __main__: train step 4547: loss: 0.8407, policy_loss: 1.5394, value_loss: 0.9075
2024-07-14 05:21:44,484 [INFO    ] __main__: train step 4548: loss: 0.8409, policy_loss: 1.5393, value_loss: 0.9075
2024-07-14 05:21:44,771 [INFO    ] __main__: train step 4549: loss: 0.8410, policy_loss: 1.5392, value_loss: 0.9075
2024-07-14 05:21:45,047 [INFO    ] __main__: train step 4550: loss: 0.8411, policy_loss: 1.5391, value_loss: 0.9074
2024-07-14 05:21:45,311 [INFO    ] __main__: train step 4551: loss: 0.8412, policy_loss: 1.5390, value_loss: 0.9074
2024-07-14 05:21:45,593 [INFO    ] __main__: train step 4552: loss: 0.8413, policy_loss: 1.5389, value_loss: 0.9074
2024-07-14 05:21:47,212 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:21:47,698 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:21:47,768 [INFO    ] __main__: train step 4553: loss: 0.8414, policy_loss: 1.5388, value_loss: 0.9073
2024-07-14 05:21:48,027 [INFO    ] __main__: train step 4554: loss: 0.8415, policy_loss: 1.5387, value_loss: 0.9073
2024-07-14 05:21:48,290 [INFO    ] __main__: train step 4555: loss: 0.8416, policy_loss: 1.5386, value_loss: 0.9073
2024-07-14 05:21:48,544 [INFO    ] __main__: train step 4556: loss: 0.8417, policy_loss: 1.5385, value_loss: 0.9073
2024-07-14 05:21:48,799 [INFO    ] __main__: train step 4557: loss: 0.8418, policy_loss: 1.5384, value_loss: 0.9072
2024-07-14 05:21:49,661 [INFO    ] __main__: train step 4558: loss: 0.8419, policy_loss: 1.5383, value_loss: 0.9072
2024-07-14 05:21:49,930 [INFO    ] __main__: train step 4559: loss: 0.8420, policy_loss: 1.5382, value_loss: 0.9072
2024-07-14 05:21:50,217 [INFO    ] __main__: train step 4560: loss: 0.8422, policy_loss: 1.5381, value_loss: 0.9071
2024-07-14 05:21:50,488 [INFO    ] __main__: train step 4561: loss: 0.8423, policy_loss: 1.5380, value_loss: 0.9071
2024-07-14 05:21:50,766 [INFO    ] __main__: train step 4562: loss: 0.8424, policy_loss: 1.5379, value_loss: 0.9071
2024-07-14 05:21:51,039 [INFO    ] __main__: train step 4563: loss: 0.8425, policy_loss: 1.5378, value_loss: 0.9070
2024-07-14 05:21:51,307 [INFO    ] __main__: train step 4564: loss: 0.8426, policy_loss: 1.5377, value_loss: 0.9070
2024-07-14 05:21:51,572 [INFO    ] __main__: train step 4565: loss: 0.8427, policy_loss: 1.5376, value_loss: 0.9070
2024-07-14 05:21:51,836 [INFO    ] __main__: train step 4566: loss: 0.8428, policy_loss: 1.5374, value_loss: 0.9070
2024-07-14 05:21:52,105 [INFO    ] __main__: train step 4567: loss: 0.8429, policy_loss: 1.5373, value_loss: 0.9069
2024-07-14 05:21:52,388 [INFO    ] __main__: train step 4568: loss: 0.8430, policy_loss: 1.5372, value_loss: 0.9069
2024-07-14 05:21:52,657 [INFO    ] __main__: train step 4569: loss: 0.8431, policy_loss: 1.5371, value_loss: 0.9069
2024-07-14 05:21:54,264 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:21:54,747 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:21:54,813 [INFO    ] __main__: train step 4570: loss: 0.8432, policy_loss: 1.5370, value_loss: 0.9068
2024-07-14 05:21:55,090 [INFO    ] __main__: train step 4571: loss: 0.8433, policy_loss: 1.5369, value_loss: 0.9068
2024-07-14 05:21:55,368 [INFO    ] __main__: train step 4572: loss: 0.8435, policy_loss: 1.5368, value_loss: 0.9068
2024-07-14 05:21:55,645 [INFO    ] __main__: train step 4573: loss: 0.8436, policy_loss: 1.5367, value_loss: 0.9068
2024-07-14 05:21:55,926 [INFO    ] __main__: train step 4574: loss: 0.8437, policy_loss: 1.5366, value_loss: 0.9067
2024-07-14 05:21:56,207 [INFO    ] __main__: train step 4575: loss: 0.8438, policy_loss: 1.5365, value_loss: 0.9067
2024-07-14 05:21:56,486 [INFO    ] __main__: train step 4576: loss: 0.8439, policy_loss: 1.5364, value_loss: 0.9067
2024-07-14 05:21:57,295 [INFO    ] __main__: train step 4577: loss: 0.8440, policy_loss: 1.5363, value_loss: 0.9066
2024-07-14 05:21:57,576 [INFO    ] __main__: train step 4578: loss: 0.8441, policy_loss: 1.5362, value_loss: 0.9066
2024-07-14 05:21:57,854 [INFO    ] __main__: train step 4579: loss: 0.8442, policy_loss: 1.5361, value_loss: 0.9066
2024-07-14 05:21:58,137 [INFO    ] __main__: train step 4580: loss: 0.8443, policy_loss: 1.5360, value_loss: 0.9066
2024-07-14 05:21:58,413 [INFO    ] __main__: train step 4581: loss: 0.8444, policy_loss: 1.5359, value_loss: 0.9065
2024-07-14 05:21:58,696 [INFO    ] __main__: train step 4582: loss: 0.8445, policy_loss: 1.5358, value_loss: 0.9065
2024-07-14 05:21:58,978 [INFO    ] __main__: train step 4583: loss: 0.8447, policy_loss: 1.5357, value_loss: 0.9065
2024-07-14 05:21:59,264 [INFO    ] __main__: train step 4584: loss: 0.8448, policy_loss: 1.5356, value_loss: 0.9064
2024-07-14 05:21:59,538 [INFO    ] __main__: train step 4585: loss: 0.8449, policy_loss: 1.5355, value_loss: 0.9064
2024-07-14 05:21:59,810 [INFO    ] __main__: train step 4586: loss: 0.8450, policy_loss: 1.5354, value_loss: 0.9064
2024-07-14 05:22:01,421 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:22:01,912 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:22:01,984 [INFO    ] __main__: train step 4587: loss: 0.8451, policy_loss: 1.5353, value_loss: 0.9063
2024-07-14 05:22:02,238 [INFO    ] __main__: train step 4588: loss: 0.8452, policy_loss: 1.5352, value_loss: 0.9063
2024-07-14 05:22:02,499 [INFO    ] __main__: train step 4589: loss: 0.8453, policy_loss: 1.5351, value_loss: 0.9063
2024-07-14 05:22:02,789 [INFO    ] __main__: train step 4590: loss: 0.8454, policy_loss: 1.5350, value_loss: 0.9063
2024-07-14 05:22:03,083 [INFO    ] __main__: train step 4591: loss: 0.8455, policy_loss: 1.5349, value_loss: 0.9062
2024-07-14 05:22:03,367 [INFO    ] __main__: train step 4592: loss: 0.8456, policy_loss: 1.5348, value_loss: 0.9062
2024-07-14 05:22:03,648 [INFO    ] __main__: train step 4593: loss: 0.8457, policy_loss: 1.5347, value_loss: 0.9062
2024-07-14 05:22:03,929 [INFO    ] __main__: train step 4594: loss: 0.8458, policy_loss: 1.5345, value_loss: 0.9061
2024-07-14 05:22:04,205 [INFO    ] __main__: train step 4595: loss: 0.8460, policy_loss: 1.5344, value_loss: 0.9061
2024-07-14 05:22:05,097 [INFO    ] __main__: train step 4596: loss: 0.8461, policy_loss: 1.5343, value_loss: 0.9061
2024-07-14 05:22:05,384 [INFO    ] __main__: train step 4597: loss: 0.8462, policy_loss: 1.5342, value_loss: 0.9061
2024-07-14 05:22:05,681 [INFO    ] __main__: train step 4598: loss: 0.8463, policy_loss: 1.5341, value_loss: 0.9060
2024-07-14 05:22:05,970 [INFO    ] __main__: train step 4599: loss: 0.8464, policy_loss: 1.5340, value_loss: 0.9060
2024-07-14 05:22:06,261 [INFO    ] __main__: train step 4600: loss: 0.8465, policy_loss: 1.5339, value_loss: 0.9060
2024-07-14 05:22:06,544 [INFO    ] __main__: train step 4601: loss: 0.8466, policy_loss: 1.5338, value_loss: 0.9059
2024-07-14 05:22:06,824 [INFO    ] __main__: train step 4602: loss: 0.8467, policy_loss: 1.5337, value_loss: 0.9059
2024-07-14 05:22:07,124 [INFO    ] __main__: train step 4603: loss: 0.8468, policy_loss: 1.5336, value_loss: 0.9059
2024-07-14 05:22:08,713 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:22:09,180 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:22:09,251 [INFO    ] __main__: train step 4604: loss: 0.8469, policy_loss: 1.5335, value_loss: 0.9059
2024-07-14 05:22:09,530 [INFO    ] __main__: train step 4605: loss: 0.8470, policy_loss: 1.5334, value_loss: 0.9058
2024-07-14 05:22:09,810 [INFO    ] __main__: train step 4606: loss: 0.8472, policy_loss: 1.5333, value_loss: 0.9058
2024-07-14 05:22:10,085 [INFO    ] __main__: train step 4607: loss: 0.8473, policy_loss: 1.5332, value_loss: 0.9058
2024-07-14 05:22:10,364 [INFO    ] __main__: train step 4608: loss: 0.8474, policy_loss: 1.5331, value_loss: 0.9057
2024-07-14 05:22:10,621 [INFO    ] __main__: train step 4609: loss: 0.8475, policy_loss: 1.5330, value_loss: 0.9057
2024-07-14 05:22:10,883 [INFO    ] __main__: train step 4610: loss: 0.8476, policy_loss: 1.5329, value_loss: 0.9057
2024-07-14 05:22:11,144 [INFO    ] __main__: train step 4611: loss: 0.8477, policy_loss: 1.5328, value_loss: 0.9056
2024-07-14 05:22:11,404 [INFO    ] __main__: train step 4612: loss: 0.8478, policy_loss: 1.5327, value_loss: 0.9056
2024-07-14 05:22:11,686 [INFO    ] __main__: train step 4613: loss: 0.8479, policy_loss: 1.5326, value_loss: 0.9056
2024-07-14 05:22:11,964 [INFO    ] __main__: train step 4614: loss: 0.8480, policy_loss: 1.5325, value_loss: 0.9055
2024-07-14 05:22:12,255 [INFO    ] __main__: train step 4615: loss: 0.8481, policy_loss: 1.5324, value_loss: 0.9055
2024-07-14 05:22:13,158 [INFO    ] __main__: train step 4616: loss: 0.8482, policy_loss: 1.5323, value_loss: 0.9055
2024-07-14 05:22:13,439 [INFO    ] __main__: train step 4617: loss: 0.8483, policy_loss: 1.5322, value_loss: 0.9054
2024-07-14 05:22:13,708 [INFO    ] __main__: train step 4618: loss: 0.8484, policy_loss: 1.5321, value_loss: 0.9054
2024-07-14 05:22:13,985 [INFO    ] __main__: train step 4619: loss: 0.8485, policy_loss: 1.5320, value_loss: 0.9054
2024-07-14 05:22:14,269 [INFO    ] __main__: train step 4620: loss: 0.8486, policy_loss: 1.5318, value_loss: 0.9054
2024-07-14 05:22:15,878 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:22:16,361 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:22:16,426 [INFO    ] __main__: train step 4621: loss: 0.8488, policy_loss: 1.5317, value_loss: 0.9053
2024-07-14 05:22:16,701 [INFO    ] __main__: train step 4622: loss: 0.8489, policy_loss: 1.5316, value_loss: 0.9053
2024-07-14 05:22:16,989 [INFO    ] __main__: train step 4623: loss: 0.8490, policy_loss: 1.5315, value_loss: 0.9053
2024-07-14 05:22:17,258 [INFO    ] __main__: train step 4624: loss: 0.8491, policy_loss: 1.5314, value_loss: 0.9052
2024-07-14 05:22:17,516 [INFO    ] __main__: train step 4625: loss: 0.8492, policy_loss: 1.5313, value_loss: 0.9052
2024-07-14 05:22:17,793 [INFO    ] __main__: train step 4626: loss: 0.8493, policy_loss: 1.5312, value_loss: 0.9052
2024-07-14 05:22:18,061 [INFO    ] __main__: train step 4627: loss: 0.8494, policy_loss: 1.5311, value_loss: 0.9051
2024-07-14 05:22:18,326 [INFO    ] __main__: train step 4628: loss: 0.8495, policy_loss: 1.5310, value_loss: 0.9051
2024-07-14 05:22:18,608 [INFO    ] __main__: train step 4629: loss: 0.8496, policy_loss: 1.5309, value_loss: 0.9051
2024-07-14 05:22:18,889 [INFO    ] __main__: train step 4630: loss: 0.8497, policy_loss: 1.5308, value_loss: 0.9051
2024-07-14 05:22:19,165 [INFO    ] __main__: train step 4631: loss: 0.8498, policy_loss: 1.5307, value_loss: 0.9050
2024-07-14 05:22:19,449 [INFO    ] __main__: train step 4632: loss: 0.8499, policy_loss: 1.5306, value_loss: 0.9050
2024-07-14 05:22:19,728 [INFO    ] __main__: train step 4633: loss: 0.8500, policy_loss: 1.5305, value_loss: 0.9050
2024-07-14 05:22:20,009 [INFO    ] __main__: train step 4634: loss: 0.8501, policy_loss: 1.5304, value_loss: 0.9049
2024-07-14 05:22:20,642 [INFO    ] __main__: train step 4635: loss: 0.8503, policy_loss: 1.5303, value_loss: 0.9049
2024-07-14 05:22:20,927 [INFO    ] __main__: train step 4636: loss: 0.8504, policy_loss: 1.5302, value_loss: 0.9049
2024-07-14 05:22:21,190 [INFO    ] __main__: train step 4637: loss: 0.8505, policy_loss: 1.5301, value_loss: 0.9048
2024-07-14 05:22:22,787 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:22:23,260 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:22:23,325 [INFO    ] __main__: train step 4638: loss: 0.8506, policy_loss: 1.5300, value_loss: 0.9048
2024-07-14 05:22:23,632 [INFO    ] __main__: train step 4639: loss: 0.8507, policy_loss: 1.5299, value_loss: 0.9048
2024-07-14 05:22:23,920 [INFO    ] __main__: train step 4640: loss: 0.8508, policy_loss: 1.5298, value_loss: 0.9048
2024-07-14 05:22:24,208 [INFO    ] __main__: train step 4641: loss: 0.8509, policy_loss: 1.5297, value_loss: 0.9047
2024-07-14 05:22:24,492 [INFO    ] __main__: train step 4642: loss: 0.8510, policy_loss: 1.5296, value_loss: 0.9047
2024-07-14 05:22:24,760 [INFO    ] __main__: train step 4643: loss: 0.8511, policy_loss: 1.5295, value_loss: 0.9047
2024-07-14 05:22:25,039 [INFO    ] __main__: train step 4644: loss: 0.8512, policy_loss: 1.5294, value_loss: 0.9046
2024-07-14 05:22:25,317 [INFO    ] __main__: train step 4645: loss: 0.8513, policy_loss: 1.5293, value_loss: 0.9046
2024-07-14 05:22:25,597 [INFO    ] __main__: train step 4646: loss: 0.8514, policy_loss: 1.5292, value_loss: 0.9046
2024-07-14 05:22:25,872 [INFO    ] __main__: train step 4647: loss: 0.8515, policy_loss: 1.5291, value_loss: 0.9045
2024-07-14 05:22:26,153 [INFO    ] __main__: train step 4648: loss: 0.8517, policy_loss: 1.5290, value_loss: 0.9045
2024-07-14 05:22:26,425 [INFO    ] __main__: train step 4649: loss: 0.8518, policy_loss: 1.5289, value_loss: 0.9045
2024-07-14 05:22:26,694 [INFO    ] __main__: train step 4650: loss: 0.8519, policy_loss: 1.5288, value_loss: 0.9045
2024-07-14 05:22:26,965 [INFO    ] __main__: train step 4651: loss: 0.8520, policy_loss: 1.5287, value_loss: 0.9044
2024-07-14 05:22:27,247 [INFO    ] __main__: train step 4652: loss: 0.8521, policy_loss: 1.5286, value_loss: 0.9044
2024-07-14 05:22:27,524 [INFO    ] __main__: train step 4653: loss: 0.8522, policy_loss: 1.5285, value_loss: 0.9044
2024-07-14 05:22:27,790 [INFO    ] __main__: train step 4654: loss: 0.8523, policy_loss: 1.5284, value_loss: 0.9043
2024-07-14 05:22:29,898 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:22:30,370 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:22:30,435 [INFO    ] __main__: train step 4655: loss: 0.8524, policy_loss: 1.5283, value_loss: 0.9043
2024-07-14 05:22:30,712 [INFO    ] __main__: train step 4656: loss: 0.8525, policy_loss: 1.5282, value_loss: 0.9043
2024-07-14 05:22:30,976 [INFO    ] __main__: train step 4657: loss: 0.8526, policy_loss: 1.5281, value_loss: 0.9042
2024-07-14 05:22:31,250 [INFO    ] __main__: train step 4658: loss: 0.8527, policy_loss: 1.5280, value_loss: 0.9042
2024-07-14 05:22:31,524 [INFO    ] __main__: train step 4659: loss: 0.8528, policy_loss: 1.5279, value_loss: 0.9042
2024-07-14 05:22:31,790 [INFO    ] __main__: train step 4660: loss: 0.8530, policy_loss: 1.5278, value_loss: 0.9042
2024-07-14 05:22:32,061 [INFO    ] __main__: train step 4661: loss: 0.8531, policy_loss: 1.5277, value_loss: 0.9041
2024-07-14 05:22:32,337 [INFO    ] __main__: train step 4662: loss: 0.8532, policy_loss: 1.5276, value_loss: 0.9041
2024-07-14 05:22:32,618 [INFO    ] __main__: train step 4663: loss: 0.8533, policy_loss: 1.5275, value_loss: 0.9041
2024-07-14 05:22:32,894 [INFO    ] __main__: train step 4664: loss: 0.8534, policy_loss: 1.5274, value_loss: 0.9040
2024-07-14 05:22:33,173 [INFO    ] __main__: train step 4665: loss: 0.8535, policy_loss: 1.5272, value_loss: 0.9040
2024-07-14 05:22:33,454 [INFO    ] __main__: train step 4666: loss: 0.8536, policy_loss: 1.5271, value_loss: 0.9040
2024-07-14 05:22:33,736 [INFO    ] __main__: train step 4667: loss: 0.8537, policy_loss: 1.5270, value_loss: 0.9039
2024-07-14 05:22:34,020 [INFO    ] __main__: train step 4668: loss: 0.8538, policy_loss: 1.5269, value_loss: 0.9039
2024-07-14 05:22:34,303 [INFO    ] __main__: train step 4669: loss: 0.8539, policy_loss: 1.5268, value_loss: 0.9039
2024-07-14 05:22:34,592 [INFO    ] __main__: train step 4670: loss: 0.8540, policy_loss: 1.5267, value_loss: 0.9039
2024-07-14 05:22:34,871 [INFO    ] __main__: train step 4671: loss: 0.8541, policy_loss: 1.5266, value_loss: 0.9038
2024-07-14 05:22:36,477 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:22:36,955 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:22:37,021 [INFO    ] __main__: train step 4672: loss: 0.8543, policy_loss: 1.5265, value_loss: 0.9038
2024-07-14 05:22:37,304 [INFO    ] __main__: train step 4673: loss: 0.8544, policy_loss: 1.5264, value_loss: 0.9038
2024-07-14 05:22:37,590 [INFO    ] __main__: train step 4674: loss: 0.8545, policy_loss: 1.5263, value_loss: 0.9037
2024-07-14 05:22:38,444 [INFO    ] __main__: train step 4675: loss: 0.8546, policy_loss: 1.5262, value_loss: 0.9037
2024-07-14 05:22:38,724 [INFO    ] __main__: train step 4676: loss: 0.8547, policy_loss: 1.5261, value_loss: 0.9037
2024-07-14 05:22:39,005 [INFO    ] __main__: train step 4677: loss: 0.8548, policy_loss: 1.5260, value_loss: 0.9037
2024-07-14 05:22:39,280 [INFO    ] __main__: train step 4678: loss: 0.8549, policy_loss: 1.5259, value_loss: 0.9036
2024-07-14 05:22:39,551 [INFO    ] __main__: train step 4679: loss: 0.8550, policy_loss: 1.5258, value_loss: 0.9036
2024-07-14 05:22:39,834 [INFO    ] __main__: train step 4680: loss: 0.8551, policy_loss: 1.5257, value_loss: 0.9036
2024-07-14 05:22:40,090 [INFO    ] __main__: train step 4681: loss: 0.8552, policy_loss: 1.5256, value_loss: 0.9035
2024-07-14 05:22:40,378 [INFO    ] __main__: train step 4682: loss: 0.8553, policy_loss: 1.5255, value_loss: 0.9035
2024-07-14 05:22:40,653 [INFO    ] __main__: train step 4683: loss: 0.8554, policy_loss: 1.5254, value_loss: 0.9035
2024-07-14 05:22:40,938 [INFO    ] __main__: train step 4684: loss: 0.8556, policy_loss: 1.5253, value_loss: 0.9035
2024-07-14 05:22:41,213 [INFO    ] __main__: train step 4685: loss: 0.8557, policy_loss: 1.5252, value_loss: 0.9034
2024-07-14 05:22:41,488 [INFO    ] __main__: train step 4686: loss: 0.8558, policy_loss: 1.5251, value_loss: 0.9034
2024-07-14 05:22:41,764 [INFO    ] __main__: train step 4687: loss: 0.8559, policy_loss: 1.5250, value_loss: 0.9034
2024-07-14 05:22:42,040 [INFO    ] __main__: train step 4688: loss: 0.8560, policy_loss: 1.5249, value_loss: 0.9033
2024-07-14 05:22:43,639 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:22:44,119 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:22:44,187 [INFO    ] __main__: train step 4689: loss: 0.8561, policy_loss: 1.5248, value_loss: 0.9033
2024-07-14 05:22:44,444 [INFO    ] __main__: train step 4690: loss: 0.8562, policy_loss: 1.5247, value_loss: 0.9033
2024-07-14 05:22:44,732 [INFO    ] __main__: train step 4691: loss: 0.8563, policy_loss: 1.5246, value_loss: 0.9033
2024-07-14 05:22:45,008 [INFO    ] __main__: train step 4692: loss: 0.8564, policy_loss: 1.5245, value_loss: 0.9032
2024-07-14 05:22:45,278 [INFO    ] __main__: train step 4693: loss: 0.8565, policy_loss: 1.5244, value_loss: 0.9032
2024-07-14 05:22:45,925 [INFO    ] __main__: train step 4694: loss: 0.8566, policy_loss: 1.5243, value_loss: 0.9032
2024-07-14 05:22:46,208 [INFO    ] __main__: train step 4695: loss: 0.8567, policy_loss: 1.5242, value_loss: 0.9031
2024-07-14 05:22:46,503 [INFO    ] __main__: train step 4696: loss: 0.8568, policy_loss: 1.5241, value_loss: 0.9031
2024-07-14 05:22:46,782 [INFO    ] __main__: train step 4697: loss: 0.8569, policy_loss: 1.5240, value_loss: 0.9031
2024-07-14 05:22:47,066 [INFO    ] __main__: train step 4698: loss: 0.8571, policy_loss: 1.5239, value_loss: 0.9030
2024-07-14 05:22:47,348 [INFO    ] __main__: train step 4699: loss: 0.8572, policy_loss: 1.5238, value_loss: 0.9030
2024-07-14 05:22:47,632 [INFO    ] __main__: train step 4700: loss: 0.8573, policy_loss: 1.5237, value_loss: 0.9030
2024-07-14 05:22:47,922 [INFO    ] __main__: train step 4701: loss: 0.8574, policy_loss: 1.5236, value_loss: 0.9030
2024-07-14 05:22:48,211 [INFO    ] __main__: train step 4702: loss: 0.8575, policy_loss: 1.5235, value_loss: 0.9029
2024-07-14 05:22:48,498 [INFO    ] __main__: train step 4703: loss: 0.8576, policy_loss: 1.5234, value_loss: 0.9029
2024-07-14 05:22:48,803 [INFO    ] __main__: train step 4704: loss: 0.8577, policy_loss: 1.5233, value_loss: 0.9029
2024-07-14 05:22:49,074 [INFO    ] __main__: train step 4705: loss: 0.8578, policy_loss: 1.5232, value_loss: 0.9028
2024-07-14 05:22:50,679 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:22:51,163 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:22:51,233 [INFO    ] __main__: train step 4706: loss: 0.8579, policy_loss: 1.5231, value_loss: 0.9028
2024-07-14 05:22:51,515 [INFO    ] __main__: train step 4707: loss: 0.8580, policy_loss: 1.5230, value_loss: 0.9028
2024-07-14 05:22:51,787 [INFO    ] __main__: train step 4708: loss: 0.8581, policy_loss: 1.5229, value_loss: 0.9027
2024-07-14 05:22:52,088 [INFO    ] __main__: train step 4709: loss: 0.8582, policy_loss: 1.5228, value_loss: 0.9027
2024-07-14 05:22:52,364 [INFO    ] __main__: train step 4710: loss: 0.8583, policy_loss: 1.5227, value_loss: 0.9027
2024-07-14 05:22:52,648 [INFO    ] __main__: train step 4711: loss: 0.8585, policy_loss: 1.5226, value_loss: 0.9027
2024-07-14 05:22:52,915 [INFO    ] __main__: train step 4712: loss: 0.8586, policy_loss: 1.5225, value_loss: 0.9026
2024-07-14 05:22:53,196 [INFO    ] __main__: train step 4713: loss: 0.8587, policy_loss: 1.5224, value_loss: 0.9026
2024-07-14 05:22:54,092 [INFO    ] __main__: train step 4714: loss: 0.8588, policy_loss: 1.5223, value_loss: 0.9026
2024-07-14 05:22:54,383 [INFO    ] __main__: train step 4715: loss: 0.8589, policy_loss: 1.5222, value_loss: 0.9025
2024-07-14 05:22:54,658 [INFO    ] __main__: train step 4716: loss: 0.8590, policy_loss: 1.5221, value_loss: 0.9025
2024-07-14 05:22:54,934 [INFO    ] __main__: train step 4717: loss: 0.8591, policy_loss: 1.5220, value_loss: 0.9025
2024-07-14 05:22:55,209 [INFO    ] __main__: train step 4718: loss: 0.8592, policy_loss: 1.5219, value_loss: 0.9024
2024-07-14 05:22:55,486 [INFO    ] __main__: train step 4719: loss: 0.8593, policy_loss: 1.5218, value_loss: 0.9024
2024-07-14 05:22:55,765 [INFO    ] __main__: train step 4720: loss: 0.8594, policy_loss: 1.5217, value_loss: 0.9024
2024-07-14 05:22:56,051 [INFO    ] __main__: train step 4721: loss: 0.8595, policy_loss: 1.5216, value_loss: 0.9024
2024-07-14 05:22:56,327 [INFO    ] __main__: train step 4722: loss: 0.8596, policy_loss: 1.5215, value_loss: 0.9023
2024-07-14 05:22:57,955 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:22:58,437 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:22:58,508 [INFO    ] __main__: train step 4723: loss: 0.8597, policy_loss: 1.5214, value_loss: 0.9023
2024-07-14 05:22:58,790 [INFO    ] __main__: train step 4724: loss: 0.8599, policy_loss: 1.5213, value_loss: 0.9023
2024-07-14 05:22:59,069 [INFO    ] __main__: train step 4725: loss: 0.8600, policy_loss: 1.5212, value_loss: 0.9022
2024-07-14 05:22:59,318 [INFO    ] __main__: train step 4726: loss: 0.8601, policy_loss: 1.5211, value_loss: 0.9022
2024-07-14 05:22:59,568 [INFO    ] __main__: train step 4727: loss: 0.8602, policy_loss: 1.5209, value_loss: 0.9022
2024-07-14 05:22:59,823 [INFO    ] __main__: train step 4728: loss: 0.8603, policy_loss: 1.5209, value_loss: 0.9021
2024-07-14 05:23:00,108 [INFO    ] __main__: train step 4729: loss: 0.8604, policy_loss: 1.5208, value_loss: 0.9021
2024-07-14 05:23:00,385 [INFO    ] __main__: train step 4730: loss: 0.8605, policy_loss: 1.5207, value_loss: 0.9021
2024-07-14 05:23:00,652 [INFO    ] __main__: train step 4731: loss: 0.8606, policy_loss: 1.5205, value_loss: 0.9021
2024-07-14 05:23:00,933 [INFO    ] __main__: train step 4732: loss: 0.8607, policy_loss: 1.5204, value_loss: 0.9020
2024-07-14 05:23:01,215 [INFO    ] __main__: train step 4733: loss: 0.8608, policy_loss: 1.5203, value_loss: 0.9020
2024-07-14 05:23:01,489 [INFO    ] __main__: train step 4734: loss: 0.8609, policy_loss: 1.5202, value_loss: 0.9020
2024-07-14 05:23:02,117 [INFO    ] __main__: train step 4735: loss: 0.8610, policy_loss: 1.5201, value_loss: 0.9019
2024-07-14 05:23:02,400 [INFO    ] __main__: train step 4736: loss: 0.8611, policy_loss: 1.5200, value_loss: 0.9019
2024-07-14 05:23:02,677 [INFO    ] __main__: train step 4737: loss: 0.8612, policy_loss: 1.5199, value_loss: 0.9019
2024-07-14 05:23:02,946 [INFO    ] __main__: train step 4738: loss: 0.8613, policy_loss: 1.5198, value_loss: 0.9018
2024-07-14 05:23:03,232 [INFO    ] __main__: train step 4739: loss: 0.8615, policy_loss: 1.5197, value_loss: 0.9018
2024-07-14 05:23:04,829 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:23:05,301 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:23:05,371 [INFO    ] __main__: train step 4740: loss: 0.8616, policy_loss: 1.5196, value_loss: 0.9018
2024-07-14 05:23:05,649 [INFO    ] __main__: train step 4741: loss: 0.8617, policy_loss: 1.5195, value_loss: 0.9017
2024-07-14 05:23:05,922 [INFO    ] __main__: train step 4742: loss: 0.8618, policy_loss: 1.5194, value_loss: 0.9017
2024-07-14 05:23:06,200 [INFO    ] __main__: train step 4743: loss: 0.8619, policy_loss: 1.5193, value_loss: 0.9017
2024-07-14 05:23:06,488 [INFO    ] __main__: train step 4744: loss: 0.8620, policy_loss: 1.5192, value_loss: 0.9017
2024-07-14 05:23:06,757 [INFO    ] __main__: train step 4745: loss: 0.8621, policy_loss: 1.5191, value_loss: 0.9016
2024-07-14 05:23:07,038 [INFO    ] __main__: train step 4746: loss: 0.8622, policy_loss: 1.5190, value_loss: 0.9016
2024-07-14 05:23:07,322 [INFO    ] __main__: train step 4747: loss: 0.8623, policy_loss: 1.5189, value_loss: 0.9016
2024-07-14 05:23:07,599 [INFO    ] __main__: train step 4748: loss: 0.8624, policy_loss: 1.5188, value_loss: 0.9015
2024-07-14 05:23:07,892 [INFO    ] __main__: train step 4749: loss: 0.8625, policy_loss: 1.5187, value_loss: 0.9015
2024-07-14 05:23:08,175 [INFO    ] __main__: train step 4750: loss: 0.8626, policy_loss: 1.5186, value_loss: 0.9015
2024-07-14 05:23:08,456 [INFO    ] __main__: train step 4751: loss: 0.8627, policy_loss: 1.5185, value_loss: 0.9014
2024-07-14 05:23:08,748 [INFO    ] __main__: train step 4752: loss: 0.8628, policy_loss: 1.5184, value_loss: 0.9014
2024-07-14 05:23:09,649 [INFO    ] __main__: train step 4753: loss: 0.8629, policy_loss: 1.5183, value_loss: 0.9014
2024-07-14 05:23:09,923 [INFO    ] __main__: train step 4754: loss: 0.8630, policy_loss: 1.5182, value_loss: 0.9014
2024-07-14 05:23:10,208 [INFO    ] __main__: train step 4755: loss: 0.8631, policy_loss: 1.5181, value_loss: 0.9013
2024-07-14 05:23:10,484 [INFO    ] __main__: train step 4756: loss: 0.8632, policy_loss: 1.5180, value_loss: 0.9013
2024-07-14 05:23:12,094 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:23:12,582 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:23:12,648 [INFO    ] __main__: train step 4757: loss: 0.8633, policy_loss: 1.5179, value_loss: 0.9013
2024-07-14 05:23:12,930 [INFO    ] __main__: train step 4758: loss: 0.8634, policy_loss: 1.5178, value_loss: 0.9012
2024-07-14 05:23:13,209 [INFO    ] __main__: train step 4759: loss: 0.8636, policy_loss: 1.5177, value_loss: 0.9012
2024-07-14 05:23:13,480 [INFO    ] __main__: train step 4760: loss: 0.8637, policy_loss: 1.5176, value_loss: 0.9012
2024-07-14 05:23:13,756 [INFO    ] __main__: train step 4761: loss: 0.8638, policy_loss: 1.5175, value_loss: 0.9011
2024-07-14 05:23:14,065 [INFO    ] __main__: train step 4762: loss: 0.8639, policy_loss: 1.5174, value_loss: 0.9011
2024-07-14 05:23:14,347 [INFO    ] __main__: train step 4763: loss: 0.8640, policy_loss: 1.5173, value_loss: 0.9011
2024-07-14 05:23:14,623 [INFO    ] __main__: train step 4764: loss: 0.8641, policy_loss: 1.5172, value_loss: 0.9011
2024-07-14 05:23:14,917 [INFO    ] __main__: train step 4765: loss: 0.8642, policy_loss: 1.5171, value_loss: 0.9010
2024-07-14 05:23:15,190 [INFO    ] __main__: train step 4766: loss: 0.8643, policy_loss: 1.5170, value_loss: 0.9010
2024-07-14 05:23:15,463 [INFO    ] __main__: train step 4767: loss: 0.8644, policy_loss: 1.5169, value_loss: 0.9010
2024-07-14 05:23:15,734 [INFO    ] __main__: train step 4768: loss: 0.8645, policy_loss: 1.5168, value_loss: 0.9009
2024-07-14 05:23:16,027 [INFO    ] __main__: train step 4769: loss: 0.8646, policy_loss: 1.5167, value_loss: 0.9009
2024-07-14 05:23:16,305 [INFO    ] __main__: train step 4770: loss: 0.8647, policy_loss: 1.5166, value_loss: 0.9009
2024-07-14 05:23:16,584 [INFO    ] __main__: train step 4771: loss: 0.8648, policy_loss: 1.5165, value_loss: 0.9009
2024-07-14 05:23:16,868 [INFO    ] __main__: train step 4772: loss: 0.8649, policy_loss: 1.5164, value_loss: 0.9008
2024-07-14 05:23:17,737 [INFO    ] __main__: train step 4773: loss: 0.8650, policy_loss: 1.5163, value_loss: 0.9008
2024-07-14 05:23:19,343 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:23:19,813 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:23:19,878 [INFO    ] __main__: train step 4774: loss: 0.8651, policy_loss: 1.5162, value_loss: 0.9008
2024-07-14 05:23:20,149 [INFO    ] __main__: train step 4775: loss: 0.8652, policy_loss: 1.5161, value_loss: 0.9007
2024-07-14 05:23:20,438 [INFO    ] __main__: train step 4776: loss: 0.8653, policy_loss: 1.5160, value_loss: 0.9007
2024-07-14 05:23:20,707 [INFO    ] __main__: train step 4777: loss: 0.8654, policy_loss: 1.5159, value_loss: 0.9007
2024-07-14 05:23:20,987 [INFO    ] __main__: train step 4778: loss: 0.8655, policy_loss: 1.5158, value_loss: 0.9006
2024-07-14 05:23:21,283 [INFO    ] __main__: train step 4779: loss: 0.8656, policy_loss: 1.5157, value_loss: 0.9006
2024-07-14 05:23:21,562 [INFO    ] __main__: train step 4780: loss: 0.8658, policy_loss: 1.5156, value_loss: 0.9006
2024-07-14 05:23:21,849 [INFO    ] __main__: train step 4781: loss: 0.8659, policy_loss: 1.5155, value_loss: 0.9006
2024-07-14 05:23:22,133 [INFO    ] __main__: train step 4782: loss: 0.8660, policy_loss: 1.5154, value_loss: 0.9005
2024-07-14 05:23:22,417 [INFO    ] __main__: train step 4783: loss: 0.8661, policy_loss: 1.5153, value_loss: 0.9005
2024-07-14 05:23:22,691 [INFO    ] __main__: train step 4784: loss: 0.8662, policy_loss: 1.5152, value_loss: 0.9005
2024-07-14 05:23:22,971 [INFO    ] __main__: train step 4785: loss: 0.8663, policy_loss: 1.5151, value_loss: 0.9004
2024-07-14 05:23:23,244 [INFO    ] __main__: train step 4786: loss: 0.8664, policy_loss: 1.5150, value_loss: 0.9004
2024-07-14 05:23:23,516 [INFO    ] __main__: train step 4787: loss: 0.8665, policy_loss: 1.5149, value_loss: 0.9004
2024-07-14 05:23:23,791 [INFO    ] __main__: train step 4788: loss: 0.8666, policy_loss: 1.5148, value_loss: 0.9004
2024-07-14 05:23:24,068 [INFO    ] __main__: train step 4789: loss: 0.8667, policy_loss: 1.5147, value_loss: 0.9003
2024-07-14 05:23:24,352 [INFO    ] __main__: train step 4790: loss: 0.8668, policy_loss: 1.5146, value_loss: 0.9003
2024-07-14 05:23:25,947 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:23:26,423 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:23:26,490 [INFO    ] __main__: train step 4791: loss: 0.8669, policy_loss: 1.5145, value_loss: 0.9003
2024-07-14 05:23:26,774 [INFO    ] __main__: train step 4792: loss: 0.8670, policy_loss: 1.5144, value_loss: 0.9002
2024-07-14 05:23:27,657 [INFO    ] __main__: train step 4793: loss: 0.8671, policy_loss: 1.5143, value_loss: 0.9002
2024-07-14 05:23:27,944 [INFO    ] __main__: train step 4794: loss: 0.8673, policy_loss: 1.5142, value_loss: 0.9002
2024-07-14 05:23:28,253 [INFO    ] __main__: train step 4795: loss: 0.8674, policy_loss: 1.5141, value_loss: 0.9001
2024-07-14 05:23:28,540 [INFO    ] __main__: train step 4796: loss: 0.8675, policy_loss: 1.5140, value_loss: 0.9001
2024-07-14 05:23:28,819 [INFO    ] __main__: train step 4797: loss: 0.8676, policy_loss: 1.5139, value_loss: 0.9001
2024-07-14 05:23:29,107 [INFO    ] __main__: train step 4798: loss: 0.8677, policy_loss: 1.5138, value_loss: 0.9000
2024-07-14 05:23:29,370 [INFO    ] __main__: train step 4799: loss: 0.8678, policy_loss: 1.5137, value_loss: 0.9000
2024-07-14 05:23:29,646 [INFO    ] __main__: train step 4800: loss: 0.8679, policy_loss: 1.5136, value_loss: 0.9000
2024-07-14 05:23:29,930 [INFO    ] __main__: train step 4801: loss: 0.8680, policy_loss: 1.5135, value_loss: 0.9000
2024-07-14 05:23:30,201 [INFO    ] __main__: train step 4802: loss: 0.8681, policy_loss: 1.5134, value_loss: 0.8999
2024-07-14 05:23:30,468 [INFO    ] __main__: train step 4803: loss: 0.8682, policy_loss: 1.5133, value_loss: 0.8999
2024-07-14 05:23:30,741 [INFO    ] __main__: train step 4804: loss: 0.8683, policy_loss: 1.5132, value_loss: 0.8999
2024-07-14 05:23:31,020 [INFO    ] __main__: train step 4805: loss: 0.8684, policy_loss: 1.5131, value_loss: 0.8998
2024-07-14 05:23:31,296 [INFO    ] __main__: train step 4806: loss: 0.8685, policy_loss: 1.5130, value_loss: 0.8998
2024-07-14 05:23:31,573 [INFO    ] __main__: train step 4807: loss: 0.8686, policy_loss: 1.5129, value_loss: 0.8998
2024-07-14 05:23:33,168 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:23:33,640 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:23:33,703 [INFO    ] __main__: train step 4808: loss: 0.8687, policy_loss: 1.5128, value_loss: 0.8997
2024-07-14 05:23:33,982 [INFO    ] __main__: train step 4809: loss: 0.8688, policy_loss: 1.5127, value_loss: 0.8997
2024-07-14 05:23:34,278 [INFO    ] __main__: train step 4810: loss: 0.8689, policy_loss: 1.5126, value_loss: 0.8997
2024-07-14 05:23:34,570 [INFO    ] __main__: train step 4811: loss: 0.8690, policy_loss: 1.5125, value_loss: 0.8996
2024-07-14 05:23:34,840 [INFO    ] __main__: train step 4812: loss: 0.8691, policy_loss: 1.5124, value_loss: 0.8996
2024-07-14 05:23:35,693 [INFO    ] __main__: train step 4813: loss: 0.8693, policy_loss: 1.5123, value_loss: 0.8996
2024-07-14 05:23:35,979 [INFO    ] __main__: train step 4814: loss: 0.8694, policy_loss: 1.5122, value_loss: 0.8996
2024-07-14 05:23:36,265 [INFO    ] __main__: train step 4815: loss: 0.8695, policy_loss: 1.5121, value_loss: 0.8995
2024-07-14 05:23:36,543 [INFO    ] __main__: train step 4816: loss: 0.8696, policy_loss: 1.5120, value_loss: 0.8995
2024-07-14 05:23:36,818 [INFO    ] __main__: train step 4817: loss: 0.8697, policy_loss: 1.5119, value_loss: 0.8995
2024-07-14 05:23:37,102 [INFO    ] __main__: train step 4818: loss: 0.8698, policy_loss: 1.5118, value_loss: 0.8994
2024-07-14 05:23:37,377 [INFO    ] __main__: train step 4819: loss: 0.8699, policy_loss: 1.5117, value_loss: 0.8994
2024-07-14 05:23:37,653 [INFO    ] __main__: train step 4820: loss: 0.8700, policy_loss: 1.5116, value_loss: 0.8994
2024-07-14 05:23:37,940 [INFO    ] __main__: train step 4821: loss: 0.8701, policy_loss: 1.5115, value_loss: 0.8993
2024-07-14 05:23:38,224 [INFO    ] __main__: train step 4822: loss: 0.8702, policy_loss: 1.5114, value_loss: 0.8993
2024-07-14 05:23:38,511 [INFO    ] __main__: train step 4823: loss: 0.8703, policy_loss: 1.5113, value_loss: 0.8993
2024-07-14 05:23:38,783 [INFO    ] __main__: train step 4824: loss: 0.8704, policy_loss: 1.5112, value_loss: 0.8993
2024-07-14 05:23:40,373 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:23:40,851 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:23:40,917 [INFO    ] __main__: train step 4825: loss: 0.8705, policy_loss: 1.5111, value_loss: 0.8992
2024-07-14 05:23:41,195 [INFO    ] __main__: train step 4826: loss: 0.8706, policy_loss: 1.5110, value_loss: 0.8992
2024-07-14 05:23:41,466 [INFO    ] __main__: train step 4827: loss: 0.8707, policy_loss: 1.5109, value_loss: 0.8992
2024-07-14 05:23:41,742 [INFO    ] __main__: train step 4828: loss: 0.8708, policy_loss: 1.5108, value_loss: 0.8991
2024-07-14 05:23:42,021 [INFO    ] __main__: train step 4829: loss: 0.8709, policy_loss: 1.5107, value_loss: 0.8991
2024-07-14 05:23:42,296 [INFO    ] __main__: train step 4830: loss: 0.8711, policy_loss: 1.5106, value_loss: 0.8991
2024-07-14 05:23:42,588 [INFO    ] __main__: train step 4831: loss: 0.8712, policy_loss: 1.5105, value_loss: 0.8991
2024-07-14 05:23:43,249 [INFO    ] __main__: train step 4832: loss: 0.8713, policy_loss: 1.5104, value_loss: 0.8990
2024-07-14 05:23:43,523 [INFO    ] __main__: train step 4833: loss: 0.8714, policy_loss: 1.5103, value_loss: 0.8990
2024-07-14 05:23:43,800 [INFO    ] __main__: train step 4834: loss: 0.8715, policy_loss: 1.5102, value_loss: 0.8990
2024-07-14 05:23:44,078 [INFO    ] __main__: train step 4835: loss: 0.8716, policy_loss: 1.5101, value_loss: 0.8989
2024-07-14 05:23:44,356 [INFO    ] __main__: train step 4836: loss: 0.8717, policy_loss: 1.5100, value_loss: 0.8989
2024-07-14 05:23:44,636 [INFO    ] __main__: train step 4837: loss: 0.8718, policy_loss: 1.5099, value_loss: 0.8989
2024-07-14 05:23:44,918 [INFO    ] __main__: train step 4838: loss: 0.8719, policy_loss: 1.5098, value_loss: 0.8988
2024-07-14 05:23:45,187 [INFO    ] __main__: train step 4839: loss: 0.8720, policy_loss: 1.5097, value_loss: 0.8988
2024-07-14 05:23:45,454 [INFO    ] __main__: train step 4840: loss: 0.8721, policy_loss: 1.5096, value_loss: 0.8988
2024-07-14 05:23:45,733 [INFO    ] __main__: train step 4841: loss: 0.8722, policy_loss: 1.5095, value_loss: 0.8988
2024-07-14 05:23:47,328 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:23:47,802 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:23:47,870 [INFO    ] __main__: train step 4842: loss: 0.8723, policy_loss: 1.5094, value_loss: 0.8987
2024-07-14 05:23:48,150 [INFO    ] __main__: train step 4843: loss: 0.8724, policy_loss: 1.5093, value_loss: 0.8987
2024-07-14 05:23:48,420 [INFO    ] __main__: train step 4844: loss: 0.8725, policy_loss: 1.5092, value_loss: 0.8987
2024-07-14 05:23:48,701 [INFO    ] __main__: train step 4845: loss: 0.8726, policy_loss: 1.5091, value_loss: 0.8986
2024-07-14 05:23:48,977 [INFO    ] __main__: train step 4846: loss: 0.8727, policy_loss: 1.5090, value_loss: 0.8986
2024-07-14 05:23:49,251 [INFO    ] __main__: train step 4847: loss: 0.8728, policy_loss: 1.5089, value_loss: 0.8986
2024-07-14 05:23:49,529 [INFO    ] __main__: train step 4848: loss: 0.8729, policy_loss: 1.5088, value_loss: 0.8985
2024-07-14 05:23:49,809 [INFO    ] __main__: train step 4849: loss: 0.8730, policy_loss: 1.5087, value_loss: 0.8985
2024-07-14 05:23:50,083 [INFO    ] __main__: train step 4850: loss: 0.8731, policy_loss: 1.5086, value_loss: 0.8985
2024-07-14 05:23:50,358 [INFO    ] __main__: train step 4851: loss: 0.8733, policy_loss: 1.5085, value_loss: 0.8985
2024-07-14 05:23:51,204 [INFO    ] __main__: train step 4852: loss: 0.8734, policy_loss: 1.5084, value_loss: 0.8984
2024-07-14 05:23:51,490 [INFO    ] __main__: train step 4853: loss: 0.8735, policy_loss: 1.5083, value_loss: 0.8984
2024-07-14 05:23:51,763 [INFO    ] __main__: train step 4854: loss: 0.8736, policy_loss: 1.5082, value_loss: 0.8984
2024-07-14 05:23:52,036 [INFO    ] __main__: train step 4855: loss: 0.8737, policy_loss: 1.5081, value_loss: 0.8983
2024-07-14 05:23:52,321 [INFO    ] __main__: train step 4856: loss: 0.8738, policy_loss: 1.5080, value_loss: 0.8983
2024-07-14 05:23:52,601 [INFO    ] __main__: train step 4857: loss: 0.8739, policy_loss: 1.5079, value_loss: 0.8983
2024-07-14 05:23:52,874 [INFO    ] __main__: train step 4858: loss: 0.8740, policy_loss: 1.5078, value_loss: 0.8982
2024-07-14 05:23:54,462 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:23:54,945 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:23:55,013 [INFO    ] __main__: train step 4859: loss: 0.8741, policy_loss: 1.5077, value_loss: 0.8982
2024-07-14 05:23:55,267 [INFO    ] __main__: train step 4860: loss: 0.8742, policy_loss: 1.5076, value_loss: 0.8982
2024-07-14 05:23:55,542 [INFO    ] __main__: train step 4861: loss: 0.8743, policy_loss: 1.5075, value_loss: 0.8982
2024-07-14 05:23:55,814 [INFO    ] __main__: train step 4862: loss: 0.8744, policy_loss: 1.5074, value_loss: 0.8981
2024-07-14 05:23:56,086 [INFO    ] __main__: train step 4863: loss: 0.8745, policy_loss: 1.5073, value_loss: 0.8981
2024-07-14 05:23:56,363 [INFO    ] __main__: train step 4864: loss: 0.8746, policy_loss: 1.5072, value_loss: 0.8981
2024-07-14 05:23:56,641 [INFO    ] __main__: train step 4865: loss: 0.8747, policy_loss: 1.5071, value_loss: 0.8980
2024-07-14 05:23:56,929 [INFO    ] __main__: train step 4866: loss: 0.8748, policy_loss: 1.5070, value_loss: 0.8980
2024-07-14 05:23:57,197 [INFO    ] __main__: train step 4867: loss: 0.8749, policy_loss: 1.5069, value_loss: 0.8980
2024-07-14 05:23:57,479 [INFO    ] __main__: train step 4868: loss: 0.8750, policy_loss: 1.5068, value_loss: 0.8980
2024-07-14 05:23:57,762 [INFO    ] __main__: train step 4869: loss: 0.8751, policy_loss: 1.5067, value_loss: 0.8979
2024-07-14 05:23:58,043 [INFO    ] __main__: train step 4870: loss: 0.8752, policy_loss: 1.5066, value_loss: 0.8979
2024-07-14 05:23:58,330 [INFO    ] __main__: train step 4871: loss: 0.8753, policy_loss: 1.5065, value_loss: 0.8979
2024-07-14 05:23:58,964 [INFO    ] __main__: train step 4872: loss: 0.8754, policy_loss: 1.5064, value_loss: 0.8978
2024-07-14 05:23:59,271 [INFO    ] __main__: train step 4873: loss: 0.8755, policy_loss: 1.5063, value_loss: 0.8978
2024-07-14 05:23:59,545 [INFO    ] __main__: train step 4874: loss: 0.8756, policy_loss: 1.5062, value_loss: 0.8978
2024-07-14 05:23:59,815 [INFO    ] __main__: train step 4875: loss: 0.8758, policy_loss: 1.5061, value_loss: 0.8977
2024-07-14 05:24:01,398 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:24:01,889 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:24:01,957 [INFO    ] __main__: train step 4876: loss: 0.8759, policy_loss: 1.5060, value_loss: 0.8977
2024-07-14 05:24:02,222 [INFO    ] __main__: train step 4877: loss: 0.8760, policy_loss: 1.5059, value_loss: 0.8977
2024-07-14 05:24:02,493 [INFO    ] __main__: train step 4878: loss: 0.8761, policy_loss: 1.5058, value_loss: 0.8977
2024-07-14 05:24:02,772 [INFO    ] __main__: train step 4879: loss: 0.8762, policy_loss: 1.5057, value_loss: 0.8976
2024-07-14 05:24:03,032 [INFO    ] __main__: train step 4880: loss: 0.8763, policy_loss: 1.5056, value_loss: 0.8976
2024-07-14 05:24:03,296 [INFO    ] __main__: train step 4881: loss: 0.8764, policy_loss: 1.5055, value_loss: 0.8976
2024-07-14 05:24:03,581 [INFO    ] __main__: train step 4882: loss: 0.8765, policy_loss: 1.5054, value_loss: 0.8975
2024-07-14 05:24:03,856 [INFO    ] __main__: train step 4883: loss: 0.8766, policy_loss: 1.5053, value_loss: 0.8975
2024-07-14 05:24:04,142 [INFO    ] __main__: train step 4884: loss: 0.8767, policy_loss: 1.5053, value_loss: 0.8975
2024-07-14 05:24:04,422 [INFO    ] __main__: train step 4885: loss: 0.8768, policy_loss: 1.5052, value_loss: 0.8974
2024-07-14 05:24:04,703 [INFO    ] __main__: train step 4886: loss: 0.8769, policy_loss: 1.5051, value_loss: 0.8974
2024-07-14 05:24:05,002 [INFO    ] __main__: train step 4887: loss: 0.8770, policy_loss: 1.5050, value_loss: 0.8974
2024-07-14 05:24:05,278 [INFO    ] __main__: train step 4888: loss: 0.8771, policy_loss: 1.5049, value_loss: 0.8974
2024-07-14 05:24:05,554 [INFO    ] __main__: train step 4889: loss: 0.8772, policy_loss: 1.5048, value_loss: 0.8973
2024-07-14 05:24:05,834 [INFO    ] __main__: train step 4890: loss: 0.8773, policy_loss: 1.5047, value_loss: 0.8973
2024-07-14 05:24:06,483 [INFO    ] __main__: train step 4891: loss: 0.8774, policy_loss: 1.5046, value_loss: 0.8973
2024-07-14 05:24:06,767 [INFO    ] __main__: train step 4892: loss: 0.8775, policy_loss: 1.5045, value_loss: 0.8972
2024-07-14 05:24:08,365 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:24:08,848 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:24:08,919 [INFO    ] __main__: train step 4893: loss: 0.8776, policy_loss: 1.5044, value_loss: 0.8972
2024-07-14 05:24:09,195 [INFO    ] __main__: train step 4894: loss: 0.8777, policy_loss: 1.5043, value_loss: 0.8972
2024-07-14 05:24:09,474 [INFO    ] __main__: train step 4895: loss: 0.8778, policy_loss: 1.5042, value_loss: 0.8972
2024-07-14 05:24:09,749 [INFO    ] __main__: train step 4896: loss: 0.8779, policy_loss: 1.5041, value_loss: 0.8971
2024-07-14 05:24:10,030 [INFO    ] __main__: train step 4897: loss: 0.8780, policy_loss: 1.5040, value_loss: 0.8971
2024-07-14 05:24:10,338 [INFO    ] __main__: train step 4898: loss: 0.8781, policy_loss: 1.5039, value_loss: 0.8971
2024-07-14 05:24:10,625 [INFO    ] __main__: train step 4899: loss: 0.8782, policy_loss: 1.5038, value_loss: 0.8970
2024-07-14 05:24:10,915 [INFO    ] __main__: train step 4900: loss: 0.8783, policy_loss: 1.5037, value_loss: 0.8970
2024-07-14 05:24:11,195 [INFO    ] __main__: train step 4901: loss: 0.8785, policy_loss: 1.5036, value_loss: 0.8970
2024-07-14 05:24:11,474 [INFO    ] __main__: train step 4902: loss: 0.8786, policy_loss: 1.5035, value_loss: 0.8969
2024-07-14 05:24:11,762 [INFO    ] __main__: train step 4903: loss: 0.8787, policy_loss: 1.5034, value_loss: 0.8969
2024-07-14 05:24:12,036 [INFO    ] __main__: train step 4904: loss: 0.8788, policy_loss: 1.5033, value_loss: 0.8969
2024-07-14 05:24:12,339 [INFO    ] __main__: train step 4905: loss: 0.8789, policy_loss: 1.5032, value_loss: 0.8969
2024-07-14 05:24:12,624 [INFO    ] __main__: train step 4906: loss: 0.8790, policy_loss: 1.5031, value_loss: 0.8968
2024-07-14 05:24:12,909 [INFO    ] __main__: train step 4907: loss: 0.8791, policy_loss: 1.5030, value_loss: 0.8968
2024-07-14 05:24:13,192 [INFO    ] __main__: train step 4908: loss: 0.8792, policy_loss: 1.5029, value_loss: 0.8968
2024-07-14 05:24:13,483 [INFO    ] __main__: train step 4909: loss: 0.8793, policy_loss: 1.5028, value_loss: 0.8967
2024-07-14 05:24:15,072 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:24:15,554 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:24:15,620 [INFO    ] __main__: train step 4910: loss: 0.8794, policy_loss: 1.5027, value_loss: 0.8967
2024-07-14 05:24:16,510 [INFO    ] __main__: train step 4911: loss: 0.8795, policy_loss: 1.5026, value_loss: 0.8967
2024-07-14 05:24:16,806 [INFO    ] __main__: train step 4912: loss: 0.8796, policy_loss: 1.5025, value_loss: 0.8967
2024-07-14 05:24:17,081 [INFO    ] __main__: train step 4913: loss: 0.8797, policy_loss: 1.5024, value_loss: 0.8966
2024-07-14 05:24:17,363 [INFO    ] __main__: train step 4914: loss: 0.8798, policy_loss: 1.5023, value_loss: 0.8966
2024-07-14 05:24:17,637 [INFO    ] __main__: train step 4915: loss: 0.8799, policy_loss: 1.5023, value_loss: 0.8966
2024-07-14 05:24:17,916 [INFO    ] __main__: train step 4916: loss: 0.8800, policy_loss: 1.5022, value_loss: 0.8965
2024-07-14 05:24:18,197 [INFO    ] __main__: train step 4917: loss: 0.8801, policy_loss: 1.5021, value_loss: 0.8965
2024-07-14 05:24:18,475 [INFO    ] __main__: train step 4918: loss: 0.8802, policy_loss: 1.5020, value_loss: 0.8965
2024-07-14 05:24:18,756 [INFO    ] __main__: train step 4919: loss: 0.8803, policy_loss: 1.5019, value_loss: 0.8964
2024-07-14 05:24:19,041 [INFO    ] __main__: train step 4920: loss: 0.8804, policy_loss: 1.5018, value_loss: 0.8964
2024-07-14 05:24:19,328 [INFO    ] __main__: train step 4921: loss: 0.8805, policy_loss: 1.5017, value_loss: 0.8964
2024-07-14 05:24:19,610 [INFO    ] __main__: train step 4922: loss: 0.8806, policy_loss: 1.5016, value_loss: 0.8963
2024-07-14 05:24:19,894 [INFO    ] __main__: train step 4923: loss: 0.8808, policy_loss: 1.5015, value_loss: 0.8963
2024-07-14 05:24:20,179 [INFO    ] __main__: train step 4924: loss: 0.8809, policy_loss: 1.5014, value_loss: 0.8963
2024-07-14 05:24:20,456 [INFO    ] __main__: train step 4925: loss: 0.8810, policy_loss: 1.5013, value_loss: 0.8963
2024-07-14 05:24:20,730 [INFO    ] __main__: train step 4926: loss: 0.8811, policy_loss: 1.5012, value_loss: 0.8962
2024-07-14 05:24:22,331 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:24:22,810 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:24:22,880 [INFO    ] __main__: train step 4927: loss: 0.8812, policy_loss: 1.5011, value_loss: 0.8962
2024-07-14 05:24:23,170 [INFO    ] __main__: train step 4928: loss: 0.8813, policy_loss: 1.5010, value_loss: 0.8962
2024-07-14 05:24:23,445 [INFO    ] __main__: train step 4929: loss: 0.8814, policy_loss: 1.5009, value_loss: 0.8961
2024-07-14 05:24:23,724 [INFO    ] __main__: train step 4930: loss: 0.8815, policy_loss: 1.5008, value_loss: 0.8961
2024-07-14 05:24:24,613 [INFO    ] __main__: train step 4931: loss: 0.8816, policy_loss: 1.5007, value_loss: 0.8961
2024-07-14 05:24:24,900 [INFO    ] __main__: train step 4932: loss: 0.8817, policy_loss: 1.5006, value_loss: 0.8960
2024-07-14 05:24:25,181 [INFO    ] __main__: train step 4933: loss: 0.8818, policy_loss: 1.5005, value_loss: 0.8960
2024-07-14 05:24:25,466 [INFO    ] __main__: train step 4934: loss: 0.8819, policy_loss: 1.5004, value_loss: 0.8960
2024-07-14 05:24:25,742 [INFO    ] __main__: train step 4935: loss: 0.8820, policy_loss: 1.5003, value_loss: 0.8960
2024-07-14 05:24:26,003 [INFO    ] __main__: train step 4936: loss: 0.8821, policy_loss: 1.5002, value_loss: 0.8959
2024-07-14 05:24:26,283 [INFO    ] __main__: train step 4937: loss: 0.8822, policy_loss: 1.5001, value_loss: 0.8959
2024-07-14 05:24:26,564 [INFO    ] __main__: train step 4938: loss: 0.8823, policy_loss: 1.5000, value_loss: 0.8959
2024-07-14 05:24:26,841 [INFO    ] __main__: train step 4939: loss: 0.8824, policy_loss: 1.4999, value_loss: 0.8958
2024-07-14 05:24:27,128 [INFO    ] __main__: train step 4940: loss: 0.8825, policy_loss: 1.4998, value_loss: 0.8958
2024-07-14 05:24:27,398 [INFO    ] __main__: train step 4941: loss: 0.8826, policy_loss: 1.4997, value_loss: 0.8958
2024-07-14 05:24:27,689 [INFO    ] __main__: train step 4942: loss: 0.8827, policy_loss: 1.4996, value_loss: 0.8958
2024-07-14 05:24:27,965 [INFO    ] __main__: train step 4943: loss: 0.8828, policy_loss: 1.4995, value_loss: 0.8957
2024-07-14 05:24:29,542 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:24:30,013 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:24:30,082 [INFO    ] __main__: train step 4944: loss: 0.8829, policy_loss: 1.4994, value_loss: 0.8957
2024-07-14 05:24:30,360 [INFO    ] __main__: train step 4945: loss: 0.8830, policy_loss: 1.4993, value_loss: 0.8957
2024-07-14 05:24:30,644 [INFO    ] __main__: train step 4946: loss: 0.8831, policy_loss: 1.4993, value_loss: 0.8956
2024-07-14 05:24:30,922 [INFO    ] __main__: train step 4947: loss: 0.8832, policy_loss: 1.4992, value_loss: 0.8956
2024-07-14 05:24:31,197 [INFO    ] __main__: train step 4948: loss: 0.8833, policy_loss: 1.4991, value_loss: 0.8956
2024-07-14 05:24:31,476 [INFO    ] __main__: train step 4949: loss: 0.8834, policy_loss: 1.4990, value_loss: 0.8956
2024-07-14 05:24:31,771 [INFO    ] __main__: train step 4950: loss: 0.8835, policy_loss: 1.4989, value_loss: 0.8955
2024-07-14 05:24:32,647 [INFO    ] __main__: train step 4951: loss: 0.8836, policy_loss: 1.4988, value_loss: 0.8955
2024-07-14 05:24:32,918 [INFO    ] __main__: train step 4952: loss: 0.8838, policy_loss: 1.4987, value_loss: 0.8955
2024-07-14 05:24:33,190 [INFO    ] __main__: train step 4953: loss: 0.8839, policy_loss: 1.4986, value_loss: 0.8954
2024-07-14 05:24:33,447 [INFO    ] __main__: train step 4954: loss: 0.8840, policy_loss: 1.4985, value_loss: 0.8954
2024-07-14 05:24:33,730 [INFO    ] __main__: train step 4955: loss: 0.8841, policy_loss: 1.4984, value_loss: 0.8954
2024-07-14 05:24:34,016 [INFO    ] __main__: train step 4956: loss: 0.8842, policy_loss: 1.4983, value_loss: 0.8954
2024-07-14 05:24:34,300 [INFO    ] __main__: train step 4957: loss: 0.8843, policy_loss: 1.4982, value_loss: 0.8953
2024-07-14 05:24:34,580 [INFO    ] __main__: train step 4958: loss: 0.8844, policy_loss: 1.4981, value_loss: 0.8953
2024-07-14 05:24:34,857 [INFO    ] __main__: train step 4959: loss: 0.8845, policy_loss: 1.4980, value_loss: 0.8953
2024-07-14 05:24:35,146 [INFO    ] __main__: train step 4960: loss: 0.8846, policy_loss: 1.4979, value_loss: 0.8952
2024-07-14 05:24:36,747 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:24:37,225 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:24:37,293 [INFO    ] __main__: train step 4961: loss: 0.8847, policy_loss: 1.4978, value_loss: 0.8952
2024-07-14 05:24:37,555 [INFO    ] __main__: train step 4962: loss: 0.8848, policy_loss: 1.4977, value_loss: 0.8952
2024-07-14 05:24:37,835 [INFO    ] __main__: train step 4963: loss: 0.8849, policy_loss: 1.4976, value_loss: 0.8952
2024-07-14 05:24:38,131 [INFO    ] __main__: train step 4964: loss: 0.8850, policy_loss: 1.4975, value_loss: 0.8951
2024-07-14 05:24:38,405 [INFO    ] __main__: train step 4965: loss: 0.8851, policy_loss: 1.4974, value_loss: 0.8951
2024-07-14 05:24:38,693 [INFO    ] __main__: train step 4966: loss: 0.8852, policy_loss: 1.4973, value_loss: 0.8951
2024-07-14 05:24:38,971 [INFO    ] __main__: train step 4967: loss: 0.8853, policy_loss: 1.4972, value_loss: 0.8951
2024-07-14 05:24:39,248 [INFO    ] __main__: train step 4968: loss: 0.8854, policy_loss: 1.4971, value_loss: 0.8950
2024-07-14 05:24:39,520 [INFO    ] __main__: train step 4969: loss: 0.8855, policy_loss: 1.4971, value_loss: 0.8950
2024-07-14 05:24:39,808 [INFO    ] __main__: train step 4970: loss: 0.8856, policy_loss: 1.4970, value_loss: 0.8950
2024-07-14 05:24:40,712 [INFO    ] __main__: train step 4971: loss: 0.8857, policy_loss: 1.4969, value_loss: 0.8949
2024-07-14 05:24:40,999 [INFO    ] __main__: train step 4972: loss: 0.8858, policy_loss: 1.4968, value_loss: 0.8949
2024-07-14 05:24:41,287 [INFO    ] __main__: train step 4973: loss: 0.8859, policy_loss: 1.4967, value_loss: 0.8949
2024-07-14 05:24:41,565 [INFO    ] __main__: train step 4974: loss: 0.8860, policy_loss: 1.4966, value_loss: 0.8948
2024-07-14 05:24:41,845 [INFO    ] __main__: train step 4975: loss: 0.8861, policy_loss: 1.4965, value_loss: 0.8948
2024-07-14 05:24:42,135 [INFO    ] __main__: train step 4976: loss: 0.8862, policy_loss: 1.4964, value_loss: 0.8948
2024-07-14 05:24:42,408 [INFO    ] __main__: train step 4977: loss: 0.8863, policy_loss: 1.4963, value_loss: 0.8947
2024-07-14 05:24:44,020 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:24:44,494 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:24:44,565 [INFO    ] __main__: train step 4978: loss: 0.8864, policy_loss: 1.4962, value_loss: 0.8947
2024-07-14 05:24:44,829 [INFO    ] __main__: train step 4979: loss: 0.8865, policy_loss: 1.4961, value_loss: 0.8947
2024-07-14 05:24:45,101 [INFO    ] __main__: train step 4980: loss: 0.8866, policy_loss: 1.4960, value_loss: 0.8947
2024-07-14 05:24:45,377 [INFO    ] __main__: train step 4981: loss: 0.8867, policy_loss: 1.4959, value_loss: 0.8946
2024-07-14 05:24:45,661 [INFO    ] __main__: train step 4982: loss: 0.8868, policy_loss: 1.4958, value_loss: 0.8946
2024-07-14 05:24:45,954 [INFO    ] __main__: train step 4983: loss: 0.8869, policy_loss: 1.4957, value_loss: 0.8946
2024-07-14 05:24:46,241 [INFO    ] __main__: train step 4984: loss: 0.8870, policy_loss: 1.4956, value_loss: 0.8945
2024-07-14 05:24:46,518 [INFO    ] __main__: train step 4985: loss: 0.8871, policy_loss: 1.4955, value_loss: 0.8945
2024-07-14 05:24:46,794 [INFO    ] __main__: train step 4986: loss: 0.8872, policy_loss: 1.4954, value_loss: 0.8945
2024-07-14 05:24:47,056 [INFO    ] __main__: train step 4987: loss: 0.8873, policy_loss: 1.4953, value_loss: 0.8944
2024-07-14 05:24:47,313 [INFO    ] __main__: train step 4988: loss: 0.8875, policy_loss: 1.4952, value_loss: 0.8944
2024-07-14 05:24:47,596 [INFO    ] __main__: train step 4989: loss: 0.8876, policy_loss: 1.4951, value_loss: 0.8944
2024-07-14 05:24:47,869 [INFO    ] __main__: train step 4990: loss: 0.8877, policy_loss: 1.4950, value_loss: 0.8944
2024-07-14 05:24:48,749 [INFO    ] __main__: train step 4991: loss: 0.8878, policy_loss: 1.4949, value_loss: 0.8943
2024-07-14 05:24:49,020 [INFO    ] __main__: train step 4992: loss: 0.8879, policy_loss: 1.4948, value_loss: 0.8943
2024-07-14 05:24:49,290 [INFO    ] __main__: train step 4993: loss: 0.8880, policy_loss: 1.4947, value_loss: 0.8943
2024-07-14 05:24:49,578 [INFO    ] __main__: train step 4994: loss: 0.8881, policy_loss: 1.4946, value_loss: 0.8942
2024-07-14 05:24:51,180 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:24:51,656 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:24:51,727 [INFO    ] __main__: train step 4995: loss: 0.8882, policy_loss: 1.4945, value_loss: 0.8942
2024-07-14 05:24:52,052 [INFO    ] __main__: train step 4996: loss: 0.8883, policy_loss: 1.4944, value_loss: 0.8942
2024-07-14 05:24:52,332 [INFO    ] __main__: train step 4997: loss: 0.8884, policy_loss: 1.4943, value_loss: 0.8942
2024-07-14 05:24:52,614 [INFO    ] __main__: train step 4998: loss: 0.8885, policy_loss: 1.4942, value_loss: 0.8941
2024-07-14 05:24:52,892 [INFO    ] __main__: train step 4999: loss: 0.8886, policy_loss: 1.4941, value_loss: 0.8941
2024-07-14 05:24:53,170 [INFO    ] __main__: train step 5000: loss: 0.8887, policy_loss: 1.4940, value_loss: 0.8941
2024-07-14 05:24:53,319 [INFO    ] __main__: restored step 4000 for evaluation
2024-07-14 05:24:58,565 [INFO    ] __main__: test network ELO difference from baseline network: +242 (+8/-8) ELO from 32000 self-played games
2024-07-14 05:24:58,568 [INFO    ] __main__: game outcomes: W: 24014, D: 1019, L: 6967
2024-07-14 05:24:58,571 [INFO    ] __main__: validation_elo_delta: 242, validation_elo: 1272
2024-07-14 05:24:59,022 [INFO    ] __main__: running self-play game for SVG generation
2024-07-14 05:26:57,370 [INFO    ] __main__: saved self-play game in animations/run2_armageddon/05000.svg
2024-07-14 05:26:57,623 [INFO    ] __main__: train step 5001: loss: 0.8888, policy_loss: 1.4940, value_loss: 0.8940
2024-07-14 05:26:57,873 [INFO    ] __main__: train step 5002: loss: 0.8889, policy_loss: 1.4939, value_loss: 0.8940
2024-07-14 05:26:58,139 [INFO    ] __main__: train step 5003: loss: 0.8890, policy_loss: 1.4938, value_loss: 0.8940
2024-07-14 05:26:58,407 [INFO    ] __main__: train step 5004: loss: 0.8891, policy_loss: 1.4937, value_loss: 0.8939
2024-07-14 05:26:58,673 [INFO    ] __main__: train step 5005: loss: 0.8892, policy_loss: 1.4936, value_loss: 0.8939
2024-07-14 05:26:58,909 [INFO    ] __main__: train step 5006: loss: 0.8893, policy_loss: 1.4935, value_loss: 0.8939
2024-07-14 05:26:59,153 [INFO    ] __main__: train step 5007: loss: 0.8894, policy_loss: 1.4934, value_loss: 0.8939
2024-07-14 05:26:59,423 [INFO    ] __main__: train step 5008: loss: 0.8895, policy_loss: 1.4933, value_loss: 0.8938
2024-07-14 05:26:59,701 [INFO    ] __main__: train step 5009: loss: 0.8896, policy_loss: 1.4932, value_loss: 0.8938
2024-07-14 05:26:59,965 [INFO    ] __main__: train step 5010: loss: 0.8897, policy_loss: 1.4931, value_loss: 0.8938
2024-07-14 05:27:01,754 [INFO    ] __main__: train step 5011: loss: 0.8898, policy_loss: 1.4930, value_loss: 0.8937
2024-07-14 05:27:03,340 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:27:03,823 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:27:03,895 [INFO    ] __main__: train step 5012: loss: 0.8899, policy_loss: 1.4929, value_loss: 0.8937
2024-07-14 05:27:04,174 [INFO    ] __main__: train step 5013: loss: 0.8900, policy_loss: 1.4928, value_loss: 0.8937
2024-07-14 05:27:04,442 [INFO    ] __main__: train step 5014: loss: 0.8901, policy_loss: 1.4927, value_loss: 0.8936
2024-07-14 05:27:04,706 [INFO    ] __main__: train step 5015: loss: 0.8902, policy_loss: 1.4926, value_loss: 0.8936
2024-07-14 05:27:04,979 [INFO    ] __main__: train step 5016: loss: 0.8903, policy_loss: 1.4925, value_loss: 0.8936
2024-07-14 05:27:05,260 [INFO    ] __main__: train step 5017: loss: 0.8904, policy_loss: 1.4924, value_loss: 0.8936
2024-07-14 05:27:05,551 [INFO    ] __main__: train step 5018: loss: 0.8905, policy_loss: 1.4923, value_loss: 0.8935
2024-07-14 05:27:05,824 [INFO    ] __main__: train step 5019: loss: 0.8906, policy_loss: 1.4922, value_loss: 0.8935
2024-07-14 05:27:06,088 [INFO    ] __main__: train step 5020: loss: 0.8907, policy_loss: 1.4921, value_loss: 0.8935
2024-07-14 05:27:06,373 [INFO    ] __main__: train step 5021: loss: 0.8908, policy_loss: 1.4921, value_loss: 0.8934
2024-07-14 05:27:06,651 [INFO    ] __main__: train step 5022: loss: 0.8909, policy_loss: 1.4920, value_loss: 0.8934
2024-07-14 05:27:06,927 [INFO    ] __main__: train step 5023: loss: 0.8910, policy_loss: 1.4919, value_loss: 0.8934
2024-07-14 05:27:07,193 [INFO    ] __main__: train step 5024: loss: 0.8911, policy_loss: 1.4918, value_loss: 0.8934
2024-07-14 05:27:07,466 [INFO    ] __main__: train step 5025: loss: 0.8912, policy_loss: 1.4917, value_loss: 0.8933
2024-07-14 05:27:07,744 [INFO    ] __main__: train step 5026: loss: 0.8913, policy_loss: 1.4916, value_loss: 0.8933
2024-07-14 05:27:08,026 [INFO    ] __main__: train step 5027: loss: 0.8914, policy_loss: 1.4915, value_loss: 0.8933
2024-07-14 05:27:08,301 [INFO    ] __main__: train step 5028: loss: 0.8915, policy_loss: 1.4914, value_loss: 0.8932
2024-07-14 05:27:09,883 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:27:10,361 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:27:10,429 [INFO    ] __main__: train step 5029: loss: 0.8916, policy_loss: 1.4913, value_loss: 0.8932
2024-07-14 05:27:10,710 [INFO    ] __main__: train step 5030: loss: 0.8917, policy_loss: 1.4912, value_loss: 0.8932
2024-07-14 05:27:10,987 [INFO    ] __main__: train step 5031: loss: 0.8918, policy_loss: 1.4911, value_loss: 0.8932
2024-07-14 05:27:11,258 [INFO    ] __main__: train step 5032: loss: 0.8919, policy_loss: 1.4910, value_loss: 0.8931
2024-07-14 05:27:11,535 [INFO    ] __main__: train step 5033: loss: 0.8920, policy_loss: 1.4909, value_loss: 0.8931
2024-07-14 05:27:11,800 [INFO    ] __main__: train step 5034: loss: 0.8921, policy_loss: 1.4908, value_loss: 0.8931
2024-07-14 05:27:12,076 [INFO    ] __main__: train step 5035: loss: 0.8923, policy_loss: 1.4907, value_loss: 0.8930
2024-07-14 05:27:12,342 [INFO    ] __main__: train step 5036: loss: 0.8923, policy_loss: 1.4906, value_loss: 0.8930
2024-07-14 05:27:12,618 [INFO    ] __main__: train step 5037: loss: 0.8924, policy_loss: 1.4905, value_loss: 0.8930
2024-07-14 05:27:12,898 [INFO    ] __main__: train step 5038: loss: 0.8926, policy_loss: 1.4904, value_loss: 0.8929
2024-07-14 05:27:13,166 [INFO    ] __main__: train step 5039: loss: 0.8927, policy_loss: 1.4903, value_loss: 0.8929
2024-07-14 05:27:13,447 [INFO    ] __main__: train step 5040: loss: 0.8928, policy_loss: 1.4902, value_loss: 0.8929
2024-07-14 05:27:13,720 [INFO    ] __main__: train step 5041: loss: 0.8929, policy_loss: 1.4901, value_loss: 0.8929
2024-07-14 05:27:13,991 [INFO    ] __main__: train step 5042: loss: 0.8930, policy_loss: 1.4900, value_loss: 0.8928
2024-07-14 05:27:14,283 [INFO    ] __main__: train step 5043: loss: 0.8931, policy_loss: 1.4899, value_loss: 0.8928
2024-07-14 05:27:14,547 [INFO    ] __main__: train step 5044: loss: 0.8932, policy_loss: 1.4898, value_loss: 0.8928
2024-07-14 05:27:14,804 [INFO    ] __main__: train step 5045: loss: 0.8933, policy_loss: 1.4898, value_loss: 0.8928
2024-07-14 05:27:16,396 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:27:16,883 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:27:16,956 [INFO    ] __main__: train step 5046: loss: 0.8934, policy_loss: 1.4897, value_loss: 0.8927
2024-07-14 05:27:17,239 [INFO    ] __main__: train step 5047: loss: 0.8935, policy_loss: 1.4896, value_loss: 0.8927
2024-07-14 05:27:17,522 [INFO    ] __main__: train step 5048: loss: 0.8936, policy_loss: 1.4895, value_loss: 0.8927
2024-07-14 05:27:17,801 [INFO    ] __main__: train step 5049: loss: 0.8937, policy_loss: 1.4894, value_loss: 0.8926
2024-07-14 05:27:18,077 [INFO    ] __main__: train step 5050: loss: 0.8938, policy_loss: 1.4893, value_loss: 0.8926
2024-07-14 05:27:18,342 [INFO    ] __main__: train step 5051: loss: 0.8939, policy_loss: 1.4892, value_loss: 0.8926
2024-07-14 05:27:18,632 [INFO    ] __main__: train step 5052: loss: 0.8940, policy_loss: 1.4891, value_loss: 0.8925
2024-07-14 05:27:18,914 [INFO    ] __main__: train step 5053: loss: 0.8941, policy_loss: 1.4890, value_loss: 0.8925
2024-07-14 05:27:19,198 [INFO    ] __main__: train step 5054: loss: 0.8942, policy_loss: 1.4889, value_loss: 0.8925
2024-07-14 05:27:19,475 [INFO    ] __main__: train step 5055: loss: 0.8943, policy_loss: 1.4888, value_loss: 0.8925
2024-07-14 05:27:19,744 [INFO    ] __main__: train step 5056: loss: 0.8944, policy_loss: 1.4887, value_loss: 0.8924
2024-07-14 05:27:20,019 [INFO    ] __main__: train step 5057: loss: 0.8945, policy_loss: 1.4886, value_loss: 0.8924
2024-07-14 05:27:20,301 [INFO    ] __main__: train step 5058: loss: 0.8946, policy_loss: 1.4885, value_loss: 0.8924
2024-07-14 05:27:20,558 [INFO    ] __main__: train step 5059: loss: 0.8947, policy_loss: 1.4884, value_loss: 0.8923
2024-07-14 05:27:20,833 [INFO    ] __main__: train step 5060: loss: 0.8948, policy_loss: 1.4883, value_loss: 0.8923
2024-07-14 05:27:21,103 [INFO    ] __main__: train step 5061: loss: 0.8949, policy_loss: 1.4882, value_loss: 0.8923
2024-07-14 05:27:21,377 [INFO    ] __main__: train step 5062: loss: 0.8950, policy_loss: 1.4881, value_loss: 0.8923
2024-07-14 05:27:22,974 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:27:23,454 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:27:23,523 [INFO    ] __main__: train step 5063: loss: 0.8951, policy_loss: 1.4880, value_loss: 0.8922
2024-07-14 05:27:23,801 [INFO    ] __main__: train step 5064: loss: 0.8952, policy_loss: 1.4880, value_loss: 0.8922
2024-07-14 05:27:24,081 [INFO    ] __main__: train step 5065: loss: 0.8953, policy_loss: 1.4879, value_loss: 0.8922
2024-07-14 05:27:25,567 [INFO    ] __main__: train step 5066: loss: 0.8954, policy_loss: 1.4878, value_loss: 0.8921
2024-07-14 05:27:25,825 [INFO    ] __main__: train step 5067: loss: 0.8955, policy_loss: 1.4877, value_loss: 0.8921
2024-07-14 05:27:26,135 [INFO    ] __main__: train step 5068: loss: 0.8956, policy_loss: 1.4876, value_loss: 0.8921
2024-07-14 05:27:26,406 [INFO    ] __main__: train step 5069: loss: 0.8957, policy_loss: 1.4875, value_loss: 0.8921
2024-07-14 05:27:26,677 [INFO    ] __main__: train step 5070: loss: 0.8958, policy_loss: 1.4874, value_loss: 0.8920
2024-07-14 05:27:26,958 [INFO    ] __main__: train step 5071: loss: 0.8959, policy_loss: 1.4873, value_loss: 0.8920
2024-07-14 05:27:27,233 [INFO    ] __main__: train step 5072: loss: 0.8960, policy_loss: 1.4872, value_loss: 0.8920
2024-07-14 05:27:27,510 [INFO    ] __main__: train step 5073: loss: 0.8961, policy_loss: 1.4871, value_loss: 0.8919
2024-07-14 05:27:27,791 [INFO    ] __main__: train step 5074: loss: 0.8962, policy_loss: 1.4870, value_loss: 0.8919
2024-07-14 05:27:28,077 [INFO    ] __main__: train step 5075: loss: 0.8963, policy_loss: 1.4869, value_loss: 0.8919
2024-07-14 05:27:28,358 [INFO    ] __main__: train step 5076: loss: 0.8964, policy_loss: 1.4868, value_loss: 0.8918
2024-07-14 05:27:28,630 [INFO    ] __main__: train step 5077: loss: 0.8965, policy_loss: 1.4867, value_loss: 0.8918
2024-07-14 05:27:28,907 [INFO    ] __main__: train step 5078: loss: 0.8966, policy_loss: 1.4866, value_loss: 0.8918
2024-07-14 05:27:29,176 [INFO    ] __main__: train step 5079: loss: 0.8967, policy_loss: 1.4865, value_loss: 0.8918
2024-07-14 05:27:30,767 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:27:31,248 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:27:31,313 [INFO    ] __main__: train step 5080: loss: 0.8968, policy_loss: 1.4865, value_loss: 0.8917
2024-07-14 05:27:31,590 [INFO    ] __main__: train step 5081: loss: 0.8969, policy_loss: 1.4864, value_loss: 0.8917
2024-07-14 05:27:31,871 [INFO    ] __main__: train step 5082: loss: 0.8971, policy_loss: 1.4863, value_loss: 0.8917
2024-07-14 05:27:32,147 [INFO    ] __main__: train step 5083: loss: 0.8972, policy_loss: 1.4862, value_loss: 0.8916
2024-07-14 05:27:32,424 [INFO    ] __main__: train step 5084: loss: 0.8973, policy_loss: 1.4861, value_loss: 0.8916
2024-07-14 05:27:32,698 [INFO    ] __main__: train step 5085: loss: 0.8974, policy_loss: 1.4860, value_loss: 0.8916
2024-07-14 05:27:32,966 [INFO    ] __main__: train step 5086: loss: 0.8975, policy_loss: 1.4859, value_loss: 0.8916
2024-07-14 05:27:33,240 [INFO    ] __main__: train step 5087: loss: 0.8976, policy_loss: 1.4858, value_loss: 0.8915
2024-07-14 05:27:33,518 [INFO    ] __main__: train step 5088: loss: 0.8977, policy_loss: 1.4857, value_loss: 0.8915
2024-07-14 05:27:33,792 [INFO    ] __main__: train step 5089: loss: 0.8978, policy_loss: 1.4856, value_loss: 0.8915
2024-07-14 05:27:34,059 [INFO    ] __main__: train step 5090: loss: 0.8979, policy_loss: 1.4855, value_loss: 0.8914
2024-07-14 05:27:34,338 [INFO    ] __main__: train step 5091: loss: 0.8980, policy_loss: 1.4854, value_loss: 0.8914
2024-07-14 05:27:34,621 [INFO    ] __main__: train step 5092: loss: 0.8981, policy_loss: 1.4854, value_loss: 0.8914
2024-07-14 05:27:34,889 [INFO    ] __main__: train step 5093: loss: 0.8982, policy_loss: 1.4853, value_loss: 0.8914
2024-07-14 05:27:35,168 [INFO    ] __main__: train step 5094: loss: 0.8983, policy_loss: 1.4852, value_loss: 0.8913
2024-07-14 05:27:35,437 [INFO    ] __main__: train step 5095: loss: 0.8984, policy_loss: 1.4851, value_loss: 0.8913
2024-07-14 05:27:35,724 [INFO    ] __main__: train step 5096: loss: 0.8985, policy_loss: 1.4850, value_loss: 0.8913
2024-07-14 05:27:37,319 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:27:37,798 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:27:37,877 [INFO    ] __main__: train step 5097: loss: 0.8986, policy_loss: 1.4849, value_loss: 0.8912
2024-07-14 05:27:38,152 [INFO    ] __main__: train step 5098: loss: 0.8987, policy_loss: 1.4848, value_loss: 0.8912
2024-07-14 05:27:38,427 [INFO    ] __main__: train step 5099: loss: 0.8988, policy_loss: 1.4847, value_loss: 0.8912
2024-07-14 05:27:38,699 [INFO    ] __main__: train step 5100: loss: 0.8989, policy_loss: 1.4846, value_loss: 0.8911
2024-07-14 05:27:38,979 [INFO    ] __main__: train step 5101: loss: 0.8990, policy_loss: 1.4845, value_loss: 0.8911
2024-07-14 05:27:39,247 [INFO    ] __main__: train step 5102: loss: 0.8991, policy_loss: 1.4844, value_loss: 0.8911
2024-07-14 05:27:39,513 [INFO    ] __main__: train step 5103: loss: 0.8992, policy_loss: 1.4844, value_loss: 0.8910
2024-07-14 05:27:39,787 [INFO    ] __main__: train step 5104: loss: 0.8993, policy_loss: 1.4843, value_loss: 0.8910
2024-07-14 05:27:40,048 [INFO    ] __main__: train step 5105: loss: 0.8994, policy_loss: 1.4842, value_loss: 0.8910
2024-07-14 05:27:40,316 [INFO    ] __main__: train step 5106: loss: 0.8995, policy_loss: 1.4841, value_loss: 0.8910
2024-07-14 05:27:40,570 [INFO    ] __main__: train step 5107: loss: 0.8996, policy_loss: 1.4840, value_loss: 0.8909
2024-07-14 05:27:40,842 [INFO    ] __main__: train step 5108: loss: 0.8997, policy_loss: 1.4839, value_loss: 0.8909
2024-07-14 05:27:41,135 [INFO    ] __main__: train step 5109: loss: 0.8998, policy_loss: 1.4838, value_loss: 0.8909
2024-07-14 05:27:41,424 [INFO    ] __main__: train step 5110: loss: 0.8999, policy_loss: 1.4837, value_loss: 0.8908
2024-07-14 05:27:41,723 [INFO    ] __main__: train step 5111: loss: 0.9000, policy_loss: 1.4836, value_loss: 0.8908
2024-07-14 05:27:42,004 [INFO    ] __main__: train step 5112: loss: 0.9001, policy_loss: 1.4835, value_loss: 0.8908
2024-07-14 05:27:42,290 [INFO    ] __main__: train step 5113: loss: 0.9002, policy_loss: 1.4834, value_loss: 0.8908
2024-07-14 05:27:43,879 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:27:44,359 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:27:44,423 [INFO    ] __main__: train step 5114: loss: 0.9003, policy_loss: 1.4833, value_loss: 0.8907
2024-07-14 05:27:44,701 [INFO    ] __main__: train step 5115: loss: 0.9004, policy_loss: 1.4833, value_loss: 0.8907
2024-07-14 05:27:44,975 [INFO    ] __main__: train step 5116: loss: 0.9005, policy_loss: 1.4832, value_loss: 0.8907
2024-07-14 05:27:45,255 [INFO    ] __main__: train step 5117: loss: 0.9006, policy_loss: 1.4831, value_loss: 0.8906
2024-07-14 05:27:45,532 [INFO    ] __main__: train step 5118: loss: 0.9007, policy_loss: 1.4830, value_loss: 0.8906
2024-07-14 05:27:45,803 [INFO    ] __main__: train step 5119: loss: 0.9008, policy_loss: 1.4829, value_loss: 0.8906
2024-07-14 05:27:47,452 [INFO    ] __main__: train step 5120: loss: 0.9009, policy_loss: 1.4828, value_loss: 0.8906
2024-07-14 05:27:47,732 [INFO    ] __main__: train step 5121: loss: 0.9010, policy_loss: 1.4827, value_loss: 0.8905
2024-07-14 05:27:48,020 [INFO    ] __main__: train step 5122: loss: 0.9011, policy_loss: 1.4826, value_loss: 0.8905
2024-07-14 05:27:48,300 [INFO    ] __main__: train step 5123: loss: 0.9012, policy_loss: 1.4825, value_loss: 0.8905
2024-07-14 05:27:48,562 [INFO    ] __main__: train step 5124: loss: 0.9013, policy_loss: 1.4824, value_loss: 0.8904
2024-07-14 05:27:48,848 [INFO    ] __main__: train step 5125: loss: 0.9014, policy_loss: 1.4823, value_loss: 0.8904
2024-07-14 05:27:49,114 [INFO    ] __main__: train step 5126: loss: 0.9015, policy_loss: 1.4822, value_loss: 0.8904
2024-07-14 05:27:49,381 [INFO    ] __main__: train step 5127: loss: 0.9016, policy_loss: 1.4821, value_loss: 0.8904
2024-07-14 05:27:49,653 [INFO    ] __main__: train step 5128: loss: 0.9017, policy_loss: 1.4820, value_loss: 0.8903
2024-07-14 05:27:49,968 [INFO    ] __main__: train step 5129: loss: 0.9018, policy_loss: 1.4820, value_loss: 0.8903
2024-07-14 05:27:50,236 [INFO    ] __main__: train step 5130: loss: 0.9020, policy_loss: 1.4819, value_loss: 0.8903
2024-07-14 05:27:51,823 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:27:52,304 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:27:52,371 [INFO    ] __main__: train step 5131: loss: 0.9021, policy_loss: 1.4818, value_loss: 0.8902
2024-07-14 05:27:52,647 [INFO    ] __main__: train step 5132: loss: 0.9022, policy_loss: 1.4817, value_loss: 0.8902
2024-07-14 05:27:52,905 [INFO    ] __main__: train step 5133: loss: 0.9023, policy_loss: 1.4816, value_loss: 0.8902
2024-07-14 05:27:53,179 [INFO    ] __main__: train step 5134: loss: 0.9024, policy_loss: 1.4815, value_loss: 0.8902
2024-07-14 05:27:53,453 [INFO    ] __main__: train step 5135: loss: 0.9025, policy_loss: 1.4814, value_loss: 0.8901
2024-07-14 05:27:53,734 [INFO    ] __main__: train step 5136: loss: 0.9026, policy_loss: 1.4813, value_loss: 0.8901
2024-07-14 05:27:54,009 [INFO    ] __main__: train step 5137: loss: 0.9027, policy_loss: 1.4812, value_loss: 0.8901
2024-07-14 05:27:54,293 [INFO    ] __main__: train step 5138: loss: 0.9028, policy_loss: 1.4811, value_loss: 0.8900
2024-07-14 05:27:54,579 [INFO    ] __main__: train step 5139: loss: 0.9029, policy_loss: 1.4810, value_loss: 0.8900
2024-07-14 05:27:54,852 [INFO    ] __main__: train step 5140: loss: 0.9030, policy_loss: 1.4810, value_loss: 0.8900
2024-07-14 05:27:55,171 [INFO    ] __main__: train step 5141: loss: 0.9031, policy_loss: 1.4809, value_loss: 0.8899
2024-07-14 05:27:55,455 [INFO    ] __main__: train step 5142: loss: 0.9032, policy_loss: 1.4808, value_loss: 0.8899
2024-07-14 05:27:55,753 [INFO    ] __main__: train step 5143: loss: 0.9033, policy_loss: 1.4807, value_loss: 0.8899
2024-07-14 05:27:56,031 [INFO    ] __main__: train step 5144: loss: 0.9034, policy_loss: 1.4806, value_loss: 0.8899
2024-07-14 05:27:56,307 [INFO    ] __main__: train step 5145: loss: 0.9035, policy_loss: 1.4805, value_loss: 0.8898
2024-07-14 05:27:56,583 [INFO    ] __main__: train step 5146: loss: 0.9036, policy_loss: 1.4804, value_loss: 0.8898
2024-07-14 05:27:56,857 [INFO    ] __main__: train step 5147: loss: 0.9037, policy_loss: 1.4803, value_loss: 0.8898
2024-07-14 05:27:58,441 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:27:58,923 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:27:58,994 [INFO    ] __main__: train step 5148: loss: 0.9038, policy_loss: 1.4802, value_loss: 0.8897
2024-07-14 05:27:59,274 [INFO    ] __main__: train step 5149: loss: 0.9039, policy_loss: 1.4801, value_loss: 0.8897
2024-07-14 05:27:59,555 [INFO    ] __main__: train step 5150: loss: 0.9040, policy_loss: 1.4800, value_loss: 0.8897
2024-07-14 05:27:59,833 [INFO    ] __main__: train step 5151: loss: 0.9041, policy_loss: 1.4799, value_loss: 0.8897
2024-07-14 05:28:00,117 [INFO    ] __main__: train step 5152: loss: 0.9042, policy_loss: 1.4798, value_loss: 0.8896
2024-07-14 05:28:00,386 [INFO    ] __main__: train step 5153: loss: 0.9043, policy_loss: 1.4797, value_loss: 0.8896
2024-07-14 05:28:00,663 [INFO    ] __main__: train step 5154: loss: 0.9044, policy_loss: 1.4797, value_loss: 0.8896
2024-07-14 05:28:00,944 [INFO    ] __main__: train step 5155: loss: 0.9045, policy_loss: 1.4796, value_loss: 0.8895
2024-07-14 05:28:01,238 [INFO    ] __main__: train step 5156: loss: 0.9046, policy_loss: 1.4795, value_loss: 0.8895
2024-07-14 05:28:01,526 [INFO    ] __main__: train step 5157: loss: 0.9047, policy_loss: 1.4794, value_loss: 0.8895
2024-07-14 05:28:01,815 [INFO    ] __main__: train step 5158: loss: 0.9048, policy_loss: 1.4793, value_loss: 0.8895
2024-07-14 05:28:02,111 [INFO    ] __main__: train step 5159: loss: 0.9049, policy_loss: 1.4792, value_loss: 0.8894
2024-07-14 05:28:02,394 [INFO    ] __main__: train step 5160: loss: 0.9050, policy_loss: 1.4791, value_loss: 0.8894
2024-07-14 05:28:02,669 [INFO    ] __main__: train step 5161: loss: 0.9051, policy_loss: 1.4790, value_loss: 0.8894
2024-07-14 05:28:02,951 [INFO    ] __main__: train step 5162: loss: 0.9052, policy_loss: 1.4789, value_loss: 0.8893
2024-07-14 05:28:03,221 [INFO    ] __main__: train step 5163: loss: 0.9053, policy_loss: 1.4788, value_loss: 0.8893
2024-07-14 05:28:03,490 [INFO    ] __main__: train step 5164: loss: 0.9054, policy_loss: 1.4787, value_loss: 0.8893
2024-07-14 05:28:05,095 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:28:05,547 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:28:05,612 [INFO    ] __main__: train step 5165: loss: 0.9055, policy_loss: 1.4786, value_loss: 0.8893
2024-07-14 05:28:05,872 [INFO    ] __main__: train step 5166: loss: 0.9056, policy_loss: 1.4786, value_loss: 0.8892
2024-07-14 05:28:06,154 [INFO    ] __main__: train step 5167: loss: 0.9057, policy_loss: 1.4785, value_loss: 0.8892
2024-07-14 05:28:06,431 [INFO    ] __main__: train step 5168: loss: 0.9058, policy_loss: 1.4784, value_loss: 0.8892
2024-07-14 05:28:06,699 [INFO    ] __main__: train step 5169: loss: 0.9059, policy_loss: 1.4783, value_loss: 0.8891
2024-07-14 05:28:06,980 [INFO    ] __main__: train step 5170: loss: 0.9060, policy_loss: 1.4782, value_loss: 0.8891
2024-07-14 05:28:07,250 [INFO    ] __main__: train step 5171: loss: 0.9061, policy_loss: 1.4781, value_loss: 0.8891
2024-07-14 05:28:07,546 [INFO    ] __main__: train step 5172: loss: 0.9062, policy_loss: 1.4780, value_loss: 0.8891
2024-07-14 05:28:07,819 [INFO    ] __main__: train step 5173: loss: 0.9063, policy_loss: 1.4779, value_loss: 0.8890
2024-07-14 05:28:08,087 [INFO    ] __main__: train step 5174: loss: 0.9064, policy_loss: 1.4778, value_loss: 0.8890
2024-07-14 05:28:08,355 [INFO    ] __main__: train step 5175: loss: 0.9065, policy_loss: 1.4777, value_loss: 0.8890
2024-07-14 05:28:09,948 [INFO    ] __main__: train step 5176: loss: 0.9066, policy_loss: 1.4777, value_loss: 0.8889
2024-07-14 05:28:10,253 [INFO    ] __main__: train step 5177: loss: 0.9067, policy_loss: 1.4776, value_loss: 0.8889
2024-07-14 05:28:10,553 [INFO    ] __main__: train step 5178: loss: 0.9068, policy_loss: 1.4775, value_loss: 0.8889
2024-07-14 05:28:10,850 [INFO    ] __main__: train step 5179: loss: 0.9070, policy_loss: 1.4774, value_loss: 0.8889
2024-07-14 05:28:11,150 [INFO    ] __main__: train step 5180: loss: 0.9071, policy_loss: 1.4773, value_loss: 0.8888
2024-07-14 05:28:11,436 [INFO    ] __main__: train step 5181: loss: 0.9072, policy_loss: 1.4772, value_loss: 0.8888
2024-07-14 05:28:13,040 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:28:13,524 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:28:13,594 [INFO    ] __main__: train step 5182: loss: 0.9072, policy_loss: 1.4771, value_loss: 0.8888
2024-07-14 05:28:13,877 [INFO    ] __main__: train step 5183: loss: 0.9073, policy_loss: 1.4770, value_loss: 0.8887
2024-07-14 05:28:14,165 [INFO    ] __main__: train step 5184: loss: 0.9074, policy_loss: 1.4769, value_loss: 0.8887
2024-07-14 05:28:14,445 [INFO    ] __main__: train step 5185: loss: 0.9076, policy_loss: 1.4768, value_loss: 0.8887
2024-07-14 05:28:14,736 [INFO    ] __main__: train step 5186: loss: 0.9077, policy_loss: 1.4768, value_loss: 0.8886
2024-07-14 05:28:15,028 [INFO    ] __main__: train step 5187: loss: 0.9078, policy_loss: 1.4767, value_loss: 0.8886
2024-07-14 05:28:15,314 [INFO    ] __main__: train step 5188: loss: 0.9079, policy_loss: 1.4766, value_loss: 0.8886
2024-07-14 05:28:15,598 [INFO    ] __main__: train step 5189: loss: 0.9079, policy_loss: 1.4765, value_loss: 0.8886
2024-07-14 05:28:15,868 [INFO    ] __main__: train step 5190: loss: 0.9081, policy_loss: 1.4764, value_loss: 0.8885
2024-07-14 05:28:16,147 [INFO    ] __main__: train step 5191: loss: 0.9082, policy_loss: 1.4763, value_loss: 0.8885
2024-07-14 05:28:16,436 [INFO    ] __main__: train step 5192: loss: 0.9082, policy_loss: 1.4762, value_loss: 0.8885
2024-07-14 05:28:16,712 [INFO    ] __main__: train step 5193: loss: 0.9084, policy_loss: 1.4761, value_loss: 0.8885
2024-07-14 05:28:16,997 [INFO    ] __main__: train step 5194: loss: 0.9085, policy_loss: 1.4760, value_loss: 0.8884
2024-07-14 05:28:17,292 [INFO    ] __main__: train step 5195: loss: 0.9086, policy_loss: 1.4759, value_loss: 0.8884
2024-07-14 05:28:17,563 [INFO    ] __main__: train step 5196: loss: 0.9087, policy_loss: 1.4758, value_loss: 0.8884
2024-07-14 05:28:17,843 [INFO    ] __main__: train step 5197: loss: 0.9088, policy_loss: 1.4757, value_loss: 0.8883
2024-07-14 05:28:18,131 [INFO    ] __main__: train step 5198: loss: 0.9089, policy_loss: 1.4757, value_loss: 0.8883
2024-07-14 05:28:19,737 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:28:20,217 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:28:20,288 [INFO    ] __main__: train step 5199: loss: 0.9090, policy_loss: 1.4756, value_loss: 0.8883
2024-07-14 05:28:20,575 [INFO    ] __main__: train step 5200: loss: 0.9091, policy_loss: 1.4755, value_loss: 0.8882
2024-07-14 05:28:20,859 [INFO    ] __main__: train step 5201: loss: 0.9092, policy_loss: 1.4754, value_loss: 0.8882
2024-07-14 05:28:21,139 [INFO    ] __main__: train step 5202: loss: 0.9093, policy_loss: 1.4753, value_loss: 0.8882
2024-07-14 05:28:21,429 [INFO    ] __main__: train step 5203: loss: 0.9094, policy_loss: 1.4752, value_loss: 0.8881
2024-07-14 05:28:21,698 [INFO    ] __main__: train step 5204: loss: 0.9094, policy_loss: 1.4751, value_loss: 0.8881
2024-07-14 05:28:21,973 [INFO    ] __main__: train step 5205: loss: 0.9095, policy_loss: 1.4750, value_loss: 0.8881
2024-07-14 05:28:22,247 [INFO    ] __main__: train step 5206: loss: 0.9097, policy_loss: 1.4749, value_loss: 0.8881
2024-07-14 05:28:22,520 [INFO    ] __main__: train step 5207: loss: 0.9098, policy_loss: 1.4748, value_loss: 0.8880
2024-07-14 05:28:22,812 [INFO    ] __main__: train step 5208: loss: 0.9099, policy_loss: 1.4747, value_loss: 0.8880
2024-07-14 05:28:23,098 [INFO    ] __main__: train step 5209: loss: 0.9100, policy_loss: 1.4747, value_loss: 0.8880
2024-07-14 05:28:23,393 [INFO    ] __main__: train step 5210: loss: 0.9101, policy_loss: 1.4746, value_loss: 0.8880
2024-07-14 05:28:23,671 [INFO    ] __main__: train step 5211: loss: 0.9102, policy_loss: 1.4745, value_loss: 0.8879
2024-07-14 05:28:23,952 [INFO    ] __main__: train step 5212: loss: 0.9103, policy_loss: 1.4744, value_loss: 0.8879
2024-07-14 05:28:24,220 [INFO    ] __main__: train step 5213: loss: 0.9104, policy_loss: 1.4743, value_loss: 0.8879
2024-07-14 05:28:24,503 [INFO    ] __main__: train step 5214: loss: 0.9105, policy_loss: 1.4742, value_loss: 0.8878
2024-07-14 05:28:24,789 [INFO    ] __main__: train step 5215: loss: 0.9106, policy_loss: 1.4741, value_loss: 0.8878
2024-07-14 05:28:26,400 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:28:26,892 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:28:26,967 [INFO    ] __main__: train step 5216: loss: 0.9107, policy_loss: 1.4740, value_loss: 0.8878
2024-07-14 05:28:27,228 [INFO    ] __main__: train step 5217: loss: 0.9108, policy_loss: 1.4739, value_loss: 0.8878
2024-07-14 05:28:27,488 [INFO    ] __main__: train step 5218: loss: 0.9109, policy_loss: 1.4739, value_loss: 0.8877
2024-07-14 05:28:27,763 [INFO    ] __main__: train step 5219: loss: 0.9110, policy_loss: 1.4738, value_loss: 0.8877
2024-07-14 05:28:28,044 [INFO    ] __main__: train step 5220: loss: 0.9111, policy_loss: 1.4737, value_loss: 0.8877
2024-07-14 05:28:28,312 [INFO    ] __main__: train step 5221: loss: 0.9112, policy_loss: 1.4736, value_loss: 0.8876
2024-07-14 05:28:28,586 [INFO    ] __main__: train step 5222: loss: 0.9113, policy_loss: 1.4735, value_loss: 0.8876
2024-07-14 05:28:28,874 [INFO    ] __main__: train step 5223: loss: 0.9114, policy_loss: 1.4734, value_loss: 0.8876
2024-07-14 05:28:29,147 [INFO    ] __main__: train step 5224: loss: 0.9115, policy_loss: 1.4733, value_loss: 0.8876
2024-07-14 05:28:29,426 [INFO    ] __main__: train step 5225: loss: 0.9116, policy_loss: 1.4732, value_loss: 0.8875
2024-07-14 05:28:29,695 [INFO    ] __main__: train step 5226: loss: 0.9117, policy_loss: 1.4731, value_loss: 0.8875
2024-07-14 05:28:29,987 [INFO    ] __main__: train step 5227: loss: 0.9118, policy_loss: 1.4730, value_loss: 0.8875
2024-07-14 05:28:30,267 [INFO    ] __main__: train step 5228: loss: 0.9119, policy_loss: 1.4729, value_loss: 0.8874
2024-07-14 05:28:30,542 [INFO    ] __main__: train step 5229: loss: 0.9120, policy_loss: 1.4729, value_loss: 0.8874
2024-07-14 05:28:32,441 [INFO    ] __main__: train step 5230: loss: 0.9121, policy_loss: 1.4728, value_loss: 0.8874
2024-07-14 05:28:32,726 [INFO    ] __main__: train step 5231: loss: 0.9122, policy_loss: 1.4727, value_loss: 0.8874
2024-07-14 05:28:33,009 [INFO    ] __main__: train step 5232: loss: 0.9123, policy_loss: 1.4726, value_loss: 0.8873
2024-07-14 05:28:34,618 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:28:35,116 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:28:35,188 [INFO    ] __main__: train step 5233: loss: 0.9124, policy_loss: 1.4725, value_loss: 0.8873
2024-07-14 05:28:35,462 [INFO    ] __main__: train step 5234: loss: 0.9125, policy_loss: 1.4724, value_loss: 0.8873
2024-07-14 05:28:35,738 [INFO    ] __main__: train step 5235: loss: 0.9126, policy_loss: 1.4723, value_loss: 0.8872
2024-07-14 05:28:36,018 [INFO    ] __main__: train step 5236: loss: 0.9127, policy_loss: 1.4722, value_loss: 0.8872
2024-07-14 05:28:36,299 [INFO    ] __main__: train step 5237: loss: 0.9128, policy_loss: 1.4721, value_loss: 0.8872
2024-07-14 05:28:36,590 [INFO    ] __main__: train step 5238: loss: 0.9129, policy_loss: 1.4721, value_loss: 0.8872
2024-07-14 05:28:36,876 [INFO    ] __main__: train step 5239: loss: 0.9130, policy_loss: 1.4720, value_loss: 0.8871
2024-07-14 05:28:37,167 [INFO    ] __main__: train step 5240: loss: 0.9131, policy_loss: 1.4719, value_loss: 0.8871
2024-07-14 05:28:37,461 [INFO    ] __main__: train step 5241: loss: 0.9132, policy_loss: 1.4718, value_loss: 0.8871
2024-07-14 05:28:37,745 [INFO    ] __main__: train step 5242: loss: 0.9133, policy_loss: 1.4717, value_loss: 0.8870
2024-07-14 05:28:38,032 [INFO    ] __main__: train step 5243: loss: 0.9134, policy_loss: 1.4716, value_loss: 0.8870
2024-07-14 05:28:38,308 [INFO    ] __main__: train step 5244: loss: 0.9135, policy_loss: 1.4715, value_loss: 0.8870
2024-07-14 05:28:38,590 [INFO    ] __main__: train step 5245: loss: 0.9136, policy_loss: 1.4714, value_loss: 0.8870
2024-07-14 05:28:38,877 [INFO    ] __main__: train step 5246: loss: 0.9137, policy_loss: 1.4713, value_loss: 0.8869
2024-07-14 05:28:39,159 [INFO    ] __main__: train step 5247: loss: 0.9138, policy_loss: 1.4712, value_loss: 0.8869
2024-07-14 05:28:39,439 [INFO    ] __main__: train step 5248: loss: 0.9139, policy_loss: 1.4712, value_loss: 0.8869
2024-07-14 05:28:39,728 [INFO    ] __main__: train step 5249: loss: 0.9140, policy_loss: 1.4711, value_loss: 0.8868
2024-07-14 05:28:41,332 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:28:41,805 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:28:41,874 [INFO    ] __main__: train step 5250: loss: 0.9141, policy_loss: 1.4710, value_loss: 0.8868
2024-07-14 05:28:42,157 [INFO    ] __main__: train step 5251: loss: 0.9142, policy_loss: 1.4709, value_loss: 0.8868
2024-07-14 05:28:42,440 [INFO    ] __main__: train step 5252: loss: 0.9143, policy_loss: 1.4708, value_loss: 0.8867
2024-07-14 05:28:42,723 [INFO    ] __main__: train step 5253: loss: 0.9144, policy_loss: 1.4707, value_loss: 0.8867
2024-07-14 05:28:42,996 [INFO    ] __main__: train step 5254: loss: 0.9145, policy_loss: 1.4706, value_loss: 0.8867
2024-07-14 05:28:43,278 [INFO    ] __main__: train step 5255: loss: 0.9146, policy_loss: 1.4705, value_loss: 0.8867
2024-07-14 05:28:43,559 [INFO    ] __main__: train step 5256: loss: 0.9147, policy_loss: 1.4704, value_loss: 0.8866
2024-07-14 05:28:43,841 [INFO    ] __main__: train step 5257: loss: 0.9148, policy_loss: 1.4704, value_loss: 0.8866
2024-07-14 05:28:44,125 [INFO    ] __main__: train step 5258: loss: 0.9149, policy_loss: 1.4703, value_loss: 0.8866
2024-07-14 05:28:44,402 [INFO    ] __main__: train step 5259: loss: 0.9150, policy_loss: 1.4702, value_loss: 0.8865
2024-07-14 05:28:44,685 [INFO    ] __main__: train step 5260: loss: 0.9151, policy_loss: 1.4701, value_loss: 0.8865
2024-07-14 05:28:44,957 [INFO    ] __main__: train step 5261: loss: 0.9152, policy_loss: 1.4700, value_loss: 0.8865
2024-07-14 05:28:45,237 [INFO    ] __main__: train step 5262: loss: 0.9153, policy_loss: 1.4699, value_loss: 0.8865
2024-07-14 05:28:45,520 [INFO    ] __main__: train step 5263: loss: 0.9154, policy_loss: 1.4698, value_loss: 0.8864
2024-07-14 05:28:45,798 [INFO    ] __main__: train step 5264: loss: 0.9155, policy_loss: 1.4697, value_loss: 0.8864
2024-07-14 05:28:46,071 [INFO    ] __main__: train step 5265: loss: 0.9156, policy_loss: 1.4696, value_loss: 0.8864
2024-07-14 05:28:46,344 [INFO    ] __main__: train step 5266: loss: 0.9157, policy_loss: 1.4695, value_loss: 0.8863
2024-07-14 05:28:47,939 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:28:48,423 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:28:48,495 [INFO    ] __main__: train step 5267: loss: 0.9158, policy_loss: 1.4695, value_loss: 0.8863
2024-07-14 05:28:48,781 [INFO    ] __main__: train step 5268: loss: 0.9159, policy_loss: 1.4694, value_loss: 0.8863
2024-07-14 05:28:49,069 [INFO    ] __main__: train step 5269: loss: 0.9160, policy_loss: 1.4693, value_loss: 0.8862
2024-07-14 05:28:49,337 [INFO    ] __main__: train step 5270: loss: 0.9161, policy_loss: 1.4692, value_loss: 0.8862
2024-07-14 05:28:49,612 [INFO    ] __main__: train step 5271: loss: 0.9162, policy_loss: 1.4691, value_loss: 0.8862
2024-07-14 05:28:49,937 [INFO    ] __main__: train step 5272: loss: 0.9163, policy_loss: 1.4690, value_loss: 0.8862
2024-07-14 05:28:50,219 [INFO    ] __main__: train step 5273: loss: 0.9164, policy_loss: 1.4689, value_loss: 0.8861
2024-07-14 05:28:50,514 [INFO    ] __main__: train step 5274: loss: 0.9165, policy_loss: 1.4688, value_loss: 0.8861
2024-07-14 05:28:50,810 [INFO    ] __main__: train step 5275: loss: 0.9166, policy_loss: 1.4687, value_loss: 0.8861
2024-07-14 05:28:51,098 [INFO    ] __main__: train step 5276: loss: 0.9167, policy_loss: 1.4687, value_loss: 0.8860
2024-07-14 05:28:51,387 [INFO    ] __main__: train step 5277: loss: 0.9168, policy_loss: 1.4686, value_loss: 0.8860
2024-07-14 05:28:51,666 [INFO    ] __main__: train step 5278: loss: 0.9169, policy_loss: 1.4685, value_loss: 0.8860
2024-07-14 05:28:51,944 [INFO    ] __main__: train step 5279: loss: 0.9170, policy_loss: 1.4684, value_loss: 0.8860
2024-07-14 05:28:52,213 [INFO    ] __main__: train step 5280: loss: 0.9171, policy_loss: 1.4683, value_loss: 0.8859
2024-07-14 05:28:52,490 [INFO    ] __main__: train step 5281: loss: 0.9172, policy_loss: 1.4682, value_loss: 0.8859
2024-07-14 05:28:52,814 [INFO    ] __main__: train step 5282: loss: 0.9173, policy_loss: 1.4681, value_loss: 0.8859
2024-07-14 05:28:53,116 [INFO    ] __main__: train step 5283: loss: 0.9174, policy_loss: 1.4680, value_loss: 0.8858
2024-07-14 05:28:56,304 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:28:56,789 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:28:56,859 [INFO    ] __main__: train step 5284: loss: 0.9175, policy_loss: 1.4679, value_loss: 0.8858
2024-07-14 05:28:57,141 [INFO    ] __main__: train step 5285: loss: 0.9176, policy_loss: 1.4679, value_loss: 0.8858
2024-07-14 05:28:57,421 [INFO    ] __main__: train step 5286: loss: 0.9177, policy_loss: 1.4678, value_loss: 0.8857
2024-07-14 05:28:57,707 [INFO    ] __main__: train step 5287: loss: 0.9178, policy_loss: 1.4677, value_loss: 0.8857
2024-07-14 05:28:57,981 [INFO    ] __main__: train step 5288: loss: 0.9179, policy_loss: 1.4676, value_loss: 0.8857
2024-07-14 05:28:58,256 [INFO    ] __main__: train step 5289: loss: 0.9180, policy_loss: 1.4675, value_loss: 0.8857
2024-07-14 05:28:58,544 [INFO    ] __main__: train step 5290: loss: 0.9181, policy_loss: 1.4674, value_loss: 0.8856
2024-07-14 05:28:58,821 [INFO    ] __main__: train step 5291: loss: 0.9182, policy_loss: 1.4673, value_loss: 0.8856
2024-07-14 05:28:59,098 [INFO    ] __main__: train step 5292: loss: 0.9183, policy_loss: 1.4672, value_loss: 0.8856
2024-07-14 05:28:59,360 [INFO    ] __main__: train step 5293: loss: 0.9184, policy_loss: 1.4672, value_loss: 0.8856
2024-07-14 05:28:59,633 [INFO    ] __main__: train step 5294: loss: 0.9185, policy_loss: 1.4671, value_loss: 0.8855
2024-07-14 05:28:59,896 [INFO    ] __main__: train step 5295: loss: 0.9186, policy_loss: 1.4670, value_loss: 0.8855
2024-07-14 05:29:00,170 [INFO    ] __main__: train step 5296: loss: 0.9187, policy_loss: 1.4669, value_loss: 0.8855
2024-07-14 05:29:00,436 [INFO    ] __main__: train step 5297: loss: 0.9188, policy_loss: 1.4668, value_loss: 0.8854
2024-07-14 05:29:00,708 [INFO    ] __main__: train step 5298: loss: 0.9189, policy_loss: 1.4667, value_loss: 0.8854
2024-07-14 05:29:00,974 [INFO    ] __main__: train step 5299: loss: 0.9190, policy_loss: 1.4666, value_loss: 0.8854
2024-07-14 05:29:01,252 [INFO    ] __main__: train step 5300: loss: 0.9191, policy_loss: 1.4665, value_loss: 0.8853
2024-07-14 05:29:02,845 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:29:03,320 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:29:03,389 [INFO    ] __main__: train step 5301: loss: 0.9192, policy_loss: 1.4665, value_loss: 0.8853
2024-07-14 05:29:03,666 [INFO    ] __main__: train step 5302: loss: 0.9193, policy_loss: 1.4664, value_loss: 0.8853
2024-07-14 05:29:03,946 [INFO    ] __main__: train step 5303: loss: 0.9194, policy_loss: 1.4663, value_loss: 0.8853
2024-07-14 05:29:04,221 [INFO    ] __main__: train step 5304: loss: 0.9195, policy_loss: 1.4662, value_loss: 0.8852
2024-07-14 05:29:04,488 [INFO    ] __main__: train step 5305: loss: 0.9196, policy_loss: 1.4661, value_loss: 0.8852
2024-07-14 05:29:04,780 [INFO    ] __main__: train step 5306: loss: 0.9197, policy_loss: 1.4660, value_loss: 0.8852
2024-07-14 05:29:05,069 [INFO    ] __main__: train step 5307: loss: 0.9198, policy_loss: 1.4659, value_loss: 0.8851
2024-07-14 05:29:05,348 [INFO    ] __main__: train step 5308: loss: 0.9199, policy_loss: 1.4658, value_loss: 0.8851
2024-07-14 05:29:05,617 [INFO    ] __main__: train step 5309: loss: 0.9200, policy_loss: 1.4657, value_loss: 0.8851
2024-07-14 05:29:05,894 [INFO    ] __main__: train step 5310: loss: 0.9201, policy_loss: 1.4657, value_loss: 0.8851
2024-07-14 05:29:06,183 [INFO    ] __main__: train step 5311: loss: 0.9202, policy_loss: 1.4656, value_loss: 0.8850
2024-07-14 05:29:06,474 [INFO    ] __main__: train step 5312: loss: 0.9203, policy_loss: 1.4655, value_loss: 0.8850
2024-07-14 05:29:06,755 [INFO    ] __main__: train step 5313: loss: 0.9204, policy_loss: 1.4654, value_loss: 0.8850
2024-07-14 05:29:07,028 [INFO    ] __main__: train step 5314: loss: 0.9205, policy_loss: 1.4653, value_loss: 0.8849
2024-07-14 05:29:07,313 [INFO    ] __main__: train step 5315: loss: 0.9206, policy_loss: 1.4652, value_loss: 0.8849
2024-07-14 05:29:07,577 [INFO    ] __main__: train step 5316: loss: 0.9207, policy_loss: 1.4651, value_loss: 0.8849
2024-07-14 05:29:07,857 [INFO    ] __main__: train step 5317: loss: 0.9208, policy_loss: 1.4650, value_loss: 0.8849
2024-07-14 05:29:09,465 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:29:09,939 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:29:10,004 [INFO    ] __main__: train step 5318: loss: 0.9208, policy_loss: 1.4649, value_loss: 0.8848
2024-07-14 05:29:10,298 [INFO    ] __main__: train step 5319: loss: 0.9209, policy_loss: 1.4649, value_loss: 0.8848
2024-07-14 05:29:10,570 [INFO    ] __main__: train step 5320: loss: 0.9210, policy_loss: 1.4648, value_loss: 0.8848
2024-07-14 05:29:10,840 [INFO    ] __main__: train step 5321: loss: 0.9212, policy_loss: 1.4647, value_loss: 0.8847
2024-07-14 05:29:11,124 [INFO    ] __main__: train step 5322: loss: 0.9213, policy_loss: 1.4646, value_loss: 0.8847
2024-07-14 05:29:11,412 [INFO    ] __main__: train step 5323: loss: 0.9214, policy_loss: 1.4645, value_loss: 0.8847
2024-07-14 05:29:11,684 [INFO    ] __main__: train step 5324: loss: 0.9215, policy_loss: 1.4644, value_loss: 0.8847
2024-07-14 05:29:11,972 [INFO    ] __main__: train step 5325: loss: 0.9216, policy_loss: 1.4643, value_loss: 0.8846
2024-07-14 05:29:12,252 [INFO    ] __main__: train step 5326: loss: 0.9217, policy_loss: 1.4642, value_loss: 0.8846
2024-07-14 05:29:12,538 [INFO    ] __main__: train step 5327: loss: 0.9218, policy_loss: 1.4642, value_loss: 0.8846
2024-07-14 05:29:12,818 [INFO    ] __main__: train step 5328: loss: 0.9218, policy_loss: 1.4641, value_loss: 0.8845
2024-07-14 05:29:13,093 [INFO    ] __main__: train step 5329: loss: 0.9220, policy_loss: 1.4640, value_loss: 0.8845
2024-07-14 05:29:13,376 [INFO    ] __main__: train step 5330: loss: 0.9220, policy_loss: 1.4639, value_loss: 0.8845
2024-07-14 05:29:13,657 [INFO    ] __main__: train step 5331: loss: 0.9221, policy_loss: 1.4638, value_loss: 0.8845
2024-07-14 05:29:13,941 [INFO    ] __main__: train step 5332: loss: 0.9222, policy_loss: 1.4637, value_loss: 0.8844
2024-07-14 05:29:14,223 [INFO    ] __main__: train step 5333: loss: 0.9223, policy_loss: 1.4636, value_loss: 0.8844
2024-07-14 05:29:14,499 [INFO    ] __main__: train step 5334: loss: 0.9224, policy_loss: 1.4635, value_loss: 0.8844
2024-07-14 05:29:16,085 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:29:16,562 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:29:16,628 [INFO    ] __main__: train step 5335: loss: 0.9225, policy_loss: 1.4635, value_loss: 0.8843
2024-07-14 05:29:16,915 [INFO    ] __main__: train step 5336: loss: 0.9226, policy_loss: 1.4634, value_loss: 0.8843
2024-07-14 05:29:17,189 [INFO    ] __main__: train step 5337: loss: 0.9227, policy_loss: 1.4633, value_loss: 0.8843
2024-07-14 05:29:17,475 [INFO    ] __main__: train step 5338: loss: 0.9228, policy_loss: 1.4632, value_loss: 0.8843
2024-07-14 05:29:19,302 [INFO    ] __main__: train step 5339: loss: 0.9229, policy_loss: 1.4631, value_loss: 0.8842
2024-07-14 05:29:19,579 [INFO    ] __main__: train step 5340: loss: 0.9230, policy_loss: 1.4630, value_loss: 0.8842
2024-07-14 05:29:19,853 [INFO    ] __main__: train step 5341: loss: 0.9231, policy_loss: 1.4629, value_loss: 0.8842
2024-07-14 05:29:20,136 [INFO    ] __main__: train step 5342: loss: 0.9232, policy_loss: 1.4628, value_loss: 0.8841
2024-07-14 05:29:20,406 [INFO    ] __main__: train step 5343: loss: 0.9233, policy_loss: 1.4628, value_loss: 0.8841
2024-07-14 05:29:20,715 [INFO    ] __main__: train step 5344: loss: 0.9234, policy_loss: 1.4627, value_loss: 0.8841
2024-07-14 05:29:20,968 [INFO    ] __main__: train step 5345: loss: 0.9235, policy_loss: 1.4626, value_loss: 0.8841
2024-07-14 05:29:21,243 [INFO    ] __main__: train step 5346: loss: 0.9236, policy_loss: 1.4625, value_loss: 0.8840
2024-07-14 05:29:21,519 [INFO    ] __main__: train step 5347: loss: 0.9237, policy_loss: 1.4624, value_loss: 0.8840
2024-07-14 05:29:21,803 [INFO    ] __main__: train step 5348: loss: 0.9238, policy_loss: 1.4623, value_loss: 0.8840
2024-07-14 05:29:22,080 [INFO    ] __main__: train step 5349: loss: 0.9239, policy_loss: 1.4622, value_loss: 0.8839
2024-07-14 05:29:22,358 [INFO    ] __main__: train step 5350: loss: 0.9240, policy_loss: 1.4621, value_loss: 0.8839
2024-07-14 05:29:22,621 [INFO    ] __main__: train step 5351: loss: 0.9241, policy_loss: 1.4620, value_loss: 0.8839
2024-07-14 05:29:24,194 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:29:24,680 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:29:24,745 [INFO    ] __main__: train step 5352: loss: 0.9242, policy_loss: 1.4620, value_loss: 0.8838
2024-07-14 05:29:25,020 [INFO    ] __main__: train step 5353: loss: 0.9243, policy_loss: 1.4619, value_loss: 0.8838
2024-07-14 05:29:25,298 [INFO    ] __main__: train step 5354: loss: 0.9244, policy_loss: 1.4618, value_loss: 0.8838
2024-07-14 05:29:25,586 [INFO    ] __main__: train step 5355: loss: 0.9245, policy_loss: 1.4617, value_loss: 0.8838
2024-07-14 05:29:25,866 [INFO    ] __main__: train step 5356: loss: 0.9246, policy_loss: 1.4616, value_loss: 0.8837
2024-07-14 05:29:26,143 [INFO    ] __main__: train step 5357: loss: 0.9247, policy_loss: 1.4615, value_loss: 0.8837
2024-07-14 05:29:26,425 [INFO    ] __main__: train step 5358: loss: 0.9248, policy_loss: 1.4614, value_loss: 0.8837
2024-07-14 05:29:26,694 [INFO    ] __main__: train step 5359: loss: 0.9249, policy_loss: 1.4613, value_loss: 0.8836
2024-07-14 05:29:26,980 [INFO    ] __main__: train step 5360: loss: 0.9250, policy_loss: 1.4612, value_loss: 0.8836
2024-07-14 05:29:27,252 [INFO    ] __main__: train step 5361: loss: 0.9251, policy_loss: 1.4612, value_loss: 0.8836
2024-07-14 05:29:27,525 [INFO    ] __main__: train step 5362: loss: 0.9252, policy_loss: 1.4611, value_loss: 0.8836
2024-07-14 05:29:27,802 [INFO    ] __main__: train step 5363: loss: 0.9253, policy_loss: 1.4610, value_loss: 0.8835
2024-07-14 05:29:28,076 [INFO    ] __main__: train step 5364: loss: 0.9254, policy_loss: 1.4609, value_loss: 0.8835
2024-07-14 05:29:28,350 [INFO    ] __main__: train step 5365: loss: 0.9255, policy_loss: 1.4608, value_loss: 0.8835
2024-07-14 05:29:28,627 [INFO    ] __main__: train step 5366: loss: 0.9256, policy_loss: 1.4607, value_loss: 0.8834
2024-07-14 05:29:28,903 [INFO    ] __main__: train step 5367: loss: 0.9257, policy_loss: 1.4606, value_loss: 0.8834
2024-07-14 05:29:29,178 [INFO    ] __main__: train step 5368: loss: 0.9258, policy_loss: 1.4605, value_loss: 0.8834
2024-07-14 05:29:30,767 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:29:31,230 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:29:31,295 [INFO    ] __main__: train step 5369: loss: 0.9259, policy_loss: 1.4604, value_loss: 0.8834
2024-07-14 05:29:31,574 [INFO    ] __main__: train step 5370: loss: 0.9260, policy_loss: 1.4604, value_loss: 0.8833
2024-07-14 05:29:31,870 [INFO    ] __main__: train step 5371: loss: 0.9261, policy_loss: 1.4603, value_loss: 0.8833
2024-07-14 05:29:32,136 [INFO    ] __main__: train step 5372: loss: 0.9262, policy_loss: 1.4602, value_loss: 0.8833
2024-07-14 05:29:32,424 [INFO    ] __main__: train step 5373: loss: 0.9263, policy_loss: 1.4601, value_loss: 0.8832
2024-07-14 05:29:32,715 [INFO    ] __main__: train step 5374: loss: 0.9264, policy_loss: 1.4600, value_loss: 0.8832
2024-07-14 05:29:33,003 [INFO    ] __main__: train step 5375: loss: 0.9265, policy_loss: 1.4599, value_loss: 0.8832
2024-07-14 05:29:33,282 [INFO    ] __main__: train step 5376: loss: 0.9266, policy_loss: 1.4598, value_loss: 0.8832
2024-07-14 05:29:33,569 [INFO    ] __main__: train step 5377: loss: 0.9267, policy_loss: 1.4597, value_loss: 0.8831
2024-07-14 05:29:33,846 [INFO    ] __main__: train step 5378: loss: 0.9267, policy_loss: 1.4597, value_loss: 0.8831
2024-07-14 05:29:34,125 [INFO    ] __main__: train step 5379: loss: 0.9268, policy_loss: 1.4596, value_loss: 0.8831
2024-07-14 05:29:34,399 [INFO    ] __main__: train step 5380: loss: 0.9269, policy_loss: 1.4595, value_loss: 0.8830
2024-07-14 05:29:34,678 [INFO    ] __main__: train step 5381: loss: 0.9270, policy_loss: 1.4594, value_loss: 0.8830
2024-07-14 05:29:34,965 [INFO    ] __main__: train step 5382: loss: 0.9271, policy_loss: 1.4593, value_loss: 0.8830
2024-07-14 05:29:35,252 [INFO    ] __main__: train step 5383: loss: 0.9272, policy_loss: 1.4592, value_loss: 0.8830
2024-07-14 05:29:35,531 [INFO    ] __main__: train step 5384: loss: 0.9273, policy_loss: 1.4591, value_loss: 0.8829
2024-07-14 05:29:35,811 [INFO    ] __main__: train step 5385: loss: 0.9274, policy_loss: 1.4590, value_loss: 0.8829
2024-07-14 05:29:37,405 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:29:37,895 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:29:37,962 [INFO    ] __main__: train step 5386: loss: 0.9275, policy_loss: 1.4590, value_loss: 0.8829
2024-07-14 05:29:38,269 [INFO    ] __main__: train step 5387: loss: 0.9276, policy_loss: 1.4589, value_loss: 0.8828
2024-07-14 05:29:38,561 [INFO    ] __main__: train step 5388: loss: 0.9277, policy_loss: 1.4588, value_loss: 0.8828
2024-07-14 05:29:38,842 [INFO    ] __main__: train step 5389: loss: 0.9278, policy_loss: 1.4587, value_loss: 0.8828
2024-07-14 05:29:39,118 [INFO    ] __main__: train step 5390: loss: 0.9279, policy_loss: 1.4586, value_loss: 0.8828
2024-07-14 05:29:39,403 [INFO    ] __main__: train step 5391: loss: 0.9280, policy_loss: 1.4585, value_loss: 0.8827
2024-07-14 05:29:39,687 [INFO    ] __main__: train step 5392: loss: 0.9281, policy_loss: 1.4584, value_loss: 0.8827
2024-07-14 05:29:39,965 [INFO    ] __main__: train step 5393: loss: 0.9282, policy_loss: 1.4583, value_loss: 0.8827
2024-07-14 05:29:41,780 [INFO    ] __main__: train step 5394: loss: 0.9283, policy_loss: 1.4582, value_loss: 0.8826
2024-07-14 05:29:42,046 [INFO    ] __main__: train step 5395: loss: 0.9284, policy_loss: 1.4582, value_loss: 0.8826
2024-07-14 05:29:42,322 [INFO    ] __main__: train step 5396: loss: 0.9285, policy_loss: 1.4581, value_loss: 0.8826
2024-07-14 05:29:42,588 [INFO    ] __main__: train step 5397: loss: 0.9286, policy_loss: 1.4580, value_loss: 0.8825
2024-07-14 05:29:42,871 [INFO    ] __main__: train step 5398: loss: 0.9287, policy_loss: 1.4579, value_loss: 0.8825
2024-07-14 05:29:43,135 [INFO    ] __main__: train step 5399: loss: 0.9288, policy_loss: 1.4578, value_loss: 0.8825
2024-07-14 05:29:43,401 [INFO    ] __main__: train step 5400: loss: 0.9289, policy_loss: 1.4577, value_loss: 0.8825
2024-07-14 05:29:43,680 [INFO    ] __main__: train step 5401: loss: 0.9290, policy_loss: 1.4576, value_loss: 0.8824
2024-07-14 05:29:43,947 [INFO    ] __main__: train step 5402: loss: 0.9291, policy_loss: 1.4575, value_loss: 0.8824
2024-07-14 05:29:45,547 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:29:46,033 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:29:46,102 [INFO    ] __main__: train step 5403: loss: 0.9292, policy_loss: 1.4574, value_loss: 0.8824
2024-07-14 05:29:46,399 [INFO    ] __main__: train step 5404: loss: 0.9293, policy_loss: 1.4574, value_loss: 0.8823
2024-07-14 05:29:46,686 [INFO    ] __main__: train step 5405: loss: 0.9294, policy_loss: 1.4573, value_loss: 0.8823
2024-07-14 05:29:46,990 [INFO    ] __main__: train step 5406: loss: 0.9295, policy_loss: 1.4572, value_loss: 0.8823
2024-07-14 05:29:47,299 [INFO    ] __main__: train step 5407: loss: 0.9296, policy_loss: 1.4571, value_loss: 0.8823
2024-07-14 05:29:47,587 [INFO    ] __main__: train step 5408: loss: 0.9297, policy_loss: 1.4570, value_loss: 0.8822
2024-07-14 05:29:47,884 [INFO    ] __main__: train step 5409: loss: 0.9298, policy_loss: 1.4569, value_loss: 0.8822
2024-07-14 05:29:48,180 [INFO    ] __main__: train step 5410: loss: 0.9299, policy_loss: 1.4568, value_loss: 0.8822
2024-07-14 05:29:48,487 [INFO    ] __main__: train step 5411: loss: 0.9299, policy_loss: 1.4567, value_loss: 0.8821
2024-07-14 05:29:48,792 [INFO    ] __main__: train step 5412: loss: 0.9300, policy_loss: 1.4566, value_loss: 0.8821
2024-07-14 05:29:49,092 [INFO    ] __main__: train step 5413: loss: 0.9301, policy_loss: 1.4566, value_loss: 0.8821
2024-07-14 05:29:49,392 [INFO    ] __main__: train step 5414: loss: 0.9302, policy_loss: 1.4565, value_loss: 0.8821
2024-07-14 05:29:49,685 [INFO    ] __main__: train step 5415: loss: 0.9303, policy_loss: 1.4564, value_loss: 0.8820
2024-07-14 05:29:49,987 [INFO    ] __main__: train step 5416: loss: 0.9304, policy_loss: 1.4563, value_loss: 0.8820
2024-07-14 05:29:50,295 [INFO    ] __main__: train step 5417: loss: 0.9305, policy_loss: 1.4562, value_loss: 0.8820
2024-07-14 05:29:50,590 [INFO    ] __main__: train step 5418: loss: 0.9306, policy_loss: 1.4561, value_loss: 0.8819
2024-07-14 05:29:50,904 [INFO    ] __main__: train step 5419: loss: 0.9307, policy_loss: 1.4560, value_loss: 0.8819
2024-07-14 05:29:52,524 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:29:53,025 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:29:53,105 [INFO    ] __main__: train step 5420: loss: 0.9308, policy_loss: 1.4560, value_loss: 0.8819
2024-07-14 05:29:53,395 [INFO    ] __main__: train step 5421: loss: 0.9309, policy_loss: 1.4559, value_loss: 0.8819
2024-07-14 05:29:53,713 [INFO    ] __main__: train step 5422: loss: 0.9310, policy_loss: 1.4558, value_loss: 0.8818
2024-07-14 05:29:54,002 [INFO    ] __main__: train step 5423: loss: 0.9311, policy_loss: 1.4557, value_loss: 0.8818
2024-07-14 05:29:54,308 [INFO    ] __main__: train step 5424: loss: 0.9312, policy_loss: 1.4556, value_loss: 0.8818
2024-07-14 05:29:54,608 [INFO    ] __main__: train step 5425: loss: 0.9313, policy_loss: 1.4555, value_loss: 0.8817
2024-07-14 05:29:54,913 [INFO    ] __main__: train step 5426: loss: 0.9314, policy_loss: 1.4554, value_loss: 0.8817
2024-07-14 05:29:55,203 [INFO    ] __main__: train step 5427: loss: 0.9315, policy_loss: 1.4554, value_loss: 0.8817
2024-07-14 05:29:55,540 [INFO    ] __main__: train step 5428: loss: 0.9316, policy_loss: 1.4553, value_loss: 0.8817
2024-07-14 05:29:55,836 [INFO    ] __main__: train step 5429: loss: 0.9317, policy_loss: 1.4552, value_loss: 0.8816
2024-07-14 05:29:56,135 [INFO    ] __main__: train step 5430: loss: 0.9318, policy_loss: 1.4551, value_loss: 0.8816
2024-07-14 05:29:56,429 [INFO    ] __main__: train step 5431: loss: 0.9319, policy_loss: 1.4550, value_loss: 0.8816
2024-07-14 05:29:56,727 [INFO    ] __main__: train step 5432: loss: 0.9320, policy_loss: 1.4549, value_loss: 0.8815
2024-07-14 05:29:57,032 [INFO    ] __main__: train step 5433: loss: 0.9321, policy_loss: 1.4548, value_loss: 0.8815
2024-07-14 05:29:57,339 [INFO    ] __main__: train step 5434: loss: 0.9322, policy_loss: 1.4548, value_loss: 0.8815
2024-07-14 05:29:57,658 [INFO    ] __main__: train step 5435: loss: 0.9323, policy_loss: 1.4547, value_loss: 0.8815
2024-07-14 05:29:57,964 [INFO    ] __main__: train step 5436: loss: 0.9324, policy_loss: 1.4546, value_loss: 0.8814
2024-07-14 05:29:59,591 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:30:00,084 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:30:00,161 [INFO    ] __main__: train step 5437: loss: 0.9325, policy_loss: 1.4545, value_loss: 0.8814
2024-07-14 05:30:00,469 [INFO    ] __main__: train step 5438: loss: 0.9326, policy_loss: 1.4544, value_loss: 0.8814
2024-07-14 05:30:00,804 [INFO    ] __main__: train step 5439: loss: 0.9327, policy_loss: 1.4543, value_loss: 0.8814
2024-07-14 05:30:01,096 [INFO    ] __main__: train step 5440: loss: 0.9328, policy_loss: 1.4542, value_loss: 0.8813
2024-07-14 05:30:01,396 [INFO    ] __main__: train step 5441: loss: 0.9329, policy_loss: 1.4541, value_loss: 0.8813
2024-07-14 05:30:01,669 [INFO    ] __main__: train step 5442: loss: 0.9330, policy_loss: 1.4541, value_loss: 0.8813
2024-07-14 05:30:01,933 [INFO    ] __main__: train step 5443: loss: 0.9331, policy_loss: 1.4540, value_loss: 0.8812
2024-07-14 05:30:02,186 [INFO    ] __main__: train step 5444: loss: 0.9332, policy_loss: 1.4539, value_loss: 0.8812
2024-07-14 05:30:02,461 [INFO    ] __main__: train step 5445: loss: 0.9333, policy_loss: 1.4538, value_loss: 0.8812
2024-07-14 05:30:02,736 [INFO    ] __main__: train step 5446: loss: 0.9334, policy_loss: 1.4537, value_loss: 0.8812
2024-07-14 05:30:03,007 [INFO    ] __main__: train step 5447: loss: 0.9335, policy_loss: 1.4536, value_loss: 0.8811
2024-07-14 05:30:03,284 [INFO    ] __main__: train step 5448: loss: 0.9336, policy_loss: 1.4535, value_loss: 0.8811
2024-07-14 05:30:03,568 [INFO    ] __main__: train step 5449: loss: 0.9337, policy_loss: 1.4535, value_loss: 0.8811
2024-07-14 05:30:05,457 [INFO    ] __main__: train step 5450: loss: 0.9338, policy_loss: 1.4534, value_loss: 0.8810
2024-07-14 05:30:05,737 [INFO    ] __main__: train step 5451: loss: 0.9339, policy_loss: 1.4533, value_loss: 0.8810
2024-07-14 05:30:06,020 [INFO    ] __main__: train step 5452: loss: 0.9340, policy_loss: 1.4532, value_loss: 0.8810
2024-07-14 05:30:06,309 [INFO    ] __main__: train step 5453: loss: 0.9341, policy_loss: 1.4531, value_loss: 0.8810
2024-07-14 05:30:07,920 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:30:08,410 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:30:08,476 [INFO    ] __main__: train step 5454: loss: 0.9342, policy_loss: 1.4530, value_loss: 0.8809
2024-07-14 05:30:08,756 [INFO    ] __main__: train step 5455: loss: 0.9342, policy_loss: 1.4529, value_loss: 0.8809
2024-07-14 05:30:09,032 [INFO    ] __main__: train step 5456: loss: 0.9343, policy_loss: 1.4528, value_loss: 0.8809
2024-07-14 05:30:09,304 [INFO    ] __main__: train step 5457: loss: 0.9344, policy_loss: 1.4528, value_loss: 0.8808
2024-07-14 05:30:09,583 [INFO    ] __main__: train step 5458: loss: 0.9345, policy_loss: 1.4527, value_loss: 0.8808
2024-07-14 05:30:09,863 [INFO    ] __main__: train step 5459: loss: 0.9346, policy_loss: 1.4526, value_loss: 0.8808
2024-07-14 05:30:10,137 [INFO    ] __main__: train step 5460: loss: 0.9347, policy_loss: 1.4525, value_loss: 0.8807
2024-07-14 05:30:10,426 [INFO    ] __main__: train step 5461: loss: 0.9348, policy_loss: 1.4524, value_loss: 0.8807
2024-07-14 05:30:10,713 [INFO    ] __main__: train step 5462: loss: 0.9349, policy_loss: 1.4523, value_loss: 0.8807
2024-07-14 05:30:10,994 [INFO    ] __main__: train step 5463: loss: 0.9350, policy_loss: 1.4522, value_loss: 0.8807
2024-07-14 05:30:11,283 [INFO    ] __main__: train step 5464: loss: 0.9351, policy_loss: 1.4522, value_loss: 0.8806
2024-07-14 05:30:11,559 [INFO    ] __main__: train step 5465: loss: 0.9352, policy_loss: 1.4521, value_loss: 0.8806
2024-07-14 05:30:11,844 [INFO    ] __main__: train step 5466: loss: 0.9353, policy_loss: 1.4520, value_loss: 0.8806
2024-07-14 05:30:12,125 [INFO    ] __main__: train step 5467: loss: 0.9354, policy_loss: 1.4519, value_loss: 0.8806
2024-07-14 05:30:12,404 [INFO    ] __main__: train step 5468: loss: 0.9355, policy_loss: 1.4518, value_loss: 0.8805
2024-07-14 05:30:12,685 [INFO    ] __main__: train step 5469: loss: 0.9356, policy_loss: 1.4517, value_loss: 0.8805
2024-07-14 05:30:12,971 [INFO    ] __main__: train step 5470: loss: 0.9357, policy_loss: 1.4516, value_loss: 0.8805
2024-07-14 05:30:14,567 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:30:15,058 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:30:15,128 [INFO    ] __main__: train step 5471: loss: 0.9358, policy_loss: 1.4515, value_loss: 0.8804
2024-07-14 05:30:15,401 [INFO    ] __main__: train step 5472: loss: 0.9359, policy_loss: 1.4515, value_loss: 0.8804
2024-07-14 05:30:15,680 [INFO    ] __main__: train step 5473: loss: 0.9360, policy_loss: 1.4514, value_loss: 0.8804
2024-07-14 05:30:15,955 [INFO    ] __main__: train step 5474: loss: 0.9361, policy_loss: 1.4513, value_loss: 0.8804
2024-07-14 05:30:16,236 [INFO    ] __main__: train step 5475: loss: 0.9362, policy_loss: 1.4512, value_loss: 0.8803
2024-07-14 05:30:16,534 [INFO    ] __main__: train step 5476: loss: 0.9363, policy_loss: 1.4511, value_loss: 0.8803
2024-07-14 05:30:16,833 [INFO    ] __main__: train step 5477: loss: 0.9364, policy_loss: 1.4510, value_loss: 0.8803
2024-07-14 05:30:17,112 [INFO    ] __main__: train step 5478: loss: 0.9365, policy_loss: 1.4509, value_loss: 0.8802
2024-07-14 05:30:17,399 [INFO    ] __main__: train step 5479: loss: 0.9366, policy_loss: 1.4508, value_loss: 0.8802
2024-07-14 05:30:17,673 [INFO    ] __main__: train step 5480: loss: 0.9367, policy_loss: 1.4508, value_loss: 0.8802
2024-07-14 05:30:17,954 [INFO    ] __main__: train step 5481: loss: 0.9367, policy_loss: 1.4507, value_loss: 0.8802
2024-07-14 05:30:18,235 [INFO    ] __main__: train step 5482: loss: 0.9368, policy_loss: 1.4506, value_loss: 0.8801
2024-07-14 05:30:18,510 [INFO    ] __main__: train step 5483: loss: 0.9369, policy_loss: 1.4505, value_loss: 0.8801
2024-07-14 05:30:18,785 [INFO    ] __main__: train step 5484: loss: 0.9370, policy_loss: 1.4504, value_loss: 0.8801
2024-07-14 05:30:19,050 [INFO    ] __main__: train step 5485: loss: 0.9371, policy_loss: 1.4503, value_loss: 0.8800
2024-07-14 05:30:19,328 [INFO    ] __main__: train step 5486: loss: 0.9372, policy_loss: 1.4502, value_loss: 0.8800
2024-07-14 05:30:19,611 [INFO    ] __main__: train step 5487: loss: 0.9373, policy_loss: 1.4501, value_loss: 0.8800
2024-07-14 05:30:21,196 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:30:21,680 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:30:21,744 [INFO    ] __main__: train step 5488: loss: 0.9374, policy_loss: 1.4501, value_loss: 0.8800
2024-07-14 05:30:22,019 [INFO    ] __main__: train step 5489: loss: 0.9375, policy_loss: 1.4500, value_loss: 0.8799
2024-07-14 05:30:22,288 [INFO    ] __main__: train step 5490: loss: 0.9376, policy_loss: 1.4499, value_loss: 0.8799
2024-07-14 05:30:22,561 [INFO    ] __main__: train step 5491: loss: 0.9377, policy_loss: 1.4498, value_loss: 0.8799
2024-07-14 05:30:22,845 [INFO    ] __main__: train step 5492: loss: 0.9378, policy_loss: 1.4497, value_loss: 0.8798
2024-07-14 05:30:23,119 [INFO    ] __main__: train step 5493: loss: 0.9379, policy_loss: 1.4496, value_loss: 0.8798
2024-07-14 05:30:23,389 [INFO    ] __main__: train step 5494: loss: 0.9380, policy_loss: 1.4495, value_loss: 0.8798
2024-07-14 05:30:23,663 [INFO    ] __main__: train step 5495: loss: 0.9381, policy_loss: 1.4494, value_loss: 0.8798
2024-07-14 05:30:23,932 [INFO    ] __main__: train step 5496: loss: 0.9382, policy_loss: 1.4494, value_loss: 0.8797
2024-07-14 05:30:24,204 [INFO    ] __main__: train step 5497: loss: 0.9383, policy_loss: 1.4493, value_loss: 0.8797
2024-07-14 05:30:24,479 [INFO    ] __main__: train step 5498: loss: 0.9384, policy_loss: 1.4492, value_loss: 0.8797
2024-07-14 05:30:24,766 [INFO    ] __main__: train step 5499: loss: 0.9385, policy_loss: 1.4491, value_loss: 0.8797
2024-07-14 05:30:25,040 [INFO    ] __main__: train step 5500: loss: 0.9386, policy_loss: 1.4490, value_loss: 0.8796
2024-07-14 05:30:25,331 [INFO    ] __main__: train step 5501: loss: 0.9387, policy_loss: 1.4489, value_loss: 0.8796
2024-07-14 05:30:25,613 [INFO    ] __main__: train step 5502: loss: 0.9388, policy_loss: 1.4488, value_loss: 0.8796
2024-07-14 05:30:26,902 [INFO    ] __main__: train step 5503: loss: 0.9389, policy_loss: 1.4488, value_loss: 0.8795
2024-07-14 05:30:27,187 [INFO    ] __main__: train step 5504: loss: 0.9390, policy_loss: 1.4487, value_loss: 0.8795
2024-07-14 05:30:28,794 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:30:29,275 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:30:29,344 [INFO    ] __main__: train step 5505: loss: 0.9390, policy_loss: 1.4486, value_loss: 0.8795
2024-07-14 05:30:29,620 [INFO    ] __main__: train step 5506: loss: 0.9391, policy_loss: 1.4485, value_loss: 0.8795
2024-07-14 05:30:29,901 [INFO    ] __main__: train step 5507: loss: 0.9392, policy_loss: 1.4484, value_loss: 0.8794
2024-07-14 05:30:30,183 [INFO    ] __main__: train step 5508: loss: 0.9393, policy_loss: 1.4483, value_loss: 0.8794
2024-07-14 05:30:30,461 [INFO    ] __main__: train step 5509: loss: 0.9394, policy_loss: 1.4482, value_loss: 0.8794
2024-07-14 05:30:30,741 [INFO    ] __main__: train step 5510: loss: 0.9395, policy_loss: 1.4481, value_loss: 0.8794
2024-07-14 05:30:31,029 [INFO    ] __main__: train step 5511: loss: 0.9396, policy_loss: 1.4481, value_loss: 0.8793
2024-07-14 05:30:31,306 [INFO    ] __main__: train step 5512: loss: 0.9397, policy_loss: 1.4480, value_loss: 0.8793
2024-07-14 05:30:31,588 [INFO    ] __main__: train step 5513: loss: 0.9398, policy_loss: 1.4479, value_loss: 0.8793
2024-07-14 05:30:31,869 [INFO    ] __main__: train step 5514: loss: 0.9399, policy_loss: 1.4478, value_loss: 0.8792
2024-07-14 05:30:32,153 [INFO    ] __main__: train step 5515: loss: 0.9400, policy_loss: 1.4477, value_loss: 0.8792
2024-07-14 05:30:32,434 [INFO    ] __main__: train step 5516: loss: 0.9401, policy_loss: 1.4476, value_loss: 0.8792
2024-07-14 05:30:32,716 [INFO    ] __main__: train step 5517: loss: 0.9402, policy_loss: 1.4475, value_loss: 0.8791
2024-07-14 05:30:32,980 [INFO    ] __main__: train step 5518: loss: 0.9403, policy_loss: 1.4474, value_loss: 0.8791
2024-07-14 05:30:33,219 [INFO    ] __main__: train step 5519: loss: 0.9404, policy_loss: 1.4474, value_loss: 0.8791
2024-07-14 05:30:33,494 [INFO    ] __main__: train step 5520: loss: 0.9405, policy_loss: 1.4473, value_loss: 0.8791
2024-07-14 05:30:33,762 [INFO    ] __main__: train step 5521: loss: 0.9406, policy_loss: 1.4472, value_loss: 0.8790
2024-07-14 05:30:35,346 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:30:35,823 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:30:35,889 [INFO    ] __main__: train step 5522: loss: 0.9407, policy_loss: 1.4471, value_loss: 0.8790
2024-07-14 05:30:36,166 [INFO    ] __main__: train step 5523: loss: 0.9407, policy_loss: 1.4470, value_loss: 0.8790
2024-07-14 05:30:36,438 [INFO    ] __main__: train step 5524: loss: 0.9408, policy_loss: 1.4469, value_loss: 0.8789
2024-07-14 05:30:36,714 [INFO    ] __main__: train step 5525: loss: 0.9409, policy_loss: 1.4469, value_loss: 0.8789
2024-07-14 05:30:36,992 [INFO    ] __main__: train step 5526: loss: 0.9410, policy_loss: 1.4468, value_loss: 0.8789
2024-07-14 05:30:37,269 [INFO    ] __main__: train step 5527: loss: 0.9411, policy_loss: 1.4467, value_loss: 0.8789
2024-07-14 05:30:37,556 [INFO    ] __main__: train step 5528: loss: 0.9412, policy_loss: 1.4466, value_loss: 0.8788
2024-07-14 05:30:37,832 [INFO    ] __main__: train step 5529: loss: 0.9413, policy_loss: 1.4465, value_loss: 0.8788
2024-07-14 05:30:38,117 [INFO    ] __main__: train step 5530: loss: 0.9414, policy_loss: 1.4464, value_loss: 0.8788
2024-07-14 05:30:38,388 [INFO    ] __main__: train step 5531: loss: 0.9415, policy_loss: 1.4463, value_loss: 0.8787
2024-07-14 05:30:38,674 [INFO    ] __main__: train step 5532: loss: 0.9416, policy_loss: 1.4463, value_loss: 0.8787
2024-07-14 05:30:38,959 [INFO    ] __main__: train step 5533: loss: 0.9417, policy_loss: 1.4462, value_loss: 0.8787
2024-07-14 05:30:39,246 [INFO    ] __main__: train step 5534: loss: 0.9418, policy_loss: 1.4461, value_loss: 0.8787
2024-07-14 05:30:39,516 [INFO    ] __main__: train step 5535: loss: 0.9419, policy_loss: 1.4460, value_loss: 0.8786
2024-07-14 05:30:39,790 [INFO    ] __main__: train step 5536: loss: 0.9420, policy_loss: 1.4459, value_loss: 0.8786
2024-07-14 05:30:40,068 [INFO    ] __main__: train step 5537: loss: 0.9421, policy_loss: 1.4458, value_loss: 0.8786
2024-07-14 05:30:40,344 [INFO    ] __main__: train step 5538: loss: 0.9422, policy_loss: 1.4457, value_loss: 0.8785
2024-07-14 05:30:41,938 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:30:42,413 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:30:42,479 [INFO    ] __main__: train step 5539: loss: 0.9423, policy_loss: 1.4457, value_loss: 0.8785
2024-07-14 05:30:42,748 [INFO    ] __main__: train step 5540: loss: 0.9424, policy_loss: 1.4456, value_loss: 0.8785
2024-07-14 05:30:43,019 [INFO    ] __main__: train step 5541: loss: 0.9425, policy_loss: 1.4455, value_loss: 0.8785
2024-07-14 05:30:43,291 [INFO    ] __main__: train step 5542: loss: 0.9426, policy_loss: 1.4454, value_loss: 0.8784
2024-07-14 05:30:43,577 [INFO    ] __main__: train step 5543: loss: 0.9426, policy_loss: 1.4453, value_loss: 0.8784
2024-07-14 05:30:43,834 [INFO    ] __main__: train step 5544: loss: 0.9427, policy_loss: 1.4452, value_loss: 0.8784
2024-07-14 05:30:44,111 [INFO    ] __main__: train step 5545: loss: 0.9428, policy_loss: 1.4451, value_loss: 0.8783
2024-07-14 05:30:44,389 [INFO    ] __main__: train step 5546: loss: 0.9429, policy_loss: 1.4451, value_loss: 0.8783
2024-07-14 05:30:44,672 [INFO    ] __main__: train step 5547: loss: 0.9430, policy_loss: 1.4450, value_loss: 0.8783
2024-07-14 05:30:44,958 [INFO    ] __main__: train step 5548: loss: 0.9431, policy_loss: 1.4449, value_loss: 0.8783
2024-07-14 05:30:45,234 [INFO    ] __main__: train step 5549: loss: 0.9432, policy_loss: 1.4448, value_loss: 0.8782
2024-07-14 05:30:45,505 [INFO    ] __main__: train step 5550: loss: 0.9433, policy_loss: 1.4447, value_loss: 0.8782
2024-07-14 05:30:45,790 [INFO    ] __main__: train step 5551: loss: 0.9434, policy_loss: 1.4446, value_loss: 0.8782
2024-07-14 05:30:46,076 [INFO    ] __main__: train step 5552: loss: 0.9435, policy_loss: 1.4445, value_loss: 0.8781
2024-07-14 05:30:46,358 [INFO    ] __main__: train step 5553: loss: 0.9436, policy_loss: 1.4445, value_loss: 0.8781
2024-07-14 05:30:46,640 [INFO    ] __main__: train step 5554: loss: 0.9437, policy_loss: 1.4444, value_loss: 0.8781
2024-07-14 05:30:46,921 [INFO    ] __main__: train step 5555: loss: 0.9438, policy_loss: 1.4443, value_loss: 0.8780
2024-07-14 05:30:48,524 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:30:48,986 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:30:49,055 [INFO    ] __main__: train step 5556: loss: 0.9439, policy_loss: 1.4442, value_loss: 0.8780
2024-07-14 05:30:49,332 [INFO    ] __main__: train step 5557: loss: 0.9440, policy_loss: 1.4441, value_loss: 0.8780
2024-07-14 05:30:51,110 [INFO    ] __main__: train step 5558: loss: 0.9441, policy_loss: 1.4440, value_loss: 0.8780
2024-07-14 05:30:51,383 [INFO    ] __main__: train step 5559: loss: 0.9442, policy_loss: 1.4440, value_loss: 0.8779
2024-07-14 05:30:51,676 [INFO    ] __main__: train step 5560: loss: 0.9443, policy_loss: 1.4439, value_loss: 0.8779
2024-07-14 05:30:51,953 [INFO    ] __main__: train step 5561: loss: 0.9443, policy_loss: 1.4438, value_loss: 0.8779
2024-07-14 05:30:52,231 [INFO    ] __main__: train step 5562: loss: 0.9444, policy_loss: 1.4437, value_loss: 0.8778
2024-07-14 05:30:52,503 [INFO    ] __main__: train step 5563: loss: 0.9445, policy_loss: 1.4436, value_loss: 0.8778
2024-07-14 05:30:52,779 [INFO    ] __main__: train step 5564: loss: 0.9446, policy_loss: 1.4435, value_loss: 0.8778
2024-07-14 05:30:53,059 [INFO    ] __main__: train step 5565: loss: 0.9447, policy_loss: 1.4434, value_loss: 0.8778
2024-07-14 05:30:53,336 [INFO    ] __main__: train step 5566: loss: 0.9448, policy_loss: 1.4434, value_loss: 0.8777
2024-07-14 05:30:53,610 [INFO    ] __main__: train step 5567: loss: 0.9449, policy_loss: 1.4433, value_loss: 0.8777
2024-07-14 05:30:53,888 [INFO    ] __main__: train step 5568: loss: 0.9450, policy_loss: 1.4432, value_loss: 0.8777
2024-07-14 05:30:54,169 [INFO    ] __main__: train step 5569: loss: 0.9451, policy_loss: 1.4431, value_loss: 0.8776
2024-07-14 05:30:54,445 [INFO    ] __main__: train step 5570: loss: 0.9452, policy_loss: 1.4430, value_loss: 0.8776
2024-07-14 05:30:54,717 [INFO    ] __main__: train step 5571: loss: 0.9453, policy_loss: 1.4429, value_loss: 0.8776
2024-07-14 05:30:54,992 [INFO    ] __main__: train step 5572: loss: 0.9454, policy_loss: 1.4428, value_loss: 0.8776
2024-07-14 05:30:56,588 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:30:57,069 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:30:57,138 [INFO    ] __main__: train step 5573: loss: 0.9455, policy_loss: 1.4428, value_loss: 0.8775
2024-07-14 05:30:57,433 [INFO    ] __main__: train step 5574: loss: 0.9456, policy_loss: 1.4427, value_loss: 0.8775
2024-07-14 05:30:57,712 [INFO    ] __main__: train step 5575: loss: 0.9457, policy_loss: 1.4426, value_loss: 0.8775
2024-07-14 05:30:57,992 [INFO    ] __main__: train step 5576: loss: 0.9458, policy_loss: 1.4425, value_loss: 0.8774
2024-07-14 05:30:58,265 [INFO    ] __main__: train step 5577: loss: 0.9459, policy_loss: 1.4424, value_loss: 0.8774
2024-07-14 05:30:58,542 [INFO    ] __main__: train step 5578: loss: 0.9460, policy_loss: 1.4423, value_loss: 0.8774
2024-07-14 05:30:58,803 [INFO    ] __main__: train step 5579: loss: 0.9460, policy_loss: 1.4422, value_loss: 0.8774
2024-07-14 05:30:59,080 [INFO    ] __main__: train step 5580: loss: 0.9461, policy_loss: 1.4422, value_loss: 0.8773
2024-07-14 05:30:59,347 [INFO    ] __main__: train step 5581: loss: 0.9462, policy_loss: 1.4421, value_loss: 0.8773
2024-07-14 05:30:59,624 [INFO    ] __main__: train step 5582: loss: 0.9463, policy_loss: 1.4420, value_loss: 0.8773
2024-07-14 05:30:59,907 [INFO    ] __main__: train step 5583: loss: 0.9464, policy_loss: 1.4419, value_loss: 0.8772
2024-07-14 05:31:00,185 [INFO    ] __main__: train step 5584: loss: 0.9465, policy_loss: 1.4418, value_loss: 0.8772
2024-07-14 05:31:00,457 [INFO    ] __main__: train step 5585: loss: 0.9466, policy_loss: 1.4417, value_loss: 0.8772
2024-07-14 05:31:00,730 [INFO    ] __main__: train step 5586: loss: 0.9467, policy_loss: 1.4416, value_loss: 0.8772
2024-07-14 05:31:01,013 [INFO    ] __main__: train step 5587: loss: 0.9468, policy_loss: 1.4416, value_loss: 0.8771
2024-07-14 05:31:01,303 [INFO    ] __main__: train step 5588: loss: 0.9469, policy_loss: 1.4415, value_loss: 0.8771
2024-07-14 05:31:01,578 [INFO    ] __main__: train step 5589: loss: 0.9470, policy_loss: 1.4414, value_loss: 0.8771
2024-07-14 05:31:03,167 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:31:03,645 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:31:03,716 [INFO    ] __main__: train step 5590: loss: 0.9471, policy_loss: 1.4413, value_loss: 0.8771
2024-07-14 05:31:03,991 [INFO    ] __main__: train step 5591: loss: 0.9472, policy_loss: 1.4412, value_loss: 0.8770
2024-07-14 05:31:04,262 [INFO    ] __main__: train step 5592: loss: 0.9473, policy_loss: 1.4411, value_loss: 0.8770
2024-07-14 05:31:04,553 [INFO    ] __main__: train step 5593: loss: 0.9474, policy_loss: 1.4411, value_loss: 0.8770
2024-07-14 05:31:04,824 [INFO    ] __main__: train step 5594: loss: 0.9475, policy_loss: 1.4410, value_loss: 0.8769
2024-07-14 05:31:05,086 [INFO    ] __main__: train step 5595: loss: 0.9476, policy_loss: 1.4409, value_loss: 0.8769
2024-07-14 05:31:05,368 [INFO    ] __main__: train step 5596: loss: 0.9477, policy_loss: 1.4408, value_loss: 0.8769
2024-07-14 05:31:05,644 [INFO    ] __main__: train step 5597: loss: 0.9477, policy_loss: 1.4407, value_loss: 0.8768
2024-07-14 05:31:05,921 [INFO    ] __main__: train step 5598: loss: 0.9478, policy_loss: 1.4406, value_loss: 0.8768
2024-07-14 05:31:06,193 [INFO    ] __main__: train step 5599: loss: 0.9479, policy_loss: 1.4405, value_loss: 0.8768
2024-07-14 05:31:06,460 [INFO    ] __main__: train step 5600: loss: 0.9480, policy_loss: 1.4405, value_loss: 0.8768
2024-07-14 05:31:06,737 [INFO    ] __main__: train step 5601: loss: 0.9481, policy_loss: 1.4404, value_loss: 0.8767
2024-07-14 05:31:07,005 [INFO    ] __main__: train step 5602: loss: 0.9482, policy_loss: 1.4403, value_loss: 0.8767
2024-07-14 05:31:07,286 [INFO    ] __main__: train step 5603: loss: 0.9483, policy_loss: 1.4402, value_loss: 0.8767
2024-07-14 05:31:07,564 [INFO    ] __main__: train step 5604: loss: 0.9484, policy_loss: 1.4401, value_loss: 0.8767
2024-07-14 05:31:07,836 [INFO    ] __main__: train step 5605: loss: 0.9485, policy_loss: 1.4400, value_loss: 0.8766
2024-07-14 05:31:08,106 [INFO    ] __main__: train step 5606: loss: 0.9486, policy_loss: 1.4400, value_loss: 0.8766
2024-07-14 05:31:09,695 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:31:10,176 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:31:10,241 [INFO    ] __main__: train step 5607: loss: 0.9487, policy_loss: 1.4399, value_loss: 0.8766
2024-07-14 05:31:10,511 [INFO    ] __main__: train step 5608: loss: 0.9488, policy_loss: 1.4398, value_loss: 0.8765
2024-07-14 05:31:10,782 [INFO    ] __main__: train step 5609: loss: 0.9489, policy_loss: 1.4397, value_loss: 0.8765
2024-07-14 05:31:11,053 [INFO    ] __main__: train step 5610: loss: 0.9490, policy_loss: 1.4396, value_loss: 0.8765
2024-07-14 05:31:11,341 [INFO    ] __main__: train step 5611: loss: 0.9490, policy_loss: 1.4395, value_loss: 0.8764
2024-07-14 05:31:11,623 [INFO    ] __main__: train step 5612: loss: 0.9491, policy_loss: 1.4394, value_loss: 0.8764
2024-07-14 05:31:13,499 [INFO    ] __main__: train step 5613: loss: 0.9492, policy_loss: 1.4394, value_loss: 0.8764
2024-07-14 05:31:13,771 [INFO    ] __main__: train step 5614: loss: 0.9493, policy_loss: 1.4393, value_loss: 0.8764
2024-07-14 05:31:14,055 [INFO    ] __main__: train step 5615: loss: 0.9494, policy_loss: 1.4392, value_loss: 0.8763
2024-07-14 05:31:14,325 [INFO    ] __main__: train step 5616: loss: 0.9495, policy_loss: 1.4391, value_loss: 0.8763
2024-07-14 05:31:14,595 [INFO    ] __main__: train step 5617: loss: 0.9496, policy_loss: 1.4390, value_loss: 0.8763
2024-07-14 05:31:14,859 [INFO    ] __main__: train step 5618: loss: 0.9497, policy_loss: 1.4389, value_loss: 0.8763
2024-07-14 05:31:15,137 [INFO    ] __main__: train step 5619: loss: 0.9498, policy_loss: 1.4388, value_loss: 0.8762
2024-07-14 05:31:15,404 [INFO    ] __main__: train step 5620: loss: 0.9499, policy_loss: 1.4388, value_loss: 0.8762
2024-07-14 05:31:15,680 [INFO    ] __main__: train step 5621: loss: 0.9500, policy_loss: 1.4387, value_loss: 0.8762
2024-07-14 05:31:15,952 [INFO    ] __main__: train step 5622: loss: 0.9501, policy_loss: 1.4386, value_loss: 0.8761
2024-07-14 05:31:16,219 [INFO    ] __main__: train step 5623: loss: 0.9502, policy_loss: 1.4385, value_loss: 0.8761
2024-07-14 05:31:17,812 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:31:18,286 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:31:18,351 [INFO    ] __main__: train step 5624: loss: 0.9503, policy_loss: 1.4384, value_loss: 0.8761
2024-07-14 05:31:18,622 [INFO    ] __main__: train step 5625: loss: 0.9504, policy_loss: 1.4383, value_loss: 0.8761
2024-07-14 05:31:18,884 [INFO    ] __main__: train step 5626: loss: 0.9504, policy_loss: 1.4382, value_loss: 0.8760
2024-07-14 05:31:19,154 [INFO    ] __main__: train step 5627: loss: 0.9505, policy_loss: 1.4382, value_loss: 0.8760
2024-07-14 05:31:19,414 [INFO    ] __main__: train step 5628: loss: 0.9506, policy_loss: 1.4381, value_loss: 0.8760
2024-07-14 05:31:19,675 [INFO    ] __main__: train step 5629: loss: 0.9507, policy_loss: 1.4380, value_loss: 0.8759
2024-07-14 05:31:19,945 [INFO    ] __main__: train step 5630: loss: 0.9508, policy_loss: 1.4379, value_loss: 0.8759
2024-07-14 05:31:20,216 [INFO    ] __main__: train step 5631: loss: 0.9509, policy_loss: 1.4378, value_loss: 0.8759
2024-07-14 05:31:20,492 [INFO    ] __main__: train step 5632: loss: 0.9510, policy_loss: 1.4377, value_loss: 0.8759
2024-07-14 05:31:20,771 [INFO    ] __main__: train step 5633: loss: 0.9511, policy_loss: 1.4376, value_loss: 0.8758
2024-07-14 05:31:21,048 [INFO    ] __main__: train step 5634: loss: 0.9512, policy_loss: 1.4376, value_loss: 0.8758
2024-07-14 05:31:21,337 [INFO    ] __main__: train step 5635: loss: 0.9513, policy_loss: 1.4375, value_loss: 0.8758
2024-07-14 05:31:21,621 [INFO    ] __main__: train step 5636: loss: 0.9514, policy_loss: 1.4374, value_loss: 0.8758
2024-07-14 05:31:21,898 [INFO    ] __main__: train step 5637: loss: 0.9515, policy_loss: 1.4373, value_loss: 0.8757
2024-07-14 05:31:22,168 [INFO    ] __main__: train step 5638: loss: 0.9516, policy_loss: 1.4372, value_loss: 0.8757
2024-07-14 05:31:22,441 [INFO    ] __main__: train step 5639: loss: 0.9517, policy_loss: 1.4371, value_loss: 0.8757
2024-07-14 05:31:22,721 [INFO    ] __main__: train step 5640: loss: 0.9518, policy_loss: 1.4371, value_loss: 0.8756
2024-07-14 05:31:24,317 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:31:24,789 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:31:24,858 [INFO    ] __main__: train step 5641: loss: 0.9519, policy_loss: 1.4370, value_loss: 0.8756
2024-07-14 05:31:25,133 [INFO    ] __main__: train step 5642: loss: 0.9519, policy_loss: 1.4369, value_loss: 0.8756
2024-07-14 05:31:25,410 [INFO    ] __main__: train step 5643: loss: 0.9520, policy_loss: 1.4368, value_loss: 0.8755
2024-07-14 05:31:25,675 [INFO    ] __main__: train step 5644: loss: 0.9521, policy_loss: 1.4367, value_loss: 0.8755
2024-07-14 05:31:25,946 [INFO    ] __main__: train step 5645: loss: 0.9522, policy_loss: 1.4366, value_loss: 0.8755
2024-07-14 05:31:26,227 [INFO    ] __main__: train step 5646: loss: 0.9523, policy_loss: 1.4366, value_loss: 0.8755
2024-07-14 05:31:26,499 [INFO    ] __main__: train step 5647: loss: 0.9524, policy_loss: 1.4365, value_loss: 0.8754
2024-07-14 05:31:26,771 [INFO    ] __main__: train step 5648: loss: 0.9525, policy_loss: 1.4364, value_loss: 0.8754
2024-07-14 05:31:27,046 [INFO    ] __main__: train step 5649: loss: 0.9526, policy_loss: 1.4363, value_loss: 0.8754
2024-07-14 05:31:27,320 [INFO    ] __main__: train step 5650: loss: 0.9527, policy_loss: 1.4362, value_loss: 0.8753
2024-07-14 05:31:27,602 [INFO    ] __main__: train step 5651: loss: 0.9528, policy_loss: 1.4361, value_loss: 0.8753
2024-07-14 05:31:27,881 [INFO    ] __main__: train step 5652: loss: 0.9529, policy_loss: 1.4360, value_loss: 0.8753
2024-07-14 05:31:28,160 [INFO    ] __main__: train step 5653: loss: 0.9530, policy_loss: 1.4360, value_loss: 0.8753
2024-07-14 05:31:28,438 [INFO    ] __main__: train step 5654: loss: 0.9531, policy_loss: 1.4359, value_loss: 0.8752
2024-07-14 05:31:28,727 [INFO    ] __main__: train step 5655: loss: 0.9532, policy_loss: 1.4358, value_loss: 0.8752
2024-07-14 05:31:29,004 [INFO    ] __main__: train step 5656: loss: 0.9532, policy_loss: 1.4357, value_loss: 0.8752
2024-07-14 05:31:29,283 [INFO    ] __main__: train step 5657: loss: 0.9533, policy_loss: 1.4356, value_loss: 0.8751
2024-07-14 05:31:30,883 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:31:31,354 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:31:31,419 [INFO    ] __main__: train step 5658: loss: 0.9534, policy_loss: 1.4355, value_loss: 0.8751
2024-07-14 05:31:31,719 [INFO    ] __main__: train step 5659: loss: 0.9535, policy_loss: 1.4354, value_loss: 0.8751
2024-07-14 05:31:31,987 [INFO    ] __main__: train step 5660: loss: 0.9536, policy_loss: 1.4354, value_loss: 0.8751
2024-07-14 05:31:32,263 [INFO    ] __main__: train step 5661: loss: 0.9537, policy_loss: 1.4353, value_loss: 0.8750
2024-07-14 05:31:32,550 [INFO    ] __main__: train step 5662: loss: 0.9538, policy_loss: 1.4352, value_loss: 0.8750
2024-07-14 05:31:32,820 [INFO    ] __main__: train step 5663: loss: 0.9539, policy_loss: 1.4351, value_loss: 0.8750
2024-07-14 05:31:33,102 [INFO    ] __main__: train step 5664: loss: 0.9540, policy_loss: 1.4350, value_loss: 0.8749
2024-07-14 05:31:33,383 [INFO    ] __main__: train step 5665: loss: 0.9541, policy_loss: 1.4349, value_loss: 0.8749
2024-07-14 05:31:33,659 [INFO    ] __main__: train step 5666: loss: 0.9542, policy_loss: 1.4349, value_loss: 0.8749
2024-07-14 05:31:35,490 [INFO    ] __main__: train step 5667: loss: 0.9543, policy_loss: 1.4348, value_loss: 0.8749
2024-07-14 05:31:35,760 [INFO    ] __main__: train step 5668: loss: 0.9543, policy_loss: 1.4347, value_loss: 0.8748
2024-07-14 05:31:36,051 [INFO    ] __main__: train step 5669: loss: 0.9544, policy_loss: 1.4346, value_loss: 0.8748
2024-07-14 05:31:36,327 [INFO    ] __main__: train step 5670: loss: 0.9545, policy_loss: 1.4345, value_loss: 0.8748
2024-07-14 05:31:36,608 [INFO    ] __main__: train step 5671: loss: 0.9546, policy_loss: 1.4344, value_loss: 0.8748
2024-07-14 05:31:36,897 [INFO    ] __main__: train step 5672: loss: 0.9547, policy_loss: 1.4344, value_loss: 0.8747
2024-07-14 05:31:37,181 [INFO    ] __main__: train step 5673: loss: 0.9548, policy_loss: 1.4343, value_loss: 0.8747
2024-07-14 05:31:37,457 [INFO    ] __main__: train step 5674: loss: 0.9549, policy_loss: 1.4342, value_loss: 0.8747
2024-07-14 05:31:39,052 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:31:39,537 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:31:39,606 [INFO    ] __main__: train step 5675: loss: 0.9550, policy_loss: 1.4341, value_loss: 0.8746
2024-07-14 05:31:39,885 [INFO    ] __main__: train step 5676: loss: 0.9551, policy_loss: 1.4340, value_loss: 0.8746
2024-07-14 05:31:40,167 [INFO    ] __main__: train step 5677: loss: 0.9552, policy_loss: 1.4339, value_loss: 0.8746
2024-07-14 05:31:40,439 [INFO    ] __main__: train step 5678: loss: 0.9553, policy_loss: 1.4339, value_loss: 0.8746
2024-07-14 05:31:40,716 [INFO    ] __main__: train step 5679: loss: 0.9554, policy_loss: 1.4338, value_loss: 0.8745
2024-07-14 05:31:40,989 [INFO    ] __main__: train step 5680: loss: 0.9555, policy_loss: 1.4337, value_loss: 0.8745
2024-07-14 05:31:41,260 [INFO    ] __main__: train step 5681: loss: 0.9556, policy_loss: 1.4336, value_loss: 0.8745
2024-07-14 05:31:41,534 [INFO    ] __main__: train step 5682: loss: 0.9556, policy_loss: 1.4335, value_loss: 0.8744
2024-07-14 05:31:41,813 [INFO    ] __main__: train step 5683: loss: 0.9557, policy_loss: 1.4334, value_loss: 0.8744
2024-07-14 05:31:42,080 [INFO    ] __main__: train step 5684: loss: 0.9558, policy_loss: 1.4333, value_loss: 0.8744
2024-07-14 05:31:42,356 [INFO    ] __main__: train step 5685: loss: 0.9559, policy_loss: 1.4333, value_loss: 0.8744
2024-07-14 05:31:42,639 [INFO    ] __main__: train step 5686: loss: 0.9560, policy_loss: 1.4332, value_loss: 0.8743
2024-07-14 05:31:42,917 [INFO    ] __main__: train step 5687: loss: 0.9561, policy_loss: 1.4331, value_loss: 0.8743
2024-07-14 05:31:43,191 [INFO    ] __main__: train step 5688: loss: 0.9562, policy_loss: 1.4330, value_loss: 0.8743
2024-07-14 05:31:43,470 [INFO    ] __main__: train step 5689: loss: 0.9563, policy_loss: 1.4329, value_loss: 0.8743
2024-07-14 05:31:43,752 [INFO    ] __main__: train step 5690: loss: 0.9564, policy_loss: 1.4329, value_loss: 0.8742
2024-07-14 05:31:44,036 [INFO    ] __main__: train step 5691: loss: 0.9565, policy_loss: 1.4328, value_loss: 0.8742
2024-07-14 05:31:46,048 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:31:46,629 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:31:46,692 [INFO    ] __main__: train step 5692: loss: 0.9566, policy_loss: 1.4327, value_loss: 0.8742
2024-07-14 05:31:46,969 [INFO    ] __main__: train step 5693: loss: 0.9567, policy_loss: 1.4326, value_loss: 0.8741
2024-07-14 05:31:47,234 [INFO    ] __main__: train step 5694: loss: 0.9568, policy_loss: 1.4325, value_loss: 0.8741
2024-07-14 05:31:47,530 [INFO    ] __main__: train step 5695: loss: 0.9569, policy_loss: 1.4324, value_loss: 0.8741
2024-07-14 05:31:47,817 [INFO    ] __main__: train step 5696: loss: 0.9570, policy_loss: 1.4323, value_loss: 0.8741
2024-07-14 05:31:48,094 [INFO    ] __main__: train step 5697: loss: 0.9570, policy_loss: 1.4323, value_loss: 0.8740
2024-07-14 05:31:48,378 [INFO    ] __main__: train step 5698: loss: 0.9571, policy_loss: 1.4322, value_loss: 0.8740
2024-07-14 05:31:48,653 [INFO    ] __main__: train step 5699: loss: 0.9572, policy_loss: 1.4321, value_loss: 0.8740
2024-07-14 05:31:48,939 [INFO    ] __main__: train step 5700: loss: 0.9573, policy_loss: 1.4320, value_loss: 0.8740
2024-07-14 05:31:49,216 [INFO    ] __main__: train step 5701: loss: 0.9574, policy_loss: 1.4319, value_loss: 0.8739
2024-07-14 05:31:49,499 [INFO    ] __main__: train step 5702: loss: 0.9575, policy_loss: 1.4319, value_loss: 0.8739
2024-07-14 05:31:49,782 [INFO    ] __main__: train step 5703: loss: 0.9576, policy_loss: 1.4318, value_loss: 0.8739
2024-07-14 05:31:50,071 [INFO    ] __main__: train step 5704: loss: 0.9577, policy_loss: 1.4317, value_loss: 0.8738
2024-07-14 05:31:50,329 [INFO    ] __main__: train step 5705: loss: 0.9578, policy_loss: 1.4316, value_loss: 0.8738
2024-07-14 05:31:50,576 [INFO    ] __main__: train step 5706: loss: 0.9579, policy_loss: 1.4315, value_loss: 0.8738
2024-07-14 05:31:50,838 [INFO    ] __main__: train step 5707: loss: 0.9580, policy_loss: 1.4314, value_loss: 0.8738
2024-07-14 05:31:51,082 [INFO    ] __main__: train step 5708: loss: 0.9581, policy_loss: 1.4314, value_loss: 0.8737
2024-07-14 05:31:52,647 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:31:53,140 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:31:53,210 [INFO    ] __main__: train step 5709: loss: 0.9582, policy_loss: 1.4313, value_loss: 0.8737
2024-07-14 05:31:53,482 [INFO    ] __main__: train step 5710: loss: 0.9583, policy_loss: 1.4312, value_loss: 0.8737
2024-07-14 05:31:53,744 [INFO    ] __main__: train step 5711: loss: 0.9584, policy_loss: 1.4311, value_loss: 0.8737
2024-07-14 05:31:54,021 [INFO    ] __main__: train step 5712: loss: 0.9585, policy_loss: 1.4310, value_loss: 0.8736
2024-07-14 05:31:54,286 [INFO    ] __main__: train step 5713: loss: 0.9585, policy_loss: 1.4309, value_loss: 0.8736
2024-07-14 05:31:54,553 [INFO    ] __main__: train step 5714: loss: 0.9586, policy_loss: 1.4309, value_loss: 0.8736
2024-07-14 05:31:54,829 [INFO    ] __main__: train step 5715: loss: 0.9587, policy_loss: 1.4308, value_loss: 0.8735
2024-07-14 05:31:55,106 [INFO    ] __main__: train step 5716: loss: 0.9588, policy_loss: 1.4307, value_loss: 0.8735
2024-07-14 05:31:55,378 [INFO    ] __main__: train step 5717: loss: 0.9589, policy_loss: 1.4306, value_loss: 0.8735
2024-07-14 05:31:55,646 [INFO    ] __main__: train step 5718: loss: 0.9590, policy_loss: 1.4305, value_loss: 0.8735
2024-07-14 05:31:55,926 [INFO    ] __main__: train step 5719: loss: 0.9591, policy_loss: 1.4305, value_loss: 0.8734
2024-07-14 05:31:56,210 [INFO    ] __main__: train step 5720: loss: 0.9592, policy_loss: 1.4304, value_loss: 0.8734
2024-07-14 05:31:56,483 [INFO    ] __main__: train step 5721: loss: 0.9593, policy_loss: 1.4303, value_loss: 0.8734
2024-07-14 05:31:58,204 [INFO    ] __main__: train step 5722: loss: 0.9594, policy_loss: 1.4302, value_loss: 0.8734
2024-07-14 05:31:58,484 [INFO    ] __main__: train step 5723: loss: 0.9595, policy_loss: 1.4301, value_loss: 0.8733
2024-07-14 05:31:58,763 [INFO    ] __main__: train step 5724: loss: 0.9596, policy_loss: 1.4300, value_loss: 0.8733
2024-07-14 05:31:59,067 [INFO    ] __main__: train step 5725: loss: 0.9597, policy_loss: 1.4299, value_loss: 0.8733
2024-07-14 05:32:00,654 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:32:01,145 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:32:01,209 [INFO    ] __main__: train step 5726: loss: 0.9597, policy_loss: 1.4299, value_loss: 0.8732
2024-07-14 05:32:01,485 [INFO    ] __main__: train step 5727: loss: 0.9598, policy_loss: 1.4298, value_loss: 0.8732
2024-07-14 05:32:01,763 [INFO    ] __main__: train step 5728: loss: 0.9599, policy_loss: 1.4297, value_loss: 0.8732
2024-07-14 05:32:02,044 [INFO    ] __main__: train step 5729: loss: 0.9600, policy_loss: 1.4296, value_loss: 0.8732
2024-07-14 05:32:02,323 [INFO    ] __main__: train step 5730: loss: 0.9601, policy_loss: 1.4295, value_loss: 0.8731
2024-07-14 05:32:02,581 [INFO    ] __main__: train step 5731: loss: 0.9602, policy_loss: 1.4295, value_loss: 0.8731
2024-07-14 05:32:02,870 [INFO    ] __main__: train step 5732: loss: 0.9603, policy_loss: 1.4294, value_loss: 0.8731
2024-07-14 05:32:03,145 [INFO    ] __main__: train step 5733: loss: 0.9604, policy_loss: 1.4293, value_loss: 0.8730
2024-07-14 05:32:03,423 [INFO    ] __main__: train step 5734: loss: 0.9605, policy_loss: 1.4292, value_loss: 0.8730
2024-07-14 05:32:03,685 [INFO    ] __main__: train step 5735: loss: 0.9606, policy_loss: 1.4291, value_loss: 0.8730
2024-07-14 05:32:03,963 [INFO    ] __main__: train step 5736: loss: 0.9607, policy_loss: 1.4290, value_loss: 0.8730
2024-07-14 05:32:04,262 [INFO    ] __main__: train step 5737: loss: 0.9608, policy_loss: 1.4290, value_loss: 0.8729
2024-07-14 05:32:04,538 [INFO    ] __main__: train step 5738: loss: 0.9609, policy_loss: 1.4289, value_loss: 0.8729
2024-07-14 05:32:04,815 [INFO    ] __main__: train step 5739: loss: 0.9609, policy_loss: 1.4288, value_loss: 0.8729
2024-07-14 05:32:05,090 [INFO    ] __main__: train step 5740: loss: 0.9610, policy_loss: 1.4287, value_loss: 0.8729
2024-07-14 05:32:05,369 [INFO    ] __main__: train step 5741: loss: 0.9611, policy_loss: 1.4286, value_loss: 0.8728
2024-07-14 05:32:05,624 [INFO    ] __main__: train step 5742: loss: 0.9612, policy_loss: 1.4285, value_loss: 0.8728
2024-07-14 05:32:07,196 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:32:07,654 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:32:07,726 [INFO    ] __main__: train step 5743: loss: 0.9613, policy_loss: 1.4285, value_loss: 0.8728
2024-07-14 05:32:08,001 [INFO    ] __main__: train step 5744: loss: 0.9614, policy_loss: 1.4284, value_loss: 0.8727
2024-07-14 05:32:08,268 [INFO    ] __main__: train step 5745: loss: 0.9615, policy_loss: 1.4283, value_loss: 0.8727
2024-07-14 05:32:08,540 [INFO    ] __main__: train step 5746: loss: 0.9616, policy_loss: 1.4282, value_loss: 0.8727
2024-07-14 05:32:08,816 [INFO    ] __main__: train step 5747: loss: 0.9617, policy_loss: 1.4281, value_loss: 0.8727
2024-07-14 05:32:09,085 [INFO    ] __main__: train step 5748: loss: 0.9618, policy_loss: 1.4280, value_loss: 0.8726
2024-07-14 05:32:09,364 [INFO    ] __main__: train step 5749: loss: 0.9619, policy_loss: 1.4280, value_loss: 0.8726
2024-07-14 05:32:09,637 [INFO    ] __main__: train step 5750: loss: 0.9620, policy_loss: 1.4279, value_loss: 0.8726
2024-07-14 05:32:09,914 [INFO    ] __main__: train step 5751: loss: 0.9621, policy_loss: 1.4278, value_loss: 0.8726
2024-07-14 05:32:10,197 [INFO    ] __main__: train step 5752: loss: 0.9621, policy_loss: 1.4277, value_loss: 0.8725
2024-07-14 05:32:10,469 [INFO    ] __main__: train step 5753: loss: 0.9622, policy_loss: 1.4276, value_loss: 0.8725
2024-07-14 05:32:10,750 [INFO    ] __main__: train step 5754: loss: 0.9623, policy_loss: 1.4276, value_loss: 0.8725
2024-07-14 05:32:11,039 [INFO    ] __main__: train step 5755: loss: 0.9624, policy_loss: 1.4275, value_loss: 0.8724
2024-07-14 05:32:11,313 [INFO    ] __main__: train step 5756: loss: 0.9625, policy_loss: 1.4274, value_loss: 0.8724
2024-07-14 05:32:11,594 [INFO    ] __main__: train step 5757: loss: 0.9626, policy_loss: 1.4273, value_loss: 0.8724
2024-07-14 05:32:11,868 [INFO    ] __main__: train step 5758: loss: 0.9627, policy_loss: 1.4272, value_loss: 0.8724
2024-07-14 05:32:12,146 [INFO    ] __main__: train step 5759: loss: 0.9628, policy_loss: 1.4271, value_loss: 0.8723
2024-07-14 05:32:13,746 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:32:14,251 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:32:14,322 [INFO    ] __main__: train step 5760: loss: 0.9629, policy_loss: 1.4271, value_loss: 0.8723
2024-07-14 05:32:14,609 [INFO    ] __main__: train step 5761: loss: 0.9630, policy_loss: 1.4270, value_loss: 0.8723
2024-07-14 05:32:14,878 [INFO    ] __main__: train step 5762: loss: 0.9631, policy_loss: 1.4269, value_loss: 0.8723
2024-07-14 05:32:15,152 [INFO    ] __main__: train step 5763: loss: 0.9632, policy_loss: 1.4268, value_loss: 0.8722
2024-07-14 05:32:15,415 [INFO    ] __main__: train step 5764: loss: 0.9633, policy_loss: 1.4267, value_loss: 0.8722
2024-07-14 05:32:15,701 [INFO    ] __main__: train step 5765: loss: 0.9634, policy_loss: 1.4267, value_loss: 0.8722
2024-07-14 05:32:15,979 [INFO    ] __main__: train step 5766: loss: 0.9634, policy_loss: 1.4266, value_loss: 0.8722
2024-07-14 05:32:16,272 [INFO    ] __main__: train step 5767: loss: 0.9635, policy_loss: 1.4265, value_loss: 0.8721
2024-07-14 05:32:16,551 [INFO    ] __main__: train step 5768: loss: 0.9636, policy_loss: 1.4264, value_loss: 0.8721
2024-07-14 05:32:16,833 [INFO    ] __main__: train step 5769: loss: 0.9637, policy_loss: 1.4263, value_loss: 0.8721
2024-07-14 05:32:17,120 [INFO    ] __main__: train step 5770: loss: 0.9638, policy_loss: 1.4262, value_loss: 0.8720
2024-07-14 05:32:17,397 [INFO    ] __main__: train step 5771: loss: 0.9639, policy_loss: 1.4262, value_loss: 0.8720
2024-07-14 05:32:17,675 [INFO    ] __main__: train step 5772: loss: 0.9640, policy_loss: 1.4261, value_loss: 0.8720
2024-07-14 05:32:17,962 [INFO    ] __main__: train step 5773: loss: 0.9641, policy_loss: 1.4260, value_loss: 0.8720
2024-07-14 05:32:18,247 [INFO    ] __main__: train step 5774: loss: 0.9642, policy_loss: 1.4259, value_loss: 0.8719
2024-07-14 05:32:18,528 [INFO    ] __main__: train step 5775: loss: 0.9643, policy_loss: 1.4258, value_loss: 0.8719
2024-07-14 05:32:19,786 [INFO    ] __main__: train step 5776: loss: 0.9644, policy_loss: 1.4258, value_loss: 0.8719
2024-07-14 05:32:21,396 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:32:21,868 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:32:21,933 [INFO    ] __main__: train step 5777: loss: 0.9645, policy_loss: 1.4257, value_loss: 0.8718
2024-07-14 05:32:22,185 [INFO    ] __main__: train step 5778: loss: 0.9645, policy_loss: 1.4256, value_loss: 0.8718
2024-07-14 05:32:22,439 [INFO    ] __main__: train step 5779: loss: 0.9646, policy_loss: 1.4255, value_loss: 0.8718
2024-07-14 05:32:22,692 [INFO    ] __main__: train step 5780: loss: 0.9647, policy_loss: 1.4254, value_loss: 0.8718
2024-07-14 05:32:22,950 [INFO    ] __main__: train step 5781: loss: 0.9648, policy_loss: 1.4253, value_loss: 0.8717
2024-07-14 05:32:23,191 [INFO    ] __main__: train step 5782: loss: 0.9649, policy_loss: 1.4253, value_loss: 0.8717
2024-07-14 05:32:23,445 [INFO    ] __main__: train step 5783: loss: 0.9650, policy_loss: 1.4252, value_loss: 0.8717
2024-07-14 05:32:23,693 [INFO    ] __main__: train step 5784: loss: 0.9651, policy_loss: 1.4251, value_loss: 0.8717
2024-07-14 05:32:23,976 [INFO    ] __main__: train step 5785: loss: 0.9652, policy_loss: 1.4250, value_loss: 0.8716
2024-07-14 05:32:24,250 [INFO    ] __main__: train step 5786: loss: 0.9653, policy_loss: 1.4249, value_loss: 0.8716
2024-07-14 05:32:24,522 [INFO    ] __main__: train step 5787: loss: 0.9654, policy_loss: 1.4248, value_loss: 0.8716
2024-07-14 05:32:24,804 [INFO    ] __main__: train step 5788: loss: 0.9655, policy_loss: 1.4248, value_loss: 0.8716
2024-07-14 05:32:25,077 [INFO    ] __main__: train step 5789: loss: 0.9655, policy_loss: 1.4247, value_loss: 0.8715
2024-07-14 05:32:25,352 [INFO    ] __main__: train step 5790: loss: 0.9656, policy_loss: 1.4246, value_loss: 0.8715
2024-07-14 05:32:25,625 [INFO    ] __main__: train step 5791: loss: 0.9657, policy_loss: 1.4245, value_loss: 0.8715
2024-07-14 05:32:25,904 [INFO    ] __main__: train step 5792: loss: 0.9658, policy_loss: 1.4244, value_loss: 0.8714
2024-07-14 05:32:26,190 [INFO    ] __main__: train step 5793: loss: 0.9659, policy_loss: 1.4243, value_loss: 0.8714
2024-07-14 05:32:27,799 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:32:28,277 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:32:28,344 [INFO    ] __main__: train step 5794: loss: 0.9660, policy_loss: 1.4243, value_loss: 0.8714
2024-07-14 05:32:28,606 [INFO    ] __main__: train step 5795: loss: 0.9661, policy_loss: 1.4242, value_loss: 0.8714
2024-07-14 05:32:28,876 [INFO    ] __main__: train step 5796: loss: 0.9662, policy_loss: 1.4241, value_loss: 0.8713
2024-07-14 05:32:29,139 [INFO    ] __main__: train step 5797: loss: 0.9663, policy_loss: 1.4240, value_loss: 0.8713
2024-07-14 05:32:29,410 [INFO    ] __main__: train step 5798: loss: 0.9664, policy_loss: 1.4239, value_loss: 0.8713
2024-07-14 05:32:29,725 [INFO    ] __main__: train step 5799: loss: 0.9665, policy_loss: 1.4239, value_loss: 0.8713
2024-07-14 05:32:30,036 [INFO    ] __main__: train step 5800: loss: 0.9666, policy_loss: 1.4238, value_loss: 0.8712
2024-07-14 05:32:30,321 [INFO    ] __main__: train step 5801: loss: 0.9667, policy_loss: 1.4237, value_loss: 0.8712
2024-07-14 05:32:30,612 [INFO    ] __main__: train step 5802: loss: 0.9668, policy_loss: 1.4236, value_loss: 0.8712
2024-07-14 05:32:30,894 [INFO    ] __main__: train step 5803: loss: 0.9668, policy_loss: 1.4235, value_loss: 0.8712
2024-07-14 05:32:31,166 [INFO    ] __main__: train step 5804: loss: 0.9669, policy_loss: 1.4234, value_loss: 0.8711
2024-07-14 05:32:31,440 [INFO    ] __main__: train step 5805: loss: 0.9670, policy_loss: 1.4234, value_loss: 0.8711
2024-07-14 05:32:31,727 [INFO    ] __main__: train step 5806: loss: 0.9671, policy_loss: 1.4233, value_loss: 0.8711
2024-07-14 05:32:32,009 [INFO    ] __main__: train step 5807: loss: 0.9672, policy_loss: 1.4232, value_loss: 0.8711
2024-07-14 05:32:32,286 [INFO    ] __main__: train step 5808: loss: 0.9673, policy_loss: 1.4231, value_loss: 0.8710
2024-07-14 05:32:32,578 [INFO    ] __main__: train step 5809: loss: 0.9674, policy_loss: 1.4230, value_loss: 0.8710
2024-07-14 05:32:32,868 [INFO    ] __main__: train step 5810: loss: 0.9675, policy_loss: 1.4230, value_loss: 0.8710
2024-07-14 05:32:34,472 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:32:34,946 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:32:35,015 [INFO    ] __main__: train step 5811: loss: 0.9676, policy_loss: 1.4229, value_loss: 0.8709
2024-07-14 05:32:35,296 [INFO    ] __main__: train step 5812: loss: 0.9677, policy_loss: 1.4228, value_loss: 0.8709
2024-07-14 05:32:35,574 [INFO    ] __main__: train step 5813: loss: 0.9677, policy_loss: 1.4227, value_loss: 0.8709
2024-07-14 05:32:35,857 [INFO    ] __main__: train step 5814: loss: 0.9678, policy_loss: 1.4226, value_loss: 0.8709
2024-07-14 05:32:36,132 [INFO    ] __main__: train step 5815: loss: 0.9679, policy_loss: 1.4225, value_loss: 0.8708
2024-07-14 05:32:36,405 [INFO    ] __main__: train step 5816: loss: 0.9680, policy_loss: 1.4225, value_loss: 0.8708
2024-07-14 05:32:36,697 [INFO    ] __main__: train step 5817: loss: 0.9681, policy_loss: 1.4224, value_loss: 0.8708
2024-07-14 05:32:36,983 [INFO    ] __main__: train step 5818: loss: 0.9682, policy_loss: 1.4223, value_loss: 0.8707
2024-07-14 05:32:37,275 [INFO    ] __main__: train step 5819: loss: 0.9683, policy_loss: 1.4222, value_loss: 0.8707
2024-07-14 05:32:37,558 [INFO    ] __main__: train step 5820: loss: 0.9684, policy_loss: 1.4221, value_loss: 0.8707
2024-07-14 05:32:37,842 [INFO    ] __main__: train step 5821: loss: 0.9685, policy_loss: 1.4221, value_loss: 0.8707
2024-07-14 05:32:38,134 [INFO    ] __main__: train step 5822: loss: 0.9686, policy_loss: 1.4220, value_loss: 0.8706
2024-07-14 05:32:38,415 [INFO    ] __main__: train step 5823: loss: 0.9687, policy_loss: 1.4219, value_loss: 0.8706
2024-07-14 05:32:38,711 [INFO    ] __main__: train step 5824: loss: 0.9687, policy_loss: 1.4218, value_loss: 0.8706
2024-07-14 05:32:38,985 [INFO    ] __main__: train step 5825: loss: 0.9688, policy_loss: 1.4217, value_loss: 0.8706
2024-07-14 05:32:39,270 [INFO    ] __main__: train step 5826: loss: 0.9689, policy_loss: 1.4216, value_loss: 0.8705
2024-07-14 05:32:39,614 [INFO    ] __main__: train step 5827: loss: 0.9690, policy_loss: 1.4216, value_loss: 0.8705
2024-07-14 05:32:41,237 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:32:41,727 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:32:41,794 [INFO    ] __main__: train step 5828: loss: 0.9691, policy_loss: 1.4215, value_loss: 0.8705
2024-07-14 05:32:42,077 [INFO    ] __main__: train step 5829: loss: 0.9692, policy_loss: 1.4214, value_loss: 0.8704
2024-07-14 05:32:42,341 [INFO    ] __main__: train step 5830: loss: 0.9693, policy_loss: 1.4213, value_loss: 0.8704
2024-07-14 05:32:43,977 [INFO    ] __main__: train step 5831: loss: 0.9694, policy_loss: 1.4212, value_loss: 0.8704
2024-07-14 05:32:44,269 [INFO    ] __main__: train step 5832: loss: 0.9695, policy_loss: 1.4211, value_loss: 0.8704
2024-07-14 05:32:44,553 [INFO    ] __main__: train step 5833: loss: 0.9695, policy_loss: 1.4211, value_loss: 0.8703
2024-07-14 05:32:44,834 [INFO    ] __main__: train step 5834: loss: 0.9696, policy_loss: 1.4210, value_loss: 0.8703
2024-07-14 05:32:45,120 [INFO    ] __main__: train step 5835: loss: 0.9697, policy_loss: 1.4209, value_loss: 0.8703
2024-07-14 05:32:45,409 [INFO    ] __main__: train step 5836: loss: 0.9698, policy_loss: 1.4208, value_loss: 0.8703
2024-07-14 05:32:45,697 [INFO    ] __main__: train step 5837: loss: 0.9699, policy_loss: 1.4207, value_loss: 0.8702
2024-07-14 05:32:45,976 [INFO    ] __main__: train step 5838: loss: 0.9700, policy_loss: 1.4206, value_loss: 0.8702
2024-07-14 05:32:46,260 [INFO    ] __main__: train step 5839: loss: 0.9701, policy_loss: 1.4206, value_loss: 0.8702
2024-07-14 05:32:46,556 [INFO    ] __main__: train step 5840: loss: 0.9702, policy_loss: 1.4205, value_loss: 0.8701
2024-07-14 05:32:46,843 [INFO    ] __main__: train step 5841: loss: 0.9703, policy_loss: 1.4204, value_loss: 0.8701
2024-07-14 05:32:47,130 [INFO    ] __main__: train step 5842: loss: 0.9704, policy_loss: 1.4203, value_loss: 0.8701
2024-07-14 05:32:47,389 [INFO    ] __main__: train step 5843: loss: 0.9704, policy_loss: 1.4202, value_loss: 0.8701
2024-07-14 05:32:47,655 [INFO    ] __main__: train step 5844: loss: 0.9705, policy_loss: 1.4202, value_loss: 0.8700
2024-07-14 05:32:49,238 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:32:49,716 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:32:49,787 [INFO    ] __main__: train step 5845: loss: 0.9706, policy_loss: 1.4201, value_loss: 0.8700
2024-07-14 05:32:50,065 [INFO    ] __main__: train step 5846: loss: 0.9707, policy_loss: 1.4200, value_loss: 0.8700
2024-07-14 05:32:50,338 [INFO    ] __main__: train step 5847: loss: 0.9708, policy_loss: 1.4199, value_loss: 0.8700
2024-07-14 05:32:50,653 [INFO    ] __main__: train step 5848: loss: 0.9709, policy_loss: 1.4198, value_loss: 0.8699
2024-07-14 05:32:50,926 [INFO    ] __main__: train step 5849: loss: 0.9710, policy_loss: 1.4197, value_loss: 0.8699
2024-07-14 05:32:51,212 [INFO    ] __main__: train step 5850: loss: 0.9711, policy_loss: 1.4197, value_loss: 0.8699
2024-07-14 05:32:51,497 [INFO    ] __main__: train step 5851: loss: 0.9712, policy_loss: 1.4196, value_loss: 0.8698
2024-07-14 05:32:51,783 [INFO    ] __main__: train step 5852: loss: 0.9712, policy_loss: 1.4195, value_loss: 0.8698
2024-07-14 05:32:52,057 [INFO    ] __main__: train step 5853: loss: 0.9713, policy_loss: 1.4194, value_loss: 0.8698
2024-07-14 05:32:52,317 [INFO    ] __main__: train step 5854: loss: 0.9714, policy_loss: 1.4193, value_loss: 0.8698
2024-07-14 05:32:52,603 [INFO    ] __main__: train step 5855: loss: 0.9715, policy_loss: 1.4192, value_loss: 0.8697
2024-07-14 05:32:52,880 [INFO    ] __main__: train step 5856: loss: 0.9716, policy_loss: 1.4192, value_loss: 0.8697
2024-07-14 05:32:53,127 [INFO    ] __main__: train step 5857: loss: 0.9717, policy_loss: 1.4191, value_loss: 0.8697
2024-07-14 05:32:53,378 [INFO    ] __main__: train step 5858: loss: 0.9718, policy_loss: 1.4190, value_loss: 0.8697
2024-07-14 05:32:53,629 [INFO    ] __main__: train step 5859: loss: 0.9719, policy_loss: 1.4189, value_loss: 0.8696
2024-07-14 05:32:53,895 [INFO    ] __main__: train step 5860: loss: 0.9720, policy_loss: 1.4188, value_loss: 0.8696
2024-07-14 05:32:54,163 [INFO    ] __main__: train step 5861: loss: 0.9720, policy_loss: 1.4187, value_loss: 0.8696
2024-07-14 05:32:55,740 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:32:56,212 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:32:56,278 [INFO    ] __main__: train step 5862: loss: 0.9721, policy_loss: 1.4187, value_loss: 0.8695
2024-07-14 05:32:56,547 [INFO    ] __main__: train step 5863: loss: 0.9722, policy_loss: 1.4186, value_loss: 0.8695
2024-07-14 05:32:56,824 [INFO    ] __main__: train step 5864: loss: 0.9723, policy_loss: 1.4185, value_loss: 0.8695
2024-07-14 05:32:57,094 [INFO    ] __main__: train step 5865: loss: 0.9724, policy_loss: 1.4184, value_loss: 0.8695
2024-07-14 05:32:57,381 [INFO    ] __main__: train step 5866: loss: 0.9725, policy_loss: 1.4183, value_loss: 0.8694
2024-07-14 05:32:57,662 [INFO    ] __main__: train step 5867: loss: 0.9726, policy_loss: 1.4182, value_loss: 0.8694
2024-07-14 05:32:57,957 [INFO    ] __main__: train step 5868: loss: 0.9726, policy_loss: 1.4182, value_loss: 0.8694
2024-07-14 05:32:58,234 [INFO    ] __main__: train step 5869: loss: 0.9727, policy_loss: 1.4181, value_loss: 0.8694
2024-07-14 05:32:58,510 [INFO    ] __main__: train step 5870: loss: 0.9728, policy_loss: 1.4180, value_loss: 0.8693
2024-07-14 05:32:58,780 [INFO    ] __main__: train step 5871: loss: 0.9729, policy_loss: 1.4179, value_loss: 0.8693
2024-07-14 05:32:59,059 [INFO    ] __main__: train step 5872: loss: 0.9730, policy_loss: 1.4178, value_loss: 0.8693
2024-07-14 05:32:59,334 [INFO    ] __main__: train step 5873: loss: 0.9731, policy_loss: 1.4178, value_loss: 0.8692
2024-07-14 05:32:59,615 [INFO    ] __main__: train step 5874: loss: 0.9732, policy_loss: 1.4177, value_loss: 0.8692
2024-07-14 05:32:59,897 [INFO    ] __main__: train step 5875: loss: 0.9733, policy_loss: 1.4176, value_loss: 0.8692
2024-07-14 05:33:00,178 [INFO    ] __main__: train step 5876: loss: 0.9734, policy_loss: 1.4175, value_loss: 0.8692
2024-07-14 05:33:00,464 [INFO    ] __main__: train step 5877: loss: 0.9735, policy_loss: 1.4174, value_loss: 0.8691
2024-07-14 05:33:00,752 [INFO    ] __main__: train step 5878: loss: 0.9735, policy_loss: 1.4174, value_loss: 0.8691
2024-07-14 05:33:02,351 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:33:02,822 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:33:02,886 [INFO    ] __main__: train step 5879: loss: 0.9736, policy_loss: 1.4173, value_loss: 0.8691
2024-07-14 05:33:03,160 [INFO    ] __main__: train step 5880: loss: 0.9737, policy_loss: 1.4172, value_loss: 0.8691
2024-07-14 05:33:03,430 [INFO    ] __main__: train step 5881: loss: 0.9738, policy_loss: 1.4171, value_loss: 0.8690
2024-07-14 05:33:03,714 [INFO    ] __main__: train step 5882: loss: 0.9739, policy_loss: 1.4170, value_loss: 0.8690
2024-07-14 05:33:03,990 [INFO    ] __main__: train step 5883: loss: 0.9740, policy_loss: 1.4169, value_loss: 0.8690
2024-07-14 05:33:04,269 [INFO    ] __main__: train step 5884: loss: 0.9741, policy_loss: 1.4169, value_loss: 0.8689
2024-07-14 05:33:04,551 [INFO    ] __main__: train step 5885: loss: 0.9742, policy_loss: 1.4168, value_loss: 0.8689
2024-07-14 05:33:06,384 [INFO    ] __main__: train step 5886: loss: 0.9743, policy_loss: 1.4167, value_loss: 0.8689
2024-07-14 05:33:06,663 [INFO    ] __main__: train step 5887: loss: 0.9743, policy_loss: 1.4166, value_loss: 0.8689
2024-07-14 05:33:06,936 [INFO    ] __main__: train step 5888: loss: 0.9744, policy_loss: 1.4165, value_loss: 0.8688
2024-07-14 05:33:07,206 [INFO    ] __main__: train step 5889: loss: 0.9745, policy_loss: 1.4165, value_loss: 0.8688
2024-07-14 05:33:07,495 [INFO    ] __main__: train step 5890: loss: 0.9746, policy_loss: 1.4164, value_loss: 0.8688
2024-07-14 05:33:07,766 [INFO    ] __main__: train step 5891: loss: 0.9747, policy_loss: 1.4163, value_loss: 0.8687
2024-07-14 05:33:08,040 [INFO    ] __main__: train step 5892: loss: 0.9748, policy_loss: 1.4162, value_loss: 0.8687
2024-07-14 05:33:08,321 [INFO    ] __main__: train step 5893: loss: 0.9749, policy_loss: 1.4161, value_loss: 0.8687
2024-07-14 05:33:08,600 [INFO    ] __main__: train step 5894: loss: 0.9750, policy_loss: 1.4161, value_loss: 0.8687
2024-07-14 05:33:08,888 [INFO    ] __main__: train step 5895: loss: 0.9751, policy_loss: 1.4160, value_loss: 0.8686
2024-07-14 05:33:10,488 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:33:10,971 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:33:11,036 [INFO    ] __main__: train step 5896: loss: 0.9751, policy_loss: 1.4159, value_loss: 0.8686
2024-07-14 05:33:11,312 [INFO    ] __main__: train step 5897: loss: 0.9752, policy_loss: 1.4158, value_loss: 0.8686
2024-07-14 05:33:11,588 [INFO    ] __main__: train step 5898: loss: 0.9753, policy_loss: 1.4157, value_loss: 0.8686
2024-07-14 05:33:11,847 [INFO    ] __main__: train step 5899: loss: 0.9754, policy_loss: 1.4157, value_loss: 0.8685
2024-07-14 05:33:12,123 [INFO    ] __main__: train step 5900: loss: 0.9755, policy_loss: 1.4156, value_loss: 0.8685
2024-07-14 05:33:12,393 [INFO    ] __main__: train step 5901: loss: 0.9756, policy_loss: 1.4155, value_loss: 0.8685
2024-07-14 05:33:12,677 [INFO    ] __main__: train step 5902: loss: 0.9757, policy_loss: 1.4154, value_loss: 0.8685
2024-07-14 05:33:12,967 [INFO    ] __main__: train step 5903: loss: 0.9758, policy_loss: 1.4153, value_loss: 0.8684
2024-07-14 05:33:13,252 [INFO    ] __main__: train step 5904: loss: 0.9759, policy_loss: 1.4153, value_loss: 0.8684
2024-07-14 05:33:13,538 [INFO    ] __main__: train step 5905: loss: 0.9760, policy_loss: 1.4152, value_loss: 0.8684
2024-07-14 05:33:13,809 [INFO    ] __main__: train step 5906: loss: 0.9760, policy_loss: 1.4151, value_loss: 0.8683
2024-07-14 05:33:14,083 [INFO    ] __main__: train step 5907: loss: 0.9761, policy_loss: 1.4150, value_loss: 0.8683
2024-07-14 05:33:14,387 [INFO    ] __main__: train step 5908: loss: 0.9762, policy_loss: 1.4149, value_loss: 0.8683
2024-07-14 05:33:14,661 [INFO    ] __main__: train step 5909: loss: 0.9763, policy_loss: 1.4149, value_loss: 0.8683
2024-07-14 05:33:14,933 [INFO    ] __main__: train step 5910: loss: 0.9764, policy_loss: 1.4148, value_loss: 0.8682
2024-07-14 05:33:15,207 [INFO    ] __main__: train step 5911: loss: 0.9765, policy_loss: 1.4147, value_loss: 0.8682
2024-07-14 05:33:15,487 [INFO    ] __main__: train step 5912: loss: 0.9766, policy_loss: 1.4146, value_loss: 0.8682
2024-07-14 05:33:17,078 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:33:17,551 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:33:17,626 [INFO    ] __main__: train step 5913: loss: 0.9767, policy_loss: 1.4145, value_loss: 0.8682
2024-07-14 05:33:17,920 [INFO    ] __main__: train step 5914: loss: 0.9768, policy_loss: 1.4144, value_loss: 0.8681
2024-07-14 05:33:18,194 [INFO    ] __main__: train step 5915: loss: 0.9768, policy_loss: 1.4144, value_loss: 0.8681
2024-07-14 05:33:18,469 [INFO    ] __main__: train step 5916: loss: 0.9769, policy_loss: 1.4143, value_loss: 0.8681
2024-07-14 05:33:18,746 [INFO    ] __main__: train step 5917: loss: 0.9770, policy_loss: 1.4142, value_loss: 0.8680
2024-07-14 05:33:19,021 [INFO    ] __main__: train step 5918: loss: 0.9771, policy_loss: 1.4141, value_loss: 0.8680
2024-07-14 05:33:19,295 [INFO    ] __main__: train step 5919: loss: 0.9772, policy_loss: 1.4140, value_loss: 0.8680
2024-07-14 05:33:19,573 [INFO    ] __main__: train step 5920: loss: 0.9773, policy_loss: 1.4140, value_loss: 0.8680
2024-07-14 05:33:19,885 [INFO    ] __main__: train step 5921: loss: 0.9774, policy_loss: 1.4139, value_loss: 0.8679
2024-07-14 05:33:20,160 [INFO    ] __main__: train step 5922: loss: 0.9775, policy_loss: 1.4138, value_loss: 0.8679
2024-07-14 05:33:20,421 [INFO    ] __main__: train step 5923: loss: 0.9775, policy_loss: 1.4137, value_loss: 0.8679
2024-07-14 05:33:20,696 [INFO    ] __main__: train step 5924: loss: 0.9776, policy_loss: 1.4136, value_loss: 0.8679
2024-07-14 05:33:20,977 [INFO    ] __main__: train step 5925: loss: 0.9777, policy_loss: 1.4135, value_loss: 0.8678
2024-07-14 05:33:21,257 [INFO    ] __main__: train step 5926: loss: 0.9778, policy_loss: 1.4135, value_loss: 0.8678
2024-07-14 05:33:21,528 [INFO    ] __main__: train step 5927: loss: 0.9779, policy_loss: 1.4134, value_loss: 0.8678
2024-07-14 05:33:21,801 [INFO    ] __main__: train step 5928: loss: 0.9780, policy_loss: 1.4133, value_loss: 0.8677
2024-07-14 05:33:22,084 [INFO    ] __main__: train step 5929: loss: 0.9781, policy_loss: 1.4132, value_loss: 0.8677
2024-07-14 05:33:23,693 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:33:24,174 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:33:24,249 [INFO    ] __main__: train step 5930: loss: 0.9782, policy_loss: 1.4131, value_loss: 0.8677
2024-07-14 05:33:24,519 [INFO    ] __main__: train step 5931: loss: 0.9783, policy_loss: 1.4131, value_loss: 0.8677
2024-07-14 05:33:24,784 [INFO    ] __main__: train step 5932: loss: 0.9783, policy_loss: 1.4130, value_loss: 0.8676
2024-07-14 05:33:25,027 [INFO    ] __main__: train step 5933: loss: 0.9784, policy_loss: 1.4129, value_loss: 0.8676
2024-07-14 05:33:25,300 [INFO    ] __main__: train step 5934: loss: 0.9785, policy_loss: 1.4128, value_loss: 0.8676
2024-07-14 05:33:25,579 [INFO    ] __main__: train step 5935: loss: 0.9786, policy_loss: 1.4127, value_loss: 0.8676
2024-07-14 05:33:25,847 [INFO    ] __main__: train step 5936: loss: 0.9787, policy_loss: 1.4127, value_loss: 0.8675
2024-07-14 05:33:26,090 [INFO    ] __main__: train step 5937: loss: 0.9788, policy_loss: 1.4126, value_loss: 0.8675
2024-07-14 05:33:26,366 [INFO    ] __main__: train step 5938: loss: 0.9789, policy_loss: 1.4125, value_loss: 0.8675
2024-07-14 05:33:26,644 [INFO    ] __main__: train step 5939: loss: 0.9789, policy_loss: 1.4124, value_loss: 0.8674
2024-07-14 05:33:26,917 [INFO    ] __main__: train step 5940: loss: 0.9790, policy_loss: 1.4123, value_loss: 0.8674
2024-07-14 05:33:28,162 [INFO    ] __main__: train step 5941: loss: 0.9791, policy_loss: 1.4122, value_loss: 0.8674
2024-07-14 05:33:28,457 [INFO    ] __main__: train step 5942: loss: 0.9792, policy_loss: 1.4122, value_loss: 0.8674
2024-07-14 05:33:28,736 [INFO    ] __main__: train step 5943: loss: 0.9793, policy_loss: 1.4121, value_loss: 0.8673
2024-07-14 05:33:29,009 [INFO    ] __main__: train step 5944: loss: 0.9794, policy_loss: 1.4120, value_loss: 0.8673
2024-07-14 05:33:29,285 [INFO    ] __main__: train step 5945: loss: 0.9795, policy_loss: 1.4119, value_loss: 0.8673
2024-07-14 05:33:29,563 [INFO    ] __main__: train step 5946: loss: 0.9796, policy_loss: 1.4118, value_loss: 0.8673
2024-07-14 05:33:31,175 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:33:31,640 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:33:31,707 [INFO    ] __main__: train step 5947: loss: 0.9796, policy_loss: 1.4118, value_loss: 0.8672
2024-07-14 05:33:31,981 [INFO    ] __main__: train step 5948: loss: 0.9797, policy_loss: 1.4117, value_loss: 0.8672
2024-07-14 05:33:32,257 [INFO    ] __main__: train step 5949: loss: 0.9798, policy_loss: 1.4116, value_loss: 0.8672
2024-07-14 05:33:32,542 [INFO    ] __main__: train step 5950: loss: 0.9799, policy_loss: 1.4115, value_loss: 0.8672
2024-07-14 05:33:32,815 [INFO    ] __main__: train step 5951: loss: 0.9800, policy_loss: 1.4114, value_loss: 0.8671
2024-07-14 05:33:33,093 [INFO    ] __main__: train step 5952: loss: 0.9801, policy_loss: 1.4114, value_loss: 0.8671
2024-07-14 05:33:33,379 [INFO    ] __main__: train step 5953: loss: 0.9802, policy_loss: 1.4113, value_loss: 0.8671
2024-07-14 05:33:33,664 [INFO    ] __main__: train step 5954: loss: 0.9803, policy_loss: 1.4112, value_loss: 0.8671
2024-07-14 05:33:33,932 [INFO    ] __main__: train step 5955: loss: 0.9803, policy_loss: 1.4111, value_loss: 0.8670
2024-07-14 05:33:34,201 [INFO    ] __main__: train step 5956: loss: 0.9804, policy_loss: 1.4110, value_loss: 0.8670
2024-07-14 05:33:34,476 [INFO    ] __main__: train step 5957: loss: 0.9805, policy_loss: 1.4109, value_loss: 0.8670
2024-07-14 05:33:34,758 [INFO    ] __main__: train step 5958: loss: 0.9806, policy_loss: 1.4109, value_loss: 0.8669
2024-07-14 05:33:35,025 [INFO    ] __main__: train step 5959: loss: 0.9807, policy_loss: 1.4108, value_loss: 0.8669
2024-07-14 05:33:35,305 [INFO    ] __main__: train step 5960: loss: 0.9808, policy_loss: 1.4107, value_loss: 0.8669
2024-07-14 05:33:35,585 [INFO    ] __main__: train step 5961: loss: 0.9809, policy_loss: 1.4106, value_loss: 0.8669
2024-07-14 05:33:35,861 [INFO    ] __main__: train step 5962: loss: 0.9810, policy_loss: 1.4105, value_loss: 0.8668
2024-07-14 05:33:36,133 [INFO    ] __main__: train step 5963: loss: 0.9810, policy_loss: 1.4105, value_loss: 0.8668
2024-07-14 05:33:37,728 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:33:38,197 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:33:38,272 [INFO    ] __main__: train step 5964: loss: 0.9811, policy_loss: 1.4104, value_loss: 0.8668
2024-07-14 05:33:38,547 [INFO    ] __main__: train step 5965: loss: 0.9812, policy_loss: 1.4103, value_loss: 0.8667
2024-07-14 05:33:38,826 [INFO    ] __main__: train step 5966: loss: 0.9813, policy_loss: 1.4102, value_loss: 0.8667
2024-07-14 05:33:39,096 [INFO    ] __main__: train step 5967: loss: 0.9814, policy_loss: 1.4101, value_loss: 0.8667
2024-07-14 05:33:39,368 [INFO    ] __main__: train step 5968: loss: 0.9815, policy_loss: 1.4101, value_loss: 0.8667
2024-07-14 05:33:39,641 [INFO    ] __main__: train step 5969: loss: 0.9816, policy_loss: 1.4100, value_loss: 0.8666
2024-07-14 05:33:39,893 [INFO    ] __main__: train step 5970: loss: 0.9816, policy_loss: 1.4099, value_loss: 0.8666
2024-07-14 05:33:40,162 [INFO    ] __main__: train step 5971: loss: 0.9817, policy_loss: 1.4098, value_loss: 0.8666
2024-07-14 05:33:40,432 [INFO    ] __main__: train step 5972: loss: 0.9818, policy_loss: 1.4097, value_loss: 0.8666
2024-07-14 05:33:40,720 [INFO    ] __main__: train step 5973: loss: 0.9819, policy_loss: 1.4097, value_loss: 0.8665
2024-07-14 05:33:41,010 [INFO    ] __main__: train step 5974: loss: 0.9820, policy_loss: 1.4096, value_loss: 0.8665
2024-07-14 05:33:41,287 [INFO    ] __main__: train step 5975: loss: 0.9821, policy_loss: 1.4095, value_loss: 0.8665
2024-07-14 05:33:41,575 [INFO    ] __main__: train step 5976: loss: 0.9822, policy_loss: 1.4094, value_loss: 0.8665
2024-07-14 05:33:41,857 [INFO    ] __main__: train step 5977: loss: 0.9823, policy_loss: 1.4093, value_loss: 0.8664
2024-07-14 05:33:42,129 [INFO    ] __main__: train step 5978: loss: 0.9824, policy_loss: 1.4092, value_loss: 0.8664
2024-07-14 05:33:42,399 [INFO    ] __main__: train step 5979: loss: 0.9824, policy_loss: 1.4092, value_loss: 0.8664
2024-07-14 05:33:42,680 [INFO    ] __main__: train step 5980: loss: 0.9825, policy_loss: 1.4091, value_loss: 0.8664
2024-07-14 05:33:44,281 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:33:44,760 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:33:44,826 [INFO    ] __main__: train step 5981: loss: 0.9826, policy_loss: 1.4090, value_loss: 0.8663
2024-07-14 05:33:45,119 [INFO    ] __main__: train step 5982: loss: 0.9827, policy_loss: 1.4089, value_loss: 0.8663
2024-07-14 05:33:45,390 [INFO    ] __main__: train step 5983: loss: 0.9828, policy_loss: 1.4088, value_loss: 0.8663
2024-07-14 05:33:45,670 [INFO    ] __main__: train step 5984: loss: 0.9829, policy_loss: 1.4088, value_loss: 0.8663
2024-07-14 05:33:45,944 [INFO    ] __main__: train step 5985: loss: 0.9830, policy_loss: 1.4087, value_loss: 0.8662
2024-07-14 05:33:46,248 [INFO    ] __main__: train step 5986: loss: 0.9831, policy_loss: 1.4086, value_loss: 0.8662
2024-07-14 05:33:46,525 [INFO    ] __main__: train step 5987: loss: 0.9831, policy_loss: 1.4085, value_loss: 0.8662
2024-07-14 05:33:46,819 [INFO    ] __main__: train step 5988: loss: 0.9832, policy_loss: 1.4084, value_loss: 0.8661
2024-07-14 05:33:47,107 [INFO    ] __main__: train step 5989: loss: 0.9833, policy_loss: 1.4084, value_loss: 0.8661
2024-07-14 05:33:47,387 [INFO    ] __main__: train step 5990: loss: 0.9834, policy_loss: 1.4083, value_loss: 0.8661
2024-07-14 05:33:47,670 [INFO    ] __main__: train step 5991: loss: 0.9835, policy_loss: 1.4082, value_loss: 0.8661
2024-07-14 05:33:47,949 [INFO    ] __main__: train step 5992: loss: 0.9836, policy_loss: 1.4081, value_loss: 0.8660
2024-07-14 05:33:48,226 [INFO    ] __main__: train step 5993: loss: 0.9837, policy_loss: 1.4080, value_loss: 0.8660
2024-07-14 05:33:48,508 [INFO    ] __main__: train step 5994: loss: 0.9838, policy_loss: 1.4080, value_loss: 0.8660
2024-07-14 05:33:48,802 [INFO    ] __main__: train step 5995: loss: 0.9838, policy_loss: 1.4079, value_loss: 0.8660
2024-07-14 05:33:50,022 [INFO    ] __main__: train step 5996: loss: 0.9839, policy_loss: 1.4078, value_loss: 0.8659
2024-07-14 05:33:50,315 [INFO    ] __main__: train step 5997: loss: 0.9840, policy_loss: 1.4077, value_loss: 0.8659
2024-07-14 05:33:51,918 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:33:52,386 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:33:52,454 [INFO    ] __main__: train step 5998: loss: 0.9841, policy_loss: 1.4076, value_loss: 0.8659
2024-07-14 05:33:52,718 [INFO    ] __main__: train step 5999: loss: 0.9842, policy_loss: 1.4076, value_loss: 0.8658
2024-07-14 05:33:53,005 [INFO    ] __main__: train step 6000: loss: 0.9843, policy_loss: 1.4075, value_loss: 0.8658
2024-07-14 05:33:53,153 [INFO    ] __main__: restored step 5000 for evaluation
2024-07-14 05:33:58,396 [INFO    ] __main__: test network ELO difference from baseline network: +174 (+8/-8) ELO from 32000 self-played games
2024-07-14 05:33:58,399 [INFO    ] __main__: game outcomes: W: 21833, D: 971, L: 9196
2024-07-14 05:33:58,402 [INFO    ] __main__: validation_elo_delta: 174, validation_elo: 1446
2024-07-14 05:33:59,165 [INFO    ] __main__: train step 6001: loss: 0.9844, policy_loss: 1.4074, value_loss: 0.8658
2024-07-14 05:33:59,435 [INFO    ] __main__: train step 6002: loss: 0.9844, policy_loss: 1.4073, value_loss: 0.8658
2024-07-14 05:33:59,709 [INFO    ] __main__: train step 6003: loss: 0.9845, policy_loss: 1.4072, value_loss: 0.8657
2024-07-14 05:33:59,977 [INFO    ] __main__: train step 6004: loss: 0.9846, policy_loss: 1.4072, value_loss: 0.8657
2024-07-14 05:34:00,259 [INFO    ] __main__: train step 6005: loss: 0.9847, policy_loss: 1.4071, value_loss: 0.8657
2024-07-14 05:34:00,535 [INFO    ] __main__: train step 6006: loss: 0.9848, policy_loss: 1.4070, value_loss: 0.8657
2024-07-14 05:34:00,815 [INFO    ] __main__: train step 6007: loss: 0.9849, policy_loss: 1.4069, value_loss: 0.8656
2024-07-14 05:34:01,087 [INFO    ] __main__: train step 6008: loss: 0.9850, policy_loss: 1.4068, value_loss: 0.8656
2024-07-14 05:34:01,366 [INFO    ] __main__: train step 6009: loss: 0.9850, policy_loss: 1.4068, value_loss: 0.8656
2024-07-14 05:34:01,645 [INFO    ] __main__: train step 6010: loss: 0.9851, policy_loss: 1.4067, value_loss: 0.8655
2024-07-14 05:34:01,923 [INFO    ] __main__: train step 6011: loss: 0.9852, policy_loss: 1.4066, value_loss: 0.8655
2024-07-14 05:34:02,200 [INFO    ] __main__: train step 6012: loss: 0.9853, policy_loss: 1.4065, value_loss: 0.8655
2024-07-14 05:34:02,478 [INFO    ] __main__: train step 6013: loss: 0.9854, policy_loss: 1.4064, value_loss: 0.8655
2024-07-14 05:34:02,750 [INFO    ] __main__: train step 6014: loss: 0.9855, policy_loss: 1.4064, value_loss: 0.8654
2024-07-14 05:34:04,338 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:34:04,959 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:34:05,027 [INFO    ] __main__: train step 6015: loss: 0.9856, policy_loss: 1.4063, value_loss: 0.8654
2024-07-14 05:34:05,294 [INFO    ] __main__: train step 6016: loss: 0.9857, policy_loss: 1.4062, value_loss: 0.8654
2024-07-14 05:34:05,565 [INFO    ] __main__: train step 6017: loss: 0.9857, policy_loss: 1.4061, value_loss: 0.8654
2024-07-14 05:34:05,838 [INFO    ] __main__: train step 6018: loss: 0.9858, policy_loss: 1.4060, value_loss: 0.8653
2024-07-14 05:34:06,114 [INFO    ] __main__: train step 6019: loss: 0.9859, policy_loss: 1.4060, value_loss: 0.8653
2024-07-14 05:34:06,386 [INFO    ] __main__: train step 6020: loss: 0.9860, policy_loss: 1.4059, value_loss: 0.8653
2024-07-14 05:34:06,670 [INFO    ] __main__: train step 6021: loss: 0.9861, policy_loss: 1.4058, value_loss: 0.8653
2024-07-14 05:34:06,952 [INFO    ] __main__: train step 6022: loss: 0.9862, policy_loss: 1.4057, value_loss: 0.8652
2024-07-14 05:34:07,239 [INFO    ] __main__: train step 6023: loss: 0.9863, policy_loss: 1.4056, value_loss: 0.8652
2024-07-14 05:34:07,509 [INFO    ] __main__: train step 6024: loss: 0.9863, policy_loss: 1.4056, value_loss: 0.8652
2024-07-14 05:34:07,784 [INFO    ] __main__: train step 6025: loss: 0.9864, policy_loss: 1.4055, value_loss: 0.8652
2024-07-14 05:34:08,073 [INFO    ] __main__: train step 6026: loss: 0.9865, policy_loss: 1.4054, value_loss: 0.8651
2024-07-14 05:34:08,359 [INFO    ] __main__: train step 6027: loss: 0.9866, policy_loss: 1.4053, value_loss: 0.8651
2024-07-14 05:34:08,631 [INFO    ] __main__: train step 6028: loss: 0.9867, policy_loss: 1.4052, value_loss: 0.8651
2024-07-14 05:34:08,900 [INFO    ] __main__: train step 6029: loss: 0.9868, policy_loss: 1.4052, value_loss: 0.8651
2024-07-14 05:34:09,169 [INFO    ] __main__: train step 6030: loss: 0.9869, policy_loss: 1.4051, value_loss: 0.8650
2024-07-14 05:34:09,418 [INFO    ] __main__: train step 6031: loss: 0.9870, policy_loss: 1.4050, value_loss: 0.8650
2024-07-14 05:34:11,018 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:34:11,500 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:34:11,570 [INFO    ] __main__: train step 6032: loss: 0.9870, policy_loss: 1.4049, value_loss: 0.8650
2024-07-14 05:34:11,842 [INFO    ] __main__: train step 6033: loss: 0.9871, policy_loss: 1.4048, value_loss: 0.8650
2024-07-14 05:34:12,111 [INFO    ] __main__: train step 6034: loss: 0.9872, policy_loss: 1.4048, value_loss: 0.8649
2024-07-14 05:34:12,382 [INFO    ] __main__: train step 6035: loss: 0.9873, policy_loss: 1.4047, value_loss: 0.8649
2024-07-14 05:34:12,655 [INFO    ] __main__: train step 6036: loss: 0.9874, policy_loss: 1.4046, value_loss: 0.8649
2024-07-14 05:34:12,935 [INFO    ] __main__: train step 6037: loss: 0.9875, policy_loss: 1.4045, value_loss: 0.8649
2024-07-14 05:34:13,214 [INFO    ] __main__: train step 6038: loss: 0.9876, policy_loss: 1.4044, value_loss: 0.8648
2024-07-14 05:34:13,502 [INFO    ] __main__: train step 6039: loss: 0.9876, policy_loss: 1.4044, value_loss: 0.8648
2024-07-14 05:34:13,781 [INFO    ] __main__: train step 6040: loss: 0.9877, policy_loss: 1.4043, value_loss: 0.8648
2024-07-14 05:34:14,060 [INFO    ] __main__: train step 6041: loss: 0.9878, policy_loss: 1.4042, value_loss: 0.8647
2024-07-14 05:34:14,336 [INFO    ] __main__: train step 6042: loss: 0.9879, policy_loss: 1.4041, value_loss: 0.8647
2024-07-14 05:34:14,616 [INFO    ] __main__: train step 6043: loss: 0.9880, policy_loss: 1.4040, value_loss: 0.8647
2024-07-14 05:34:14,901 [INFO    ] __main__: train step 6044: loss: 0.9881, policy_loss: 1.4039, value_loss: 0.8647
2024-07-14 05:34:15,178 [INFO    ] __main__: train step 6045: loss: 0.9882, policy_loss: 1.4039, value_loss: 0.8646
2024-07-14 05:34:15,448 [INFO    ] __main__: train step 6046: loss: 0.9882, policy_loss: 1.4038, value_loss: 0.8646
2024-07-14 05:34:15,720 [INFO    ] __main__: train step 6047: loss: 0.9883, policy_loss: 1.4037, value_loss: 0.8646
2024-07-14 05:34:15,999 [INFO    ] __main__: train step 6048: loss: 0.9884, policy_loss: 1.4036, value_loss: 0.8646
2024-07-14 05:34:17,600 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:34:18,080 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:34:18,148 [INFO    ] __main__: train step 6049: loss: 0.9885, policy_loss: 1.4035, value_loss: 0.8645
2024-07-14 05:34:18,443 [INFO    ] __main__: train step 6050: loss: 0.9886, policy_loss: 1.4035, value_loss: 0.8645
2024-07-14 05:34:19,758 [INFO    ] __main__: train step 6051: loss: 0.9887, policy_loss: 1.4034, value_loss: 0.8645
2024-07-14 05:34:20,039 [INFO    ] __main__: train step 6052: loss: 0.9888, policy_loss: 1.4033, value_loss: 0.8645
2024-07-14 05:34:20,321 [INFO    ] __main__: train step 6053: loss: 0.9888, policy_loss: 1.4032, value_loss: 0.8644
2024-07-14 05:34:20,603 [INFO    ] __main__: train step 6054: loss: 0.9889, policy_loss: 1.4031, value_loss: 0.8644
2024-07-14 05:34:20,880 [INFO    ] __main__: train step 6055: loss: 0.9890, policy_loss: 1.4031, value_loss: 0.8644
2024-07-14 05:34:21,169 [INFO    ] __main__: train step 6056: loss: 0.9891, policy_loss: 1.4030, value_loss: 0.8644
2024-07-14 05:34:21,447 [INFO    ] __main__: train step 6057: loss: 0.9892, policy_loss: 1.4029, value_loss: 0.8643
2024-07-14 05:34:21,717 [INFO    ] __main__: train step 6058: loss: 0.9893, policy_loss: 1.4028, value_loss: 0.8643
2024-07-14 05:34:21,988 [INFO    ] __main__: train step 6059: loss: 0.9894, policy_loss: 1.4027, value_loss: 0.8643
2024-07-14 05:34:22,262 [INFO    ] __main__: train step 6060: loss: 0.9894, policy_loss: 1.4027, value_loss: 0.8643
2024-07-14 05:34:22,518 [INFO    ] __main__: train step 6061: loss: 0.9895, policy_loss: 1.4026, value_loss: 0.8642
2024-07-14 05:34:22,795 [INFO    ] __main__: train step 6062: loss: 0.9896, policy_loss: 1.4025, value_loss: 0.8642
2024-07-14 05:34:23,082 [INFO    ] __main__: train step 6063: loss: 0.9897, policy_loss: 1.4024, value_loss: 0.8642
2024-07-14 05:34:23,364 [INFO    ] __main__: train step 6064: loss: 0.9898, policy_loss: 1.4023, value_loss: 0.8642
2024-07-14 05:34:23,665 [INFO    ] __main__: train step 6065: loss: 0.9899, policy_loss: 1.4023, value_loss: 0.8641
2024-07-14 05:34:25,247 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:34:25,731 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:34:25,802 [INFO    ] __main__: train step 6066: loss: 0.9899, policy_loss: 1.4022, value_loss: 0.8641
2024-07-14 05:34:26,064 [INFO    ] __main__: train step 6067: loss: 0.9900, policy_loss: 1.4021, value_loss: 0.8641
2024-07-14 05:34:26,335 [INFO    ] __main__: train step 6068: loss: 0.9901, policy_loss: 1.4020, value_loss: 0.8640
2024-07-14 05:34:26,607 [INFO    ] __main__: train step 6069: loss: 0.9902, policy_loss: 1.4019, value_loss: 0.8640
2024-07-14 05:34:26,870 [INFO    ] __main__: train step 6070: loss: 0.9903, policy_loss: 1.4019, value_loss: 0.8640
2024-07-14 05:34:27,140 [INFO    ] __main__: train step 6071: loss: 0.9904, policy_loss: 1.4018, value_loss: 0.8640
2024-07-14 05:34:27,417 [INFO    ] __main__: train step 6072: loss: 0.9905, policy_loss: 1.4017, value_loss: 0.8639
2024-07-14 05:34:27,692 [INFO    ] __main__: train step 6073: loss: 0.9906, policy_loss: 1.4016, value_loss: 0.8639
2024-07-14 05:34:27,982 [INFO    ] __main__: train step 6074: loss: 0.9906, policy_loss: 1.4016, value_loss: 0.8639
2024-07-14 05:34:28,262 [INFO    ] __main__: train step 6075: loss: 0.9907, policy_loss: 1.4015, value_loss: 0.8639
2024-07-14 05:34:28,535 [INFO    ] __main__: train step 6076: loss: 0.9908, policy_loss: 1.4014, value_loss: 0.8638
2024-07-14 05:34:28,805 [INFO    ] __main__: train step 6077: loss: 0.9909, policy_loss: 1.4013, value_loss: 0.8638
2024-07-14 05:34:29,070 [INFO    ] __main__: train step 6078: loss: 0.9910, policy_loss: 1.4012, value_loss: 0.8638
2024-07-14 05:34:29,350 [INFO    ] __main__: train step 6079: loss: 0.9911, policy_loss: 1.4012, value_loss: 0.8638
2024-07-14 05:34:29,631 [INFO    ] __main__: train step 6080: loss: 0.9912, policy_loss: 1.4011, value_loss: 0.8637
2024-07-14 05:34:29,897 [INFO    ] __main__: train step 6081: loss: 0.9912, policy_loss: 1.4010, value_loss: 0.8637
2024-07-14 05:34:30,169 [INFO    ] __main__: train step 6082: loss: 0.9913, policy_loss: 1.4009, value_loss: 0.8637
2024-07-14 05:34:31,763 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:34:32,232 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:34:32,305 [INFO    ] __main__: train step 6083: loss: 0.9914, policy_loss: 1.4008, value_loss: 0.8637
2024-07-14 05:34:32,581 [INFO    ] __main__: train step 6084: loss: 0.9915, policy_loss: 1.4008, value_loss: 0.8636
2024-07-14 05:34:32,861 [INFO    ] __main__: train step 6085: loss: 0.9916, policy_loss: 1.4007, value_loss: 0.8636
2024-07-14 05:34:33,132 [INFO    ] __main__: train step 6086: loss: 0.9917, policy_loss: 1.4006, value_loss: 0.8636
2024-07-14 05:34:33,406 [INFO    ] __main__: train step 6087: loss: 0.9917, policy_loss: 1.4005, value_loss: 0.8635
2024-07-14 05:34:33,670 [INFO    ] __main__: train step 6088: loss: 0.9918, policy_loss: 1.4004, value_loss: 0.8635
2024-07-14 05:34:33,950 [INFO    ] __main__: train step 6089: loss: 0.9919, policy_loss: 1.4004, value_loss: 0.8635
2024-07-14 05:34:34,222 [INFO    ] __main__: train step 6090: loss: 0.9920, policy_loss: 1.4003, value_loss: 0.8635
2024-07-14 05:34:34,493 [INFO    ] __main__: train step 6091: loss: 0.9921, policy_loss: 1.4002, value_loss: 0.8634
2024-07-14 05:34:34,773 [INFO    ] __main__: train step 6092: loss: 0.9922, policy_loss: 1.4001, value_loss: 0.8634
2024-07-14 05:34:35,048 [INFO    ] __main__: train step 6093: loss: 0.9923, policy_loss: 1.4000, value_loss: 0.8634
2024-07-14 05:34:35,318 [INFO    ] __main__: train step 6094: loss: 0.9923, policy_loss: 1.4000, value_loss: 0.8634
2024-07-14 05:34:35,584 [INFO    ] __main__: train step 6095: loss: 0.9924, policy_loss: 1.3999, value_loss: 0.8633
2024-07-14 05:34:35,869 [INFO    ] __main__: train step 6096: loss: 0.9925, policy_loss: 1.3998, value_loss: 0.8633
2024-07-14 05:34:36,159 [INFO    ] __main__: train step 6097: loss: 0.9926, policy_loss: 1.3997, value_loss: 0.8633
2024-07-14 05:34:36,441 [INFO    ] __main__: train step 6098: loss: 0.9927, policy_loss: 1.3996, value_loss: 0.8633
2024-07-14 05:34:36,717 [INFO    ] __main__: train step 6099: loss: 0.9928, policy_loss: 1.3996, value_loss: 0.8632
2024-07-14 05:34:38,303 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:34:38,783 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:34:38,853 [INFO    ] __main__: train step 6100: loss: 0.9929, policy_loss: 1.3995, value_loss: 0.8632
2024-07-14 05:34:39,112 [INFO    ] __main__: train step 6101: loss: 0.9929, policy_loss: 1.3994, value_loss: 0.8632
2024-07-14 05:34:39,396 [INFO    ] __main__: train step 6102: loss: 0.9930, policy_loss: 1.3993, value_loss: 0.8632
2024-07-14 05:34:39,662 [INFO    ] __main__: train step 6103: loss: 0.9931, policy_loss: 1.3993, value_loss: 0.8631
2024-07-14 05:34:39,911 [INFO    ] __main__: train step 6104: loss: 0.9932, policy_loss: 1.3992, value_loss: 0.8631
2024-07-14 05:34:41,609 [INFO    ] __main__: train step 6105: loss: 0.9933, policy_loss: 1.3991, value_loss: 0.8631
2024-07-14 05:34:41,874 [INFO    ] __main__: train step 6106: loss: 0.9934, policy_loss: 1.3990, value_loss: 0.8631
2024-07-14 05:34:42,149 [INFO    ] __main__: train step 6107: loss: 0.9935, policy_loss: 1.3989, value_loss: 0.8630
2024-07-14 05:34:42,439 [INFO    ] __main__: train step 6108: loss: 0.9935, policy_loss: 1.3989, value_loss: 0.8630
2024-07-14 05:34:42,703 [INFO    ] __main__: train step 6109: loss: 0.9936, policy_loss: 1.3988, value_loss: 0.8630
2024-07-14 05:34:42,978 [INFO    ] __main__: train step 6110: loss: 0.9937, policy_loss: 1.3987, value_loss: 0.8630
2024-07-14 05:34:43,259 [INFO    ] __main__: train step 6111: loss: 0.9938, policy_loss: 1.3986, value_loss: 0.8629
2024-07-14 05:34:43,531 [INFO    ] __main__: train step 6112: loss: 0.9939, policy_loss: 1.3985, value_loss: 0.8629
2024-07-14 05:34:43,803 [INFO    ] __main__: train step 6113: loss: 0.9940, policy_loss: 1.3985, value_loss: 0.8629
2024-07-14 05:34:44,079 [INFO    ] __main__: train step 6114: loss: 0.9940, policy_loss: 1.3984, value_loss: 0.8629
2024-07-14 05:34:44,347 [INFO    ] __main__: train step 6115: loss: 0.9941, policy_loss: 1.3983, value_loss: 0.8628
2024-07-14 05:34:44,622 [INFO    ] __main__: train step 6116: loss: 0.9942, policy_loss: 1.3982, value_loss: 0.8628
2024-07-14 05:34:46,201 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:34:46,675 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:34:46,743 [INFO    ] __main__: train step 6117: loss: 0.9943, policy_loss: 1.3981, value_loss: 0.8628
2024-07-14 05:34:47,014 [INFO    ] __main__: train step 6118: loss: 0.9944, policy_loss: 1.3980, value_loss: 0.8627
2024-07-14 05:34:47,279 [INFO    ] __main__: train step 6119: loss: 0.9944, policy_loss: 1.3980, value_loss: 0.8627
2024-07-14 05:34:47,552 [INFO    ] __main__: train step 6120: loss: 0.9945, policy_loss: 1.3979, value_loss: 0.8627
2024-07-14 05:34:47,825 [INFO    ] __main__: train step 6121: loss: 0.9946, policy_loss: 1.3978, value_loss: 0.8627
2024-07-14 05:34:48,094 [INFO    ] __main__: train step 6122: loss: 0.9947, policy_loss: 1.3977, value_loss: 0.8626
2024-07-14 05:34:48,374 [INFO    ] __main__: train step 6123: loss: 0.9948, policy_loss: 1.3977, value_loss: 0.8626
2024-07-14 05:34:48,650 [INFO    ] __main__: train step 6124: loss: 0.9949, policy_loss: 1.3976, value_loss: 0.8626
2024-07-14 05:34:48,916 [INFO    ] __main__: train step 6125: loss: 0.9950, policy_loss: 1.3975, value_loss: 0.8626
2024-07-14 05:34:49,182 [INFO    ] __main__: train step 6126: loss: 0.9950, policy_loss: 1.3974, value_loss: 0.8625
2024-07-14 05:34:49,457 [INFO    ] __main__: train step 6127: loss: 0.9951, policy_loss: 1.3973, value_loss: 0.8625
2024-07-14 05:34:49,740 [INFO    ] __main__: train step 6128: loss: 0.9952, policy_loss: 1.3973, value_loss: 0.8625
2024-07-14 05:34:50,023 [INFO    ] __main__: train step 6129: loss: 0.9953, policy_loss: 1.3972, value_loss: 0.8624
2024-07-14 05:34:50,311 [INFO    ] __main__: train step 6130: loss: 0.9954, policy_loss: 1.3971, value_loss: 0.8624
2024-07-14 05:34:50,584 [INFO    ] __main__: train step 6131: loss: 0.9955, policy_loss: 1.3970, value_loss: 0.8624
2024-07-14 05:34:50,870 [INFO    ] __main__: train step 6132: loss: 0.9955, policy_loss: 1.3969, value_loss: 0.8624
2024-07-14 05:34:51,141 [INFO    ] __main__: train step 6133: loss: 0.9956, policy_loss: 1.3969, value_loss: 0.8623
2024-07-14 05:34:52,754 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:34:53,232 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:34:53,296 [INFO    ] __main__: train step 6134: loss: 0.9957, policy_loss: 1.3968, value_loss: 0.8623
2024-07-14 05:34:53,596 [INFO    ] __main__: train step 6135: loss: 0.9958, policy_loss: 1.3967, value_loss: 0.8623
2024-07-14 05:34:53,863 [INFO    ] __main__: train step 6136: loss: 0.9959, policy_loss: 1.3966, value_loss: 0.8623
2024-07-14 05:34:54,135 [INFO    ] __main__: train step 6137: loss: 0.9960, policy_loss: 1.3965, value_loss: 0.8622
2024-07-14 05:34:54,404 [INFO    ] __main__: train step 6138: loss: 0.9960, policy_loss: 1.3965, value_loss: 0.8622
2024-07-14 05:34:54,680 [INFO    ] __main__: train step 6139: loss: 0.9961, policy_loss: 1.3964, value_loss: 0.8622
2024-07-14 05:34:54,944 [INFO    ] __main__: train step 6140: loss: 0.9962, policy_loss: 1.3963, value_loss: 0.8622
2024-07-14 05:34:55,221 [INFO    ] __main__: train step 6141: loss: 0.9963, policy_loss: 1.3962, value_loss: 0.8621
2024-07-14 05:34:55,507 [INFO    ] __main__: train step 6142: loss: 0.9964, policy_loss: 1.3961, value_loss: 0.8621
2024-07-14 05:34:55,773 [INFO    ] __main__: train step 6143: loss: 0.9965, policy_loss: 1.3961, value_loss: 0.8621
2024-07-14 05:34:56,074 [INFO    ] __main__: train step 6144: loss: 0.9965, policy_loss: 1.3960, value_loss: 0.8621
2024-07-14 05:34:56,357 [INFO    ] __main__: train step 6145: loss: 0.9966, policy_loss: 1.3959, value_loss: 0.8620
2024-07-14 05:34:56,630 [INFO    ] __main__: train step 6146: loss: 0.9967, policy_loss: 1.3958, value_loss: 0.8620
2024-07-14 05:34:56,911 [INFO    ] __main__: train step 6147: loss: 0.9968, policy_loss: 1.3958, value_loss: 0.8620
2024-07-14 05:34:57,197 [INFO    ] __main__: train step 6148: loss: 0.9969, policy_loss: 1.3957, value_loss: 0.8620
2024-07-14 05:34:57,469 [INFO    ] __main__: train step 6149: loss: 0.9970, policy_loss: 1.3956, value_loss: 0.8619
2024-07-14 05:34:57,752 [INFO    ] __main__: train step 6150: loss: 0.9970, policy_loss: 1.3955, value_loss: 0.8619
2024-07-14 05:34:59,345 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:34:59,821 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:34:59,890 [INFO    ] __main__: train step 6151: loss: 0.9971, policy_loss: 1.3954, value_loss: 0.8619
2024-07-14 05:35:00,153 [INFO    ] __main__: train step 6152: loss: 0.9972, policy_loss: 1.3954, value_loss: 0.8619
2024-07-14 05:35:00,426 [INFO    ] __main__: train step 6153: loss: 0.9973, policy_loss: 1.3953, value_loss: 0.8618
2024-07-14 05:35:00,693 [INFO    ] __main__: train step 6154: loss: 0.9974, policy_loss: 1.3952, value_loss: 0.8618
2024-07-14 05:35:00,963 [INFO    ] __main__: train step 6155: loss: 0.9975, policy_loss: 1.3951, value_loss: 0.8618
2024-07-14 05:35:01,265 [INFO    ] __main__: train step 6156: loss: 0.9975, policy_loss: 1.3950, value_loss: 0.8618
2024-07-14 05:35:01,542 [INFO    ] __main__: train step 6157: loss: 0.9976, policy_loss: 1.3950, value_loss: 0.8617
2024-07-14 05:35:01,810 [INFO    ] __main__: train step 6158: loss: 0.9977, policy_loss: 1.3949, value_loss: 0.8617
2024-07-14 05:35:02,093 [INFO    ] __main__: train step 6159: loss: 0.9978, policy_loss: 1.3948, value_loss: 0.8617
2024-07-14 05:35:03,316 [INFO    ] __main__: train step 6160: loss: 0.9979, policy_loss: 1.3947, value_loss: 0.8617
2024-07-14 05:35:03,598 [INFO    ] __main__: train step 6161: loss: 0.9980, policy_loss: 1.3946, value_loss: 0.8616
2024-07-14 05:35:03,873 [INFO    ] __main__: train step 6162: loss: 0.9981, policy_loss: 1.3946, value_loss: 0.8616
2024-07-14 05:35:04,153 [INFO    ] __main__: train step 6163: loss: 0.9981, policy_loss: 1.3945, value_loss: 0.8616
2024-07-14 05:35:04,434 [INFO    ] __main__: train step 6164: loss: 0.9982, policy_loss: 1.3944, value_loss: 0.8616
2024-07-14 05:35:04,715 [INFO    ] __main__: train step 6165: loss: 0.9983, policy_loss: 1.3943, value_loss: 0.8615
2024-07-14 05:35:04,992 [INFO    ] __main__: train step 6166: loss: 0.9984, policy_loss: 1.3943, value_loss: 0.8615
2024-07-14 05:35:05,278 [INFO    ] __main__: train step 6167: loss: 0.9985, policy_loss: 1.3942, value_loss: 0.8615
2024-07-14 05:35:06,854 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:35:07,314 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:35:07,388 [INFO    ] __main__: train step 6168: loss: 0.9986, policy_loss: 1.3941, value_loss: 0.8614
2024-07-14 05:35:07,667 [INFO    ] __main__: train step 6169: loss: 0.9986, policy_loss: 1.3940, value_loss: 0.8614
2024-07-14 05:35:07,938 [INFO    ] __main__: train step 6170: loss: 0.9987, policy_loss: 1.3939, value_loss: 0.8614
2024-07-14 05:35:08,219 [INFO    ] __main__: train step 6171: loss: 0.9988, policy_loss: 1.3939, value_loss: 0.8614
2024-07-14 05:35:08,499 [INFO    ] __main__: train step 6172: loss: 0.9989, policy_loss: 1.3938, value_loss: 0.8613
2024-07-14 05:35:08,778 [INFO    ] __main__: train step 6173: loss: 0.9990, policy_loss: 1.3937, value_loss: 0.8613
2024-07-14 05:35:09,054 [INFO    ] __main__: train step 6174: loss: 0.9991, policy_loss: 1.3936, value_loss: 0.8613
2024-07-14 05:35:09,333 [INFO    ] __main__: train step 6175: loss: 0.9991, policy_loss: 1.3936, value_loss: 0.8613
2024-07-14 05:35:09,618 [INFO    ] __main__: train step 6176: loss: 0.9992, policy_loss: 1.3935, value_loss: 0.8612
2024-07-14 05:35:09,894 [INFO    ] __main__: train step 6177: loss: 0.9993, policy_loss: 1.3934, value_loss: 0.8612
2024-07-14 05:35:10,166 [INFO    ] __main__: train step 6178: loss: 0.9994, policy_loss: 1.3933, value_loss: 0.8612
2024-07-14 05:35:10,448 [INFO    ] __main__: train step 6179: loss: 0.9995, policy_loss: 1.3932, value_loss: 0.8612
2024-07-14 05:35:10,733 [INFO    ] __main__: train step 6180: loss: 0.9996, policy_loss: 1.3932, value_loss: 0.8611
2024-07-14 05:35:11,001 [INFO    ] __main__: train step 6181: loss: 0.9996, policy_loss: 1.3931, value_loss: 0.8611
2024-07-14 05:35:11,281 [INFO    ] __main__: train step 6182: loss: 0.9997, policy_loss: 1.3930, value_loss: 0.8611
2024-07-14 05:35:11,541 [INFO    ] __main__: train step 6183: loss: 0.9998, policy_loss: 1.3929, value_loss: 0.8611
2024-07-14 05:35:11,797 [INFO    ] __main__: train step 6184: loss: 0.9999, policy_loss: 1.3928, value_loss: 0.8610
2024-07-14 05:35:13,385 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:35:13,855 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:35:13,923 [INFO    ] __main__: train step 6185: loss: 1.0000, policy_loss: 1.3928, value_loss: 0.8610
2024-07-14 05:35:14,193 [INFO    ] __main__: train step 6186: loss: 1.0000, policy_loss: 1.3927, value_loss: 0.8610
2024-07-14 05:35:14,471 [INFO    ] __main__: train step 6187: loss: 1.0001, policy_loss: 1.3926, value_loss: 0.8610
2024-07-14 05:35:14,745 [INFO    ] __main__: train step 6188: loss: 1.0002, policy_loss: 1.3925, value_loss: 0.8609
2024-07-14 05:35:15,017 [INFO    ] __main__: train step 6189: loss: 1.0003, policy_loss: 1.3925, value_loss: 0.8609
2024-07-14 05:35:15,287 [INFO    ] __main__: train step 6190: loss: 1.0004, policy_loss: 1.3924, value_loss: 0.8609
2024-07-14 05:35:15,561 [INFO    ] __main__: train step 6191: loss: 1.0005, policy_loss: 1.3923, value_loss: 0.8609
2024-07-14 05:35:15,854 [INFO    ] __main__: train step 6192: loss: 1.0005, policy_loss: 1.3922, value_loss: 0.8608
2024-07-14 05:35:16,140 [INFO    ] __main__: train step 6193: loss: 1.0006, policy_loss: 1.3921, value_loss: 0.8608
2024-07-14 05:35:16,426 [INFO    ] __main__: train step 6194: loss: 1.0007, policy_loss: 1.3921, value_loss: 0.8608
2024-07-14 05:35:16,697 [INFO    ] __main__: train step 6195: loss: 1.0008, policy_loss: 1.3920, value_loss: 0.8608
2024-07-14 05:35:16,982 [INFO    ] __main__: train step 6196: loss: 1.0009, policy_loss: 1.3919, value_loss: 0.8607
2024-07-14 05:35:17,261 [INFO    ] __main__: train step 6197: loss: 1.0010, policy_loss: 1.3918, value_loss: 0.8607
2024-07-14 05:35:17,536 [INFO    ] __main__: train step 6198: loss: 1.0010, policy_loss: 1.3917, value_loss: 0.8607
2024-07-14 05:35:17,804 [INFO    ] __main__: train step 6199: loss: 1.0011, policy_loss: 1.3917, value_loss: 0.8606
2024-07-14 05:35:18,090 [INFO    ] __main__: train step 6200: loss: 1.0012, policy_loss: 1.3916, value_loss: 0.8606
2024-07-14 05:35:18,360 [INFO    ] __main__: train step 6201: loss: 1.0013, policy_loss: 1.3915, value_loss: 0.8606
2024-07-14 05:35:19,950 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:35:20,430 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:35:20,497 [INFO    ] __main__: train step 6202: loss: 1.0014, policy_loss: 1.3914, value_loss: 0.8606
2024-07-14 05:35:20,774 [INFO    ] __main__: train step 6203: loss: 1.0015, policy_loss: 1.3914, value_loss: 0.8605
2024-07-14 05:35:21,041 [INFO    ] __main__: train step 6204: loss: 1.0015, policy_loss: 1.3913, value_loss: 0.8605
2024-07-14 05:35:21,321 [INFO    ] __main__: train step 6205: loss: 1.0016, policy_loss: 1.3912, value_loss: 0.8605
2024-07-14 05:35:21,596 [INFO    ] __main__: train step 6206: loss: 1.0017, policy_loss: 1.3911, value_loss: 0.8605
2024-07-14 05:35:21,874 [INFO    ] __main__: train step 6207: loss: 1.0018, policy_loss: 1.3910, value_loss: 0.8604
2024-07-14 05:35:22,162 [INFO    ] __main__: train step 6208: loss: 1.0019, policy_loss: 1.3910, value_loss: 0.8604
2024-07-14 05:35:22,441 [INFO    ] __main__: train step 6209: loss: 1.0019, policy_loss: 1.3909, value_loss: 0.8604
2024-07-14 05:35:22,733 [INFO    ] __main__: train step 6210: loss: 1.0020, policy_loss: 1.3908, value_loss: 0.8604
2024-07-14 05:35:23,010 [INFO    ] __main__: train step 6211: loss: 1.0021, policy_loss: 1.3907, value_loss: 0.8603
2024-07-14 05:35:23,284 [INFO    ] __main__: train step 6212: loss: 1.0022, policy_loss: 1.3906, value_loss: 0.8603
2024-07-14 05:35:23,565 [INFO    ] __main__: train step 6213: loss: 1.0023, policy_loss: 1.3906, value_loss: 0.8603
2024-07-14 05:35:23,847 [INFO    ] __main__: train step 6214: loss: 1.0024, policy_loss: 1.3905, value_loss: 0.8603
2024-07-14 05:35:25,641 [INFO    ] __main__: train step 6215: loss: 1.0024, policy_loss: 1.3904, value_loss: 0.8602
2024-07-14 05:35:25,925 [INFO    ] __main__: train step 6216: loss: 1.0025, policy_loss: 1.3903, value_loss: 0.8602
2024-07-14 05:35:26,196 [INFO    ] __main__: train step 6217: loss: 1.0026, policy_loss: 1.3903, value_loss: 0.8602
2024-07-14 05:35:26,487 [INFO    ] __main__: train step 6218: loss: 1.0027, policy_loss: 1.3902, value_loss: 0.8602
2024-07-14 05:35:28,088 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:35:28,556 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:35:28,620 [INFO    ] __main__: train step 6219: loss: 1.0028, policy_loss: 1.3901, value_loss: 0.8601
2024-07-14 05:35:28,902 [INFO    ] __main__: train step 6220: loss: 1.0029, policy_loss: 1.3900, value_loss: 0.8601
2024-07-14 05:35:29,170 [INFO    ] __main__: train step 6221: loss: 1.0029, policy_loss: 1.3899, value_loss: 0.8601
2024-07-14 05:35:29,446 [INFO    ] __main__: train step 6222: loss: 1.0030, policy_loss: 1.3899, value_loss: 0.8601
2024-07-14 05:35:29,725 [INFO    ] __main__: train step 6223: loss: 1.0031, policy_loss: 1.3898, value_loss: 0.8600
2024-07-14 05:35:30,005 [INFO    ] __main__: train step 6224: loss: 1.0032, policy_loss: 1.3897, value_loss: 0.8600
2024-07-14 05:35:30,284 [INFO    ] __main__: train step 6225: loss: 1.0033, policy_loss: 1.3896, value_loss: 0.8600
2024-07-14 05:35:30,582 [INFO    ] __main__: train step 6226: loss: 1.0033, policy_loss: 1.3895, value_loss: 0.8600
2024-07-14 05:35:30,862 [INFO    ] __main__: train step 6227: loss: 1.0034, policy_loss: 1.3895, value_loss: 0.8599
2024-07-14 05:35:31,140 [INFO    ] __main__: train step 6228: loss: 1.0035, policy_loss: 1.3894, value_loss: 0.8599
2024-07-14 05:35:31,416 [INFO    ] __main__: train step 6229: loss: 1.0036, policy_loss: 1.3893, value_loss: 0.8599
2024-07-14 05:35:31,690 [INFO    ] __main__: train step 6230: loss: 1.0037, policy_loss: 1.3892, value_loss: 0.8599
2024-07-14 05:35:31,974 [INFO    ] __main__: train step 6231: loss: 1.0038, policy_loss: 1.3892, value_loss: 0.8598
2024-07-14 05:35:32,223 [INFO    ] __main__: train step 6232: loss: 1.0038, policy_loss: 1.3891, value_loss: 0.8598
2024-07-14 05:35:32,478 [INFO    ] __main__: train step 6233: loss: 1.0039, policy_loss: 1.3890, value_loss: 0.8598
2024-07-14 05:35:32,736 [INFO    ] __main__: train step 6234: loss: 1.0040, policy_loss: 1.3889, value_loss: 0.8598
2024-07-14 05:35:32,999 [INFO    ] __main__: train step 6235: loss: 1.0041, policy_loss: 1.3888, value_loss: 0.8597
2024-07-14 05:35:34,607 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:35:35,088 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:35:35,160 [INFO    ] __main__: train step 6236: loss: 1.0042, policy_loss: 1.3888, value_loss: 0.8597
2024-07-14 05:35:35,440 [INFO    ] __main__: train step 6237: loss: 1.0042, policy_loss: 1.3887, value_loss: 0.8597
2024-07-14 05:35:35,719 [INFO    ] __main__: train step 6238: loss: 1.0043, policy_loss: 1.3886, value_loss: 0.8597
2024-07-14 05:35:36,021 [INFO    ] __main__: train step 6239: loss: 1.0044, policy_loss: 1.3885, value_loss: 0.8596
2024-07-14 05:35:36,293 [INFO    ] __main__: train step 6240: loss: 1.0045, policy_loss: 1.3884, value_loss: 0.8596
2024-07-14 05:35:36,568 [INFO    ] __main__: train step 6241: loss: 1.0046, policy_loss: 1.3884, value_loss: 0.8596
2024-07-14 05:35:36,854 [INFO    ] __main__: train step 6242: loss: 1.0047, policy_loss: 1.3883, value_loss: 0.8596
2024-07-14 05:35:37,135 [INFO    ] __main__: train step 6243: loss: 1.0047, policy_loss: 1.3882, value_loss: 0.8595
2024-07-14 05:35:37,408 [INFO    ] __main__: train step 6244: loss: 1.0048, policy_loss: 1.3881, value_loss: 0.8595
2024-07-14 05:35:37,676 [INFO    ] __main__: train step 6245: loss: 1.0049, policy_loss: 1.3881, value_loss: 0.8595
2024-07-14 05:35:37,964 [INFO    ] __main__: train step 6246: loss: 1.0050, policy_loss: 1.3880, value_loss: 0.8595
2024-07-14 05:35:38,258 [INFO    ] __main__: train step 6247: loss: 1.0051, policy_loss: 1.3879, value_loss: 0.8594
2024-07-14 05:35:38,535 [INFO    ] __main__: train step 6248: loss: 1.0051, policy_loss: 1.3878, value_loss: 0.8594
2024-07-14 05:35:38,829 [INFO    ] __main__: train step 6249: loss: 1.0052, policy_loss: 1.3877, value_loss: 0.8594
2024-07-14 05:35:39,110 [INFO    ] __main__: train step 6250: loss: 1.0053, policy_loss: 1.3877, value_loss: 0.8593
2024-07-14 05:35:39,388 [INFO    ] __main__: train step 6251: loss: 1.0054, policy_loss: 1.3876, value_loss: 0.8593
2024-07-14 05:35:39,652 [INFO    ] __main__: train step 6252: loss: 1.0055, policy_loss: 1.3875, value_loss: 0.8593
2024-07-14 05:35:41,276 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:35:41,761 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:35:41,828 [INFO    ] __main__: train step 6253: loss: 1.0055, policy_loss: 1.3874, value_loss: 0.8593
2024-07-14 05:35:42,108 [INFO    ] __main__: train step 6254: loss: 1.0056, policy_loss: 1.3873, value_loss: 0.8592
2024-07-14 05:35:42,387 [INFO    ] __main__: train step 6255: loss: 1.0057, policy_loss: 1.3873, value_loss: 0.8592
2024-07-14 05:35:42,676 [INFO    ] __main__: train step 6256: loss: 1.0058, policy_loss: 1.3872, value_loss: 0.8592
2024-07-14 05:35:42,934 [INFO    ] __main__: train step 6257: loss: 1.0059, policy_loss: 1.3871, value_loss: 0.8592
2024-07-14 05:35:43,204 [INFO    ] __main__: train step 6258: loss: 1.0059, policy_loss: 1.3870, value_loss: 0.8591
2024-07-14 05:35:43,479 [INFO    ] __main__: train step 6259: loss: 1.0060, policy_loss: 1.3870, value_loss: 0.8591
2024-07-14 05:35:43,758 [INFO    ] __main__: train step 6260: loss: 1.0061, policy_loss: 1.3869, value_loss: 0.8591
2024-07-14 05:35:44,020 [INFO    ] __main__: train step 6261: loss: 1.0062, policy_loss: 1.3868, value_loss: 0.8591
2024-07-14 05:35:44,291 [INFO    ] __main__: train step 6262: loss: 1.0063, policy_loss: 1.3867, value_loss: 0.8590
2024-07-14 05:35:44,577 [INFO    ] __main__: train step 6263: loss: 1.0063, policy_loss: 1.3866, value_loss: 0.8590
2024-07-14 05:35:44,859 [INFO    ] __main__: train step 6264: loss: 1.0064, policy_loss: 1.3866, value_loss: 0.8590
2024-07-14 05:35:45,141 [INFO    ] __main__: train step 6265: loss: 1.0065, policy_loss: 1.3865, value_loss: 0.8590
2024-07-14 05:35:45,439 [INFO    ] __main__: train step 6266: loss: 1.0066, policy_loss: 1.3864, value_loss: 0.8589
2024-07-14 05:35:45,746 [INFO    ] __main__: train step 6267: loss: 1.0067, policy_loss: 1.3863, value_loss: 0.8589
2024-07-14 05:35:46,025 [INFO    ] __main__: train step 6268: loss: 1.0068, policy_loss: 1.3863, value_loss: 0.8589
2024-07-14 05:35:46,308 [INFO    ] __main__: train step 6269: loss: 1.0068, policy_loss: 1.3862, value_loss: 0.8589
2024-07-14 05:35:49,398 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:35:49,868 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:35:49,938 [INFO    ] __main__: train step 6270: loss: 1.0069, policy_loss: 1.3861, value_loss: 0.8588
2024-07-14 05:35:50,209 [INFO    ] __main__: train step 6271: loss: 1.0070, policy_loss: 1.3860, value_loss: 0.8588
2024-07-14 05:35:50,496 [INFO    ] __main__: train step 6272: loss: 1.0071, policy_loss: 1.3859, value_loss: 0.8588
2024-07-14 05:35:50,780 [INFO    ] __main__: train step 6273: loss: 1.0072, policy_loss: 1.3859, value_loss: 0.8588
2024-07-14 05:35:51,057 [INFO    ] __main__: train step 6274: loss: 1.0072, policy_loss: 1.3858, value_loss: 0.8587
2024-07-14 05:35:51,349 [INFO    ] __main__: train step 6275: loss: 1.0073, policy_loss: 1.3857, value_loss: 0.8587
2024-07-14 05:35:51,625 [INFO    ] __main__: train step 6276: loss: 1.0074, policy_loss: 1.3856, value_loss: 0.8587
2024-07-14 05:35:51,901 [INFO    ] __main__: train step 6277: loss: 1.0075, policy_loss: 1.3856, value_loss: 0.8587
2024-07-14 05:35:52,175 [INFO    ] __main__: train step 6278: loss: 1.0076, policy_loss: 1.3855, value_loss: 0.8586
2024-07-14 05:35:52,434 [INFO    ] __main__: train step 6279: loss: 1.0077, policy_loss: 1.3854, value_loss: 0.8586
2024-07-14 05:35:52,708 [INFO    ] __main__: train step 6280: loss: 1.0077, policy_loss: 1.3853, value_loss: 0.8586
2024-07-14 05:35:52,985 [INFO    ] __main__: train step 6281: loss: 1.0078, policy_loss: 1.3853, value_loss: 0.8586
2024-07-14 05:35:53,265 [INFO    ] __main__: train step 6282: loss: 1.0079, policy_loss: 1.3852, value_loss: 0.8585
2024-07-14 05:35:53,551 [INFO    ] __main__: train step 6283: loss: 1.0080, policy_loss: 1.3851, value_loss: 0.8585
2024-07-14 05:35:53,826 [INFO    ] __main__: train step 6284: loss: 1.0081, policy_loss: 1.3850, value_loss: 0.8585
2024-07-14 05:35:54,104 [INFO    ] __main__: train step 6285: loss: 1.0081, policy_loss: 1.3849, value_loss: 0.8585
2024-07-14 05:35:54,383 [INFO    ] __main__: train step 6286: loss: 1.0082, policy_loss: 1.3849, value_loss: 0.8584
2024-07-14 05:35:55,983 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:35:56,457 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:35:56,528 [INFO    ] __main__: train step 6287: loss: 1.0083, policy_loss: 1.3848, value_loss: 0.8584
2024-07-14 05:35:56,808 [INFO    ] __main__: train step 6288: loss: 1.0084, policy_loss: 1.3847, value_loss: 0.8584
2024-07-14 05:35:57,090 [INFO    ] __main__: train step 6289: loss: 1.0085, policy_loss: 1.3846, value_loss: 0.8584
2024-07-14 05:35:57,379 [INFO    ] __main__: train step 6290: loss: 1.0085, policy_loss: 1.3846, value_loss: 0.8583
2024-07-14 05:35:57,656 [INFO    ] __main__: train step 6291: loss: 1.0086, policy_loss: 1.3845, value_loss: 0.8583
2024-07-14 05:35:57,937 [INFO    ] __main__: train step 6292: loss: 1.0087, policy_loss: 1.3844, value_loss: 0.8583
2024-07-14 05:35:58,240 [INFO    ] __main__: train step 6293: loss: 1.0088, policy_loss: 1.3843, value_loss: 0.8582
2024-07-14 05:35:58,516 [INFO    ] __main__: train step 6294: loss: 1.0089, policy_loss: 1.3842, value_loss: 0.8582
2024-07-14 05:35:58,789 [INFO    ] __main__: train step 6295: loss: 1.0089, policy_loss: 1.3842, value_loss: 0.8582
2024-07-14 05:35:59,068 [INFO    ] __main__: train step 6296: loss: 1.0090, policy_loss: 1.3841, value_loss: 0.8582
2024-07-14 05:35:59,352 [INFO    ] __main__: train step 6297: loss: 1.0091, policy_loss: 1.3840, value_loss: 0.8582
2024-07-14 05:35:59,630 [INFO    ] __main__: train step 6298: loss: 1.0092, policy_loss: 1.3839, value_loss: 0.8581
2024-07-14 05:35:59,913 [INFO    ] __main__: train step 6299: loss: 1.0093, policy_loss: 1.3839, value_loss: 0.8581
2024-07-14 05:36:00,193 [INFO    ] __main__: train step 6300: loss: 1.0093, policy_loss: 1.3838, value_loss: 0.8581
2024-07-14 05:36:00,471 [INFO    ] __main__: train step 6301: loss: 1.0094, policy_loss: 1.3837, value_loss: 0.8580
2024-07-14 05:36:00,753 [INFO    ] __main__: train step 6302: loss: 1.0095, policy_loss: 1.3836, value_loss: 0.8580
2024-07-14 05:36:01,031 [INFO    ] __main__: train step 6303: loss: 1.0096, policy_loss: 1.3836, value_loss: 0.8580
2024-07-14 05:36:02,617 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:36:03,110 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:36:03,180 [INFO    ] __main__: train step 6304: loss: 1.0097, policy_loss: 1.3835, value_loss: 0.8580
2024-07-14 05:36:03,457 [INFO    ] __main__: train step 6305: loss: 1.0097, policy_loss: 1.3834, value_loss: 0.8579
2024-07-14 05:36:03,734 [INFO    ] __main__: train step 6306: loss: 1.0098, policy_loss: 1.3833, value_loss: 0.8579
2024-07-14 05:36:04,021 [INFO    ] __main__: train step 6307: loss: 1.0099, policy_loss: 1.3833, value_loss: 0.8579
2024-07-14 05:36:04,297 [INFO    ] __main__: train step 6308: loss: 1.0100, policy_loss: 1.3832, value_loss: 0.8579
2024-07-14 05:36:04,591 [INFO    ] __main__: train step 6309: loss: 1.0101, policy_loss: 1.3831, value_loss: 0.8578
2024-07-14 05:36:04,865 [INFO    ] __main__: train step 6310: loss: 1.0102, policy_loss: 1.3830, value_loss: 0.8578
2024-07-14 05:36:05,143 [INFO    ] __main__: train step 6311: loss: 1.0102, policy_loss: 1.3829, value_loss: 0.8578
2024-07-14 05:36:05,430 [INFO    ] __main__: train step 6312: loss: 1.0103, policy_loss: 1.3829, value_loss: 0.8578
2024-07-14 05:36:05,707 [INFO    ] __main__: train step 6313: loss: 1.0104, policy_loss: 1.3828, value_loss: 0.8578
2024-07-14 05:36:05,986 [INFO    ] __main__: train step 6314: loss: 1.0105, policy_loss: 1.3827, value_loss: 0.8577
2024-07-14 05:36:06,261 [INFO    ] __main__: train step 6315: loss: 1.0106, policy_loss: 1.3826, value_loss: 0.8577
2024-07-14 05:36:06,540 [INFO    ] __main__: train step 6316: loss: 1.0106, policy_loss: 1.3826, value_loss: 0.8577
2024-07-14 05:36:06,811 [INFO    ] __main__: train step 6317: loss: 1.0107, policy_loss: 1.3825, value_loss: 0.8576
2024-07-14 05:36:07,076 [INFO    ] __main__: train step 6318: loss: 1.0108, policy_loss: 1.3824, value_loss: 0.8576
2024-07-14 05:36:07,361 [INFO    ] __main__: train step 6319: loss: 1.0109, policy_loss: 1.3823, value_loss: 0.8576
2024-07-14 05:36:07,609 [INFO    ] __main__: train step 6320: loss: 1.0110, policy_loss: 1.3823, value_loss: 0.8576
2024-07-14 05:36:09,216 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:36:09,682 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:36:09,749 [INFO    ] __main__: train step 6321: loss: 1.0110, policy_loss: 1.3822, value_loss: 0.8576
2024-07-14 05:36:10,030 [INFO    ] __main__: train step 6322: loss: 1.0111, policy_loss: 1.3821, value_loss: 0.8575
2024-07-14 05:36:10,299 [INFO    ] __main__: train step 6323: loss: 1.0112, policy_loss: 1.3820, value_loss: 0.8575
2024-07-14 05:36:10,579 [INFO    ] __main__: train step 6324: loss: 1.0113, policy_loss: 1.3819, value_loss: 0.8575
2024-07-14 05:36:11,888 [INFO    ] __main__: train step 6325: loss: 1.0114, policy_loss: 1.3819, value_loss: 0.8574
2024-07-14 05:36:12,163 [INFO    ] __main__: train step 6326: loss: 1.0114, policy_loss: 1.3818, value_loss: 0.8574
2024-07-14 05:36:12,447 [INFO    ] __main__: train step 6327: loss: 1.0115, policy_loss: 1.3817, value_loss: 0.8574
2024-07-14 05:36:12,736 [INFO    ] __main__: train step 6328: loss: 1.0116, policy_loss: 1.3816, value_loss: 0.8574
2024-07-14 05:36:13,025 [INFO    ] __main__: train step 6329: loss: 1.0117, policy_loss: 1.3816, value_loss: 0.8573
2024-07-14 05:36:13,318 [INFO    ] __main__: train step 6330: loss: 1.0118, policy_loss: 1.3815, value_loss: 0.8573
2024-07-14 05:36:13,610 [INFO    ] __main__: train step 6331: loss: 1.0118, policy_loss: 1.3814, value_loss: 0.8573
2024-07-14 05:36:13,892 [INFO    ] __main__: train step 6332: loss: 1.0119, policy_loss: 1.3813, value_loss: 0.8573
2024-07-14 05:36:14,156 [INFO    ] __main__: train step 6333: loss: 1.0120, policy_loss: 1.3813, value_loss: 0.8572
2024-07-14 05:36:14,430 [INFO    ] __main__: train step 6334: loss: 1.0121, policy_loss: 1.3812, value_loss: 0.8572
2024-07-14 05:36:14,714 [INFO    ] __main__: train step 6335: loss: 1.0122, policy_loss: 1.3811, value_loss: 0.8572
2024-07-14 05:36:15,014 [INFO    ] __main__: train step 6336: loss: 1.0123, policy_loss: 1.3810, value_loss: 0.8572
2024-07-14 05:36:15,281 [INFO    ] __main__: train step 6337: loss: 1.0123, policy_loss: 1.3810, value_loss: 0.8571
2024-07-14 05:36:16,874 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:36:17,342 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:36:17,410 [INFO    ] __main__: train step 6338: loss: 1.0124, policy_loss: 1.3809, value_loss: 0.8571
2024-07-14 05:36:17,701 [INFO    ] __main__: train step 6339: loss: 1.0125, policy_loss: 1.3808, value_loss: 0.8571
2024-07-14 05:36:17,979 [INFO    ] __main__: train step 6340: loss: 1.0126, policy_loss: 1.3808, value_loss: 0.8571
2024-07-14 05:36:18,254 [INFO    ] __main__: train step 6341: loss: 1.0127, policy_loss: 1.3807, value_loss: 0.8570
2024-07-14 05:36:18,533 [INFO    ] __main__: train step 6342: loss: 1.0128, policy_loss: 1.3806, value_loss: 0.8570
2024-07-14 05:36:18,819 [INFO    ] __main__: train step 6343: loss: 1.0128, policy_loss: 1.3805, value_loss: 0.8570
2024-07-14 05:36:19,102 [INFO    ] __main__: train step 6344: loss: 1.0129, policy_loss: 1.3805, value_loss: 0.8570
2024-07-14 05:36:19,389 [INFO    ] __main__: train step 6345: loss: 1.0130, policy_loss: 1.3804, value_loss: 0.8569
2024-07-14 05:36:19,666 [INFO    ] __main__: train step 6346: loss: 1.0131, policy_loss: 1.3803, value_loss: 0.8569
2024-07-14 05:36:19,970 [INFO    ] __main__: train step 6347: loss: 1.0132, policy_loss: 1.3803, value_loss: 0.8569
2024-07-14 05:36:20,256 [INFO    ] __main__: train step 6348: loss: 1.0133, policy_loss: 1.3802, value_loss: 0.8569
2024-07-14 05:36:20,527 [INFO    ] __main__: train step 6349: loss: 1.0133, policy_loss: 1.3801, value_loss: 0.8568
2024-07-14 05:36:20,810 [INFO    ] __main__: train step 6350: loss: 1.0134, policy_loss: 1.3800, value_loss: 0.8568
2024-07-14 05:36:21,092 [INFO    ] __main__: train step 6351: loss: 1.0135, policy_loss: 1.3800, value_loss: 0.8568
2024-07-14 05:36:21,375 [INFO    ] __main__: train step 6352: loss: 1.0136, policy_loss: 1.3799, value_loss: 0.8568
2024-07-14 05:36:21,660 [INFO    ] __main__: train step 6353: loss: 1.0137, policy_loss: 1.3798, value_loss: 0.8568
2024-07-14 05:36:21,942 [INFO    ] __main__: train step 6354: loss: 1.0138, policy_loss: 1.3797, value_loss: 0.8567
2024-07-14 05:36:23,570 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:36:24,035 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:36:24,104 [INFO    ] __main__: train step 6355: loss: 1.0138, policy_loss: 1.3797, value_loss: 0.8567
2024-07-14 05:36:24,389 [INFO    ] __main__: train step 6356: loss: 1.0139, policy_loss: 1.3796, value_loss: 0.8567
2024-07-14 05:36:24,670 [INFO    ] __main__: train step 6357: loss: 1.0140, policy_loss: 1.3795, value_loss: 0.8567
2024-07-14 05:36:24,950 [INFO    ] __main__: train step 6358: loss: 1.0141, policy_loss: 1.3794, value_loss: 0.8566
2024-07-14 05:36:25,236 [INFO    ] __main__: train step 6359: loss: 1.0142, policy_loss: 1.3794, value_loss: 0.8566
2024-07-14 05:36:25,524 [INFO    ] __main__: train step 6360: loss: 1.0142, policy_loss: 1.3793, value_loss: 0.8566
2024-07-14 05:36:25,812 [INFO    ] __main__: train step 6361: loss: 1.0143, policy_loss: 1.3792, value_loss: 0.8566
2024-07-14 05:36:26,078 [INFO    ] __main__: train step 6362: loss: 1.0144, policy_loss: 1.3791, value_loss: 0.8565
2024-07-14 05:36:26,355 [INFO    ] __main__: train step 6363: loss: 1.0145, policy_loss: 1.3791, value_loss: 0.8565
2024-07-14 05:36:26,644 [INFO    ] __main__: train step 6364: loss: 1.0146, policy_loss: 1.3790, value_loss: 0.8565
2024-07-14 05:36:26,924 [INFO    ] __main__: train step 6365: loss: 1.0146, policy_loss: 1.3789, value_loss: 0.8565
2024-07-14 05:36:27,203 [INFO    ] __main__: train step 6366: loss: 1.0147, policy_loss: 1.3788, value_loss: 0.8564
2024-07-14 05:36:27,485 [INFO    ] __main__: train step 6367: loss: 1.0148, policy_loss: 1.3788, value_loss: 0.8564
2024-07-14 05:36:27,775 [INFO    ] __main__: train step 6368: loss: 1.0149, policy_loss: 1.3787, value_loss: 0.8564
2024-07-14 05:36:28,052 [INFO    ] __main__: train step 6369: loss: 1.0150, policy_loss: 1.3786, value_loss: 0.8564
2024-07-14 05:36:28,339 [INFO    ] __main__: train step 6370: loss: 1.0150, policy_loss: 1.3785, value_loss: 0.8563
2024-07-14 05:36:28,616 [INFO    ] __main__: train step 6371: loss: 1.0151, policy_loss: 1.3785, value_loss: 0.8563
2024-07-14 05:36:30,226 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:36:30,714 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:36:30,785 [INFO    ] __main__: train step 6372: loss: 1.0152, policy_loss: 1.3784, value_loss: 0.8563
2024-07-14 05:36:31,086 [INFO    ] __main__: train step 6373: loss: 1.0153, policy_loss: 1.3783, value_loss: 0.8563
2024-07-14 05:36:31,369 [INFO    ] __main__: train step 6374: loss: 1.0153, policy_loss: 1.3782, value_loss: 0.8562
2024-07-14 05:36:31,645 [INFO    ] __main__: train step 6375: loss: 1.0154, policy_loss: 1.3781, value_loss: 0.8562
2024-07-14 05:36:31,940 [INFO    ] __main__: train step 6376: loss: 1.0155, policy_loss: 1.3781, value_loss: 0.8562
2024-07-14 05:36:32,219 [INFO    ] __main__: train step 6377: loss: 1.0156, policy_loss: 1.3780, value_loss: 0.8562
2024-07-14 05:36:32,496 [INFO    ] __main__: train step 6378: loss: 1.0157, policy_loss: 1.3779, value_loss: 0.8561
2024-07-14 05:36:32,775 [INFO    ] __main__: train step 6379: loss: 1.0157, policy_loss: 1.3778, value_loss: 0.8561
2024-07-14 05:36:34,481 [INFO    ] __main__: train step 6380: loss: 1.0158, policy_loss: 1.3778, value_loss: 0.8561
2024-07-14 05:36:34,771 [INFO    ] __main__: train step 6381: loss: 1.0159, policy_loss: 1.3777, value_loss: 0.8561
2024-07-14 05:36:35,057 [INFO    ] __main__: train step 6382: loss: 1.0160, policy_loss: 1.3776, value_loss: 0.8560
2024-07-14 05:36:35,346 [INFO    ] __main__: train step 6383: loss: 1.0161, policy_loss: 1.3775, value_loss: 0.8560
2024-07-14 05:36:35,640 [INFO    ] __main__: train step 6384: loss: 1.0162, policy_loss: 1.3775, value_loss: 0.8560
2024-07-14 05:36:35,949 [INFO    ] __main__: train step 6385: loss: 1.0162, policy_loss: 1.3774, value_loss: 0.8560
2024-07-14 05:36:36,245 [INFO    ] __main__: train step 6386: loss: 1.0163, policy_loss: 1.3773, value_loss: 0.8559
2024-07-14 05:36:36,531 [INFO    ] __main__: train step 6387: loss: 1.0164, policy_loss: 1.3772, value_loss: 0.8559
2024-07-14 05:36:36,821 [INFO    ] __main__: train step 6388: loss: 1.0165, policy_loss: 1.3772, value_loss: 0.8559
2024-07-14 05:36:38,449 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:36:38,924 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:36:38,992 [INFO    ] __main__: train step 6389: loss: 1.0166, policy_loss: 1.3771, value_loss: 0.8559
2024-07-14 05:36:39,279 [INFO    ] __main__: train step 6390: loss: 1.0166, policy_loss: 1.3770, value_loss: 0.8558
2024-07-14 05:36:39,558 [INFO    ] __main__: train step 6391: loss: 1.0167, policy_loss: 1.3769, value_loss: 0.8558
2024-07-14 05:36:39,846 [INFO    ] __main__: train step 6392: loss: 1.0168, policy_loss: 1.3769, value_loss: 0.8558
2024-07-14 05:36:40,131 [INFO    ] __main__: train step 6393: loss: 1.0169, policy_loss: 1.3768, value_loss: 0.8558
2024-07-14 05:36:40,419 [INFO    ] __main__: train step 6394: loss: 1.0170, policy_loss: 1.3767, value_loss: 0.8558
2024-07-14 05:36:40,696 [INFO    ] __main__: train step 6395: loss: 1.0170, policy_loss: 1.3766, value_loss: 0.8557
2024-07-14 05:36:40,975 [INFO    ] __main__: train step 6396: loss: 1.0171, policy_loss: 1.3766, value_loss: 0.8557
2024-07-14 05:36:41,252 [INFO    ] __main__: train step 6397: loss: 1.0172, policy_loss: 1.3765, value_loss: 0.8557
2024-07-14 05:36:41,531 [INFO    ] __main__: train step 6398: loss: 1.0173, policy_loss: 1.3764, value_loss: 0.8557
2024-07-14 05:36:41,832 [INFO    ] __main__: train step 6399: loss: 1.0174, policy_loss: 1.3764, value_loss: 0.8556
2024-07-14 05:36:42,112 [INFO    ] __main__: train step 6400: loss: 1.0174, policy_loss: 1.3763, value_loss: 0.8556
2024-07-14 05:36:42,401 [INFO    ] __main__: train step 6401: loss: 1.0175, policy_loss: 1.3762, value_loss: 0.8556
2024-07-14 05:36:42,683 [INFO    ] __main__: train step 6402: loss: 1.0176, policy_loss: 1.3761, value_loss: 0.8556
2024-07-14 05:36:42,955 [INFO    ] __main__: train step 6403: loss: 1.0177, policy_loss: 1.3761, value_loss: 0.8555
2024-07-14 05:36:43,237 [INFO    ] __main__: train step 6404: loss: 1.0178, policy_loss: 1.3760, value_loss: 0.8555
2024-07-14 05:36:43,520 [INFO    ] __main__: train step 6405: loss: 1.0178, policy_loss: 1.3759, value_loss: 0.8555
2024-07-14 05:36:45,129 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:36:45,616 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:36:45,688 [INFO    ] __main__: train step 6406: loss: 1.0179, policy_loss: 1.3758, value_loss: 0.8555
2024-07-14 05:36:45,967 [INFO    ] __main__: train step 6407: loss: 1.0180, policy_loss: 1.3758, value_loss: 0.8554
2024-07-14 05:36:46,236 [INFO    ] __main__: train step 6408: loss: 1.0181, policy_loss: 1.3757, value_loss: 0.8554
2024-07-14 05:36:46,504 [INFO    ] __main__: train step 6409: loss: 1.0182, policy_loss: 1.3756, value_loss: 0.8554
2024-07-14 05:36:46,785 [INFO    ] __main__: train step 6410: loss: 1.0182, policy_loss: 1.3755, value_loss: 0.8554
2024-07-14 05:36:47,061 [INFO    ] __main__: train step 6411: loss: 1.0183, policy_loss: 1.3755, value_loss: 0.8553
2024-07-14 05:36:47,339 [INFO    ] __main__: train step 6412: loss: 1.0184, policy_loss: 1.3754, value_loss: 0.8553
2024-07-14 05:36:47,625 [INFO    ] __main__: train step 6413: loss: 1.0185, policy_loss: 1.3753, value_loss: 0.8553
2024-07-14 05:36:47,906 [INFO    ] __main__: train step 6414: loss: 1.0186, policy_loss: 1.3752, value_loss: 0.8553
2024-07-14 05:36:48,187 [INFO    ] __main__: train step 6415: loss: 1.0187, policy_loss: 1.3752, value_loss: 0.8552
2024-07-14 05:36:48,463 [INFO    ] __main__: train step 6416: loss: 1.0187, policy_loss: 1.3751, value_loss: 0.8552
2024-07-14 05:36:48,748 [INFO    ] __main__: train step 6417: loss: 1.0188, policy_loss: 1.3750, value_loss: 0.8552
2024-07-14 05:36:49,028 [INFO    ] __main__: train step 6418: loss: 1.0189, policy_loss: 1.3749, value_loss: 0.8552
2024-07-14 05:36:49,308 [INFO    ] __main__: train step 6419: loss: 1.0190, policy_loss: 1.3749, value_loss: 0.8552
2024-07-14 05:36:49,586 [INFO    ] __main__: train step 6420: loss: 1.0191, policy_loss: 1.3748, value_loss: 0.8551
2024-07-14 05:36:49,866 [INFO    ] __main__: train step 6421: loss: 1.0191, policy_loss: 1.3747, value_loss: 0.8551
2024-07-14 05:36:50,138 [INFO    ] __main__: train step 6422: loss: 1.0192, policy_loss: 1.3746, value_loss: 0.8551
2024-07-14 05:36:51,729 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:36:52,221 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:36:52,287 [INFO    ] __main__: train step 6423: loss: 1.0193, policy_loss: 1.3746, value_loss: 0.8551
2024-07-14 05:36:52,567 [INFO    ] __main__: train step 6424: loss: 1.0194, policy_loss: 1.3745, value_loss: 0.8550
2024-07-14 05:36:52,839 [INFO    ] __main__: train step 6425: loss: 1.0195, policy_loss: 1.3744, value_loss: 0.8550
2024-07-14 05:36:53,106 [INFO    ] __main__: train step 6426: loss: 1.0195, policy_loss: 1.3744, value_loss: 0.8550
2024-07-14 05:36:53,368 [INFO    ] __main__: train step 6427: loss: 1.0196, policy_loss: 1.3743, value_loss: 0.8550
2024-07-14 05:36:53,650 [INFO    ] __main__: train step 6428: loss: 1.0197, policy_loss: 1.3742, value_loss: 0.8549
2024-07-14 05:36:53,929 [INFO    ] __main__: train step 6429: loss: 1.0198, policy_loss: 1.3741, value_loss: 0.8549
2024-07-14 05:36:54,197 [INFO    ] __main__: train step 6430: loss: 1.0199, policy_loss: 1.3741, value_loss: 0.8549
2024-07-14 05:36:54,473 [INFO    ] __main__: train step 6431: loss: 1.0200, policy_loss: 1.3740, value_loss: 0.8549
2024-07-14 05:36:54,750 [INFO    ] __main__: train step 6432: loss: 1.0200, policy_loss: 1.3739, value_loss: 0.8548
2024-07-14 05:36:55,028 [INFO    ] __main__: train step 6433: loss: 1.0201, policy_loss: 1.3739, value_loss: 0.8548
2024-07-14 05:36:56,773 [INFO    ] __main__: train step 6434: loss: 1.0202, policy_loss: 1.3738, value_loss: 0.8548
2024-07-14 05:36:57,057 [INFO    ] __main__: train step 6435: loss: 1.0203, policy_loss: 1.3737, value_loss: 0.8548
2024-07-14 05:36:57,330 [INFO    ] __main__: train step 6436: loss: 1.0204, policy_loss: 1.3736, value_loss: 0.8547
2024-07-14 05:36:57,601 [INFO    ] __main__: train step 6437: loss: 1.0204, policy_loss: 1.3736, value_loss: 0.8547
2024-07-14 05:36:57,879 [INFO    ] __main__: train step 6438: loss: 1.0205, policy_loss: 1.3735, value_loss: 0.8547
2024-07-14 05:36:58,147 [INFO    ] __main__: train step 6439: loss: 1.0206, policy_loss: 1.3734, value_loss: 0.8547
2024-07-14 05:36:59,750 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:37:00,227 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:37:00,299 [INFO    ] __main__: train step 6440: loss: 1.0207, policy_loss: 1.3733, value_loss: 0.8546
2024-07-14 05:37:00,568 [INFO    ] __main__: train step 6441: loss: 1.0207, policy_loss: 1.3733, value_loss: 0.8546
2024-07-14 05:37:00,851 [INFO    ] __main__: train step 6442: loss: 1.0208, policy_loss: 1.3732, value_loss: 0.8546
2024-07-14 05:37:01,124 [INFO    ] __main__: train step 6443: loss: 1.0209, policy_loss: 1.3731, value_loss: 0.8546
2024-07-14 05:37:01,394 [INFO    ] __main__: train step 6444: loss: 1.0210, policy_loss: 1.3730, value_loss: 0.8545
2024-07-14 05:37:01,669 [INFO    ] __main__: train step 6445: loss: 1.0211, policy_loss: 1.3730, value_loss: 0.8545
2024-07-14 05:37:01,951 [INFO    ] __main__: train step 6446: loss: 1.0211, policy_loss: 1.3729, value_loss: 0.8545
2024-07-14 05:37:02,235 [INFO    ] __main__: train step 6447: loss: 1.0212, policy_loss: 1.3728, value_loss: 0.8545
2024-07-14 05:37:02,511 [INFO    ] __main__: train step 6448: loss: 1.0213, policy_loss: 1.3728, value_loss: 0.8544
2024-07-14 05:37:02,802 [INFO    ] __main__: train step 6449: loss: 1.0214, policy_loss: 1.3727, value_loss: 0.8544
2024-07-14 05:37:03,098 [INFO    ] __main__: train step 6450: loss: 1.0215, policy_loss: 1.3726, value_loss: 0.8544
2024-07-14 05:37:03,384 [INFO    ] __main__: train step 6451: loss: 1.0215, policy_loss: 1.3725, value_loss: 0.8544
2024-07-14 05:37:03,680 [INFO    ] __main__: train step 6452: loss: 1.0216, policy_loss: 1.3725, value_loss: 0.8544
2024-07-14 05:37:03,957 [INFO    ] __main__: train step 6453: loss: 1.0217, policy_loss: 1.3724, value_loss: 0.8543
2024-07-14 05:37:04,235 [INFO    ] __main__: train step 6454: loss: 1.0218, policy_loss: 1.3723, value_loss: 0.8543
2024-07-14 05:37:04,515 [INFO    ] __main__: train step 6455: loss: 1.0219, policy_loss: 1.3723, value_loss: 0.8543
2024-07-14 05:37:04,810 [INFO    ] __main__: train step 6456: loss: 1.0220, policy_loss: 1.3722, value_loss: 0.8543
2024-07-14 05:37:06,410 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:37:06,895 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:37:06,962 [INFO    ] __main__: train step 6457: loss: 1.0221, policy_loss: 1.3721, value_loss: 0.8542
2024-07-14 05:37:07,244 [INFO    ] __main__: train step 6458: loss: 1.0221, policy_loss: 1.3721, value_loss: 0.8542
2024-07-14 05:37:07,516 [INFO    ] __main__: train step 6459: loss: 1.0222, policy_loss: 1.3720, value_loss: 0.8542
2024-07-14 05:37:07,799 [INFO    ] __main__: train step 6460: loss: 1.0223, policy_loss: 1.3719, value_loss: 0.8542
2024-07-14 05:37:08,079 [INFO    ] __main__: train step 6461: loss: 1.0224, policy_loss: 1.3718, value_loss: 0.8541
2024-07-14 05:37:08,368 [INFO    ] __main__: train step 6462: loss: 1.0225, policy_loss: 1.3718, value_loss: 0.8541
2024-07-14 05:37:08,648 [INFO    ] __main__: train step 6463: loss: 1.0225, policy_loss: 1.3717, value_loss: 0.8541
2024-07-14 05:37:08,904 [INFO    ] __main__: train step 6464: loss: 1.0226, policy_loss: 1.3716, value_loss: 0.8541
2024-07-14 05:37:09,152 [INFO    ] __main__: train step 6465: loss: 1.0227, policy_loss: 1.3716, value_loss: 0.8540
2024-07-14 05:37:09,408 [INFO    ] __main__: train step 6466: loss: 1.0228, policy_loss: 1.3715, value_loss: 0.8540
2024-07-14 05:37:09,672 [INFO    ] __main__: train step 6467: loss: 1.0229, policy_loss: 1.3714, value_loss: 0.8540
2024-07-14 05:37:09,954 [INFO    ] __main__: train step 6468: loss: 1.0229, policy_loss: 1.3713, value_loss: 0.8540
2024-07-14 05:37:10,235 [INFO    ] __main__: train step 6469: loss: 1.0230, policy_loss: 1.3713, value_loss: 0.8540
2024-07-14 05:37:10,511 [INFO    ] __main__: train step 6470: loss: 1.0231, policy_loss: 1.3712, value_loss: 0.8539
2024-07-14 05:37:10,792 [INFO    ] __main__: train step 6471: loss: 1.0232, policy_loss: 1.3711, value_loss: 0.8539
2024-07-14 05:37:11,067 [INFO    ] __main__: train step 6472: loss: 1.0233, policy_loss: 1.3710, value_loss: 0.8539
2024-07-14 05:37:11,343 [INFO    ] __main__: train step 6473: loss: 1.0233, policy_loss: 1.3710, value_loss: 0.8539
2024-07-14 05:37:12,939 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:37:13,420 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:37:13,487 [INFO    ] __main__: train step 6474: loss: 1.0234, policy_loss: 1.3709, value_loss: 0.8538
2024-07-14 05:37:13,770 [INFO    ] __main__: train step 6475: loss: 1.0235, policy_loss: 1.3708, value_loss: 0.8538
2024-07-14 05:37:14,049 [INFO    ] __main__: train step 6476: loss: 1.0236, policy_loss: 1.3708, value_loss: 0.8538
2024-07-14 05:37:14,343 [INFO    ] __main__: train step 6477: loss: 1.0237, policy_loss: 1.3707, value_loss: 0.8538
2024-07-14 05:37:14,617 [INFO    ] __main__: train step 6478: loss: 1.0237, policy_loss: 1.3706, value_loss: 0.8537
2024-07-14 05:37:14,910 [INFO    ] __main__: train step 6479: loss: 1.0238, policy_loss: 1.3705, value_loss: 0.8537
2024-07-14 05:37:15,180 [INFO    ] __main__: train step 6480: loss: 1.0239, policy_loss: 1.3705, value_loss: 0.8537
2024-07-14 05:37:15,465 [INFO    ] __main__: train step 6481: loss: 1.0240, policy_loss: 1.3704, value_loss: 0.8537
2024-07-14 05:37:15,733 [INFO    ] __main__: train step 6482: loss: 1.0240, policy_loss: 1.3703, value_loss: 0.8536
2024-07-14 05:37:16,010 [INFO    ] __main__: train step 6483: loss: 1.0241, policy_loss: 1.3702, value_loss: 0.8536
2024-07-14 05:37:16,301 [INFO    ] __main__: train step 6484: loss: 1.0242, policy_loss: 1.3702, value_loss: 0.8536
2024-07-14 05:37:16,579 [INFO    ] __main__: train step 6485: loss: 1.0243, policy_loss: 1.3701, value_loss: 0.8536
2024-07-14 05:37:16,864 [INFO    ] __main__: train step 6486: loss: 1.0244, policy_loss: 1.3700, value_loss: 0.8535
2024-07-14 05:37:17,143 [INFO    ] __main__: train step 6487: loss: 1.0244, policy_loss: 1.3700, value_loss: 0.8535
2024-07-14 05:37:17,410 [INFO    ] __main__: train step 6488: loss: 1.0245, policy_loss: 1.3699, value_loss: 0.8535
2024-07-14 05:37:19,159 [INFO    ] __main__: train step 6489: loss: 1.0246, policy_loss: 1.3698, value_loss: 0.8535
2024-07-14 05:37:19,427 [INFO    ] __main__: train step 6490: loss: 1.0247, policy_loss: 1.3697, value_loss: 0.8534
2024-07-14 05:37:20,988 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:37:21,463 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:37:21,535 [INFO    ] __main__: train step 6491: loss: 1.0247, policy_loss: 1.3697, value_loss: 0.8534
2024-07-14 05:37:21,805 [INFO    ] __main__: train step 6492: loss: 1.0248, policy_loss: 1.3696, value_loss: 0.8534
2024-07-14 05:37:22,088 [INFO    ] __main__: train step 6493: loss: 1.0249, policy_loss: 1.3695, value_loss: 0.8534
2024-07-14 05:37:22,375 [INFO    ] __main__: train step 6494: loss: 1.0250, policy_loss: 1.3694, value_loss: 0.8533
2024-07-14 05:37:22,660 [INFO    ] __main__: train step 6495: loss: 1.0250, policy_loss: 1.3694, value_loss: 0.8533
2024-07-14 05:37:22,941 [INFO    ] __main__: train step 6496: loss: 1.0251, policy_loss: 1.3693, value_loss: 0.8533
2024-07-14 05:37:23,227 [INFO    ] __main__: train step 6497: loss: 1.0252, policy_loss: 1.3692, value_loss: 0.8533
2024-07-14 05:37:23,516 [INFO    ] __main__: train step 6498: loss: 1.0253, policy_loss: 1.3691, value_loss: 0.8532
2024-07-14 05:37:23,800 [INFO    ] __main__: train step 6499: loss: 1.0254, policy_loss: 1.3691, value_loss: 0.8532
2024-07-14 05:37:24,084 [INFO    ] __main__: train step 6500: loss: 1.0254, policy_loss: 1.3690, value_loss: 0.8532
2024-07-14 05:37:24,363 [INFO    ] __main__: train step 6501: loss: 1.0255, policy_loss: 1.3689, value_loss: 0.8532
2024-07-14 05:37:24,653 [INFO    ] __main__: train step 6502: loss: 1.0256, policy_loss: 1.3689, value_loss: 0.8531
2024-07-14 05:37:24,931 [INFO    ] __main__: train step 6503: loss: 1.0257, policy_loss: 1.3688, value_loss: 0.8531
2024-07-14 05:37:25,207 [INFO    ] __main__: train step 6504: loss: 1.0257, policy_loss: 1.3687, value_loss: 0.8531
2024-07-14 05:37:25,477 [INFO    ] __main__: train step 6505: loss: 1.0258, policy_loss: 1.3686, value_loss: 0.8531
2024-07-14 05:37:25,759 [INFO    ] __main__: train step 6506: loss: 1.0259, policy_loss: 1.3686, value_loss: 0.8530
2024-07-14 05:37:26,039 [INFO    ] __main__: train step 6507: loss: 1.0260, policy_loss: 1.3685, value_loss: 0.8530
2024-07-14 05:37:27,666 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:37:28,137 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:37:28,207 [INFO    ] __main__: train step 6508: loss: 1.0261, policy_loss: 1.3684, value_loss: 0.8530
2024-07-14 05:37:28,457 [INFO    ] __main__: train step 6509: loss: 1.0261, policy_loss: 1.3683, value_loss: 0.8530
2024-07-14 05:37:28,717 [INFO    ] __main__: train step 6510: loss: 1.0262, policy_loss: 1.3683, value_loss: 0.8529
2024-07-14 05:37:28,998 [INFO    ] __main__: train step 6511: loss: 1.0263, policy_loss: 1.3682, value_loss: 0.8529
2024-07-14 05:37:29,281 [INFO    ] __main__: train step 6512: loss: 1.0264, policy_loss: 1.3681, value_loss: 0.8529
2024-07-14 05:37:29,550 [INFO    ] __main__: train step 6513: loss: 1.0264, policy_loss: 1.3680, value_loss: 0.8529
2024-07-14 05:37:29,832 [INFO    ] __main__: train step 6514: loss: 1.0265, policy_loss: 1.3680, value_loss: 0.8529
2024-07-14 05:37:30,109 [INFO    ] __main__: train step 6515: loss: 1.0266, policy_loss: 1.3679, value_loss: 0.8528
2024-07-14 05:37:30,396 [INFO    ] __main__: train step 6516: loss: 1.0267, policy_loss: 1.3678, value_loss: 0.8528
2024-07-14 05:37:30,679 [INFO    ] __main__: train step 6517: loss: 1.0268, policy_loss: 1.3678, value_loss: 0.8528
2024-07-14 05:37:30,957 [INFO    ] __main__: train step 6518: loss: 1.0268, policy_loss: 1.3677, value_loss: 0.8528
2024-07-14 05:37:31,230 [INFO    ] __main__: train step 6519: loss: 1.0269, policy_loss: 1.3676, value_loss: 0.8527
2024-07-14 05:37:31,507 [INFO    ] __main__: train step 6520: loss: 1.0270, policy_loss: 1.3675, value_loss: 0.8527
2024-07-14 05:37:31,790 [INFO    ] __main__: train step 6521: loss: 1.0271, policy_loss: 1.3675, value_loss: 0.8527
2024-07-14 05:37:32,066 [INFO    ] __main__: train step 6522: loss: 1.0271, policy_loss: 1.3674, value_loss: 0.8527
2024-07-14 05:37:32,355 [INFO    ] __main__: train step 6523: loss: 1.0272, policy_loss: 1.3673, value_loss: 0.8526
2024-07-14 05:37:32,641 [INFO    ] __main__: train step 6524: loss: 1.0273, policy_loss: 1.3672, value_loss: 0.8526
2024-07-14 05:37:34,231 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:37:34,709 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:37:34,779 [INFO    ] __main__: train step 6525: loss: 1.0274, policy_loss: 1.3672, value_loss: 0.8526
2024-07-14 05:37:35,053 [INFO    ] __main__: train step 6526: loss: 1.0274, policy_loss: 1.3671, value_loss: 0.8526
2024-07-14 05:37:35,324 [INFO    ] __main__: train step 6527: loss: 1.0275, policy_loss: 1.3670, value_loss: 0.8525
2024-07-14 05:37:35,595 [INFO    ] __main__: train step 6528: loss: 1.0276, policy_loss: 1.3670, value_loss: 0.8525
2024-07-14 05:37:35,866 [INFO    ] __main__: train step 6529: loss: 1.0277, policy_loss: 1.3669, value_loss: 0.8525
2024-07-14 05:37:36,143 [INFO    ] __main__: train step 6530: loss: 1.0278, policy_loss: 1.3668, value_loss: 0.8525
2024-07-14 05:37:36,420 [INFO    ] __main__: train step 6531: loss: 1.0278, policy_loss: 1.3667, value_loss: 0.8524
2024-07-14 05:37:36,695 [INFO    ] __main__: train step 6532: loss: 1.0279, policy_loss: 1.3667, value_loss: 0.8524
2024-07-14 05:37:36,974 [INFO    ] __main__: train step 6533: loss: 1.0280, policy_loss: 1.3666, value_loss: 0.8524
2024-07-14 05:37:37,252 [INFO    ] __main__: train step 6534: loss: 1.0281, policy_loss: 1.3665, value_loss: 0.8524
2024-07-14 05:37:37,531 [INFO    ] __main__: train step 6535: loss: 1.0281, policy_loss: 1.3664, value_loss: 0.8523
2024-07-14 05:37:37,808 [INFO    ] __main__: train step 6536: loss: 1.0282, policy_loss: 1.3664, value_loss: 0.8523
2024-07-14 05:37:38,095 [INFO    ] __main__: train step 6537: loss: 1.0283, policy_loss: 1.3663, value_loss: 0.8523
2024-07-14 05:37:38,368 [INFO    ] __main__: train step 6538: loss: 1.0284, policy_loss: 1.3662, value_loss: 0.8523
2024-07-14 05:37:38,642 [INFO    ] __main__: train step 6539: loss: 1.0284, policy_loss: 1.3662, value_loss: 0.8522
2024-07-14 05:37:38,932 [INFO    ] __main__: train step 6540: loss: 1.0285, policy_loss: 1.3661, value_loss: 0.8522
2024-07-14 05:37:39,210 [INFO    ] __main__: train step 6541: loss: 1.0286, policy_loss: 1.3660, value_loss: 0.8522
2024-07-14 05:37:40,815 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:37:41,292 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:37:41,358 [INFO    ] __main__: train step 6542: loss: 1.0287, policy_loss: 1.3659, value_loss: 0.8522
2024-07-14 05:37:43,188 [INFO    ] __main__: train step 6543: loss: 1.0288, policy_loss: 1.3659, value_loss: 0.8521
2024-07-14 05:37:43,470 [INFO    ] __main__: train step 6544: loss: 1.0288, policy_loss: 1.3658, value_loss: 0.8521
2024-07-14 05:37:43,751 [INFO    ] __main__: train step 6545: loss: 1.0289, policy_loss: 1.3657, value_loss: 0.8521
2024-07-14 05:37:44,029 [INFO    ] __main__: train step 6546: loss: 1.0290, policy_loss: 1.3657, value_loss: 0.8521
2024-07-14 05:37:44,309 [INFO    ] __main__: train step 6547: loss: 1.0291, policy_loss: 1.3656, value_loss: 0.8520
2024-07-14 05:37:44,591 [INFO    ] __main__: train step 6548: loss: 1.0291, policy_loss: 1.3655, value_loss: 0.8520
2024-07-14 05:37:44,876 [INFO    ] __main__: train step 6549: loss: 1.0292, policy_loss: 1.3654, value_loss: 0.8520
2024-07-14 05:37:45,160 [INFO    ] __main__: train step 6550: loss: 1.0293, policy_loss: 1.3654, value_loss: 0.8520
2024-07-14 05:37:45,439 [INFO    ] __main__: train step 6551: loss: 1.0294, policy_loss: 1.3653, value_loss: 0.8519
2024-07-14 05:37:45,720 [INFO    ] __main__: train step 6552: loss: 1.0294, policy_loss: 1.3652, value_loss: 0.8519
2024-07-14 05:37:45,996 [INFO    ] __main__: train step 6553: loss: 1.0295, policy_loss: 1.3651, value_loss: 0.8519
2024-07-14 05:37:46,278 [INFO    ] __main__: train step 6554: loss: 1.0296, policy_loss: 1.3651, value_loss: 0.8519
2024-07-14 05:37:46,551 [INFO    ] __main__: train step 6555: loss: 1.0297, policy_loss: 1.3650, value_loss: 0.8518
2024-07-14 05:37:46,831 [INFO    ] __main__: train step 6556: loss: 1.0297, policy_loss: 1.3649, value_loss: 0.8518
2024-07-14 05:37:47,105 [INFO    ] __main__: train step 6557: loss: 1.0298, policy_loss: 1.3649, value_loss: 0.8518
2024-07-14 05:37:47,378 [INFO    ] __main__: train step 6558: loss: 1.0299, policy_loss: 1.3648, value_loss: 0.8518
2024-07-14 05:37:48,986 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:37:49,458 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:37:49,525 [INFO    ] __main__: train step 6559: loss: 1.0300, policy_loss: 1.3647, value_loss: 0.8517
2024-07-14 05:37:49,788 [INFO    ] __main__: train step 6560: loss: 1.0300, policy_loss: 1.3646, value_loss: 0.8517
2024-07-14 05:37:50,052 [INFO    ] __main__: train step 6561: loss: 1.0301, policy_loss: 1.3646, value_loss: 0.8517
2024-07-14 05:37:50,295 [INFO    ] __main__: train step 6562: loss: 1.0302, policy_loss: 1.3645, value_loss: 0.8517
2024-07-14 05:37:50,546 [INFO    ] __main__: train step 6563: loss: 1.0303, policy_loss: 1.3644, value_loss: 0.8517
2024-07-14 05:37:50,811 [INFO    ] __main__: train step 6564: loss: 1.0304, policy_loss: 1.3644, value_loss: 0.8516
2024-07-14 05:37:51,085 [INFO    ] __main__: train step 6565: loss: 1.0304, policy_loss: 1.3643, value_loss: 0.8516
2024-07-14 05:37:51,350 [INFO    ] __main__: train step 6566: loss: 1.0305, policy_loss: 1.3642, value_loss: 0.8516
2024-07-14 05:37:51,635 [INFO    ] __main__: train step 6567: loss: 1.0306, policy_loss: 1.3642, value_loss: 0.8516
2024-07-14 05:37:51,918 [INFO    ] __main__: train step 6568: loss: 1.0307, policy_loss: 1.3641, value_loss: 0.8515
2024-07-14 05:37:52,221 [INFO    ] __main__: train step 6569: loss: 1.0308, policy_loss: 1.3640, value_loss: 0.8515
2024-07-14 05:37:52,502 [INFO    ] __main__: train step 6570: loss: 1.0308, policy_loss: 1.3639, value_loss: 0.8515
2024-07-14 05:37:52,790 [INFO    ] __main__: train step 6571: loss: 1.0309, policy_loss: 1.3639, value_loss: 0.8515
2024-07-14 05:37:53,072 [INFO    ] __main__: train step 6572: loss: 1.0310, policy_loss: 1.3638, value_loss: 0.8514
2024-07-14 05:37:53,358 [INFO    ] __main__: train step 6573: loss: 1.0311, policy_loss: 1.3637, value_loss: 0.8514
2024-07-14 05:37:53,638 [INFO    ] __main__: train step 6574: loss: 1.0311, policy_loss: 1.3637, value_loss: 0.8514
2024-07-14 05:37:53,921 [INFO    ] __main__: train step 6575: loss: 1.0312, policy_loss: 1.3636, value_loss: 0.8514
2024-07-14 05:37:55,572 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:37:56,045 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:37:56,113 [INFO    ] __main__: train step 6576: loss: 1.0313, policy_loss: 1.3635, value_loss: 0.8513
2024-07-14 05:37:56,393 [INFO    ] __main__: train step 6577: loss: 1.0314, policy_loss: 1.3634, value_loss: 0.8513
2024-07-14 05:37:56,675 [INFO    ] __main__: train step 6578: loss: 1.0314, policy_loss: 1.3634, value_loss: 0.8513
2024-07-14 05:37:56,948 [INFO    ] __main__: train step 6579: loss: 1.0315, policy_loss: 1.3633, value_loss: 0.8513
2024-07-14 05:37:57,223 [INFO    ] __main__: train step 6580: loss: 1.0316, policy_loss: 1.3632, value_loss: 0.8512
2024-07-14 05:37:57,504 [INFO    ] __main__: train step 6581: loss: 1.0317, policy_loss: 1.3632, value_loss: 0.8512
2024-07-14 05:37:57,780 [INFO    ] __main__: train step 6582: loss: 1.0318, policy_loss: 1.3631, value_loss: 0.8512
2024-07-14 05:37:58,067 [INFO    ] __main__: train step 6583: loss: 1.0318, policy_loss: 1.3630, value_loss: 0.8512
2024-07-14 05:37:58,352 [INFO    ] __main__: train step 6584: loss: 1.0319, policy_loss: 1.3629, value_loss: 0.8511
2024-07-14 05:37:58,632 [INFO    ] __main__: train step 6585: loss: 1.0320, policy_loss: 1.3629, value_loss: 0.8511
2024-07-14 05:37:58,903 [INFO    ] __main__: train step 6586: loss: 1.0321, policy_loss: 1.3628, value_loss: 0.8511
2024-07-14 05:37:59,174 [INFO    ] __main__: train step 6587: loss: 1.0321, policy_loss: 1.3627, value_loss: 0.8511
2024-07-14 05:37:59,458 [INFO    ] __main__: train step 6588: loss: 1.0322, policy_loss: 1.3627, value_loss: 0.8510
2024-07-14 05:37:59,746 [INFO    ] __main__: train step 6589: loss: 1.0323, policy_loss: 1.3626, value_loss: 0.8510
2024-07-14 05:38:00,031 [INFO    ] __main__: train step 6590: loss: 1.0324, policy_loss: 1.3625, value_loss: 0.8510
2024-07-14 05:38:00,310 [INFO    ] __main__: train step 6591: loss: 1.0324, policy_loss: 1.3624, value_loss: 0.8510
2024-07-14 05:38:00,593 [INFO    ] __main__: train step 6592: loss: 1.0325, policy_loss: 1.3624, value_loss: 0.8510
2024-07-14 05:38:02,194 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:38:02,669 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:38:02,736 [INFO    ] __main__: train step 6593: loss: 1.0326, policy_loss: 1.3623, value_loss: 0.8509
2024-07-14 05:38:03,019 [INFO    ] __main__: train step 6594: loss: 1.0327, policy_loss: 1.3622, value_loss: 0.8509
2024-07-14 05:38:03,301 [INFO    ] __main__: train step 6595: loss: 1.0328, policy_loss: 1.3622, value_loss: 0.8509
2024-07-14 05:38:03,576 [INFO    ] __main__: train step 6596: loss: 1.0328, policy_loss: 1.3621, value_loss: 0.8509
2024-07-14 05:38:03,853 [INFO    ] __main__: train step 6597: loss: 1.0329, policy_loss: 1.3620, value_loss: 0.8508
2024-07-14 05:38:05,039 [INFO    ] __main__: train step 6598: loss: 1.0330, policy_loss: 1.3620, value_loss: 0.8508
2024-07-14 05:38:05,326 [INFO    ] __main__: train step 6599: loss: 1.0331, policy_loss: 1.3619, value_loss: 0.8508
2024-07-14 05:38:05,604 [INFO    ] __main__: train step 6600: loss: 1.0331, policy_loss: 1.3618, value_loss: 0.8508
2024-07-14 05:38:05,883 [INFO    ] __main__: train step 6601: loss: 1.0332, policy_loss: 1.3617, value_loss: 0.8507
2024-07-14 05:38:06,165 [INFO    ] __main__: train step 6602: loss: 1.0333, policy_loss: 1.3617, value_loss: 0.8507
2024-07-14 05:38:06,436 [INFO    ] __main__: train step 6603: loss: 1.0334, policy_loss: 1.3616, value_loss: 0.8507
2024-07-14 05:38:06,689 [INFO    ] __main__: train step 6604: loss: 1.0334, policy_loss: 1.3615, value_loss: 0.8507
2024-07-14 05:38:06,949 [INFO    ] __main__: train step 6605: loss: 1.0335, policy_loss: 1.3614, value_loss: 0.8507
2024-07-14 05:38:07,200 [INFO    ] __main__: train step 6606: loss: 1.0336, policy_loss: 1.3614, value_loss: 0.8506
2024-07-14 05:38:07,450 [INFO    ] __main__: train step 6607: loss: 1.0337, policy_loss: 1.3613, value_loss: 0.8506
2024-07-14 05:38:07,697 [INFO    ] __main__: train step 6608: loss: 1.0338, policy_loss: 1.3612, value_loss: 0.8506
2024-07-14 05:38:07,949 [INFO    ] __main__: train step 6609: loss: 1.0338, policy_loss: 1.3612, value_loss: 0.8506
2024-07-14 05:38:09,532 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:38:09,999 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:38:10,071 [INFO    ] __main__: train step 6610: loss: 1.0339, policy_loss: 1.3611, value_loss: 0.8505
2024-07-14 05:38:10,350 [INFO    ] __main__: train step 6611: loss: 1.0340, policy_loss: 1.3610, value_loss: 0.8505
2024-07-14 05:38:10,629 [INFO    ] __main__: train step 6612: loss: 1.0340, policy_loss: 1.3610, value_loss: 0.8505
2024-07-14 05:38:10,910 [INFO    ] __main__: train step 6613: loss: 1.0341, policy_loss: 1.3609, value_loss: 0.8505
2024-07-14 05:38:11,205 [INFO    ] __main__: train step 6614: loss: 1.0342, policy_loss: 1.3608, value_loss: 0.8504
2024-07-14 05:38:11,479 [INFO    ] __main__: train step 6615: loss: 1.0343, policy_loss: 1.3607, value_loss: 0.8504
2024-07-14 05:38:11,765 [INFO    ] __main__: train step 6616: loss: 1.0343, policy_loss: 1.3607, value_loss: 0.8504
2024-07-14 05:38:12,043 [INFO    ] __main__: train step 6617: loss: 1.0344, policy_loss: 1.3606, value_loss: 0.8504
2024-07-14 05:38:12,328 [INFO    ] __main__: train step 6618: loss: 1.0345, policy_loss: 1.3605, value_loss: 0.8503
2024-07-14 05:38:12,603 [INFO    ] __main__: train step 6619: loss: 1.0346, policy_loss: 1.3605, value_loss: 0.8503
2024-07-14 05:38:12,882 [INFO    ] __main__: train step 6620: loss: 1.0347, policy_loss: 1.3604, value_loss: 0.8503
2024-07-14 05:38:13,185 [INFO    ] __main__: train step 6621: loss: 1.0347, policy_loss: 1.3603, value_loss: 0.8503
2024-07-14 05:38:13,464 [INFO    ] __main__: train step 6622: loss: 1.0348, policy_loss: 1.3603, value_loss: 0.8502
2024-07-14 05:38:13,746 [INFO    ] __main__: train step 6623: loss: 1.0349, policy_loss: 1.3602, value_loss: 0.8502
2024-07-14 05:38:14,026 [INFO    ] __main__: train step 6624: loss: 1.0350, policy_loss: 1.3601, value_loss: 0.8502
2024-07-14 05:38:14,315 [INFO    ] __main__: train step 6625: loss: 1.0350, policy_loss: 1.3600, value_loss: 0.8502
2024-07-14 05:38:14,587 [INFO    ] __main__: train step 6626: loss: 1.0351, policy_loss: 1.3600, value_loss: 0.8501
2024-07-14 05:38:16,180 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:38:16,649 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:38:16,714 [INFO    ] __main__: train step 6627: loss: 1.0352, policy_loss: 1.3599, value_loss: 0.8501
2024-07-14 05:38:16,989 [INFO    ] __main__: train step 6628: loss: 1.0353, policy_loss: 1.3598, value_loss: 0.8501
2024-07-14 05:38:17,268 [INFO    ] __main__: train step 6629: loss: 1.0353, policy_loss: 1.3598, value_loss: 0.8501
2024-07-14 05:38:17,519 [INFO    ] __main__: train step 6630: loss: 1.0354, policy_loss: 1.3597, value_loss: 0.8500
2024-07-14 05:38:17,782 [INFO    ] __main__: train step 6631: loss: 1.0355, policy_loss: 1.3596, value_loss: 0.8500
2024-07-14 05:38:18,057 [INFO    ] __main__: train step 6632: loss: 1.0356, policy_loss: 1.3596, value_loss: 0.8500
2024-07-14 05:38:18,329 [INFO    ] __main__: train step 6633: loss: 1.0356, policy_loss: 1.3595, value_loss: 0.8500
2024-07-14 05:38:18,600 [INFO    ] __main__: train step 6634: loss: 1.0357, policy_loss: 1.3594, value_loss: 0.8499
2024-07-14 05:38:18,880 [INFO    ] __main__: train step 6635: loss: 1.0358, policy_loss: 1.3593, value_loss: 0.8499
2024-07-14 05:38:19,164 [INFO    ] __main__: train step 6636: loss: 1.0359, policy_loss: 1.3593, value_loss: 0.8499
2024-07-14 05:38:19,434 [INFO    ] __main__: train step 6637: loss: 1.0359, policy_loss: 1.3592, value_loss: 0.8499
2024-07-14 05:38:19,711 [INFO    ] __main__: train step 6638: loss: 1.0360, policy_loss: 1.3591, value_loss: 0.8498
2024-07-14 05:38:19,988 [INFO    ] __main__: train step 6639: loss: 1.0361, policy_loss: 1.3591, value_loss: 0.8498
2024-07-14 05:38:20,262 [INFO    ] __main__: train step 6640: loss: 1.0362, policy_loss: 1.3590, value_loss: 0.8498
2024-07-14 05:38:20,535 [INFO    ] __main__: train step 6641: loss: 1.0362, policy_loss: 1.3589, value_loss: 0.8498
2024-07-14 05:38:20,817 [INFO    ] __main__: train step 6642: loss: 1.0363, policy_loss: 1.3588, value_loss: 0.8497
2024-07-14 05:38:21,096 [INFO    ] __main__: train step 6643: loss: 1.0364, policy_loss: 1.3588, value_loss: 0.8497
2024-07-14 05:38:22,685 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:38:23,162 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:38:23,225 [INFO    ] __main__: train step 6644: loss: 1.0365, policy_loss: 1.3587, value_loss: 0.8497
2024-07-14 05:38:23,508 [INFO    ] __main__: train step 6645: loss: 1.0365, policy_loss: 1.3586, value_loss: 0.8497
2024-07-14 05:38:23,782 [INFO    ] __main__: train step 6646: loss: 1.0366, policy_loss: 1.3586, value_loss: 0.8497
2024-07-14 05:38:24,063 [INFO    ] __main__: train step 6647: loss: 1.0367, policy_loss: 1.3585, value_loss: 0.8496
2024-07-14 05:38:24,344 [INFO    ] __main__: train step 6648: loss: 1.0368, policy_loss: 1.3584, value_loss: 0.8496
2024-07-14 05:38:24,621 [INFO    ] __main__: train step 6649: loss: 1.0368, policy_loss: 1.3584, value_loss: 0.8496
2024-07-14 05:38:24,903 [INFO    ] __main__: train step 6650: loss: 1.0369, policy_loss: 1.3583, value_loss: 0.8496
2024-07-14 05:38:25,183 [INFO    ] __main__: train step 6651: loss: 1.0370, policy_loss: 1.3582, value_loss: 0.8495
2024-07-14 05:38:25,459 [INFO    ] __main__: train step 6652: loss: 1.0371, policy_loss: 1.3581, value_loss: 0.8495
2024-07-14 05:38:27,237 [INFO    ] __main__: train step 6653: loss: 1.0371, policy_loss: 1.3581, value_loss: 0.8495
2024-07-14 05:38:27,504 [INFO    ] __main__: train step 6654: loss: 1.0372, policy_loss: 1.3580, value_loss: 0.8495
2024-07-14 05:38:27,789 [INFO    ] __main__: train step 6655: loss: 1.0373, policy_loss: 1.3579, value_loss: 0.8494
2024-07-14 05:38:28,076 [INFO    ] __main__: train step 6656: loss: 1.0374, policy_loss: 1.3579, value_loss: 0.8494
2024-07-14 05:38:28,347 [INFO    ] __main__: train step 6657: loss: 1.0375, policy_loss: 1.3578, value_loss: 0.8494
2024-07-14 05:38:28,636 [INFO    ] __main__: train step 6658: loss: 1.0375, policy_loss: 1.3577, value_loss: 0.8494
2024-07-14 05:38:28,914 [INFO    ] __main__: train step 6659: loss: 1.0376, policy_loss: 1.3577, value_loss: 0.8493
2024-07-14 05:38:29,183 [INFO    ] __main__: train step 6660: loss: 1.0377, policy_loss: 1.3576, value_loss: 0.8493
2024-07-14 05:38:30,789 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:38:31,267 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:38:31,333 [INFO    ] __main__: train step 6661: loss: 1.0377, policy_loss: 1.3575, value_loss: 0.8493
2024-07-14 05:38:31,615 [INFO    ] __main__: train step 6662: loss: 1.0378, policy_loss: 1.3574, value_loss: 0.8493
2024-07-14 05:38:31,889 [INFO    ] __main__: train step 6663: loss: 1.0379, policy_loss: 1.3574, value_loss: 0.8492
2024-07-14 05:38:32,168 [INFO    ] __main__: train step 6664: loss: 1.0380, policy_loss: 1.3573, value_loss: 0.8492
2024-07-14 05:38:32,442 [INFO    ] __main__: train step 6665: loss: 1.0380, policy_loss: 1.3572, value_loss: 0.8492
2024-07-14 05:38:32,719 [INFO    ] __main__: train step 6666: loss: 1.0381, policy_loss: 1.3572, value_loss: 0.8492
2024-07-14 05:38:33,004 [INFO    ] __main__: train step 6667: loss: 1.0382, policy_loss: 1.3571, value_loss: 0.8491
2024-07-14 05:38:33,281 [INFO    ] __main__: train step 6668: loss: 1.0383, policy_loss: 1.3570, value_loss: 0.8491
2024-07-14 05:38:33,560 [INFO    ] __main__: train step 6669: loss: 1.0383, policy_loss: 1.3570, value_loss: 0.8491
2024-07-14 05:38:33,852 [INFO    ] __main__: train step 6670: loss: 1.0384, policy_loss: 1.3569, value_loss: 0.8491
2024-07-14 05:38:34,125 [INFO    ] __main__: train step 6671: loss: 1.0385, policy_loss: 1.3568, value_loss: 0.8490
2024-07-14 05:38:34,404 [INFO    ] __main__: train step 6672: loss: 1.0386, policy_loss: 1.3567, value_loss: 0.8490
2024-07-14 05:38:34,669 [INFO    ] __main__: train step 6673: loss: 1.0386, policy_loss: 1.3567, value_loss: 0.8490
2024-07-14 05:38:34,953 [INFO    ] __main__: train step 6674: loss: 1.0387, policy_loss: 1.3566, value_loss: 0.8490
2024-07-14 05:38:35,241 [INFO    ] __main__: train step 6675: loss: 1.0388, policy_loss: 1.3565, value_loss: 0.8490
2024-07-14 05:38:35,531 [INFO    ] __main__: train step 6676: loss: 1.0389, policy_loss: 1.3565, value_loss: 0.8489
2024-07-14 05:38:35,812 [INFO    ] __main__: train step 6677: loss: 1.0389, policy_loss: 1.3564, value_loss: 0.8489
2024-07-14 05:38:37,407 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:38:37,882 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:38:37,949 [INFO    ] __main__: train step 6678: loss: 1.0390, policy_loss: 1.3563, value_loss: 0.8489
2024-07-14 05:38:38,232 [INFO    ] __main__: train step 6679: loss: 1.0391, policy_loss: 1.3563, value_loss: 0.8489
2024-07-14 05:38:38,502 [INFO    ] __main__: train step 6680: loss: 1.0392, policy_loss: 1.3562, value_loss: 0.8488
2024-07-14 05:38:38,785 [INFO    ] __main__: train step 6681: loss: 1.0392, policy_loss: 1.3561, value_loss: 0.8488
2024-07-14 05:38:39,063 [INFO    ] __main__: train step 6682: loss: 1.0393, policy_loss: 1.3561, value_loss: 0.8488
2024-07-14 05:38:39,332 [INFO    ] __main__: train step 6683: loss: 1.0394, policy_loss: 1.3560, value_loss: 0.8488
2024-07-14 05:38:39,639 [INFO    ] __main__: train step 6684: loss: 1.0395, policy_loss: 1.3559, value_loss: 0.8487
2024-07-14 05:38:39,918 [INFO    ] __main__: train step 6685: loss: 1.0395, policy_loss: 1.3558, value_loss: 0.8487
2024-07-14 05:38:40,201 [INFO    ] __main__: train step 6686: loss: 1.0396, policy_loss: 1.3558, value_loss: 0.8487
2024-07-14 05:38:40,482 [INFO    ] __main__: train step 6687: loss: 1.0397, policy_loss: 1.3557, value_loss: 0.8487
2024-07-14 05:38:40,764 [INFO    ] __main__: train step 6688: loss: 1.0398, policy_loss: 1.3556, value_loss: 0.8486
2024-07-14 05:38:41,047 [INFO    ] __main__: train step 6689: loss: 1.0398, policy_loss: 1.3556, value_loss: 0.8486
2024-07-14 05:38:41,341 [INFO    ] __main__: train step 6690: loss: 1.0399, policy_loss: 1.3555, value_loss: 0.8486
2024-07-14 05:38:41,619 [INFO    ] __main__: train step 6691: loss: 1.0400, policy_loss: 1.3554, value_loss: 0.8486
2024-07-14 05:38:41,885 [INFO    ] __main__: train step 6692: loss: 1.0401, policy_loss: 1.3554, value_loss: 0.8485
2024-07-14 05:38:42,173 [INFO    ] __main__: train step 6693: loss: 1.0401, policy_loss: 1.3553, value_loss: 0.8485
2024-07-14 05:38:42,457 [INFO    ] __main__: train step 6694: loss: 1.0402, policy_loss: 1.3552, value_loss: 0.8485
2024-07-14 05:38:44,068 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:38:44,545 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:38:44,613 [INFO    ] __main__: train step 6695: loss: 1.0403, policy_loss: 1.3552, value_loss: 0.8485
2024-07-14 05:38:44,910 [INFO    ] __main__: train step 6696: loss: 1.0403, policy_loss: 1.3551, value_loss: 0.8484
2024-07-14 05:38:45,200 [INFO    ] __main__: train step 6697: loss: 1.0404, policy_loss: 1.3550, value_loss: 0.8484
2024-07-14 05:38:45,480 [INFO    ] __main__: train step 6698: loss: 1.0405, policy_loss: 1.3549, value_loss: 0.8484
2024-07-14 05:38:45,758 [INFO    ] __main__: train step 6699: loss: 1.0406, policy_loss: 1.3549, value_loss: 0.8484
2024-07-14 05:38:46,038 [INFO    ] __main__: train step 6700: loss: 1.0406, policy_loss: 1.3548, value_loss: 0.8483
2024-07-14 05:38:46,318 [INFO    ] __main__: train step 6701: loss: 1.0407, policy_loss: 1.3547, value_loss: 0.8483
2024-07-14 05:38:46,588 [INFO    ] __main__: train step 6702: loss: 1.0408, policy_loss: 1.3547, value_loss: 0.8483
2024-07-14 05:38:46,863 [INFO    ] __main__: train step 6703: loss: 1.0409, policy_loss: 1.3546, value_loss: 0.8483
2024-07-14 05:38:47,146 [INFO    ] __main__: train step 6704: loss: 1.0409, policy_loss: 1.3545, value_loss: 0.8482
2024-07-14 05:38:47,430 [INFO    ] __main__: train step 6705: loss: 1.0410, policy_loss: 1.3544, value_loss: 0.8482
2024-07-14 05:38:47,698 [INFO    ] __main__: train step 6706: loss: 1.0411, policy_loss: 1.3544, value_loss: 0.8482
2024-07-14 05:38:48,932 [INFO    ] __main__: train step 6707: loss: 1.0411, policy_loss: 1.3543, value_loss: 0.8482
2024-07-14 05:38:49,222 [INFO    ] __main__: train step 6708: loss: 1.0412, policy_loss: 1.3542, value_loss: 0.8481
2024-07-14 05:38:49,476 [INFO    ] __main__: train step 6709: loss: 1.0413, policy_loss: 1.3542, value_loss: 0.8481
2024-07-14 05:38:49,743 [INFO    ] __main__: train step 6710: loss: 1.0414, policy_loss: 1.3541, value_loss: 0.8481
2024-07-14 05:38:50,009 [INFO    ] __main__: train step 6711: loss: 1.0414, policy_loss: 1.3540, value_loss: 0.8481
2024-07-14 05:38:51,599 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:38:52,073 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:38:52,143 [INFO    ] __main__: train step 6712: loss: 1.0415, policy_loss: 1.3540, value_loss: 0.8480
2024-07-14 05:38:52,390 [INFO    ] __main__: train step 6713: loss: 1.0416, policy_loss: 1.3539, value_loss: 0.8480
2024-07-14 05:38:52,652 [INFO    ] __main__: train step 6714: loss: 1.0417, policy_loss: 1.3538, value_loss: 0.8480
2024-07-14 05:38:52,921 [INFO    ] __main__: train step 6715: loss: 1.0417, policy_loss: 1.3538, value_loss: 0.8480
2024-07-14 05:38:53,201 [INFO    ] __main__: train step 6716: loss: 1.0418, policy_loss: 1.3537, value_loss: 0.8479
2024-07-14 05:38:53,459 [INFO    ] __main__: train step 6717: loss: 1.0419, policy_loss: 1.3536, value_loss: 0.8479
2024-07-14 05:38:53,733 [INFO    ] __main__: train step 6718: loss: 1.0419, policy_loss: 1.3535, value_loss: 0.8479
2024-07-14 05:38:54,004 [INFO    ] __main__: train step 6719: loss: 1.0420, policy_loss: 1.3535, value_loss: 0.8479
2024-07-14 05:38:54,301 [INFO    ] __main__: train step 6720: loss: 1.0421, policy_loss: 1.3534, value_loss: 0.8478
2024-07-14 05:38:54,584 [INFO    ] __main__: train step 6721: loss: 1.0422, policy_loss: 1.3533, value_loss: 0.8478
2024-07-14 05:38:54,880 [INFO    ] __main__: train step 6722: loss: 1.0422, policy_loss: 1.3533, value_loss: 0.8478
2024-07-14 05:38:55,152 [INFO    ] __main__: train step 6723: loss: 1.0423, policy_loss: 1.3532, value_loss: 0.8478
2024-07-14 05:38:55,429 [INFO    ] __main__: train step 6724: loss: 1.0424, policy_loss: 1.3531, value_loss: 0.8478
2024-07-14 05:38:55,700 [INFO    ] __main__: train step 6725: loss: 1.0425, policy_loss: 1.3531, value_loss: 0.8477
2024-07-14 05:38:56,005 [INFO    ] __main__: train step 6726: loss: 1.0425, policy_loss: 1.3530, value_loss: 0.8477
2024-07-14 05:38:56,282 [INFO    ] __main__: train step 6727: loss: 1.0426, policy_loss: 1.3529, value_loss: 0.8477
2024-07-14 05:38:56,565 [INFO    ] __main__: train step 6728: loss: 1.0427, policy_loss: 1.3529, value_loss: 0.8477
2024-07-14 05:38:58,163 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:38:58,639 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:38:58,715 [INFO    ] __main__: train step 6729: loss: 1.0427, policy_loss: 1.3528, value_loss: 0.8476
2024-07-14 05:38:59,001 [INFO    ] __main__: train step 6730: loss: 1.0428, policy_loss: 1.3527, value_loss: 0.8476
2024-07-14 05:38:59,282 [INFO    ] __main__: train step 6731: loss: 1.0429, policy_loss: 1.3526, value_loss: 0.8476
2024-07-14 05:38:59,563 [INFO    ] __main__: train step 6732: loss: 1.0430, policy_loss: 1.3526, value_loss: 0.8476
2024-07-14 05:38:59,848 [INFO    ] __main__: train step 6733: loss: 1.0430, policy_loss: 1.3525, value_loss: 0.8475
2024-07-14 05:39:00,119 [INFO    ] __main__: train step 6734: loss: 1.0431, policy_loss: 1.3524, value_loss: 0.8475
2024-07-14 05:39:00,405 [INFO    ] __main__: train step 6735: loss: 1.0432, policy_loss: 1.3524, value_loss: 0.8475
2024-07-14 05:39:00,693 [INFO    ] __main__: train step 6736: loss: 1.0432, policy_loss: 1.3523, value_loss: 0.8475
2024-07-14 05:39:00,972 [INFO    ] __main__: train step 6737: loss: 1.0433, policy_loss: 1.3522, value_loss: 0.8474
2024-07-14 05:39:01,255 [INFO    ] __main__: train step 6738: loss: 1.0434, policy_loss: 1.3522, value_loss: 0.8474
2024-07-14 05:39:01,528 [INFO    ] __main__: train step 6739: loss: 1.0435, policy_loss: 1.3521, value_loss: 0.8474
2024-07-14 05:39:01,792 [INFO    ] __main__: train step 6740: loss: 1.0435, policy_loss: 1.3520, value_loss: 0.8474
2024-07-14 05:39:02,067 [INFO    ] __main__: train step 6741: loss: 1.0436, policy_loss: 1.3520, value_loss: 0.8473
2024-07-14 05:39:02,352 [INFO    ] __main__: train step 6742: loss: 1.0437, policy_loss: 1.3519, value_loss: 0.8473
2024-07-14 05:39:02,632 [INFO    ] __main__: train step 6743: loss: 1.0438, policy_loss: 1.3518, value_loss: 0.8473
2024-07-14 05:39:02,917 [INFO    ] __main__: train step 6744: loss: 1.0438, policy_loss: 1.3518, value_loss: 0.8473
2024-07-14 05:39:03,176 [INFO    ] __main__: train step 6745: loss: 1.0439, policy_loss: 1.3517, value_loss: 0.8472
2024-07-14 05:39:04,785 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:39:05,260 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:39:05,331 [INFO    ] __main__: train step 6746: loss: 1.0440, policy_loss: 1.3516, value_loss: 0.8472
2024-07-14 05:39:05,608 [INFO    ] __main__: train step 6747: loss: 1.0440, policy_loss: 1.3516, value_loss: 0.8472
2024-07-14 05:39:05,884 [INFO    ] __main__: train step 6748: loss: 1.0441, policy_loss: 1.3515, value_loss: 0.8471
2024-07-14 05:39:06,168 [INFO    ] __main__: train step 6749: loss: 1.0442, policy_loss: 1.3514, value_loss: 0.8471
2024-07-14 05:39:06,438 [INFO    ] __main__: train step 6750: loss: 1.0443, policy_loss: 1.3514, value_loss: 0.8471
2024-07-14 05:39:06,716 [INFO    ] __main__: train step 6751: loss: 1.0443, policy_loss: 1.3513, value_loss: 0.8471
2024-07-14 05:39:06,998 [INFO    ] __main__: train step 6752: loss: 1.0444, policy_loss: 1.3512, value_loss: 0.8471
2024-07-14 05:39:07,279 [INFO    ] __main__: train step 6753: loss: 1.0445, policy_loss: 1.3511, value_loss: 0.8470
2024-07-14 05:39:07,557 [INFO    ] __main__: train step 6754: loss: 1.0445, policy_loss: 1.3511, value_loss: 0.8470
2024-07-14 05:39:07,835 [INFO    ] __main__: train step 6755: loss: 1.0446, policy_loss: 1.3510, value_loss: 0.8470
2024-07-14 05:39:08,122 [INFO    ] __main__: train step 6756: loss: 1.0447, policy_loss: 1.3509, value_loss: 0.8470
2024-07-14 05:39:08,414 [INFO    ] __main__: train step 6757: loss: 1.0448, policy_loss: 1.3509, value_loss: 0.8469
2024-07-14 05:39:08,690 [INFO    ] __main__: train step 6758: loss: 1.0448, policy_loss: 1.3508, value_loss: 0.8469
2024-07-14 05:39:08,972 [INFO    ] __main__: train step 6759: loss: 1.0449, policy_loss: 1.3507, value_loss: 0.8469
2024-07-14 05:39:09,252 [INFO    ] __main__: train step 6760: loss: 1.0450, policy_loss: 1.3507, value_loss: 0.8469
2024-07-14 05:39:09,535 [INFO    ] __main__: train step 6761: loss: 1.0451, policy_loss: 1.3506, value_loss: 0.8468
2024-07-14 05:39:09,818 [INFO    ] __main__: train step 6762: loss: 1.0451, policy_loss: 1.3505, value_loss: 0.8468
2024-07-14 05:39:12,856 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:39:13,328 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:39:13,391 [INFO    ] __main__: train step 6763: loss: 1.0452, policy_loss: 1.3505, value_loss: 0.8468
2024-07-14 05:39:13,644 [INFO    ] __main__: train step 6764: loss: 1.0453, policy_loss: 1.3504, value_loss: 0.8468
2024-07-14 05:39:13,912 [INFO    ] __main__: train step 6765: loss: 1.0453, policy_loss: 1.3503, value_loss: 0.8467
2024-07-14 05:39:14,178 [INFO    ] __main__: train step 6766: loss: 1.0454, policy_loss: 1.3503, value_loss: 0.8467
2024-07-14 05:39:14,444 [INFO    ] __main__: train step 6767: loss: 1.0455, policy_loss: 1.3502, value_loss: 0.8467
2024-07-14 05:39:14,715 [INFO    ] __main__: train step 6768: loss: 1.0456, policy_loss: 1.3501, value_loss: 0.8467
2024-07-14 05:39:14,999 [INFO    ] __main__: train step 6769: loss: 1.0456, policy_loss: 1.3500, value_loss: 0.8466
2024-07-14 05:39:15,278 [INFO    ] __main__: train step 6770: loss: 1.0457, policy_loss: 1.3500, value_loss: 0.8466
2024-07-14 05:39:15,561 [INFO    ] __main__: train step 6771: loss: 1.0458, policy_loss: 1.3499, value_loss: 0.8466
2024-07-14 05:39:15,855 [INFO    ] __main__: train step 6772: loss: 1.0458, policy_loss: 1.3498, value_loss: 0.8466
2024-07-14 05:39:16,129 [INFO    ] __main__: train step 6773: loss: 1.0459, policy_loss: 1.3498, value_loss: 0.8465
2024-07-14 05:39:16,426 [INFO    ] __main__: train step 6774: loss: 1.0460, policy_loss: 1.3497, value_loss: 0.8465
2024-07-14 05:39:16,693 [INFO    ] __main__: train step 6775: loss: 1.0461, policy_loss: 1.3496, value_loss: 0.8465
2024-07-14 05:39:16,984 [INFO    ] __main__: train step 6776: loss: 1.0461, policy_loss: 1.3496, value_loss: 0.8465
2024-07-14 05:39:17,267 [INFO    ] __main__: train step 6777: loss: 1.0462, policy_loss: 1.3495, value_loss: 0.8464
2024-07-14 05:39:17,551 [INFO    ] __main__: train step 6778: loss: 1.0463, policy_loss: 1.3494, value_loss: 0.8464
2024-07-14 05:39:17,841 [INFO    ] __main__: train step 6779: loss: 1.0463, policy_loss: 1.3494, value_loss: 0.8464
2024-07-14 05:39:19,435 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:39:19,926 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:39:19,997 [INFO    ] __main__: train step 6780: loss: 1.0464, policy_loss: 1.3493, value_loss: 0.8464
2024-07-14 05:39:20,281 [INFO    ] __main__: train step 6781: loss: 1.0465, policy_loss: 1.3492, value_loss: 0.8463
2024-07-14 05:39:20,565 [INFO    ] __main__: train step 6782: loss: 1.0466, policy_loss: 1.3492, value_loss: 0.8463
2024-07-14 05:39:20,855 [INFO    ] __main__: train step 6783: loss: 1.0466, policy_loss: 1.3491, value_loss: 0.8463
2024-07-14 05:39:21,144 [INFO    ] __main__: train step 6784: loss: 1.0467, policy_loss: 1.3490, value_loss: 0.8463
2024-07-14 05:39:21,435 [INFO    ] __main__: train step 6785: loss: 1.0468, policy_loss: 1.3490, value_loss: 0.8462
2024-07-14 05:39:21,709 [INFO    ] __main__: train step 6786: loss: 1.0469, policy_loss: 1.3489, value_loss: 0.8462
2024-07-14 05:39:21,974 [INFO    ] __main__: train step 6787: loss: 1.0469, policy_loss: 1.3488, value_loss: 0.8462
2024-07-14 05:39:22,252 [INFO    ] __main__: train step 6788: loss: 1.0470, policy_loss: 1.3488, value_loss: 0.8462
2024-07-14 05:39:22,543 [INFO    ] __main__: train step 6789: loss: 1.0471, policy_loss: 1.3487, value_loss: 0.8461
2024-07-14 05:39:22,837 [INFO    ] __main__: train step 6790: loss: 1.0471, policy_loss: 1.3486, value_loss: 0.8461
2024-07-14 05:39:23,104 [INFO    ] __main__: train step 6791: loss: 1.0472, policy_loss: 1.3486, value_loss: 0.8461
2024-07-14 05:39:23,364 [INFO    ] __main__: train step 6792: loss: 1.0473, policy_loss: 1.3485, value_loss: 0.8461
2024-07-14 05:39:23,622 [INFO    ] __main__: train step 6793: loss: 1.0474, policy_loss: 1.3484, value_loss: 0.8461
2024-07-14 05:39:23,914 [INFO    ] __main__: train step 6794: loss: 1.0474, policy_loss: 1.3484, value_loss: 0.8460
2024-07-14 05:39:24,191 [INFO    ] __main__: train step 6795: loss: 1.0475, policy_loss: 1.3483, value_loss: 0.8460
2024-07-14 05:39:24,447 [INFO    ] __main__: train step 6796: loss: 1.0476, policy_loss: 1.3482, value_loss: 0.8460
2024-07-14 05:39:26,043 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:39:26,522 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:39:26,594 [INFO    ] __main__: train step 6797: loss: 1.0476, policy_loss: 1.3482, value_loss: 0.8460
2024-07-14 05:39:26,876 [INFO    ] __main__: train step 6798: loss: 1.0477, policy_loss: 1.3481, value_loss: 0.8459
2024-07-14 05:39:27,134 [INFO    ] __main__: train step 6799: loss: 1.0478, policy_loss: 1.3480, value_loss: 0.8459
2024-07-14 05:39:27,405 [INFO    ] __main__: train step 6800: loss: 1.0479, policy_loss: 1.3479, value_loss: 0.8459
2024-07-14 05:39:27,686 [INFO    ] __main__: train step 6801: loss: 1.0479, policy_loss: 1.3479, value_loss: 0.8459
2024-07-14 05:39:27,959 [INFO    ] __main__: train step 6802: loss: 1.0480, policy_loss: 1.3478, value_loss: 0.8458
2024-07-14 05:39:28,225 [INFO    ] __main__: train step 6803: loss: 1.0481, policy_loss: 1.3477, value_loss: 0.8458
2024-07-14 05:39:28,504 [INFO    ] __main__: train step 6804: loss: 1.0481, policy_loss: 1.3477, value_loss: 0.8458
2024-07-14 05:39:28,793 [INFO    ] __main__: train step 6805: loss: 1.0482, policy_loss: 1.3476, value_loss: 0.8458
2024-07-14 05:39:29,052 [INFO    ] __main__: train step 6806: loss: 1.0483, policy_loss: 1.3475, value_loss: 0.8458
2024-07-14 05:39:29,336 [INFO    ] __main__: train step 6807: loss: 1.0484, policy_loss: 1.3475, value_loss: 0.8457
2024-07-14 05:39:29,613 [INFO    ] __main__: train step 6808: loss: 1.0484, policy_loss: 1.3474, value_loss: 0.8457
2024-07-14 05:39:29,895 [INFO    ] __main__: train step 6809: loss: 1.0485, policy_loss: 1.3473, value_loss: 0.8457
2024-07-14 05:39:30,168 [INFO    ] __main__: train step 6810: loss: 1.0486, policy_loss: 1.3473, value_loss: 0.8457
2024-07-14 05:39:30,462 [INFO    ] __main__: train step 6811: loss: 1.0486, policy_loss: 1.3472, value_loss: 0.8456
2024-07-14 05:39:30,709 [INFO    ] __main__: train step 6812: loss: 1.0487, policy_loss: 1.3471, value_loss: 0.8456
2024-07-14 05:39:30,981 [INFO    ] __main__: train step 6813: loss: 1.0488, policy_loss: 1.3471, value_loss: 0.8456
2024-07-14 05:39:32,597 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:39:33,073 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:39:33,149 [INFO    ] __main__: train step 6814: loss: 1.0489, policy_loss: 1.3470, value_loss: 0.8456
2024-07-14 05:39:33,446 [INFO    ] __main__: train step 6815: loss: 1.0489, policy_loss: 1.3469, value_loss: 0.8455
2024-07-14 05:39:35,194 [INFO    ] __main__: train step 6816: loss: 1.0490, policy_loss: 1.3469, value_loss: 0.8455
2024-07-14 05:39:35,463 [INFO    ] __main__: train step 6817: loss: 1.0491, policy_loss: 1.3468, value_loss: 0.8455
2024-07-14 05:39:35,734 [INFO    ] __main__: train step 6818: loss: 1.0491, policy_loss: 1.3467, value_loss: 0.8455
2024-07-14 05:39:36,009 [INFO    ] __main__: train step 6819: loss: 1.0492, policy_loss: 1.3467, value_loss: 0.8454
2024-07-14 05:39:36,285 [INFO    ] __main__: train step 6820: loss: 1.0493, policy_loss: 1.3466, value_loss: 0.8454
2024-07-14 05:39:36,559 [INFO    ] __main__: train step 6821: loss: 1.0494, policy_loss: 1.3465, value_loss: 0.8454
2024-07-14 05:39:36,843 [INFO    ] __main__: train step 6822: loss: 1.0494, policy_loss: 1.3465, value_loss: 0.8454
2024-07-14 05:39:37,125 [INFO    ] __main__: train step 6823: loss: 1.0495, policy_loss: 1.3464, value_loss: 0.8453
2024-07-14 05:39:37,425 [INFO    ] __main__: train step 6824: loss: 1.0496, policy_loss: 1.3463, value_loss: 0.8453
2024-07-14 05:39:37,713 [INFO    ] __main__: train step 6825: loss: 1.0496, policy_loss: 1.3463, value_loss: 0.8453
2024-07-14 05:39:38,025 [INFO    ] __main__: train step 6826: loss: 1.0497, policy_loss: 1.3462, value_loss: 0.8453
2024-07-14 05:39:38,315 [INFO    ] __main__: train step 6827: loss: 1.0498, policy_loss: 1.3461, value_loss: 0.8452
2024-07-14 05:39:38,610 [INFO    ] __main__: train step 6828: loss: 1.0499, policy_loss: 1.3461, value_loss: 0.8452
2024-07-14 05:39:38,913 [INFO    ] __main__: train step 6829: loss: 1.0499, policy_loss: 1.3460, value_loss: 0.8452
2024-07-14 05:39:39,208 [INFO    ] __main__: train step 6830: loss: 1.0500, policy_loss: 1.3459, value_loss: 0.8452
2024-07-14 05:39:40,849 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:39:41,359 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:39:41,431 [INFO    ] __main__: train step 6831: loss: 1.0501, policy_loss: 1.3458, value_loss: 0.8451
2024-07-14 05:39:41,716 [INFO    ] __main__: train step 6832: loss: 1.0501, policy_loss: 1.3458, value_loss: 0.8451
2024-07-14 05:39:42,006 [INFO    ] __main__: train step 6833: loss: 1.0502, policy_loss: 1.3457, value_loss: 0.8451
2024-07-14 05:39:42,282 [INFO    ] __main__: train step 6834: loss: 1.0503, policy_loss: 1.3456, value_loss: 0.8451
2024-07-14 05:39:42,564 [INFO    ] __main__: train step 6835: loss: 1.0503, policy_loss: 1.3456, value_loss: 0.8450
2024-07-14 05:39:42,849 [INFO    ] __main__: train step 6836: loss: 1.0504, policy_loss: 1.3455, value_loss: 0.8450
2024-07-14 05:39:43,132 [INFO    ] __main__: train step 6837: loss: 1.0505, policy_loss: 1.3454, value_loss: 0.8450
2024-07-14 05:39:43,419 [INFO    ] __main__: train step 6838: loss: 1.0506, policy_loss: 1.3454, value_loss: 0.8450
2024-07-14 05:39:43,702 [INFO    ] __main__: train step 6839: loss: 1.0506, policy_loss: 1.3453, value_loss: 0.8450
2024-07-14 05:39:43,983 [INFO    ] __main__: train step 6840: loss: 1.0507, policy_loss: 1.3452, value_loss: 0.8449
2024-07-14 05:39:44,252 [INFO    ] __main__: train step 6841: loss: 1.0508, policy_loss: 1.3452, value_loss: 0.8449
2024-07-14 05:39:44,526 [INFO    ] __main__: train step 6842: loss: 1.0508, policy_loss: 1.3451, value_loss: 0.8449
2024-07-14 05:39:44,819 [INFO    ] __main__: train step 6843: loss: 1.0509, policy_loss: 1.3450, value_loss: 0.8449
2024-07-14 05:39:45,104 [INFO    ] __main__: train step 6844: loss: 1.0510, policy_loss: 1.3450, value_loss: 0.8448
2024-07-14 05:39:45,391 [INFO    ] __main__: train step 6845: loss: 1.0510, policy_loss: 1.3449, value_loss: 0.8448
2024-07-14 05:39:45,671 [INFO    ] __main__: train step 6846: loss: 1.0511, policy_loss: 1.3448, value_loss: 0.8448
2024-07-14 05:39:45,952 [INFO    ] __main__: train step 6847: loss: 1.0512, policy_loss: 1.3448, value_loss: 0.8448
2024-07-14 05:39:47,560 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:39:48,063 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:39:48,134 [INFO    ] __main__: train step 6848: loss: 1.0512, policy_loss: 1.3447, value_loss: 0.8447
2024-07-14 05:39:48,417 [INFO    ] __main__: train step 6849: loss: 1.0513, policy_loss: 1.3446, value_loss: 0.8447
2024-07-14 05:39:48,704 [INFO    ] __main__: train step 6850: loss: 1.0514, policy_loss: 1.3446, value_loss: 0.8447
2024-07-14 05:39:48,996 [INFO    ] __main__: train step 6851: loss: 1.0515, policy_loss: 1.3445, value_loss: 0.8447
2024-07-14 05:39:49,286 [INFO    ] __main__: train step 6852: loss: 1.0515, policy_loss: 1.3444, value_loss: 0.8446
2024-07-14 05:39:49,565 [INFO    ] __main__: train step 6853: loss: 1.0516, policy_loss: 1.3444, value_loss: 0.8446
2024-07-14 05:39:49,849 [INFO    ] __main__: train step 6854: loss: 1.0517, policy_loss: 1.3443, value_loss: 0.8446
2024-07-14 05:39:50,139 [INFO    ] __main__: train step 6855: loss: 1.0517, policy_loss: 1.3442, value_loss: 0.8446
2024-07-14 05:39:50,426 [INFO    ] __main__: train step 6856: loss: 1.0518, policy_loss: 1.3442, value_loss: 0.8445
2024-07-14 05:39:50,733 [INFO    ] __main__: train step 6857: loss: 1.0519, policy_loss: 1.3441, value_loss: 0.8445
2024-07-14 05:39:51,043 [INFO    ] __main__: train step 6858: loss: 1.0520, policy_loss: 1.3440, value_loss: 0.8445
2024-07-14 05:39:51,343 [INFO    ] __main__: train step 6859: loss: 1.0520, policy_loss: 1.3440, value_loss: 0.8445
2024-07-14 05:39:51,626 [INFO    ] __main__: train step 6860: loss: 1.0521, policy_loss: 1.3439, value_loss: 0.8444
2024-07-14 05:39:51,908 [INFO    ] __main__: train step 6861: loss: 1.0522, policy_loss: 1.3438, value_loss: 0.8444
2024-07-14 05:39:52,194 [INFO    ] __main__: train step 6862: loss: 1.0522, policy_loss: 1.3438, value_loss: 0.8444
2024-07-14 05:39:52,457 [INFO    ] __main__: train step 6863: loss: 1.0523, policy_loss: 1.3437, value_loss: 0.8444
2024-07-14 05:39:52,737 [INFO    ] __main__: train step 6864: loss: 1.0524, policy_loss: 1.3436, value_loss: 0.8443
2024-07-14 05:39:54,344 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:39:54,830 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:39:54,900 [INFO    ] __main__: train step 6865: loss: 1.0525, policy_loss: 1.3436, value_loss: 0.8443
2024-07-14 05:39:55,193 [INFO    ] __main__: train step 6866: loss: 1.0525, policy_loss: 1.3435, value_loss: 0.8443
2024-07-14 05:39:55,487 [INFO    ] __main__: train step 6867: loss: 1.0526, policy_loss: 1.3434, value_loss: 0.8443
2024-07-14 05:39:55,751 [INFO    ] __main__: train step 6868: loss: 1.0527, policy_loss: 1.3434, value_loss: 0.8442
2024-07-14 05:39:56,024 [INFO    ] __main__: train step 6869: loss: 1.0527, policy_loss: 1.3433, value_loss: 0.8442
2024-07-14 05:39:56,308 [INFO    ] __main__: train step 6870: loss: 1.0528, policy_loss: 1.3432, value_loss: 0.8442
2024-07-14 05:39:58,192 [INFO    ] __main__: train step 6871: loss: 1.0529, policy_loss: 1.3431, value_loss: 0.8442
2024-07-14 05:39:58,480 [INFO    ] __main__: train step 6872: loss: 1.0529, policy_loss: 1.3431, value_loss: 0.8441
2024-07-14 05:39:58,784 [INFO    ] __main__: train step 6873: loss: 1.0530, policy_loss: 1.3430, value_loss: 0.8441
2024-07-14 05:39:59,067 [INFO    ] __main__: train step 6874: loss: 1.0531, policy_loss: 1.3429, value_loss: 0.8441
2024-07-14 05:39:59,354 [INFO    ] __main__: train step 6875: loss: 1.0531, policy_loss: 1.3429, value_loss: 0.8441
2024-07-14 05:39:59,638 [INFO    ] __main__: train step 6876: loss: 1.0532, policy_loss: 1.3428, value_loss: 0.8441
2024-07-14 05:39:59,923 [INFO    ] __main__: train step 6877: loss: 1.0533, policy_loss: 1.3427, value_loss: 0.8440
2024-07-14 05:40:00,209 [INFO    ] __main__: train step 6878: loss: 1.0533, policy_loss: 1.3427, value_loss: 0.8440
2024-07-14 05:40:00,499 [INFO    ] __main__: train step 6879: loss: 1.0534, policy_loss: 1.3426, value_loss: 0.8440
2024-07-14 05:40:00,786 [INFO    ] __main__: train step 6880: loss: 1.0535, policy_loss: 1.3425, value_loss: 0.8440
2024-07-14 05:40:01,073 [INFO    ] __main__: train step 6881: loss: 1.0536, policy_loss: 1.3425, value_loss: 0.8439
2024-07-14 05:40:02,695 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:40:03,178 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:40:03,250 [INFO    ] __main__: train step 6882: loss: 1.0536, policy_loss: 1.3424, value_loss: 0.8439
2024-07-14 05:40:03,525 [INFO    ] __main__: train step 6883: loss: 1.0537, policy_loss: 1.3423, value_loss: 0.8439
2024-07-14 05:40:03,810 [INFO    ] __main__: train step 6884: loss: 1.0538, policy_loss: 1.3423, value_loss: 0.8439
2024-07-14 05:40:04,089 [INFO    ] __main__: train step 6885: loss: 1.0538, policy_loss: 1.3422, value_loss: 0.8438
2024-07-14 05:40:04,366 [INFO    ] __main__: train step 6886: loss: 1.0539, policy_loss: 1.3421, value_loss: 0.8438
2024-07-14 05:40:04,639 [INFO    ] __main__: train step 6887: loss: 1.0540, policy_loss: 1.3421, value_loss: 0.8438
2024-07-14 05:40:04,906 [INFO    ] __main__: train step 6888: loss: 1.0540, policy_loss: 1.3420, value_loss: 0.8438
2024-07-14 05:40:05,194 [INFO    ] __main__: train step 6889: loss: 1.0541, policy_loss: 1.3419, value_loss: 0.8437
2024-07-14 05:40:05,473 [INFO    ] __main__: train step 6890: loss: 1.0542, policy_loss: 1.3419, value_loss: 0.8437
2024-07-14 05:40:05,770 [INFO    ] __main__: train step 6891: loss: 1.0542, policy_loss: 1.3418, value_loss: 0.8437
2024-07-14 05:40:06,056 [INFO    ] __main__: train step 6892: loss: 1.0543, policy_loss: 1.3417, value_loss: 0.8437
2024-07-14 05:40:06,338 [INFO    ] __main__: train step 6893: loss: 1.0544, policy_loss: 1.3417, value_loss: 0.8436
2024-07-14 05:40:06,629 [INFO    ] __main__: train step 6894: loss: 1.0544, policy_loss: 1.3416, value_loss: 0.8436
2024-07-14 05:40:06,921 [INFO    ] __main__: train step 6895: loss: 1.0545, policy_loss: 1.3415, value_loss: 0.8436
2024-07-14 05:40:07,198 [INFO    ] __main__: train step 6896: loss: 1.0546, policy_loss: 1.3415, value_loss: 0.8436
2024-07-14 05:40:07,484 [INFO    ] __main__: train step 6897: loss: 1.0546, policy_loss: 1.3414, value_loss: 0.8435
2024-07-14 05:40:07,768 [INFO    ] __main__: train step 6898: loss: 1.0547, policy_loss: 1.3413, value_loss: 0.8435
2024-07-14 05:40:09,364 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:40:09,838 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:40:09,907 [INFO    ] __main__: train step 6899: loss: 1.0548, policy_loss: 1.3413, value_loss: 0.8435
2024-07-14 05:40:10,170 [INFO    ] __main__: train step 6900: loss: 1.0548, policy_loss: 1.3412, value_loss: 0.8435
2024-07-14 05:40:10,446 [INFO    ] __main__: train step 6901: loss: 1.0549, policy_loss: 1.3411, value_loss: 0.8434
2024-07-14 05:40:10,730 [INFO    ] __main__: train step 6902: loss: 1.0550, policy_loss: 1.3411, value_loss: 0.8434
2024-07-14 05:40:11,012 [INFO    ] __main__: train step 6903: loss: 1.0550, policy_loss: 1.3410, value_loss: 0.8434
2024-07-14 05:40:11,295 [INFO    ] __main__: train step 6904: loss: 1.0551, policy_loss: 1.3409, value_loss: 0.8434
2024-07-14 05:40:11,578 [INFO    ] __main__: train step 6905: loss: 1.0552, policy_loss: 1.3409, value_loss: 0.8433
2024-07-14 05:40:11,858 [INFO    ] __main__: train step 6906: loss: 1.0553, policy_loss: 1.3408, value_loss: 0.8433
2024-07-14 05:40:12,146 [INFO    ] __main__: train step 6907: loss: 1.0553, policy_loss: 1.3407, value_loss: 0.8433
2024-07-14 05:40:12,426 [INFO    ] __main__: train step 6908: loss: 1.0554, policy_loss: 1.3407, value_loss: 0.8433
2024-07-14 05:40:12,707 [INFO    ] __main__: train step 6909: loss: 1.0555, policy_loss: 1.3406, value_loss: 0.8432
2024-07-14 05:40:12,989 [INFO    ] __main__: train step 6910: loss: 1.0555, policy_loss: 1.3405, value_loss: 0.8432
2024-07-14 05:40:13,272 [INFO    ] __main__: train step 6911: loss: 1.0556, policy_loss: 1.3405, value_loss: 0.8432
2024-07-14 05:40:13,559 [INFO    ] __main__: train step 6912: loss: 1.0557, policy_loss: 1.3404, value_loss: 0.8432
2024-07-14 05:40:13,847 [INFO    ] __main__: train step 6913: loss: 1.0557, policy_loss: 1.3403, value_loss: 0.8431
2024-07-14 05:40:14,126 [INFO    ] __main__: train step 6914: loss: 1.0558, policy_loss: 1.3403, value_loss: 0.8431
2024-07-14 05:40:14,413 [INFO    ] __main__: train step 6915: loss: 1.0559, policy_loss: 1.3402, value_loss: 0.8431
2024-07-14 05:40:16,018 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:40:16,498 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:40:16,570 [INFO    ] __main__: train step 6916: loss: 1.0559, policy_loss: 1.3401, value_loss: 0.8431
2024-07-14 05:40:16,846 [INFO    ] __main__: train step 6917: loss: 1.0560, policy_loss: 1.3401, value_loss: 0.8430
2024-07-14 05:40:17,130 [INFO    ] __main__: train step 6918: loss: 1.0561, policy_loss: 1.3400, value_loss: 0.8430
2024-07-14 05:40:17,413 [INFO    ] __main__: train step 6919: loss: 1.0561, policy_loss: 1.3399, value_loss: 0.8430
2024-07-14 05:40:17,694 [INFO    ] __main__: train step 6920: loss: 1.0562, policy_loss: 1.3399, value_loss: 0.8430
2024-07-14 05:40:17,977 [INFO    ] __main__: train step 6921: loss: 1.0563, policy_loss: 1.3398, value_loss: 0.8429
2024-07-14 05:40:18,256 [INFO    ] __main__: train step 6922: loss: 1.0563, policy_loss: 1.3397, value_loss: 0.8429
2024-07-14 05:40:18,540 [INFO    ] __main__: train step 6923: loss: 1.0564, policy_loss: 1.3397, value_loss: 0.8429
2024-07-14 05:40:18,828 [INFO    ] __main__: train step 6924: loss: 1.0565, policy_loss: 1.3396, value_loss: 0.8429
2024-07-14 05:40:19,116 [INFO    ] __main__: train step 6925: loss: 1.0565, policy_loss: 1.3395, value_loss: 0.8428
2024-07-14 05:40:20,312 [INFO    ] __main__: train step 6926: loss: 1.0566, policy_loss: 1.3395, value_loss: 0.8428
2024-07-14 05:40:20,597 [INFO    ] __main__: train step 6927: loss: 1.0567, policy_loss: 1.3394, value_loss: 0.8428
2024-07-14 05:40:20,877 [INFO    ] __main__: train step 6928: loss: 1.0567, policy_loss: 1.3393, value_loss: 0.8428
2024-07-14 05:40:21,155 [INFO    ] __main__: train step 6929: loss: 1.0568, policy_loss: 1.3393, value_loss: 0.8427
2024-07-14 05:40:21,456 [INFO    ] __main__: train step 6930: loss: 1.0569, policy_loss: 1.3392, value_loss: 0.8427
2024-07-14 05:40:21,757 [INFO    ] __main__: train step 6931: loss: 1.0569, policy_loss: 1.3391, value_loss: 0.8427
2024-07-14 05:40:22,044 [INFO    ] __main__: train step 6932: loss: 1.0570, policy_loss: 1.3391, value_loss: 0.8427
2024-07-14 05:40:23,671 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:40:24,150 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:40:24,218 [INFO    ] __main__: train step 6933: loss: 1.0571, policy_loss: 1.3390, value_loss: 0.8426
2024-07-14 05:40:24,502 [INFO    ] __main__: train step 6934: loss: 1.0572, policy_loss: 1.3389, value_loss: 0.8426
2024-07-14 05:40:24,775 [INFO    ] __main__: train step 6935: loss: 1.0572, policy_loss: 1.3389, value_loss: 0.8426
2024-07-14 05:40:25,053 [INFO    ] __main__: train step 6936: loss: 1.0573, policy_loss: 1.3388, value_loss: 0.8426
2024-07-14 05:40:25,337 [INFO    ] __main__: train step 6937: loss: 1.0574, policy_loss: 1.3388, value_loss: 0.8425
2024-07-14 05:40:25,618 [INFO    ] __main__: train step 6938: loss: 1.0574, policy_loss: 1.3387, value_loss: 0.8425
2024-07-14 05:40:25,900 [INFO    ] __main__: train step 6939: loss: 1.0575, policy_loss: 1.3386, value_loss: 0.8425
2024-07-14 05:40:26,184 [INFO    ] __main__: train step 6940: loss: 1.0576, policy_loss: 1.3386, value_loss: 0.8425
2024-07-14 05:40:26,475 [INFO    ] __main__: train step 6941: loss: 1.0576, policy_loss: 1.3385, value_loss: 0.8424
2024-07-14 05:40:26,756 [INFO    ] __main__: train step 6942: loss: 1.0577, policy_loss: 1.3384, value_loss: 0.8424
2024-07-14 05:40:27,041 [INFO    ] __main__: train step 6943: loss: 1.0578, policy_loss: 1.3384, value_loss: 0.8424
2024-07-14 05:40:27,312 [INFO    ] __main__: train step 6944: loss: 1.0578, policy_loss: 1.3383, value_loss: 0.8424
2024-07-14 05:40:27,595 [INFO    ] __main__: train step 6945: loss: 1.0579, policy_loss: 1.3382, value_loss: 0.8423
2024-07-14 05:40:27,856 [INFO    ] __main__: train step 6946: loss: 1.0580, policy_loss: 1.3382, value_loss: 0.8423
2024-07-14 05:40:28,146 [INFO    ] __main__: train step 6947: loss: 1.0580, policy_loss: 1.3381, value_loss: 0.8423
2024-07-14 05:40:28,423 [INFO    ] __main__: train step 6948: loss: 1.0581, policy_loss: 1.3380, value_loss: 0.8423
2024-07-14 05:40:28,713 [INFO    ] __main__: train step 6949: loss: 1.0582, policy_loss: 1.3380, value_loss: 0.8422
2024-07-14 05:40:30,325 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:40:30,801 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:40:30,867 [INFO    ] __main__: train step 6950: loss: 1.0582, policy_loss: 1.3379, value_loss: 0.8422
2024-07-14 05:40:31,146 [INFO    ] __main__: train step 6951: loss: 1.0583, policy_loss: 1.3378, value_loss: 0.8422
2024-07-14 05:40:31,413 [INFO    ] __main__: train step 6952: loss: 1.0584, policy_loss: 1.3378, value_loss: 0.8422
2024-07-14 05:40:31,693 [INFO    ] __main__: train step 6953: loss: 1.0584, policy_loss: 1.3377, value_loss: 0.8421
2024-07-14 05:40:31,973 [INFO    ] __main__: train step 6954: loss: 1.0585, policy_loss: 1.3376, value_loss: 0.8421
2024-07-14 05:40:32,265 [INFO    ] __main__: train step 6955: loss: 1.0586, policy_loss: 1.3376, value_loss: 0.8421
2024-07-14 05:40:32,548 [INFO    ] __main__: train step 6956: loss: 1.0586, policy_loss: 1.3375, value_loss: 0.8421
2024-07-14 05:40:32,838 [INFO    ] __main__: train step 6957: loss: 1.0587, policy_loss: 1.3374, value_loss: 0.8420
2024-07-14 05:40:33,123 [INFO    ] __main__: train step 6958: loss: 1.0588, policy_loss: 1.3374, value_loss: 0.8420
2024-07-14 05:40:33,410 [INFO    ] __main__: train step 6959: loss: 1.0588, policy_loss: 1.3373, value_loss: 0.8420
2024-07-14 05:40:33,689 [INFO    ] __main__: train step 6960: loss: 1.0589, policy_loss: 1.3372, value_loss: 0.8420
2024-07-14 05:40:33,966 [INFO    ] __main__: train step 6961: loss: 1.0590, policy_loss: 1.3372, value_loss: 0.8419
2024-07-14 05:40:34,243 [INFO    ] __main__: train step 6962: loss: 1.0591, policy_loss: 1.3371, value_loss: 0.8419
2024-07-14 05:40:34,521 [INFO    ] __main__: train step 6963: loss: 1.0591, policy_loss: 1.3371, value_loss: 0.8419
2024-07-14 05:40:34,799 [INFO    ] __main__: train step 6964: loss: 1.0592, policy_loss: 1.3370, value_loss: 0.8419
2024-07-14 05:40:35,092 [INFO    ] __main__: train step 6965: loss: 1.0593, policy_loss: 1.3369, value_loss: 0.8419
2024-07-14 05:40:35,375 [INFO    ] __main__: train step 6966: loss: 1.0593, policy_loss: 1.3369, value_loss: 0.8418
2024-07-14 05:40:36,970 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:40:37,452 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:40:37,520 [INFO    ] __main__: train step 6967: loss: 1.0594, policy_loss: 1.3368, value_loss: 0.8418
2024-07-14 05:40:37,807 [INFO    ] __main__: train step 6968: loss: 1.0595, policy_loss: 1.3367, value_loss: 0.8418
2024-07-14 05:40:38,093 [INFO    ] __main__: train step 6969: loss: 1.0595, policy_loss: 1.3367, value_loss: 0.8418
2024-07-14 05:40:38,377 [INFO    ] __main__: train step 6970: loss: 1.0596, policy_loss: 1.3366, value_loss: 0.8417
2024-07-14 05:40:38,661 [INFO    ] __main__: train step 6971: loss: 1.0597, policy_loss: 1.3365, value_loss: 0.8417
2024-07-14 05:40:38,943 [INFO    ] __main__: train step 6972: loss: 1.0597, policy_loss: 1.3365, value_loss: 0.8417
2024-07-14 05:40:39,233 [INFO    ] __main__: train step 6973: loss: 1.0598, policy_loss: 1.3364, value_loss: 0.8417
2024-07-14 05:40:39,510 [INFO    ] __main__: train step 6974: loss: 1.0599, policy_loss: 1.3363, value_loss: 0.8416
2024-07-14 05:40:39,790 [INFO    ] __main__: train step 6975: loss: 1.0599, policy_loss: 1.3363, value_loss: 0.8416
2024-07-14 05:40:40,080 [INFO    ] __main__: train step 6976: loss: 1.0600, policy_loss: 1.3362, value_loss: 0.8416
2024-07-14 05:40:40,347 [INFO    ] __main__: train step 6977: loss: 1.0601, policy_loss: 1.3361, value_loss: 0.8416
2024-07-14 05:40:40,637 [INFO    ] __main__: train step 6978: loss: 1.0601, policy_loss: 1.3361, value_loss: 0.8415
2024-07-14 05:40:40,926 [INFO    ] __main__: train step 6979: loss: 1.0602, policy_loss: 1.3360, value_loss: 0.8415
2024-07-14 05:40:41,211 [INFO    ] __main__: train step 6980: loss: 1.0603, policy_loss: 1.3359, value_loss: 0.8415
2024-07-14 05:40:42,471 [INFO    ] __main__: train step 6981: loss: 1.0603, policy_loss: 1.3359, value_loss: 0.8415
2024-07-14 05:40:42,741 [INFO    ] __main__: train step 6982: loss: 1.0604, policy_loss: 1.3358, value_loss: 0.8414
2024-07-14 05:40:43,024 [INFO    ] __main__: train step 6983: loss: 1.0605, policy_loss: 1.3357, value_loss: 0.8414
2024-07-14 05:40:44,644 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:40:45,125 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:40:45,196 [INFO    ] __main__: train step 6984: loss: 1.0605, policy_loss: 1.3357, value_loss: 0.8414
2024-07-14 05:40:45,470 [INFO    ] __main__: train step 6985: loss: 1.0606, policy_loss: 1.3356, value_loss: 0.8414
2024-07-14 05:40:45,743 [INFO    ] __main__: train step 6986: loss: 1.0607, policy_loss: 1.3356, value_loss: 0.8413
2024-07-14 05:40:46,037 [INFO    ] __main__: train step 6987: loss: 1.0607, policy_loss: 1.3355, value_loss: 0.8413
2024-07-14 05:40:46,315 [INFO    ] __main__: train step 6988: loss: 1.0608, policy_loss: 1.3354, value_loss: 0.8413
2024-07-14 05:40:46,590 [INFO    ] __main__: train step 6989: loss: 1.0609, policy_loss: 1.3354, value_loss: 0.8413
2024-07-14 05:40:46,884 [INFO    ] __main__: train step 6990: loss: 1.0609, policy_loss: 1.3353, value_loss: 0.8412
2024-07-14 05:40:47,160 [INFO    ] __main__: train step 6991: loss: 1.0610, policy_loss: 1.3352, value_loss: 0.8412
2024-07-14 05:40:47,440 [INFO    ] __main__: train step 6992: loss: 1.0611, policy_loss: 1.3352, value_loss: 0.8412
2024-07-14 05:40:47,729 [INFO    ] __main__: train step 6993: loss: 1.0611, policy_loss: 1.3351, value_loss: 0.8412
2024-07-14 05:40:48,015 [INFO    ] __main__: train step 6994: loss: 1.0612, policy_loss: 1.3350, value_loss: 0.8412
2024-07-14 05:40:48,289 [INFO    ] __main__: train step 6995: loss: 1.0613, policy_loss: 1.3350, value_loss: 0.8411
2024-07-14 05:40:48,562 [INFO    ] __main__: train step 6996: loss: 1.0613, policy_loss: 1.3349, value_loss: 0.8411
2024-07-14 05:40:48,833 [INFO    ] __main__: train step 6997: loss: 1.0614, policy_loss: 1.3348, value_loss: 0.8411
2024-07-14 05:40:49,112 [INFO    ] __main__: train step 6998: loss: 1.0615, policy_loss: 1.3348, value_loss: 0.8411
2024-07-14 05:40:49,395 [INFO    ] __main__: train step 6999: loss: 1.0615, policy_loss: 1.3347, value_loss: 0.8410
2024-07-14 05:40:49,669 [INFO    ] __main__: train step 7000: loss: 1.0616, policy_loss: 1.3346, value_loss: 0.8410
2024-07-14 05:40:49,804 [INFO    ] __main__: restored step 6000 for evaluation
2024-07-14 05:40:55,055 [INFO    ] __main__: test network ELO difference from baseline network: +160 (+8/-8) ELO from 32000 self-played games
2024-07-14 05:40:55,058 [INFO    ] __main__: game outcomes: W: 21459, D: 736, L: 9805
2024-07-14 05:40:55,061 [INFO    ] __main__: validation_elo_delta: 160, validation_elo: 1606
2024-07-14 05:40:57,149 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:40:57,637 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:40:57,702 [INFO    ] __main__: train step 7001: loss: 1.0617, policy_loss: 1.3346, value_loss: 0.8410
2024-07-14 05:40:57,987 [INFO    ] __main__: train step 7002: loss: 1.0617, policy_loss: 1.3345, value_loss: 0.8410
2024-07-14 05:40:58,257 [INFO    ] __main__: train step 7003: loss: 1.0618, policy_loss: 1.3345, value_loss: 0.8409
2024-07-14 05:40:58,502 [INFO    ] __main__: train step 7004: loss: 1.0619, policy_loss: 1.3344, value_loss: 0.8409
2024-07-14 05:40:58,780 [INFO    ] __main__: train step 7005: loss: 1.0619, policy_loss: 1.3343, value_loss: 0.8409
2024-07-14 05:40:59,054 [INFO    ] __main__: train step 7006: loss: 1.0620, policy_loss: 1.3343, value_loss: 0.8409
2024-07-14 05:40:59,323 [INFO    ] __main__: train step 7007: loss: 1.0621, policy_loss: 1.3342, value_loss: 0.8408
2024-07-14 05:40:59,616 [INFO    ] __main__: train step 7008: loss: 1.0621, policy_loss: 1.3341, value_loss: 0.8408
2024-07-14 05:40:59,910 [INFO    ] __main__: train step 7009: loss: 1.0622, policy_loss: 1.3341, value_loss: 0.8408
2024-07-14 05:41:00,204 [INFO    ] __main__: train step 7010: loss: 1.0623, policy_loss: 1.3340, value_loss: 0.8408
2024-07-14 05:41:00,481 [INFO    ] __main__: train step 7011: loss: 1.0623, policy_loss: 1.3339, value_loss: 0.8407
2024-07-14 05:41:00,761 [INFO    ] __main__: train step 7012: loss: 1.0624, policy_loss: 1.3339, value_loss: 0.8407
2024-07-14 05:41:01,084 [INFO    ] __main__: train step 7013: loss: 1.0625, policy_loss: 1.3338, value_loss: 0.8407
2024-07-14 05:41:01,365 [INFO    ] __main__: train step 7014: loss: 1.0625, policy_loss: 1.3337, value_loss: 0.8407
2024-07-14 05:41:01,637 [INFO    ] __main__: train step 7015: loss: 1.0626, policy_loss: 1.3337, value_loss: 0.8406
2024-07-14 05:41:01,908 [INFO    ] __main__: train step 7016: loss: 1.0627, policy_loss: 1.3336, value_loss: 0.8406
2024-07-14 05:41:02,188 [INFO    ] __main__: train step 7017: loss: 1.0627, policy_loss: 1.3335, value_loss: 0.8406
2024-07-14 05:41:03,787 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:41:04,258 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:41:04,323 [INFO    ] __main__: train step 7018: loss: 1.0628, policy_loss: 1.3335, value_loss: 0.8406
2024-07-14 05:41:04,591 [INFO    ] __main__: train step 7019: loss: 1.0629, policy_loss: 1.3334, value_loss: 0.8405
2024-07-14 05:41:04,875 [INFO    ] __main__: train step 7020: loss: 1.0629, policy_loss: 1.3334, value_loss: 0.8405
2024-07-14 05:41:05,159 [INFO    ] __main__: train step 7021: loss: 1.0630, policy_loss: 1.3333, value_loss: 0.8405
2024-07-14 05:41:05,438 [INFO    ] __main__: train step 7022: loss: 1.0631, policy_loss: 1.3332, value_loss: 0.8405
2024-07-14 05:41:05,730 [INFO    ] __main__: train step 7023: loss: 1.0631, policy_loss: 1.3332, value_loss: 0.8404
2024-07-14 05:41:06,012 [INFO    ] __main__: train step 7024: loss: 1.0632, policy_loss: 1.3331, value_loss: 0.8404
2024-07-14 05:41:06,295 [INFO    ] __main__: train step 7025: loss: 1.0633, policy_loss: 1.3330, value_loss: 0.8404
2024-07-14 05:41:06,579 [INFO    ] __main__: train step 7026: loss: 1.0633, policy_loss: 1.3330, value_loss: 0.8404
2024-07-14 05:41:06,866 [INFO    ] __main__: train step 7027: loss: 1.0634, policy_loss: 1.3329, value_loss: 0.8403
2024-07-14 05:41:07,150 [INFO    ] __main__: train step 7028: loss: 1.0635, policy_loss: 1.3328, value_loss: 0.8403
2024-07-14 05:41:07,431 [INFO    ] __main__: train step 7029: loss: 1.0635, policy_loss: 1.3328, value_loss: 0.8403
2024-07-14 05:41:07,720 [INFO    ] __main__: train step 7030: loss: 1.0636, policy_loss: 1.3327, value_loss: 0.8403
2024-07-14 05:41:08,001 [INFO    ] __main__: train step 7031: loss: 1.0637, policy_loss: 1.3326, value_loss: 0.8402
2024-07-14 05:41:08,277 [INFO    ] __main__: train step 7032: loss: 1.0637, policy_loss: 1.3326, value_loss: 0.8402
2024-07-14 05:41:08,547 [INFO    ] __main__: train step 7033: loss: 1.0638, policy_loss: 1.3325, value_loss: 0.8402
2024-07-14 05:41:08,812 [INFO    ] __main__: train step 7034: loss: 1.0639, policy_loss: 1.3324, value_loss: 0.8402
2024-07-14 05:41:10,411 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:41:10,899 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:41:10,971 [INFO    ] __main__: train step 7035: loss: 1.0639, policy_loss: 1.3324, value_loss: 0.8401
2024-07-14 05:41:12,721 [INFO    ] __main__: train step 7036: loss: 1.0640, policy_loss: 1.3323, value_loss: 0.8401
2024-07-14 05:41:13,000 [INFO    ] __main__: train step 7037: loss: 1.0640, policy_loss: 1.3323, value_loss: 0.8401
2024-07-14 05:41:13,268 [INFO    ] __main__: train step 7038: loss: 1.0641, policy_loss: 1.3322, value_loss: 0.8401
2024-07-14 05:41:13,547 [INFO    ] __main__: train step 7039: loss: 1.0642, policy_loss: 1.3321, value_loss: 0.8400
2024-07-14 05:41:13,833 [INFO    ] __main__: train step 7040: loss: 1.0642, policy_loss: 1.3321, value_loss: 0.8400
2024-07-14 05:41:14,115 [INFO    ] __main__: train step 7041: loss: 1.0643, policy_loss: 1.3320, value_loss: 0.8400
2024-07-14 05:41:14,409 [INFO    ] __main__: train step 7042: loss: 1.0644, policy_loss: 1.3319, value_loss: 0.8400
2024-07-14 05:41:14,684 [INFO    ] __main__: train step 7043: loss: 1.0644, policy_loss: 1.3319, value_loss: 0.8399
2024-07-14 05:41:14,966 [INFO    ] __main__: train step 7044: loss: 1.0645, policy_loss: 1.3318, value_loss: 0.8399
2024-07-14 05:41:15,254 [INFO    ] __main__: train step 7045: loss: 1.0646, policy_loss: 1.3317, value_loss: 0.8399
2024-07-14 05:41:15,541 [INFO    ] __main__: train step 7046: loss: 1.0646, policy_loss: 1.3317, value_loss: 0.8399
2024-07-14 05:41:15,822 [INFO    ] __main__: train step 7047: loss: 1.0647, policy_loss: 1.3316, value_loss: 0.8398
2024-07-14 05:41:16,105 [INFO    ] __main__: train step 7048: loss: 1.0648, policy_loss: 1.3315, value_loss: 0.8398
2024-07-14 05:41:16,388 [INFO    ] __main__: train step 7049: loss: 1.0648, policy_loss: 1.3315, value_loss: 0.8398
2024-07-14 05:41:16,671 [INFO    ] __main__: train step 7050: loss: 1.0649, policy_loss: 1.3314, value_loss: 0.8398
2024-07-14 05:41:16,955 [INFO    ] __main__: train step 7051: loss: 1.0649, policy_loss: 1.3314, value_loss: 0.8397
2024-07-14 05:41:18,538 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:41:19,000 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:41:19,071 [INFO    ] __main__: train step 7052: loss: 1.0650, policy_loss: 1.3313, value_loss: 0.8397
2024-07-14 05:41:19,363 [INFO    ] __main__: train step 7053: loss: 1.0651, policy_loss: 1.3312, value_loss: 0.8397
2024-07-14 05:41:19,642 [INFO    ] __main__: train step 7054: loss: 1.0651, policy_loss: 1.3312, value_loss: 0.8397
2024-07-14 05:41:19,920 [INFO    ] __main__: train step 7055: loss: 1.0652, policy_loss: 1.3311, value_loss: 0.8396
2024-07-14 05:41:20,199 [INFO    ] __main__: train step 7056: loss: 1.0653, policy_loss: 1.3310, value_loss: 0.8396
2024-07-14 05:41:20,480 [INFO    ] __main__: train step 7057: loss: 1.0653, policy_loss: 1.3310, value_loss: 0.8396
2024-07-14 05:41:20,763 [INFO    ] __main__: train step 7058: loss: 1.0654, policy_loss: 1.3309, value_loss: 0.8396
2024-07-14 05:41:21,055 [INFO    ] __main__: train step 7059: loss: 1.0655, policy_loss: 1.3308, value_loss: 0.8395
2024-07-14 05:41:21,344 [INFO    ] __main__: train step 7060: loss: 1.0655, policy_loss: 1.3308, value_loss: 0.8395
2024-07-14 05:41:21,629 [INFO    ] __main__: train step 7061: loss: 1.0656, policy_loss: 1.3307, value_loss: 0.8395
2024-07-14 05:41:21,899 [INFO    ] __main__: train step 7062: loss: 1.0657, policy_loss: 1.3306, value_loss: 0.8395
2024-07-14 05:41:22,177 [INFO    ] __main__: train step 7063: loss: 1.0657, policy_loss: 1.3306, value_loss: 0.8394
2024-07-14 05:41:22,455 [INFO    ] __main__: train step 7064: loss: 1.0658, policy_loss: 1.3305, value_loss: 0.8394
2024-07-14 05:41:22,744 [INFO    ] __main__: train step 7065: loss: 1.0659, policy_loss: 1.3304, value_loss: 0.8394
2024-07-14 05:41:23,021 [INFO    ] __main__: train step 7066: loss: 1.0659, policy_loss: 1.3304, value_loss: 0.8394
2024-07-14 05:41:23,298 [INFO    ] __main__: train step 7067: loss: 1.0660, policy_loss: 1.3303, value_loss: 0.8393
2024-07-14 05:41:23,586 [INFO    ] __main__: train step 7068: loss: 1.0660, policy_loss: 1.3303, value_loss: 0.8393
2024-07-14 05:41:25,174 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:41:25,652 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:41:25,725 [INFO    ] __main__: train step 7069: loss: 1.0661, policy_loss: 1.3302, value_loss: 0.8393
2024-07-14 05:41:26,002 [INFO    ] __main__: train step 7070: loss: 1.0662, policy_loss: 1.3301, value_loss: 0.8393
2024-07-14 05:41:26,281 [INFO    ] __main__: train step 7071: loss: 1.0662, policy_loss: 1.3301, value_loss: 0.8392
2024-07-14 05:41:26,559 [INFO    ] __main__: train step 7072: loss: 1.0663, policy_loss: 1.3300, value_loss: 0.8392
2024-07-14 05:41:26,841 [INFO    ] __main__: train step 7073: loss: 1.0664, policy_loss: 1.3299, value_loss: 0.8392
2024-07-14 05:41:27,113 [INFO    ] __main__: train step 7074: loss: 1.0664, policy_loss: 1.3299, value_loss: 0.8392
2024-07-14 05:41:27,389 [INFO    ] __main__: train step 7075: loss: 1.0665, policy_loss: 1.3298, value_loss: 0.8391
2024-07-14 05:41:27,667 [INFO    ] __main__: train step 7076: loss: 1.0665, policy_loss: 1.3297, value_loss: 0.8391
2024-07-14 05:41:27,951 [INFO    ] __main__: train step 7077: loss: 1.0666, policy_loss: 1.3297, value_loss: 0.8391
2024-07-14 05:41:28,249 [INFO    ] __main__: train step 7078: loss: 1.0667, policy_loss: 1.3296, value_loss: 0.8391
2024-07-14 05:41:28,524 [INFO    ] __main__: train step 7079: loss: 1.0667, policy_loss: 1.3295, value_loss: 0.8390
2024-07-14 05:41:28,808 [INFO    ] __main__: train step 7080: loss: 1.0668, policy_loss: 1.3295, value_loss: 0.8390
2024-07-14 05:41:29,090 [INFO    ] __main__: train step 7081: loss: 1.0669, policy_loss: 1.3294, value_loss: 0.8390
2024-07-14 05:41:29,368 [INFO    ] __main__: train step 7082: loss: 1.0669, policy_loss: 1.3294, value_loss: 0.8390
2024-07-14 05:41:29,644 [INFO    ] __main__: train step 7083: loss: 1.0670, policy_loss: 1.3293, value_loss: 0.8389
2024-07-14 05:41:29,892 [INFO    ] __main__: train step 7084: loss: 1.0671, policy_loss: 1.3292, value_loss: 0.8389
2024-07-14 05:41:30,143 [INFO    ] __main__: train step 7085: loss: 1.0671, policy_loss: 1.3292, value_loss: 0.8389
2024-07-14 05:41:31,708 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:41:32,181 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:41:32,247 [INFO    ] __main__: train step 7086: loss: 1.0672, policy_loss: 1.3291, value_loss: 0.8389
2024-07-14 05:41:32,519 [INFO    ] __main__: train step 7087: loss: 1.0672, policy_loss: 1.3290, value_loss: 0.8388
2024-07-14 05:41:32,790 [INFO    ] __main__: train step 7088: loss: 1.0673, policy_loss: 1.3290, value_loss: 0.8388
2024-07-14 05:41:33,045 [INFO    ] __main__: train step 7089: loss: 1.0674, policy_loss: 1.3289, value_loss: 0.8388
2024-07-14 05:41:34,872 [INFO    ] __main__: train step 7090: loss: 1.0674, policy_loss: 1.3288, value_loss: 0.8388
2024-07-14 05:41:35,157 [INFO    ] __main__: train step 7091: loss: 1.0675, policy_loss: 1.3288, value_loss: 0.8387
2024-07-14 05:41:35,439 [INFO    ] __main__: train step 7092: loss: 1.0676, policy_loss: 1.3287, value_loss: 0.8387
2024-07-14 05:41:35,729 [INFO    ] __main__: train step 7093: loss: 1.0676, policy_loss: 1.3287, value_loss: 0.8387
2024-07-14 05:41:36,014 [INFO    ] __main__: train step 7094: loss: 1.0677, policy_loss: 1.3286, value_loss: 0.8387
2024-07-14 05:41:36,296 [INFO    ] __main__: train step 7095: loss: 1.0678, policy_loss: 1.3285, value_loss: 0.8386
2024-07-14 05:41:36,575 [INFO    ] __main__: train step 7096: loss: 1.0678, policy_loss: 1.3285, value_loss: 0.8386
2024-07-14 05:41:36,860 [INFO    ] __main__: train step 7097: loss: 1.0679, policy_loss: 1.3284, value_loss: 0.8386
2024-07-14 05:41:37,133 [INFO    ] __main__: train step 7098: loss: 1.0679, policy_loss: 1.3283, value_loss: 0.8386
2024-07-14 05:41:37,408 [INFO    ] __main__: train step 7099: loss: 1.0680, policy_loss: 1.3283, value_loss: 0.8385
2024-07-14 05:41:37,715 [INFO    ] __main__: train step 7100: loss: 1.0681, policy_loss: 1.3282, value_loss: 0.8385
2024-07-14 05:41:37,995 [INFO    ] __main__: train step 7101: loss: 1.0681, policy_loss: 1.3281, value_loss: 0.8385
2024-07-14 05:41:38,269 [INFO    ] __main__: train step 7102: loss: 1.0682, policy_loss: 1.3281, value_loss: 0.8385
2024-07-14 05:41:39,890 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:41:40,375 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:41:40,441 [INFO    ] __main__: train step 7103: loss: 1.0683, policy_loss: 1.3280, value_loss: 0.8384
2024-07-14 05:41:40,719 [INFO    ] __main__: train step 7104: loss: 1.0683, policy_loss: 1.3280, value_loss: 0.8384
2024-07-14 05:41:41,005 [INFO    ] __main__: train step 7105: loss: 1.0684, policy_loss: 1.3279, value_loss: 0.8384
2024-07-14 05:41:41,293 [INFO    ] __main__: train step 7106: loss: 1.0685, policy_loss: 1.3278, value_loss: 0.8384
2024-07-14 05:41:41,567 [INFO    ] __main__: train step 7107: loss: 1.0685, policy_loss: 1.3278, value_loss: 0.8383
2024-07-14 05:41:41,838 [INFO    ] __main__: train step 7108: loss: 1.0686, policy_loss: 1.3277, value_loss: 0.8383
2024-07-14 05:41:42,121 [INFO    ] __main__: train step 7109: loss: 1.0686, policy_loss: 1.3276, value_loss: 0.8383
2024-07-14 05:41:42,397 [INFO    ] __main__: train step 7110: loss: 1.0687, policy_loss: 1.3276, value_loss: 0.8383
2024-07-14 05:41:42,669 [INFO    ] __main__: train step 7111: loss: 1.0688, policy_loss: 1.3275, value_loss: 0.8382
2024-07-14 05:41:42,938 [INFO    ] __main__: train step 7112: loss: 1.0688, policy_loss: 1.3274, value_loss: 0.8382
2024-07-14 05:41:43,216 [INFO    ] __main__: train step 7113: loss: 1.0689, policy_loss: 1.3274, value_loss: 0.8382
2024-07-14 05:41:43,499 [INFO    ] __main__: train step 7114: loss: 1.0690, policy_loss: 1.3273, value_loss: 0.8382
2024-07-14 05:41:43,776 [INFO    ] __main__: train step 7115: loss: 1.0690, policy_loss: 1.3273, value_loss: 0.8381
2024-07-14 05:41:44,064 [INFO    ] __main__: train step 7116: loss: 1.0691, policy_loss: 1.3272, value_loss: 0.8381
2024-07-14 05:41:44,360 [INFO    ] __main__: train step 7117: loss: 1.0692, policy_loss: 1.3271, value_loss: 0.8381
2024-07-14 05:41:44,631 [INFO    ] __main__: train step 7118: loss: 1.0692, policy_loss: 1.3271, value_loss: 0.8381
2024-07-14 05:41:44,912 [INFO    ] __main__: train step 7119: loss: 1.0693, policy_loss: 1.3270, value_loss: 0.8380
2024-07-14 05:41:46,517 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:41:46,990 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:41:47,058 [INFO    ] __main__: train step 7120: loss: 1.0693, policy_loss: 1.3269, value_loss: 0.8380
2024-07-14 05:41:47,333 [INFO    ] __main__: train step 7121: loss: 1.0694, policy_loss: 1.3269, value_loss: 0.8380
2024-07-14 05:41:47,605 [INFO    ] __main__: train step 7122: loss: 1.0695, policy_loss: 1.3268, value_loss: 0.8380
2024-07-14 05:41:47,888 [INFO    ] __main__: train step 7123: loss: 1.0695, policy_loss: 1.3267, value_loss: 0.8379
2024-07-14 05:41:48,161 [INFO    ] __main__: train step 7124: loss: 1.0696, policy_loss: 1.3267, value_loss: 0.8379
2024-07-14 05:41:48,437 [INFO    ] __main__: train step 7125: loss: 1.0696, policy_loss: 1.3266, value_loss: 0.8379
2024-07-14 05:41:48,711 [INFO    ] __main__: train step 7126: loss: 1.0697, policy_loss: 1.3266, value_loss: 0.8379
2024-07-14 05:41:48,992 [INFO    ] __main__: train step 7127: loss: 1.0698, policy_loss: 1.3265, value_loss: 0.8378
2024-07-14 05:41:49,268 [INFO    ] __main__: train step 7128: loss: 1.0698, policy_loss: 1.3264, value_loss: 0.8378
2024-07-14 05:41:49,547 [INFO    ] __main__: train step 7129: loss: 1.0699, policy_loss: 1.3264, value_loss: 0.8378
2024-07-14 05:41:49,831 [INFO    ] __main__: train step 7130: loss: 1.0700, policy_loss: 1.3263, value_loss: 0.8377
2024-07-14 05:41:50,109 [INFO    ] __main__: train step 7131: loss: 1.0700, policy_loss: 1.3262, value_loss: 0.8377
2024-07-14 05:41:50,390 [INFO    ] __main__: train step 7132: loss: 1.0701, policy_loss: 1.3262, value_loss: 0.8377
2024-07-14 05:41:50,669 [INFO    ] __main__: train step 7133: loss: 1.0701, policy_loss: 1.3261, value_loss: 0.8377
2024-07-14 05:41:50,952 [INFO    ] __main__: train step 7134: loss: 1.0702, policy_loss: 1.3260, value_loss: 0.8376
2024-07-14 05:41:51,226 [INFO    ] __main__: train step 7135: loss: 1.0703, policy_loss: 1.3260, value_loss: 0.8376
2024-07-14 05:41:51,503 [INFO    ] __main__: train step 7136: loss: 1.0703, policy_loss: 1.3259, value_loss: 0.8376
2024-07-14 05:41:53,091 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:41:53,568 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:41:53,635 [INFO    ] __main__: train step 7137: loss: 1.0704, policy_loss: 1.3259, value_loss: 0.8376
2024-07-14 05:41:53,916 [INFO    ] __main__: train step 7138: loss: 1.0705, policy_loss: 1.3258, value_loss: 0.8375
2024-07-14 05:41:54,207 [INFO    ] __main__: train step 7139: loss: 1.0705, policy_loss: 1.3257, value_loss: 0.8375
2024-07-14 05:41:54,493 [INFO    ] __main__: train step 7140: loss: 1.0706, policy_loss: 1.3257, value_loss: 0.8375
2024-07-14 05:41:54,796 [INFO    ] __main__: train step 7141: loss: 1.0706, policy_loss: 1.3256, value_loss: 0.8375
2024-07-14 05:41:55,083 [INFO    ] __main__: train step 7142: loss: 1.0707, policy_loss: 1.3255, value_loss: 0.8374
2024-07-14 05:41:55,347 [INFO    ] __main__: train step 7143: loss: 1.0708, policy_loss: 1.3255, value_loss: 0.8374
2024-07-14 05:41:55,625 [INFO    ] __main__: train step 7144: loss: 1.0708, policy_loss: 1.3254, value_loss: 0.8374
2024-07-14 05:41:55,904 [INFO    ] __main__: train step 7145: loss: 1.0709, policy_loss: 1.3254, value_loss: 0.8374
2024-07-14 05:41:57,124 [INFO    ] __main__: train step 7146: loss: 1.0710, policy_loss: 1.3253, value_loss: 0.8373
2024-07-14 05:41:57,399 [INFO    ] __main__: train step 7147: loss: 1.0710, policy_loss: 1.3252, value_loss: 0.8373
2024-07-14 05:41:57,669 [INFO    ] __main__: train step 7148: loss: 1.0711, policy_loss: 1.3252, value_loss: 0.8373
2024-07-14 05:41:57,961 [INFO    ] __main__: train step 7149: loss: 1.0711, policy_loss: 1.3251, value_loss: 0.8373
2024-07-14 05:41:58,238 [INFO    ] __main__: train step 7150: loss: 1.0712, policy_loss: 1.3250, value_loss: 0.8373
2024-07-14 05:41:58,513 [INFO    ] __main__: train step 7151: loss: 1.0713, policy_loss: 1.3250, value_loss: 0.8372
2024-07-14 05:41:58,793 [INFO    ] __main__: train step 7152: loss: 1.0713, policy_loss: 1.3249, value_loss: 0.8372
2024-07-14 05:41:59,081 [INFO    ] __main__: train step 7153: loss: 1.0714, policy_loss: 1.3248, value_loss: 0.8372
2024-07-14 05:42:00,675 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:42:01,163 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:42:01,232 [INFO    ] __main__: train step 7154: loss: 1.0715, policy_loss: 1.3248, value_loss: 0.8372
2024-07-14 05:42:01,503 [INFO    ] __main__: train step 7155: loss: 1.0715, policy_loss: 1.3247, value_loss: 0.8371
2024-07-14 05:42:01,761 [INFO    ] __main__: train step 7156: loss: 1.0716, policy_loss: 1.3247, value_loss: 0.8371
2024-07-14 05:42:02,045 [INFO    ] __main__: train step 7157: loss: 1.0716, policy_loss: 1.3246, value_loss: 0.8371
2024-07-14 05:42:02,293 [INFO    ] __main__: train step 7158: loss: 1.0717, policy_loss: 1.3245, value_loss: 0.8371
2024-07-14 05:42:02,550 [INFO    ] __main__: train step 7159: loss: 1.0718, policy_loss: 1.3245, value_loss: 0.8370
2024-07-14 05:42:02,817 [INFO    ] __main__: train step 7160: loss: 1.0718, policy_loss: 1.3244, value_loss: 0.8370
2024-07-14 05:42:03,101 [INFO    ] __main__: train step 7161: loss: 1.0719, policy_loss: 1.3243, value_loss: 0.8370
2024-07-14 05:42:03,379 [INFO    ] __main__: train step 7162: loss: 1.0719, policy_loss: 1.3243, value_loss: 0.8370
2024-07-14 05:42:03,665 [INFO    ] __main__: train step 7163: loss: 1.0720, policy_loss: 1.3242, value_loss: 0.8369
2024-07-14 05:42:03,948 [INFO    ] __main__: train step 7164: loss: 1.0721, policy_loss: 1.3241, value_loss: 0.8369
2024-07-14 05:42:04,224 [INFO    ] __main__: train step 7165: loss: 1.0721, policy_loss: 1.3241, value_loss: 0.8369
2024-07-14 05:42:04,511 [INFO    ] __main__: train step 7166: loss: 1.0722, policy_loss: 1.3240, value_loss: 0.8368
2024-07-14 05:42:04,784 [INFO    ] __main__: train step 7167: loss: 1.0722, policy_loss: 1.3240, value_loss: 0.8368
2024-07-14 05:42:05,062 [INFO    ] __main__: train step 7168: loss: 1.0723, policy_loss: 1.3239, value_loss: 0.8368
2024-07-14 05:42:05,359 [INFO    ] __main__: train step 7169: loss: 1.0724, policy_loss: 1.3238, value_loss: 0.8368
2024-07-14 05:42:05,640 [INFO    ] __main__: train step 7170: loss: 1.0724, policy_loss: 1.3238, value_loss: 0.8367
2024-07-14 05:42:07,241 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:42:07,724 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:42:07,793 [INFO    ] __main__: train step 7171: loss: 1.0725, policy_loss: 1.3237, value_loss: 0.8367
2024-07-14 05:42:08,066 [INFO    ] __main__: train step 7172: loss: 1.0725, policy_loss: 1.3236, value_loss: 0.8367
2024-07-14 05:42:08,343 [INFO    ] __main__: train step 7173: loss: 1.0726, policy_loss: 1.3236, value_loss: 0.8367
2024-07-14 05:42:08,623 [INFO    ] __main__: train step 7174: loss: 1.0727, policy_loss: 1.3235, value_loss: 0.8366
2024-07-14 05:42:08,902 [INFO    ] __main__: train step 7175: loss: 1.0727, policy_loss: 1.3234, value_loss: 0.8366
2024-07-14 05:42:09,185 [INFO    ] __main__: train step 7176: loss: 1.0728, policy_loss: 1.3234, value_loss: 0.8366
2024-07-14 05:42:09,462 [INFO    ] __main__: train step 7177: loss: 1.0728, policy_loss: 1.3233, value_loss: 0.8366
2024-07-14 05:42:09,723 [INFO    ] __main__: train step 7178: loss: 1.0729, policy_loss: 1.3232, value_loss: 0.8365
2024-07-14 05:42:09,995 [INFO    ] __main__: train step 7179: loss: 1.0730, policy_loss: 1.3232, value_loss: 0.8365
2024-07-14 05:42:10,285 [INFO    ] __main__: train step 7180: loss: 1.0730, policy_loss: 1.3231, value_loss: 0.8365
2024-07-14 05:42:10,566 [INFO    ] __main__: train step 7181: loss: 1.0731, policy_loss: 1.3231, value_loss: 0.8365
2024-07-14 05:42:10,843 [INFO    ] __main__: train step 7182: loss: 1.0731, policy_loss: 1.3230, value_loss: 0.8364
2024-07-14 05:42:11,139 [INFO    ] __main__: train step 7183: loss: 1.0732, policy_loss: 1.3229, value_loss: 0.8364
2024-07-14 05:42:11,418 [INFO    ] __main__: train step 7184: loss: 1.0733, policy_loss: 1.3229, value_loss: 0.8364
2024-07-14 05:42:11,684 [INFO    ] __main__: train step 7185: loss: 1.0733, policy_loss: 1.3228, value_loss: 0.8364
2024-07-14 05:42:11,949 [INFO    ] __main__: train step 7186: loss: 1.0734, policy_loss: 1.3227, value_loss: 0.8363
2024-07-14 05:42:12,210 [INFO    ] __main__: train step 7187: loss: 1.0734, policy_loss: 1.3227, value_loss: 0.8363
2024-07-14 05:42:13,782 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:42:14,248 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:42:14,317 [INFO    ] __main__: train step 7188: loss: 1.0735, policy_loss: 1.3226, value_loss: 0.8363
2024-07-14 05:42:14,609 [INFO    ] __main__: train step 7189: loss: 1.0736, policy_loss: 1.3225, value_loss: 0.8363
2024-07-14 05:42:14,895 [INFO    ] __main__: train step 7190: loss: 1.0736, policy_loss: 1.3225, value_loss: 0.8362
2024-07-14 05:42:15,172 [INFO    ] __main__: train step 7191: loss: 1.0737, policy_loss: 1.3224, value_loss: 0.8362
2024-07-14 05:42:15,449 [INFO    ] __main__: train step 7192: loss: 1.0737, policy_loss: 1.3224, value_loss: 0.8362
2024-07-14 05:42:15,732 [INFO    ] __main__: train step 7193: loss: 1.0738, policy_loss: 1.3223, value_loss: 0.8362
2024-07-14 05:42:15,994 [INFO    ] __main__: train step 7194: loss: 1.0739, policy_loss: 1.3222, value_loss: 0.8361
2024-07-14 05:42:16,275 [INFO    ] __main__: train step 7195: loss: 1.0739, policy_loss: 1.3222, value_loss: 0.8361
2024-07-14 05:42:16,533 [INFO    ] __main__: train step 7196: loss: 1.0740, policy_loss: 1.3221, value_loss: 0.8361
2024-07-14 05:42:16,776 [INFO    ] __main__: train step 7197: loss: 1.0740, policy_loss: 1.3220, value_loss: 0.8361
2024-07-14 05:42:17,033 [INFO    ] __main__: train step 7198: loss: 1.0741, policy_loss: 1.3220, value_loss: 0.8360
2024-07-14 05:42:17,297 [INFO    ] __main__: train step 7199: loss: 1.0742, policy_loss: 1.3219, value_loss: 0.8360
2024-07-14 05:42:17,579 [INFO    ] __main__: train step 7200: loss: 1.0742, policy_loss: 1.3218, value_loss: 0.8360
2024-07-14 05:42:17,847 [INFO    ] __main__: train step 7201: loss: 1.0743, policy_loss: 1.3218, value_loss: 0.8360
2024-07-14 05:42:19,466 [INFO    ] __main__: train step 7202: loss: 1.0743, policy_loss: 1.3217, value_loss: 0.8359
2024-07-14 05:42:19,728 [INFO    ] __main__: train step 7203: loss: 1.0744, policy_loss: 1.3216, value_loss: 0.8359
2024-07-14 05:42:19,982 [INFO    ] __main__: train step 7204: loss: 1.0745, policy_loss: 1.3216, value_loss: 0.8359
2024-07-14 05:42:21,526 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:42:21,981 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:42:22,049 [INFO    ] __main__: train step 7205: loss: 1.0745, policy_loss: 1.3215, value_loss: 0.8359
2024-07-14 05:42:22,304 [INFO    ] __main__: train step 7206: loss: 1.0746, policy_loss: 1.3215, value_loss: 0.8358
2024-07-14 05:42:22,553 [INFO    ] __main__: train step 7207: loss: 1.0746, policy_loss: 1.3214, value_loss: 0.8358
2024-07-14 05:42:22,816 [INFO    ] __main__: train step 7208: loss: 1.0747, policy_loss: 1.3213, value_loss: 0.8358
2024-07-14 05:42:23,080 [INFO    ] __main__: train step 7209: loss: 1.0748, policy_loss: 1.3213, value_loss: 0.8358
2024-07-14 05:42:23,377 [INFO    ] __main__: train step 7210: loss: 1.0748, policy_loss: 1.3212, value_loss: 0.8357
2024-07-14 05:42:23,646 [INFO    ] __main__: train step 7211: loss: 1.0749, policy_loss: 1.3211, value_loss: 0.8357
2024-07-14 05:42:23,935 [INFO    ] __main__: train step 7212: loss: 1.0749, policy_loss: 1.3211, value_loss: 0.8357
2024-07-14 05:42:24,216 [INFO    ] __main__: train step 7213: loss: 1.0750, policy_loss: 1.3210, value_loss: 0.8357
2024-07-14 05:42:24,491 [INFO    ] __main__: train step 7214: loss: 1.0750, policy_loss: 1.3209, value_loss: 0.8356
2024-07-14 05:42:24,769 [INFO    ] __main__: train step 7215: loss: 1.0751, policy_loss: 1.3209, value_loss: 0.8356
2024-07-14 05:42:25,048 [INFO    ] __main__: train step 7216: loss: 1.0752, policy_loss: 1.3208, value_loss: 0.8356
2024-07-14 05:42:25,328 [INFO    ] __main__: train step 7217: loss: 1.0752, policy_loss: 1.3208, value_loss: 0.8356
2024-07-14 05:42:25,617 [INFO    ] __main__: train step 7218: loss: 1.0753, policy_loss: 1.3207, value_loss: 0.8355
2024-07-14 05:42:25,887 [INFO    ] __main__: train step 7219: loss: 1.0753, policy_loss: 1.3206, value_loss: 0.8355
2024-07-14 05:42:26,168 [INFO    ] __main__: train step 7220: loss: 1.0754, policy_loss: 1.3206, value_loss: 0.8355
2024-07-14 05:42:26,443 [INFO    ] __main__: train step 7221: loss: 1.0755, policy_loss: 1.3205, value_loss: 0.8355
2024-07-14 05:42:28,051 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:42:28,527 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:42:28,598 [INFO    ] __main__: train step 7222: loss: 1.0755, policy_loss: 1.3204, value_loss: 0.8354
2024-07-14 05:42:28,879 [INFO    ] __main__: train step 7223: loss: 1.0756, policy_loss: 1.3204, value_loss: 0.8354
2024-07-14 05:42:29,159 [INFO    ] __main__: train step 7224: loss: 1.0756, policy_loss: 1.3203, value_loss: 0.8354
2024-07-14 05:42:29,425 [INFO    ] __main__: train step 7225: loss: 1.0757, policy_loss: 1.3202, value_loss: 0.8354
2024-07-14 05:42:29,698 [INFO    ] __main__: train step 7226: loss: 1.0758, policy_loss: 1.3202, value_loss: 0.8353
2024-07-14 05:42:29,983 [INFO    ] __main__: train step 7227: loss: 1.0758, policy_loss: 1.3201, value_loss: 0.8353
2024-07-14 05:42:30,289 [INFO    ] __main__: train step 7228: loss: 1.0759, policy_loss: 1.3201, value_loss: 0.8353
2024-07-14 05:42:30,577 [INFO    ] __main__: train step 7229: loss: 1.0759, policy_loss: 1.3200, value_loss: 0.8353
2024-07-14 05:42:30,852 [INFO    ] __main__: train step 7230: loss: 1.0760, policy_loss: 1.3199, value_loss: 0.8352
2024-07-14 05:42:31,126 [INFO    ] __main__: train step 7231: loss: 1.0760, policy_loss: 1.3199, value_loss: 0.8352
2024-07-14 05:42:31,401 [INFO    ] __main__: train step 7232: loss: 1.0761, policy_loss: 1.3198, value_loss: 0.8352
2024-07-14 05:42:31,681 [INFO    ] __main__: train step 7233: loss: 1.0762, policy_loss: 1.3197, value_loss: 0.8352
2024-07-14 05:42:31,948 [INFO    ] __main__: train step 7234: loss: 1.0762, policy_loss: 1.3197, value_loss: 0.8351
2024-07-14 05:42:32,219 [INFO    ] __main__: train step 7235: loss: 1.0763, policy_loss: 1.3196, value_loss: 0.8351
2024-07-14 05:42:32,486 [INFO    ] __main__: train step 7236: loss: 1.0763, policy_loss: 1.3195, value_loss: 0.8351
2024-07-14 05:42:32,763 [INFO    ] __main__: train step 7237: loss: 1.0764, policy_loss: 1.3195, value_loss: 0.8351
2024-07-14 05:42:33,032 [INFO    ] __main__: train step 7238: loss: 1.0765, policy_loss: 1.3194, value_loss: 0.8350
2024-07-14 05:42:34,643 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:42:35,114 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:42:35,185 [INFO    ] __main__: train step 7239: loss: 1.0765, policy_loss: 1.3193, value_loss: 0.8350
2024-07-14 05:42:35,458 [INFO    ] __main__: train step 7240: loss: 1.0766, policy_loss: 1.3193, value_loss: 0.8350
2024-07-14 05:42:35,743 [INFO    ] __main__: train step 7241: loss: 1.0766, policy_loss: 1.3192, value_loss: 0.8350
2024-07-14 05:42:36,019 [INFO    ] __main__: train step 7242: loss: 1.0767, policy_loss: 1.3192, value_loss: 0.8349
2024-07-14 05:42:36,291 [INFO    ] __main__: train step 7243: loss: 1.0767, policy_loss: 1.3191, value_loss: 0.8349
2024-07-14 05:42:36,573 [INFO    ] __main__: train step 7244: loss: 1.0768, policy_loss: 1.3190, value_loss: 0.8349
2024-07-14 05:42:36,839 [INFO    ] __main__: train step 7245: loss: 1.0769, policy_loss: 1.3190, value_loss: 0.8349
2024-07-14 05:42:37,095 [INFO    ] __main__: train step 7246: loss: 1.0769, policy_loss: 1.3189, value_loss: 0.8348
2024-07-14 05:42:37,362 [INFO    ] __main__: train step 7247: loss: 1.0770, policy_loss: 1.3188, value_loss: 0.8348
2024-07-14 05:42:37,647 [INFO    ] __main__: train step 7248: loss: 1.0770, policy_loss: 1.3188, value_loss: 0.8348
2024-07-14 05:42:37,912 [INFO    ] __main__: train step 7249: loss: 1.0771, policy_loss: 1.3187, value_loss: 0.8348
2024-07-14 05:42:38,166 [INFO    ] __main__: train step 7250: loss: 1.0771, policy_loss: 1.3186, value_loss: 0.8347
2024-07-14 05:42:38,433 [INFO    ] __main__: train step 7251: loss: 1.0772, policy_loss: 1.3186, value_loss: 0.8347
2024-07-14 05:42:38,701 [INFO    ] __main__: train step 7252: loss: 1.0773, policy_loss: 1.3185, value_loss: 0.8347
2024-07-14 05:42:38,974 [INFO    ] __main__: train step 7253: loss: 1.0773, policy_loss: 1.3184, value_loss: 0.8347
2024-07-14 05:42:39,249 [INFO    ] __main__: train step 7254: loss: 1.0774, policy_loss: 1.3184, value_loss: 0.8346
2024-07-14 05:42:39,523 [INFO    ] __main__: train step 7255: loss: 1.0774, policy_loss: 1.3183, value_loss: 0.8346
2024-07-14 05:42:41,106 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:42:41,570 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:42:41,638 [INFO    ] __main__: train step 7256: loss: 1.0775, policy_loss: 1.3182, value_loss: 0.8346
2024-07-14 05:42:43,416 [INFO    ] __main__: train step 7257: loss: 1.0775, policy_loss: 1.3182, value_loss: 0.8346
2024-07-14 05:42:43,697 [INFO    ] __main__: train step 7258: loss: 1.0776, policy_loss: 1.3181, value_loss: 0.8346
2024-07-14 05:42:43,972 [INFO    ] __main__: train step 7259: loss: 1.0777, policy_loss: 1.3181, value_loss: 0.8345
2024-07-14 05:42:44,254 [INFO    ] __main__: train step 7260: loss: 1.0777, policy_loss: 1.3180, value_loss: 0.8345
2024-07-14 05:42:44,533 [INFO    ] __main__: train step 7261: loss: 1.0778, policy_loss: 1.3179, value_loss: 0.8345
2024-07-14 05:42:44,809 [INFO    ] __main__: train step 7262: loss: 1.0778, policy_loss: 1.3179, value_loss: 0.8345
2024-07-14 05:42:45,086 [INFO    ] __main__: train step 7263: loss: 1.0779, policy_loss: 1.3178, value_loss: 0.8344
2024-07-14 05:42:45,365 [INFO    ] __main__: train step 7264: loss: 1.0779, policy_loss: 1.3177, value_loss: 0.8344
2024-07-14 05:42:45,650 [INFO    ] __main__: train step 7265: loss: 1.0780, policy_loss: 1.3177, value_loss: 0.8344
2024-07-14 05:42:45,925 [INFO    ] __main__: train step 7266: loss: 1.0781, policy_loss: 1.3176, value_loss: 0.8344
2024-07-14 05:42:46,201 [INFO    ] __main__: train step 7267: loss: 1.0781, policy_loss: 1.3175, value_loss: 0.8343
2024-07-14 05:42:46,479 [INFO    ] __main__: train step 7268: loss: 1.0782, policy_loss: 1.3175, value_loss: 0.8343
2024-07-14 05:42:46,750 [INFO    ] __main__: train step 7269: loss: 1.0782, policy_loss: 1.3174, value_loss: 0.8343
2024-07-14 05:42:47,017 [INFO    ] __main__: train step 7270: loss: 1.0783, policy_loss: 1.3173, value_loss: 0.8343
2024-07-14 05:42:47,266 [INFO    ] __main__: train step 7271: loss: 1.0783, policy_loss: 1.3173, value_loss: 0.8342
2024-07-14 05:42:47,543 [INFO    ] __main__: train step 7272: loss: 1.0784, policy_loss: 1.3172, value_loss: 0.8342
2024-07-14 05:42:49,141 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:42:49,603 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:42:49,673 [INFO    ] __main__: train step 7273: loss: 1.0785, policy_loss: 1.3171, value_loss: 0.8342
2024-07-14 05:42:49,947 [INFO    ] __main__: train step 7274: loss: 1.0785, policy_loss: 1.3171, value_loss: 0.8342
2024-07-14 05:42:50,222 [INFO    ] __main__: train step 7275: loss: 1.0786, policy_loss: 1.3170, value_loss: 0.8341
2024-07-14 05:42:50,500 [INFO    ] __main__: train step 7276: loss: 1.0786, policy_loss: 1.3169, value_loss: 0.8341
2024-07-14 05:42:50,771 [INFO    ] __main__: train step 7277: loss: 1.0787, policy_loss: 1.3169, value_loss: 0.8341
2024-07-14 05:42:51,059 [INFO    ] __main__: train step 7278: loss: 1.0788, policy_loss: 1.3168, value_loss: 0.8341
2024-07-14 05:42:51,331 [INFO    ] __main__: train step 7279: loss: 1.0788, policy_loss: 1.3168, value_loss: 0.8341
2024-07-14 05:42:51,607 [INFO    ] __main__: train step 7280: loss: 1.0789, policy_loss: 1.3167, value_loss: 0.8340
2024-07-14 05:42:51,883 [INFO    ] __main__: train step 7281: loss: 1.0789, policy_loss: 1.3166, value_loss: 0.8340
2024-07-14 05:42:52,197 [INFO    ] __main__: train step 7282: loss: 1.0790, policy_loss: 1.3166, value_loss: 0.8340
2024-07-14 05:42:52,480 [INFO    ] __main__: train step 7283: loss: 1.0790, policy_loss: 1.3165, value_loss: 0.8340
2024-07-14 05:42:52,788 [INFO    ] __main__: train step 7284: loss: 1.0791, policy_loss: 1.3164, value_loss: 0.8339
2024-07-14 05:42:53,065 [INFO    ] __main__: train step 7285: loss: 1.0791, policy_loss: 1.3164, value_loss: 0.8339
2024-07-14 05:42:53,352 [INFO    ] __main__: train step 7286: loss: 1.0792, policy_loss: 1.3163, value_loss: 0.8339
2024-07-14 05:42:53,626 [INFO    ] __main__: train step 7287: loss: 1.0793, policy_loss: 1.3162, value_loss: 0.8339
2024-07-14 05:42:53,900 [INFO    ] __main__: train step 7288: loss: 1.0793, policy_loss: 1.3162, value_loss: 0.8338
2024-07-14 05:42:54,189 [INFO    ] __main__: train step 7289: loss: 1.0794, policy_loss: 1.3161, value_loss: 0.8338
2024-07-14 05:42:55,825 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:42:56,299 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:42:56,367 [INFO    ] __main__: train step 7290: loss: 1.0794, policy_loss: 1.3160, value_loss: 0.8338
2024-07-14 05:42:56,649 [INFO    ] __main__: train step 7291: loss: 1.0795, policy_loss: 1.3160, value_loss: 0.8338
2024-07-14 05:42:56,927 [INFO    ] __main__: train step 7292: loss: 1.0795, policy_loss: 1.3159, value_loss: 0.8337
2024-07-14 05:42:57,191 [INFO    ] __main__: train step 7293: loss: 1.0796, policy_loss: 1.3159, value_loss: 0.8337
2024-07-14 05:42:57,464 [INFO    ] __main__: train step 7294: loss: 1.0796, policy_loss: 1.3158, value_loss: 0.8337
2024-07-14 05:42:57,742 [INFO    ] __main__: train step 7295: loss: 1.0797, policy_loss: 1.3157, value_loss: 0.8337
2024-07-14 05:42:58,013 [INFO    ] __main__: train step 7296: loss: 1.0798, policy_loss: 1.3157, value_loss: 0.8336
2024-07-14 05:42:58,286 [INFO    ] __main__: train step 7297: loss: 1.0798, policy_loss: 1.3156, value_loss: 0.8336
2024-07-14 05:42:58,555 [INFO    ] __main__: train step 7298: loss: 1.0799, policy_loss: 1.3155, value_loss: 0.8336
2024-07-14 05:42:58,824 [INFO    ] __main__: train step 7299: loss: 1.0799, policy_loss: 1.3155, value_loss: 0.8336
2024-07-14 05:42:59,097 [INFO    ] __main__: train step 7300: loss: 1.0800, policy_loss: 1.3154, value_loss: 0.8335
2024-07-14 05:42:59,382 [INFO    ] __main__: train step 7301: loss: 1.0800, policy_loss: 1.3153, value_loss: 0.8335
2024-07-14 05:42:59,665 [INFO    ] __main__: train step 7302: loss: 1.0801, policy_loss: 1.3153, value_loss: 0.8335
2024-07-14 05:42:59,958 [INFO    ] __main__: train step 7303: loss: 1.0802, policy_loss: 1.3152, value_loss: 0.8335
2024-07-14 05:43:00,236 [INFO    ] __main__: train step 7304: loss: 1.0802, policy_loss: 1.3151, value_loss: 0.8334
2024-07-14 05:43:00,507 [INFO    ] __main__: train step 7305: loss: 1.0803, policy_loss: 1.3151, value_loss: 0.8334
2024-07-14 05:43:00,777 [INFO    ] __main__: train step 7306: loss: 1.0803, policy_loss: 1.3150, value_loss: 0.8334
2024-07-14 05:43:02,366 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:43:02,831 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:43:02,898 [INFO    ] __main__: train step 7307: loss: 1.0804, policy_loss: 1.3150, value_loss: 0.8334
2024-07-14 05:43:03,180 [INFO    ] __main__: train step 7308: loss: 1.0804, policy_loss: 1.3149, value_loss: 0.8333
2024-07-14 05:43:03,444 [INFO    ] __main__: train step 7309: loss: 1.0805, policy_loss: 1.3148, value_loss: 0.8333
2024-07-14 05:43:03,725 [INFO    ] __main__: train step 7310: loss: 1.0806, policy_loss: 1.3148, value_loss: 0.8333
2024-07-14 05:43:05,497 [INFO    ] __main__: train step 7311: loss: 1.0806, policy_loss: 1.3147, value_loss: 0.8333
2024-07-14 05:43:05,776 [INFO    ] __main__: train step 7312: loss: 1.0807, policy_loss: 1.3146, value_loss: 0.8332
2024-07-14 05:43:06,048 [INFO    ] __main__: train step 7313: loss: 1.0807, policy_loss: 1.3146, value_loss: 0.8332
2024-07-14 05:43:06,335 [INFO    ] __main__: train step 7314: loss: 1.0808, policy_loss: 1.3145, value_loss: 0.8332
2024-07-14 05:43:06,618 [INFO    ] __main__: train step 7315: loss: 1.0808, policy_loss: 1.3144, value_loss: 0.8332
2024-07-14 05:43:06,903 [INFO    ] __main__: train step 7316: loss: 1.0809, policy_loss: 1.3144, value_loss: 0.8331
2024-07-14 05:43:07,181 [INFO    ] __main__: train step 7317: loss: 1.0809, policy_loss: 1.3143, value_loss: 0.8331
2024-07-14 05:43:07,467 [INFO    ] __main__: train step 7318: loss: 1.0810, policy_loss: 1.3142, value_loss: 0.8331
2024-07-14 05:43:07,746 [INFO    ] __main__: train step 7319: loss: 1.0811, policy_loss: 1.3142, value_loss: 0.8331
2024-07-14 05:43:08,031 [INFO    ] __main__: train step 7320: loss: 1.0811, policy_loss: 1.3141, value_loss: 0.8331
2024-07-14 05:43:08,319 [INFO    ] __main__: train step 7321: loss: 1.0812, policy_loss: 1.3141, value_loss: 0.8330
2024-07-14 05:43:08,613 [INFO    ] __main__: train step 7322: loss: 1.0812, policy_loss: 1.3140, value_loss: 0.8330
2024-07-14 05:43:08,870 [INFO    ] __main__: train step 7323: loss: 1.0813, policy_loss: 1.3139, value_loss: 0.8330
2024-07-14 05:43:10,468 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:43:10,945 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:43:11,008 [INFO    ] __main__: train step 7324: loss: 1.0813, policy_loss: 1.3139, value_loss: 0.8330
2024-07-14 05:43:11,295 [INFO    ] __main__: train step 7325: loss: 1.0814, policy_loss: 1.3138, value_loss: 0.8329
2024-07-14 05:43:11,565 [INFO    ] __main__: train step 7326: loss: 1.0814, policy_loss: 1.3137, value_loss: 0.8329
2024-07-14 05:43:11,846 [INFO    ] __main__: train step 7327: loss: 1.0815, policy_loss: 1.3137, value_loss: 0.8329
2024-07-14 05:43:12,126 [INFO    ] __main__: train step 7328: loss: 1.0815, policy_loss: 1.3136, value_loss: 0.8329
2024-07-14 05:43:12,401 [INFO    ] __main__: train step 7329: loss: 1.0816, policy_loss: 1.3135, value_loss: 0.8328
2024-07-14 05:43:12,675 [INFO    ] __main__: train step 7330: loss: 1.0817, policy_loss: 1.3135, value_loss: 0.8328
2024-07-14 05:43:12,957 [INFO    ] __main__: train step 7331: loss: 1.0817, policy_loss: 1.3134, value_loss: 0.8328
2024-07-14 05:43:13,236 [INFO    ] __main__: train step 7332: loss: 1.0818, policy_loss: 1.3133, value_loss: 0.8328
2024-07-14 05:43:13,497 [INFO    ] __main__: train step 7333: loss: 1.0818, policy_loss: 1.3133, value_loss: 0.8327
2024-07-14 05:43:13,758 [INFO    ] __main__: train step 7334: loss: 1.0819, policy_loss: 1.3132, value_loss: 0.8327
2024-07-14 05:43:14,033 [INFO    ] __main__: train step 7335: loss: 1.0819, policy_loss: 1.3131, value_loss: 0.8327
2024-07-14 05:43:14,315 [INFO    ] __main__: train step 7336: loss: 1.0820, policy_loss: 1.3131, value_loss: 0.8327
2024-07-14 05:43:14,589 [INFO    ] __main__: train step 7337: loss: 1.0820, policy_loss: 1.3130, value_loss: 0.8326
2024-07-14 05:43:14,875 [INFO    ] __main__: train step 7338: loss: 1.0821, policy_loss: 1.3130, value_loss: 0.8326
2024-07-14 05:43:15,163 [INFO    ] __main__: train step 7339: loss: 1.0822, policy_loss: 1.3129, value_loss: 0.8326
2024-07-14 05:43:15,457 [INFO    ] __main__: train step 7340: loss: 1.0822, policy_loss: 1.3128, value_loss: 0.8326
2024-07-14 05:43:17,061 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:43:17,552 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:43:17,627 [INFO    ] __main__: train step 7341: loss: 1.0823, policy_loss: 1.3128, value_loss: 0.8325
2024-07-14 05:43:17,897 [INFO    ] __main__: train step 7342: loss: 1.0823, policy_loss: 1.3127, value_loss: 0.8325
2024-07-14 05:43:18,188 [INFO    ] __main__: train step 7343: loss: 1.0824, policy_loss: 1.3126, value_loss: 0.8325
2024-07-14 05:43:18,477 [INFO    ] __main__: train step 7344: loss: 1.0824, policy_loss: 1.3126, value_loss: 0.8325
2024-07-14 05:43:18,748 [INFO    ] __main__: train step 7345: loss: 1.0825, policy_loss: 1.3125, value_loss: 0.8325
2024-07-14 05:43:19,020 [INFO    ] __main__: train step 7346: loss: 1.0825, policy_loss: 1.3124, value_loss: 0.8324
2024-07-14 05:43:19,293 [INFO    ] __main__: train step 7347: loss: 1.0826, policy_loss: 1.3124, value_loss: 0.8324
2024-07-14 05:43:19,569 [INFO    ] __main__: train step 7348: loss: 1.0826, policy_loss: 1.3123, value_loss: 0.8324
2024-07-14 05:43:19,845 [INFO    ] __main__: train step 7349: loss: 1.0827, policy_loss: 1.3123, value_loss: 0.8324
2024-07-14 05:43:20,132 [INFO    ] __main__: train step 7350: loss: 1.0827, policy_loss: 1.3122, value_loss: 0.8323
2024-07-14 05:43:20,402 [INFO    ] __main__: train step 7351: loss: 1.0828, policy_loss: 1.3121, value_loss: 0.8323
2024-07-14 05:43:20,659 [INFO    ] __main__: train step 7352: loss: 1.0829, policy_loss: 1.3121, value_loss: 0.8323
2024-07-14 05:43:20,929 [INFO    ] __main__: train step 7353: loss: 1.0829, policy_loss: 1.3120, value_loss: 0.8323
2024-07-14 05:43:21,191 [INFO    ] __main__: train step 7354: loss: 1.0830, policy_loss: 1.3119, value_loss: 0.8322
2024-07-14 05:43:21,454 [INFO    ] __main__: train step 7355: loss: 1.0830, policy_loss: 1.3119, value_loss: 0.8322
2024-07-14 05:43:21,721 [INFO    ] __main__: train step 7356: loss: 1.0831, policy_loss: 1.3118, value_loss: 0.8322
2024-07-14 05:43:22,006 [INFO    ] __main__: train step 7357: loss: 1.0831, policy_loss: 1.3117, value_loss: 0.8322
2024-07-14 05:43:23,621 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:43:24,113 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:43:24,187 [INFO    ] __main__: train step 7358: loss: 1.0832, policy_loss: 1.3117, value_loss: 0.8321
2024-07-14 05:43:24,455 [INFO    ] __main__: train step 7359: loss: 1.0832, policy_loss: 1.3116, value_loss: 0.8321
2024-07-14 05:43:24,716 [INFO    ] __main__: train step 7360: loss: 1.0833, policy_loss: 1.3115, value_loss: 0.8321
2024-07-14 05:43:24,976 [INFO    ] __main__: train step 7361: loss: 1.0833, policy_loss: 1.3115, value_loss: 0.8321
2024-07-14 05:43:25,249 [INFO    ] __main__: train step 7362: loss: 1.0834, policy_loss: 1.3114, value_loss: 0.8320
2024-07-14 05:43:25,549 [INFO    ] __main__: train step 7363: loss: 1.0835, policy_loss: 1.3113, value_loss: 0.8320
2024-07-14 05:43:25,861 [INFO    ] __main__: train step 7364: loss: 1.0835, policy_loss: 1.3113, value_loss: 0.8320
2024-07-14 05:43:26,160 [INFO    ] __main__: train step 7365: loss: 1.0836, policy_loss: 1.3112, value_loss: 0.8320
2024-07-14 05:43:28,945 [INFO    ] __main__: train step 7366: loss: 1.0836, policy_loss: 1.3111, value_loss: 0.8320
2024-07-14 05:43:29,246 [INFO    ] __main__: train step 7367: loss: 1.0837, policy_loss: 1.3111, value_loss: 0.8319
2024-07-14 05:43:29,565 [INFO    ] __main__: train step 7368: loss: 1.0837, policy_loss: 1.3110, value_loss: 0.8319
2024-07-14 05:43:29,881 [INFO    ] __main__: train step 7369: loss: 1.0838, policy_loss: 1.3110, value_loss: 0.8319
2024-07-14 05:43:30,181 [INFO    ] __main__: train step 7370: loss: 1.0839, policy_loss: 1.3109, value_loss: 0.8319
2024-07-14 05:43:30,484 [INFO    ] __main__: train step 7371: loss: 1.0839, policy_loss: 1.3108, value_loss: 0.8318
2024-07-14 05:43:30,793 [INFO    ] __main__: train step 7372: loss: 1.0840, policy_loss: 1.3108, value_loss: 0.8318
2024-07-14 05:43:31,094 [INFO    ] __main__: train step 7373: loss: 1.0840, policy_loss: 1.3107, value_loss: 0.8318
2024-07-14 05:43:31,404 [INFO    ] __main__: train step 7374: loss: 1.0841, policy_loss: 1.3106, value_loss: 0.8318
2024-07-14 05:43:33,018 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:43:33,498 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:43:33,570 [INFO    ] __main__: train step 7375: loss: 1.0841, policy_loss: 1.3106, value_loss: 0.8317
2024-07-14 05:43:33,881 [INFO    ] __main__: train step 7376: loss: 1.0842, policy_loss: 1.3105, value_loss: 0.8317
2024-07-14 05:43:34,186 [INFO    ] __main__: train step 7377: loss: 1.0842, policy_loss: 1.3104, value_loss: 0.8317
2024-07-14 05:43:34,476 [INFO    ] __main__: train step 7378: loss: 1.0843, policy_loss: 1.3104, value_loss: 0.8317
2024-07-14 05:43:34,767 [INFO    ] __main__: train step 7379: loss: 1.0843, policy_loss: 1.3103, value_loss: 0.8316
2024-07-14 05:43:35,066 [INFO    ] __main__: train step 7380: loss: 1.0844, policy_loss: 1.3103, value_loss: 0.8316
2024-07-14 05:43:35,364 [INFO    ] __main__: train step 7381: loss: 1.0844, policy_loss: 1.3102, value_loss: 0.8316
2024-07-14 05:43:35,665 [INFO    ] __main__: train step 7382: loss: 1.0845, policy_loss: 1.3101, value_loss: 0.8316
2024-07-14 05:43:35,954 [INFO    ] __main__: train step 7383: loss: 1.0845, policy_loss: 1.3101, value_loss: 0.8315
2024-07-14 05:43:36,236 [INFO    ] __main__: train step 7384: loss: 1.0846, policy_loss: 1.3100, value_loss: 0.8315
2024-07-14 05:43:36,519 [INFO    ] __main__: train step 7385: loss: 1.0846, policy_loss: 1.3099, value_loss: 0.8315
2024-07-14 05:43:36,803 [INFO    ] __main__: train step 7386: loss: 1.0847, policy_loss: 1.3099, value_loss: 0.8315
2024-07-14 05:43:37,098 [INFO    ] __main__: train step 7387: loss: 1.0848, policy_loss: 1.3098, value_loss: 0.8315
2024-07-14 05:43:37,374 [INFO    ] __main__: train step 7388: loss: 1.0848, policy_loss: 1.3097, value_loss: 0.8314
2024-07-14 05:43:37,651 [INFO    ] __main__: train step 7389: loss: 1.0849, policy_loss: 1.3097, value_loss: 0.8314
2024-07-14 05:43:37,918 [INFO    ] __main__: train step 7390: loss: 1.0849, policy_loss: 1.3096, value_loss: 0.8314
2024-07-14 05:43:38,196 [INFO    ] __main__: train step 7391: loss: 1.0850, policy_loss: 1.3095, value_loss: 0.8314
2024-07-14 05:43:39,798 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:43:40,285 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:43:40,350 [INFO    ] __main__: train step 7392: loss: 1.0850, policy_loss: 1.3095, value_loss: 0.8313
2024-07-14 05:43:40,629 [INFO    ] __main__: train step 7393: loss: 1.0851, policy_loss: 1.3094, value_loss: 0.8313
2024-07-14 05:43:40,912 [INFO    ] __main__: train step 7394: loss: 1.0851, policy_loss: 1.3094, value_loss: 0.8313
2024-07-14 05:43:41,163 [INFO    ] __main__: train step 7395: loss: 1.0852, policy_loss: 1.3093, value_loss: 0.8313
2024-07-14 05:43:41,441 [INFO    ] __main__: train step 7396: loss: 1.0852, policy_loss: 1.3092, value_loss: 0.8312
2024-07-14 05:43:41,740 [INFO    ] __main__: train step 7397: loss: 1.0853, policy_loss: 1.3092, value_loss: 0.8312
2024-07-14 05:43:42,025 [INFO    ] __main__: train step 7398: loss: 1.0854, policy_loss: 1.3091, value_loss: 0.8312
2024-07-14 05:43:42,319 [INFO    ] __main__: train step 7399: loss: 1.0854, policy_loss: 1.3090, value_loss: 0.8312
2024-07-14 05:43:42,597 [INFO    ] __main__: train step 7400: loss: 1.0855, policy_loss: 1.3090, value_loss: 0.8311
2024-07-14 05:43:42,873 [INFO    ] __main__: train step 7401: loss: 1.0855, policy_loss: 1.3089, value_loss: 0.8311
2024-07-14 05:43:43,164 [INFO    ] __main__: train step 7402: loss: 1.0856, policy_loss: 1.3088, value_loss: 0.8311
2024-07-14 05:43:43,445 [INFO    ] __main__: train step 7403: loss: 1.0856, policy_loss: 1.3088, value_loss: 0.8311
2024-07-14 05:43:43,731 [INFO    ] __main__: train step 7404: loss: 1.0857, policy_loss: 1.3087, value_loss: 0.8311
2024-07-14 05:43:44,007 [INFO    ] __main__: train step 7405: loss: 1.0857, policy_loss: 1.3086, value_loss: 0.8310
2024-07-14 05:43:44,288 [INFO    ] __main__: train step 7406: loss: 1.0858, policy_loss: 1.3086, value_loss: 0.8310
2024-07-14 05:43:44,576 [INFO    ] __main__: train step 7407: loss: 1.0858, policy_loss: 1.3085, value_loss: 0.8310
2024-07-14 05:43:44,862 [INFO    ] __main__: train step 7408: loss: 1.0859, policy_loss: 1.3084, value_loss: 0.8310
2024-07-14 05:43:46,463 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:43:46,951 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:43:47,030 [INFO    ] __main__: train step 7409: loss: 1.0859, policy_loss: 1.3084, value_loss: 0.8309
2024-07-14 05:43:47,320 [INFO    ] __main__: train step 7410: loss: 1.0860, policy_loss: 1.3083, value_loss: 0.8309
2024-07-14 05:43:47,596 [INFO    ] __main__: train step 7411: loss: 1.0860, policy_loss: 1.3083, value_loss: 0.8309
2024-07-14 05:43:47,882 [INFO    ] __main__: train step 7412: loss: 1.0861, policy_loss: 1.3082, value_loss: 0.8309
2024-07-14 05:43:48,160 [INFO    ] __main__: train step 7413: loss: 1.0862, policy_loss: 1.3081, value_loss: 0.8308
2024-07-14 05:43:48,439 [INFO    ] __main__: train step 7414: loss: 1.0862, policy_loss: 1.3081, value_loss: 0.8308
2024-07-14 05:43:48,714 [INFO    ] __main__: train step 7415: loss: 1.0863, policy_loss: 1.3080, value_loss: 0.8308
2024-07-14 05:43:48,983 [INFO    ] __main__: train step 7416: loss: 1.0863, policy_loss: 1.3079, value_loss: 0.8308
2024-07-14 05:43:49,265 [INFO    ] __main__: train step 7417: loss: 1.0864, policy_loss: 1.3079, value_loss: 0.8308
2024-07-14 05:43:49,531 [INFO    ] __main__: train step 7418: loss: 1.0864, policy_loss: 1.3078, value_loss: 0.8307
2024-07-14 05:43:49,804 [INFO    ] __main__: train step 7419: loss: 1.0865, policy_loss: 1.3077, value_loss: 0.8307
2024-07-14 05:43:50,087 [INFO    ] __main__: train step 7420: loss: 1.0865, policy_loss: 1.3077, value_loss: 0.8307
2024-07-14 05:43:51,872 [INFO    ] __main__: train step 7421: loss: 1.0866, policy_loss: 1.3076, value_loss: 0.8307
2024-07-14 05:43:52,140 [INFO    ] __main__: train step 7422: loss: 1.0866, policy_loss: 1.3075, value_loss: 0.8306
2024-07-14 05:43:52,423 [INFO    ] __main__: train step 7423: loss: 1.0867, policy_loss: 1.3075, value_loss: 0.8306
2024-07-14 05:43:52,696 [INFO    ] __main__: train step 7424: loss: 1.0867, policy_loss: 1.3074, value_loss: 0.8306
2024-07-14 05:43:52,991 [INFO    ] __main__: train step 7425: loss: 1.0868, policy_loss: 1.3074, value_loss: 0.8306
2024-07-14 05:43:54,589 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:43:55,072 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:43:55,145 [INFO    ] __main__: train step 7426: loss: 1.0868, policy_loss: 1.3073, value_loss: 0.8305
2024-07-14 05:43:55,423 [INFO    ] __main__: train step 7427: loss: 1.0869, policy_loss: 1.3072, value_loss: 0.8305
2024-07-14 05:43:55,698 [INFO    ] __main__: train step 7428: loss: 1.0869, policy_loss: 1.3072, value_loss: 0.8305
2024-07-14 05:43:55,985 [INFO    ] __main__: train step 7429: loss: 1.0870, policy_loss: 1.3071, value_loss: 0.8305
2024-07-14 05:43:56,269 [INFO    ] __main__: train step 7430: loss: 1.0870, policy_loss: 1.3070, value_loss: 0.8304
2024-07-14 05:43:56,545 [INFO    ] __main__: train step 7431: loss: 1.0871, policy_loss: 1.3070, value_loss: 0.8304
2024-07-14 05:43:56,824 [INFO    ] __main__: train step 7432: loss: 1.0871, policy_loss: 1.3069, value_loss: 0.8304
2024-07-14 05:43:57,109 [INFO    ] __main__: train step 7433: loss: 1.0872, policy_loss: 1.3068, value_loss: 0.8304
2024-07-14 05:43:57,389 [INFO    ] __main__: train step 7434: loss: 1.0872, policy_loss: 1.3068, value_loss: 0.8303
2024-07-14 05:43:57,681 [INFO    ] __main__: train step 7435: loss: 1.0873, policy_loss: 1.3067, value_loss: 0.8303
2024-07-14 05:43:57,969 [INFO    ] __main__: train step 7436: loss: 1.0874, policy_loss: 1.3067, value_loss: 0.8303
2024-07-14 05:43:58,259 [INFO    ] __main__: train step 7437: loss: 1.0874, policy_loss: 1.3066, value_loss: 0.8303
2024-07-14 05:43:58,566 [INFO    ] __main__: train step 7438: loss: 1.0875, policy_loss: 1.3065, value_loss: 0.8303
2024-07-14 05:43:58,852 [INFO    ] __main__: train step 7439: loss: 1.0875, policy_loss: 1.3065, value_loss: 0.8302
2024-07-14 05:43:59,156 [INFO    ] __main__: train step 7440: loss: 1.0876, policy_loss: 1.3064, value_loss: 0.8302
2024-07-14 05:43:59,448 [INFO    ] __main__: train step 7441: loss: 1.0876, policy_loss: 1.3063, value_loss: 0.8302
2024-07-14 05:43:59,739 [INFO    ] __main__: train step 7442: loss: 1.0877, policy_loss: 1.3063, value_loss: 0.8302
2024-07-14 05:44:01,336 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:44:01,806 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:44:01,873 [INFO    ] __main__: train step 7443: loss: 1.0877, policy_loss: 1.3062, value_loss: 0.8301
2024-07-14 05:44:02,166 [INFO    ] __main__: train step 7444: loss: 1.0878, policy_loss: 1.3061, value_loss: 0.8301
2024-07-14 05:44:02,448 [INFO    ] __main__: train step 7445: loss: 1.0878, policy_loss: 1.3061, value_loss: 0.8301
2024-07-14 05:44:02,721 [INFO    ] __main__: train step 7446: loss: 1.0879, policy_loss: 1.3060, value_loss: 0.8301
2024-07-14 05:44:03,000 [INFO    ] __main__: train step 7447: loss: 1.0879, policy_loss: 1.3059, value_loss: 0.8300
2024-07-14 05:44:03,286 [INFO    ] __main__: train step 7448: loss: 1.0880, policy_loss: 1.3059, value_loss: 0.8300
2024-07-14 05:44:03,571 [INFO    ] __main__: train step 7449: loss: 1.0880, policy_loss: 1.3058, value_loss: 0.8300
2024-07-14 05:44:03,852 [INFO    ] __main__: train step 7450: loss: 1.0881, policy_loss: 1.3058, value_loss: 0.8300
2024-07-14 05:44:04,138 [INFO    ] __main__: train step 7451: loss: 1.0881, policy_loss: 1.3057, value_loss: 0.8299
2024-07-14 05:44:04,419 [INFO    ] __main__: train step 7452: loss: 1.0882, policy_loss: 1.3056, value_loss: 0.8299
2024-07-14 05:44:04,709 [INFO    ] __main__: train step 7453: loss: 1.0882, policy_loss: 1.3056, value_loss: 0.8299
2024-07-14 05:44:04,994 [INFO    ] __main__: train step 7454: loss: 1.0883, policy_loss: 1.3055, value_loss: 0.8299
2024-07-14 05:44:05,313 [INFO    ] __main__: train step 7455: loss: 1.0883, policy_loss: 1.3054, value_loss: 0.8298
2024-07-14 05:44:05,618 [INFO    ] __main__: train step 7456: loss: 1.0884, policy_loss: 1.3054, value_loss: 0.8298
2024-07-14 05:44:05,917 [INFO    ] __main__: train step 7457: loss: 1.0884, policy_loss: 1.3053, value_loss: 0.8298
2024-07-14 05:44:06,209 [INFO    ] __main__: train step 7458: loss: 1.0885, policy_loss: 1.3052, value_loss: 0.8298
2024-07-14 05:44:06,512 [INFO    ] __main__: train step 7459: loss: 1.0885, policy_loss: 1.3052, value_loss: 0.8298
2024-07-14 05:44:08,155 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:44:08,649 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:44:08,730 [INFO    ] __main__: train step 7460: loss: 1.0886, policy_loss: 1.3051, value_loss: 0.8297
2024-07-14 05:44:09,070 [INFO    ] __main__: train step 7461: loss: 1.0886, policy_loss: 1.3050, value_loss: 0.8297
2024-07-14 05:44:09,379 [INFO    ] __main__: train step 7462: loss: 1.0887, policy_loss: 1.3050, value_loss: 0.8297
2024-07-14 05:44:09,681 [INFO    ] __main__: train step 7463: loss: 1.0887, policy_loss: 1.3049, value_loss: 0.8297
2024-07-14 05:44:10,023 [INFO    ] __main__: train step 7464: loss: 1.0888, policy_loss: 1.3049, value_loss: 0.8296
2024-07-14 05:44:10,350 [INFO    ] __main__: train step 7465: loss: 1.0888, policy_loss: 1.3048, value_loss: 0.8296
2024-07-14 05:44:10,665 [INFO    ] __main__: train step 7466: loss: 1.0889, policy_loss: 1.3047, value_loss: 0.8296
2024-07-14 05:44:10,969 [INFO    ] __main__: train step 7467: loss: 1.0889, policy_loss: 1.3047, value_loss: 0.8296
2024-07-14 05:44:11,271 [INFO    ] __main__: train step 7468: loss: 1.0890, policy_loss: 1.3046, value_loss: 0.8295
2024-07-14 05:44:11,565 [INFO    ] __main__: train step 7469: loss: 1.0890, policy_loss: 1.3045, value_loss: 0.8295
2024-07-14 05:44:11,860 [INFO    ] __main__: train step 7470: loss: 1.0891, policy_loss: 1.3045, value_loss: 0.8295
2024-07-14 05:44:12,153 [INFO    ] __main__: train step 7471: loss: 1.0892, policy_loss: 1.3044, value_loss: 0.8295
2024-07-14 05:44:12,453 [INFO    ] __main__: train step 7472: loss: 1.0892, policy_loss: 1.3043, value_loss: 0.8294
2024-07-14 05:44:12,766 [INFO    ] __main__: train step 7473: loss: 1.0893, policy_loss: 1.3043, value_loss: 0.8294
2024-07-14 05:44:13,074 [INFO    ] __main__: train step 7474: loss: 1.0893, policy_loss: 1.3042, value_loss: 0.8294
2024-07-14 05:44:13,366 [INFO    ] __main__: train step 7475: loss: 1.0894, policy_loss: 1.3041, value_loss: 0.8294
2024-07-14 05:44:16,254 [INFO    ] __main__: train step 7476: loss: 1.0894, policy_loss: 1.3041, value_loss: 0.8294
2024-07-14 05:44:17,873 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:44:18,341 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:44:18,410 [INFO    ] __main__: train step 7477: loss: 1.0895, policy_loss: 1.3040, value_loss: 0.8293
2024-07-14 05:44:18,713 [INFO    ] __main__: train step 7478: loss: 1.0895, policy_loss: 1.3040, value_loss: 0.8293
2024-07-14 05:44:19,009 [INFO    ] __main__: train step 7479: loss: 1.0896, policy_loss: 1.3039, value_loss: 0.8293
2024-07-14 05:44:19,300 [INFO    ] __main__: train step 7480: loss: 1.0896, policy_loss: 1.3038, value_loss: 0.8293
2024-07-14 05:44:19,605 [INFO    ] __main__: train step 7481: loss: 1.0897, policy_loss: 1.3038, value_loss: 0.8292
2024-07-14 05:44:19,911 [INFO    ] __main__: train step 7482: loss: 1.0897, policy_loss: 1.3037, value_loss: 0.8292
2024-07-14 05:44:20,177 [INFO    ] __main__: train step 7483: loss: 1.0898, policy_loss: 1.3036, value_loss: 0.8292
2024-07-14 05:44:20,467 [INFO    ] __main__: train step 7484: loss: 1.0898, policy_loss: 1.3036, value_loss: 0.8292
2024-07-14 05:44:20,761 [INFO    ] __main__: train step 7485: loss: 1.0899, policy_loss: 1.3035, value_loss: 0.8291
2024-07-14 05:44:21,030 [INFO    ] __main__: train step 7486: loss: 1.0899, policy_loss: 1.3034, value_loss: 0.8291
2024-07-14 05:44:21,301 [INFO    ] __main__: train step 7487: loss: 1.0900, policy_loss: 1.3034, value_loss: 0.8291
2024-07-14 05:44:21,579 [INFO    ] __main__: train step 7488: loss: 1.0900, policy_loss: 1.3033, value_loss: 0.8291
2024-07-14 05:44:21,873 [INFO    ] __main__: train step 7489: loss: 1.0901, policy_loss: 1.3033, value_loss: 0.8290
2024-07-14 05:44:22,176 [INFO    ] __main__: train step 7490: loss: 1.0901, policy_loss: 1.3032, value_loss: 0.8290
2024-07-14 05:44:22,471 [INFO    ] __main__: train step 7491: loss: 1.0902, policy_loss: 1.3031, value_loss: 0.8290
2024-07-14 05:44:22,774 [INFO    ] __main__: train step 7492: loss: 1.0902, policy_loss: 1.3031, value_loss: 0.8290
2024-07-14 05:44:23,082 [INFO    ] __main__: train step 7493: loss: 1.0903, policy_loss: 1.3030, value_loss: 0.8290
2024-07-14 05:44:24,716 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:44:25,237 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:44:25,311 [INFO    ] __main__: train step 7494: loss: 1.0903, policy_loss: 1.3029, value_loss: 0.8289
2024-07-14 05:44:25,598 [INFO    ] __main__: train step 7495: loss: 1.0904, policy_loss: 1.3029, value_loss: 0.8289
2024-07-14 05:44:25,891 [INFO    ] __main__: train step 7496: loss: 1.0904, policy_loss: 1.3028, value_loss: 0.8289
2024-07-14 05:44:26,181 [INFO    ] __main__: train step 7497: loss: 1.0905, policy_loss: 1.3027, value_loss: 0.8289
2024-07-14 05:44:26,476 [INFO    ] __main__: train step 7498: loss: 1.0905, policy_loss: 1.3027, value_loss: 0.8288
2024-07-14 05:44:26,770 [INFO    ] __main__: train step 7499: loss: 1.0906, policy_loss: 1.3026, value_loss: 0.8288
2024-07-14 05:44:27,074 [INFO    ] __main__: train step 7500: loss: 1.0906, policy_loss: 1.3025, value_loss: 0.8288
2024-07-14 05:44:27,381 [INFO    ] __main__: train step 7501: loss: 1.0907, policy_loss: 1.3025, value_loss: 0.8288
2024-07-14 05:44:27,703 [INFO    ] __main__: train step 7502: loss: 1.0907, policy_loss: 1.3024, value_loss: 0.8287
2024-07-14 05:44:27,998 [INFO    ] __main__: train step 7503: loss: 1.0908, policy_loss: 1.3024, value_loss: 0.8287
2024-07-14 05:44:28,301 [INFO    ] __main__: train step 7504: loss: 1.0908, policy_loss: 1.3023, value_loss: 0.8287
2024-07-14 05:44:28,600 [INFO    ] __main__: train step 7505: loss: 1.0909, policy_loss: 1.3022, value_loss: 0.8287
2024-07-14 05:44:28,900 [INFO    ] __main__: train step 7506: loss: 1.0909, policy_loss: 1.3022, value_loss: 0.8286
2024-07-14 05:44:29,182 [INFO    ] __main__: train step 7507: loss: 1.0910, policy_loss: 1.3021, value_loss: 0.8286
2024-07-14 05:44:29,486 [INFO    ] __main__: train step 7508: loss: 1.0910, policy_loss: 1.3020, value_loss: 0.8286
2024-07-14 05:44:29,794 [INFO    ] __main__: train step 7509: loss: 1.0911, policy_loss: 1.3020, value_loss: 0.8286
2024-07-14 05:44:30,095 [INFO    ] __main__: train step 7510: loss: 1.0911, policy_loss: 1.3019, value_loss: 0.8286
2024-07-14 05:44:31,709 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:44:32,197 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:44:32,276 [INFO    ] __main__: train step 7511: loss: 1.0912, policy_loss: 1.3018, value_loss: 0.8285
2024-07-14 05:44:32,550 [INFO    ] __main__: train step 7512: loss: 1.0912, policy_loss: 1.3018, value_loss: 0.8285
2024-07-14 05:44:32,855 [INFO    ] __main__: train step 7513: loss: 1.0913, policy_loss: 1.3017, value_loss: 0.8285
2024-07-14 05:44:33,151 [INFO    ] __main__: train step 7514: loss: 1.0913, policy_loss: 1.3017, value_loss: 0.8285
2024-07-14 05:44:33,438 [INFO    ] __main__: train step 7515: loss: 1.0914, policy_loss: 1.3016, value_loss: 0.8284
2024-07-14 05:44:33,722 [INFO    ] __main__: train step 7516: loss: 1.0914, policy_loss: 1.3015, value_loss: 0.8284
2024-07-14 05:44:34,004 [INFO    ] __main__: train step 7517: loss: 1.0915, policy_loss: 1.3015, value_loss: 0.8284
2024-07-14 05:44:34,304 [INFO    ] __main__: train step 7518: loss: 1.0915, policy_loss: 1.3014, value_loss: 0.8284
2024-07-14 05:44:34,602 [INFO    ] __main__: train step 7519: loss: 1.0916, policy_loss: 1.3013, value_loss: 0.8283
2024-07-14 05:44:34,893 [INFO    ] __main__: train step 7520: loss: 1.0916, policy_loss: 1.3013, value_loss: 0.8283
2024-07-14 05:44:35,187 [INFO    ] __main__: train step 7521: loss: 1.0917, policy_loss: 1.3012, value_loss: 0.8283
2024-07-14 05:44:35,491 [INFO    ] __main__: train step 7522: loss: 1.0917, policy_loss: 1.3011, value_loss: 0.8283
2024-07-14 05:44:35,768 [INFO    ] __main__: train step 7523: loss: 1.0918, policy_loss: 1.3011, value_loss: 0.8282
2024-07-14 05:44:36,074 [INFO    ] __main__: train step 7524: loss: 1.0918, policy_loss: 1.3010, value_loss: 0.8282
2024-07-14 05:44:36,379 [INFO    ] __main__: train step 7525: loss: 1.0919, policy_loss: 1.3010, value_loss: 0.8282
2024-07-14 05:44:36,678 [INFO    ] __main__: train step 7526: loss: 1.0919, policy_loss: 1.3009, value_loss: 0.8282
2024-07-14 05:44:36,984 [INFO    ] __main__: train step 7527: loss: 1.0920, policy_loss: 1.3008, value_loss: 0.8281
2024-07-14 05:44:38,610 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:44:39,093 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:44:39,166 [INFO    ] __main__: train step 7528: loss: 1.0920, policy_loss: 1.3008, value_loss: 0.8281
2024-07-14 05:44:39,466 [INFO    ] __main__: train step 7529: loss: 1.0921, policy_loss: 1.3007, value_loss: 0.8281
2024-07-14 05:44:39,762 [INFO    ] __main__: train step 7530: loss: 1.0921, policy_loss: 1.3006, value_loss: 0.8281
2024-07-14 05:44:42,242 [INFO    ] __main__: train step 7531: loss: 1.0922, policy_loss: 1.3006, value_loss: 0.8280
2024-07-14 05:44:42,532 [INFO    ] __main__: train step 7532: loss: 1.0922, policy_loss: 1.3005, value_loss: 0.8280
2024-07-14 05:44:42,817 [INFO    ] __main__: train step 7533: loss: 1.0923, policy_loss: 1.3004, value_loss: 0.8280
2024-07-14 05:44:43,105 [INFO    ] __main__: train step 7534: loss: 1.0923, policy_loss: 1.3004, value_loss: 0.8280
2024-07-14 05:44:43,408 [INFO    ] __main__: train step 7535: loss: 1.0924, policy_loss: 1.3003, value_loss: 0.8280
2024-07-14 05:44:43,711 [INFO    ] __main__: train step 7536: loss: 1.0924, policy_loss: 1.3002, value_loss: 0.8279
2024-07-14 05:44:44,020 [INFO    ] __main__: train step 7537: loss: 1.0925, policy_loss: 1.3002, value_loss: 0.8279
2024-07-14 05:44:44,342 [INFO    ] __main__: train step 7538: loss: 1.0925, policy_loss: 1.3001, value_loss: 0.8279
2024-07-14 05:44:44,630 [INFO    ] __main__: train step 7539: loss: 1.0926, policy_loss: 1.3001, value_loss: 0.8279
2024-07-14 05:44:44,924 [INFO    ] __main__: train step 7540: loss: 1.0926, policy_loss: 1.3000, value_loss: 0.8278
2024-07-14 05:44:45,216 [INFO    ] __main__: train step 7541: loss: 1.0927, policy_loss: 1.2999, value_loss: 0.8278
2024-07-14 05:44:45,511 [INFO    ] __main__: train step 7542: loss: 1.0927, policy_loss: 1.2999, value_loss: 0.8278
2024-07-14 05:44:45,804 [INFO    ] __main__: train step 7543: loss: 1.0927, policy_loss: 1.2998, value_loss: 0.8278
2024-07-14 05:44:46,096 [INFO    ] __main__: train step 7544: loss: 1.0928, policy_loss: 1.2997, value_loss: 0.8277
2024-07-14 05:44:47,680 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:44:48,135 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:44:48,212 [INFO    ] __main__: train step 7545: loss: 1.0928, policy_loss: 1.2997, value_loss: 0.8277
2024-07-14 05:44:48,528 [INFO    ] __main__: train step 7546: loss: 1.0929, policy_loss: 1.2996, value_loss: 0.8277
2024-07-14 05:44:48,850 [INFO    ] __main__: train step 7547: loss: 1.0929, policy_loss: 1.2995, value_loss: 0.8277
2024-07-14 05:44:49,186 [INFO    ] __main__: train step 7548: loss: 1.0930, policy_loss: 1.2995, value_loss: 0.8277
2024-07-14 05:44:49,493 [INFO    ] __main__: train step 7549: loss: 1.0930, policy_loss: 1.2994, value_loss: 0.8276
2024-07-14 05:44:49,790 [INFO    ] __main__: train step 7550: loss: 1.0931, policy_loss: 1.2993, value_loss: 0.8276
2024-07-14 05:44:50,105 [INFO    ] __main__: train step 7551: loss: 1.0931, policy_loss: 1.2993, value_loss: 0.8276
2024-07-14 05:44:50,407 [INFO    ] __main__: train step 7552: loss: 1.0932, policy_loss: 1.2992, value_loss: 0.8276
2024-07-14 05:44:50,696 [INFO    ] __main__: train step 7553: loss: 1.0932, policy_loss: 1.2992, value_loss: 0.8275
2024-07-14 05:44:50,992 [INFO    ] __main__: train step 7554: loss: 1.0933, policy_loss: 1.2991, value_loss: 0.8275
2024-07-14 05:44:51,278 [INFO    ] __main__: train step 7555: loss: 1.0933, policy_loss: 1.2990, value_loss: 0.8275
2024-07-14 05:44:51,589 [INFO    ] __main__: train step 7556: loss: 1.0934, policy_loss: 1.2990, value_loss: 0.8275
2024-07-14 05:44:51,890 [INFO    ] __main__: train step 7557: loss: 1.0934, policy_loss: 1.2989, value_loss: 0.8274
2024-07-14 05:44:52,185 [INFO    ] __main__: train step 7558: loss: 1.0935, policy_loss: 1.2988, value_loss: 0.8274
2024-07-14 05:44:52,494 [INFO    ] __main__: train step 7559: loss: 1.0935, policy_loss: 1.2988, value_loss: 0.8274
2024-07-14 05:44:52,785 [INFO    ] __main__: train step 7560: loss: 1.0936, policy_loss: 1.2987, value_loss: 0.8274
2024-07-14 05:44:53,080 [INFO    ] __main__: train step 7561: loss: 1.0936, policy_loss: 1.2986, value_loss: 0.8273
2024-07-14 05:44:54,700 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:44:55,191 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:44:55,261 [INFO    ] __main__: train step 7562: loss: 1.0937, policy_loss: 1.2986, value_loss: 0.8273
2024-07-14 05:44:55,573 [INFO    ] __main__: train step 7563: loss: 1.0937, policy_loss: 1.2985, value_loss: 0.8273
2024-07-14 05:44:55,917 [INFO    ] __main__: train step 7564: loss: 1.0938, policy_loss: 1.2984, value_loss: 0.8273
2024-07-14 05:44:56,200 [INFO    ] __main__: train step 7565: loss: 1.0938, policy_loss: 1.2984, value_loss: 0.8272
2024-07-14 05:44:56,461 [INFO    ] __main__: train step 7566: loss: 1.0939, policy_loss: 1.2983, value_loss: 0.8272
2024-07-14 05:44:56,741 [INFO    ] __main__: train step 7567: loss: 1.0939, policy_loss: 1.2983, value_loss: 0.8272
2024-07-14 05:44:57,031 [INFO    ] __main__: train step 7568: loss: 1.0940, policy_loss: 1.2982, value_loss: 0.8272
2024-07-14 05:44:57,334 [INFO    ] __main__: train step 7569: loss: 1.0940, policy_loss: 1.2981, value_loss: 0.8272
2024-07-14 05:44:57,637 [INFO    ] __main__: train step 7570: loss: 1.0940, policy_loss: 1.2981, value_loss: 0.8271
2024-07-14 05:44:57,938 [INFO    ] __main__: train step 7571: loss: 1.0941, policy_loss: 1.2980, value_loss: 0.8271
2024-07-14 05:44:58,235 [INFO    ] __main__: train step 7572: loss: 1.0942, policy_loss: 1.2979, value_loss: 0.8271
2024-07-14 05:44:58,526 [INFO    ] __main__: train step 7573: loss: 1.0942, policy_loss: 1.2979, value_loss: 0.8271
2024-07-14 05:44:58,822 [INFO    ] __main__: train step 7574: loss: 1.0942, policy_loss: 1.2978, value_loss: 0.8270
2024-07-14 05:44:59,131 [INFO    ] __main__: train step 7575: loss: 1.0943, policy_loss: 1.2978, value_loss: 0.8270
2024-07-14 05:44:59,419 [INFO    ] __main__: train step 7576: loss: 1.0943, policy_loss: 1.2977, value_loss: 0.8270
2024-07-14 05:44:59,759 [INFO    ] __main__: train step 7577: loss: 1.0944, policy_loss: 1.2976, value_loss: 0.8270
2024-07-14 05:45:00,062 [INFO    ] __main__: train step 7578: loss: 1.0944, policy_loss: 1.2976, value_loss: 0.8270
2024-07-14 05:45:01,688 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:45:02,138 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:45:02,210 [INFO    ] __main__: train step 7579: loss: 1.0945, policy_loss: 1.2975, value_loss: 0.8269
2024-07-14 05:45:02,516 [INFO    ] __main__: train step 7580: loss: 1.0945, policy_loss: 1.2974, value_loss: 0.8269
2024-07-14 05:45:02,814 [INFO    ] __main__: train step 7581: loss: 1.0946, policy_loss: 1.2974, value_loss: 0.8269
2024-07-14 05:45:03,098 [INFO    ] __main__: train step 7582: loss: 1.0946, policy_loss: 1.2973, value_loss: 0.8269
2024-07-14 05:45:03,393 [INFO    ] __main__: train step 7583: loss: 1.0947, policy_loss: 1.2972, value_loss: 0.8268
2024-07-14 05:45:03,705 [INFO    ] __main__: train step 7584: loss: 1.0947, policy_loss: 1.2972, value_loss: 0.8268
2024-07-14 05:45:04,000 [INFO    ] __main__: train step 7585: loss: 1.0948, policy_loss: 1.2971, value_loss: 0.8268
2024-07-14 05:45:06,205 [INFO    ] __main__: train step 7586: loss: 1.0948, policy_loss: 1.2970, value_loss: 0.8268
2024-07-14 05:45:06,509 [INFO    ] __main__: train step 7587: loss: 1.0949, policy_loss: 1.2970, value_loss: 0.8267
2024-07-14 05:45:06,796 [INFO    ] __main__: train step 7588: loss: 1.0949, policy_loss: 1.2969, value_loss: 0.8267
2024-07-14 05:45:07,091 [INFO    ] __main__: train step 7589: loss: 1.0950, policy_loss: 1.2968, value_loss: 0.8267
2024-07-14 05:45:07,371 [INFO    ] __main__: train step 7590: loss: 1.0950, policy_loss: 1.2968, value_loss: 0.8267
2024-07-14 05:45:07,688 [INFO    ] __main__: train step 7591: loss: 1.0951, policy_loss: 1.2967, value_loss: 0.8267
2024-07-14 05:45:07,988 [INFO    ] __main__: train step 7592: loss: 1.0951, policy_loss: 1.2967, value_loss: 0.8266
2024-07-14 05:45:08,305 [INFO    ] __main__: train step 7593: loss: 1.0952, policy_loss: 1.2966, value_loss: 0.8266
2024-07-14 05:45:08,626 [INFO    ] __main__: train step 7594: loss: 1.0952, policy_loss: 1.2965, value_loss: 0.8266
2024-07-14 05:45:08,935 [INFO    ] __main__: train step 7595: loss: 1.0952, policy_loss: 1.2965, value_loss: 0.8266
2024-07-14 05:45:10,556 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:45:11,046 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:45:11,115 [INFO    ] __main__: train step 7596: loss: 1.0953, policy_loss: 1.2964, value_loss: 0.8265
2024-07-14 05:45:11,423 [INFO    ] __main__: train step 7597: loss: 1.0953, policy_loss: 1.2963, value_loss: 0.8265
2024-07-14 05:45:11,710 [INFO    ] __main__: train step 7598: loss: 1.0954, policy_loss: 1.2963, value_loss: 0.8265
2024-07-14 05:45:11,995 [INFO    ] __main__: train step 7599: loss: 1.0954, policy_loss: 1.2962, value_loss: 0.8265
2024-07-14 05:45:12,284 [INFO    ] __main__: train step 7600: loss: 1.0955, policy_loss: 1.2961, value_loss: 0.8265
2024-07-14 05:45:12,573 [INFO    ] __main__: train step 7601: loss: 1.0955, policy_loss: 1.2961, value_loss: 0.8264
2024-07-14 05:45:12,870 [INFO    ] __main__: train step 7602: loss: 1.0956, policy_loss: 1.2960, value_loss: 0.8264
2024-07-14 05:45:13,167 [INFO    ] __main__: train step 7603: loss: 1.0956, policy_loss: 1.2959, value_loss: 0.8264
2024-07-14 05:45:13,463 [INFO    ] __main__: train step 7604: loss: 1.0957, policy_loss: 1.2959, value_loss: 0.8264
2024-07-14 05:45:13,763 [INFO    ] __main__: train step 7605: loss: 1.0957, policy_loss: 1.2958, value_loss: 0.8263
2024-07-14 05:45:14,084 [INFO    ] __main__: train step 7606: loss: 1.0958, policy_loss: 1.2958, value_loss: 0.8263
2024-07-14 05:45:14,389 [INFO    ] __main__: train step 7607: loss: 1.0958, policy_loss: 1.2957, value_loss: 0.8263
2024-07-14 05:45:14,688 [INFO    ] __main__: train step 7608: loss: 1.0959, policy_loss: 1.2956, value_loss: 0.8263
2024-07-14 05:45:14,976 [INFO    ] __main__: train step 7609: loss: 1.0959, policy_loss: 1.2956, value_loss: 0.8262
2024-07-14 05:45:15,275 [INFO    ] __main__: train step 7610: loss: 1.0960, policy_loss: 1.2955, value_loss: 0.8262
2024-07-14 05:45:15,572 [INFO    ] __main__: train step 7611: loss: 1.0960, policy_loss: 1.2954, value_loss: 0.8262
2024-07-14 05:45:15,864 [INFO    ] __main__: train step 7612: loss: 1.0960, policy_loss: 1.2954, value_loss: 0.8262
2024-07-14 05:45:17,488 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:45:17,998 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:45:18,069 [INFO    ] __main__: train step 7613: loss: 1.0961, policy_loss: 1.2953, value_loss: 0.8262
2024-07-14 05:45:18,369 [INFO    ] __main__: train step 7614: loss: 1.0961, policy_loss: 1.2952, value_loss: 0.8261
2024-07-14 05:45:18,655 [INFO    ] __main__: train step 7615: loss: 1.0962, policy_loss: 1.2952, value_loss: 0.8261
2024-07-14 05:45:18,988 [INFO    ] __main__: train step 7616: loss: 1.0962, policy_loss: 1.2951, value_loss: 0.8261
2024-07-14 05:45:19,288 [INFO    ] __main__: train step 7617: loss: 1.0963, policy_loss: 1.2950, value_loss: 0.8261
2024-07-14 05:45:19,576 [INFO    ] __main__: train step 7618: loss: 1.0963, policy_loss: 1.2950, value_loss: 0.8260
2024-07-14 05:45:19,875 [INFO    ] __main__: train step 7619: loss: 1.0964, policy_loss: 1.2949, value_loss: 0.8260
2024-07-14 05:45:20,171 [INFO    ] __main__: train step 7620: loss: 1.0964, policy_loss: 1.2949, value_loss: 0.8260
2024-07-14 05:45:20,434 [INFO    ] __main__: train step 7621: loss: 1.0965, policy_loss: 1.2948, value_loss: 0.8260
2024-07-14 05:45:20,719 [INFO    ] __main__: train step 7622: loss: 1.0965, policy_loss: 1.2947, value_loss: 0.8259
2024-07-14 05:45:21,012 [INFO    ] __main__: train step 7623: loss: 1.0966, policy_loss: 1.2947, value_loss: 0.8259
2024-07-14 05:45:21,302 [INFO    ] __main__: train step 7624: loss: 1.0966, policy_loss: 1.2946, value_loss: 0.8259
2024-07-14 05:45:21,597 [INFO    ] __main__: train step 7625: loss: 1.0967, policy_loss: 1.2945, value_loss: 0.8259
2024-07-14 05:45:21,896 [INFO    ] __main__: train step 7626: loss: 1.0967, policy_loss: 1.2945, value_loss: 0.8259
2024-07-14 05:45:22,199 [INFO    ] __main__: train step 7627: loss: 1.0968, policy_loss: 1.2944, value_loss: 0.8258
2024-07-14 05:45:22,479 [INFO    ] __main__: train step 7628: loss: 1.0968, policy_loss: 1.2943, value_loss: 0.8258
2024-07-14 05:45:22,763 [INFO    ] __main__: train step 7629: loss: 1.0968, policy_loss: 1.2943, value_loss: 0.8258
2024-07-14 05:45:24,355 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:45:24,825 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:45:24,893 [INFO    ] __main__: train step 7630: loss: 1.0969, policy_loss: 1.2942, value_loss: 0.8258
2024-07-14 05:45:25,172 [INFO    ] __main__: train step 7631: loss: 1.0969, policy_loss: 1.2941, value_loss: 0.8257
2024-07-14 05:45:25,463 [INFO    ] __main__: train step 7632: loss: 1.0970, policy_loss: 1.2941, value_loss: 0.8257
2024-07-14 05:45:25,754 [INFO    ] __main__: train step 7633: loss: 1.0970, policy_loss: 1.2940, value_loss: 0.8257
2024-07-14 05:45:26,053 [INFO    ] __main__: train step 7634: loss: 1.0971, policy_loss: 1.2939, value_loss: 0.8257
2024-07-14 05:45:26,343 [INFO    ] __main__: train step 7635: loss: 1.0971, policy_loss: 1.2939, value_loss: 0.8257
2024-07-14 05:45:26,641 [INFO    ] __main__: train step 7636: loss: 1.0972, policy_loss: 1.2938, value_loss: 0.8256
2024-07-14 05:45:26,942 [INFO    ] __main__: train step 7637: loss: 1.0972, policy_loss: 1.2938, value_loss: 0.8256
2024-07-14 05:45:27,226 [INFO    ] __main__: train step 7638: loss: 1.0973, policy_loss: 1.2937, value_loss: 0.8256
2024-07-14 05:45:27,513 [INFO    ] __main__: train step 7639: loss: 1.0973, policy_loss: 1.2936, value_loss: 0.8256
2024-07-14 05:45:27,834 [INFO    ] __main__: train step 7640: loss: 1.0973, policy_loss: 1.2936, value_loss: 0.8255
2024-07-14 05:45:30,586 [INFO    ] __main__: train step 7641: loss: 1.0974, policy_loss: 1.2935, value_loss: 0.8255
2024-07-14 05:45:30,888 [INFO    ] __main__: train step 7642: loss: 1.0974, policy_loss: 1.2934, value_loss: 0.8255
2024-07-14 05:45:31,178 [INFO    ] __main__: train step 7643: loss: 1.0975, policy_loss: 1.2934, value_loss: 0.8255
2024-07-14 05:45:31,459 [INFO    ] __main__: train step 7644: loss: 1.0975, policy_loss: 1.2933, value_loss: 0.8254
2024-07-14 05:45:31,744 [INFO    ] __main__: train step 7645: loss: 1.0976, policy_loss: 1.2932, value_loss: 0.8254
2024-07-14 05:45:32,031 [INFO    ] __main__: train step 7646: loss: 1.0976, policy_loss: 1.2932, value_loss: 0.8254
2024-07-14 05:45:33,651 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:45:34,123 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:45:34,196 [INFO    ] __main__: train step 7647: loss: 1.0977, policy_loss: 1.2931, value_loss: 0.8254
2024-07-14 05:45:34,489 [INFO    ] __main__: train step 7648: loss: 1.0977, policy_loss: 1.2931, value_loss: 0.8253
2024-07-14 05:45:34,781 [INFO    ] __main__: train step 7649: loss: 1.0977, policy_loss: 1.2930, value_loss: 0.8253
2024-07-14 05:45:35,073 [INFO    ] __main__: train step 7650: loss: 1.0978, policy_loss: 1.2929, value_loss: 0.8253
2024-07-14 05:45:35,366 [INFO    ] __main__: train step 7651: loss: 1.0978, policy_loss: 1.2929, value_loss: 0.8253
2024-07-14 05:45:35,654 [INFO    ] __main__: train step 7652: loss: 1.0979, policy_loss: 1.2928, value_loss: 0.8252
2024-07-14 05:45:35,948 [INFO    ] __main__: train step 7653: loss: 1.0979, policy_loss: 1.2927, value_loss: 0.8252
2024-07-14 05:45:36,246 [INFO    ] __main__: train step 7654: loss: 1.0980, policy_loss: 1.2927, value_loss: 0.8252
2024-07-14 05:45:36,543 [INFO    ] __main__: train step 7655: loss: 1.0980, policy_loss: 1.2926, value_loss: 0.8252
2024-07-14 05:45:36,839 [INFO    ] __main__: train step 7656: loss: 1.0981, policy_loss: 1.2925, value_loss: 0.8252
2024-07-14 05:45:37,135 [INFO    ] __main__: train step 7657: loss: 1.0981, policy_loss: 1.2925, value_loss: 0.8251
2024-07-14 05:45:37,427 [INFO    ] __main__: train step 7658: loss: 1.0981, policy_loss: 1.2924, value_loss: 0.8251
2024-07-14 05:45:37,715 [INFO    ] __main__: train step 7659: loss: 1.0982, policy_loss: 1.2923, value_loss: 0.8251
2024-07-14 05:45:38,008 [INFO    ] __main__: train step 7660: loss: 1.0982, policy_loss: 1.2923, value_loss: 0.8251
2024-07-14 05:45:38,301 [INFO    ] __main__: train step 7661: loss: 1.0983, policy_loss: 1.2922, value_loss: 0.8250
2024-07-14 05:45:38,604 [INFO    ] __main__: train step 7662: loss: 1.0983, policy_loss: 1.2922, value_loss: 0.8250
2024-07-14 05:45:38,868 [INFO    ] __main__: train step 7663: loss: 1.0984, policy_loss: 1.2921, value_loss: 0.8250
2024-07-14 05:45:40,464 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:45:40,951 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:45:41,021 [INFO    ] __main__: train step 7664: loss: 1.0984, policy_loss: 1.2920, value_loss: 0.8250
2024-07-14 05:45:41,330 [INFO    ] __main__: train step 7665: loss: 1.0985, policy_loss: 1.2920, value_loss: 0.8249
2024-07-14 05:45:41,625 [INFO    ] __main__: train step 7666: loss: 1.0985, policy_loss: 1.2919, value_loss: 0.8249
2024-07-14 05:45:41,901 [INFO    ] __main__: train step 7667: loss: 1.0985, policy_loss: 1.2918, value_loss: 0.8249
2024-07-14 05:45:42,179 [INFO    ] __main__: train step 7668: loss: 1.0986, policy_loss: 1.2918, value_loss: 0.8249
2024-07-14 05:45:42,502 [INFO    ] __main__: train step 7669: loss: 1.0986, policy_loss: 1.2917, value_loss: 0.8248
2024-07-14 05:45:42,805 [INFO    ] __main__: train step 7670: loss: 1.0987, policy_loss: 1.2916, value_loss: 0.8248
2024-07-14 05:45:43,105 [INFO    ] __main__: train step 7671: loss: 1.0987, policy_loss: 1.2916, value_loss: 0.8248
2024-07-14 05:45:43,400 [INFO    ] __main__: train step 7672: loss: 1.0988, policy_loss: 1.2915, value_loss: 0.8248
2024-07-14 05:45:43,690 [INFO    ] __main__: train step 7673: loss: 1.0988, policy_loss: 1.2915, value_loss: 0.8248
2024-07-14 05:45:43,984 [INFO    ] __main__: train step 7674: loss: 1.0989, policy_loss: 1.2914, value_loss: 0.8247
2024-07-14 05:45:44,275 [INFO    ] __main__: train step 7675: loss: 1.0989, policy_loss: 1.2913, value_loss: 0.8247
2024-07-14 05:45:44,557 [INFO    ] __main__: train step 7676: loss: 1.0990, policy_loss: 1.2913, value_loss: 0.8247
2024-07-14 05:45:44,841 [INFO    ] __main__: train step 7677: loss: 1.0990, policy_loss: 1.2912, value_loss: 0.8247
2024-07-14 05:45:45,129 [INFO    ] __main__: train step 7678: loss: 1.0990, policy_loss: 1.2911, value_loss: 0.8246
2024-07-14 05:45:45,418 [INFO    ] __main__: train step 7679: loss: 1.0991, policy_loss: 1.2911, value_loss: 0.8246
2024-07-14 05:45:45,706 [INFO    ] __main__: train step 7680: loss: 1.0991, policy_loss: 1.2910, value_loss: 0.8246
2024-07-14 05:45:47,335 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:45:47,836 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:45:47,909 [INFO    ] __main__: train step 7681: loss: 1.0992, policy_loss: 1.2909, value_loss: 0.8246
2024-07-14 05:45:48,203 [INFO    ] __main__: train step 7682: loss: 1.0992, policy_loss: 1.2909, value_loss: 0.8245
2024-07-14 05:45:48,484 [INFO    ] __main__: train step 7683: loss: 1.0993, policy_loss: 1.2908, value_loss: 0.8245
2024-07-14 05:45:48,749 [INFO    ] __main__: train step 7684: loss: 1.0993, policy_loss: 1.2908, value_loss: 0.8245
2024-07-14 05:45:49,038 [INFO    ] __main__: train step 7685: loss: 1.0994, policy_loss: 1.2907, value_loss: 0.8245
2024-07-14 05:45:49,332 [INFO    ] __main__: train step 7686: loss: 1.0994, policy_loss: 1.2906, value_loss: 0.8245
2024-07-14 05:45:49,633 [INFO    ] __main__: train step 7687: loss: 1.0994, policy_loss: 1.2906, value_loss: 0.8244
2024-07-14 05:45:49,909 [INFO    ] __main__: train step 7688: loss: 1.0995, policy_loss: 1.2905, value_loss: 0.8244
2024-07-14 05:45:50,211 [INFO    ] __main__: train step 7689: loss: 1.0995, policy_loss: 1.2904, value_loss: 0.8244
2024-07-14 05:45:50,498 [INFO    ] __main__: train step 7690: loss: 1.0996, policy_loss: 1.2904, value_loss: 0.8244
2024-07-14 05:45:50,791 [INFO    ] __main__: train step 7691: loss: 1.0996, policy_loss: 1.2903, value_loss: 0.8243
2024-07-14 05:45:51,093 [INFO    ] __main__: train step 7692: loss: 1.0997, policy_loss: 1.2902, value_loss: 0.8243
2024-07-14 05:45:51,383 [INFO    ] __main__: train step 7693: loss: 1.0997, policy_loss: 1.2902, value_loss: 0.8243
2024-07-14 05:45:51,684 [INFO    ] __main__: train step 7694: loss: 1.0998, policy_loss: 1.2901, value_loss: 0.8243
2024-07-14 05:45:54,362 [INFO    ] __main__: train step 7695: loss: 1.0998, policy_loss: 1.2901, value_loss: 0.8242
2024-07-14 05:45:54,674 [INFO    ] __main__: train step 7696: loss: 1.0998, policy_loss: 1.2900, value_loss: 0.8242
2024-07-14 05:45:54,978 [INFO    ] __main__: train step 7697: loss: 1.0999, policy_loss: 1.2899, value_loss: 0.8242
2024-07-14 05:45:56,611 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:45:57,080 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:45:57,149 [INFO    ] __main__: train step 7698: loss: 1.0999, policy_loss: 1.2899, value_loss: 0.8242
2024-07-14 05:45:57,457 [INFO    ] __main__: train step 7699: loss: 1.1000, policy_loss: 1.2898, value_loss: 0.8242
2024-07-14 05:45:57,746 [INFO    ] __main__: train step 7700: loss: 1.1000, policy_loss: 1.2897, value_loss: 0.8241
2024-07-14 05:45:58,034 [INFO    ] __main__: train step 7701: loss: 1.1001, policy_loss: 1.2897, value_loss: 0.8241
2024-07-14 05:45:58,330 [INFO    ] __main__: train step 7702: loss: 1.1001, policy_loss: 1.2896, value_loss: 0.8241
2024-07-14 05:45:58,638 [INFO    ] __main__: train step 7703: loss: 1.1002, policy_loss: 1.2895, value_loss: 0.8241
2024-07-14 05:45:58,932 [INFO    ] __main__: train step 7704: loss: 1.1002, policy_loss: 1.2895, value_loss: 0.8240
2024-07-14 05:45:59,227 [INFO    ] __main__: train step 7705: loss: 1.1002, policy_loss: 1.2894, value_loss: 0.8240
2024-07-14 05:45:59,512 [INFO    ] __main__: train step 7706: loss: 1.1003, policy_loss: 1.2893, value_loss: 0.8240
2024-07-14 05:45:59,799 [INFO    ] __main__: train step 7707: loss: 1.1003, policy_loss: 1.2893, value_loss: 0.8240
2024-07-14 05:46:00,083 [INFO    ] __main__: train step 7708: loss: 1.1004, policy_loss: 1.2892, value_loss: 0.8239
2024-07-14 05:46:00,385 [INFO    ] __main__: train step 7709: loss: 1.1004, policy_loss: 1.2892, value_loss: 0.8239
2024-07-14 05:46:00,687 [INFO    ] __main__: train step 7710: loss: 1.1005, policy_loss: 1.2891, value_loss: 0.8239
2024-07-14 05:46:00,976 [INFO    ] __main__: train step 7711: loss: 1.1005, policy_loss: 1.2890, value_loss: 0.8239
2024-07-14 05:46:01,271 [INFO    ] __main__: train step 7712: loss: 1.1005, policy_loss: 1.2890, value_loss: 0.8238
2024-07-14 05:46:01,562 [INFO    ] __main__: train step 7713: loss: 1.1006, policy_loss: 1.2889, value_loss: 0.8238
2024-07-14 05:46:01,859 [INFO    ] __main__: train step 7714: loss: 1.1006, policy_loss: 1.2888, value_loss: 0.8238
2024-07-14 05:46:03,478 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:46:04,518 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:46:04,592 [INFO    ] __main__: train step 7715: loss: 1.1007, policy_loss: 1.2888, value_loss: 0.8238
2024-07-14 05:46:04,910 [INFO    ] __main__: train step 7716: loss: 1.1007, policy_loss: 1.2887, value_loss: 0.8238
2024-07-14 05:46:05,229 [INFO    ] __main__: train step 7717: loss: 1.1008, policy_loss: 1.2886, value_loss: 0.8237
2024-07-14 05:46:05,506 [INFO    ] __main__: train step 7718: loss: 1.1008, policy_loss: 1.2886, value_loss: 0.8237
2024-07-14 05:46:05,801 [INFO    ] __main__: train step 7719: loss: 1.1008, policy_loss: 1.2885, value_loss: 0.8237
2024-07-14 05:46:06,070 [INFO    ] __main__: train step 7720: loss: 1.1009, policy_loss: 1.2885, value_loss: 0.8237
2024-07-14 05:46:06,350 [INFO    ] __main__: train step 7721: loss: 1.1009, policy_loss: 1.2884, value_loss: 0.8236
2024-07-14 05:46:06,631 [INFO    ] __main__: train step 7722: loss: 1.1010, policy_loss: 1.2883, value_loss: 0.8236
2024-07-14 05:46:06,909 [INFO    ] __main__: train step 7723: loss: 1.1010, policy_loss: 1.2883, value_loss: 0.8236
2024-07-14 05:46:07,203 [INFO    ] __main__: train step 7724: loss: 1.1011, policy_loss: 1.2882, value_loss: 0.8236
2024-07-14 05:46:07,483 [INFO    ] __main__: train step 7725: loss: 1.1011, policy_loss: 1.2881, value_loss: 0.8235
2024-07-14 05:46:07,756 [INFO    ] __main__: train step 7726: loss: 1.1011, policy_loss: 1.2881, value_loss: 0.8235
2024-07-14 05:46:08,045 [INFO    ] __main__: train step 7727: loss: 1.1012, policy_loss: 1.2880, value_loss: 0.8235
2024-07-14 05:46:08,344 [INFO    ] __main__: train step 7728: loss: 1.1012, policy_loss: 1.2879, value_loss: 0.8235
2024-07-14 05:46:08,637 [INFO    ] __main__: train step 7729: loss: 1.1013, policy_loss: 1.2879, value_loss: 0.8234
2024-07-14 05:46:08,925 [INFO    ] __main__: train step 7730: loss: 1.1013, policy_loss: 1.2878, value_loss: 0.8234
2024-07-14 05:46:09,210 [INFO    ] __main__: train step 7731: loss: 1.1014, policy_loss: 1.2878, value_loss: 0.8234
2024-07-14 05:46:10,841 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:46:11,293 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:46:11,360 [INFO    ] __main__: train step 7732: loss: 1.1014, policy_loss: 1.2877, value_loss: 0.8234
2024-07-14 05:46:11,664 [INFO    ] __main__: train step 7733: loss: 1.1014, policy_loss: 1.2876, value_loss: 0.8233
2024-07-14 05:46:11,943 [INFO    ] __main__: train step 7734: loss: 1.1015, policy_loss: 1.2876, value_loss: 0.8233
2024-07-14 05:46:12,226 [INFO    ] __main__: train step 7735: loss: 1.1015, policy_loss: 1.2875, value_loss: 0.8233
2024-07-14 05:46:12,512 [INFO    ] __main__: train step 7736: loss: 1.1016, policy_loss: 1.2874, value_loss: 0.8233
2024-07-14 05:46:12,800 [INFO    ] __main__: train step 7737: loss: 1.1016, policy_loss: 1.2874, value_loss: 0.8233
2024-07-14 05:46:13,072 [INFO    ] __main__: train step 7738: loss: 1.1017, policy_loss: 1.2873, value_loss: 0.8232
2024-07-14 05:46:13,394 [INFO    ] __main__: train step 7739: loss: 1.1017, policy_loss: 1.2872, value_loss: 0.8232
2024-07-14 05:46:13,685 [INFO    ] __main__: train step 7740: loss: 1.1017, policy_loss: 1.2872, value_loss: 0.8232
2024-07-14 05:46:13,979 [INFO    ] __main__: train step 7741: loss: 1.1018, policy_loss: 1.2871, value_loss: 0.8232
2024-07-14 05:46:14,283 [INFO    ] __main__: train step 7742: loss: 1.1018, policy_loss: 1.2870, value_loss: 0.8231
2024-07-14 05:46:14,570 [INFO    ] __main__: train step 7743: loss: 1.1019, policy_loss: 1.2870, value_loss: 0.8231
2024-07-14 05:46:14,857 [INFO    ] __main__: train step 7744: loss: 1.1019, policy_loss: 1.2869, value_loss: 0.8231
2024-07-14 05:46:15,147 [INFO    ] __main__: train step 7745: loss: 1.1020, policy_loss: 1.2869, value_loss: 0.8231
2024-07-14 05:46:15,426 [INFO    ] __main__: train step 7746: loss: 1.1020, policy_loss: 1.2868, value_loss: 0.8230
2024-07-14 05:46:15,725 [INFO    ] __main__: train step 7747: loss: 1.1020, policy_loss: 1.2867, value_loss: 0.8230
2024-07-14 05:46:16,039 [INFO    ] __main__: train step 7748: loss: 1.1021, policy_loss: 1.2867, value_loss: 0.8230
2024-07-14 05:46:19,375 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:46:19,879 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:46:19,957 [INFO    ] __main__: train step 7749: loss: 1.1021, policy_loss: 1.2866, value_loss: 0.8230
2024-07-14 05:46:20,264 [INFO    ] __main__: train step 7750: loss: 1.1022, policy_loss: 1.2865, value_loss: 0.8230
2024-07-14 05:46:20,574 [INFO    ] __main__: train step 7751: loss: 1.1022, policy_loss: 1.2865, value_loss: 0.8229
2024-07-14 05:46:20,903 [INFO    ] __main__: train step 7752: loss: 1.1023, policy_loss: 1.2864, value_loss: 0.8229
2024-07-14 05:46:21,216 [INFO    ] __main__: train step 7753: loss: 1.1023, policy_loss: 1.2863, value_loss: 0.8229
2024-07-14 05:46:21,523 [INFO    ] __main__: train step 7754: loss: 1.1023, policy_loss: 1.2863, value_loss: 0.8229
2024-07-14 05:46:21,819 [INFO    ] __main__: train step 7755: loss: 1.1024, policy_loss: 1.2862, value_loss: 0.8228
2024-07-14 05:46:22,112 [INFO    ] __main__: train step 7756: loss: 1.1024, policy_loss: 1.2862, value_loss: 0.8228
2024-07-14 05:46:22,426 [INFO    ] __main__: train step 7757: loss: 1.1025, policy_loss: 1.2861, value_loss: 0.8228
2024-07-14 05:46:22,735 [INFO    ] __main__: train step 7758: loss: 1.1025, policy_loss: 1.2860, value_loss: 0.8228
2024-07-14 05:46:23,043 [INFO    ] __main__: train step 7759: loss: 1.1025, policy_loss: 1.2860, value_loss: 0.8227
2024-07-14 05:46:23,344 [INFO    ] __main__: train step 7760: loss: 1.1026, policy_loss: 1.2859, value_loss: 0.8227
2024-07-14 05:46:23,655 [INFO    ] __main__: train step 7761: loss: 1.1026, policy_loss: 1.2858, value_loss: 0.8227
2024-07-14 05:46:23,975 [INFO    ] __main__: train step 7762: loss: 1.1027, policy_loss: 1.2858, value_loss: 0.8227
2024-07-14 05:46:24,281 [INFO    ] __main__: train step 7763: loss: 1.1027, policy_loss: 1.2857, value_loss: 0.8226
2024-07-14 05:46:24,575 [INFO    ] __main__: train step 7764: loss: 1.1027, policy_loss: 1.2857, value_loss: 0.8226
2024-07-14 05:46:24,871 [INFO    ] __main__: train step 7765: loss: 1.1028, policy_loss: 1.2856, value_loss: 0.8226
2024-07-14 05:46:26,510 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:46:26,982 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:46:27,052 [INFO    ] __main__: train step 7766: loss: 1.1028, policy_loss: 1.2855, value_loss: 0.8226
2024-07-14 05:46:27,359 [INFO    ] __main__: train step 7767: loss: 1.1029, policy_loss: 1.2855, value_loss: 0.8225
2024-07-14 05:46:27,658 [INFO    ] __main__: train step 7768: loss: 1.1029, policy_loss: 1.2854, value_loss: 0.8225
2024-07-14 05:46:27,971 [INFO    ] __main__: train step 7769: loss: 1.1030, policy_loss: 1.2853, value_loss: 0.8225
2024-07-14 05:46:28,279 [INFO    ] __main__: train step 7770: loss: 1.1030, policy_loss: 1.2853, value_loss: 0.8225
2024-07-14 05:46:28,556 [INFO    ] __main__: train step 7771: loss: 1.1030, policy_loss: 1.2852, value_loss: 0.8224
2024-07-14 05:46:28,846 [INFO    ] __main__: train step 7772: loss: 1.1031, policy_loss: 1.2851, value_loss: 0.8224
2024-07-14 05:46:29,152 [INFO    ] __main__: train step 7773: loss: 1.1031, policy_loss: 1.2851, value_loss: 0.8224
2024-07-14 05:46:29,466 [INFO    ] __main__: train step 7774: loss: 1.1032, policy_loss: 1.2850, value_loss: 0.8224
2024-07-14 05:46:29,800 [INFO    ] __main__: train step 7775: loss: 1.1032, policy_loss: 1.2850, value_loss: 0.8224
2024-07-14 05:46:30,100 [INFO    ] __main__: train step 7776: loss: 1.1033, policy_loss: 1.2849, value_loss: 0.8223
2024-07-14 05:46:30,393 [INFO    ] __main__: train step 7777: loss: 1.1033, policy_loss: 1.2848, value_loss: 0.8223
2024-07-14 05:46:30,694 [INFO    ] __main__: train step 7778: loss: 1.1033, policy_loss: 1.2848, value_loss: 0.8223
2024-07-14 05:46:31,007 [INFO    ] __main__: train step 7779: loss: 1.1034, policy_loss: 1.2847, value_loss: 0.8223
2024-07-14 05:46:31,313 [INFO    ] __main__: train step 7780: loss: 1.1034, policy_loss: 1.2846, value_loss: 0.8222
2024-07-14 05:46:31,621 [INFO    ] __main__: train step 7781: loss: 1.1035, policy_loss: 1.2846, value_loss: 0.8222
2024-07-14 05:46:31,926 [INFO    ] __main__: train step 7782: loss: 1.1035, policy_loss: 1.2845, value_loss: 0.8222
2024-07-14 05:46:33,568 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:46:34,062 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:46:34,136 [INFO    ] __main__: train step 7783: loss: 1.1035, policy_loss: 1.2845, value_loss: 0.8222
2024-07-14 05:46:34,422 [INFO    ] __main__: train step 7784: loss: 1.1036, policy_loss: 1.2844, value_loss: 0.8221
2024-07-14 05:46:34,718 [INFO    ] __main__: train step 7785: loss: 1.1036, policy_loss: 1.2843, value_loss: 0.8221
2024-07-14 05:46:35,007 [INFO    ] __main__: train step 7786: loss: 1.1037, policy_loss: 1.2843, value_loss: 0.8221
2024-07-14 05:46:35,292 [INFO    ] __main__: train step 7787: loss: 1.1037, policy_loss: 1.2842, value_loss: 0.8221
2024-07-14 05:46:35,584 [INFO    ] __main__: train step 7788: loss: 1.1037, policy_loss: 1.2841, value_loss: 0.8220
2024-07-14 05:46:35,890 [INFO    ] __main__: train step 7789: loss: 1.1038, policy_loss: 1.2841, value_loss: 0.8220
2024-07-14 05:46:36,191 [INFO    ] __main__: train step 7790: loss: 1.1038, policy_loss: 1.2840, value_loss: 0.8220
2024-07-14 05:46:36,496 [INFO    ] __main__: train step 7791: loss: 1.1039, policy_loss: 1.2839, value_loss: 0.8220
2024-07-14 05:46:36,806 [INFO    ] __main__: train step 7792: loss: 1.1039, policy_loss: 1.2839, value_loss: 0.8220
2024-07-14 05:46:37,122 [INFO    ] __main__: train step 7793: loss: 1.1040, policy_loss: 1.2838, value_loss: 0.8219
2024-07-14 05:46:37,430 [INFO    ] __main__: train step 7794: loss: 1.1040, policy_loss: 1.2838, value_loss: 0.8219
2024-07-14 05:46:37,737 [INFO    ] __main__: train step 7795: loss: 1.1040, policy_loss: 1.2837, value_loss: 0.8219
2024-07-14 05:46:38,037 [INFO    ] __main__: train step 7796: loss: 1.1041, policy_loss: 1.2836, value_loss: 0.8219
2024-07-14 05:46:38,332 [INFO    ] __main__: train step 7797: loss: 1.1041, policy_loss: 1.2836, value_loss: 0.8218
2024-07-14 05:46:38,631 [INFO    ] __main__: train step 7798: loss: 1.1042, policy_loss: 1.2835, value_loss: 0.8218
2024-07-14 05:46:38,915 [INFO    ] __main__: train step 7799: loss: 1.1042, policy_loss: 1.2834, value_loss: 0.8218
2024-07-14 05:46:40,547 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:46:41,034 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:46:41,104 [INFO    ] __main__: train step 7800: loss: 1.1042, policy_loss: 1.2834, value_loss: 0.8218
2024-07-14 05:46:41,402 [INFO    ] __main__: train step 7801: loss: 1.1043, policy_loss: 1.2833, value_loss: 0.8217
2024-07-14 05:46:41,673 [INFO    ] __main__: train step 7802: loss: 1.1043, policy_loss: 1.2832, value_loss: 0.8217
2024-07-14 05:46:41,949 [INFO    ] __main__: train step 7803: loss: 1.1044, policy_loss: 1.2832, value_loss: 0.8217
2024-07-14 05:46:44,017 [INFO    ] __main__: train step 7804: loss: 1.1044, policy_loss: 1.2831, value_loss: 0.8217
2024-07-14 05:46:44,309 [INFO    ] __main__: train step 7805: loss: 1.1044, policy_loss: 1.2831, value_loss: 0.8216
2024-07-14 05:46:44,597 [INFO    ] __main__: train step 7806: loss: 1.1045, policy_loss: 1.2830, value_loss: 0.8216
2024-07-14 05:46:44,899 [INFO    ] __main__: train step 7807: loss: 1.1045, policy_loss: 1.2829, value_loss: 0.8216
2024-07-14 05:46:45,205 [INFO    ] __main__: train step 7808: loss: 1.1046, policy_loss: 1.2829, value_loss: 0.8216
2024-07-14 05:46:45,521 [INFO    ] __main__: train step 7809: loss: 1.1046, policy_loss: 1.2828, value_loss: 0.8215
2024-07-14 05:46:45,826 [INFO    ] __main__: train step 7810: loss: 1.1046, policy_loss: 1.2827, value_loss: 0.8215
2024-07-14 05:46:46,141 [INFO    ] __main__: train step 7811: loss: 1.1047, policy_loss: 1.2827, value_loss: 0.8215
2024-07-14 05:46:46,451 [INFO    ] __main__: train step 7812: loss: 1.1047, policy_loss: 1.2826, value_loss: 0.8215
2024-07-14 05:46:46,729 [INFO    ] __main__: train step 7813: loss: 1.1048, policy_loss: 1.2825, value_loss: 0.8215
2024-07-14 05:46:47,007 [INFO    ] __main__: train step 7814: loss: 1.1048, policy_loss: 1.2825, value_loss: 0.8214
2024-07-14 05:46:47,287 [INFO    ] __main__: train step 7815: loss: 1.1049, policy_loss: 1.2824, value_loss: 0.8214
2024-07-14 05:46:47,579 [INFO    ] __main__: train step 7816: loss: 1.1049, policy_loss: 1.2824, value_loss: 0.8214
2024-07-14 05:46:49,213 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:46:49,694 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:46:49,764 [INFO    ] __main__: train step 7817: loss: 1.1049, policy_loss: 1.2823, value_loss: 0.8214
2024-07-14 05:46:50,073 [INFO    ] __main__: train step 7818: loss: 1.1050, policy_loss: 1.2822, value_loss: 0.8213
2024-07-14 05:46:50,376 [INFO    ] __main__: train step 7819: loss: 1.1050, policy_loss: 1.2822, value_loss: 0.8213
2024-07-14 05:46:50,679 [INFO    ] __main__: train step 7820: loss: 1.1051, policy_loss: 1.2821, value_loss: 0.8213
2024-07-14 05:46:50,992 [INFO    ] __main__: train step 7821: loss: 1.1051, policy_loss: 1.2821, value_loss: 0.8213
2024-07-14 05:46:51,304 [INFO    ] __main__: train step 7822: loss: 1.1051, policy_loss: 1.2820, value_loss: 0.8212
2024-07-14 05:46:51,583 [INFO    ] __main__: train step 7823: loss: 1.1052, policy_loss: 1.2819, value_loss: 0.8212
2024-07-14 05:46:51,890 [INFO    ] __main__: train step 7824: loss: 1.1052, policy_loss: 1.2819, value_loss: 0.8212
2024-07-14 05:46:52,195 [INFO    ] __main__: train step 7825: loss: 1.1053, policy_loss: 1.2818, value_loss: 0.8212
2024-07-14 05:46:52,504 [INFO    ] __main__: train step 7826: loss: 1.1053, policy_loss: 1.2817, value_loss: 0.8212
2024-07-14 05:46:52,817 [INFO    ] __main__: train step 7827: loss: 1.1053, policy_loss: 1.2817, value_loss: 0.8211
2024-07-14 05:46:53,105 [INFO    ] __main__: train step 7828: loss: 1.1054, policy_loss: 1.2816, value_loss: 0.8211
2024-07-14 05:46:53,408 [INFO    ] __main__: train step 7829: loss: 1.1054, policy_loss: 1.2815, value_loss: 0.8211
2024-07-14 05:46:53,706 [INFO    ] __main__: train step 7830: loss: 1.1055, policy_loss: 1.2815, value_loss: 0.8211
2024-07-14 05:46:54,015 [INFO    ] __main__: train step 7831: loss: 1.1055, policy_loss: 1.2814, value_loss: 0.8210
2024-07-14 05:46:54,323 [INFO    ] __main__: train step 7832: loss: 1.1056, policy_loss: 1.2814, value_loss: 0.8210
2024-07-14 05:46:54,623 [INFO    ] __main__: train step 7833: loss: 1.1056, policy_loss: 1.2813, value_loss: 0.8210
2024-07-14 05:46:56,246 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:46:56,734 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:46:56,804 [INFO    ] __main__: train step 7834: loss: 1.1056, policy_loss: 1.2812, value_loss: 0.8210
2024-07-14 05:46:57,119 [INFO    ] __main__: train step 7835: loss: 1.1057, policy_loss: 1.2812, value_loss: 0.8209
2024-07-14 05:46:57,421 [INFO    ] __main__: train step 7836: loss: 1.1057, policy_loss: 1.2811, value_loss: 0.8209
2024-07-14 05:46:57,716 [INFO    ] __main__: train step 7837: loss: 1.1058, policy_loss: 1.2810, value_loss: 0.8209
2024-07-14 05:46:58,007 [INFO    ] __main__: train step 7838: loss: 1.1058, policy_loss: 1.2810, value_loss: 0.8209
2024-07-14 05:46:58,309 [INFO    ] __main__: train step 7839: loss: 1.1058, policy_loss: 1.2809, value_loss: 0.8209
2024-07-14 05:46:58,595 [INFO    ] __main__: train step 7840: loss: 1.1059, policy_loss: 1.2809, value_loss: 0.8208
2024-07-14 05:46:58,903 [INFO    ] __main__: train step 7841: loss: 1.1059, policy_loss: 1.2808, value_loss: 0.8208
2024-07-14 05:46:59,204 [INFO    ] __main__: train step 7842: loss: 1.1059, policy_loss: 1.2807, value_loss: 0.8208
2024-07-14 05:46:59,518 [INFO    ] __main__: train step 7843: loss: 1.1060, policy_loss: 1.2807, value_loss: 0.8208
2024-07-14 05:46:59,874 [INFO    ] __main__: train step 7844: loss: 1.1060, policy_loss: 1.2806, value_loss: 0.8207
2024-07-14 05:47:00,180 [INFO    ] __main__: train step 7845: loss: 1.1061, policy_loss: 1.2805, value_loss: 0.8207
2024-07-14 05:47:00,486 [INFO    ] __main__: train step 7846: loss: 1.1061, policy_loss: 1.2805, value_loss: 0.8207
2024-07-14 05:47:00,831 [INFO    ] __main__: train step 7847: loss: 1.1061, policy_loss: 1.2804, value_loss: 0.8207
2024-07-14 05:47:01,128 [INFO    ] __main__: train step 7848: loss: 1.1062, policy_loss: 1.2803, value_loss: 0.8206
2024-07-14 05:47:01,408 [INFO    ] __main__: train step 7849: loss: 1.1062, policy_loss: 1.2803, value_loss: 0.8206
2024-07-14 05:47:01,687 [INFO    ] __main__: train step 7850: loss: 1.1063, policy_loss: 1.2802, value_loss: 0.8206
2024-07-14 05:47:03,335 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:47:03,822 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:47:03,897 [INFO    ] __main__: train step 7851: loss: 1.1063, policy_loss: 1.2802, value_loss: 0.8206
2024-07-14 05:47:04,205 [INFO    ] __main__: train step 7852: loss: 1.1063, policy_loss: 1.2801, value_loss: 0.8205
2024-07-14 05:47:04,504 [INFO    ] __main__: train step 7853: loss: 1.1064, policy_loss: 1.2800, value_loss: 0.8205
2024-07-14 05:47:04,798 [INFO    ] __main__: train step 7854: loss: 1.1064, policy_loss: 1.2800, value_loss: 0.8205
2024-07-14 05:47:05,094 [INFO    ] __main__: train step 7855: loss: 1.1065, policy_loss: 1.2799, value_loss: 0.8205
2024-07-14 05:47:05,400 [INFO    ] __main__: train step 7856: loss: 1.1065, policy_loss: 1.2798, value_loss: 0.8205
2024-07-14 05:47:05,691 [INFO    ] __main__: train step 7857: loss: 1.1065, policy_loss: 1.2798, value_loss: 0.8204
2024-07-14 05:47:05,988 [INFO    ] __main__: train step 7858: loss: 1.1066, policy_loss: 1.2797, value_loss: 0.8204
2024-07-14 05:47:07,603 [INFO    ] __main__: train step 7859: loss: 1.1066, policy_loss: 1.2796, value_loss: 0.8204
2024-07-14 05:47:07,898 [INFO    ] __main__: train step 7860: loss: 1.1067, policy_loss: 1.2796, value_loss: 0.8204
2024-07-14 05:47:08,192 [INFO    ] __main__: train step 7861: loss: 1.1067, policy_loss: 1.2795, value_loss: 0.8203
2024-07-14 05:47:08,491 [INFO    ] __main__: train step 7862: loss: 1.1067, policy_loss: 1.2795, value_loss: 0.8203
2024-07-14 05:47:08,803 [INFO    ] __main__: train step 7863: loss: 1.1068, policy_loss: 1.2794, value_loss: 0.8203
2024-07-14 05:47:09,101 [INFO    ] __main__: train step 7864: loss: 1.1068, policy_loss: 1.2793, value_loss: 0.8203
2024-07-14 05:47:09,408 [INFO    ] __main__: train step 7865: loss: 1.1069, policy_loss: 1.2793, value_loss: 0.8202
2024-07-14 05:47:09,705 [INFO    ] __main__: train step 7866: loss: 1.1069, policy_loss: 1.2792, value_loss: 0.8202
2024-07-14 05:47:10,012 [INFO    ] __main__: train step 7867: loss: 1.1069, policy_loss: 1.2791, value_loss: 0.8202
2024-07-14 05:47:11,636 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:47:12,153 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:47:12,228 [INFO    ] __main__: train step 7868: loss: 1.1070, policy_loss: 1.2791, value_loss: 0.8202
2024-07-14 05:47:12,568 [INFO    ] __main__: train step 7869: loss: 1.1070, policy_loss: 1.2790, value_loss: 0.8201
2024-07-14 05:47:12,875 [INFO    ] __main__: train step 7870: loss: 1.1070, policy_loss: 1.2789, value_loss: 0.8201
2024-07-14 05:47:13,168 [INFO    ] __main__: train step 7871: loss: 1.1071, policy_loss: 1.2789, value_loss: 0.8201
2024-07-14 05:47:13,468 [INFO    ] __main__: train step 7872: loss: 1.1071, policy_loss: 1.2788, value_loss: 0.8201
2024-07-14 05:47:13,769 [INFO    ] __main__: train step 7873: loss: 1.1072, policy_loss: 1.2788, value_loss: 0.8200
2024-07-14 05:47:14,088 [INFO    ] __main__: train step 7874: loss: 1.1072, policy_loss: 1.2787, value_loss: 0.8200
2024-07-14 05:47:14,401 [INFO    ] __main__: train step 7875: loss: 1.1072, policy_loss: 1.2786, value_loss: 0.8200
2024-07-14 05:47:14,755 [INFO    ] __main__: train step 7876: loss: 1.1073, policy_loss: 1.2786, value_loss: 0.8200
2024-07-14 05:47:15,090 [INFO    ] __main__: train step 7877: loss: 1.1073, policy_loss: 1.2785, value_loss: 0.8200
2024-07-14 05:47:15,399 [INFO    ] __main__: train step 7878: loss: 1.1073, policy_loss: 1.2784, value_loss: 0.8199
2024-07-14 05:47:15,703 [INFO    ] __main__: train step 7879: loss: 1.1074, policy_loss: 1.2784, value_loss: 0.8199
2024-07-14 05:47:16,013 [INFO    ] __main__: train step 7880: loss: 1.1074, policy_loss: 1.2783, value_loss: 0.8199
2024-07-14 05:47:16,314 [INFO    ] __main__: train step 7881: loss: 1.1075, policy_loss: 1.2783, value_loss: 0.8199
2024-07-14 05:47:16,631 [INFO    ] __main__: train step 7882: loss: 1.1075, policy_loss: 1.2782, value_loss: 0.8198
2024-07-14 05:47:16,939 [INFO    ] __main__: train step 7883: loss: 1.1075, policy_loss: 1.2781, value_loss: 0.8198
2024-07-14 05:47:17,241 [INFO    ] __main__: train step 7884: loss: 1.1076, policy_loss: 1.2781, value_loss: 0.8198
2024-07-14 05:47:18,861 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:47:19,356 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:47:19,434 [INFO    ] __main__: train step 7885: loss: 1.1076, policy_loss: 1.2780, value_loss: 0.8198
2024-07-14 05:47:19,739 [INFO    ] __main__: train step 7886: loss: 1.1077, policy_loss: 1.2779, value_loss: 0.8197
2024-07-14 05:47:20,047 [INFO    ] __main__: train step 7887: loss: 1.1077, policy_loss: 1.2779, value_loss: 0.8197
2024-07-14 05:47:20,321 [INFO    ] __main__: train step 7888: loss: 1.1077, policy_loss: 1.2778, value_loss: 0.8197
2024-07-14 05:47:20,633 [INFO    ] __main__: train step 7889: loss: 1.1078, policy_loss: 1.2777, value_loss: 0.8197
2024-07-14 05:47:20,946 [INFO    ] __main__: train step 7890: loss: 1.1078, policy_loss: 1.2777, value_loss: 0.8196
2024-07-14 05:47:21,247 [INFO    ] __main__: train step 7891: loss: 1.1078, policy_loss: 1.2776, value_loss: 0.8196
2024-07-14 05:47:21,564 [INFO    ] __main__: train step 7892: loss: 1.1079, policy_loss: 1.2776, value_loss: 0.8196
2024-07-14 05:47:21,866 [INFO    ] __main__: train step 7893: loss: 1.1079, policy_loss: 1.2775, value_loss: 0.8196
2024-07-14 05:47:22,170 [INFO    ] __main__: train step 7894: loss: 1.1080, policy_loss: 1.2774, value_loss: 0.8195
2024-07-14 05:47:22,479 [INFO    ] __main__: train step 7895: loss: 1.1080, policy_loss: 1.2774, value_loss: 0.8195
2024-07-14 05:47:22,795 [INFO    ] __main__: train step 7896: loss: 1.1080, policy_loss: 1.2773, value_loss: 0.8195
2024-07-14 05:47:23,094 [INFO    ] __main__: train step 7897: loss: 1.1081, policy_loss: 1.2772, value_loss: 0.8195
2024-07-14 05:47:23,393 [INFO    ] __main__: train step 7898: loss: 1.1081, policy_loss: 1.2772, value_loss: 0.8195
2024-07-14 05:47:23,682 [INFO    ] __main__: train step 7899: loss: 1.1081, policy_loss: 1.2771, value_loss: 0.8194
2024-07-14 05:47:23,987 [INFO    ] __main__: train step 7900: loss: 1.1082, policy_loss: 1.2771, value_loss: 0.8194
2024-07-14 05:47:24,288 [INFO    ] __main__: train step 7901: loss: 1.1082, policy_loss: 1.2770, value_loss: 0.8194
2024-07-14 05:47:25,895 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:47:26,383 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:47:26,457 [INFO    ] __main__: train step 7902: loss: 1.1083, policy_loss: 1.2769, value_loss: 0.8194
2024-07-14 05:47:26,757 [INFO    ] __main__: train step 7903: loss: 1.1083, policy_loss: 1.2769, value_loss: 0.8193
2024-07-14 05:47:27,051 [INFO    ] __main__: train step 7904: loss: 1.1083, policy_loss: 1.2768, value_loss: 0.8193
2024-07-14 05:47:27,351 [INFO    ] __main__: train step 7905: loss: 1.1084, policy_loss: 1.2767, value_loss: 0.8193
2024-07-14 05:47:27,656 [INFO    ] __main__: train step 7906: loss: 1.1084, policy_loss: 1.2767, value_loss: 0.8193
2024-07-14 05:47:27,929 [INFO    ] __main__: train step 7907: loss: 1.1084, policy_loss: 1.2766, value_loss: 0.8192
2024-07-14 05:47:28,212 [INFO    ] __main__: train step 7908: loss: 1.1085, policy_loss: 1.2765, value_loss: 0.8192
2024-07-14 05:47:28,501 [INFO    ] __main__: train step 7909: loss: 1.1085, policy_loss: 1.2765, value_loss: 0.8192
2024-07-14 05:47:28,800 [INFO    ] __main__: train step 7910: loss: 1.1086, policy_loss: 1.2764, value_loss: 0.8192
2024-07-14 05:47:29,094 [INFO    ] __main__: train step 7911: loss: 1.1086, policy_loss: 1.2764, value_loss: 0.8191
2024-07-14 05:47:29,404 [INFO    ] __main__: train step 7912: loss: 1.1086, policy_loss: 1.2763, value_loss: 0.8191
2024-07-14 05:47:29,699 [INFO    ] __main__: train step 7913: loss: 1.1087, policy_loss: 1.2762, value_loss: 0.8191
2024-07-14 05:47:31,610 [INFO    ] __main__: train step 7914: loss: 1.1087, policy_loss: 1.2762, value_loss: 0.8191
2024-07-14 05:47:31,910 [INFO    ] __main__: train step 7915: loss: 1.1087, policy_loss: 1.2761, value_loss: 0.8190
2024-07-14 05:47:32,202 [INFO    ] __main__: train step 7916: loss: 1.1088, policy_loss: 1.2760, value_loss: 0.8190
2024-07-14 05:47:32,496 [INFO    ] __main__: train step 7917: loss: 1.1088, policy_loss: 1.2760, value_loss: 0.8190
2024-07-14 05:47:32,791 [INFO    ] __main__: train step 7918: loss: 1.1089, policy_loss: 1.2759, value_loss: 0.8190
2024-07-14 05:47:34,398 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:47:34,890 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:47:34,963 [INFO    ] __main__: train step 7919: loss: 1.1089, policy_loss: 1.2758, value_loss: 0.8189
2024-07-14 05:47:35,259 [INFO    ] __main__: train step 7920: loss: 1.1089, policy_loss: 1.2758, value_loss: 0.8189
2024-07-14 05:47:35,548 [INFO    ] __main__: train step 7921: loss: 1.1090, policy_loss: 1.2757, value_loss: 0.8189
2024-07-14 05:47:35,849 [INFO    ] __main__: train step 7922: loss: 1.1090, policy_loss: 1.2757, value_loss: 0.8189
2024-07-14 05:47:36,144 [INFO    ] __main__: train step 7923: loss: 1.1090, policy_loss: 1.2756, value_loss: 0.8188
2024-07-14 05:47:36,445 [INFO    ] __main__: train step 7924: loss: 1.1091, policy_loss: 1.2755, value_loss: 0.8188
2024-07-14 05:47:36,743 [INFO    ] __main__: train step 7925: loss: 1.1091, policy_loss: 1.2755, value_loss: 0.8188
2024-07-14 05:47:37,019 [INFO    ] __main__: train step 7926: loss: 1.1091, policy_loss: 1.2754, value_loss: 0.8188
2024-07-14 05:47:37,318 [INFO    ] __main__: train step 7927: loss: 1.1092, policy_loss: 1.2754, value_loss: 0.8187
2024-07-14 05:47:37,618 [INFO    ] __main__: train step 7928: loss: 1.1092, policy_loss: 1.2753, value_loss: 0.8187
2024-07-14 05:47:37,922 [INFO    ] __main__: train step 7929: loss: 1.1093, policy_loss: 1.2752, value_loss: 0.8187
2024-07-14 05:47:38,221 [INFO    ] __main__: train step 7930: loss: 1.1093, policy_loss: 1.2752, value_loss: 0.8187
2024-07-14 05:47:38,525 [INFO    ] __main__: train step 7931: loss: 1.1093, policy_loss: 1.2751, value_loss: 0.8186
2024-07-14 05:47:38,820 [INFO    ] __main__: train step 7932: loss: 1.1094, policy_loss: 1.2750, value_loss: 0.8186
2024-07-14 05:47:39,114 [INFO    ] __main__: train step 7933: loss: 1.1094, policy_loss: 1.2750, value_loss: 0.8186
2024-07-14 05:47:39,413 [INFO    ] __main__: train step 7934: loss: 1.1094, policy_loss: 1.2749, value_loss: 0.8186
2024-07-14 05:47:39,708 [INFO    ] __main__: train step 7935: loss: 1.1095, policy_loss: 1.2748, value_loss: 0.8185
2024-07-14 05:47:41,354 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:47:41,844 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:47:41,919 [INFO    ] __main__: train step 7936: loss: 1.1095, policy_loss: 1.2748, value_loss: 0.8185
2024-07-14 05:47:42,198 [INFO    ] __main__: train step 7937: loss: 1.1095, policy_loss: 1.2747, value_loss: 0.8185
2024-07-14 05:47:42,490 [INFO    ] __main__: train step 7938: loss: 1.1096, policy_loss: 1.2747, value_loss: 0.8185
2024-07-14 05:47:42,786 [INFO    ] __main__: train step 7939: loss: 1.1096, policy_loss: 1.2746, value_loss: 0.8184
2024-07-14 05:47:43,084 [INFO    ] __main__: train step 7940: loss: 1.1096, policy_loss: 1.2745, value_loss: 0.8184
2024-07-14 05:47:43,387 [INFO    ] __main__: train step 7941: loss: 1.1097, policy_loss: 1.2745, value_loss: 0.8184
2024-07-14 05:47:43,679 [INFO    ] __main__: train step 7942: loss: 1.1097, policy_loss: 1.2744, value_loss: 0.8184
2024-07-14 05:47:43,996 [INFO    ] __main__: train step 7943: loss: 1.1097, policy_loss: 1.2743, value_loss: 0.8184
2024-07-14 05:47:44,320 [INFO    ] __main__: train step 7944: loss: 1.1098, policy_loss: 1.2743, value_loss: 0.8183
2024-07-14 05:47:44,622 [INFO    ] __main__: train step 7945: loss: 1.1098, policy_loss: 1.2742, value_loss: 0.8183
2024-07-14 05:47:44,927 [INFO    ] __main__: train step 7946: loss: 1.1099, policy_loss: 1.2741, value_loss: 0.8183
2024-07-14 05:47:45,223 [INFO    ] __main__: train step 7947: loss: 1.1099, policy_loss: 1.2741, value_loss: 0.8183
2024-07-14 05:47:45,519 [INFO    ] __main__: train step 7948: loss: 1.1099, policy_loss: 1.2740, value_loss: 0.8182
2024-07-14 05:47:45,798 [INFO    ] __main__: train step 7949: loss: 1.1100, policy_loss: 1.2740, value_loss: 0.8182
2024-07-14 05:47:46,105 [INFO    ] __main__: train step 7950: loss: 1.1100, policy_loss: 1.2739, value_loss: 0.8182
2024-07-14 05:47:46,401 [INFO    ] __main__: train step 7951: loss: 1.1100, policy_loss: 1.2738, value_loss: 0.8182
2024-07-14 05:47:46,698 [INFO    ] __main__: train step 7952: loss: 1.1101, policy_loss: 1.2738, value_loss: 0.8181
2024-07-14 05:47:48,332 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:47:48,824 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:47:48,897 [INFO    ] __main__: train step 7953: loss: 1.1101, policy_loss: 1.2737, value_loss: 0.8181
2024-07-14 05:47:49,202 [INFO    ] __main__: train step 7954: loss: 1.1101, policy_loss: 1.2736, value_loss: 0.8181
2024-07-14 05:47:49,498 [INFO    ] __main__: train step 7955: loss: 1.1102, policy_loss: 1.2736, value_loss: 0.8181
2024-07-14 05:47:49,807 [INFO    ] __main__: train step 7956: loss: 1.1102, policy_loss: 1.2735, value_loss: 0.8180
2024-07-14 05:47:50,102 [INFO    ] __main__: train step 7957: loss: 1.1102, policy_loss: 1.2735, value_loss: 0.8180
2024-07-14 05:47:50,405 [INFO    ] __main__: train step 7958: loss: 1.1103, policy_loss: 1.2734, value_loss: 0.8180
2024-07-14 05:47:50,705 [INFO    ] __main__: train step 7959: loss: 1.1103, policy_loss: 1.2733, value_loss: 0.8180
2024-07-14 05:47:51,006 [INFO    ] __main__: train step 7960: loss: 1.1103, policy_loss: 1.2733, value_loss: 0.8179
2024-07-14 05:47:51,300 [INFO    ] __main__: train step 7961: loss: 1.1104, policy_loss: 1.2732, value_loss: 0.8179
2024-07-14 05:47:51,618 [INFO    ] __main__: train step 7962: loss: 1.1104, policy_loss: 1.2731, value_loss: 0.8179
2024-07-14 05:47:51,925 [INFO    ] __main__: train step 7963: loss: 1.1104, policy_loss: 1.2731, value_loss: 0.8179
2024-07-14 05:47:52,224 [INFO    ] __main__: train step 7964: loss: 1.1105, policy_loss: 1.2730, value_loss: 0.8178
2024-07-14 05:47:52,518 [INFO    ] __main__: train step 7965: loss: 1.1105, policy_loss: 1.2729, value_loss: 0.8178
2024-07-14 05:47:52,823 [INFO    ] __main__: train step 7966: loss: 1.1105, policy_loss: 1.2729, value_loss: 0.8178
2024-07-14 05:47:53,088 [INFO    ] __main__: train step 7967: loss: 1.1106, policy_loss: 1.2728, value_loss: 0.8178
2024-07-14 05:47:55,660 [INFO    ] __main__: train step 7968: loss: 1.1106, policy_loss: 1.2727, value_loss: 0.8177
2024-07-14 05:47:55,960 [INFO    ] __main__: train step 7969: loss: 1.1107, policy_loss: 1.2727, value_loss: 0.8177
2024-07-14 05:47:57,594 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:47:58,087 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:47:58,158 [INFO    ] __main__: train step 7970: loss: 1.1107, policy_loss: 1.2726, value_loss: 0.8177
2024-07-14 05:47:58,430 [INFO    ] __main__: train step 7971: loss: 1.1107, policy_loss: 1.2726, value_loss: 0.8177
2024-07-14 05:47:58,700 [INFO    ] __main__: train step 7972: loss: 1.1108, policy_loss: 1.2725, value_loss: 0.8176
2024-07-14 05:47:58,977 [INFO    ] __main__: train step 7973: loss: 1.1108, policy_loss: 1.2724, value_loss: 0.8176
2024-07-14 05:47:59,246 [INFO    ] __main__: train step 7974: loss: 1.1108, policy_loss: 1.2724, value_loss: 0.8176
2024-07-14 05:47:59,536 [INFO    ] __main__: train step 7975: loss: 1.1109, policy_loss: 1.2723, value_loss: 0.8176
2024-07-14 05:47:59,838 [INFO    ] __main__: train step 7976: loss: 1.1109, policy_loss: 1.2722, value_loss: 0.8175
2024-07-14 05:48:00,125 [INFO    ] __main__: train step 7977: loss: 1.1109, policy_loss: 1.2722, value_loss: 0.8175
2024-07-14 05:48:00,396 [INFO    ] __main__: train step 7978: loss: 1.1110, policy_loss: 1.2721, value_loss: 0.8175
2024-07-14 05:48:00,652 [INFO    ] __main__: train step 7979: loss: 1.1110, policy_loss: 1.2720, value_loss: 0.8175
2024-07-14 05:48:00,910 [INFO    ] __main__: train step 7980: loss: 1.1110, policy_loss: 1.2720, value_loss: 0.8174
2024-07-14 05:48:01,185 [INFO    ] __main__: train step 7981: loss: 1.1111, policy_loss: 1.2719, value_loss: 0.8174
2024-07-14 05:48:01,476 [INFO    ] __main__: train step 7982: loss: 1.1111, policy_loss: 1.2719, value_loss: 0.8174
2024-07-14 05:48:01,770 [INFO    ] __main__: train step 7983: loss: 1.1111, policy_loss: 1.2718, value_loss: 0.8174
2024-07-14 05:48:02,062 [INFO    ] __main__: train step 7984: loss: 1.1112, policy_loss: 1.2717, value_loss: 0.8173
2024-07-14 05:48:02,364 [INFO    ] __main__: train step 7985: loss: 1.1112, policy_loss: 1.2717, value_loss: 0.8173
2024-07-14 05:48:02,663 [INFO    ] __main__: train step 7986: loss: 1.1112, policy_loss: 1.2716, value_loss: 0.8173
2024-07-14 05:48:04,298 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:48:04,811 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:48:04,883 [INFO    ] __main__: train step 7987: loss: 1.1113, policy_loss: 1.2715, value_loss: 0.8173
2024-07-14 05:48:05,191 [INFO    ] __main__: train step 7988: loss: 1.1113, policy_loss: 1.2715, value_loss: 0.8172
2024-07-14 05:48:05,491 [INFO    ] __main__: train step 7989: loss: 1.1113, policy_loss: 1.2714, value_loss: 0.8172
2024-07-14 05:48:05,798 [INFO    ] __main__: train step 7990: loss: 1.1114, policy_loss: 1.2713, value_loss: 0.8172
2024-07-14 05:48:06,093 [INFO    ] __main__: train step 7991: loss: 1.1114, policy_loss: 1.2713, value_loss: 0.8172
2024-07-14 05:48:06,396 [INFO    ] __main__: train step 7992: loss: 1.1114, policy_loss: 1.2712, value_loss: 0.8171
2024-07-14 05:48:06,692 [INFO    ] __main__: train step 7993: loss: 1.1115, policy_loss: 1.2712, value_loss: 0.8171
2024-07-14 05:48:06,999 [INFO    ] __main__: train step 7994: loss: 1.1115, policy_loss: 1.2711, value_loss: 0.8171
2024-07-14 05:48:07,296 [INFO    ] __main__: train step 7995: loss: 1.1115, policy_loss: 1.2710, value_loss: 0.8171
2024-07-14 05:48:07,590 [INFO    ] __main__: train step 7996: loss: 1.1116, policy_loss: 1.2710, value_loss: 0.8170
2024-07-14 05:48:07,891 [INFO    ] __main__: train step 7997: loss: 1.1116, policy_loss: 1.2709, value_loss: 0.8170
2024-07-14 05:48:08,185 [INFO    ] __main__: train step 7998: loss: 1.1116, policy_loss: 1.2708, value_loss: 0.8170
2024-07-14 05:48:08,482 [INFO    ] __main__: train step 7999: loss: 1.1117, policy_loss: 1.2708, value_loss: 0.8170
2024-07-14 05:48:08,781 [INFO    ] __main__: train step 8000: loss: 1.1117, policy_loss: 1.2707, value_loss: 0.8169
2024-07-14 05:48:08,952 [INFO    ] __main__: restored step 7000 for evaluation
2024-07-14 05:48:14,203 [INFO    ] __main__: test network ELO difference from baseline network: +208 (+8/-8) ELO from 32000 self-played games
2024-07-14 05:48:14,206 [INFO    ] __main__: game outcomes: W: 22984, D: 938, L: 8078
2024-07-14 05:48:14,209 [INFO    ] __main__: validation_elo_delta: 208, validation_elo: 1814
2024-07-14 05:48:14,992 [INFO    ] __main__: train step 8001: loss: 1.1117, policy_loss: 1.2706, value_loss: 0.8169
2024-07-14 05:48:15,289 [INFO    ] __main__: train step 8002: loss: 1.1118, policy_loss: 1.2706, value_loss: 0.8169
2024-07-14 05:48:15,585 [INFO    ] __main__: train step 8003: loss: 1.1118, policy_loss: 1.2705, value_loss: 0.8169
2024-07-14 05:48:17,189 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:48:17,683 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:48:17,753 [INFO    ] __main__: train step 8004: loss: 1.1118, policy_loss: 1.2705, value_loss: 0.8168
2024-07-14 05:48:18,049 [INFO    ] __main__: train step 8005: loss: 1.1119, policy_loss: 1.2704, value_loss: 0.8168
2024-07-14 05:48:18,346 [INFO    ] __main__: train step 8006: loss: 1.1119, policy_loss: 1.2703, value_loss: 0.8168
2024-07-14 05:48:18,648 [INFO    ] __main__: train step 8007: loss: 1.1119, policy_loss: 1.2703, value_loss: 0.8168
2024-07-14 05:48:18,952 [INFO    ] __main__: train step 8008: loss: 1.1120, policy_loss: 1.2702, value_loss: 0.8167
2024-07-14 05:48:19,250 [INFO    ] __main__: train step 8009: loss: 1.1120, policy_loss: 1.2701, value_loss: 0.8167
2024-07-14 05:48:19,558 [INFO    ] __main__: train step 8010: loss: 1.1120, policy_loss: 1.2701, value_loss: 0.8167
2024-07-14 05:48:19,851 [INFO    ] __main__: train step 8011: loss: 1.1121, policy_loss: 1.2700, value_loss: 0.8167
2024-07-14 05:48:20,154 [INFO    ] __main__: train step 8012: loss: 1.1121, policy_loss: 1.2699, value_loss: 0.8166
2024-07-14 05:48:20,458 [INFO    ] __main__: train step 8013: loss: 1.1121, policy_loss: 1.2699, value_loss: 0.8166
2024-07-14 05:48:20,787 [INFO    ] __main__: train step 8014: loss: 1.1122, policy_loss: 1.2698, value_loss: 0.8166
2024-07-14 05:48:21,085 [INFO    ] __main__: train step 8015: loss: 1.1122, policy_loss: 1.2698, value_loss: 0.8166
2024-07-14 05:48:21,398 [INFO    ] __main__: train step 8016: loss: 1.1122, policy_loss: 1.2697, value_loss: 0.8165
2024-07-14 05:48:21,725 [INFO    ] __main__: train step 8017: loss: 1.1123, policy_loss: 1.2696, value_loss: 0.8165
2024-07-14 05:48:22,020 [INFO    ] __main__: train step 8018: loss: 1.1123, policy_loss: 1.2696, value_loss: 0.8165
2024-07-14 05:48:22,319 [INFO    ] __main__: train step 8019: loss: 1.1123, policy_loss: 1.2695, value_loss: 0.8165
2024-07-14 05:48:22,617 [INFO    ] __main__: train step 8020: loss: 1.1124, policy_loss: 1.2694, value_loss: 0.8164
2024-07-14 05:48:24,223 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:48:24,719 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:48:24,804 [INFO    ] __main__: train step 8021: loss: 1.1124, policy_loss: 1.2694, value_loss: 0.8164
2024-07-14 05:48:26,705 [INFO    ] __main__: train step 8022: loss: 1.1124, policy_loss: 1.2693, value_loss: 0.8164
2024-07-14 05:48:27,020 [INFO    ] __main__: train step 8023: loss: 1.1125, policy_loss: 1.2693, value_loss: 0.8164
2024-07-14 05:48:27,320 [INFO    ] __main__: train step 8024: loss: 1.1125, policy_loss: 1.2692, value_loss: 0.8163
2024-07-14 05:48:27,624 [INFO    ] __main__: train step 8025: loss: 1.1125, policy_loss: 1.2691, value_loss: 0.8163
2024-07-14 05:48:27,914 [INFO    ] __main__: train step 8026: loss: 1.1125, policy_loss: 1.2691, value_loss: 0.8163
2024-07-14 05:48:28,211 [INFO    ] __main__: train step 8027: loss: 1.1126, policy_loss: 1.2690, value_loss: 0.8163
2024-07-14 05:48:28,512 [INFO    ] __main__: train step 8028: loss: 1.1126, policy_loss: 1.2689, value_loss: 0.8162
2024-07-14 05:48:28,815 [INFO    ] __main__: train step 8029: loss: 1.1126, policy_loss: 1.2689, value_loss: 0.8162
2024-07-14 05:48:29,123 [INFO    ] __main__: train step 8030: loss: 1.1127, policy_loss: 1.2688, value_loss: 0.8162
2024-07-14 05:48:29,441 [INFO    ] __main__: train step 8031: loss: 1.1127, policy_loss: 1.2687, value_loss: 0.8162
2024-07-14 05:48:29,738 [INFO    ] __main__: train step 8032: loss: 1.1127, policy_loss: 1.2687, value_loss: 0.8161
2024-07-14 05:48:30,031 [INFO    ] __main__: train step 8033: loss: 1.1128, policy_loss: 1.2686, value_loss: 0.8161
2024-07-14 05:48:30,330 [INFO    ] __main__: train step 8034: loss: 1.1128, policy_loss: 1.2686, value_loss: 0.8161
2024-07-14 05:48:30,615 [INFO    ] __main__: train step 8035: loss: 1.1128, policy_loss: 1.2685, value_loss: 0.8161
2024-07-14 05:48:30,907 [INFO    ] __main__: train step 8036: loss: 1.1129, policy_loss: 1.2684, value_loss: 0.8160
2024-07-14 05:48:31,192 [INFO    ] __main__: train step 8037: loss: 1.1129, policy_loss: 1.2684, value_loss: 0.8160
2024-07-14 05:48:32,805 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:48:33,291 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:48:33,362 [INFO    ] __main__: train step 8038: loss: 1.1129, policy_loss: 1.2683, value_loss: 0.8160
2024-07-14 05:48:33,660 [INFO    ] __main__: train step 8039: loss: 1.1130, policy_loss: 1.2682, value_loss: 0.8160
2024-07-14 05:48:33,959 [INFO    ] __main__: train step 8040: loss: 1.1130, policy_loss: 1.2682, value_loss: 0.8159
2024-07-14 05:48:34,267 [INFO    ] __main__: train step 8041: loss: 1.1130, policy_loss: 1.2681, value_loss: 0.8159
2024-07-14 05:48:34,560 [INFO    ] __main__: train step 8042: loss: 1.1131, policy_loss: 1.2680, value_loss: 0.8159
2024-07-14 05:48:34,856 [INFO    ] __main__: train step 8043: loss: 1.1131, policy_loss: 1.2680, value_loss: 0.8158
2024-07-14 05:48:35,150 [INFO    ] __main__: train step 8044: loss: 1.1131, policy_loss: 1.2679, value_loss: 0.8158
2024-07-14 05:48:35,452 [INFO    ] __main__: train step 8045: loss: 1.1131, policy_loss: 1.2679, value_loss: 0.8158
2024-07-14 05:48:35,746 [INFO    ] __main__: train step 8046: loss: 1.1132, policy_loss: 1.2678, value_loss: 0.8158
2024-07-14 05:48:36,042 [INFO    ] __main__: train step 8047: loss: 1.1132, policy_loss: 1.2677, value_loss: 0.8157
2024-07-14 05:48:36,346 [INFO    ] __main__: train step 8048: loss: 1.1132, policy_loss: 1.2677, value_loss: 0.8157
2024-07-14 05:48:36,643 [INFO    ] __main__: train step 8049: loss: 1.1133, policy_loss: 1.2676, value_loss: 0.8157
2024-07-14 05:48:36,935 [INFO    ] __main__: train step 8050: loss: 1.1133, policy_loss: 1.2675, value_loss: 0.8157
2024-07-14 05:48:37,241 [INFO    ] __main__: train step 8051: loss: 1.1133, policy_loss: 1.2675, value_loss: 0.8156
2024-07-14 05:48:37,530 [INFO    ] __main__: train step 8052: loss: 1.1134, policy_loss: 1.2674, value_loss: 0.8156
2024-07-14 05:48:37,826 [INFO    ] __main__: train step 8053: loss: 1.1134, policy_loss: 1.2673, value_loss: 0.8156
2024-07-14 05:48:38,132 [INFO    ] __main__: train step 8054: loss: 1.1134, policy_loss: 1.2673, value_loss: 0.8156
2024-07-14 05:48:39,754 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:48:40,248 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:48:40,322 [INFO    ] __main__: train step 8055: loss: 1.1135, policy_loss: 1.2672, value_loss: 0.8155
2024-07-14 05:48:40,598 [INFO    ] __main__: train step 8056: loss: 1.1135, policy_loss: 1.2672, value_loss: 0.8155
2024-07-14 05:48:40,894 [INFO    ] __main__: train step 8057: loss: 1.1135, policy_loss: 1.2671, value_loss: 0.8155
2024-07-14 05:48:41,183 [INFO    ] __main__: train step 8058: loss: 1.1135, policy_loss: 1.2670, value_loss: 0.8155
2024-07-14 05:48:41,477 [INFO    ] __main__: train step 8059: loss: 1.1136, policy_loss: 1.2670, value_loss: 0.8154
2024-07-14 05:48:41,776 [INFO    ] __main__: train step 8060: loss: 1.1136, policy_loss: 1.2669, value_loss: 0.8154
2024-07-14 05:48:42,070 [INFO    ] __main__: train step 8061: loss: 1.1136, policy_loss: 1.2668, value_loss: 0.8154
2024-07-14 05:48:42,359 [INFO    ] __main__: train step 8062: loss: 1.1137, policy_loss: 1.2668, value_loss: 0.8154
2024-07-14 05:48:42,641 [INFO    ] __main__: train step 8063: loss: 1.1137, policy_loss: 1.2667, value_loss: 0.8153
2024-07-14 05:48:42,947 [INFO    ] __main__: train step 8064: loss: 1.1137, policy_loss: 1.2667, value_loss: 0.8153
2024-07-14 05:48:43,235 [INFO    ] __main__: train step 8065: loss: 1.1138, policy_loss: 1.2666, value_loss: 0.8153
2024-07-14 05:48:43,531 [INFO    ] __main__: train step 8066: loss: 1.1138, policy_loss: 1.2665, value_loss: 0.8152
2024-07-14 05:48:43,842 [INFO    ] __main__: train step 8067: loss: 1.1138, policy_loss: 1.2665, value_loss: 0.8152
2024-07-14 05:48:44,152 [INFO    ] __main__: train step 8068: loss: 1.1139, policy_loss: 1.2664, value_loss: 0.8152
2024-07-14 05:48:44,447 [INFO    ] __main__: train step 8069: loss: 1.1139, policy_loss: 1.2663, value_loss: 0.8152
2024-07-14 05:48:44,740 [INFO    ] __main__: train step 8070: loss: 1.1139, policy_loss: 1.2663, value_loss: 0.8151
2024-07-14 05:48:45,037 [INFO    ] __main__: train step 8071: loss: 1.1140, policy_loss: 1.2662, value_loss: 0.8151
2024-07-14 05:48:46,651 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:48:47,146 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:48:47,223 [INFO    ] __main__: train step 8072: loss: 1.1140, policy_loss: 1.2662, value_loss: 0.8151
2024-07-14 05:48:47,520 [INFO    ] __main__: train step 8073: loss: 1.1140, policy_loss: 1.2661, value_loss: 0.8151
2024-07-14 05:48:47,808 [INFO    ] __main__: train step 8074: loss: 1.1140, policy_loss: 1.2660, value_loss: 0.8150
2024-07-14 05:48:48,104 [INFO    ] __main__: train step 8075: loss: 1.1141, policy_loss: 1.2660, value_loss: 0.8150
2024-07-14 05:48:49,817 [INFO    ] __main__: train step 8076: loss: 1.1141, policy_loss: 1.2659, value_loss: 0.8150
2024-07-14 05:48:50,119 [INFO    ] __main__: train step 8077: loss: 1.1141, policy_loss: 1.2658, value_loss: 0.8150
2024-07-14 05:48:50,416 [INFO    ] __main__: train step 8078: loss: 1.1142, policy_loss: 1.2658, value_loss: 0.8149
2024-07-14 05:48:50,717 [INFO    ] __main__: train step 8079: loss: 1.1142, policy_loss: 1.2657, value_loss: 0.8149
2024-07-14 05:48:51,025 [INFO    ] __main__: train step 8080: loss: 1.1142, policy_loss: 1.2656, value_loss: 0.8149
2024-07-14 05:48:51,337 [INFO    ] __main__: train step 8081: loss: 1.1143, policy_loss: 1.2656, value_loss: 0.8149
2024-07-14 05:48:51,640 [INFO    ] __main__: train step 8082: loss: 1.1143, policy_loss: 1.2655, value_loss: 0.8148
2024-07-14 05:48:51,948 [INFO    ] __main__: train step 8083: loss: 1.1143, policy_loss: 1.2655, value_loss: 0.8148
2024-07-14 05:48:52,235 [INFO    ] __main__: train step 8084: loss: 1.1143, policy_loss: 1.2654, value_loss: 0.8148
2024-07-14 05:48:52,537 [INFO    ] __main__: train step 8085: loss: 1.1144, policy_loss: 1.2653, value_loss: 0.8148
2024-07-14 05:48:52,842 [INFO    ] __main__: train step 8086: loss: 1.1144, policy_loss: 1.2653, value_loss: 0.8147
2024-07-14 05:48:53,154 [INFO    ] __main__: train step 8087: loss: 1.1144, policy_loss: 1.2652, value_loss: 0.8147
2024-07-14 05:48:53,449 [INFO    ] __main__: train step 8088: loss: 1.1145, policy_loss: 1.2651, value_loss: 0.8147
2024-07-14 05:48:55,079 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:48:55,560 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:48:55,630 [INFO    ] __main__: train step 8089: loss: 1.1145, policy_loss: 1.2651, value_loss: 0.8147
2024-07-14 05:48:55,905 [INFO    ] __main__: train step 8090: loss: 1.1145, policy_loss: 1.2650, value_loss: 0.8146
2024-07-14 05:48:56,162 [INFO    ] __main__: train step 8091: loss: 1.1146, policy_loss: 1.2649, value_loss: 0.8146
2024-07-14 05:48:56,454 [INFO    ] __main__: train step 8092: loss: 1.1146, policy_loss: 1.2649, value_loss: 0.8146
2024-07-14 05:48:56,749 [INFO    ] __main__: train step 8093: loss: 1.1146, policy_loss: 1.2648, value_loss: 0.8146
2024-07-14 05:48:57,025 [INFO    ] __main__: train step 8094: loss: 1.1146, policy_loss: 1.2648, value_loss: 0.8145
2024-07-14 05:48:57,327 [INFO    ] __main__: train step 8095: loss: 1.1147, policy_loss: 1.2647, value_loss: 0.8145
2024-07-14 05:48:57,617 [INFO    ] __main__: train step 8096: loss: 1.1147, policy_loss: 1.2646, value_loss: 0.8145
2024-07-14 05:48:57,905 [INFO    ] __main__: train step 8097: loss: 1.1147, policy_loss: 1.2646, value_loss: 0.8145
2024-07-14 05:48:58,162 [INFO    ] __main__: train step 8098: loss: 1.1148, policy_loss: 1.2645, value_loss: 0.8144
2024-07-14 05:48:58,431 [INFO    ] __main__: train step 8099: loss: 1.1148, policy_loss: 1.2645, value_loss: 0.8144
2024-07-14 05:48:58,708 [INFO    ] __main__: train step 8100: loss: 1.1148, policy_loss: 1.2644, value_loss: 0.8144
2024-07-14 05:48:58,969 [INFO    ] __main__: train step 8101: loss: 1.1149, policy_loss: 1.2643, value_loss: 0.8143
2024-07-14 05:48:59,259 [INFO    ] __main__: train step 8102: loss: 1.1149, policy_loss: 1.2643, value_loss: 0.8143
2024-07-14 05:48:59,530 [INFO    ] __main__: train step 8103: loss: 1.1149, policy_loss: 1.2642, value_loss: 0.8143
2024-07-14 05:48:59,796 [INFO    ] __main__: train step 8104: loss: 1.1150, policy_loss: 1.2641, value_loss: 0.8143
2024-07-14 05:49:00,051 [INFO    ] __main__: train step 8105: loss: 1.1150, policy_loss: 1.2641, value_loss: 0.8142
2024-07-14 05:49:01,625 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:49:02,102 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:49:02,167 [INFO    ] __main__: train step 8106: loss: 1.1150, policy_loss: 1.2640, value_loss: 0.8142
2024-07-14 05:49:02,421 [INFO    ] __main__: train step 8107: loss: 1.1150, policy_loss: 1.2640, value_loss: 0.8142
2024-07-14 05:49:02,672 [INFO    ] __main__: train step 8108: loss: 1.1151, policy_loss: 1.2639, value_loss: 0.8142
2024-07-14 05:49:02,918 [INFO    ] __main__: train step 8109: loss: 1.1151, policy_loss: 1.2638, value_loss: 0.8141
2024-07-14 05:49:03,167 [INFO    ] __main__: train step 8110: loss: 1.1151, policy_loss: 1.2638, value_loss: 0.8141
2024-07-14 05:49:03,419 [INFO    ] __main__: train step 8111: loss: 1.1151, policy_loss: 1.2637, value_loss: 0.8141
2024-07-14 05:49:03,671 [INFO    ] __main__: train step 8112: loss: 1.1152, policy_loss: 1.2636, value_loss: 0.8141
2024-07-14 05:49:03,946 [INFO    ] __main__: train step 8113: loss: 1.1152, policy_loss: 1.2636, value_loss: 0.8140
2024-07-14 05:49:04,220 [INFO    ] __main__: train step 8114: loss: 1.1152, policy_loss: 1.2635, value_loss: 0.8140
2024-07-14 05:49:04,498 [INFO    ] __main__: train step 8115: loss: 1.1153, policy_loss: 1.2634, value_loss: 0.8140
2024-07-14 05:49:04,764 [INFO    ] __main__: train step 8116: loss: 1.1153, policy_loss: 1.2634, value_loss: 0.8139
2024-07-14 05:49:05,035 [INFO    ] __main__: train step 8117: loss: 1.1153, policy_loss: 1.2633, value_loss: 0.8139
2024-07-14 05:49:05,310 [INFO    ] __main__: train step 8118: loss: 1.1153, policy_loss: 1.2633, value_loss: 0.8139
2024-07-14 05:49:05,553 [INFO    ] __main__: train step 8119: loss: 1.1154, policy_loss: 1.2632, value_loss: 0.8139
2024-07-14 05:49:05,820 [INFO    ] __main__: train step 8120: loss: 1.1154, policy_loss: 1.2631, value_loss: 0.8138
2024-07-14 05:49:06,105 [INFO    ] __main__: train step 8121: loss: 1.1154, policy_loss: 1.2631, value_loss: 0.8138
2024-07-14 05:49:06,347 [INFO    ] __main__: train step 8122: loss: 1.1155, policy_loss: 1.2630, value_loss: 0.8138
2024-07-14 05:49:07,907 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:49:08,367 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:49:08,447 [INFO    ] __main__: train step 8123: loss: 1.1155, policy_loss: 1.2629, value_loss: 0.8138
2024-07-14 05:49:08,703 [INFO    ] __main__: train step 8124: loss: 1.1155, policy_loss: 1.2629, value_loss: 0.8137
2024-07-14 05:49:08,948 [INFO    ] __main__: train step 8125: loss: 1.1155, policy_loss: 1.2628, value_loss: 0.8137
2024-07-14 05:49:09,220 [INFO    ] __main__: train step 8126: loss: 1.1156, policy_loss: 1.2627, value_loss: 0.8137
2024-07-14 05:49:09,483 [INFO    ] __main__: train step 8127: loss: 1.1156, policy_loss: 1.2627, value_loss: 0.8137
2024-07-14 05:49:09,725 [INFO    ] __main__: train step 8128: loss: 1.1156, policy_loss: 1.2626, value_loss: 0.8136
2024-07-14 05:49:09,972 [INFO    ] __main__: train step 8129: loss: 1.1157, policy_loss: 1.2626, value_loss: 0.8136
2024-07-14 05:49:10,229 [INFO    ] __main__: train step 8130: loss: 1.1157, policy_loss: 1.2625, value_loss: 0.8136
2024-07-14 05:49:10,491 [INFO    ] __main__: train step 8131: loss: 1.1157, policy_loss: 1.2624, value_loss: 0.8135
2024-07-14 05:49:12,299 [INFO    ] __main__: train step 8132: loss: 1.1157, policy_loss: 1.2624, value_loss: 0.8135
2024-07-14 05:49:12,589 [INFO    ] __main__: train step 8133: loss: 1.1158, policy_loss: 1.2623, value_loss: 0.8135
2024-07-14 05:49:12,866 [INFO    ] __main__: train step 8134: loss: 1.1158, policy_loss: 1.2622, value_loss: 0.8135
2024-07-14 05:49:13,143 [INFO    ] __main__: train step 8135: loss: 1.1158, policy_loss: 1.2622, value_loss: 0.8134
2024-07-14 05:49:13,411 [INFO    ] __main__: train step 8136: loss: 1.1158, policy_loss: 1.2621, value_loss: 0.8134
2024-07-14 05:49:13,674 [INFO    ] __main__: train step 8137: loss: 1.1159, policy_loss: 1.2620, value_loss: 0.8134
2024-07-14 05:49:13,934 [INFO    ] __main__: train step 8138: loss: 1.1159, policy_loss: 1.2620, value_loss: 0.8134
2024-07-14 05:49:14,195 [INFO    ] __main__: train step 8139: loss: 1.1159, policy_loss: 1.2619, value_loss: 0.8133
2024-07-14 05:49:15,778 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:49:16,279 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:49:16,346 [INFO    ] __main__: train step 8140: loss: 1.1159, policy_loss: 1.2619, value_loss: 0.8133
2024-07-14 05:49:16,631 [INFO    ] __main__: train step 8141: loss: 1.1160, policy_loss: 1.2618, value_loss: 0.8133
2024-07-14 05:49:16,908 [INFO    ] __main__: train step 8142: loss: 1.1160, policy_loss: 1.2617, value_loss: 0.8132
2024-07-14 05:49:17,153 [INFO    ] __main__: train step 8143: loss: 1.1160, policy_loss: 1.2617, value_loss: 0.8132
2024-07-14 05:49:17,416 [INFO    ] __main__: train step 8144: loss: 1.1161, policy_loss: 1.2616, value_loss: 0.8132
2024-07-14 05:49:17,701 [INFO    ] __main__: train step 8145: loss: 1.1161, policy_loss: 1.2615, value_loss: 0.8132
2024-07-14 05:49:17,954 [INFO    ] __main__: train step 8146: loss: 1.1161, policy_loss: 1.2615, value_loss: 0.8131
2024-07-14 05:49:18,222 [INFO    ] __main__: train step 8147: loss: 1.1161, policy_loss: 1.2614, value_loss: 0.8131
2024-07-14 05:49:18,477 [INFO    ] __main__: train step 8148: loss: 1.1162, policy_loss: 1.2614, value_loss: 0.8131
2024-07-14 05:49:18,721 [INFO    ] __main__: train step 8149: loss: 1.1162, policy_loss: 1.2613, value_loss: 0.8131
2024-07-14 05:49:18,985 [INFO    ] __main__: train step 8150: loss: 1.1162, policy_loss: 1.2612, value_loss: 0.8130
2024-07-14 05:49:19,238 [INFO    ] __main__: train step 8151: loss: 1.1163, policy_loss: 1.2612, value_loss: 0.8130
2024-07-14 05:49:19,498 [INFO    ] __main__: train step 8152: loss: 1.1163, policy_loss: 1.2611, value_loss: 0.8130
2024-07-14 05:49:19,753 [INFO    ] __main__: train step 8153: loss: 1.1163, policy_loss: 1.2610, value_loss: 0.8129
2024-07-14 05:49:20,023 [INFO    ] __main__: train step 8154: loss: 1.1163, policy_loss: 1.2610, value_loss: 0.8129
2024-07-14 05:49:20,286 [INFO    ] __main__: train step 8155: loss: 1.1164, policy_loss: 1.2609, value_loss: 0.8129
2024-07-14 05:49:20,545 [INFO    ] __main__: train step 8156: loss: 1.1164, policy_loss: 1.2608, value_loss: 0.8129
2024-07-14 05:49:22,120 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:49:22,583 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:49:22,648 [INFO    ] __main__: train step 8157: loss: 1.1164, policy_loss: 1.2608, value_loss: 0.8128
2024-07-14 05:49:22,908 [INFO    ] __main__: train step 8158: loss: 1.1164, policy_loss: 1.2607, value_loss: 0.8128
2024-07-14 05:49:23,155 [INFO    ] __main__: train step 8159: loss: 1.1165, policy_loss: 1.2607, value_loss: 0.8128
2024-07-14 05:49:23,404 [INFO    ] __main__: train step 8160: loss: 1.1165, policy_loss: 1.2606, value_loss: 0.8128
2024-07-14 05:49:23,660 [INFO    ] __main__: train step 8161: loss: 1.1165, policy_loss: 1.2605, value_loss: 0.8127
2024-07-14 05:49:23,934 [INFO    ] __main__: train step 8162: loss: 1.1165, policy_loss: 1.2605, value_loss: 0.8127
2024-07-14 05:49:24,200 [INFO    ] __main__: train step 8163: loss: 1.1166, policy_loss: 1.2604, value_loss: 0.8127
2024-07-14 05:49:24,476 [INFO    ] __main__: train step 8164: loss: 1.1166, policy_loss: 1.2603, value_loss: 0.8126
2024-07-14 05:49:24,747 [INFO    ] __main__: train step 8165: loss: 1.1166, policy_loss: 1.2603, value_loss: 0.8126
2024-07-14 05:49:25,010 [INFO    ] __main__: train step 8166: loss: 1.1167, policy_loss: 1.2602, value_loss: 0.8126
2024-07-14 05:49:25,270 [INFO    ] __main__: train step 8167: loss: 1.1167, policy_loss: 1.2602, value_loss: 0.8126
2024-07-14 05:49:25,535 [INFO    ] __main__: train step 8168: loss: 1.1167, policy_loss: 1.2601, value_loss: 0.8125
2024-07-14 05:49:25,809 [INFO    ] __main__: train step 8169: loss: 1.1167, policy_loss: 1.2600, value_loss: 0.8125
2024-07-14 05:49:26,076 [INFO    ] __main__: train step 8170: loss: 1.1168, policy_loss: 1.2600, value_loss: 0.8125
2024-07-14 05:49:26,334 [INFO    ] __main__: train step 8171: loss: 1.1168, policy_loss: 1.2599, value_loss: 0.8125
2024-07-14 05:49:26,593 [INFO    ] __main__: train step 8172: loss: 1.1168, policy_loss: 1.2598, value_loss: 0.8124
2024-07-14 05:49:26,843 [INFO    ] __main__: train step 8173: loss: 1.1168, policy_loss: 1.2598, value_loss: 0.8124
2024-07-14 05:49:28,418 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:49:28,887 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:49:28,951 [INFO    ] __main__: train step 8174: loss: 1.1169, policy_loss: 1.2597, value_loss: 0.8124
2024-07-14 05:49:29,210 [INFO    ] __main__: train step 8175: loss: 1.1169, policy_loss: 1.2596, value_loss: 0.8124
2024-07-14 05:49:29,490 [INFO    ] __main__: train step 8176: loss: 1.1169, policy_loss: 1.2596, value_loss: 0.8123
2024-07-14 05:49:29,785 [INFO    ] __main__: train step 8177: loss: 1.1169, policy_loss: 1.2595, value_loss: 0.8123
2024-07-14 05:49:30,079 [INFO    ] __main__: train step 8178: loss: 1.1170, policy_loss: 1.2595, value_loss: 0.8123
2024-07-14 05:49:30,356 [INFO    ] __main__: train step 8179: loss: 1.1170, policy_loss: 1.2594, value_loss: 0.8122
2024-07-14 05:49:30,637 [INFO    ] __main__: train step 8180: loss: 1.1170, policy_loss: 1.2593, value_loss: 0.8122
2024-07-14 05:49:30,910 [INFO    ] __main__: train step 8181: loss: 1.1170, policy_loss: 1.2593, value_loss: 0.8122
2024-07-14 05:49:31,204 [INFO    ] __main__: train step 8182: loss: 1.1171, policy_loss: 1.2592, value_loss: 0.8122
2024-07-14 05:49:31,483 [INFO    ] __main__: train step 8183: loss: 1.1171, policy_loss: 1.2591, value_loss: 0.8121
2024-07-14 05:49:31,770 [INFO    ] __main__: train step 8184: loss: 1.1171, policy_loss: 1.2591, value_loss: 0.8121
2024-07-14 05:49:32,080 [INFO    ] __main__: train step 8185: loss: 1.1171, policy_loss: 1.2590, value_loss: 0.8121
2024-07-14 05:49:33,903 [INFO    ] __main__: train step 8186: loss: 1.1172, policy_loss: 1.2590, value_loss: 0.8120
2024-07-14 05:49:34,196 [INFO    ] __main__: train step 8187: loss: 1.1172, policy_loss: 1.2589, value_loss: 0.8120
2024-07-14 05:49:34,495 [INFO    ] __main__: train step 8188: loss: 1.1172, policy_loss: 1.2588, value_loss: 0.8120
2024-07-14 05:49:34,797 [INFO    ] __main__: train step 8189: loss: 1.1172, policy_loss: 1.2588, value_loss: 0.8120
2024-07-14 05:49:35,092 [INFO    ] __main__: train step 8190: loss: 1.1173, policy_loss: 1.2587, value_loss: 0.8119
2024-07-14 05:49:36,714 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:49:37,202 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:49:37,273 [INFO    ] __main__: train step 8191: loss: 1.1173, policy_loss: 1.2586, value_loss: 0.8119
2024-07-14 05:49:37,579 [INFO    ] __main__: train step 8192: loss: 1.1173, policy_loss: 1.2586, value_loss: 0.8119
2024-07-14 05:49:37,875 [INFO    ] __main__: train step 8193: loss: 1.1173, policy_loss: 1.2585, value_loss: 0.8118
2024-07-14 05:49:38,166 [INFO    ] __main__: train step 8194: loss: 1.1174, policy_loss: 1.2585, value_loss: 0.8118
2024-07-14 05:49:38,467 [INFO    ] __main__: train step 8195: loss: 1.1174, policy_loss: 1.2584, value_loss: 0.8118
2024-07-14 05:49:38,777 [INFO    ] __main__: train step 8196: loss: 1.1174, policy_loss: 1.2583, value_loss: 0.8118
2024-07-14 05:49:39,075 [INFO    ] __main__: train step 8197: loss: 1.1174, policy_loss: 1.2583, value_loss: 0.8117
2024-07-14 05:49:39,386 [INFO    ] __main__: train step 8198: loss: 1.1175, policy_loss: 1.2582, value_loss: 0.8117
2024-07-14 05:49:39,682 [INFO    ] __main__: train step 8199: loss: 1.1175, policy_loss: 1.2581, value_loss: 0.8117
2024-07-14 05:49:39,989 [INFO    ] __main__: train step 8200: loss: 1.1175, policy_loss: 1.2581, value_loss: 0.8116
2024-07-14 05:49:40,298 [INFO    ] __main__: train step 8201: loss: 1.1175, policy_loss: 1.2580, value_loss: 0.8116
2024-07-14 05:49:40,598 [INFO    ] __main__: train step 8202: loss: 1.1176, policy_loss: 1.2579, value_loss: 0.8116
2024-07-14 05:49:40,911 [INFO    ] __main__: train step 8203: loss: 1.1176, policy_loss: 1.2579, value_loss: 0.8116
2024-07-14 05:49:41,198 [INFO    ] __main__: train step 8204: loss: 1.1176, policy_loss: 1.2578, value_loss: 0.8115
2024-07-14 05:49:41,494 [INFO    ] __main__: train step 8205: loss: 1.1176, policy_loss: 1.2578, value_loss: 0.8115
2024-07-14 05:49:41,792 [INFO    ] __main__: train step 8206: loss: 1.1177, policy_loss: 1.2577, value_loss: 0.8115
2024-07-14 05:49:42,081 [INFO    ] __main__: train step 8207: loss: 1.1177, policy_loss: 1.2576, value_loss: 0.8114
2024-07-14 05:49:43,708 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:49:44,203 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:49:44,273 [INFO    ] __main__: train step 8208: loss: 1.1177, policy_loss: 1.2576, value_loss: 0.8114
2024-07-14 05:49:44,555 [INFO    ] __main__: train step 8209: loss: 1.1177, policy_loss: 1.2575, value_loss: 0.8114
2024-07-14 05:49:44,867 [INFO    ] __main__: train step 8210: loss: 1.1178, policy_loss: 1.2574, value_loss: 0.8114
2024-07-14 05:49:45,160 [INFO    ] __main__: train step 8211: loss: 1.1178, policy_loss: 1.2574, value_loss: 0.8113
2024-07-14 05:49:45,468 [INFO    ] __main__: train step 8212: loss: 1.1178, policy_loss: 1.2573, value_loss: 0.8113
2024-07-14 05:49:45,772 [INFO    ] __main__: train step 8213: loss: 1.1178, policy_loss: 1.2573, value_loss: 0.8113
2024-07-14 05:49:46,071 [INFO    ] __main__: train step 8214: loss: 1.1179, policy_loss: 1.2572, value_loss: 0.8112
2024-07-14 05:49:46,371 [INFO    ] __main__: train step 8215: loss: 1.1179, policy_loss: 1.2571, value_loss: 0.8112
2024-07-14 05:49:46,661 [INFO    ] __main__: train step 8216: loss: 1.1179, policy_loss: 1.2571, value_loss: 0.8112
2024-07-14 05:49:46,976 [INFO    ] __main__: train step 8217: loss: 1.1179, policy_loss: 1.2570, value_loss: 0.8112
2024-07-14 05:49:47,283 [INFO    ] __main__: train step 8218: loss: 1.1180, policy_loss: 1.2569, value_loss: 0.8111
2024-07-14 05:49:47,583 [INFO    ] __main__: train step 8219: loss: 1.1180, policy_loss: 1.2569, value_loss: 0.8111
2024-07-14 05:49:47,879 [INFO    ] __main__: train step 8220: loss: 1.1180, policy_loss: 1.2568, value_loss: 0.8111
2024-07-14 05:49:48,191 [INFO    ] __main__: train step 8221: loss: 1.1180, policy_loss: 1.2568, value_loss: 0.8110
2024-07-14 05:49:48,480 [INFO    ] __main__: train step 8222: loss: 1.1181, policy_loss: 1.2567, value_loss: 0.8110
2024-07-14 05:49:48,776 [INFO    ] __main__: train step 8223: loss: 1.1181, policy_loss: 1.2566, value_loss: 0.8110
2024-07-14 05:49:49,079 [INFO    ] __main__: train step 8224: loss: 1.1181, policy_loss: 1.2566, value_loss: 0.8110
2024-07-14 05:49:50,718 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:49:51,191 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:49:51,261 [INFO    ] __main__: train step 8225: loss: 1.1181, policy_loss: 1.2565, value_loss: 0.8109
2024-07-14 05:49:51,562 [INFO    ] __main__: train step 8226: loss: 1.1182, policy_loss: 1.2565, value_loss: 0.8109
2024-07-14 05:49:51,857 [INFO    ] __main__: train step 8227: loss: 1.1182, policy_loss: 1.2564, value_loss: 0.8109
2024-07-14 05:49:52,149 [INFO    ] __main__: train step 8228: loss: 1.1182, policy_loss: 1.2563, value_loss: 0.8109
2024-07-14 05:49:52,439 [INFO    ] __main__: train step 8229: loss: 1.1182, policy_loss: 1.2563, value_loss: 0.8108
2024-07-14 05:49:52,729 [INFO    ] __main__: train step 8230: loss: 1.1183, policy_loss: 1.2562, value_loss: 0.8108
2024-07-14 05:49:53,023 [INFO    ] __main__: train step 8231: loss: 1.1183, policy_loss: 1.2561, value_loss: 0.8108
2024-07-14 05:49:53,295 [INFO    ] __main__: train step 8232: loss: 1.1183, policy_loss: 1.2561, value_loss: 0.8107
2024-07-14 05:49:53,547 [INFO    ] __main__: train step 8233: loss: 1.1183, policy_loss: 1.2560, value_loss: 0.8107
2024-07-14 05:49:53,835 [INFO    ] __main__: train step 8234: loss: 1.1184, policy_loss: 1.2560, value_loss: 0.8107
2024-07-14 05:49:54,107 [INFO    ] __main__: train step 8235: loss: 1.1184, policy_loss: 1.2559, value_loss: 0.8107
2024-07-14 05:49:54,378 [INFO    ] __main__: train step 8236: loss: 1.1184, policy_loss: 1.2558, value_loss: 0.8106
2024-07-14 05:49:54,641 [INFO    ] __main__: train step 8237: loss: 1.1184, policy_loss: 1.2558, value_loss: 0.8106
2024-07-14 05:49:54,904 [INFO    ] __main__: train step 8238: loss: 1.1185, policy_loss: 1.2557, value_loss: 0.8106
2024-07-14 05:49:55,161 [INFO    ] __main__: train step 8239: loss: 1.1185, policy_loss: 1.2556, value_loss: 0.8105
2024-07-14 05:49:56,778 [INFO    ] __main__: train step 8240: loss: 1.1185, policy_loss: 1.2556, value_loss: 0.8105
2024-07-14 05:49:57,038 [INFO    ] __main__: train step 8241: loss: 1.1185, policy_loss: 1.2555, value_loss: 0.8105
2024-07-14 05:49:58,605 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:49:59,063 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:49:59,129 [INFO    ] __main__: train step 8242: loss: 1.1185, policy_loss: 1.2555, value_loss: 0.8104
2024-07-14 05:49:59,400 [INFO    ] __main__: train step 8243: loss: 1.1186, policy_loss: 1.2554, value_loss: 0.8104
2024-07-14 05:49:59,663 [INFO    ] __main__: train step 8244: loss: 1.1186, policy_loss: 1.2553, value_loss: 0.8104
2024-07-14 05:49:59,935 [INFO    ] __main__: train step 8245: loss: 1.1186, policy_loss: 1.2553, value_loss: 0.8104
2024-07-14 05:50:00,210 [INFO    ] __main__: train step 8246: loss: 1.1186, policy_loss: 1.2552, value_loss: 0.8103
2024-07-14 05:50:00,475 [INFO    ] __main__: train step 8247: loss: 1.1187, policy_loss: 1.2551, value_loss: 0.8103
2024-07-14 05:50:00,753 [INFO    ] __main__: train step 8248: loss: 1.1187, policy_loss: 1.2551, value_loss: 0.8103
2024-07-14 05:50:01,028 [INFO    ] __main__: train step 8249: loss: 1.1187, policy_loss: 1.2550, value_loss: 0.8102
2024-07-14 05:50:01,292 [INFO    ] __main__: train step 8250: loss: 1.1187, policy_loss: 1.2550, value_loss: 0.8102
2024-07-14 05:50:01,561 [INFO    ] __main__: train step 8251: loss: 1.1188, policy_loss: 1.2549, value_loss: 0.8102
2024-07-14 05:50:01,811 [INFO    ] __main__: train step 8252: loss: 1.1188, policy_loss: 1.2548, value_loss: 0.8102
2024-07-14 05:50:02,059 [INFO    ] __main__: train step 8253: loss: 1.1188, policy_loss: 1.2548, value_loss: 0.8101
2024-07-14 05:50:02,312 [INFO    ] __main__: train step 8254: loss: 1.1188, policy_loss: 1.2547, value_loss: 0.8101
2024-07-14 05:50:02,579 [INFO    ] __main__: train step 8255: loss: 1.1189, policy_loss: 1.2546, value_loss: 0.8101
2024-07-14 05:50:02,846 [INFO    ] __main__: train step 8256: loss: 1.1189, policy_loss: 1.2546, value_loss: 0.8100
2024-07-14 05:50:03,101 [INFO    ] __main__: train step 8257: loss: 1.1189, policy_loss: 1.2545, value_loss: 0.8100
2024-07-14 05:50:03,389 [INFO    ] __main__: train step 8258: loss: 1.1189, policy_loss: 1.2545, value_loss: 0.8100
2024-07-14 05:50:04,959 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:50:05,432 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:50:05,496 [INFO    ] __main__: train step 8259: loss: 1.1189, policy_loss: 1.2544, value_loss: 0.8100
2024-07-14 05:50:05,745 [INFO    ] __main__: train step 8260: loss: 1.1190, policy_loss: 1.2543, value_loss: 0.8099
2024-07-14 05:50:06,016 [INFO    ] __main__: train step 8261: loss: 1.1190, policy_loss: 1.2543, value_loss: 0.8099
2024-07-14 05:50:06,301 [INFO    ] __main__: train step 8262: loss: 1.1190, policy_loss: 1.2542, value_loss: 0.8099
2024-07-14 05:50:06,557 [INFO    ] __main__: train step 8263: loss: 1.1190, policy_loss: 1.2542, value_loss: 0.8098
2024-07-14 05:50:06,804 [INFO    ] __main__: train step 8264: loss: 1.1191, policy_loss: 1.2541, value_loss: 0.8098
2024-07-14 05:50:07,093 [INFO    ] __main__: train step 8265: loss: 1.1191, policy_loss: 1.2540, value_loss: 0.8098
2024-07-14 05:50:07,378 [INFO    ] __main__: train step 8266: loss: 1.1191, policy_loss: 1.2540, value_loss: 0.8097
2024-07-14 05:50:07,635 [INFO    ] __main__: train step 8267: loss: 1.1191, policy_loss: 1.2539, value_loss: 0.8097
2024-07-14 05:50:07,902 [INFO    ] __main__: train step 8268: loss: 1.1191, policy_loss: 1.2538, value_loss: 0.8097
2024-07-14 05:50:08,153 [INFO    ] __main__: train step 8269: loss: 1.1192, policy_loss: 1.2538, value_loss: 0.8097
2024-07-14 05:50:08,412 [INFO    ] __main__: train step 8270: loss: 1.1192, policy_loss: 1.2537, value_loss: 0.8096
2024-07-14 05:50:08,656 [INFO    ] __main__: train step 8271: loss: 1.1192, policy_loss: 1.2537, value_loss: 0.8096
2024-07-14 05:50:08,904 [INFO    ] __main__: train step 8272: loss: 1.1192, policy_loss: 1.2536, value_loss: 0.8096
2024-07-14 05:50:09,143 [INFO    ] __main__: train step 8273: loss: 1.1193, policy_loss: 1.2535, value_loss: 0.8095
2024-07-14 05:50:09,395 [INFO    ] __main__: train step 8274: loss: 1.1193, policy_loss: 1.2535, value_loss: 0.8095
2024-07-14 05:50:09,642 [INFO    ] __main__: train step 8275: loss: 1.1193, policy_loss: 1.2534, value_loss: 0.8095
2024-07-14 05:50:11,207 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:50:11,698 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:50:11,764 [INFO    ] __main__: train step 8276: loss: 1.1193, policy_loss: 1.2533, value_loss: 0.8094
2024-07-14 05:50:12,012 [INFO    ] __main__: train step 8277: loss: 1.1193, policy_loss: 1.2533, value_loss: 0.8094
2024-07-14 05:50:12,275 [INFO    ] __main__: train step 8278: loss: 1.1194, policy_loss: 1.2532, value_loss: 0.8094
2024-07-14 05:50:12,519 [INFO    ] __main__: train step 8279: loss: 1.1194, policy_loss: 1.2532, value_loss: 0.8094
2024-07-14 05:50:12,783 [INFO    ] __main__: train step 8280: loss: 1.1194, policy_loss: 1.2531, value_loss: 0.8093
2024-07-14 05:50:13,029 [INFO    ] __main__: train step 8281: loss: 1.1194, policy_loss: 1.2530, value_loss: 0.8093
2024-07-14 05:50:13,274 [INFO    ] __main__: train step 8282: loss: 1.1194, policy_loss: 1.2530, value_loss: 0.8093
2024-07-14 05:50:13,515 [INFO    ] __main__: train step 8283: loss: 1.1195, policy_loss: 1.2529, value_loss: 0.8092
2024-07-14 05:50:13,779 [INFO    ] __main__: train step 8284: loss: 1.1195, policy_loss: 1.2528, value_loss: 0.8092
2024-07-14 05:50:14,037 [INFO    ] __main__: train step 8285: loss: 1.1195, policy_loss: 1.2528, value_loss: 0.8092
2024-07-14 05:50:14,298 [INFO    ] __main__: train step 8286: loss: 1.1195, policy_loss: 1.2527, value_loss: 0.8091
2024-07-14 05:50:14,540 [INFO    ] __main__: train step 8287: loss: 1.1196, policy_loss: 1.2527, value_loss: 0.8091
2024-07-14 05:50:14,791 [INFO    ] __main__: train step 8288: loss: 1.1196, policy_loss: 1.2526, value_loss: 0.8091
2024-07-14 05:50:15,059 [INFO    ] __main__: train step 8289: loss: 1.1196, policy_loss: 1.2525, value_loss: 0.8091
2024-07-14 05:50:15,339 [INFO    ] __main__: train step 8290: loss: 1.1196, policy_loss: 1.2525, value_loss: 0.8090
2024-07-14 05:50:15,622 [INFO    ] __main__: train step 8291: loss: 1.1196, policy_loss: 1.2524, value_loss: 0.8090
2024-07-14 05:50:15,907 [INFO    ] __main__: train step 8292: loss: 1.1197, policy_loss: 1.2523, value_loss: 0.8090
2024-07-14 05:50:17,483 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:50:17,984 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:50:18,053 [INFO    ] __main__: train step 8293: loss: 1.1197, policy_loss: 1.2523, value_loss: 0.8089
2024-07-14 05:50:18,322 [INFO    ] __main__: train step 8294: loss: 1.1197, policy_loss: 1.2522, value_loss: 0.8089
2024-07-14 05:50:20,095 [INFO    ] __main__: train step 8295: loss: 1.1197, policy_loss: 1.2522, value_loss: 0.8089
2024-07-14 05:50:20,363 [INFO    ] __main__: train step 8296: loss: 1.1197, policy_loss: 1.2521, value_loss: 0.8088
2024-07-14 05:50:20,626 [INFO    ] __main__: train step 8297: loss: 1.1198, policy_loss: 1.2520, value_loss: 0.8088
2024-07-14 05:50:20,892 [INFO    ] __main__: train step 8298: loss: 1.1198, policy_loss: 1.2520, value_loss: 0.8088
2024-07-14 05:50:21,160 [INFO    ] __main__: train step 8299: loss: 1.1198, policy_loss: 1.2519, value_loss: 0.8088
2024-07-14 05:50:21,426 [INFO    ] __main__: train step 8300: loss: 1.1198, policy_loss: 1.2518, value_loss: 0.8087
2024-07-14 05:50:21,697 [INFO    ] __main__: train step 8301: loss: 1.1199, policy_loss: 1.2518, value_loss: 0.8087
2024-07-14 05:50:21,953 [INFO    ] __main__: train step 8302: loss: 1.1199, policy_loss: 1.2517, value_loss: 0.8087
2024-07-14 05:50:22,218 [INFO    ] __main__: train step 8303: loss: 1.1199, policy_loss: 1.2517, value_loss: 0.8086
2024-07-14 05:50:22,476 [INFO    ] __main__: train step 8304: loss: 1.1199, policy_loss: 1.2516, value_loss: 0.8086
2024-07-14 05:50:22,742 [INFO    ] __main__: train step 8305: loss: 1.1199, policy_loss: 1.2515, value_loss: 0.8086
2024-07-14 05:50:23,008 [INFO    ] __main__: train step 8306: loss: 1.1200, policy_loss: 1.2515, value_loss: 0.8086
2024-07-14 05:50:23,268 [INFO    ] __main__: train step 8307: loss: 1.1200, policy_loss: 1.2514, value_loss: 0.8085
2024-07-14 05:50:23,533 [INFO    ] __main__: train step 8308: loss: 1.1200, policy_loss: 1.2513, value_loss: 0.8085
2024-07-14 05:50:23,815 [INFO    ] __main__: train step 8309: loss: 1.1200, policy_loss: 1.2513, value_loss: 0.8085
2024-07-14 05:50:25,387 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:50:25,872 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:50:25,942 [INFO    ] __main__: train step 8310: loss: 1.1200, policy_loss: 1.2512, value_loss: 0.8084
2024-07-14 05:50:26,199 [INFO    ] __main__: train step 8311: loss: 1.1201, policy_loss: 1.2512, value_loss: 0.8084
2024-07-14 05:50:26,461 [INFO    ] __main__: train step 8312: loss: 1.1201, policy_loss: 1.2511, value_loss: 0.8084
2024-07-14 05:50:26,723 [INFO    ] __main__: train step 8313: loss: 1.1201, policy_loss: 1.2510, value_loss: 0.8083
2024-07-14 05:50:26,987 [INFO    ] __main__: train step 8314: loss: 1.1201, policy_loss: 1.2510, value_loss: 0.8083
2024-07-14 05:50:27,245 [INFO    ] __main__: train step 8315: loss: 1.1201, policy_loss: 1.2509, value_loss: 0.8083
2024-07-14 05:50:27,503 [INFO    ] __main__: train step 8316: loss: 1.1202, policy_loss: 1.2508, value_loss: 0.8082
2024-07-14 05:50:27,750 [INFO    ] __main__: train step 8317: loss: 1.1202, policy_loss: 1.2508, value_loss: 0.8082
2024-07-14 05:50:28,001 [INFO    ] __main__: train step 8318: loss: 1.1202, policy_loss: 1.2507, value_loss: 0.8082
2024-07-14 05:50:28,257 [INFO    ] __main__: train step 8319: loss: 1.1202, policy_loss: 1.2507, value_loss: 0.8082
2024-07-14 05:50:28,512 [INFO    ] __main__: train step 8320: loss: 1.1202, policy_loss: 1.2506, value_loss: 0.8081
2024-07-14 05:50:28,782 [INFO    ] __main__: train step 8321: loss: 1.1203, policy_loss: 1.2505, value_loss: 0.8081
2024-07-14 05:50:29,035 [INFO    ] __main__: train step 8322: loss: 1.1203, policy_loss: 1.2505, value_loss: 0.8081
2024-07-14 05:50:29,290 [INFO    ] __main__: train step 8323: loss: 1.1203, policy_loss: 1.2504, value_loss: 0.8080
2024-07-14 05:50:29,537 [INFO    ] __main__: train step 8324: loss: 1.1203, policy_loss: 1.2503, value_loss: 0.8080
2024-07-14 05:50:29,802 [INFO    ] __main__: train step 8325: loss: 1.1203, policy_loss: 1.2503, value_loss: 0.8080
2024-07-14 05:50:30,038 [INFO    ] __main__: train step 8326: loss: 1.1204, policy_loss: 1.2502, value_loss: 0.8079
2024-07-14 05:50:31,669 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:50:32,175 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:50:32,245 [INFO    ] __main__: train step 8327: loss: 1.1204, policy_loss: 1.2502, value_loss: 0.8079
2024-07-14 05:50:32,506 [INFO    ] __main__: train step 8328: loss: 1.1204, policy_loss: 1.2501, value_loss: 0.8079
2024-07-14 05:50:32,767 [INFO    ] __main__: train step 8329: loss: 1.1204, policy_loss: 1.2500, value_loss: 0.8079
2024-07-14 05:50:33,028 [INFO    ] __main__: train step 8330: loss: 1.1204, policy_loss: 1.2500, value_loss: 0.8078
2024-07-14 05:50:33,296 [INFO    ] __main__: train step 8331: loss: 1.1205, policy_loss: 1.2499, value_loss: 0.8078
2024-07-14 05:50:33,546 [INFO    ] __main__: train step 8332: loss: 1.1205, policy_loss: 1.2499, value_loss: 0.8078
2024-07-14 05:50:33,808 [INFO    ] __main__: train step 8333: loss: 1.1205, policy_loss: 1.2498, value_loss: 0.8077
2024-07-14 05:50:34,077 [INFO    ] __main__: train step 8334: loss: 1.1205, policy_loss: 1.2497, value_loss: 0.8077
2024-07-14 05:50:34,347 [INFO    ] __main__: train step 8335: loss: 1.1205, policy_loss: 1.2497, value_loss: 0.8077
2024-07-14 05:50:34,617 [INFO    ] __main__: train step 8336: loss: 1.1206, policy_loss: 1.2496, value_loss: 0.8076
2024-07-14 05:50:34,904 [INFO    ] __main__: train step 8337: loss: 1.1206, policy_loss: 1.2495, value_loss: 0.8076
2024-07-14 05:50:35,194 [INFO    ] __main__: train step 8338: loss: 1.1206, policy_loss: 1.2495, value_loss: 0.8076
2024-07-14 05:50:35,484 [INFO    ] __main__: train step 8339: loss: 1.1206, policy_loss: 1.2494, value_loss: 0.8076
2024-07-14 05:50:35,768 [INFO    ] __main__: train step 8340: loss: 1.1206, policy_loss: 1.2494, value_loss: 0.8075
2024-07-14 05:50:36,058 [INFO    ] __main__: train step 8341: loss: 1.1207, policy_loss: 1.2493, value_loss: 0.8075
2024-07-14 05:50:36,344 [INFO    ] __main__: train step 8342: loss: 1.1207, policy_loss: 1.2492, value_loss: 0.8075
2024-07-14 05:50:36,637 [INFO    ] __main__: train step 8343: loss: 1.1207, policy_loss: 1.2492, value_loss: 0.8074
2024-07-14 05:50:38,274 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:50:38,756 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:50:38,828 [INFO    ] __main__: train step 8344: loss: 1.1207, policy_loss: 1.2491, value_loss: 0.8074
2024-07-14 05:50:39,107 [INFO    ] __main__: train step 8345: loss: 1.1207, policy_loss: 1.2490, value_loss: 0.8074
2024-07-14 05:50:39,370 [INFO    ] __main__: train step 8346: loss: 1.1208, policy_loss: 1.2490, value_loss: 0.8073
2024-07-14 05:50:39,622 [INFO    ] __main__: train step 8347: loss: 1.1208, policy_loss: 1.2489, value_loss: 0.8073
2024-07-14 05:50:39,902 [INFO    ] __main__: train step 8348: loss: 1.1208, policy_loss: 1.2489, value_loss: 0.8073
2024-07-14 05:50:41,828 [INFO    ] __main__: train step 8349: loss: 1.1208, policy_loss: 1.2488, value_loss: 0.8073
2024-07-14 05:50:42,124 [INFO    ] __main__: train step 8350: loss: 1.1208, policy_loss: 1.2487, value_loss: 0.8072
2024-07-14 05:50:42,442 [INFO    ] __main__: train step 8351: loss: 1.1209, policy_loss: 1.2487, value_loss: 0.8072
2024-07-14 05:50:42,739 [INFO    ] __main__: train step 8352: loss: 1.1209, policy_loss: 1.2486, value_loss: 0.8072
2024-07-14 05:50:43,043 [INFO    ] __main__: train step 8353: loss: 1.1209, policy_loss: 1.2485, value_loss: 0.8071
2024-07-14 05:50:43,343 [INFO    ] __main__: train step 8354: loss: 1.1209, policy_loss: 1.2485, value_loss: 0.8071
2024-07-14 05:50:43,652 [INFO    ] __main__: train step 8355: loss: 1.1209, policy_loss: 1.2484, value_loss: 0.8071
2024-07-14 05:50:43,972 [INFO    ] __main__: train step 8356: loss: 1.1209, policy_loss: 1.2483, value_loss: 0.8070
2024-07-14 05:50:44,269 [INFO    ] __main__: train step 8357: loss: 1.1210, policy_loss: 1.2483, value_loss: 0.8070
2024-07-14 05:50:44,560 [INFO    ] __main__: train step 8358: loss: 1.1210, policy_loss: 1.2482, value_loss: 0.8070
2024-07-14 05:50:44,854 [INFO    ] __main__: train step 8359: loss: 1.1210, policy_loss: 1.2482, value_loss: 0.8069
2024-07-14 05:50:45,146 [INFO    ] __main__: train step 8360: loss: 1.1210, policy_loss: 1.2481, value_loss: 0.8069
2024-07-14 05:50:46,781 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:50:47,298 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:50:47,372 [INFO    ] __main__: train step 8361: loss: 1.1210, policy_loss: 1.2480, value_loss: 0.8069
2024-07-14 05:50:47,666 [INFO    ] __main__: train step 8362: loss: 1.1210, policy_loss: 1.2480, value_loss: 0.8069
2024-07-14 05:50:47,964 [INFO    ] __main__: train step 8363: loss: 1.1211, policy_loss: 1.2479, value_loss: 0.8068
2024-07-14 05:50:48,271 [INFO    ] __main__: train step 8364: loss: 1.1211, policy_loss: 1.2478, value_loss: 0.8068
2024-07-14 05:50:48,562 [INFO    ] __main__: train step 8365: loss: 1.1211, policy_loss: 1.2478, value_loss: 0.8068
2024-07-14 05:50:48,855 [INFO    ] __main__: train step 8366: loss: 1.1211, policy_loss: 1.2477, value_loss: 0.8067
2024-07-14 05:50:49,172 [INFO    ] __main__: train step 8367: loss: 1.1211, policy_loss: 1.2477, value_loss: 0.8067
2024-07-14 05:50:49,462 [INFO    ] __main__: train step 8368: loss: 1.1212, policy_loss: 1.2476, value_loss: 0.8067
2024-07-14 05:50:49,767 [INFO    ] __main__: train step 8369: loss: 1.1212, policy_loss: 1.2475, value_loss: 0.8066
2024-07-14 05:50:50,069 [INFO    ] __main__: train step 8370: loss: 1.1212, policy_loss: 1.2475, value_loss: 0.8066
2024-07-14 05:50:50,363 [INFO    ] __main__: train step 8371: loss: 1.1212, policy_loss: 1.2474, value_loss: 0.8066
2024-07-14 05:50:50,655 [INFO    ] __main__: train step 8372: loss: 1.1212, policy_loss: 1.2473, value_loss: 0.8065
2024-07-14 05:50:50,949 [INFO    ] __main__: train step 8373: loss: 1.1212, policy_loss: 1.2473, value_loss: 0.8065
2024-07-14 05:50:51,244 [INFO    ] __main__: train step 8374: loss: 1.1213, policy_loss: 1.2472, value_loss: 0.8065
2024-07-14 05:50:51,535 [INFO    ] __main__: train step 8375: loss: 1.1213, policy_loss: 1.2472, value_loss: 0.8064
2024-07-14 05:50:51,830 [INFO    ] __main__: train step 8376: loss: 1.1213, policy_loss: 1.2471, value_loss: 0.8064
2024-07-14 05:50:52,123 [INFO    ] __main__: train step 8377: loss: 1.1213, policy_loss: 1.2470, value_loss: 0.8064
2024-07-14 05:50:53,750 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:50:54,238 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:50:54,308 [INFO    ] __main__: train step 8378: loss: 1.1213, policy_loss: 1.2470, value_loss: 0.8064
2024-07-14 05:50:54,583 [INFO    ] __main__: train step 8379: loss: 1.1213, policy_loss: 1.2469, value_loss: 0.8063
2024-07-14 05:50:54,886 [INFO    ] __main__: train step 8380: loss: 1.1214, policy_loss: 1.2468, value_loss: 0.8063
2024-07-14 05:50:55,167 [INFO    ] __main__: train step 8381: loss: 1.1214, policy_loss: 1.2468, value_loss: 0.8063
2024-07-14 05:50:55,428 [INFO    ] __main__: train step 8382: loss: 1.1214, policy_loss: 1.2467, value_loss: 0.8062
2024-07-14 05:50:55,713 [INFO    ] __main__: train step 8383: loss: 1.1214, policy_loss: 1.2467, value_loss: 0.8062
2024-07-14 05:50:56,009 [INFO    ] __main__: train step 8384: loss: 1.1214, policy_loss: 1.2466, value_loss: 0.8062
2024-07-14 05:50:56,299 [INFO    ] __main__: train step 8385: loss: 1.1215, policy_loss: 1.2465, value_loss: 0.8061
2024-07-14 05:50:56,590 [INFO    ] __main__: train step 8386: loss: 1.1215, policy_loss: 1.2465, value_loss: 0.8061
2024-07-14 05:50:56,887 [INFO    ] __main__: train step 8387: loss: 1.1215, policy_loss: 1.2464, value_loss: 0.8061
2024-07-14 05:50:57,177 [INFO    ] __main__: train step 8388: loss: 1.1215, policy_loss: 1.2463, value_loss: 0.8061
2024-07-14 05:50:57,458 [INFO    ] __main__: train step 8389: loss: 1.1215, policy_loss: 1.2463, value_loss: 0.8060
2024-07-14 05:50:57,716 [INFO    ] __main__: train step 8390: loss: 1.1215, policy_loss: 1.2462, value_loss: 0.8060
2024-07-14 05:50:58,005 [INFO    ] __main__: train step 8391: loss: 1.1216, policy_loss: 1.2462, value_loss: 0.8060
2024-07-14 05:50:58,298 [INFO    ] __main__: train step 8392: loss: 1.1216, policy_loss: 1.2461, value_loss: 0.8059
2024-07-14 05:50:58,592 [INFO    ] __main__: train step 8393: loss: 1.1216, policy_loss: 1.2460, value_loss: 0.8059
2024-07-14 05:50:58,876 [INFO    ] __main__: train step 8394: loss: 1.1216, policy_loss: 1.2460, value_loss: 0.8059
2024-07-14 05:51:00,515 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:51:01,009 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:51:01,084 [INFO    ] __main__: train step 8395: loss: 1.1216, policy_loss: 1.2459, value_loss: 0.8058
2024-07-14 05:51:01,387 [INFO    ] __main__: train step 8396: loss: 1.1217, policy_loss: 1.2458, value_loss: 0.8058
2024-07-14 05:51:01,673 [INFO    ] __main__: train step 8397: loss: 1.1217, policy_loss: 1.2458, value_loss: 0.8058
2024-07-14 05:51:01,959 [INFO    ] __main__: train step 8398: loss: 1.1217, policy_loss: 1.2457, value_loss: 0.8057
2024-07-14 05:51:02,246 [INFO    ] __main__: train step 8399: loss: 1.1217, policy_loss: 1.2457, value_loss: 0.8057
2024-07-14 05:51:02,542 [INFO    ] __main__: train step 8400: loss: 1.1217, policy_loss: 1.2456, value_loss: 0.8057
2024-07-14 05:51:02,817 [INFO    ] __main__: train step 8401: loss: 1.1217, policy_loss: 1.2455, value_loss: 0.8057
2024-07-14 05:51:03,102 [INFO    ] __main__: train step 8402: loss: 1.1218, policy_loss: 1.2455, value_loss: 0.8056
2024-07-14 05:51:04,900 [INFO    ] __main__: train step 8403: loss: 1.1218, policy_loss: 1.2454, value_loss: 0.8056
2024-07-14 05:51:05,211 [INFO    ] __main__: train step 8404: loss: 1.1218, policy_loss: 1.2453, value_loss: 0.8056
2024-07-14 05:51:05,510 [INFO    ] __main__: train step 8405: loss: 1.1218, policy_loss: 1.2453, value_loss: 0.8055
2024-07-14 05:51:05,805 [INFO    ] __main__: train step 8406: loss: 1.1218, policy_loss: 1.2452, value_loss: 0.8055
2024-07-14 05:51:06,097 [INFO    ] __main__: train step 8407: loss: 1.1218, policy_loss: 1.2452, value_loss: 0.8055
2024-07-14 05:51:06,387 [INFO    ] __main__: train step 8408: loss: 1.1219, policy_loss: 1.2451, value_loss: 0.8054
2024-07-14 05:51:06,671 [INFO    ] __main__: train step 8409: loss: 1.1219, policy_loss: 1.2450, value_loss: 0.8054
2024-07-14 05:51:06,963 [INFO    ] __main__: train step 8410: loss: 1.1219, policy_loss: 1.2450, value_loss: 0.8054
2024-07-14 05:51:07,253 [INFO    ] __main__: train step 8411: loss: 1.1219, policy_loss: 1.2449, value_loss: 0.8053
2024-07-14 05:51:08,849 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:51:09,335 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:51:09,407 [INFO    ] __main__: train step 8412: loss: 1.1219, policy_loss: 1.2448, value_loss: 0.8053
2024-07-14 05:51:09,702 [INFO    ] __main__: train step 8413: loss: 1.1219, policy_loss: 1.2448, value_loss: 0.8053
2024-07-14 05:51:09,996 [INFO    ] __main__: train step 8414: loss: 1.1220, policy_loss: 1.2447, value_loss: 0.8053
2024-07-14 05:51:10,295 [INFO    ] __main__: train step 8415: loss: 1.1220, policy_loss: 1.2447, value_loss: 0.8052
2024-07-14 05:51:10,592 [INFO    ] __main__: train step 8416: loss: 1.1220, policy_loss: 1.2446, value_loss: 0.8052
2024-07-14 05:51:10,882 [INFO    ] __main__: train step 8417: loss: 1.1220, policy_loss: 1.2445, value_loss: 0.8052
2024-07-14 05:51:11,175 [INFO    ] __main__: train step 8418: loss: 1.1220, policy_loss: 1.2445, value_loss: 0.8051
2024-07-14 05:51:11,476 [INFO    ] __main__: train step 8419: loss: 1.1220, policy_loss: 1.2444, value_loss: 0.8051
2024-07-14 05:51:11,782 [INFO    ] __main__: train step 8420: loss: 1.1221, policy_loss: 1.2443, value_loss: 0.8051
2024-07-14 05:51:12,073 [INFO    ] __main__: train step 8421: loss: 1.1221, policy_loss: 1.2443, value_loss: 0.8050
2024-07-14 05:51:12,376 [INFO    ] __main__: train step 8422: loss: 1.1221, policy_loss: 1.2442, value_loss: 0.8050
2024-07-14 05:51:12,672 [INFO    ] __main__: train step 8423: loss: 1.1221, policy_loss: 1.2442, value_loss: 0.8050
2024-07-14 05:51:12,977 [INFO    ] __main__: train step 8424: loss: 1.1221, policy_loss: 1.2441, value_loss: 0.8049
2024-07-14 05:51:13,270 [INFO    ] __main__: train step 8425: loss: 1.1221, policy_loss: 1.2440, value_loss: 0.8049
2024-07-14 05:51:13,547 [INFO    ] __main__: train step 8426: loss: 1.1222, policy_loss: 1.2440, value_loss: 0.8049
2024-07-14 05:51:13,845 [INFO    ] __main__: train step 8427: loss: 1.1222, policy_loss: 1.2439, value_loss: 0.8049
2024-07-14 05:51:14,140 [INFO    ] __main__: train step 8428: loss: 1.1222, policy_loss: 1.2439, value_loss: 0.8048
2024-07-14 05:51:15,757 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:51:16,263 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:51:16,332 [INFO    ] __main__: train step 8429: loss: 1.1222, policy_loss: 1.2438, value_loss: 0.8048
2024-07-14 05:51:16,628 [INFO    ] __main__: train step 8430: loss: 1.1222, policy_loss: 1.2437, value_loss: 0.8048
2024-07-14 05:51:16,918 [INFO    ] __main__: train step 8431: loss: 1.1223, policy_loss: 1.2437, value_loss: 0.8047
2024-07-14 05:51:17,245 [INFO    ] __main__: train step 8432: loss: 1.1223, policy_loss: 1.2436, value_loss: 0.8047
2024-07-14 05:51:17,536 [INFO    ] __main__: train step 8433: loss: 1.1223, policy_loss: 1.2435, value_loss: 0.8047
2024-07-14 05:51:17,847 [INFO    ] __main__: train step 8434: loss: 1.1223, policy_loss: 1.2435, value_loss: 0.8046
2024-07-14 05:51:18,151 [INFO    ] __main__: train step 8435: loss: 1.1223, policy_loss: 1.2434, value_loss: 0.8046
2024-07-14 05:51:18,465 [INFO    ] __main__: train step 8436: loss: 1.1223, policy_loss: 1.2433, value_loss: 0.8046
2024-07-14 05:51:18,766 [INFO    ] __main__: train step 8437: loss: 1.1224, policy_loss: 1.2433, value_loss: 0.8045
2024-07-14 05:51:19,063 [INFO    ] __main__: train step 8438: loss: 1.1224, policy_loss: 1.2432, value_loss: 0.8045
2024-07-14 05:51:19,387 [INFO    ] __main__: train step 8439: loss: 1.1224, policy_loss: 1.2432, value_loss: 0.8045
2024-07-14 05:51:19,675 [INFO    ] __main__: train step 8440: loss: 1.1224, policy_loss: 1.2431, value_loss: 0.8045
2024-07-14 05:51:19,970 [INFO    ] __main__: train step 8441: loss: 1.1224, policy_loss: 1.2430, value_loss: 0.8044
2024-07-14 05:51:20,264 [INFO    ] __main__: train step 8442: loss: 1.1224, policy_loss: 1.2430, value_loss: 0.8044
2024-07-14 05:51:20,574 [INFO    ] __main__: train step 8443: loss: 1.1225, policy_loss: 1.2429, value_loss: 0.8044
2024-07-14 05:51:20,870 [INFO    ] __main__: train step 8444: loss: 1.1225, policy_loss: 1.2429, value_loss: 0.8043
2024-07-14 05:51:21,163 [INFO    ] __main__: train step 8445: loss: 1.1225, policy_loss: 1.2428, value_loss: 0.8043
2024-07-14 05:51:22,762 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:51:23,256 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:51:23,328 [INFO    ] __main__: train step 8446: loss: 1.1225, policy_loss: 1.2427, value_loss: 0.8043
2024-07-14 05:51:23,621 [INFO    ] __main__: train step 8447: loss: 1.1225, policy_loss: 1.2427, value_loss: 0.8042
2024-07-14 05:51:23,909 [INFO    ] __main__: train step 8448: loss: 1.1225, policy_loss: 1.2426, value_loss: 0.8042
2024-07-14 05:51:24,190 [INFO    ] __main__: train step 8449: loss: 1.1225, policy_loss: 1.2425, value_loss: 0.8042
2024-07-14 05:51:24,482 [INFO    ] __main__: train step 8450: loss: 1.1226, policy_loss: 1.2425, value_loss: 0.8041
2024-07-14 05:51:24,772 [INFO    ] __main__: train step 8451: loss: 1.1226, policy_loss: 1.2424, value_loss: 0.8041
2024-07-14 05:51:25,059 [INFO    ] __main__: train step 8452: loss: 1.1226, policy_loss: 1.2423, value_loss: 0.8041
2024-07-14 05:51:25,346 [INFO    ] __main__: train step 8453: loss: 1.1226, policy_loss: 1.2423, value_loss: 0.8040
2024-07-14 05:51:25,637 [INFO    ] __main__: train step 8454: loss: 1.1226, policy_loss: 1.2422, value_loss: 0.8040
2024-07-14 05:51:25,916 [INFO    ] __main__: train step 8455: loss: 1.1226, policy_loss: 1.2422, value_loss: 0.8040
2024-07-14 05:51:26,202 [INFO    ] __main__: train step 8456: loss: 1.1226, policy_loss: 1.2421, value_loss: 0.8040
2024-07-14 05:51:26,478 [INFO    ] __main__: train step 8457: loss: 1.1227, policy_loss: 1.2420, value_loss: 0.8039
2024-07-14 05:51:28,398 [INFO    ] __main__: train step 8458: loss: 1.1227, policy_loss: 1.2420, value_loss: 0.8039
2024-07-14 05:51:28,699 [INFO    ] __main__: train step 8459: loss: 1.1227, policy_loss: 1.2419, value_loss: 0.8039
2024-07-14 05:51:28,993 [INFO    ] __main__: train step 8460: loss: 1.1227, policy_loss: 1.2418, value_loss: 0.8038
2024-07-14 05:51:29,295 [INFO    ] __main__: train step 8461: loss: 1.1227, policy_loss: 1.2418, value_loss: 0.8038
2024-07-14 05:51:29,583 [INFO    ] __main__: train step 8462: loss: 1.1227, policy_loss: 1.2417, value_loss: 0.8038
2024-07-14 05:51:31,182 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:51:31,673 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:51:31,744 [INFO    ] __main__: train step 8463: loss: 1.1227, policy_loss: 1.2417, value_loss: 0.8037
2024-07-14 05:51:32,030 [INFO    ] __main__: train step 8464: loss: 1.1227, policy_loss: 1.2416, value_loss: 0.8037
2024-07-14 05:51:32,317 [INFO    ] __main__: train step 8465: loss: 1.1228, policy_loss: 1.2415, value_loss: 0.8037
2024-07-14 05:51:32,606 [INFO    ] __main__: train step 8466: loss: 1.1228, policy_loss: 1.2415, value_loss: 0.8036
2024-07-14 05:51:32,894 [INFO    ] __main__: train step 8467: loss: 1.1228, policy_loss: 1.2414, value_loss: 0.8036
2024-07-14 05:51:33,189 [INFO    ] __main__: train step 8468: loss: 1.1228, policy_loss: 1.2413, value_loss: 0.8036
2024-07-14 05:51:33,469 [INFO    ] __main__: train step 8469: loss: 1.1228, policy_loss: 1.2413, value_loss: 0.8035
2024-07-14 05:51:33,757 [INFO    ] __main__: train step 8470: loss: 1.1228, policy_loss: 1.2412, value_loss: 0.8035
2024-07-14 05:51:34,024 [INFO    ] __main__: train step 8471: loss: 1.1228, policy_loss: 1.2411, value_loss: 0.8035
2024-07-14 05:51:34,287 [INFO    ] __main__: train step 8472: loss: 1.1229, policy_loss: 1.2411, value_loss: 0.8034
2024-07-14 05:51:34,545 [INFO    ] __main__: train step 8473: loss: 1.1229, policy_loss: 1.2410, value_loss: 0.8034
2024-07-14 05:51:34,807 [INFO    ] __main__: train step 8474: loss: 1.1229, policy_loss: 1.2410, value_loss: 0.8034
2024-07-14 05:51:35,084 [INFO    ] __main__: train step 8475: loss: 1.1229, policy_loss: 1.2409, value_loss: 0.8033
2024-07-14 05:51:35,353 [INFO    ] __main__: train step 8476: loss: 1.1229, policy_loss: 1.2408, value_loss: 0.8033
2024-07-14 05:51:35,615 [INFO    ] __main__: train step 8477: loss: 1.1229, policy_loss: 1.2408, value_loss: 0.8033
2024-07-14 05:51:35,874 [INFO    ] __main__: train step 8478: loss: 1.1229, policy_loss: 1.2407, value_loss: 0.8032
2024-07-14 05:51:36,132 [INFO    ] __main__: train step 8479: loss: 1.1230, policy_loss: 1.2406, value_loss: 0.8032
2024-07-14 05:51:37,714 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:51:38,180 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:51:38,246 [INFO    ] __main__: train step 8480: loss: 1.1230, policy_loss: 1.2406, value_loss: 0.8032
2024-07-14 05:51:38,531 [INFO    ] __main__: train step 8481: loss: 1.1230, policy_loss: 1.2405, value_loss: 0.8031
2024-07-14 05:51:38,802 [INFO    ] __main__: train step 8482: loss: 1.1230, policy_loss: 1.2405, value_loss: 0.8031
2024-07-14 05:51:39,063 [INFO    ] __main__: train step 8483: loss: 1.1230, policy_loss: 1.2404, value_loss: 0.8031
2024-07-14 05:51:39,315 [INFO    ] __main__: train step 8484: loss: 1.1230, policy_loss: 1.2403, value_loss: 0.8031
2024-07-14 05:51:39,571 [INFO    ] __main__: train step 8485: loss: 1.1230, policy_loss: 1.2403, value_loss: 0.8030
2024-07-14 05:51:39,818 [INFO    ] __main__: train step 8486: loss: 1.1231, policy_loss: 1.2402, value_loss: 0.8030
2024-07-14 05:51:40,070 [INFO    ] __main__: train step 8487: loss: 1.1231, policy_loss: 1.2401, value_loss: 0.8030
2024-07-14 05:51:40,318 [INFO    ] __main__: train step 8488: loss: 1.1231, policy_loss: 1.2401, value_loss: 0.8029
2024-07-14 05:51:40,592 [INFO    ] __main__: train step 8489: loss: 1.1231, policy_loss: 1.2400, value_loss: 0.8029
2024-07-14 05:51:40,836 [INFO    ] __main__: train step 8490: loss: 1.1231, policy_loss: 1.2400, value_loss: 0.8029
2024-07-14 05:51:41,083 [INFO    ] __main__: train step 8491: loss: 1.1231, policy_loss: 1.2399, value_loss: 0.8028
2024-07-14 05:51:41,337 [INFO    ] __main__: train step 8492: loss: 1.1231, policy_loss: 1.2398, value_loss: 0.8028
2024-07-14 05:51:41,600 [INFO    ] __main__: train step 8493: loss: 1.1231, policy_loss: 1.2398, value_loss: 0.8028
2024-07-14 05:51:41,837 [INFO    ] __main__: train step 8494: loss: 1.1232, policy_loss: 1.2397, value_loss: 0.8027
2024-07-14 05:51:42,089 [INFO    ] __main__: train step 8495: loss: 1.1232, policy_loss: 1.2396, value_loss: 0.8027
2024-07-14 05:51:42,334 [INFO    ] __main__: train step 8496: loss: 1.1232, policy_loss: 1.2396, value_loss: 0.8027
2024-07-14 05:51:43,919 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:51:44,379 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:51:44,447 [INFO    ] __main__: train step 8497: loss: 1.1232, policy_loss: 1.2395, value_loss: 0.8026
2024-07-14 05:51:44,704 [INFO    ] __main__: train step 8498: loss: 1.1232, policy_loss: 1.2395, value_loss: 0.8026
2024-07-14 05:51:44,960 [INFO    ] __main__: train step 8499: loss: 1.1232, policy_loss: 1.2394, value_loss: 0.8026
2024-07-14 05:51:45,211 [INFO    ] __main__: train step 8500: loss: 1.1232, policy_loss: 1.2393, value_loss: 0.8025
2024-07-14 05:51:45,464 [INFO    ] __main__: train step 8501: loss: 1.1233, policy_loss: 1.2393, value_loss: 0.8025
2024-07-14 05:51:45,710 [INFO    ] __main__: train step 8502: loss: 1.1233, policy_loss: 1.2392, value_loss: 0.8025
2024-07-14 05:51:45,972 [INFO    ] __main__: train step 8503: loss: 1.1233, policy_loss: 1.2391, value_loss: 0.8024
2024-07-14 05:51:46,244 [INFO    ] __main__: train step 8504: loss: 1.1233, policy_loss: 1.2391, value_loss: 0.8024
2024-07-14 05:51:46,501 [INFO    ] __main__: train step 8505: loss: 1.1233, policy_loss: 1.2390, value_loss: 0.8024
2024-07-14 05:51:46,762 [INFO    ] __main__: train step 8506: loss: 1.1233, policy_loss: 1.2390, value_loss: 0.8023
2024-07-14 05:51:47,016 [INFO    ] __main__: train step 8507: loss: 1.1233, policy_loss: 1.2389, value_loss: 0.8023
2024-07-14 05:51:47,275 [INFO    ] __main__: train step 8508: loss: 1.1233, policy_loss: 1.2388, value_loss: 0.8023
2024-07-14 05:51:47,550 [INFO    ] __main__: train step 8509: loss: 1.1234, policy_loss: 1.2388, value_loss: 0.8022
2024-07-14 05:51:47,805 [INFO    ] __main__: train step 8510: loss: 1.1234, policy_loss: 1.2387, value_loss: 0.8022
2024-07-14 05:51:48,086 [INFO    ] __main__: train step 8511: loss: 1.1234, policy_loss: 1.2386, value_loss: 0.8022
2024-07-14 05:51:49,949 [INFO    ] __main__: train step 8512: loss: 1.1234, policy_loss: 1.2386, value_loss: 0.8021
2024-07-14 05:51:50,235 [INFO    ] __main__: train step 8513: loss: 1.1234, policy_loss: 1.2385, value_loss: 0.8021
2024-07-14 05:51:51,869 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:51:52,374 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:51:52,442 [INFO    ] __main__: train step 8514: loss: 1.1234, policy_loss: 1.2385, value_loss: 0.8021
2024-07-14 05:51:52,729 [INFO    ] __main__: train step 8515: loss: 1.1234, policy_loss: 1.2384, value_loss: 0.8020
2024-07-14 05:51:53,018 [INFO    ] __main__: train step 8516: loss: 1.1234, policy_loss: 1.2383, value_loss: 0.8020
2024-07-14 05:51:53,314 [INFO    ] __main__: train step 8517: loss: 1.1234, policy_loss: 1.2383, value_loss: 0.8020
2024-07-14 05:51:53,614 [INFO    ] __main__: train step 8518: loss: 1.1235, policy_loss: 1.2382, value_loss: 0.8020
2024-07-14 05:51:53,913 [INFO    ] __main__: train step 8519: loss: 1.1235, policy_loss: 1.2381, value_loss: 0.8019
2024-07-14 05:51:54,211 [INFO    ] __main__: train step 8520: loss: 1.1235, policy_loss: 1.2381, value_loss: 0.8019
2024-07-14 05:51:54,501 [INFO    ] __main__: train step 8521: loss: 1.1235, policy_loss: 1.2380, value_loss: 0.8019
2024-07-14 05:51:54,799 [INFO    ] __main__: train step 8522: loss: 1.1235, policy_loss: 1.2379, value_loss: 0.8018
2024-07-14 05:51:55,096 [INFO    ] __main__: train step 8523: loss: 1.1235, policy_loss: 1.2379, value_loss: 0.8018
2024-07-14 05:51:55,388 [INFO    ] __main__: train step 8524: loss: 1.1235, policy_loss: 1.2378, value_loss: 0.8018
2024-07-14 05:51:55,679 [INFO    ] __main__: train step 8525: loss: 1.1235, policy_loss: 1.2378, value_loss: 0.8017
2024-07-14 05:51:55,976 [INFO    ] __main__: train step 8526: loss: 1.1236, policy_loss: 1.2377, value_loss: 0.8017
2024-07-14 05:51:56,272 [INFO    ] __main__: train step 8527: loss: 1.1236, policy_loss: 1.2376, value_loss: 0.8017
2024-07-14 05:51:56,571 [INFO    ] __main__: train step 8528: loss: 1.1236, policy_loss: 1.2376, value_loss: 0.8016
2024-07-14 05:51:56,874 [INFO    ] __main__: train step 8529: loss: 1.1236, policy_loss: 1.2375, value_loss: 0.8016
2024-07-14 05:51:57,166 [INFO    ] __main__: train step 8530: loss: 1.1236, policy_loss: 1.2374, value_loss: 0.8016
2024-07-14 05:51:58,764 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:51:59,255 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:51:59,324 [INFO    ] __main__: train step 8531: loss: 1.1236, policy_loss: 1.2374, value_loss: 0.8015
2024-07-14 05:51:59,612 [INFO    ] __main__: train step 8532: loss: 1.1236, policy_loss: 1.2373, value_loss: 0.8015
2024-07-14 05:51:59,907 [INFO    ] __main__: train step 8533: loss: 1.1236, policy_loss: 1.2372, value_loss: 0.8015
2024-07-14 05:52:00,199 [INFO    ] __main__: train step 8534: loss: 1.1236, policy_loss: 1.2372, value_loss: 0.8014
2024-07-14 05:52:00,485 [INFO    ] __main__: train step 8535: loss: 1.1236, policy_loss: 1.2371, value_loss: 0.8014
2024-07-14 05:52:00,777 [INFO    ] __main__: train step 8536: loss: 1.1237, policy_loss: 1.2371, value_loss: 0.8014
2024-07-14 05:52:01,082 [INFO    ] __main__: train step 8537: loss: 1.1237, policy_loss: 1.2370, value_loss: 0.8013
2024-07-14 05:52:01,380 [INFO    ] __main__: train step 8538: loss: 1.1237, policy_loss: 1.2369, value_loss: 0.8013
2024-07-14 05:52:01,667 [INFO    ] __main__: train step 8539: loss: 1.1237, policy_loss: 1.2369, value_loss: 0.8013
2024-07-14 05:52:01,964 [INFO    ] __main__: train step 8540: loss: 1.1237, policy_loss: 1.2368, value_loss: 0.8012
2024-07-14 05:52:02,250 [INFO    ] __main__: train step 8541: loss: 1.1237, policy_loss: 1.2367, value_loss: 0.8012
2024-07-14 05:52:02,548 [INFO    ] __main__: train step 8542: loss: 1.1237, policy_loss: 1.2367, value_loss: 0.8012
2024-07-14 05:52:02,847 [INFO    ] __main__: train step 8543: loss: 1.1237, policy_loss: 1.2366, value_loss: 0.8011
2024-07-14 05:52:03,140 [INFO    ] __main__: train step 8544: loss: 1.1238, policy_loss: 1.2366, value_loss: 0.8011
2024-07-14 05:52:03,434 [INFO    ] __main__: train step 8545: loss: 1.1238, policy_loss: 1.2365, value_loss: 0.8011
2024-07-14 05:52:03,731 [INFO    ] __main__: train step 8546: loss: 1.1238, policy_loss: 1.2364, value_loss: 0.8010
2024-07-14 05:52:04,027 [INFO    ] __main__: train step 8547: loss: 1.1238, policy_loss: 1.2364, value_loss: 0.8010
2024-07-14 05:52:05,652 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:52:06,145 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:52:06,214 [INFO    ] __main__: train step 8548: loss: 1.1238, policy_loss: 1.2363, value_loss: 0.8010
2024-07-14 05:52:06,517 [INFO    ] __main__: train step 8549: loss: 1.1238, policy_loss: 1.2362, value_loss: 0.8009
2024-07-14 05:52:06,819 [INFO    ] __main__: train step 8550: loss: 1.1238, policy_loss: 1.2362, value_loss: 0.8009
2024-07-14 05:52:07,113 [INFO    ] __main__: train step 8551: loss: 1.1238, policy_loss: 1.2361, value_loss: 0.8009
2024-07-14 05:52:07,410 [INFO    ] __main__: train step 8552: loss: 1.1238, policy_loss: 1.2360, value_loss: 0.8008
2024-07-14 05:52:07,689 [INFO    ] __main__: train step 8553: loss: 1.1238, policy_loss: 1.2360, value_loss: 0.8008
2024-07-14 05:52:07,971 [INFO    ] __main__: train step 8554: loss: 1.1239, policy_loss: 1.2359, value_loss: 0.8008
2024-07-14 05:52:08,268 [INFO    ] __main__: train step 8555: loss: 1.1239, policy_loss: 1.2359, value_loss: 0.8007
2024-07-14 05:52:08,564 [INFO    ] __main__: train step 8556: loss: 1.1239, policy_loss: 1.2358, value_loss: 0.8007
2024-07-14 05:52:08,843 [INFO    ] __main__: train step 8557: loss: 1.1239, policy_loss: 1.2357, value_loss: 0.8007
2024-07-14 05:52:09,141 [INFO    ] __main__: train step 8558: loss: 1.1239, policy_loss: 1.2357, value_loss: 0.8006
2024-07-14 05:52:09,426 [INFO    ] __main__: train step 8559: loss: 1.1239, policy_loss: 1.2356, value_loss: 0.8006
2024-07-14 05:52:09,710 [INFO    ] __main__: train step 8560: loss: 1.1239, policy_loss: 1.2355, value_loss: 0.8006
2024-07-14 05:52:10,007 [INFO    ] __main__: train step 8561: loss: 1.1239, policy_loss: 1.2355, value_loss: 0.8005
2024-07-14 05:52:10,292 [INFO    ] __main__: train step 8562: loss: 1.1240, policy_loss: 1.2354, value_loss: 0.8005
2024-07-14 05:52:10,577 [INFO    ] __main__: train step 8563: loss: 1.1240, policy_loss: 1.2354, value_loss: 0.8005
2024-07-14 05:52:10,852 [INFO    ] __main__: train step 8564: loss: 1.1240, policy_loss: 1.2353, value_loss: 0.8005
2024-07-14 05:52:12,463 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:52:12,963 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:52:13,041 [INFO    ] __main__: train step 8565: loss: 1.1240, policy_loss: 1.2352, value_loss: 0.8004
2024-07-14 05:52:13,338 [INFO    ] __main__: train step 8566: loss: 1.1240, policy_loss: 1.2352, value_loss: 0.8004
2024-07-14 05:52:13,644 [INFO    ] __main__: train step 8567: loss: 1.1240, policy_loss: 1.2351, value_loss: 0.8003
2024-07-14 05:52:15,540 [INFO    ] __main__: train step 8568: loss: 1.1240, policy_loss: 1.2350, value_loss: 0.8003
2024-07-14 05:52:15,831 [INFO    ] __main__: train step 8569: loss: 1.1240, policy_loss: 1.2350, value_loss: 0.8003
2024-07-14 05:52:16,134 [INFO    ] __main__: train step 8570: loss: 1.1240, policy_loss: 1.2349, value_loss: 0.8002
2024-07-14 05:52:16,432 [INFO    ] __main__: train step 8571: loss: 1.1240, policy_loss: 1.2349, value_loss: 0.8002
2024-07-14 05:52:16,728 [INFO    ] __main__: train step 8572: loss: 1.1241, policy_loss: 1.2348, value_loss: 0.8002
2024-07-14 05:52:17,030 [INFO    ] __main__: train step 8573: loss: 1.1241, policy_loss: 1.2347, value_loss: 0.8001
2024-07-14 05:52:17,332 [INFO    ] __main__: train step 8574: loss: 1.1241, policy_loss: 1.2347, value_loss: 0.8001
2024-07-14 05:52:17,644 [INFO    ] __main__: train step 8575: loss: 1.1241, policy_loss: 1.2346, value_loss: 0.8001
2024-07-14 05:52:17,957 [INFO    ] __main__: train step 8576: loss: 1.1241, policy_loss: 1.2345, value_loss: 0.8000
2024-07-14 05:52:18,260 [INFO    ] __main__: train step 8577: loss: 1.1241, policy_loss: 1.2345, value_loss: 0.8000
2024-07-14 05:52:18,549 [INFO    ] __main__: train step 8578: loss: 1.1241, policy_loss: 1.2344, value_loss: 0.8000
2024-07-14 05:52:18,855 [INFO    ] __main__: train step 8579: loss: 1.1241, policy_loss: 1.2343, value_loss: 0.8000
2024-07-14 05:52:19,155 [INFO    ] __main__: train step 8580: loss: 1.1241, policy_loss: 1.2343, value_loss: 0.7999
2024-07-14 05:52:19,450 [INFO    ] __main__: train step 8581: loss: 1.1241, policy_loss: 1.2342, value_loss: 0.7999
2024-07-14 05:52:21,076 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:52:21,567 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:52:21,635 [INFO    ] __main__: train step 8582: loss: 1.1242, policy_loss: 1.2342, value_loss: 0.7999
2024-07-14 05:52:21,932 [INFO    ] __main__: train step 8583: loss: 1.1242, policy_loss: 1.2341, value_loss: 0.7998
2024-07-14 05:52:22,229 [INFO    ] __main__: train step 8584: loss: 1.1242, policy_loss: 1.2340, value_loss: 0.7998
2024-07-14 05:52:22,525 [INFO    ] __main__: train step 8585: loss: 1.1242, policy_loss: 1.2340, value_loss: 0.7998
2024-07-14 05:52:22,810 [INFO    ] __main__: train step 8586: loss: 1.1242, policy_loss: 1.2339, value_loss: 0.7997
2024-07-14 05:52:23,084 [INFO    ] __main__: train step 8587: loss: 1.1242, policy_loss: 1.2338, value_loss: 0.7997
2024-07-14 05:52:23,363 [INFO    ] __main__: train step 8588: loss: 1.1242, policy_loss: 1.2338, value_loss: 0.7997
2024-07-14 05:52:23,647 [INFO    ] __main__: train step 8589: loss: 1.1242, policy_loss: 1.2337, value_loss: 0.7996
2024-07-14 05:52:23,949 [INFO    ] __main__: train step 8590: loss: 1.1242, policy_loss: 1.2337, value_loss: 0.7996
2024-07-14 05:52:24,243 [INFO    ] __main__: train step 8591: loss: 1.1242, policy_loss: 1.2336, value_loss: 0.7995
2024-07-14 05:52:24,538 [INFO    ] __main__: train step 8592: loss: 1.1242, policy_loss: 1.2335, value_loss: 0.7995
2024-07-14 05:52:24,819 [INFO    ] __main__: train step 8593: loss: 1.1243, policy_loss: 1.2335, value_loss: 0.7995
2024-07-14 05:52:25,110 [INFO    ] __main__: train step 8594: loss: 1.1243, policy_loss: 1.2334, value_loss: 0.7994
2024-07-14 05:52:25,403 [INFO    ] __main__: train step 8595: loss: 1.1243, policy_loss: 1.2333, value_loss: 0.7994
2024-07-14 05:52:25,684 [INFO    ] __main__: train step 8596: loss: 1.1243, policy_loss: 1.2333, value_loss: 0.7994
2024-07-14 05:52:25,981 [INFO    ] __main__: train step 8597: loss: 1.1243, policy_loss: 1.2332, value_loss: 0.7994
2024-07-14 05:52:26,275 [INFO    ] __main__: train step 8598: loss: 1.1243, policy_loss: 1.2331, value_loss: 0.7993
2024-07-14 05:52:27,892 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:52:28,425 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:52:28,498 [INFO    ] __main__: train step 8599: loss: 1.1243, policy_loss: 1.2331, value_loss: 0.7993
2024-07-14 05:52:28,809 [INFO    ] __main__: train step 8600: loss: 1.1243, policy_loss: 1.2330, value_loss: 0.7993
2024-07-14 05:52:29,101 [INFO    ] __main__: train step 8601: loss: 1.1243, policy_loss: 1.2330, value_loss: 0.7992
2024-07-14 05:52:29,399 [INFO    ] __main__: train step 8602: loss: 1.1243, policy_loss: 1.2329, value_loss: 0.7992
2024-07-14 05:52:29,694 [INFO    ] __main__: train step 8603: loss: 1.1243, policy_loss: 1.2328, value_loss: 0.7992
2024-07-14 05:52:29,999 [INFO    ] __main__: train step 8604: loss: 1.1243, policy_loss: 1.2328, value_loss: 0.7991
2024-07-14 05:52:30,286 [INFO    ] __main__: train step 8605: loss: 1.1244, policy_loss: 1.2327, value_loss: 0.7991
2024-07-14 05:52:30,562 [INFO    ] __main__: train step 8606: loss: 1.1244, policy_loss: 1.2326, value_loss: 0.7991
2024-07-14 05:52:30,854 [INFO    ] __main__: train step 8607: loss: 1.1244, policy_loss: 1.2326, value_loss: 0.7990
2024-07-14 05:52:31,145 [INFO    ] __main__: train step 8608: loss: 1.1244, policy_loss: 1.2325, value_loss: 0.7990
2024-07-14 05:52:31,466 [INFO    ] __main__: train step 8609: loss: 1.1244, policy_loss: 1.2324, value_loss: 0.7989
2024-07-14 05:52:31,759 [INFO    ] __main__: train step 8610: loss: 1.1244, policy_loss: 1.2324, value_loss: 0.7989
2024-07-14 05:52:32,061 [INFO    ] __main__: train step 8611: loss: 1.1244, policy_loss: 1.2323, value_loss: 0.7989
2024-07-14 05:52:32,354 [INFO    ] __main__: train step 8612: loss: 1.1244, policy_loss: 1.2323, value_loss: 0.7988
2024-07-14 05:52:32,657 [INFO    ] __main__: train step 8613: loss: 1.1244, policy_loss: 1.2322, value_loss: 0.7988
2024-07-14 05:52:32,950 [INFO    ] __main__: train step 8614: loss: 1.1244, policy_loss: 1.2321, value_loss: 0.7988
2024-07-14 05:52:33,250 [INFO    ] __main__: train step 8615: loss: 1.1244, policy_loss: 1.2321, value_loss: 0.7987
2024-07-14 05:52:34,869 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:52:35,365 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:52:35,437 [INFO    ] __main__: train step 8616: loss: 1.1244, policy_loss: 1.2320, value_loss: 0.7987
2024-07-14 05:52:35,726 [INFO    ] __main__: train step 8617: loss: 1.1244, policy_loss: 1.2319, value_loss: 0.7987
2024-07-14 05:52:36,012 [INFO    ] __main__: train step 8618: loss: 1.1245, policy_loss: 1.2319, value_loss: 0.7986
2024-07-14 05:52:36,298 [INFO    ] __main__: train step 8619: loss: 1.1245, policy_loss: 1.2318, value_loss: 0.7986
2024-07-14 05:52:36,585 [INFO    ] __main__: train step 8620: loss: 1.1245, policy_loss: 1.2317, value_loss: 0.7986
2024-07-14 05:52:36,878 [INFO    ] __main__: train step 8621: loss: 1.1245, policy_loss: 1.2317, value_loss: 0.7985
2024-07-14 05:52:37,166 [INFO    ] __main__: train step 8622: loss: 1.1245, policy_loss: 1.2316, value_loss: 0.7985
2024-07-14 05:52:39,028 [INFO    ] __main__: train step 8623: loss: 1.1245, policy_loss: 1.2315, value_loss: 0.7985
2024-07-14 05:52:39,326 [INFO    ] __main__: train step 8624: loss: 1.1245, policy_loss: 1.2315, value_loss: 0.7984
2024-07-14 05:52:39,626 [INFO    ] __main__: train step 8625: loss: 1.1245, policy_loss: 1.2314, value_loss: 0.7984
2024-07-14 05:52:39,931 [INFO    ] __main__: train step 8626: loss: 1.1245, policy_loss: 1.2314, value_loss: 0.7984
2024-07-14 05:52:40,228 [INFO    ] __main__: train step 8627: loss: 1.1245, policy_loss: 1.2313, value_loss: 0.7983
2024-07-14 05:52:40,522 [INFO    ] __main__: train step 8628: loss: 1.1245, policy_loss: 1.2312, value_loss: 0.7983
2024-07-14 05:52:40,822 [INFO    ] __main__: train step 8629: loss: 1.1245, policy_loss: 1.2312, value_loss: 0.7983
2024-07-14 05:52:41,114 [INFO    ] __main__: train step 8630: loss: 1.1245, policy_loss: 1.2311, value_loss: 0.7982
2024-07-14 05:52:41,409 [INFO    ] __main__: train step 8631: loss: 1.1245, policy_loss: 1.2310, value_loss: 0.7982
2024-07-14 05:52:41,700 [INFO    ] __main__: train step 8632: loss: 1.1245, policy_loss: 1.2310, value_loss: 0.7982
2024-07-14 05:52:43,317 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:52:43,806 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:52:43,877 [INFO    ] __main__: train step 8633: loss: 1.1245, policy_loss: 1.2309, value_loss: 0.7981
2024-07-14 05:52:44,149 [INFO    ] __main__: train step 8634: loss: 1.1246, policy_loss: 1.2308, value_loss: 0.7981
2024-07-14 05:52:44,425 [INFO    ] __main__: train step 8635: loss: 1.1246, policy_loss: 1.2308, value_loss: 0.7981
2024-07-14 05:52:44,691 [INFO    ] __main__: train step 8636: loss: 1.1246, policy_loss: 1.2307, value_loss: 0.7980
2024-07-14 05:52:44,970 [INFO    ] __main__: train step 8637: loss: 1.1246, policy_loss: 1.2306, value_loss: 0.7980
2024-07-14 05:52:45,268 [INFO    ] __main__: train step 8638: loss: 1.1246, policy_loss: 1.2306, value_loss: 0.7980
2024-07-14 05:52:45,563 [INFO    ] __main__: train step 8639: loss: 1.1246, policy_loss: 1.2305, value_loss: 0.7979
2024-07-14 05:52:45,867 [INFO    ] __main__: train step 8640: loss: 1.1246, policy_loss: 1.2305, value_loss: 0.7979
2024-07-14 05:52:46,168 [INFO    ] __main__: train step 8641: loss: 1.1246, policy_loss: 1.2304, value_loss: 0.7979
2024-07-14 05:52:46,453 [INFO    ] __main__: train step 8642: loss: 1.1246, policy_loss: 1.2303, value_loss: 0.7978
2024-07-14 05:52:46,747 [INFO    ] __main__: train step 8643: loss: 1.1246, policy_loss: 1.2303, value_loss: 0.7978
2024-07-14 05:52:47,043 [INFO    ] __main__: train step 8644: loss: 1.1246, policy_loss: 1.2302, value_loss: 0.7978
2024-07-14 05:52:47,335 [INFO    ] __main__: train step 8645: loss: 1.1246, policy_loss: 1.2301, value_loss: 0.7977
2024-07-14 05:52:47,625 [INFO    ] __main__: train step 8646: loss: 1.1246, policy_loss: 1.2301, value_loss: 0.7977
2024-07-14 05:52:47,915 [INFO    ] __main__: train step 8647: loss: 1.1246, policy_loss: 1.2300, value_loss: 0.7977
2024-07-14 05:52:48,209 [INFO    ] __main__: train step 8648: loss: 1.1246, policy_loss: 1.2299, value_loss: 0.7976
2024-07-14 05:52:48,481 [INFO    ] __main__: train step 8649: loss: 1.1247, policy_loss: 1.2299, value_loss: 0.7976
2024-07-14 05:52:50,098 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:52:50,592 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:52:50,665 [INFO    ] __main__: train step 8650: loss: 1.1247, policy_loss: 1.2298, value_loss: 0.7976
2024-07-14 05:52:50,971 [INFO    ] __main__: train step 8651: loss: 1.1247, policy_loss: 1.2297, value_loss: 0.7975
2024-07-14 05:52:51,270 [INFO    ] __main__: train step 8652: loss: 1.1247, policy_loss: 1.2297, value_loss: 0.7975
2024-07-14 05:52:51,563 [INFO    ] __main__: train step 8653: loss: 1.1247, policy_loss: 1.2296, value_loss: 0.7975
2024-07-14 05:52:51,865 [INFO    ] __main__: train step 8654: loss: 1.1247, policy_loss: 1.2296, value_loss: 0.7974
2024-07-14 05:52:52,153 [INFO    ] __main__: train step 8655: loss: 1.1247, policy_loss: 1.2295, value_loss: 0.7974
2024-07-14 05:52:52,423 [INFO    ] __main__: train step 8656: loss: 1.1247, policy_loss: 1.2294, value_loss: 0.7974
2024-07-14 05:52:52,722 [INFO    ] __main__: train step 8657: loss: 1.1247, policy_loss: 1.2294, value_loss: 0.7973
2024-07-14 05:52:53,018 [INFO    ] __main__: train step 8658: loss: 1.1247, policy_loss: 1.2293, value_loss: 0.7973
2024-07-14 05:52:53,311 [INFO    ] __main__: train step 8659: loss: 1.1247, policy_loss: 1.2292, value_loss: 0.7973
2024-07-14 05:52:53,617 [INFO    ] __main__: train step 8660: loss: 1.1247, policy_loss: 1.2292, value_loss: 0.7972
2024-07-14 05:52:53,926 [INFO    ] __main__: train step 8661: loss: 1.1247, policy_loss: 1.2291, value_loss: 0.7972
2024-07-14 05:52:54,225 [INFO    ] __main__: train step 8662: loss: 1.1247, policy_loss: 1.2290, value_loss: 0.7972
2024-07-14 05:52:54,528 [INFO    ] __main__: train step 8663: loss: 1.1247, policy_loss: 1.2290, value_loss: 0.7971
2024-07-14 05:52:54,841 [INFO    ] __main__: train step 8664: loss: 1.1248, policy_loss: 1.2289, value_loss: 0.7971
2024-07-14 05:52:55,137 [INFO    ] __main__: train step 8665: loss: 1.1248, policy_loss: 1.2289, value_loss: 0.7971
2024-07-14 05:52:55,421 [INFO    ] __main__: train step 8666: loss: 1.1248, policy_loss: 1.2288, value_loss: 0.7970
2024-07-14 05:52:57,034 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:52:57,520 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:52:57,597 [INFO    ] __main__: train step 8667: loss: 1.1248, policy_loss: 1.2287, value_loss: 0.7970
2024-07-14 05:52:57,895 [INFO    ] __main__: train step 8668: loss: 1.1248, policy_loss: 1.2287, value_loss: 0.7969
2024-07-14 05:52:58,195 [INFO    ] __main__: train step 8669: loss: 1.1248, policy_loss: 1.2286, value_loss: 0.7969
2024-07-14 05:52:58,488 [INFO    ] __main__: train step 8670: loss: 1.1248, policy_loss: 1.2285, value_loss: 0.7969
2024-07-14 05:52:58,774 [INFO    ] __main__: train step 8671: loss: 1.1248, policy_loss: 1.2285, value_loss: 0.7968
2024-07-14 05:52:59,064 [INFO    ] __main__: train step 8672: loss: 1.1248, policy_loss: 1.2284, value_loss: 0.7968
2024-07-14 05:52:59,353 [INFO    ] __main__: train step 8673: loss: 1.1248, policy_loss: 1.2283, value_loss: 0.7968
2024-07-14 05:52:59,644 [INFO    ] __main__: train step 8674: loss: 1.1248, policy_loss: 1.2283, value_loss: 0.7967
2024-07-14 05:52:59,936 [INFO    ] __main__: train step 8675: loss: 1.1248, policy_loss: 1.2282, value_loss: 0.7967
2024-07-14 05:53:00,236 [INFO    ] __main__: train step 8676: loss: 1.1248, policy_loss: 1.2281, value_loss: 0.7967
2024-07-14 05:53:00,535 [INFO    ] __main__: train step 8677: loss: 1.1248, policy_loss: 1.2281, value_loss: 0.7966
2024-07-14 05:53:02,368 [INFO    ] __main__: train step 8678: loss: 1.1248, policy_loss: 1.2280, value_loss: 0.7966
2024-07-14 05:53:02,665 [INFO    ] __main__: train step 8679: loss: 1.1248, policy_loss: 1.2280, value_loss: 0.7966
2024-07-14 05:53:02,955 [INFO    ] __main__: train step 8680: loss: 1.1248, policy_loss: 1.2279, value_loss: 0.7965
2024-07-14 05:53:03,250 [INFO    ] __main__: train step 8681: loss: 1.1248, policy_loss: 1.2278, value_loss: 0.7965
2024-07-14 05:53:03,537 [INFO    ] __main__: train step 8682: loss: 1.1248, policy_loss: 1.2278, value_loss: 0.7965
2024-07-14 05:53:03,827 [INFO    ] __main__: train step 8683: loss: 1.1249, policy_loss: 1.2277, value_loss: 0.7964
2024-07-14 05:53:05,447 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:53:05,947 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:53:06,018 [INFO    ] __main__: train step 8684: loss: 1.1249, policy_loss: 1.2276, value_loss: 0.7964
2024-07-14 05:53:06,302 [INFO    ] __main__: train step 8685: loss: 1.1249, policy_loss: 1.2276, value_loss: 0.7964
2024-07-14 05:53:06,593 [INFO    ] __main__: train step 8686: loss: 1.1249, policy_loss: 1.2275, value_loss: 0.7963
2024-07-14 05:53:06,901 [INFO    ] __main__: train step 8687: loss: 1.1249, policy_loss: 1.2274, value_loss: 0.7963
2024-07-14 05:53:07,192 [INFO    ] __main__: train step 8688: loss: 1.1249, policy_loss: 1.2274, value_loss: 0.7963
2024-07-14 05:53:07,486 [INFO    ] __main__: train step 8689: loss: 1.1249, policy_loss: 1.2273, value_loss: 0.7962
2024-07-14 05:53:07,779 [INFO    ] __main__: train step 8690: loss: 1.1249, policy_loss: 1.2272, value_loss: 0.7962
2024-07-14 05:53:08,082 [INFO    ] __main__: train step 8691: loss: 1.1249, policy_loss: 1.2272, value_loss: 0.7962
2024-07-14 05:53:08,372 [INFO    ] __main__: train step 8692: loss: 1.1249, policy_loss: 1.2271, value_loss: 0.7961
2024-07-14 05:53:08,668 [INFO    ] __main__: train step 8693: loss: 1.1249, policy_loss: 1.2271, value_loss: 0.7961
2024-07-14 05:53:08,957 [INFO    ] __main__: train step 8694: loss: 1.1249, policy_loss: 1.2270, value_loss: 0.7961
2024-07-14 05:53:09,224 [INFO    ] __main__: train step 8695: loss: 1.1249, policy_loss: 1.2269, value_loss: 0.7960
2024-07-14 05:53:09,518 [INFO    ] __main__: train step 8696: loss: 1.1249, policy_loss: 1.2269, value_loss: 0.7960
2024-07-14 05:53:09,806 [INFO    ] __main__: train step 8697: loss: 1.1249, policy_loss: 1.2268, value_loss: 0.7960
2024-07-14 05:53:10,103 [INFO    ] __main__: train step 8698: loss: 1.1249, policy_loss: 1.2267, value_loss: 0.7959
2024-07-14 05:53:10,398 [INFO    ] __main__: train step 8699: loss: 1.1249, policy_loss: 1.2267, value_loss: 0.7959
2024-07-14 05:53:10,706 [INFO    ] __main__: train step 8700: loss: 1.1249, policy_loss: 1.2266, value_loss: 0.7958
2024-07-14 05:53:12,320 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:53:12,824 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:53:12,897 [INFO    ] __main__: train step 8701: loss: 1.1249, policy_loss: 1.2265, value_loss: 0.7958
2024-07-14 05:53:13,201 [INFO    ] __main__: train step 8702: loss: 1.1249, policy_loss: 1.2265, value_loss: 0.7958
2024-07-14 05:53:13,505 [INFO    ] __main__: train step 8703: loss: 1.1249, policy_loss: 1.2264, value_loss: 0.7957
2024-07-14 05:53:13,803 [INFO    ] __main__: train step 8704: loss: 1.1249, policy_loss: 1.2263, value_loss: 0.7957
2024-07-14 05:53:14,097 [INFO    ] __main__: train step 8705: loss: 1.1249, policy_loss: 1.2263, value_loss: 0.7957
2024-07-14 05:53:14,373 [INFO    ] __main__: train step 8706: loss: 1.1249, policy_loss: 1.2262, value_loss: 0.7956
2024-07-14 05:53:14,644 [INFO    ] __main__: train step 8707: loss: 1.1250, policy_loss: 1.2262, value_loss: 0.7956
2024-07-14 05:53:14,902 [INFO    ] __main__: train step 8708: loss: 1.1250, policy_loss: 1.2261, value_loss: 0.7956
2024-07-14 05:53:15,172 [INFO    ] __main__: train step 8709: loss: 1.1250, policy_loss: 1.2260, value_loss: 0.7955
2024-07-14 05:53:15,464 [INFO    ] __main__: train step 8710: loss: 1.1250, policy_loss: 1.2260, value_loss: 0.7955
2024-07-14 05:53:15,736 [INFO    ] __main__: train step 8711: loss: 1.1250, policy_loss: 1.2259, value_loss: 0.7955
2024-07-14 05:53:16,016 [INFO    ] __main__: train step 8712: loss: 1.1250, policy_loss: 1.2258, value_loss: 0.7954
2024-07-14 05:53:16,306 [INFO    ] __main__: train step 8713: loss: 1.1250, policy_loss: 1.2258, value_loss: 0.7954
2024-07-14 05:53:16,600 [INFO    ] __main__: train step 8714: loss: 1.1250, policy_loss: 1.2257, value_loss: 0.7954
2024-07-14 05:53:16,895 [INFO    ] __main__: train step 8715: loss: 1.1250, policy_loss: 1.2256, value_loss: 0.7953
2024-07-14 05:53:17,186 [INFO    ] __main__: train step 8716: loss: 1.1250, policy_loss: 1.2256, value_loss: 0.7953
2024-07-14 05:53:17,466 [INFO    ] __main__: train step 8717: loss: 1.1250, policy_loss: 1.2255, value_loss: 0.7953
2024-07-14 05:53:19,075 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:53:19,585 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:53:19,658 [INFO    ] __main__: train step 8718: loss: 1.1250, policy_loss: 1.2255, value_loss: 0.7952
2024-07-14 05:53:19,943 [INFO    ] __main__: train step 8719: loss: 1.1250, policy_loss: 1.2254, value_loss: 0.7952
2024-07-14 05:53:20,248 [INFO    ] __main__: train step 8720: loss: 1.1250, policy_loss: 1.2253, value_loss: 0.7952
2024-07-14 05:53:20,547 [INFO    ] __main__: train step 8721: loss: 1.1250, policy_loss: 1.2253, value_loss: 0.7951
2024-07-14 05:53:20,838 [INFO    ] __main__: train step 8722: loss: 1.1250, policy_loss: 1.2252, value_loss: 0.7951
2024-07-14 05:53:21,130 [INFO    ] __main__: train step 8723: loss: 1.1250, policy_loss: 1.2251, value_loss: 0.7951
2024-07-14 05:53:21,433 [INFO    ] __main__: train step 8724: loss: 1.1250, policy_loss: 1.2251, value_loss: 0.7950
2024-07-14 05:53:21,721 [INFO    ] __main__: train step 8725: loss: 1.1250, policy_loss: 1.2250, value_loss: 0.7950
2024-07-14 05:53:22,017 [INFO    ] __main__: train step 8726: loss: 1.1250, policy_loss: 1.2249, value_loss: 0.7950
2024-07-14 05:53:22,317 [INFO    ] __main__: train step 8727: loss: 1.1251, policy_loss: 1.2249, value_loss: 0.7949
2024-07-14 05:53:22,616 [INFO    ] __main__: train step 8728: loss: 1.1251, policy_loss: 1.2248, value_loss: 0.7949
2024-07-14 05:53:22,914 [INFO    ] __main__: train step 8729: loss: 1.1251, policy_loss: 1.2247, value_loss: 0.7949
2024-07-14 05:53:23,214 [INFO    ] __main__: train step 8730: loss: 1.1251, policy_loss: 1.2247, value_loss: 0.7948
2024-07-14 05:53:23,499 [INFO    ] __main__: train step 8731: loss: 1.1251, policy_loss: 1.2246, value_loss: 0.7948
2024-07-14 05:53:25,230 [INFO    ] __main__: train step 8732: loss: 1.1251, policy_loss: 1.2246, value_loss: 0.7948
2024-07-14 05:53:25,487 [INFO    ] __main__: train step 8733: loss: 1.1251, policy_loss: 1.2245, value_loss: 0.7947
2024-07-14 05:53:25,734 [INFO    ] __main__: train step 8734: loss: 1.1251, policy_loss: 1.2244, value_loss: 0.7947
2024-07-14 05:53:27,303 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:53:27,754 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:53:27,819 [INFO    ] __main__: train step 8735: loss: 1.1251, policy_loss: 1.2244, value_loss: 0.7946
2024-07-14 05:53:28,083 [INFO    ] __main__: train step 8736: loss: 1.1251, policy_loss: 1.2243, value_loss: 0.7946
2024-07-14 05:53:28,358 [INFO    ] __main__: train step 8737: loss: 1.1251, policy_loss: 1.2242, value_loss: 0.7946
2024-07-14 05:53:28,610 [INFO    ] __main__: train step 8738: loss: 1.1251, policy_loss: 1.2242, value_loss: 0.7945
2024-07-14 05:53:28,862 [INFO    ] __main__: train step 8739: loss: 1.1251, policy_loss: 1.2241, value_loss: 0.7945
2024-07-14 05:53:29,138 [INFO    ] __main__: train step 8740: loss: 1.1251, policy_loss: 1.2240, value_loss: 0.7945
2024-07-14 05:53:29,412 [INFO    ] __main__: train step 8741: loss: 1.1251, policy_loss: 1.2240, value_loss: 0.7944
2024-07-14 05:53:29,683 [INFO    ] __main__: train step 8742: loss: 1.1251, policy_loss: 1.2239, value_loss: 0.7944
2024-07-14 05:53:29,925 [INFO    ] __main__: train step 8743: loss: 1.1251, policy_loss: 1.2238, value_loss: 0.7944
2024-07-14 05:53:30,205 [INFO    ] __main__: train step 8744: loss: 1.1251, policy_loss: 1.2238, value_loss: 0.7943
2024-07-14 05:53:30,471 [INFO    ] __main__: train step 8745: loss: 1.1251, policy_loss: 1.2237, value_loss: 0.7943
2024-07-14 05:53:30,728 [INFO    ] __main__: train step 8746: loss: 1.1251, policy_loss: 1.2237, value_loss: 0.7943
2024-07-14 05:53:30,989 [INFO    ] __main__: train step 8747: loss: 1.1251, policy_loss: 1.2236, value_loss: 0.7942
2024-07-14 05:53:31,229 [INFO    ] __main__: train step 8748: loss: 1.1251, policy_loss: 1.2235, value_loss: 0.7942
2024-07-14 05:53:31,470 [INFO    ] __main__: train step 8749: loss: 1.1251, policy_loss: 1.2235, value_loss: 0.7942
2024-07-14 05:53:31,711 [INFO    ] __main__: train step 8750: loss: 1.1251, policy_loss: 1.2234, value_loss: 0.7941
2024-07-14 05:53:31,947 [INFO    ] __main__: train step 8751: loss: 1.1251, policy_loss: 1.2233, value_loss: 0.7941
2024-07-14 05:53:33,522 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:53:33,991 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:53:34,057 [INFO    ] __main__: train step 8752: loss: 1.1251, policy_loss: 1.2233, value_loss: 0.7941
2024-07-14 05:53:34,317 [INFO    ] __main__: train step 8753: loss: 1.1251, policy_loss: 1.2232, value_loss: 0.7940
2024-07-14 05:53:34,575 [INFO    ] __main__: train step 8754: loss: 1.1251, policy_loss: 1.2231, value_loss: 0.7940
2024-07-14 05:53:34,832 [INFO    ] __main__: train step 8755: loss: 1.1251, policy_loss: 1.2231, value_loss: 0.7940
2024-07-14 05:53:35,108 [INFO    ] __main__: train step 8756: loss: 1.1251, policy_loss: 1.2230, value_loss: 0.7939
2024-07-14 05:53:35,379 [INFO    ] __main__: train step 8757: loss: 1.1251, policy_loss: 1.2229, value_loss: 0.7939
2024-07-14 05:53:35,653 [INFO    ] __main__: train step 8758: loss: 1.1251, policy_loss: 1.2229, value_loss: 0.7939
2024-07-14 05:53:35,918 [INFO    ] __main__: train step 8759: loss: 1.1252, policy_loss: 1.2228, value_loss: 0.7938
2024-07-14 05:53:36,188 [INFO    ] __main__: train step 8760: loss: 1.1252, policy_loss: 1.2228, value_loss: 0.7938
2024-07-14 05:53:36,453 [INFO    ] __main__: train step 8761: loss: 1.1252, policy_loss: 1.2227, value_loss: 0.7938
2024-07-14 05:53:36,723 [INFO    ] __main__: train step 8762: loss: 1.1252, policy_loss: 1.2226, value_loss: 0.7937
2024-07-14 05:53:36,984 [INFO    ] __main__: train step 8763: loss: 1.1252, policy_loss: 1.2226, value_loss: 0.7937
2024-07-14 05:53:37,248 [INFO    ] __main__: train step 8764: loss: 1.1252, policy_loss: 1.2225, value_loss: 0.7936
2024-07-14 05:53:37,502 [INFO    ] __main__: train step 8765: loss: 1.1252, policy_loss: 1.2224, value_loss: 0.7936
2024-07-14 05:53:37,766 [INFO    ] __main__: train step 8766: loss: 1.1252, policy_loss: 1.2224, value_loss: 0.7936
2024-07-14 05:53:38,014 [INFO    ] __main__: train step 8767: loss: 1.1252, policy_loss: 1.2223, value_loss: 0.7935
2024-07-14 05:53:38,279 [INFO    ] __main__: train step 8768: loss: 1.1252, policy_loss: 1.2222, value_loss: 0.7935
2024-07-14 05:53:39,885 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:53:40,391 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:53:40,456 [INFO    ] __main__: train step 8769: loss: 1.1252, policy_loss: 1.2222, value_loss: 0.7935
2024-07-14 05:53:40,741 [INFO    ] __main__: train step 8770: loss: 1.1252, policy_loss: 1.2221, value_loss: 0.7934
2024-07-14 05:53:41,028 [INFO    ] __main__: train step 8771: loss: 1.1252, policy_loss: 1.2220, value_loss: 0.7934
2024-07-14 05:53:41,319 [INFO    ] __main__: train step 8772: loss: 1.1252, policy_loss: 1.2220, value_loss: 0.7934
2024-07-14 05:53:41,607 [INFO    ] __main__: train step 8773: loss: 1.1252, policy_loss: 1.2219, value_loss: 0.7933
2024-07-14 05:53:41,903 [INFO    ] __main__: train step 8774: loss: 1.1252, policy_loss: 1.2219, value_loss: 0.7933
2024-07-14 05:53:42,216 [INFO    ] __main__: train step 8775: loss: 1.1252, policy_loss: 1.2218, value_loss: 0.7933
2024-07-14 05:53:42,507 [INFO    ] __main__: train step 8776: loss: 1.1252, policy_loss: 1.2217, value_loss: 0.7932
2024-07-14 05:53:42,800 [INFO    ] __main__: train step 8777: loss: 1.1252, policy_loss: 1.2217, value_loss: 0.7932
2024-07-14 05:53:43,101 [INFO    ] __main__: train step 8778: loss: 1.1252, policy_loss: 1.2216, value_loss: 0.7932
2024-07-14 05:53:43,394 [INFO    ] __main__: train step 8779: loss: 1.1252, policy_loss: 1.2215, value_loss: 0.7931
2024-07-14 05:53:43,674 [INFO    ] __main__: train step 8780: loss: 1.1252, policy_loss: 1.2215, value_loss: 0.7931
2024-07-14 05:53:43,963 [INFO    ] __main__: train step 8781: loss: 1.1252, policy_loss: 1.2214, value_loss: 0.7931
2024-07-14 05:53:44,260 [INFO    ] __main__: train step 8782: loss: 1.1252, policy_loss: 1.2213, value_loss: 0.7930
2024-07-14 05:53:44,549 [INFO    ] __main__: train step 8783: loss: 1.1252, policy_loss: 1.2213, value_loss: 0.7930
2024-07-14 05:53:44,863 [INFO    ] __main__: train step 8784: loss: 1.1252, policy_loss: 1.2212, value_loss: 0.7930
2024-07-14 05:53:45,146 [INFO    ] __main__: train step 8785: loss: 1.1252, policy_loss: 1.2211, value_loss: 0.7929
2024-07-14 05:53:46,789 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:53:47,290 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:53:47,364 [INFO    ] __main__: train step 8786: loss: 1.1252, policy_loss: 1.2211, value_loss: 0.7929
2024-07-14 05:53:49,265 [INFO    ] __main__: train step 8787: loss: 1.1252, policy_loss: 1.2210, value_loss: 0.7929
2024-07-14 05:53:49,559 [INFO    ] __main__: train step 8788: loss: 1.1252, policy_loss: 1.2210, value_loss: 0.7928
2024-07-14 05:53:49,858 [INFO    ] __main__: train step 8789: loss: 1.1252, policy_loss: 1.2209, value_loss: 0.7928
2024-07-14 05:53:50,147 [INFO    ] __main__: train step 8790: loss: 1.1252, policy_loss: 1.2208, value_loss: 0.7927
2024-07-14 05:53:50,437 [INFO    ] __main__: train step 8791: loss: 1.1252, policy_loss: 1.2208, value_loss: 0.7927
2024-07-14 05:53:50,722 [INFO    ] __main__: train step 8792: loss: 1.1252, policy_loss: 1.2207, value_loss: 0.7927
2024-07-14 05:53:51,014 [INFO    ] __main__: train step 8793: loss: 1.1252, policy_loss: 1.2206, value_loss: 0.7926
2024-07-14 05:53:51,316 [INFO    ] __main__: train step 8794: loss: 1.1252, policy_loss: 1.2206, value_loss: 0.7926
2024-07-14 05:53:51,639 [INFO    ] __main__: train step 8795: loss: 1.1252, policy_loss: 1.2205, value_loss: 0.7926
2024-07-14 05:53:51,932 [INFO    ] __main__: train step 8796: loss: 1.1252, policy_loss: 1.2204, value_loss: 0.7925
2024-07-14 05:53:52,219 [INFO    ] __main__: train step 8797: loss: 1.1252, policy_loss: 1.2204, value_loss: 0.7925
2024-07-14 05:53:52,509 [INFO    ] __main__: train step 8798: loss: 1.1253, policy_loss: 1.2203, value_loss: 0.7925
2024-07-14 05:53:52,817 [INFO    ] __main__: train step 8799: loss: 1.1253, policy_loss: 1.2202, value_loss: 0.7924
2024-07-14 05:53:53,090 [INFO    ] __main__: train step 8800: loss: 1.1253, policy_loss: 1.2202, value_loss: 0.7924
2024-07-14 05:53:53,389 [INFO    ] __main__: train step 8801: loss: 1.1253, policy_loss: 1.2201, value_loss: 0.7924
2024-07-14 05:53:53,675 [INFO    ] __main__: train step 8802: loss: 1.1253, policy_loss: 1.2201, value_loss: 0.7923
2024-07-14 05:53:55,313 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:53:55,807 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:53:55,878 [INFO    ] __main__: train step 8803: loss: 1.1253, policy_loss: 1.2200, value_loss: 0.7923
2024-07-14 05:53:56,181 [INFO    ] __main__: train step 8804: loss: 1.1253, policy_loss: 1.2199, value_loss: 0.7923
2024-07-14 05:53:56,472 [INFO    ] __main__: train step 8805: loss: 1.1253, policy_loss: 1.2199, value_loss: 0.7922
2024-07-14 05:53:56,754 [INFO    ] __main__: train step 8806: loss: 1.1253, policy_loss: 1.2198, value_loss: 0.7922
2024-07-14 05:53:57,039 [INFO    ] __main__: train step 8807: loss: 1.1253, policy_loss: 1.2197, value_loss: 0.7922
2024-07-14 05:53:57,343 [INFO    ] __main__: train step 8808: loss: 1.1253, policy_loss: 1.2197, value_loss: 0.7921
2024-07-14 05:53:57,637 [INFO    ] __main__: train step 8809: loss: 1.1253, policy_loss: 1.2196, value_loss: 0.7921
2024-07-14 05:53:57,936 [INFO    ] __main__: train step 8810: loss: 1.1253, policy_loss: 1.2195, value_loss: 0.7921
2024-07-14 05:53:58,233 [INFO    ] __main__: train step 8811: loss: 1.1253, policy_loss: 1.2195, value_loss: 0.7920
2024-07-14 05:53:58,564 [INFO    ] __main__: train step 8812: loss: 1.1253, policy_loss: 1.2194, value_loss: 0.7920
2024-07-14 05:53:58,865 [INFO    ] __main__: train step 8813: loss: 1.1253, policy_loss: 1.2193, value_loss: 0.7920
2024-07-14 05:53:59,155 [INFO    ] __main__: train step 8814: loss: 1.1253, policy_loss: 1.2193, value_loss: 0.7919
2024-07-14 05:53:59,408 [INFO    ] __main__: train step 8815: loss: 1.1253, policy_loss: 1.2192, value_loss: 0.7919
2024-07-14 05:53:59,674 [INFO    ] __main__: train step 8816: loss: 1.1253, policy_loss: 1.2191, value_loss: 0.7919
2024-07-14 05:53:59,936 [INFO    ] __main__: train step 8817: loss: 1.1253, policy_loss: 1.2191, value_loss: 0.7918
2024-07-14 05:54:00,209 [INFO    ] __main__: train step 8818: loss: 1.1253, policy_loss: 1.2190, value_loss: 0.7918
2024-07-14 05:54:00,474 [INFO    ] __main__: train step 8819: loss: 1.1253, policy_loss: 1.2190, value_loss: 0.7917
2024-07-14 05:54:02,095 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:54:02,595 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:54:02,673 [INFO    ] __main__: train step 8820: loss: 1.1253, policy_loss: 1.2189, value_loss: 0.7917
2024-07-14 05:54:02,990 [INFO    ] __main__: train step 8821: loss: 1.1253, policy_loss: 1.2188, value_loss: 0.7917
2024-07-14 05:54:03,290 [INFO    ] __main__: train step 8822: loss: 1.1253, policy_loss: 1.2188, value_loss: 0.7916
2024-07-14 05:54:03,594 [INFO    ] __main__: train step 8823: loss: 1.1253, policy_loss: 1.2187, value_loss: 0.7916
2024-07-14 05:54:03,891 [INFO    ] __main__: train step 8824: loss: 1.1253, policy_loss: 1.2186, value_loss: 0.7916
2024-07-14 05:54:04,160 [INFO    ] __main__: train step 8825: loss: 1.1253, policy_loss: 1.2186, value_loss: 0.7915
2024-07-14 05:54:04,441 [INFO    ] __main__: train step 8826: loss: 1.1253, policy_loss: 1.2185, value_loss: 0.7915
2024-07-14 05:54:04,715 [INFO    ] __main__: train step 8827: loss: 1.1253, policy_loss: 1.2184, value_loss: 0.7915
2024-07-14 05:54:05,000 [INFO    ] __main__: train step 8828: loss: 1.1253, policy_loss: 1.2184, value_loss: 0.7914
2024-07-14 05:54:05,295 [INFO    ] __main__: train step 8829: loss: 1.1253, policy_loss: 1.2183, value_loss: 0.7914
2024-07-14 05:54:05,598 [INFO    ] __main__: train step 8830: loss: 1.1253, policy_loss: 1.2182, value_loss: 0.7914
2024-07-14 05:54:05,908 [INFO    ] __main__: train step 8831: loss: 1.1253, policy_loss: 1.2182, value_loss: 0.7913
2024-07-14 05:54:06,197 [INFO    ] __main__: train step 8832: loss: 1.1253, policy_loss: 1.2181, value_loss: 0.7913
2024-07-14 05:54:06,497 [INFO    ] __main__: train step 8833: loss: 1.1253, policy_loss: 1.2181, value_loss: 0.7913
2024-07-14 05:54:06,800 [INFO    ] __main__: train step 8834: loss: 1.1253, policy_loss: 1.2180, value_loss: 0.7912
2024-07-14 05:54:07,106 [INFO    ] __main__: train step 8835: loss: 1.1253, policy_loss: 1.2179, value_loss: 0.7912
2024-07-14 05:54:07,399 [INFO    ] __main__: train step 8836: loss: 1.1253, policy_loss: 1.2179, value_loss: 0.7911
2024-07-14 05:54:09,018 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:54:09,509 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:54:09,581 [INFO    ] __main__: train step 8837: loss: 1.1253, policy_loss: 1.2178, value_loss: 0.7911
2024-07-14 05:54:09,881 [INFO    ] __main__: train step 8838: loss: 1.1253, policy_loss: 1.2177, value_loss: 0.7911
2024-07-14 05:54:10,175 [INFO    ] __main__: train step 8839: loss: 1.1253, policy_loss: 1.2177, value_loss: 0.7910
2024-07-14 05:54:10,467 [INFO    ] __main__: train step 8840: loss: 1.1253, policy_loss: 1.2176, value_loss: 0.7910
2024-07-14 05:54:10,766 [INFO    ] __main__: train step 8841: loss: 1.1253, policy_loss: 1.2175, value_loss: 0.7910
2024-07-14 05:54:12,633 [INFO    ] __main__: train step 8842: loss: 1.1253, policy_loss: 1.2175, value_loss: 0.7909
2024-07-14 05:54:12,927 [INFO    ] __main__: train step 8843: loss: 1.1253, policy_loss: 1.2174, value_loss: 0.7909
2024-07-14 05:54:13,228 [INFO    ] __main__: train step 8844: loss: 1.1253, policy_loss: 1.2174, value_loss: 0.7909
2024-07-14 05:54:13,529 [INFO    ] __main__: train step 8845: loss: 1.1253, policy_loss: 1.2173, value_loss: 0.7908
2024-07-14 05:54:13,822 [INFO    ] __main__: train step 8846: loss: 1.1253, policy_loss: 1.2172, value_loss: 0.7908
2024-07-14 05:54:14,105 [INFO    ] __main__: train step 8847: loss: 1.1253, policy_loss: 1.2172, value_loss: 0.7908
2024-07-14 05:54:14,403 [INFO    ] __main__: train step 8848: loss: 1.1253, policy_loss: 1.2171, value_loss: 0.7907
2024-07-14 05:54:14,694 [INFO    ] __main__: train step 8849: loss: 1.1253, policy_loss: 1.2170, value_loss: 0.7907
2024-07-14 05:54:14,993 [INFO    ] __main__: train step 8850: loss: 1.1253, policy_loss: 1.2170, value_loss: 0.7907
2024-07-14 05:54:15,294 [INFO    ] __main__: train step 8851: loss: 1.1253, policy_loss: 1.2169, value_loss: 0.7906
2024-07-14 05:54:15,599 [INFO    ] __main__: train step 8852: loss: 1.1253, policy_loss: 1.2168, value_loss: 0.7906
2024-07-14 05:54:15,874 [INFO    ] __main__: train step 8853: loss: 1.1253, policy_loss: 1.2168, value_loss: 0.7906
2024-07-14 05:54:17,488 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:54:17,948 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:54:18,015 [INFO    ] __main__: train step 8854: loss: 1.1253, policy_loss: 1.2167, value_loss: 0.7905
2024-07-14 05:54:18,277 [INFO    ] __main__: train step 8855: loss: 1.1253, policy_loss: 1.2167, value_loss: 0.7905
2024-07-14 05:54:18,528 [INFO    ] __main__: train step 8856: loss: 1.1253, policy_loss: 1.2166, value_loss: 0.7904
2024-07-14 05:54:18,783 [INFO    ] __main__: train step 8857: loss: 1.1253, policy_loss: 1.2165, value_loss: 0.7904
2024-07-14 05:54:19,037 [INFO    ] __main__: train step 8858: loss: 1.1253, policy_loss: 1.2165, value_loss: 0.7904
2024-07-14 05:54:19,289 [INFO    ] __main__: train step 8859: loss: 1.1253, policy_loss: 1.2164, value_loss: 0.7903
2024-07-14 05:54:19,558 [INFO    ] __main__: train step 8860: loss: 1.1253, policy_loss: 1.2163, value_loss: 0.7903
2024-07-14 05:54:19,817 [INFO    ] __main__: train step 8861: loss: 1.1253, policy_loss: 1.2163, value_loss: 0.7903
2024-07-14 05:54:20,068 [INFO    ] __main__: train step 8862: loss: 1.1253, policy_loss: 1.2162, value_loss: 0.7902
2024-07-14 05:54:20,315 [INFO    ] __main__: train step 8863: loss: 1.1253, policy_loss: 1.2161, value_loss: 0.7902
2024-07-14 05:54:20,564 [INFO    ] __main__: train step 8864: loss: 1.1253, policy_loss: 1.2161, value_loss: 0.7902
2024-07-14 05:54:20,822 [INFO    ] __main__: train step 8865: loss: 1.1253, policy_loss: 1.2160, value_loss: 0.7901
2024-07-14 05:54:21,088 [INFO    ] __main__: train step 8866: loss: 1.1253, policy_loss: 1.2160, value_loss: 0.7901
2024-07-14 05:54:21,360 [INFO    ] __main__: train step 8867: loss: 1.1253, policy_loss: 1.2159, value_loss: 0.7901
2024-07-14 05:54:21,631 [INFO    ] __main__: train step 8868: loss: 1.1253, policy_loss: 1.2158, value_loss: 0.7900
2024-07-14 05:54:21,919 [INFO    ] __main__: train step 8869: loss: 1.1253, policy_loss: 1.2158, value_loss: 0.7900
2024-07-14 05:54:22,187 [INFO    ] __main__: train step 8870: loss: 1.1253, policy_loss: 1.2157, value_loss: 0.7899
2024-07-14 05:54:23,790 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:54:24,273 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:54:24,343 [INFO    ] __main__: train step 8871: loss: 1.1253, policy_loss: 1.2156, value_loss: 0.7899
2024-07-14 05:54:24,616 [INFO    ] __main__: train step 8872: loss: 1.1253, policy_loss: 1.2156, value_loss: 0.7899
2024-07-14 05:54:24,874 [INFO    ] __main__: train step 8873: loss: 1.1253, policy_loss: 1.2155, value_loss: 0.7898
2024-07-14 05:54:25,138 [INFO    ] __main__: train step 8874: loss: 1.1253, policy_loss: 1.2154, value_loss: 0.7898
2024-07-14 05:54:25,395 [INFO    ] __main__: train step 8875: loss: 1.1253, policy_loss: 1.2154, value_loss: 0.7898
2024-07-14 05:54:25,660 [INFO    ] __main__: train step 8876: loss: 1.1253, policy_loss: 1.2153, value_loss: 0.7897
2024-07-14 05:54:25,924 [INFO    ] __main__: train step 8877: loss: 1.1253, policy_loss: 1.2153, value_loss: 0.7897
2024-07-14 05:54:26,201 [INFO    ] __main__: train step 8878: loss: 1.1253, policy_loss: 1.2152, value_loss: 0.7897
2024-07-14 05:54:26,445 [INFO    ] __main__: train step 8879: loss: 1.1253, policy_loss: 1.2151, value_loss: 0.7896
2024-07-14 05:54:26,718 [INFO    ] __main__: train step 8880: loss: 1.1253, policy_loss: 1.2151, value_loss: 0.7896
2024-07-14 05:54:26,984 [INFO    ] __main__: train step 8881: loss: 1.1253, policy_loss: 1.2150, value_loss: 0.7896
2024-07-14 05:54:27,250 [INFO    ] __main__: train step 8882: loss: 1.1253, policy_loss: 1.2149, value_loss: 0.7895
2024-07-14 05:54:27,515 [INFO    ] __main__: train step 8883: loss: 1.1253, policy_loss: 1.2149, value_loss: 0.7895
2024-07-14 05:54:27,775 [INFO    ] __main__: train step 8884: loss: 1.1253, policy_loss: 1.2148, value_loss: 0.7895
2024-07-14 05:54:28,032 [INFO    ] __main__: train step 8885: loss: 1.1253, policy_loss: 1.2147, value_loss: 0.7894
2024-07-14 05:54:28,303 [INFO    ] __main__: train step 8886: loss: 1.1253, policy_loss: 1.2147, value_loss: 0.7894
2024-07-14 05:54:28,561 [INFO    ] __main__: train step 8887: loss: 1.1253, policy_loss: 1.2146, value_loss: 0.7893
2024-07-14 05:54:30,132 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:54:30,604 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:54:30,670 [INFO    ] __main__: train step 8888: loss: 1.1253, policy_loss: 1.2146, value_loss: 0.7893
2024-07-14 05:54:30,936 [INFO    ] __main__: train step 8889: loss: 1.1253, policy_loss: 1.2145, value_loss: 0.7893
2024-07-14 05:54:31,197 [INFO    ] __main__: train step 8890: loss: 1.1253, policy_loss: 1.2144, value_loss: 0.7892
2024-07-14 05:54:31,447 [INFO    ] __main__: train step 8891: loss: 1.1253, policy_loss: 1.2144, value_loss: 0.7892
2024-07-14 05:54:31,716 [INFO    ] __main__: train step 8892: loss: 1.1253, policy_loss: 1.2143, value_loss: 0.7892
2024-07-14 05:54:31,986 [INFO    ] __main__: train step 8893: loss: 1.1253, policy_loss: 1.2142, value_loss: 0.7891
2024-07-14 05:54:32,259 [INFO    ] __main__: train step 8894: loss: 1.1253, policy_loss: 1.2142, value_loss: 0.7891
2024-07-14 05:54:32,519 [INFO    ] __main__: train step 8895: loss: 1.1253, policy_loss: 1.2141, value_loss: 0.7891
2024-07-14 05:54:32,799 [INFO    ] __main__: train step 8896: loss: 1.1253, policy_loss: 1.2140, value_loss: 0.7890
2024-07-14 05:54:34,634 [INFO    ] __main__: train step 8897: loss: 1.1253, policy_loss: 1.2140, value_loss: 0.7890
2024-07-14 05:54:34,932 [INFO    ] __main__: train step 8898: loss: 1.1253, policy_loss: 1.2139, value_loss: 0.7890
2024-07-14 05:54:35,225 [INFO    ] __main__: train step 8899: loss: 1.1253, policy_loss: 1.2139, value_loss: 0.7889
2024-07-14 05:54:35,523 [INFO    ] __main__: train step 8900: loss: 1.1253, policy_loss: 1.2138, value_loss: 0.7889
2024-07-14 05:54:35,827 [INFO    ] __main__: train step 8901: loss: 1.1253, policy_loss: 1.2137, value_loss: 0.7888
2024-07-14 05:54:36,123 [INFO    ] __main__: train step 8902: loss: 1.1253, policy_loss: 1.2137, value_loss: 0.7888
2024-07-14 05:54:36,419 [INFO    ] __main__: train step 8903: loss: 1.1253, policy_loss: 1.2136, value_loss: 0.7888
2024-07-14 05:54:36,713 [INFO    ] __main__: train step 8904: loss: 1.1253, policy_loss: 1.2135, value_loss: 0.7887
2024-07-14 05:54:38,345 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:54:38,842 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:54:38,912 [INFO    ] __main__: train step 8905: loss: 1.1253, policy_loss: 1.2135, value_loss: 0.7887
2024-07-14 05:54:39,211 [INFO    ] __main__: train step 8906: loss: 1.1253, policy_loss: 1.2134, value_loss: 0.7887
2024-07-14 05:54:39,493 [INFO    ] __main__: train step 8907: loss: 1.1253, policy_loss: 1.2133, value_loss: 0.7886
2024-07-14 05:54:39,781 [INFO    ] __main__: train step 8908: loss: 1.1253, policy_loss: 1.2133, value_loss: 0.7886
2024-07-14 05:54:40,063 [INFO    ] __main__: train step 8909: loss: 1.1253, policy_loss: 1.2132, value_loss: 0.7886
2024-07-14 05:54:40,360 [INFO    ] __main__: train step 8910: loss: 1.1253, policy_loss: 1.2132, value_loss: 0.7885
2024-07-14 05:54:40,654 [INFO    ] __main__: train step 8911: loss: 1.1253, policy_loss: 1.2131, value_loss: 0.7885
2024-07-14 05:54:40,957 [INFO    ] __main__: train step 8912: loss: 1.1253, policy_loss: 1.2130, value_loss: 0.7885
2024-07-14 05:54:41,253 [INFO    ] __main__: train step 8913: loss: 1.1253, policy_loss: 1.2130, value_loss: 0.7884
2024-07-14 05:54:41,536 [INFO    ] __main__: train step 8914: loss: 1.1253, policy_loss: 1.2129, value_loss: 0.7884
2024-07-14 05:54:41,838 [INFO    ] __main__: train step 8915: loss: 1.1253, policy_loss: 1.2128, value_loss: 0.7883
2024-07-14 05:54:42,139 [INFO    ] __main__: train step 8916: loss: 1.1253, policy_loss: 1.2128, value_loss: 0.7883
2024-07-14 05:54:42,426 [INFO    ] __main__: train step 8917: loss: 1.1253, policy_loss: 1.2127, value_loss: 0.7883
2024-07-14 05:54:42,740 [INFO    ] __main__: train step 8918: loss: 1.1253, policy_loss: 1.2126, value_loss: 0.7882
2024-07-14 05:54:43,036 [INFO    ] __main__: train step 8919: loss: 1.1253, policy_loss: 1.2126, value_loss: 0.7882
2024-07-14 05:54:43,325 [INFO    ] __main__: train step 8920: loss: 1.1253, policy_loss: 1.2125, value_loss: 0.7882
2024-07-14 05:54:43,624 [INFO    ] __main__: train step 8921: loss: 1.1253, policy_loss: 1.2125, value_loss: 0.7881
2024-07-14 05:54:45,245 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:54:45,748 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:54:45,822 [INFO    ] __main__: train step 8922: loss: 1.1253, policy_loss: 1.2124, value_loss: 0.7881
2024-07-14 05:54:46,104 [INFO    ] __main__: train step 8923: loss: 1.1253, policy_loss: 1.2123, value_loss: 0.7881
2024-07-14 05:54:46,383 [INFO    ] __main__: train step 8924: loss: 1.1253, policy_loss: 1.2123, value_loss: 0.7880
2024-07-14 05:54:46,670 [INFO    ] __main__: train step 8925: loss: 1.1253, policy_loss: 1.2122, value_loss: 0.7880
2024-07-14 05:54:46,952 [INFO    ] __main__: train step 8926: loss: 1.1253, policy_loss: 1.2121, value_loss: 0.7879
2024-07-14 05:54:47,244 [INFO    ] __main__: train step 8927: loss: 1.1253, policy_loss: 1.2121, value_loss: 0.7879
2024-07-14 05:54:47,536 [INFO    ] __main__: train step 8928: loss: 1.1253, policy_loss: 1.2120, value_loss: 0.7879
2024-07-14 05:54:47,839 [INFO    ] __main__: train step 8929: loss: 1.1253, policy_loss: 1.2120, value_loss: 0.7878
2024-07-14 05:54:48,119 [INFO    ] __main__: train step 8930: loss: 1.1253, policy_loss: 1.2119, value_loss: 0.7878
2024-07-14 05:54:48,380 [INFO    ] __main__: train step 8931: loss: 1.1253, policy_loss: 1.2118, value_loss: 0.7878
2024-07-14 05:54:48,649 [INFO    ] __main__: train step 8932: loss: 1.1253, policy_loss: 1.2118, value_loss: 0.7877
2024-07-14 05:54:48,936 [INFO    ] __main__: train step 8933: loss: 1.1253, policy_loss: 1.2117, value_loss: 0.7877
2024-07-14 05:54:49,232 [INFO    ] __main__: train step 8934: loss: 1.1253, policy_loss: 1.2116, value_loss: 0.7877
2024-07-14 05:54:49,534 [INFO    ] __main__: train step 8935: loss: 1.1253, policy_loss: 1.2116, value_loss: 0.7876
2024-07-14 05:54:49,832 [INFO    ] __main__: train step 8936: loss: 1.1253, policy_loss: 1.2115, value_loss: 0.7876
2024-07-14 05:54:50,128 [INFO    ] __main__: train step 8937: loss: 1.1253, policy_loss: 1.2115, value_loss: 0.7875
2024-07-14 05:54:50,432 [INFO    ] __main__: train step 8938: loss: 1.1253, policy_loss: 1.2114, value_loss: 0.7875
2024-07-14 05:54:52,057 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:54:52,560 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:54:52,636 [INFO    ] __main__: train step 8939: loss: 1.1253, policy_loss: 1.2113, value_loss: 0.7875
2024-07-14 05:54:52,932 [INFO    ] __main__: train step 8940: loss: 1.1253, policy_loss: 1.2113, value_loss: 0.7874
2024-07-14 05:54:53,212 [INFO    ] __main__: train step 8941: loss: 1.1253, policy_loss: 1.2112, value_loss: 0.7874
2024-07-14 05:54:53,493 [INFO    ] __main__: train step 8942: loss: 1.1253, policy_loss: 1.2111, value_loss: 0.7874
2024-07-14 05:54:53,786 [INFO    ] __main__: train step 8943: loss: 1.1253, policy_loss: 1.2111, value_loss: 0.7873
2024-07-14 05:54:54,082 [INFO    ] __main__: train step 8944: loss: 1.1252, policy_loss: 1.2110, value_loss: 0.7873
2024-07-14 05:54:54,382 [INFO    ] __main__: train step 8945: loss: 1.1252, policy_loss: 1.2109, value_loss: 0.7873
2024-07-14 05:54:54,670 [INFO    ] __main__: train step 8946: loss: 1.1252, policy_loss: 1.2109, value_loss: 0.7872
2024-07-14 05:54:54,967 [INFO    ] __main__: train step 8947: loss: 1.1252, policy_loss: 1.2108, value_loss: 0.7872
2024-07-14 05:54:55,276 [INFO    ] __main__: train step 8948: loss: 1.1252, policy_loss: 1.2108, value_loss: 0.7872
2024-07-14 05:54:55,582 [INFO    ] __main__: train step 8949: loss: 1.1252, policy_loss: 1.2107, value_loss: 0.7871
2024-07-14 05:54:55,881 [INFO    ] __main__: train step 8950: loss: 1.1252, policy_loss: 1.2106, value_loss: 0.7871
2024-07-14 05:54:57,730 [INFO    ] __main__: train step 8951: loss: 1.1252, policy_loss: 1.2106, value_loss: 0.7870
2024-07-14 05:54:58,038 [INFO    ] __main__: train step 8952: loss: 1.1252, policy_loss: 1.2105, value_loss: 0.7870
2024-07-14 05:54:58,340 [INFO    ] __main__: train step 8953: loss: 1.1252, policy_loss: 1.2104, value_loss: 0.7870
2024-07-14 05:54:58,641 [INFO    ] __main__: train step 8954: loss: 1.1252, policy_loss: 1.2104, value_loss: 0.7869
2024-07-14 05:54:58,939 [INFO    ] __main__: train step 8955: loss: 1.1252, policy_loss: 1.2103, value_loss: 0.7869
2024-07-14 05:55:00,545 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:55:01,037 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:55:01,107 [INFO    ] __main__: train step 8956: loss: 1.1252, policy_loss: 1.2102, value_loss: 0.7869
2024-07-14 05:55:01,397 [INFO    ] __main__: train step 8957: loss: 1.1252, policy_loss: 1.2102, value_loss: 0.7868
2024-07-14 05:55:01,691 [INFO    ] __main__: train step 8958: loss: 1.1252, policy_loss: 1.2101, value_loss: 0.7868
2024-07-14 05:55:01,990 [INFO    ] __main__: train step 8959: loss: 1.1252, policy_loss: 1.2101, value_loss: 0.7868
2024-07-14 05:55:02,285 [INFO    ] __main__: train step 8960: loss: 1.1252, policy_loss: 1.2100, value_loss: 0.7867
2024-07-14 05:55:02,572 [INFO    ] __main__: train step 8961: loss: 1.1252, policy_loss: 1.2099, value_loss: 0.7867
2024-07-14 05:55:02,864 [INFO    ] __main__: train step 8962: loss: 1.1252, policy_loss: 1.2099, value_loss: 0.7867
2024-07-14 05:55:03,163 [INFO    ] __main__: train step 8963: loss: 1.1252, policy_loss: 1.2098, value_loss: 0.7866
2024-07-14 05:55:03,461 [INFO    ] __main__: train step 8964: loss: 1.1252, policy_loss: 1.2097, value_loss: 0.7866
2024-07-14 05:55:03,758 [INFO    ] __main__: train step 8965: loss: 1.1252, policy_loss: 1.2097, value_loss: 0.7866
2024-07-14 05:55:04,046 [INFO    ] __main__: train step 8966: loss: 1.1252, policy_loss: 1.2096, value_loss: 0.7865
2024-07-14 05:55:04,345 [INFO    ] __main__: train step 8967: loss: 1.1252, policy_loss: 1.2095, value_loss: 0.7865
2024-07-14 05:55:04,631 [INFO    ] __main__: train step 8968: loss: 1.1252, policy_loss: 1.2095, value_loss: 0.7864
2024-07-14 05:55:04,929 [INFO    ] __main__: train step 8969: loss: 1.1252, policy_loss: 1.2094, value_loss: 0.7864
2024-07-14 05:55:05,217 [INFO    ] __main__: train step 8970: loss: 1.1252, policy_loss: 1.2094, value_loss: 0.7864
2024-07-14 05:55:05,500 [INFO    ] __main__: train step 8971: loss: 1.1252, policy_loss: 1.2093, value_loss: 0.7863
2024-07-14 05:55:05,800 [INFO    ] __main__: train step 8972: loss: 1.1252, policy_loss: 1.2092, value_loss: 0.7863
2024-07-14 05:55:07,427 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:55:07,924 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:55:07,996 [INFO    ] __main__: train step 8973: loss: 1.1252, policy_loss: 1.2092, value_loss: 0.7863
2024-07-14 05:55:08,294 [INFO    ] __main__: train step 8974: loss: 1.1252, policy_loss: 1.2091, value_loss: 0.7862
2024-07-14 05:55:08,581 [INFO    ] __main__: train step 8975: loss: 1.1252, policy_loss: 1.2090, value_loss: 0.7862
2024-07-14 05:55:08,874 [INFO    ] __main__: train step 8976: loss: 1.1252, policy_loss: 1.2090, value_loss: 0.7861
2024-07-14 05:55:09,180 [INFO    ] __main__: train step 8977: loss: 1.1252, policy_loss: 1.2089, value_loss: 0.7861
2024-07-14 05:55:09,469 [INFO    ] __main__: train step 8978: loss: 1.1252, policy_loss: 1.2088, value_loss: 0.7861
2024-07-14 05:55:09,778 [INFO    ] __main__: train step 8979: loss: 1.1252, policy_loss: 1.2088, value_loss: 0.7860
2024-07-14 05:55:10,092 [INFO    ] __main__: train step 8980: loss: 1.1252, policy_loss: 1.2087, value_loss: 0.7860
2024-07-14 05:55:10,372 [INFO    ] __main__: train step 8981: loss: 1.1252, policy_loss: 1.2087, value_loss: 0.7860
2024-07-14 05:55:10,652 [INFO    ] __main__: train step 8982: loss: 1.1252, policy_loss: 1.2086, value_loss: 0.7859
2024-07-14 05:55:10,956 [INFO    ] __main__: train step 8983: loss: 1.1252, policy_loss: 1.2085, value_loss: 0.7859
2024-07-14 05:55:11,250 [INFO    ] __main__: train step 8984: loss: 1.1252, policy_loss: 1.2085, value_loss: 0.7859
2024-07-14 05:55:11,539 [INFO    ] __main__: train step 8985: loss: 1.1251, policy_loss: 1.2084, value_loss: 0.7858
2024-07-14 05:55:11,837 [INFO    ] __main__: train step 8986: loss: 1.1251, policy_loss: 1.2083, value_loss: 0.7858
2024-07-14 05:55:12,139 [INFO    ] __main__: train step 8987: loss: 1.1251, policy_loss: 1.2083, value_loss: 0.7857
2024-07-14 05:55:12,431 [INFO    ] __main__: train step 8988: loss: 1.1251, policy_loss: 1.2082, value_loss: 0.7857
2024-07-14 05:55:12,719 [INFO    ] __main__: train step 8989: loss: 1.1251, policy_loss: 1.2081, value_loss: 0.7857
2024-07-14 05:55:14,336 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:55:14,837 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:55:14,913 [INFO    ] __main__: train step 8990: loss: 1.1251, policy_loss: 1.2081, value_loss: 0.7856
2024-07-14 05:55:15,211 [INFO    ] __main__: train step 8991: loss: 1.1251, policy_loss: 1.2080, value_loss: 0.7856
2024-07-14 05:55:15,503 [INFO    ] __main__: train step 8992: loss: 1.1251, policy_loss: 1.2080, value_loss: 0.7856
2024-07-14 05:55:15,797 [INFO    ] __main__: train step 8993: loss: 1.1251, policy_loss: 1.2079, value_loss: 0.7855
2024-07-14 05:55:16,100 [INFO    ] __main__: train step 8994: loss: 1.1251, policy_loss: 1.2078, value_loss: 0.7855
2024-07-14 05:55:16,423 [INFO    ] __main__: train step 8995: loss: 1.1251, policy_loss: 1.2078, value_loss: 0.7855
2024-07-14 05:55:16,721 [INFO    ] __main__: train step 8996: loss: 1.1251, policy_loss: 1.2077, value_loss: 0.7854
2024-07-14 05:55:17,031 [INFO    ] __main__: train step 8997: loss: 1.1251, policy_loss: 1.2076, value_loss: 0.7854
2024-07-14 05:55:17,331 [INFO    ] __main__: train step 8998: loss: 1.1251, policy_loss: 1.2076, value_loss: 0.7853
2024-07-14 05:55:17,637 [INFO    ] __main__: train step 8999: loss: 1.1251, policy_loss: 1.2075, value_loss: 0.7853
2024-07-14 05:55:17,933 [INFO    ] __main__: train step 9000: loss: 1.1251, policy_loss: 1.2074, value_loss: 0.7853
2024-07-14 05:55:18,090 [INFO    ] __main__: restored step 8000 for evaluation
2024-07-14 05:55:23,364 [INFO    ] __main__: test network ELO difference from baseline network: +166 (+8/-8) ELO from 32000 self-played games
2024-07-14 05:55:23,367 [INFO    ] __main__: game outcomes: W: 21641, D: 953, L: 9406
2024-07-14 05:55:23,371 [INFO    ] __main__: validation_elo_delta: 166, validation_elo: 1980
2024-07-14 05:55:24,169 [INFO    ] __main__: train step 9001: loss: 1.1251, policy_loss: 1.2074, value_loss: 0.7852
2024-07-14 05:55:24,462 [INFO    ] __main__: train step 9002: loss: 1.1251, policy_loss: 1.2073, value_loss: 0.7852
2024-07-14 05:55:24,762 [INFO    ] __main__: train step 9003: loss: 1.1251, policy_loss: 1.2072, value_loss: 0.7852
2024-07-14 05:55:26,700 [INFO    ] __main__: train step 9004: loss: 1.1251, policy_loss: 1.2072, value_loss: 0.7851
2024-07-14 05:55:26,996 [INFO    ] __main__: train step 9005: loss: 1.1251, policy_loss: 1.2071, value_loss: 0.7851
2024-07-14 05:55:27,295 [INFO    ] __main__: train step 9006: loss: 1.1251, policy_loss: 1.2071, value_loss: 0.7851
2024-07-14 05:55:28,919 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:55:29,413 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:55:29,485 [INFO    ] __main__: train step 9007: loss: 1.1251, policy_loss: 1.2070, value_loss: 0.7850
2024-07-14 05:55:29,795 [INFO    ] __main__: train step 9008: loss: 1.1251, policy_loss: 1.2069, value_loss: 0.7850
2024-07-14 05:55:30,070 [INFO    ] __main__: train step 9009: loss: 1.1251, policy_loss: 1.2069, value_loss: 0.7849
2024-07-14 05:55:30,366 [INFO    ] __main__: train step 9010: loss: 1.1251, policy_loss: 1.2068, value_loss: 0.7849
2024-07-14 05:55:30,661 [INFO    ] __main__: train step 9011: loss: 1.1250, policy_loss: 1.2067, value_loss: 0.7849
2024-07-14 05:55:30,955 [INFO    ] __main__: train step 9012: loss: 1.1250, policy_loss: 1.2067, value_loss: 0.7848
2024-07-14 05:55:31,251 [INFO    ] __main__: train step 9013: loss: 1.1250, policy_loss: 1.2066, value_loss: 0.7848
2024-07-14 05:55:31,552 [INFO    ] __main__: train step 9014: loss: 1.1250, policy_loss: 1.2065, value_loss: 0.7848
2024-07-14 05:55:31,844 [INFO    ] __main__: train step 9015: loss: 1.1250, policy_loss: 1.2065, value_loss: 0.7847
2024-07-14 05:55:32,135 [INFO    ] __main__: train step 9016: loss: 1.1250, policy_loss: 1.2064, value_loss: 0.7847
2024-07-14 05:55:32,442 [INFO    ] __main__: train step 9017: loss: 1.1250, policy_loss: 1.2063, value_loss: 0.7846
2024-07-14 05:55:32,736 [INFO    ] __main__: train step 9018: loss: 1.1250, policy_loss: 1.2063, value_loss: 0.7846
2024-07-14 05:55:33,022 [INFO    ] __main__: train step 9019: loss: 1.1250, policy_loss: 1.2062, value_loss: 0.7846
2024-07-14 05:55:33,312 [INFO    ] __main__: train step 9020: loss: 1.1250, policy_loss: 1.2061, value_loss: 0.7845
2024-07-14 05:55:33,613 [INFO    ] __main__: train step 9021: loss: 1.1250, policy_loss: 1.2061, value_loss: 0.7845
2024-07-14 05:55:33,895 [INFO    ] __main__: train step 9022: loss: 1.1250, policy_loss: 1.2060, value_loss: 0.7845
2024-07-14 05:55:34,164 [INFO    ] __main__: train step 9023: loss: 1.1250, policy_loss: 1.2060, value_loss: 0.7844
2024-07-14 05:55:35,759 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:55:36,235 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:55:36,303 [INFO    ] __main__: train step 9024: loss: 1.1250, policy_loss: 1.2059, value_loss: 0.7844
2024-07-14 05:55:36,575 [INFO    ] __main__: train step 9025: loss: 1.1250, policy_loss: 1.2058, value_loss: 0.7844
2024-07-14 05:55:36,851 [INFO    ] __main__: train step 9026: loss: 1.1250, policy_loss: 1.2058, value_loss: 0.7843
2024-07-14 05:55:37,137 [INFO    ] __main__: train step 9027: loss: 1.1250, policy_loss: 1.2057, value_loss: 0.7843
2024-07-14 05:55:37,425 [INFO    ] __main__: train step 9028: loss: 1.1250, policy_loss: 1.2056, value_loss: 0.7842
2024-07-14 05:55:37,724 [INFO    ] __main__: train step 9029: loss: 1.1250, policy_loss: 1.2056, value_loss: 0.7842
2024-07-14 05:55:38,017 [INFO    ] __main__: train step 9030: loss: 1.1249, policy_loss: 1.2055, value_loss: 0.7842
2024-07-14 05:55:38,306 [INFO    ] __main__: train step 9031: loss: 1.1249, policy_loss: 1.2054, value_loss: 0.7841
2024-07-14 05:55:38,616 [INFO    ] __main__: train step 9032: loss: 1.1249, policy_loss: 1.2054, value_loss: 0.7841
2024-07-14 05:55:38,911 [INFO    ] __main__: train step 9033: loss: 1.1249, policy_loss: 1.2053, value_loss: 0.7841
2024-07-14 05:55:39,200 [INFO    ] __main__: train step 9034: loss: 1.1249, policy_loss: 1.2053, value_loss: 0.7840
2024-07-14 05:55:39,487 [INFO    ] __main__: train step 9035: loss: 1.1249, policy_loss: 1.2052, value_loss: 0.7840
2024-07-14 05:55:39,787 [INFO    ] __main__: train step 9036: loss: 1.1249, policy_loss: 1.2051, value_loss: 0.7840
2024-07-14 05:55:40,105 [INFO    ] __main__: train step 9037: loss: 1.1249, policy_loss: 1.2051, value_loss: 0.7839
2024-07-14 05:55:40,395 [INFO    ] __main__: train step 9038: loss: 1.1249, policy_loss: 1.2050, value_loss: 0.7839
2024-07-14 05:55:40,682 [INFO    ] __main__: train step 9039: loss: 1.1249, policy_loss: 1.2049, value_loss: 0.7838
2024-07-14 05:55:40,985 [INFO    ] __main__: train step 9040: loss: 1.1249, policy_loss: 1.2049, value_loss: 0.7838
2024-07-14 05:55:42,617 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:55:43,108 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:55:43,180 [INFO    ] __main__: train step 9041: loss: 1.1249, policy_loss: 1.2048, value_loss: 0.7838
2024-07-14 05:55:43,478 [INFO    ] __main__: train step 9042: loss: 1.1249, policy_loss: 1.2047, value_loss: 0.7837
2024-07-14 05:55:43,764 [INFO    ] __main__: train step 9043: loss: 1.1249, policy_loss: 1.2047, value_loss: 0.7837
2024-07-14 05:55:44,066 [INFO    ] __main__: train step 9044: loss: 1.1249, policy_loss: 1.2046, value_loss: 0.7837
2024-07-14 05:55:44,358 [INFO    ] __main__: train step 9045: loss: 1.1249, policy_loss: 1.2045, value_loss: 0.7836
2024-07-14 05:55:44,648 [INFO    ] __main__: train step 9046: loss: 1.1249, policy_loss: 1.2045, value_loss: 0.7836
2024-07-14 05:55:44,945 [INFO    ] __main__: train step 9047: loss: 1.1249, policy_loss: 1.2044, value_loss: 0.7835
2024-07-14 05:55:45,226 [INFO    ] __main__: train step 9048: loss: 1.1248, policy_loss: 1.2044, value_loss: 0.7835
2024-07-14 05:55:45,515 [INFO    ] __main__: train step 9049: loss: 1.1248, policy_loss: 1.2043, value_loss: 0.7835
2024-07-14 05:55:45,818 [INFO    ] __main__: train step 9050: loss: 1.1248, policy_loss: 1.2042, value_loss: 0.7834
2024-07-14 05:55:46,109 [INFO    ] __main__: train step 9051: loss: 1.1248, policy_loss: 1.2042, value_loss: 0.7834
2024-07-14 05:55:46,413 [INFO    ] __main__: train step 9052: loss: 1.1248, policy_loss: 1.2041, value_loss: 0.7834
2024-07-14 05:55:46,695 [INFO    ] __main__: train step 9053: loss: 1.1248, policy_loss: 1.2040, value_loss: 0.7833
2024-07-14 05:55:46,990 [INFO    ] __main__: train step 9054: loss: 1.1248, policy_loss: 1.2040, value_loss: 0.7833
2024-07-14 05:55:47,275 [INFO    ] __main__: train step 9055: loss: 1.1248, policy_loss: 1.2039, value_loss: 0.7832
2024-07-14 05:55:47,568 [INFO    ] __main__: train step 9056: loss: 1.1248, policy_loss: 1.2038, value_loss: 0.7832
2024-07-14 05:55:47,860 [INFO    ] __main__: train step 9057: loss: 1.1248, policy_loss: 1.2038, value_loss: 0.7832
2024-07-14 05:55:49,501 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:55:50,001 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:55:50,071 [INFO    ] __main__: train step 9058: loss: 1.1248, policy_loss: 1.2037, value_loss: 0.7831
2024-07-14 05:55:51,854 [INFO    ] __main__: train step 9059: loss: 1.1248, policy_loss: 1.2037, value_loss: 0.7831
2024-07-14 05:55:52,151 [INFO    ] __main__: train step 9060: loss: 1.1248, policy_loss: 1.2036, value_loss: 0.7831
2024-07-14 05:55:52,430 [INFO    ] __main__: train step 9061: loss: 1.1248, policy_loss: 1.2035, value_loss: 0.7830
2024-07-14 05:55:52,712 [INFO    ] __main__: train step 9062: loss: 1.1248, policy_loss: 1.2035, value_loss: 0.7830
2024-07-14 05:55:53,008 [INFO    ] __main__: train step 9063: loss: 1.1248, policy_loss: 1.2034, value_loss: 0.7829
2024-07-14 05:55:53,304 [INFO    ] __main__: train step 9064: loss: 1.1247, policy_loss: 1.2033, value_loss: 0.7829
2024-07-14 05:55:53,599 [INFO    ] __main__: train step 9065: loss: 1.1247, policy_loss: 1.2033, value_loss: 0.7829
2024-07-14 05:55:53,895 [INFO    ] __main__: train step 9066: loss: 1.1247, policy_loss: 1.2032, value_loss: 0.7828
2024-07-14 05:55:54,203 [INFO    ] __main__: train step 9067: loss: 1.1247, policy_loss: 1.2031, value_loss: 0.7828
2024-07-14 05:55:54,520 [INFO    ] __main__: train step 9068: loss: 1.1247, policy_loss: 1.2031, value_loss: 0.7828
2024-07-14 05:55:54,807 [INFO    ] __main__: train step 9069: loss: 1.1247, policy_loss: 1.2030, value_loss: 0.7827
2024-07-14 05:55:55,111 [INFO    ] __main__: train step 9070: loss: 1.1247, policy_loss: 1.2029, value_loss: 0.7827
2024-07-14 05:55:55,407 [INFO    ] __main__: train step 9071: loss: 1.1247, policy_loss: 1.2029, value_loss: 0.7827
2024-07-14 05:55:55,695 [INFO    ] __main__: train step 9072: loss: 1.1247, policy_loss: 1.2028, value_loss: 0.7826
2024-07-14 05:55:55,990 [INFO    ] __main__: train step 9073: loss: 1.1247, policy_loss: 1.2028, value_loss: 0.7826
2024-07-14 05:55:56,287 [INFO    ] __main__: train step 9074: loss: 1.1247, policy_loss: 1.2027, value_loss: 0.7825
2024-07-14 05:55:57,898 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:55:58,399 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:55:58,468 [INFO    ] __main__: train step 9075: loss: 1.1247, policy_loss: 1.2026, value_loss: 0.7825
2024-07-14 05:55:58,768 [INFO    ] __main__: train step 9076: loss: 1.1247, policy_loss: 1.2026, value_loss: 0.7825
2024-07-14 05:55:59,060 [INFO    ] __main__: train step 9077: loss: 1.1247, policy_loss: 1.2025, value_loss: 0.7824
2024-07-14 05:55:59,357 [INFO    ] __main__: train step 9078: loss: 1.1247, policy_loss: 1.2024, value_loss: 0.7824
2024-07-14 05:55:59,646 [INFO    ] __main__: train step 9079: loss: 1.1246, policy_loss: 1.2024, value_loss: 0.7823
2024-07-14 05:55:59,942 [INFO    ] __main__: train step 9080: loss: 1.1246, policy_loss: 1.2023, value_loss: 0.7823
2024-07-14 05:56:00,236 [INFO    ] __main__: train step 9081: loss: 1.1246, policy_loss: 1.2022, value_loss: 0.7823
2024-07-14 05:56:00,518 [INFO    ] __main__: train step 9082: loss: 1.1246, policy_loss: 1.2022, value_loss: 0.7822
2024-07-14 05:56:00,817 [INFO    ] __main__: train step 9083: loss: 1.1246, policy_loss: 1.2021, value_loss: 0.7822
2024-07-14 05:56:01,125 [INFO    ] __main__: train step 9084: loss: 1.1246, policy_loss: 1.2020, value_loss: 0.7822
2024-07-14 05:56:01,423 [INFO    ] __main__: train step 9085: loss: 1.1246, policy_loss: 1.2020, value_loss: 0.7821
2024-07-14 05:56:01,696 [INFO    ] __main__: train step 9086: loss: 1.1246, policy_loss: 1.2019, value_loss: 0.7821
2024-07-14 05:56:01,980 [INFO    ] __main__: train step 9087: loss: 1.1246, policy_loss: 1.2019, value_loss: 0.7820
2024-07-14 05:56:02,278 [INFO    ] __main__: train step 9088: loss: 1.1246, policy_loss: 1.2018, value_loss: 0.7820
2024-07-14 05:56:02,584 [INFO    ] __main__: train step 9089: loss: 1.1246, policy_loss: 1.2017, value_loss: 0.7820
2024-07-14 05:56:02,862 [INFO    ] __main__: train step 9090: loss: 1.1246, policy_loss: 1.2017, value_loss: 0.7819
2024-07-14 05:56:03,137 [INFO    ] __main__: train step 9091: loss: 1.1246, policy_loss: 1.2016, value_loss: 0.7819
2024-07-14 05:56:04,731 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:56:05,205 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:56:05,278 [INFO    ] __main__: train step 9092: loss: 1.1246, policy_loss: 1.2015, value_loss: 0.7819
2024-07-14 05:56:05,584 [INFO    ] __main__: train step 9093: loss: 1.1245, policy_loss: 1.2015, value_loss: 0.7818
2024-07-14 05:56:05,874 [INFO    ] __main__: train step 9094: loss: 1.1245, policy_loss: 1.2014, value_loss: 0.7818
2024-07-14 05:56:06,164 [INFO    ] __main__: train step 9095: loss: 1.1245, policy_loss: 1.2013, value_loss: 0.7818
2024-07-14 05:56:06,463 [INFO    ] __main__: train step 9096: loss: 1.1245, policy_loss: 1.2013, value_loss: 0.7817
2024-07-14 05:56:06,753 [INFO    ] __main__: train step 9097: loss: 1.1245, policy_loss: 1.2012, value_loss: 0.7817
2024-07-14 05:56:07,065 [INFO    ] __main__: train step 9098: loss: 1.1245, policy_loss: 1.2011, value_loss: 0.7816
2024-07-14 05:56:07,378 [INFO    ] __main__: train step 9099: loss: 1.1245, policy_loss: 1.2011, value_loss: 0.7816
2024-07-14 05:56:07,671 [INFO    ] __main__: train step 9100: loss: 1.1245, policy_loss: 1.2010, value_loss: 0.7816
2024-07-14 05:56:07,979 [INFO    ] __main__: train step 9101: loss: 1.1245, policy_loss: 1.2010, value_loss: 0.7815
2024-07-14 05:56:08,292 [INFO    ] __main__: train step 9102: loss: 1.1245, policy_loss: 1.2009, value_loss: 0.7815
2024-07-14 05:56:08,597 [INFO    ] __main__: train step 9103: loss: 1.1245, policy_loss: 1.2008, value_loss: 0.7815
2024-07-14 05:56:08,892 [INFO    ] __main__: train step 9104: loss: 1.1245, policy_loss: 1.2008, value_loss: 0.7814
2024-07-14 05:56:09,184 [INFO    ] __main__: train step 9105: loss: 1.1245, policy_loss: 1.2007, value_loss: 0.7814
2024-07-14 05:56:09,488 [INFO    ] __main__: train step 9106: loss: 1.1245, policy_loss: 1.2006, value_loss: 0.7813
2024-07-14 05:56:09,787 [INFO    ] __main__: train step 9107: loss: 1.1244, policy_loss: 1.2006, value_loss: 0.7813
2024-07-14 05:56:10,080 [INFO    ] __main__: train step 9108: loss: 1.1244, policy_loss: 1.2005, value_loss: 0.7813
2024-07-14 05:56:11,708 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:56:12,196 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:56:12,264 [INFO    ] __main__: train step 9109: loss: 1.1244, policy_loss: 1.2004, value_loss: 0.7812
2024-07-14 05:56:12,566 [INFO    ] __main__: train step 9110: loss: 1.1244, policy_loss: 1.2004, value_loss: 0.7812
2024-07-14 05:56:12,857 [INFO    ] __main__: train step 9111: loss: 1.1244, policy_loss: 1.2003, value_loss: 0.7812
2024-07-14 05:56:13,150 [INFO    ] __main__: train step 9112: loss: 1.1244, policy_loss: 1.2002, value_loss: 0.7811
2024-07-14 05:56:13,444 [INFO    ] __main__: train step 9113: loss: 1.1244, policy_loss: 1.2002, value_loss: 0.7811
2024-07-14 05:56:15,320 [INFO    ] __main__: train step 9114: loss: 1.1244, policy_loss: 1.2001, value_loss: 0.7810
2024-07-14 05:56:15,625 [INFO    ] __main__: train step 9115: loss: 1.1244, policy_loss: 1.2001, value_loss: 0.7810
2024-07-14 05:56:15,931 [INFO    ] __main__: train step 9116: loss: 1.1244, policy_loss: 1.2000, value_loss: 0.7810
2024-07-14 05:56:16,224 [INFO    ] __main__: train step 9117: loss: 1.1244, policy_loss: 1.1999, value_loss: 0.7809
2024-07-14 05:56:16,531 [INFO    ] __main__: train step 9118: loss: 1.1244, policy_loss: 1.1999, value_loss: 0.7809
2024-07-14 05:56:16,831 [INFO    ] __main__: train step 9119: loss: 1.1244, policy_loss: 1.1998, value_loss: 0.7809
2024-07-14 05:56:17,127 [INFO    ] __main__: train step 9120: loss: 1.1243, policy_loss: 1.1997, value_loss: 0.7808
2024-07-14 05:56:17,428 [INFO    ] __main__: train step 9121: loss: 1.1243, policy_loss: 1.1997, value_loss: 0.7808
2024-07-14 05:56:17,738 [INFO    ] __main__: train step 9122: loss: 1.1243, policy_loss: 1.1996, value_loss: 0.7807
2024-07-14 05:56:18,041 [INFO    ] __main__: train step 9123: loss: 1.1243, policy_loss: 1.1995, value_loss: 0.7807
2024-07-14 05:56:18,355 [INFO    ] __main__: train step 9124: loss: 1.1243, policy_loss: 1.1995, value_loss: 0.7807
2024-07-14 05:56:18,642 [INFO    ] __main__: train step 9125: loss: 1.1243, policy_loss: 1.1994, value_loss: 0.7806
2024-07-14 05:56:20,283 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:56:20,767 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:56:20,835 [INFO    ] __main__: train step 9126: loss: 1.1243, policy_loss: 1.1993, value_loss: 0.7806
2024-07-14 05:56:21,138 [INFO    ] __main__: train step 9127: loss: 1.1243, policy_loss: 1.1993, value_loss: 0.7806
2024-07-14 05:56:21,445 [INFO    ] __main__: train step 9128: loss: 1.1243, policy_loss: 1.1992, value_loss: 0.7805
2024-07-14 05:56:21,746 [INFO    ] __main__: train step 9129: loss: 1.1243, policy_loss: 1.1991, value_loss: 0.7805
2024-07-14 05:56:22,043 [INFO    ] __main__: train step 9130: loss: 1.1243, policy_loss: 1.1991, value_loss: 0.7804
2024-07-14 05:56:22,350 [INFO    ] __main__: train step 9131: loss: 1.1242, policy_loss: 1.1990, value_loss: 0.7804
2024-07-14 05:56:22,660 [INFO    ] __main__: train step 9132: loss: 1.1242, policy_loss: 1.1990, value_loss: 0.7804
2024-07-14 05:56:22,964 [INFO    ] __main__: train step 9133: loss: 1.1242, policy_loss: 1.1989, value_loss: 0.7803
2024-07-14 05:56:23,254 [INFO    ] __main__: train step 9134: loss: 1.1242, policy_loss: 1.1988, value_loss: 0.7803
2024-07-14 05:56:23,559 [INFO    ] __main__: train step 9135: loss: 1.1242, policy_loss: 1.1988, value_loss: 0.7803
2024-07-14 05:56:23,860 [INFO    ] __main__: train step 9136: loss: 1.1242, policy_loss: 1.1987, value_loss: 0.7802
2024-07-14 05:56:24,154 [INFO    ] __main__: train step 9137: loss: 1.1242, policy_loss: 1.1986, value_loss: 0.7802
2024-07-14 05:56:24,456 [INFO    ] __main__: train step 9138: loss: 1.1242, policy_loss: 1.1986, value_loss: 0.7801
2024-07-14 05:56:24,746 [INFO    ] __main__: train step 9139: loss: 1.1242, policy_loss: 1.1985, value_loss: 0.7801
2024-07-14 05:56:25,040 [INFO    ] __main__: train step 9140: loss: 1.1242, policy_loss: 1.1984, value_loss: 0.7801
2024-07-14 05:56:25,346 [INFO    ] __main__: train step 9141: loss: 1.1242, policy_loss: 1.1984, value_loss: 0.7800
2024-07-14 05:56:25,651 [INFO    ] __main__: train step 9142: loss: 1.1241, policy_loss: 1.1983, value_loss: 0.7800
2024-07-14 05:56:27,276 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:56:27,753 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:56:27,827 [INFO    ] __main__: train step 9143: loss: 1.1241, policy_loss: 1.1982, value_loss: 0.7799
2024-07-14 05:56:28,122 [INFO    ] __main__: train step 9144: loss: 1.1241, policy_loss: 1.1982, value_loss: 0.7799
2024-07-14 05:56:28,425 [INFO    ] __main__: train step 9145: loss: 1.1241, policy_loss: 1.1981, value_loss: 0.7799
2024-07-14 05:56:28,723 [INFO    ] __main__: train step 9146: loss: 1.1241, policy_loss: 1.1980, value_loss: 0.7798
2024-07-14 05:56:29,027 [INFO    ] __main__: train step 9147: loss: 1.1241, policy_loss: 1.1980, value_loss: 0.7798
2024-07-14 05:56:29,325 [INFO    ] __main__: train step 9148: loss: 1.1241, policy_loss: 1.1979, value_loss: 0.7798
2024-07-14 05:56:29,621 [INFO    ] __main__: train step 9149: loss: 1.1241, policy_loss: 1.1978, value_loss: 0.7797
2024-07-14 05:56:29,931 [INFO    ] __main__: train step 9150: loss: 1.1241, policy_loss: 1.1978, value_loss: 0.7797
2024-07-14 05:56:30,235 [INFO    ] __main__: train step 9151: loss: 1.1241, policy_loss: 1.1977, value_loss: 0.7796
2024-07-14 05:56:30,514 [INFO    ] __main__: train step 9152: loss: 1.1241, policy_loss: 1.1977, value_loss: 0.7796
2024-07-14 05:56:30,786 [INFO    ] __main__: train step 9153: loss: 1.1240, policy_loss: 1.1976, value_loss: 0.7796
2024-07-14 05:56:31,089 [INFO    ] __main__: train step 9154: loss: 1.1240, policy_loss: 1.1975, value_loss: 0.7795
2024-07-14 05:56:31,409 [INFO    ] __main__: train step 9155: loss: 1.1240, policy_loss: 1.1975, value_loss: 0.7795
2024-07-14 05:56:31,700 [INFO    ] __main__: train step 9156: loss: 1.1240, policy_loss: 1.1974, value_loss: 0.7795
2024-07-14 05:56:32,009 [INFO    ] __main__: train step 9157: loss: 1.1240, policy_loss: 1.1973, value_loss: 0.7794
2024-07-14 05:56:32,307 [INFO    ] __main__: train step 9158: loss: 1.1240, policy_loss: 1.1973, value_loss: 0.7794
2024-07-14 05:56:32,631 [INFO    ] __main__: train step 9159: loss: 1.1240, policy_loss: 1.1972, value_loss: 0.7793
2024-07-14 05:56:34,253 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:56:34,741 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:56:34,814 [INFO    ] __main__: train step 9160: loss: 1.1240, policy_loss: 1.1971, value_loss: 0.7793
2024-07-14 05:56:35,109 [INFO    ] __main__: train step 9161: loss: 1.1240, policy_loss: 1.1971, value_loss: 0.7793
2024-07-14 05:56:35,404 [INFO    ] __main__: train step 9162: loss: 1.1240, policy_loss: 1.1970, value_loss: 0.7792
2024-07-14 05:56:35,703 [INFO    ] __main__: train step 9163: loss: 1.1239, policy_loss: 1.1969, value_loss: 0.7792
2024-07-14 05:56:36,007 [INFO    ] __main__: train step 9164: loss: 1.1239, policy_loss: 1.1969, value_loss: 0.7792
2024-07-14 05:56:36,306 [INFO    ] __main__: train step 9165: loss: 1.1239, policy_loss: 1.1968, value_loss: 0.7791
2024-07-14 05:56:36,607 [INFO    ] __main__: train step 9166: loss: 1.1239, policy_loss: 1.1967, value_loss: 0.7791
2024-07-14 05:56:36,910 [INFO    ] __main__: train step 9167: loss: 1.1239, policy_loss: 1.1967, value_loss: 0.7791
2024-07-14 05:56:37,208 [INFO    ] __main__: train step 9168: loss: 1.1239, policy_loss: 1.1966, value_loss: 0.7790
2024-07-14 05:56:37,513 [INFO    ] __main__: train step 9169: loss: 1.1239, policy_loss: 1.1966, value_loss: 0.7790
2024-07-14 05:56:39,367 [INFO    ] __main__: train step 9170: loss: 1.1239, policy_loss: 1.1965, value_loss: 0.7789
2024-07-14 05:56:39,668 [INFO    ] __main__: train step 9171: loss: 1.1239, policy_loss: 1.1964, value_loss: 0.7789
2024-07-14 05:56:39,973 [INFO    ] __main__: train step 9172: loss: 1.1239, policy_loss: 1.1964, value_loss: 0.7789
2024-07-14 05:56:40,267 [INFO    ] __main__: train step 9173: loss: 1.1239, policy_loss: 1.1963, value_loss: 0.7788
2024-07-14 05:56:40,572 [INFO    ] __main__: train step 9174: loss: 1.1239, policy_loss: 1.1962, value_loss: 0.7788
2024-07-14 05:56:40,860 [INFO    ] __main__: train step 9175: loss: 1.1238, policy_loss: 1.1962, value_loss: 0.7787
2024-07-14 05:56:41,166 [INFO    ] __main__: train step 9176: loss: 1.1238, policy_loss: 1.1961, value_loss: 0.7787
2024-07-14 05:56:42,824 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:56:43,319 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:56:43,391 [INFO    ] __main__: train step 9177: loss: 1.1238, policy_loss: 1.1960, value_loss: 0.7787
2024-07-14 05:56:43,701 [INFO    ] __main__: train step 9178: loss: 1.1238, policy_loss: 1.1960, value_loss: 0.7786
2024-07-14 05:56:44,002 [INFO    ] __main__: train step 9179: loss: 1.1238, policy_loss: 1.1959, value_loss: 0.7786
2024-07-14 05:56:44,312 [INFO    ] __main__: train step 9180: loss: 1.1238, policy_loss: 1.1959, value_loss: 0.7786
2024-07-14 05:56:44,610 [INFO    ] __main__: train step 9181: loss: 1.1238, policy_loss: 1.1958, value_loss: 0.7785
2024-07-14 05:56:44,932 [INFO    ] __main__: train step 9182: loss: 1.1238, policy_loss: 1.1957, value_loss: 0.7785
2024-07-14 05:56:45,231 [INFO    ] __main__: train step 9183: loss: 1.1238, policy_loss: 1.1957, value_loss: 0.7784
2024-07-14 05:56:45,527 [INFO    ] __main__: train step 9184: loss: 1.1238, policy_loss: 1.1956, value_loss: 0.7784
2024-07-14 05:56:45,833 [INFO    ] __main__: train step 9185: loss: 1.1237, policy_loss: 1.1955, value_loss: 0.7784
2024-07-14 05:56:46,145 [INFO    ] __main__: train step 9186: loss: 1.1237, policy_loss: 1.1955, value_loss: 0.7783
2024-07-14 05:56:46,450 [INFO    ] __main__: train step 9187: loss: 1.1237, policy_loss: 1.1954, value_loss: 0.7783
2024-07-14 05:56:46,749 [INFO    ] __main__: train step 9188: loss: 1.1237, policy_loss: 1.1953, value_loss: 0.7783
2024-07-14 05:56:47,057 [INFO    ] __main__: train step 9189: loss: 1.1237, policy_loss: 1.1953, value_loss: 0.7782
2024-07-14 05:56:47,357 [INFO    ] __main__: train step 9190: loss: 1.1237, policy_loss: 1.1952, value_loss: 0.7782
2024-07-14 05:56:47,653 [INFO    ] __main__: train step 9191: loss: 1.1237, policy_loss: 1.1951, value_loss: 0.7781
2024-07-14 05:56:47,951 [INFO    ] __main__: train step 9192: loss: 1.1237, policy_loss: 1.1951, value_loss: 0.7781
2024-07-14 05:56:48,215 [INFO    ] __main__: train step 9193: loss: 1.1237, policy_loss: 1.1950, value_loss: 0.7781
2024-07-14 05:56:49,829 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:56:50,310 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:56:50,380 [INFO    ] __main__: train step 9194: loss: 1.1237, policy_loss: 1.1950, value_loss: 0.7780
2024-07-14 05:56:50,671 [INFO    ] __main__: train step 9195: loss: 1.1237, policy_loss: 1.1949, value_loss: 0.7780
2024-07-14 05:56:50,976 [INFO    ] __main__: train step 9196: loss: 1.1236, policy_loss: 1.1948, value_loss: 0.7780
2024-07-14 05:56:51,267 [INFO    ] __main__: train step 9197: loss: 1.1236, policy_loss: 1.1948, value_loss: 0.7779
2024-07-14 05:56:51,553 [INFO    ] __main__: train step 9198: loss: 1.1236, policy_loss: 1.1947, value_loss: 0.7779
2024-07-14 05:56:51,848 [INFO    ] __main__: train step 9199: loss: 1.1236, policy_loss: 1.1946, value_loss: 0.7778
2024-07-14 05:56:52,147 [INFO    ] __main__: train step 9200: loss: 1.1236, policy_loss: 1.1946, value_loss: 0.7778
2024-07-14 05:56:52,450 [INFO    ] __main__: train step 9201: loss: 1.1236, policy_loss: 1.1945, value_loss: 0.7778
2024-07-14 05:56:52,750 [INFO    ] __main__: train step 9202: loss: 1.1236, policy_loss: 1.1944, value_loss: 0.7777
2024-07-14 05:56:53,048 [INFO    ] __main__: train step 9203: loss: 1.1236, policy_loss: 1.1944, value_loss: 0.7777
2024-07-14 05:56:53,347 [INFO    ] __main__: train step 9204: loss: 1.1236, policy_loss: 1.1943, value_loss: 0.7776
2024-07-14 05:56:53,645 [INFO    ] __main__: train step 9205: loss: 1.1235, policy_loss: 1.1942, value_loss: 0.7776
2024-07-14 05:56:53,929 [INFO    ] __main__: train step 9206: loss: 1.1235, policy_loss: 1.1942, value_loss: 0.7776
2024-07-14 05:56:54,186 [INFO    ] __main__: train step 9207: loss: 1.1235, policy_loss: 1.1941, value_loss: 0.7775
2024-07-14 05:56:54,460 [INFO    ] __main__: train step 9208: loss: 1.1235, policy_loss: 1.1941, value_loss: 0.7775
2024-07-14 05:56:54,746 [INFO    ] __main__: train step 9209: loss: 1.1235, policy_loss: 1.1940, value_loss: 0.7774
2024-07-14 05:56:55,047 [INFO    ] __main__: train step 9210: loss: 1.1235, policy_loss: 1.1939, value_loss: 0.7774
2024-07-14 05:56:56,647 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:56:57,140 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:56:57,210 [INFO    ] __main__: train step 9211: loss: 1.1235, policy_loss: 1.1939, value_loss: 0.7774
2024-07-14 05:56:57,501 [INFO    ] __main__: train step 9212: loss: 1.1235, policy_loss: 1.1938, value_loss: 0.7773
2024-07-14 05:56:57,807 [INFO    ] __main__: train step 9213: loss: 1.1235, policy_loss: 1.1937, value_loss: 0.7773
2024-07-14 05:56:58,104 [INFO    ] __main__: train step 9214: loss: 1.1234, policy_loss: 1.1937, value_loss: 0.7773
2024-07-14 05:56:58,410 [INFO    ] __main__: train step 9215: loss: 1.1234, policy_loss: 1.1936, value_loss: 0.7772
2024-07-14 05:56:58,700 [INFO    ] __main__: train step 9216: loss: 1.1234, policy_loss: 1.1935, value_loss: 0.7772
2024-07-14 05:56:58,992 [INFO    ] __main__: train step 9217: loss: 1.1234, policy_loss: 1.1935, value_loss: 0.7772
2024-07-14 05:56:59,289 [INFO    ] __main__: train step 9218: loss: 1.1234, policy_loss: 1.1934, value_loss: 0.7771
2024-07-14 05:56:59,584 [INFO    ] __main__: train step 9219: loss: 1.1234, policy_loss: 1.1933, value_loss: 0.7771
2024-07-14 05:56:59,880 [INFO    ] __main__: train step 9220: loss: 1.1234, policy_loss: 1.1933, value_loss: 0.7770
2024-07-14 05:57:00,154 [INFO    ] __main__: train step 9221: loss: 1.1234, policy_loss: 1.1932, value_loss: 0.7770
2024-07-14 05:57:00,449 [INFO    ] __main__: train step 9222: loss: 1.1234, policy_loss: 1.1931, value_loss: 0.7770
2024-07-14 05:57:00,751 [INFO    ] __main__: train step 9223: loss: 1.1234, policy_loss: 1.1931, value_loss: 0.7769
2024-07-14 05:57:01,050 [INFO    ] __main__: train step 9224: loss: 1.1233, policy_loss: 1.1930, value_loss: 0.7769
2024-07-14 05:57:02,973 [INFO    ] __main__: train step 9225: loss: 1.1233, policy_loss: 1.1930, value_loss: 0.7768
2024-07-14 05:57:03,261 [INFO    ] __main__: train step 9226: loss: 1.1233, policy_loss: 1.1929, value_loss: 0.7768
2024-07-14 05:57:03,543 [INFO    ] __main__: train step 9227: loss: 1.1233, policy_loss: 1.1928, value_loss: 0.7768
2024-07-14 05:57:05,156 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:57:05,629 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:57:05,702 [INFO    ] __main__: train step 9228: loss: 1.1233, policy_loss: 1.1928, value_loss: 0.7767
2024-07-14 05:57:06,004 [INFO    ] __main__: train step 9229: loss: 1.1233, policy_loss: 1.1927, value_loss: 0.7767
2024-07-14 05:57:06,292 [INFO    ] __main__: train step 9230: loss: 1.1233, policy_loss: 1.1926, value_loss: 0.7766
2024-07-14 05:57:06,587 [INFO    ] __main__: train step 9231: loss: 1.1233, policy_loss: 1.1926, value_loss: 0.7766
2024-07-14 05:57:06,889 [INFO    ] __main__: train step 9232: loss: 1.1232, policy_loss: 1.1925, value_loss: 0.7766
2024-07-14 05:57:07,184 [INFO    ] __main__: train step 9233: loss: 1.1232, policy_loss: 1.1924, value_loss: 0.7765
2024-07-14 05:57:07,473 [INFO    ] __main__: train step 9234: loss: 1.1232, policy_loss: 1.1924, value_loss: 0.7765
2024-07-14 05:57:07,753 [INFO    ] __main__: train step 9235: loss: 1.1232, policy_loss: 1.1923, value_loss: 0.7765
2024-07-14 05:57:08,048 [INFO    ] __main__: train step 9236: loss: 1.1232, policy_loss: 1.1922, value_loss: 0.7764
2024-07-14 05:57:08,342 [INFO    ] __main__: train step 9237: loss: 1.1232, policy_loss: 1.1922, value_loss: 0.7764
2024-07-14 05:57:08,639 [INFO    ] __main__: train step 9238: loss: 1.1232, policy_loss: 1.1921, value_loss: 0.7763
2024-07-14 05:57:08,939 [INFO    ] __main__: train step 9239: loss: 1.1232, policy_loss: 1.1921, value_loss: 0.7763
2024-07-14 05:57:09,231 [INFO    ] __main__: train step 9240: loss: 1.1232, policy_loss: 1.1920, value_loss: 0.7763
2024-07-14 05:57:09,526 [INFO    ] __main__: train step 9241: loss: 1.1231, policy_loss: 1.1919, value_loss: 0.7762
2024-07-14 05:57:09,816 [INFO    ] __main__: train step 9242: loss: 1.1231, policy_loss: 1.1919, value_loss: 0.7762
2024-07-14 05:57:10,117 [INFO    ] __main__: train step 9243: loss: 1.1231, policy_loss: 1.1918, value_loss: 0.7761
2024-07-14 05:57:10,416 [INFO    ] __main__: train step 9244: loss: 1.1231, policy_loss: 1.1917, value_loss: 0.7761
2024-07-14 05:57:12,031 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:57:12,512 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:57:12,586 [INFO    ] __main__: train step 9245: loss: 1.1231, policy_loss: 1.1917, value_loss: 0.7761
2024-07-14 05:57:12,883 [INFO    ] __main__: train step 9246: loss: 1.1231, policy_loss: 1.1916, value_loss: 0.7760
2024-07-14 05:57:13,212 [INFO    ] __main__: train step 9247: loss: 1.1231, policy_loss: 1.1915, value_loss: 0.7760
2024-07-14 05:57:13,523 [INFO    ] __main__: train step 9248: loss: 1.1231, policy_loss: 1.1915, value_loss: 0.7759
2024-07-14 05:57:13,820 [INFO    ] __main__: train step 9249: loss: 1.1230, policy_loss: 1.1914, value_loss: 0.7759
2024-07-14 05:57:14,097 [INFO    ] __main__: train step 9250: loss: 1.1230, policy_loss: 1.1913, value_loss: 0.7759
2024-07-14 05:57:14,385 [INFO    ] __main__: train step 9251: loss: 1.1230, policy_loss: 1.1913, value_loss: 0.7758
2024-07-14 05:57:14,699 [INFO    ] __main__: train step 9252: loss: 1.1230, policy_loss: 1.1912, value_loss: 0.7758
2024-07-14 05:57:15,004 [INFO    ] __main__: train step 9253: loss: 1.1230, policy_loss: 1.1912, value_loss: 0.7757
2024-07-14 05:57:15,304 [INFO    ] __main__: train step 9254: loss: 1.1230, policy_loss: 1.1911, value_loss: 0.7757
2024-07-14 05:57:15,617 [INFO    ] __main__: train step 9255: loss: 1.1230, policy_loss: 1.1910, value_loss: 0.7757
2024-07-14 05:57:15,911 [INFO    ] __main__: train step 9256: loss: 1.1230, policy_loss: 1.1910, value_loss: 0.7756
2024-07-14 05:57:16,205 [INFO    ] __main__: train step 9257: loss: 1.1229, policy_loss: 1.1909, value_loss: 0.7756
2024-07-14 05:57:16,472 [INFO    ] __main__: train step 9258: loss: 1.1229, policy_loss: 1.1908, value_loss: 0.7755
2024-07-14 05:57:16,748 [INFO    ] __main__: train step 9259: loss: 1.1229, policy_loss: 1.1908, value_loss: 0.7755
2024-07-14 05:57:17,030 [INFO    ] __main__: train step 9260: loss: 1.1229, policy_loss: 1.1907, value_loss: 0.7755
2024-07-14 05:57:17,293 [INFO    ] __main__: train step 9261: loss: 1.1229, policy_loss: 1.1906, value_loss: 0.7754
2024-07-14 05:57:18,933 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:57:19,430 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:57:19,505 [INFO    ] __main__: train step 9262: loss: 1.1229, policy_loss: 1.1906, value_loss: 0.7754
2024-07-14 05:57:19,811 [INFO    ] __main__: train step 9263: loss: 1.1229, policy_loss: 1.1905, value_loss: 0.7753
2024-07-14 05:57:20,101 [INFO    ] __main__: train step 9264: loss: 1.1228, policy_loss: 1.1904, value_loss: 0.7753
2024-07-14 05:57:20,398 [INFO    ] __main__: train step 9265: loss: 1.1228, policy_loss: 1.1904, value_loss: 0.7753
2024-07-14 05:57:20,687 [INFO    ] __main__: train step 9266: loss: 1.1228, policy_loss: 1.1903, value_loss: 0.7752
2024-07-14 05:57:20,971 [INFO    ] __main__: train step 9267: loss: 1.1228, policy_loss: 1.1903, value_loss: 0.7752
2024-07-14 05:57:21,263 [INFO    ] __main__: train step 9268: loss: 1.1228, policy_loss: 1.1902, value_loss: 0.7751
2024-07-14 05:57:21,553 [INFO    ] __main__: train step 9269: loss: 1.1228, policy_loss: 1.1901, value_loss: 0.7751
2024-07-14 05:57:21,846 [INFO    ] __main__: train step 9270: loss: 1.1228, policy_loss: 1.1901, value_loss: 0.7751
2024-07-14 05:57:22,141 [INFO    ] __main__: train step 9271: loss: 1.1227, policy_loss: 1.1900, value_loss: 0.7750
2024-07-14 05:57:22,440 [INFO    ] __main__: train step 9272: loss: 1.1227, policy_loss: 1.1899, value_loss: 0.7750
2024-07-14 05:57:22,742 [INFO    ] __main__: train step 9273: loss: 1.1227, policy_loss: 1.1899, value_loss: 0.7749
2024-07-14 05:57:23,043 [INFO    ] __main__: train step 9274: loss: 1.1227, policy_loss: 1.1898, value_loss: 0.7749
2024-07-14 05:57:23,339 [INFO    ] __main__: train step 9275: loss: 1.1227, policy_loss: 1.1897, value_loss: 0.7749
2024-07-14 05:57:23,638 [INFO    ] __main__: train step 9276: loss: 1.1227, policy_loss: 1.1897, value_loss: 0.7748
2024-07-14 05:57:23,928 [INFO    ] __main__: train step 9277: loss: 1.1227, policy_loss: 1.1896, value_loss: 0.7748
2024-07-14 05:57:24,213 [INFO    ] __main__: train step 9278: loss: 1.1227, policy_loss: 1.1895, value_loss: 0.7747
2024-07-14 05:57:27,241 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:57:27,725 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:57:27,795 [INFO    ] __main__: train step 9279: loss: 1.1226, policy_loss: 1.1895, value_loss: 0.7747
2024-07-14 05:57:28,089 [INFO    ] __main__: train step 9280: loss: 1.1226, policy_loss: 1.1894, value_loss: 0.7747
2024-07-14 05:57:28,381 [INFO    ] __main__: train step 9281: loss: 1.1226, policy_loss: 1.1893, value_loss: 0.7746
2024-07-14 05:57:28,664 [INFO    ] __main__: train step 9282: loss: 1.1226, policy_loss: 1.1893, value_loss: 0.7746
2024-07-14 05:57:28,943 [INFO    ] __main__: train step 9283: loss: 1.1226, policy_loss: 1.1892, value_loss: 0.7745
2024-07-14 05:57:29,225 [INFO    ] __main__: train step 9284: loss: 1.1226, policy_loss: 1.1892, value_loss: 0.7745
2024-07-14 05:57:29,510 [INFO    ] __main__: train step 9285: loss: 1.1225, policy_loss: 1.1891, value_loss: 0.7745
2024-07-14 05:57:29,811 [INFO    ] __main__: train step 9286: loss: 1.1225, policy_loss: 1.1890, value_loss: 0.7744
2024-07-14 05:57:30,110 [INFO    ] __main__: train step 9287: loss: 1.1225, policy_loss: 1.1890, value_loss: 0.7744
2024-07-14 05:57:30,412 [INFO    ] __main__: train step 9288: loss: 1.1225, policy_loss: 1.1889, value_loss: 0.7743
2024-07-14 05:57:30,705 [INFO    ] __main__: train step 9289: loss: 1.1225, policy_loss: 1.1888, value_loss: 0.7743
2024-07-14 05:57:31,009 [INFO    ] __main__: train step 9290: loss: 1.1225, policy_loss: 1.1888, value_loss: 0.7742
2024-07-14 05:57:31,317 [INFO    ] __main__: train step 9291: loss: 1.1225, policy_loss: 1.1887, value_loss: 0.7742
2024-07-14 05:57:31,610 [INFO    ] __main__: train step 9292: loss: 1.1224, policy_loss: 1.1886, value_loss: 0.7742
2024-07-14 05:57:31,896 [INFO    ] __main__: train step 9293: loss: 1.1224, policy_loss: 1.1886, value_loss: 0.7741
2024-07-14 05:57:32,170 [INFO    ] __main__: train step 9294: loss: 1.1224, policy_loss: 1.1885, value_loss: 0.7741
2024-07-14 05:57:32,464 [INFO    ] __main__: train step 9295: loss: 1.1224, policy_loss: 1.1884, value_loss: 0.7741
2024-07-14 05:57:34,104 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:57:34,589 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:57:34,658 [INFO    ] __main__: train step 9296: loss: 1.1224, policy_loss: 1.1884, value_loss: 0.7740
2024-07-14 05:57:34,955 [INFO    ] __main__: train step 9297: loss: 1.1224, policy_loss: 1.1883, value_loss: 0.7740
2024-07-14 05:57:35,271 [INFO    ] __main__: train step 9298: loss: 1.1224, policy_loss: 1.1883, value_loss: 0.7739
2024-07-14 05:57:35,562 [INFO    ] __main__: train step 9299: loss: 1.1224, policy_loss: 1.1882, value_loss: 0.7739
2024-07-14 05:57:35,882 [INFO    ] __main__: train step 9300: loss: 1.1223, policy_loss: 1.1881, value_loss: 0.7738
2024-07-14 05:57:36,176 [INFO    ] __main__: train step 9301: loss: 1.1223, policy_loss: 1.1881, value_loss: 0.7738
2024-07-14 05:57:36,484 [INFO    ] __main__: train step 9302: loss: 1.1223, policy_loss: 1.1880, value_loss: 0.7738
2024-07-14 05:57:36,783 [INFO    ] __main__: train step 9303: loss: 1.1223, policy_loss: 1.1879, value_loss: 0.7737
2024-07-14 05:57:37,073 [INFO    ] __main__: train step 9304: loss: 1.1223, policy_loss: 1.1879, value_loss: 0.7737
2024-07-14 05:57:37,376 [INFO    ] __main__: train step 9305: loss: 1.1223, policy_loss: 1.1878, value_loss: 0.7736
2024-07-14 05:57:37,673 [INFO    ] __main__: train step 9306: loss: 1.1223, policy_loss: 1.1877, value_loss: 0.7736
2024-07-14 05:57:37,972 [INFO    ] __main__: train step 9307: loss: 1.1222, policy_loss: 1.1877, value_loss: 0.7736
2024-07-14 05:57:38,263 [INFO    ] __main__: train step 9308: loss: 1.1222, policy_loss: 1.1876, value_loss: 0.7735
2024-07-14 05:57:38,550 [INFO    ] __main__: train step 9309: loss: 1.1222, policy_loss: 1.1876, value_loss: 0.7735
2024-07-14 05:57:38,839 [INFO    ] __main__: train step 9310: loss: 1.1222, policy_loss: 1.1875, value_loss: 0.7734
2024-07-14 05:57:39,127 [INFO    ] __main__: train step 9311: loss: 1.1222, policy_loss: 1.1874, value_loss: 0.7734
2024-07-14 05:57:39,419 [INFO    ] __main__: train step 9312: loss: 1.1222, policy_loss: 1.1874, value_loss: 0.7734
2024-07-14 05:57:41,037 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:57:41,528 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:57:41,604 [INFO    ] __main__: train step 9313: loss: 1.1222, policy_loss: 1.1873, value_loss: 0.7733
2024-07-14 05:57:41,908 [INFO    ] __main__: train step 9314: loss: 1.1221, policy_loss: 1.1872, value_loss: 0.7733
2024-07-14 05:57:42,204 [INFO    ] __main__: train step 9315: loss: 1.1221, policy_loss: 1.1872, value_loss: 0.7732
2024-07-14 05:57:42,498 [INFO    ] __main__: train step 9316: loss: 1.1221, policy_loss: 1.1871, value_loss: 0.7732
2024-07-14 05:57:42,802 [INFO    ] __main__: train step 9317: loss: 1.1221, policy_loss: 1.1871, value_loss: 0.7732
2024-07-14 05:57:43,109 [INFO    ] __main__: train step 9318: loss: 1.1221, policy_loss: 1.1870, value_loss: 0.7731
2024-07-14 05:57:43,415 [INFO    ] __main__: train step 9319: loss: 1.1221, policy_loss: 1.1869, value_loss: 0.7731
2024-07-14 05:57:43,728 [INFO    ] __main__: train step 9320: loss: 1.1221, policy_loss: 1.1869, value_loss: 0.7730
2024-07-14 05:57:44,025 [INFO    ] __main__: train step 9321: loss: 1.1220, policy_loss: 1.1868, value_loss: 0.7730
2024-07-14 05:57:44,316 [INFO    ] __main__: train step 9322: loss: 1.1220, policy_loss: 1.1867, value_loss: 0.7730
2024-07-14 05:57:44,614 [INFO    ] __main__: train step 9323: loss: 1.1220, policy_loss: 1.1867, value_loss: 0.7729
2024-07-14 05:57:44,907 [INFO    ] __main__: train step 9324: loss: 1.1220, policy_loss: 1.1866, value_loss: 0.7729
2024-07-14 05:57:45,218 [INFO    ] __main__: train step 9325: loss: 1.1220, policy_loss: 1.1865, value_loss: 0.7728
2024-07-14 05:57:45,515 [INFO    ] __main__: train step 9326: loss: 1.1220, policy_loss: 1.1865, value_loss: 0.7728
2024-07-14 05:57:45,815 [INFO    ] __main__: train step 9327: loss: 1.1220, policy_loss: 1.1864, value_loss: 0.7728
2024-07-14 05:57:46,113 [INFO    ] __main__: train step 9328: loss: 1.1219, policy_loss: 1.1863, value_loss: 0.7727
2024-07-14 05:57:46,410 [INFO    ] __main__: train step 9329: loss: 1.1219, policy_loss: 1.1863, value_loss: 0.7727
2024-07-14 05:57:48,030 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:57:48,522 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:57:48,594 [INFO    ] __main__: train step 9330: loss: 1.1219, policy_loss: 1.1862, value_loss: 0.7726
2024-07-14 05:57:48,889 [INFO    ] __main__: train step 9331: loss: 1.1219, policy_loss: 1.1861, value_loss: 0.7726
2024-07-14 05:57:49,194 [INFO    ] __main__: train step 9332: loss: 1.1219, policy_loss: 1.1861, value_loss: 0.7725
2024-07-14 05:57:49,491 [INFO    ] __main__: train step 9333: loss: 1.1219, policy_loss: 1.1860, value_loss: 0.7725
2024-07-14 05:57:51,406 [INFO    ] __main__: train step 9334: loss: 1.1218, policy_loss: 1.1860, value_loss: 0.7725
2024-07-14 05:57:51,699 [INFO    ] __main__: train step 9335: loss: 1.1218, policy_loss: 1.1859, value_loss: 0.7724
2024-07-14 05:57:52,017 [INFO    ] __main__: train step 9336: loss: 1.1218, policy_loss: 1.1858, value_loss: 0.7724
2024-07-14 05:57:52,315 [INFO    ] __main__: train step 9337: loss: 1.1218, policy_loss: 1.1858, value_loss: 0.7723
2024-07-14 05:57:52,607 [INFO    ] __main__: train step 9338: loss: 1.1218, policy_loss: 1.1857, value_loss: 0.7723
2024-07-14 05:57:52,912 [INFO    ] __main__: train step 9339: loss: 1.1218, policy_loss: 1.1856, value_loss: 0.7723
2024-07-14 05:57:53,206 [INFO    ] __main__: train step 9340: loss: 1.1217, policy_loss: 1.1856, value_loss: 0.7722
2024-07-14 05:57:53,496 [INFO    ] __main__: train step 9341: loss: 1.1217, policy_loss: 1.1855, value_loss: 0.7722
2024-07-14 05:57:53,792 [INFO    ] __main__: train step 9342: loss: 1.1217, policy_loss: 1.1855, value_loss: 0.7721
2024-07-14 05:57:54,090 [INFO    ] __main__: train step 9343: loss: 1.1217, policy_loss: 1.1854, value_loss: 0.7721
2024-07-14 05:57:54,392 [INFO    ] __main__: train step 9344: loss: 1.1217, policy_loss: 1.1853, value_loss: 0.7721
2024-07-14 05:57:54,678 [INFO    ] __main__: train step 9345: loss: 1.1217, policy_loss: 1.1853, value_loss: 0.7720
2024-07-14 05:57:54,968 [INFO    ] __main__: train step 9346: loss: 1.1217, policy_loss: 1.1852, value_loss: 0.7720
2024-07-14 05:57:56,593 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:57:57,095 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:57:57,164 [INFO    ] __main__: train step 9347: loss: 1.1216, policy_loss: 1.1851, value_loss: 0.7719
2024-07-14 05:57:57,464 [INFO    ] __main__: train step 9348: loss: 1.1216, policy_loss: 1.1851, value_loss: 0.7719
2024-07-14 05:57:57,769 [INFO    ] __main__: train step 9349: loss: 1.1216, policy_loss: 1.1850, value_loss: 0.7718
2024-07-14 05:57:58,063 [INFO    ] __main__: train step 9350: loss: 1.1216, policy_loss: 1.1850, value_loss: 0.7718
2024-07-14 05:57:58,352 [INFO    ] __main__: train step 9351: loss: 1.1216, policy_loss: 1.1849, value_loss: 0.7718
2024-07-14 05:57:58,654 [INFO    ] __main__: train step 9352: loss: 1.1216, policy_loss: 1.1848, value_loss: 0.7717
2024-07-14 05:57:58,945 [INFO    ] __main__: train step 9353: loss: 1.1216, policy_loss: 1.1848, value_loss: 0.7717
2024-07-14 05:57:59,238 [INFO    ] __main__: train step 9354: loss: 1.1215, policy_loss: 1.1847, value_loss: 0.7716
2024-07-14 05:57:59,529 [INFO    ] __main__: train step 9355: loss: 1.1215, policy_loss: 1.1846, value_loss: 0.7716
2024-07-14 05:57:59,829 [INFO    ] __main__: train step 9356: loss: 1.1215, policy_loss: 1.1846, value_loss: 0.7715
2024-07-14 05:58:00,127 [INFO    ] __main__: train step 9357: loss: 1.1215, policy_loss: 1.1845, value_loss: 0.7715
2024-07-14 05:58:00,416 [INFO    ] __main__: train step 9358: loss: 1.1215, policy_loss: 1.1844, value_loss: 0.7715
2024-07-14 05:58:00,705 [INFO    ] __main__: train step 9359: loss: 1.1215, policy_loss: 1.1844, value_loss: 0.7714
2024-07-14 05:58:00,993 [INFO    ] __main__: train step 9360: loss: 1.1214, policy_loss: 1.1843, value_loss: 0.7714
2024-07-14 05:58:01,290 [INFO    ] __main__: train step 9361: loss: 1.1214, policy_loss: 1.1843, value_loss: 0.7713
2024-07-14 05:58:01,580 [INFO    ] __main__: train step 9362: loss: 1.1214, policy_loss: 1.1842, value_loss: 0.7713
2024-07-14 05:58:01,880 [INFO    ] __main__: train step 9363: loss: 1.1214, policy_loss: 1.1841, value_loss: 0.7713
2024-07-14 05:58:03,489 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:58:03,987 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:58:04,062 [INFO    ] __main__: train step 9364: loss: 1.1214, policy_loss: 1.1841, value_loss: 0.7712
2024-07-14 05:58:04,365 [INFO    ] __main__: train step 9365: loss: 1.1214, policy_loss: 1.1840, value_loss: 0.7712
2024-07-14 05:58:04,652 [INFO    ] __main__: train step 9366: loss: 1.1213, policy_loss: 1.1839, value_loss: 0.7711
2024-07-14 05:58:04,953 [INFO    ] __main__: train step 9367: loss: 1.1213, policy_loss: 1.1839, value_loss: 0.7711
2024-07-14 05:58:05,247 [INFO    ] __main__: train step 9368: loss: 1.1213, policy_loss: 1.1838, value_loss: 0.7710
2024-07-14 05:58:05,544 [INFO    ] __main__: train step 9369: loss: 1.1213, policy_loss: 1.1837, value_loss: 0.7710
2024-07-14 05:58:05,843 [INFO    ] __main__: train step 9370: loss: 1.1213, policy_loss: 1.1837, value_loss: 0.7710
2024-07-14 05:58:06,137 [INFO    ] __main__: train step 9371: loss: 1.1213, policy_loss: 1.1836, value_loss: 0.7709
2024-07-14 05:58:06,417 [INFO    ] __main__: train step 9372: loss: 1.1212, policy_loss: 1.1836, value_loss: 0.7709
2024-07-14 05:58:06,694 [INFO    ] __main__: train step 9373: loss: 1.1212, policy_loss: 1.1835, value_loss: 0.7708
2024-07-14 05:58:06,961 [INFO    ] __main__: train step 9374: loss: 1.1212, policy_loss: 1.1834, value_loss: 0.7708
2024-07-14 05:58:07,258 [INFO    ] __main__: train step 9375: loss: 1.1212, policy_loss: 1.1834, value_loss: 0.7707
2024-07-14 05:58:07,550 [INFO    ] __main__: train step 9376: loss: 1.1212, policy_loss: 1.1833, value_loss: 0.7707
2024-07-14 05:58:07,857 [INFO    ] __main__: train step 9377: loss: 1.1211, policy_loss: 1.1832, value_loss: 0.7707
2024-07-14 05:58:08,172 [INFO    ] __main__: train step 9378: loss: 1.1211, policy_loss: 1.1832, value_loss: 0.7706
2024-07-14 05:58:08,460 [INFO    ] __main__: train step 9379: loss: 1.1211, policy_loss: 1.1831, value_loss: 0.7706
2024-07-14 05:58:08,756 [INFO    ] __main__: train step 9380: loss: 1.1211, policy_loss: 1.1830, value_loss: 0.7705
2024-07-14 05:58:10,381 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:58:10,881 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:58:10,951 [INFO    ] __main__: train step 9381: loss: 1.1211, policy_loss: 1.1830, value_loss: 0.7705
2024-07-14 05:58:11,237 [INFO    ] __main__: train step 9382: loss: 1.1211, policy_loss: 1.1829, value_loss: 0.7705
2024-07-14 05:58:11,513 [INFO    ] __main__: train step 9383: loss: 1.1211, policy_loss: 1.1829, value_loss: 0.7704
2024-07-14 05:58:11,804 [INFO    ] __main__: train step 9384: loss: 1.1210, policy_loss: 1.1828, value_loss: 0.7704
2024-07-14 05:58:12,095 [INFO    ] __main__: train step 9385: loss: 1.1210, policy_loss: 1.1827, value_loss: 0.7703
2024-07-14 05:58:12,366 [INFO    ] __main__: train step 9386: loss: 1.1210, policy_loss: 1.1827, value_loss: 0.7703
2024-07-14 05:58:12,633 [INFO    ] __main__: train step 9387: loss: 1.1210, policy_loss: 1.1826, value_loss: 0.7702
2024-07-14 05:58:12,928 [INFO    ] __main__: train step 9388: loss: 1.1210, policy_loss: 1.1825, value_loss: 0.7702
2024-07-14 05:58:13,226 [INFO    ] __main__: train step 9389: loss: 1.1209, policy_loss: 1.1825, value_loss: 0.7702
2024-07-14 05:58:14,860 [INFO    ] __main__: train step 9390: loss: 1.1209, policy_loss: 1.1824, value_loss: 0.7701
2024-07-14 05:58:15,169 [INFO    ] __main__: train step 9391: loss: 1.1209, policy_loss: 1.1823, value_loss: 0.7701
2024-07-14 05:58:15,448 [INFO    ] __main__: train step 9392: loss: 1.1209, policy_loss: 1.1823, value_loss: 0.7700
2024-07-14 05:58:15,728 [INFO    ] __main__: train step 9393: loss: 1.1209, policy_loss: 1.1822, value_loss: 0.7700
2024-07-14 05:58:16,001 [INFO    ] __main__: train step 9394: loss: 1.1209, policy_loss: 1.1822, value_loss: 0.7699
2024-07-14 05:58:16,316 [INFO    ] __main__: train step 9395: loss: 1.1209, policy_loss: 1.1821, value_loss: 0.7699
2024-07-14 05:58:16,627 [INFO    ] __main__: train step 9396: loss: 1.1208, policy_loss: 1.1820, value_loss: 0.7699
2024-07-14 05:58:16,936 [INFO    ] __main__: train step 9397: loss: 1.1208, policy_loss: 1.1820, value_loss: 0.7698
2024-07-14 05:58:18,564 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:58:19,049 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:58:19,125 [INFO    ] __main__: train step 9398: loss: 1.1208, policy_loss: 1.1819, value_loss: 0.7698
2024-07-14 05:58:19,424 [INFO    ] __main__: train step 9399: loss: 1.1208, policy_loss: 1.1818, value_loss: 0.7697
2024-07-14 05:58:19,713 [INFO    ] __main__: train step 9400: loss: 1.1208, policy_loss: 1.1818, value_loss: 0.7697
2024-07-14 05:58:20,014 [INFO    ] __main__: train step 9401: loss: 1.1208, policy_loss: 1.1817, value_loss: 0.7697
2024-07-14 05:58:20,313 [INFO    ] __main__: train step 9402: loss: 1.1207, policy_loss: 1.1817, value_loss: 0.7696
2024-07-14 05:58:20,622 [INFO    ] __main__: train step 9403: loss: 1.1207, policy_loss: 1.1816, value_loss: 0.7696
2024-07-14 05:58:20,924 [INFO    ] __main__: train step 9404: loss: 1.1207, policy_loss: 1.1815, value_loss: 0.7695
2024-07-14 05:58:21,212 [INFO    ] __main__: train step 9405: loss: 1.1207, policy_loss: 1.1815, value_loss: 0.7695
2024-07-14 05:58:21,503 [INFO    ] __main__: train step 9406: loss: 1.1207, policy_loss: 1.1814, value_loss: 0.7694
2024-07-14 05:58:21,805 [INFO    ] __main__: train step 9407: loss: 1.1206, policy_loss: 1.1813, value_loss: 0.7694
2024-07-14 05:58:22,120 [INFO    ] __main__: train step 9408: loss: 1.1206, policy_loss: 1.1813, value_loss: 0.7694
2024-07-14 05:58:22,435 [INFO    ] __main__: train step 9409: loss: 1.1206, policy_loss: 1.1812, value_loss: 0.7693
2024-07-14 05:58:22,747 [INFO    ] __main__: train step 9410: loss: 1.1206, policy_loss: 1.1812, value_loss: 0.7693
2024-07-14 05:58:23,048 [INFO    ] __main__: train step 9411: loss: 1.1206, policy_loss: 1.1811, value_loss: 0.7692
2024-07-14 05:58:23,339 [INFO    ] __main__: train step 9412: loss: 1.1206, policy_loss: 1.1810, value_loss: 0.7692
2024-07-14 05:58:23,644 [INFO    ] __main__: train step 9413: loss: 1.1205, policy_loss: 1.1810, value_loss: 0.7691
2024-07-14 05:58:23,944 [INFO    ] __main__: train step 9414: loss: 1.1205, policy_loss: 1.1809, value_loss: 0.7691
2024-07-14 05:58:25,569 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:58:26,072 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:58:26,143 [INFO    ] __main__: train step 9415: loss: 1.1205, policy_loss: 1.1808, value_loss: 0.7690
2024-07-14 05:58:26,439 [INFO    ] __main__: train step 9416: loss: 1.1205, policy_loss: 1.1808, value_loss: 0.7690
2024-07-14 05:58:26,712 [INFO    ] __main__: train step 9417: loss: 1.1205, policy_loss: 1.1807, value_loss: 0.7690
2024-07-14 05:58:26,986 [INFO    ] __main__: train step 9418: loss: 1.1204, policy_loss: 1.1806, value_loss: 0.7689
2024-07-14 05:58:27,289 [INFO    ] __main__: train step 9419: loss: 1.1204, policy_loss: 1.1806, value_loss: 0.7689
2024-07-14 05:58:27,613 [INFO    ] __main__: train step 9420: loss: 1.1204, policy_loss: 1.1805, value_loss: 0.7688
2024-07-14 05:58:27,906 [INFO    ] __main__: train step 9421: loss: 1.1204, policy_loss: 1.1805, value_loss: 0.7688
2024-07-14 05:58:28,225 [INFO    ] __main__: train step 9422: loss: 1.1204, policy_loss: 1.1804, value_loss: 0.7687
2024-07-14 05:58:28,523 [INFO    ] __main__: train step 9423: loss: 1.1203, policy_loss: 1.1803, value_loss: 0.7687
2024-07-14 05:58:28,821 [INFO    ] __main__: train step 9424: loss: 1.1203, policy_loss: 1.1803, value_loss: 0.7686
2024-07-14 05:58:29,111 [INFO    ] __main__: train step 9425: loss: 1.1203, policy_loss: 1.1802, value_loss: 0.7686
2024-07-14 05:58:29,396 [INFO    ] __main__: train step 9426: loss: 1.1203, policy_loss: 1.1801, value_loss: 0.7686
2024-07-14 05:58:29,696 [INFO    ] __main__: train step 9427: loss: 1.1203, policy_loss: 1.1801, value_loss: 0.7685
2024-07-14 05:58:29,984 [INFO    ] __main__: train step 9428: loss: 1.1203, policy_loss: 1.1800, value_loss: 0.7685
2024-07-14 05:58:30,294 [INFO    ] __main__: train step 9429: loss: 1.1202, policy_loss: 1.1800, value_loss: 0.7684
2024-07-14 05:58:30,592 [INFO    ] __main__: train step 9430: loss: 1.1202, policy_loss: 1.1799, value_loss: 0.7684
2024-07-14 05:58:30,891 [INFO    ] __main__: train step 9431: loss: 1.1202, policy_loss: 1.1798, value_loss: 0.7683
2024-07-14 05:58:32,519 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:58:33,008 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:58:33,082 [INFO    ] __main__: train step 9432: loss: 1.1202, policy_loss: 1.1798, value_loss: 0.7683
2024-07-14 05:58:33,379 [INFO    ] __main__: train step 9433: loss: 1.1202, policy_loss: 1.1797, value_loss: 0.7683
2024-07-14 05:58:33,668 [INFO    ] __main__: train step 9434: loss: 1.1201, policy_loss: 1.1796, value_loss: 0.7682
2024-07-14 05:58:33,956 [INFO    ] __main__: train step 9435: loss: 1.1201, policy_loss: 1.1796, value_loss: 0.7682
2024-07-14 05:58:34,262 [INFO    ] __main__: train step 9436: loss: 1.1201, policy_loss: 1.1795, value_loss: 0.7681
2024-07-14 05:58:34,555 [INFO    ] __main__: train step 9437: loss: 1.1201, policy_loss: 1.1795, value_loss: 0.7681
2024-07-14 05:58:34,853 [INFO    ] __main__: train step 9438: loss: 1.1201, policy_loss: 1.1794, value_loss: 0.7680
2024-07-14 05:58:35,158 [INFO    ] __main__: train step 9439: loss: 1.1201, policy_loss: 1.1793, value_loss: 0.7680
2024-07-14 05:58:35,450 [INFO    ] __main__: train step 9440: loss: 1.1200, policy_loss: 1.1793, value_loss: 0.7680
2024-07-14 05:58:35,746 [INFO    ] __main__: train step 9441: loss: 1.1200, policy_loss: 1.1792, value_loss: 0.7679
2024-07-14 05:58:36,044 [INFO    ] __main__: train step 9442: loss: 1.1200, policy_loss: 1.1791, value_loss: 0.7679
2024-07-14 05:58:36,321 [INFO    ] __main__: train step 9443: loss: 1.1200, policy_loss: 1.1791, value_loss: 0.7678
2024-07-14 05:58:38,147 [INFO    ] __main__: train step 9444: loss: 1.1200, policy_loss: 1.1790, value_loss: 0.7678
2024-07-14 05:58:38,446 [INFO    ] __main__: train step 9445: loss: 1.1199, policy_loss: 1.1790, value_loss: 0.7677
2024-07-14 05:58:38,739 [INFO    ] __main__: train step 9446: loss: 1.1199, policy_loss: 1.1789, value_loss: 0.7677
2024-07-14 05:58:39,034 [INFO    ] __main__: train step 9447: loss: 1.1199, policy_loss: 1.1788, value_loss: 0.7676
2024-07-14 05:58:39,321 [INFO    ] __main__: train step 9448: loss: 1.1199, policy_loss: 1.1788, value_loss: 0.7676
2024-07-14 05:58:40,947 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:58:41,448 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:58:41,522 [INFO    ] __main__: train step 9449: loss: 1.1199, policy_loss: 1.1787, value_loss: 0.7676
2024-07-14 05:58:41,814 [INFO    ] __main__: train step 9450: loss: 1.1198, policy_loss: 1.1786, value_loss: 0.7675
2024-07-14 05:58:42,097 [INFO    ] __main__: train step 9451: loss: 1.1198, policy_loss: 1.1786, value_loss: 0.7675
2024-07-14 05:58:42,388 [INFO    ] __main__: train step 9452: loss: 1.1198, policy_loss: 1.1785, value_loss: 0.7674
2024-07-14 05:58:42,680 [INFO    ] __main__: train step 9453: loss: 1.1198, policy_loss: 1.1785, value_loss: 0.7674
2024-07-14 05:58:42,973 [INFO    ] __main__: train step 9454: loss: 1.1198, policy_loss: 1.1784, value_loss: 0.7673
2024-07-14 05:58:43,286 [INFO    ] __main__: train step 9455: loss: 1.1197, policy_loss: 1.1783, value_loss: 0.7673
2024-07-14 05:58:43,586 [INFO    ] __main__: train step 9456: loss: 1.1197, policy_loss: 1.1783, value_loss: 0.7672
2024-07-14 05:58:43,877 [INFO    ] __main__: train step 9457: loss: 1.1197, policy_loss: 1.1782, value_loss: 0.7672
2024-07-14 05:58:44,172 [INFO    ] __main__: train step 9458: loss: 1.1197, policy_loss: 1.1782, value_loss: 0.7672
2024-07-14 05:58:44,464 [INFO    ] __main__: train step 9459: loss: 1.1197, policy_loss: 1.1781, value_loss: 0.7671
2024-07-14 05:58:44,749 [INFO    ] __main__: train step 9460: loss: 1.1197, policy_loss: 1.1780, value_loss: 0.7671
2024-07-14 05:58:45,049 [INFO    ] __main__: train step 9461: loss: 1.1196, policy_loss: 1.1780, value_loss: 0.7670
2024-07-14 05:58:45,342 [INFO    ] __main__: train step 9462: loss: 1.1196, policy_loss: 1.1779, value_loss: 0.7670
2024-07-14 05:58:45,637 [INFO    ] __main__: train step 9463: loss: 1.1196, policy_loss: 1.1778, value_loss: 0.7669
2024-07-14 05:58:45,945 [INFO    ] __main__: train step 9464: loss: 1.1196, policy_loss: 1.1778, value_loss: 0.7669
2024-07-14 05:58:46,241 [INFO    ] __main__: train step 9465: loss: 1.1196, policy_loss: 1.1777, value_loss: 0.7669
2024-07-14 05:58:47,863 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:58:48,354 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:58:48,425 [INFO    ] __main__: train step 9466: loss: 1.1196, policy_loss: 1.1777, value_loss: 0.7668
2024-07-14 05:58:48,709 [INFO    ] __main__: train step 9467: loss: 1.1195, policy_loss: 1.1776, value_loss: 0.7668
2024-07-14 05:58:49,011 [INFO    ] __main__: train step 9468: loss: 1.1195, policy_loss: 1.1775, value_loss: 0.7667
2024-07-14 05:58:49,318 [INFO    ] __main__: train step 9469: loss: 1.1195, policy_loss: 1.1775, value_loss: 0.7667
2024-07-14 05:58:49,618 [INFO    ] __main__: train step 9470: loss: 1.1195, policy_loss: 1.1774, value_loss: 0.7666
2024-07-14 05:58:49,958 [INFO    ] __main__: train step 9471: loss: 1.1195, policy_loss: 1.1774, value_loss: 0.7666
2024-07-14 05:58:50,259 [INFO    ] __main__: train step 9472: loss: 1.1194, policy_loss: 1.1773, value_loss: 0.7665
2024-07-14 05:58:50,551 [INFO    ] __main__: train step 9473: loss: 1.1194, policy_loss: 1.1772, value_loss: 0.7665
2024-07-14 05:58:50,840 [INFO    ] __main__: train step 9474: loss: 1.1194, policy_loss: 1.1772, value_loss: 0.7665
2024-07-14 05:58:51,132 [INFO    ] __main__: train step 9475: loss: 1.1194, policy_loss: 1.1771, value_loss: 0.7664
2024-07-14 05:58:51,429 [INFO    ] __main__: train step 9476: loss: 1.1194, policy_loss: 1.1771, value_loss: 0.7664
2024-07-14 05:58:51,724 [INFO    ] __main__: train step 9477: loss: 1.1194, policy_loss: 1.1770, value_loss: 0.7663
2024-07-14 05:58:52,026 [INFO    ] __main__: train step 9478: loss: 1.1193, policy_loss: 1.1769, value_loss: 0.7663
2024-07-14 05:58:52,319 [INFO    ] __main__: train step 9479: loss: 1.1193, policy_loss: 1.1769, value_loss: 0.7662
2024-07-14 05:58:52,616 [INFO    ] __main__: train step 9480: loss: 1.1193, policy_loss: 1.1768, value_loss: 0.7662
2024-07-14 05:58:52,908 [INFO    ] __main__: train step 9481: loss: 1.1193, policy_loss: 1.1767, value_loss: 0.7661
2024-07-14 05:58:53,204 [INFO    ] __main__: train step 9482: loss: 1.1193, policy_loss: 1.1767, value_loss: 0.7661
2024-07-14 05:58:54,798 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:58:55,275 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:58:55,349 [INFO    ] __main__: train step 9483: loss: 1.1192, policy_loss: 1.1766, value_loss: 0.7661
2024-07-14 05:58:55,635 [INFO    ] __main__: train step 9484: loss: 1.1192, policy_loss: 1.1766, value_loss: 0.7660
2024-07-14 05:58:55,931 [INFO    ] __main__: train step 9485: loss: 1.1192, policy_loss: 1.1765, value_loss: 0.7660
2024-07-14 05:58:56,231 [INFO    ] __main__: train step 9486: loss: 1.1192, policy_loss: 1.1764, value_loss: 0.7659
2024-07-14 05:58:56,528 [INFO    ] __main__: train step 9487: loss: 1.1192, policy_loss: 1.1764, value_loss: 0.7659
2024-07-14 05:58:56,813 [INFO    ] __main__: train step 9488: loss: 1.1191, policy_loss: 1.1763, value_loss: 0.7658
2024-07-14 05:58:57,097 [INFO    ] __main__: train step 9489: loss: 1.1191, policy_loss: 1.1763, value_loss: 0.7658
2024-07-14 05:58:57,391 [INFO    ] __main__: train step 9490: loss: 1.1191, policy_loss: 1.1762, value_loss: 0.7657
2024-07-14 05:58:57,688 [INFO    ] __main__: train step 9491: loss: 1.1191, policy_loss: 1.1761, value_loss: 0.7657
2024-07-14 05:58:57,991 [INFO    ] __main__: train step 9492: loss: 1.1191, policy_loss: 1.1761, value_loss: 0.7657
2024-07-14 05:58:58,286 [INFO    ] __main__: train step 9493: loss: 1.1191, policy_loss: 1.1760, value_loss: 0.7656
2024-07-14 05:58:58,584 [INFO    ] __main__: train step 9494: loss: 1.1190, policy_loss: 1.1760, value_loss: 0.7656
2024-07-14 05:58:58,886 [INFO    ] __main__: train step 9495: loss: 1.1190, policy_loss: 1.1759, value_loss: 0.7655
2024-07-14 05:58:59,187 [INFO    ] __main__: train step 9496: loss: 1.1190, policy_loss: 1.1758, value_loss: 0.7655
2024-07-14 05:58:59,499 [INFO    ] __main__: train step 9497: loss: 1.1190, policy_loss: 1.1758, value_loss: 0.7654
2024-07-14 05:58:59,794 [INFO    ] __main__: train step 9498: loss: 1.1190, policy_loss: 1.1757, value_loss: 0.7654
2024-07-14 05:59:01,015 [INFO    ] __main__: train step 9499: loss: 1.1189, policy_loss: 1.1756, value_loss: 0.7653
2024-07-14 05:59:02,637 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:59:03,139 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:59:03,207 [INFO    ] __main__: train step 9500: loss: 1.1189, policy_loss: 1.1756, value_loss: 0.7653
2024-07-14 05:59:03,500 [INFO    ] __main__: train step 9501: loss: 1.1189, policy_loss: 1.1755, value_loss: 0.7653
2024-07-14 05:59:03,788 [INFO    ] __main__: train step 9502: loss: 1.1189, policy_loss: 1.1755, value_loss: 0.7652
2024-07-14 05:59:04,092 [INFO    ] __main__: train step 9503: loss: 1.1189, policy_loss: 1.1754, value_loss: 0.7652
2024-07-14 05:59:04,384 [INFO    ] __main__: train step 9504: loss: 1.1188, policy_loss: 1.1753, value_loss: 0.7651
2024-07-14 05:59:04,679 [INFO    ] __main__: train step 9505: loss: 1.1188, policy_loss: 1.1753, value_loss: 0.7651
2024-07-14 05:59:04,979 [INFO    ] __main__: train step 9506: loss: 1.1188, policy_loss: 1.1752, value_loss: 0.7650
2024-07-14 05:59:05,279 [INFO    ] __main__: train step 9507: loss: 1.1188, policy_loss: 1.1752, value_loss: 0.7650
2024-07-14 05:59:05,576 [INFO    ] __main__: train step 9508: loss: 1.1188, policy_loss: 1.1751, value_loss: 0.7649
2024-07-14 05:59:05,875 [INFO    ] __main__: train step 9509: loss: 1.1187, policy_loss: 1.1750, value_loss: 0.7649
2024-07-14 05:59:06,173 [INFO    ] __main__: train step 9510: loss: 1.1187, policy_loss: 1.1750, value_loss: 0.7648
2024-07-14 05:59:06,473 [INFO    ] __main__: train step 9511: loss: 1.1187, policy_loss: 1.1749, value_loss: 0.7648
2024-07-14 05:59:06,784 [INFO    ] __main__: train step 9512: loss: 1.1187, policy_loss: 1.1749, value_loss: 0.7648
2024-07-14 05:59:07,082 [INFO    ] __main__: train step 9513: loss: 1.1187, policy_loss: 1.1748, value_loss: 0.7647
2024-07-14 05:59:07,375 [INFO    ] __main__: train step 9514: loss: 1.1187, policy_loss: 1.1747, value_loss: 0.7647
2024-07-14 05:59:07,666 [INFO    ] __main__: train step 9515: loss: 1.1186, policy_loss: 1.1747, value_loss: 0.7646
2024-07-14 05:59:07,958 [INFO    ] __main__: train step 9516: loss: 1.1186, policy_loss: 1.1746, value_loss: 0.7646
2024-07-14 05:59:09,579 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:59:10,071 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:59:10,144 [INFO    ] __main__: train step 9517: loss: 1.1186, policy_loss: 1.1746, value_loss: 0.7645
2024-07-14 05:59:10,433 [INFO    ] __main__: train step 9518: loss: 1.1186, policy_loss: 1.1745, value_loss: 0.7645
2024-07-14 05:59:10,725 [INFO    ] __main__: train step 9519: loss: 1.1186, policy_loss: 1.1744, value_loss: 0.7644
2024-07-14 05:59:11,020 [INFO    ] __main__: train step 9520: loss: 1.1185, policy_loss: 1.1744, value_loss: 0.7644
2024-07-14 05:59:11,309 [INFO    ] __main__: train step 9521: loss: 1.1185, policy_loss: 1.1743, value_loss: 0.7644
2024-07-14 05:59:11,611 [INFO    ] __main__: train step 9522: loss: 1.1185, policy_loss: 1.1742, value_loss: 0.7643
2024-07-14 05:59:11,916 [INFO    ] __main__: train step 9523: loss: 1.1185, policy_loss: 1.1742, value_loss: 0.7643
2024-07-14 05:59:12,207 [INFO    ] __main__: train step 9524: loss: 1.1185, policy_loss: 1.1741, value_loss: 0.7642
2024-07-14 05:59:12,496 [INFO    ] __main__: train step 9525: loss: 1.1184, policy_loss: 1.1741, value_loss: 0.7642
2024-07-14 05:59:12,790 [INFO    ] __main__: train step 9526: loss: 1.1184, policy_loss: 1.1740, value_loss: 0.7641
2024-07-14 05:59:13,118 [INFO    ] __main__: train step 9527: loss: 1.1184, policy_loss: 1.1739, value_loss: 0.7641
2024-07-14 05:59:13,412 [INFO    ] __main__: train step 9528: loss: 1.1184, policy_loss: 1.1739, value_loss: 0.7640
2024-07-14 05:59:13,704 [INFO    ] __main__: train step 9529: loss: 1.1184, policy_loss: 1.1738, value_loss: 0.7640
2024-07-14 05:59:13,998 [INFO    ] __main__: train step 9530: loss: 1.1183, policy_loss: 1.1738, value_loss: 0.7639
2024-07-14 05:59:14,287 [INFO    ] __main__: train step 9531: loss: 1.1183, policy_loss: 1.1737, value_loss: 0.7639
2024-07-14 05:59:14,581 [INFO    ] __main__: train step 9532: loss: 1.1183, policy_loss: 1.1736, value_loss: 0.7639
2024-07-14 05:59:14,870 [INFO    ] __main__: train step 9533: loss: 1.1183, policy_loss: 1.1736, value_loss: 0.7638
2024-07-14 05:59:16,504 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:59:16,991 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:59:17,061 [INFO    ] __main__: train step 9534: loss: 1.1183, policy_loss: 1.1735, value_loss: 0.7638
2024-07-14 05:59:17,357 [INFO    ] __main__: train step 9535: loss: 1.1182, policy_loss: 1.1735, value_loss: 0.7637
2024-07-14 05:59:17,648 [INFO    ] __main__: train step 9536: loss: 1.1182, policy_loss: 1.1734, value_loss: 0.7637
2024-07-14 05:59:17,946 [INFO    ] __main__: train step 9537: loss: 1.1182, policy_loss: 1.1733, value_loss: 0.7636
2024-07-14 05:59:18,237 [INFO    ] __main__: train step 9538: loss: 1.1182, policy_loss: 1.1733, value_loss: 0.7636
2024-07-14 05:59:18,524 [INFO    ] __main__: train step 9539: loss: 1.1182, policy_loss: 1.1732, value_loss: 0.7635
2024-07-14 05:59:18,821 [INFO    ] __main__: train step 9540: loss: 1.1181, policy_loss: 1.1732, value_loss: 0.7635
2024-07-14 05:59:19,115 [INFO    ] __main__: train step 9541: loss: 1.1181, policy_loss: 1.1731, value_loss: 0.7634
2024-07-14 05:59:19,414 [INFO    ] __main__: train step 9542: loss: 1.1181, policy_loss: 1.1730, value_loss: 0.7634
2024-07-14 05:59:19,716 [INFO    ] __main__: train step 9543: loss: 1.1181, policy_loss: 1.1730, value_loss: 0.7634
2024-07-14 05:59:20,021 [INFO    ] __main__: train step 9544: loss: 1.1181, policy_loss: 1.1729, value_loss: 0.7633
2024-07-14 05:59:20,325 [INFO    ] __main__: train step 9545: loss: 1.1180, policy_loss: 1.1729, value_loss: 0.7633
2024-07-14 05:59:20,630 [INFO    ] __main__: train step 9546: loss: 1.1180, policy_loss: 1.1728, value_loss: 0.7632
2024-07-14 05:59:20,925 [INFO    ] __main__: train step 9547: loss: 1.1180, policy_loss: 1.1727, value_loss: 0.7632
2024-07-14 05:59:21,220 [INFO    ] __main__: train step 9548: loss: 1.1180, policy_loss: 1.1727, value_loss: 0.7631
2024-07-14 05:59:21,507 [INFO    ] __main__: train step 9549: loss: 1.1180, policy_loss: 1.1726, value_loss: 0.7631
2024-07-14 05:59:21,799 [INFO    ] __main__: train step 9550: loss: 1.1179, policy_loss: 1.1726, value_loss: 0.7630
2024-07-14 05:59:23,433 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:59:23,914 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:59:23,984 [INFO    ] __main__: train step 9551: loss: 1.1179, policy_loss: 1.1725, value_loss: 0.7630
2024-07-14 05:59:25,779 [INFO    ] __main__: train step 9552: loss: 1.1179, policy_loss: 1.1724, value_loss: 0.7630
2024-07-14 05:59:26,080 [INFO    ] __main__: train step 9553: loss: 1.1179, policy_loss: 1.1724, value_loss: 0.7629
2024-07-14 05:59:26,384 [INFO    ] __main__: train step 9554: loss: 1.1179, policy_loss: 1.1723, value_loss: 0.7629
2024-07-14 05:59:26,691 [INFO    ] __main__: train step 9555: loss: 1.1178, policy_loss: 1.1723, value_loss: 0.7628
2024-07-14 05:59:26,990 [INFO    ] __main__: train step 9556: loss: 1.1178, policy_loss: 1.1722, value_loss: 0.7628
2024-07-14 05:59:27,272 [INFO    ] __main__: train step 9557: loss: 1.1178, policy_loss: 1.1721, value_loss: 0.7627
2024-07-14 05:59:27,564 [INFO    ] __main__: train step 9558: loss: 1.1178, policy_loss: 1.1721, value_loss: 0.7627
2024-07-14 05:59:27,851 [INFO    ] __main__: train step 9559: loss: 1.1178, policy_loss: 1.1720, value_loss: 0.7626
2024-07-14 05:59:28,162 [INFO    ] __main__: train step 9560: loss: 1.1177, policy_loss: 1.1720, value_loss: 0.7626
2024-07-14 05:59:28,469 [INFO    ] __main__: train step 9561: loss: 1.1177, policy_loss: 1.1719, value_loss: 0.7625
2024-07-14 05:59:28,762 [INFO    ] __main__: train step 9562: loss: 1.1177, policy_loss: 1.1718, value_loss: 0.7625
2024-07-14 05:59:29,052 [INFO    ] __main__: train step 9563: loss: 1.1177, policy_loss: 1.1718, value_loss: 0.7624
2024-07-14 05:59:29,342 [INFO    ] __main__: train step 9564: loss: 1.1176, policy_loss: 1.1717, value_loss: 0.7624
2024-07-14 05:59:29,634 [INFO    ] __main__: train step 9565: loss: 1.1176, policy_loss: 1.1717, value_loss: 0.7624
2024-07-14 05:59:29,935 [INFO    ] __main__: train step 9566: loss: 1.1176, policy_loss: 1.1716, value_loss: 0.7623
2024-07-14 05:59:30,220 [INFO    ] __main__: train step 9567: loss: 1.1176, policy_loss: 1.1715, value_loss: 0.7623
2024-07-14 05:59:31,862 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:59:32,353 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:59:32,424 [INFO    ] __main__: train step 9568: loss: 1.1176, policy_loss: 1.1715, value_loss: 0.7622
2024-07-14 05:59:32,710 [INFO    ] __main__: train step 9569: loss: 1.1175, policy_loss: 1.1714, value_loss: 0.7622
2024-07-14 05:59:33,004 [INFO    ] __main__: train step 9570: loss: 1.1175, policy_loss: 1.1714, value_loss: 0.7621
2024-07-14 05:59:33,297 [INFO    ] __main__: train step 9571: loss: 1.1175, policy_loss: 1.1713, value_loss: 0.7621
2024-07-14 05:59:33,587 [INFO    ] __main__: train step 9572: loss: 1.1175, policy_loss: 1.1712, value_loss: 0.7620
2024-07-14 05:59:33,889 [INFO    ] __main__: train step 9573: loss: 1.1175, policy_loss: 1.1712, value_loss: 0.7620
2024-07-14 05:59:34,176 [INFO    ] __main__: train step 9574: loss: 1.1175, policy_loss: 1.1711, value_loss: 0.7619
2024-07-14 05:59:34,471 [INFO    ] __main__: train step 9575: loss: 1.1174, policy_loss: 1.1711, value_loss: 0.7619
2024-07-14 05:59:34,766 [INFO    ] __main__: train step 9576: loss: 1.1174, policy_loss: 1.1710, value_loss: 0.7619
2024-07-14 05:59:35,063 [INFO    ] __main__: train step 9577: loss: 1.1174, policy_loss: 1.1709, value_loss: 0.7618
2024-07-14 05:59:35,400 [INFO    ] __main__: train step 9578: loss: 1.1174, policy_loss: 1.1709, value_loss: 0.7618
2024-07-14 05:59:35,709 [INFO    ] __main__: train step 9579: loss: 1.1173, policy_loss: 1.1708, value_loss: 0.7617
2024-07-14 05:59:36,015 [INFO    ] __main__: train step 9580: loss: 1.1173, policy_loss: 1.1707, value_loss: 0.7617
2024-07-14 05:59:36,325 [INFO    ] __main__: train step 9581: loss: 1.1173, policy_loss: 1.1707, value_loss: 0.7616
2024-07-14 05:59:36,628 [INFO    ] __main__: train step 9582: loss: 1.1173, policy_loss: 1.1706, value_loss: 0.7616
2024-07-14 05:59:36,930 [INFO    ] __main__: train step 9583: loss: 1.1173, policy_loss: 1.1706, value_loss: 0.7615
2024-07-14 05:59:37,227 [INFO    ] __main__: train step 9584: loss: 1.1172, policy_loss: 1.1705, value_loss: 0.7615
2024-07-14 05:59:38,844 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:59:39,335 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:59:39,406 [INFO    ] __main__: train step 9585: loss: 1.1172, policy_loss: 1.1705, value_loss: 0.7614
2024-07-14 05:59:39,702 [INFO    ] __main__: train step 9586: loss: 1.1172, policy_loss: 1.1704, value_loss: 0.7614
2024-07-14 05:59:39,991 [INFO    ] __main__: train step 9587: loss: 1.1172, policy_loss: 1.1703, value_loss: 0.7613
2024-07-14 05:59:40,278 [INFO    ] __main__: train step 9588: loss: 1.1172, policy_loss: 1.1703, value_loss: 0.7613
2024-07-14 05:59:40,565 [INFO    ] __main__: train step 9589: loss: 1.1171, policy_loss: 1.1702, value_loss: 0.7613
2024-07-14 05:59:40,888 [INFO    ] __main__: train step 9590: loss: 1.1171, policy_loss: 1.1702, value_loss: 0.7612
2024-07-14 05:59:41,181 [INFO    ] __main__: train step 9591: loss: 1.1171, policy_loss: 1.1701, value_loss: 0.7612
2024-07-14 05:59:41,483 [INFO    ] __main__: train step 9592: loss: 1.1171, policy_loss: 1.1700, value_loss: 0.7611
2024-07-14 05:59:41,788 [INFO    ] __main__: train step 9593: loss: 1.1170, policy_loss: 1.1700, value_loss: 0.7611
2024-07-14 05:59:42,080 [INFO    ] __main__: train step 9594: loss: 1.1170, policy_loss: 1.1699, value_loss: 0.7610
2024-07-14 05:59:42,380 [INFO    ] __main__: train step 9595: loss: 1.1170, policy_loss: 1.1699, value_loss: 0.7610
2024-07-14 05:59:42,666 [INFO    ] __main__: train step 9596: loss: 1.1170, policy_loss: 1.1698, value_loss: 0.7609
2024-07-14 05:59:42,955 [INFO    ] __main__: train step 9597: loss: 1.1170, policy_loss: 1.1697, value_loss: 0.7609
2024-07-14 05:59:43,239 [INFO    ] __main__: train step 9598: loss: 1.1169, policy_loss: 1.1697, value_loss: 0.7608
2024-07-14 05:59:43,545 [INFO    ] __main__: train step 9599: loss: 1.1169, policy_loss: 1.1696, value_loss: 0.7608
2024-07-14 05:59:43,851 [INFO    ] __main__: train step 9600: loss: 1.1169, policy_loss: 1.1696, value_loss: 0.7607
2024-07-14 05:59:44,149 [INFO    ] __main__: train step 9601: loss: 1.1169, policy_loss: 1.1695, value_loss: 0.7607
2024-07-14 05:59:45,768 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:59:46,239 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:59:46,312 [INFO    ] __main__: train step 9602: loss: 1.1169, policy_loss: 1.1694, value_loss: 0.7607
2024-07-14 05:59:46,613 [INFO    ] __main__: train step 9603: loss: 1.1168, policy_loss: 1.1694, value_loss: 0.7606
2024-07-14 05:59:46,917 [INFO    ] __main__: train step 9604: loss: 1.1168, policy_loss: 1.1693, value_loss: 0.7606
2024-07-14 05:59:47,209 [INFO    ] __main__: train step 9605: loss: 1.1168, policy_loss: 1.1693, value_loss: 0.7605
2024-07-14 05:59:49,016 [INFO    ] __main__: train step 9606: loss: 1.1168, policy_loss: 1.1692, value_loss: 0.7605
2024-07-14 05:59:49,314 [INFO    ] __main__: train step 9607: loss: 1.1168, policy_loss: 1.1691, value_loss: 0.7604
2024-07-14 05:59:49,625 [INFO    ] __main__: train step 9608: loss: 1.1167, policy_loss: 1.1691, value_loss: 0.7604
2024-07-14 05:59:49,934 [INFO    ] __main__: train step 9609: loss: 1.1167, policy_loss: 1.1690, value_loss: 0.7603
2024-07-14 05:59:50,227 [INFO    ] __main__: train step 9610: loss: 1.1167, policy_loss: 1.1690, value_loss: 0.7603
2024-07-14 05:59:50,532 [INFO    ] __main__: train step 9611: loss: 1.1167, policy_loss: 1.1689, value_loss: 0.7602
2024-07-14 05:59:50,848 [INFO    ] __main__: train step 9612: loss: 1.1166, policy_loss: 1.1689, value_loss: 0.7602
2024-07-14 05:59:51,154 [INFO    ] __main__: train step 9613: loss: 1.1166, policy_loss: 1.1688, value_loss: 0.7601
2024-07-14 05:59:51,449 [INFO    ] __main__: train step 9614: loss: 1.1166, policy_loss: 1.1687, value_loss: 0.7601
2024-07-14 05:59:51,747 [INFO    ] __main__: train step 9615: loss: 1.1166, policy_loss: 1.1687, value_loss: 0.7600
2024-07-14 05:59:52,043 [INFO    ] __main__: train step 9616: loss: 1.1166, policy_loss: 1.1686, value_loss: 0.7600
2024-07-14 05:59:52,346 [INFO    ] __main__: train step 9617: loss: 1.1165, policy_loss: 1.1686, value_loss: 0.7599
2024-07-14 05:59:52,639 [INFO    ] __main__: train step 9618: loss: 1.1165, policy_loss: 1.1685, value_loss: 0.7599
2024-07-14 05:59:54,260 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 05:59:54,754 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 05:59:54,824 [INFO    ] __main__: train step 9619: loss: 1.1165, policy_loss: 1.1684, value_loss: 0.7599
2024-07-14 05:59:55,117 [INFO    ] __main__: train step 9620: loss: 1.1165, policy_loss: 1.1684, value_loss: 0.7598
2024-07-14 05:59:55,415 [INFO    ] __main__: train step 9621: loss: 1.1165, policy_loss: 1.1683, value_loss: 0.7598
2024-07-14 05:59:55,705 [INFO    ] __main__: train step 9622: loss: 1.1164, policy_loss: 1.1683, value_loss: 0.7597
2024-07-14 05:59:55,994 [INFO    ] __main__: train step 9623: loss: 1.1164, policy_loss: 1.1682, value_loss: 0.7597
2024-07-14 05:59:56,279 [INFO    ] __main__: train step 9624: loss: 1.1164, policy_loss: 1.1681, value_loss: 0.7596
2024-07-14 05:59:56,579 [INFO    ] __main__: train step 9625: loss: 1.1164, policy_loss: 1.1681, value_loss: 0.7596
2024-07-14 05:59:56,870 [INFO    ] __main__: train step 9626: loss: 1.1163, policy_loss: 1.1680, value_loss: 0.7595
2024-07-14 05:59:57,167 [INFO    ] __main__: train step 9627: loss: 1.1163, policy_loss: 1.1680, value_loss: 0.7595
2024-07-14 05:59:57,448 [INFO    ] __main__: train step 9628: loss: 1.1163, policy_loss: 1.1679, value_loss: 0.7594
2024-07-14 05:59:57,733 [INFO    ] __main__: train step 9629: loss: 1.1163, policy_loss: 1.1679, value_loss: 0.7594
2024-07-14 05:59:58,030 [INFO    ] __main__: train step 9630: loss: 1.1163, policy_loss: 1.1678, value_loss: 0.7593
2024-07-14 05:59:58,327 [INFO    ] __main__: train step 9631: loss: 1.1162, policy_loss: 1.1677, value_loss: 0.7593
2024-07-14 05:59:58,623 [INFO    ] __main__: train step 9632: loss: 1.1162, policy_loss: 1.1677, value_loss: 0.7592
2024-07-14 05:59:58,914 [INFO    ] __main__: train step 9633: loss: 1.1162, policy_loss: 1.1676, value_loss: 0.7592
2024-07-14 05:59:59,212 [INFO    ] __main__: train step 9634: loss: 1.1162, policy_loss: 1.1676, value_loss: 0.7591
2024-07-14 05:59:59,496 [INFO    ] __main__: train step 9635: loss: 1.1161, policy_loss: 1.1675, value_loss: 0.7591
2024-07-14 06:00:01,121 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:00:01,610 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:00:01,678 [INFO    ] __main__: train step 9636: loss: 1.1161, policy_loss: 1.1674, value_loss: 0.7591
2024-07-14 06:00:01,972 [INFO    ] __main__: train step 9637: loss: 1.1161, policy_loss: 1.1674, value_loss: 0.7590
2024-07-14 06:00:02,271 [INFO    ] __main__: train step 9638: loss: 1.1161, policy_loss: 1.1673, value_loss: 0.7590
2024-07-14 06:00:02,574 [INFO    ] __main__: train step 9639: loss: 1.1161, policy_loss: 1.1673, value_loss: 0.7589
2024-07-14 06:00:02,870 [INFO    ] __main__: train step 9640: loss: 1.1160, policy_loss: 1.1672, value_loss: 0.7589
2024-07-14 06:00:03,153 [INFO    ] __main__: train step 9641: loss: 1.1160, policy_loss: 1.1671, value_loss: 0.7588
2024-07-14 06:00:03,425 [INFO    ] __main__: train step 9642: loss: 1.1160, policy_loss: 1.1671, value_loss: 0.7588
2024-07-14 06:00:03,710 [INFO    ] __main__: train step 9643: loss: 1.1160, policy_loss: 1.1670, value_loss: 0.7587
2024-07-14 06:00:03,987 [INFO    ] __main__: train step 9644: loss: 1.1159, policy_loss: 1.1670, value_loss: 0.7587
2024-07-14 06:00:04,275 [INFO    ] __main__: train step 9645: loss: 1.1159, policy_loss: 1.1669, value_loss: 0.7586
2024-07-14 06:00:04,536 [INFO    ] __main__: train step 9646: loss: 1.1159, policy_loss: 1.1669, value_loss: 0.7586
2024-07-14 06:00:04,812 [INFO    ] __main__: train step 9647: loss: 1.1159, policy_loss: 1.1668, value_loss: 0.7585
2024-07-14 06:00:05,091 [INFO    ] __main__: train step 9648: loss: 1.1159, policy_loss: 1.1667, value_loss: 0.7585
2024-07-14 06:00:05,356 [INFO    ] __main__: train step 9649: loss: 1.1158, policy_loss: 1.1667, value_loss: 0.7584
2024-07-14 06:00:05,655 [INFO    ] __main__: train step 9650: loss: 1.1158, policy_loss: 1.1666, value_loss: 0.7584
2024-07-14 06:00:05,944 [INFO    ] __main__: train step 9651: loss: 1.1158, policy_loss: 1.1666, value_loss: 0.7583
2024-07-14 06:00:06,239 [INFO    ] __main__: train step 9652: loss: 1.1158, policy_loss: 1.1665, value_loss: 0.7583
2024-07-14 06:00:07,876 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:00:08,366 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:00:08,438 [INFO    ] __main__: train step 9653: loss: 1.1157, policy_loss: 1.1664, value_loss: 0.7582
2024-07-14 06:00:08,738 [INFO    ] __main__: train step 9654: loss: 1.1157, policy_loss: 1.1664, value_loss: 0.7582
2024-07-14 06:00:09,023 [INFO    ] __main__: train step 9655: loss: 1.1157, policy_loss: 1.1663, value_loss: 0.7581
2024-07-14 06:00:09,317 [INFO    ] __main__: train step 9656: loss: 1.1157, policy_loss: 1.1663, value_loss: 0.7581
2024-07-14 06:00:09,603 [INFO    ] __main__: train step 9657: loss: 1.1156, policy_loss: 1.1662, value_loss: 0.7580
2024-07-14 06:00:09,906 [INFO    ] __main__: train step 9658: loss: 1.1156, policy_loss: 1.1661, value_loss: 0.7580
2024-07-14 06:00:10,195 [INFO    ] __main__: train step 9659: loss: 1.1156, policy_loss: 1.1661, value_loss: 0.7579
2024-07-14 06:00:12,115 [INFO    ] __main__: train step 9660: loss: 1.1156, policy_loss: 1.1660, value_loss: 0.7579
2024-07-14 06:00:12,414 [INFO    ] __main__: train step 9661: loss: 1.1156, policy_loss: 1.1660, value_loss: 0.7578
2024-07-14 06:00:12,707 [INFO    ] __main__: train step 9662: loss: 1.1155, policy_loss: 1.1659, value_loss: 0.7578
2024-07-14 06:00:13,007 [INFO    ] __main__: train step 9663: loss: 1.1155, policy_loss: 1.1659, value_loss: 0.7577
2024-07-14 06:00:13,313 [INFO    ] __main__: train step 9664: loss: 1.1155, policy_loss: 1.1658, value_loss: 0.7577
2024-07-14 06:00:13,598 [INFO    ] __main__: train step 9665: loss: 1.1155, policy_loss: 1.1657, value_loss: 0.7577
2024-07-14 06:00:13,890 [INFO    ] __main__: train step 9666: loss: 1.1154, policy_loss: 1.1657, value_loss: 0.7576
2024-07-14 06:00:14,189 [INFO    ] __main__: train step 9667: loss: 1.1154, policy_loss: 1.1656, value_loss: 0.7576
2024-07-14 06:00:14,480 [INFO    ] __main__: train step 9668: loss: 1.1154, policy_loss: 1.1656, value_loss: 0.7575
2024-07-14 06:00:14,779 [INFO    ] __main__: train step 9669: loss: 1.1154, policy_loss: 1.1655, value_loss: 0.7575
2024-07-14 06:00:16,406 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:00:16,840 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:00:16,906 [INFO    ] __main__: train step 9670: loss: 1.1153, policy_loss: 1.1655, value_loss: 0.7574
2024-07-14 06:00:17,167 [INFO    ] __main__: train step 9671: loss: 1.1153, policy_loss: 1.1654, value_loss: 0.7574
2024-07-14 06:00:17,447 [INFO    ] __main__: train step 9672: loss: 1.1153, policy_loss: 1.1653, value_loss: 0.7573
2024-07-14 06:00:17,730 [INFO    ] __main__: train step 9673: loss: 1.1153, policy_loss: 1.1653, value_loss: 0.7573
2024-07-14 06:00:18,024 [INFO    ] __main__: train step 9674: loss: 1.1152, policy_loss: 1.1652, value_loss: 0.7572
2024-07-14 06:00:18,316 [INFO    ] __main__: train step 9675: loss: 1.1152, policy_loss: 1.1652, value_loss: 0.7572
2024-07-14 06:00:18,607 [INFO    ] __main__: train step 9676: loss: 1.1152, policy_loss: 1.1651, value_loss: 0.7571
2024-07-14 06:00:18,901 [INFO    ] __main__: train step 9677: loss: 1.1152, policy_loss: 1.1651, value_loss: 0.7571
2024-07-14 06:00:19,172 [INFO    ] __main__: train step 9678: loss: 1.1152, policy_loss: 1.1650, value_loss: 0.7570
2024-07-14 06:00:19,473 [INFO    ] __main__: train step 9679: loss: 1.1151, policy_loss: 1.1649, value_loss: 0.7570
2024-07-14 06:00:19,763 [INFO    ] __main__: train step 9680: loss: 1.1151, policy_loss: 1.1649, value_loss: 0.7569
2024-07-14 06:00:20,046 [INFO    ] __main__: train step 9681: loss: 1.1151, policy_loss: 1.1648, value_loss: 0.7569
2024-07-14 06:00:20,336 [INFO    ] __main__: train step 9682: loss: 1.1151, policy_loss: 1.1648, value_loss: 0.7568
2024-07-14 06:00:20,638 [INFO    ] __main__: train step 9683: loss: 1.1150, policy_loss: 1.1647, value_loss: 0.7568
2024-07-14 06:00:20,949 [INFO    ] __main__: train step 9684: loss: 1.1150, policy_loss: 1.1646, value_loss: 0.7567
2024-07-14 06:00:21,258 [INFO    ] __main__: train step 9685: loss: 1.1150, policy_loss: 1.1646, value_loss: 0.7567
2024-07-14 06:00:21,553 [INFO    ] __main__: train step 9686: loss: 1.1150, policy_loss: 1.1645, value_loss: 0.7566
2024-07-14 06:00:23,180 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:00:23,675 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:00:23,749 [INFO    ] __main__: train step 9687: loss: 1.1150, policy_loss: 1.1645, value_loss: 0.7566
2024-07-14 06:00:24,052 [INFO    ] __main__: train step 9688: loss: 1.1149, policy_loss: 1.1644, value_loss: 0.7565
2024-07-14 06:00:24,354 [INFO    ] __main__: train step 9689: loss: 1.1149, policy_loss: 1.1644, value_loss: 0.7565
2024-07-14 06:00:24,653 [INFO    ] __main__: train step 9690: loss: 1.1149, policy_loss: 1.1643, value_loss: 0.7564
2024-07-14 06:00:24,957 [INFO    ] __main__: train step 9691: loss: 1.1149, policy_loss: 1.1642, value_loss: 0.7564
2024-07-14 06:00:25,257 [INFO    ] __main__: train step 9692: loss: 1.1148, policy_loss: 1.1642, value_loss: 0.7563
2024-07-14 06:00:25,561 [INFO    ] __main__: train step 9693: loss: 1.1148, policy_loss: 1.1641, value_loss: 0.7563
2024-07-14 06:00:25,856 [INFO    ] __main__: train step 9694: loss: 1.1148, policy_loss: 1.1641, value_loss: 0.7562
2024-07-14 06:00:26,146 [INFO    ] __main__: train step 9695: loss: 1.1148, policy_loss: 1.1640, value_loss: 0.7562
2024-07-14 06:00:26,444 [INFO    ] __main__: train step 9696: loss: 1.1148, policy_loss: 1.1640, value_loss: 0.7561
2024-07-14 06:00:26,754 [INFO    ] __main__: train step 9697: loss: 1.1147, policy_loss: 1.1639, value_loss: 0.7561
2024-07-14 06:00:27,054 [INFO    ] __main__: train step 9698: loss: 1.1147, policy_loss: 1.1638, value_loss: 0.7560
2024-07-14 06:00:27,351 [INFO    ] __main__: train step 9699: loss: 1.1147, policy_loss: 1.1638, value_loss: 0.7560
2024-07-14 06:00:27,650 [INFO    ] __main__: train step 9700: loss: 1.1147, policy_loss: 1.1637, value_loss: 0.7559
2024-07-14 06:00:27,943 [INFO    ] __main__: train step 9701: loss: 1.1146, policy_loss: 1.1637, value_loss: 0.7559
2024-07-14 06:00:28,219 [INFO    ] __main__: train step 9702: loss: 1.1146, policy_loss: 1.1636, value_loss: 0.7559
2024-07-14 06:00:28,506 [INFO    ] __main__: train step 9703: loss: 1.1146, policy_loss: 1.1636, value_loss: 0.7558
2024-07-14 06:00:30,119 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:00:30,589 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:00:30,659 [INFO    ] __main__: train step 9704: loss: 1.1146, policy_loss: 1.1635, value_loss: 0.7558
2024-07-14 06:00:30,931 [INFO    ] __main__: train step 9705: loss: 1.1145, policy_loss: 1.1634, value_loss: 0.7557
2024-07-14 06:00:31,221 [INFO    ] __main__: train step 9706: loss: 1.1145, policy_loss: 1.1634, value_loss: 0.7557
2024-07-14 06:00:31,505 [INFO    ] __main__: train step 9707: loss: 1.1145, policy_loss: 1.1633, value_loss: 0.7556
2024-07-14 06:00:31,799 [INFO    ] __main__: train step 9708: loss: 1.1145, policy_loss: 1.1633, value_loss: 0.7556
2024-07-14 06:00:32,104 [INFO    ] __main__: train step 9709: loss: 1.1144, policy_loss: 1.1632, value_loss: 0.7555
2024-07-14 06:00:32,385 [INFO    ] __main__: train step 9710: loss: 1.1144, policy_loss: 1.1631, value_loss: 0.7555
2024-07-14 06:00:32,677 [INFO    ] __main__: train step 9711: loss: 1.1144, policy_loss: 1.1631, value_loss: 0.7554
2024-07-14 06:00:32,980 [INFO    ] __main__: train step 9712: loss: 1.1144, policy_loss: 1.1630, value_loss: 0.7554
2024-07-14 06:00:33,284 [INFO    ] __main__: train step 9713: loss: 1.1144, policy_loss: 1.1630, value_loss: 0.7553
2024-07-14 06:00:34,984 [INFO    ] __main__: train step 9714: loss: 1.1143, policy_loss: 1.1629, value_loss: 0.7553
2024-07-14 06:00:35,315 [INFO    ] __main__: train step 9715: loss: 1.1143, policy_loss: 1.1629, value_loss: 0.7552
2024-07-14 06:00:35,607 [INFO    ] __main__: train step 9716: loss: 1.1143, policy_loss: 1.1628, value_loss: 0.7552
2024-07-14 06:00:35,906 [INFO    ] __main__: train step 9717: loss: 1.1143, policy_loss: 1.1627, value_loss: 0.7551
2024-07-14 06:00:36,193 [INFO    ] __main__: train step 9718: loss: 1.1142, policy_loss: 1.1627, value_loss: 0.7551
2024-07-14 06:00:36,498 [INFO    ] __main__: train step 9719: loss: 1.1142, policy_loss: 1.1626, value_loss: 0.7550
2024-07-14 06:00:36,798 [INFO    ] __main__: train step 9720: loss: 1.1142, policy_loss: 1.1626, value_loss: 0.7550
2024-07-14 06:00:38,402 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:00:38,871 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:00:38,941 [INFO    ] __main__: train step 9721: loss: 1.1142, policy_loss: 1.1625, value_loss: 0.7549
2024-07-14 06:00:39,234 [INFO    ] __main__: train step 9722: loss: 1.1141, policy_loss: 1.1625, value_loss: 0.7549
2024-07-14 06:00:39,514 [INFO    ] __main__: train step 9723: loss: 1.1141, policy_loss: 1.1624, value_loss: 0.7548
2024-07-14 06:00:39,819 [INFO    ] __main__: train step 9724: loss: 1.1141, policy_loss: 1.1623, value_loss: 0.7548
2024-07-14 06:00:40,111 [INFO    ] __main__: train step 9725: loss: 1.1141, policy_loss: 1.1623, value_loss: 0.7547
2024-07-14 06:00:40,405 [INFO    ] __main__: train step 9726: loss: 1.1140, policy_loss: 1.1622, value_loss: 0.7547
2024-07-14 06:00:40,708 [INFO    ] __main__: train step 9727: loss: 1.1140, policy_loss: 1.1622, value_loss: 0.7546
2024-07-14 06:00:41,067 [INFO    ] __main__: train step 9728: loss: 1.1140, policy_loss: 1.1621, value_loss: 0.7546
2024-07-14 06:00:41,368 [INFO    ] __main__: train step 9729: loss: 1.1140, policy_loss: 1.1621, value_loss: 0.7545
2024-07-14 06:00:41,668 [INFO    ] __main__: train step 9730: loss: 1.1140, policy_loss: 1.1620, value_loss: 0.7545
2024-07-14 06:00:41,967 [INFO    ] __main__: train step 9731: loss: 1.1139, policy_loss: 1.1620, value_loss: 0.7544
2024-07-14 06:00:42,261 [INFO    ] __main__: train step 9732: loss: 1.1139, policy_loss: 1.1619, value_loss: 0.7544
2024-07-14 06:00:42,563 [INFO    ] __main__: train step 9733: loss: 1.1139, policy_loss: 1.1618, value_loss: 0.7543
2024-07-14 06:00:42,868 [INFO    ] __main__: train step 9734: loss: 1.1139, policy_loss: 1.1618, value_loss: 0.7543
2024-07-14 06:00:43,167 [INFO    ] __main__: train step 9735: loss: 1.1138, policy_loss: 1.1617, value_loss: 0.7542
2024-07-14 06:00:43,464 [INFO    ] __main__: train step 9736: loss: 1.1138, policy_loss: 1.1617, value_loss: 0.7542
2024-07-14 06:00:43,758 [INFO    ] __main__: train step 9737: loss: 1.1138, policy_loss: 1.1616, value_loss: 0.7541
2024-07-14 06:00:45,363 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:00:45,860 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:00:45,931 [INFO    ] __main__: train step 9738: loss: 1.1138, policy_loss: 1.1615, value_loss: 0.7541
2024-07-14 06:00:46,221 [INFO    ] __main__: train step 9739: loss: 1.1137, policy_loss: 1.1615, value_loss: 0.7540
2024-07-14 06:00:46,539 [INFO    ] __main__: train step 9740: loss: 1.1137, policy_loss: 1.1614, value_loss: 0.7540
2024-07-14 06:00:46,856 [INFO    ] __main__: train step 9741: loss: 1.1137, policy_loss: 1.1614, value_loss: 0.7539
2024-07-14 06:00:47,148 [INFO    ] __main__: train step 9742: loss: 1.1137, policy_loss: 1.1613, value_loss: 0.7539
2024-07-14 06:00:47,447 [INFO    ] __main__: train step 9743: loss: 1.1137, policy_loss: 1.1613, value_loss: 0.7538
2024-07-14 06:00:47,733 [INFO    ] __main__: train step 9744: loss: 1.1136, policy_loss: 1.1612, value_loss: 0.7538
2024-07-14 06:00:48,035 [INFO    ] __main__: train step 9745: loss: 1.1136, policy_loss: 1.1612, value_loss: 0.7537
2024-07-14 06:00:48,333 [INFO    ] __main__: train step 9746: loss: 1.1136, policy_loss: 1.1611, value_loss: 0.7537
2024-07-14 06:00:48,633 [INFO    ] __main__: train step 9747: loss: 1.1136, policy_loss: 1.1610, value_loss: 0.7536
2024-07-14 06:00:48,917 [INFO    ] __main__: train step 9748: loss: 1.1135, policy_loss: 1.1610, value_loss: 0.7536
2024-07-14 06:00:49,217 [INFO    ] __main__: train step 9749: loss: 1.1135, policy_loss: 1.1609, value_loss: 0.7535
2024-07-14 06:00:49,512 [INFO    ] __main__: train step 9750: loss: 1.1135, policy_loss: 1.1609, value_loss: 0.7535
2024-07-14 06:00:49,816 [INFO    ] __main__: train step 9751: loss: 1.1135, policy_loss: 1.1608, value_loss: 0.7534
2024-07-14 06:00:50,109 [INFO    ] __main__: train step 9752: loss: 1.1134, policy_loss: 1.1608, value_loss: 0.7534
2024-07-14 06:00:50,414 [INFO    ] __main__: train step 9753: loss: 1.1134, policy_loss: 1.1607, value_loss: 0.7533
2024-07-14 06:00:50,705 [INFO    ] __main__: train step 9754: loss: 1.1134, policy_loss: 1.1606, value_loss: 0.7533
2024-07-14 06:00:52,345 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:00:52,851 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:00:52,919 [INFO    ] __main__: train step 9755: loss: 1.1134, policy_loss: 1.1606, value_loss: 0.7532
2024-07-14 06:00:53,209 [INFO    ] __main__: train step 9756: loss: 1.1133, policy_loss: 1.1605, value_loss: 0.7532
2024-07-14 06:00:53,503 [INFO    ] __main__: train step 9757: loss: 1.1133, policy_loss: 1.1605, value_loss: 0.7531
2024-07-14 06:00:53,802 [INFO    ] __main__: train step 9758: loss: 1.1133, policy_loss: 1.1604, value_loss: 0.7531
2024-07-14 06:00:54,103 [INFO    ] __main__: train step 9759: loss: 1.1133, policy_loss: 1.1604, value_loss: 0.7530
2024-07-14 06:00:54,405 [INFO    ] __main__: train step 9760: loss: 1.1132, policy_loss: 1.1603, value_loss: 0.7530
2024-07-14 06:00:54,694 [INFO    ] __main__: train step 9761: loss: 1.1132, policy_loss: 1.1603, value_loss: 0.7529
2024-07-14 06:00:55,010 [INFO    ] __main__: train step 9762: loss: 1.1132, policy_loss: 1.1602, value_loss: 0.7529
2024-07-14 06:00:55,314 [INFO    ] __main__: train step 9763: loss: 1.1132, policy_loss: 1.1601, value_loss: 0.7528
2024-07-14 06:00:55,612 [INFO    ] __main__: train step 9764: loss: 1.1131, policy_loss: 1.1601, value_loss: 0.7528
2024-07-14 06:00:55,905 [INFO    ] __main__: train step 9765: loss: 1.1131, policy_loss: 1.1600, value_loss: 0.7527
2024-07-14 06:00:56,198 [INFO    ] __main__: train step 9766: loss: 1.1131, policy_loss: 1.1600, value_loss: 0.7527
2024-07-14 06:00:56,493 [INFO    ] __main__: train step 9767: loss: 1.1131, policy_loss: 1.1599, value_loss: 0.7526
2024-07-14 06:00:56,790 [INFO    ] __main__: train step 9768: loss: 1.1130, policy_loss: 1.1599, value_loss: 0.7526
2024-07-14 06:00:58,914 [INFO    ] __main__: train step 9769: loss: 1.1130, policy_loss: 1.1598, value_loss: 0.7525
2024-07-14 06:00:59,217 [INFO    ] __main__: train step 9770: loss: 1.1130, policy_loss: 1.1598, value_loss: 0.7525
2024-07-14 06:00:59,538 [INFO    ] __main__: train step 9771: loss: 1.1130, policy_loss: 1.1597, value_loss: 0.7524
2024-07-14 06:01:01,168 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:01:01,659 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:01:01,731 [INFO    ] __main__: train step 9772: loss: 1.1130, policy_loss: 1.1596, value_loss: 0.7524
2024-07-14 06:01:02,034 [INFO    ] __main__: train step 9773: loss: 1.1129, policy_loss: 1.1596, value_loss: 0.7523
2024-07-14 06:01:02,335 [INFO    ] __main__: train step 9774: loss: 1.1129, policy_loss: 1.1595, value_loss: 0.7523
2024-07-14 06:01:02,618 [INFO    ] __main__: train step 9775: loss: 1.1129, policy_loss: 1.1595, value_loss: 0.7522
2024-07-14 06:01:02,900 [INFO    ] __main__: train step 9776: loss: 1.1129, policy_loss: 1.1594, value_loss: 0.7522
2024-07-14 06:01:03,199 [INFO    ] __main__: train step 9777: loss: 1.1128, policy_loss: 1.1594, value_loss: 0.7521
2024-07-14 06:01:03,499 [INFO    ] __main__: train step 9778: loss: 1.1128, policy_loss: 1.1593, value_loss: 0.7521
2024-07-14 06:01:03,790 [INFO    ] __main__: train step 9779: loss: 1.1128, policy_loss: 1.1593, value_loss: 0.7520
2024-07-14 06:01:04,096 [INFO    ] __main__: train step 9780: loss: 1.1128, policy_loss: 1.1592, value_loss: 0.7520
2024-07-14 06:01:04,402 [INFO    ] __main__: train step 9781: loss: 1.1127, policy_loss: 1.1592, value_loss: 0.7519
2024-07-14 06:01:04,709 [INFO    ] __main__: train step 9782: loss: 1.1127, policy_loss: 1.1591, value_loss: 0.7519
2024-07-14 06:01:05,006 [INFO    ] __main__: train step 9783: loss: 1.1127, policy_loss: 1.1590, value_loss: 0.7518
2024-07-14 06:01:05,295 [INFO    ] __main__: train step 9784: loss: 1.1127, policy_loss: 1.1590, value_loss: 0.7518
2024-07-14 06:01:05,599 [INFO    ] __main__: train step 9785: loss: 1.1126, policy_loss: 1.1589, value_loss: 0.7517
2024-07-14 06:01:05,904 [INFO    ] __main__: train step 9786: loss: 1.1126, policy_loss: 1.1589, value_loss: 0.7517
2024-07-14 06:01:06,194 [INFO    ] __main__: train step 9787: loss: 1.1126, policy_loss: 1.1588, value_loss: 0.7516
2024-07-14 06:01:06,490 [INFO    ] __main__: train step 9788: loss: 1.1126, policy_loss: 1.1588, value_loss: 0.7516
2024-07-14 06:01:08,122 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:01:08,613 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:01:08,688 [INFO    ] __main__: train step 9789: loss: 1.1125, policy_loss: 1.1587, value_loss: 0.7515
2024-07-14 06:01:08,967 [INFO    ] __main__: train step 9790: loss: 1.1125, policy_loss: 1.1587, value_loss: 0.7515
2024-07-14 06:01:09,251 [INFO    ] __main__: train step 9791: loss: 1.1125, policy_loss: 1.1586, value_loss: 0.7514
2024-07-14 06:01:09,541 [INFO    ] __main__: train step 9792: loss: 1.1125, policy_loss: 1.1585, value_loss: 0.7514
2024-07-14 06:01:09,835 [INFO    ] __main__: train step 9793: loss: 1.1124, policy_loss: 1.1585, value_loss: 0.7513
2024-07-14 06:01:10,127 [INFO    ] __main__: train step 9794: loss: 1.1124, policy_loss: 1.1584, value_loss: 0.7513
2024-07-14 06:01:10,419 [INFO    ] __main__: train step 9795: loss: 1.1124, policy_loss: 1.1584, value_loss: 0.7512
2024-07-14 06:01:10,709 [INFO    ] __main__: train step 9796: loss: 1.1124, policy_loss: 1.1583, value_loss: 0.7512
2024-07-14 06:01:11,005 [INFO    ] __main__: train step 9797: loss: 1.1124, policy_loss: 1.1583, value_loss: 0.7511
2024-07-14 06:01:11,314 [INFO    ] __main__: train step 9798: loss: 1.1123, policy_loss: 1.1582, value_loss: 0.7511
2024-07-14 06:01:11,598 [INFO    ] __main__: train step 9799: loss: 1.1123, policy_loss: 1.1582, value_loss: 0.7510
2024-07-14 06:01:11,882 [INFO    ] __main__: train step 9800: loss: 1.1123, policy_loss: 1.1581, value_loss: 0.7510
2024-07-14 06:01:12,178 [INFO    ] __main__: train step 9801: loss: 1.1123, policy_loss: 1.1581, value_loss: 0.7509
2024-07-14 06:01:12,477 [INFO    ] __main__: train step 9802: loss: 1.1122, policy_loss: 1.1580, value_loss: 0.7509
2024-07-14 06:01:12,772 [INFO    ] __main__: train step 9803: loss: 1.1122, policy_loss: 1.1579, value_loss: 0.7508
2024-07-14 06:01:13,053 [INFO    ] __main__: train step 9804: loss: 1.1122, policy_loss: 1.1579, value_loss: 0.7508
2024-07-14 06:01:13,347 [INFO    ] __main__: train step 9805: loss: 1.1122, policy_loss: 1.1578, value_loss: 0.7507
2024-07-14 06:01:14,962 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:01:15,451 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:01:15,525 [INFO    ] __main__: train step 9806: loss: 1.1121, policy_loss: 1.1578, value_loss: 0.7507
2024-07-14 06:01:15,806 [INFO    ] __main__: train step 9807: loss: 1.1121, policy_loss: 1.1577, value_loss: 0.7506
2024-07-14 06:01:16,078 [INFO    ] __main__: train step 9808: loss: 1.1121, policy_loss: 1.1577, value_loss: 0.7506
2024-07-14 06:01:16,345 [INFO    ] __main__: train step 9809: loss: 1.1121, policy_loss: 1.1576, value_loss: 0.7505
2024-07-14 06:01:16,621 [INFO    ] __main__: train step 9810: loss: 1.1120, policy_loss: 1.1576, value_loss: 0.7505
2024-07-14 06:01:16,891 [INFO    ] __main__: train step 9811: loss: 1.1120, policy_loss: 1.1575, value_loss: 0.7504
2024-07-14 06:01:17,177 [INFO    ] __main__: train step 9812: loss: 1.1120, policy_loss: 1.1574, value_loss: 0.7504
2024-07-14 06:01:17,454 [INFO    ] __main__: train step 9813: loss: 1.1120, policy_loss: 1.1574, value_loss: 0.7503
2024-07-14 06:01:17,734 [INFO    ] __main__: train step 9814: loss: 1.1119, policy_loss: 1.1573, value_loss: 0.7503
2024-07-14 06:01:18,018 [INFO    ] __main__: train step 9815: loss: 1.1119, policy_loss: 1.1573, value_loss: 0.7502
2024-07-14 06:01:18,319 [INFO    ] __main__: train step 9816: loss: 1.1119, policy_loss: 1.1572, value_loss: 0.7502
2024-07-14 06:01:18,615 [INFO    ] __main__: train step 9817: loss: 1.1119, policy_loss: 1.1572, value_loss: 0.7501
2024-07-14 06:01:18,901 [INFO    ] __main__: train step 9818: loss: 1.1118, policy_loss: 1.1571, value_loss: 0.7501
2024-07-14 06:01:19,192 [INFO    ] __main__: train step 9819: loss: 1.1118, policy_loss: 1.1571, value_loss: 0.7500
2024-07-14 06:01:19,482 [INFO    ] __main__: train step 9820: loss: 1.1118, policy_loss: 1.1570, value_loss: 0.7500
2024-07-14 06:01:19,772 [INFO    ] __main__: train step 9821: loss: 1.1118, policy_loss: 1.1570, value_loss: 0.7499
2024-07-14 06:01:20,069 [INFO    ] __main__: train step 9822: loss: 1.1117, policy_loss: 1.1569, value_loss: 0.7499
2024-07-14 06:01:21,677 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:01:22,175 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:01:22,245 [INFO    ] __main__: train step 9823: loss: 1.1117, policy_loss: 1.1568, value_loss: 0.7498
2024-07-14 06:01:22,534 [INFO    ] __main__: train step 9824: loss: 1.1117, policy_loss: 1.1568, value_loss: 0.7498
2024-07-14 06:01:24,411 [INFO    ] __main__: train step 9825: loss: 1.1117, policy_loss: 1.1567, value_loss: 0.7497
2024-07-14 06:01:24,709 [INFO    ] __main__: train step 9826: loss: 1.1116, policy_loss: 1.1567, value_loss: 0.7497
2024-07-14 06:01:25,009 [INFO    ] __main__: train step 9827: loss: 1.1116, policy_loss: 1.1566, value_loss: 0.7496
2024-07-14 06:01:25,310 [INFO    ] __main__: train step 9828: loss: 1.1116, policy_loss: 1.1566, value_loss: 0.7496
2024-07-14 06:01:25,599 [INFO    ] __main__: train step 9829: loss: 1.1116, policy_loss: 1.1565, value_loss: 0.7495
2024-07-14 06:01:25,898 [INFO    ] __main__: train step 9830: loss: 1.1115, policy_loss: 1.1565, value_loss: 0.7495
2024-07-14 06:01:26,201 [INFO    ] __main__: train step 9831: loss: 1.1115, policy_loss: 1.1564, value_loss: 0.7494
2024-07-14 06:01:26,491 [INFO    ] __main__: train step 9832: loss: 1.1115, policy_loss: 1.1564, value_loss: 0.7494
2024-07-14 06:01:26,814 [INFO    ] __main__: train step 9833: loss: 1.1115, policy_loss: 1.1563, value_loss: 0.7493
2024-07-14 06:01:27,114 [INFO    ] __main__: train step 9834: loss: 1.1114, policy_loss: 1.1562, value_loss: 0.7493
2024-07-14 06:01:27,406 [INFO    ] __main__: train step 9835: loss: 1.1114, policy_loss: 1.1562, value_loss: 0.7492
2024-07-14 06:01:27,706 [INFO    ] __main__: train step 9836: loss: 1.1114, policy_loss: 1.1561, value_loss: 0.7492
2024-07-14 06:01:28,011 [INFO    ] __main__: train step 9837: loss: 1.1114, policy_loss: 1.1561, value_loss: 0.7491
2024-07-14 06:01:28,304 [INFO    ] __main__: train step 9838: loss: 1.1114, policy_loss: 1.1560, value_loss: 0.7491
2024-07-14 06:01:28,587 [INFO    ] __main__: train step 9839: loss: 1.1113, policy_loss: 1.1560, value_loss: 0.7490
2024-07-14 06:01:30,196 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:01:30,683 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:01:30,757 [INFO    ] __main__: train step 9840: loss: 1.1113, policy_loss: 1.1559, value_loss: 0.7489
2024-07-14 06:01:31,030 [INFO    ] __main__: train step 9841: loss: 1.1113, policy_loss: 1.1559, value_loss: 0.7489
2024-07-14 06:01:31,309 [INFO    ] __main__: train step 9842: loss: 1.1113, policy_loss: 1.1558, value_loss: 0.7488
2024-07-14 06:01:31,605 [INFO    ] __main__: train step 9843: loss: 1.1112, policy_loss: 1.1558, value_loss: 0.7488
2024-07-14 06:01:31,896 [INFO    ] __main__: train step 9844: loss: 1.1112, policy_loss: 1.1557, value_loss: 0.7487
2024-07-14 06:01:32,187 [INFO    ] __main__: train step 9845: loss: 1.1112, policy_loss: 1.1556, value_loss: 0.7487
2024-07-14 06:01:32,468 [INFO    ] __main__: train step 9846: loss: 1.1112, policy_loss: 1.1556, value_loss: 0.7486
2024-07-14 06:01:32,769 [INFO    ] __main__: train step 9847: loss: 1.1111, policy_loss: 1.1555, value_loss: 0.7486
2024-07-14 06:01:33,075 [INFO    ] __main__: train step 9848: loss: 1.1111, policy_loss: 1.1555, value_loss: 0.7485
2024-07-14 06:01:33,375 [INFO    ] __main__: train step 9849: loss: 1.1111, policy_loss: 1.1554, value_loss: 0.7485
2024-07-14 06:01:33,666 [INFO    ] __main__: train step 9850: loss: 1.1111, policy_loss: 1.1554, value_loss: 0.7484
2024-07-14 06:01:33,964 [INFO    ] __main__: train step 9851: loss: 1.1110, policy_loss: 1.1553, value_loss: 0.7484
2024-07-14 06:01:34,254 [INFO    ] __main__: train step 9852: loss: 1.1110, policy_loss: 1.1553, value_loss: 0.7483
2024-07-14 06:01:34,529 [INFO    ] __main__: train step 9853: loss: 1.1110, policy_loss: 1.1552, value_loss: 0.7483
2024-07-14 06:01:34,805 [INFO    ] __main__: train step 9854: loss: 1.1110, policy_loss: 1.1552, value_loss: 0.7482
2024-07-14 06:01:35,073 [INFO    ] __main__: train step 9855: loss: 1.1109, policy_loss: 1.1551, value_loss: 0.7482
2024-07-14 06:01:35,351 [INFO    ] __main__: train step 9856: loss: 1.1109, policy_loss: 1.1551, value_loss: 0.7481
2024-07-14 06:01:36,939 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:01:37,420 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:01:37,492 [INFO    ] __main__: train step 9857: loss: 1.1109, policy_loss: 1.1550, value_loss: 0.7481
2024-07-14 06:01:37,824 [INFO    ] __main__: train step 9858: loss: 1.1109, policy_loss: 1.1549, value_loss: 0.7480
2024-07-14 06:01:38,123 [INFO    ] __main__: train step 9859: loss: 1.1108, policy_loss: 1.1549, value_loss: 0.7480
2024-07-14 06:01:38,418 [INFO    ] __main__: train step 9860: loss: 1.1108, policy_loss: 1.1548, value_loss: 0.7479
2024-07-14 06:01:38,711 [INFO    ] __main__: train step 9861: loss: 1.1108, policy_loss: 1.1548, value_loss: 0.7479
2024-07-14 06:01:39,014 [INFO    ] __main__: train step 9862: loss: 1.1108, policy_loss: 1.1547, value_loss: 0.7478
2024-07-14 06:01:39,306 [INFO    ] __main__: train step 9863: loss: 1.1107, policy_loss: 1.1547, value_loss: 0.7478
2024-07-14 06:01:39,595 [INFO    ] __main__: train step 9864: loss: 1.1107, policy_loss: 1.1546, value_loss: 0.7477
2024-07-14 06:01:39,882 [INFO    ] __main__: train step 9865: loss: 1.1107, policy_loss: 1.1546, value_loss: 0.7477
2024-07-14 06:01:40,177 [INFO    ] __main__: train step 9866: loss: 1.1107, policy_loss: 1.1545, value_loss: 0.7476
2024-07-14 06:01:40,474 [INFO    ] __main__: train step 9867: loss: 1.1106, policy_loss: 1.1545, value_loss: 0.7476
2024-07-14 06:01:40,764 [INFO    ] __main__: train step 9868: loss: 1.1106, policy_loss: 1.1544, value_loss: 0.7475
2024-07-14 06:01:41,052 [INFO    ] __main__: train step 9869: loss: 1.1106, policy_loss: 1.1544, value_loss: 0.7475
2024-07-14 06:01:41,356 [INFO    ] __main__: train step 9870: loss: 1.1106, policy_loss: 1.1543, value_loss: 0.7474
2024-07-14 06:01:41,646 [INFO    ] __main__: train step 9871: loss: 1.1106, policy_loss: 1.1543, value_loss: 0.7474
2024-07-14 06:01:41,940 [INFO    ] __main__: train step 9872: loss: 1.1105, policy_loss: 1.1542, value_loss: 0.7473
2024-07-14 06:01:42,239 [INFO    ] __main__: train step 9873: loss: 1.1105, policy_loss: 1.1541, value_loss: 0.7473
2024-07-14 06:01:43,868 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:01:44,344 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:01:44,414 [INFO    ] __main__: train step 9874: loss: 1.1105, policy_loss: 1.1541, value_loss: 0.7472
2024-07-14 06:01:44,705 [INFO    ] __main__: train step 9875: loss: 1.1105, policy_loss: 1.1540, value_loss: 0.7472
2024-07-14 06:01:44,984 [INFO    ] __main__: train step 9876: loss: 1.1104, policy_loss: 1.1540, value_loss: 0.7471
2024-07-14 06:01:45,279 [INFO    ] __main__: train step 9877: loss: 1.1104, policy_loss: 1.1539, value_loss: 0.7471
2024-07-14 06:01:45,566 [INFO    ] __main__: train step 9878: loss: 1.1104, policy_loss: 1.1539, value_loss: 0.7470
2024-07-14 06:01:45,862 [INFO    ] __main__: train step 9879: loss: 1.1104, policy_loss: 1.1538, value_loss: 0.7470
2024-07-14 06:01:47,681 [INFO    ] __main__: train step 9880: loss: 1.1104, policy_loss: 1.1538, value_loss: 0.7469
2024-07-14 06:01:47,977 [INFO    ] __main__: train step 9881: loss: 1.1103, policy_loss: 1.1537, value_loss: 0.7469
2024-07-14 06:01:48,273 [INFO    ] __main__: train step 9882: loss: 1.1103, policy_loss: 1.1537, value_loss: 0.7468
2024-07-14 06:01:48,561 [INFO    ] __main__: train step 9883: loss: 1.1103, policy_loss: 1.1536, value_loss: 0.7468
2024-07-14 06:01:48,855 [INFO    ] __main__: train step 9884: loss: 1.1103, policy_loss: 1.1536, value_loss: 0.7467
2024-07-14 06:01:49,154 [INFO    ] __main__: train step 9885: loss: 1.1102, policy_loss: 1.1535, value_loss: 0.7467
2024-07-14 06:01:49,442 [INFO    ] __main__: train step 9886: loss: 1.1102, policy_loss: 1.1535, value_loss: 0.7466
2024-07-14 06:01:49,747 [INFO    ] __main__: train step 9887: loss: 1.1102, policy_loss: 1.1534, value_loss: 0.7466
2024-07-14 06:01:50,040 [INFO    ] __main__: train step 9888: loss: 1.1102, policy_loss: 1.1534, value_loss: 0.7465
2024-07-14 06:01:50,309 [INFO    ] __main__: train step 9889: loss: 1.1101, policy_loss: 1.1533, value_loss: 0.7465
2024-07-14 06:01:50,627 [INFO    ] __main__: train step 9890: loss: 1.1101, policy_loss: 1.1532, value_loss: 0.7464
2024-07-14 06:01:52,225 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:01:52,715 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:01:52,786 [INFO    ] __main__: train step 9891: loss: 1.1101, policy_loss: 1.1532, value_loss: 0.7464
2024-07-14 06:01:53,081 [INFO    ] __main__: train step 9892: loss: 1.1101, policy_loss: 1.1531, value_loss: 0.7463
2024-07-14 06:01:53,383 [INFO    ] __main__: train step 9893: loss: 1.1100, policy_loss: 1.1531, value_loss: 0.7463
2024-07-14 06:01:53,659 [INFO    ] __main__: train step 9894: loss: 1.1100, policy_loss: 1.1530, value_loss: 0.7462
2024-07-14 06:01:53,945 [INFO    ] __main__: train step 9895: loss: 1.1100, policy_loss: 1.1530, value_loss: 0.7462
2024-07-14 06:01:54,243 [INFO    ] __main__: train step 9896: loss: 1.1100, policy_loss: 1.1529, value_loss: 0.7461
2024-07-14 06:01:54,537 [INFO    ] __main__: train step 9897: loss: 1.1099, policy_loss: 1.1529, value_loss: 0.7461
2024-07-14 06:01:54,842 [INFO    ] __main__: train step 9898: loss: 1.1099, policy_loss: 1.1528, value_loss: 0.7460
2024-07-14 06:01:55,139 [INFO    ] __main__: train step 9899: loss: 1.1099, policy_loss: 1.1528, value_loss: 0.7460
2024-07-14 06:01:55,438 [INFO    ] __main__: train step 9900: loss: 1.1099, policy_loss: 1.1527, value_loss: 0.7459
2024-07-14 06:01:55,737 [INFO    ] __main__: train step 9901: loss: 1.1098, policy_loss: 1.1527, value_loss: 0.7459
2024-07-14 06:01:56,038 [INFO    ] __main__: train step 9902: loss: 1.1098, policy_loss: 1.1526, value_loss: 0.7458
2024-07-14 06:01:56,327 [INFO    ] __main__: train step 9903: loss: 1.1098, policy_loss: 1.1526, value_loss: 0.7457
2024-07-14 06:01:56,622 [INFO    ] __main__: train step 9904: loss: 1.1098, policy_loss: 1.1525, value_loss: 0.7457
2024-07-14 06:01:56,916 [INFO    ] __main__: train step 9905: loss: 1.1097, policy_loss: 1.1525, value_loss: 0.7456
2024-07-14 06:01:57,213 [INFO    ] __main__: train step 9906: loss: 1.1097, policy_loss: 1.1524, value_loss: 0.7456
2024-07-14 06:01:57,504 [INFO    ] __main__: train step 9907: loss: 1.1097, policy_loss: 1.1523, value_loss: 0.7455
2024-07-14 06:01:59,132 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:01:59,627 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:01:59,697 [INFO    ] __main__: train step 9908: loss: 1.1097, policy_loss: 1.1523, value_loss: 0.7455
2024-07-14 06:01:59,979 [INFO    ] __main__: train step 9909: loss: 1.1096, policy_loss: 1.1522, value_loss: 0.7454
2024-07-14 06:02:00,274 [INFO    ] __main__: train step 9910: loss: 1.1096, policy_loss: 1.1522, value_loss: 0.7454
2024-07-14 06:02:00,600 [INFO    ] __main__: train step 9911: loss: 1.1096, policy_loss: 1.1521, value_loss: 0.7453
2024-07-14 06:02:00,891 [INFO    ] __main__: train step 9912: loss: 1.1096, policy_loss: 1.1521, value_loss: 0.7453
2024-07-14 06:02:01,182 [INFO    ] __main__: train step 9913: loss: 1.1095, policy_loss: 1.1520, value_loss: 0.7452
2024-07-14 06:02:01,476 [INFO    ] __main__: train step 9914: loss: 1.1095, policy_loss: 1.1520, value_loss: 0.7452
2024-07-14 06:02:01,772 [INFO    ] __main__: train step 9915: loss: 1.1095, policy_loss: 1.1519, value_loss: 0.7451
2024-07-14 06:02:02,078 [INFO    ] __main__: train step 9916: loss: 1.1095, policy_loss: 1.1519, value_loss: 0.7451
2024-07-14 06:02:02,364 [INFO    ] __main__: train step 9917: loss: 1.1094, policy_loss: 1.1518, value_loss: 0.7450
2024-07-14 06:02:02,657 [INFO    ] __main__: train step 9918: loss: 1.1094, policy_loss: 1.1518, value_loss: 0.7450
2024-07-14 06:02:02,942 [INFO    ] __main__: train step 9919: loss: 1.1094, policy_loss: 1.1517, value_loss: 0.7449
2024-07-14 06:02:03,239 [INFO    ] __main__: train step 9920: loss: 1.1094, policy_loss: 1.1517, value_loss: 0.7449
2024-07-14 06:02:03,533 [INFO    ] __main__: train step 9921: loss: 1.1094, policy_loss: 1.1516, value_loss: 0.7448
2024-07-14 06:02:03,819 [INFO    ] __main__: train step 9922: loss: 1.1093, policy_loss: 1.1516, value_loss: 0.7448
2024-07-14 06:02:04,104 [INFO    ] __main__: train step 9923: loss: 1.1093, policy_loss: 1.1515, value_loss: 0.7447
2024-07-14 06:02:04,392 [INFO    ] __main__: train step 9924: loss: 1.1093, policy_loss: 1.1515, value_loss: 0.7447
2024-07-14 06:02:06,023 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:02:06,511 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:02:06,584 [INFO    ] __main__: train step 9925: loss: 1.1093, policy_loss: 1.1514, value_loss: 0.7446
2024-07-14 06:02:06,898 [INFO    ] __main__: train step 9926: loss: 1.1092, policy_loss: 1.1513, value_loss: 0.7446
2024-07-14 06:02:07,191 [INFO    ] __main__: train step 9927: loss: 1.1092, policy_loss: 1.1513, value_loss: 0.7445
2024-07-14 06:02:07,474 [INFO    ] __main__: train step 9928: loss: 1.1092, policy_loss: 1.1512, value_loss: 0.7445
2024-07-14 06:02:07,775 [INFO    ] __main__: train step 9929: loss: 1.1092, policy_loss: 1.1512, value_loss: 0.7444
2024-07-14 06:02:08,064 [INFO    ] __main__: train step 9930: loss: 1.1091, policy_loss: 1.1511, value_loss: 0.7444
2024-07-14 06:02:08,365 [INFO    ] __main__: train step 9931: loss: 1.1091, policy_loss: 1.1511, value_loss: 0.7443
2024-07-14 06:02:08,659 [INFO    ] __main__: train step 9932: loss: 1.1091, policy_loss: 1.1510, value_loss: 0.7443
2024-07-14 06:02:08,954 [INFO    ] __main__: train step 9933: loss: 1.1091, policy_loss: 1.1510, value_loss: 0.7442
2024-07-14 06:02:10,830 [INFO    ] __main__: train step 9934: loss: 1.1090, policy_loss: 1.1509, value_loss: 0.7442
2024-07-14 06:02:11,119 [INFO    ] __main__: train step 9935: loss: 1.1090, policy_loss: 1.1509, value_loss: 0.7441
2024-07-14 06:02:11,420 [INFO    ] __main__: train step 9936: loss: 1.1090, policy_loss: 1.1508, value_loss: 0.7441
2024-07-14 06:02:11,711 [INFO    ] __main__: train step 9937: loss: 1.1090, policy_loss: 1.1508, value_loss: 0.7440
2024-07-14 06:02:12,007 [INFO    ] __main__: train step 9938: loss: 1.1089, policy_loss: 1.1507, value_loss: 0.7440
2024-07-14 06:02:12,304 [INFO    ] __main__: train step 9939: loss: 1.1089, policy_loss: 1.1507, value_loss: 0.7439
2024-07-14 06:02:12,599 [INFO    ] __main__: train step 9940: loss: 1.1089, policy_loss: 1.1506, value_loss: 0.7438
2024-07-14 06:02:12,904 [INFO    ] __main__: train step 9941: loss: 1.1089, policy_loss: 1.1506, value_loss: 0.7438
2024-07-14 06:02:14,533 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:02:15,008 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:02:15,080 [INFO    ] __main__: train step 9942: loss: 1.1088, policy_loss: 1.1505, value_loss: 0.7437
2024-07-14 06:02:15,386 [INFO    ] __main__: train step 9943: loss: 1.1088, policy_loss: 1.1505, value_loss: 0.7437
2024-07-14 06:02:15,677 [INFO    ] __main__: train step 9944: loss: 1.1088, policy_loss: 1.1504, value_loss: 0.7436
2024-07-14 06:02:15,964 [INFO    ] __main__: train step 9945: loss: 1.1088, policy_loss: 1.1504, value_loss: 0.7436
2024-07-14 06:02:16,249 [INFO    ] __main__: train step 9946: loss: 1.1087, policy_loss: 1.1503, value_loss: 0.7435
2024-07-14 06:02:16,534 [INFO    ] __main__: train step 9947: loss: 1.1087, policy_loss: 1.1503, value_loss: 0.7435
2024-07-14 06:02:16,841 [INFO    ] __main__: train step 9948: loss: 1.1087, policy_loss: 1.1502, value_loss: 0.7434
2024-07-14 06:02:17,140 [INFO    ] __main__: train step 9949: loss: 1.1087, policy_loss: 1.1502, value_loss: 0.7434
2024-07-14 06:02:17,431 [INFO    ] __main__: train step 9950: loss: 1.1086, policy_loss: 1.1501, value_loss: 0.7433
2024-07-14 06:02:17,723 [INFO    ] __main__: train step 9951: loss: 1.1086, policy_loss: 1.1501, value_loss: 0.7433
2024-07-14 06:02:18,020 [INFO    ] __main__: train step 9952: loss: 1.1086, policy_loss: 1.1500, value_loss: 0.7432
2024-07-14 06:02:18,314 [INFO    ] __main__: train step 9953: loss: 1.1086, policy_loss: 1.1500, value_loss: 0.7432
2024-07-14 06:02:18,593 [INFO    ] __main__: train step 9954: loss: 1.1086, policy_loss: 1.1499, value_loss: 0.7431
2024-07-14 06:02:18,883 [INFO    ] __main__: train step 9955: loss: 1.1085, policy_loss: 1.1499, value_loss: 0.7431
2024-07-14 06:02:19,170 [INFO    ] __main__: train step 9956: loss: 1.1085, policy_loss: 1.1498, value_loss: 0.7430
2024-07-14 06:02:19,469 [INFO    ] __main__: train step 9957: loss: 1.1085, policy_loss: 1.1497, value_loss: 0.7430
2024-07-14 06:02:19,765 [INFO    ] __main__: train step 9958: loss: 1.1085, policy_loss: 1.1497, value_loss: 0.7429
2024-07-14 06:02:21,375 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:02:21,860 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:02:21,928 [INFO    ] __main__: train step 9959: loss: 1.1084, policy_loss: 1.1496, value_loss: 0.7429
2024-07-14 06:02:22,214 [INFO    ] __main__: train step 9960: loss: 1.1084, policy_loss: 1.1496, value_loss: 0.7428
2024-07-14 06:02:22,508 [INFO    ] __main__: train step 9961: loss: 1.1084, policy_loss: 1.1495, value_loss: 0.7428
2024-07-14 06:02:22,799 [INFO    ] __main__: train step 9962: loss: 1.1084, policy_loss: 1.1495, value_loss: 0.7427
2024-07-14 06:02:23,093 [INFO    ] __main__: train step 9963: loss: 1.1084, policy_loss: 1.1494, value_loss: 0.7427
2024-07-14 06:02:23,407 [INFO    ] __main__: train step 9964: loss: 1.1083, policy_loss: 1.1494, value_loss: 0.7426
2024-07-14 06:02:23,703 [INFO    ] __main__: train step 9965: loss: 1.1083, policy_loss: 1.1493, value_loss: 0.7426
2024-07-14 06:02:24,008 [INFO    ] __main__: train step 9966: loss: 1.1083, policy_loss: 1.1493, value_loss: 0.7425
2024-07-14 06:02:24,313 [INFO    ] __main__: train step 9967: loss: 1.1083, policy_loss: 1.1492, value_loss: 0.7425
2024-07-14 06:02:24,616 [INFO    ] __main__: train step 9968: loss: 1.1082, policy_loss: 1.1492, value_loss: 0.7424
2024-07-14 06:02:24,910 [INFO    ] __main__: train step 9969: loss: 1.1082, policy_loss: 1.1491, value_loss: 0.7424
2024-07-14 06:02:25,207 [INFO    ] __main__: train step 9970: loss: 1.1082, policy_loss: 1.1491, value_loss: 0.7423
2024-07-14 06:02:25,502 [INFO    ] __main__: train step 9971: loss: 1.1082, policy_loss: 1.1490, value_loss: 0.7423
2024-07-14 06:02:25,805 [INFO    ] __main__: train step 9972: loss: 1.1081, policy_loss: 1.1490, value_loss: 0.7422
2024-07-14 06:02:26,091 [INFO    ] __main__: train step 9973: loss: 1.1081, policy_loss: 1.1489, value_loss: 0.7422
2024-07-14 06:02:26,380 [INFO    ] __main__: train step 9974: loss: 1.1081, policy_loss: 1.1489, value_loss: 0.7421
2024-07-14 06:02:26,678 [INFO    ] __main__: train step 9975: loss: 1.1081, policy_loss: 1.1488, value_loss: 0.7421
2024-07-14 06:02:28,305 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:02:28,794 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:02:28,865 [INFO    ] __main__: train step 9976: loss: 1.1081, policy_loss: 1.1488, value_loss: 0.7420
2024-07-14 06:02:29,159 [INFO    ] __main__: train step 9977: loss: 1.1080, policy_loss: 1.1487, value_loss: 0.7420
2024-07-14 06:02:29,446 [INFO    ] __main__: train step 9978: loss: 1.1080, policy_loss: 1.1487, value_loss: 0.7419
2024-07-14 06:02:29,740 [INFO    ] __main__: train step 9979: loss: 1.1080, policy_loss: 1.1486, value_loss: 0.7419
2024-07-14 06:02:30,033 [INFO    ] __main__: train step 9980: loss: 1.1080, policy_loss: 1.1486, value_loss: 0.7418
2024-07-14 06:02:30,336 [INFO    ] __main__: train step 9981: loss: 1.1079, policy_loss: 1.1485, value_loss: 0.7418
2024-07-14 06:02:30,628 [INFO    ] __main__: train step 9982: loss: 1.1079, policy_loss: 1.1485, value_loss: 0.7417
2024-07-14 06:02:30,931 [INFO    ] __main__: train step 9983: loss: 1.1079, policy_loss: 1.1484, value_loss: 0.7417
2024-07-14 06:02:31,227 [INFO    ] __main__: train step 9984: loss: 1.1079, policy_loss: 1.1484, value_loss: 0.7416
2024-07-14 06:02:31,510 [INFO    ] __main__: train step 9985: loss: 1.1079, policy_loss: 1.1483, value_loss: 0.7416
2024-07-14 06:02:31,812 [INFO    ] __main__: train step 9986: loss: 1.1078, policy_loss: 1.1483, value_loss: 0.7415
2024-07-14 06:02:32,114 [INFO    ] __main__: train step 9987: loss: 1.1078, policy_loss: 1.1482, value_loss: 0.7415
2024-07-14 06:02:32,412 [INFO    ] __main__: train step 9988: loss: 1.1078, policy_loss: 1.1482, value_loss: 0.7414
2024-07-14 06:02:34,241 [INFO    ] __main__: train step 9989: loss: 1.1078, policy_loss: 1.1481, value_loss: 0.7414
2024-07-14 06:02:34,534 [INFO    ] __main__: train step 9990: loss: 1.1077, policy_loss: 1.1481, value_loss: 0.7413
2024-07-14 06:02:34,836 [INFO    ] __main__: train step 9991: loss: 1.1077, policy_loss: 1.1480, value_loss: 0.7413
2024-07-14 06:02:35,137 [INFO    ] __main__: train step 9992: loss: 1.1077, policy_loss: 1.1480, value_loss: 0.7412
2024-07-14 06:02:36,746 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:02:37,241 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:02:37,311 [INFO    ] __main__: train step 9993: loss: 1.1077, policy_loss: 1.1479, value_loss: 0.7412
2024-07-14 06:02:37,610 [INFO    ] __main__: train step 9994: loss: 1.1077, policy_loss: 1.1479, value_loss: 0.7411
2024-07-14 06:02:37,919 [INFO    ] __main__: train step 9995: loss: 1.1076, policy_loss: 1.1478, value_loss: 0.7411
2024-07-14 06:02:38,219 [INFO    ] __main__: train step 9996: loss: 1.1076, policy_loss: 1.1478, value_loss: 0.7410
2024-07-14 06:02:38,514 [INFO    ] __main__: train step 9997: loss: 1.1076, policy_loss: 1.1477, value_loss: 0.7410
2024-07-14 06:02:38,824 [INFO    ] __main__: train step 9998: loss: 1.1076, policy_loss: 1.1477, value_loss: 0.7409
2024-07-14 06:02:39,129 [INFO    ] __main__: train step 9999: loss: 1.1076, policy_loss: 1.1476, value_loss: 0.7409
2024-07-14 06:02:39,429 [INFO    ] __main__: train step 10000: loss: 1.1075, policy_loss: 1.1476, value_loss: 0.7408
2024-07-14 06:02:39,595 [INFO    ] __main__: restored step 9000 for evaluation
2024-07-14 06:02:44,840 [INFO    ] __main__: test network ELO difference from baseline network: +190 (+8/-8) ELO from 32000 self-played games
2024-07-14 06:02:44,842 [INFO    ] __main__: game outcomes: W: 22462, D: 1063, L: 8475
2024-07-14 06:02:44,845 [INFO    ] __main__: validation_elo_delta: 190, validation_elo: 2170
2024-07-14 06:02:45,314 [INFO    ] __main__: running self-play game for SVG generation
2024-07-14 06:05:11,633 [INFO    ] __main__: saved self-play game in animations/run2_armageddon/10000.svg
2024-07-14 06:05:11,909 [INFO    ] __main__: train step 10001: loss: 1.1075, policy_loss: 1.1475, value_loss: 0.7408
2024-07-14 06:05:12,191 [INFO    ] __main__: train step 10002: loss: 1.1075, policy_loss: 1.1475, value_loss: 0.7407
2024-07-14 06:05:12,470 [INFO    ] __main__: train step 10003: loss: 1.1075, policy_loss: 1.1474, value_loss: 0.7407
2024-07-14 06:05:12,744 [INFO    ] __main__: train step 10004: loss: 1.1074, policy_loss: 1.1474, value_loss: 0.7406
2024-07-14 06:05:13,023 [INFO    ] __main__: train step 10005: loss: 1.1074, policy_loss: 1.1473, value_loss: 0.7406
2024-07-14 06:05:13,302 [INFO    ] __main__: train step 10006: loss: 1.1074, policy_loss: 1.1473, value_loss: 0.7405
2024-07-14 06:05:13,580 [INFO    ] __main__: train step 10007: loss: 1.1074, policy_loss: 1.1472, value_loss: 0.7405
2024-07-14 06:05:13,846 [INFO    ] __main__: train step 10008: loss: 1.1074, policy_loss: 1.1472, value_loss: 0.7404
2024-07-14 06:05:14,118 [INFO    ] __main__: train step 10009: loss: 1.1073, policy_loss: 1.1471, value_loss: 0.7404
2024-07-14 06:05:15,733 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:05:16,232 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:05:16,301 [INFO    ] __main__: train step 10010: loss: 1.1073, policy_loss: 1.1471, value_loss: 0.7403
2024-07-14 06:05:16,592 [INFO    ] __main__: train step 10011: loss: 1.1073, policy_loss: 1.1470, value_loss: 0.7403
2024-07-14 06:05:16,869 [INFO    ] __main__: train step 10012: loss: 1.1073, policy_loss: 1.1470, value_loss: 0.7402
2024-07-14 06:05:17,150 [INFO    ] __main__: train step 10013: loss: 1.1072, policy_loss: 1.1469, value_loss: 0.7402
2024-07-14 06:05:17,433 [INFO    ] __main__: train step 10014: loss: 1.1072, policy_loss: 1.1469, value_loss: 0.7401
2024-07-14 06:05:17,723 [INFO    ] __main__: train step 10015: loss: 1.1072, policy_loss: 1.1468, value_loss: 0.7401
2024-07-14 06:05:18,029 [INFO    ] __main__: train step 10016: loss: 1.1072, policy_loss: 1.1468, value_loss: 0.7400
2024-07-14 06:05:18,340 [INFO    ] __main__: train step 10017: loss: 1.1072, policy_loss: 1.1467, value_loss: 0.7400
2024-07-14 06:05:18,638 [INFO    ] __main__: train step 10018: loss: 1.1071, policy_loss: 1.1467, value_loss: 0.7399
2024-07-14 06:05:18,926 [INFO    ] __main__: train step 10019: loss: 1.1071, policy_loss: 1.1466, value_loss: 0.7399
2024-07-14 06:05:19,203 [INFO    ] __main__: train step 10020: loss: 1.1071, policy_loss: 1.1466, value_loss: 0.7398
2024-07-14 06:05:19,489 [INFO    ] __main__: train step 10021: loss: 1.1071, policy_loss: 1.1465, value_loss: 0.7398
2024-07-14 06:05:19,769 [INFO    ] __main__: train step 10022: loss: 1.1071, policy_loss: 1.1465, value_loss: 0.7397
2024-07-14 06:05:20,050 [INFO    ] __main__: train step 10023: loss: 1.1070, policy_loss: 1.1464, value_loss: 0.7397
2024-07-14 06:05:20,310 [INFO    ] __main__: train step 10024: loss: 1.1070, policy_loss: 1.1464, value_loss: 0.7396
2024-07-14 06:05:20,584 [INFO    ] __main__: train step 10025: loss: 1.1070, policy_loss: 1.1463, value_loss: 0.7396
2024-07-14 06:05:20,865 [INFO    ] __main__: train step 10026: loss: 1.1070, policy_loss: 1.1463, value_loss: 0.7395
2024-07-14 06:05:22,477 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:05:22,966 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:05:23,033 [INFO    ] __main__: train step 10027: loss: 1.1069, policy_loss: 1.1462, value_loss: 0.7395
2024-07-14 06:05:23,319 [INFO    ] __main__: train step 10028: loss: 1.1069, policy_loss: 1.1462, value_loss: 0.7394
2024-07-14 06:05:23,596 [INFO    ] __main__: train step 10029: loss: 1.1069, policy_loss: 1.1461, value_loss: 0.7394
2024-07-14 06:05:23,884 [INFO    ] __main__: train step 10030: loss: 1.1069, policy_loss: 1.1461, value_loss: 0.7393
2024-07-14 06:05:24,166 [INFO    ] __main__: train step 10031: loss: 1.1069, policy_loss: 1.1461, value_loss: 0.7393
2024-07-14 06:05:24,465 [INFO    ] __main__: train step 10032: loss: 1.1068, policy_loss: 1.1460, value_loss: 0.7392
2024-07-14 06:05:24,752 [INFO    ] __main__: train step 10033: loss: 1.1068, policy_loss: 1.1460, value_loss: 0.7392
2024-07-14 06:05:25,034 [INFO    ] __main__: train step 10034: loss: 1.1068, policy_loss: 1.1459, value_loss: 0.7391
2024-07-14 06:05:25,307 [INFO    ] __main__: train step 10035: loss: 1.1068, policy_loss: 1.1459, value_loss: 0.7391
2024-07-14 06:05:25,596 [INFO    ] __main__: train step 10036: loss: 1.1068, policy_loss: 1.1458, value_loss: 0.7390
2024-07-14 06:05:25,879 [INFO    ] __main__: train step 10037: loss: 1.1067, policy_loss: 1.1458, value_loss: 0.7390
2024-07-14 06:05:26,166 [INFO    ] __main__: train step 10038: loss: 1.1067, policy_loss: 1.1457, value_loss: 0.7389
2024-07-14 06:05:26,455 [INFO    ] __main__: train step 10039: loss: 1.1067, policy_loss: 1.1457, value_loss: 0.7389
2024-07-14 06:05:26,765 [INFO    ] __main__: train step 10040: loss: 1.1067, policy_loss: 1.1456, value_loss: 0.7388
2024-07-14 06:05:27,055 [INFO    ] __main__: train step 10041: loss: 1.1067, policy_loss: 1.1456, value_loss: 0.7388
2024-07-14 06:05:27,345 [INFO    ] __main__: train step 10042: loss: 1.1066, policy_loss: 1.1455, value_loss: 0.7387
2024-07-14 06:05:27,631 [INFO    ] __main__: train step 10043: loss: 1.1066, policy_loss: 1.1455, value_loss: 0.7387
2024-07-14 06:05:29,259 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:05:29,755 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:05:29,826 [INFO    ] __main__: train step 10044: loss: 1.1066, policy_loss: 1.1454, value_loss: 0.7386
2024-07-14 06:05:30,115 [INFO    ] __main__: train step 10045: loss: 1.1066, policy_loss: 1.1454, value_loss: 0.7386
2024-07-14 06:05:30,398 [INFO    ] __main__: train step 10046: loss: 1.1066, policy_loss: 1.1453, value_loss: 0.7385
2024-07-14 06:05:30,690 [INFO    ] __main__: train step 10047: loss: 1.1065, policy_loss: 1.1453, value_loss: 0.7385
2024-07-14 06:05:30,977 [INFO    ] __main__: train step 10048: loss: 1.1065, policy_loss: 1.1452, value_loss: 0.7384
2024-07-14 06:05:31,257 [INFO    ] __main__: train step 10049: loss: 1.1065, policy_loss: 1.1452, value_loss: 0.7384
2024-07-14 06:05:31,542 [INFO    ] __main__: train step 10050: loss: 1.1065, policy_loss: 1.1451, value_loss: 0.7383
2024-07-14 06:05:31,832 [INFO    ] __main__: train step 10051: loss: 1.1065, policy_loss: 1.1451, value_loss: 0.7383
2024-07-14 06:05:32,137 [INFO    ] __main__: train step 10052: loss: 1.1064, policy_loss: 1.1450, value_loss: 0.7382
2024-07-14 06:05:32,428 [INFO    ] __main__: train step 10053: loss: 1.1064, policy_loss: 1.1450, value_loss: 0.7382
2024-07-14 06:05:32,723 [INFO    ] __main__: train step 10054: loss: 1.1064, policy_loss: 1.1449, value_loss: 0.7381
2024-07-14 06:05:33,014 [INFO    ] __main__: train step 10055: loss: 1.1064, policy_loss: 1.1449, value_loss: 0.7381
2024-07-14 06:05:33,305 [INFO    ] __main__: train step 10056: loss: 1.1064, policy_loss: 1.1448, value_loss: 0.7380
2024-07-14 06:05:33,585 [INFO    ] __main__: train step 10057: loss: 1.1063, policy_loss: 1.1448, value_loss: 0.7380
2024-07-14 06:05:33,871 [INFO    ] __main__: train step 10058: loss: 1.1063, policy_loss: 1.1447, value_loss: 0.7379
2024-07-14 06:05:34,158 [INFO    ] __main__: train step 10059: loss: 1.1063, policy_loss: 1.1447, value_loss: 0.7379
2024-07-14 06:05:34,451 [INFO    ] __main__: train step 10060: loss: 1.1063, policy_loss: 1.1446, value_loss: 0.7378
2024-07-14 06:05:36,075 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:05:36,565 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:05:36,636 [INFO    ] __main__: train step 10061: loss: 1.1063, policy_loss: 1.1446, value_loss: 0.7378
2024-07-14 06:05:36,928 [INFO    ] __main__: train step 10062: loss: 1.1062, policy_loss: 1.1445, value_loss: 0.7377
2024-07-14 06:05:37,222 [INFO    ] __main__: train step 10063: loss: 1.1062, policy_loss: 1.1445, value_loss: 0.7377
2024-07-14 06:05:37,480 [INFO    ] __main__: train step 10064: loss: 1.1062, policy_loss: 1.1445, value_loss: 0.7376
2024-07-14 06:05:37,764 [INFO    ] __main__: train step 10065: loss: 1.1062, policy_loss: 1.1444, value_loss: 0.7376
2024-07-14 06:05:38,042 [INFO    ] __main__: train step 10066: loss: 1.1062, policy_loss: 1.1444, value_loss: 0.7375
2024-07-14 06:05:38,320 [INFO    ] __main__: train step 10067: loss: 1.1061, policy_loss: 1.1443, value_loss: 0.7375
2024-07-14 06:05:41,321 [INFO    ] __main__: train step 10068: loss: 1.1061, policy_loss: 1.1443, value_loss: 0.7374
2024-07-14 06:05:41,602 [INFO    ] __main__: train step 10069: loss: 1.1061, policy_loss: 1.1442, value_loss: 0.7374
2024-07-14 06:05:41,886 [INFO    ] __main__: train step 10070: loss: 1.1061, policy_loss: 1.1442, value_loss: 0.7373
2024-07-14 06:05:42,177 [INFO    ] __main__: train step 10071: loss: 1.1060, policy_loss: 1.1441, value_loss: 0.7373
2024-07-14 06:05:42,470 [INFO    ] __main__: train step 10072: loss: 1.1060, policy_loss: 1.1441, value_loss: 0.7372
2024-07-14 06:05:42,757 [INFO    ] __main__: train step 10073: loss: 1.1060, policy_loss: 1.1440, value_loss: 0.7372
2024-07-14 06:05:43,051 [INFO    ] __main__: train step 10074: loss: 1.1060, policy_loss: 1.1440, value_loss: 0.7372
2024-07-14 06:05:43,358 [INFO    ] __main__: train step 10075: loss: 1.1060, policy_loss: 1.1439, value_loss: 0.7371
2024-07-14 06:05:43,651 [INFO    ] __main__: train step 10076: loss: 1.1060, policy_loss: 1.1439, value_loss: 0.7371
2024-07-14 06:05:43,942 [INFO    ] __main__: train step 10077: loss: 1.1059, policy_loss: 1.1438, value_loss: 0.7370
2024-07-14 06:05:45,533 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:05:46,028 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:05:46,101 [INFO    ] __main__: train step 10078: loss: 1.1059, policy_loss: 1.1438, value_loss: 0.7370
2024-07-14 06:05:46,386 [INFO    ] __main__: train step 10079: loss: 1.1059, policy_loss: 1.1437, value_loss: 0.7369
2024-07-14 06:05:46,670 [INFO    ] __main__: train step 10080: loss: 1.1059, policy_loss: 1.1437, value_loss: 0.7369
2024-07-14 06:05:46,952 [INFO    ] __main__: train step 10081: loss: 1.1059, policy_loss: 1.1436, value_loss: 0.7368
2024-07-14 06:05:47,224 [INFO    ] __main__: train step 10082: loss: 1.1058, policy_loss: 1.1436, value_loss: 0.7368
2024-07-14 06:05:47,517 [INFO    ] __main__: train step 10083: loss: 1.1058, policy_loss: 1.1435, value_loss: 0.7367
2024-07-14 06:05:47,815 [INFO    ] __main__: train step 10084: loss: 1.1058, policy_loss: 1.1435, value_loss: 0.7367
2024-07-14 06:05:48,105 [INFO    ] __main__: train step 10085: loss: 1.1058, policy_loss: 1.1435, value_loss: 0.7366
2024-07-14 06:05:48,394 [INFO    ] __main__: train step 10086: loss: 1.1058, policy_loss: 1.1434, value_loss: 0.7366
2024-07-14 06:05:48,692 [INFO    ] __main__: train step 10087: loss: 1.1057, policy_loss: 1.1434, value_loss: 0.7365
2024-07-14 06:05:48,983 [INFO    ] __main__: train step 10088: loss: 1.1057, policy_loss: 1.1433, value_loss: 0.7365
2024-07-14 06:05:49,260 [INFO    ] __main__: train step 10089: loss: 1.1057, policy_loss: 1.1433, value_loss: 0.7364
2024-07-14 06:05:49,561 [INFO    ] __main__: train step 10090: loss: 1.1057, policy_loss: 1.1432, value_loss: 0.7364
2024-07-14 06:05:49,862 [INFO    ] __main__: train step 10091: loss: 1.1057, policy_loss: 1.1432, value_loss: 0.7363
2024-07-14 06:05:50,147 [INFO    ] __main__: train step 10092: loss: 1.1056, policy_loss: 1.1431, value_loss: 0.7363
2024-07-14 06:05:50,433 [INFO    ] __main__: train step 10093: loss: 1.1056, policy_loss: 1.1431, value_loss: 0.7362
2024-07-14 06:05:50,728 [INFO    ] __main__: train step 10094: loss: 1.1056, policy_loss: 1.1430, value_loss: 0.7362
2024-07-14 06:05:52,353 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:05:52,839 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:05:52,914 [INFO    ] __main__: train step 10095: loss: 1.1056, policy_loss: 1.1430, value_loss: 0.7361
2024-07-14 06:05:53,210 [INFO    ] __main__: train step 10096: loss: 1.1056, policy_loss: 1.1429, value_loss: 0.7361
2024-07-14 06:05:53,502 [INFO    ] __main__: train step 10097: loss: 1.1055, policy_loss: 1.1429, value_loss: 0.7360
2024-07-14 06:05:53,821 [INFO    ] __main__: train step 10098: loss: 1.1055, policy_loss: 1.1428, value_loss: 0.7360
2024-07-14 06:05:54,122 [INFO    ] __main__: train step 10099: loss: 1.1055, policy_loss: 1.1428, value_loss: 0.7359
2024-07-14 06:05:54,416 [INFO    ] __main__: train step 10100: loss: 1.1055, policy_loss: 1.1427, value_loss: 0.7359
2024-07-14 06:05:54,714 [INFO    ] __main__: train step 10101: loss: 1.1055, policy_loss: 1.1427, value_loss: 0.7358
2024-07-14 06:05:55,001 [INFO    ] __main__: train step 10102: loss: 1.1055, policy_loss: 1.1427, value_loss: 0.7358
2024-07-14 06:05:55,288 [INFO    ] __main__: train step 10103: loss: 1.1054, policy_loss: 1.1426, value_loss: 0.7357
2024-07-14 06:05:55,597 [INFO    ] __main__: train step 10104: loss: 1.1054, policy_loss: 1.1426, value_loss: 0.7357
2024-07-14 06:05:55,896 [INFO    ] __main__: train step 10105: loss: 1.1054, policy_loss: 1.1425, value_loss: 0.7356
2024-07-14 06:05:56,185 [INFO    ] __main__: train step 10106: loss: 1.1054, policy_loss: 1.1425, value_loss: 0.7356
2024-07-14 06:05:56,475 [INFO    ] __main__: train step 10107: loss: 1.1054, policy_loss: 1.1424, value_loss: 0.7355
2024-07-14 06:05:56,750 [INFO    ] __main__: train step 10108: loss: 1.1053, policy_loss: 1.1424, value_loss: 0.7355
2024-07-14 06:05:57,044 [INFO    ] __main__: train step 10109: loss: 1.1053, policy_loss: 1.1423, value_loss: 0.7354
2024-07-14 06:05:57,331 [INFO    ] __main__: train step 10110: loss: 1.1053, policy_loss: 1.1423, value_loss: 0.7354
2024-07-14 06:05:57,616 [INFO    ] __main__: train step 10111: loss: 1.1053, policy_loss: 1.1422, value_loss: 0.7353
2024-07-14 06:05:59,228 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:05:59,725 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:05:59,800 [INFO    ] __main__: train step 10112: loss: 1.1053, policy_loss: 1.1422, value_loss: 0.7353
2024-07-14 06:06:00,089 [INFO    ] __main__: train step 10113: loss: 1.1052, policy_loss: 1.1421, value_loss: 0.7353
2024-07-14 06:06:00,382 [INFO    ] __main__: train step 10114: loss: 1.1052, policy_loss: 1.1421, value_loss: 0.7352
2024-07-14 06:06:00,665 [INFO    ] __main__: train step 10115: loss: 1.1052, policy_loss: 1.1420, value_loss: 0.7352
2024-07-14 06:06:00,960 [INFO    ] __main__: train step 10116: loss: 1.1052, policy_loss: 1.1420, value_loss: 0.7351
2024-07-14 06:06:01,254 [INFO    ] __main__: train step 10117: loss: 1.1052, policy_loss: 1.1419, value_loss: 0.7351
2024-07-14 06:06:01,552 [INFO    ] __main__: train step 10118: loss: 1.1052, policy_loss: 1.1419, value_loss: 0.7350
2024-07-14 06:06:01,842 [INFO    ] __main__: train step 10119: loss: 1.1051, policy_loss: 1.1419, value_loss: 0.7350
2024-07-14 06:06:02,141 [INFO    ] __main__: train step 10120: loss: 1.1051, policy_loss: 1.1418, value_loss: 0.7349
2024-07-14 06:06:02,419 [INFO    ] __main__: train step 10121: loss: 1.1051, policy_loss: 1.1418, value_loss: 0.7349
2024-07-14 06:06:02,692 [INFO    ] __main__: train step 10122: loss: 1.1051, policy_loss: 1.1417, value_loss: 0.7348
2024-07-14 06:06:02,960 [INFO    ] __main__: train step 10123: loss: 1.1051, policy_loss: 1.1417, value_loss: 0.7348
2024-07-14 06:06:03,243 [INFO    ] __main__: train step 10124: loss: 1.1050, policy_loss: 1.1416, value_loss: 0.7347
2024-07-14 06:06:03,533 [INFO    ] __main__: train step 10125: loss: 1.1050, policy_loss: 1.1416, value_loss: 0.7347
2024-07-14 06:06:03,822 [INFO    ] __main__: train step 10126: loss: 1.1050, policy_loss: 1.1415, value_loss: 0.7346
2024-07-14 06:06:04,124 [INFO    ] __main__: train step 10127: loss: 1.1050, policy_loss: 1.1415, value_loss: 0.7346
2024-07-14 06:06:04,415 [INFO    ] __main__: train step 10128: loss: 1.1050, policy_loss: 1.1414, value_loss: 0.7345
2024-07-14 06:06:06,031 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:06:06,518 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:06:06,589 [INFO    ] __main__: train step 10129: loss: 1.1049, policy_loss: 1.1414, value_loss: 0.7345
2024-07-14 06:06:06,924 [INFO    ] __main__: train step 10130: loss: 1.1049, policy_loss: 1.1413, value_loss: 0.7344
2024-07-14 06:06:07,202 [INFO    ] __main__: train step 10131: loss: 1.1049, policy_loss: 1.1413, value_loss: 0.7344
2024-07-14 06:06:07,498 [INFO    ] __main__: train step 10132: loss: 1.1049, policy_loss: 1.1413, value_loss: 0.7343
2024-07-14 06:06:07,783 [INFO    ] __main__: train step 10133: loss: 1.1049, policy_loss: 1.1412, value_loss: 0.7343
2024-07-14 06:06:08,084 [INFO    ] __main__: train step 10134: loss: 1.1049, policy_loss: 1.1412, value_loss: 0.7342
2024-07-14 06:06:08,372 [INFO    ] __main__: train step 10135: loss: 1.1048, policy_loss: 1.1411, value_loss: 0.7342
2024-07-14 06:06:08,648 [INFO    ] __main__: train step 10136: loss: 1.1048, policy_loss: 1.1411, value_loss: 0.7341
2024-07-14 06:06:08,939 [INFO    ] __main__: train step 10137: loss: 1.1048, policy_loss: 1.1410, value_loss: 0.7341
2024-07-14 06:06:09,223 [INFO    ] __main__: train step 10138: loss: 1.1048, policy_loss: 1.1410, value_loss: 0.7340
2024-07-14 06:06:09,511 [INFO    ] __main__: train step 10139: loss: 1.1048, policy_loss: 1.1409, value_loss: 0.7340
2024-07-14 06:06:09,800 [INFO    ] __main__: train step 10140: loss: 1.1047, policy_loss: 1.1409, value_loss: 0.7340
2024-07-14 06:06:10,086 [INFO    ] __main__: train step 10141: loss: 1.1047, policy_loss: 1.1408, value_loss: 0.7339
2024-07-14 06:06:10,379 [INFO    ] __main__: train step 10142: loss: 1.1047, policy_loss: 1.1408, value_loss: 0.7339
2024-07-14 06:06:10,670 [INFO    ] __main__: train step 10143: loss: 1.1047, policy_loss: 1.1407, value_loss: 0.7338
2024-07-14 06:06:10,959 [INFO    ] __main__: train step 10144: loss: 1.1047, policy_loss: 1.1407, value_loss: 0.7338
2024-07-14 06:06:11,246 [INFO    ] __main__: train step 10145: loss: 1.1047, policy_loss: 1.1407, value_loss: 0.7337
2024-07-14 06:06:12,872 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:06:13,371 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:06:13,440 [INFO    ] __main__: train step 10146: loss: 1.1046, policy_loss: 1.1406, value_loss: 0.7337
2024-07-14 06:06:13,724 [INFO    ] __main__: train step 10147: loss: 1.1046, policy_loss: 1.1406, value_loss: 0.7336
2024-07-14 06:06:14,012 [INFO    ] __main__: train step 10148: loss: 1.1046, policy_loss: 1.1405, value_loss: 0.7336
2024-07-14 06:06:14,307 [INFO    ] __main__: train step 10149: loss: 1.1046, policy_loss: 1.1405, value_loss: 0.7335
2024-07-14 06:06:14,606 [INFO    ] __main__: train step 10150: loss: 1.1046, policy_loss: 1.1404, value_loss: 0.7335
2024-07-14 06:06:14,892 [INFO    ] __main__: train step 10151: loss: 1.1045, policy_loss: 1.1404, value_loss: 0.7334
2024-07-14 06:06:15,182 [INFO    ] __main__: train step 10152: loss: 1.1045, policy_loss: 1.1403, value_loss: 0.7334
2024-07-14 06:06:15,457 [INFO    ] __main__: train step 10153: loss: 1.1045, policy_loss: 1.1403, value_loss: 0.7333
2024-07-14 06:06:15,759 [INFO    ] __main__: train step 10154: loss: 1.1045, policy_loss: 1.1402, value_loss: 0.7333
2024-07-14 06:06:16,029 [INFO    ] __main__: train step 10155: loss: 1.1045, policy_loss: 1.1402, value_loss: 0.7332
2024-07-14 06:06:16,316 [INFO    ] __main__: train step 10156: loss: 1.1045, policy_loss: 1.1402, value_loss: 0.7332
2024-07-14 06:06:19,208 [INFO    ] __main__: train step 10157: loss: 1.1044, policy_loss: 1.1401, value_loss: 0.7331
2024-07-14 06:06:19,495 [INFO    ] __main__: train step 10158: loss: 1.1044, policy_loss: 1.1401, value_loss: 0.7331
2024-07-14 06:06:19,794 [INFO    ] __main__: train step 10159: loss: 1.1044, policy_loss: 1.1400, value_loss: 0.7330
2024-07-14 06:06:20,081 [INFO    ] __main__: train step 10160: loss: 1.1044, policy_loss: 1.1400, value_loss: 0.7330
2024-07-14 06:06:20,367 [INFO    ] __main__: train step 10161: loss: 1.1044, policy_loss: 1.1399, value_loss: 0.7329
2024-07-14 06:06:20,656 [INFO    ] __main__: train step 10162: loss: 1.1044, policy_loss: 1.1399, value_loss: 0.7329
2024-07-14 06:06:22,287 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:06:22,789 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:06:22,862 [INFO    ] __main__: train step 10163: loss: 1.1043, policy_loss: 1.1398, value_loss: 0.7328
2024-07-14 06:06:23,153 [INFO    ] __main__: train step 10164: loss: 1.1043, policy_loss: 1.1398, value_loss: 0.7328
2024-07-14 06:06:23,427 [INFO    ] __main__: train step 10165: loss: 1.1043, policy_loss: 1.1398, value_loss: 0.7328
2024-07-14 06:06:23,714 [INFO    ] __main__: train step 10166: loss: 1.1043, policy_loss: 1.1397, value_loss: 0.7327
2024-07-14 06:06:23,994 [INFO    ] __main__: train step 10167: loss: 1.1043, policy_loss: 1.1397, value_loss: 0.7327
2024-07-14 06:06:24,275 [INFO    ] __main__: train step 10168: loss: 1.1043, policy_loss: 1.1396, value_loss: 0.7326
2024-07-14 06:06:24,564 [INFO    ] __main__: train step 10169: loss: 1.1042, policy_loss: 1.1396, value_loss: 0.7326
2024-07-14 06:06:24,857 [INFO    ] __main__: train step 10170: loss: 1.1042, policy_loss: 1.1395, value_loss: 0.7325
2024-07-14 06:06:25,137 [INFO    ] __main__: train step 10171: loss: 1.1042, policy_loss: 1.1395, value_loss: 0.7325
2024-07-14 06:06:25,423 [INFO    ] __main__: train step 10172: loss: 1.1042, policy_loss: 1.1394, value_loss: 0.7324
2024-07-14 06:06:25,719 [INFO    ] __main__: train step 10173: loss: 1.1042, policy_loss: 1.1394, value_loss: 0.7324
2024-07-14 06:06:26,021 [INFO    ] __main__: train step 10174: loss: 1.1042, policy_loss: 1.1394, value_loss: 0.7323
2024-07-14 06:06:26,309 [INFO    ] __main__: train step 10175: loss: 1.1041, policy_loss: 1.1393, value_loss: 0.7323
2024-07-14 06:06:26,597 [INFO    ] __main__: train step 10176: loss: 1.1041, policy_loss: 1.1393, value_loss: 0.7322
2024-07-14 06:06:26,896 [INFO    ] __main__: train step 10177: loss: 1.1041, policy_loss: 1.1392, value_loss: 0.7322
2024-07-14 06:06:27,187 [INFO    ] __main__: train step 10178: loss: 1.1041, policy_loss: 1.1392, value_loss: 0.7321
2024-07-14 06:06:27,474 [INFO    ] __main__: train step 10179: loss: 1.1041, policy_loss: 1.1391, value_loss: 0.7321
2024-07-14 06:06:29,082 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:06:29,579 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:06:29,656 [INFO    ] __main__: train step 10180: loss: 1.1041, policy_loss: 1.1391, value_loss: 0.7320
2024-07-14 06:06:29,944 [INFO    ] __main__: train step 10181: loss: 1.1040, policy_loss: 1.1390, value_loss: 0.7320
2024-07-14 06:06:30,225 [INFO    ] __main__: train step 10182: loss: 1.1040, policy_loss: 1.1390, value_loss: 0.7319
2024-07-14 06:06:30,516 [INFO    ] __main__: train step 10183: loss: 1.1040, policy_loss: 1.1389, value_loss: 0.7319
2024-07-14 06:06:30,811 [INFO    ] __main__: train step 10184: loss: 1.1040, policy_loss: 1.1389, value_loss: 0.7318
2024-07-14 06:06:31,110 [INFO    ] __main__: train step 10185: loss: 1.1040, policy_loss: 1.1389, value_loss: 0.7318
2024-07-14 06:06:31,412 [INFO    ] __main__: train step 10186: loss: 1.1039, policy_loss: 1.1388, value_loss: 0.7317
2024-07-14 06:06:31,705 [INFO    ] __main__: train step 10187: loss: 1.1039, policy_loss: 1.1388, value_loss: 0.7317
2024-07-14 06:06:32,005 [INFO    ] __main__: train step 10188: loss: 1.1039, policy_loss: 1.1387, value_loss: 0.7317
2024-07-14 06:06:32,302 [INFO    ] __main__: train step 10189: loss: 1.1039, policy_loss: 1.1387, value_loss: 0.7316
2024-07-14 06:06:32,610 [INFO    ] __main__: train step 10190: loss: 1.1039, policy_loss: 1.1386, value_loss: 0.7316
2024-07-14 06:06:32,912 [INFO    ] __main__: train step 10191: loss: 1.1039, policy_loss: 1.1386, value_loss: 0.7315
2024-07-14 06:06:33,200 [INFO    ] __main__: train step 10192: loss: 1.1038, policy_loss: 1.1385, value_loss: 0.7315
2024-07-14 06:06:33,497 [INFO    ] __main__: train step 10193: loss: 1.1038, policy_loss: 1.1385, value_loss: 0.7314
2024-07-14 06:06:33,792 [INFO    ] __main__: train step 10194: loss: 1.1038, policy_loss: 1.1385, value_loss: 0.7314
2024-07-14 06:06:34,090 [INFO    ] __main__: train step 10195: loss: 1.1038, policy_loss: 1.1384, value_loss: 0.7313
2024-07-14 06:06:34,389 [INFO    ] __main__: train step 10196: loss: 1.1038, policy_loss: 1.1384, value_loss: 0.7313
2024-07-14 06:06:36,013 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:06:36,496 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:06:36,569 [INFO    ] __main__: train step 10197: loss: 1.1038, policy_loss: 1.1383, value_loss: 0.7312
2024-07-14 06:06:36,855 [INFO    ] __main__: train step 10198: loss: 1.1037, policy_loss: 1.1383, value_loss: 0.7312
2024-07-14 06:06:37,150 [INFO    ] __main__: train step 10199: loss: 1.1037, policy_loss: 1.1382, value_loss: 0.7311
2024-07-14 06:06:37,453 [INFO    ] __main__: train step 10200: loss: 1.1037, policy_loss: 1.1382, value_loss: 0.7311
2024-07-14 06:06:37,742 [INFO    ] __main__: train step 10201: loss: 1.1037, policy_loss: 1.1381, value_loss: 0.7310
2024-07-14 06:06:38,037 [INFO    ] __main__: train step 10202: loss: 1.1037, policy_loss: 1.1381, value_loss: 0.7310
2024-07-14 06:06:38,330 [INFO    ] __main__: train step 10203: loss: 1.1037, policy_loss: 1.1381, value_loss: 0.7309
2024-07-14 06:06:38,623 [INFO    ] __main__: train step 10204: loss: 1.1036, policy_loss: 1.1380, value_loss: 0.7309
2024-07-14 06:06:38,920 [INFO    ] __main__: train step 10205: loss: 1.1036, policy_loss: 1.1380, value_loss: 0.7308
2024-07-14 06:06:39,213 [INFO    ] __main__: train step 10206: loss: 1.1036, policy_loss: 1.1379, value_loss: 0.7308
2024-07-14 06:06:39,511 [INFO    ] __main__: train step 10207: loss: 1.1036, policy_loss: 1.1379, value_loss: 0.7308
2024-07-14 06:06:39,797 [INFO    ] __main__: train step 10208: loss: 1.1036, policy_loss: 1.1378, value_loss: 0.7307
2024-07-14 06:06:40,095 [INFO    ] __main__: train step 10209: loss: 1.1036, policy_loss: 1.1378, value_loss: 0.7307
2024-07-14 06:06:40,391 [INFO    ] __main__: train step 10210: loss: 1.1036, policy_loss: 1.1378, value_loss: 0.7306
2024-07-14 06:06:40,680 [INFO    ] __main__: train step 10211: loss: 1.1035, policy_loss: 1.1377, value_loss: 0.7306
2024-07-14 06:06:40,970 [INFO    ] __main__: train step 10212: loss: 1.1035, policy_loss: 1.1377, value_loss: 0.7305
2024-07-14 06:06:41,261 [INFO    ] __main__: train step 10213: loss: 1.1035, policy_loss: 1.1376, value_loss: 0.7305
2024-07-14 06:06:42,879 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:06:43,369 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:06:43,441 [INFO    ] __main__: train step 10214: loss: 1.1035, policy_loss: 1.1376, value_loss: 0.7304
2024-07-14 06:06:43,726 [INFO    ] __main__: train step 10215: loss: 1.1035, policy_loss: 1.1375, value_loss: 0.7304
2024-07-14 06:06:44,029 [INFO    ] __main__: train step 10216: loss: 1.1035, policy_loss: 1.1375, value_loss: 0.7303
2024-07-14 06:06:44,316 [INFO    ] __main__: train step 10217: loss: 1.1034, policy_loss: 1.1375, value_loss: 0.7303
2024-07-14 06:06:44,598 [INFO    ] __main__: train step 10218: loss: 1.1034, policy_loss: 1.1374, value_loss: 0.7302
2024-07-14 06:06:44,892 [INFO    ] __main__: train step 10219: loss: 1.1034, policy_loss: 1.1374, value_loss: 0.7302
2024-07-14 06:06:45,182 [INFO    ] __main__: train step 10220: loss: 1.1034, policy_loss: 1.1373, value_loss: 0.7301
2024-07-14 06:06:45,477 [INFO    ] __main__: train step 10221: loss: 1.1034, policy_loss: 1.1373, value_loss: 0.7301
2024-07-14 06:06:45,760 [INFO    ] __main__: train step 10222: loss: 1.1034, policy_loss: 1.1372, value_loss: 0.7300
2024-07-14 06:06:46,061 [INFO    ] __main__: train step 10223: loss: 1.1033, policy_loss: 1.1372, value_loss: 0.7300
2024-07-14 06:06:46,362 [INFO    ] __main__: train step 10224: loss: 1.1033, policy_loss: 1.1371, value_loss: 0.7299
2024-07-14 06:06:46,653 [INFO    ] __main__: train step 10225: loss: 1.1033, policy_loss: 1.1371, value_loss: 0.7299
2024-07-14 06:06:46,933 [INFO    ] __main__: train step 10226: loss: 1.1033, policy_loss: 1.1371, value_loss: 0.7298
2024-07-14 06:06:47,218 [INFO    ] __main__: train step 10227: loss: 1.1033, policy_loss: 1.1370, value_loss: 0.7298
2024-07-14 06:06:47,487 [INFO    ] __main__: train step 10228: loss: 1.1033, policy_loss: 1.1370, value_loss: 0.7298
2024-07-14 06:06:47,774 [INFO    ] __main__: train step 10229: loss: 1.1033, policy_loss: 1.1369, value_loss: 0.7297
2024-07-14 06:06:48,069 [INFO    ] __main__: train step 10230: loss: 1.1032, policy_loss: 1.1369, value_loss: 0.7297
2024-07-14 06:06:49,689 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:06:50,173 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:06:50,239 [INFO    ] __main__: train step 10231: loss: 1.1032, policy_loss: 1.1368, value_loss: 0.7296
2024-07-14 06:06:50,537 [INFO    ] __main__: train step 10232: loss: 1.1032, policy_loss: 1.1368, value_loss: 0.7296
2024-07-14 06:06:50,838 [INFO    ] __main__: train step 10233: loss: 1.1032, policy_loss: 1.1368, value_loss: 0.7295
2024-07-14 06:06:51,150 [INFO    ] __main__: train step 10234: loss: 1.1032, policy_loss: 1.1367, value_loss: 0.7295
2024-07-14 06:06:51,433 [INFO    ] __main__: train step 10235: loss: 1.1032, policy_loss: 1.1367, value_loss: 0.7294
2024-07-14 06:06:51,723 [INFO    ] __main__: train step 10236: loss: 1.1031, policy_loss: 1.1366, value_loss: 0.7294
2024-07-14 06:06:52,026 [INFO    ] __main__: train step 10237: loss: 1.1031, policy_loss: 1.1366, value_loss: 0.7293
2024-07-14 06:06:52,340 [INFO    ] __main__: train step 10238: loss: 1.1031, policy_loss: 1.1366, value_loss: 0.7293
2024-07-14 06:06:52,620 [INFO    ] __main__: train step 10239: loss: 1.1031, policy_loss: 1.1365, value_loss: 0.7292
2024-07-14 06:06:52,906 [INFO    ] __main__: train step 10240: loss: 1.1031, policy_loss: 1.1365, value_loss: 0.7292
2024-07-14 06:06:53,188 [INFO    ] __main__: train step 10241: loss: 1.1031, policy_loss: 1.1364, value_loss: 0.7291
2024-07-14 06:06:53,479 [INFO    ] __main__: train step 10242: loss: 1.1031, policy_loss: 1.1364, value_loss: 0.7291
2024-07-14 06:06:53,763 [INFO    ] __main__: train step 10243: loss: 1.1030, policy_loss: 1.1363, value_loss: 0.7290
2024-07-14 06:06:54,054 [INFO    ] __main__: train step 10244: loss: 1.1030, policy_loss: 1.1363, value_loss: 0.7290
2024-07-14 06:06:54,342 [INFO    ] __main__: train step 10245: loss: 1.1030, policy_loss: 1.1363, value_loss: 0.7290
2024-07-14 06:06:54,617 [INFO    ] __main__: train step 10246: loss: 1.1030, policy_loss: 1.1362, value_loss: 0.7289
2024-07-14 06:06:57,586 [INFO    ] __main__: train step 10247: loss: 1.1030, policy_loss: 1.1362, value_loss: 0.7289
2024-07-14 06:06:59,210 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:06:59,703 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:06:59,774 [INFO    ] __main__: train step 10248: loss: 1.1030, policy_loss: 1.1361, value_loss: 0.7288
2024-07-14 06:07:00,075 [INFO    ] __main__: train step 10249: loss: 1.1029, policy_loss: 1.1361, value_loss: 0.7288
2024-07-14 06:07:00,365 [INFO    ] __main__: train step 10250: loss: 1.1029, policy_loss: 1.1360, value_loss: 0.7287
2024-07-14 06:07:00,651 [INFO    ] __main__: train step 10251: loss: 1.1029, policy_loss: 1.1360, value_loss: 0.7287
2024-07-14 06:07:00,945 [INFO    ] __main__: train step 10252: loss: 1.1029, policy_loss: 1.1360, value_loss: 0.7286
2024-07-14 06:07:01,242 [INFO    ] __main__: train step 10253: loss: 1.1029, policy_loss: 1.1359, value_loss: 0.7286
2024-07-14 06:07:01,528 [INFO    ] __main__: train step 10254: loss: 1.1029, policy_loss: 1.1359, value_loss: 0.7285
2024-07-14 06:07:01,828 [INFO    ] __main__: train step 10255: loss: 1.1028, policy_loss: 1.1358, value_loss: 0.7285
2024-07-14 06:07:02,117 [INFO    ] __main__: train step 10256: loss: 1.1028, policy_loss: 1.1358, value_loss: 0.7284
2024-07-14 06:07:02,413 [INFO    ] __main__: train step 10257: loss: 1.1028, policy_loss: 1.1357, value_loss: 0.7284
2024-07-14 06:07:02,712 [INFO    ] __main__: train step 10258: loss: 1.1028, policy_loss: 1.1357, value_loss: 0.7283
2024-07-14 06:07:03,023 [INFO    ] __main__: train step 10259: loss: 1.1028, policy_loss: 1.1357, value_loss: 0.7283
2024-07-14 06:07:03,333 [INFO    ] __main__: train step 10260: loss: 1.1028, policy_loss: 1.1356, value_loss: 0.7282
2024-07-14 06:07:03,632 [INFO    ] __main__: train step 10261: loss: 1.1028, policy_loss: 1.1356, value_loss: 0.7282
2024-07-14 06:07:03,934 [INFO    ] __main__: train step 10262: loss: 1.1027, policy_loss: 1.1355, value_loss: 0.7282
2024-07-14 06:07:04,231 [INFO    ] __main__: train step 10263: loss: 1.1027, policy_loss: 1.1355, value_loss: 0.7281
2024-07-14 06:07:04,512 [INFO    ] __main__: train step 10264: loss: 1.1027, policy_loss: 1.1354, value_loss: 0.7281
2024-07-14 06:07:06,150 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:07:06,639 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:07:06,707 [INFO    ] __main__: train step 10265: loss: 1.1027, policy_loss: 1.1354, value_loss: 0.7280
2024-07-14 06:07:06,997 [INFO    ] __main__: train step 10266: loss: 1.1027, policy_loss: 1.1354, value_loss: 0.7280
2024-07-14 06:07:07,292 [INFO    ] __main__: train step 10267: loss: 1.1027, policy_loss: 1.1353, value_loss: 0.7279
2024-07-14 06:07:07,585 [INFO    ] __main__: train step 10268: loss: 1.1027, policy_loss: 1.1353, value_loss: 0.7279
2024-07-14 06:07:07,882 [INFO    ] __main__: train step 10269: loss: 1.1026, policy_loss: 1.1352, value_loss: 0.7278
2024-07-14 06:07:08,181 [INFO    ] __main__: train step 10270: loss: 1.1026, policy_loss: 1.1352, value_loss: 0.7278
2024-07-14 06:07:08,458 [INFO    ] __main__: train step 10271: loss: 1.1026, policy_loss: 1.1352, value_loss: 0.7277
2024-07-14 06:07:08,760 [INFO    ] __main__: train step 10272: loss: 1.1026, policy_loss: 1.1351, value_loss: 0.7277
2024-07-14 06:07:09,045 [INFO    ] __main__: train step 10273: loss: 1.1026, policy_loss: 1.1351, value_loss: 0.7276
2024-07-14 06:07:09,347 [INFO    ] __main__: train step 10274: loss: 1.1026, policy_loss: 1.1350, value_loss: 0.7276
2024-07-14 06:07:09,636 [INFO    ] __main__: train step 10275: loss: 1.1026, policy_loss: 1.1350, value_loss: 0.7275
2024-07-14 06:07:09,940 [INFO    ] __main__: train step 10276: loss: 1.1025, policy_loss: 1.1349, value_loss: 0.7275
2024-07-14 06:07:10,224 [INFO    ] __main__: train step 10277: loss: 1.1025, policy_loss: 1.1349, value_loss: 0.7274
2024-07-14 06:07:10,514 [INFO    ] __main__: train step 10278: loss: 1.1025, policy_loss: 1.1349, value_loss: 0.7274
2024-07-14 06:07:10,814 [INFO    ] __main__: train step 10279: loss: 1.1025, policy_loss: 1.1348, value_loss: 0.7274
2024-07-14 06:07:11,112 [INFO    ] __main__: train step 10280: loss: 1.1025, policy_loss: 1.1348, value_loss: 0.7273
2024-07-14 06:07:11,412 [INFO    ] __main__: train step 10281: loss: 1.1025, policy_loss: 1.1347, value_loss: 0.7273
2024-07-14 06:07:13,032 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:07:13,523 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:07:13,595 [INFO    ] __main__: train step 10282: loss: 1.1025, policy_loss: 1.1347, value_loss: 0.7272
2024-07-14 06:07:13,886 [INFO    ] __main__: train step 10283: loss: 1.1024, policy_loss: 1.1347, value_loss: 0.7272
2024-07-14 06:07:14,167 [INFO    ] __main__: train step 10284: loss: 1.1024, policy_loss: 1.1346, value_loss: 0.7271
2024-07-14 06:07:14,452 [INFO    ] __main__: train step 10285: loss: 1.1024, policy_loss: 1.1346, value_loss: 0.7271
2024-07-14 06:07:14,740 [INFO    ] __main__: train step 10286: loss: 1.1024, policy_loss: 1.1345, value_loss: 0.7270
2024-07-14 06:07:15,026 [INFO    ] __main__: train step 10287: loss: 1.1024, policy_loss: 1.1345, value_loss: 0.7270
2024-07-14 06:07:15,327 [INFO    ] __main__: train step 10288: loss: 1.1024, policy_loss: 1.1344, value_loss: 0.7269
2024-07-14 06:07:15,626 [INFO    ] __main__: train step 10289: loss: 1.1024, policy_loss: 1.1344, value_loss: 0.7269
2024-07-14 06:07:15,915 [INFO    ] __main__: train step 10290: loss: 1.1023, policy_loss: 1.1344, value_loss: 0.7268
2024-07-14 06:07:16,213 [INFO    ] __main__: train step 10291: loss: 1.1023, policy_loss: 1.1343, value_loss: 0.7268
2024-07-14 06:07:16,509 [INFO    ] __main__: train step 10292: loss: 1.1023, policy_loss: 1.1343, value_loss: 0.7267
2024-07-14 06:07:16,792 [INFO    ] __main__: train step 10293: loss: 1.1023, policy_loss: 1.1342, value_loss: 0.7267
2024-07-14 06:07:17,077 [INFO    ] __main__: train step 10294: loss: 1.1023, policy_loss: 1.1342, value_loss: 0.7267
2024-07-14 06:07:17,371 [INFO    ] __main__: train step 10295: loss: 1.1023, policy_loss: 1.1342, value_loss: 0.7266
2024-07-14 06:07:17,660 [INFO    ] __main__: train step 10296: loss: 1.1023, policy_loss: 1.1341, value_loss: 0.7266
2024-07-14 06:07:17,955 [INFO    ] __main__: train step 10297: loss: 1.1022, policy_loss: 1.1341, value_loss: 0.7265
2024-07-14 06:07:18,241 [INFO    ] __main__: train step 10298: loss: 1.1022, policy_loss: 1.1340, value_loss: 0.7265
2024-07-14 06:07:19,855 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:07:20,345 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:07:20,414 [INFO    ] __main__: train step 10299: loss: 1.1022, policy_loss: 1.1340, value_loss: 0.7264
2024-07-14 06:07:20,708 [INFO    ] __main__: train step 10300: loss: 1.1022, policy_loss: 1.1339, value_loss: 0.7264
2024-07-14 06:07:21,001 [INFO    ] __main__: train step 10301: loss: 1.1022, policy_loss: 1.1339, value_loss: 0.7263
2024-07-14 06:07:21,299 [INFO    ] __main__: train step 10302: loss: 1.1022, policy_loss: 1.1339, value_loss: 0.7263
2024-07-14 06:07:21,596 [INFO    ] __main__: train step 10303: loss: 1.1022, policy_loss: 1.1338, value_loss: 0.7262
2024-07-14 06:07:21,883 [INFO    ] __main__: train step 10304: loss: 1.1021, policy_loss: 1.1338, value_loss: 0.7262
2024-07-14 06:07:22,175 [INFO    ] __main__: train step 10305: loss: 1.1021, policy_loss: 1.1337, value_loss: 0.7261
2024-07-14 06:07:22,476 [INFO    ] __main__: train step 10306: loss: 1.1021, policy_loss: 1.1337, value_loss: 0.7261
2024-07-14 06:07:22,761 [INFO    ] __main__: train step 10307: loss: 1.1021, policy_loss: 1.1337, value_loss: 0.7261
2024-07-14 06:07:23,070 [INFO    ] __main__: train step 10308: loss: 1.1021, policy_loss: 1.1336, value_loss: 0.7260
2024-07-14 06:07:23,366 [INFO    ] __main__: train step 10309: loss: 1.1021, policy_loss: 1.1336, value_loss: 0.7260
2024-07-14 06:07:23,663 [INFO    ] __main__: train step 10310: loss: 1.1021, policy_loss: 1.1335, value_loss: 0.7259
2024-07-14 06:07:23,967 [INFO    ] __main__: train step 10311: loss: 1.1020, policy_loss: 1.1335, value_loss: 0.7259
2024-07-14 06:07:24,259 [INFO    ] __main__: train step 10312: loss: 1.1020, policy_loss: 1.1335, value_loss: 0.7258
2024-07-14 06:07:24,547 [INFO    ] __main__: train step 10313: loss: 1.1020, policy_loss: 1.1334, value_loss: 0.7258
2024-07-14 06:07:24,831 [INFO    ] __main__: train step 10314: loss: 1.1020, policy_loss: 1.1334, value_loss: 0.7257
2024-07-14 06:07:25,122 [INFO    ] __main__: train step 10315: loss: 1.1020, policy_loss: 1.1333, value_loss: 0.7257
2024-07-14 06:07:26,741 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:07:27,231 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:07:27,304 [INFO    ] __main__: train step 10316: loss: 1.1020, policy_loss: 1.1333, value_loss: 0.7256
2024-07-14 06:07:27,588 [INFO    ] __main__: train step 10317: loss: 1.1020, policy_loss: 1.1333, value_loss: 0.7256
2024-07-14 06:07:27,871 [INFO    ] __main__: train step 10318: loss: 1.1020, policy_loss: 1.1332, value_loss: 0.7255
2024-07-14 06:07:28,157 [INFO    ] __main__: train step 10319: loss: 1.1019, policy_loss: 1.1332, value_loss: 0.7255
2024-07-14 06:07:28,449 [INFO    ] __main__: train step 10320: loss: 1.1019, policy_loss: 1.1331, value_loss: 0.7255
2024-07-14 06:07:28,750 [INFO    ] __main__: train step 10321: loss: 1.1019, policy_loss: 1.1331, value_loss: 0.7254
2024-07-14 06:07:29,047 [INFO    ] __main__: train step 10322: loss: 1.1019, policy_loss: 1.1331, value_loss: 0.7254
2024-07-14 06:07:29,354 [INFO    ] __main__: train step 10323: loss: 1.1019, policy_loss: 1.1330, value_loss: 0.7253
2024-07-14 06:07:29,638 [INFO    ] __main__: train step 10324: loss: 1.1019, policy_loss: 1.1330, value_loss: 0.7253
2024-07-14 06:07:29,924 [INFO    ] __main__: train step 10325: loss: 1.1019, policy_loss: 1.1329, value_loss: 0.7252
2024-07-14 06:07:30,219 [INFO    ] __main__: train step 10326: loss: 1.1018, policy_loss: 1.1329, value_loss: 0.7252
2024-07-14 06:07:30,504 [INFO    ] __main__: train step 10327: loss: 1.1018, policy_loss: 1.1328, value_loss: 0.7251
2024-07-14 06:07:30,793 [INFO    ] __main__: train step 10328: loss: 1.1018, policy_loss: 1.1328, value_loss: 0.7251
2024-07-14 06:07:31,086 [INFO    ] __main__: train step 10329: loss: 1.1018, policy_loss: 1.1328, value_loss: 0.7250
2024-07-14 06:07:31,371 [INFO    ] __main__: train step 10330: loss: 1.1018, policy_loss: 1.1327, value_loss: 0.7250
2024-07-14 06:07:31,655 [INFO    ] __main__: train step 10331: loss: 1.1018, policy_loss: 1.1327, value_loss: 0.7249
2024-07-14 06:07:31,948 [INFO    ] __main__: train step 10332: loss: 1.1018, policy_loss: 1.1326, value_loss: 0.7249
2024-07-14 06:07:33,560 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:07:34,048 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:07:34,121 [INFO    ] __main__: train step 10333: loss: 1.1017, policy_loss: 1.1326, value_loss: 0.7249
2024-07-14 06:07:34,418 [INFO    ] __main__: train step 10334: loss: 1.1017, policy_loss: 1.1326, value_loss: 0.7248
2024-07-14 06:07:34,717 [INFO    ] __main__: train step 10335: loss: 1.1017, policy_loss: 1.1325, value_loss: 0.7248
2024-07-14 06:07:37,375 [INFO    ] __main__: train step 10336: loss: 1.1017, policy_loss: 1.1325, value_loss: 0.7247
2024-07-14 06:07:37,667 [INFO    ] __main__: train step 10337: loss: 1.1017, policy_loss: 1.1324, value_loss: 0.7247
2024-07-14 06:07:37,961 [INFO    ] __main__: train step 10338: loss: 1.1017, policy_loss: 1.1324, value_loss: 0.7246
2024-07-14 06:07:38,261 [INFO    ] __main__: train step 10339: loss: 1.1017, policy_loss: 1.1324, value_loss: 0.7246
2024-07-14 06:07:38,578 [INFO    ] __main__: train step 10340: loss: 1.1017, policy_loss: 1.1323, value_loss: 0.7245
2024-07-14 06:07:38,875 [INFO    ] __main__: train step 10341: loss: 1.1016, policy_loss: 1.1323, value_loss: 0.7245
2024-07-14 06:07:39,168 [INFO    ] __main__: train step 10342: loss: 1.1016, policy_loss: 1.1322, value_loss: 0.7244
2024-07-14 06:07:39,468 [INFO    ] __main__: train step 10343: loss: 1.1016, policy_loss: 1.1322, value_loss: 0.7244
2024-07-14 06:07:39,764 [INFO    ] __main__: train step 10344: loss: 1.1016, policy_loss: 1.1322, value_loss: 0.7244
2024-07-14 06:07:40,060 [INFO    ] __main__: train step 10345: loss: 1.1016, policy_loss: 1.1321, value_loss: 0.7243
2024-07-14 06:07:40,361 [INFO    ] __main__: train step 10346: loss: 1.1016, policy_loss: 1.1321, value_loss: 0.7243
2024-07-14 06:07:40,645 [INFO    ] __main__: train step 10347: loss: 1.1016, policy_loss: 1.1320, value_loss: 0.7242
2024-07-14 06:07:40,934 [INFO    ] __main__: train step 10348: loss: 1.1015, policy_loss: 1.1320, value_loss: 0.7242
2024-07-14 06:07:41,221 [INFO    ] __main__: train step 10349: loss: 1.1015, policy_loss: 1.1320, value_loss: 0.7241
2024-07-14 06:07:42,844 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:07:43,336 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:07:43,407 [INFO    ] __main__: train step 10350: loss: 1.1015, policy_loss: 1.1319, value_loss: 0.7241
2024-07-14 06:07:43,705 [INFO    ] __main__: train step 10351: loss: 1.1015, policy_loss: 1.1319, value_loss: 0.7240
2024-07-14 06:07:43,989 [INFO    ] __main__: train step 10352: loss: 1.1015, policy_loss: 1.1318, value_loss: 0.7240
2024-07-14 06:07:44,281 [INFO    ] __main__: train step 10353: loss: 1.1015, policy_loss: 1.1318, value_loss: 0.7239
2024-07-14 06:07:44,559 [INFO    ] __main__: train step 10354: loss: 1.1015, policy_loss: 1.1318, value_loss: 0.7239
2024-07-14 06:07:44,865 [INFO    ] __main__: train step 10355: loss: 1.1015, policy_loss: 1.1317, value_loss: 0.7238
2024-07-14 06:07:45,139 [INFO    ] __main__: train step 10356: loss: 1.1014, policy_loss: 1.1317, value_loss: 0.7238
2024-07-14 06:07:45,419 [INFO    ] __main__: train step 10357: loss: 1.1014, policy_loss: 1.1316, value_loss: 0.7237
2024-07-14 06:07:45,702 [INFO    ] __main__: train step 10358: loss: 1.1014, policy_loss: 1.1316, value_loss: 0.7237
2024-07-14 06:07:45,980 [INFO    ] __main__: train step 10359: loss: 1.1014, policy_loss: 1.1315, value_loss: 0.7237
2024-07-14 06:07:46,276 [INFO    ] __main__: train step 10360: loss: 1.1014, policy_loss: 1.1315, value_loss: 0.7236
2024-07-14 06:07:46,571 [INFO    ] __main__: train step 10361: loss: 1.1014, policy_loss: 1.1315, value_loss: 0.7236
2024-07-14 06:07:46,854 [INFO    ] __main__: train step 10362: loss: 1.1014, policy_loss: 1.1314, value_loss: 0.7235
2024-07-14 06:07:47,133 [INFO    ] __main__: train step 10363: loss: 1.1013, policy_loss: 1.1314, value_loss: 0.7235
2024-07-14 06:07:47,415 [INFO    ] __main__: train step 10364: loss: 1.1013, policy_loss: 1.1313, value_loss: 0.7234
2024-07-14 06:07:47,687 [INFO    ] __main__: train step 10365: loss: 1.1013, policy_loss: 1.1313, value_loss: 0.7234
2024-07-14 06:07:47,969 [INFO    ] __main__: train step 10366: loss: 1.1013, policy_loss: 1.1313, value_loss: 0.7233
2024-07-14 06:07:49,570 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:07:50,051 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:07:50,125 [INFO    ] __main__: train step 10367: loss: 1.1013, policy_loss: 1.1312, value_loss: 0.7233
2024-07-14 06:07:50,416 [INFO    ] __main__: train step 10368: loss: 1.1013, policy_loss: 1.1312, value_loss: 0.7232
2024-07-14 06:07:50,692 [INFO    ] __main__: train step 10369: loss: 1.1013, policy_loss: 1.1312, value_loss: 0.7232
2024-07-14 06:07:50,980 [INFO    ] __main__: train step 10370: loss: 1.1013, policy_loss: 1.1311, value_loss: 0.7232
2024-07-14 06:07:51,264 [INFO    ] __main__: train step 10371: loss: 1.1012, policy_loss: 1.1311, value_loss: 0.7231
2024-07-14 06:07:51,560 [INFO    ] __main__: train step 10372: loss: 1.1012, policy_loss: 1.1310, value_loss: 0.7231
2024-07-14 06:07:51,851 [INFO    ] __main__: train step 10373: loss: 1.1012, policy_loss: 1.1310, value_loss: 0.7230
2024-07-14 06:07:52,144 [INFO    ] __main__: train step 10374: loss: 1.1012, policy_loss: 1.1310, value_loss: 0.7230
2024-07-14 06:07:52,428 [INFO    ] __main__: train step 10375: loss: 1.1012, policy_loss: 1.1309, value_loss: 0.7229
2024-07-14 06:07:52,721 [INFO    ] __main__: train step 10376: loss: 1.1012, policy_loss: 1.1309, value_loss: 0.7229
2024-07-14 06:07:53,015 [INFO    ] __main__: train step 10377: loss: 1.1012, policy_loss: 1.1308, value_loss: 0.7228
2024-07-14 06:07:53,305 [INFO    ] __main__: train step 10378: loss: 1.1012, policy_loss: 1.1308, value_loss: 0.7228
2024-07-14 06:07:53,593 [INFO    ] __main__: train step 10379: loss: 1.1011, policy_loss: 1.1308, value_loss: 0.7227
2024-07-14 06:07:53,887 [INFO    ] __main__: train step 10380: loss: 1.1011, policy_loss: 1.1307, value_loss: 0.7227
2024-07-14 06:07:54,185 [INFO    ] __main__: train step 10381: loss: 1.1011, policy_loss: 1.1307, value_loss: 0.7227
2024-07-14 06:07:54,481 [INFO    ] __main__: train step 10382: loss: 1.1011, policy_loss: 1.1306, value_loss: 0.7226
2024-07-14 06:07:54,778 [INFO    ] __main__: train step 10383: loss: 1.1011, policy_loss: 1.1306, value_loss: 0.7226
2024-07-14 06:07:56,392 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:07:56,877 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:07:56,946 [INFO    ] __main__: train step 10384: loss: 1.1011, policy_loss: 1.1306, value_loss: 0.7225
2024-07-14 06:07:57,243 [INFO    ] __main__: train step 10385: loss: 1.1011, policy_loss: 1.1305, value_loss: 0.7225
2024-07-14 06:07:57,539 [INFO    ] __main__: train step 10386: loss: 1.1011, policy_loss: 1.1305, value_loss: 0.7224
2024-07-14 06:07:57,836 [INFO    ] __main__: train step 10387: loss: 1.1010, policy_loss: 1.1304, value_loss: 0.7224
2024-07-14 06:07:58,126 [INFO    ] __main__: train step 10388: loss: 1.1010, policy_loss: 1.1304, value_loss: 0.7223
2024-07-14 06:07:58,418 [INFO    ] __main__: train step 10389: loss: 1.1010, policy_loss: 1.1304, value_loss: 0.7223
2024-07-14 06:07:58,698 [INFO    ] __main__: train step 10390: loss: 1.1010, policy_loss: 1.1303, value_loss: 0.7222
2024-07-14 06:07:58,991 [INFO    ] __main__: train step 10391: loss: 1.1010, policy_loss: 1.1303, value_loss: 0.7222
2024-07-14 06:07:59,286 [INFO    ] __main__: train step 10392: loss: 1.1010, policy_loss: 1.1302, value_loss: 0.7221
2024-07-14 06:07:59,571 [INFO    ] __main__: train step 10393: loss: 1.1010, policy_loss: 1.1302, value_loss: 0.7221
2024-07-14 06:07:59,857 [INFO    ] __main__: train step 10394: loss: 1.1009, policy_loss: 1.1302, value_loss: 0.7221
2024-07-14 06:08:00,149 [INFO    ] __main__: train step 10395: loss: 1.1009, policy_loss: 1.1301, value_loss: 0.7220
2024-07-14 06:08:00,441 [INFO    ] __main__: train step 10396: loss: 1.1009, policy_loss: 1.1301, value_loss: 0.7220
2024-07-14 06:08:00,734 [INFO    ] __main__: train step 10397: loss: 1.1009, policy_loss: 1.1300, value_loss: 0.7219
2024-07-14 06:08:01,027 [INFO    ] __main__: train step 10398: loss: 1.1009, policy_loss: 1.1300, value_loss: 0.7219
2024-07-14 06:08:01,336 [INFO    ] __main__: train step 10399: loss: 1.1009, policy_loss: 1.1300, value_loss: 0.7218
2024-07-14 06:08:01,634 [INFO    ] __main__: train step 10400: loss: 1.1009, policy_loss: 1.1299, value_loss: 0.7218
2024-07-14 06:08:03,239 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:08:03,742 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:08:03,809 [INFO    ] __main__: train step 10401: loss: 1.1009, policy_loss: 1.1299, value_loss: 0.7217
2024-07-14 06:08:04,099 [INFO    ] __main__: train step 10402: loss: 1.1008, policy_loss: 1.1298, value_loss: 0.7217
2024-07-14 06:08:04,388 [INFO    ] __main__: train step 10403: loss: 1.1008, policy_loss: 1.1298, value_loss: 0.7216
2024-07-14 06:08:04,676 [INFO    ] __main__: train step 10404: loss: 1.1008, policy_loss: 1.1298, value_loss: 0.7216
2024-07-14 06:08:04,972 [INFO    ] __main__: train step 10405: loss: 1.1008, policy_loss: 1.1297, value_loss: 0.7216
2024-07-14 06:08:05,258 [INFO    ] __main__: train step 10406: loss: 1.1008, policy_loss: 1.1297, value_loss: 0.7215
2024-07-14 06:08:05,547 [INFO    ] __main__: train step 10407: loss: 1.1008, policy_loss: 1.1297, value_loss: 0.7215
2024-07-14 06:08:05,831 [INFO    ] __main__: train step 10408: loss: 1.1008, policy_loss: 1.1296, value_loss: 0.7214
2024-07-14 06:08:06,118 [INFO    ] __main__: train step 10409: loss: 1.1008, policy_loss: 1.1296, value_loss: 0.7214
2024-07-14 06:08:06,409 [INFO    ] __main__: train step 10410: loss: 1.1007, policy_loss: 1.1295, value_loss: 0.7213
2024-07-14 06:08:06,696 [INFO    ] __main__: train step 10411: loss: 1.1007, policy_loss: 1.1295, value_loss: 0.7213
2024-07-14 06:08:06,986 [INFO    ] __main__: train step 10412: loss: 1.1007, policy_loss: 1.1295, value_loss: 0.7212
2024-07-14 06:08:07,277 [INFO    ] __main__: train step 10413: loss: 1.1007, policy_loss: 1.1294, value_loss: 0.7212
2024-07-14 06:08:07,557 [INFO    ] __main__: train step 10414: loss: 1.1007, policy_loss: 1.1294, value_loss: 0.7211
2024-07-14 06:08:07,836 [INFO    ] __main__: train step 10415: loss: 1.1007, policy_loss: 1.1293, value_loss: 0.7211
2024-07-14 06:08:08,128 [INFO    ] __main__: train step 10416: loss: 1.1007, policy_loss: 1.1293, value_loss: 0.7211
2024-07-14 06:08:08,421 [INFO    ] __main__: train step 10417: loss: 1.1007, policy_loss: 1.1293, value_loss: 0.7210
2024-07-14 06:08:10,029 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:08:10,515 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:08:10,583 [INFO    ] __main__: train step 10418: loss: 1.1006, policy_loss: 1.1292, value_loss: 0.7210
2024-07-14 06:08:10,873 [INFO    ] __main__: train step 10419: loss: 1.1006, policy_loss: 1.1292, value_loss: 0.7209
2024-07-14 06:08:11,154 [INFO    ] __main__: train step 10420: loss: 1.1006, policy_loss: 1.1291, value_loss: 0.7209
2024-07-14 06:08:11,437 [INFO    ] __main__: train step 10421: loss: 1.1006, policy_loss: 1.1291, value_loss: 0.7208
2024-07-14 06:08:11,728 [INFO    ] __main__: train step 10422: loss: 1.1006, policy_loss: 1.1291, value_loss: 0.7208
2024-07-14 06:08:12,026 [INFO    ] __main__: train step 10423: loss: 1.1006, policy_loss: 1.1290, value_loss: 0.7207
2024-07-14 06:08:12,325 [INFO    ] __main__: train step 10424: loss: 1.1006, policy_loss: 1.1290, value_loss: 0.7207
2024-07-14 06:08:15,217 [INFO    ] __main__: train step 10425: loss: 1.1006, policy_loss: 1.1290, value_loss: 0.7206
2024-07-14 06:08:15,515 [INFO    ] __main__: train step 10426: loss: 1.1005, policy_loss: 1.1289, value_loss: 0.7206
2024-07-14 06:08:15,807 [INFO    ] __main__: train step 10427: loss: 1.1005, policy_loss: 1.1289, value_loss: 0.7206
2024-07-14 06:08:16,095 [INFO    ] __main__: train step 10428: loss: 1.1005, policy_loss: 1.1288, value_loss: 0.7205
2024-07-14 06:08:16,387 [INFO    ] __main__: train step 10429: loss: 1.1005, policy_loss: 1.1288, value_loss: 0.7205
2024-07-14 06:08:16,678 [INFO    ] __main__: train step 10430: loss: 1.1005, policy_loss: 1.1288, value_loss: 0.7204
2024-07-14 06:08:16,962 [INFO    ] __main__: train step 10431: loss: 1.1005, policy_loss: 1.1287, value_loss: 0.7204
2024-07-14 06:08:17,257 [INFO    ] __main__: train step 10432: loss: 1.1005, policy_loss: 1.1287, value_loss: 0.7203
2024-07-14 06:08:17,555 [INFO    ] __main__: train step 10433: loss: 1.1005, policy_loss: 1.1286, value_loss: 0.7203
2024-07-14 06:08:17,856 [INFO    ] __main__: train step 10434: loss: 1.1004, policy_loss: 1.1286, value_loss: 0.7202
2024-07-14 06:08:19,456 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:08:19,943 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:08:20,014 [INFO    ] __main__: train step 10435: loss: 1.1004, policy_loss: 1.1286, value_loss: 0.7202
2024-07-14 06:08:20,298 [INFO    ] __main__: train step 10436: loss: 1.1004, policy_loss: 1.1285, value_loss: 0.7202
2024-07-14 06:08:20,592 [INFO    ] __main__: train step 10437: loss: 1.1004, policy_loss: 1.1285, value_loss: 0.7201
2024-07-14 06:08:20,869 [INFO    ] __main__: train step 10438: loss: 1.1004, policy_loss: 1.1284, value_loss: 0.7201
2024-07-14 06:08:21,159 [INFO    ] __main__: train step 10439: loss: 1.1004, policy_loss: 1.1284, value_loss: 0.7200
2024-07-14 06:08:21,451 [INFO    ] __main__: train step 10440: loss: 1.1004, policy_loss: 1.1284, value_loss: 0.7200
2024-07-14 06:08:21,741 [INFO    ] __main__: train step 10441: loss: 1.1004, policy_loss: 1.1283, value_loss: 0.7199
2024-07-14 06:08:22,025 [INFO    ] __main__: train step 10442: loss: 1.1004, policy_loss: 1.1283, value_loss: 0.7199
2024-07-14 06:08:22,320 [INFO    ] __main__: train step 10443: loss: 1.1003, policy_loss: 1.1283, value_loss: 0.7198
2024-07-14 06:08:22,614 [INFO    ] __main__: train step 10444: loss: 1.1003, policy_loss: 1.1282, value_loss: 0.7198
2024-07-14 06:08:22,900 [INFO    ] __main__: train step 10445: loss: 1.1003, policy_loss: 1.1282, value_loss: 0.7197
2024-07-14 06:08:23,205 [INFO    ] __main__: train step 10446: loss: 1.1003, policy_loss: 1.1281, value_loss: 0.7197
2024-07-14 06:08:23,500 [INFO    ] __main__: train step 10447: loss: 1.1003, policy_loss: 1.1281, value_loss: 0.7197
2024-07-14 06:08:23,795 [INFO    ] __main__: train step 10448: loss: 1.1003, policy_loss: 1.1281, value_loss: 0.7196
2024-07-14 06:08:24,091 [INFO    ] __main__: train step 10449: loss: 1.1003, policy_loss: 1.1280, value_loss: 0.7196
2024-07-14 06:08:24,376 [INFO    ] __main__: train step 10450: loss: 1.1003, policy_loss: 1.1280, value_loss: 0.7195
2024-07-14 06:08:24,661 [INFO    ] __main__: train step 10451: loss: 1.1002, policy_loss: 1.1279, value_loss: 0.7195
2024-07-14 06:08:26,276 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:08:26,765 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:08:26,836 [INFO    ] __main__: train step 10452: loss: 1.1002, policy_loss: 1.1279, value_loss: 0.7194
2024-07-14 06:08:27,135 [INFO    ] __main__: train step 10453: loss: 1.1002, policy_loss: 1.1279, value_loss: 0.7194
2024-07-14 06:08:27,423 [INFO    ] __main__: train step 10454: loss: 1.1002, policy_loss: 1.1278, value_loss: 0.7193
2024-07-14 06:08:27,710 [INFO    ] __main__: train step 10455: loss: 1.1002, policy_loss: 1.1278, value_loss: 0.7193
2024-07-14 06:08:28,001 [INFO    ] __main__: train step 10456: loss: 1.1002, policy_loss: 1.1278, value_loss: 0.7193
2024-07-14 06:08:28,298 [INFO    ] __main__: train step 10457: loss: 1.1002, policy_loss: 1.1277, value_loss: 0.7192
2024-07-14 06:08:28,589 [INFO    ] __main__: train step 10458: loss: 1.1002, policy_loss: 1.1277, value_loss: 0.7192
2024-07-14 06:08:28,879 [INFO    ] __main__: train step 10459: loss: 1.1002, policy_loss: 1.1276, value_loss: 0.7191
2024-07-14 06:08:29,175 [INFO    ] __main__: train step 10460: loss: 1.1001, policy_loss: 1.1276, value_loss: 0.7191
2024-07-14 06:08:29,470 [INFO    ] __main__: train step 10461: loss: 1.1001, policy_loss: 1.1276, value_loss: 0.7190
2024-07-14 06:08:29,766 [INFO    ] __main__: train step 10462: loss: 1.1001, policy_loss: 1.1275, value_loss: 0.7190
2024-07-14 06:08:30,061 [INFO    ] __main__: train step 10463: loss: 1.1001, policy_loss: 1.1275, value_loss: 0.7189
2024-07-14 06:08:30,349 [INFO    ] __main__: train step 10464: loss: 1.1001, policy_loss: 1.1274, value_loss: 0.7189
2024-07-14 06:08:30,643 [INFO    ] __main__: train step 10465: loss: 1.1001, policy_loss: 1.1274, value_loss: 0.7188
2024-07-14 06:08:30,947 [INFO    ] __main__: train step 10466: loss: 1.1001, policy_loss: 1.1274, value_loss: 0.7188
2024-07-14 06:08:31,230 [INFO    ] __main__: train step 10467: loss: 1.1001, policy_loss: 1.1273, value_loss: 0.7188
2024-07-14 06:08:31,516 [INFO    ] __main__: train step 10468: loss: 1.1000, policy_loss: 1.1273, value_loss: 0.7187
2024-07-14 06:08:33,132 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:08:33,604 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:08:33,676 [INFO    ] __main__: train step 10469: loss: 1.1000, policy_loss: 1.1273, value_loss: 0.7187
2024-07-14 06:08:33,974 [INFO    ] __main__: train step 10470: loss: 1.1000, policy_loss: 1.1272, value_loss: 0.7186
2024-07-14 06:08:34,270 [INFO    ] __main__: train step 10471: loss: 1.1000, policy_loss: 1.1272, value_loss: 0.7186
2024-07-14 06:08:34,550 [INFO    ] __main__: train step 10472: loss: 1.1000, policy_loss: 1.1271, value_loss: 0.7185
2024-07-14 06:08:34,842 [INFO    ] __main__: train step 10473: loss: 1.1000, policy_loss: 1.1271, value_loss: 0.7185
2024-07-14 06:08:35,147 [INFO    ] __main__: train step 10474: loss: 1.1000, policy_loss: 1.1271, value_loss: 0.7184
2024-07-14 06:08:35,442 [INFO    ] __main__: train step 10475: loss: 1.1000, policy_loss: 1.1270, value_loss: 0.7184
2024-07-14 06:08:35,720 [INFO    ] __main__: train step 10476: loss: 1.1000, policy_loss: 1.1270, value_loss: 0.7184
2024-07-14 06:08:35,986 [INFO    ] __main__: train step 10477: loss: 1.0999, policy_loss: 1.1270, value_loss: 0.7183
2024-07-14 06:08:36,291 [INFO    ] __main__: train step 10478: loss: 1.0999, policy_loss: 1.1269, value_loss: 0.7183
2024-07-14 06:08:36,575 [INFO    ] __main__: train step 10479: loss: 1.0999, policy_loss: 1.1269, value_loss: 0.7182
2024-07-14 06:08:36,862 [INFO    ] __main__: train step 10480: loss: 1.0999, policy_loss: 1.1268, value_loss: 0.7182
2024-07-14 06:08:37,168 [INFO    ] __main__: train step 10481: loss: 1.0999, policy_loss: 1.1268, value_loss: 0.7181
2024-07-14 06:08:37,452 [INFO    ] __main__: train step 10482: loss: 1.0999, policy_loss: 1.1268, value_loss: 0.7181
2024-07-14 06:08:37,759 [INFO    ] __main__: train step 10483: loss: 1.0999, policy_loss: 1.1267, value_loss: 0.7180
2024-07-14 06:08:38,060 [INFO    ] __main__: train step 10484: loss: 1.0999, policy_loss: 1.1267, value_loss: 0.7180
2024-07-14 06:08:38,364 [INFO    ] __main__: train step 10485: loss: 1.0999, policy_loss: 1.1267, value_loss: 0.7180
2024-07-14 06:08:39,974 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:08:40,478 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:08:40,546 [INFO    ] __main__: train step 10486: loss: 1.0998, policy_loss: 1.1266, value_loss: 0.7179
2024-07-14 06:08:40,844 [INFO    ] __main__: train step 10487: loss: 1.0998, policy_loss: 1.1266, value_loss: 0.7179
2024-07-14 06:08:41,145 [INFO    ] __main__: train step 10488: loss: 1.0998, policy_loss: 1.1265, value_loss: 0.7178
2024-07-14 06:08:41,431 [INFO    ] __main__: train step 10489: loss: 1.0998, policy_loss: 1.1265, value_loss: 0.7178
2024-07-14 06:08:41,725 [INFO    ] __main__: train step 10490: loss: 1.0998, policy_loss: 1.1265, value_loss: 0.7177
2024-07-14 06:08:42,025 [INFO    ] __main__: train step 10491: loss: 1.0998, policy_loss: 1.1264, value_loss: 0.7177
2024-07-14 06:08:42,333 [INFO    ] __main__: train step 10492: loss: 1.0998, policy_loss: 1.1264, value_loss: 0.7176
2024-07-14 06:08:42,627 [INFO    ] __main__: train step 10493: loss: 1.0998, policy_loss: 1.1264, value_loss: 0.7176
2024-07-14 06:08:42,929 [INFO    ] __main__: train step 10494: loss: 1.0998, policy_loss: 1.1263, value_loss: 0.7176
2024-07-14 06:08:43,228 [INFO    ] __main__: train step 10495: loss: 1.0998, policy_loss: 1.1263, value_loss: 0.7175
2024-07-14 06:08:43,515 [INFO    ] __main__: train step 10496: loss: 1.0997, policy_loss: 1.1262, value_loss: 0.7175
2024-07-14 06:08:43,792 [INFO    ] __main__: train step 10497: loss: 1.0997, policy_loss: 1.1262, value_loss: 0.7174
2024-07-14 06:08:44,061 [INFO    ] __main__: train step 10498: loss: 1.0997, policy_loss: 1.1262, value_loss: 0.7174
2024-07-14 06:08:44,364 [INFO    ] __main__: train step 10499: loss: 1.0997, policy_loss: 1.1261, value_loss: 0.7173
2024-07-14 06:08:44,649 [INFO    ] __main__: train step 10500: loss: 1.0997, policy_loss: 1.1261, value_loss: 0.7173
2024-07-14 06:08:44,940 [INFO    ] __main__: train step 10501: loss: 1.0997, policy_loss: 1.1261, value_loss: 0.7173
2024-07-14 06:08:45,259 [INFO    ] __main__: train step 10502: loss: 1.0997, policy_loss: 1.1260, value_loss: 0.7172
2024-07-14 06:08:46,880 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:08:47,372 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:08:47,445 [INFO    ] __main__: train step 10503: loss: 1.0997, policy_loss: 1.1260, value_loss: 0.7172
2024-07-14 06:08:47,748 [INFO    ] __main__: train step 10504: loss: 1.0997, policy_loss: 1.1259, value_loss: 0.7171
2024-07-14 06:08:48,037 [INFO    ] __main__: train step 10505: loss: 1.0996, policy_loss: 1.1259, value_loss: 0.7171
2024-07-14 06:08:48,326 [INFO    ] __main__: train step 10506: loss: 1.0996, policy_loss: 1.1259, value_loss: 0.7170
2024-07-14 06:08:48,618 [INFO    ] __main__: train step 10507: loss: 1.0996, policy_loss: 1.1258, value_loss: 0.7170
2024-07-14 06:08:48,897 [INFO    ] __main__: train step 10508: loss: 1.0996, policy_loss: 1.1258, value_loss: 0.7169
2024-07-14 06:08:49,198 [INFO    ] __main__: train step 10509: loss: 1.0996, policy_loss: 1.1258, value_loss: 0.7169
2024-07-14 06:08:49,507 [INFO    ] __main__: train step 10510: loss: 1.0996, policy_loss: 1.1257, value_loss: 0.7168
2024-07-14 06:08:49,804 [INFO    ] __main__: train step 10511: loss: 1.0996, policy_loss: 1.1257, value_loss: 0.7168
2024-07-14 06:08:50,094 [INFO    ] __main__: train step 10512: loss: 1.0996, policy_loss: 1.1257, value_loss: 0.7168
2024-07-14 06:08:50,383 [INFO    ] __main__: train step 10513: loss: 1.0996, policy_loss: 1.1256, value_loss: 0.7167
2024-07-14 06:08:53,367 [INFO    ] __main__: train step 10514: loss: 1.0995, policy_loss: 1.1256, value_loss: 0.7167
2024-07-14 06:08:53,659 [INFO    ] __main__: train step 10515: loss: 1.0995, policy_loss: 1.1255, value_loss: 0.7166
2024-07-14 06:08:53,946 [INFO    ] __main__: train step 10516: loss: 1.0995, policy_loss: 1.1255, value_loss: 0.7166
2024-07-14 06:08:54,236 [INFO    ] __main__: train step 10517: loss: 1.0995, policy_loss: 1.1255, value_loss: 0.7165
2024-07-14 06:08:54,536 [INFO    ] __main__: train step 10518: loss: 1.0995, policy_loss: 1.1254, value_loss: 0.7165
2024-07-14 06:08:54,826 [INFO    ] __main__: train step 10519: loss: 1.0995, policy_loss: 1.1254, value_loss: 0.7165
2024-07-14 06:08:56,422 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:08:56,895 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:08:56,966 [INFO    ] __main__: train step 10520: loss: 1.0995, policy_loss: 1.1254, value_loss: 0.7164
2024-07-14 06:08:57,238 [INFO    ] __main__: train step 10521: loss: 1.0995, policy_loss: 1.1253, value_loss: 0.7164
2024-07-14 06:08:57,510 [INFO    ] __main__: train step 10522: loss: 1.0995, policy_loss: 1.1253, value_loss: 0.7163
2024-07-14 06:08:57,779 [INFO    ] __main__: train step 10523: loss: 1.0995, policy_loss: 1.1252, value_loss: 0.7163
2024-07-14 06:08:58,054 [INFO    ] __main__: train step 10524: loss: 1.0994, policy_loss: 1.1252, value_loss: 0.7162
2024-07-14 06:08:58,346 [INFO    ] __main__: train step 10525: loss: 1.0994, policy_loss: 1.1252, value_loss: 0.7162
2024-07-14 06:08:58,641 [INFO    ] __main__: train step 10526: loss: 1.0994, policy_loss: 1.1251, value_loss: 0.7161
2024-07-14 06:08:58,937 [INFO    ] __main__: train step 10527: loss: 1.0994, policy_loss: 1.1251, value_loss: 0.7161
2024-07-14 06:08:59,220 [INFO    ] __main__: train step 10528: loss: 1.0994, policy_loss: 1.1251, value_loss: 0.7161
2024-07-14 06:08:59,513 [INFO    ] __main__: train step 10529: loss: 1.0994, policy_loss: 1.1250, value_loss: 0.7160
2024-07-14 06:08:59,801 [INFO    ] __main__: train step 10530: loss: 1.0994, policy_loss: 1.1250, value_loss: 0.7160
2024-07-14 06:09:00,104 [INFO    ] __main__: train step 10531: loss: 1.0994, policy_loss: 1.1250, value_loss: 0.7159
2024-07-14 06:09:00,394 [INFO    ] __main__: train step 10532: loss: 1.0994, policy_loss: 1.1249, value_loss: 0.7159
2024-07-14 06:09:00,697 [INFO    ] __main__: train step 10533: loss: 1.0994, policy_loss: 1.1249, value_loss: 0.7158
2024-07-14 06:09:01,006 [INFO    ] __main__: train step 10534: loss: 1.0993, policy_loss: 1.1248, value_loss: 0.7158
2024-07-14 06:09:01,296 [INFO    ] __main__: train step 10535: loss: 1.0993, policy_loss: 1.1248, value_loss: 0.7157
2024-07-14 06:09:01,579 [INFO    ] __main__: train step 10536: loss: 1.0993, policy_loss: 1.1248, value_loss: 0.7157
2024-07-14 06:09:03,214 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:09:03,704 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:09:03,778 [INFO    ] __main__: train step 10537: loss: 1.0993, policy_loss: 1.1247, value_loss: 0.7157
2024-07-14 06:09:04,044 [INFO    ] __main__: train step 10538: loss: 1.0993, policy_loss: 1.1247, value_loss: 0.7156
2024-07-14 06:09:04,328 [INFO    ] __main__: train step 10539: loss: 1.0993, policy_loss: 1.1247, value_loss: 0.7156
2024-07-14 06:09:04,617 [INFO    ] __main__: train step 10540: loss: 1.0993, policy_loss: 1.1246, value_loss: 0.7155
2024-07-14 06:09:04,908 [INFO    ] __main__: train step 10541: loss: 1.0993, policy_loss: 1.1246, value_loss: 0.7155
2024-07-14 06:09:05,201 [INFO    ] __main__: train step 10542: loss: 1.0993, policy_loss: 1.1245, value_loss: 0.7154
2024-07-14 06:09:05,495 [INFO    ] __main__: train step 10543: loss: 1.0992, policy_loss: 1.1245, value_loss: 0.7154
2024-07-14 06:09:05,790 [INFO    ] __main__: train step 10544: loss: 1.0992, policy_loss: 1.1245, value_loss: 0.7154
2024-07-14 06:09:06,076 [INFO    ] __main__: train step 10545: loss: 1.0992, policy_loss: 1.1244, value_loss: 0.7153
2024-07-14 06:09:06,365 [INFO    ] __main__: train step 10546: loss: 1.0992, policy_loss: 1.1244, value_loss: 0.7153
2024-07-14 06:09:06,647 [INFO    ] __main__: train step 10547: loss: 1.0992, policy_loss: 1.1244, value_loss: 0.7152
2024-07-14 06:09:06,936 [INFO    ] __main__: train step 10548: loss: 1.0992, policy_loss: 1.1243, value_loss: 0.7152
2024-07-14 06:09:07,218 [INFO    ] __main__: train step 10549: loss: 1.0992, policy_loss: 1.1243, value_loss: 0.7151
2024-07-14 06:09:07,514 [INFO    ] __main__: train step 10550: loss: 1.0992, policy_loss: 1.1243, value_loss: 0.7151
2024-07-14 06:09:07,804 [INFO    ] __main__: train step 10551: loss: 1.0992, policy_loss: 1.1242, value_loss: 0.7150
2024-07-14 06:09:08,085 [INFO    ] __main__: train step 10552: loss: 1.0992, policy_loss: 1.1242, value_loss: 0.7150
2024-07-14 06:09:08,377 [INFO    ] __main__: train step 10553: loss: 1.0991, policy_loss: 1.1241, value_loss: 0.7150
2024-07-14 06:09:09,988 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:09:10,482 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:09:10,553 [INFO    ] __main__: train step 10554: loss: 1.0991, policy_loss: 1.1241, value_loss: 0.7149
2024-07-14 06:09:10,828 [INFO    ] __main__: train step 10555: loss: 1.0991, policy_loss: 1.1241, value_loss: 0.7149
2024-07-14 06:09:11,117 [INFO    ] __main__: train step 10556: loss: 1.0991, policy_loss: 1.1240, value_loss: 0.7148
2024-07-14 06:09:11,408 [INFO    ] __main__: train step 10557: loss: 1.0991, policy_loss: 1.1240, value_loss: 0.7148
2024-07-14 06:09:11,673 [INFO    ] __main__: train step 10558: loss: 1.0991, policy_loss: 1.1240, value_loss: 0.7147
2024-07-14 06:09:11,935 [INFO    ] __main__: train step 10559: loss: 1.0991, policy_loss: 1.1239, value_loss: 0.7147
2024-07-14 06:09:12,204 [INFO    ] __main__: train step 10560: loss: 1.0991, policy_loss: 1.1239, value_loss: 0.7146
2024-07-14 06:09:12,471 [INFO    ] __main__: train step 10561: loss: 1.0991, policy_loss: 1.1239, value_loss: 0.7146
2024-07-14 06:09:12,767 [INFO    ] __main__: train step 10562: loss: 1.0991, policy_loss: 1.1238, value_loss: 0.7146
2024-07-14 06:09:13,056 [INFO    ] __main__: train step 10563: loss: 1.0991, policy_loss: 1.1238, value_loss: 0.7145
2024-07-14 06:09:13,350 [INFO    ] __main__: train step 10564: loss: 1.0990, policy_loss: 1.1238, value_loss: 0.7145
2024-07-14 06:09:13,641 [INFO    ] __main__: train step 10565: loss: 1.0990, policy_loss: 1.1237, value_loss: 0.7144
2024-07-14 06:09:13,947 [INFO    ] __main__: train step 10566: loss: 1.0990, policy_loss: 1.1237, value_loss: 0.7144
2024-07-14 06:09:14,237 [INFO    ] __main__: train step 10567: loss: 1.0990, policy_loss: 1.1237, value_loss: 0.7143
2024-07-14 06:09:14,541 [INFO    ] __main__: train step 10568: loss: 1.0990, policy_loss: 1.1236, value_loss: 0.7143
2024-07-14 06:09:14,824 [INFO    ] __main__: train step 10569: loss: 1.0990, policy_loss: 1.1236, value_loss: 0.7142
2024-07-14 06:09:15,119 [INFO    ] __main__: train step 10570: loss: 1.0990, policy_loss: 1.1235, value_loss: 0.7142
2024-07-14 06:09:16,744 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:09:17,239 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:09:17,311 [INFO    ] __main__: train step 10571: loss: 1.0990, policy_loss: 1.1235, value_loss: 0.7142
2024-07-14 06:09:17,594 [INFO    ] __main__: train step 10572: loss: 1.0990, policy_loss: 1.1235, value_loss: 0.7141
2024-07-14 06:09:17,878 [INFO    ] __main__: train step 10573: loss: 1.0989, policy_loss: 1.1234, value_loss: 0.7141
2024-07-14 06:09:18,172 [INFO    ] __main__: train step 10574: loss: 1.0989, policy_loss: 1.1234, value_loss: 0.7140
2024-07-14 06:09:18,460 [INFO    ] __main__: train step 10575: loss: 1.0989, policy_loss: 1.1234, value_loss: 0.7140
2024-07-14 06:09:18,759 [INFO    ] __main__: train step 10576: loss: 1.0989, policy_loss: 1.1233, value_loss: 0.7139
2024-07-14 06:09:19,060 [INFO    ] __main__: train step 10577: loss: 1.0989, policy_loss: 1.1233, value_loss: 0.7139
2024-07-14 06:09:19,362 [INFO    ] __main__: train step 10578: loss: 1.0989, policy_loss: 1.1232, value_loss: 0.7139
2024-07-14 06:09:19,651 [INFO    ] __main__: train step 10579: loss: 1.0989, policy_loss: 1.1232, value_loss: 0.7138
2024-07-14 06:09:19,944 [INFO    ] __main__: train step 10580: loss: 1.0989, policy_loss: 1.1232, value_loss: 0.7138
2024-07-14 06:09:20,236 [INFO    ] __main__: train step 10581: loss: 1.0989, policy_loss: 1.1231, value_loss: 0.7137
2024-07-14 06:09:20,530 [INFO    ] __main__: train step 10582: loss: 1.0989, policy_loss: 1.1231, value_loss: 0.7137
2024-07-14 06:09:20,811 [INFO    ] __main__: train step 10583: loss: 1.0989, policy_loss: 1.1231, value_loss: 0.7136
2024-07-14 06:09:21,095 [INFO    ] __main__: train step 10584: loss: 1.0988, policy_loss: 1.1230, value_loss: 0.7136
2024-07-14 06:09:21,390 [INFO    ] __main__: train step 10585: loss: 1.0988, policy_loss: 1.1230, value_loss: 0.7136
2024-07-14 06:09:21,677 [INFO    ] __main__: train step 10586: loss: 1.0988, policy_loss: 1.1230, value_loss: 0.7135
2024-07-14 06:09:21,981 [INFO    ] __main__: train step 10587: loss: 1.0988, policy_loss: 1.1229, value_loss: 0.7135
2024-07-14 06:09:23,608 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:09:24,101 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:09:24,169 [INFO    ] __main__: train step 10588: loss: 1.0988, policy_loss: 1.1229, value_loss: 0.7134
2024-07-14 06:09:24,459 [INFO    ] __main__: train step 10589: loss: 1.0988, policy_loss: 1.1229, value_loss: 0.7134
2024-07-14 06:09:24,745 [INFO    ] __main__: train step 10590: loss: 1.0988, policy_loss: 1.1228, value_loss: 0.7133
2024-07-14 06:09:25,039 [INFO    ] __main__: train step 10591: loss: 1.0988, policy_loss: 1.1228, value_loss: 0.7133
2024-07-14 06:09:25,329 [INFO    ] __main__: train step 10592: loss: 1.0988, policy_loss: 1.1228, value_loss: 0.7133
2024-07-14 06:09:25,629 [INFO    ] __main__: train step 10593: loss: 1.0988, policy_loss: 1.1227, value_loss: 0.7132
2024-07-14 06:09:25,928 [INFO    ] __main__: train step 10594: loss: 1.0988, policy_loss: 1.1227, value_loss: 0.7132
2024-07-14 06:09:26,216 [INFO    ] __main__: train step 10595: loss: 1.0987, policy_loss: 1.1226, value_loss: 0.7131
2024-07-14 06:09:26,499 [INFO    ] __main__: train step 10596: loss: 1.0987, policy_loss: 1.1226, value_loss: 0.7131
2024-07-14 06:09:26,793 [INFO    ] __main__: train step 10597: loss: 1.0987, policy_loss: 1.1226, value_loss: 0.7130
2024-07-14 06:09:27,080 [INFO    ] __main__: train step 10598: loss: 1.0987, policy_loss: 1.1225, value_loss: 0.7130
2024-07-14 06:09:27,378 [INFO    ] __main__: train step 10599: loss: 1.0987, policy_loss: 1.1225, value_loss: 0.7129
2024-07-14 06:09:27,672 [INFO    ] __main__: train step 10600: loss: 1.0987, policy_loss: 1.1225, value_loss: 0.7129
2024-07-14 06:09:27,964 [INFO    ] __main__: train step 10601: loss: 1.0987, policy_loss: 1.1224, value_loss: 0.7129
2024-07-14 06:09:28,250 [INFO    ] __main__: train step 10602: loss: 1.0987, policy_loss: 1.1224, value_loss: 0.7128
2024-07-14 06:09:31,173 [INFO    ] __main__: train step 10603: loss: 1.0987, policy_loss: 1.1224, value_loss: 0.7128
2024-07-14 06:09:31,466 [INFO    ] __main__: train step 10604: loss: 1.0987, policy_loss: 1.1223, value_loss: 0.7127
2024-07-14 06:09:33,101 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:09:33,591 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:09:33,666 [INFO    ] __main__: train step 10605: loss: 1.0987, policy_loss: 1.1223, value_loss: 0.7127
2024-07-14 06:09:33,962 [INFO    ] __main__: train step 10606: loss: 1.0986, policy_loss: 1.1223, value_loss: 0.7126
2024-07-14 06:09:34,264 [INFO    ] __main__: train step 10607: loss: 1.0986, policy_loss: 1.1222, value_loss: 0.7126
2024-07-14 06:09:34,569 [INFO    ] __main__: train step 10608: loss: 1.0986, policy_loss: 1.1222, value_loss: 0.7126
2024-07-14 06:09:34,862 [INFO    ] __main__: train step 10609: loss: 1.0986, policy_loss: 1.1222, value_loss: 0.7125
2024-07-14 06:09:35,165 [INFO    ] __main__: train step 10610: loss: 1.0986, policy_loss: 1.1221, value_loss: 0.7125
2024-07-14 06:09:35,459 [INFO    ] __main__: train step 10611: loss: 1.0986, policy_loss: 1.1221, value_loss: 0.7124
2024-07-14 06:09:35,751 [INFO    ] __main__: train step 10612: loss: 1.0986, policy_loss: 1.1221, value_loss: 0.7124
2024-07-14 06:09:36,052 [INFO    ] __main__: train step 10613: loss: 1.0986, policy_loss: 1.1220, value_loss: 0.7123
2024-07-14 06:09:36,357 [INFO    ] __main__: train step 10614: loss: 1.0986, policy_loss: 1.1220, value_loss: 0.7123
2024-07-14 06:09:36,645 [INFO    ] __main__: train step 10615: loss: 1.0986, policy_loss: 1.1219, value_loss: 0.7123
2024-07-14 06:09:36,943 [INFO    ] __main__: train step 10616: loss: 1.0986, policy_loss: 1.1219, value_loss: 0.7122
2024-07-14 06:09:37,218 [INFO    ] __main__: train step 10617: loss: 1.0986, policy_loss: 1.1219, value_loss: 0.7122
2024-07-14 06:09:37,510 [INFO    ] __main__: train step 10618: loss: 1.0985, policy_loss: 1.1218, value_loss: 0.7121
2024-07-14 06:09:37,805 [INFO    ] __main__: train step 10619: loss: 1.0985, policy_loss: 1.1218, value_loss: 0.7121
2024-07-14 06:09:38,100 [INFO    ] __main__: train step 10620: loss: 1.0985, policy_loss: 1.1218, value_loss: 0.7120
2024-07-14 06:09:38,397 [INFO    ] __main__: train step 10621: loss: 1.0985, policy_loss: 1.1217, value_loss: 0.7120
2024-07-14 06:09:40,015 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:09:40,506 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:09:40,579 [INFO    ] __main__: train step 10622: loss: 1.0985, policy_loss: 1.1217, value_loss: 0.7120
2024-07-14 06:09:40,868 [INFO    ] __main__: train step 10623: loss: 1.0985, policy_loss: 1.1217, value_loss: 0.7119
2024-07-14 06:09:41,143 [INFO    ] __main__: train step 10624: loss: 1.0985, policy_loss: 1.1216, value_loss: 0.7119
2024-07-14 06:09:41,426 [INFO    ] __main__: train step 10625: loss: 1.0985, policy_loss: 1.1216, value_loss: 0.7118
2024-07-14 06:09:41,710 [INFO    ] __main__: train step 10626: loss: 1.0985, policy_loss: 1.1216, value_loss: 0.7118
2024-07-14 06:09:42,010 [INFO    ] __main__: train step 10627: loss: 1.0985, policy_loss: 1.1215, value_loss: 0.7117
2024-07-14 06:09:42,303 [INFO    ] __main__: train step 10628: loss: 1.0985, policy_loss: 1.1215, value_loss: 0.7117
2024-07-14 06:09:42,602 [INFO    ] __main__: train step 10629: loss: 1.0985, policy_loss: 1.1215, value_loss: 0.7117
2024-07-14 06:09:42,894 [INFO    ] __main__: train step 10630: loss: 1.0984, policy_loss: 1.1214, value_loss: 0.7116
2024-07-14 06:09:43,203 [INFO    ] __main__: train step 10631: loss: 1.0984, policy_loss: 1.1214, value_loss: 0.7116
2024-07-14 06:09:43,478 [INFO    ] __main__: train step 10632: loss: 1.0984, policy_loss: 1.1214, value_loss: 0.7115
2024-07-14 06:09:43,778 [INFO    ] __main__: train step 10633: loss: 1.0984, policy_loss: 1.1213, value_loss: 0.7115
2024-07-14 06:09:44,070 [INFO    ] __main__: train step 10634: loss: 1.0984, policy_loss: 1.1213, value_loss: 0.7114
2024-07-14 06:09:44,355 [INFO    ] __main__: train step 10635: loss: 1.0984, policy_loss: 1.1213, value_loss: 0.7114
2024-07-14 06:09:44,639 [INFO    ] __main__: train step 10636: loss: 1.0984, policy_loss: 1.1212, value_loss: 0.7113
2024-07-14 06:09:44,925 [INFO    ] __main__: train step 10637: loss: 1.0984, policy_loss: 1.1212, value_loss: 0.7113
2024-07-14 06:09:45,193 [INFO    ] __main__: train step 10638: loss: 1.0984, policy_loss: 1.1211, value_loss: 0.7113
2024-07-14 06:09:46,800 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:09:47,280 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:09:47,352 [INFO    ] __main__: train step 10639: loss: 1.0984, policy_loss: 1.1211, value_loss: 0.7112
2024-07-14 06:09:47,642 [INFO    ] __main__: train step 10640: loss: 1.0984, policy_loss: 1.1211, value_loss: 0.7112
2024-07-14 06:09:47,942 [INFO    ] __main__: train step 10641: loss: 1.0983, policy_loss: 1.1210, value_loss: 0.7111
2024-07-14 06:09:48,231 [INFO    ] __main__: train step 10642: loss: 1.0983, policy_loss: 1.1210, value_loss: 0.7111
2024-07-14 06:09:48,522 [INFO    ] __main__: train step 10643: loss: 1.0983, policy_loss: 1.1210, value_loss: 0.7111
2024-07-14 06:09:48,786 [INFO    ] __main__: train step 10644: loss: 1.0983, policy_loss: 1.1209, value_loss: 0.7110
2024-07-14 06:09:49,053 [INFO    ] __main__: train step 10645: loss: 1.0983, policy_loss: 1.1209, value_loss: 0.7110
2024-07-14 06:09:49,312 [INFO    ] __main__: train step 10646: loss: 1.0983, policy_loss: 1.1209, value_loss: 0.7109
2024-07-14 06:09:49,591 [INFO    ] __main__: train step 10647: loss: 1.0983, policy_loss: 1.1208, value_loss: 0.7109
2024-07-14 06:09:49,881 [INFO    ] __main__: train step 10648: loss: 1.0983, policy_loss: 1.1208, value_loss: 0.7108
2024-07-14 06:09:50,172 [INFO    ] __main__: train step 10649: loss: 1.0983, policy_loss: 1.1208, value_loss: 0.7108
2024-07-14 06:09:50,462 [INFO    ] __main__: train step 10650: loss: 1.0983, policy_loss: 1.1207, value_loss: 0.7108
2024-07-14 06:09:50,766 [INFO    ] __main__: train step 10651: loss: 1.0983, policy_loss: 1.1207, value_loss: 0.7107
2024-07-14 06:09:51,059 [INFO    ] __main__: train step 10652: loss: 1.0983, policy_loss: 1.1207, value_loss: 0.7107
2024-07-14 06:09:51,359 [INFO    ] __main__: train step 10653: loss: 1.0983, policy_loss: 1.1206, value_loss: 0.7106
2024-07-14 06:09:51,649 [INFO    ] __main__: train step 10654: loss: 1.0982, policy_loss: 1.1206, value_loss: 0.7106
2024-07-14 06:09:51,936 [INFO    ] __main__: train step 10655: loss: 1.0982, policy_loss: 1.1206, value_loss: 0.7105
2024-07-14 06:09:53,554 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:09:54,051 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:09:54,120 [INFO    ] __main__: train step 10656: loss: 1.0982, policy_loss: 1.1205, value_loss: 0.7105
2024-07-14 06:09:54,420 [INFO    ] __main__: train step 10657: loss: 1.0982, policy_loss: 1.1205, value_loss: 0.7105
2024-07-14 06:09:54,710 [INFO    ] __main__: train step 10658: loss: 1.0982, policy_loss: 1.1205, value_loss: 0.7104
2024-07-14 06:09:55,002 [INFO    ] __main__: train step 10659: loss: 1.0982, policy_loss: 1.1204, value_loss: 0.7104
2024-07-14 06:09:55,290 [INFO    ] __main__: train step 10660: loss: 1.0982, policy_loss: 1.1204, value_loss: 0.7103
2024-07-14 06:09:55,595 [INFO    ] __main__: train step 10661: loss: 1.0982, policy_loss: 1.1204, value_loss: 0.7103
2024-07-14 06:09:55,892 [INFO    ] __main__: train step 10662: loss: 1.0982, policy_loss: 1.1203, value_loss: 0.7102
2024-07-14 06:09:56,184 [INFO    ] __main__: train step 10663: loss: 1.0982, policy_loss: 1.1203, value_loss: 0.7102
2024-07-14 06:09:56,475 [INFO    ] __main__: train step 10664: loss: 1.0982, policy_loss: 1.1203, value_loss: 0.7102
2024-07-14 06:09:56,765 [INFO    ] __main__: train step 10665: loss: 1.0982, policy_loss: 1.1202, value_loss: 0.7101
2024-07-14 06:09:57,045 [INFO    ] __main__: train step 10666: loss: 1.0982, policy_loss: 1.1202, value_loss: 0.7101
2024-07-14 06:09:57,338 [INFO    ] __main__: train step 10667: loss: 1.0981, policy_loss: 1.1202, value_loss: 0.7100
2024-07-14 06:09:57,639 [INFO    ] __main__: train step 10668: loss: 1.0981, policy_loss: 1.1201, value_loss: 0.7100
2024-07-14 06:09:57,930 [INFO    ] __main__: train step 10669: loss: 1.0981, policy_loss: 1.1201, value_loss: 0.7099
2024-07-14 06:09:58,213 [INFO    ] __main__: train step 10670: loss: 1.0981, policy_loss: 1.1201, value_loss: 0.7099
2024-07-14 06:09:58,499 [INFO    ] __main__: train step 10671: loss: 1.0981, policy_loss: 1.1200, value_loss: 0.7099
2024-07-14 06:09:58,799 [INFO    ] __main__: train step 10672: loss: 1.0981, policy_loss: 1.1200, value_loss: 0.7098
2024-07-14 06:10:00,385 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:10:00,861 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:10:00,929 [INFO    ] __main__: train step 10673: loss: 1.0981, policy_loss: 1.1200, value_loss: 0.7098
2024-07-14 06:10:01,191 [INFO    ] __main__: train step 10674: loss: 1.0981, policy_loss: 1.1199, value_loss: 0.7097
2024-07-14 06:10:01,443 [INFO    ] __main__: train step 10675: loss: 1.0981, policy_loss: 1.1199, value_loss: 0.7097
2024-07-14 06:10:01,716 [INFO    ] __main__: train step 10676: loss: 1.0981, policy_loss: 1.1199, value_loss: 0.7096
2024-07-14 06:10:02,001 [INFO    ] __main__: train step 10677: loss: 1.0981, policy_loss: 1.1198, value_loss: 0.7096
2024-07-14 06:10:02,291 [INFO    ] __main__: train step 10678: loss: 1.0981, policy_loss: 1.1198, value_loss: 0.7096
2024-07-14 06:10:02,589 [INFO    ] __main__: train step 10679: loss: 1.0981, policy_loss: 1.1198, value_loss: 0.7095
2024-07-14 06:10:02,876 [INFO    ] __main__: train step 10680: loss: 1.0980, policy_loss: 1.1197, value_loss: 0.7095
2024-07-14 06:10:03,169 [INFO    ] __main__: train step 10681: loss: 1.0980, policy_loss: 1.1197, value_loss: 0.7094
2024-07-14 06:10:03,448 [INFO    ] __main__: train step 10682: loss: 1.0980, policy_loss: 1.1197, value_loss: 0.7094
2024-07-14 06:10:03,727 [INFO    ] __main__: train step 10683: loss: 1.0980, policy_loss: 1.1196, value_loss: 0.7093
2024-07-14 06:10:04,013 [INFO    ] __main__: train step 10684: loss: 1.0980, policy_loss: 1.1196, value_loss: 0.7093
2024-07-14 06:10:04,302 [INFO    ] __main__: train step 10685: loss: 1.0980, policy_loss: 1.1196, value_loss: 0.7093
2024-07-14 06:10:04,594 [INFO    ] __main__: train step 10686: loss: 1.0980, policy_loss: 1.1195, value_loss: 0.7092
2024-07-14 06:10:04,882 [INFO    ] __main__: train step 10687: loss: 1.0980, policy_loss: 1.1195, value_loss: 0.7092
2024-07-14 06:10:05,178 [INFO    ] __main__: train step 10688: loss: 1.0980, policy_loss: 1.1195, value_loss: 0.7091
2024-07-14 06:10:05,468 [INFO    ] __main__: train step 10689: loss: 1.0980, policy_loss: 1.1194, value_loss: 0.7091
2024-07-14 06:10:07,098 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:10:07,591 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:10:07,664 [INFO    ] __main__: train step 10690: loss: 1.0980, policy_loss: 1.1194, value_loss: 0.7090
2024-07-14 06:10:07,950 [INFO    ] __main__: train step 10691: loss: 1.0980, policy_loss: 1.1194, value_loss: 0.7090
2024-07-14 06:10:08,245 [INFO    ] __main__: train step 10692: loss: 1.0980, policy_loss: 1.1193, value_loss: 0.7090
2024-07-14 06:10:11,060 [INFO    ] __main__: train step 10693: loss: 1.0980, policy_loss: 1.1193, value_loss: 0.7089
2024-07-14 06:10:11,355 [INFO    ] __main__: train step 10694: loss: 1.0980, policy_loss: 1.1193, value_loss: 0.7089
2024-07-14 06:10:11,640 [INFO    ] __main__: train step 10695: loss: 1.0980, policy_loss: 1.1192, value_loss: 0.7088
2024-07-14 06:10:11,935 [INFO    ] __main__: train step 10696: loss: 1.0979, policy_loss: 1.1192, value_loss: 0.7088
2024-07-14 06:10:12,221 [INFO    ] __main__: train step 10697: loss: 1.0979, policy_loss: 1.1192, value_loss: 0.7088
2024-07-14 06:10:12,510 [INFO    ] __main__: train step 10698: loss: 1.0979, policy_loss: 1.1191, value_loss: 0.7087
2024-07-14 06:10:12,805 [INFO    ] __main__: train step 10699: loss: 1.0979, policy_loss: 1.1191, value_loss: 0.7087
2024-07-14 06:10:13,098 [INFO    ] __main__: train step 10700: loss: 1.0979, policy_loss: 1.1191, value_loss: 0.7086
2024-07-14 06:10:13,393 [INFO    ] __main__: train step 10701: loss: 1.0979, policy_loss: 1.1190, value_loss: 0.7086
2024-07-14 06:10:13,683 [INFO    ] __main__: train step 10702: loss: 1.0979, policy_loss: 1.1190, value_loss: 0.7085
2024-07-14 06:10:13,971 [INFO    ] __main__: train step 10703: loss: 1.0979, policy_loss: 1.1190, value_loss: 0.7085
2024-07-14 06:10:14,271 [INFO    ] __main__: train step 10704: loss: 1.0979, policy_loss: 1.1189, value_loss: 0.7085
2024-07-14 06:10:14,555 [INFO    ] __main__: train step 10705: loss: 1.0979, policy_loss: 1.1189, value_loss: 0.7084
2024-07-14 06:10:14,843 [INFO    ] __main__: train step 10706: loss: 1.0979, policy_loss: 1.1189, value_loss: 0.7084
2024-07-14 06:10:16,428 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:10:16,907 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:10:16,979 [INFO    ] __main__: train step 10707: loss: 1.0979, policy_loss: 1.1188, value_loss: 0.7083
2024-07-14 06:10:17,273 [INFO    ] __main__: train step 10708: loss: 1.0979, policy_loss: 1.1188, value_loss: 0.7083
2024-07-14 06:10:17,566 [INFO    ] __main__: train step 10709: loss: 1.0979, policy_loss: 1.1188, value_loss: 0.7082
2024-07-14 06:10:17,854 [INFO    ] __main__: train step 10710: loss: 1.0978, policy_loss: 1.1188, value_loss: 0.7082
2024-07-14 06:10:18,142 [INFO    ] __main__: train step 10711: loss: 1.0978, policy_loss: 1.1187, value_loss: 0.7082
2024-07-14 06:10:18,427 [INFO    ] __main__: train step 10712: loss: 1.0978, policy_loss: 1.1187, value_loss: 0.7081
2024-07-14 06:10:18,703 [INFO    ] __main__: train step 10713: loss: 1.0978, policy_loss: 1.1187, value_loss: 0.7081
2024-07-14 06:10:19,000 [INFO    ] __main__: train step 10714: loss: 1.0978, policy_loss: 1.1186, value_loss: 0.7080
2024-07-14 06:10:19,290 [INFO    ] __main__: train step 10715: loss: 1.0978, policy_loss: 1.1186, value_loss: 0.7080
2024-07-14 06:10:19,620 [INFO    ] __main__: train step 10716: loss: 1.0978, policy_loss: 1.1186, value_loss: 0.7079
2024-07-14 06:10:19,908 [INFO    ] __main__: train step 10717: loss: 1.0978, policy_loss: 1.1185, value_loss: 0.7079
2024-07-14 06:10:20,210 [INFO    ] __main__: train step 10718: loss: 1.0978, policy_loss: 1.1185, value_loss: 0.7079
2024-07-14 06:10:20,511 [INFO    ] __main__: train step 10719: loss: 1.0978, policy_loss: 1.1185, value_loss: 0.7078
2024-07-14 06:10:20,807 [INFO    ] __main__: train step 10720: loss: 1.0978, policy_loss: 1.1184, value_loss: 0.7078
2024-07-14 06:10:21,098 [INFO    ] __main__: train step 10721: loss: 1.0978, policy_loss: 1.1184, value_loss: 0.7077
2024-07-14 06:10:21,385 [INFO    ] __main__: train step 10722: loss: 1.0978, policy_loss: 1.1184, value_loss: 0.7077
2024-07-14 06:10:21,663 [INFO    ] __main__: train step 10723: loss: 1.0978, policy_loss: 1.1183, value_loss: 0.7076
2024-07-14 06:10:23,280 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:10:23,789 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:10:23,863 [INFO    ] __main__: train step 10724: loss: 1.0977, policy_loss: 1.1183, value_loss: 0.7076
2024-07-14 06:10:24,177 [INFO    ] __main__: train step 10725: loss: 1.0977, policy_loss: 1.1183, value_loss: 0.7076
2024-07-14 06:10:24,480 [INFO    ] __main__: train step 10726: loss: 1.0977, policy_loss: 1.1182, value_loss: 0.7075
2024-07-14 06:10:24,777 [INFO    ] __main__: train step 10727: loss: 1.0977, policy_loss: 1.1182, value_loss: 0.7075
2024-07-14 06:10:25,072 [INFO    ] __main__: train step 10728: loss: 1.0977, policy_loss: 1.1182, value_loss: 0.7074
2024-07-14 06:10:25,368 [INFO    ] __main__: train step 10729: loss: 1.0977, policy_loss: 1.1181, value_loss: 0.7074
2024-07-14 06:10:25,660 [INFO    ] __main__: train step 10730: loss: 1.0977, policy_loss: 1.1181, value_loss: 0.7073
2024-07-14 06:10:25,960 [INFO    ] __main__: train step 10731: loss: 1.0977, policy_loss: 1.1181, value_loss: 0.7073
2024-07-14 06:10:26,265 [INFO    ] __main__: train step 10732: loss: 1.0977, policy_loss: 1.1180, value_loss: 0.7073
2024-07-14 06:10:26,548 [INFO    ] __main__: train step 10733: loss: 1.0977, policy_loss: 1.1180, value_loss: 0.7072
2024-07-14 06:10:26,839 [INFO    ] __main__: train step 10734: loss: 1.0977, policy_loss: 1.1180, value_loss: 0.7072
2024-07-14 06:10:27,135 [INFO    ] __main__: train step 10735: loss: 1.0977, policy_loss: 1.1179, value_loss: 0.7071
2024-07-14 06:10:27,432 [INFO    ] __main__: train step 10736: loss: 1.0977, policy_loss: 1.1179, value_loss: 0.7071
2024-07-14 06:10:27,712 [INFO    ] __main__: train step 10737: loss: 1.0977, policy_loss: 1.1179, value_loss: 0.7071
2024-07-14 06:10:27,988 [INFO    ] __main__: train step 10738: loss: 1.0976, policy_loss: 1.1178, value_loss: 0.7070
2024-07-14 06:10:28,282 [INFO    ] __main__: train step 10739: loss: 1.0976, policy_loss: 1.1178, value_loss: 0.7070
2024-07-14 06:10:28,573 [INFO    ] __main__: train step 10740: loss: 1.0976, policy_loss: 1.1178, value_loss: 0.7069
2024-07-14 06:10:30,187 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:10:30,688 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:10:30,761 [INFO    ] __main__: train step 10741: loss: 1.0976, policy_loss: 1.1177, value_loss: 0.7069
2024-07-14 06:10:31,036 [INFO    ] __main__: train step 10742: loss: 1.0976, policy_loss: 1.1177, value_loss: 0.7068
2024-07-14 06:10:31,329 [INFO    ] __main__: train step 10743: loss: 1.0976, policy_loss: 1.1177, value_loss: 0.7068
2024-07-14 06:10:31,649 [INFO    ] __main__: train step 10744: loss: 1.0976, policy_loss: 1.1176, value_loss: 0.7068
2024-07-14 06:10:31,944 [INFO    ] __main__: train step 10745: loss: 1.0976, policy_loss: 1.1176, value_loss: 0.7067
2024-07-14 06:10:32,230 [INFO    ] __main__: train step 10746: loss: 1.0976, policy_loss: 1.1176, value_loss: 0.7067
2024-07-14 06:10:32,517 [INFO    ] __main__: train step 10747: loss: 1.0976, policy_loss: 1.1176, value_loss: 0.7066
2024-07-14 06:10:32,816 [INFO    ] __main__: train step 10748: loss: 1.0976, policy_loss: 1.1175, value_loss: 0.7066
2024-07-14 06:10:33,111 [INFO    ] __main__: train step 10749: loss: 1.0976, policy_loss: 1.1175, value_loss: 0.7065
2024-07-14 06:10:33,402 [INFO    ] __main__: train step 10750: loss: 1.0976, policy_loss: 1.1175, value_loss: 0.7065
2024-07-14 06:10:33,699 [INFO    ] __main__: train step 10751: loss: 1.0976, policy_loss: 1.1174, value_loss: 0.7065
2024-07-14 06:10:33,993 [INFO    ] __main__: train step 10752: loss: 1.0976, policy_loss: 1.1174, value_loss: 0.7064
2024-07-14 06:10:34,292 [INFO    ] __main__: train step 10753: loss: 1.0976, policy_loss: 1.1174, value_loss: 0.7064
2024-07-14 06:10:34,582 [INFO    ] __main__: train step 10754: loss: 1.0975, policy_loss: 1.1173, value_loss: 0.7063
2024-07-14 06:10:34,877 [INFO    ] __main__: train step 10755: loss: 1.0975, policy_loss: 1.1173, value_loss: 0.7063
2024-07-14 06:10:35,164 [INFO    ] __main__: train step 10756: loss: 1.0975, policy_loss: 1.1173, value_loss: 0.7063
2024-07-14 06:10:35,460 [INFO    ] __main__: train step 10757: loss: 1.0975, policy_loss: 1.1172, value_loss: 0.7062
2024-07-14 06:10:37,099 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:10:37,591 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:10:37,666 [INFO    ] __main__: train step 10758: loss: 1.0975, policy_loss: 1.1172, value_loss: 0.7062
2024-07-14 06:10:37,959 [INFO    ] __main__: train step 10759: loss: 1.0975, policy_loss: 1.1172, value_loss: 0.7061
2024-07-14 06:10:38,234 [INFO    ] __main__: train step 10760: loss: 1.0975, policy_loss: 1.1171, value_loss: 0.7061
2024-07-14 06:10:38,535 [INFO    ] __main__: train step 10761: loss: 1.0975, policy_loss: 1.1171, value_loss: 0.7060
2024-07-14 06:10:38,821 [INFO    ] __main__: train step 10762: loss: 1.0975, policy_loss: 1.1171, value_loss: 0.7060
2024-07-14 06:10:39,111 [INFO    ] __main__: train step 10763: loss: 1.0975, policy_loss: 1.1170, value_loss: 0.7060
2024-07-14 06:10:39,398 [INFO    ] __main__: train step 10764: loss: 1.0975, policy_loss: 1.1170, value_loss: 0.7059
2024-07-14 06:10:39,709 [INFO    ] __main__: train step 10765: loss: 1.0975, policy_loss: 1.1170, value_loss: 0.7059
2024-07-14 06:10:40,010 [INFO    ] __main__: train step 10766: loss: 1.0975, policy_loss: 1.1170, value_loss: 0.7058
2024-07-14 06:10:40,303 [INFO    ] __main__: train step 10767: loss: 1.0975, policy_loss: 1.1169, value_loss: 0.7058
2024-07-14 06:10:40,588 [INFO    ] __main__: train step 10768: loss: 1.0975, policy_loss: 1.1169, value_loss: 0.7057
2024-07-14 06:10:40,879 [INFO    ] __main__: train step 10769: loss: 1.0974, policy_loss: 1.1169, value_loss: 0.7057
2024-07-14 06:10:41,150 [INFO    ] __main__: train step 10770: loss: 1.0974, policy_loss: 1.1168, value_loss: 0.7057
2024-07-14 06:10:41,445 [INFO    ] __main__: train step 10771: loss: 1.0974, policy_loss: 1.1168, value_loss: 0.7056
2024-07-14 06:10:41,736 [INFO    ] __main__: train step 10772: loss: 1.0974, policy_loss: 1.1168, value_loss: 0.7056
2024-07-14 06:10:42,027 [INFO    ] __main__: train step 10773: loss: 1.0974, policy_loss: 1.1167, value_loss: 0.7055
2024-07-14 06:10:42,329 [INFO    ] __main__: train step 10774: loss: 1.0974, policy_loss: 1.1167, value_loss: 0.7055
2024-07-14 06:10:43,955 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:10:44,454 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:10:44,525 [INFO    ] __main__: train step 10775: loss: 1.0974, policy_loss: 1.1167, value_loss: 0.7055
2024-07-14 06:10:44,831 [INFO    ] __main__: train step 10776: loss: 1.0974, policy_loss: 1.1166, value_loss: 0.7054
2024-07-14 06:10:45,132 [INFO    ] __main__: train step 10777: loss: 1.0974, policy_loss: 1.1166, value_loss: 0.7054
2024-07-14 06:10:45,402 [INFO    ] __main__: train step 10778: loss: 1.0974, policy_loss: 1.1166, value_loss: 0.7053
2024-07-14 06:10:45,660 [INFO    ] __main__: train step 10779: loss: 1.0974, policy_loss: 1.1165, value_loss: 0.7053
2024-07-14 06:10:45,932 [INFO    ] __main__: train step 10780: loss: 1.0974, policy_loss: 1.1165, value_loss: 0.7052
2024-07-14 06:10:46,212 [INFO    ] __main__: train step 10781: loss: 1.0974, policy_loss: 1.1165, value_loss: 0.7052
2024-07-14 06:10:46,491 [INFO    ] __main__: train step 10782: loss: 1.0974, policy_loss: 1.1164, value_loss: 0.7052
2024-07-14 06:10:49,480 [INFO    ] __main__: train step 10783: loss: 1.0974, policy_loss: 1.1164, value_loss: 0.7051
2024-07-14 06:10:49,777 [INFO    ] __main__: train step 10784: loss: 1.0974, policy_loss: 1.1164, value_loss: 0.7051
2024-07-14 06:10:50,084 [INFO    ] __main__: train step 10785: loss: 1.0974, policy_loss: 1.1164, value_loss: 0.7050
2024-07-14 06:10:50,383 [INFO    ] __main__: train step 10786: loss: 1.0973, policy_loss: 1.1163, value_loss: 0.7050
2024-07-14 06:10:50,674 [INFO    ] __main__: train step 10787: loss: 1.0973, policy_loss: 1.1163, value_loss: 0.7050
2024-07-14 06:10:50,967 [INFO    ] __main__: train step 10788: loss: 1.0973, policy_loss: 1.1163, value_loss: 0.7049
2024-07-14 06:10:51,263 [INFO    ] __main__: train step 10789: loss: 1.0973, policy_loss: 1.1162, value_loss: 0.7049
2024-07-14 06:10:51,554 [INFO    ] __main__: train step 10790: loss: 1.0973, policy_loss: 1.1162, value_loss: 0.7048
2024-07-14 06:10:51,839 [INFO    ] __main__: train step 10791: loss: 1.0973, policy_loss: 1.1162, value_loss: 0.7048
2024-07-14 06:10:53,458 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:10:53,955 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:10:54,025 [INFO    ] __main__: train step 10792: loss: 1.0973, policy_loss: 1.1161, value_loss: 0.7047
2024-07-14 06:10:54,325 [INFO    ] __main__: train step 10793: loss: 1.0973, policy_loss: 1.1161, value_loss: 0.7047
2024-07-14 06:10:54,604 [INFO    ] __main__: train step 10794: loss: 1.0973, policy_loss: 1.1161, value_loss: 0.7047
2024-07-14 06:10:54,885 [INFO    ] __main__: train step 10795: loss: 1.0973, policy_loss: 1.1160, value_loss: 0.7046
2024-07-14 06:10:55,172 [INFO    ] __main__: train step 10796: loss: 1.0973, policy_loss: 1.1160, value_loss: 0.7046
2024-07-14 06:10:55,469 [INFO    ] __main__: train step 10797: loss: 1.0973, policy_loss: 1.1160, value_loss: 0.7045
2024-07-14 06:10:55,767 [INFO    ] __main__: train step 10798: loss: 1.0973, policy_loss: 1.1159, value_loss: 0.7045
2024-07-14 06:10:56,058 [INFO    ] __main__: train step 10799: loss: 1.0973, policy_loss: 1.1159, value_loss: 0.7044
2024-07-14 06:10:56,362 [INFO    ] __main__: train step 10800: loss: 1.0973, policy_loss: 1.1159, value_loss: 0.7044
2024-07-14 06:10:56,681 [INFO    ] __main__: train step 10801: loss: 1.0972, policy_loss: 1.1159, value_loss: 0.7044
2024-07-14 06:10:56,976 [INFO    ] __main__: train step 10802: loss: 1.0972, policy_loss: 1.1158, value_loss: 0.7043
2024-07-14 06:10:57,267 [INFO    ] __main__: train step 10803: loss: 1.0972, policy_loss: 1.1158, value_loss: 0.7043
2024-07-14 06:10:57,552 [INFO    ] __main__: train step 10804: loss: 1.0972, policy_loss: 1.1158, value_loss: 0.7042
2024-07-14 06:10:57,858 [INFO    ] __main__: train step 10805: loss: 1.0972, policy_loss: 1.1157, value_loss: 0.7042
2024-07-14 06:10:58,152 [INFO    ] __main__: train step 10806: loss: 1.0972, policy_loss: 1.1157, value_loss: 0.7042
2024-07-14 06:10:58,442 [INFO    ] __main__: train step 10807: loss: 1.0972, policy_loss: 1.1157, value_loss: 0.7041
2024-07-14 06:10:58,742 [INFO    ] __main__: train step 10808: loss: 1.0972, policy_loss: 1.1156, value_loss: 0.7041
2024-07-14 06:11:00,379 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:11:00,868 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:11:00,942 [INFO    ] __main__: train step 10809: loss: 1.0972, policy_loss: 1.1156, value_loss: 0.7040
2024-07-14 06:11:01,232 [INFO    ] __main__: train step 10810: loss: 1.0972, policy_loss: 1.1156, value_loss: 0.7040
2024-07-14 06:11:01,550 [INFO    ] __main__: train step 10811: loss: 1.0972, policy_loss: 1.1155, value_loss: 0.7040
2024-07-14 06:11:01,871 [INFO    ] __main__: train step 10812: loss: 1.0972, policy_loss: 1.1155, value_loss: 0.7039
2024-07-14 06:11:02,172 [INFO    ] __main__: train step 10813: loss: 1.0972, policy_loss: 1.1155, value_loss: 0.7039
2024-07-14 06:11:02,459 [INFO    ] __main__: train step 10814: loss: 1.0972, policy_loss: 1.1154, value_loss: 0.7038
2024-07-14 06:11:02,746 [INFO    ] __main__: train step 10815: loss: 1.0972, policy_loss: 1.1154, value_loss: 0.7038
2024-07-14 06:11:03,039 [INFO    ] __main__: train step 10816: loss: 1.0972, policy_loss: 1.1154, value_loss: 0.7037
2024-07-14 06:11:03,332 [INFO    ] __main__: train step 10817: loss: 1.0972, policy_loss: 1.1154, value_loss: 0.7037
2024-07-14 06:11:03,632 [INFO    ] __main__: train step 10818: loss: 1.0972, policy_loss: 1.1153, value_loss: 0.7037
2024-07-14 06:11:03,927 [INFO    ] __main__: train step 10819: loss: 1.0972, policy_loss: 1.1153, value_loss: 0.7036
2024-07-14 06:11:04,228 [INFO    ] __main__: train step 10820: loss: 1.0971, policy_loss: 1.1153, value_loss: 0.7036
2024-07-14 06:11:04,519 [INFO    ] __main__: train step 10821: loss: 1.0971, policy_loss: 1.1152, value_loss: 0.7035
2024-07-14 06:11:04,805 [INFO    ] __main__: train step 10822: loss: 1.0971, policy_loss: 1.1152, value_loss: 0.7035
2024-07-14 06:11:05,090 [INFO    ] __main__: train step 10823: loss: 1.0971, policy_loss: 1.1152, value_loss: 0.7035
2024-07-14 06:11:05,381 [INFO    ] __main__: train step 10824: loss: 1.0971, policy_loss: 1.1151, value_loss: 0.7034
2024-07-14 06:11:05,660 [INFO    ] __main__: train step 10825: loss: 1.0971, policy_loss: 1.1151, value_loss: 0.7034
2024-07-14 06:11:07,266 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:11:07,754 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:11:07,830 [INFO    ] __main__: train step 10826: loss: 1.0971, policy_loss: 1.1151, value_loss: 0.7033
2024-07-14 06:11:08,133 [INFO    ] __main__: train step 10827: loss: 1.0971, policy_loss: 1.1151, value_loss: 0.7033
2024-07-14 06:11:08,418 [INFO    ] __main__: train step 10828: loss: 1.0971, policy_loss: 1.1150, value_loss: 0.7032
2024-07-14 06:11:08,703 [INFO    ] __main__: train step 10829: loss: 1.0971, policy_loss: 1.1150, value_loss: 0.7032
2024-07-14 06:11:08,991 [INFO    ] __main__: train step 10830: loss: 1.0971, policy_loss: 1.1150, value_loss: 0.7032
2024-07-14 06:11:09,284 [INFO    ] __main__: train step 10831: loss: 1.0971, policy_loss: 1.1149, value_loss: 0.7031
2024-07-14 06:11:09,576 [INFO    ] __main__: train step 10832: loss: 1.0971, policy_loss: 1.1149, value_loss: 0.7031
2024-07-14 06:11:09,868 [INFO    ] __main__: train step 10833: loss: 1.0971, policy_loss: 1.1149, value_loss: 0.7030
2024-07-14 06:11:10,155 [INFO    ] __main__: train step 10834: loss: 1.0971, policy_loss: 1.1148, value_loss: 0.7030
2024-07-14 06:11:10,458 [INFO    ] __main__: train step 10835: loss: 1.0971, policy_loss: 1.1148, value_loss: 0.7030
2024-07-14 06:11:10,747 [INFO    ] __main__: train step 10836: loss: 1.0971, policy_loss: 1.1148, value_loss: 0.7029
2024-07-14 06:11:11,027 [INFO    ] __main__: train step 10837: loss: 1.0971, policy_loss: 1.1147, value_loss: 0.7029
2024-07-14 06:11:11,316 [INFO    ] __main__: train step 10838: loss: 1.0970, policy_loss: 1.1147, value_loss: 0.7028
2024-07-14 06:11:11,606 [INFO    ] __main__: train step 10839: loss: 1.0970, policy_loss: 1.1147, value_loss: 0.7028
2024-07-14 06:11:11,906 [INFO    ] __main__: train step 10840: loss: 1.0970, policy_loss: 1.1147, value_loss: 0.7027
2024-07-14 06:11:12,191 [INFO    ] __main__: train step 10841: loss: 1.0970, policy_loss: 1.1146, value_loss: 0.7027
2024-07-14 06:11:12,484 [INFO    ] __main__: train step 10842: loss: 1.0970, policy_loss: 1.1146, value_loss: 0.7027
2024-07-14 06:11:14,105 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:11:14,594 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:11:14,669 [INFO    ] __main__: train step 10843: loss: 1.0970, policy_loss: 1.1146, value_loss: 0.7026
2024-07-14 06:11:14,953 [INFO    ] __main__: train step 10844: loss: 1.0970, policy_loss: 1.1145, value_loss: 0.7026
2024-07-14 06:11:15,239 [INFO    ] __main__: train step 10845: loss: 1.0970, policy_loss: 1.1145, value_loss: 0.7025
2024-07-14 06:11:15,531 [INFO    ] __main__: train step 10846: loss: 1.0970, policy_loss: 1.1145, value_loss: 0.7025
2024-07-14 06:11:15,814 [INFO    ] __main__: train step 10847: loss: 1.0970, policy_loss: 1.1144, value_loss: 0.7025
2024-07-14 06:11:16,106 [INFO    ] __main__: train step 10848: loss: 1.0970, policy_loss: 1.1144, value_loss: 0.7024
2024-07-14 06:11:16,404 [INFO    ] __main__: train step 10849: loss: 1.0970, policy_loss: 1.1144, value_loss: 0.7024
2024-07-14 06:11:16,693 [INFO    ] __main__: train step 10850: loss: 1.0970, policy_loss: 1.1144, value_loss: 0.7023
2024-07-14 06:11:16,988 [INFO    ] __main__: train step 10851: loss: 1.0970, policy_loss: 1.1143, value_loss: 0.7023
2024-07-14 06:11:17,292 [INFO    ] __main__: train step 10852: loss: 1.0970, policy_loss: 1.1143, value_loss: 0.7023
2024-07-14 06:11:17,611 [INFO    ] __main__: train step 10853: loss: 1.0970, policy_loss: 1.1143, value_loss: 0.7022
2024-07-14 06:11:17,897 [INFO    ] __main__: train step 10854: loss: 1.0970, policy_loss: 1.1142, value_loss: 0.7022
2024-07-14 06:11:18,201 [INFO    ] __main__: train step 10855: loss: 1.0970, policy_loss: 1.1142, value_loss: 0.7021
2024-07-14 06:11:18,494 [INFO    ] __main__: train step 10856: loss: 1.0970, policy_loss: 1.1142, value_loss: 0.7021
2024-07-14 06:11:18,781 [INFO    ] __main__: train step 10857: loss: 1.0970, policy_loss: 1.1141, value_loss: 0.7020
2024-07-14 06:11:19,082 [INFO    ] __main__: train step 10858: loss: 1.0970, policy_loss: 1.1141, value_loss: 0.7020
2024-07-14 06:11:19,372 [INFO    ] __main__: train step 10859: loss: 1.0969, policy_loss: 1.1141, value_loss: 0.7020
2024-07-14 06:11:20,998 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:11:21,489 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:11:21,557 [INFO    ] __main__: train step 10860: loss: 1.0969, policy_loss: 1.1141, value_loss: 0.7019
2024-07-14 06:11:21,854 [INFO    ] __main__: train step 10861: loss: 1.0969, policy_loss: 1.1140, value_loss: 0.7019
2024-07-14 06:11:22,147 [INFO    ] __main__: train step 10862: loss: 1.0969, policy_loss: 1.1140, value_loss: 0.7018
2024-07-14 06:11:22,442 [INFO    ] __main__: train step 10863: loss: 1.0969, policy_loss: 1.1140, value_loss: 0.7018
2024-07-14 06:11:22,733 [INFO    ] __main__: train step 10864: loss: 1.0969, policy_loss: 1.1139, value_loss: 0.7018
2024-07-14 06:11:23,047 [INFO    ] __main__: train step 10865: loss: 1.0969, policy_loss: 1.1139, value_loss: 0.7017
2024-07-14 06:11:23,348 [INFO    ] __main__: train step 10866: loss: 1.0969, policy_loss: 1.1139, value_loss: 0.7017
2024-07-14 06:11:23,653 [INFO    ] __main__: train step 10867: loss: 1.0969, policy_loss: 1.1138, value_loss: 0.7016
2024-07-14 06:11:23,954 [INFO    ] __main__: train step 10868: loss: 1.0969, policy_loss: 1.1138, value_loss: 0.7016
2024-07-14 06:11:24,250 [INFO    ] __main__: train step 10869: loss: 1.0969, policy_loss: 1.1138, value_loss: 0.7016
2024-07-14 06:11:24,558 [INFO    ] __main__: train step 10870: loss: 1.0969, policy_loss: 1.1138, value_loss: 0.7015
2024-07-14 06:11:26,777 [INFO    ] __main__: train step 10871: loss: 1.0969, policy_loss: 1.1137, value_loss: 0.7015
2024-07-14 06:11:27,079 [INFO    ] __main__: train step 10872: loss: 1.0969, policy_loss: 1.1137, value_loss: 0.7014
2024-07-14 06:11:27,376 [INFO    ] __main__: train step 10873: loss: 1.0969, policy_loss: 1.1137, value_loss: 0.7014
2024-07-14 06:11:27,672 [INFO    ] __main__: train step 10874: loss: 1.0969, policy_loss: 1.1136, value_loss: 0.7014
2024-07-14 06:11:27,964 [INFO    ] __main__: train step 10875: loss: 1.0969, policy_loss: 1.1136, value_loss: 0.7013
2024-07-14 06:11:28,256 [INFO    ] __main__: train step 10876: loss: 1.0969, policy_loss: 1.1136, value_loss: 0.7013
2024-07-14 06:11:29,888 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:11:30,384 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:11:30,456 [INFO    ] __main__: train step 10877: loss: 1.0969, policy_loss: 1.1135, value_loss: 0.7012
2024-07-14 06:11:30,763 [INFO    ] __main__: train step 10878: loss: 1.0969, policy_loss: 1.1135, value_loss: 0.7012
2024-07-14 06:11:31,055 [INFO    ] __main__: train step 10879: loss: 1.0968, policy_loss: 1.1135, value_loss: 0.7011
2024-07-14 06:11:31,353 [INFO    ] __main__: train step 10880: loss: 1.0968, policy_loss: 1.1135, value_loss: 0.7011
2024-07-14 06:11:31,643 [INFO    ] __main__: train step 10881: loss: 1.0968, policy_loss: 1.1134, value_loss: 0.7011
2024-07-14 06:11:31,941 [INFO    ] __main__: train step 10882: loss: 1.0968, policy_loss: 1.1134, value_loss: 0.7010
2024-07-14 06:11:32,256 [INFO    ] __main__: train step 10883: loss: 1.0968, policy_loss: 1.1134, value_loss: 0.7010
2024-07-14 06:11:32,562 [INFO    ] __main__: train step 10884: loss: 1.0968, policy_loss: 1.1133, value_loss: 0.7009
2024-07-14 06:11:32,857 [INFO    ] __main__: train step 10885: loss: 1.0968, policy_loss: 1.1133, value_loss: 0.7009
2024-07-14 06:11:33,149 [INFO    ] __main__: train step 10886: loss: 1.0968, policy_loss: 1.1133, value_loss: 0.7009
2024-07-14 06:11:33,443 [INFO    ] __main__: train step 10887: loss: 1.0968, policy_loss: 1.1133, value_loss: 0.7008
2024-07-14 06:11:33,760 [INFO    ] __main__: train step 10888: loss: 1.0968, policy_loss: 1.1132, value_loss: 0.7008
2024-07-14 06:11:34,044 [INFO    ] __main__: train step 10889: loss: 1.0968, policy_loss: 1.1132, value_loss: 0.7007
2024-07-14 06:11:34,336 [INFO    ] __main__: train step 10890: loss: 1.0968, policy_loss: 1.1132, value_loss: 0.7007
2024-07-14 06:11:34,634 [INFO    ] __main__: train step 10891: loss: 1.0968, policy_loss: 1.1131, value_loss: 0.7007
2024-07-14 06:11:34,937 [INFO    ] __main__: train step 10892: loss: 1.0968, policy_loss: 1.1131, value_loss: 0.7006
2024-07-14 06:11:35,230 [INFO    ] __main__: train step 10893: loss: 1.0968, policy_loss: 1.1131, value_loss: 0.7006
2024-07-14 06:11:36,859 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:11:37,354 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:11:37,429 [INFO    ] __main__: train step 10894: loss: 1.0968, policy_loss: 1.1130, value_loss: 0.7005
2024-07-14 06:11:37,715 [INFO    ] __main__: train step 10895: loss: 1.0968, policy_loss: 1.1130, value_loss: 0.7005
2024-07-14 06:11:38,016 [INFO    ] __main__: train step 10896: loss: 1.0968, policy_loss: 1.1130, value_loss: 0.7005
2024-07-14 06:11:38,303 [INFO    ] __main__: train step 10897: loss: 1.0968, policy_loss: 1.1130, value_loss: 0.7004
2024-07-14 06:11:38,590 [INFO    ] __main__: train step 10898: loss: 1.0968, policy_loss: 1.1129, value_loss: 0.7004
2024-07-14 06:11:38,878 [INFO    ] __main__: train step 10899: loss: 1.0968, policy_loss: 1.1129, value_loss: 0.7003
2024-07-14 06:11:39,164 [INFO    ] __main__: train step 10900: loss: 1.0968, policy_loss: 1.1129, value_loss: 0.7003
2024-07-14 06:11:39,455 [INFO    ] __main__: train step 10901: loss: 1.0968, policy_loss: 1.1128, value_loss: 0.7003
2024-07-14 06:11:39,750 [INFO    ] __main__: train step 10902: loss: 1.0967, policy_loss: 1.1128, value_loss: 0.7002
2024-07-14 06:11:40,041 [INFO    ] __main__: train step 10903: loss: 1.0967, policy_loss: 1.1128, value_loss: 0.7002
2024-07-14 06:11:40,331 [INFO    ] __main__: train step 10904: loss: 1.0967, policy_loss: 1.1127, value_loss: 0.7001
2024-07-14 06:11:40,622 [INFO    ] __main__: train step 10905: loss: 1.0967, policy_loss: 1.1127, value_loss: 0.7001
2024-07-14 06:11:40,913 [INFO    ] __main__: train step 10906: loss: 1.0967, policy_loss: 1.1127, value_loss: 0.7000
2024-07-14 06:11:41,190 [INFO    ] __main__: train step 10907: loss: 1.0967, policy_loss: 1.1127, value_loss: 0.7000
2024-07-14 06:11:41,478 [INFO    ] __main__: train step 10908: loss: 1.0967, policy_loss: 1.1126, value_loss: 0.7000
2024-07-14 06:11:41,769 [INFO    ] __main__: train step 10909: loss: 1.0967, policy_loss: 1.1126, value_loss: 0.6999
2024-07-14 06:11:42,064 [INFO    ] __main__: train step 10910: loss: 1.0967, policy_loss: 1.1126, value_loss: 0.6999
2024-07-14 06:11:43,678 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:11:44,167 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:11:44,237 [INFO    ] __main__: train step 10911: loss: 1.0967, policy_loss: 1.1125, value_loss: 0.6998
2024-07-14 06:11:44,522 [INFO    ] __main__: train step 10912: loss: 1.0967, policy_loss: 1.1125, value_loss: 0.6998
2024-07-14 06:11:44,806 [INFO    ] __main__: train step 10913: loss: 1.0967, policy_loss: 1.1125, value_loss: 0.6998
2024-07-14 06:11:45,093 [INFO    ] __main__: train step 10914: loss: 1.0967, policy_loss: 1.1124, value_loss: 0.6997
2024-07-14 06:11:45,372 [INFO    ] __main__: train step 10915: loss: 1.0967, policy_loss: 1.1124, value_loss: 0.6997
2024-07-14 06:11:45,662 [INFO    ] __main__: train step 10916: loss: 1.0967, policy_loss: 1.1124, value_loss: 0.6996
2024-07-14 06:11:45,942 [INFO    ] __main__: train step 10917: loss: 1.0967, policy_loss: 1.1124, value_loss: 0.6996
2024-07-14 06:11:46,231 [INFO    ] __main__: train step 10918: loss: 1.0967, policy_loss: 1.1123, value_loss: 0.6996
2024-07-14 06:11:46,528 [INFO    ] __main__: train step 10919: loss: 1.0967, policy_loss: 1.1123, value_loss: 0.6995
2024-07-14 06:11:46,824 [INFO    ] __main__: train step 10920: loss: 1.0967, policy_loss: 1.1123, value_loss: 0.6995
2024-07-14 06:11:47,091 [INFO    ] __main__: train step 10921: loss: 1.0967, policy_loss: 1.1122, value_loss: 0.6994
2024-07-14 06:11:47,368 [INFO    ] __main__: train step 10922: loss: 1.0966, policy_loss: 1.1122, value_loss: 0.6994
2024-07-14 06:11:47,649 [INFO    ] __main__: train step 10923: loss: 1.0966, policy_loss: 1.1122, value_loss: 0.6994
2024-07-14 06:11:47,947 [INFO    ] __main__: train step 10924: loss: 1.0966, policy_loss: 1.1122, value_loss: 0.6993
2024-07-14 06:11:48,257 [INFO    ] __main__: train step 10925: loss: 1.0966, policy_loss: 1.1121, value_loss: 0.6993
2024-07-14 06:11:48,557 [INFO    ] __main__: train step 10926: loss: 1.0966, policy_loss: 1.1121, value_loss: 0.6992
2024-07-14 06:11:48,855 [INFO    ] __main__: train step 10927: loss: 1.0966, policy_loss: 1.1121, value_loss: 0.6992
2024-07-14 06:11:50,471 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:11:50,951 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:11:51,026 [INFO    ] __main__: train step 10928: loss: 1.0966, policy_loss: 1.1120, value_loss: 0.6992
2024-07-14 06:11:51,322 [INFO    ] __main__: train step 10929: loss: 1.0966, policy_loss: 1.1120, value_loss: 0.6991
2024-07-14 06:11:51,619 [INFO    ] __main__: train step 10930: loss: 1.0966, policy_loss: 1.1120, value_loss: 0.6991
2024-07-14 06:11:51,931 [INFO    ] __main__: train step 10931: loss: 1.0966, policy_loss: 1.1119, value_loss: 0.6990
2024-07-14 06:11:52,228 [INFO    ] __main__: train step 10932: loss: 1.0966, policy_loss: 1.1119, value_loss: 0.6990
2024-07-14 06:11:52,533 [INFO    ] __main__: train step 10933: loss: 1.0966, policy_loss: 1.1119, value_loss: 0.6989
2024-07-14 06:11:52,833 [INFO    ] __main__: train step 10934: loss: 1.0966, policy_loss: 1.1119, value_loss: 0.6989
2024-07-14 06:11:53,125 [INFO    ] __main__: train step 10935: loss: 1.0966, policy_loss: 1.1118, value_loss: 0.6989
2024-07-14 06:11:53,410 [INFO    ] __main__: train step 10936: loss: 1.0966, policy_loss: 1.1118, value_loss: 0.6988
2024-07-14 06:11:53,707 [INFO    ] __main__: train step 10937: loss: 1.0966, policy_loss: 1.1118, value_loss: 0.6988
2024-07-14 06:11:54,008 [INFO    ] __main__: train step 10938: loss: 1.0966, policy_loss: 1.1117, value_loss: 0.6987
2024-07-14 06:11:54,311 [INFO    ] __main__: train step 10939: loss: 1.0966, policy_loss: 1.1117, value_loss: 0.6987
2024-07-14 06:11:54,609 [INFO    ] __main__: train step 10940: loss: 1.0966, policy_loss: 1.1117, value_loss: 0.6987
2024-07-14 06:11:54,915 [INFO    ] __main__: train step 10941: loss: 1.0966, policy_loss: 1.1117, value_loss: 0.6986
2024-07-14 06:11:55,208 [INFO    ] __main__: train step 10942: loss: 1.0965, policy_loss: 1.1116, value_loss: 0.6986
2024-07-14 06:11:55,495 [INFO    ] __main__: train step 10943: loss: 1.0965, policy_loss: 1.1116, value_loss: 0.6985
2024-07-14 06:11:55,791 [INFO    ] __main__: train step 10944: loss: 1.0965, policy_loss: 1.1116, value_loss: 0.6985
2024-07-14 06:11:57,423 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:11:57,913 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:11:57,986 [INFO    ] __main__: train step 10945: loss: 1.0965, policy_loss: 1.1115, value_loss: 0.6984
2024-07-14 06:11:58,286 [INFO    ] __main__: train step 10946: loss: 1.0965, policy_loss: 1.1115, value_loss: 0.6984
2024-07-14 06:11:58,577 [INFO    ] __main__: train step 10947: loss: 1.0965, policy_loss: 1.1115, value_loss: 0.6984
2024-07-14 06:11:58,868 [INFO    ] __main__: train step 10948: loss: 1.0965, policy_loss: 1.1115, value_loss: 0.6983
2024-07-14 06:11:59,171 [INFO    ] __main__: train step 10949: loss: 1.0965, policy_loss: 1.1114, value_loss: 0.6983
2024-07-14 06:11:59,456 [INFO    ] __main__: train step 10950: loss: 1.0965, policy_loss: 1.1114, value_loss: 0.6982
2024-07-14 06:11:59,742 [INFO    ] __main__: train step 10951: loss: 1.0965, policy_loss: 1.1114, value_loss: 0.6982
2024-07-14 06:12:00,035 [INFO    ] __main__: train step 10952: loss: 1.0965, policy_loss: 1.1113, value_loss: 0.6982
2024-07-14 06:12:00,328 [INFO    ] __main__: train step 10953: loss: 1.0965, policy_loss: 1.1113, value_loss: 0.6981
2024-07-14 06:12:00,618 [INFO    ] __main__: train step 10954: loss: 1.0965, policy_loss: 1.1113, value_loss: 0.6981
2024-07-14 06:12:00,909 [INFO    ] __main__: train step 10955: loss: 1.0965, policy_loss: 1.1113, value_loss: 0.6980
2024-07-14 06:12:01,203 [INFO    ] __main__: train step 10956: loss: 1.0965, policy_loss: 1.1112, value_loss: 0.6980
2024-07-14 06:12:01,488 [INFO    ] __main__: train step 10957: loss: 1.0965, policy_loss: 1.1112, value_loss: 0.6979
2024-07-14 06:12:01,781 [INFO    ] __main__: train step 10958: loss: 1.0965, policy_loss: 1.1112, value_loss: 0.6979
2024-07-14 06:12:04,532 [INFO    ] __main__: train step 10959: loss: 1.0965, policy_loss: 1.1111, value_loss: 0.6979
2024-07-14 06:12:04,830 [INFO    ] __main__: train step 10960: loss: 1.0965, policy_loss: 1.1111, value_loss: 0.6978
2024-07-14 06:12:05,142 [INFO    ] __main__: train step 10961: loss: 1.0965, policy_loss: 1.1111, value_loss: 0.6978
2024-07-14 06:12:06,763 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:12:07,255 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:12:07,327 [INFO    ] __main__: train step 10962: loss: 1.0964, policy_loss: 1.1110, value_loss: 0.6977
2024-07-14 06:12:07,625 [INFO    ] __main__: train step 10963: loss: 1.0964, policy_loss: 1.1110, value_loss: 0.6977
2024-07-14 06:12:07,901 [INFO    ] __main__: train step 10964: loss: 1.0964, policy_loss: 1.1110, value_loss: 0.6977
2024-07-14 06:12:08,194 [INFO    ] __main__: train step 10965: loss: 1.0964, policy_loss: 1.1110, value_loss: 0.6976
2024-07-14 06:12:08,492 [INFO    ] __main__: train step 10966: loss: 1.0964, policy_loss: 1.1109, value_loss: 0.6976
2024-07-14 06:12:08,787 [INFO    ] __main__: train step 10967: loss: 1.0964, policy_loss: 1.1109, value_loss: 0.6975
2024-07-14 06:12:09,080 [INFO    ] __main__: train step 10968: loss: 1.0964, policy_loss: 1.1109, value_loss: 0.6975
2024-07-14 06:12:09,378 [INFO    ] __main__: train step 10969: loss: 1.0964, policy_loss: 1.1108, value_loss: 0.6975
2024-07-14 06:12:09,666 [INFO    ] __main__: train step 10970: loss: 1.0964, policy_loss: 1.1108, value_loss: 0.6974
2024-07-14 06:12:09,957 [INFO    ] __main__: train step 10971: loss: 1.0964, policy_loss: 1.1108, value_loss: 0.6974
2024-07-14 06:12:10,250 [INFO    ] __main__: train step 10972: loss: 1.0964, policy_loss: 1.1108, value_loss: 0.6973
2024-07-14 06:12:10,541 [INFO    ] __main__: train step 10973: loss: 1.0964, policy_loss: 1.1107, value_loss: 0.6973
2024-07-14 06:12:10,835 [INFO    ] __main__: train step 10974: loss: 1.0964, policy_loss: 1.1107, value_loss: 0.6973
2024-07-14 06:12:11,134 [INFO    ] __main__: train step 10975: loss: 1.0964, policy_loss: 1.1107, value_loss: 0.6972
2024-07-14 06:12:11,424 [INFO    ] __main__: train step 10976: loss: 1.0964, policy_loss: 1.1106, value_loss: 0.6972
2024-07-14 06:12:11,715 [INFO    ] __main__: train step 10977: loss: 1.0964, policy_loss: 1.1106, value_loss: 0.6971
2024-07-14 06:12:12,010 [INFO    ] __main__: train step 10978: loss: 1.0964, policy_loss: 1.1106, value_loss: 0.6971
2024-07-14 06:12:13,625 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:12:14,114 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:12:14,181 [INFO    ] __main__: train step 10979: loss: 1.0964, policy_loss: 1.1106, value_loss: 0.6971
2024-07-14 06:12:14,462 [INFO    ] __main__: train step 10980: loss: 1.0964, policy_loss: 1.1105, value_loss: 0.6970
2024-07-14 06:12:14,748 [INFO    ] __main__: train step 10981: loss: 1.0964, policy_loss: 1.1105, value_loss: 0.6970
2024-07-14 06:12:15,033 [INFO    ] __main__: train step 10982: loss: 1.0964, policy_loss: 1.1105, value_loss: 0.6969
2024-07-14 06:12:15,327 [INFO    ] __main__: train step 10983: loss: 1.0964, policy_loss: 1.1105, value_loss: 0.6969
2024-07-14 06:12:15,612 [INFO    ] __main__: train step 10984: loss: 1.0964, policy_loss: 1.1104, value_loss: 0.6969
2024-07-14 06:12:15,896 [INFO    ] __main__: train step 10985: loss: 1.0964, policy_loss: 1.1104, value_loss: 0.6968
2024-07-14 06:12:16,176 [INFO    ] __main__: train step 10986: loss: 1.0963, policy_loss: 1.1104, value_loss: 0.6968
2024-07-14 06:12:16,459 [INFO    ] __main__: train step 10987: loss: 1.0963, policy_loss: 1.1103, value_loss: 0.6967
2024-07-14 06:12:16,744 [INFO    ] __main__: train step 10988: loss: 1.0963, policy_loss: 1.1103, value_loss: 0.6967
2024-07-14 06:12:17,037 [INFO    ] __main__: train step 10989: loss: 1.0963, policy_loss: 1.1103, value_loss: 0.6967
2024-07-14 06:12:17,324 [INFO    ] __main__: train step 10990: loss: 1.0963, policy_loss: 1.1103, value_loss: 0.6966
2024-07-14 06:12:17,624 [INFO    ] __main__: train step 10991: loss: 1.0963, policy_loss: 1.1102, value_loss: 0.6966
2024-07-14 06:12:17,906 [INFO    ] __main__: train step 10992: loss: 1.0963, policy_loss: 1.1102, value_loss: 0.6965
2024-07-14 06:12:18,199 [INFO    ] __main__: train step 10993: loss: 1.0963, policy_loss: 1.1102, value_loss: 0.6965
2024-07-14 06:12:18,492 [INFO    ] __main__: train step 10994: loss: 1.0963, policy_loss: 1.1101, value_loss: 0.6964
2024-07-14 06:12:18,780 [INFO    ] __main__: train step 10995: loss: 1.0963, policy_loss: 1.1101, value_loss: 0.6964
2024-07-14 06:12:20,394 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:12:20,883 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:12:20,954 [INFO    ] __main__: train step 10996: loss: 1.0963, policy_loss: 1.1101, value_loss: 0.6964
2024-07-14 06:12:21,233 [INFO    ] __main__: train step 10997: loss: 1.0963, policy_loss: 1.1101, value_loss: 0.6963
2024-07-14 06:12:21,509 [INFO    ] __main__: train step 10998: loss: 1.0963, policy_loss: 1.1100, value_loss: 0.6963
2024-07-14 06:12:21,799 [INFO    ] __main__: train step 10999: loss: 1.0963, policy_loss: 1.1100, value_loss: 0.6962
2024-07-14 06:12:22,110 [INFO    ] __main__: train step 11000: loss: 1.0963, policy_loss: 1.1100, value_loss: 0.6962
2024-07-14 06:12:22,266 [INFO    ] __main__: restored step 10000 for evaluation
2024-07-14 06:12:27,522 [INFO    ] __main__: test network ELO difference from baseline network: +124 (+8/-8) ELO from 32000 self-played games
2024-07-14 06:12:27,524 [INFO    ] __main__: game outcomes: W: 20355, D: 496, L: 11149
2024-07-14 06:12:27,527 [INFO    ] __main__: validation_elo_delta: 124, validation_elo: 2294
2024-07-14 06:12:28,262 [INFO    ] __main__: train step 11001: loss: 1.0963, policy_loss: 1.1100, value_loss: 0.6962
2024-07-14 06:12:28,551 [INFO    ] __main__: train step 11002: loss: 1.0963, policy_loss: 1.1099, value_loss: 0.6961
2024-07-14 06:12:28,841 [INFO    ] __main__: train step 11003: loss: 1.0963, policy_loss: 1.1099, value_loss: 0.6961
2024-07-14 06:12:29,127 [INFO    ] __main__: train step 11004: loss: 1.0963, policy_loss: 1.1099, value_loss: 0.6960
2024-07-14 06:12:29,408 [INFO    ] __main__: train step 11005: loss: 1.0963, policy_loss: 1.1098, value_loss: 0.6960
2024-07-14 06:12:29,696 [INFO    ] __main__: train step 11006: loss: 1.0963, policy_loss: 1.1098, value_loss: 0.6960
2024-07-14 06:12:29,974 [INFO    ] __main__: train step 11007: loss: 1.0963, policy_loss: 1.1098, value_loss: 0.6959
2024-07-14 06:12:30,252 [INFO    ] __main__: train step 11008: loss: 1.0963, policy_loss: 1.1098, value_loss: 0.6959
2024-07-14 06:12:30,530 [INFO    ] __main__: train step 11009: loss: 1.0963, policy_loss: 1.1097, value_loss: 0.6958
2024-07-14 06:12:30,817 [INFO    ] __main__: train step 11010: loss: 1.0963, policy_loss: 1.1097, value_loss: 0.6958
2024-07-14 06:12:31,113 [INFO    ] __main__: train step 11011: loss: 1.0963, policy_loss: 1.1097, value_loss: 0.6958
2024-07-14 06:12:31,400 [INFO    ] __main__: train step 11012: loss: 1.0963, policy_loss: 1.1096, value_loss: 0.6957
2024-07-14 06:12:33,020 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:12:33,515 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:12:33,586 [INFO    ] __main__: train step 11013: loss: 1.0962, policy_loss: 1.1096, value_loss: 0.6957
2024-07-14 06:12:33,881 [INFO    ] __main__: train step 11014: loss: 1.0962, policy_loss: 1.1096, value_loss: 0.6956
2024-07-14 06:12:34,178 [INFO    ] __main__: train step 11015: loss: 1.0962, policy_loss: 1.1096, value_loss: 0.6956
2024-07-14 06:12:34,460 [INFO    ] __main__: train step 11016: loss: 1.0962, policy_loss: 1.1095, value_loss: 0.6956
2024-07-14 06:12:34,749 [INFO    ] __main__: train step 11017: loss: 1.0962, policy_loss: 1.1095, value_loss: 0.6955
2024-07-14 06:12:35,044 [INFO    ] __main__: train step 11018: loss: 1.0962, policy_loss: 1.1095, value_loss: 0.6955
2024-07-14 06:12:35,332 [INFO    ] __main__: train step 11019: loss: 1.0962, policy_loss: 1.1095, value_loss: 0.6954
2024-07-14 06:12:35,614 [INFO    ] __main__: train step 11020: loss: 1.0962, policy_loss: 1.1094, value_loss: 0.6954
2024-07-14 06:12:35,895 [INFO    ] __main__: train step 11021: loss: 1.0962, policy_loss: 1.1094, value_loss: 0.6954
2024-07-14 06:12:36,179 [INFO    ] __main__: train step 11022: loss: 1.0962, policy_loss: 1.1094, value_loss: 0.6953
2024-07-14 06:12:36,464 [INFO    ] __main__: train step 11023: loss: 1.0962, policy_loss: 1.1093, value_loss: 0.6953
2024-07-14 06:12:36,745 [INFO    ] __main__: train step 11024: loss: 1.0962, policy_loss: 1.1093, value_loss: 0.6952
2024-07-14 06:12:37,029 [INFO    ] __main__: train step 11025: loss: 1.0962, policy_loss: 1.1093, value_loss: 0.6952
2024-07-14 06:12:37,307 [INFO    ] __main__: train step 11026: loss: 1.0962, policy_loss: 1.1093, value_loss: 0.6952
2024-07-14 06:12:37,592 [INFO    ] __main__: train step 11027: loss: 1.0962, policy_loss: 1.1092, value_loss: 0.6951
2024-07-14 06:12:37,890 [INFO    ] __main__: train step 11028: loss: 1.0962, policy_loss: 1.1092, value_loss: 0.6951
2024-07-14 06:12:38,186 [INFO    ] __main__: train step 11029: loss: 1.0962, policy_loss: 1.1092, value_loss: 0.6950
2024-07-14 06:12:39,799 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:12:40,288 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:12:40,358 [INFO    ] __main__: train step 11030: loss: 1.0962, policy_loss: 1.1091, value_loss: 0.6950
2024-07-14 06:12:40,648 [INFO    ] __main__: train step 11031: loss: 1.0962, policy_loss: 1.1091, value_loss: 0.6950
2024-07-14 06:12:40,926 [INFO    ] __main__: train step 11032: loss: 1.0962, policy_loss: 1.1091, value_loss: 0.6949
2024-07-14 06:12:41,216 [INFO    ] __main__: train step 11033: loss: 1.0962, policy_loss: 1.1091, value_loss: 0.6949
2024-07-14 06:12:41,498 [INFO    ] __main__: train step 11034: loss: 1.0962, policy_loss: 1.1090, value_loss: 0.6948
2024-07-14 06:12:41,784 [INFO    ] __main__: train step 11035: loss: 1.0962, policy_loss: 1.1090, value_loss: 0.6948
2024-07-14 06:12:42,085 [INFO    ] __main__: train step 11036: loss: 1.0962, policy_loss: 1.1090, value_loss: 0.6948
2024-07-14 06:12:42,376 [INFO    ] __main__: train step 11037: loss: 1.0962, policy_loss: 1.1090, value_loss: 0.6947
2024-07-14 06:12:42,669 [INFO    ] __main__: train step 11038: loss: 1.0962, policy_loss: 1.1089, value_loss: 0.6947
2024-07-14 06:12:42,971 [INFO    ] __main__: train step 11039: loss: 1.0962, policy_loss: 1.1089, value_loss: 0.6946
2024-07-14 06:12:43,253 [INFO    ] __main__: train step 11040: loss: 1.0962, policy_loss: 1.1089, value_loss: 0.6946
2024-07-14 06:12:43,516 [INFO    ] __main__: train step 11041: loss: 1.0962, policy_loss: 1.1089, value_loss: 0.6946
2024-07-14 06:12:43,779 [INFO    ] __main__: train step 11042: loss: 1.0962, policy_loss: 1.1088, value_loss: 0.6945
2024-07-14 06:12:44,074 [INFO    ] __main__: train step 11043: loss: 1.0962, policy_loss: 1.1088, value_loss: 0.6945
2024-07-14 06:12:44,370 [INFO    ] __main__: train step 11044: loss: 1.0962, policy_loss: 1.1088, value_loss: 0.6944
2024-07-14 06:12:44,657 [INFO    ] __main__: train step 11045: loss: 1.0961, policy_loss: 1.1087, value_loss: 0.6944
2024-07-14 06:12:44,939 [INFO    ] __main__: train step 11046: loss: 1.0961, policy_loss: 1.1087, value_loss: 0.6944
2024-07-14 06:12:46,538 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:12:47,023 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:12:47,100 [INFO    ] __main__: train step 11047: loss: 1.0961, policy_loss: 1.1087, value_loss: 0.6943
2024-07-14 06:12:50,102 [INFO    ] __main__: train step 11048: loss: 1.0961, policy_loss: 1.1087, value_loss: 0.6943
2024-07-14 06:12:50,381 [INFO    ] __main__: train step 11049: loss: 1.0961, policy_loss: 1.1086, value_loss: 0.6942
2024-07-14 06:12:50,664 [INFO    ] __main__: train step 11050: loss: 1.0961, policy_loss: 1.1086, value_loss: 0.6942
2024-07-14 06:12:50,952 [INFO    ] __main__: train step 11051: loss: 1.0961, policy_loss: 1.1086, value_loss: 0.6942
2024-07-14 06:12:51,235 [INFO    ] __main__: train step 11052: loss: 1.0961, policy_loss: 1.1086, value_loss: 0.6941
2024-07-14 06:12:51,535 [INFO    ] __main__: train step 11053: loss: 1.0961, policy_loss: 1.1085, value_loss: 0.6941
2024-07-14 06:12:51,823 [INFO    ] __main__: train step 11054: loss: 1.0961, policy_loss: 1.1085, value_loss: 0.6940
2024-07-14 06:12:52,114 [INFO    ] __main__: train step 11055: loss: 1.0961, policy_loss: 1.1085, value_loss: 0.6940
2024-07-14 06:12:52,420 [INFO    ] __main__: train step 11056: loss: 1.0961, policy_loss: 1.1085, value_loss: 0.6940
2024-07-14 06:12:52,714 [INFO    ] __main__: train step 11057: loss: 1.0961, policy_loss: 1.1084, value_loss: 0.6939
2024-07-14 06:12:53,015 [INFO    ] __main__: train step 11058: loss: 1.0961, policy_loss: 1.1084, value_loss: 0.6939
2024-07-14 06:12:53,310 [INFO    ] __main__: train step 11059: loss: 1.0961, policy_loss: 1.1084, value_loss: 0.6938
2024-07-14 06:12:53,589 [INFO    ] __main__: train step 11060: loss: 1.0961, policy_loss: 1.1083, value_loss: 0.6938
2024-07-14 06:12:53,867 [INFO    ] __main__: train step 11061: loss: 1.0961, policy_loss: 1.1083, value_loss: 0.6938
2024-07-14 06:12:54,162 [INFO    ] __main__: train step 11062: loss: 1.0961, policy_loss: 1.1083, value_loss: 0.6937
2024-07-14 06:12:54,454 [INFO    ] __main__: train step 11063: loss: 1.0961, policy_loss: 1.1083, value_loss: 0.6937
2024-07-14 06:12:56,090 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:12:56,575 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:12:56,648 [INFO    ] __main__: train step 11064: loss: 1.0961, policy_loss: 1.1082, value_loss: 0.6936
2024-07-14 06:12:56,931 [INFO    ] __main__: train step 11065: loss: 1.0961, policy_loss: 1.1082, value_loss: 0.6936
2024-07-14 06:12:57,224 [INFO    ] __main__: train step 11066: loss: 1.0961, policy_loss: 1.1082, value_loss: 0.6936
2024-07-14 06:12:57,517 [INFO    ] __main__: train step 11067: loss: 1.0961, policy_loss: 1.1082, value_loss: 0.6935
2024-07-14 06:12:57,808 [INFO    ] __main__: train step 11068: loss: 1.0961, policy_loss: 1.1081, value_loss: 0.6935
2024-07-14 06:12:58,118 [INFO    ] __main__: train step 11069: loss: 1.0961, policy_loss: 1.1081, value_loss: 0.6934
2024-07-14 06:12:58,411 [INFO    ] __main__: train step 11070: loss: 1.0961, policy_loss: 1.1081, value_loss: 0.6934
2024-07-14 06:12:58,694 [INFO    ] __main__: train step 11071: loss: 1.0961, policy_loss: 1.1081, value_loss: 0.6934
2024-07-14 06:12:58,983 [INFO    ] __main__: train step 11072: loss: 1.0961, policy_loss: 1.1080, value_loss: 0.6933
2024-07-14 06:12:59,282 [INFO    ] __main__: train step 11073: loss: 1.0961, policy_loss: 1.1080, value_loss: 0.6933
2024-07-14 06:12:59,591 [INFO    ] __main__: train step 11074: loss: 1.0961, policy_loss: 1.1080, value_loss: 0.6932
2024-07-14 06:12:59,882 [INFO    ] __main__: train step 11075: loss: 1.0961, policy_loss: 1.1079, value_loss: 0.6932
2024-07-14 06:13:00,181 [INFO    ] __main__: train step 11076: loss: 1.0961, policy_loss: 1.1079, value_loss: 0.6932
2024-07-14 06:13:00,478 [INFO    ] __main__: train step 11077: loss: 1.0961, policy_loss: 1.1079, value_loss: 0.6931
2024-07-14 06:13:00,756 [INFO    ] __main__: train step 11078: loss: 1.0961, policy_loss: 1.1079, value_loss: 0.6931
2024-07-14 06:13:01,072 [INFO    ] __main__: train step 11079: loss: 1.0961, policy_loss: 1.1078, value_loss: 0.6930
2024-07-14 06:13:01,369 [INFO    ] __main__: train step 11080: loss: 1.0961, policy_loss: 1.1078, value_loss: 0.6930
2024-07-14 06:13:02,984 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:13:03,480 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:13:03,549 [INFO    ] __main__: train step 11081: loss: 1.0961, policy_loss: 1.1078, value_loss: 0.6930
2024-07-14 06:13:03,861 [INFO    ] __main__: train step 11082: loss: 1.0961, policy_loss: 1.1078, value_loss: 0.6929
2024-07-14 06:13:04,152 [INFO    ] __main__: train step 11083: loss: 1.0961, policy_loss: 1.1077, value_loss: 0.6929
2024-07-14 06:13:04,436 [INFO    ] __main__: train step 11084: loss: 1.0960, policy_loss: 1.1077, value_loss: 0.6929
2024-07-14 06:13:04,722 [INFO    ] __main__: train step 11085: loss: 1.0960, policy_loss: 1.1077, value_loss: 0.6928
2024-07-14 06:13:05,023 [INFO    ] __main__: train step 11086: loss: 1.0960, policy_loss: 1.1077, value_loss: 0.6928
2024-07-14 06:13:05,312 [INFO    ] __main__: train step 11087: loss: 1.0960, policy_loss: 1.1076, value_loss: 0.6927
2024-07-14 06:13:05,602 [INFO    ] __main__: train step 11088: loss: 1.0960, policy_loss: 1.1076, value_loss: 0.6927
2024-07-14 06:13:05,893 [INFO    ] __main__: train step 11089: loss: 1.0960, policy_loss: 1.1076, value_loss: 0.6927
2024-07-14 06:13:06,184 [INFO    ] __main__: train step 11090: loss: 1.0960, policy_loss: 1.1076, value_loss: 0.6926
2024-07-14 06:13:06,449 [INFO    ] __main__: train step 11091: loss: 1.0960, policy_loss: 1.1075, value_loss: 0.6926
2024-07-14 06:13:06,719 [INFO    ] __main__: train step 11092: loss: 1.0960, policy_loss: 1.1075, value_loss: 0.6925
2024-07-14 06:13:07,005 [INFO    ] __main__: train step 11093: loss: 1.0960, policy_loss: 1.1075, value_loss: 0.6925
2024-07-14 06:13:07,297 [INFO    ] __main__: train step 11094: loss: 1.0960, policy_loss: 1.1075, value_loss: 0.6925
2024-07-14 06:13:07,598 [INFO    ] __main__: train step 11095: loss: 1.0960, policy_loss: 1.1074, value_loss: 0.6924
2024-07-14 06:13:07,892 [INFO    ] __main__: train step 11096: loss: 1.0960, policy_loss: 1.1074, value_loss: 0.6924
2024-07-14 06:13:08,189 [INFO    ] __main__: train step 11097: loss: 1.0960, policy_loss: 1.1074, value_loss: 0.6923
2024-07-14 06:13:09,817 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:13:10,288 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:13:10,359 [INFO    ] __main__: train step 11098: loss: 1.0960, policy_loss: 1.1073, value_loss: 0.6923
2024-07-14 06:13:10,666 [INFO    ] __main__: train step 11099: loss: 1.0960, policy_loss: 1.1073, value_loss: 0.6923
2024-07-14 06:13:10,947 [INFO    ] __main__: train step 11100: loss: 1.0960, policy_loss: 1.1073, value_loss: 0.6922
2024-07-14 06:13:11,241 [INFO    ] __main__: train step 11101: loss: 1.0960, policy_loss: 1.1073, value_loss: 0.6922
2024-07-14 06:13:11,533 [INFO    ] __main__: train step 11102: loss: 1.0960, policy_loss: 1.1072, value_loss: 0.6921
2024-07-14 06:13:11,821 [INFO    ] __main__: train step 11103: loss: 1.0960, policy_loss: 1.1072, value_loss: 0.6921
2024-07-14 06:13:12,117 [INFO    ] __main__: train step 11104: loss: 1.0960, policy_loss: 1.1072, value_loss: 0.6921
2024-07-14 06:13:12,418 [INFO    ] __main__: train step 11105: loss: 1.0960, policy_loss: 1.1072, value_loss: 0.6920
2024-07-14 06:13:12,686 [INFO    ] __main__: train step 11106: loss: 1.0960, policy_loss: 1.1071, value_loss: 0.6920
2024-07-14 06:13:12,976 [INFO    ] __main__: train step 11107: loss: 1.0960, policy_loss: 1.1071, value_loss: 0.6920
2024-07-14 06:13:13,250 [INFO    ] __main__: train step 11108: loss: 1.0960, policy_loss: 1.1071, value_loss: 0.6919
2024-07-14 06:13:13,511 [INFO    ] __main__: train step 11109: loss: 1.0960, policy_loss: 1.1071, value_loss: 0.6919
2024-07-14 06:13:13,790 [INFO    ] __main__: train step 11110: loss: 1.0960, policy_loss: 1.1070, value_loss: 0.6918
2024-07-14 06:13:14,093 [INFO    ] __main__: train step 11111: loss: 1.0960, policy_loss: 1.1070, value_loss: 0.6918
2024-07-14 06:13:14,389 [INFO    ] __main__: train step 11112: loss: 1.0960, policy_loss: 1.1070, value_loss: 0.6918
2024-07-14 06:13:14,696 [INFO    ] __main__: train step 11113: loss: 1.0960, policy_loss: 1.1070, value_loss: 0.6917
2024-07-14 06:13:14,983 [INFO    ] __main__: train step 11114: loss: 1.0960, policy_loss: 1.1069, value_loss: 0.6917
2024-07-14 06:13:16,599 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:13:17,105 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:13:17,175 [INFO    ] __main__: train step 11115: loss: 1.0960, policy_loss: 1.1069, value_loss: 0.6916
2024-07-14 06:13:17,474 [INFO    ] __main__: train step 11116: loss: 1.0960, policy_loss: 1.1069, value_loss: 0.6916
2024-07-14 06:13:17,756 [INFO    ] __main__: train step 11117: loss: 1.0960, policy_loss: 1.1069, value_loss: 0.6916
2024-07-14 06:13:18,039 [INFO    ] __main__: train step 11118: loss: 1.0960, policy_loss: 1.1068, value_loss: 0.6915
2024-07-14 06:13:18,334 [INFO    ] __main__: train step 11119: loss: 1.0960, policy_loss: 1.1068, value_loss: 0.6915
2024-07-14 06:13:18,624 [INFO    ] __main__: train step 11120: loss: 1.0960, policy_loss: 1.1068, value_loss: 0.6914
2024-07-14 06:13:18,925 [INFO    ] __main__: train step 11121: loss: 1.0960, policy_loss: 1.1068, value_loss: 0.6914
2024-07-14 06:13:19,223 [INFO    ] __main__: train step 11122: loss: 1.0960, policy_loss: 1.1067, value_loss: 0.6914
2024-07-14 06:13:19,522 [INFO    ] __main__: train step 11123: loss: 1.0960, policy_loss: 1.1067, value_loss: 0.6913
2024-07-14 06:13:19,809 [INFO    ] __main__: train step 11124: loss: 1.0960, policy_loss: 1.1067, value_loss: 0.6913
2024-07-14 06:13:20,107 [INFO    ] __main__: train step 11125: loss: 1.0960, policy_loss: 1.1067, value_loss: 0.6912
2024-07-14 06:13:20,401 [INFO    ] __main__: train step 11126: loss: 1.0960, policy_loss: 1.1066, value_loss: 0.6912
2024-07-14 06:13:20,690 [INFO    ] __main__: train step 11127: loss: 1.0960, policy_loss: 1.1066, value_loss: 0.6912
2024-07-14 06:13:20,995 [INFO    ] __main__: train step 11128: loss: 1.0960, policy_loss: 1.1066, value_loss: 0.6911
2024-07-14 06:13:21,292 [INFO    ] __main__: train step 11129: loss: 1.0960, policy_loss: 1.1065, value_loss: 0.6911
2024-07-14 06:13:21,588 [INFO    ] __main__: train step 11130: loss: 1.0960, policy_loss: 1.1065, value_loss: 0.6911
2024-07-14 06:13:21,875 [INFO    ] __main__: train step 11131: loss: 1.0960, policy_loss: 1.1065, value_loss: 0.6910
2024-07-14 06:13:23,500 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:13:23,986 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:13:24,058 [INFO    ] __main__: train step 11132: loss: 1.0960, policy_loss: 1.1065, value_loss: 0.6910
2024-07-14 06:13:24,362 [INFO    ] __main__: train step 11133: loss: 1.0960, policy_loss: 1.1064, value_loss: 0.6909
2024-07-14 06:13:24,654 [INFO    ] __main__: train step 11134: loss: 1.0960, policy_loss: 1.1064, value_loss: 0.6909
2024-07-14 06:13:24,948 [INFO    ] __main__: train step 11135: loss: 1.0960, policy_loss: 1.1064, value_loss: 0.6909
2024-07-14 06:13:25,232 [INFO    ] __main__: train step 11136: loss: 1.0960, policy_loss: 1.1064, value_loss: 0.6908
2024-07-14 06:13:28,204 [INFO    ] __main__: train step 11137: loss: 1.0960, policy_loss: 1.1063, value_loss: 0.6908
2024-07-14 06:13:28,499 [INFO    ] __main__: train step 11138: loss: 1.0960, policy_loss: 1.1063, value_loss: 0.6907
2024-07-14 06:13:28,799 [INFO    ] __main__: train step 11139: loss: 1.0960, policy_loss: 1.1063, value_loss: 0.6907
2024-07-14 06:13:29,112 [INFO    ] __main__: train step 11140: loss: 1.0960, policy_loss: 1.1063, value_loss: 0.6907
2024-07-14 06:13:29,420 [INFO    ] __main__: train step 11141: loss: 1.0960, policy_loss: 1.1062, value_loss: 0.6906
2024-07-14 06:13:29,724 [INFO    ] __main__: train step 11142: loss: 1.0960, policy_loss: 1.1062, value_loss: 0.6906
2024-07-14 06:13:30,011 [INFO    ] __main__: train step 11143: loss: 1.0960, policy_loss: 1.1062, value_loss: 0.6905
2024-07-14 06:13:30,305 [INFO    ] __main__: train step 11144: loss: 1.0960, policy_loss: 1.1062, value_loss: 0.6905
2024-07-14 06:13:30,601 [INFO    ] __main__: train step 11145: loss: 1.0960, policy_loss: 1.1061, value_loss: 0.6905
2024-07-14 06:13:30,897 [INFO    ] __main__: train step 11146: loss: 1.0960, policy_loss: 1.1061, value_loss: 0.6904
2024-07-14 06:13:31,198 [INFO    ] __main__: train step 11147: loss: 1.0960, policy_loss: 1.1061, value_loss: 0.6904
2024-07-14 06:13:31,478 [INFO    ] __main__: train step 11148: loss: 1.0960, policy_loss: 1.1061, value_loss: 0.6904
2024-07-14 06:13:33,108 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:13:33,595 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:13:33,666 [INFO    ] __main__: train step 11149: loss: 1.0960, policy_loss: 1.1060, value_loss: 0.6903
2024-07-14 06:13:33,966 [INFO    ] __main__: train step 11150: loss: 1.0960, policy_loss: 1.1060, value_loss: 0.6903
2024-07-14 06:13:34,256 [INFO    ] __main__: train step 11151: loss: 1.0960, policy_loss: 1.1060, value_loss: 0.6902
2024-07-14 06:13:34,542 [INFO    ] __main__: train step 11152: loss: 1.0960, policy_loss: 1.1060, value_loss: 0.6902
2024-07-14 06:13:34,845 [INFO    ] __main__: train step 11153: loss: 1.0960, policy_loss: 1.1059, value_loss: 0.6902
2024-07-14 06:13:35,142 [INFO    ] __main__: train step 11154: loss: 1.0960, policy_loss: 1.1059, value_loss: 0.6901
2024-07-14 06:13:35,436 [INFO    ] __main__: train step 11155: loss: 1.0960, policy_loss: 1.1059, value_loss: 0.6901
2024-07-14 06:13:35,731 [INFO    ] __main__: train step 11156: loss: 1.0960, policy_loss: 1.1059, value_loss: 0.6901
2024-07-14 06:13:36,018 [INFO    ] __main__: train step 11157: loss: 1.0960, policy_loss: 1.1059, value_loss: 0.6900
2024-07-14 06:13:36,319 [INFO    ] __main__: train step 11158: loss: 1.0960, policy_loss: 1.1058, value_loss: 0.6900
2024-07-14 06:13:36,606 [INFO    ] __main__: train step 11159: loss: 1.0960, policy_loss: 1.1058, value_loss: 0.6899
2024-07-14 06:13:36,902 [INFO    ] __main__: train step 11160: loss: 1.0960, policy_loss: 1.1058, value_loss: 0.6899
2024-07-14 06:13:37,188 [INFO    ] __main__: train step 11161: loss: 1.0960, policy_loss: 1.1057, value_loss: 0.6899
2024-07-14 06:13:37,480 [INFO    ] __main__: train step 11162: loss: 1.0960, policy_loss: 1.1057, value_loss: 0.6898
2024-07-14 06:13:37,769 [INFO    ] __main__: train step 11163: loss: 1.0960, policy_loss: 1.1057, value_loss: 0.6898
2024-07-14 06:13:38,076 [INFO    ] __main__: train step 11164: loss: 1.0960, policy_loss: 1.1057, value_loss: 0.6897
2024-07-14 06:13:38,355 [INFO    ] __main__: train step 11165: loss: 1.0960, policy_loss: 1.1057, value_loss: 0.6897
2024-07-14 06:13:39,965 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:13:40,453 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:13:40,523 [INFO    ] __main__: train step 11166: loss: 1.0960, policy_loss: 1.1056, value_loss: 0.6897
2024-07-14 06:13:40,819 [INFO    ] __main__: train step 11167: loss: 1.0960, policy_loss: 1.1056, value_loss: 0.6896
2024-07-14 06:13:41,113 [INFO    ] __main__: train step 11168: loss: 1.0960, policy_loss: 1.1056, value_loss: 0.6896
2024-07-14 06:13:41,401 [INFO    ] __main__: train step 11169: loss: 1.0960, policy_loss: 1.1056, value_loss: 0.6896
2024-07-14 06:13:41,696 [INFO    ] __main__: train step 11170: loss: 1.0960, policy_loss: 1.1055, value_loss: 0.6895
2024-07-14 06:13:42,003 [INFO    ] __main__: train step 11171: loss: 1.0960, policy_loss: 1.1055, value_loss: 0.6895
2024-07-14 06:13:42,293 [INFO    ] __main__: train step 11172: loss: 1.0960, policy_loss: 1.1055, value_loss: 0.6894
2024-07-14 06:13:42,579 [INFO    ] __main__: train step 11173: loss: 1.0960, policy_loss: 1.1055, value_loss: 0.6894
2024-07-14 06:13:42,871 [INFO    ] __main__: train step 11174: loss: 1.0960, policy_loss: 1.1054, value_loss: 0.6894
2024-07-14 06:13:43,160 [INFO    ] __main__: train step 11175: loss: 1.0960, policy_loss: 1.1054, value_loss: 0.6893
2024-07-14 06:13:43,445 [INFO    ] __main__: train step 11176: loss: 1.0960, policy_loss: 1.1054, value_loss: 0.6893
2024-07-14 06:13:43,747 [INFO    ] __main__: train step 11177: loss: 1.0960, policy_loss: 1.1054, value_loss: 0.6892
2024-07-14 06:13:44,048 [INFO    ] __main__: train step 11178: loss: 1.0960, policy_loss: 1.1053, value_loss: 0.6892
2024-07-14 06:13:44,333 [INFO    ] __main__: train step 11179: loss: 1.0960, policy_loss: 1.1053, value_loss: 0.6892
2024-07-14 06:13:44,623 [INFO    ] __main__: train step 11180: loss: 1.0960, policy_loss: 1.1053, value_loss: 0.6891
2024-07-14 06:13:44,925 [INFO    ] __main__: train step 11181: loss: 1.0960, policy_loss: 1.1053, value_loss: 0.6891
2024-07-14 06:13:45,214 [INFO    ] __main__: train step 11182: loss: 1.0960, policy_loss: 1.1052, value_loss: 0.6891
2024-07-14 06:13:46,835 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:13:47,332 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:13:47,403 [INFO    ] __main__: train step 11183: loss: 1.0960, policy_loss: 1.1052, value_loss: 0.6890
2024-07-14 06:13:47,697 [INFO    ] __main__: train step 11184: loss: 1.0960, policy_loss: 1.1052, value_loss: 0.6890
2024-07-14 06:13:47,982 [INFO    ] __main__: train step 11185: loss: 1.0960, policy_loss: 1.1052, value_loss: 0.6889
2024-07-14 06:13:48,271 [INFO    ] __main__: train step 11186: loss: 1.0959, policy_loss: 1.1051, value_loss: 0.6889
2024-07-14 06:13:48,561 [INFO    ] __main__: train step 11187: loss: 1.0959, policy_loss: 1.1051, value_loss: 0.6889
2024-07-14 06:13:48,834 [INFO    ] __main__: train step 11188: loss: 1.0959, policy_loss: 1.1051, value_loss: 0.6888
2024-07-14 06:13:49,128 [INFO    ] __main__: train step 11189: loss: 1.0959, policy_loss: 1.1051, value_loss: 0.6888
2024-07-14 06:13:49,420 [INFO    ] __main__: train step 11190: loss: 1.0959, policy_loss: 1.1050, value_loss: 0.6887
2024-07-14 06:13:49,702 [INFO    ] __main__: train step 11191: loss: 1.0959, policy_loss: 1.1050, value_loss: 0.6887
2024-07-14 06:13:49,987 [INFO    ] __main__: train step 11192: loss: 1.0959, policy_loss: 1.1050, value_loss: 0.6887
2024-07-14 06:13:50,284 [INFO    ] __main__: train step 11193: loss: 1.0959, policy_loss: 1.1050, value_loss: 0.6886
2024-07-14 06:13:50,591 [INFO    ] __main__: train step 11194: loss: 1.0959, policy_loss: 1.1049, value_loss: 0.6886
2024-07-14 06:13:50,881 [INFO    ] __main__: train step 11195: loss: 1.0959, policy_loss: 1.1049, value_loss: 0.6886
2024-07-14 06:13:51,143 [INFO    ] __main__: train step 11196: loss: 1.0959, policy_loss: 1.1049, value_loss: 0.6885
2024-07-14 06:13:51,421 [INFO    ] __main__: train step 11197: loss: 1.0959, policy_loss: 1.1049, value_loss: 0.6885
2024-07-14 06:13:51,681 [INFO    ] __main__: train step 11198: loss: 1.0959, policy_loss: 1.1048, value_loss: 0.6884
2024-07-14 06:13:51,958 [INFO    ] __main__: train step 11199: loss: 1.0959, policy_loss: 1.1048, value_loss: 0.6884
2024-07-14 06:13:53,551 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:13:54,035 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:13:54,107 [INFO    ] __main__: train step 11200: loss: 1.0959, policy_loss: 1.1048, value_loss: 0.6884
2024-07-14 06:13:54,387 [INFO    ] __main__: train step 11201: loss: 1.0959, policy_loss: 1.1048, value_loss: 0.6883
2024-07-14 06:13:54,681 [INFO    ] __main__: train step 11202: loss: 1.0959, policy_loss: 1.1047, value_loss: 0.6883
2024-07-14 06:13:54,971 [INFO    ] __main__: train step 11203: loss: 1.0959, policy_loss: 1.1047, value_loss: 0.6882
2024-07-14 06:13:55,254 [INFO    ] __main__: train step 11204: loss: 1.0959, policy_loss: 1.1047, value_loss: 0.6882
2024-07-14 06:13:55,515 [INFO    ] __main__: train step 11205: loss: 1.0959, policy_loss: 1.1047, value_loss: 0.6882
2024-07-14 06:13:55,791 [INFO    ] __main__: train step 11206: loss: 1.0959, policy_loss: 1.1046, value_loss: 0.6881
2024-07-14 06:13:56,083 [INFO    ] __main__: train step 11207: loss: 1.0959, policy_loss: 1.1046, value_loss: 0.6881
2024-07-14 06:13:56,377 [INFO    ] __main__: train step 11208: loss: 1.0959, policy_loss: 1.1046, value_loss: 0.6881
2024-07-14 06:13:56,668 [INFO    ] __main__: train step 11209: loss: 1.0959, policy_loss: 1.1046, value_loss: 0.6880
2024-07-14 06:13:56,955 [INFO    ] __main__: train step 11210: loss: 1.0959, policy_loss: 1.1045, value_loss: 0.6880
2024-07-14 06:13:57,248 [INFO    ] __main__: train step 11211: loss: 1.0959, policy_loss: 1.1045, value_loss: 0.6879
2024-07-14 06:13:57,546 [INFO    ] __main__: train step 11212: loss: 1.0959, policy_loss: 1.1045, value_loss: 0.6879
2024-07-14 06:13:57,837 [INFO    ] __main__: train step 11213: loss: 1.0959, policy_loss: 1.1045, value_loss: 0.6879
2024-07-14 06:13:58,131 [INFO    ] __main__: train step 11214: loss: 1.0959, policy_loss: 1.1044, value_loss: 0.6878
2024-07-14 06:13:58,431 [INFO    ] __main__: train step 11215: loss: 1.0959, policy_loss: 1.1044, value_loss: 0.6878
2024-07-14 06:13:58,727 [INFO    ] __main__: train step 11216: loss: 1.0959, policy_loss: 1.1044, value_loss: 0.6877
2024-07-14 06:14:00,361 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:14:00,846 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:14:00,912 [INFO    ] __main__: train step 11217: loss: 1.0959, policy_loss: 1.1044, value_loss: 0.6877
2024-07-14 06:14:01,205 [INFO    ] __main__: train step 11218: loss: 1.0959, policy_loss: 1.1044, value_loss: 0.6877
2024-07-14 06:14:01,478 [INFO    ] __main__: train step 11219: loss: 1.0959, policy_loss: 1.1043, value_loss: 0.6876
2024-07-14 06:14:01,758 [INFO    ] __main__: train step 11220: loss: 1.0959, policy_loss: 1.1043, value_loss: 0.6876
2024-07-14 06:14:02,049 [INFO    ] __main__: train step 11221: loss: 1.0959, policy_loss: 1.1043, value_loss: 0.6876
2024-07-14 06:14:02,331 [INFO    ] __main__: train step 11222: loss: 1.0959, policy_loss: 1.1043, value_loss: 0.6875
2024-07-14 06:14:02,615 [INFO    ] __main__: train step 11223: loss: 1.0959, policy_loss: 1.1042, value_loss: 0.6875
2024-07-14 06:14:02,917 [INFO    ] __main__: train step 11224: loss: 1.0959, policy_loss: 1.1042, value_loss: 0.6874
2024-07-14 06:14:03,204 [INFO    ] __main__: train step 11225: loss: 1.0959, policy_loss: 1.1042, value_loss: 0.6874
2024-07-14 06:14:06,216 [INFO    ] __main__: train step 11226: loss: 1.0959, policy_loss: 1.1042, value_loss: 0.6874
2024-07-14 06:14:06,508 [INFO    ] __main__: train step 11227: loss: 1.0959, policy_loss: 1.1041, value_loss: 0.6873
2024-07-14 06:14:06,812 [INFO    ] __main__: train step 11228: loss: 1.0959, policy_loss: 1.1041, value_loss: 0.6873
2024-07-14 06:14:07,102 [INFO    ] __main__: train step 11229: loss: 1.0959, policy_loss: 1.1041, value_loss: 0.6873
2024-07-14 06:14:07,404 [INFO    ] __main__: train step 11230: loss: 1.0959, policy_loss: 1.1041, value_loss: 0.6872
2024-07-14 06:14:07,691 [INFO    ] __main__: train step 11231: loss: 1.0959, policy_loss: 1.1040, value_loss: 0.6872
2024-07-14 06:14:07,984 [INFO    ] __main__: train step 11232: loss: 1.0959, policy_loss: 1.1040, value_loss: 0.6871
2024-07-14 06:14:08,282 [INFO    ] __main__: train step 11233: loss: 1.0959, policy_loss: 1.1040, value_loss: 0.6871
2024-07-14 06:14:09,917 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:14:10,419 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:14:10,491 [INFO    ] __main__: train step 11234: loss: 1.0959, policy_loss: 1.1040, value_loss: 0.6871
2024-07-14 06:14:10,786 [INFO    ] __main__: train step 11235: loss: 1.0959, policy_loss: 1.1039, value_loss: 0.6870
2024-07-14 06:14:11,083 [INFO    ] __main__: train step 11236: loss: 1.0959, policy_loss: 1.1039, value_loss: 0.6870
2024-07-14 06:14:11,367 [INFO    ] __main__: train step 11237: loss: 1.0959, policy_loss: 1.1039, value_loss: 0.6869
2024-07-14 06:14:11,676 [INFO    ] __main__: train step 11238: loss: 1.0959, policy_loss: 1.1039, value_loss: 0.6869
2024-07-14 06:14:11,986 [INFO    ] __main__: train step 11239: loss: 1.0959, policy_loss: 1.1039, value_loss: 0.6869
2024-07-14 06:14:12,284 [INFO    ] __main__: train step 11240: loss: 1.0959, policy_loss: 1.1038, value_loss: 0.6868
2024-07-14 06:14:12,569 [INFO    ] __main__: train step 11241: loss: 1.0959, policy_loss: 1.1038, value_loss: 0.6868
2024-07-14 06:14:12,860 [INFO    ] __main__: train step 11242: loss: 1.0959, policy_loss: 1.1038, value_loss: 0.6868
2024-07-14 06:14:13,156 [INFO    ] __main__: train step 11243: loss: 1.0959, policy_loss: 1.1038, value_loss: 0.6867
2024-07-14 06:14:13,447 [INFO    ] __main__: train step 11244: loss: 1.0959, policy_loss: 1.1037, value_loss: 0.6867
2024-07-14 06:14:13,742 [INFO    ] __main__: train step 11245: loss: 1.0959, policy_loss: 1.1037, value_loss: 0.6866
2024-07-14 06:14:14,038 [INFO    ] __main__: train step 11246: loss: 1.0959, policy_loss: 1.1037, value_loss: 0.6866
2024-07-14 06:14:14,312 [INFO    ] __main__: train step 11247: loss: 1.0959, policy_loss: 1.1037, value_loss: 0.6866
2024-07-14 06:14:14,597 [INFO    ] __main__: train step 11248: loss: 1.0959, policy_loss: 1.1036, value_loss: 0.6865
2024-07-14 06:14:14,899 [INFO    ] __main__: train step 11249: loss: 1.0959, policy_loss: 1.1036, value_loss: 0.6865
2024-07-14 06:14:15,198 [INFO    ] __main__: train step 11250: loss: 1.0959, policy_loss: 1.1036, value_loss: 0.6865
2024-07-14 06:14:16,828 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:14:17,328 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:14:17,402 [INFO    ] __main__: train step 11251: loss: 1.0959, policy_loss: 1.1036, value_loss: 0.6864
2024-07-14 06:14:17,694 [INFO    ] __main__: train step 11252: loss: 1.0959, policy_loss: 1.1035, value_loss: 0.6864
2024-07-14 06:14:18,004 [INFO    ] __main__: train step 11253: loss: 1.0959, policy_loss: 1.1035, value_loss: 0.6863
2024-07-14 06:14:18,301 [INFO    ] __main__: train step 11254: loss: 1.0959, policy_loss: 1.1035, value_loss: 0.6863
2024-07-14 06:14:18,598 [INFO    ] __main__: train step 11255: loss: 1.0959, policy_loss: 1.1035, value_loss: 0.6863
2024-07-14 06:14:18,917 [INFO    ] __main__: train step 11256: loss: 1.0959, policy_loss: 1.1035, value_loss: 0.6862
2024-07-14 06:14:19,206 [INFO    ] __main__: train step 11257: loss: 1.0959, policy_loss: 1.1034, value_loss: 0.6862
2024-07-14 06:14:19,509 [INFO    ] __main__: train step 11258: loss: 1.0959, policy_loss: 1.1034, value_loss: 0.6862
2024-07-14 06:14:19,803 [INFO    ] __main__: train step 11259: loss: 1.0959, policy_loss: 1.1034, value_loss: 0.6861
2024-07-14 06:14:20,109 [INFO    ] __main__: train step 11260: loss: 1.0959, policy_loss: 1.1034, value_loss: 0.6861
2024-07-14 06:14:20,406 [INFO    ] __main__: train step 11261: loss: 1.0959, policy_loss: 1.1033, value_loss: 0.6860
2024-07-14 06:14:20,699 [INFO    ] __main__: train step 11262: loss: 1.0959, policy_loss: 1.1033, value_loss: 0.6860
2024-07-14 06:14:20,999 [INFO    ] __main__: train step 11263: loss: 1.0959, policy_loss: 1.1033, value_loss: 0.6860
2024-07-14 06:14:21,292 [INFO    ] __main__: train step 11264: loss: 1.0959, policy_loss: 1.1033, value_loss: 0.6859
2024-07-14 06:14:21,586 [INFO    ] __main__: train step 11265: loss: 1.0959, policy_loss: 1.1032, value_loss: 0.6859
2024-07-14 06:14:21,870 [INFO    ] __main__: train step 11266: loss: 1.0959, policy_loss: 1.1032, value_loss: 0.6859
2024-07-14 06:14:22,158 [INFO    ] __main__: train step 11267: loss: 1.0959, policy_loss: 1.1032, value_loss: 0.6858
2024-07-14 06:14:23,769 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:14:24,272 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:14:24,339 [INFO    ] __main__: train step 11268: loss: 1.0959, policy_loss: 1.1032, value_loss: 0.6858
2024-07-14 06:14:24,630 [INFO    ] __main__: train step 11269: loss: 1.0959, policy_loss: 1.1031, value_loss: 0.6857
2024-07-14 06:14:24,925 [INFO    ] __main__: train step 11270: loss: 1.0959, policy_loss: 1.1031, value_loss: 0.6857
2024-07-14 06:14:25,225 [INFO    ] __main__: train step 11271: loss: 1.0959, policy_loss: 1.1031, value_loss: 0.6857
2024-07-14 06:14:25,511 [INFO    ] __main__: train step 11272: loss: 1.0959, policy_loss: 1.1031, value_loss: 0.6856
2024-07-14 06:14:25,797 [INFO    ] __main__: train step 11273: loss: 1.0959, policy_loss: 1.1031, value_loss: 0.6856
2024-07-14 06:14:26,095 [INFO    ] __main__: train step 11274: loss: 1.0959, policy_loss: 1.1030, value_loss: 0.6855
2024-07-14 06:14:26,395 [INFO    ] __main__: train step 11275: loss: 1.0959, policy_loss: 1.1030, value_loss: 0.6855
2024-07-14 06:14:26,693 [INFO    ] __main__: train step 11276: loss: 1.0959, policy_loss: 1.1030, value_loss: 0.6855
2024-07-14 06:14:26,978 [INFO    ] __main__: train step 11277: loss: 1.0959, policy_loss: 1.1030, value_loss: 0.6854
2024-07-14 06:14:27,267 [INFO    ] __main__: train step 11278: loss: 1.0959, policy_loss: 1.1029, value_loss: 0.6854
2024-07-14 06:14:27,553 [INFO    ] __main__: train step 11279: loss: 1.0959, policy_loss: 1.1029, value_loss: 0.6854
2024-07-14 06:14:27,857 [INFO    ] __main__: train step 11280: loss: 1.0959, policy_loss: 1.1029, value_loss: 0.6853
2024-07-14 06:14:28,151 [INFO    ] __main__: train step 11281: loss: 1.0959, policy_loss: 1.1029, value_loss: 0.6853
2024-07-14 06:14:28,445 [INFO    ] __main__: train step 11282: loss: 1.0959, policy_loss: 1.1028, value_loss: 0.6852
2024-07-14 06:14:28,754 [INFO    ] __main__: train step 11283: loss: 1.0959, policy_loss: 1.1028, value_loss: 0.6852
2024-07-14 06:14:29,043 [INFO    ] __main__: train step 11284: loss: 1.0960, policy_loss: 1.1028, value_loss: 0.6852
2024-07-14 06:14:30,659 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:14:31,161 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:14:31,234 [INFO    ] __main__: train step 11285: loss: 1.0960, policy_loss: 1.1028, value_loss: 0.6851
2024-07-14 06:14:31,525 [INFO    ] __main__: train step 11286: loss: 1.0960, policy_loss: 1.1028, value_loss: 0.6851
2024-07-14 06:14:31,817 [INFO    ] __main__: train step 11287: loss: 1.0960, policy_loss: 1.1027, value_loss: 0.6851
2024-07-14 06:14:32,106 [INFO    ] __main__: train step 11288: loss: 1.0960, policy_loss: 1.1027, value_loss: 0.6850
2024-07-14 06:14:32,395 [INFO    ] __main__: train step 11289: loss: 1.0960, policy_loss: 1.1027, value_loss: 0.6850
2024-07-14 06:14:32,685 [INFO    ] __main__: train step 11290: loss: 1.0960, policy_loss: 1.1027, value_loss: 0.6849
2024-07-14 06:14:32,963 [INFO    ] __main__: train step 11291: loss: 1.0960, policy_loss: 1.1026, value_loss: 0.6849
2024-07-14 06:14:33,234 [INFO    ] __main__: train step 11292: loss: 1.0960, policy_loss: 1.1026, value_loss: 0.6849
2024-07-14 06:14:33,522 [INFO    ] __main__: train step 11293: loss: 1.0960, policy_loss: 1.1026, value_loss: 0.6848
2024-07-14 06:14:33,806 [INFO    ] __main__: train step 11294: loss: 1.0960, policy_loss: 1.1026, value_loss: 0.6848
2024-07-14 06:14:34,092 [INFO    ] __main__: train step 11295: loss: 1.0960, policy_loss: 1.1026, value_loss: 0.6848
2024-07-14 06:14:34,390 [INFO    ] __main__: train step 11296: loss: 1.0960, policy_loss: 1.1025, value_loss: 0.6847
2024-07-14 06:14:34,681 [INFO    ] __main__: train step 11297: loss: 1.0960, policy_loss: 1.1025, value_loss: 0.6847
2024-07-14 06:14:34,969 [INFO    ] __main__: train step 11298: loss: 1.0960, policy_loss: 1.1025, value_loss: 0.6846
2024-07-14 06:14:35,238 [INFO    ] __main__: train step 11299: loss: 1.0960, policy_loss: 1.1025, value_loss: 0.6846
2024-07-14 06:14:35,531 [INFO    ] __main__: train step 11300: loss: 1.0960, policy_loss: 1.1024, value_loss: 0.6846
2024-07-14 06:14:35,830 [INFO    ] __main__: train step 11301: loss: 1.0960, policy_loss: 1.1024, value_loss: 0.6845
2024-07-14 06:14:37,452 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:14:37,938 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:14:38,007 [INFO    ] __main__: train step 11302: loss: 1.0960, policy_loss: 1.1024, value_loss: 0.6845
2024-07-14 06:14:38,297 [INFO    ] __main__: train step 11303: loss: 1.0960, policy_loss: 1.1024, value_loss: 0.6845
2024-07-14 06:14:38,564 [INFO    ] __main__: train step 11304: loss: 1.0960, policy_loss: 1.1023, value_loss: 0.6844
2024-07-14 06:14:38,849 [INFO    ] __main__: train step 11305: loss: 1.0960, policy_loss: 1.1023, value_loss: 0.6844
2024-07-14 06:14:39,122 [INFO    ] __main__: train step 11306: loss: 1.0960, policy_loss: 1.1023, value_loss: 0.6844
2024-07-14 06:14:39,396 [INFO    ] __main__: train step 11307: loss: 1.0960, policy_loss: 1.1023, value_loss: 0.6843
2024-07-14 06:14:39,691 [INFO    ] __main__: train step 11308: loss: 1.0960, policy_loss: 1.1023, value_loss: 0.6843
2024-07-14 06:14:39,983 [INFO    ] __main__: train step 11309: loss: 1.0960, policy_loss: 1.1022, value_loss: 0.6842
2024-07-14 06:14:40,271 [INFO    ] __main__: train step 11310: loss: 1.0960, policy_loss: 1.1022, value_loss: 0.6842
2024-07-14 06:14:40,558 [INFO    ] __main__: train step 11311: loss: 1.0960, policy_loss: 1.1022, value_loss: 0.6842
2024-07-14 06:14:40,841 [INFO    ] __main__: train step 11312: loss: 1.0960, policy_loss: 1.1022, value_loss: 0.6841
2024-07-14 06:14:41,127 [INFO    ] __main__: train step 11313: loss: 1.0960, policy_loss: 1.1021, value_loss: 0.6841
2024-07-14 06:14:41,409 [INFO    ] __main__: train step 11314: loss: 1.0960, policy_loss: 1.1021, value_loss: 0.6841
2024-07-14 06:14:44,351 [INFO    ] __main__: train step 11315: loss: 1.0960, policy_loss: 1.1021, value_loss: 0.6840
2024-07-14 06:14:44,641 [INFO    ] __main__: train step 11316: loss: 1.0960, policy_loss: 1.1021, value_loss: 0.6840
2024-07-14 06:14:44,930 [INFO    ] __main__: train step 11317: loss: 1.0960, policy_loss: 1.1021, value_loss: 0.6839
2024-07-14 06:14:45,212 [INFO    ] __main__: train step 11318: loss: 1.0960, policy_loss: 1.1020, value_loss: 0.6839
2024-07-14 06:14:46,822 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:14:47,308 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:14:47,377 [INFO    ] __main__: train step 11319: loss: 1.0960, policy_loss: 1.1020, value_loss: 0.6839
2024-07-14 06:14:47,674 [INFO    ] __main__: train step 11320: loss: 1.0960, policy_loss: 1.1020, value_loss: 0.6838
2024-07-14 06:14:47,958 [INFO    ] __main__: train step 11321: loss: 1.0960, policy_loss: 1.1020, value_loss: 0.6838
2024-07-14 06:14:48,245 [INFO    ] __main__: train step 11322: loss: 1.0960, policy_loss: 1.1019, value_loss: 0.6838
2024-07-14 06:14:48,523 [INFO    ] __main__: train step 11323: loss: 1.0960, policy_loss: 1.1019, value_loss: 0.6837
2024-07-14 06:14:48,812 [INFO    ] __main__: train step 11324: loss: 1.0960, policy_loss: 1.1019, value_loss: 0.6837
2024-07-14 06:14:49,097 [INFO    ] __main__: train step 11325: loss: 1.0960, policy_loss: 1.1019, value_loss: 0.6836
2024-07-14 06:14:49,396 [INFO    ] __main__: train step 11326: loss: 1.0960, policy_loss: 1.1019, value_loss: 0.6836
2024-07-14 06:14:49,692 [INFO    ] __main__: train step 11327: loss: 1.0960, policy_loss: 1.1018, value_loss: 0.6836
2024-07-14 06:14:49,993 [INFO    ] __main__: train step 11328: loss: 1.0960, policy_loss: 1.1018, value_loss: 0.6835
2024-07-14 06:14:50,301 [INFO    ] __main__: train step 11329: loss: 1.0960, policy_loss: 1.1018, value_loss: 0.6835
2024-07-14 06:14:50,600 [INFO    ] __main__: train step 11330: loss: 1.0960, policy_loss: 1.1018, value_loss: 0.6835
2024-07-14 06:14:50,898 [INFO    ] __main__: train step 11331: loss: 1.0960, policy_loss: 1.1017, value_loss: 0.6834
2024-07-14 06:14:51,189 [INFO    ] __main__: train step 11332: loss: 1.0960, policy_loss: 1.1017, value_loss: 0.6834
2024-07-14 06:14:51,482 [INFO    ] __main__: train step 11333: loss: 1.0960, policy_loss: 1.1017, value_loss: 0.6833
2024-07-14 06:14:51,782 [INFO    ] __main__: train step 11334: loss: 1.0960, policy_loss: 1.1017, value_loss: 0.6833
2024-07-14 06:14:52,080 [INFO    ] __main__: train step 11335: loss: 1.0960, policy_loss: 1.1017, value_loss: 0.6833
2024-07-14 06:14:53,703 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:14:54,192 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:14:54,267 [INFO    ] __main__: train step 11336: loss: 1.0960, policy_loss: 1.1016, value_loss: 0.6832
2024-07-14 06:14:54,564 [INFO    ] __main__: train step 11337: loss: 1.0960, policy_loss: 1.1016, value_loss: 0.6832
2024-07-14 06:14:54,859 [INFO    ] __main__: train step 11338: loss: 1.0960, policy_loss: 1.1016, value_loss: 0.6832
2024-07-14 06:14:55,143 [INFO    ] __main__: train step 11339: loss: 1.0960, policy_loss: 1.1016, value_loss: 0.6831
2024-07-14 06:14:55,435 [INFO    ] __main__: train step 11340: loss: 1.0960, policy_loss: 1.1015, value_loss: 0.6831
2024-07-14 06:14:55,726 [INFO    ] __main__: train step 11341: loss: 1.0960, policy_loss: 1.1015, value_loss: 0.6830
2024-07-14 06:14:56,021 [INFO    ] __main__: train step 11342: loss: 1.0960, policy_loss: 1.1015, value_loss: 0.6830
2024-07-14 06:14:56,330 [INFO    ] __main__: train step 11343: loss: 1.0960, policy_loss: 1.1015, value_loss: 0.6830
2024-07-14 06:14:56,632 [INFO    ] __main__: train step 11344: loss: 1.0960, policy_loss: 1.1015, value_loss: 0.6829
2024-07-14 06:14:56,905 [INFO    ] __main__: train step 11345: loss: 1.0960, policy_loss: 1.1014, value_loss: 0.6829
2024-07-14 06:14:57,192 [INFO    ] __main__: train step 11346: loss: 1.0960, policy_loss: 1.1014, value_loss: 0.6829
2024-07-14 06:14:57,481 [INFO    ] __main__: train step 11347: loss: 1.0960, policy_loss: 1.1014, value_loss: 0.6828
2024-07-14 06:14:57,770 [INFO    ] __main__: train step 11348: loss: 1.0960, policy_loss: 1.1014, value_loss: 0.6828
2024-07-14 06:14:58,073 [INFO    ] __main__: train step 11349: loss: 1.0960, policy_loss: 1.1013, value_loss: 0.6828
2024-07-14 06:14:58,365 [INFO    ] __main__: train step 11350: loss: 1.0960, policy_loss: 1.1013, value_loss: 0.6827
2024-07-14 06:14:58,653 [INFO    ] __main__: train step 11351: loss: 1.0960, policy_loss: 1.1013, value_loss: 0.6827
2024-07-14 06:14:58,950 [INFO    ] __main__: train step 11352: loss: 1.0960, policy_loss: 1.1013, value_loss: 0.6826
2024-07-14 06:15:00,558 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:15:01,053 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:15:01,130 [INFO    ] __main__: train step 11353: loss: 1.0960, policy_loss: 1.1013, value_loss: 0.6826
2024-07-14 06:15:01,424 [INFO    ] __main__: train step 11354: loss: 1.0960, policy_loss: 1.1012, value_loss: 0.6826
2024-07-14 06:15:01,719 [INFO    ] __main__: train step 11355: loss: 1.0960, policy_loss: 1.1012, value_loss: 0.6825
2024-07-14 06:15:02,006 [INFO    ] __main__: train step 11356: loss: 1.0961, policy_loss: 1.1012, value_loss: 0.6825
2024-07-14 06:15:02,290 [INFO    ] __main__: train step 11357: loss: 1.0961, policy_loss: 1.1012, value_loss: 0.6825
2024-07-14 06:15:02,587 [INFO    ] __main__: train step 11358: loss: 1.0961, policy_loss: 1.1011, value_loss: 0.6824
2024-07-14 06:15:02,868 [INFO    ] __main__: train step 11359: loss: 1.0961, policy_loss: 1.1011, value_loss: 0.6824
2024-07-14 06:15:03,156 [INFO    ] __main__: train step 11360: loss: 1.0961, policy_loss: 1.1011, value_loss: 0.6823
2024-07-14 06:15:03,448 [INFO    ] __main__: train step 11361: loss: 1.0961, policy_loss: 1.1011, value_loss: 0.6823
2024-07-14 06:15:03,732 [INFO    ] __main__: train step 11362: loss: 1.0961, policy_loss: 1.1011, value_loss: 0.6823
2024-07-14 06:15:04,029 [INFO    ] __main__: train step 11363: loss: 1.0961, policy_loss: 1.1010, value_loss: 0.6822
2024-07-14 06:15:04,320 [INFO    ] __main__: train step 11364: loss: 1.0961, policy_loss: 1.1010, value_loss: 0.6822
2024-07-14 06:15:04,613 [INFO    ] __main__: train step 11365: loss: 1.0961, policy_loss: 1.1010, value_loss: 0.6822
2024-07-14 06:15:04,916 [INFO    ] __main__: train step 11366: loss: 1.0961, policy_loss: 1.1010, value_loss: 0.6821
2024-07-14 06:15:05,209 [INFO    ] __main__: train step 11367: loss: 1.0961, policy_loss: 1.1010, value_loss: 0.6821
2024-07-14 06:15:05,499 [INFO    ] __main__: train step 11368: loss: 1.0961, policy_loss: 1.1009, value_loss: 0.6821
2024-07-14 06:15:05,796 [INFO    ] __main__: train step 11369: loss: 1.0961, policy_loss: 1.1009, value_loss: 0.6820
2024-07-14 06:15:07,410 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:15:07,894 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:15:07,966 [INFO    ] __main__: train step 11370: loss: 1.0961, policy_loss: 1.1009, value_loss: 0.6820
2024-07-14 06:15:08,257 [INFO    ] __main__: train step 11371: loss: 1.0961, policy_loss: 1.1009, value_loss: 0.6819
2024-07-14 06:15:08,544 [INFO    ] __main__: train step 11372: loss: 1.0961, policy_loss: 1.1008, value_loss: 0.6819
2024-07-14 06:15:08,840 [INFO    ] __main__: train step 11373: loss: 1.0961, policy_loss: 1.1008, value_loss: 0.6819
2024-07-14 06:15:09,138 [INFO    ] __main__: train step 11374: loss: 1.0961, policy_loss: 1.1008, value_loss: 0.6818
2024-07-14 06:15:09,451 [INFO    ] __main__: train step 11375: loss: 1.0961, policy_loss: 1.1008, value_loss: 0.6818
2024-07-14 06:15:09,745 [INFO    ] __main__: train step 11376: loss: 1.0961, policy_loss: 1.1008, value_loss: 0.6818
2024-07-14 06:15:10,043 [INFO    ] __main__: train step 11377: loss: 1.0961, policy_loss: 1.1007, value_loss: 0.6817
2024-07-14 06:15:10,327 [INFO    ] __main__: train step 11378: loss: 1.0961, policy_loss: 1.1007, value_loss: 0.6817
2024-07-14 06:15:10,629 [INFO    ] __main__: train step 11379: loss: 1.0961, policy_loss: 1.1007, value_loss: 0.6816
2024-07-14 06:15:10,916 [INFO    ] __main__: train step 11380: loss: 1.0961, policy_loss: 1.1007, value_loss: 0.6816
2024-07-14 06:15:11,215 [INFO    ] __main__: train step 11381: loss: 1.0961, policy_loss: 1.1006, value_loss: 0.6816
2024-07-14 06:15:11,499 [INFO    ] __main__: train step 11382: loss: 1.0961, policy_loss: 1.1006, value_loss: 0.6815
2024-07-14 06:15:11,784 [INFO    ] __main__: train step 11383: loss: 1.0961, policy_loss: 1.1006, value_loss: 0.6815
2024-07-14 06:15:12,100 [INFO    ] __main__: train step 11384: loss: 1.0961, policy_loss: 1.1006, value_loss: 0.6815
2024-07-14 06:15:12,391 [INFO    ] __main__: train step 11385: loss: 1.0961, policy_loss: 1.1006, value_loss: 0.6814
2024-07-14 06:15:12,694 [INFO    ] __main__: train step 11386: loss: 1.0961, policy_loss: 1.1005, value_loss: 0.6814
2024-07-14 06:15:14,329 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:15:14,818 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:15:14,889 [INFO    ] __main__: train step 11387: loss: 1.0961, policy_loss: 1.1005, value_loss: 0.6814
2024-07-14 06:15:15,186 [INFO    ] __main__: train step 11388: loss: 1.0961, policy_loss: 1.1005, value_loss: 0.6813
2024-07-14 06:15:15,481 [INFO    ] __main__: train step 11389: loss: 1.0961, policy_loss: 1.1005, value_loss: 0.6813
2024-07-14 06:15:15,784 [INFO    ] __main__: train step 11390: loss: 1.0961, policy_loss: 1.1005, value_loss: 0.6812
2024-07-14 06:15:16,083 [INFO    ] __main__: train step 11391: loss: 1.0961, policy_loss: 1.1004, value_loss: 0.6812
2024-07-14 06:15:16,380 [INFO    ] __main__: train step 11392: loss: 1.0961, policy_loss: 1.1004, value_loss: 0.6812
2024-07-14 06:15:16,659 [INFO    ] __main__: train step 11393: loss: 1.0961, policy_loss: 1.1004, value_loss: 0.6811
2024-07-14 06:15:16,952 [INFO    ] __main__: train step 11394: loss: 1.0961, policy_loss: 1.1004, value_loss: 0.6811
2024-07-14 06:15:17,228 [INFO    ] __main__: train step 11395: loss: 1.0961, policy_loss: 1.1003, value_loss: 0.6811
2024-07-14 06:15:17,522 [INFO    ] __main__: train step 11396: loss: 1.0961, policy_loss: 1.1003, value_loss: 0.6810
2024-07-14 06:15:17,808 [INFO    ] __main__: train step 11397: loss: 1.0961, policy_loss: 1.1003, value_loss: 0.6810
2024-07-14 06:15:18,098 [INFO    ] __main__: train step 11398: loss: 1.0961, policy_loss: 1.1003, value_loss: 0.6809
2024-07-14 06:15:18,385 [INFO    ] __main__: train step 11399: loss: 1.0961, policy_loss: 1.1003, value_loss: 0.6809
2024-07-14 06:15:18,674 [INFO    ] __main__: train step 11400: loss: 1.0961, policy_loss: 1.1002, value_loss: 0.6809
2024-07-14 06:15:18,970 [INFO    ] __main__: train step 11401: loss: 1.0961, policy_loss: 1.1002, value_loss: 0.6808
2024-07-14 06:15:19,264 [INFO    ] __main__: train step 11402: loss: 1.0961, policy_loss: 1.1002, value_loss: 0.6808
2024-07-14 06:15:19,558 [INFO    ] __main__: train step 11403: loss: 1.0961, policy_loss: 1.1002, value_loss: 0.6808
2024-07-14 06:15:23,864 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:15:24,354 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:15:24,425 [INFO    ] __main__: train step 11404: loss: 1.0961, policy_loss: 1.1002, value_loss: 0.6807
2024-07-14 06:15:24,721 [INFO    ] __main__: train step 11405: loss: 1.0961, policy_loss: 1.1001, value_loss: 0.6807
2024-07-14 06:15:25,002 [INFO    ] __main__: train step 11406: loss: 1.0961, policy_loss: 1.1001, value_loss: 0.6806
2024-07-14 06:15:25,304 [INFO    ] __main__: train step 11407: loss: 1.0961, policy_loss: 1.1001, value_loss: 0.6806
2024-07-14 06:15:25,617 [INFO    ] __main__: train step 11408: loss: 1.0961, policy_loss: 1.1001, value_loss: 0.6806
2024-07-14 06:15:25,912 [INFO    ] __main__: train step 11409: loss: 1.0961, policy_loss: 1.1000, value_loss: 0.6805
2024-07-14 06:15:26,204 [INFO    ] __main__: train step 11410: loss: 1.0961, policy_loss: 1.1000, value_loss: 0.6805
2024-07-14 06:15:26,496 [INFO    ] __main__: train step 11411: loss: 1.0961, policy_loss: 1.1000, value_loss: 0.6805
2024-07-14 06:15:26,788 [INFO    ] __main__: train step 11412: loss: 1.0962, policy_loss: 1.1000, value_loss: 0.6804
2024-07-14 06:15:27,082 [INFO    ] __main__: train step 11413: loss: 1.0962, policy_loss: 1.1000, value_loss: 0.6804
2024-07-14 06:15:27,373 [INFO    ] __main__: train step 11414: loss: 1.0962, policy_loss: 1.0999, value_loss: 0.6804
2024-07-14 06:15:27,682 [INFO    ] __main__: train step 11415: loss: 1.0962, policy_loss: 1.0999, value_loss: 0.6803
2024-07-14 06:15:27,967 [INFO    ] __main__: train step 11416: loss: 1.0962, policy_loss: 1.0999, value_loss: 0.6803
2024-07-14 06:15:28,259 [INFO    ] __main__: train step 11417: loss: 1.0962, policy_loss: 1.0999, value_loss: 0.6802
2024-07-14 06:15:28,557 [INFO    ] __main__: train step 11418: loss: 1.0962, policy_loss: 1.0999, value_loss: 0.6802
2024-07-14 06:15:28,839 [INFO    ] __main__: train step 11419: loss: 1.0962, policy_loss: 1.0998, value_loss: 0.6802
2024-07-14 06:15:29,131 [INFO    ] __main__: train step 11420: loss: 1.0962, policy_loss: 1.0998, value_loss: 0.6801
2024-07-14 06:15:30,749 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:15:31,198 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:15:31,266 [INFO    ] __main__: train step 11421: loss: 1.0962, policy_loss: 1.0998, value_loss: 0.6801
2024-07-14 06:15:31,555 [INFO    ] __main__: train step 11422: loss: 1.0962, policy_loss: 1.0998, value_loss: 0.6801
2024-07-14 06:15:31,845 [INFO    ] __main__: train step 11423: loss: 1.0962, policy_loss: 1.0997, value_loss: 0.6800
2024-07-14 06:15:32,129 [INFO    ] __main__: train step 11424: loss: 1.0962, policy_loss: 1.0997, value_loss: 0.6800
2024-07-14 06:15:32,421 [INFO    ] __main__: train step 11425: loss: 1.0962, policy_loss: 1.0997, value_loss: 0.6800
2024-07-14 06:15:32,719 [INFO    ] __main__: train step 11426: loss: 1.0962, policy_loss: 1.0997, value_loss: 0.6799
2024-07-14 06:15:33,007 [INFO    ] __main__: train step 11427: loss: 1.0962, policy_loss: 1.0997, value_loss: 0.6799
2024-07-14 06:15:33,310 [INFO    ] __main__: train step 11428: loss: 1.0962, policy_loss: 1.0996, value_loss: 0.6799
2024-07-14 06:15:33,628 [INFO    ] __main__: train step 11429: loss: 1.0962, policy_loss: 1.0996, value_loss: 0.6798
2024-07-14 06:15:33,929 [INFO    ] __main__: train step 11430: loss: 1.0962, policy_loss: 1.0996, value_loss: 0.6798
2024-07-14 06:15:34,225 [INFO    ] __main__: train step 11431: loss: 1.0962, policy_loss: 1.0996, value_loss: 0.6797
2024-07-14 06:15:34,536 [INFO    ] __main__: train step 11432: loss: 1.0962, policy_loss: 1.0996, value_loss: 0.6797
2024-07-14 06:15:34,825 [INFO    ] __main__: train step 11433: loss: 1.0962, policy_loss: 1.0995, value_loss: 0.6797
2024-07-14 06:15:35,114 [INFO    ] __main__: train step 11434: loss: 1.0962, policy_loss: 1.0995, value_loss: 0.6796
2024-07-14 06:15:35,387 [INFO    ] __main__: train step 11435: loss: 1.0962, policy_loss: 1.0995, value_loss: 0.6796
2024-07-14 06:15:35,665 [INFO    ] __main__: train step 11436: loss: 1.0962, policy_loss: 1.0995, value_loss: 0.6796
2024-07-14 06:15:35,959 [INFO    ] __main__: train step 11437: loss: 1.0962, policy_loss: 1.0995, value_loss: 0.6795
2024-07-14 06:15:37,555 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:15:38,048 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:15:38,124 [INFO    ] __main__: train step 11438: loss: 1.0962, policy_loss: 1.0994, value_loss: 0.6795
2024-07-14 06:15:38,413 [INFO    ] __main__: train step 11439: loss: 1.0962, policy_loss: 1.0994, value_loss: 0.6795
2024-07-14 06:15:38,710 [INFO    ] __main__: train step 11440: loss: 1.0962, policy_loss: 1.0994, value_loss: 0.6794
2024-07-14 06:15:39,001 [INFO    ] __main__: train step 11441: loss: 1.0962, policy_loss: 1.0994, value_loss: 0.6794
2024-07-14 06:15:39,298 [INFO    ] __main__: train step 11442: loss: 1.0962, policy_loss: 1.0993, value_loss: 0.6793
2024-07-14 06:15:39,591 [INFO    ] __main__: train step 11443: loss: 1.0962, policy_loss: 1.0993, value_loss: 0.6793
2024-07-14 06:15:39,877 [INFO    ] __main__: train step 11444: loss: 1.0962, policy_loss: 1.0993, value_loss: 0.6793
2024-07-14 06:15:40,143 [INFO    ] __main__: train step 11445: loss: 1.0962, policy_loss: 1.0993, value_loss: 0.6792
2024-07-14 06:15:40,409 [INFO    ] __main__: train step 11446: loss: 1.0962, policy_loss: 1.0993, value_loss: 0.6792
2024-07-14 06:15:40,678 [INFO    ] __main__: train step 11447: loss: 1.0962, policy_loss: 1.0992, value_loss: 0.6792
2024-07-14 06:15:40,953 [INFO    ] __main__: train step 11448: loss: 1.0962, policy_loss: 1.0992, value_loss: 0.6791
2024-07-14 06:15:41,239 [INFO    ] __main__: train step 11449: loss: 1.0962, policy_loss: 1.0992, value_loss: 0.6791
2024-07-14 06:15:41,530 [INFO    ] __main__: train step 11450: loss: 1.0962, policy_loss: 1.0992, value_loss: 0.6791
2024-07-14 06:15:41,807 [INFO    ] __main__: train step 11451: loss: 1.0962, policy_loss: 1.0992, value_loss: 0.6790
2024-07-14 06:15:42,109 [INFO    ] __main__: train step 11452: loss: 1.0962, policy_loss: 1.0991, value_loss: 0.6790
2024-07-14 06:15:42,405 [INFO    ] __main__: train step 11453: loss: 1.0963, policy_loss: 1.0991, value_loss: 0.6789
2024-07-14 06:15:42,700 [INFO    ] __main__: train step 11454: loss: 1.0963, policy_loss: 1.0991, value_loss: 0.6789
2024-07-14 06:15:44,309 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:15:44,797 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:15:44,866 [INFO    ] __main__: train step 11455: loss: 1.0963, policy_loss: 1.0991, value_loss: 0.6789
2024-07-14 06:15:45,160 [INFO    ] __main__: train step 11456: loss: 1.0963, policy_loss: 1.0991, value_loss: 0.6788
2024-07-14 06:15:45,441 [INFO    ] __main__: train step 11457: loss: 1.0963, policy_loss: 1.0990, value_loss: 0.6788
2024-07-14 06:15:45,726 [INFO    ] __main__: train step 11458: loss: 1.0963, policy_loss: 1.0990, value_loss: 0.6788
2024-07-14 06:15:46,014 [INFO    ] __main__: train step 11459: loss: 1.0963, policy_loss: 1.0990, value_loss: 0.6787
2024-07-14 06:15:46,308 [INFO    ] __main__: train step 11460: loss: 1.0963, policy_loss: 1.0990, value_loss: 0.6787
2024-07-14 06:15:46,601 [INFO    ] __main__: train step 11461: loss: 1.0963, policy_loss: 1.0989, value_loss: 0.6787
2024-07-14 06:15:46,900 [INFO    ] __main__: train step 11462: loss: 1.0963, policy_loss: 1.0989, value_loss: 0.6786
2024-07-14 06:15:47,190 [INFO    ] __main__: train step 11463: loss: 1.0963, policy_loss: 1.0989, value_loss: 0.6786
2024-07-14 06:15:47,499 [INFO    ] __main__: train step 11464: loss: 1.0963, policy_loss: 1.0989, value_loss: 0.6785
2024-07-14 06:15:47,795 [INFO    ] __main__: train step 11465: loss: 1.0963, policy_loss: 1.0989, value_loss: 0.6785
2024-07-14 06:15:48,081 [INFO    ] __main__: train step 11466: loss: 1.0963, policy_loss: 1.0988, value_loss: 0.6785
2024-07-14 06:15:48,373 [INFO    ] __main__: train step 11467: loss: 1.0963, policy_loss: 1.0988, value_loss: 0.6784
2024-07-14 06:15:48,669 [INFO    ] __main__: train step 11468: loss: 1.0963, policy_loss: 1.0988, value_loss: 0.6784
2024-07-14 06:15:48,968 [INFO    ] __main__: train step 11469: loss: 1.0963, policy_loss: 1.0988, value_loss: 0.6784
2024-07-14 06:15:49,252 [INFO    ] __main__: train step 11470: loss: 1.0963, policy_loss: 1.0988, value_loss: 0.6783
2024-07-14 06:15:49,547 [INFO    ] __main__: train step 11471: loss: 1.0963, policy_loss: 1.0987, value_loss: 0.6783
2024-07-14 06:15:51,165 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:15:51,661 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:15:51,732 [INFO    ] __main__: train step 11472: loss: 1.0963, policy_loss: 1.0987, value_loss: 0.6783
2024-07-14 06:15:52,026 [INFO    ] __main__: train step 11473: loss: 1.0963, policy_loss: 1.0987, value_loss: 0.6782
2024-07-14 06:15:52,314 [INFO    ] __main__: train step 11474: loss: 1.0963, policy_loss: 1.0987, value_loss: 0.6782
2024-07-14 06:15:52,613 [INFO    ] __main__: train step 11475: loss: 1.0963, policy_loss: 1.0987, value_loss: 0.6781
2024-07-14 06:15:52,905 [INFO    ] __main__: train step 11476: loss: 1.0963, policy_loss: 1.0986, value_loss: 0.6781
2024-07-14 06:15:53,199 [INFO    ] __main__: train step 11477: loss: 1.0963, policy_loss: 1.0986, value_loss: 0.6781
2024-07-14 06:15:53,505 [INFO    ] __main__: train step 11478: loss: 1.0963, policy_loss: 1.0986, value_loss: 0.6780
2024-07-14 06:15:53,803 [INFO    ] __main__: train step 11479: loss: 1.0963, policy_loss: 1.0986, value_loss: 0.6780
2024-07-14 06:15:54,087 [INFO    ] __main__: train step 11480: loss: 1.0963, policy_loss: 1.0986, value_loss: 0.6780
2024-07-14 06:15:54,384 [INFO    ] __main__: train step 11481: loss: 1.0963, policy_loss: 1.0985, value_loss: 0.6779
2024-07-14 06:15:54,666 [INFO    ] __main__: train step 11482: loss: 1.0963, policy_loss: 1.0985, value_loss: 0.6779
2024-07-14 06:15:54,959 [INFO    ] __main__: train step 11483: loss: 1.0963, policy_loss: 1.0985, value_loss: 0.6779
2024-07-14 06:15:55,257 [INFO    ] __main__: train step 11484: loss: 1.0963, policy_loss: 1.0985, value_loss: 0.6778
2024-07-14 06:15:55,540 [INFO    ] __main__: train step 11485: loss: 1.0963, policy_loss: 1.0985, value_loss: 0.6778
2024-07-14 06:15:55,831 [INFO    ] __main__: train step 11486: loss: 1.0963, policy_loss: 1.0984, value_loss: 0.6777
2024-07-14 06:15:56,112 [INFO    ] __main__: train step 11487: loss: 1.0963, policy_loss: 1.0984, value_loss: 0.6777
2024-07-14 06:15:56,400 [INFO    ] __main__: train step 11488: loss: 1.0963, policy_loss: 1.0984, value_loss: 0.6777
2024-07-14 06:15:58,001 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:15:58,475 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:15:58,550 [INFO    ] __main__: train step 11489: loss: 1.0963, policy_loss: 1.0984, value_loss: 0.6776
2024-07-14 06:15:58,847 [INFO    ] __main__: train step 11490: loss: 1.0963, policy_loss: 1.0983, value_loss: 0.6776
2024-07-14 06:15:59,146 [INFO    ] __main__: train step 11491: loss: 1.0963, policy_loss: 1.0983, value_loss: 0.6776
2024-07-14 06:16:02,138 [INFO    ] __main__: train step 11492: loss: 1.0963, policy_loss: 1.0983, value_loss: 0.6775
2024-07-14 06:16:02,430 [INFO    ] __main__: train step 11493: loss: 1.0963, policy_loss: 1.0983, value_loss: 0.6775
2024-07-14 06:16:02,726 [INFO    ] __main__: train step 11494: loss: 1.0963, policy_loss: 1.0983, value_loss: 0.6775
2024-07-14 06:16:03,023 [INFO    ] __main__: train step 11495: loss: 1.0963, policy_loss: 1.0982, value_loss: 0.6774
2024-07-14 06:16:03,322 [INFO    ] __main__: train step 11496: loss: 1.0963, policy_loss: 1.0982, value_loss: 0.6774
2024-07-14 06:16:03,623 [INFO    ] __main__: train step 11497: loss: 1.0963, policy_loss: 1.0982, value_loss: 0.6773
2024-07-14 06:16:03,931 [INFO    ] __main__: train step 11498: loss: 1.0964, policy_loss: 1.0982, value_loss: 0.6773
2024-07-14 06:16:04,236 [INFO    ] __main__: train step 11499: loss: 1.0964, policy_loss: 1.0982, value_loss: 0.6773
2024-07-14 06:16:04,538 [INFO    ] __main__: train step 11500: loss: 1.0964, policy_loss: 1.0981, value_loss: 0.6772
2024-07-14 06:16:04,835 [INFO    ] __main__: train step 11501: loss: 1.0964, policy_loss: 1.0981, value_loss: 0.6772
2024-07-14 06:16:05,134 [INFO    ] __main__: train step 11502: loss: 1.0964, policy_loss: 1.0981, value_loss: 0.6772
2024-07-14 06:16:05,432 [INFO    ] __main__: train step 11503: loss: 1.0964, policy_loss: 1.0981, value_loss: 0.6771
2024-07-14 06:16:05,719 [INFO    ] __main__: train step 11504: loss: 1.0964, policy_loss: 1.0981, value_loss: 0.6771
2024-07-14 06:16:06,021 [INFO    ] __main__: train step 11505: loss: 1.0964, policy_loss: 1.0980, value_loss: 0.6771
2024-07-14 06:16:07,638 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:16:08,131 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:16:08,200 [INFO    ] __main__: train step 11506: loss: 1.0964, policy_loss: 1.0980, value_loss: 0.6770
2024-07-14 06:16:08,493 [INFO    ] __main__: train step 11507: loss: 1.0964, policy_loss: 1.0980, value_loss: 0.6770
2024-07-14 06:16:08,770 [INFO    ] __main__: train step 11508: loss: 1.0964, policy_loss: 1.0980, value_loss: 0.6769
2024-07-14 06:16:09,063 [INFO    ] __main__: train step 11509: loss: 1.0964, policy_loss: 1.0980, value_loss: 0.6769
2024-07-14 06:16:09,339 [INFO    ] __main__: train step 11510: loss: 1.0964, policy_loss: 1.0979, value_loss: 0.6769
2024-07-14 06:16:09,624 [INFO    ] __main__: train step 11511: loss: 1.0964, policy_loss: 1.0979, value_loss: 0.6768
2024-07-14 06:16:09,915 [INFO    ] __main__: train step 11512: loss: 1.0964, policy_loss: 1.0979, value_loss: 0.6768
2024-07-14 06:16:10,207 [INFO    ] __main__: train step 11513: loss: 1.0964, policy_loss: 1.0979, value_loss: 0.6768
2024-07-14 06:16:10,479 [INFO    ] __main__: train step 11514: loss: 1.0964, policy_loss: 1.0978, value_loss: 0.6767
2024-07-14 06:16:10,791 [INFO    ] __main__: train step 11515: loss: 1.0964, policy_loss: 1.0978, value_loss: 0.6767
2024-07-14 06:16:11,077 [INFO    ] __main__: train step 11516: loss: 1.0964, policy_loss: 1.0978, value_loss: 0.6767
2024-07-14 06:16:11,348 [INFO    ] __main__: train step 11517: loss: 1.0964, policy_loss: 1.0978, value_loss: 0.6766
2024-07-14 06:16:11,620 [INFO    ] __main__: train step 11518: loss: 1.0964, policy_loss: 1.0978, value_loss: 0.6766
2024-07-14 06:16:11,901 [INFO    ] __main__: train step 11519: loss: 1.0964, policy_loss: 1.0977, value_loss: 0.6765
2024-07-14 06:16:12,191 [INFO    ] __main__: train step 11520: loss: 1.0964, policy_loss: 1.0977, value_loss: 0.6765
2024-07-14 06:16:12,486 [INFO    ] __main__: train step 11521: loss: 1.0964, policy_loss: 1.0977, value_loss: 0.6765
2024-07-14 06:16:12,784 [INFO    ] __main__: train step 11522: loss: 1.0964, policy_loss: 1.0977, value_loss: 0.6764
2024-07-14 06:16:14,409 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:16:14,897 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:16:14,969 [INFO    ] __main__: train step 11523: loss: 1.0964, policy_loss: 1.0977, value_loss: 0.6764
2024-07-14 06:16:15,262 [INFO    ] __main__: train step 11524: loss: 1.0964, policy_loss: 1.0976, value_loss: 0.6764
2024-07-14 06:16:15,537 [INFO    ] __main__: train step 11525: loss: 1.0964, policy_loss: 1.0976, value_loss: 0.6763
2024-07-14 06:16:15,825 [INFO    ] __main__: train step 11526: loss: 1.0964, policy_loss: 1.0976, value_loss: 0.6763
2024-07-14 06:16:16,117 [INFO    ] __main__: train step 11527: loss: 1.0964, policy_loss: 1.0976, value_loss: 0.6763
2024-07-14 06:16:16,413 [INFO    ] __main__: train step 11528: loss: 1.0964, policy_loss: 1.0976, value_loss: 0.6762
2024-07-14 06:16:16,704 [INFO    ] __main__: train step 11529: loss: 1.0964, policy_loss: 1.0975, value_loss: 0.6762
2024-07-14 06:16:16,987 [INFO    ] __main__: train step 11530: loss: 1.0964, policy_loss: 1.0975, value_loss: 0.6761
2024-07-14 06:16:17,287 [INFO    ] __main__: train step 11531: loss: 1.0964, policy_loss: 1.0975, value_loss: 0.6761
2024-07-14 06:16:17,588 [INFO    ] __main__: train step 11532: loss: 1.0964, policy_loss: 1.0975, value_loss: 0.6761
2024-07-14 06:16:17,892 [INFO    ] __main__: train step 11533: loss: 1.0964, policy_loss: 1.0975, value_loss: 0.6760
2024-07-14 06:16:18,186 [INFO    ] __main__: train step 11534: loss: 1.0964, policy_loss: 1.0974, value_loss: 0.6760
2024-07-14 06:16:18,486 [INFO    ] __main__: train step 11535: loss: 1.0964, policy_loss: 1.0974, value_loss: 0.6760
2024-07-14 06:16:18,783 [INFO    ] __main__: train step 11536: loss: 1.0964, policy_loss: 1.0974, value_loss: 0.6759
2024-07-14 06:16:19,083 [INFO    ] __main__: train step 11537: loss: 1.0964, policy_loss: 1.0974, value_loss: 0.6759
2024-07-14 06:16:19,386 [INFO    ] __main__: train step 11538: loss: 1.0964, policy_loss: 1.0973, value_loss: 0.6759
2024-07-14 06:16:19,672 [INFO    ] __main__: train step 11539: loss: 1.0964, policy_loss: 1.0973, value_loss: 0.6758
2024-07-14 06:16:21,300 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:16:21,788 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:16:21,857 [INFO    ] __main__: train step 11540: loss: 1.0964, policy_loss: 1.0973, value_loss: 0.6758
2024-07-14 06:16:22,154 [INFO    ] __main__: train step 11541: loss: 1.0964, policy_loss: 1.0973, value_loss: 0.6758
2024-07-14 06:16:22,449 [INFO    ] __main__: train step 11542: loss: 1.0964, policy_loss: 1.0973, value_loss: 0.6757
2024-07-14 06:16:22,748 [INFO    ] __main__: train step 11543: loss: 1.0964, policy_loss: 1.0972, value_loss: 0.6757
2024-07-14 06:16:23,047 [INFO    ] __main__: train step 11544: loss: 1.0964, policy_loss: 1.0972, value_loss: 0.6756
2024-07-14 06:16:23,344 [INFO    ] __main__: train step 11545: loss: 1.0964, policy_loss: 1.0972, value_loss: 0.6756
2024-07-14 06:16:23,636 [INFO    ] __main__: train step 11546: loss: 1.0964, policy_loss: 1.0972, value_loss: 0.6756
2024-07-14 06:16:23,940 [INFO    ] __main__: train step 11547: loss: 1.0964, policy_loss: 1.0972, value_loss: 0.6755
2024-07-14 06:16:24,252 [INFO    ] __main__: train step 11548: loss: 1.0964, policy_loss: 1.0971, value_loss: 0.6755
2024-07-14 06:16:24,554 [INFO    ] __main__: train step 11549: loss: 1.0964, policy_loss: 1.0971, value_loss: 0.6755
2024-07-14 06:16:24,860 [INFO    ] __main__: train step 11550: loss: 1.0964, policy_loss: 1.0971, value_loss: 0.6754
2024-07-14 06:16:25,161 [INFO    ] __main__: train step 11551: loss: 1.0964, policy_loss: 1.0971, value_loss: 0.6754
2024-07-14 06:16:25,450 [INFO    ] __main__: train step 11552: loss: 1.0965, policy_loss: 1.0971, value_loss: 0.6754
2024-07-14 06:16:25,761 [INFO    ] __main__: train step 11553: loss: 1.0965, policy_loss: 1.0971, value_loss: 0.6753
2024-07-14 06:16:26,063 [INFO    ] __main__: train step 11554: loss: 1.0965, policy_loss: 1.0970, value_loss: 0.6753
2024-07-14 06:16:26,352 [INFO    ] __main__: train step 11555: loss: 1.0965, policy_loss: 1.0970, value_loss: 0.6752
2024-07-14 06:16:26,632 [INFO    ] __main__: train step 11556: loss: 1.0965, policy_loss: 1.0970, value_loss: 0.6752
2024-07-14 06:16:28,265 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:16:28,770 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:16:28,842 [INFO    ] __main__: train step 11557: loss: 1.0965, policy_loss: 1.0970, value_loss: 0.6752
2024-07-14 06:16:29,146 [INFO    ] __main__: train step 11558: loss: 1.0965, policy_loss: 1.0969, value_loss: 0.6751
2024-07-14 06:16:29,432 [INFO    ] __main__: train step 11559: loss: 1.0965, policy_loss: 1.0969, value_loss: 0.6751
2024-07-14 06:16:29,730 [INFO    ] __main__: train step 11560: loss: 1.0965, policy_loss: 1.0969, value_loss: 0.6751
2024-07-14 06:16:30,031 [INFO    ] __main__: train step 11561: loss: 1.0965, policy_loss: 1.0969, value_loss: 0.6750
2024-07-14 06:16:30,331 [INFO    ] __main__: train step 11562: loss: 1.0965, policy_loss: 1.0969, value_loss: 0.6750
2024-07-14 06:16:30,629 [INFO    ] __main__: train step 11563: loss: 1.0965, policy_loss: 1.0968, value_loss: 0.6750
2024-07-14 06:16:30,929 [INFO    ] __main__: train step 11564: loss: 1.0965, policy_loss: 1.0968, value_loss: 0.6749
2024-07-14 06:16:31,223 [INFO    ] __main__: train step 11565: loss: 1.0965, policy_loss: 1.0968, value_loss: 0.6749
2024-07-14 06:16:31,504 [INFO    ] __main__: train step 11566: loss: 1.0965, policy_loss: 1.0968, value_loss: 0.6748
2024-07-14 06:16:31,796 [INFO    ] __main__: train step 11567: loss: 1.0965, policy_loss: 1.0968, value_loss: 0.6748
2024-07-14 06:16:32,095 [INFO    ] __main__: train step 11568: loss: 1.0965, policy_loss: 1.0967, value_loss: 0.6748
2024-07-14 06:16:32,387 [INFO    ] __main__: train step 11569: loss: 1.0965, policy_loss: 1.0967, value_loss: 0.6747
2024-07-14 06:16:32,689 [INFO    ] __main__: train step 11570: loss: 1.0965, policy_loss: 1.0967, value_loss: 0.6747
2024-07-14 06:16:32,986 [INFO    ] __main__: train step 11571: loss: 1.0965, policy_loss: 1.0967, value_loss: 0.6747
2024-07-14 06:16:33,277 [INFO    ] __main__: train step 11572: loss: 1.0965, policy_loss: 1.0967, value_loss: 0.6746
2024-07-14 06:16:33,555 [INFO    ] __main__: train step 11573: loss: 1.0965, policy_loss: 1.0966, value_loss: 0.6746
2024-07-14 06:16:35,175 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:16:35,649 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:16:35,719 [INFO    ] __main__: train step 11574: loss: 1.0965, policy_loss: 1.0966, value_loss: 0.6746
2024-07-14 06:16:36,018 [INFO    ] __main__: train step 11575: loss: 1.0965, policy_loss: 1.0966, value_loss: 0.6745
2024-07-14 06:16:36,315 [INFO    ] __main__: train step 11576: loss: 1.0965, policy_loss: 1.0966, value_loss: 0.6745
2024-07-14 06:16:36,605 [INFO    ] __main__: train step 11577: loss: 1.0965, policy_loss: 1.0966, value_loss: 0.6745
2024-07-14 06:16:36,899 [INFO    ] __main__: train step 11578: loss: 1.0965, policy_loss: 1.0965, value_loss: 0.6744
2024-07-14 06:16:37,221 [INFO    ] __main__: train step 11579: loss: 1.0965, policy_loss: 1.0965, value_loss: 0.6744
2024-07-14 06:16:40,130 [INFO    ] __main__: train step 11580: loss: 1.0965, policy_loss: 1.0965, value_loss: 0.6743
2024-07-14 06:16:40,421 [INFO    ] __main__: train step 11581: loss: 1.0965, policy_loss: 1.0965, value_loss: 0.6743
2024-07-14 06:16:40,702 [INFO    ] __main__: train step 11582: loss: 1.0965, policy_loss: 1.0965, value_loss: 0.6743
2024-07-14 06:16:41,029 [INFO    ] __main__: train step 11583: loss: 1.0965, policy_loss: 1.0964, value_loss: 0.6742
2024-07-14 06:16:41,320 [INFO    ] __main__: train step 11584: loss: 1.0965, policy_loss: 1.0964, value_loss: 0.6742
2024-07-14 06:16:41,612 [INFO    ] __main__: train step 11585: loss: 1.0965, policy_loss: 1.0964, value_loss: 0.6742
2024-07-14 06:16:41,899 [INFO    ] __main__: train step 11586: loss: 1.0965, policy_loss: 1.0964, value_loss: 0.6741
2024-07-14 06:16:42,191 [INFO    ] __main__: train step 11587: loss: 1.0965, policy_loss: 1.0964, value_loss: 0.6741
2024-07-14 06:16:42,471 [INFO    ] __main__: train step 11588: loss: 1.0965, policy_loss: 1.0963, value_loss: 0.6741
2024-07-14 06:16:42,771 [INFO    ] __main__: train step 11589: loss: 1.0965, policy_loss: 1.0963, value_loss: 0.6740
2024-07-14 06:16:43,080 [INFO    ] __main__: train step 11590: loss: 1.0965, policy_loss: 1.0963, value_loss: 0.6740
2024-07-14 06:16:44,704 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:16:45,199 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:16:45,272 [INFO    ] __main__: train step 11591: loss: 1.0965, policy_loss: 1.0963, value_loss: 0.6739
2024-07-14 06:16:45,579 [INFO    ] __main__: train step 11592: loss: 1.0965, policy_loss: 1.0963, value_loss: 0.6739
2024-07-14 06:16:45,871 [INFO    ] __main__: train step 11593: loss: 1.0965, policy_loss: 1.0962, value_loss: 0.6739
2024-07-14 06:16:46,160 [INFO    ] __main__: train step 11594: loss: 1.0965, policy_loss: 1.0962, value_loss: 0.6738
2024-07-14 06:16:46,444 [INFO    ] __main__: train step 11595: loss: 1.0965, policy_loss: 1.0962, value_loss: 0.6738
2024-07-14 06:16:46,738 [INFO    ] __main__: train step 11596: loss: 1.0965, policy_loss: 1.0962, value_loss: 0.6738
2024-07-14 06:16:47,024 [INFO    ] __main__: train step 11597: loss: 1.0965, policy_loss: 1.0962, value_loss: 0.6737
2024-07-14 06:16:47,324 [INFO    ] __main__: train step 11598: loss: 1.0965, policy_loss: 1.0961, value_loss: 0.6737
2024-07-14 06:16:47,626 [INFO    ] __main__: train step 11599: loss: 1.0966, policy_loss: 1.0961, value_loss: 0.6737
2024-07-14 06:16:47,930 [INFO    ] __main__: train step 11600: loss: 1.0966, policy_loss: 1.0961, value_loss: 0.6736
2024-07-14 06:16:48,228 [INFO    ] __main__: train step 11601: loss: 1.0966, policy_loss: 1.0961, value_loss: 0.6736
2024-07-14 06:16:48,510 [INFO    ] __main__: train step 11602: loss: 1.0966, policy_loss: 1.0961, value_loss: 0.6736
2024-07-14 06:16:48,817 [INFO    ] __main__: train step 11603: loss: 1.0966, policy_loss: 1.0960, value_loss: 0.6735
2024-07-14 06:16:49,108 [INFO    ] __main__: train step 11604: loss: 1.0966, policy_loss: 1.0960, value_loss: 0.6735
2024-07-14 06:16:49,400 [INFO    ] __main__: train step 11605: loss: 1.0966, policy_loss: 1.0960, value_loss: 0.6735
2024-07-14 06:16:49,687 [INFO    ] __main__: train step 11606: loss: 1.0966, policy_loss: 1.0960, value_loss: 0.6734
2024-07-14 06:16:49,980 [INFO    ] __main__: train step 11607: loss: 1.0966, policy_loss: 1.0960, value_loss: 0.6734
2024-07-14 06:16:51,604 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:16:52,103 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:16:52,174 [INFO    ] __main__: train step 11608: loss: 1.0966, policy_loss: 1.0959, value_loss: 0.6733
2024-07-14 06:16:52,485 [INFO    ] __main__: train step 11609: loss: 1.0966, policy_loss: 1.0959, value_loss: 0.6733
2024-07-14 06:16:52,782 [INFO    ] __main__: train step 11610: loss: 1.0966, policy_loss: 1.0959, value_loss: 0.6733
2024-07-14 06:16:53,061 [INFO    ] __main__: train step 11611: loss: 1.0966, policy_loss: 1.0959, value_loss: 0.6732
2024-07-14 06:16:53,350 [INFO    ] __main__: train step 11612: loss: 1.0966, policy_loss: 1.0959, value_loss: 0.6732
2024-07-14 06:16:53,642 [INFO    ] __main__: train step 11613: loss: 1.0966, policy_loss: 1.0958, value_loss: 0.6732
2024-07-14 06:16:53,940 [INFO    ] __main__: train step 11614: loss: 1.0966, policy_loss: 1.0958, value_loss: 0.6731
2024-07-14 06:16:54,222 [INFO    ] __main__: train step 11615: loss: 1.0966, policy_loss: 1.0958, value_loss: 0.6731
2024-07-14 06:16:54,503 [INFO    ] __main__: train step 11616: loss: 1.0966, policy_loss: 1.0958, value_loss: 0.6731
2024-07-14 06:16:54,799 [INFO    ] __main__: train step 11617: loss: 1.0966, policy_loss: 1.0958, value_loss: 0.6730
2024-07-14 06:16:55,094 [INFO    ] __main__: train step 11618: loss: 1.0966, policy_loss: 1.0957, value_loss: 0.6730
2024-07-14 06:16:55,389 [INFO    ] __main__: train step 11619: loss: 1.0966, policy_loss: 1.0957, value_loss: 0.6729
2024-07-14 06:16:55,676 [INFO    ] __main__: train step 11620: loss: 1.0966, policy_loss: 1.0957, value_loss: 0.6729
2024-07-14 06:16:55,967 [INFO    ] __main__: train step 11621: loss: 1.0966, policy_loss: 1.0957, value_loss: 0.6729
2024-07-14 06:16:56,251 [INFO    ] __main__: train step 11622: loss: 1.0966, policy_loss: 1.0957, value_loss: 0.6728
2024-07-14 06:16:56,531 [INFO    ] __main__: train step 11623: loss: 1.0966, policy_loss: 1.0956, value_loss: 0.6728
2024-07-14 06:16:56,817 [INFO    ] __main__: train step 11624: loss: 1.0966, policy_loss: 1.0956, value_loss: 0.6728
2024-07-14 06:16:58,438 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:16:58,919 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:16:58,987 [INFO    ] __main__: train step 11625: loss: 1.0966, policy_loss: 1.0956, value_loss: 0.6727
2024-07-14 06:16:59,263 [INFO    ] __main__: train step 11626: loss: 1.0966, policy_loss: 1.0956, value_loss: 0.6727
2024-07-14 06:16:59,549 [INFO    ] __main__: train step 11627: loss: 1.0966, policy_loss: 1.0956, value_loss: 0.6727
2024-07-14 06:16:59,825 [INFO    ] __main__: train step 11628: loss: 1.0966, policy_loss: 1.0955, value_loss: 0.6726
2024-07-14 06:17:00,112 [INFO    ] __main__: train step 11629: loss: 1.0966, policy_loss: 1.0955, value_loss: 0.6726
2024-07-14 06:17:00,411 [INFO    ] __main__: train step 11630: loss: 1.0966, policy_loss: 1.0955, value_loss: 0.6726
2024-07-14 06:17:00,701 [INFO    ] __main__: train step 11631: loss: 1.0966, policy_loss: 1.0955, value_loss: 0.6725
2024-07-14 06:17:00,992 [INFO    ] __main__: train step 11632: loss: 1.0966, policy_loss: 1.0954, value_loss: 0.6725
2024-07-14 06:17:01,285 [INFO    ] __main__: train step 11633: loss: 1.0966, policy_loss: 1.0954, value_loss: 0.6724
2024-07-14 06:17:01,563 [INFO    ] __main__: train step 11634: loss: 1.0966, policy_loss: 1.0954, value_loss: 0.6724
2024-07-14 06:17:01,855 [INFO    ] __main__: train step 11635: loss: 1.0966, policy_loss: 1.0954, value_loss: 0.6724
2024-07-14 06:17:02,145 [INFO    ] __main__: train step 11636: loss: 1.0966, policy_loss: 1.0954, value_loss: 0.6723
2024-07-14 06:17:02,426 [INFO    ] __main__: train step 11637: loss: 1.0966, policy_loss: 1.0954, value_loss: 0.6723
2024-07-14 06:17:02,711 [INFO    ] __main__: train step 11638: loss: 1.0966, policy_loss: 1.0953, value_loss: 0.6723
2024-07-14 06:17:02,998 [INFO    ] __main__: train step 11639: loss: 1.0966, policy_loss: 1.0953, value_loss: 0.6722
2024-07-14 06:17:03,295 [INFO    ] __main__: train step 11640: loss: 1.0966, policy_loss: 1.0953, value_loss: 0.6722
2024-07-14 06:17:03,582 [INFO    ] __main__: train step 11641: loss: 1.0966, policy_loss: 1.0953, value_loss: 0.6722
2024-07-14 06:17:05,214 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:17:05,714 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:17:05,784 [INFO    ] __main__: train step 11642: loss: 1.0966, policy_loss: 1.0952, value_loss: 0.6721
2024-07-14 06:17:06,091 [INFO    ] __main__: train step 11643: loss: 1.0966, policy_loss: 1.0952, value_loss: 0.6721
2024-07-14 06:17:06,379 [INFO    ] __main__: train step 11644: loss: 1.0966, policy_loss: 1.0952, value_loss: 0.6720
2024-07-14 06:17:06,665 [INFO    ] __main__: train step 11645: loss: 1.0966, policy_loss: 1.0952, value_loss: 0.6720
2024-07-14 06:17:06,950 [INFO    ] __main__: train step 11646: loss: 1.0966, policy_loss: 1.0952, value_loss: 0.6720
2024-07-14 06:17:07,236 [INFO    ] __main__: train step 11647: loss: 1.0966, policy_loss: 1.0951, value_loss: 0.6719
2024-07-14 06:17:07,518 [INFO    ] __main__: train step 11648: loss: 1.0966, policy_loss: 1.0951, value_loss: 0.6719
2024-07-14 06:17:07,807 [INFO    ] __main__: train step 11649: loss: 1.0966, policy_loss: 1.0951, value_loss: 0.6719
2024-07-14 06:17:08,108 [INFO    ] __main__: train step 11650: loss: 1.0966, policy_loss: 1.0951, value_loss: 0.6718
2024-07-14 06:17:08,402 [INFO    ] __main__: train step 11651: loss: 1.0966, policy_loss: 1.0951, value_loss: 0.6718
2024-07-14 06:17:08,697 [INFO    ] __main__: train step 11652: loss: 1.0966, policy_loss: 1.0950, value_loss: 0.6718
2024-07-14 06:17:08,985 [INFO    ] __main__: train step 11653: loss: 1.0966, policy_loss: 1.0950, value_loss: 0.6717
2024-07-14 06:17:09,295 [INFO    ] __main__: train step 11654: loss: 1.0966, policy_loss: 1.0950, value_loss: 0.6717
2024-07-14 06:17:09,584 [INFO    ] __main__: train step 11655: loss: 1.0966, policy_loss: 1.0950, value_loss: 0.6717
2024-07-14 06:17:09,872 [INFO    ] __main__: train step 11656: loss: 1.0966, policy_loss: 1.0950, value_loss: 0.6716
2024-07-14 06:17:10,157 [INFO    ] __main__: train step 11657: loss: 1.0966, policy_loss: 1.0949, value_loss: 0.6716
2024-07-14 06:17:10,443 [INFO    ] __main__: train step 11658: loss: 1.0966, policy_loss: 1.0949, value_loss: 0.6715
2024-07-14 06:17:12,043 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:17:12,525 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:17:12,600 [INFO    ] __main__: train step 11659: loss: 1.0966, policy_loss: 1.0949, value_loss: 0.6715
2024-07-14 06:17:12,899 [INFO    ] __main__: train step 11660: loss: 1.0967, policy_loss: 1.0949, value_loss: 0.6715
2024-07-14 06:17:13,184 [INFO    ] __main__: train step 11661: loss: 1.0967, policy_loss: 1.0949, value_loss: 0.6714
2024-07-14 06:17:13,473 [INFO    ] __main__: train step 11662: loss: 1.0967, policy_loss: 1.0948, value_loss: 0.6714
2024-07-14 06:17:13,779 [INFO    ] __main__: train step 11663: loss: 1.0967, policy_loss: 1.0948, value_loss: 0.6714
2024-07-14 06:17:14,086 [INFO    ] __main__: train step 11664: loss: 1.0967, policy_loss: 1.0948, value_loss: 0.6713
2024-07-14 06:17:14,387 [INFO    ] __main__: train step 11665: loss: 1.0967, policy_loss: 1.0948, value_loss: 0.6713
2024-07-14 06:17:14,697 [INFO    ] __main__: train step 11666: loss: 1.0967, policy_loss: 1.0948, value_loss: 0.6713
2024-07-14 06:17:14,995 [INFO    ] __main__: train step 11667: loss: 1.0967, policy_loss: 1.0947, value_loss: 0.6712
2024-07-14 06:17:18,017 [INFO    ] __main__: train step 11668: loss: 1.0967, policy_loss: 1.0947, value_loss: 0.6712
2024-07-14 06:17:18,305 [INFO    ] __main__: train step 11669: loss: 1.0967, policy_loss: 1.0947, value_loss: 0.6712
2024-07-14 06:17:18,603 [INFO    ] __main__: train step 11670: loss: 1.0967, policy_loss: 1.0947, value_loss: 0.6711
2024-07-14 06:17:18,910 [INFO    ] __main__: train step 11671: loss: 1.0967, policy_loss: 1.0947, value_loss: 0.6711
2024-07-14 06:17:19,215 [INFO    ] __main__: train step 11672: loss: 1.0967, policy_loss: 1.0946, value_loss: 0.6711
2024-07-14 06:17:19,500 [INFO    ] __main__: train step 11673: loss: 1.0967, policy_loss: 1.0946, value_loss: 0.6710
2024-07-14 06:17:19,791 [INFO    ] __main__: train step 11674: loss: 1.0967, policy_loss: 1.0946, value_loss: 0.6710
2024-07-14 06:17:20,087 [INFO    ] __main__: train step 11675: loss: 1.0967, policy_loss: 1.0946, value_loss: 0.6710
2024-07-14 06:17:21,688 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:17:22,183 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:17:22,255 [INFO    ] __main__: train step 11676: loss: 1.0967, policy_loss: 1.0946, value_loss: 0.6709
2024-07-14 06:17:22,535 [INFO    ] __main__: train step 11677: loss: 1.0967, policy_loss: 1.0945, value_loss: 0.6709
2024-07-14 06:17:22,825 [INFO    ] __main__: train step 11678: loss: 1.0967, policy_loss: 1.0945, value_loss: 0.6708
2024-07-14 06:17:23,117 [INFO    ] __main__: train step 11679: loss: 1.0967, policy_loss: 1.0945, value_loss: 0.6708
2024-07-14 06:17:23,416 [INFO    ] __main__: train step 11680: loss: 1.0967, policy_loss: 1.0945, value_loss: 0.6708
2024-07-14 06:17:23,695 [INFO    ] __main__: train step 11681: loss: 1.0967, policy_loss: 1.0945, value_loss: 0.6707
2024-07-14 06:17:23,978 [INFO    ] __main__: train step 11682: loss: 1.0967, policy_loss: 1.0944, value_loss: 0.6707
2024-07-14 06:17:24,268 [INFO    ] __main__: train step 11683: loss: 1.0967, policy_loss: 1.0944, value_loss: 0.6707
2024-07-14 06:17:24,566 [INFO    ] __main__: train step 11684: loss: 1.0967, policy_loss: 1.0944, value_loss: 0.6706
2024-07-14 06:17:24,852 [INFO    ] __main__: train step 11685: loss: 1.0967, policy_loss: 1.0944, value_loss: 0.6706
2024-07-14 06:17:25,141 [INFO    ] __main__: train step 11686: loss: 1.0967, policy_loss: 1.0944, value_loss: 0.6706
2024-07-14 06:17:25,454 [INFO    ] __main__: train step 11687: loss: 1.0967, policy_loss: 1.0943, value_loss: 0.6705
2024-07-14 06:17:25,756 [INFO    ] __main__: train step 11688: loss: 1.0967, policy_loss: 1.0943, value_loss: 0.6705
2024-07-14 06:17:26,039 [INFO    ] __main__: train step 11689: loss: 1.0967, policy_loss: 1.0943, value_loss: 0.6705
2024-07-14 06:17:26,344 [INFO    ] __main__: train step 11690: loss: 1.0967, policy_loss: 1.0943, value_loss: 0.6704
2024-07-14 06:17:26,632 [INFO    ] __main__: train step 11691: loss: 1.0967, policy_loss: 1.0943, value_loss: 0.6704
2024-07-14 06:17:26,934 [INFO    ] __main__: train step 11692: loss: 1.0967, policy_loss: 1.0942, value_loss: 0.6704
2024-07-14 06:17:28,565 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:17:29,058 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:17:29,132 [INFO    ] __main__: train step 11693: loss: 1.0967, policy_loss: 1.0942, value_loss: 0.6703
2024-07-14 06:17:29,428 [INFO    ] __main__: train step 11694: loss: 1.0967, policy_loss: 1.0942, value_loss: 0.6703
2024-07-14 06:17:29,722 [INFO    ] __main__: train step 11695: loss: 1.0967, policy_loss: 1.0942, value_loss: 0.6702
2024-07-14 06:17:29,996 [INFO    ] __main__: train step 11696: loss: 1.0967, policy_loss: 1.0942, value_loss: 0.6702
2024-07-14 06:17:30,292 [INFO    ] __main__: train step 11697: loss: 1.0967, policy_loss: 1.0941, value_loss: 0.6702
2024-07-14 06:17:30,589 [INFO    ] __main__: train step 11698: loss: 1.0967, policy_loss: 1.0941, value_loss: 0.6701
2024-07-14 06:17:30,882 [INFO    ] __main__: train step 11699: loss: 1.0967, policy_loss: 1.0941, value_loss: 0.6701
2024-07-14 06:17:31,176 [INFO    ] __main__: train step 11700: loss: 1.0967, policy_loss: 1.0941, value_loss: 0.6701
2024-07-14 06:17:31,459 [INFO    ] __main__: train step 11701: loss: 1.0967, policy_loss: 1.0941, value_loss: 0.6700
2024-07-14 06:17:31,758 [INFO    ] __main__: train step 11702: loss: 1.0967, policy_loss: 1.0940, value_loss: 0.6700
2024-07-14 06:17:32,055 [INFO    ] __main__: train step 11703: loss: 1.0967, policy_loss: 1.0940, value_loss: 0.6700
2024-07-14 06:17:32,355 [INFO    ] __main__: train step 11704: loss: 1.0967, policy_loss: 1.0940, value_loss: 0.6699
2024-07-14 06:17:32,643 [INFO    ] __main__: train step 11705: loss: 1.0967, policy_loss: 1.0940, value_loss: 0.6699
2024-07-14 06:17:32,933 [INFO    ] __main__: train step 11706: loss: 1.0967, policy_loss: 1.0940, value_loss: 0.6699
2024-07-14 06:17:33,212 [INFO    ] __main__: train step 11707: loss: 1.0967, policy_loss: 1.0939, value_loss: 0.6698
2024-07-14 06:17:33,501 [INFO    ] __main__: train step 11708: loss: 1.0968, policy_loss: 1.0939, value_loss: 0.6698
2024-07-14 06:17:33,795 [INFO    ] __main__: train step 11709: loss: 1.0968, policy_loss: 1.0939, value_loss: 0.6698
2024-07-14 06:17:35,414 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:17:35,908 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:17:35,978 [INFO    ] __main__: train step 11710: loss: 1.0968, policy_loss: 1.0939, value_loss: 0.6697
2024-07-14 06:17:36,264 [INFO    ] __main__: train step 11711: loss: 1.0968, policy_loss: 1.0939, value_loss: 0.6697
2024-07-14 06:17:36,542 [INFO    ] __main__: train step 11712: loss: 1.0968, policy_loss: 1.0939, value_loss: 0.6696
2024-07-14 06:17:36,837 [INFO    ] __main__: train step 11713: loss: 1.0968, policy_loss: 1.0938, value_loss: 0.6696
2024-07-14 06:17:37,130 [INFO    ] __main__: train step 11714: loss: 1.0968, policy_loss: 1.0938, value_loss: 0.6696
2024-07-14 06:17:37,419 [INFO    ] __main__: train step 11715: loss: 1.0968, policy_loss: 1.0938, value_loss: 0.6695
2024-07-14 06:17:37,712 [INFO    ] __main__: train step 11716: loss: 1.0968, policy_loss: 1.0938, value_loss: 0.6695
2024-07-14 06:17:37,995 [INFO    ] __main__: train step 11717: loss: 1.0968, policy_loss: 1.0938, value_loss: 0.6695
2024-07-14 06:17:38,293 [INFO    ] __main__: train step 11718: loss: 1.0968, policy_loss: 1.0937, value_loss: 0.6694
2024-07-14 06:17:38,587 [INFO    ] __main__: train step 11719: loss: 1.0968, policy_loss: 1.0937, value_loss: 0.6694
2024-07-14 06:17:38,869 [INFO    ] __main__: train step 11720: loss: 1.0968, policy_loss: 1.0937, value_loss: 0.6694
2024-07-14 06:17:39,154 [INFO    ] __main__: train step 11721: loss: 1.0968, policy_loss: 1.0937, value_loss: 0.6693
2024-07-14 06:17:39,450 [INFO    ] __main__: train step 11722: loss: 1.0968, policy_loss: 1.0937, value_loss: 0.6693
2024-07-14 06:17:39,744 [INFO    ] __main__: train step 11723: loss: 1.0968, policy_loss: 1.0936, value_loss: 0.6693
2024-07-14 06:17:40,040 [INFO    ] __main__: train step 11724: loss: 1.0968, policy_loss: 1.0936, value_loss: 0.6692
2024-07-14 06:17:40,339 [INFO    ] __main__: train step 11725: loss: 1.0968, policy_loss: 1.0936, value_loss: 0.6692
2024-07-14 06:17:40,636 [INFO    ] __main__: train step 11726: loss: 1.0968, policy_loss: 1.0936, value_loss: 0.6691
2024-07-14 06:17:42,255 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:17:42,745 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:17:42,818 [INFO    ] __main__: train step 11727: loss: 1.0968, policy_loss: 1.0936, value_loss: 0.6691
2024-07-14 06:17:43,112 [INFO    ] __main__: train step 11728: loss: 1.0968, policy_loss: 1.0935, value_loss: 0.6691
2024-07-14 06:17:43,397 [INFO    ] __main__: train step 11729: loss: 1.0968, policy_loss: 1.0935, value_loss: 0.6690
2024-07-14 06:17:43,678 [INFO    ] __main__: train step 11730: loss: 1.0968, policy_loss: 1.0935, value_loss: 0.6690
2024-07-14 06:17:43,958 [INFO    ] __main__: train step 11731: loss: 1.0968, policy_loss: 1.0935, value_loss: 0.6690
2024-07-14 06:17:44,229 [INFO    ] __main__: train step 11732: loss: 1.0968, policy_loss: 1.0935, value_loss: 0.6689
2024-07-14 06:17:44,497 [INFO    ] __main__: train step 11733: loss: 1.0968, policy_loss: 1.0934, value_loss: 0.6689
2024-07-14 06:17:44,775 [INFO    ] __main__: train step 11734: loss: 1.0968, policy_loss: 1.0934, value_loss: 0.6689
2024-07-14 06:17:45,069 [INFO    ] __main__: train step 11735: loss: 1.0968, policy_loss: 1.0934, value_loss: 0.6688
2024-07-14 06:17:45,367 [INFO    ] __main__: train step 11736: loss: 1.0968, policy_loss: 1.0934, value_loss: 0.6688
2024-07-14 06:17:45,646 [INFO    ] __main__: train step 11737: loss: 1.0968, policy_loss: 1.0934, value_loss: 0.6688
2024-07-14 06:17:45,943 [INFO    ] __main__: train step 11738: loss: 1.0968, policy_loss: 1.0934, value_loss: 0.6687
2024-07-14 06:17:46,220 [INFO    ] __main__: train step 11739: loss: 1.0968, policy_loss: 1.0933, value_loss: 0.6687
2024-07-14 06:17:46,504 [INFO    ] __main__: train step 11740: loss: 1.0968, policy_loss: 1.0933, value_loss: 0.6687
2024-07-14 06:17:46,796 [INFO    ] __main__: train step 11741: loss: 1.0968, policy_loss: 1.0933, value_loss: 0.6686
2024-07-14 06:17:47,097 [INFO    ] __main__: train step 11742: loss: 1.0968, policy_loss: 1.0933, value_loss: 0.6686
2024-07-14 06:17:47,409 [INFO    ] __main__: train step 11743: loss: 1.0968, policy_loss: 1.0933, value_loss: 0.6685
2024-07-14 06:17:49,045 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:17:49,532 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:17:49,606 [INFO    ] __main__: train step 11744: loss: 1.0968, policy_loss: 1.0932, value_loss: 0.6685
2024-07-14 06:17:49,892 [INFO    ] __main__: train step 11745: loss: 1.0968, policy_loss: 1.0932, value_loss: 0.6685
2024-07-14 06:17:50,185 [INFO    ] __main__: train step 11746: loss: 1.0968, policy_loss: 1.0932, value_loss: 0.6684
2024-07-14 06:17:50,474 [INFO    ] __main__: train step 11747: loss: 1.0968, policy_loss: 1.0932, value_loss: 0.6684
2024-07-14 06:17:50,765 [INFO    ] __main__: train step 11748: loss: 1.0968, policy_loss: 1.0932, value_loss: 0.6684
2024-07-14 06:17:51,059 [INFO    ] __main__: train step 11749: loss: 1.0968, policy_loss: 1.0931, value_loss: 0.6683
2024-07-14 06:17:51,347 [INFO    ] __main__: train step 11750: loss: 1.0968, policy_loss: 1.0931, value_loss: 0.6683
2024-07-14 06:17:51,629 [INFO    ] __main__: train step 11751: loss: 1.0968, policy_loss: 1.0931, value_loss: 0.6683
2024-07-14 06:17:51,916 [INFO    ] __main__: train step 11752: loss: 1.0968, policy_loss: 1.0931, value_loss: 0.6682
2024-07-14 06:17:52,198 [INFO    ] __main__: train step 11753: loss: 1.0969, policy_loss: 1.0931, value_loss: 0.6682
2024-07-14 06:17:52,491 [INFO    ] __main__: train step 11754: loss: 1.0969, policy_loss: 1.0930, value_loss: 0.6682
2024-07-14 06:17:55,455 [INFO    ] __main__: train step 11755: loss: 1.0969, policy_loss: 1.0930, value_loss: 0.6681
2024-07-14 06:17:55,748 [INFO    ] __main__: train step 11756: loss: 1.0969, policy_loss: 1.0930, value_loss: 0.6681
2024-07-14 06:17:56,036 [INFO    ] __main__: train step 11757: loss: 1.0969, policy_loss: 1.0930, value_loss: 0.6681
2024-07-14 06:17:56,344 [INFO    ] __main__: train step 11758: loss: 1.0969, policy_loss: 1.0930, value_loss: 0.6680
2024-07-14 06:17:56,639 [INFO    ] __main__: train step 11759: loss: 1.0969, policy_loss: 1.0929, value_loss: 0.6680
2024-07-14 06:17:56,931 [INFO    ] __main__: train step 11760: loss: 1.0969, policy_loss: 1.0929, value_loss: 0.6680
2024-07-14 06:17:58,549 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:17:59,051 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:17:59,123 [INFO    ] __main__: train step 11761: loss: 1.0969, policy_loss: 1.0929, value_loss: 0.6679
2024-07-14 06:17:59,413 [INFO    ] __main__: train step 11762: loss: 1.0969, policy_loss: 1.0929, value_loss: 0.6679
2024-07-14 06:17:59,698 [INFO    ] __main__: train step 11763: loss: 1.0969, policy_loss: 1.0929, value_loss: 0.6679
2024-07-14 06:17:59,984 [INFO    ] __main__: train step 11764: loss: 1.0969, policy_loss: 1.0928, value_loss: 0.6678
2024-07-14 06:18:00,277 [INFO    ] __main__: train step 11765: loss: 1.0969, policy_loss: 1.0928, value_loss: 0.6678
2024-07-14 06:18:00,561 [INFO    ] __main__: train step 11766: loss: 1.0969, policy_loss: 1.0928, value_loss: 0.6677
2024-07-14 06:18:00,853 [INFO    ] __main__: train step 11767: loss: 1.0969, policy_loss: 1.0928, value_loss: 0.6677
2024-07-14 06:18:01,147 [INFO    ] __main__: train step 11768: loss: 1.0969, policy_loss: 1.0928, value_loss: 0.6677
2024-07-14 06:18:01,432 [INFO    ] __main__: train step 11769: loss: 1.0969, policy_loss: 1.0927, value_loss: 0.6676
2024-07-14 06:18:01,724 [INFO    ] __main__: train step 11770: loss: 1.0969, policy_loss: 1.0927, value_loss: 0.6676
2024-07-14 06:18:02,026 [INFO    ] __main__: train step 11771: loss: 1.0969, policy_loss: 1.0927, value_loss: 0.6676
2024-07-14 06:18:02,319 [INFO    ] __main__: train step 11772: loss: 1.0969, policy_loss: 1.0927, value_loss: 0.6675
2024-07-14 06:18:02,623 [INFO    ] __main__: train step 11773: loss: 1.0969, policy_loss: 1.0927, value_loss: 0.6675
2024-07-14 06:18:02,920 [INFO    ] __main__: train step 11774: loss: 1.0969, policy_loss: 1.0926, value_loss: 0.6675
2024-07-14 06:18:03,216 [INFO    ] __main__: train step 11775: loss: 1.0969, policy_loss: 1.0926, value_loss: 0.6674
2024-07-14 06:18:03,518 [INFO    ] __main__: train step 11776: loss: 1.0969, policy_loss: 1.0926, value_loss: 0.6674
2024-07-14 06:18:03,799 [INFO    ] __main__: train step 11777: loss: 1.0969, policy_loss: 1.0926, value_loss: 0.6674
2024-07-14 06:18:05,409 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:18:05,911 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:18:05,982 [INFO    ] __main__: train step 11778: loss: 1.0969, policy_loss: 1.0926, value_loss: 0.6673
2024-07-14 06:18:06,277 [INFO    ] __main__: train step 11779: loss: 1.0969, policy_loss: 1.0925, value_loss: 0.6673
2024-07-14 06:18:06,574 [INFO    ] __main__: train step 11780: loss: 1.0969, policy_loss: 1.0925, value_loss: 0.6673
2024-07-14 06:18:06,855 [INFO    ] __main__: train step 11781: loss: 1.0969, policy_loss: 1.0925, value_loss: 0.6672
2024-07-14 06:18:07,146 [INFO    ] __main__: train step 11782: loss: 1.0969, policy_loss: 1.0925, value_loss: 0.6672
2024-07-14 06:18:07,438 [INFO    ] __main__: train step 11783: loss: 1.0969, policy_loss: 1.0925, value_loss: 0.6671
2024-07-14 06:18:07,723 [INFO    ] __main__: train step 11784: loss: 1.0969, policy_loss: 1.0925, value_loss: 0.6671
2024-07-14 06:18:08,007 [INFO    ] __main__: train step 11785: loss: 1.0969, policy_loss: 1.0924, value_loss: 0.6671
2024-07-14 06:18:08,308 [INFO    ] __main__: train step 11786: loss: 1.0969, policy_loss: 1.0924, value_loss: 0.6670
2024-07-14 06:18:08,596 [INFO    ] __main__: train step 11787: loss: 1.0969, policy_loss: 1.0924, value_loss: 0.6670
2024-07-14 06:18:08,876 [INFO    ] __main__: train step 11788: loss: 1.0969, policy_loss: 1.0924, value_loss: 0.6670
2024-07-14 06:18:09,170 [INFO    ] __main__: train step 11789: loss: 1.0969, policy_loss: 1.0923, value_loss: 0.6669
2024-07-14 06:18:09,437 [INFO    ] __main__: train step 11790: loss: 1.0969, policy_loss: 1.0923, value_loss: 0.6669
2024-07-14 06:18:09,693 [INFO    ] __main__: train step 11791: loss: 1.0969, policy_loss: 1.0923, value_loss: 0.6669
2024-07-14 06:18:09,959 [INFO    ] __main__: train step 11792: loss: 1.0969, policy_loss: 1.0923, value_loss: 0.6668
2024-07-14 06:18:10,227 [INFO    ] __main__: train step 11793: loss: 1.0969, policy_loss: 1.0923, value_loss: 0.6668
2024-07-14 06:18:10,520 [INFO    ] __main__: train step 11794: loss: 1.0969, policy_loss: 1.0923, value_loss: 0.6668
2024-07-14 06:18:12,153 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:18:12,646 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:18:12,716 [INFO    ] __main__: train step 11795: loss: 1.0969, policy_loss: 1.0922, value_loss: 0.6667
2024-07-14 06:18:13,013 [INFO    ] __main__: train step 11796: loss: 1.0969, policy_loss: 1.0922, value_loss: 0.6667
2024-07-14 06:18:13,312 [INFO    ] __main__: train step 11797: loss: 1.0969, policy_loss: 1.0922, value_loss: 0.6667
2024-07-14 06:18:13,608 [INFO    ] __main__: train step 11798: loss: 1.0969, policy_loss: 1.0922, value_loss: 0.6666
2024-07-14 06:18:13,892 [INFO    ] __main__: train step 11799: loss: 1.0969, policy_loss: 1.0922, value_loss: 0.6666
2024-07-14 06:18:14,181 [INFO    ] __main__: train step 11800: loss: 1.0969, policy_loss: 1.0921, value_loss: 0.6665
2024-07-14 06:18:14,468 [INFO    ] __main__: train step 11801: loss: 1.0969, policy_loss: 1.0921, value_loss: 0.6665
2024-07-14 06:18:14,750 [INFO    ] __main__: train step 11802: loss: 1.0969, policy_loss: 1.0921, value_loss: 0.6665
2024-07-14 06:18:15,027 [INFO    ] __main__: train step 11803: loss: 1.0969, policy_loss: 1.0921, value_loss: 0.6664
2024-07-14 06:18:15,328 [INFO    ] __main__: train step 11804: loss: 1.0969, policy_loss: 1.0921, value_loss: 0.6664
2024-07-14 06:18:15,614 [INFO    ] __main__: train step 11805: loss: 1.0969, policy_loss: 1.0920, value_loss: 0.6664
2024-07-14 06:18:15,903 [INFO    ] __main__: train step 11806: loss: 1.0969, policy_loss: 1.0920, value_loss: 0.6663
2024-07-14 06:18:16,177 [INFO    ] __main__: train step 11807: loss: 1.0969, policy_loss: 1.0920, value_loss: 0.6663
2024-07-14 06:18:16,459 [INFO    ] __main__: train step 11808: loss: 1.0969, policy_loss: 1.0920, value_loss: 0.6663
2024-07-14 06:18:16,764 [INFO    ] __main__: train step 11809: loss: 1.0969, policy_loss: 1.0920, value_loss: 0.6662
2024-07-14 06:18:17,057 [INFO    ] __main__: train step 11810: loss: 1.0969, policy_loss: 1.0919, value_loss: 0.6662
2024-07-14 06:18:17,348 [INFO    ] __main__: train step 11811: loss: 1.0969, policy_loss: 1.0919, value_loss: 0.6662
2024-07-14 06:18:18,988 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:18:19,483 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:18:19,562 [INFO    ] __main__: train step 11812: loss: 1.0969, policy_loss: 1.0919, value_loss: 0.6661
2024-07-14 06:18:19,855 [INFO    ] __main__: train step 11813: loss: 1.0969, policy_loss: 1.0919, value_loss: 0.6661
2024-07-14 06:18:20,147 [INFO    ] __main__: train step 11814: loss: 1.0969, policy_loss: 1.0919, value_loss: 0.6661
2024-07-14 06:18:20,432 [INFO    ] __main__: train step 11815: loss: 1.0969, policy_loss: 1.0918, value_loss: 0.6660
2024-07-14 06:18:20,722 [INFO    ] __main__: train step 11816: loss: 1.0969, policy_loss: 1.0918, value_loss: 0.6660
2024-07-14 06:18:21,020 [INFO    ] __main__: train step 11817: loss: 1.0969, policy_loss: 1.0918, value_loss: 0.6659
2024-07-14 06:18:21,331 [INFO    ] __main__: train step 11818: loss: 1.0969, policy_loss: 1.0918, value_loss: 0.6659
2024-07-14 06:18:21,627 [INFO    ] __main__: train step 11819: loss: 1.0969, policy_loss: 1.0918, value_loss: 0.6659
2024-07-14 06:18:21,929 [INFO    ] __main__: train step 11820: loss: 1.0969, policy_loss: 1.0918, value_loss: 0.6658
2024-07-14 06:18:22,225 [INFO    ] __main__: train step 11821: loss: 1.0969, policy_loss: 1.0917, value_loss: 0.6658
2024-07-14 06:18:22,531 [INFO    ] __main__: train step 11822: loss: 1.0969, policy_loss: 1.0917, value_loss: 0.6658
2024-07-14 06:18:22,834 [INFO    ] __main__: train step 11823: loss: 1.0969, policy_loss: 1.0917, value_loss: 0.6657
2024-07-14 06:18:23,123 [INFO    ] __main__: train step 11824: loss: 1.0969, policy_loss: 1.0917, value_loss: 0.6657
2024-07-14 06:18:23,430 [INFO    ] __main__: train step 11825: loss: 1.0969, policy_loss: 1.0917, value_loss: 0.6657
2024-07-14 06:18:23,715 [INFO    ] __main__: train step 11826: loss: 1.0970, policy_loss: 1.0916, value_loss: 0.6656
2024-07-14 06:18:23,996 [INFO    ] __main__: train step 11827: loss: 1.0970, policy_loss: 1.0916, value_loss: 0.6656
2024-07-14 06:18:24,291 [INFO    ] __main__: train step 11828: loss: 1.0970, policy_loss: 1.0916, value_loss: 0.6656
2024-07-14 06:18:25,934 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:18:26,418 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:18:26,489 [INFO    ] __main__: train step 11829: loss: 1.0970, policy_loss: 1.0916, value_loss: 0.6655
2024-07-14 06:18:26,780 [INFO    ] __main__: train step 11830: loss: 1.0970, policy_loss: 1.0916, value_loss: 0.6655
2024-07-14 06:18:27,064 [INFO    ] __main__: train step 11831: loss: 1.0970, policy_loss: 1.0915, value_loss: 0.6655
2024-07-14 06:18:27,361 [INFO    ] __main__: train step 11832: loss: 1.0970, policy_loss: 1.0915, value_loss: 0.6654
2024-07-14 06:18:27,659 [INFO    ] __main__: train step 11833: loss: 1.0970, policy_loss: 1.0915, value_loss: 0.6654
2024-07-14 06:18:27,959 [INFO    ] __main__: train step 11834: loss: 1.0970, policy_loss: 1.0915, value_loss: 0.6653
2024-07-14 06:18:28,250 [INFO    ] __main__: train step 11835: loss: 1.0970, policy_loss: 1.0915, value_loss: 0.6653
2024-07-14 06:18:28,546 [INFO    ] __main__: train step 11836: loss: 1.0970, policy_loss: 1.0914, value_loss: 0.6653
2024-07-14 06:18:28,832 [INFO    ] __main__: train step 11837: loss: 1.0970, policy_loss: 1.0914, value_loss: 0.6652
2024-07-14 06:18:29,120 [INFO    ] __main__: train step 11838: loss: 1.0970, policy_loss: 1.0914, value_loss: 0.6652
2024-07-14 06:18:29,410 [INFO    ] __main__: train step 11839: loss: 1.0970, policy_loss: 1.0914, value_loss: 0.6652
2024-07-14 06:18:29,705 [INFO    ] __main__: train step 11840: loss: 1.0970, policy_loss: 1.0914, value_loss: 0.6651
2024-07-14 06:18:30,000 [INFO    ] __main__: train step 11841: loss: 1.0970, policy_loss: 1.0913, value_loss: 0.6651
2024-07-14 06:18:30,296 [INFO    ] __main__: train step 11842: loss: 1.0970, policy_loss: 1.0913, value_loss: 0.6651
2024-07-14 06:18:30,581 [INFO    ] __main__: train step 11843: loss: 1.0970, policy_loss: 1.0913, value_loss: 0.6650
2024-07-14 06:18:30,876 [INFO    ] __main__: train step 11844: loss: 1.0970, policy_loss: 1.0913, value_loss: 0.6650
2024-07-14 06:18:33,911 [INFO    ] __main__: train step 11845: loss: 1.0970, policy_loss: 1.0913, value_loss: 0.6650
2024-07-14 06:18:35,531 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:18:36,029 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:18:36,103 [INFO    ] __main__: train step 11846: loss: 1.0970, policy_loss: 1.0912, value_loss: 0.6649
2024-07-14 06:18:36,386 [INFO    ] __main__: train step 11847: loss: 1.0970, policy_loss: 1.0912, value_loss: 0.6649
2024-07-14 06:18:36,677 [INFO    ] __main__: train step 11848: loss: 1.0970, policy_loss: 1.0912, value_loss: 0.6648
2024-07-14 06:18:36,967 [INFO    ] __main__: train step 11849: loss: 1.0970, policy_loss: 1.0912, value_loss: 0.6648
2024-07-14 06:18:37,254 [INFO    ] __main__: train step 11850: loss: 1.0970, policy_loss: 1.0912, value_loss: 0.6648
2024-07-14 06:18:37,558 [INFO    ] __main__: train step 11851: loss: 1.0970, policy_loss: 1.0911, value_loss: 0.6647
2024-07-14 06:18:37,871 [INFO    ] __main__: train step 11852: loss: 1.0970, policy_loss: 1.0911, value_loss: 0.6647
2024-07-14 06:18:38,175 [INFO    ] __main__: train step 11853: loss: 1.0970, policy_loss: 1.0911, value_loss: 0.6647
2024-07-14 06:18:38,471 [INFO    ] __main__: train step 11854: loss: 1.0970, policy_loss: 1.0911, value_loss: 0.6646
2024-07-14 06:18:38,766 [INFO    ] __main__: train step 11855: loss: 1.0970, policy_loss: 1.0911, value_loss: 0.6646
2024-07-14 06:18:39,063 [INFO    ] __main__: train step 11856: loss: 1.0970, policy_loss: 1.0911, value_loss: 0.6646
2024-07-14 06:18:39,362 [INFO    ] __main__: train step 11857: loss: 1.0970, policy_loss: 1.0910, value_loss: 0.6645
2024-07-14 06:18:39,675 [INFO    ] __main__: train step 11858: loss: 1.0970, policy_loss: 1.0910, value_loss: 0.6645
2024-07-14 06:18:39,994 [INFO    ] __main__: train step 11859: loss: 1.0970, policy_loss: 1.0910, value_loss: 0.6645
2024-07-14 06:18:40,288 [INFO    ] __main__: train step 11860: loss: 1.0970, policy_loss: 1.0910, value_loss: 0.6644
2024-07-14 06:18:40,581 [INFO    ] __main__: train step 11861: loss: 1.0970, policy_loss: 1.0910, value_loss: 0.6644
2024-07-14 06:18:40,862 [INFO    ] __main__: train step 11862: loss: 1.0970, policy_loss: 1.0909, value_loss: 0.6644
2024-07-14 06:18:42,475 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:18:42,957 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:18:43,026 [INFO    ] __main__: train step 11863: loss: 1.0970, policy_loss: 1.0909, value_loss: 0.6643
2024-07-14 06:18:43,300 [INFO    ] __main__: train step 11864: loss: 1.0970, policy_loss: 1.0909, value_loss: 0.6643
2024-07-14 06:18:43,575 [INFO    ] __main__: train step 11865: loss: 1.0970, policy_loss: 1.0909, value_loss: 0.6643
2024-07-14 06:18:43,840 [INFO    ] __main__: train step 11866: loss: 1.0970, policy_loss: 1.0909, value_loss: 0.6642
2024-07-14 06:18:44,116 [INFO    ] __main__: train step 11867: loss: 1.0970, policy_loss: 1.0908, value_loss: 0.6642
2024-07-14 06:18:44,430 [INFO    ] __main__: train step 11868: loss: 1.0970, policy_loss: 1.0908, value_loss: 0.6642
2024-07-14 06:18:44,729 [INFO    ] __main__: train step 11869: loss: 1.0970, policy_loss: 1.0908, value_loss: 0.6641
2024-07-14 06:18:45,028 [INFO    ] __main__: train step 11870: loss: 1.0970, policy_loss: 1.0908, value_loss: 0.6641
2024-07-14 06:18:45,319 [INFO    ] __main__: train step 11871: loss: 1.0970, policy_loss: 1.0908, value_loss: 0.6640
2024-07-14 06:18:45,619 [INFO    ] __main__: train step 11872: loss: 1.0970, policy_loss: 1.0907, value_loss: 0.6640
2024-07-14 06:18:45,913 [INFO    ] __main__: train step 11873: loss: 1.0970, policy_loss: 1.0907, value_loss: 0.6640
2024-07-14 06:18:46,198 [INFO    ] __main__: train step 11874: loss: 1.0970, policy_loss: 1.0907, value_loss: 0.6639
2024-07-14 06:18:46,493 [INFO    ] __main__: train step 11875: loss: 1.0970, policy_loss: 1.0907, value_loss: 0.6639
2024-07-14 06:18:46,791 [INFO    ] __main__: train step 11876: loss: 1.0970, policy_loss: 1.0907, value_loss: 0.6639
2024-07-14 06:18:47,084 [INFO    ] __main__: train step 11877: loss: 1.0970, policy_loss: 1.0906, value_loss: 0.6638
2024-07-14 06:18:47,384 [INFO    ] __main__: train step 11878: loss: 1.0970, policy_loss: 1.0906, value_loss: 0.6638
2024-07-14 06:18:47,679 [INFO    ] __main__: train step 11879: loss: 1.0970, policy_loss: 1.0906, value_loss: 0.6638
2024-07-14 06:18:49,297 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:18:49,781 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:18:49,851 [INFO    ] __main__: train step 11880: loss: 1.0970, policy_loss: 1.0906, value_loss: 0.6637
2024-07-14 06:18:50,138 [INFO    ] __main__: train step 11881: loss: 1.0970, policy_loss: 1.0906, value_loss: 0.6637
2024-07-14 06:18:50,424 [INFO    ] __main__: train step 11882: loss: 1.0970, policy_loss: 1.0905, value_loss: 0.6637
2024-07-14 06:18:50,713 [INFO    ] __main__: train step 11883: loss: 1.0970, policy_loss: 1.0905, value_loss: 0.6636
2024-07-14 06:18:51,020 [INFO    ] __main__: train step 11884: loss: 1.0970, policy_loss: 1.0905, value_loss: 0.6636
2024-07-14 06:18:51,316 [INFO    ] __main__: train step 11885: loss: 1.0970, policy_loss: 1.0905, value_loss: 0.6636
2024-07-14 06:18:51,608 [INFO    ] __main__: train step 11886: loss: 1.0970, policy_loss: 1.0905, value_loss: 0.6635
2024-07-14 06:18:51,907 [INFO    ] __main__: train step 11887: loss: 1.0970, policy_loss: 1.0904, value_loss: 0.6635
2024-07-14 06:18:52,202 [INFO    ] __main__: train step 11888: loss: 1.0970, policy_loss: 1.0904, value_loss: 0.6634
2024-07-14 06:18:52,512 [INFO    ] __main__: train step 11889: loss: 1.0970, policy_loss: 1.0904, value_loss: 0.6634
2024-07-14 06:18:52,805 [INFO    ] __main__: train step 11890: loss: 1.0970, policy_loss: 1.0904, value_loss: 0.6634
2024-07-14 06:18:53,109 [INFO    ] __main__: train step 11891: loss: 1.0970, policy_loss: 1.0904, value_loss: 0.6633
2024-07-14 06:18:53,410 [INFO    ] __main__: train step 11892: loss: 1.0970, policy_loss: 1.0903, value_loss: 0.6633
2024-07-14 06:18:53,713 [INFO    ] __main__: train step 11893: loss: 1.0970, policy_loss: 1.0903, value_loss: 0.6633
2024-07-14 06:18:54,001 [INFO    ] __main__: train step 11894: loss: 1.0970, policy_loss: 1.0903, value_loss: 0.6632
2024-07-14 06:18:54,294 [INFO    ] __main__: train step 11895: loss: 1.0970, policy_loss: 1.0903, value_loss: 0.6632
2024-07-14 06:18:54,585 [INFO    ] __main__: train step 11896: loss: 1.0970, policy_loss: 1.0903, value_loss: 0.6632
2024-07-14 06:18:56,215 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:18:56,701 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:18:56,774 [INFO    ] __main__: train step 11897: loss: 1.0970, policy_loss: 1.0903, value_loss: 0.6631
2024-07-14 06:18:57,043 [INFO    ] __main__: train step 11898: loss: 1.0970, policy_loss: 1.0902, value_loss: 0.6631
2024-07-14 06:18:57,321 [INFO    ] __main__: train step 11899: loss: 1.0970, policy_loss: 1.0902, value_loss: 0.6631
2024-07-14 06:18:57,592 [INFO    ] __main__: train step 11900: loss: 1.0970, policy_loss: 1.0902, value_loss: 0.6630
2024-07-14 06:18:57,880 [INFO    ] __main__: train step 11901: loss: 1.0970, policy_loss: 1.0902, value_loss: 0.6630
2024-07-14 06:18:58,178 [INFO    ] __main__: train step 11902: loss: 1.0970, policy_loss: 1.0902, value_loss: 0.6630
2024-07-14 06:18:58,455 [INFO    ] __main__: train step 11903: loss: 1.0970, policy_loss: 1.0901, value_loss: 0.6629
2024-07-14 06:18:58,751 [INFO    ] __main__: train step 11904: loss: 1.0970, policy_loss: 1.0901, value_loss: 0.6629
2024-07-14 06:18:59,041 [INFO    ] __main__: train step 11905: loss: 1.0970, policy_loss: 1.0901, value_loss: 0.6629
2024-07-14 06:18:59,339 [INFO    ] __main__: train step 11906: loss: 1.0970, policy_loss: 1.0901, value_loss: 0.6628
2024-07-14 06:18:59,630 [INFO    ] __main__: train step 11907: loss: 1.0970, policy_loss: 1.0901, value_loss: 0.6628
2024-07-14 06:18:59,940 [INFO    ] __main__: train step 11908: loss: 1.0970, policy_loss: 1.0900, value_loss: 0.6628
2024-07-14 06:19:00,224 [INFO    ] __main__: train step 11909: loss: 1.0970, policy_loss: 1.0900, value_loss: 0.6627
2024-07-14 06:19:00,516 [INFO    ] __main__: train step 11910: loss: 1.0970, policy_loss: 1.0900, value_loss: 0.6627
2024-07-14 06:19:00,806 [INFO    ] __main__: train step 11911: loss: 1.0970, policy_loss: 1.0900, value_loss: 0.6626
2024-07-14 06:19:01,096 [INFO    ] __main__: train step 11912: loss: 1.0970, policy_loss: 1.0900, value_loss: 0.6626
2024-07-14 06:19:01,391 [INFO    ] __main__: train step 11913: loss: 1.0970, policy_loss: 1.0899, value_loss: 0.6626
2024-07-14 06:19:03,018 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:19:03,522 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:19:03,592 [INFO    ] __main__: train step 11914: loss: 1.0970, policy_loss: 1.0899, value_loss: 0.6625
2024-07-14 06:19:03,883 [INFO    ] __main__: train step 11915: loss: 1.0970, policy_loss: 1.0899, value_loss: 0.6625
2024-07-14 06:19:04,182 [INFO    ] __main__: train step 11916: loss: 1.0970, policy_loss: 1.0899, value_loss: 0.6625
2024-07-14 06:19:04,468 [INFO    ] __main__: train step 11917: loss: 1.0970, policy_loss: 1.0899, value_loss: 0.6624
2024-07-14 06:19:04,754 [INFO    ] __main__: train step 11918: loss: 1.0970, policy_loss: 1.0898, value_loss: 0.6624
2024-07-14 06:19:05,040 [INFO    ] __main__: train step 11919: loss: 1.0970, policy_loss: 1.0898, value_loss: 0.6624
2024-07-14 06:19:05,353 [INFO    ] __main__: train step 11920: loss: 1.0970, policy_loss: 1.0898, value_loss: 0.6623
2024-07-14 06:19:05,633 [INFO    ] __main__: train step 11921: loss: 1.0970, policy_loss: 1.0898, value_loss: 0.6623
2024-07-14 06:19:05,926 [INFO    ] __main__: train step 11922: loss: 1.0970, policy_loss: 1.0898, value_loss: 0.6623
2024-07-14 06:19:06,234 [INFO    ] __main__: train step 11923: loss: 1.0970, policy_loss: 1.0897, value_loss: 0.6622
2024-07-14 06:19:06,530 [INFO    ] __main__: train step 11924: loss: 1.0970, policy_loss: 1.0897, value_loss: 0.6622
2024-07-14 06:19:06,813 [INFO    ] __main__: train step 11925: loss: 1.0970, policy_loss: 1.0897, value_loss: 0.6622
2024-07-14 06:19:07,110 [INFO    ] __main__: train step 11926: loss: 1.0970, policy_loss: 1.0897, value_loss: 0.6621
2024-07-14 06:19:07,400 [INFO    ] __main__: train step 11927: loss: 1.0970, policy_loss: 1.0897, value_loss: 0.6621
2024-07-14 06:19:07,691 [INFO    ] __main__: train step 11928: loss: 1.0970, policy_loss: 1.0896, value_loss: 0.6621
2024-07-14 06:19:07,985 [INFO    ] __main__: train step 11929: loss: 1.0970, policy_loss: 1.0896, value_loss: 0.6620
2024-07-14 06:19:08,271 [INFO    ] __main__: train step 11930: loss: 1.0970, policy_loss: 1.0896, value_loss: 0.6620
2024-07-14 06:19:09,898 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:19:10,390 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:19:10,466 [INFO    ] __main__: train step 11931: loss: 1.0970, policy_loss: 1.0896, value_loss: 0.6619
2024-07-14 06:19:10,758 [INFO    ] __main__: train step 11932: loss: 1.0970, policy_loss: 1.0896, value_loss: 0.6619
2024-07-14 06:19:13,734 [INFO    ] __main__: train step 11933: loss: 1.0970, policy_loss: 1.0895, value_loss: 0.6619
2024-07-14 06:19:14,024 [INFO    ] __main__: train step 11934: loss: 1.0970, policy_loss: 1.0895, value_loss: 0.6618
2024-07-14 06:19:14,317 [INFO    ] __main__: train step 11935: loss: 1.0970, policy_loss: 1.0895, value_loss: 0.6618
2024-07-14 06:19:14,604 [INFO    ] __main__: train step 11936: loss: 1.0970, policy_loss: 1.0895, value_loss: 0.6618
2024-07-14 06:19:14,885 [INFO    ] __main__: train step 11937: loss: 1.0970, policy_loss: 1.0895, value_loss: 0.6617
2024-07-14 06:19:15,189 [INFO    ] __main__: train step 11938: loss: 1.0970, policy_loss: 1.0895, value_loss: 0.6617
2024-07-14 06:19:15,473 [INFO    ] __main__: train step 11939: loss: 1.0970, policy_loss: 1.0894, value_loss: 0.6617
2024-07-14 06:19:15,762 [INFO    ] __main__: train step 11940: loss: 1.0970, policy_loss: 1.0894, value_loss: 0.6616
2024-07-14 06:19:16,054 [INFO    ] __main__: train step 11941: loss: 1.0970, policy_loss: 1.0894, value_loss: 0.6616
2024-07-14 06:19:16,345 [INFO    ] __main__: train step 11942: loss: 1.0970, policy_loss: 1.0894, value_loss: 0.6616
2024-07-14 06:19:16,628 [INFO    ] __main__: train step 11943: loss: 1.0970, policy_loss: 1.0894, value_loss: 0.6615
2024-07-14 06:19:16,911 [INFO    ] __main__: train step 11944: loss: 1.0970, policy_loss: 1.0893, value_loss: 0.6615
2024-07-14 06:19:17,204 [INFO    ] __main__: train step 11945: loss: 1.0970, policy_loss: 1.0893, value_loss: 0.6615
2024-07-14 06:19:17,491 [INFO    ] __main__: train step 11946: loss: 1.0970, policy_loss: 1.0893, value_loss: 0.6614
2024-07-14 06:19:17,796 [INFO    ] __main__: train step 11947: loss: 1.0970, policy_loss: 1.0893, value_loss: 0.6614
2024-07-14 06:19:19,436 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:19:19,918 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:19:19,994 [INFO    ] __main__: train step 11948: loss: 1.0970, policy_loss: 1.0893, value_loss: 0.6614
2024-07-14 06:19:20,280 [INFO    ] __main__: train step 11949: loss: 1.0970, policy_loss: 1.0892, value_loss: 0.6613
2024-07-14 06:19:20,566 [INFO    ] __main__: train step 11950: loss: 1.0970, policy_loss: 1.0892, value_loss: 0.6613
2024-07-14 06:19:20,854 [INFO    ] __main__: train step 11951: loss: 1.0970, policy_loss: 1.0892, value_loss: 0.6613
2024-07-14 06:19:21,150 [INFO    ] __main__: train step 11952: loss: 1.0970, policy_loss: 1.0892, value_loss: 0.6612
2024-07-14 06:19:21,444 [INFO    ] __main__: train step 11953: loss: 1.0970, policy_loss: 1.0892, value_loss: 0.6612
2024-07-14 06:19:21,733 [INFO    ] __main__: train step 11954: loss: 1.0970, policy_loss: 1.0891, value_loss: 0.6611
2024-07-14 06:19:22,028 [INFO    ] __main__: train step 11955: loss: 1.0970, policy_loss: 1.0891, value_loss: 0.6611
2024-07-14 06:19:22,318 [INFO    ] __main__: train step 11956: loss: 1.0970, policy_loss: 1.0891, value_loss: 0.6611
2024-07-14 06:19:22,609 [INFO    ] __main__: train step 11957: loss: 1.0970, policy_loss: 1.0891, value_loss: 0.6610
2024-07-14 06:19:22,905 [INFO    ] __main__: train step 11958: loss: 1.0970, policy_loss: 1.0891, value_loss: 0.6610
2024-07-14 06:19:23,195 [INFO    ] __main__: train step 11959: loss: 1.0970, policy_loss: 1.0890, value_loss: 0.6610
2024-07-14 06:19:23,480 [INFO    ] __main__: train step 11960: loss: 1.0970, policy_loss: 1.0890, value_loss: 0.6609
2024-07-14 06:19:23,764 [INFO    ] __main__: train step 11961: loss: 1.0970, policy_loss: 1.0890, value_loss: 0.6609
2024-07-14 06:19:24,058 [INFO    ] __main__: train step 11962: loss: 1.0970, policy_loss: 1.0890, value_loss: 0.6609
2024-07-14 06:19:24,354 [INFO    ] __main__: train step 11963: loss: 1.0970, policy_loss: 1.0890, value_loss: 0.6608
2024-07-14 06:19:24,647 [INFO    ] __main__: train step 11964: loss: 1.0970, policy_loss: 1.0889, value_loss: 0.6608
2024-07-14 06:19:26,269 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:19:26,759 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:19:26,830 [INFO    ] __main__: train step 11965: loss: 1.0970, policy_loss: 1.0889, value_loss: 0.6608
2024-07-14 06:19:27,125 [INFO    ] __main__: train step 11966: loss: 1.0970, policy_loss: 1.0889, value_loss: 0.6607
2024-07-14 06:19:27,414 [INFO    ] __main__: train step 11967: loss: 1.0970, policy_loss: 1.0889, value_loss: 0.6607
2024-07-14 06:19:27,693 [INFO    ] __main__: train step 11968: loss: 1.0971, policy_loss: 1.0889, value_loss: 0.6607
2024-07-14 06:19:27,980 [INFO    ] __main__: train step 11969: loss: 1.0971, policy_loss: 1.0888, value_loss: 0.6606
2024-07-14 06:19:28,270 [INFO    ] __main__: train step 11970: loss: 1.0971, policy_loss: 1.0888, value_loss: 0.6606
2024-07-14 06:19:28,561 [INFO    ] __main__: train step 11971: loss: 1.0971, policy_loss: 1.0888, value_loss: 0.6606
2024-07-14 06:19:28,834 [INFO    ] __main__: train step 11972: loss: 1.0971, policy_loss: 1.0888, value_loss: 0.6605
2024-07-14 06:19:29,106 [INFO    ] __main__: train step 11973: loss: 1.0971, policy_loss: 1.0888, value_loss: 0.6605
2024-07-14 06:19:29,394 [INFO    ] __main__: train step 11974: loss: 1.0971, policy_loss: 1.0887, value_loss: 0.6605
2024-07-14 06:19:29,666 [INFO    ] __main__: train step 11975: loss: 1.0971, policy_loss: 1.0887, value_loss: 0.6604
2024-07-14 06:19:29,960 [INFO    ] __main__: train step 11976: loss: 1.0971, policy_loss: 1.0887, value_loss: 0.6604
2024-07-14 06:19:30,246 [INFO    ] __main__: train step 11977: loss: 1.0971, policy_loss: 1.0887, value_loss: 0.6604
2024-07-14 06:19:30,523 [INFO    ] __main__: train step 11978: loss: 1.0971, policy_loss: 1.0887, value_loss: 0.6603
2024-07-14 06:19:30,812 [INFO    ] __main__: train step 11979: loss: 1.0971, policy_loss: 1.0886, value_loss: 0.6603
2024-07-14 06:19:31,093 [INFO    ] __main__: train step 11980: loss: 1.0971, policy_loss: 1.0886, value_loss: 0.6603
2024-07-14 06:19:31,386 [INFO    ] __main__: train step 11981: loss: 1.0971, policy_loss: 1.0886, value_loss: 0.6602
2024-07-14 06:19:32,997 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:19:33,486 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:19:33,556 [INFO    ] __main__: train step 11982: loss: 1.0971, policy_loss: 1.0886, value_loss: 0.6602
2024-07-14 06:19:33,858 [INFO    ] __main__: train step 11983: loss: 1.0971, policy_loss: 1.0886, value_loss: 0.6601
2024-07-14 06:19:34,145 [INFO    ] __main__: train step 11984: loss: 1.0971, policy_loss: 1.0885, value_loss: 0.6601
2024-07-14 06:19:34,430 [INFO    ] __main__: train step 11985: loss: 1.0971, policy_loss: 1.0885, value_loss: 0.6601
2024-07-14 06:19:34,715 [INFO    ] __main__: train step 11986: loss: 1.0971, policy_loss: 1.0885, value_loss: 0.6600
2024-07-14 06:19:35,009 [INFO    ] __main__: train step 11987: loss: 1.0971, policy_loss: 1.0885, value_loss: 0.6600
2024-07-14 06:19:35,294 [INFO    ] __main__: train step 11988: loss: 1.0971, policy_loss: 1.0885, value_loss: 0.6600
2024-07-14 06:19:35,575 [INFO    ] __main__: train step 11989: loss: 1.0971, policy_loss: 1.0885, value_loss: 0.6599
2024-07-14 06:19:35,861 [INFO    ] __main__: train step 11990: loss: 1.0971, policy_loss: 1.0884, value_loss: 0.6599
2024-07-14 06:19:36,150 [INFO    ] __main__: train step 11991: loss: 1.0971, policy_loss: 1.0884, value_loss: 0.6599
2024-07-14 06:19:36,436 [INFO    ] __main__: train step 11992: loss: 1.0971, policy_loss: 1.0884, value_loss: 0.6598
2024-07-14 06:19:36,727 [INFO    ] __main__: train step 11993: loss: 1.0971, policy_loss: 1.0884, value_loss: 0.6598
2024-07-14 06:19:37,019 [INFO    ] __main__: train step 11994: loss: 1.0971, policy_loss: 1.0884, value_loss: 0.6598
2024-07-14 06:19:37,309 [INFO    ] __main__: train step 11995: loss: 1.0971, policy_loss: 1.0883, value_loss: 0.6597
2024-07-14 06:19:37,590 [INFO    ] __main__: train step 11996: loss: 1.0971, policy_loss: 1.0883, value_loss: 0.6597
2024-07-14 06:19:37,883 [INFO    ] __main__: train step 11997: loss: 1.0971, policy_loss: 1.0883, value_loss: 0.6597
2024-07-14 06:19:38,174 [INFO    ] __main__: train step 11998: loss: 1.0971, policy_loss: 1.0883, value_loss: 0.6596
2024-07-14 06:19:39,782 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:19:40,279 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:19:40,348 [INFO    ] __main__: train step 11999: loss: 1.0971, policy_loss: 1.0883, value_loss: 0.6596
2024-07-14 06:19:40,643 [INFO    ] __main__: train step 12000: loss: 1.0971, policy_loss: 1.0882, value_loss: 0.6596
2024-07-14 06:19:40,790 [INFO    ] __main__: restored step 11000 for evaluation
2024-07-14 06:19:46,036 [INFO    ] __main__: test network ELO difference from baseline network: +50 (+8/-8) ELO from 32000 self-played games
2024-07-14 06:19:46,039 [INFO    ] __main__: game outcomes: W: 17741, D: 199, L: 14060
2024-07-14 06:19:46,043 [INFO    ] __main__: validation_elo_delta: 50, validation_elo: 2344
2024-07-14 06:19:46,799 [INFO    ] __main__: train step 12001: loss: 1.0971, policy_loss: 1.0882, value_loss: 0.6595
2024-07-14 06:19:47,096 [INFO    ] __main__: train step 12002: loss: 1.0971, policy_loss: 1.0882, value_loss: 0.6595
2024-07-14 06:19:47,384 [INFO    ] __main__: train step 12003: loss: 1.0971, policy_loss: 1.0882, value_loss: 0.6595
2024-07-14 06:19:47,677 [INFO    ] __main__: train step 12004: loss: 1.0971, policy_loss: 1.0882, value_loss: 0.6594
2024-07-14 06:19:47,967 [INFO    ] __main__: train step 12005: loss: 1.0971, policy_loss: 1.0881, value_loss: 0.6594
2024-07-14 06:19:48,250 [INFO    ] __main__: train step 12006: loss: 1.0971, policy_loss: 1.0881, value_loss: 0.6593
2024-07-14 06:19:48,541 [INFO    ] __main__: train step 12007: loss: 1.0971, policy_loss: 1.0881, value_loss: 0.6593
2024-07-14 06:19:48,819 [INFO    ] __main__: train step 12008: loss: 1.0971, policy_loss: 1.0881, value_loss: 0.6593
2024-07-14 06:19:49,105 [INFO    ] __main__: train step 12009: loss: 1.0971, policy_loss: 1.0881, value_loss: 0.6592
2024-07-14 06:19:49,398 [INFO    ] __main__: train step 12010: loss: 1.0971, policy_loss: 1.0880, value_loss: 0.6592
2024-07-14 06:19:49,678 [INFO    ] __main__: train step 12011: loss: 1.0971, policy_loss: 1.0880, value_loss: 0.6592
2024-07-14 06:19:49,964 [INFO    ] __main__: train step 12012: loss: 1.0971, policy_loss: 1.0880, value_loss: 0.6591
2024-07-14 06:19:50,261 [INFO    ] __main__: train step 12013: loss: 1.0971, policy_loss: 1.0880, value_loss: 0.6591
2024-07-14 06:19:50,548 [INFO    ] __main__: train step 12014: loss: 1.0971, policy_loss: 1.0880, value_loss: 0.6591
2024-07-14 06:19:50,831 [INFO    ] __main__: train step 12015: loss: 1.0971, policy_loss: 1.0879, value_loss: 0.6590
2024-07-14 06:19:52,442 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:19:52,928 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:19:52,995 [INFO    ] __main__: train step 12016: loss: 1.0971, policy_loss: 1.0879, value_loss: 0.6590
2024-07-14 06:19:53,284 [INFO    ] __main__: train step 12017: loss: 1.0970, policy_loss: 1.0879, value_loss: 0.6590
2024-07-14 06:19:53,585 [INFO    ] __main__: train step 12018: loss: 1.0970, policy_loss: 1.0879, value_loss: 0.6589
2024-07-14 06:19:53,857 [INFO    ] __main__: train step 12019: loss: 1.0970, policy_loss: 1.0879, value_loss: 0.6589
2024-07-14 06:19:55,943 [INFO    ] __main__: train step 12020: loss: 1.0970, policy_loss: 1.0878, value_loss: 0.6589
2024-07-14 06:19:56,231 [INFO    ] __main__: train step 12021: loss: 1.0970, policy_loss: 1.0878, value_loss: 0.6588
2024-07-14 06:19:56,534 [INFO    ] __main__: train step 12022: loss: 1.0970, policy_loss: 1.0878, value_loss: 0.6588
2024-07-14 06:19:56,824 [INFO    ] __main__: train step 12023: loss: 1.0970, policy_loss: 1.0878, value_loss: 0.6588
2024-07-14 06:19:57,115 [INFO    ] __main__: train step 12024: loss: 1.0970, policy_loss: 1.0878, value_loss: 0.6587
2024-07-14 06:19:57,415 [INFO    ] __main__: train step 12025: loss: 1.0970, policy_loss: 1.0877, value_loss: 0.6587
2024-07-14 06:19:57,706 [INFO    ] __main__: train step 12026: loss: 1.0970, policy_loss: 1.0877, value_loss: 0.6587
2024-07-14 06:19:57,998 [INFO    ] __main__: train step 12027: loss: 1.0970, policy_loss: 1.0877, value_loss: 0.6586
2024-07-14 06:19:58,293 [INFO    ] __main__: train step 12028: loss: 1.0970, policy_loss: 1.0877, value_loss: 0.6586
2024-07-14 06:19:58,575 [INFO    ] __main__: train step 12029: loss: 1.0970, policy_loss: 1.0877, value_loss: 0.6585
2024-07-14 06:19:58,854 [INFO    ] __main__: train step 12030: loss: 1.0970, policy_loss: 1.0876, value_loss: 0.6585
2024-07-14 06:19:59,131 [INFO    ] __main__: train step 12031: loss: 1.0970, policy_loss: 1.0876, value_loss: 0.6585
2024-07-14 06:19:59,418 [INFO    ] __main__: train step 12032: loss: 1.0970, policy_loss: 1.0876, value_loss: 0.6584
2024-07-14 06:20:01,023 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:20:01,500 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:20:01,571 [INFO    ] __main__: train step 12033: loss: 1.0970, policy_loss: 1.0876, value_loss: 0.6584
2024-07-14 06:20:01,866 [INFO    ] __main__: train step 12034: loss: 1.0970, policy_loss: 1.0876, value_loss: 0.6584
2024-07-14 06:20:02,148 [INFO    ] __main__: train step 12035: loss: 1.0970, policy_loss: 1.0875, value_loss: 0.6583
2024-07-14 06:20:02,435 [INFO    ] __main__: train step 12036: loss: 1.0970, policy_loss: 1.0875, value_loss: 0.6583
2024-07-14 06:20:02,715 [INFO    ] __main__: train step 12037: loss: 1.0970, policy_loss: 1.0875, value_loss: 0.6583
2024-07-14 06:20:03,008 [INFO    ] __main__: train step 12038: loss: 1.0970, policy_loss: 1.0875, value_loss: 0.6582
2024-07-14 06:20:03,301 [INFO    ] __main__: train step 12039: loss: 1.0970, policy_loss: 1.0875, value_loss: 0.6582
2024-07-14 06:20:03,586 [INFO    ] __main__: train step 12040: loss: 1.0970, policy_loss: 1.0874, value_loss: 0.6582
2024-07-14 06:20:03,877 [INFO    ] __main__: train step 12041: loss: 1.0970, policy_loss: 1.0874, value_loss: 0.6581
2024-07-14 06:20:04,167 [INFO    ] __main__: train step 12042: loss: 1.0970, policy_loss: 1.0874, value_loss: 0.6581
2024-07-14 06:20:04,460 [INFO    ] __main__: train step 12043: loss: 1.0970, policy_loss: 1.0874, value_loss: 0.6581
2024-07-14 06:20:04,745 [INFO    ] __main__: train step 12044: loss: 1.0970, policy_loss: 1.0874, value_loss: 0.6580
2024-07-14 06:20:05,046 [INFO    ] __main__: train step 12045: loss: 1.0970, policy_loss: 1.0873, value_loss: 0.6580
2024-07-14 06:20:05,343 [INFO    ] __main__: train step 12046: loss: 1.0970, policy_loss: 1.0873, value_loss: 0.6580
2024-07-14 06:20:05,625 [INFO    ] __main__: train step 12047: loss: 1.0970, policy_loss: 1.0873, value_loss: 0.6579
2024-07-14 06:20:05,914 [INFO    ] __main__: train step 12048: loss: 1.0970, policy_loss: 1.0873, value_loss: 0.6579
2024-07-14 06:20:06,202 [INFO    ] __main__: train step 12049: loss: 1.0970, policy_loss: 1.0873, value_loss: 0.6579
2024-07-14 06:20:07,802 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:20:08,288 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:20:08,357 [INFO    ] __main__: train step 12050: loss: 1.0970, policy_loss: 1.0872, value_loss: 0.6578
2024-07-14 06:20:08,644 [INFO    ] __main__: train step 12051: loss: 1.0970, policy_loss: 1.0872, value_loss: 0.6578
2024-07-14 06:20:08,949 [INFO    ] __main__: train step 12052: loss: 1.0970, policy_loss: 1.0872, value_loss: 0.6578
2024-07-14 06:20:09,229 [INFO    ] __main__: train step 12053: loss: 1.0970, policy_loss: 1.0872, value_loss: 0.6577
2024-07-14 06:20:09,501 [INFO    ] __main__: train step 12054: loss: 1.0970, policy_loss: 1.0872, value_loss: 0.6577
2024-07-14 06:20:09,792 [INFO    ] __main__: train step 12055: loss: 1.0970, policy_loss: 1.0871, value_loss: 0.6576
2024-07-14 06:20:10,086 [INFO    ] __main__: train step 12056: loss: 1.0970, policy_loss: 1.0871, value_loss: 0.6576
2024-07-14 06:20:10,376 [INFO    ] __main__: train step 12057: loss: 1.0970, policy_loss: 1.0871, value_loss: 0.6576
2024-07-14 06:20:10,670 [INFO    ] __main__: train step 12058: loss: 1.0970, policy_loss: 1.0871, value_loss: 0.6575
2024-07-14 06:20:10,958 [INFO    ] __main__: train step 12059: loss: 1.0970, policy_loss: 1.0871, value_loss: 0.6575
2024-07-14 06:20:11,245 [INFO    ] __main__: train step 12060: loss: 1.0970, policy_loss: 1.0870, value_loss: 0.6575
2024-07-14 06:20:11,530 [INFO    ] __main__: train step 12061: loss: 1.0970, policy_loss: 1.0870, value_loss: 0.6574
2024-07-14 06:20:11,829 [INFO    ] __main__: train step 12062: loss: 1.0970, policy_loss: 1.0870, value_loss: 0.6574
2024-07-14 06:20:12,132 [INFO    ] __main__: train step 12063: loss: 1.0970, policy_loss: 1.0870, value_loss: 0.6574
2024-07-14 06:20:12,415 [INFO    ] __main__: train step 12064: loss: 1.0970, policy_loss: 1.0870, value_loss: 0.6573
2024-07-14 06:20:12,700 [INFO    ] __main__: train step 12065: loss: 1.0970, policy_loss: 1.0869, value_loss: 0.6573
2024-07-14 06:20:12,992 [INFO    ] __main__: train step 12066: loss: 1.0970, policy_loss: 1.0869, value_loss: 0.6573
2024-07-14 06:20:14,607 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:20:15,108 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:20:15,176 [INFO    ] __main__: train step 12067: loss: 1.0970, policy_loss: 1.0869, value_loss: 0.6572
2024-07-14 06:20:15,462 [INFO    ] __main__: train step 12068: loss: 1.0970, policy_loss: 1.0869, value_loss: 0.6572
2024-07-14 06:20:15,749 [INFO    ] __main__: train step 12069: loss: 1.0970, policy_loss: 1.0869, value_loss: 0.6572
2024-07-14 06:20:16,044 [INFO    ] __main__: train step 12070: loss: 1.0970, policy_loss: 1.0868, value_loss: 0.6571
2024-07-14 06:20:16,321 [INFO    ] __main__: train step 12071: loss: 1.0970, policy_loss: 1.0868, value_loss: 0.6571
2024-07-14 06:20:16,620 [INFO    ] __main__: train step 12072: loss: 1.0970, policy_loss: 1.0868, value_loss: 0.6571
2024-07-14 06:20:16,920 [INFO    ] __main__: train step 12073: loss: 1.0970, policy_loss: 1.0868, value_loss: 0.6570
2024-07-14 06:20:17,204 [INFO    ] __main__: train step 12074: loss: 1.0970, policy_loss: 1.0868, value_loss: 0.6570
2024-07-14 06:20:17,500 [INFO    ] __main__: train step 12075: loss: 1.0970, policy_loss: 1.0867, value_loss: 0.6570
2024-07-14 06:20:17,783 [INFO    ] __main__: train step 12076: loss: 1.0970, policy_loss: 1.0867, value_loss: 0.6569
2024-07-14 06:20:18,080 [INFO    ] __main__: train step 12077: loss: 1.0970, policy_loss: 1.0867, value_loss: 0.6569
2024-07-14 06:20:18,377 [INFO    ] __main__: train step 12078: loss: 1.0970, policy_loss: 1.0867, value_loss: 0.6569
2024-07-14 06:20:18,659 [INFO    ] __main__: train step 12079: loss: 1.0970, policy_loss: 1.0867, value_loss: 0.6568
2024-07-14 06:20:18,952 [INFO    ] __main__: train step 12080: loss: 1.0970, policy_loss: 1.0866, value_loss: 0.6568
2024-07-14 06:20:19,245 [INFO    ] __main__: train step 12081: loss: 1.0970, policy_loss: 1.0866, value_loss: 0.6568
2024-07-14 06:20:19,526 [INFO    ] __main__: train step 12082: loss: 1.0970, policy_loss: 1.0866, value_loss: 0.6567
2024-07-14 06:20:19,807 [INFO    ] __main__: train step 12083: loss: 1.0970, policy_loss: 1.0866, value_loss: 0.6567
2024-07-14 06:20:21,420 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:20:21,896 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:20:21,967 [INFO    ] __main__: train step 12084: loss: 1.0970, policy_loss: 1.0866, value_loss: 0.6566
2024-07-14 06:20:22,265 [INFO    ] __main__: train step 12085: loss: 1.0970, policy_loss: 1.0865, value_loss: 0.6566
2024-07-14 06:20:22,540 [INFO    ] __main__: train step 12086: loss: 1.0970, policy_loss: 1.0865, value_loss: 0.6566
2024-07-14 06:20:22,831 [INFO    ] __main__: train step 12087: loss: 1.0970, policy_loss: 1.0865, value_loss: 0.6565
2024-07-14 06:20:23,123 [INFO    ] __main__: train step 12088: loss: 1.0970, policy_loss: 1.0865, value_loss: 0.6565
2024-07-14 06:20:23,408 [INFO    ] __main__: train step 12089: loss: 1.0970, policy_loss: 1.0865, value_loss: 0.6565
2024-07-14 06:20:23,691 [INFO    ] __main__: train step 12090: loss: 1.0970, policy_loss: 1.0864, value_loss: 0.6564
2024-07-14 06:20:23,971 [INFO    ] __main__: train step 12091: loss: 1.0970, policy_loss: 1.0864, value_loss: 0.6564
2024-07-14 06:20:24,254 [INFO    ] __main__: train step 12092: loss: 1.0970, policy_loss: 1.0864, value_loss: 0.6564
2024-07-14 06:20:24,540 [INFO    ] __main__: train step 12093: loss: 1.0970, policy_loss: 1.0864, value_loss: 0.6563
2024-07-14 06:20:24,836 [INFO    ] __main__: train step 12094: loss: 1.0970, policy_loss: 1.0864, value_loss: 0.6563
2024-07-14 06:20:25,117 [INFO    ] __main__: train step 12095: loss: 1.0970, policy_loss: 1.0863, value_loss: 0.6563
2024-07-14 06:20:25,401 [INFO    ] __main__: train step 12096: loss: 1.0970, policy_loss: 1.0863, value_loss: 0.6562
2024-07-14 06:20:25,696 [INFO    ] __main__: train step 12097: loss: 1.0970, policy_loss: 1.0863, value_loss: 0.6562
2024-07-14 06:20:26,001 [INFO    ] __main__: train step 12098: loss: 1.0970, policy_loss: 1.0863, value_loss: 0.6562
2024-07-14 06:20:26,289 [INFO    ] __main__: train step 12099: loss: 1.0970, policy_loss: 1.0863, value_loss: 0.6561
2024-07-14 06:20:26,572 [INFO    ] __main__: train step 12100: loss: 1.0970, policy_loss: 1.0862, value_loss: 0.6561
2024-07-14 06:20:28,176 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:20:28,660 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:20:28,728 [INFO    ] __main__: train step 12101: loss: 1.0970, policy_loss: 1.0862, value_loss: 0.6561
2024-07-14 06:20:29,011 [INFO    ] __main__: train step 12102: loss: 1.0970, policy_loss: 1.0862, value_loss: 0.6560
2024-07-14 06:20:29,297 [INFO    ] __main__: train step 12103: loss: 1.0970, policy_loss: 1.0862, value_loss: 0.6560
2024-07-14 06:20:29,579 [INFO    ] __main__: train step 12104: loss: 1.0970, policy_loss: 1.0862, value_loss: 0.6559
2024-07-14 06:20:29,866 [INFO    ] __main__: train step 12105: loss: 1.0970, policy_loss: 1.0861, value_loss: 0.6559
2024-07-14 06:20:30,156 [INFO    ] __main__: train step 12106: loss: 1.0970, policy_loss: 1.0861, value_loss: 0.6559
2024-07-14 06:20:30,448 [INFO    ] __main__: train step 12107: loss: 1.0970, policy_loss: 1.0861, value_loss: 0.6558
2024-07-14 06:20:32,511 [INFO    ] __main__: train step 12108: loss: 1.0970, policy_loss: 1.0861, value_loss: 0.6558
2024-07-14 06:20:32,798 [INFO    ] __main__: train step 12109: loss: 1.0969, policy_loss: 1.0861, value_loss: 0.6558
2024-07-14 06:20:33,080 [INFO    ] __main__: train step 12110: loss: 1.0969, policy_loss: 1.0860, value_loss: 0.6557
2024-07-14 06:20:33,359 [INFO    ] __main__: train step 12111: loss: 1.0969, policy_loss: 1.0860, value_loss: 0.6557
2024-07-14 06:20:33,635 [INFO    ] __main__: train step 12112: loss: 1.0969, policy_loss: 1.0860, value_loss: 0.6557
2024-07-14 06:20:33,928 [INFO    ] __main__: train step 12113: loss: 1.0969, policy_loss: 1.0860, value_loss: 0.6556
2024-07-14 06:20:34,201 [INFO    ] __main__: train step 12114: loss: 1.0969, policy_loss: 1.0860, value_loss: 0.6556
2024-07-14 06:20:34,472 [INFO    ] __main__: train step 12115: loss: 1.0969, policy_loss: 1.0859, value_loss: 0.6556
2024-07-14 06:20:34,748 [INFO    ] __main__: train step 12116: loss: 1.0969, policy_loss: 1.0859, value_loss: 0.6555
2024-07-14 06:20:35,037 [INFO    ] __main__: train step 12117: loss: 1.0969, policy_loss: 1.0859, value_loss: 0.6555
2024-07-14 06:20:36,649 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:20:37,132 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:20:37,204 [INFO    ] __main__: train step 12118: loss: 1.0969, policy_loss: 1.0859, value_loss: 0.6555
2024-07-14 06:20:37,476 [INFO    ] __main__: train step 12119: loss: 1.0969, policy_loss: 1.0859, value_loss: 0.6554
2024-07-14 06:20:37,753 [INFO    ] __main__: train step 12120: loss: 1.0969, policy_loss: 1.0858, value_loss: 0.6554
2024-07-14 06:20:38,034 [INFO    ] __main__: train step 12121: loss: 1.0969, policy_loss: 1.0858, value_loss: 0.6554
2024-07-14 06:20:38,319 [INFO    ] __main__: train step 12122: loss: 1.0969, policy_loss: 1.0858, value_loss: 0.6553
2024-07-14 06:20:38,602 [INFO    ] __main__: train step 12123: loss: 1.0969, policy_loss: 1.0858, value_loss: 0.6553
2024-07-14 06:20:38,887 [INFO    ] __main__: train step 12124: loss: 1.0969, policy_loss: 1.0858, value_loss: 0.6553
2024-07-14 06:20:39,163 [INFO    ] __main__: train step 12125: loss: 1.0969, policy_loss: 1.0857, value_loss: 0.6552
2024-07-14 06:20:39,455 [INFO    ] __main__: train step 12126: loss: 1.0969, policy_loss: 1.0857, value_loss: 0.6552
2024-07-14 06:20:39,751 [INFO    ] __main__: train step 12127: loss: 1.0969, policy_loss: 1.0857, value_loss: 0.6551
2024-07-14 06:20:40,039 [INFO    ] __main__: train step 12128: loss: 1.0969, policy_loss: 1.0857, value_loss: 0.6551
2024-07-14 06:20:40,325 [INFO    ] __main__: train step 12129: loss: 1.0969, policy_loss: 1.0857, value_loss: 0.6551
2024-07-14 06:20:40,596 [INFO    ] __main__: train step 12130: loss: 1.0969, policy_loss: 1.0856, value_loss: 0.6550
2024-07-14 06:20:40,880 [INFO    ] __main__: train step 12131: loss: 1.0969, policy_loss: 1.0856, value_loss: 0.6550
2024-07-14 06:20:41,167 [INFO    ] __main__: train step 12132: loss: 1.0969, policy_loss: 1.0856, value_loss: 0.6550
2024-07-14 06:20:41,450 [INFO    ] __main__: train step 12133: loss: 1.0969, policy_loss: 1.0856, value_loss: 0.6549
2024-07-14 06:20:41,747 [INFO    ] __main__: train step 12134: loss: 1.0969, policy_loss: 1.0856, value_loss: 0.6549
2024-07-14 06:20:43,338 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:20:43,833 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:20:43,902 [INFO    ] __main__: train step 12135: loss: 1.0969, policy_loss: 1.0855, value_loss: 0.6549
2024-07-14 06:20:44,180 [INFO    ] __main__: train step 12136: loss: 1.0969, policy_loss: 1.0855, value_loss: 0.6548
2024-07-14 06:20:44,472 [INFO    ] __main__: train step 12137: loss: 1.0969, policy_loss: 1.0855, value_loss: 0.6548
2024-07-14 06:20:44,763 [INFO    ] __main__: train step 12138: loss: 1.0969, policy_loss: 1.0855, value_loss: 0.6548
2024-07-14 06:20:45,062 [INFO    ] __main__: train step 12139: loss: 1.0969, policy_loss: 1.0855, value_loss: 0.6547
2024-07-14 06:20:45,349 [INFO    ] __main__: train step 12140: loss: 1.0969, policy_loss: 1.0854, value_loss: 0.6547
2024-07-14 06:20:45,640 [INFO    ] __main__: train step 12141: loss: 1.0969, policy_loss: 1.0854, value_loss: 0.6547
2024-07-14 06:20:45,946 [INFO    ] __main__: train step 12142: loss: 1.0969, policy_loss: 1.0854, value_loss: 0.6546
2024-07-14 06:20:46,240 [INFO    ] __main__: train step 12143: loss: 1.0969, policy_loss: 1.0854, value_loss: 0.6546
2024-07-14 06:20:46,564 [INFO    ] __main__: train step 12144: loss: 1.0969, policy_loss: 1.0854, value_loss: 0.6546
2024-07-14 06:20:46,852 [INFO    ] __main__: train step 12145: loss: 1.0969, policy_loss: 1.0853, value_loss: 0.6545
2024-07-14 06:20:47,128 [INFO    ] __main__: train step 12146: loss: 1.0969, policy_loss: 1.0853, value_loss: 0.6545
2024-07-14 06:20:47,423 [INFO    ] __main__: train step 12147: loss: 1.0969, policy_loss: 1.0853, value_loss: 0.6545
2024-07-14 06:20:47,701 [INFO    ] __main__: train step 12148: loss: 1.0969, policy_loss: 1.0853, value_loss: 0.6544
2024-07-14 06:20:47,997 [INFO    ] __main__: train step 12149: loss: 1.0969, policy_loss: 1.0853, value_loss: 0.6544
2024-07-14 06:20:48,282 [INFO    ] __main__: train step 12150: loss: 1.0969, policy_loss: 1.0852, value_loss: 0.6544
2024-07-14 06:20:48,569 [INFO    ] __main__: train step 12151: loss: 1.0969, policy_loss: 1.0852, value_loss: 0.6543
2024-07-14 06:20:50,171 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:20:50,660 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:20:50,733 [INFO    ] __main__: train step 12152: loss: 1.0969, policy_loss: 1.0852, value_loss: 0.6543
2024-07-14 06:20:51,022 [INFO    ] __main__: train step 12153: loss: 1.0969, policy_loss: 1.0852, value_loss: 0.6543
2024-07-14 06:20:51,304 [INFO    ] __main__: train step 12154: loss: 1.0969, policy_loss: 1.0851, value_loss: 0.6542
2024-07-14 06:20:51,582 [INFO    ] __main__: train step 12155: loss: 1.0969, policy_loss: 1.0851, value_loss: 0.6542
2024-07-14 06:20:51,856 [INFO    ] __main__: train step 12156: loss: 1.0969, policy_loss: 1.0851, value_loss: 0.6541
2024-07-14 06:20:52,142 [INFO    ] __main__: train step 12157: loss: 1.0969, policy_loss: 1.0851, value_loss: 0.6541
2024-07-14 06:20:52,427 [INFO    ] __main__: train step 12158: loss: 1.0969, policy_loss: 1.0851, value_loss: 0.6541
2024-07-14 06:20:52,715 [INFO    ] __main__: train step 12159: loss: 1.0969, policy_loss: 1.0850, value_loss: 0.6540
2024-07-14 06:20:52,998 [INFO    ] __main__: train step 12160: loss: 1.0969, policy_loss: 1.0850, value_loss: 0.6540
2024-07-14 06:20:53,284 [INFO    ] __main__: train step 12161: loss: 1.0969, policy_loss: 1.0850, value_loss: 0.6540
2024-07-14 06:20:53,570 [INFO    ] __main__: train step 12162: loss: 1.0969, policy_loss: 1.0850, value_loss: 0.6539
2024-07-14 06:20:53,860 [INFO    ] __main__: train step 12163: loss: 1.0968, policy_loss: 1.0850, value_loss: 0.6539
2024-07-14 06:20:54,143 [INFO    ] __main__: train step 12164: loss: 1.0968, policy_loss: 1.0849, value_loss: 0.6539
2024-07-14 06:20:54,431 [INFO    ] __main__: train step 12165: loss: 1.0968, policy_loss: 1.0849, value_loss: 0.6538
2024-07-14 06:20:54,704 [INFO    ] __main__: train step 12166: loss: 1.0968, policy_loss: 1.0849, value_loss: 0.6538
2024-07-14 06:20:54,991 [INFO    ] __main__: train step 12167: loss: 1.0968, policy_loss: 1.0849, value_loss: 0.6538
2024-07-14 06:20:55,277 [INFO    ] __main__: train step 12168: loss: 1.0968, policy_loss: 1.0849, value_loss: 0.6537
2024-07-14 06:20:56,897 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:20:57,393 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:20:57,461 [INFO    ] __main__: train step 12169: loss: 1.0968, policy_loss: 1.0848, value_loss: 0.6537
2024-07-14 06:20:57,744 [INFO    ] __main__: train step 12170: loss: 1.0968, policy_loss: 1.0848, value_loss: 0.6537
2024-07-14 06:20:58,037 [INFO    ] __main__: train step 12171: loss: 1.0968, policy_loss: 1.0848, value_loss: 0.6536
2024-07-14 06:20:58,322 [INFO    ] __main__: train step 12172: loss: 1.0968, policy_loss: 1.0848, value_loss: 0.6536
2024-07-14 06:20:58,608 [INFO    ] __main__: train step 12173: loss: 1.0968, policy_loss: 1.0848, value_loss: 0.6536
2024-07-14 06:20:58,895 [INFO    ] __main__: train step 12174: loss: 1.0968, policy_loss: 1.0847, value_loss: 0.6535
2024-07-14 06:20:59,170 [INFO    ] __main__: train step 12175: loss: 1.0968, policy_loss: 1.0847, value_loss: 0.6535
2024-07-14 06:20:59,451 [INFO    ] __main__: train step 12176: loss: 1.0968, policy_loss: 1.0847, value_loss: 0.6535
2024-07-14 06:20:59,745 [INFO    ] __main__: train step 12177: loss: 1.0968, policy_loss: 1.0847, value_loss: 0.6534
2024-07-14 06:21:00,044 [INFO    ] __main__: train step 12178: loss: 1.0968, policy_loss: 1.0847, value_loss: 0.6534
2024-07-14 06:21:00,332 [INFO    ] __main__: train step 12179: loss: 1.0968, policy_loss: 1.0846, value_loss: 0.6534
2024-07-14 06:21:00,627 [INFO    ] __main__: train step 12180: loss: 1.0968, policy_loss: 1.0846, value_loss: 0.6533
2024-07-14 06:21:00,921 [INFO    ] __main__: train step 12181: loss: 1.0968, policy_loss: 1.0846, value_loss: 0.6533
2024-07-14 06:21:01,209 [INFO    ] __main__: train step 12182: loss: 1.0968, policy_loss: 1.0846, value_loss: 0.6532
2024-07-14 06:21:01,499 [INFO    ] __main__: train step 12183: loss: 1.0968, policy_loss: 1.0846, value_loss: 0.6532
2024-07-14 06:21:01,789 [INFO    ] __main__: train step 12184: loss: 1.0968, policy_loss: 1.0845, value_loss: 0.6532
2024-07-14 06:21:02,082 [INFO    ] __main__: train step 12185: loss: 1.0968, policy_loss: 1.0845, value_loss: 0.6531
2024-07-14 06:21:03,706 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:21:04,205 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:21:04,276 [INFO    ] __main__: train step 12186: loss: 1.0968, policy_loss: 1.0845, value_loss: 0.6531
2024-07-14 06:21:04,569 [INFO    ] __main__: train step 12187: loss: 1.0968, policy_loss: 1.0845, value_loss: 0.6531
2024-07-14 06:21:04,857 [INFO    ] __main__: train step 12188: loss: 1.0968, policy_loss: 1.0845, value_loss: 0.6530
2024-07-14 06:21:05,145 [INFO    ] __main__: train step 12189: loss: 1.0968, policy_loss: 1.0844, value_loss: 0.6530
2024-07-14 06:21:05,424 [INFO    ] __main__: train step 12190: loss: 1.0968, policy_loss: 1.0844, value_loss: 0.6530
2024-07-14 06:21:05,707 [INFO    ] __main__: train step 12191: loss: 1.0968, policy_loss: 1.0844, value_loss: 0.6529
2024-07-14 06:21:06,003 [INFO    ] __main__: train step 12192: loss: 1.0968, policy_loss: 1.0844, value_loss: 0.6529
2024-07-14 06:21:06,302 [INFO    ] __main__: train step 12193: loss: 1.0968, policy_loss: 1.0844, value_loss: 0.6529
2024-07-14 06:21:06,593 [INFO    ] __main__: train step 12194: loss: 1.0968, policy_loss: 1.0843, value_loss: 0.6528
2024-07-14 06:21:06,869 [INFO    ] __main__: train step 12195: loss: 1.0968, policy_loss: 1.0843, value_loss: 0.6528
2024-07-14 06:21:09,618 [INFO    ] __main__: train step 12196: loss: 1.0968, policy_loss: 1.0843, value_loss: 0.6528
2024-07-14 06:21:09,912 [INFO    ] __main__: train step 12197: loss: 1.0968, policy_loss: 1.0843, value_loss: 0.6527
2024-07-14 06:21:10,200 [INFO    ] __main__: train step 12198: loss: 1.0968, policy_loss: 1.0843, value_loss: 0.6527
2024-07-14 06:21:10,487 [INFO    ] __main__: train step 12199: loss: 1.0968, policy_loss: 1.0842, value_loss: 0.6527
2024-07-14 06:21:10,779 [INFO    ] __main__: train step 12200: loss: 1.0968, policy_loss: 1.0842, value_loss: 0.6526
2024-07-14 06:21:11,076 [INFO    ] __main__: train step 12201: loss: 1.0968, policy_loss: 1.0842, value_loss: 0.6526
2024-07-14 06:21:11,370 [INFO    ] __main__: train step 12202: loss: 1.0968, policy_loss: 1.0842, value_loss: 0.6525
2024-07-14 06:21:12,989 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:21:13,473 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:21:13,549 [INFO    ] __main__: train step 12203: loss: 1.0967, policy_loss: 1.0842, value_loss: 0.6525
2024-07-14 06:21:13,839 [INFO    ] __main__: train step 12204: loss: 1.0967, policy_loss: 1.0841, value_loss: 0.6525
2024-07-14 06:21:14,121 [INFO    ] __main__: train step 12205: loss: 1.0967, policy_loss: 1.0841, value_loss: 0.6524
2024-07-14 06:21:14,412 [INFO    ] __main__: train step 12206: loss: 1.0967, policy_loss: 1.0841, value_loss: 0.6524
2024-07-14 06:21:14,698 [INFO    ] __main__: train step 12207: loss: 1.0967, policy_loss: 1.0841, value_loss: 0.6524
2024-07-14 06:21:14,991 [INFO    ] __main__: train step 12208: loss: 1.0967, policy_loss: 1.0840, value_loss: 0.6523
2024-07-14 06:21:15,278 [INFO    ] __main__: train step 12209: loss: 1.0967, policy_loss: 1.0840, value_loss: 0.6523
2024-07-14 06:21:15,564 [INFO    ] __main__: train step 12210: loss: 1.0967, policy_loss: 1.0840, value_loss: 0.6523
2024-07-14 06:21:15,853 [INFO    ] __main__: train step 12211: loss: 1.0967, policy_loss: 1.0840, value_loss: 0.6522
2024-07-14 06:21:16,145 [INFO    ] __main__: train step 12212: loss: 1.0967, policy_loss: 1.0840, value_loss: 0.6522
2024-07-14 06:21:16,431 [INFO    ] __main__: train step 12213: loss: 1.0967, policy_loss: 1.0839, value_loss: 0.6522
2024-07-14 06:21:16,726 [INFO    ] __main__: train step 12214: loss: 1.0967, policy_loss: 1.0839, value_loss: 0.6521
2024-07-14 06:21:17,004 [INFO    ] __main__: train step 12215: loss: 1.0967, policy_loss: 1.0839, value_loss: 0.6521
2024-07-14 06:21:17,279 [INFO    ] __main__: train step 12216: loss: 1.0967, policy_loss: 1.0839, value_loss: 0.6521
2024-07-14 06:21:17,563 [INFO    ] __main__: train step 12217: loss: 1.0967, policy_loss: 1.0839, value_loss: 0.6520
2024-07-14 06:21:17,848 [INFO    ] __main__: train step 12218: loss: 1.0967, policy_loss: 1.0838, value_loss: 0.6520
2024-07-14 06:21:18,153 [INFO    ] __main__: train step 12219: loss: 1.0967, policy_loss: 1.0838, value_loss: 0.6519
2024-07-14 06:21:19,761 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:21:20,250 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:21:20,323 [INFO    ] __main__: train step 12220: loss: 1.0967, policy_loss: 1.0838, value_loss: 0.6519
2024-07-14 06:21:20,608 [INFO    ] __main__: train step 12221: loss: 1.0967, policy_loss: 1.0838, value_loss: 0.6519
2024-07-14 06:21:20,908 [INFO    ] __main__: train step 12222: loss: 1.0967, policy_loss: 1.0838, value_loss: 0.6518
2024-07-14 06:21:21,197 [INFO    ] __main__: train step 12223: loss: 1.0967, policy_loss: 1.0837, value_loss: 0.6518
2024-07-14 06:21:21,472 [INFO    ] __main__: train step 12224: loss: 1.0967, policy_loss: 1.0837, value_loss: 0.6518
2024-07-14 06:21:21,763 [INFO    ] __main__: train step 12225: loss: 1.0967, policy_loss: 1.0837, value_loss: 0.6517
2024-07-14 06:21:22,056 [INFO    ] __main__: train step 12226: loss: 1.0967, policy_loss: 1.0837, value_loss: 0.6517
2024-07-14 06:21:22,346 [INFO    ] __main__: train step 12227: loss: 1.0967, policy_loss: 1.0837, value_loss: 0.6517
2024-07-14 06:21:22,632 [INFO    ] __main__: train step 12228: loss: 1.0967, policy_loss: 1.0836, value_loss: 0.6516
2024-07-14 06:21:22,925 [INFO    ] __main__: train step 12229: loss: 1.0967, policy_loss: 1.0836, value_loss: 0.6516
2024-07-14 06:21:23,206 [INFO    ] __main__: train step 12230: loss: 1.0967, policy_loss: 1.0836, value_loss: 0.6516
2024-07-14 06:21:23,509 [INFO    ] __main__: train step 12231: loss: 1.0967, policy_loss: 1.0836, value_loss: 0.6515
2024-07-14 06:21:23,804 [INFO    ] __main__: train step 12232: loss: 1.0967, policy_loss: 1.0836, value_loss: 0.6515
2024-07-14 06:21:24,101 [INFO    ] __main__: train step 12233: loss: 1.0966, policy_loss: 1.0835, value_loss: 0.6515
2024-07-14 06:21:24,397 [INFO    ] __main__: train step 12234: loss: 1.0966, policy_loss: 1.0835, value_loss: 0.6514
2024-07-14 06:21:24,681 [INFO    ] __main__: train step 12235: loss: 1.0966, policy_loss: 1.0835, value_loss: 0.6514
2024-07-14 06:21:24,972 [INFO    ] __main__: train step 12236: loss: 1.0966, policy_loss: 1.0835, value_loss: 0.6513
2024-07-14 06:21:26,593 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:21:27,084 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:21:27,156 [INFO    ] __main__: train step 12237: loss: 1.0966, policy_loss: 1.0835, value_loss: 0.6513
2024-07-14 06:21:27,448 [INFO    ] __main__: train step 12238: loss: 1.0966, policy_loss: 1.0834, value_loss: 0.6513
2024-07-14 06:21:27,734 [INFO    ] __main__: train step 12239: loss: 1.0966, policy_loss: 1.0834, value_loss: 0.6512
2024-07-14 06:21:28,031 [INFO    ] __main__: train step 12240: loss: 1.0966, policy_loss: 1.0834, value_loss: 0.6512
2024-07-14 06:21:28,336 [INFO    ] __main__: train step 12241: loss: 1.0966, policy_loss: 1.0834, value_loss: 0.6512
2024-07-14 06:21:28,629 [INFO    ] __main__: train step 12242: loss: 1.0966, policy_loss: 1.0834, value_loss: 0.6511
2024-07-14 06:21:28,909 [INFO    ] __main__: train step 12243: loss: 1.0966, policy_loss: 1.0833, value_loss: 0.6511
2024-07-14 06:21:29,178 [INFO    ] __main__: train step 12244: loss: 1.0966, policy_loss: 1.0833, value_loss: 0.6511
2024-07-14 06:21:29,438 [INFO    ] __main__: train step 12245: loss: 1.0966, policy_loss: 1.0833, value_loss: 0.6510
2024-07-14 06:21:29,695 [INFO    ] __main__: train step 12246: loss: 1.0966, policy_loss: 1.0833, value_loss: 0.6510
2024-07-14 06:21:29,965 [INFO    ] __main__: train step 12247: loss: 1.0966, policy_loss: 1.0833, value_loss: 0.6510
2024-07-14 06:21:30,232 [INFO    ] __main__: train step 12248: loss: 1.0966, policy_loss: 1.0832, value_loss: 0.6509
2024-07-14 06:21:30,527 [INFO    ] __main__: train step 12249: loss: 1.0966, policy_loss: 1.0832, value_loss: 0.6509
2024-07-14 06:21:30,814 [INFO    ] __main__: train step 12250: loss: 1.0966, policy_loss: 1.0832, value_loss: 0.6509
2024-07-14 06:21:31,107 [INFO    ] __main__: train step 12251: loss: 1.0966, policy_loss: 1.0832, value_loss: 0.6508
2024-07-14 06:21:31,402 [INFO    ] __main__: train step 12252: loss: 1.0966, policy_loss: 1.0832, value_loss: 0.6508
2024-07-14 06:21:31,694 [INFO    ] __main__: train step 12253: loss: 1.0966, policy_loss: 1.0831, value_loss: 0.6508
2024-07-14 06:21:33,313 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:21:33,803 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:21:33,873 [INFO    ] __main__: train step 12254: loss: 1.0966, policy_loss: 1.0831, value_loss: 0.6507
2024-07-14 06:21:34,165 [INFO    ] __main__: train step 12255: loss: 1.0966, policy_loss: 1.0831, value_loss: 0.6507
2024-07-14 06:21:34,453 [INFO    ] __main__: train step 12256: loss: 1.0966, policy_loss: 1.0831, value_loss: 0.6507
2024-07-14 06:21:34,742 [INFO    ] __main__: train step 12257: loss: 1.0966, policy_loss: 1.0831, value_loss: 0.6506
2024-07-14 06:21:35,022 [INFO    ] __main__: train step 12258: loss: 1.0966, policy_loss: 1.0830, value_loss: 0.6506
2024-07-14 06:21:35,307 [INFO    ] __main__: train step 12259: loss: 1.0966, policy_loss: 1.0830, value_loss: 0.6506
2024-07-14 06:21:35,592 [INFO    ] __main__: train step 12260: loss: 1.0966, policy_loss: 1.0830, value_loss: 0.6505
2024-07-14 06:21:35,875 [INFO    ] __main__: train step 12261: loss: 1.0966, policy_loss: 1.0830, value_loss: 0.6505
2024-07-14 06:21:36,173 [INFO    ] __main__: train step 12262: loss: 1.0966, policy_loss: 1.0829, value_loss: 0.6504
2024-07-14 06:21:36,458 [INFO    ] __main__: train step 12263: loss: 1.0966, policy_loss: 1.0829, value_loss: 0.6504
2024-07-14 06:21:36,731 [INFO    ] __main__: train step 12264: loss: 1.0966, policy_loss: 1.0829, value_loss: 0.6504
2024-07-14 06:21:37,003 [INFO    ] __main__: train step 12265: loss: 1.0966, policy_loss: 1.0829, value_loss: 0.6503
2024-07-14 06:21:37,270 [INFO    ] __main__: train step 12266: loss: 1.0966, policy_loss: 1.0829, value_loss: 0.6503
2024-07-14 06:21:37,539 [INFO    ] __main__: train step 12267: loss: 1.0966, policy_loss: 1.0828, value_loss: 0.6503
2024-07-14 06:21:37,813 [INFO    ] __main__: train step 12268: loss: 1.0965, policy_loss: 1.0828, value_loss: 0.6502
2024-07-14 06:21:38,104 [INFO    ] __main__: train step 12269: loss: 1.0965, policy_loss: 1.0828, value_loss: 0.6502
2024-07-14 06:21:38,402 [INFO    ] __main__: train step 12270: loss: 1.0965, policy_loss: 1.0828, value_loss: 0.6502
2024-07-14 06:21:39,998 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:21:40,496 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:21:40,564 [INFO    ] __main__: train step 12271: loss: 1.0965, policy_loss: 1.0828, value_loss: 0.6501
2024-07-14 06:21:40,848 [INFO    ] __main__: train step 12272: loss: 1.0965, policy_loss: 1.0827, value_loss: 0.6501
2024-07-14 06:21:41,139 [INFO    ] __main__: train step 12273: loss: 1.0965, policy_loss: 1.0827, value_loss: 0.6501
2024-07-14 06:21:41,426 [INFO    ] __main__: train step 12274: loss: 1.0965, policy_loss: 1.0827, value_loss: 0.6500
2024-07-14 06:21:41,712 [INFO    ] __main__: train step 12275: loss: 1.0965, policy_loss: 1.0827, value_loss: 0.6500
2024-07-14 06:21:42,003 [INFO    ] __main__: train step 12276: loss: 1.0965, policy_loss: 1.0827, value_loss: 0.6500
2024-07-14 06:21:42,282 [INFO    ] __main__: train step 12277: loss: 1.0965, policy_loss: 1.0826, value_loss: 0.6499
2024-07-14 06:21:42,565 [INFO    ] __main__: train step 12278: loss: 1.0965, policy_loss: 1.0826, value_loss: 0.6499
2024-07-14 06:21:42,856 [INFO    ] __main__: train step 12279: loss: 1.0965, policy_loss: 1.0826, value_loss: 0.6499
2024-07-14 06:21:43,144 [INFO    ] __main__: train step 12280: loss: 1.0965, policy_loss: 1.0826, value_loss: 0.6498
2024-07-14 06:21:43,436 [INFO    ] __main__: train step 12281: loss: 1.0965, policy_loss: 1.0826, value_loss: 0.6498
2024-07-14 06:21:43,706 [INFO    ] __main__: train step 12282: loss: 1.0965, policy_loss: 1.0825, value_loss: 0.6498
2024-07-14 06:21:46,569 [INFO    ] __main__: train step 12283: loss: 1.0965, policy_loss: 1.0825, value_loss: 0.6497
2024-07-14 06:21:46,859 [INFO    ] __main__: train step 12284: loss: 1.0965, policy_loss: 1.0825, value_loss: 0.6497
2024-07-14 06:21:47,151 [INFO    ] __main__: train step 12285: loss: 1.0965, policy_loss: 1.0825, value_loss: 0.6497
2024-07-14 06:21:47,441 [INFO    ] __main__: train step 12286: loss: 1.0965, policy_loss: 1.0825, value_loss: 0.6496
2024-07-14 06:21:47,738 [INFO    ] __main__: train step 12287: loss: 1.0965, policy_loss: 1.0824, value_loss: 0.6496
2024-07-14 06:21:49,345 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:21:49,835 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:21:49,902 [INFO    ] __main__: train step 12288: loss: 1.0965, policy_loss: 1.0824, value_loss: 0.6496
2024-07-14 06:21:50,198 [INFO    ] __main__: train step 12289: loss: 1.0965, policy_loss: 1.0824, value_loss: 0.6495
2024-07-14 06:21:50,482 [INFO    ] __main__: train step 12290: loss: 1.0965, policy_loss: 1.0824, value_loss: 0.6495
2024-07-14 06:21:50,769 [INFO    ] __main__: train step 12291: loss: 1.0965, policy_loss: 1.0824, value_loss: 0.6495
2024-07-14 06:21:51,072 [INFO    ] __main__: train step 12292: loss: 1.0965, policy_loss: 1.0823, value_loss: 0.6494
2024-07-14 06:21:51,356 [INFO    ] __main__: train step 12293: loss: 1.0965, policy_loss: 1.0823, value_loss: 0.6494
2024-07-14 06:21:51,643 [INFO    ] __main__: train step 12294: loss: 1.0965, policy_loss: 1.0823, value_loss: 0.6493
2024-07-14 06:21:51,937 [INFO    ] __main__: train step 12295: loss: 1.0965, policy_loss: 1.0823, value_loss: 0.6493
2024-07-14 06:21:52,242 [INFO    ] __main__: train step 12296: loss: 1.0965, policy_loss: 1.0823, value_loss: 0.6493
2024-07-14 06:21:52,532 [INFO    ] __main__: train step 12297: loss: 1.0965, policy_loss: 1.0822, value_loss: 0.6492
2024-07-14 06:21:52,818 [INFO    ] __main__: train step 12298: loss: 1.0965, policy_loss: 1.0822, value_loss: 0.6492
2024-07-14 06:21:53,114 [INFO    ] __main__: train step 12299: loss: 1.0964, policy_loss: 1.0822, value_loss: 0.6492
2024-07-14 06:21:53,406 [INFO    ] __main__: train step 12300: loss: 1.0964, policy_loss: 1.0822, value_loss: 0.6491
2024-07-14 06:21:53,699 [INFO    ] __main__: train step 12301: loss: 1.0964, policy_loss: 1.0822, value_loss: 0.6491
2024-07-14 06:21:53,981 [INFO    ] __main__: train step 12302: loss: 1.0964, policy_loss: 1.0821, value_loss: 0.6491
2024-07-14 06:21:54,266 [INFO    ] __main__: train step 12303: loss: 1.0964, policy_loss: 1.0821, value_loss: 0.6490
2024-07-14 06:21:54,552 [INFO    ] __main__: train step 12304: loss: 1.0964, policy_loss: 1.0821, value_loss: 0.6490
2024-07-14 06:21:56,167 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:21:56,645 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:21:56,714 [INFO    ] __main__: train step 12305: loss: 1.0964, policy_loss: 1.0821, value_loss: 0.6490
2024-07-14 06:21:57,007 [INFO    ] __main__: train step 12306: loss: 1.0964, policy_loss: 1.0821, value_loss: 0.6489
2024-07-14 06:21:57,302 [INFO    ] __main__: train step 12307: loss: 1.0964, policy_loss: 1.0820, value_loss: 0.6489
2024-07-14 06:21:57,599 [INFO    ] __main__: train step 12308: loss: 1.0964, policy_loss: 1.0820, value_loss: 0.6489
2024-07-14 06:21:57,888 [INFO    ] __main__: train step 12309: loss: 1.0964, policy_loss: 1.0820, value_loss: 0.6488
2024-07-14 06:21:58,180 [INFO    ] __main__: train step 12310: loss: 1.0964, policy_loss: 1.0820, value_loss: 0.6488
2024-07-14 06:21:58,467 [INFO    ] __main__: train step 12311: loss: 1.0964, policy_loss: 1.0819, value_loss: 0.6488
2024-07-14 06:21:58,757 [INFO    ] __main__: train step 12312: loss: 1.0964, policy_loss: 1.0819, value_loss: 0.6487
2024-07-14 06:21:59,040 [INFO    ] __main__: train step 12313: loss: 1.0964, policy_loss: 1.0819, value_loss: 0.6487
2024-07-14 06:21:59,335 [INFO    ] __main__: train step 12314: loss: 1.0964, policy_loss: 1.0819, value_loss: 0.6486
2024-07-14 06:21:59,624 [INFO    ] __main__: train step 12315: loss: 1.0964, policy_loss: 1.0819, value_loss: 0.6486
2024-07-14 06:21:59,908 [INFO    ] __main__: train step 12316: loss: 1.0964, policy_loss: 1.0818, value_loss: 0.6486
2024-07-14 06:22:00,199 [INFO    ] __main__: train step 12317: loss: 1.0964, policy_loss: 1.0818, value_loss: 0.6485
2024-07-14 06:22:00,488 [INFO    ] __main__: train step 12318: loss: 1.0964, policy_loss: 1.0818, value_loss: 0.6485
2024-07-14 06:22:00,784 [INFO    ] __main__: train step 12319: loss: 1.0964, policy_loss: 1.0818, value_loss: 0.6485
2024-07-14 06:22:01,075 [INFO    ] __main__: train step 12320: loss: 1.0964, policy_loss: 1.0818, value_loss: 0.6484
2024-07-14 06:22:01,372 [INFO    ] __main__: train step 12321: loss: 1.0964, policy_loss: 1.0817, value_loss: 0.6484
2024-07-14 06:22:02,997 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:22:03,483 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:22:03,553 [INFO    ] __main__: train step 12322: loss: 1.0964, policy_loss: 1.0817, value_loss: 0.6484
2024-07-14 06:22:03,841 [INFO    ] __main__: train step 12323: loss: 1.0964, policy_loss: 1.0817, value_loss: 0.6483
2024-07-14 06:22:04,125 [INFO    ] __main__: train step 12324: loss: 1.0964, policy_loss: 1.0817, value_loss: 0.6483
2024-07-14 06:22:04,414 [INFO    ] __main__: train step 12325: loss: 1.0963, policy_loss: 1.0817, value_loss: 0.6483
2024-07-14 06:22:04,703 [INFO    ] __main__: train step 12326: loss: 1.0963, policy_loss: 1.0816, value_loss: 0.6482
2024-07-14 06:22:05,000 [INFO    ] __main__: train step 12327: loss: 1.0963, policy_loss: 1.0816, value_loss: 0.6482
2024-07-14 06:22:05,290 [INFO    ] __main__: train step 12328: loss: 1.0963, policy_loss: 1.0816, value_loss: 0.6482
2024-07-14 06:22:05,570 [INFO    ] __main__: train step 12329: loss: 1.0963, policy_loss: 1.0816, value_loss: 0.6481
2024-07-14 06:22:05,868 [INFO    ] __main__: train step 12330: loss: 1.0963, policy_loss: 1.0816, value_loss: 0.6481
2024-07-14 06:22:06,160 [INFO    ] __main__: train step 12331: loss: 1.0963, policy_loss: 1.0815, value_loss: 0.6481
2024-07-14 06:22:06,451 [INFO    ] __main__: train step 12332: loss: 1.0963, policy_loss: 1.0815, value_loss: 0.6480
2024-07-14 06:22:06,762 [INFO    ] __main__: train step 12333: loss: 1.0963, policy_loss: 1.0815, value_loss: 0.6480
2024-07-14 06:22:07,064 [INFO    ] __main__: train step 12334: loss: 1.0963, policy_loss: 1.0815, value_loss: 0.6480
2024-07-14 06:22:07,365 [INFO    ] __main__: train step 12335: loss: 1.0963, policy_loss: 1.0814, value_loss: 0.6479
2024-07-14 06:22:07,659 [INFO    ] __main__: train step 12336: loss: 1.0963, policy_loss: 1.0814, value_loss: 0.6479
2024-07-14 06:22:07,937 [INFO    ] __main__: train step 12337: loss: 1.0963, policy_loss: 1.0814, value_loss: 0.6479
2024-07-14 06:22:08,228 [INFO    ] __main__: train step 12338: loss: 1.0963, policy_loss: 1.0814, value_loss: 0.6478
2024-07-14 06:22:09,866 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:22:10,355 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:22:10,426 [INFO    ] __main__: train step 12339: loss: 1.0963, policy_loss: 1.0814, value_loss: 0.6478
2024-07-14 06:22:10,719 [INFO    ] __main__: train step 12340: loss: 1.0963, policy_loss: 1.0813, value_loss: 0.6477
2024-07-14 06:22:11,013 [INFO    ] __main__: train step 12341: loss: 1.0963, policy_loss: 1.0813, value_loss: 0.6477
2024-07-14 06:22:11,305 [INFO    ] __main__: train step 12342: loss: 1.0963, policy_loss: 1.0813, value_loss: 0.6477
2024-07-14 06:22:11,599 [INFO    ] __main__: train step 12343: loss: 1.0963, policy_loss: 1.0813, value_loss: 0.6476
2024-07-14 06:22:11,892 [INFO    ] __main__: train step 12344: loss: 1.0963, policy_loss: 1.0813, value_loss: 0.6476
2024-07-14 06:22:12,187 [INFO    ] __main__: train step 12345: loss: 1.0963, policy_loss: 1.0812, value_loss: 0.6476
2024-07-14 06:22:12,467 [INFO    ] __main__: train step 12346: loss: 1.0963, policy_loss: 1.0812, value_loss: 0.6475
2024-07-14 06:22:12,769 [INFO    ] __main__: train step 12347: loss: 1.0962, policy_loss: 1.0812, value_loss: 0.6475
2024-07-14 06:22:13,064 [INFO    ] __main__: train step 12348: loss: 1.0962, policy_loss: 1.0812, value_loss: 0.6475
2024-07-14 06:22:13,364 [INFO    ] __main__: train step 12349: loss: 1.0962, policy_loss: 1.0811, value_loss: 0.6474
2024-07-14 06:22:13,670 [INFO    ] __main__: train step 12350: loss: 1.0962, policy_loss: 1.0811, value_loss: 0.6474
2024-07-14 06:22:13,961 [INFO    ] __main__: train step 12351: loss: 1.0962, policy_loss: 1.0811, value_loss: 0.6474
2024-07-14 06:22:14,258 [INFO    ] __main__: train step 12352: loss: 1.0962, policy_loss: 1.0811, value_loss: 0.6473
2024-07-14 06:22:14,553 [INFO    ] __main__: train step 12353: loss: 1.0962, policy_loss: 1.0811, value_loss: 0.6473
2024-07-14 06:22:14,849 [INFO    ] __main__: train step 12354: loss: 1.0962, policy_loss: 1.0810, value_loss: 0.6473
2024-07-14 06:22:15,146 [INFO    ] __main__: train step 12355: loss: 1.0962, policy_loss: 1.0810, value_loss: 0.6472
2024-07-14 06:22:16,773 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:22:17,284 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:22:17,359 [INFO    ] __main__: train step 12356: loss: 1.0962, policy_loss: 1.0810, value_loss: 0.6472
2024-07-14 06:22:17,657 [INFO    ] __main__: train step 12357: loss: 1.0962, policy_loss: 1.0810, value_loss: 0.6472
2024-07-14 06:22:17,961 [INFO    ] __main__: train step 12358: loss: 1.0962, policy_loss: 1.0810, value_loss: 0.6471
2024-07-14 06:22:18,253 [INFO    ] __main__: train step 12359: loss: 1.0962, policy_loss: 1.0809, value_loss: 0.6471
2024-07-14 06:22:18,552 [INFO    ] __main__: train step 12360: loss: 1.0962, policy_loss: 1.0809, value_loss: 0.6471
2024-07-14 06:22:18,845 [INFO    ] __main__: train step 12361: loss: 1.0962, policy_loss: 1.0809, value_loss: 0.6470
2024-07-14 06:22:19,132 [INFO    ] __main__: train step 12362: loss: 1.0962, policy_loss: 1.0809, value_loss: 0.6470
2024-07-14 06:22:19,414 [INFO    ] __main__: train step 12363: loss: 1.0962, policy_loss: 1.0809, value_loss: 0.6470
2024-07-14 06:22:19,706 [INFO    ] __main__: train step 12364: loss: 1.0962, policy_loss: 1.0808, value_loss: 0.6469
2024-07-14 06:22:19,997 [INFO    ] __main__: train step 12365: loss: 1.0962, policy_loss: 1.0808, value_loss: 0.6469
2024-07-14 06:22:20,292 [INFO    ] __main__: train step 12366: loss: 1.0962, policy_loss: 1.0808, value_loss: 0.6468
2024-07-14 06:22:20,588 [INFO    ] __main__: train step 12367: loss: 1.0962, policy_loss: 1.0808, value_loss: 0.6468
2024-07-14 06:22:20,874 [INFO    ] __main__: train step 12368: loss: 1.0962, policy_loss: 1.0807, value_loss: 0.6468
2024-07-14 06:22:21,155 [INFO    ] __main__: train step 12369: loss: 1.0961, policy_loss: 1.0807, value_loss: 0.6467
2024-07-14 06:22:21,432 [INFO    ] __main__: train step 12370: loss: 1.0961, policy_loss: 1.0807, value_loss: 0.6467
2024-07-14 06:22:21,706 [INFO    ] __main__: train step 12371: loss: 1.0961, policy_loss: 1.0807, value_loss: 0.6467
2024-07-14 06:22:24,629 [INFO    ] __main__: train step 12372: loss: 1.0961, policy_loss: 1.0807, value_loss: 0.6466
2024-07-14 06:22:26,256 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:22:26,746 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:22:26,813 [INFO    ] __main__: train step 12373: loss: 1.0961, policy_loss: 1.0806, value_loss: 0.6466
2024-07-14 06:22:27,126 [INFO    ] __main__: train step 12374: loss: 1.0961, policy_loss: 1.0806, value_loss: 0.6466
2024-07-14 06:22:27,420 [INFO    ] __main__: train step 12375: loss: 1.0961, policy_loss: 1.0806, value_loss: 0.6465
2024-07-14 06:22:27,713 [INFO    ] __main__: train step 12376: loss: 1.0961, policy_loss: 1.0806, value_loss: 0.6465
2024-07-14 06:22:28,007 [INFO    ] __main__: train step 12377: loss: 1.0961, policy_loss: 1.0806, value_loss: 0.6465
2024-07-14 06:22:28,298 [INFO    ] __main__: train step 12378: loss: 1.0961, policy_loss: 1.0805, value_loss: 0.6464
2024-07-14 06:22:28,590 [INFO    ] __main__: train step 12379: loss: 1.0961, policy_loss: 1.0805, value_loss: 0.6464
2024-07-14 06:22:28,887 [INFO    ] __main__: train step 12380: loss: 1.0961, policy_loss: 1.0805, value_loss: 0.6464
2024-07-14 06:22:29,176 [INFO    ] __main__: train step 12381: loss: 1.0961, policy_loss: 1.0805, value_loss: 0.6463
2024-07-14 06:22:29,473 [INFO    ] __main__: train step 12382: loss: 1.0961, policy_loss: 1.0805, value_loss: 0.6463
2024-07-14 06:22:29,775 [INFO    ] __main__: train step 12383: loss: 1.0961, policy_loss: 1.0804, value_loss: 0.6463
2024-07-14 06:22:30,080 [INFO    ] __main__: train step 12384: loss: 1.0961, policy_loss: 1.0804, value_loss: 0.6462
2024-07-14 06:22:30,380 [INFO    ] __main__: train step 12385: loss: 1.0961, policy_loss: 1.0804, value_loss: 0.6462
2024-07-14 06:22:30,686 [INFO    ] __main__: train step 12386: loss: 1.0961, policy_loss: 1.0804, value_loss: 0.6462
2024-07-14 06:22:30,985 [INFO    ] __main__: train step 12387: loss: 1.0961, policy_loss: 1.0803, value_loss: 0.6461
2024-07-14 06:22:31,278 [INFO    ] __main__: train step 12388: loss: 1.0961, policy_loss: 1.0803, value_loss: 0.6461
2024-07-14 06:22:31,571 [INFO    ] __main__: train step 12389: loss: 1.0961, policy_loss: 1.0803, value_loss: 0.6461
2024-07-14 06:22:33,194 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:22:33,675 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:22:33,750 [INFO    ] __main__: train step 12390: loss: 1.0960, policy_loss: 1.0803, value_loss: 0.6460
2024-07-14 06:22:34,034 [INFO    ] __main__: train step 12391: loss: 1.0960, policy_loss: 1.0803, value_loss: 0.6460
2024-07-14 06:22:34,335 [INFO    ] __main__: train step 12392: loss: 1.0960, policy_loss: 1.0802, value_loss: 0.6459
2024-07-14 06:22:34,623 [INFO    ] __main__: train step 12393: loss: 1.0960, policy_loss: 1.0802, value_loss: 0.6459
2024-07-14 06:22:34,921 [INFO    ] __main__: train step 12394: loss: 1.0960, policy_loss: 1.0802, value_loss: 0.6459
2024-07-14 06:22:35,205 [INFO    ] __main__: train step 12395: loss: 1.0960, policy_loss: 1.0802, value_loss: 0.6458
2024-07-14 06:22:35,484 [INFO    ] __main__: train step 12396: loss: 1.0960, policy_loss: 1.0802, value_loss: 0.6458
2024-07-14 06:22:35,768 [INFO    ] __main__: train step 12397: loss: 1.0960, policy_loss: 1.0801, value_loss: 0.6458
2024-07-14 06:22:36,064 [INFO    ] __main__: train step 12398: loss: 1.0960, policy_loss: 1.0801, value_loss: 0.6457
2024-07-14 06:22:36,349 [INFO    ] __main__: train step 12399: loss: 1.0960, policy_loss: 1.0801, value_loss: 0.6457
2024-07-14 06:22:36,635 [INFO    ] __main__: train step 12400: loss: 1.0960, policy_loss: 1.0801, value_loss: 0.6457
2024-07-14 06:22:36,922 [INFO    ] __main__: train step 12401: loss: 1.0960, policy_loss: 1.0801, value_loss: 0.6456
2024-07-14 06:22:37,198 [INFO    ] __main__: train step 12402: loss: 1.0960, policy_loss: 1.0800, value_loss: 0.6456
2024-07-14 06:22:37,493 [INFO    ] __main__: train step 12403: loss: 1.0960, policy_loss: 1.0800, value_loss: 0.6456
2024-07-14 06:22:37,794 [INFO    ] __main__: train step 12404: loss: 1.0960, policy_loss: 1.0800, value_loss: 0.6455
2024-07-14 06:22:38,080 [INFO    ] __main__: train step 12405: loss: 1.0960, policy_loss: 1.0800, value_loss: 0.6455
2024-07-14 06:22:38,367 [INFO    ] __main__: train step 12406: loss: 1.0960, policy_loss: 1.0799, value_loss: 0.6455
2024-07-14 06:22:39,983 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:22:40,495 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:22:40,569 [INFO    ] __main__: train step 12407: loss: 1.0960, policy_loss: 1.0799, value_loss: 0.6454
2024-07-14 06:22:40,862 [INFO    ] __main__: train step 12408: loss: 1.0960, policy_loss: 1.0799, value_loss: 0.6454
2024-07-14 06:22:41,146 [INFO    ] __main__: train step 12409: loss: 1.0960, policy_loss: 1.0799, value_loss: 0.6454
2024-07-14 06:22:41,438 [INFO    ] __main__: train step 12410: loss: 1.0959, policy_loss: 1.0799, value_loss: 0.6453
2024-07-14 06:22:41,726 [INFO    ] __main__: train step 12411: loss: 1.0959, policy_loss: 1.0798, value_loss: 0.6453
2024-07-14 06:22:42,011 [INFO    ] __main__: train step 12412: loss: 1.0959, policy_loss: 1.0798, value_loss: 0.6453
2024-07-14 06:22:42,298 [INFO    ] __main__: train step 12413: loss: 1.0959, policy_loss: 1.0798, value_loss: 0.6452
2024-07-14 06:22:42,591 [INFO    ] __main__: train step 12414: loss: 1.0959, policy_loss: 1.0798, value_loss: 0.6452
2024-07-14 06:22:42,885 [INFO    ] __main__: train step 12415: loss: 1.0959, policy_loss: 1.0798, value_loss: 0.6451
2024-07-14 06:22:43,187 [INFO    ] __main__: train step 12416: loss: 1.0959, policy_loss: 1.0797, value_loss: 0.6451
2024-07-14 06:22:43,470 [INFO    ] __main__: train step 12417: loss: 1.0959, policy_loss: 1.0797, value_loss: 0.6451
2024-07-14 06:22:43,764 [INFO    ] __main__: train step 12418: loss: 1.0959, policy_loss: 1.0797, value_loss: 0.6450
2024-07-14 06:22:44,058 [INFO    ] __main__: train step 12419: loss: 1.0959, policy_loss: 1.0797, value_loss: 0.6450
2024-07-14 06:22:44,347 [INFO    ] __main__: train step 12420: loss: 1.0959, policy_loss: 1.0797, value_loss: 0.6450
2024-07-14 06:22:44,635 [INFO    ] __main__: train step 12421: loss: 1.0959, policy_loss: 1.0796, value_loss: 0.6449
2024-07-14 06:22:44,933 [INFO    ] __main__: train step 12422: loss: 1.0959, policy_loss: 1.0796, value_loss: 0.6449
2024-07-14 06:22:45,225 [INFO    ] __main__: train step 12423: loss: 1.0959, policy_loss: 1.0796, value_loss: 0.6449
2024-07-14 06:22:46,801 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:22:47,298 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:22:47,372 [INFO    ] __main__: train step 12424: loss: 1.0959, policy_loss: 1.0796, value_loss: 0.6448
2024-07-14 06:22:47,697 [INFO    ] __main__: train step 12425: loss: 1.0959, policy_loss: 1.0795, value_loss: 0.6448
2024-07-14 06:22:47,987 [INFO    ] __main__: train step 12426: loss: 1.0959, policy_loss: 1.0795, value_loss: 0.6448
2024-07-14 06:22:48,255 [INFO    ] __main__: train step 12427: loss: 1.0959, policy_loss: 1.0795, value_loss: 0.6447
2024-07-14 06:22:48,561 [INFO    ] __main__: train step 12428: loss: 1.0959, policy_loss: 1.0795, value_loss: 0.6447
2024-07-14 06:22:48,848 [INFO    ] __main__: train step 12429: loss: 1.0958, policy_loss: 1.0795, value_loss: 0.6447
2024-07-14 06:22:49,152 [INFO    ] __main__: train step 12430: loss: 1.0958, policy_loss: 1.0794, value_loss: 0.6446
2024-07-14 06:22:49,444 [INFO    ] __main__: train step 12431: loss: 1.0958, policy_loss: 1.0794, value_loss: 0.6446
2024-07-14 06:22:49,741 [INFO    ] __main__: train step 12432: loss: 1.0958, policy_loss: 1.0794, value_loss: 0.6446
2024-07-14 06:22:50,020 [INFO    ] __main__: train step 12433: loss: 1.0958, policy_loss: 1.0794, value_loss: 0.6445
2024-07-14 06:22:50,303 [INFO    ] __main__: train step 12434: loss: 1.0958, policy_loss: 1.0794, value_loss: 0.6445
2024-07-14 06:22:50,593 [INFO    ] __main__: train step 12435: loss: 1.0958, policy_loss: 1.0793, value_loss: 0.6445
2024-07-14 06:22:50,883 [INFO    ] __main__: train step 12436: loss: 1.0958, policy_loss: 1.0793, value_loss: 0.6444
2024-07-14 06:22:51,179 [INFO    ] __main__: train step 12437: loss: 1.0958, policy_loss: 1.0793, value_loss: 0.6444
2024-07-14 06:22:51,469 [INFO    ] __main__: train step 12438: loss: 1.0958, policy_loss: 1.0793, value_loss: 0.6444
2024-07-14 06:22:51,758 [INFO    ] __main__: train step 12439: loss: 1.0958, policy_loss: 1.0792, value_loss: 0.6443
2024-07-14 06:22:52,043 [INFO    ] __main__: train step 12440: loss: 1.0958, policy_loss: 1.0792, value_loss: 0.6443
2024-07-14 06:22:53,673 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:22:54,160 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:22:54,237 [INFO    ] __main__: train step 12441: loss: 1.0958, policy_loss: 1.0792, value_loss: 0.6443
2024-07-14 06:22:54,524 [INFO    ] __main__: train step 12442: loss: 1.0958, policy_loss: 1.0792, value_loss: 0.6442
2024-07-14 06:22:54,810 [INFO    ] __main__: train step 12443: loss: 1.0958, policy_loss: 1.0792, value_loss: 0.6442
2024-07-14 06:22:55,092 [INFO    ] __main__: train step 12444: loss: 1.0958, policy_loss: 1.0791, value_loss: 0.6442
2024-07-14 06:22:55,375 [INFO    ] __main__: train step 12445: loss: 1.0958, policy_loss: 1.0791, value_loss: 0.6441
2024-07-14 06:22:55,656 [INFO    ] __main__: train step 12446: loss: 1.0958, policy_loss: 1.0791, value_loss: 0.6441
2024-07-14 06:22:55,933 [INFO    ] __main__: train step 12447: loss: 1.0958, policy_loss: 1.0791, value_loss: 0.6440
2024-07-14 06:22:56,214 [INFO    ] __main__: train step 12448: loss: 1.0958, policy_loss: 1.0791, value_loss: 0.6440
2024-07-14 06:22:56,493 [INFO    ] __main__: train step 12449: loss: 1.0958, policy_loss: 1.0790, value_loss: 0.6440
2024-07-14 06:22:56,763 [INFO    ] __main__: train step 12450: loss: 1.0958, policy_loss: 1.0790, value_loss: 0.6439
2024-07-14 06:22:57,037 [INFO    ] __main__: train step 12451: loss: 1.0957, policy_loss: 1.0790, value_loss: 0.6439
2024-07-14 06:22:57,323 [INFO    ] __main__: train step 12452: loss: 1.0957, policy_loss: 1.0790, value_loss: 0.6439
2024-07-14 06:22:57,616 [INFO    ] __main__: train step 12453: loss: 1.0957, policy_loss: 1.0790, value_loss: 0.6438
2024-07-14 06:22:57,931 [INFO    ] __main__: train step 12454: loss: 1.0957, policy_loss: 1.0789, value_loss: 0.6438
2024-07-14 06:22:58,219 [INFO    ] __main__: train step 12455: loss: 1.0957, policy_loss: 1.0789, value_loss: 0.6438
2024-07-14 06:22:58,518 [INFO    ] __main__: train step 12456: loss: 1.0957, policy_loss: 1.0789, value_loss: 0.6437
2024-07-14 06:22:58,805 [INFO    ] __main__: train step 12457: loss: 1.0957, policy_loss: 1.0789, value_loss: 0.6437
2024-07-14 06:23:00,405 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:23:00,899 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:23:00,968 [INFO    ] __main__: train step 12458: loss: 1.0957, policy_loss: 1.0789, value_loss: 0.6437
2024-07-14 06:23:01,253 [INFO    ] __main__: train step 12459: loss: 1.0957, policy_loss: 1.0788, value_loss: 0.6436
2024-07-14 06:23:01,543 [INFO    ] __main__: train step 12460: loss: 1.0957, policy_loss: 1.0788, value_loss: 0.6436
2024-07-14 06:23:01,827 [INFO    ] __main__: train step 12461: loss: 1.0957, policy_loss: 1.0788, value_loss: 0.6436
2024-07-14 06:23:04,859 [INFO    ] __main__: train step 12462: loss: 1.0957, policy_loss: 1.0788, value_loss: 0.6435
2024-07-14 06:23:05,148 [INFO    ] __main__: train step 12463: loss: 1.0957, policy_loss: 1.0787, value_loss: 0.6435
2024-07-14 06:23:05,444 [INFO    ] __main__: train step 12464: loss: 1.0957, policy_loss: 1.0787, value_loss: 0.6435
2024-07-14 06:23:05,736 [INFO    ] __main__: train step 12465: loss: 1.0957, policy_loss: 1.0787, value_loss: 0.6434
2024-07-14 06:23:06,035 [INFO    ] __main__: train step 12466: loss: 1.0957, policy_loss: 1.0787, value_loss: 0.6434
2024-07-14 06:23:06,328 [INFO    ] __main__: train step 12467: loss: 1.0957, policy_loss: 1.0787, value_loss: 0.6434
2024-07-14 06:23:06,619 [INFO    ] __main__: train step 12468: loss: 1.0957, policy_loss: 1.0786, value_loss: 0.6433
2024-07-14 06:23:06,920 [INFO    ] __main__: train step 12469: loss: 1.0957, policy_loss: 1.0786, value_loss: 0.6433
2024-07-14 06:23:07,205 [INFO    ] __main__: train step 12470: loss: 1.0956, policy_loss: 1.0786, value_loss: 0.6433
2024-07-14 06:23:07,499 [INFO    ] __main__: train step 12471: loss: 1.0956, policy_loss: 1.0786, value_loss: 0.6432
2024-07-14 06:23:07,799 [INFO    ] __main__: train step 12472: loss: 1.0956, policy_loss: 1.0786, value_loss: 0.6432
2024-07-14 06:23:08,084 [INFO    ] __main__: train step 12473: loss: 1.0956, policy_loss: 1.0785, value_loss: 0.6432
2024-07-14 06:23:08,384 [INFO    ] __main__: train step 12474: loss: 1.0956, policy_loss: 1.0785, value_loss: 0.6431
2024-07-14 06:23:09,996 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:23:10,487 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:23:10,557 [INFO    ] __main__: train step 12475: loss: 1.0956, policy_loss: 1.0785, value_loss: 0.6431
2024-07-14 06:23:10,855 [INFO    ] __main__: train step 12476: loss: 1.0956, policy_loss: 1.0785, value_loss: 0.6431
2024-07-14 06:23:11,140 [INFO    ] __main__: train step 12477: loss: 1.0956, policy_loss: 1.0784, value_loss: 0.6430
2024-07-14 06:23:11,430 [INFO    ] __main__: train step 12478: loss: 1.0956, policy_loss: 1.0784, value_loss: 0.6430
2024-07-14 06:23:11,724 [INFO    ] __main__: train step 12479: loss: 1.0956, policy_loss: 1.0784, value_loss: 0.6430
2024-07-14 06:23:12,014 [INFO    ] __main__: train step 12480: loss: 1.0956, policy_loss: 1.0784, value_loss: 0.6429
2024-07-14 06:23:12,302 [INFO    ] __main__: train step 12481: loss: 1.0956, policy_loss: 1.0784, value_loss: 0.6429
2024-07-14 06:23:12,596 [INFO    ] __main__: train step 12482: loss: 1.0956, policy_loss: 1.0783, value_loss: 0.6429
2024-07-14 06:23:12,901 [INFO    ] __main__: train step 12483: loss: 1.0956, policy_loss: 1.0783, value_loss: 0.6428
2024-07-14 06:23:13,188 [INFO    ] __main__: train step 12484: loss: 1.0956, policy_loss: 1.0783, value_loss: 0.6428
2024-07-14 06:23:13,478 [INFO    ] __main__: train step 12485: loss: 1.0956, policy_loss: 1.0783, value_loss: 0.6427
2024-07-14 06:23:13,758 [INFO    ] __main__: train step 12486: loss: 1.0956, policy_loss: 1.0782, value_loss: 0.6427
2024-07-14 06:23:14,059 [INFO    ] __main__: train step 12487: loss: 1.0955, policy_loss: 1.0782, value_loss: 0.6427
2024-07-14 06:23:14,358 [INFO    ] __main__: train step 12488: loss: 1.0955, policy_loss: 1.0782, value_loss: 0.6426
2024-07-14 06:23:14,660 [INFO    ] __main__: train step 12489: loss: 1.0955, policy_loss: 1.0782, value_loss: 0.6426
2024-07-14 06:23:14,950 [INFO    ] __main__: train step 12490: loss: 1.0955, policy_loss: 1.0782, value_loss: 0.6426
2024-07-14 06:23:15,235 [INFO    ] __main__: train step 12491: loss: 1.0955, policy_loss: 1.0781, value_loss: 0.6425
2024-07-14 06:23:16,814 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:23:17,299 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:23:17,373 [INFO    ] __main__: train step 12492: loss: 1.0955, policy_loss: 1.0781, value_loss: 0.6425
2024-07-14 06:23:17,675 [INFO    ] __main__: train step 12493: loss: 1.0955, policy_loss: 1.0781, value_loss: 0.6425
2024-07-14 06:23:17,985 [INFO    ] __main__: train step 12494: loss: 1.0955, policy_loss: 1.0781, value_loss: 0.6424
2024-07-14 06:23:18,276 [INFO    ] __main__: train step 12495: loss: 1.0955, policy_loss: 1.0781, value_loss: 0.6424
2024-07-14 06:23:18,584 [INFO    ] __main__: train step 12496: loss: 1.0955, policy_loss: 1.0780, value_loss: 0.6424
2024-07-14 06:23:18,886 [INFO    ] __main__: train step 12497: loss: 1.0955, policy_loss: 1.0780, value_loss: 0.6423
2024-07-14 06:23:19,181 [INFO    ] __main__: train step 12498: loss: 1.0955, policy_loss: 1.0780, value_loss: 0.6423
2024-07-14 06:23:19,469 [INFO    ] __main__: train step 12499: loss: 1.0955, policy_loss: 1.0780, value_loss: 0.6423
2024-07-14 06:23:19,763 [INFO    ] __main__: train step 12500: loss: 1.0955, policy_loss: 1.0780, value_loss: 0.6422
2024-07-14 06:23:20,063 [INFO    ] __main__: train step 12501: loss: 1.0955, policy_loss: 1.0779, value_loss: 0.6422
2024-07-14 06:23:20,356 [INFO    ] __main__: train step 12502: loss: 1.0955, policy_loss: 1.0779, value_loss: 0.6422
2024-07-14 06:23:20,656 [INFO    ] __main__: train step 12503: loss: 1.0955, policy_loss: 1.0779, value_loss: 0.6421
2024-07-14 06:23:20,953 [INFO    ] __main__: train step 12504: loss: 1.0955, policy_loss: 1.0779, value_loss: 0.6421
2024-07-14 06:23:21,224 [INFO    ] __main__: train step 12505: loss: 1.0954, policy_loss: 1.0778, value_loss: 0.6421
2024-07-14 06:23:21,479 [INFO    ] __main__: train step 12506: loss: 1.0954, policy_loss: 1.0778, value_loss: 0.6420
2024-07-14 06:23:21,741 [INFO    ] __main__: train step 12507: loss: 1.0954, policy_loss: 1.0778, value_loss: 0.6420
2024-07-14 06:23:22,022 [INFO    ] __main__: train step 12508: loss: 1.0954, policy_loss: 1.0778, value_loss: 0.6420
2024-07-14 06:23:23,629 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:23:24,114 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:23:24,185 [INFO    ] __main__: train step 12509: loss: 1.0954, policy_loss: 1.0778, value_loss: 0.6419
2024-07-14 06:23:24,473 [INFO    ] __main__: train step 12510: loss: 1.0954, policy_loss: 1.0777, value_loss: 0.6419
2024-07-14 06:23:24,758 [INFO    ] __main__: train step 12511: loss: 1.0954, policy_loss: 1.0777, value_loss: 0.6419
2024-07-14 06:23:25,039 [INFO    ] __main__: train step 12512: loss: 1.0954, policy_loss: 1.0777, value_loss: 0.6418
2024-07-14 06:23:25,329 [INFO    ] __main__: train step 12513: loss: 1.0954, policy_loss: 1.0777, value_loss: 0.6418
2024-07-14 06:23:25,615 [INFO    ] __main__: train step 12514: loss: 1.0954, policy_loss: 1.0777, value_loss: 0.6417
2024-07-14 06:23:25,909 [INFO    ] __main__: train step 12515: loss: 1.0954, policy_loss: 1.0776, value_loss: 0.6417
2024-07-14 06:23:26,205 [INFO    ] __main__: train step 12516: loss: 1.0954, policy_loss: 1.0776, value_loss: 0.6417
2024-07-14 06:23:26,497 [INFO    ] __main__: train step 12517: loss: 1.0954, policy_loss: 1.0776, value_loss: 0.6416
2024-07-14 06:23:26,788 [INFO    ] __main__: train step 12518: loss: 1.0954, policy_loss: 1.0776, value_loss: 0.6416
2024-07-14 06:23:27,082 [INFO    ] __main__: train step 12519: loss: 1.0954, policy_loss: 1.0775, value_loss: 0.6416
2024-07-14 06:23:27,372 [INFO    ] __main__: train step 12520: loss: 1.0954, policy_loss: 1.0775, value_loss: 0.6415
2024-07-14 06:23:27,667 [INFO    ] __main__: train step 12521: loss: 1.0954, policy_loss: 1.0775, value_loss: 0.6415
2024-07-14 06:23:27,963 [INFO    ] __main__: train step 12522: loss: 1.0953, policy_loss: 1.0775, value_loss: 0.6415
2024-07-14 06:23:28,256 [INFO    ] __main__: train step 12523: loss: 1.0953, policy_loss: 1.0775, value_loss: 0.6414
2024-07-14 06:23:28,546 [INFO    ] __main__: train step 12524: loss: 1.0953, policy_loss: 1.0774, value_loss: 0.6414
2024-07-14 06:23:28,823 [INFO    ] __main__: train step 12525: loss: 1.0953, policy_loss: 1.0774, value_loss: 0.6414
2024-07-14 06:23:30,445 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:23:30,927 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:23:30,998 [INFO    ] __main__: train step 12526: loss: 1.0953, policy_loss: 1.0774, value_loss: 0.6413
2024-07-14 06:23:31,290 [INFO    ] __main__: train step 12527: loss: 1.0953, policy_loss: 1.0774, value_loss: 0.6413
2024-07-14 06:23:31,574 [INFO    ] __main__: train step 12528: loss: 1.0953, policy_loss: 1.0774, value_loss: 0.6413
2024-07-14 06:23:31,850 [INFO    ] __main__: train step 12529: loss: 1.0953, policy_loss: 1.0773, value_loss: 0.6412
2024-07-14 06:23:32,135 [INFO    ] __main__: train step 12530: loss: 1.0953, policy_loss: 1.0773, value_loss: 0.6412
2024-07-14 06:23:32,430 [INFO    ] __main__: train step 12531: loss: 1.0953, policy_loss: 1.0773, value_loss: 0.6412
2024-07-14 06:23:32,724 [INFO    ] __main__: train step 12532: loss: 1.0953, policy_loss: 1.0773, value_loss: 0.6411
2024-07-14 06:23:33,018 [INFO    ] __main__: train step 12533: loss: 1.0953, policy_loss: 1.0772, value_loss: 0.6411
2024-07-14 06:23:33,312 [INFO    ] __main__: train step 12534: loss: 1.0953, policy_loss: 1.0772, value_loss: 0.6411
2024-07-14 06:23:33,600 [INFO    ] __main__: train step 12535: loss: 1.0953, policy_loss: 1.0772, value_loss: 0.6410
2024-07-14 06:23:33,901 [INFO    ] __main__: train step 12536: loss: 1.0953, policy_loss: 1.0772, value_loss: 0.6410
2024-07-14 06:23:34,206 [INFO    ] __main__: train step 12537: loss: 1.0953, policy_loss: 1.0772, value_loss: 0.6410
2024-07-14 06:23:34,495 [INFO    ] __main__: train step 12538: loss: 1.0953, policy_loss: 1.0771, value_loss: 0.6409
2024-07-14 06:23:34,780 [INFO    ] __main__: train step 12539: loss: 1.0953, policy_loss: 1.0771, value_loss: 0.6409
2024-07-14 06:23:35,073 [INFO    ] __main__: train step 12540: loss: 1.0952, policy_loss: 1.0771, value_loss: 0.6409
2024-07-14 06:23:35,378 [INFO    ] __main__: train step 12541: loss: 1.0952, policy_loss: 1.0771, value_loss: 0.6408
2024-07-14 06:23:35,678 [INFO    ] __main__: train step 12542: loss: 1.0952, policy_loss: 1.0771, value_loss: 0.6408
2024-07-14 06:23:37,301 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:23:37,785 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:23:37,854 [INFO    ] __main__: train step 12543: loss: 1.0952, policy_loss: 1.0770, value_loss: 0.6408
2024-07-14 06:23:38,142 [INFO    ] __main__: train step 12544: loss: 1.0952, policy_loss: 1.0770, value_loss: 0.6407
2024-07-14 06:23:38,431 [INFO    ] __main__: train step 12545: loss: 1.0952, policy_loss: 1.0770, value_loss: 0.6407
2024-07-14 06:23:38,722 [INFO    ] __main__: train step 12546: loss: 1.0952, policy_loss: 1.0770, value_loss: 0.6407
2024-07-14 06:23:39,014 [INFO    ] __main__: train step 12547: loss: 1.0952, policy_loss: 1.0770, value_loss: 0.6406
2024-07-14 06:23:39,309 [INFO    ] __main__: train step 12548: loss: 1.0952, policy_loss: 1.0769, value_loss: 0.6406
2024-07-14 06:23:39,603 [INFO    ] __main__: train step 12549: loss: 1.0952, policy_loss: 1.0769, value_loss: 0.6406
2024-07-14 06:23:42,532 [INFO    ] __main__: train step 12550: loss: 1.0952, policy_loss: 1.0769, value_loss: 0.6405
2024-07-14 06:23:42,837 [INFO    ] __main__: train step 12551: loss: 1.0952, policy_loss: 1.0769, value_loss: 0.6405
2024-07-14 06:23:43,132 [INFO    ] __main__: train step 12552: loss: 1.0952, policy_loss: 1.0768, value_loss: 0.6405
2024-07-14 06:23:43,437 [INFO    ] __main__: train step 12553: loss: 1.0952, policy_loss: 1.0768, value_loss: 0.6404
2024-07-14 06:23:43,703 [INFO    ] __main__: train step 12554: loss: 1.0952, policy_loss: 1.0768, value_loss: 0.6404
2024-07-14 06:23:44,005 [INFO    ] __main__: train step 12555: loss: 1.0952, policy_loss: 1.0768, value_loss: 0.6403
2024-07-14 06:23:44,280 [INFO    ] __main__: train step 12556: loss: 1.0951, policy_loss: 1.0768, value_loss: 0.6403
2024-07-14 06:23:44,573 [INFO    ] __main__: train step 12557: loss: 1.0951, policy_loss: 1.0767, value_loss: 0.6403
2024-07-14 06:23:44,865 [INFO    ] __main__: train step 12558: loss: 1.0951, policy_loss: 1.0767, value_loss: 0.6402
2024-07-14 06:23:45,159 [INFO    ] __main__: train step 12559: loss: 1.0951, policy_loss: 1.0767, value_loss: 0.6402
2024-07-14 06:23:46,768 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:23:47,267 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:23:47,337 [INFO    ] __main__: train step 12560: loss: 1.0951, policy_loss: 1.0767, value_loss: 0.6402
2024-07-14 06:23:47,633 [INFO    ] __main__: train step 12561: loss: 1.0951, policy_loss: 1.0766, value_loss: 0.6401
2024-07-14 06:23:47,922 [INFO    ] __main__: train step 12562: loss: 1.0951, policy_loss: 1.0766, value_loss: 0.6401
2024-07-14 06:23:48,212 [INFO    ] __main__: train step 12563: loss: 1.0951, policy_loss: 1.0766, value_loss: 0.6401
2024-07-14 06:23:48,501 [INFO    ] __main__: train step 12564: loss: 1.0951, policy_loss: 1.0766, value_loss: 0.6400
2024-07-14 06:23:48,764 [INFO    ] __main__: train step 12565: loss: 1.0951, policy_loss: 1.0766, value_loss: 0.6400
2024-07-14 06:23:49,036 [INFO    ] __main__: train step 12566: loss: 1.0951, policy_loss: 1.0765, value_loss: 0.6400
2024-07-14 06:23:49,298 [INFO    ] __main__: train step 12567: loss: 1.0951, policy_loss: 1.0765, value_loss: 0.6399
2024-07-14 06:23:49,587 [INFO    ] __main__: train step 12568: loss: 1.0951, policy_loss: 1.0765, value_loss: 0.6399
2024-07-14 06:23:49,896 [INFO    ] __main__: train step 12569: loss: 1.0951, policy_loss: 1.0765, value_loss: 0.6399
2024-07-14 06:23:50,200 [INFO    ] __main__: train step 12570: loss: 1.0951, policy_loss: 1.0765, value_loss: 0.6398
2024-07-14 06:23:50,495 [INFO    ] __main__: train step 12571: loss: 1.0950, policy_loss: 1.0764, value_loss: 0.6398
2024-07-14 06:23:50,790 [INFO    ] __main__: train step 12572: loss: 1.0950, policy_loss: 1.0764, value_loss: 0.6398
2024-07-14 06:23:51,074 [INFO    ] __main__: train step 12573: loss: 1.0950, policy_loss: 1.0764, value_loss: 0.6397
2024-07-14 06:23:51,366 [INFO    ] __main__: train step 12574: loss: 1.0950, policy_loss: 1.0764, value_loss: 0.6397
2024-07-14 06:23:51,649 [INFO    ] __main__: train step 12575: loss: 1.0950, policy_loss: 1.0764, value_loss: 0.6397
2024-07-14 06:23:51,942 [INFO    ] __main__: train step 12576: loss: 1.0950, policy_loss: 1.0763, value_loss: 0.6396
2024-07-14 06:23:53,545 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:23:54,024 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:23:54,096 [INFO    ] __main__: train step 12577: loss: 1.0950, policy_loss: 1.0763, value_loss: 0.6396
2024-07-14 06:23:54,382 [INFO    ] __main__: train step 12578: loss: 1.0950, policy_loss: 1.0763, value_loss: 0.6396
2024-07-14 06:23:54,670 [INFO    ] __main__: train step 12579: loss: 1.0950, policy_loss: 1.0763, value_loss: 0.6395
2024-07-14 06:23:54,951 [INFO    ] __main__: train step 12580: loss: 1.0950, policy_loss: 1.0762, value_loss: 0.6395
2024-07-14 06:23:55,236 [INFO    ] __main__: train step 12581: loss: 1.0950, policy_loss: 1.0762, value_loss: 0.6395
2024-07-14 06:23:55,518 [INFO    ] __main__: train step 12582: loss: 1.0950, policy_loss: 1.0762, value_loss: 0.6394
2024-07-14 06:23:55,805 [INFO    ] __main__: train step 12583: loss: 1.0950, policy_loss: 1.0762, value_loss: 0.6394
2024-07-14 06:23:56,092 [INFO    ] __main__: train step 12584: loss: 1.0950, policy_loss: 1.0762, value_loss: 0.6393
2024-07-14 06:23:56,382 [INFO    ] __main__: train step 12585: loss: 1.0950, policy_loss: 1.0761, value_loss: 0.6393
2024-07-14 06:23:56,657 [INFO    ] __main__: train step 12586: loss: 1.0950, policy_loss: 1.0761, value_loss: 0.6393
2024-07-14 06:23:56,947 [INFO    ] __main__: train step 12587: loss: 1.0949, policy_loss: 1.0761, value_loss: 0.6392
2024-07-14 06:23:57,239 [INFO    ] __main__: train step 12588: loss: 1.0949, policy_loss: 1.0761, value_loss: 0.6392
2024-07-14 06:23:57,529 [INFO    ] __main__: train step 12589: loss: 1.0949, policy_loss: 1.0761, value_loss: 0.6392
2024-07-14 06:23:57,819 [INFO    ] __main__: train step 12590: loss: 1.0949, policy_loss: 1.0760, value_loss: 0.6391
2024-07-14 06:23:58,113 [INFO    ] __main__: train step 12591: loss: 1.0949, policy_loss: 1.0760, value_loss: 0.6391
2024-07-14 06:23:58,385 [INFO    ] __main__: train step 12592: loss: 1.0949, policy_loss: 1.0760, value_loss: 0.6391
2024-07-14 06:23:58,665 [INFO    ] __main__: train step 12593: loss: 1.0949, policy_loss: 1.0760, value_loss: 0.6390
2024-07-14 06:24:00,290 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:24:00,770 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:24:00,845 [INFO    ] __main__: train step 12594: loss: 1.0949, policy_loss: 1.0760, value_loss: 0.6390
2024-07-14 06:24:01,147 [INFO    ] __main__: train step 12595: loss: 1.0949, policy_loss: 1.0759, value_loss: 0.6390
2024-07-14 06:24:01,434 [INFO    ] __main__: train step 12596: loss: 1.0949, policy_loss: 1.0759, value_loss: 0.6389
2024-07-14 06:24:01,728 [INFO    ] __main__: train step 12597: loss: 1.0949, policy_loss: 1.0759, value_loss: 0.6389
2024-07-14 06:24:02,011 [INFO    ] __main__: train step 12598: loss: 1.0949, policy_loss: 1.0759, value_loss: 0.6389
2024-07-14 06:24:02,303 [INFO    ] __main__: train step 12599: loss: 1.0949, policy_loss: 1.0758, value_loss: 0.6388
2024-07-14 06:24:02,572 [INFO    ] __main__: train step 12600: loss: 1.0949, policy_loss: 1.0758, value_loss: 0.6388
2024-07-14 06:24:02,856 [INFO    ] __main__: train step 12601: loss: 1.0949, policy_loss: 1.0758, value_loss: 0.6388
2024-07-14 06:24:03,132 [INFO    ] __main__: train step 12602: loss: 1.0949, policy_loss: 1.0758, value_loss: 0.6387
2024-07-14 06:24:03,422 [INFO    ] __main__: train step 12603: loss: 1.0948, policy_loss: 1.0758, value_loss: 0.6387
2024-07-14 06:24:03,716 [INFO    ] __main__: train step 12604: loss: 1.0948, policy_loss: 1.0757, value_loss: 0.6387
2024-07-14 06:24:04,006 [INFO    ] __main__: train step 12605: loss: 1.0948, policy_loss: 1.0757, value_loss: 0.6386
2024-07-14 06:24:04,301 [INFO    ] __main__: train step 12606: loss: 1.0948, policy_loss: 1.0757, value_loss: 0.6386
2024-07-14 06:24:04,591 [INFO    ] __main__: train step 12607: loss: 1.0948, policy_loss: 1.0757, value_loss: 0.6385
2024-07-14 06:24:04,884 [INFO    ] __main__: train step 12608: loss: 1.0948, policy_loss: 1.0757, value_loss: 0.6385
2024-07-14 06:24:05,157 [INFO    ] __main__: train step 12609: loss: 1.0948, policy_loss: 1.0756, value_loss: 0.6385
2024-07-14 06:24:05,423 [INFO    ] __main__: train step 12610: loss: 1.0948, policy_loss: 1.0756, value_loss: 0.6384
2024-07-14 06:24:07,003 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:24:07,482 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:24:07,554 [INFO    ] __main__: train step 12611: loss: 1.0948, policy_loss: 1.0756, value_loss: 0.6384
2024-07-14 06:24:07,810 [INFO    ] __main__: train step 12612: loss: 1.0948, policy_loss: 1.0756, value_loss: 0.6384
2024-07-14 06:24:08,076 [INFO    ] __main__: train step 12613: loss: 1.0948, policy_loss: 1.0755, value_loss: 0.6383
2024-07-14 06:24:08,341 [INFO    ] __main__: train step 12614: loss: 1.0948, policy_loss: 1.0755, value_loss: 0.6383
2024-07-14 06:24:08,607 [INFO    ] __main__: train step 12615: loss: 1.0948, policy_loss: 1.0755, value_loss: 0.6383
2024-07-14 06:24:08,876 [INFO    ] __main__: train step 12616: loss: 1.0948, policy_loss: 1.0755, value_loss: 0.6382
2024-07-14 06:24:09,165 [INFO    ] __main__: train step 12617: loss: 1.0947, policy_loss: 1.0755, value_loss: 0.6382
2024-07-14 06:24:09,455 [INFO    ] __main__: train step 12618: loss: 1.0947, policy_loss: 1.0754, value_loss: 0.6382
2024-07-14 06:24:09,746 [INFO    ] __main__: train step 12619: loss: 1.0947, policy_loss: 1.0754, value_loss: 0.6381
2024-07-14 06:24:10,038 [INFO    ] __main__: train step 12620: loss: 1.0947, policy_loss: 1.0754, value_loss: 0.6381
2024-07-14 06:24:10,314 [INFO    ] __main__: train step 12621: loss: 1.0947, policy_loss: 1.0754, value_loss: 0.6381
2024-07-14 06:24:10,603 [INFO    ] __main__: train step 12622: loss: 1.0947, policy_loss: 1.0754, value_loss: 0.6380
2024-07-14 06:24:10,893 [INFO    ] __main__: train step 12623: loss: 1.0947, policy_loss: 1.0753, value_loss: 0.6380
2024-07-14 06:24:11,181 [INFO    ] __main__: train step 12624: loss: 1.0947, policy_loss: 1.0753, value_loss: 0.6380
2024-07-14 06:24:11,469 [INFO    ] __main__: train step 12625: loss: 1.0947, policy_loss: 1.0753, value_loss: 0.6379
2024-07-14 06:24:11,769 [INFO    ] __main__: train step 12626: loss: 1.0947, policy_loss: 1.0753, value_loss: 0.6379
2024-07-14 06:24:12,062 [INFO    ] __main__: train step 12627: loss: 1.0947, policy_loss: 1.0752, value_loss: 0.6379
2024-07-14 06:24:13,692 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:24:14,183 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:24:14,254 [INFO    ] __main__: train step 12628: loss: 1.0947, policy_loss: 1.0752, value_loss: 0.6378
2024-07-14 06:24:14,547 [INFO    ] __main__: train step 12629: loss: 1.0947, policy_loss: 1.0752, value_loss: 0.6378
2024-07-14 06:24:14,835 [INFO    ] __main__: train step 12630: loss: 1.0947, policy_loss: 1.0752, value_loss: 0.6378
2024-07-14 06:24:15,106 [INFO    ] __main__: train step 12631: loss: 1.0947, policy_loss: 1.0752, value_loss: 0.6377
2024-07-14 06:24:15,391 [INFO    ] __main__: train step 12632: loss: 1.0946, policy_loss: 1.0751, value_loss: 0.6377
2024-07-14 06:24:15,688 [INFO    ] __main__: train step 12633: loss: 1.0946, policy_loss: 1.0751, value_loss: 0.6377
2024-07-14 06:24:15,983 [INFO    ] __main__: train step 12634: loss: 1.0946, policy_loss: 1.0751, value_loss: 0.6376
2024-07-14 06:24:16,289 [INFO    ] __main__: train step 12635: loss: 1.0946, policy_loss: 1.0751, value_loss: 0.6376
2024-07-14 06:24:16,583 [INFO    ] __main__: train step 12636: loss: 1.0946, policy_loss: 1.0751, value_loss: 0.6376
2024-07-14 06:24:19,583 [INFO    ] __main__: train step 12637: loss: 1.0946, policy_loss: 1.0750, value_loss: 0.6375
2024-07-14 06:24:19,874 [INFO    ] __main__: train step 12638: loss: 1.0946, policy_loss: 1.0750, value_loss: 0.6375
2024-07-14 06:24:20,165 [INFO    ] __main__: train step 12639: loss: 1.0946, policy_loss: 1.0750, value_loss: 0.6374
2024-07-14 06:24:20,475 [INFO    ] __main__: train step 12640: loss: 1.0946, policy_loss: 1.0750, value_loss: 0.6374
2024-07-14 06:24:20,763 [INFO    ] __main__: train step 12641: loss: 1.0946, policy_loss: 1.0750, value_loss: 0.6374
2024-07-14 06:24:21,042 [INFO    ] __main__: train step 12642: loss: 1.0946, policy_loss: 1.0749, value_loss: 0.6373
2024-07-14 06:24:21,318 [INFO    ] __main__: train step 12643: loss: 1.0946, policy_loss: 1.0749, value_loss: 0.6373
2024-07-14 06:24:21,614 [INFO    ] __main__: train step 12644: loss: 1.0946, policy_loss: 1.0749, value_loss: 0.6373
2024-07-14 06:24:23,249 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:24:23,745 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:24:23,818 [INFO    ] __main__: train step 12645: loss: 1.0946, policy_loss: 1.0749, value_loss: 0.6372
2024-07-14 06:24:24,092 [INFO    ] __main__: train step 12646: loss: 1.0946, policy_loss: 1.0748, value_loss: 0.6372
2024-07-14 06:24:24,384 [INFO    ] __main__: train step 12647: loss: 1.0945, policy_loss: 1.0748, value_loss: 0.6372
2024-07-14 06:24:24,672 [INFO    ] __main__: train step 12648: loss: 1.0945, policy_loss: 1.0748, value_loss: 0.6371
2024-07-14 06:24:24,966 [INFO    ] __main__: train step 12649: loss: 1.0945, policy_loss: 1.0748, value_loss: 0.6371
2024-07-14 06:24:25,264 [INFO    ] __main__: train step 12650: loss: 1.0945, policy_loss: 1.0748, value_loss: 0.6371
2024-07-14 06:24:25,557 [INFO    ] __main__: train step 12651: loss: 1.0945, policy_loss: 1.0747, value_loss: 0.6370
2024-07-14 06:24:25,849 [INFO    ] __main__: train step 12652: loss: 1.0945, policy_loss: 1.0747, value_loss: 0.6370
2024-07-14 06:24:26,138 [INFO    ] __main__: train step 12653: loss: 1.0945, policy_loss: 1.0747, value_loss: 0.6370
2024-07-14 06:24:26,433 [INFO    ] __main__: train step 12654: loss: 1.0945, policy_loss: 1.0747, value_loss: 0.6369
2024-07-14 06:24:26,736 [INFO    ] __main__: train step 12655: loss: 1.0945, policy_loss: 1.0746, value_loss: 0.6369
2024-07-14 06:24:27,028 [INFO    ] __main__: train step 12656: loss: 1.0945, policy_loss: 1.0746, value_loss: 0.6369
2024-07-14 06:24:27,323 [INFO    ] __main__: train step 12657: loss: 1.0945, policy_loss: 1.0746, value_loss: 0.6368
2024-07-14 06:24:27,612 [INFO    ] __main__: train step 12658: loss: 1.0945, policy_loss: 1.0746, value_loss: 0.6368
2024-07-14 06:24:27,907 [INFO    ] __main__: train step 12659: loss: 1.0945, policy_loss: 1.0746, value_loss: 0.6368
2024-07-14 06:24:28,195 [INFO    ] __main__: train step 12660: loss: 1.0945, policy_loss: 1.0745, value_loss: 0.6367
2024-07-14 06:24:28,494 [INFO    ] __main__: train step 12661: loss: 1.0944, policy_loss: 1.0745, value_loss: 0.6367
2024-07-14 06:24:30,112 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:24:30,594 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:24:30,660 [INFO    ] __main__: train step 12662: loss: 1.0944, policy_loss: 1.0745, value_loss: 0.6367
2024-07-14 06:24:30,949 [INFO    ] __main__: train step 12663: loss: 1.0944, policy_loss: 1.0745, value_loss: 0.6366
2024-07-14 06:24:31,240 [INFO    ] __main__: train step 12664: loss: 1.0944, policy_loss: 1.0745, value_loss: 0.6366
2024-07-14 06:24:31,526 [INFO    ] __main__: train step 12665: loss: 1.0944, policy_loss: 1.0744, value_loss: 0.6366
2024-07-14 06:24:31,808 [INFO    ] __main__: train step 12666: loss: 1.0944, policy_loss: 1.0744, value_loss: 0.6365
2024-07-14 06:24:32,098 [INFO    ] __main__: train step 12667: loss: 1.0944, policy_loss: 1.0744, value_loss: 0.6365
2024-07-14 06:24:32,400 [INFO    ] __main__: train step 12668: loss: 1.0944, policy_loss: 1.0744, value_loss: 0.6365
2024-07-14 06:24:32,692 [INFO    ] __main__: train step 12669: loss: 1.0944, policy_loss: 1.0743, value_loss: 0.6364
2024-07-14 06:24:32,989 [INFO    ] __main__: train step 12670: loss: 1.0944, policy_loss: 1.0743, value_loss: 0.6364
2024-07-14 06:24:33,286 [INFO    ] __main__: train step 12671: loss: 1.0944, policy_loss: 1.0743, value_loss: 0.6364
2024-07-14 06:24:33,584 [INFO    ] __main__: train step 12672: loss: 1.0944, policy_loss: 1.0743, value_loss: 0.6363
2024-07-14 06:24:33,874 [INFO    ] __main__: train step 12673: loss: 1.0944, policy_loss: 1.0743, value_loss: 0.6363
2024-07-14 06:24:34,177 [INFO    ] __main__: train step 12674: loss: 1.0944, policy_loss: 1.0742, value_loss: 0.6363
2024-07-14 06:24:34,464 [INFO    ] __main__: train step 12675: loss: 1.0943, policy_loss: 1.0742, value_loss: 0.6362
2024-07-14 06:24:34,753 [INFO    ] __main__: train step 12676: loss: 1.0943, policy_loss: 1.0742, value_loss: 0.6362
2024-07-14 06:24:35,041 [INFO    ] __main__: train step 12677: loss: 1.0943, policy_loss: 1.0742, value_loss: 0.6361
2024-07-14 06:24:35,333 [INFO    ] __main__: train step 12678: loss: 1.0943, policy_loss: 1.0742, value_loss: 0.6361
2024-07-14 06:24:36,941 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:24:37,434 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:24:37,505 [INFO    ] __main__: train step 12679: loss: 1.0943, policy_loss: 1.0741, value_loss: 0.6361
2024-07-14 06:24:37,794 [INFO    ] __main__: train step 12680: loss: 1.0943, policy_loss: 1.0741, value_loss: 0.6360
2024-07-14 06:24:38,091 [INFO    ] __main__: train step 12681: loss: 1.0943, policy_loss: 1.0741, value_loss: 0.6360
2024-07-14 06:24:38,378 [INFO    ] __main__: train step 12682: loss: 1.0943, policy_loss: 1.0741, value_loss: 0.6360
2024-07-14 06:24:38,665 [INFO    ] __main__: train step 12683: loss: 1.0943, policy_loss: 1.0740, value_loss: 0.6359
2024-07-14 06:24:38,947 [INFO    ] __main__: train step 12684: loss: 1.0943, policy_loss: 1.0740, value_loss: 0.6359
2024-07-14 06:24:39,231 [INFO    ] __main__: train step 12685: loss: 1.0943, policy_loss: 1.0740, value_loss: 0.6359
2024-07-14 06:24:39,513 [INFO    ] __main__: train step 12686: loss: 1.0943, policy_loss: 1.0740, value_loss: 0.6358
2024-07-14 06:24:39,813 [INFO    ] __main__: train step 12687: loss: 1.0943, policy_loss: 1.0740, value_loss: 0.6358
2024-07-14 06:24:40,106 [INFO    ] __main__: train step 12688: loss: 1.0943, policy_loss: 1.0739, value_loss: 0.6358
2024-07-14 06:24:40,403 [INFO    ] __main__: train step 12689: loss: 1.0943, policy_loss: 1.0739, value_loss: 0.6357
2024-07-14 06:24:40,692 [INFO    ] __main__: train step 12690: loss: 1.0942, policy_loss: 1.0739, value_loss: 0.6357
2024-07-14 06:24:40,983 [INFO    ] __main__: train step 12691: loss: 1.0942, policy_loss: 1.0739, value_loss: 0.6357
2024-07-14 06:24:41,280 [INFO    ] __main__: train step 12692: loss: 1.0942, policy_loss: 1.0739, value_loss: 0.6356
2024-07-14 06:24:41,571 [INFO    ] __main__: train step 12693: loss: 1.0942, policy_loss: 1.0738, value_loss: 0.6356
2024-07-14 06:24:41,875 [INFO    ] __main__: train step 12694: loss: 1.0942, policy_loss: 1.0738, value_loss: 0.6356
2024-07-14 06:24:42,168 [INFO    ] __main__: train step 12695: loss: 1.0942, policy_loss: 1.0738, value_loss: 0.6355
2024-07-14 06:24:43,770 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:24:44,258 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:24:44,326 [INFO    ] __main__: train step 12696: loss: 1.0942, policy_loss: 1.0738, value_loss: 0.6355
2024-07-14 06:24:44,609 [INFO    ] __main__: train step 12697: loss: 1.0942, policy_loss: 1.0737, value_loss: 0.6355
2024-07-14 06:24:44,893 [INFO    ] __main__: train step 12698: loss: 1.0942, policy_loss: 1.0737, value_loss: 0.6354
2024-07-14 06:24:45,174 [INFO    ] __main__: train step 12699: loss: 1.0942, policy_loss: 1.0737, value_loss: 0.6354
2024-07-14 06:24:45,460 [INFO    ] __main__: train step 12700: loss: 1.0942, policy_loss: 1.0737, value_loss: 0.6354
2024-07-14 06:24:45,752 [INFO    ] __main__: train step 12701: loss: 1.0942, policy_loss: 1.0737, value_loss: 0.6353
2024-07-14 06:24:46,035 [INFO    ] __main__: train step 12702: loss: 1.0942, policy_loss: 1.0736, value_loss: 0.6353
2024-07-14 06:24:46,326 [INFO    ] __main__: train step 12703: loss: 1.0941, policy_loss: 1.0736, value_loss: 0.6353
2024-07-14 06:24:46,625 [INFO    ] __main__: train step 12704: loss: 1.0941, policy_loss: 1.0736, value_loss: 0.6352
2024-07-14 06:24:46,925 [INFO    ] __main__: train step 12705: loss: 1.0941, policy_loss: 1.0736, value_loss: 0.6352
2024-07-14 06:24:47,212 [INFO    ] __main__: train step 12706: loss: 1.0941, policy_loss: 1.0735, value_loss: 0.6352
2024-07-14 06:24:47,495 [INFO    ] __main__: train step 12707: loss: 1.0941, policy_loss: 1.0735, value_loss: 0.6351
2024-07-14 06:24:47,781 [INFO    ] __main__: train step 12708: loss: 1.0941, policy_loss: 1.0735, value_loss: 0.6351
2024-07-14 06:24:48,078 [INFO    ] __main__: train step 12709: loss: 1.0941, policy_loss: 1.0735, value_loss: 0.6351
2024-07-14 06:24:48,357 [INFO    ] __main__: train step 12710: loss: 1.0941, policy_loss: 1.0735, value_loss: 0.6350
2024-07-14 06:24:48,642 [INFO    ] __main__: train step 12711: loss: 1.0941, policy_loss: 1.0734, value_loss: 0.6350
2024-07-14 06:24:48,932 [INFO    ] __main__: train step 12712: loss: 1.0941, policy_loss: 1.0734, value_loss: 0.6350
2024-07-14 06:24:50,543 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:24:51,039 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:24:51,108 [INFO    ] __main__: train step 12713: loss: 1.0941, policy_loss: 1.0734, value_loss: 0.6349
2024-07-14 06:24:51,393 [INFO    ] __main__: train step 12714: loss: 1.0941, policy_loss: 1.0734, value_loss: 0.6349
2024-07-14 06:24:51,682 [INFO    ] __main__: train step 12715: loss: 1.0941, policy_loss: 1.0734, value_loss: 0.6349
2024-07-14 06:24:51,970 [INFO    ] __main__: train step 12716: loss: 1.0941, policy_loss: 1.0733, value_loss: 0.6348
2024-07-14 06:24:52,258 [INFO    ] __main__: train step 12717: loss: 1.0941, policy_loss: 1.0733, value_loss: 0.6348
2024-07-14 06:24:52,573 [INFO    ] __main__: train step 12718: loss: 1.0940, policy_loss: 1.0733, value_loss: 0.6348
2024-07-14 06:24:52,871 [INFO    ] __main__: train step 12719: loss: 1.0940, policy_loss: 1.0733, value_loss: 0.6347
2024-07-14 06:24:53,160 [INFO    ] __main__: train step 12720: loss: 1.0940, policy_loss: 1.0732, value_loss: 0.6347
2024-07-14 06:24:53,455 [INFO    ] __main__: train step 12721: loss: 1.0940, policy_loss: 1.0732, value_loss: 0.6347
2024-07-14 06:24:53,740 [INFO    ] __main__: train step 12722: loss: 1.0940, policy_loss: 1.0732, value_loss: 0.6346
2024-07-14 06:24:54,032 [INFO    ] __main__: train step 12723: loss: 1.0940, policy_loss: 1.0732, value_loss: 0.6346
2024-07-14 06:24:54,318 [INFO    ] __main__: train step 12724: loss: 1.0940, policy_loss: 1.0732, value_loss: 0.6346
2024-07-14 06:24:54,591 [INFO    ] __main__: train step 12725: loss: 1.0940, policy_loss: 1.0731, value_loss: 0.6345
2024-07-14 06:24:57,466 [INFO    ] __main__: train step 12726: loss: 1.0940, policy_loss: 1.0731, value_loss: 0.6345
2024-07-14 06:24:57,744 [INFO    ] __main__: train step 12727: loss: 1.0940, policy_loss: 1.0731, value_loss: 0.6344
2024-07-14 06:24:58,016 [INFO    ] __main__: train step 12728: loss: 1.0940, policy_loss: 1.0731, value_loss: 0.6344
2024-07-14 06:24:58,311 [INFO    ] __main__: train step 12729: loss: 1.0940, policy_loss: 1.0731, value_loss: 0.6344
2024-07-14 06:24:59,940 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:25:00,437 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:25:00,506 [INFO    ] __main__: train step 12730: loss: 1.0940, policy_loss: 1.0730, value_loss: 0.6343
2024-07-14 06:25:00,804 [INFO    ] __main__: train step 12731: loss: 1.0939, policy_loss: 1.0730, value_loss: 0.6343
2024-07-14 06:25:01,084 [INFO    ] __main__: train step 12732: loss: 1.0939, policy_loss: 1.0730, value_loss: 0.6343
2024-07-14 06:25:01,364 [INFO    ] __main__: train step 12733: loss: 1.0939, policy_loss: 1.0730, value_loss: 0.6342
2024-07-14 06:25:01,651 [INFO    ] __main__: train step 12734: loss: 1.0939, policy_loss: 1.0729, value_loss: 0.6342
2024-07-14 06:25:01,938 [INFO    ] __main__: train step 12735: loss: 1.0939, policy_loss: 1.0729, value_loss: 0.6342
2024-07-14 06:25:02,223 [INFO    ] __main__: train step 12736: loss: 1.0939, policy_loss: 1.0729, value_loss: 0.6341
2024-07-14 06:25:02,507 [INFO    ] __main__: train step 12737: loss: 1.0939, policy_loss: 1.0729, value_loss: 0.6341
2024-07-14 06:25:02,796 [INFO    ] __main__: train step 12738: loss: 1.0939, policy_loss: 1.0729, value_loss: 0.6341
2024-07-14 06:25:03,083 [INFO    ] __main__: train step 12739: loss: 1.0939, policy_loss: 1.0728, value_loss: 0.6340
2024-07-14 06:25:03,369 [INFO    ] __main__: train step 12740: loss: 1.0939, policy_loss: 1.0728, value_loss: 0.6340
2024-07-14 06:25:03,667 [INFO    ] __main__: train step 12741: loss: 1.0939, policy_loss: 1.0728, value_loss: 0.6340
2024-07-14 06:25:03,965 [INFO    ] __main__: train step 12742: loss: 1.0939, policy_loss: 1.0728, value_loss: 0.6339
2024-07-14 06:25:04,247 [INFO    ] __main__: train step 12743: loss: 1.0939, policy_loss: 1.0727, value_loss: 0.6339
2024-07-14 06:25:04,542 [INFO    ] __main__: train step 12744: loss: 1.0938, policy_loss: 1.0727, value_loss: 0.6339
2024-07-14 06:25:04,814 [INFO    ] __main__: train step 12745: loss: 1.0938, policy_loss: 1.0727, value_loss: 0.6338
2024-07-14 06:25:05,103 [INFO    ] __main__: train step 12746: loss: 1.0938, policy_loss: 1.0727, value_loss: 0.6338
2024-07-14 06:25:06,718 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:25:07,210 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:25:07,278 [INFO    ] __main__: train step 12747: loss: 1.0938, policy_loss: 1.0727, value_loss: 0.6338
2024-07-14 06:25:07,566 [INFO    ] __main__: train step 12748: loss: 1.0938, policy_loss: 1.0726, value_loss: 0.6337
2024-07-14 06:25:07,868 [INFO    ] __main__: train step 12749: loss: 1.0938, policy_loss: 1.0726, value_loss: 0.6337
2024-07-14 06:25:08,154 [INFO    ] __main__: train step 12750: loss: 1.0938, policy_loss: 1.0726, value_loss: 0.6337
2024-07-14 06:25:08,445 [INFO    ] __main__: train step 12751: loss: 1.0938, policy_loss: 1.0726, value_loss: 0.6336
2024-07-14 06:25:08,733 [INFO    ] __main__: train step 12752: loss: 1.0938, policy_loss: 1.0725, value_loss: 0.6336
2024-07-14 06:25:09,020 [INFO    ] __main__: train step 12753: loss: 1.0938, policy_loss: 1.0725, value_loss: 0.6336
2024-07-14 06:25:09,314 [INFO    ] __main__: train step 12754: loss: 1.0938, policy_loss: 1.0725, value_loss: 0.6335
2024-07-14 06:25:09,603 [INFO    ] __main__: train step 12755: loss: 1.0938, policy_loss: 1.0725, value_loss: 0.6335
2024-07-14 06:25:09,895 [INFO    ] __main__: train step 12756: loss: 1.0938, policy_loss: 1.0725, value_loss: 0.6335
2024-07-14 06:25:10,177 [INFO    ] __main__: train step 12757: loss: 1.0937, policy_loss: 1.0724, value_loss: 0.6334
2024-07-14 06:25:10,469 [INFO    ] __main__: train step 12758: loss: 1.0937, policy_loss: 1.0724, value_loss: 0.6334
2024-07-14 06:25:10,770 [INFO    ] __main__: train step 12759: loss: 1.0937, policy_loss: 1.0724, value_loss: 0.6334
2024-07-14 06:25:11,061 [INFO    ] __main__: train step 12760: loss: 1.0937, policy_loss: 1.0724, value_loss: 0.6333
2024-07-14 06:25:11,335 [INFO    ] __main__: train step 12761: loss: 1.0937, policy_loss: 1.0724, value_loss: 0.6333
2024-07-14 06:25:11,611 [INFO    ] __main__: train step 12762: loss: 1.0937, policy_loss: 1.0723, value_loss: 0.6333
2024-07-14 06:25:11,898 [INFO    ] __main__: train step 12763: loss: 1.0937, policy_loss: 1.0723, value_loss: 0.6332
2024-07-14 06:25:13,504 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:25:14,007 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:25:14,077 [INFO    ] __main__: train step 12764: loss: 1.0937, policy_loss: 1.0723, value_loss: 0.6332
2024-07-14 06:25:14,375 [INFO    ] __main__: train step 12765: loss: 1.0937, policy_loss: 1.0723, value_loss: 0.6332
2024-07-14 06:25:14,651 [INFO    ] __main__: train step 12766: loss: 1.0937, policy_loss: 1.0722, value_loss: 0.6331
2024-07-14 06:25:14,937 [INFO    ] __main__: train step 12767: loss: 1.0937, policy_loss: 1.0722, value_loss: 0.6331
2024-07-14 06:25:15,218 [INFO    ] __main__: train step 12768: loss: 1.0937, policy_loss: 1.0722, value_loss: 0.6331
2024-07-14 06:25:15,504 [INFO    ] __main__: train step 12769: loss: 1.0937, policy_loss: 1.0722, value_loss: 0.6330
2024-07-14 06:25:15,786 [INFO    ] __main__: train step 12770: loss: 1.0936, policy_loss: 1.0722, value_loss: 0.6330
2024-07-14 06:25:16,067 [INFO    ] __main__: train step 12771: loss: 1.0936, policy_loss: 1.0721, value_loss: 0.6330
2024-07-14 06:25:16,350 [INFO    ] __main__: train step 12772: loss: 1.0936, policy_loss: 1.0721, value_loss: 0.6329
2024-07-14 06:25:16,640 [INFO    ] __main__: train step 12773: loss: 1.0936, policy_loss: 1.0721, value_loss: 0.6329
2024-07-14 06:25:16,927 [INFO    ] __main__: train step 12774: loss: 1.0936, policy_loss: 1.0721, value_loss: 0.6329
2024-07-14 06:25:17,215 [INFO    ] __main__: train step 12775: loss: 1.0936, policy_loss: 1.0720, value_loss: 0.6328
2024-07-14 06:25:17,513 [INFO    ] __main__: train step 12776: loss: 1.0936, policy_loss: 1.0720, value_loss: 0.6328
2024-07-14 06:25:17,799 [INFO    ] __main__: train step 12777: loss: 1.0936, policy_loss: 1.0720, value_loss: 0.6328
2024-07-14 06:25:18,095 [INFO    ] __main__: train step 12778: loss: 1.0936, policy_loss: 1.0720, value_loss: 0.6327
2024-07-14 06:25:18,384 [INFO    ] __main__: train step 12779: loss: 1.0936, policy_loss: 1.0720, value_loss: 0.6327
2024-07-14 06:25:18,671 [INFO    ] __main__: train step 12780: loss: 1.0936, policy_loss: 1.0719, value_loss: 0.6327
2024-07-14 06:25:20,291 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:25:20,776 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:25:20,845 [INFO    ] __main__: train step 12781: loss: 1.0936, policy_loss: 1.0719, value_loss: 0.6326
2024-07-14 06:25:21,146 [INFO    ] __main__: train step 12782: loss: 1.0936, policy_loss: 1.0719, value_loss: 0.6326
2024-07-14 06:25:21,443 [INFO    ] __main__: train step 12783: loss: 1.0936, policy_loss: 1.0719, value_loss: 0.6326
2024-07-14 06:25:21,734 [INFO    ] __main__: train step 12784: loss: 1.0935, policy_loss: 1.0719, value_loss: 0.6325
2024-07-14 06:25:22,021 [INFO    ] __main__: train step 12785: loss: 1.0935, policy_loss: 1.0718, value_loss: 0.6325
2024-07-14 06:25:22,309 [INFO    ] __main__: train step 12786: loss: 1.0935, policy_loss: 1.0718, value_loss: 0.6325
2024-07-14 06:25:22,597 [INFO    ] __main__: train step 12787: loss: 1.0935, policy_loss: 1.0718, value_loss: 0.6324
2024-07-14 06:25:22,886 [INFO    ] __main__: train step 12788: loss: 1.0935, policy_loss: 1.0718, value_loss: 0.6324
2024-07-14 06:25:23,173 [INFO    ] __main__: train step 12789: loss: 1.0935, policy_loss: 1.0717, value_loss: 0.6324
2024-07-14 06:25:23,464 [INFO    ] __main__: train step 12790: loss: 1.0935, policy_loss: 1.0717, value_loss: 0.6323
2024-07-14 06:25:23,752 [INFO    ] __main__: train step 12791: loss: 1.0935, policy_loss: 1.0717, value_loss: 0.6323
2024-07-14 06:25:24,046 [INFO    ] __main__: train step 12792: loss: 1.0935, policy_loss: 1.0717, value_loss: 0.6323
2024-07-14 06:25:24,331 [INFO    ] __main__: train step 12793: loss: 1.0935, policy_loss: 1.0717, value_loss: 0.6322
2024-07-14 06:25:24,619 [INFO    ] __main__: train step 12794: loss: 1.0935, policy_loss: 1.0716, value_loss: 0.6322
2024-07-14 06:25:24,910 [INFO    ] __main__: train step 12795: loss: 1.0935, policy_loss: 1.0716, value_loss: 0.6321
2024-07-14 06:25:25,206 [INFO    ] __main__: train step 12796: loss: 1.0934, policy_loss: 1.0716, value_loss: 0.6321
2024-07-14 06:25:25,492 [INFO    ] __main__: train step 12797: loss: 1.0934, policy_loss: 1.0716, value_loss: 0.6321
2024-07-14 06:25:27,113 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:25:27,601 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:25:27,674 [INFO    ] __main__: train step 12798: loss: 1.0934, policy_loss: 1.0715, value_loss: 0.6321
2024-07-14 06:25:27,965 [INFO    ] __main__: train step 12799: loss: 1.0934, policy_loss: 1.0715, value_loss: 0.6320
2024-07-14 06:25:28,250 [INFO    ] __main__: train step 12800: loss: 1.0934, policy_loss: 1.0715, value_loss: 0.6320
2024-07-14 06:25:28,534 [INFO    ] __main__: train step 12801: loss: 1.0934, policy_loss: 1.0715, value_loss: 0.6319
2024-07-14 06:25:28,813 [INFO    ] __main__: train step 12802: loss: 1.0934, policy_loss: 1.0715, value_loss: 0.6319
2024-07-14 06:25:29,083 [INFO    ] __main__: train step 12803: loss: 1.0934, policy_loss: 1.0714, value_loss: 0.6319
2024-07-14 06:25:29,341 [INFO    ] __main__: train step 12804: loss: 1.0934, policy_loss: 1.0714, value_loss: 0.6318
2024-07-14 06:25:29,635 [INFO    ] __main__: train step 12805: loss: 1.0934, policy_loss: 1.0714, value_loss: 0.6318
2024-07-14 06:25:29,925 [INFO    ] __main__: train step 12806: loss: 1.0934, policy_loss: 1.0714, value_loss: 0.6318
2024-07-14 06:25:30,227 [INFO    ] __main__: train step 12807: loss: 1.0934, policy_loss: 1.0714, value_loss: 0.6317
2024-07-14 06:25:30,513 [INFO    ] __main__: train step 12808: loss: 1.0933, policy_loss: 1.0713, value_loss: 0.6317
2024-07-14 06:25:30,806 [INFO    ] __main__: train step 12809: loss: 1.0933, policy_loss: 1.0713, value_loss: 0.6317
2024-07-14 06:25:31,088 [INFO    ] __main__: train step 12810: loss: 1.0933, policy_loss: 1.0713, value_loss: 0.6316
2024-07-14 06:25:31,387 [INFO    ] __main__: train step 12811: loss: 1.0933, policy_loss: 1.0713, value_loss: 0.6316
2024-07-14 06:25:31,670 [INFO    ] __main__: train step 12812: loss: 1.0933, policy_loss: 1.0712, value_loss: 0.6316
2024-07-14 06:25:31,950 [INFO    ] __main__: train step 12813: loss: 1.0933, policy_loss: 1.0712, value_loss: 0.6315
2024-07-14 06:25:32,225 [INFO    ] __main__: train step 12814: loss: 1.0933, policy_loss: 1.0712, value_loss: 0.6315
2024-07-14 06:25:33,836 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:25:34,330 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:25:34,401 [INFO    ] __main__: train step 12815: loss: 1.0933, policy_loss: 1.0712, value_loss: 0.6315
2024-07-14 06:25:34,688 [INFO    ] __main__: train step 12816: loss: 1.0933, policy_loss: 1.0712, value_loss: 0.6314
2024-07-14 06:25:36,695 [INFO    ] __main__: train step 12817: loss: 1.0933, policy_loss: 1.0711, value_loss: 0.6314
2024-07-14 06:25:36,984 [INFO    ] __main__: train step 12818: loss: 1.0933, policy_loss: 1.0711, value_loss: 0.6314
2024-07-14 06:25:37,288 [INFO    ] __main__: train step 12819: loss: 1.0933, policy_loss: 1.0711, value_loss: 0.6313
2024-07-14 06:25:37,576 [INFO    ] __main__: train step 12820: loss: 1.0933, policy_loss: 1.0711, value_loss: 0.6313
2024-07-14 06:25:37,860 [INFO    ] __main__: train step 12821: loss: 1.0932, policy_loss: 1.0710, value_loss: 0.6313
2024-07-14 06:25:38,114 [INFO    ] __main__: train step 12822: loss: 1.0932, policy_loss: 1.0710, value_loss: 0.6312
2024-07-14 06:25:38,376 [INFO    ] __main__: train step 12823: loss: 1.0932, policy_loss: 1.0710, value_loss: 0.6312
2024-07-14 06:25:38,664 [INFO    ] __main__: train step 12824: loss: 1.0932, policy_loss: 1.0710, value_loss: 0.6312
2024-07-14 06:25:38,948 [INFO    ] __main__: train step 12825: loss: 1.0932, policy_loss: 1.0710, value_loss: 0.6311
2024-07-14 06:25:39,232 [INFO    ] __main__: train step 12826: loss: 1.0932, policy_loss: 1.0709, value_loss: 0.6311
2024-07-14 06:25:39,528 [INFO    ] __main__: train step 12827: loss: 1.0932, policy_loss: 1.0709, value_loss: 0.6311
2024-07-14 06:25:39,820 [INFO    ] __main__: train step 12828: loss: 1.0932, policy_loss: 1.0709, value_loss: 0.6310
2024-07-14 06:25:40,103 [INFO    ] __main__: train step 12829: loss: 1.0932, policy_loss: 1.0709, value_loss: 0.6310
2024-07-14 06:25:40,393 [INFO    ] __main__: train step 12830: loss: 1.0932, policy_loss: 1.0709, value_loss: 0.6310
2024-07-14 06:25:40,670 [INFO    ] __main__: train step 12831: loss: 1.0932, policy_loss: 1.0708, value_loss: 0.6309
2024-07-14 06:25:42,278 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:25:42,767 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:25:42,836 [INFO    ] __main__: train step 12832: loss: 1.0932, policy_loss: 1.0708, value_loss: 0.6309
2024-07-14 06:25:43,126 [INFO    ] __main__: train step 12833: loss: 1.0932, policy_loss: 1.0708, value_loss: 0.6309
2024-07-14 06:25:43,410 [INFO    ] __main__: train step 12834: loss: 1.0931, policy_loss: 1.0708, value_loss: 0.6308
2024-07-14 06:25:43,695 [INFO    ] __main__: train step 12835: loss: 1.0931, policy_loss: 1.0707, value_loss: 0.6308
2024-07-14 06:25:43,970 [INFO    ] __main__: train step 12836: loss: 1.0931, policy_loss: 1.0707, value_loss: 0.6308
2024-07-14 06:25:44,251 [INFO    ] __main__: train step 12837: loss: 1.0931, policy_loss: 1.0707, value_loss: 0.6307
2024-07-14 06:25:44,518 [INFO    ] __main__: train step 12838: loss: 1.0931, policy_loss: 1.0707, value_loss: 0.6307
2024-07-14 06:25:44,809 [INFO    ] __main__: train step 12839: loss: 1.0931, policy_loss: 1.0707, value_loss: 0.6307
2024-07-14 06:25:45,102 [INFO    ] __main__: train step 12840: loss: 1.0931, policy_loss: 1.0706, value_loss: 0.6306
2024-07-14 06:25:45,391 [INFO    ] __main__: train step 12841: loss: 1.0931, policy_loss: 1.0706, value_loss: 0.6306
2024-07-14 06:25:45,675 [INFO    ] __main__: train step 12842: loss: 1.0931, policy_loss: 1.0706, value_loss: 0.6306
2024-07-14 06:25:45,958 [INFO    ] __main__: train step 12843: loss: 1.0931, policy_loss: 1.0706, value_loss: 0.6305
2024-07-14 06:25:46,245 [INFO    ] __main__: train step 12844: loss: 1.0931, policy_loss: 1.0706, value_loss: 0.6305
2024-07-14 06:25:46,531 [INFO    ] __main__: train step 12845: loss: 1.0931, policy_loss: 1.0705, value_loss: 0.6305
2024-07-14 06:25:46,812 [INFO    ] __main__: train step 12846: loss: 1.0931, policy_loss: 1.0705, value_loss: 0.6304
2024-07-14 06:25:47,085 [INFO    ] __main__: train step 12847: loss: 1.0930, policy_loss: 1.0705, value_loss: 0.6304
2024-07-14 06:25:47,371 [INFO    ] __main__: train step 12848: loss: 1.0930, policy_loss: 1.0705, value_loss: 0.6304
2024-07-14 06:25:48,936 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:25:49,409 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:25:49,483 [INFO    ] __main__: train step 12849: loss: 1.0930, policy_loss: 1.0704, value_loss: 0.6303
2024-07-14 06:25:49,750 [INFO    ] __main__: train step 12850: loss: 1.0930, policy_loss: 1.0704, value_loss: 0.6303
2024-07-14 06:25:50,034 [INFO    ] __main__: train step 12851: loss: 1.0930, policy_loss: 1.0704, value_loss: 0.6303
2024-07-14 06:25:50,325 [INFO    ] __main__: train step 12852: loss: 1.0930, policy_loss: 1.0704, value_loss: 0.6302
2024-07-14 06:25:50,609 [INFO    ] __main__: train step 12853: loss: 1.0930, policy_loss: 1.0704, value_loss: 0.6302
2024-07-14 06:25:50,896 [INFO    ] __main__: train step 12854: loss: 1.0930, policy_loss: 1.0703, value_loss: 0.6302
2024-07-14 06:25:51,179 [INFO    ] __main__: train step 12855: loss: 1.0930, policy_loss: 1.0703, value_loss: 0.6301
2024-07-14 06:25:51,459 [INFO    ] __main__: train step 12856: loss: 1.0930, policy_loss: 1.0703, value_loss: 0.6301
2024-07-14 06:25:51,741 [INFO    ] __main__: train step 12857: loss: 1.0930, policy_loss: 1.0703, value_loss: 0.6301
2024-07-14 06:25:52,021 [INFO    ] __main__: train step 12858: loss: 1.0930, policy_loss: 1.0702, value_loss: 0.6300
2024-07-14 06:25:52,309 [INFO    ] __main__: train step 12859: loss: 1.0929, policy_loss: 1.0702, value_loss: 0.6300
2024-07-14 06:25:52,589 [INFO    ] __main__: train step 12860: loss: 1.0929, policy_loss: 1.0702, value_loss: 0.6300
2024-07-14 06:25:52,865 [INFO    ] __main__: train step 12861: loss: 1.0929, policy_loss: 1.0702, value_loss: 0.6299
2024-07-14 06:25:53,144 [INFO    ] __main__: train step 12862: loss: 1.0929, policy_loss: 1.0702, value_loss: 0.6299
2024-07-14 06:25:53,424 [INFO    ] __main__: train step 12863: loss: 1.0929, policy_loss: 1.0701, value_loss: 0.6299
2024-07-14 06:25:53,708 [INFO    ] __main__: train step 12864: loss: 1.0929, policy_loss: 1.0701, value_loss: 0.6298
2024-07-14 06:25:53,996 [INFO    ] __main__: train step 12865: loss: 1.0929, policy_loss: 1.0701, value_loss: 0.6298
2024-07-14 06:25:55,617 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:25:56,103 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:25:56,174 [INFO    ] __main__: train step 12866: loss: 1.0929, policy_loss: 1.0701, value_loss: 0.6298
2024-07-14 06:25:56,465 [INFO    ] __main__: train step 12867: loss: 1.0929, policy_loss: 1.0700, value_loss: 0.6297
2024-07-14 06:25:56,757 [INFO    ] __main__: train step 12868: loss: 1.0929, policy_loss: 1.0700, value_loss: 0.6297
2024-07-14 06:25:57,052 [INFO    ] __main__: train step 12869: loss: 1.0929, policy_loss: 1.0700, value_loss: 0.6297
2024-07-14 06:25:57,337 [INFO    ] __main__: train step 12870: loss: 1.0929, policy_loss: 1.0700, value_loss: 0.6296
2024-07-14 06:25:57,628 [INFO    ] __main__: train step 12871: loss: 1.0928, policy_loss: 1.0700, value_loss: 0.6296
2024-07-14 06:25:57,918 [INFO    ] __main__: train step 12872: loss: 1.0928, policy_loss: 1.0699, value_loss: 0.6296
2024-07-14 06:25:58,207 [INFO    ] __main__: train step 12873: loss: 1.0928, policy_loss: 1.0699, value_loss: 0.6295
2024-07-14 06:25:58,498 [INFO    ] __main__: train step 12874: loss: 1.0928, policy_loss: 1.0699, value_loss: 0.6295
2024-07-14 06:25:58,803 [INFO    ] __main__: train step 12875: loss: 1.0928, policy_loss: 1.0699, value_loss: 0.6295
2024-07-14 06:25:59,090 [INFO    ] __main__: train step 12876: loss: 1.0928, policy_loss: 1.0698, value_loss: 0.6294
2024-07-14 06:25:59,398 [INFO    ] __main__: train step 12877: loss: 1.0928, policy_loss: 1.0698, value_loss: 0.6294
2024-07-14 06:25:59,681 [INFO    ] __main__: train step 12878: loss: 1.0928, policy_loss: 1.0698, value_loss: 0.6294
2024-07-14 06:25:59,963 [INFO    ] __main__: train step 12879: loss: 1.0928, policy_loss: 1.0698, value_loss: 0.6293
2024-07-14 06:26:00,257 [INFO    ] __main__: train step 12880: loss: 1.0928, policy_loss: 1.0698, value_loss: 0.6293
2024-07-14 06:26:00,553 [INFO    ] __main__: train step 12881: loss: 1.0928, policy_loss: 1.0697, value_loss: 0.6293
2024-07-14 06:26:00,833 [INFO    ] __main__: train step 12882: loss: 1.0928, policy_loss: 1.0697, value_loss: 0.6292
2024-07-14 06:26:02,457 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:26:02,956 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:26:03,025 [INFO    ] __main__: train step 12883: loss: 1.0927, policy_loss: 1.0697, value_loss: 0.6292
2024-07-14 06:26:03,322 [INFO    ] __main__: train step 12884: loss: 1.0927, policy_loss: 1.0697, value_loss: 0.6292
2024-07-14 06:26:03,612 [INFO    ] __main__: train step 12885: loss: 1.0927, policy_loss: 1.0697, value_loss: 0.6291
2024-07-14 06:26:03,899 [INFO    ] __main__: train step 12886: loss: 1.0927, policy_loss: 1.0696, value_loss: 0.6291
2024-07-14 06:26:04,191 [INFO    ] __main__: train step 12887: loss: 1.0927, policy_loss: 1.0696, value_loss: 0.6291
2024-07-14 06:26:04,470 [INFO    ] __main__: train step 12888: loss: 1.0927, policy_loss: 1.0696, value_loss: 0.6290
2024-07-14 06:26:04,757 [INFO    ] __main__: train step 12889: loss: 1.0927, policy_loss: 1.0696, value_loss: 0.6290
2024-07-14 06:26:05,054 [INFO    ] __main__: train step 12890: loss: 1.0927, policy_loss: 1.0695, value_loss: 0.6290
2024-07-14 06:26:05,348 [INFO    ] __main__: train step 12891: loss: 1.0927, policy_loss: 1.0695, value_loss: 0.6289
2024-07-14 06:26:05,650 [INFO    ] __main__: train step 12892: loss: 1.0927, policy_loss: 1.0695, value_loss: 0.6289
2024-07-14 06:26:05,929 [INFO    ] __main__: train step 12893: loss: 1.0927, policy_loss: 1.0695, value_loss: 0.6289
2024-07-14 06:26:06,247 [INFO    ] __main__: train step 12894: loss: 1.0927, policy_loss: 1.0695, value_loss: 0.6288
2024-07-14 06:26:06,542 [INFO    ] __main__: train step 12895: loss: 1.0926, policy_loss: 1.0694, value_loss: 0.6288
2024-07-14 06:26:06,849 [INFO    ] __main__: train step 12896: loss: 1.0926, policy_loss: 1.0694, value_loss: 0.6288
2024-07-14 06:26:07,135 [INFO    ] __main__: train step 12897: loss: 1.0926, policy_loss: 1.0694, value_loss: 0.6287
2024-07-14 06:26:07,442 [INFO    ] __main__: train step 12898: loss: 1.0926, policy_loss: 1.0694, value_loss: 0.6287
2024-07-14 06:26:07,735 [INFO    ] __main__: train step 12899: loss: 1.0926, policy_loss: 1.0693, value_loss: 0.6287
2024-07-14 06:26:09,354 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:26:09,845 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:26:09,915 [INFO    ] __main__: train step 12900: loss: 1.0926, policy_loss: 1.0693, value_loss: 0.6286
2024-07-14 06:26:10,212 [INFO    ] __main__: train step 12901: loss: 1.0926, policy_loss: 1.0693, value_loss: 0.6286
2024-07-14 06:26:10,516 [INFO    ] __main__: train step 12902: loss: 1.0926, policy_loss: 1.0693, value_loss: 0.6286
2024-07-14 06:26:13,414 [INFO    ] __main__: train step 12903: loss: 1.0926, policy_loss: 1.0693, value_loss: 0.6285
2024-07-14 06:26:13,722 [INFO    ] __main__: train step 12904: loss: 1.0926, policy_loss: 1.0692, value_loss: 0.6285
2024-07-14 06:26:14,015 [INFO    ] __main__: train step 12905: loss: 1.0926, policy_loss: 1.0692, value_loss: 0.6285
2024-07-14 06:26:14,302 [INFO    ] __main__: train step 12906: loss: 1.0926, policy_loss: 1.0692, value_loss: 0.6284
2024-07-14 06:26:14,602 [INFO    ] __main__: train step 12907: loss: 1.0926, policy_loss: 1.0692, value_loss: 0.6284
2024-07-14 06:26:14,893 [INFO    ] __main__: train step 12908: loss: 1.0925, policy_loss: 1.0692, value_loss: 0.6284
2024-07-14 06:26:15,179 [INFO    ] __main__: train step 12909: loss: 1.0925, policy_loss: 1.0691, value_loss: 0.6283
2024-07-14 06:26:15,463 [INFO    ] __main__: train step 12910: loss: 1.0925, policy_loss: 1.0691, value_loss: 0.6283
2024-07-14 06:26:15,768 [INFO    ] __main__: train step 12911: loss: 1.0925, policy_loss: 1.0691, value_loss: 0.6283
2024-07-14 06:26:16,054 [INFO    ] __main__: train step 12912: loss: 1.0925, policy_loss: 1.0691, value_loss: 0.6282
2024-07-14 06:26:16,336 [INFO    ] __main__: train step 12913: loss: 1.0925, policy_loss: 1.0690, value_loss: 0.6282
2024-07-14 06:26:16,626 [INFO    ] __main__: train step 12914: loss: 1.0925, policy_loss: 1.0690, value_loss: 0.6282
2024-07-14 06:26:16,924 [INFO    ] __main__: train step 12915: loss: 1.0925, policy_loss: 1.0690, value_loss: 0.6281
2024-07-14 06:26:17,207 [INFO    ] __main__: train step 12916: loss: 1.0925, policy_loss: 1.0690, value_loss: 0.6281
2024-07-14 06:26:18,825 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:26:19,311 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:26:19,379 [INFO    ] __main__: train step 12917: loss: 1.0925, policy_loss: 1.0690, value_loss: 0.6281
2024-07-14 06:26:19,662 [INFO    ] __main__: train step 12918: loss: 1.0925, policy_loss: 1.0689, value_loss: 0.6280
2024-07-14 06:26:19,923 [INFO    ] __main__: train step 12919: loss: 1.0925, policy_loss: 1.0689, value_loss: 0.6280
2024-07-14 06:26:20,218 [INFO    ] __main__: train step 12920: loss: 1.0924, policy_loss: 1.0689, value_loss: 0.6280
2024-07-14 06:26:20,500 [INFO    ] __main__: train step 12921: loss: 1.0924, policy_loss: 1.0689, value_loss: 0.6279
2024-07-14 06:26:20,791 [INFO    ] __main__: train step 12922: loss: 1.0924, policy_loss: 1.0689, value_loss: 0.6279
2024-07-14 06:26:21,086 [INFO    ] __main__: train step 12923: loss: 1.0924, policy_loss: 1.0688, value_loss: 0.6279
2024-07-14 06:26:21,383 [INFO    ] __main__: train step 12924: loss: 1.0924, policy_loss: 1.0688, value_loss: 0.6278
2024-07-14 06:26:21,665 [INFO    ] __main__: train step 12925: loss: 1.0924, policy_loss: 1.0688, value_loss: 0.6278
2024-07-14 06:26:21,956 [INFO    ] __main__: train step 12926: loss: 1.0924, policy_loss: 1.0688, value_loss: 0.6278
2024-07-14 06:26:22,252 [INFO    ] __main__: train step 12927: loss: 1.0924, policy_loss: 1.0687, value_loss: 0.6277
2024-07-14 06:26:22,548 [INFO    ] __main__: train step 12928: loss: 1.0924, policy_loss: 1.0687, value_loss: 0.6277
2024-07-14 06:26:22,844 [INFO    ] __main__: train step 12929: loss: 1.0924, policy_loss: 1.0687, value_loss: 0.6277
2024-07-14 06:26:23,135 [INFO    ] __main__: train step 12930: loss: 1.0924, policy_loss: 1.0687, value_loss: 0.6276
2024-07-14 06:26:23,427 [INFO    ] __main__: train step 12931: loss: 1.0924, policy_loss: 1.0687, value_loss: 0.6276
2024-07-14 06:26:23,711 [INFO    ] __main__: train step 12932: loss: 1.0924, policy_loss: 1.0686, value_loss: 0.6276
2024-07-14 06:26:24,004 [INFO    ] __main__: train step 12933: loss: 1.0923, policy_loss: 1.0686, value_loss: 0.6275
2024-07-14 06:26:25,626 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:26:26,115 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:26:26,187 [INFO    ] __main__: train step 12934: loss: 1.0923, policy_loss: 1.0686, value_loss: 0.6275
2024-07-14 06:26:26,488 [INFO    ] __main__: train step 12935: loss: 1.0923, policy_loss: 1.0686, value_loss: 0.6275
2024-07-14 06:26:26,773 [INFO    ] __main__: train step 12936: loss: 1.0923, policy_loss: 1.0685, value_loss: 0.6274
2024-07-14 06:26:27,061 [INFO    ] __main__: train step 12937: loss: 1.0923, policy_loss: 1.0685, value_loss: 0.6274
2024-07-14 06:26:27,337 [INFO    ] __main__: train step 12938: loss: 1.0923, policy_loss: 1.0685, value_loss: 0.6274
2024-07-14 06:26:27,619 [INFO    ] __main__: train step 12939: loss: 1.0923, policy_loss: 1.0685, value_loss: 0.6273
2024-07-14 06:26:27,909 [INFO    ] __main__: train step 12940: loss: 1.0923, policy_loss: 1.0685, value_loss: 0.6273
2024-07-14 06:26:28,194 [INFO    ] __main__: train step 12941: loss: 1.0923, policy_loss: 1.0684, value_loss: 0.6273
2024-07-14 06:26:28,465 [INFO    ] __main__: train step 12942: loss: 1.0923, policy_loss: 1.0684, value_loss: 0.6272
2024-07-14 06:26:28,732 [INFO    ] __main__: train step 12943: loss: 1.0923, policy_loss: 1.0684, value_loss: 0.6272
2024-07-14 06:26:28,999 [INFO    ] __main__: train step 12944: loss: 1.0923, policy_loss: 1.0684, value_loss: 0.6272
2024-07-14 06:26:29,262 [INFO    ] __main__: train step 12945: loss: 1.0922, policy_loss: 1.0683, value_loss: 0.6271
2024-07-14 06:26:29,526 [INFO    ] __main__: train step 12946: loss: 1.0922, policy_loss: 1.0683, value_loss: 0.6271
2024-07-14 06:26:29,794 [INFO    ] __main__: train step 12947: loss: 1.0922, policy_loss: 1.0683, value_loss: 0.6271
2024-07-14 06:26:30,091 [INFO    ] __main__: train step 12948: loss: 1.0922, policy_loss: 1.0683, value_loss: 0.6270
2024-07-14 06:26:30,380 [INFO    ] __main__: train step 12949: loss: 1.0922, policy_loss: 1.0683, value_loss: 0.6270
2024-07-14 06:26:30,661 [INFO    ] __main__: train step 12950: loss: 1.0922, policy_loss: 1.0682, value_loss: 0.6270
2024-07-14 06:26:32,280 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:26:32,769 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:26:32,841 [INFO    ] __main__: train step 12951: loss: 1.0922, policy_loss: 1.0682, value_loss: 0.6269
2024-07-14 06:26:33,142 [INFO    ] __main__: train step 12952: loss: 1.0922, policy_loss: 1.0682, value_loss: 0.6269
2024-07-14 06:26:33,424 [INFO    ] __main__: train step 12953: loss: 1.0922, policy_loss: 1.0682, value_loss: 0.6269
2024-07-14 06:26:33,709 [INFO    ] __main__: train step 12954: loss: 1.0922, policy_loss: 1.0681, value_loss: 0.6268
2024-07-14 06:26:34,001 [INFO    ] __main__: train step 12955: loss: 1.0922, policy_loss: 1.0681, value_loss: 0.6268
2024-07-14 06:26:34,296 [INFO    ] __main__: train step 12956: loss: 1.0921, policy_loss: 1.0681, value_loss: 0.6268
2024-07-14 06:26:34,593 [INFO    ] __main__: train step 12957: loss: 1.0921, policy_loss: 1.0681, value_loss: 0.6267
2024-07-14 06:26:34,879 [INFO    ] __main__: train step 12958: loss: 1.0921, policy_loss: 1.0681, value_loss: 0.6267
2024-07-14 06:26:35,173 [INFO    ] __main__: train step 12959: loss: 1.0921, policy_loss: 1.0680, value_loss: 0.6267
2024-07-14 06:26:35,467 [INFO    ] __main__: train step 12960: loss: 1.0921, policy_loss: 1.0680, value_loss: 0.6266
2024-07-14 06:26:35,760 [INFO    ] __main__: train step 12961: loss: 1.0921, policy_loss: 1.0680, value_loss: 0.6266
2024-07-14 06:26:36,073 [INFO    ] __main__: train step 12962: loss: 1.0921, policy_loss: 1.0680, value_loss: 0.6266
2024-07-14 06:26:36,360 [INFO    ] __main__: train step 12963: loss: 1.0921, policy_loss: 1.0680, value_loss: 0.6265
2024-07-14 06:26:36,645 [INFO    ] __main__: train step 12964: loss: 1.0921, policy_loss: 1.0679, value_loss: 0.6265
2024-07-14 06:26:36,934 [INFO    ] __main__: train step 12965: loss: 1.0921, policy_loss: 1.0679, value_loss: 0.6265
2024-07-14 06:26:37,224 [INFO    ] __main__: train step 12966: loss: 1.0921, policy_loss: 1.0679, value_loss: 0.6264
2024-07-14 06:26:37,515 [INFO    ] __main__: train step 12967: loss: 1.0921, policy_loss: 1.0679, value_loss: 0.6264
2024-07-14 06:26:39,119 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:26:39,608 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:26:39,677 [INFO    ] __main__: train step 12968: loss: 1.0920, policy_loss: 1.0678, value_loss: 0.6264
2024-07-14 06:26:39,965 [INFO    ] __main__: train step 12969: loss: 1.0920, policy_loss: 1.0678, value_loss: 0.6263
2024-07-14 06:26:40,261 [INFO    ] __main__: train step 12970: loss: 1.0920, policy_loss: 1.0678, value_loss: 0.6263
2024-07-14 06:26:40,539 [INFO    ] __main__: train step 12971: loss: 1.0920, policy_loss: 1.0678, value_loss: 0.6263
2024-07-14 06:26:40,808 [INFO    ] __main__: train step 12972: loss: 1.0920, policy_loss: 1.0678, value_loss: 0.6262
2024-07-14 06:26:41,092 [INFO    ] __main__: train step 12973: loss: 1.0920, policy_loss: 1.0677, value_loss: 0.6262
2024-07-14 06:26:41,384 [INFO    ] __main__: train step 12974: loss: 1.0920, policy_loss: 1.0677, value_loss: 0.6262
2024-07-14 06:26:41,684 [INFO    ] __main__: train step 12975: loss: 1.0920, policy_loss: 1.0677, value_loss: 0.6261
2024-07-14 06:26:41,972 [INFO    ] __main__: train step 12976: loss: 1.0920, policy_loss: 1.0677, value_loss: 0.6261
2024-07-14 06:26:42,265 [INFO    ] __main__: train step 12977: loss: 1.0920, policy_loss: 1.0676, value_loss: 0.6261
2024-07-14 06:26:42,565 [INFO    ] __main__: train step 12978: loss: 1.0920, policy_loss: 1.0676, value_loss: 0.6260
2024-07-14 06:26:42,858 [INFO    ] __main__: train step 12979: loss: 1.0920, policy_loss: 1.0676, value_loss: 0.6260
2024-07-14 06:26:43,138 [INFO    ] __main__: train step 12980: loss: 1.0919, policy_loss: 1.0676, value_loss: 0.6260
2024-07-14 06:26:43,443 [INFO    ] __main__: train step 12981: loss: 1.0919, policy_loss: 1.0676, value_loss: 0.6259
2024-07-14 06:26:43,736 [INFO    ] __main__: train step 12982: loss: 1.0919, policy_loss: 1.0675, value_loss: 0.6259
2024-07-14 06:26:44,012 [INFO    ] __main__: train step 12983: loss: 1.0919, policy_loss: 1.0675, value_loss: 0.6259
2024-07-14 06:26:44,290 [INFO    ] __main__: train step 12984: loss: 1.0919, policy_loss: 1.0675, value_loss: 0.6258
2024-07-14 06:26:45,921 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:26:46,412 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:26:46,484 [INFO    ] __main__: train step 12985: loss: 1.0919, policy_loss: 1.0675, value_loss: 0.6258
2024-07-14 06:26:46,763 [INFO    ] __main__: train step 12986: loss: 1.0919, policy_loss: 1.0674, value_loss: 0.6258
2024-07-14 06:26:47,060 [INFO    ] __main__: train step 12987: loss: 1.0919, policy_loss: 1.0674, value_loss: 0.6257
2024-07-14 06:26:47,385 [INFO    ] __main__: train step 12988: loss: 1.0919, policy_loss: 1.0674, value_loss: 0.6257
2024-07-14 06:26:47,679 [INFO    ] __main__: train step 12989: loss: 1.0919, policy_loss: 1.0674, value_loss: 0.6257
2024-07-14 06:26:47,980 [INFO    ] __main__: train step 12990: loss: 1.0919, policy_loss: 1.0674, value_loss: 0.6256
2024-07-14 06:26:50,224 [INFO    ] __main__: train step 12991: loss: 1.0919, policy_loss: 1.0673, value_loss: 0.6256
2024-07-14 06:26:50,515 [INFO    ] __main__: train step 12992: loss: 1.0918, policy_loss: 1.0673, value_loss: 0.6256
2024-07-14 06:26:50,810 [INFO    ] __main__: train step 12993: loss: 1.0918, policy_loss: 1.0673, value_loss: 0.6255
2024-07-14 06:26:51,099 [INFO    ] __main__: train step 12994: loss: 1.0918, policy_loss: 1.0673, value_loss: 0.6255
2024-07-14 06:26:51,396 [INFO    ] __main__: train step 12995: loss: 1.0918, policy_loss: 1.0673, value_loss: 0.6255
2024-07-14 06:26:51,697 [INFO    ] __main__: train step 12996: loss: 1.0918, policy_loss: 1.0672, value_loss: 0.6254
2024-07-14 06:26:51,988 [INFO    ] __main__: train step 12997: loss: 1.0918, policy_loss: 1.0672, value_loss: 0.6254
2024-07-14 06:26:52,292 [INFO    ] __main__: train step 12998: loss: 1.0918, policy_loss: 1.0672, value_loss: 0.6254
2024-07-14 06:26:52,594 [INFO    ] __main__: train step 12999: loss: 1.0918, policy_loss: 1.0672, value_loss: 0.6253
2024-07-14 06:26:52,884 [INFO    ] __main__: train step 13000: loss: 1.0918, policy_loss: 1.0671, value_loss: 0.6253
2024-07-14 06:26:53,038 [INFO    ] __main__: restored step 12000 for evaluation
2024-07-14 06:26:58,285 [INFO    ] __main__: test network ELO difference from baseline network: +74 (+8/-8) ELO from 32000 self-played games
2024-07-14 06:26:58,288 [INFO    ] __main__: game outcomes: W: 18581, D: 335, L: 13084
2024-07-14 06:26:58,291 [INFO    ] __main__: validation_elo_delta: 74, validation_elo: 2418
2024-07-14 06:26:59,040 [INFO    ] __main__: train step 13001: loss: 1.0918, policy_loss: 1.0671, value_loss: 0.6253
2024-07-14 06:27:00,639 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:27:01,137 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:27:01,205 [INFO    ] __main__: train step 13002: loss: 1.0918, policy_loss: 1.0671, value_loss: 0.6252
2024-07-14 06:27:01,473 [INFO    ] __main__: train step 13003: loss: 1.0917, policy_loss: 1.0671, value_loss: 0.6252
2024-07-14 06:27:01,753 [INFO    ] __main__: train step 13004: loss: 1.0917, policy_loss: 1.0671, value_loss: 0.6252
2024-07-14 06:27:02,054 [INFO    ] __main__: train step 13005: loss: 1.0917, policy_loss: 1.0670, value_loss: 0.6251
2024-07-14 06:27:02,347 [INFO    ] __main__: train step 13006: loss: 1.0917, policy_loss: 1.0670, value_loss: 0.6251
2024-07-14 06:27:02,647 [INFO    ] __main__: train step 13007: loss: 1.0917, policy_loss: 1.0670, value_loss: 0.6251
2024-07-14 06:27:02,936 [INFO    ] __main__: train step 13008: loss: 1.0917, policy_loss: 1.0670, value_loss: 0.6250
2024-07-14 06:27:03,206 [INFO    ] __main__: train step 13009: loss: 1.0917, policy_loss: 1.0669, value_loss: 0.6250
2024-07-14 06:27:03,491 [INFO    ] __main__: train step 13010: loss: 1.0917, policy_loss: 1.0669, value_loss: 0.6250
2024-07-14 06:27:03,786 [INFO    ] __main__: train step 13011: loss: 1.0917, policy_loss: 1.0669, value_loss: 0.6249
2024-07-14 06:27:04,088 [INFO    ] __main__: train step 13012: loss: 1.0917, policy_loss: 1.0669, value_loss: 0.6249
2024-07-14 06:27:04,392 [INFO    ] __main__: train step 13013: loss: 1.0916, policy_loss: 1.0669, value_loss: 0.6249
2024-07-14 06:27:04,678 [INFO    ] __main__: train step 13014: loss: 1.0916, policy_loss: 1.0668, value_loss: 0.6248
2024-07-14 06:27:04,964 [INFO    ] __main__: train step 13015: loss: 1.0916, policy_loss: 1.0668, value_loss: 0.6248
2024-07-14 06:27:05,259 [INFO    ] __main__: train step 13016: loss: 1.0916, policy_loss: 1.0668, value_loss: 0.6248
2024-07-14 06:27:05,554 [INFO    ] __main__: train step 13017: loss: 1.0916, policy_loss: 1.0668, value_loss: 0.6247
2024-07-14 06:27:05,826 [INFO    ] __main__: train step 13018: loss: 1.0916, policy_loss: 1.0667, value_loss: 0.6247
2024-07-14 06:27:07,436 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:27:07,935 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:27:08,005 [INFO    ] __main__: train step 13019: loss: 1.0916, policy_loss: 1.0667, value_loss: 0.6247
2024-07-14 06:27:08,296 [INFO    ] __main__: train step 13020: loss: 1.0916, policy_loss: 1.0667, value_loss: 0.6246
2024-07-14 06:27:08,568 [INFO    ] __main__: train step 13021: loss: 1.0916, policy_loss: 1.0667, value_loss: 0.6246
2024-07-14 06:27:08,857 [INFO    ] __main__: train step 13022: loss: 1.0916, policy_loss: 1.0667, value_loss: 0.6246
2024-07-14 06:27:09,149 [INFO    ] __main__: train step 13023: loss: 1.0916, policy_loss: 1.0666, value_loss: 0.6245
2024-07-14 06:27:09,446 [INFO    ] __main__: train step 13024: loss: 1.0915, policy_loss: 1.0666, value_loss: 0.6245
2024-07-14 06:27:09,734 [INFO    ] __main__: train step 13025: loss: 1.0915, policy_loss: 1.0666, value_loss: 0.6245
2024-07-14 06:27:10,026 [INFO    ] __main__: train step 13026: loss: 1.0915, policy_loss: 1.0666, value_loss: 0.6244
2024-07-14 06:27:10,334 [INFO    ] __main__: train step 13027: loss: 1.0915, policy_loss: 1.0665, value_loss: 0.6244
2024-07-14 06:27:10,618 [INFO    ] __main__: train step 13028: loss: 1.0915, policy_loss: 1.0665, value_loss: 0.6244
2024-07-14 06:27:10,917 [INFO    ] __main__: train step 13029: loss: 1.0915, policy_loss: 1.0665, value_loss: 0.6243
2024-07-14 06:27:11,222 [INFO    ] __main__: train step 13030: loss: 1.0915, policy_loss: 1.0665, value_loss: 0.6243
2024-07-14 06:27:11,519 [INFO    ] __main__: train step 13031: loss: 1.0915, policy_loss: 1.0665, value_loss: 0.6243
2024-07-14 06:27:11,818 [INFO    ] __main__: train step 13032: loss: 1.0915, policy_loss: 1.0664, value_loss: 0.6242
2024-07-14 06:27:12,126 [INFO    ] __main__: train step 13033: loss: 1.0915, policy_loss: 1.0664, value_loss: 0.6242
2024-07-14 06:27:12,427 [INFO    ] __main__: train step 13034: loss: 1.0915, policy_loss: 1.0664, value_loss: 0.6242
2024-07-14 06:27:12,715 [INFO    ] __main__: train step 13035: loss: 1.0914, policy_loss: 1.0664, value_loss: 0.6241
2024-07-14 06:27:14,308 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:27:14,797 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:27:14,868 [INFO    ] __main__: train step 13036: loss: 1.0914, policy_loss: 1.0664, value_loss: 0.6241
2024-07-14 06:27:15,158 [INFO    ] __main__: train step 13037: loss: 1.0914, policy_loss: 1.0663, value_loss: 0.6241
2024-07-14 06:27:15,465 [INFO    ] __main__: train step 13038: loss: 1.0914, policy_loss: 1.0663, value_loss: 0.6240
2024-07-14 06:27:15,760 [INFO    ] __main__: train step 13039: loss: 1.0914, policy_loss: 1.0663, value_loss: 0.6240
2024-07-14 06:27:16,057 [INFO    ] __main__: train step 13040: loss: 1.0914, policy_loss: 1.0663, value_loss: 0.6240
2024-07-14 06:27:16,360 [INFO    ] __main__: train step 13041: loss: 1.0914, policy_loss: 1.0662, value_loss: 0.6239
2024-07-14 06:27:16,660 [INFO    ] __main__: train step 13042: loss: 1.0914, policy_loss: 1.0662, value_loss: 0.6239
2024-07-14 06:27:16,964 [INFO    ] __main__: train step 13043: loss: 1.0914, policy_loss: 1.0662, value_loss: 0.6239
2024-07-14 06:27:17,275 [INFO    ] __main__: train step 13044: loss: 1.0914, policy_loss: 1.0662, value_loss: 0.6238
2024-07-14 06:27:17,584 [INFO    ] __main__: train step 13045: loss: 1.0914, policy_loss: 1.0662, value_loss: 0.6238
2024-07-14 06:27:17,894 [INFO    ] __main__: train step 13046: loss: 1.0913, policy_loss: 1.0661, value_loss: 0.6238
2024-07-14 06:27:18,206 [INFO    ] __main__: train step 13047: loss: 1.0913, policy_loss: 1.0661, value_loss: 0.6238
2024-07-14 06:27:18,507 [INFO    ] __main__: train step 13048: loss: 1.0913, policy_loss: 1.0661, value_loss: 0.6237
2024-07-14 06:27:18,822 [INFO    ] __main__: train step 13049: loss: 1.0913, policy_loss: 1.0661, value_loss: 0.6237
2024-07-14 06:27:19,127 [INFO    ] __main__: train step 13050: loss: 1.0913, policy_loss: 1.0660, value_loss: 0.6237
2024-07-14 06:27:19,429 [INFO    ] __main__: train step 13051: loss: 1.0913, policy_loss: 1.0660, value_loss: 0.6236
2024-07-14 06:27:19,751 [INFO    ] __main__: train step 13052: loss: 1.0913, policy_loss: 1.0660, value_loss: 0.6236
2024-07-14 06:27:21,384 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:27:21,873 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:27:21,954 [INFO    ] __main__: train step 13053: loss: 1.0913, policy_loss: 1.0660, value_loss: 0.6235
2024-07-14 06:27:22,250 [INFO    ] __main__: train step 13054: loss: 1.0913, policy_loss: 1.0659, value_loss: 0.6235
2024-07-14 06:27:22,549 [INFO    ] __main__: train step 13055: loss: 1.0913, policy_loss: 1.0659, value_loss: 0.6235
2024-07-14 06:27:22,838 [INFO    ] __main__: train step 13056: loss: 1.0912, policy_loss: 1.0659, value_loss: 0.6234
2024-07-14 06:27:23,141 [INFO    ] __main__: train step 13057: loss: 1.0912, policy_loss: 1.0659, value_loss: 0.6234
2024-07-14 06:27:23,441 [INFO    ] __main__: train step 13058: loss: 1.0912, policy_loss: 1.0659, value_loss: 0.6234
2024-07-14 06:27:23,734 [INFO    ] __main__: train step 13059: loss: 1.0912, policy_loss: 1.0658, value_loss: 0.6234
2024-07-14 06:27:24,028 [INFO    ] __main__: train step 13060: loss: 1.0912, policy_loss: 1.0658, value_loss: 0.6233
2024-07-14 06:27:24,322 [INFO    ] __main__: train step 13061: loss: 1.0912, policy_loss: 1.0658, value_loss: 0.6233
2024-07-14 06:27:24,612 [INFO    ] __main__: train step 13062: loss: 1.0912, policy_loss: 1.0658, value_loss: 0.6233
2024-07-14 06:27:24,912 [INFO    ] __main__: train step 13063: loss: 1.0912, policy_loss: 1.0657, value_loss: 0.6232
2024-07-14 06:27:25,209 [INFO    ] __main__: train step 13064: loss: 1.0912, policy_loss: 1.0657, value_loss: 0.6232
2024-07-14 06:27:25,509 [INFO    ] __main__: train step 13065: loss: 1.0912, policy_loss: 1.0657, value_loss: 0.6232
2024-07-14 06:27:25,812 [INFO    ] __main__: train step 13066: loss: 1.0911, policy_loss: 1.0657, value_loss: 0.6231
2024-07-14 06:27:26,108 [INFO    ] __main__: train step 13067: loss: 1.0911, policy_loss: 1.0657, value_loss: 0.6231
2024-07-14 06:27:26,414 [INFO    ] __main__: train step 13068: loss: 1.0911, policy_loss: 1.0656, value_loss: 0.6231
2024-07-14 06:27:26,710 [INFO    ] __main__: train step 13069: loss: 1.0911, policy_loss: 1.0656, value_loss: 0.6230
2024-07-14 06:27:28,339 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:27:28,837 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:27:28,906 [INFO    ] __main__: train step 13070: loss: 1.0911, policy_loss: 1.0656, value_loss: 0.6230
2024-07-14 06:27:29,200 [INFO    ] __main__: train step 13071: loss: 1.0911, policy_loss: 1.0656, value_loss: 0.6230
2024-07-14 06:27:29,498 [INFO    ] __main__: train step 13072: loss: 1.0911, policy_loss: 1.0655, value_loss: 0.6229
2024-07-14 06:27:29,787 [INFO    ] __main__: train step 13073: loss: 1.0911, policy_loss: 1.0655, value_loss: 0.6229
2024-07-14 06:27:30,078 [INFO    ] __main__: train step 13074: loss: 1.0911, policy_loss: 1.0655, value_loss: 0.6229
2024-07-14 06:27:30,371 [INFO    ] __main__: train step 13075: loss: 1.0911, policy_loss: 1.0655, value_loss: 0.6228
2024-07-14 06:27:30,673 [INFO    ] __main__: train step 13076: loss: 1.0911, policy_loss: 1.0655, value_loss: 0.6228
2024-07-14 06:27:30,965 [INFO    ] __main__: train step 13077: loss: 1.0910, policy_loss: 1.0654, value_loss: 0.6228
2024-07-14 06:27:33,947 [INFO    ] __main__: train step 13078: loss: 1.0910, policy_loss: 1.0654, value_loss: 0.6227
2024-07-14 06:27:34,236 [INFO    ] __main__: train step 13079: loss: 1.0910, policy_loss: 1.0654, value_loss: 0.6227
2024-07-14 06:27:34,531 [INFO    ] __main__: train step 13080: loss: 1.0910, policy_loss: 1.0654, value_loss: 0.6227
2024-07-14 06:27:34,835 [INFO    ] __main__: train step 13081: loss: 1.0910, policy_loss: 1.0653, value_loss: 0.6226
2024-07-14 06:27:35,125 [INFO    ] __main__: train step 13082: loss: 1.0910, policy_loss: 1.0653, value_loss: 0.6226
2024-07-14 06:27:35,394 [INFO    ] __main__: train step 13083: loss: 1.0910, policy_loss: 1.0653, value_loss: 0.6226
2024-07-14 06:27:35,663 [INFO    ] __main__: train step 13084: loss: 1.0910, policy_loss: 1.0653, value_loss: 0.6225
2024-07-14 06:27:35,931 [INFO    ] __main__: train step 13085: loss: 1.0910, policy_loss: 1.0653, value_loss: 0.6225
2024-07-14 06:27:36,195 [INFO    ] __main__: train step 13086: loss: 1.0910, policy_loss: 1.0652, value_loss: 0.6225
2024-07-14 06:27:37,793 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:27:38,298 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:27:38,367 [INFO    ] __main__: train step 13087: loss: 1.0910, policy_loss: 1.0652, value_loss: 0.6224
2024-07-14 06:27:38,653 [INFO    ] __main__: train step 13088: loss: 1.0909, policy_loss: 1.0652, value_loss: 0.6224
2024-07-14 06:27:38,928 [INFO    ] __main__: train step 13089: loss: 1.0909, policy_loss: 1.0652, value_loss: 0.6224
2024-07-14 06:27:39,212 [INFO    ] __main__: train step 13090: loss: 1.0909, policy_loss: 1.0651, value_loss: 0.6223
2024-07-14 06:27:39,505 [INFO    ] __main__: train step 13091: loss: 1.0909, policy_loss: 1.0651, value_loss: 0.6223
2024-07-14 06:27:39,802 [INFO    ] __main__: train step 13092: loss: 1.0909, policy_loss: 1.0651, value_loss: 0.6223
2024-07-14 06:27:40,087 [INFO    ] __main__: train step 13093: loss: 1.0909, policy_loss: 1.0651, value_loss: 0.6222
2024-07-14 06:27:40,374 [INFO    ] __main__: train step 13094: loss: 1.0909, policy_loss: 1.0651, value_loss: 0.6222
2024-07-14 06:27:40,664 [INFO    ] __main__: train step 13095: loss: 1.0909, policy_loss: 1.0650, value_loss: 0.6222
2024-07-14 06:27:40,958 [INFO    ] __main__: train step 13096: loss: 1.0909, policy_loss: 1.0650, value_loss: 0.6221
2024-07-14 06:27:41,256 [INFO    ] __main__: train step 13097: loss: 1.0909, policy_loss: 1.0650, value_loss: 0.6221
2024-07-14 06:27:41,547 [INFO    ] __main__: train step 13098: loss: 1.0908, policy_loss: 1.0650, value_loss: 0.6221
2024-07-14 06:27:41,832 [INFO    ] __main__: train step 13099: loss: 1.0908, policy_loss: 1.0649, value_loss: 0.6220
2024-07-14 06:27:42,124 [INFO    ] __main__: train step 13100: loss: 1.0908, policy_loss: 1.0649, value_loss: 0.6220
2024-07-14 06:27:42,424 [INFO    ] __main__: train step 13101: loss: 1.0908, policy_loss: 1.0649, value_loss: 0.6220
2024-07-14 06:27:42,712 [INFO    ] __main__: train step 13102: loss: 1.0908, policy_loss: 1.0649, value_loss: 0.6219
2024-07-14 06:27:42,997 [INFO    ] __main__: train step 13103: loss: 1.0908, policy_loss: 1.0649, value_loss: 0.6219
2024-07-14 06:27:44,596 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:27:45,071 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:27:45,145 [INFO    ] __main__: train step 13104: loss: 1.0908, policy_loss: 1.0648, value_loss: 0.6219
2024-07-14 06:27:45,439 [INFO    ] __main__: train step 13105: loss: 1.0908, policy_loss: 1.0648, value_loss: 0.6218
2024-07-14 06:27:45,740 [INFO    ] __main__: train step 13106: loss: 1.0908, policy_loss: 1.0648, value_loss: 0.6218
2024-07-14 06:27:46,030 [INFO    ] __main__: train step 13107: loss: 1.0908, policy_loss: 1.0648, value_loss: 0.6218
2024-07-14 06:27:46,327 [INFO    ] __main__: train step 13108: loss: 1.0907, policy_loss: 1.0647, value_loss: 0.6217
2024-07-14 06:27:46,618 [INFO    ] __main__: train step 13109: loss: 1.0907, policy_loss: 1.0647, value_loss: 0.6217
2024-07-14 06:27:46,912 [INFO    ] __main__: train step 13110: loss: 1.0907, policy_loss: 1.0647, value_loss: 0.6217
2024-07-14 06:27:47,204 [INFO    ] __main__: train step 13111: loss: 1.0907, policy_loss: 1.0647, value_loss: 0.6216
2024-07-14 06:27:47,506 [INFO    ] __main__: train step 13112: loss: 1.0907, policy_loss: 1.0647, value_loss: 0.6216
2024-07-14 06:27:47,779 [INFO    ] __main__: train step 13113: loss: 1.0907, policy_loss: 1.0646, value_loss: 0.6216
2024-07-14 06:27:48,059 [INFO    ] __main__: train step 13114: loss: 1.0907, policy_loss: 1.0646, value_loss: 0.6215
2024-07-14 06:27:48,347 [INFO    ] __main__: train step 13115: loss: 1.0907, policy_loss: 1.0646, value_loss: 0.6215
2024-07-14 06:27:48,646 [INFO    ] __main__: train step 13116: loss: 1.0907, policy_loss: 1.0646, value_loss: 0.6215
2024-07-14 06:27:48,940 [INFO    ] __main__: train step 13117: loss: 1.0907, policy_loss: 1.0645, value_loss: 0.6214
2024-07-14 06:27:49,214 [INFO    ] __main__: train step 13118: loss: 1.0907, policy_loss: 1.0645, value_loss: 0.6214
2024-07-14 06:27:49,495 [INFO    ] __main__: train step 13119: loss: 1.0906, policy_loss: 1.0645, value_loss: 0.6214
2024-07-14 06:27:49,791 [INFO    ] __main__: train step 13120: loss: 1.0906, policy_loss: 1.0645, value_loss: 0.6213
2024-07-14 06:27:51,406 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:27:51,846 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:27:51,914 [INFO    ] __main__: train step 13121: loss: 1.0906, policy_loss: 1.0645, value_loss: 0.6213
2024-07-14 06:27:52,209 [INFO    ] __main__: train step 13122: loss: 1.0906, policy_loss: 1.0644, value_loss: 0.6213
2024-07-14 06:27:52,516 [INFO    ] __main__: train step 13123: loss: 1.0906, policy_loss: 1.0644, value_loss: 0.6213
2024-07-14 06:27:52,805 [INFO    ] __main__: train step 13124: loss: 1.0906, policy_loss: 1.0644, value_loss: 0.6212
2024-07-14 06:27:53,091 [INFO    ] __main__: train step 13125: loss: 1.0906, policy_loss: 1.0644, value_loss: 0.6212
2024-07-14 06:27:53,372 [INFO    ] __main__: train step 13126: loss: 1.0906, policy_loss: 1.0643, value_loss: 0.6212
2024-07-14 06:27:53,655 [INFO    ] __main__: train step 13127: loss: 1.0906, policy_loss: 1.0643, value_loss: 0.6211
2024-07-14 06:27:53,946 [INFO    ] __main__: train step 13128: loss: 1.0906, policy_loss: 1.0643, value_loss: 0.6211
2024-07-14 06:27:54,232 [INFO    ] __main__: train step 13129: loss: 1.0905, policy_loss: 1.0643, value_loss: 0.6211
2024-07-14 06:27:54,515 [INFO    ] __main__: train step 13130: loss: 1.0905, policy_loss: 1.0643, value_loss: 0.6210
2024-07-14 06:27:54,800 [INFO    ] __main__: train step 13131: loss: 1.0905, policy_loss: 1.0642, value_loss: 0.6210
2024-07-14 06:27:55,091 [INFO    ] __main__: train step 13132: loss: 1.0905, policy_loss: 1.0642, value_loss: 0.6210
2024-07-14 06:27:55,374 [INFO    ] __main__: train step 13133: loss: 1.0905, policy_loss: 1.0642, value_loss: 0.6209
2024-07-14 06:27:55,652 [INFO    ] __main__: train step 13134: loss: 1.0905, policy_loss: 1.0642, value_loss: 0.6209
2024-07-14 06:27:55,945 [INFO    ] __main__: train step 13135: loss: 1.0905, policy_loss: 1.0641, value_loss: 0.6209
2024-07-14 06:27:56,241 [INFO    ] __main__: train step 13136: loss: 1.0905, policy_loss: 1.0641, value_loss: 0.6208
2024-07-14 06:27:56,535 [INFO    ] __main__: train step 13137: loss: 1.0905, policy_loss: 1.0641, value_loss: 0.6208
2024-07-14 06:27:58,164 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:27:58,667 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:27:58,740 [INFO    ] __main__: train step 13138: loss: 1.0904, policy_loss: 1.0641, value_loss: 0.6208
2024-07-14 06:27:59,032 [INFO    ] __main__: train step 13139: loss: 1.0904, policy_loss: 1.0640, value_loss: 0.6207
2024-07-14 06:27:59,328 [INFO    ] __main__: train step 13140: loss: 1.0904, policy_loss: 1.0640, value_loss: 0.6207
2024-07-14 06:27:59,616 [INFO    ] __main__: train step 13141: loss: 1.0904, policy_loss: 1.0640, value_loss: 0.6207
2024-07-14 06:27:59,912 [INFO    ] __main__: train step 13142: loss: 1.0904, policy_loss: 1.0640, value_loss: 0.6206
2024-07-14 06:28:00,210 [INFO    ] __main__: train step 13143: loss: 1.0904, policy_loss: 1.0640, value_loss: 0.6206
2024-07-14 06:28:00,508 [INFO    ] __main__: train step 13144: loss: 1.0904, policy_loss: 1.0639, value_loss: 0.6206
2024-07-14 06:28:00,807 [INFO    ] __main__: train step 13145: loss: 1.0904, policy_loss: 1.0639, value_loss: 0.6205
2024-07-14 06:28:01,110 [INFO    ] __main__: train step 13146: loss: 1.0904, policy_loss: 1.0639, value_loss: 0.6205
2024-07-14 06:28:01,417 [INFO    ] __main__: train step 13147: loss: 1.0904, policy_loss: 1.0639, value_loss: 0.6205
2024-07-14 06:28:01,719 [INFO    ] __main__: train step 13148: loss: 1.0904, policy_loss: 1.0639, value_loss: 0.6204
2024-07-14 06:28:02,018 [INFO    ] __main__: train step 13149: loss: 1.0903, policy_loss: 1.0638, value_loss: 0.6204
2024-07-14 06:28:02,314 [INFO    ] __main__: train step 13150: loss: 1.0903, policy_loss: 1.0638, value_loss: 0.6204
2024-07-14 06:28:02,628 [INFO    ] __main__: train step 13151: loss: 1.0903, policy_loss: 1.0638, value_loss: 0.6203
2024-07-14 06:28:02,958 [INFO    ] __main__: train step 13152: loss: 1.0903, policy_loss: 1.0638, value_loss: 0.6203
2024-07-14 06:28:03,246 [INFO    ] __main__: train step 13153: loss: 1.0903, policy_loss: 1.0637, value_loss: 0.6203
2024-07-14 06:28:03,544 [INFO    ] __main__: train step 13154: loss: 1.0903, policy_loss: 1.0637, value_loss: 0.6202
2024-07-14 06:28:05,172 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:28:05,682 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:28:05,754 [INFO    ] __main__: train step 13155: loss: 1.0903, policy_loss: 1.0637, value_loss: 0.6202
2024-07-14 06:28:06,058 [INFO    ] __main__: train step 13156: loss: 1.0903, policy_loss: 1.0637, value_loss: 0.6202
2024-07-14 06:28:06,364 [INFO    ] __main__: train step 13157: loss: 1.0903, policy_loss: 1.0636, value_loss: 0.6201
2024-07-14 06:28:06,651 [INFO    ] __main__: train step 13158: loss: 1.0903, policy_loss: 1.0636, value_loss: 0.6201
2024-07-14 06:28:06,948 [INFO    ] __main__: train step 13159: loss: 1.0902, policy_loss: 1.0636, value_loss: 0.6201
2024-07-14 06:28:07,238 [INFO    ] __main__: train step 13160: loss: 1.0902, policy_loss: 1.0636, value_loss: 0.6200
2024-07-14 06:28:07,537 [INFO    ] __main__: train step 13161: loss: 1.0902, policy_loss: 1.0636, value_loss: 0.6200
2024-07-14 06:28:07,839 [INFO    ] __main__: train step 13162: loss: 1.0902, policy_loss: 1.0635, value_loss: 0.6200
2024-07-14 06:28:08,142 [INFO    ] __main__: train step 13163: loss: 1.0902, policy_loss: 1.0635, value_loss: 0.6199
2024-07-14 06:28:08,435 [INFO    ] __main__: train step 13164: loss: 1.0902, policy_loss: 1.0635, value_loss: 0.6199
2024-07-14 06:28:08,740 [INFO    ] __main__: train step 13165: loss: 1.0902, policy_loss: 1.0635, value_loss: 0.6199
2024-07-14 06:28:09,036 [INFO    ] __main__: train step 13166: loss: 1.0902, policy_loss: 1.0634, value_loss: 0.6198
2024-07-14 06:28:11,645 [INFO    ] __main__: train step 13167: loss: 1.0902, policy_loss: 1.0634, value_loss: 0.6198
2024-07-14 06:28:11,945 [INFO    ] __main__: train step 13168: loss: 1.0901, policy_loss: 1.0634, value_loss: 0.6198
2024-07-14 06:28:12,252 [INFO    ] __main__: train step 13169: loss: 1.0901, policy_loss: 1.0634, value_loss: 0.6197
2024-07-14 06:28:12,553 [INFO    ] __main__: train step 13170: loss: 1.0901, policy_loss: 1.0634, value_loss: 0.6197
2024-07-14 06:28:12,844 [INFO    ] __main__: train step 13171: loss: 1.0901, policy_loss: 1.0633, value_loss: 0.6197
2024-07-14 06:28:14,465 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:28:14,957 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:28:15,031 [INFO    ] __main__: train step 13172: loss: 1.0901, policy_loss: 1.0633, value_loss: 0.6196
2024-07-14 06:28:15,332 [INFO    ] __main__: train step 13173: loss: 1.0901, policy_loss: 1.0633, value_loss: 0.6196
2024-07-14 06:28:15,629 [INFO    ] __main__: train step 13174: loss: 1.0901, policy_loss: 1.0633, value_loss: 0.6196
2024-07-14 06:28:15,912 [INFO    ] __main__: train step 13175: loss: 1.0901, policy_loss: 1.0632, value_loss: 0.6195
2024-07-14 06:28:16,205 [INFO    ] __main__: train step 13176: loss: 1.0901, policy_loss: 1.0632, value_loss: 0.6195
2024-07-14 06:28:16,496 [INFO    ] __main__: train step 13177: loss: 1.0900, policy_loss: 1.0632, value_loss: 0.6195
2024-07-14 06:28:16,795 [INFO    ] __main__: train step 13178: loss: 1.0900, policy_loss: 1.0632, value_loss: 0.6194
2024-07-14 06:28:17,081 [INFO    ] __main__: train step 13179: loss: 1.0900, policy_loss: 1.0631, value_loss: 0.6194
2024-07-14 06:28:17,382 [INFO    ] __main__: train step 13180: loss: 1.0900, policy_loss: 1.0631, value_loss: 0.6194
2024-07-14 06:28:17,662 [INFO    ] __main__: train step 13181: loss: 1.0900, policy_loss: 1.0631, value_loss: 0.6193
2024-07-14 06:28:17,956 [INFO    ] __main__: train step 13182: loss: 1.0900, policy_loss: 1.0631, value_loss: 0.6193
2024-07-14 06:28:18,228 [INFO    ] __main__: train step 13183: loss: 1.0900, policy_loss: 1.0631, value_loss: 0.6193
2024-07-14 06:28:18,501 [INFO    ] __main__: train step 13184: loss: 1.0900, policy_loss: 1.0630, value_loss: 0.6192
2024-07-14 06:28:18,765 [INFO    ] __main__: train step 13185: loss: 1.0900, policy_loss: 1.0630, value_loss: 0.6192
2024-07-14 06:28:19,034 [INFO    ] __main__: train step 13186: loss: 1.0900, policy_loss: 1.0630, value_loss: 0.6192
2024-07-14 06:28:19,317 [INFO    ] __main__: train step 13187: loss: 1.0899, policy_loss: 1.0630, value_loss: 0.6191
2024-07-14 06:28:19,610 [INFO    ] __main__: train step 13188: loss: 1.0899, policy_loss: 1.0629, value_loss: 0.6191
2024-07-14 06:28:21,228 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:28:21,711 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:28:21,779 [INFO    ] __main__: train step 13189: loss: 1.0899, policy_loss: 1.0629, value_loss: 0.6191
2024-07-14 06:28:22,070 [INFO    ] __main__: train step 13190: loss: 1.0899, policy_loss: 1.0629, value_loss: 0.6190
2024-07-14 06:28:22,349 [INFO    ] __main__: train step 13191: loss: 1.0899, policy_loss: 1.0629, value_loss: 0.6190
2024-07-14 06:28:22,638 [INFO    ] __main__: train step 13192: loss: 1.0899, policy_loss: 1.0629, value_loss: 0.6190
2024-07-14 06:28:22,947 [INFO    ] __main__: train step 13193: loss: 1.0899, policy_loss: 1.0628, value_loss: 0.6189
2024-07-14 06:28:23,235 [INFO    ] __main__: train step 13194: loss: 1.0899, policy_loss: 1.0628, value_loss: 0.6189
2024-07-14 06:28:23,529 [INFO    ] __main__: train step 13195: loss: 1.0899, policy_loss: 1.0628, value_loss: 0.6189
2024-07-14 06:28:23,820 [INFO    ] __main__: train step 13196: loss: 1.0898, policy_loss: 1.0628, value_loss: 0.6188
2024-07-14 06:28:24,116 [INFO    ] __main__: train step 13197: loss: 1.0898, policy_loss: 1.0627, value_loss: 0.6188
2024-07-14 06:28:24,388 [INFO    ] __main__: train step 13198: loss: 1.0898, policy_loss: 1.0627, value_loss: 0.6188
2024-07-14 06:28:24,646 [INFO    ] __main__: train step 13199: loss: 1.0898, policy_loss: 1.0627, value_loss: 0.6188
2024-07-14 06:28:24,918 [INFO    ] __main__: train step 13200: loss: 1.0898, policy_loss: 1.0627, value_loss: 0.6187
2024-07-14 06:28:25,187 [INFO    ] __main__: train step 13201: loss: 1.0898, policy_loss: 1.0627, value_loss: 0.6187
2024-07-14 06:28:25,476 [INFO    ] __main__: train step 13202: loss: 1.0898, policy_loss: 1.0626, value_loss: 0.6187
2024-07-14 06:28:25,766 [INFO    ] __main__: train step 13203: loss: 1.0898, policy_loss: 1.0626, value_loss: 0.6186
2024-07-14 06:28:26,056 [INFO    ] __main__: train step 13204: loss: 1.0898, policy_loss: 1.0626, value_loss: 0.6186
2024-07-14 06:28:26,354 [INFO    ] __main__: train step 13205: loss: 1.0898, policy_loss: 1.0626, value_loss: 0.6186
2024-07-14 06:28:27,977 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:28:28,460 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:28:28,535 [INFO    ] __main__: train step 13206: loss: 1.0898, policy_loss: 1.0625, value_loss: 0.6185
2024-07-14 06:28:28,825 [INFO    ] __main__: train step 13207: loss: 1.0897, policy_loss: 1.0625, value_loss: 0.6185
2024-07-14 06:28:29,117 [INFO    ] __main__: train step 13208: loss: 1.0897, policy_loss: 1.0625, value_loss: 0.6185
2024-07-14 06:28:29,410 [INFO    ] __main__: train step 13209: loss: 1.0897, policy_loss: 1.0625, value_loss: 0.6184
2024-07-14 06:28:29,700 [INFO    ] __main__: train step 13210: loss: 1.0897, policy_loss: 1.0625, value_loss: 0.6184
2024-07-14 06:28:29,987 [INFO    ] __main__: train step 13211: loss: 1.0897, policy_loss: 1.0624, value_loss: 0.6184
2024-07-14 06:28:30,276 [INFO    ] __main__: train step 13212: loss: 1.0897, policy_loss: 1.0624, value_loss: 0.6183
2024-07-14 06:28:30,565 [INFO    ] __main__: train step 13213: loss: 1.0897, policy_loss: 1.0624, value_loss: 0.6183
2024-07-14 06:28:30,855 [INFO    ] __main__: train step 13214: loss: 1.0897, policy_loss: 1.0624, value_loss: 0.6183
2024-07-14 06:28:31,142 [INFO    ] __main__: train step 13215: loss: 1.0897, policy_loss: 1.0623, value_loss: 0.6182
2024-07-14 06:28:31,441 [INFO    ] __main__: train step 13216: loss: 1.0896, policy_loss: 1.0623, value_loss: 0.6182
2024-07-14 06:28:31,736 [INFO    ] __main__: train step 13217: loss: 1.0896, policy_loss: 1.0623, value_loss: 0.6182
2024-07-14 06:28:32,029 [INFO    ] __main__: train step 13218: loss: 1.0896, policy_loss: 1.0623, value_loss: 0.6181
2024-07-14 06:28:32,317 [INFO    ] __main__: train step 13219: loss: 1.0896, policy_loss: 1.0623, value_loss: 0.6181
2024-07-14 06:28:32,596 [INFO    ] __main__: train step 13220: loss: 1.0896, policy_loss: 1.0622, value_loss: 0.6181
2024-07-14 06:28:32,908 [INFO    ] __main__: train step 13221: loss: 1.0896, policy_loss: 1.0622, value_loss: 0.6180
2024-07-14 06:28:33,206 [INFO    ] __main__: train step 13222: loss: 1.0896, policy_loss: 1.0622, value_loss: 0.6180
2024-07-14 06:28:34,837 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:28:35,323 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:28:35,401 [INFO    ] __main__: train step 13223: loss: 1.0896, policy_loss: 1.0622, value_loss: 0.6180
2024-07-14 06:28:35,683 [INFO    ] __main__: train step 13224: loss: 1.0896, policy_loss: 1.0621, value_loss: 0.6179
2024-07-14 06:28:35,976 [INFO    ] __main__: train step 13225: loss: 1.0895, policy_loss: 1.0621, value_loss: 0.6179
2024-07-14 06:28:36,267 [INFO    ] __main__: train step 13226: loss: 1.0895, policy_loss: 1.0621, value_loss: 0.6179
2024-07-14 06:28:36,558 [INFO    ] __main__: train step 13227: loss: 1.0895, policy_loss: 1.0621, value_loss: 0.6178
2024-07-14 06:28:36,848 [INFO    ] __main__: train step 13228: loss: 1.0895, policy_loss: 1.0620, value_loss: 0.6178
2024-07-14 06:28:37,142 [INFO    ] __main__: train step 13229: loss: 1.0895, policy_loss: 1.0620, value_loss: 0.6178
2024-07-14 06:28:37,430 [INFO    ] __main__: train step 13230: loss: 1.0895, policy_loss: 1.0620, value_loss: 0.6177
2024-07-14 06:28:37,717 [INFO    ] __main__: train step 13231: loss: 1.0895, policy_loss: 1.0620, value_loss: 0.6177
2024-07-14 06:28:38,011 [INFO    ] __main__: train step 13232: loss: 1.0895, policy_loss: 1.0620, value_loss: 0.6177
2024-07-14 06:28:38,306 [INFO    ] __main__: train step 13233: loss: 1.0895, policy_loss: 1.0619, value_loss: 0.6176
2024-07-14 06:28:38,607 [INFO    ] __main__: train step 13234: loss: 1.0895, policy_loss: 1.0619, value_loss: 0.6176
2024-07-14 06:28:38,902 [INFO    ] __main__: train step 13235: loss: 1.0894, policy_loss: 1.0619, value_loss: 0.6176
2024-07-14 06:28:39,185 [INFO    ] __main__: train step 13236: loss: 1.0894, policy_loss: 1.0619, value_loss: 0.6175
2024-07-14 06:28:39,480 [INFO    ] __main__: train step 13237: loss: 1.0894, policy_loss: 1.0618, value_loss: 0.6175
2024-07-14 06:28:39,776 [INFO    ] __main__: train step 13238: loss: 1.0894, policy_loss: 1.0618, value_loss: 0.6175
2024-07-14 06:28:40,067 [INFO    ] __main__: train step 13239: loss: 1.0894, policy_loss: 1.0618, value_loss: 0.6174
2024-07-14 06:28:41,674 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:28:42,161 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:28:42,232 [INFO    ] __main__: train step 13240: loss: 1.0894, policy_loss: 1.0618, value_loss: 0.6174
2024-07-14 06:28:42,522 [INFO    ] __main__: train step 13241: loss: 1.0894, policy_loss: 1.0618, value_loss: 0.6174
2024-07-14 06:28:42,827 [INFO    ] __main__: train step 13242: loss: 1.0894, policy_loss: 1.0617, value_loss: 0.6173
2024-07-14 06:28:43,126 [INFO    ] __main__: train step 13243: loss: 1.0894, policy_loss: 1.0617, value_loss: 0.6173
2024-07-14 06:28:43,421 [INFO    ] __main__: train step 13244: loss: 1.0893, policy_loss: 1.0617, value_loss: 0.6173
2024-07-14 06:28:43,717 [INFO    ] __main__: train step 13245: loss: 1.0893, policy_loss: 1.0617, value_loss: 0.6172
2024-07-14 06:28:44,012 [INFO    ] __main__: train step 13246: loss: 1.0893, policy_loss: 1.0616, value_loss: 0.6172
2024-07-14 06:28:44,316 [INFO    ] __main__: train step 13247: loss: 1.0893, policy_loss: 1.0616, value_loss: 0.6172
2024-07-14 06:28:44,615 [INFO    ] __main__: train step 13248: loss: 1.0893, policy_loss: 1.0616, value_loss: 0.6171
2024-07-14 06:28:44,910 [INFO    ] __main__: train step 13249: loss: 1.0893, policy_loss: 1.0616, value_loss: 0.6171
2024-07-14 06:28:45,195 [INFO    ] __main__: train step 13250: loss: 1.0893, policy_loss: 1.0616, value_loss: 0.6171
2024-07-14 06:28:45,481 [INFO    ] __main__: train step 13251: loss: 1.0893, policy_loss: 1.0615, value_loss: 0.6170
2024-07-14 06:28:45,773 [INFO    ] __main__: train step 13252: loss: 1.0893, policy_loss: 1.0615, value_loss: 0.6170
2024-07-14 06:28:46,066 [INFO    ] __main__: train step 13253: loss: 1.0892, policy_loss: 1.0615, value_loss: 0.6170
2024-07-14 06:28:46,364 [INFO    ] __main__: train step 13254: loss: 1.0892, policy_loss: 1.0615, value_loss: 0.6169
2024-07-14 06:28:46,661 [INFO    ] __main__: train step 13255: loss: 1.0892, policy_loss: 1.0614, value_loss: 0.6169
2024-07-14 06:28:49,643 [INFO    ] __main__: train step 13256: loss: 1.0892, policy_loss: 1.0614, value_loss: 0.6169
2024-07-14 06:28:51,251 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:28:51,746 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:28:51,818 [INFO    ] __main__: train step 13257: loss: 1.0892, policy_loss: 1.0614, value_loss: 0.6168
2024-07-14 06:28:52,119 [INFO    ] __main__: train step 13258: loss: 1.0892, policy_loss: 1.0614, value_loss: 0.6168
2024-07-14 06:28:52,418 [INFO    ] __main__: train step 13259: loss: 1.0892, policy_loss: 1.0614, value_loss: 0.6168
2024-07-14 06:28:52,712 [INFO    ] __main__: train step 13260: loss: 1.0892, policy_loss: 1.0613, value_loss: 0.6167
2024-07-14 06:28:53,003 [INFO    ] __main__: train step 13261: loss: 1.0892, policy_loss: 1.0613, value_loss: 0.6167
2024-07-14 06:28:53,299 [INFO    ] __main__: train step 13262: loss: 1.0891, policy_loss: 1.0613, value_loss: 0.6167
2024-07-14 06:28:53,600 [INFO    ] __main__: train step 13263: loss: 1.0891, policy_loss: 1.0613, value_loss: 0.6166
2024-07-14 06:28:53,903 [INFO    ] __main__: train step 13264: loss: 1.0891, policy_loss: 1.0612, value_loss: 0.6166
2024-07-14 06:28:54,199 [INFO    ] __main__: train step 13265: loss: 1.0891, policy_loss: 1.0612, value_loss: 0.6166
2024-07-14 06:28:54,501 [INFO    ] __main__: train step 13266: loss: 1.0891, policy_loss: 1.0612, value_loss: 0.6165
2024-07-14 06:28:54,803 [INFO    ] __main__: train step 13267: loss: 1.0891, policy_loss: 1.0612, value_loss: 0.6165
2024-07-14 06:28:55,104 [INFO    ] __main__: train step 13268: loss: 1.0891, policy_loss: 1.0612, value_loss: 0.6165
2024-07-14 06:28:55,427 [INFO    ] __main__: train step 13269: loss: 1.0891, policy_loss: 1.0611, value_loss: 0.6164
2024-07-14 06:28:55,730 [INFO    ] __main__: train step 13270: loss: 1.0891, policy_loss: 1.0611, value_loss: 0.6164
2024-07-14 06:28:56,027 [INFO    ] __main__: train step 13271: loss: 1.0890, policy_loss: 1.0611, value_loss: 0.6164
2024-07-14 06:28:56,314 [INFO    ] __main__: train step 13272: loss: 1.0890, policy_loss: 1.0611, value_loss: 0.6164
2024-07-14 06:28:56,603 [INFO    ] __main__: train step 13273: loss: 1.0890, policy_loss: 1.0610, value_loss: 0.6163
2024-07-14 06:28:58,222 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:28:58,660 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:28:58,727 [INFO    ] __main__: train step 13274: loss: 1.0890, policy_loss: 1.0610, value_loss: 0.6163
2024-07-14 06:28:59,025 [INFO    ] __main__: train step 13275: loss: 1.0890, policy_loss: 1.0610, value_loss: 0.6163
2024-07-14 06:28:59,315 [INFO    ] __main__: train step 13276: loss: 1.0890, policy_loss: 1.0610, value_loss: 0.6162
2024-07-14 06:28:59,606 [INFO    ] __main__: train step 13277: loss: 1.0890, policy_loss: 1.0609, value_loss: 0.6162
2024-07-14 06:28:59,901 [INFO    ] __main__: train step 13278: loss: 1.0890, policy_loss: 1.0609, value_loss: 0.6162
2024-07-14 06:29:00,205 [INFO    ] __main__: train step 13279: loss: 1.0890, policy_loss: 1.0609, value_loss: 0.6161
2024-07-14 06:29:00,498 [INFO    ] __main__: train step 13280: loss: 1.0890, policy_loss: 1.0609, value_loss: 0.6161
2024-07-14 06:29:00,787 [INFO    ] __main__: train step 13281: loss: 1.0889, policy_loss: 1.0609, value_loss: 0.6161
2024-07-14 06:29:01,079 [INFO    ] __main__: train step 13282: loss: 1.0889, policy_loss: 1.0608, value_loss: 0.6160
2024-07-14 06:29:01,391 [INFO    ] __main__: train step 13283: loss: 1.0889, policy_loss: 1.0608, value_loss: 0.6160
2024-07-14 06:29:01,684 [INFO    ] __main__: train step 13284: loss: 1.0889, policy_loss: 1.0608, value_loss: 0.6160
2024-07-14 06:29:01,986 [INFO    ] __main__: train step 13285: loss: 1.0889, policy_loss: 1.0608, value_loss: 0.6159
2024-07-14 06:29:02,284 [INFO    ] __main__: train step 13286: loss: 1.0889, policy_loss: 1.0607, value_loss: 0.6159
2024-07-14 06:29:02,589 [INFO    ] __main__: train step 13287: loss: 1.0889, policy_loss: 1.0607, value_loss: 0.6159
2024-07-14 06:29:02,878 [INFO    ] __main__: train step 13288: loss: 1.0889, policy_loss: 1.0607, value_loss: 0.6158
2024-07-14 06:29:03,190 [INFO    ] __main__: train step 13289: loss: 1.0889, policy_loss: 1.0607, value_loss: 0.6158
2024-07-14 06:29:03,487 [INFO    ] __main__: train step 13290: loss: 1.0888, policy_loss: 1.0607, value_loss: 0.6158
2024-07-14 06:29:05,094 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:29:05,591 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:29:05,665 [INFO    ] __main__: train step 13291: loss: 1.0888, policy_loss: 1.0606, value_loss: 0.6157
2024-07-14 06:29:05,957 [INFO    ] __main__: train step 13292: loss: 1.0888, policy_loss: 1.0606, value_loss: 0.6157
2024-07-14 06:29:06,248 [INFO    ] __main__: train step 13293: loss: 1.0888, policy_loss: 1.0606, value_loss: 0.6157
2024-07-14 06:29:06,541 [INFO    ] __main__: train step 13294: loss: 1.0888, policy_loss: 1.0606, value_loss: 0.6156
2024-07-14 06:29:06,834 [INFO    ] __main__: train step 13295: loss: 1.0888, policy_loss: 1.0605, value_loss: 0.6156
2024-07-14 06:29:07,140 [INFO    ] __main__: train step 13296: loss: 1.0888, policy_loss: 1.0605, value_loss: 0.6156
2024-07-14 06:29:07,442 [INFO    ] __main__: train step 13297: loss: 1.0888, policy_loss: 1.0605, value_loss: 0.6155
2024-07-14 06:29:07,738 [INFO    ] __main__: train step 13298: loss: 1.0888, policy_loss: 1.0605, value_loss: 0.6155
2024-07-14 06:29:08,038 [INFO    ] __main__: train step 13299: loss: 1.0887, policy_loss: 1.0605, value_loss: 0.6155
2024-07-14 06:29:08,343 [INFO    ] __main__: train step 13300: loss: 1.0887, policy_loss: 1.0604, value_loss: 0.6154
2024-07-14 06:29:08,635 [INFO    ] __main__: train step 13301: loss: 1.0887, policy_loss: 1.0604, value_loss: 0.6154
2024-07-14 06:29:08,927 [INFO    ] __main__: train step 13302: loss: 1.0887, policy_loss: 1.0604, value_loss: 0.6154
2024-07-14 06:29:09,218 [INFO    ] __main__: train step 13303: loss: 1.0887, policy_loss: 1.0604, value_loss: 0.6153
2024-07-14 06:29:09,523 [INFO    ] __main__: train step 13304: loss: 1.0887, policy_loss: 1.0603, value_loss: 0.6153
2024-07-14 06:29:09,815 [INFO    ] __main__: train step 13305: loss: 1.0887, policy_loss: 1.0603, value_loss: 0.6153
2024-07-14 06:29:10,128 [INFO    ] __main__: train step 13306: loss: 1.0887, policy_loss: 1.0603, value_loss: 0.6152
2024-07-14 06:29:10,420 [INFO    ] __main__: train step 13307: loss: 1.0887, policy_loss: 1.0603, value_loss: 0.6152
2024-07-14 06:29:12,045 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:29:12,547 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:29:12,617 [INFO    ] __main__: train step 13308: loss: 1.0886, policy_loss: 1.0603, value_loss: 0.6152
2024-07-14 06:29:12,904 [INFO    ] __main__: train step 13309: loss: 1.0886, policy_loss: 1.0602, value_loss: 0.6152
2024-07-14 06:29:13,191 [INFO    ] __main__: train step 13310: loss: 1.0886, policy_loss: 1.0602, value_loss: 0.6151
2024-07-14 06:29:13,485 [INFO    ] __main__: train step 13311: loss: 1.0886, policy_loss: 1.0602, value_loss: 0.6151
2024-07-14 06:29:13,785 [INFO    ] __main__: train step 13312: loss: 1.0886, policy_loss: 1.0602, value_loss: 0.6151
2024-07-14 06:29:14,086 [INFO    ] __main__: train step 13313: loss: 1.0886, policy_loss: 1.0601, value_loss: 0.6150
2024-07-14 06:29:14,381 [INFO    ] __main__: train step 13314: loss: 1.0886, policy_loss: 1.0601, value_loss: 0.6150
2024-07-14 06:29:14,667 [INFO    ] __main__: train step 13315: loss: 1.0886, policy_loss: 1.0601, value_loss: 0.6150
2024-07-14 06:29:14,956 [INFO    ] __main__: train step 13316: loss: 1.0886, policy_loss: 1.0601, value_loss: 0.6149
2024-07-14 06:29:15,252 [INFO    ] __main__: train step 13317: loss: 1.0885, policy_loss: 1.0600, value_loss: 0.6149
2024-07-14 06:29:15,545 [INFO    ] __main__: train step 13318: loss: 1.0885, policy_loss: 1.0600, value_loss: 0.6149
2024-07-14 06:29:15,840 [INFO    ] __main__: train step 13319: loss: 1.0885, policy_loss: 1.0600, value_loss: 0.6148
2024-07-14 06:29:16,140 [INFO    ] __main__: train step 13320: loss: 1.0885, policy_loss: 1.0600, value_loss: 0.6148
2024-07-14 06:29:16,430 [INFO    ] __main__: train step 13321: loss: 1.0885, policy_loss: 1.0600, value_loss: 0.6148
2024-07-14 06:29:16,715 [INFO    ] __main__: train step 13322: loss: 1.0885, policy_loss: 1.0599, value_loss: 0.6147
2024-07-14 06:29:16,995 [INFO    ] __main__: train step 13323: loss: 1.0885, policy_loss: 1.0599, value_loss: 0.6147
2024-07-14 06:29:17,287 [INFO    ] __main__: train step 13324: loss: 1.0885, policy_loss: 1.0599, value_loss: 0.6147
2024-07-14 06:29:18,907 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:29:19,399 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:29:19,469 [INFO    ] __main__: train step 13325: loss: 1.0885, policy_loss: 1.0599, value_loss: 0.6146
2024-07-14 06:29:19,769 [INFO    ] __main__: train step 13326: loss: 1.0885, policy_loss: 1.0598, value_loss: 0.6146
2024-07-14 06:29:20,061 [INFO    ] __main__: train step 13327: loss: 1.0884, policy_loss: 1.0598, value_loss: 0.6146
2024-07-14 06:29:20,350 [INFO    ] __main__: train step 13328: loss: 1.0884, policy_loss: 1.0598, value_loss: 0.6145
2024-07-14 06:29:20,633 [INFO    ] __main__: train step 13329: loss: 1.0884, policy_loss: 1.0598, value_loss: 0.6145
2024-07-14 06:29:20,928 [INFO    ] __main__: train step 13330: loss: 1.0884, policy_loss: 1.0598, value_loss: 0.6145
2024-07-14 06:29:21,221 [INFO    ] __main__: train step 13331: loss: 1.0884, policy_loss: 1.0597, value_loss: 0.6144
2024-07-14 06:29:21,521 [INFO    ] __main__: train step 13332: loss: 1.0884, policy_loss: 1.0597, value_loss: 0.6144
2024-07-14 06:29:21,828 [INFO    ] __main__: train step 13333: loss: 1.0884, policy_loss: 1.0597, value_loss: 0.6144
2024-07-14 06:29:22,124 [INFO    ] __main__: train step 13334: loss: 1.0884, policy_loss: 1.0597, value_loss: 0.6143
2024-07-14 06:29:22,421 [INFO    ] __main__: train step 13335: loss: 1.0884, policy_loss: 1.0596, value_loss: 0.6143
2024-07-14 06:29:22,722 [INFO    ] __main__: train step 13336: loss: 1.0883, policy_loss: 1.0596, value_loss: 0.6143
2024-07-14 06:29:23,017 [INFO    ] __main__: train step 13337: loss: 1.0883, policy_loss: 1.0596, value_loss: 0.6142
2024-07-14 06:29:23,313 [INFO    ] __main__: train step 13338: loss: 1.0883, policy_loss: 1.0596, value_loss: 0.6142
2024-07-14 06:29:23,607 [INFO    ] __main__: train step 13339: loss: 1.0883, policy_loss: 1.0596, value_loss: 0.6142
2024-07-14 06:29:23,902 [INFO    ] __main__: train step 13340: loss: 1.0883, policy_loss: 1.0595, value_loss: 0.6141
2024-07-14 06:29:24,192 [INFO    ] __main__: train step 13341: loss: 1.0883, policy_loss: 1.0595, value_loss: 0.6141
2024-07-14 06:29:25,812 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:29:26,303 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:29:26,374 [INFO    ] __main__: train step 13342: loss: 1.0883, policy_loss: 1.0595, value_loss: 0.6141
2024-07-14 06:29:26,662 [INFO    ] __main__: train step 13343: loss: 1.0883, policy_loss: 1.0595, value_loss: 0.6140
2024-07-14 06:29:26,952 [INFO    ] __main__: train step 13344: loss: 1.0883, policy_loss: 1.0594, value_loss: 0.6140
2024-07-14 06:29:27,231 [INFO    ] __main__: train step 13345: loss: 1.0882, policy_loss: 1.0594, value_loss: 0.6140
2024-07-14 06:29:30,020 [INFO    ] __main__: train step 13346: loss: 1.0882, policy_loss: 1.0594, value_loss: 0.6139
2024-07-14 06:29:30,309 [INFO    ] __main__: train step 13347: loss: 1.0882, policy_loss: 1.0594, value_loss: 0.6139
2024-07-14 06:29:30,613 [INFO    ] __main__: train step 13348: loss: 1.0882, policy_loss: 1.0594, value_loss: 0.6139
2024-07-14 06:29:30,904 [INFO    ] __main__: train step 13349: loss: 1.0882, policy_loss: 1.0593, value_loss: 0.6138
2024-07-14 06:29:31,194 [INFO    ] __main__: train step 13350: loss: 1.0882, policy_loss: 1.0593, value_loss: 0.6138
2024-07-14 06:29:31,483 [INFO    ] __main__: train step 13351: loss: 1.0882, policy_loss: 1.0593, value_loss: 0.6138
2024-07-14 06:29:31,775 [INFO    ] __main__: train step 13352: loss: 1.0882, policy_loss: 1.0593, value_loss: 0.6137
2024-07-14 06:29:32,070 [INFO    ] __main__: train step 13353: loss: 1.0881, policy_loss: 1.0592, value_loss: 0.6137
2024-07-14 06:29:32,360 [INFO    ] __main__: train step 13354: loss: 1.0881, policy_loss: 1.0592, value_loss: 0.6137
2024-07-14 06:29:32,650 [INFO    ] __main__: train step 13355: loss: 1.0881, policy_loss: 1.0592, value_loss: 0.6137
2024-07-14 06:29:32,940 [INFO    ] __main__: train step 13356: loss: 1.0881, policy_loss: 1.0592, value_loss: 0.6136
2024-07-14 06:29:33,225 [INFO    ] __main__: train step 13357: loss: 1.0881, policy_loss: 1.0591, value_loss: 0.6136
2024-07-14 06:29:33,518 [INFO    ] __main__: train step 13358: loss: 1.0881, policy_loss: 1.0591, value_loss: 0.6136
2024-07-14 06:29:35,130 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:29:35,627 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:29:35,702 [INFO    ] __main__: train step 13359: loss: 1.0881, policy_loss: 1.0591, value_loss: 0.6135
2024-07-14 06:29:36,000 [INFO    ] __main__: train step 13360: loss: 1.0881, policy_loss: 1.0591, value_loss: 0.6135
2024-07-14 06:29:36,286 [INFO    ] __main__: train step 13361: loss: 1.0881, policy_loss: 1.0591, value_loss: 0.6135
2024-07-14 06:29:36,594 [INFO    ] __main__: train step 13362: loss: 1.0881, policy_loss: 1.0590, value_loss: 0.6134
2024-07-14 06:29:36,883 [INFO    ] __main__: train step 13363: loss: 1.0880, policy_loss: 1.0590, value_loss: 0.6134
2024-07-14 06:29:37,178 [INFO    ] __main__: train step 13364: loss: 1.0880, policy_loss: 1.0590, value_loss: 0.6134
2024-07-14 06:29:37,488 [INFO    ] __main__: train step 13365: loss: 1.0880, policy_loss: 1.0590, value_loss: 0.6133
2024-07-14 06:29:37,782 [INFO    ] __main__: train step 13366: loss: 1.0880, policy_loss: 1.0589, value_loss: 0.6133
2024-07-14 06:29:38,065 [INFO    ] __main__: train step 13367: loss: 1.0880, policy_loss: 1.0589, value_loss: 0.6133
2024-07-14 06:29:38,352 [INFO    ] __main__: train step 13368: loss: 1.0880, policy_loss: 1.0589, value_loss: 0.6132
2024-07-14 06:29:38,641 [INFO    ] __main__: train step 13369: loss: 1.0880, policy_loss: 1.0589, value_loss: 0.6132
2024-07-14 06:29:38,927 [INFO    ] __main__: train step 13370: loss: 1.0880, policy_loss: 1.0589, value_loss: 0.6132
2024-07-14 06:29:39,234 [INFO    ] __main__: train step 13371: loss: 1.0879, policy_loss: 1.0588, value_loss: 0.6131
2024-07-14 06:29:39,509 [INFO    ] __main__: train step 13372: loss: 1.0879, policy_loss: 1.0588, value_loss: 0.6131
2024-07-14 06:29:39,796 [INFO    ] __main__: train step 13373: loss: 1.0879, policy_loss: 1.0588, value_loss: 0.6131
2024-07-14 06:29:40,088 [INFO    ] __main__: train step 13374: loss: 1.0879, policy_loss: 1.0588, value_loss: 0.6130
2024-07-14 06:29:40,392 [INFO    ] __main__: train step 13375: loss: 1.0879, policy_loss: 1.0587, value_loss: 0.6130
2024-07-14 06:29:42,002 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:29:42,516 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:29:42,586 [INFO    ] __main__: train step 13376: loss: 1.0879, policy_loss: 1.0587, value_loss: 0.6130
2024-07-14 06:29:42,856 [INFO    ] __main__: train step 13377: loss: 1.0879, policy_loss: 1.0587, value_loss: 0.6129
2024-07-14 06:29:43,138 [INFO    ] __main__: train step 13378: loss: 1.0879, policy_loss: 1.0587, value_loss: 0.6129
2024-07-14 06:29:43,433 [INFO    ] __main__: train step 13379: loss: 1.0879, policy_loss: 1.0586, value_loss: 0.6129
2024-07-14 06:29:43,715 [INFO    ] __main__: train step 13380: loss: 1.0878, policy_loss: 1.0586, value_loss: 0.6128
2024-07-14 06:29:44,004 [INFO    ] __main__: train step 13381: loss: 1.0878, policy_loss: 1.0586, value_loss: 0.6128
2024-07-14 06:29:44,302 [INFO    ] __main__: train step 13382: loss: 1.0878, policy_loss: 1.0586, value_loss: 0.6128
2024-07-14 06:29:44,598 [INFO    ] __main__: train step 13383: loss: 1.0878, policy_loss: 1.0586, value_loss: 0.6127
2024-07-14 06:29:44,901 [INFO    ] __main__: train step 13384: loss: 1.0878, policy_loss: 1.0585, value_loss: 0.6127
2024-07-14 06:29:45,209 [INFO    ] __main__: train step 13385: loss: 1.0878, policy_loss: 1.0585, value_loss: 0.6127
2024-07-14 06:29:45,539 [INFO    ] __main__: train step 13386: loss: 1.0878, policy_loss: 1.0585, value_loss: 0.6127
2024-07-14 06:29:45,837 [INFO    ] __main__: train step 13387: loss: 1.0878, policy_loss: 1.0585, value_loss: 0.6126
2024-07-14 06:29:46,132 [INFO    ] __main__: train step 13388: loss: 1.0877, policy_loss: 1.0584, value_loss: 0.6126
2024-07-14 06:29:46,429 [INFO    ] __main__: train step 13389: loss: 1.0877, policy_loss: 1.0584, value_loss: 0.6126
2024-07-14 06:29:46,716 [INFO    ] __main__: train step 13390: loss: 1.0877, policy_loss: 1.0584, value_loss: 0.6125
2024-07-14 06:29:47,012 [INFO    ] __main__: train step 13391: loss: 1.0877, policy_loss: 1.0584, value_loss: 0.6125
2024-07-14 06:29:47,307 [INFO    ] __main__: train step 13392: loss: 1.0877, policy_loss: 1.0584, value_loss: 0.6125
2024-07-14 06:29:48,919 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:29:49,414 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:29:49,486 [INFO    ] __main__: train step 13393: loss: 1.0877, policy_loss: 1.0583, value_loss: 0.6124
2024-07-14 06:29:49,788 [INFO    ] __main__: train step 13394: loss: 1.0877, policy_loss: 1.0583, value_loss: 0.6124
2024-07-14 06:29:50,071 [INFO    ] __main__: train step 13395: loss: 1.0877, policy_loss: 1.0583, value_loss: 0.6124
2024-07-14 06:29:50,345 [INFO    ] __main__: train step 13396: loss: 1.0877, policy_loss: 1.0583, value_loss: 0.6123
2024-07-14 06:29:50,639 [INFO    ] __main__: train step 13397: loss: 1.0877, policy_loss: 1.0582, value_loss: 0.6123
2024-07-14 06:29:50,928 [INFO    ] __main__: train step 13398: loss: 1.0876, policy_loss: 1.0582, value_loss: 0.6123
2024-07-14 06:29:51,210 [INFO    ] __main__: train step 13399: loss: 1.0876, policy_loss: 1.0582, value_loss: 0.6122
2024-07-14 06:29:51,496 [INFO    ] __main__: train step 13400: loss: 1.0876, policy_loss: 1.0582, value_loss: 0.6122
2024-07-14 06:29:51,802 [INFO    ] __main__: train step 13401: loss: 1.0876, policy_loss: 1.0581, value_loss: 0.6122
2024-07-14 06:29:52,098 [INFO    ] __main__: train step 13402: loss: 1.0876, policy_loss: 1.0581, value_loss: 0.6121
2024-07-14 06:29:52,388 [INFO    ] __main__: train step 13403: loss: 1.0876, policy_loss: 1.0581, value_loss: 0.6121
2024-07-14 06:29:52,675 [INFO    ] __main__: train step 13404: loss: 1.0876, policy_loss: 1.0581, value_loss: 0.6121
2024-07-14 06:29:52,975 [INFO    ] __main__: train step 13405: loss: 1.0876, policy_loss: 1.0581, value_loss: 0.6120
2024-07-14 06:29:53,257 [INFO    ] __main__: train step 13406: loss: 1.0875, policy_loss: 1.0580, value_loss: 0.6120
2024-07-14 06:29:53,537 [INFO    ] __main__: train step 13407: loss: 1.0875, policy_loss: 1.0580, value_loss: 0.6120
2024-07-14 06:29:53,819 [INFO    ] __main__: train step 13408: loss: 1.0875, policy_loss: 1.0580, value_loss: 0.6119
2024-07-14 06:29:54,107 [INFO    ] __main__: train step 13409: loss: 1.0875, policy_loss: 1.0580, value_loss: 0.6119
2024-07-14 06:29:55,730 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:29:56,224 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:29:56,295 [INFO    ] __main__: train step 13410: loss: 1.0875, policy_loss: 1.0579, value_loss: 0.6119
2024-07-14 06:29:56,558 [INFO    ] __main__: train step 13411: loss: 1.0875, policy_loss: 1.0579, value_loss: 0.6118
2024-07-14 06:29:56,838 [INFO    ] __main__: train step 13412: loss: 1.0875, policy_loss: 1.0579, value_loss: 0.6118
2024-07-14 06:29:57,137 [INFO    ] __main__: train step 13413: loss: 1.0875, policy_loss: 1.0579, value_loss: 0.6118
2024-07-14 06:29:57,430 [INFO    ] __main__: train step 13414: loss: 1.0875, policy_loss: 1.0579, value_loss: 0.6117
2024-07-14 06:29:57,729 [INFO    ] __main__: train step 13415: loss: 1.0874, policy_loss: 1.0578, value_loss: 0.6117
2024-07-14 06:29:58,011 [INFO    ] __main__: train step 13416: loss: 1.0874, policy_loss: 1.0578, value_loss: 0.6117
2024-07-14 06:29:58,308 [INFO    ] __main__: train step 13417: loss: 1.0874, policy_loss: 1.0578, value_loss: 0.6117
2024-07-14 06:29:58,592 [INFO    ] __main__: train step 13418: loss: 1.0874, policy_loss: 1.0578, value_loss: 0.6116
2024-07-14 06:29:58,888 [INFO    ] __main__: train step 13419: loss: 1.0874, policy_loss: 1.0577, value_loss: 0.6116
2024-07-14 06:29:59,175 [INFO    ] __main__: train step 13420: loss: 1.0874, policy_loss: 1.0577, value_loss: 0.6116
2024-07-14 06:29:59,457 [INFO    ] __main__: train step 13421: loss: 1.0874, policy_loss: 1.0577, value_loss: 0.6115
2024-07-14 06:29:59,741 [INFO    ] __main__: train step 13422: loss: 1.0874, policy_loss: 1.0577, value_loss: 0.6115
2024-07-14 06:30:00,027 [INFO    ] __main__: train step 13423: loss: 1.0874, policy_loss: 1.0576, value_loss: 0.6115
2024-07-14 06:30:00,314 [INFO    ] __main__: train step 13424: loss: 1.0873, policy_loss: 1.0576, value_loss: 0.6114
2024-07-14 06:30:00,607 [INFO    ] __main__: train step 13425: loss: 1.0873, policy_loss: 1.0576, value_loss: 0.6114
2024-07-14 06:30:00,901 [INFO    ] __main__: train step 13426: loss: 1.0873, policy_loss: 1.0576, value_loss: 0.6114
2024-07-14 06:30:02,515 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:30:03,021 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:30:03,088 [INFO    ] __main__: train step 13427: loss: 1.0873, policy_loss: 1.0576, value_loss: 0.6113
2024-07-14 06:30:03,418 [INFO    ] __main__: train step 13428: loss: 1.0873, policy_loss: 1.0575, value_loss: 0.6113
2024-07-14 06:30:03,710 [INFO    ] __main__: train step 13429: loss: 1.0873, policy_loss: 1.0575, value_loss: 0.6113
2024-07-14 06:30:04,016 [INFO    ] __main__: train step 13430: loss: 1.0873, policy_loss: 1.0575, value_loss: 0.6112
2024-07-14 06:30:04,309 [INFO    ] __main__: train step 13431: loss: 1.0873, policy_loss: 1.0575, value_loss: 0.6112
2024-07-14 06:30:07,208 [INFO    ] __main__: train step 13432: loss: 1.0873, policy_loss: 1.0574, value_loss: 0.6112
2024-07-14 06:30:07,495 [INFO    ] __main__: train step 13433: loss: 1.0872, policy_loss: 1.0574, value_loss: 0.6111
2024-07-14 06:30:07,786 [INFO    ] __main__: train step 13434: loss: 1.0872, policy_loss: 1.0574, value_loss: 0.6111
2024-07-14 06:30:08,078 [INFO    ] __main__: train step 13435: loss: 1.0872, policy_loss: 1.0574, value_loss: 0.6111
2024-07-14 06:30:08,373 [INFO    ] __main__: train step 13436: loss: 1.0872, policy_loss: 1.0574, value_loss: 0.6110
2024-07-14 06:30:08,663 [INFO    ] __main__: train step 13437: loss: 1.0872, policy_loss: 1.0573, value_loss: 0.6110
2024-07-14 06:30:08,945 [INFO    ] __main__: train step 13438: loss: 1.0872, policy_loss: 1.0573, value_loss: 0.6110
2024-07-14 06:30:09,234 [INFO    ] __main__: train step 13439: loss: 1.0872, policy_loss: 1.0573, value_loss: 0.6110
2024-07-14 06:30:09,523 [INFO    ] __main__: train step 13440: loss: 1.0872, policy_loss: 1.0573, value_loss: 0.6109
2024-07-14 06:30:09,796 [INFO    ] __main__: train step 13441: loss: 1.0872, policy_loss: 1.0572, value_loss: 0.6109
2024-07-14 06:30:10,068 [INFO    ] __main__: train step 13442: loss: 1.0871, policy_loss: 1.0572, value_loss: 0.6109
2024-07-14 06:30:10,341 [INFO    ] __main__: train step 13443: loss: 1.0871, policy_loss: 1.0572, value_loss: 0.6108
2024-07-14 06:30:11,945 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:30:12,443 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:30:12,510 [INFO    ] __main__: train step 13444: loss: 1.0871, policy_loss: 1.0572, value_loss: 0.6108
2024-07-14 06:30:12,804 [INFO    ] __main__: train step 13445: loss: 1.0871, policy_loss: 1.0572, value_loss: 0.6108
2024-07-14 06:30:13,102 [INFO    ] __main__: train step 13446: loss: 1.0871, policy_loss: 1.0571, value_loss: 0.6107
2024-07-14 06:30:13,395 [INFO    ] __main__: train step 13447: loss: 1.0871, policy_loss: 1.0571, value_loss: 0.6107
2024-07-14 06:30:13,688 [INFO    ] __main__: train step 13448: loss: 1.0871, policy_loss: 1.0571, value_loss: 0.6107
2024-07-14 06:30:13,983 [INFO    ] __main__: train step 13449: loss: 1.0871, policy_loss: 1.0571, value_loss: 0.6106
2024-07-14 06:30:14,275 [INFO    ] __main__: train step 13450: loss: 1.0871, policy_loss: 1.0570, value_loss: 0.6106
2024-07-14 06:30:14,565 [INFO    ] __main__: train step 13451: loss: 1.0870, policy_loss: 1.0570, value_loss: 0.6106
2024-07-14 06:30:14,862 [INFO    ] __main__: train step 13452: loss: 1.0870, policy_loss: 1.0570, value_loss: 0.6105
2024-07-14 06:30:15,154 [INFO    ] __main__: train step 13453: loss: 1.0870, policy_loss: 1.0570, value_loss: 0.6105
2024-07-14 06:30:15,455 [INFO    ] __main__: train step 13454: loss: 1.0870, policy_loss: 1.0569, value_loss: 0.6105
2024-07-14 06:30:15,756 [INFO    ] __main__: train step 13455: loss: 1.0870, policy_loss: 1.0569, value_loss: 0.6104
2024-07-14 06:30:16,051 [INFO    ] __main__: train step 13456: loss: 1.0870, policy_loss: 1.0569, value_loss: 0.6104
2024-07-14 06:30:16,340 [INFO    ] __main__: train step 13457: loss: 1.0870, policy_loss: 1.0569, value_loss: 0.6104
2024-07-14 06:30:16,611 [INFO    ] __main__: train step 13458: loss: 1.0870, policy_loss: 1.0569, value_loss: 0.6104
2024-07-14 06:30:16,888 [INFO    ] __main__: train step 13459: loss: 1.0870, policy_loss: 1.0568, value_loss: 0.6103
2024-07-14 06:30:17,157 [INFO    ] __main__: train step 13460: loss: 1.0869, policy_loss: 1.0568, value_loss: 0.6103
2024-07-14 06:30:18,756 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:30:19,238 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:30:19,312 [INFO    ] __main__: train step 13461: loss: 1.0869, policy_loss: 1.0568, value_loss: 0.6103
2024-07-14 06:30:19,605 [INFO    ] __main__: train step 13462: loss: 1.0869, policy_loss: 1.0568, value_loss: 0.6102
2024-07-14 06:30:19,898 [INFO    ] __main__: train step 13463: loss: 1.0869, policy_loss: 1.0567, value_loss: 0.6102
2024-07-14 06:30:20,192 [INFO    ] __main__: train step 13464: loss: 1.0869, policy_loss: 1.0567, value_loss: 0.6102
2024-07-14 06:30:20,517 [INFO    ] __main__: train step 13465: loss: 1.0869, policy_loss: 1.0567, value_loss: 0.6101
2024-07-14 06:30:20,817 [INFO    ] __main__: train step 13466: loss: 1.0869, policy_loss: 1.0567, value_loss: 0.6101
2024-07-14 06:30:21,107 [INFO    ] __main__: train step 13467: loss: 1.0869, policy_loss: 1.0567, value_loss: 0.6101
2024-07-14 06:30:21,404 [INFO    ] __main__: train step 13468: loss: 1.0869, policy_loss: 1.0566, value_loss: 0.6100
2024-07-14 06:30:21,697 [INFO    ] __main__: train step 13469: loss: 1.0868, policy_loss: 1.0566, value_loss: 0.6100
2024-07-14 06:30:21,991 [INFO    ] __main__: train step 13470: loss: 1.0868, policy_loss: 1.0566, value_loss: 0.6100
2024-07-14 06:30:22,293 [INFO    ] __main__: train step 13471: loss: 1.0868, policy_loss: 1.0566, value_loss: 0.6100
2024-07-14 06:30:22,586 [INFO    ] __main__: train step 13472: loss: 1.0868, policy_loss: 1.0565, value_loss: 0.6099
2024-07-14 06:30:22,875 [INFO    ] __main__: train step 13473: loss: 1.0868, policy_loss: 1.0565, value_loss: 0.6099
2024-07-14 06:30:23,167 [INFO    ] __main__: train step 13474: loss: 1.0868, policy_loss: 1.0565, value_loss: 0.6099
2024-07-14 06:30:23,456 [INFO    ] __main__: train step 13475: loss: 1.0868, policy_loss: 1.0565, value_loss: 0.6098
2024-07-14 06:30:23,763 [INFO    ] __main__: train step 13476: loss: 1.0868, policy_loss: 1.0564, value_loss: 0.6098
2024-07-14 06:30:24,060 [INFO    ] __main__: train step 13477: loss: 1.0868, policy_loss: 1.0564, value_loss: 0.6098
2024-07-14 06:30:25,661 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:30:26,129 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:30:26,201 [INFO    ] __main__: train step 13478: loss: 1.0867, policy_loss: 1.0564, value_loss: 0.6097
2024-07-14 06:30:26,494 [INFO    ] __main__: train step 13479: loss: 1.0867, policy_loss: 1.0564, value_loss: 0.6097
2024-07-14 06:30:26,785 [INFO    ] __main__: train step 13480: loss: 1.0867, policy_loss: 1.0563, value_loss: 0.6097
2024-07-14 06:30:27,082 [INFO    ] __main__: train step 13481: loss: 1.0867, policy_loss: 1.0563, value_loss: 0.6096
2024-07-14 06:30:27,384 [INFO    ] __main__: train step 13482: loss: 1.0867, policy_loss: 1.0563, value_loss: 0.6096
2024-07-14 06:30:27,687 [INFO    ] __main__: train step 13483: loss: 1.0867, policy_loss: 1.0563, value_loss: 0.6096
2024-07-14 06:30:27,967 [INFO    ] __main__: train step 13484: loss: 1.0867, policy_loss: 1.0563, value_loss: 0.6095
2024-07-14 06:30:28,264 [INFO    ] __main__: train step 13485: loss: 1.0867, policy_loss: 1.0562, value_loss: 0.6095
2024-07-14 06:30:28,564 [INFO    ] __main__: train step 13486: loss: 1.0867, policy_loss: 1.0562, value_loss: 0.6095
2024-07-14 06:30:28,857 [INFO    ] __main__: train step 13487: loss: 1.0866, policy_loss: 1.0562, value_loss: 0.6095
2024-07-14 06:30:29,157 [INFO    ] __main__: train step 13488: loss: 1.0866, policy_loss: 1.0562, value_loss: 0.6094
2024-07-14 06:30:29,449 [INFO    ] __main__: train step 13489: loss: 1.0866, policy_loss: 1.0561, value_loss: 0.6094
2024-07-14 06:30:29,740 [INFO    ] __main__: train step 13490: loss: 1.0866, policy_loss: 1.0561, value_loss: 0.6094
2024-07-14 06:30:30,034 [INFO    ] __main__: train step 13491: loss: 1.0866, policy_loss: 1.0561, value_loss: 0.6093
2024-07-14 06:30:30,303 [INFO    ] __main__: train step 13492: loss: 1.0866, policy_loss: 1.0561, value_loss: 0.6093
2024-07-14 06:30:30,588 [INFO    ] __main__: train step 13493: loss: 1.0866, policy_loss: 1.0560, value_loss: 0.6093
2024-07-14 06:30:30,863 [INFO    ] __main__: train step 13494: loss: 1.0866, policy_loss: 1.0560, value_loss: 0.6092
2024-07-14 06:30:32,470 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:30:32,961 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:30:33,032 [INFO    ] __main__: train step 13495: loss: 1.0865, policy_loss: 1.0560, value_loss: 0.6092
2024-07-14 06:30:33,328 [INFO    ] __main__: train step 13496: loss: 1.0865, policy_loss: 1.0560, value_loss: 0.6092
2024-07-14 06:30:33,622 [INFO    ] __main__: train step 13497: loss: 1.0865, policy_loss: 1.0560, value_loss: 0.6091
2024-07-14 06:30:33,910 [INFO    ] __main__: train step 13498: loss: 1.0865, policy_loss: 1.0559, value_loss: 0.6091
2024-07-14 06:30:34,199 [INFO    ] __main__: train step 13499: loss: 1.0865, policy_loss: 1.0559, value_loss: 0.6091
2024-07-14 06:30:34,492 [INFO    ] __main__: train step 13500: loss: 1.0865, policy_loss: 1.0559, value_loss: 0.6090
2024-07-14 06:30:34,772 [INFO    ] __main__: train step 13501: loss: 1.0865, policy_loss: 1.0559, value_loss: 0.6090
2024-07-14 06:30:35,077 [INFO    ] __main__: train step 13502: loss: 1.0865, policy_loss: 1.0558, value_loss: 0.6090
2024-07-14 06:30:35,360 [INFO    ] __main__: train step 13503: loss: 1.0865, policy_loss: 1.0558, value_loss: 0.6090
2024-07-14 06:30:35,655 [INFO    ] __main__: train step 13504: loss: 1.0864, policy_loss: 1.0558, value_loss: 0.6089
2024-07-14 06:30:35,949 [INFO    ] __main__: train step 13505: loss: 1.0864, policy_loss: 1.0558, value_loss: 0.6089
2024-07-14 06:30:36,243 [INFO    ] __main__: train step 13506: loss: 1.0864, policy_loss: 1.0557, value_loss: 0.6089
2024-07-14 06:30:36,551 [INFO    ] __main__: train step 13507: loss: 1.0864, policy_loss: 1.0557, value_loss: 0.6088
2024-07-14 06:30:36,836 [INFO    ] __main__: train step 13508: loss: 1.0864, policy_loss: 1.0557, value_loss: 0.6088
2024-07-14 06:30:37,129 [INFO    ] __main__: train step 13509: loss: 1.0864, policy_loss: 1.0557, value_loss: 0.6088
2024-07-14 06:30:37,419 [INFO    ] __main__: train step 13510: loss: 1.0864, policy_loss: 1.0557, value_loss: 0.6087
2024-07-14 06:30:37,708 [INFO    ] __main__: train step 13511: loss: 1.0864, policy_loss: 1.0556, value_loss: 0.6087
2024-07-14 06:30:39,334 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:30:39,830 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:30:39,899 [INFO    ] __main__: train step 13512: loss: 1.0863, policy_loss: 1.0556, value_loss: 0.6087
2024-07-14 06:30:40,190 [INFO    ] __main__: train step 13513: loss: 1.0863, policy_loss: 1.0556, value_loss: 0.6086
2024-07-14 06:30:40,485 [INFO    ] __main__: train step 13514: loss: 1.0863, policy_loss: 1.0556, value_loss: 0.6086
2024-07-14 06:30:40,770 [INFO    ] __main__: train step 13515: loss: 1.0863, policy_loss: 1.0555, value_loss: 0.6086
2024-07-14 06:30:41,074 [INFO    ] __main__: train step 13516: loss: 1.0863, policy_loss: 1.0555, value_loss: 0.6085
2024-07-14 06:30:41,358 [INFO    ] __main__: train step 13517: loss: 1.0863, policy_loss: 1.0555, value_loss: 0.6085
2024-07-14 06:30:41,627 [INFO    ] __main__: train step 13518: loss: 1.0863, policy_loss: 1.0555, value_loss: 0.6085
2024-07-14 06:30:41,893 [INFO    ] __main__: train step 13519: loss: 1.0863, policy_loss: 1.0554, value_loss: 0.6085
2024-07-14 06:30:44,576 [INFO    ] __main__: train step 13520: loss: 1.0863, policy_loss: 1.0554, value_loss: 0.6084
2024-07-14 06:30:44,874 [INFO    ] __main__: train step 13521: loss: 1.0862, policy_loss: 1.0554, value_loss: 0.6084
2024-07-14 06:30:45,164 [INFO    ] __main__: train step 13522: loss: 1.0862, policy_loss: 1.0554, value_loss: 0.6084
2024-07-14 06:30:45,433 [INFO    ] __main__: train step 13523: loss: 1.0862, policy_loss: 1.0553, value_loss: 0.6083
2024-07-14 06:30:45,709 [INFO    ] __main__: train step 13524: loss: 1.0862, policy_loss: 1.0553, value_loss: 0.6083
2024-07-14 06:30:45,963 [INFO    ] __main__: train step 13525: loss: 1.0862, policy_loss: 1.0553, value_loss: 0.6083
2024-07-14 06:30:46,254 [INFO    ] __main__: train step 13526: loss: 1.0862, policy_loss: 1.0553, value_loss: 0.6082
2024-07-14 06:30:46,543 [INFO    ] __main__: train step 13527: loss: 1.0862, policy_loss: 1.0553, value_loss: 0.6082
2024-07-14 06:30:46,836 [INFO    ] __main__: train step 13528: loss: 1.0862, policy_loss: 1.0552, value_loss: 0.6082
2024-07-14 06:30:48,458 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:30:48,956 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:30:49,031 [INFO    ] __main__: train step 13529: loss: 1.0862, policy_loss: 1.0552, value_loss: 0.6081
2024-07-14 06:30:49,307 [INFO    ] __main__: train step 13530: loss: 1.0861, policy_loss: 1.0552, value_loss: 0.6081
2024-07-14 06:30:49,591 [INFO    ] __main__: train step 13531: loss: 1.0861, policy_loss: 1.0552, value_loss: 0.6081
2024-07-14 06:30:49,884 [INFO    ] __main__: train step 13532: loss: 1.0861, policy_loss: 1.0551, value_loss: 0.6081
2024-07-14 06:30:50,172 [INFO    ] __main__: train step 13533: loss: 1.0861, policy_loss: 1.0551, value_loss: 0.6080
2024-07-14 06:30:50,452 [INFO    ] __main__: train step 13534: loss: 1.0861, policy_loss: 1.0551, value_loss: 0.6080
2024-07-14 06:30:50,735 [INFO    ] __main__: train step 13535: loss: 1.0861, policy_loss: 1.0551, value_loss: 0.6080
2024-07-14 06:30:51,029 [INFO    ] __main__: train step 13536: loss: 1.0861, policy_loss: 1.0550, value_loss: 0.6079
2024-07-14 06:30:51,310 [INFO    ] __main__: train step 13537: loss: 1.0861, policy_loss: 1.0550, value_loss: 0.6079
2024-07-14 06:30:51,601 [INFO    ] __main__: train step 13538: loss: 1.0861, policy_loss: 1.0550, value_loss: 0.6079
2024-07-14 06:30:51,886 [INFO    ] __main__: train step 13539: loss: 1.0860, policy_loss: 1.0550, value_loss: 0.6078
2024-07-14 06:30:52,188 [INFO    ] __main__: train step 13540: loss: 1.0860, policy_loss: 1.0549, value_loss: 0.6078
2024-07-14 06:30:52,479 [INFO    ] __main__: train step 13541: loss: 1.0860, policy_loss: 1.0549, value_loss: 0.6078
2024-07-14 06:30:52,764 [INFO    ] __main__: train step 13542: loss: 1.0860, policy_loss: 1.0549, value_loss: 0.6077
2024-07-14 06:30:53,050 [INFO    ] __main__: train step 13543: loss: 1.0860, policy_loss: 1.0549, value_loss: 0.6077
2024-07-14 06:30:53,334 [INFO    ] __main__: train step 13544: loss: 1.0860, policy_loss: 1.0549, value_loss: 0.6077
2024-07-14 06:30:53,629 [INFO    ] __main__: train step 13545: loss: 1.0860, policy_loss: 1.0548, value_loss: 0.6077
2024-07-14 06:30:55,240 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:30:55,724 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:30:55,793 [INFO    ] __main__: train step 13546: loss: 1.0860, policy_loss: 1.0548, value_loss: 0.6076
2024-07-14 06:30:56,093 [INFO    ] __main__: train step 13547: loss: 1.0859, policy_loss: 1.0548, value_loss: 0.6076
2024-07-14 06:30:56,358 [INFO    ] __main__: train step 13548: loss: 1.0859, policy_loss: 1.0548, value_loss: 0.6076
2024-07-14 06:30:56,625 [INFO    ] __main__: train step 13549: loss: 1.0859, policy_loss: 1.0547, value_loss: 0.6075
2024-07-14 06:30:56,907 [INFO    ] __main__: train step 13550: loss: 1.0859, policy_loss: 1.0547, value_loss: 0.6075
2024-07-14 06:30:57,193 [INFO    ] __main__: train step 13551: loss: 1.0859, policy_loss: 1.0547, value_loss: 0.6075
2024-07-14 06:30:57,477 [INFO    ] __main__: train step 13552: loss: 1.0859, policy_loss: 1.0547, value_loss: 0.6074
2024-07-14 06:30:57,756 [INFO    ] __main__: train step 13553: loss: 1.0859, policy_loss: 1.0546, value_loss: 0.6074
2024-07-14 06:30:58,032 [INFO    ] __main__: train step 13554: loss: 1.0859, policy_loss: 1.0546, value_loss: 0.6074
2024-07-14 06:30:58,316 [INFO    ] __main__: train step 13555: loss: 1.0859, policy_loss: 1.0546, value_loss: 0.6073
2024-07-14 06:30:58,605 [INFO    ] __main__: train step 13556: loss: 1.0858, policy_loss: 1.0546, value_loss: 0.6073
2024-07-14 06:30:58,888 [INFO    ] __main__: train step 13557: loss: 1.0858, policy_loss: 1.0546, value_loss: 0.6073
2024-07-14 06:30:59,162 [INFO    ] __main__: train step 13558: loss: 1.0858, policy_loss: 1.0545, value_loss: 0.6073
2024-07-14 06:30:59,444 [INFO    ] __main__: train step 13559: loss: 1.0858, policy_loss: 1.0545, value_loss: 0.6072
2024-07-14 06:30:59,729 [INFO    ] __main__: train step 13560: loss: 1.0858, policy_loss: 1.0545, value_loss: 0.6072
2024-07-14 06:31:00,016 [INFO    ] __main__: train step 13561: loss: 1.0858, policy_loss: 1.0545, value_loss: 0.6072
2024-07-14 06:31:00,303 [INFO    ] __main__: train step 13562: loss: 1.0858, policy_loss: 1.0544, value_loss: 0.6071
2024-07-14 06:31:01,915 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:31:02,401 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:31:02,473 [INFO    ] __main__: train step 13563: loss: 1.0858, policy_loss: 1.0544, value_loss: 0.6071
2024-07-14 06:31:02,761 [INFO    ] __main__: train step 13564: loss: 1.0858, policy_loss: 1.0544, value_loss: 0.6071
2024-07-14 06:31:03,045 [INFO    ] __main__: train step 13565: loss: 1.0857, policy_loss: 1.0544, value_loss: 0.6070
2024-07-14 06:31:03,328 [INFO    ] __main__: train step 13566: loss: 1.0857, policy_loss: 1.0543, value_loss: 0.6070
2024-07-14 06:31:03,608 [INFO    ] __main__: train step 13567: loss: 1.0857, policy_loss: 1.0543, value_loss: 0.6070
2024-07-14 06:31:03,899 [INFO    ] __main__: train step 13568: loss: 1.0857, policy_loss: 1.0543, value_loss: 0.6070
2024-07-14 06:31:04,186 [INFO    ] __main__: train step 13569: loss: 1.0857, policy_loss: 1.0543, value_loss: 0.6069
2024-07-14 06:31:04,475 [INFO    ] __main__: train step 13570: loss: 1.0857, policy_loss: 1.0543, value_loss: 0.6069
2024-07-14 06:31:04,765 [INFO    ] __main__: train step 13571: loss: 1.0857, policy_loss: 1.0542, value_loss: 0.6069
2024-07-14 06:31:05,061 [INFO    ] __main__: train step 13572: loss: 1.0857, policy_loss: 1.0542, value_loss: 0.6068
2024-07-14 06:31:05,350 [INFO    ] __main__: train step 13573: loss: 1.0857, policy_loss: 1.0542, value_loss: 0.6068
2024-07-14 06:31:05,616 [INFO    ] __main__: train step 13574: loss: 1.0856, policy_loss: 1.0542, value_loss: 0.6068
2024-07-14 06:31:05,901 [INFO    ] __main__: train step 13575: loss: 1.0856, policy_loss: 1.0541, value_loss: 0.6067
2024-07-14 06:31:06,193 [INFO    ] __main__: train step 13576: loss: 1.0856, policy_loss: 1.0541, value_loss: 0.6067
2024-07-14 06:31:06,491 [INFO    ] __main__: train step 13577: loss: 1.0856, policy_loss: 1.0541, value_loss: 0.6067
2024-07-14 06:31:06,784 [INFO    ] __main__: train step 13578: loss: 1.0856, policy_loss: 1.0541, value_loss: 0.6067
2024-07-14 06:31:07,060 [INFO    ] __main__: train step 13579: loss: 1.0856, policy_loss: 1.0540, value_loss: 0.6066
2024-07-14 06:31:08,686 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:31:09,172 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:31:09,242 [INFO    ] __main__: train step 13580: loss: 1.0856, policy_loss: 1.0540, value_loss: 0.6066
2024-07-14 06:31:09,536 [INFO    ] __main__: train step 13581: loss: 1.0856, policy_loss: 1.0540, value_loss: 0.6066
2024-07-14 06:31:09,826 [INFO    ] __main__: train step 13582: loss: 1.0856, policy_loss: 1.0540, value_loss: 0.6065
2024-07-14 06:31:10,114 [INFO    ] __main__: train step 13583: loss: 1.0855, policy_loss: 1.0539, value_loss: 0.6065
2024-07-14 06:31:10,407 [INFO    ] __main__: train step 13584: loss: 1.0855, policy_loss: 1.0539, value_loss: 0.6065
2024-07-14 06:31:10,696 [INFO    ] __main__: train step 13585: loss: 1.0855, policy_loss: 1.0539, value_loss: 0.6064
2024-07-14 06:31:10,970 [INFO    ] __main__: train step 13586: loss: 1.0855, policy_loss: 1.0539, value_loss: 0.6064
2024-07-14 06:31:11,265 [INFO    ] __main__: train step 13587: loss: 1.0855, policy_loss: 1.0539, value_loss: 0.6064
2024-07-14 06:31:11,562 [INFO    ] __main__: train step 13588: loss: 1.0855, policy_loss: 1.0538, value_loss: 0.6063
2024-07-14 06:31:11,859 [INFO    ] __main__: train step 13589: loss: 1.0855, policy_loss: 1.0538, value_loss: 0.6063
2024-07-14 06:31:12,153 [INFO    ] __main__: train step 13590: loss: 1.0855, policy_loss: 1.0538, value_loss: 0.6063
2024-07-14 06:31:12,444 [INFO    ] __main__: train step 13591: loss: 1.0854, policy_loss: 1.0538, value_loss: 0.6063
2024-07-14 06:31:12,744 [INFO    ] __main__: train step 13592: loss: 1.0854, policy_loss: 1.0537, value_loss: 0.6062
2024-07-14 06:31:13,036 [INFO    ] __main__: train step 13593: loss: 1.0854, policy_loss: 1.0537, value_loss: 0.6062
2024-07-14 06:31:13,340 [INFO    ] __main__: train step 13594: loss: 1.0854, policy_loss: 1.0537, value_loss: 0.6062
2024-07-14 06:31:13,629 [INFO    ] __main__: train step 13595: loss: 1.0854, policy_loss: 1.0537, value_loss: 0.6061
2024-07-14 06:31:13,926 [INFO    ] __main__: train step 13596: loss: 1.0854, policy_loss: 1.0536, value_loss: 0.6061
2024-07-14 06:31:15,546 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:31:16,037 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:31:16,110 [INFO    ] __main__: train step 13597: loss: 1.0854, policy_loss: 1.0536, value_loss: 0.6061
2024-07-14 06:31:16,387 [INFO    ] __main__: train step 13598: loss: 1.0854, policy_loss: 1.0536, value_loss: 0.6060
2024-07-14 06:31:16,649 [INFO    ] __main__: train step 13599: loss: 1.0853, policy_loss: 1.0536, value_loss: 0.6060
2024-07-14 06:31:16,921 [INFO    ] __main__: train step 13600: loss: 1.0853, policy_loss: 1.0535, value_loss: 0.6060
2024-07-14 06:31:17,200 [INFO    ] __main__: train step 13601: loss: 1.0853, policy_loss: 1.0535, value_loss: 0.6060
2024-07-14 06:31:17,497 [INFO    ] __main__: train step 13602: loss: 1.0853, policy_loss: 1.0535, value_loss: 0.6059
2024-07-14 06:31:17,800 [INFO    ] __main__: train step 13603: loss: 1.0853, policy_loss: 1.0535, value_loss: 0.6059
2024-07-14 06:31:18,097 [INFO    ] __main__: train step 13604: loss: 1.0853, policy_loss: 1.0534, value_loss: 0.6059
2024-07-14 06:31:18,386 [INFO    ] __main__: train step 13605: loss: 1.0853, policy_loss: 1.0534, value_loss: 0.6058
2024-07-14 06:31:18,681 [INFO    ] __main__: train step 13606: loss: 1.0853, policy_loss: 1.0534, value_loss: 0.6058
2024-07-14 06:31:21,277 [INFO    ] __main__: train step 13607: loss: 1.0852, policy_loss: 1.0534, value_loss: 0.6058
2024-07-14 06:31:21,547 [INFO    ] __main__: train step 13608: loss: 1.0852, policy_loss: 1.0533, value_loss: 0.6057
2024-07-14 06:31:21,833 [INFO    ] __main__: train step 13609: loss: 1.0852, policy_loss: 1.0533, value_loss: 0.6057
2024-07-14 06:31:22,130 [INFO    ] __main__: train step 13610: loss: 1.0852, policy_loss: 1.0533, value_loss: 0.6057
2024-07-14 06:31:22,417 [INFO    ] __main__: train step 13611: loss: 1.0852, policy_loss: 1.0533, value_loss: 0.6056
2024-07-14 06:31:22,718 [INFO    ] __main__: train step 13612: loss: 1.0852, policy_loss: 1.0532, value_loss: 0.6056
2024-07-14 06:31:23,014 [INFO    ] __main__: train step 13613: loss: 1.0852, policy_loss: 1.0532, value_loss: 0.6056
2024-07-14 06:31:24,594 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:31:25,065 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:31:25,137 [INFO    ] __main__: train step 13614: loss: 1.0852, policy_loss: 1.0532, value_loss: 0.6056
2024-07-14 06:31:25,400 [INFO    ] __main__: train step 13615: loss: 1.0852, policy_loss: 1.0532, value_loss: 0.6055
2024-07-14 06:31:25,668 [INFO    ] __main__: train step 13616: loss: 1.0851, policy_loss: 1.0532, value_loss: 0.6055
2024-07-14 06:31:25,939 [INFO    ] __main__: train step 13617: loss: 1.0851, policy_loss: 1.0531, value_loss: 0.6055
2024-07-14 06:31:26,207 [INFO    ] __main__: train step 13618: loss: 1.0851, policy_loss: 1.0531, value_loss: 0.6054
2024-07-14 06:31:26,500 [INFO    ] __main__: train step 13619: loss: 1.0851, policy_loss: 1.0531, value_loss: 0.6054
2024-07-14 06:31:26,790 [INFO    ] __main__: train step 13620: loss: 1.0851, policy_loss: 1.0531, value_loss: 0.6054
2024-07-14 06:31:27,081 [INFO    ] __main__: train step 13621: loss: 1.0851, policy_loss: 1.0530, value_loss: 0.6053
2024-07-14 06:31:27,368 [INFO    ] __main__: train step 13622: loss: 1.0851, policy_loss: 1.0530, value_loss: 0.6053
2024-07-14 06:31:27,664 [INFO    ] __main__: train step 13623: loss: 1.0851, policy_loss: 1.0530, value_loss: 0.6053
2024-07-14 06:31:27,952 [INFO    ] __main__: train step 13624: loss: 1.0850, policy_loss: 1.0530, value_loss: 0.6053
2024-07-14 06:31:28,246 [INFO    ] __main__: train step 13625: loss: 1.0850, policy_loss: 1.0529, value_loss: 0.6052
2024-07-14 06:31:28,541 [INFO    ] __main__: train step 13626: loss: 1.0850, policy_loss: 1.0529, value_loss: 0.6052
2024-07-14 06:31:28,827 [INFO    ] __main__: train step 13627: loss: 1.0850, policy_loss: 1.0529, value_loss: 0.6052
2024-07-14 06:31:29,114 [INFO    ] __main__: train step 13628: loss: 1.0850, policy_loss: 1.0529, value_loss: 0.6051
2024-07-14 06:31:29,417 [INFO    ] __main__: train step 13629: loss: 1.0850, policy_loss: 1.0528, value_loss: 0.6051
2024-07-14 06:31:29,708 [INFO    ] __main__: train step 13630: loss: 1.0850, policy_loss: 1.0528, value_loss: 0.6051
2024-07-14 06:31:31,340 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:31:31,841 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:31:31,908 [INFO    ] __main__: train step 13631: loss: 1.0850, policy_loss: 1.0528, value_loss: 0.6050
2024-07-14 06:31:32,199 [INFO    ] __main__: train step 13632: loss: 1.0849, policy_loss: 1.0528, value_loss: 0.6050
2024-07-14 06:31:32,493 [INFO    ] __main__: train step 13633: loss: 1.0849, policy_loss: 1.0527, value_loss: 0.6050
2024-07-14 06:31:32,779 [INFO    ] __main__: train step 13634: loss: 1.0849, policy_loss: 1.0527, value_loss: 0.6050
2024-07-14 06:31:33,072 [INFO    ] __main__: train step 13635: loss: 1.0849, policy_loss: 1.0527, value_loss: 0.6049
2024-07-14 06:31:33,365 [INFO    ] __main__: train step 13636: loss: 1.0849, policy_loss: 1.0527, value_loss: 0.6049
2024-07-14 06:31:33,654 [INFO    ] __main__: train step 13637: loss: 1.0849, policy_loss: 1.0527, value_loss: 0.6049
2024-07-14 06:31:33,964 [INFO    ] __main__: train step 13638: loss: 1.0849, policy_loss: 1.0526, value_loss: 0.6048
2024-07-14 06:31:34,259 [INFO    ] __main__: train step 13639: loss: 1.0849, policy_loss: 1.0526, value_loss: 0.6048
2024-07-14 06:31:34,550 [INFO    ] __main__: train step 13640: loss: 1.0848, policy_loss: 1.0526, value_loss: 0.6048
2024-07-14 06:31:34,838 [INFO    ] __main__: train step 13641: loss: 1.0848, policy_loss: 1.0526, value_loss: 0.6047
2024-07-14 06:31:35,130 [INFO    ] __main__: train step 13642: loss: 1.0848, policy_loss: 1.0525, value_loss: 0.6047
2024-07-14 06:31:35,396 [INFO    ] __main__: train step 13643: loss: 1.0848, policy_loss: 1.0525, value_loss: 0.6047
2024-07-14 06:31:35,663 [INFO    ] __main__: train step 13644: loss: 1.0848, policy_loss: 1.0525, value_loss: 0.6047
2024-07-14 06:31:35,932 [INFO    ] __main__: train step 13645: loss: 1.0848, policy_loss: 1.0525, value_loss: 0.6046
2024-07-14 06:31:36,227 [INFO    ] __main__: train step 13646: loss: 1.0848, policy_loss: 1.0524, value_loss: 0.6046
2024-07-14 06:31:36,520 [INFO    ] __main__: train step 13647: loss: 1.0848, policy_loss: 1.0524, value_loss: 0.6046
2024-07-14 06:31:38,141 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:31:38,623 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:31:38,697 [INFO    ] __main__: train step 13648: loss: 1.0848, policy_loss: 1.0524, value_loss: 0.6045
2024-07-14 06:31:38,991 [INFO    ] __main__: train step 13649: loss: 1.0847, policy_loss: 1.0524, value_loss: 0.6045
2024-07-14 06:31:39,293 [INFO    ] __main__: train step 13650: loss: 1.0847, policy_loss: 1.0523, value_loss: 0.6045
2024-07-14 06:31:39,594 [INFO    ] __main__: train step 13651: loss: 1.0847, policy_loss: 1.0523, value_loss: 0.6044
2024-07-14 06:31:39,879 [INFO    ] __main__: train step 13652: loss: 1.0847, policy_loss: 1.0523, value_loss: 0.6044
2024-07-14 06:31:40,172 [INFO    ] __main__: train step 13653: loss: 1.0847, policy_loss: 1.0523, value_loss: 0.6044
2024-07-14 06:31:40,467 [INFO    ] __main__: train step 13654: loss: 1.0847, policy_loss: 1.0522, value_loss: 0.6044
2024-07-14 06:31:40,764 [INFO    ] __main__: train step 13655: loss: 1.0847, policy_loss: 1.0522, value_loss: 0.6043
2024-07-14 06:31:41,056 [INFO    ] __main__: train step 13656: loss: 1.0847, policy_loss: 1.0522, value_loss: 0.6043
2024-07-14 06:31:41,351 [INFO    ] __main__: train step 13657: loss: 1.0846, policy_loss: 1.0522, value_loss: 0.6043
2024-07-14 06:31:41,637 [INFO    ] __main__: train step 13658: loss: 1.0846, policy_loss: 1.0522, value_loss: 0.6042
2024-07-14 06:31:41,938 [INFO    ] __main__: train step 13659: loss: 1.0846, policy_loss: 1.0521, value_loss: 0.6042
2024-07-14 06:31:42,225 [INFO    ] __main__: train step 13660: loss: 1.0846, policy_loss: 1.0521, value_loss: 0.6042
2024-07-14 06:31:42,522 [INFO    ] __main__: train step 13661: loss: 1.0846, policy_loss: 1.0521, value_loss: 0.6041
2024-07-14 06:31:42,820 [INFO    ] __main__: train step 13662: loss: 1.0846, policy_loss: 1.0521, value_loss: 0.6041
2024-07-14 06:31:43,105 [INFO    ] __main__: train step 13663: loss: 1.0846, policy_loss: 1.0520, value_loss: 0.6041
2024-07-14 06:31:43,402 [INFO    ] __main__: train step 13664: loss: 1.0846, policy_loss: 1.0520, value_loss: 0.6041
2024-07-14 06:31:45,022 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:31:45,530 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:31:45,602 [INFO    ] __main__: train step 13665: loss: 1.0846, policy_loss: 1.0520, value_loss: 0.6040
2024-07-14 06:31:45,910 [INFO    ] __main__: train step 13666: loss: 1.0845, policy_loss: 1.0520, value_loss: 0.6040
2024-07-14 06:31:46,202 [INFO    ] __main__: train step 13667: loss: 1.0845, policy_loss: 1.0519, value_loss: 0.6040
2024-07-14 06:31:46,483 [INFO    ] __main__: train step 13668: loss: 1.0845, policy_loss: 1.0519, value_loss: 0.6039
2024-07-14 06:31:46,778 [INFO    ] __main__: train step 13669: loss: 1.0845, policy_loss: 1.0519, value_loss: 0.6039
2024-07-14 06:31:47,062 [INFO    ] __main__: train step 13670: loss: 1.0845, policy_loss: 1.0519, value_loss: 0.6039
2024-07-14 06:31:47,345 [INFO    ] __main__: train step 13671: loss: 1.0845, policy_loss: 1.0518, value_loss: 0.6039
2024-07-14 06:31:47,632 [INFO    ] __main__: train step 13672: loss: 1.0845, policy_loss: 1.0518, value_loss: 0.6038
2024-07-14 06:31:47,930 [INFO    ] __main__: train step 13673: loss: 1.0845, policy_loss: 1.0518, value_loss: 0.6038
2024-07-14 06:31:48,210 [INFO    ] __main__: train step 13674: loss: 1.0844, policy_loss: 1.0518, value_loss: 0.6038
2024-07-14 06:31:48,481 [INFO    ] __main__: train step 13675: loss: 1.0844, policy_loss: 1.0517, value_loss: 0.6037
2024-07-14 06:31:48,771 [INFO    ] __main__: train step 13676: loss: 1.0844, policy_loss: 1.0517, value_loss: 0.6037
2024-07-14 06:31:49,052 [INFO    ] __main__: train step 13677: loss: 1.0844, policy_loss: 1.0517, value_loss: 0.6037
2024-07-14 06:31:49,335 [INFO    ] __main__: train step 13678: loss: 1.0844, policy_loss: 1.0517, value_loss: 0.6036
2024-07-14 06:31:49,627 [INFO    ] __main__: train step 13679: loss: 1.0844, policy_loss: 1.0516, value_loss: 0.6036
2024-07-14 06:31:49,904 [INFO    ] __main__: train step 13680: loss: 1.0844, policy_loss: 1.0516, value_loss: 0.6036
2024-07-14 06:31:50,190 [INFO    ] __main__: train step 13681: loss: 1.0844, policy_loss: 1.0516, value_loss: 0.6036
2024-07-14 06:31:51,809 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:31:52,299 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:31:52,373 [INFO    ] __main__: train step 13682: loss: 1.0843, policy_loss: 1.0516, value_loss: 0.6035
2024-07-14 06:31:52,664 [INFO    ] __main__: train step 13683: loss: 1.0843, policy_loss: 1.0515, value_loss: 0.6035
2024-07-14 06:31:52,949 [INFO    ] __main__: train step 13684: loss: 1.0843, policy_loss: 1.0515, value_loss: 0.6035
2024-07-14 06:31:53,255 [INFO    ] __main__: train step 13685: loss: 1.0843, policy_loss: 1.0515, value_loss: 0.6034
2024-07-14 06:31:53,557 [INFO    ] __main__: train step 13686: loss: 1.0843, policy_loss: 1.0515, value_loss: 0.6034
2024-07-14 06:31:53,841 [INFO    ] __main__: train step 13687: loss: 1.0843, policy_loss: 1.0514, value_loss: 0.6034
2024-07-14 06:31:54,131 [INFO    ] __main__: train step 13688: loss: 1.0843, policy_loss: 1.0514, value_loss: 0.6033
2024-07-14 06:31:54,424 [INFO    ] __main__: train step 13689: loss: 1.0843, policy_loss: 1.0514, value_loss: 0.6033
2024-07-14 06:31:54,715 [INFO    ] __main__: train step 13690: loss: 1.0842, policy_loss: 1.0514, value_loss: 0.6033
2024-07-14 06:31:55,007 [INFO    ] __main__: train step 13691: loss: 1.0842, policy_loss: 1.0513, value_loss: 0.6033
2024-07-14 06:31:55,293 [INFO    ] __main__: train step 13692: loss: 1.0842, policy_loss: 1.0513, value_loss: 0.6032
2024-07-14 06:31:55,590 [INFO    ] __main__: train step 13693: loss: 1.0842, policy_loss: 1.0513, value_loss: 0.6032
2024-07-14 06:31:55,878 [INFO    ] __main__: train step 13694: loss: 1.0842, policy_loss: 1.0513, value_loss: 0.6032
2024-07-14 06:31:56,171 [INFO    ] __main__: train step 13695: loss: 1.0842, policy_loss: 1.0512, value_loss: 0.6031
2024-07-14 06:31:58,272 [INFO    ] __main__: train step 13696: loss: 1.0842, policy_loss: 1.0512, value_loss: 0.6031
2024-07-14 06:31:58,571 [INFO    ] __main__: train step 13697: loss: 1.0841, policy_loss: 1.0512, value_loss: 0.6031
2024-07-14 06:31:58,860 [INFO    ] __main__: train step 13698: loss: 1.0841, policy_loss: 1.0512, value_loss: 0.6030
2024-07-14 06:32:00,483 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:32:00,977 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:32:01,050 [INFO    ] __main__: train step 13699: loss: 1.0841, policy_loss: 1.0511, value_loss: 0.6030
2024-07-14 06:32:01,338 [INFO    ] __main__: train step 13700: loss: 1.0841, policy_loss: 1.0511, value_loss: 0.6030
2024-07-14 06:32:01,616 [INFO    ] __main__: train step 13701: loss: 1.0841, policy_loss: 1.0511, value_loss: 0.6030
2024-07-14 06:32:01,893 [INFO    ] __main__: train step 13702: loss: 1.0841, policy_loss: 1.0511, value_loss: 0.6029
2024-07-14 06:32:02,184 [INFO    ] __main__: train step 13703: loss: 1.0841, policy_loss: 1.0510, value_loss: 0.6029
2024-07-14 06:32:02,474 [INFO    ] __main__: train step 13704: loss: 1.0841, policy_loss: 1.0510, value_loss: 0.6029
2024-07-14 06:32:02,763 [INFO    ] __main__: train step 13705: loss: 1.0841, policy_loss: 1.0510, value_loss: 0.6028
2024-07-14 06:32:03,058 [INFO    ] __main__: train step 13706: loss: 1.0840, policy_loss: 1.0510, value_loss: 0.6028
2024-07-14 06:32:03,347 [INFO    ] __main__: train step 13707: loss: 1.0840, policy_loss: 1.0510, value_loss: 0.6028
2024-07-14 06:32:03,637 [INFO    ] __main__: train step 13708: loss: 1.0840, policy_loss: 1.0509, value_loss: 0.6027
2024-07-14 06:32:03,930 [INFO    ] __main__: train step 13709: loss: 1.0840, policy_loss: 1.0509, value_loss: 0.6027
2024-07-14 06:32:04,219 [INFO    ] __main__: train step 13710: loss: 1.0840, policy_loss: 1.0509, value_loss: 0.6027
2024-07-14 06:32:04,509 [INFO    ] __main__: train step 13711: loss: 1.0840, policy_loss: 1.0509, value_loss: 0.6027
2024-07-14 06:32:04,803 [INFO    ] __main__: train step 13712: loss: 1.0840, policy_loss: 1.0508, value_loss: 0.6026
2024-07-14 06:32:05,104 [INFO    ] __main__: train step 13713: loss: 1.0839, policy_loss: 1.0508, value_loss: 0.6026
2024-07-14 06:32:05,396 [INFO    ] __main__: train step 13714: loss: 1.0839, policy_loss: 1.0508, value_loss: 0.6026
2024-07-14 06:32:05,670 [INFO    ] __main__: train step 13715: loss: 1.0839, policy_loss: 1.0508, value_loss: 0.6025
2024-07-14 06:32:07,295 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:32:07,788 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:32:07,865 [INFO    ] __main__: train step 13716: loss: 1.0839, policy_loss: 1.0507, value_loss: 0.6025
2024-07-14 06:32:08,158 [INFO    ] __main__: train step 13717: loss: 1.0839, policy_loss: 1.0507, value_loss: 0.6025
2024-07-14 06:32:08,448 [INFO    ] __main__: train step 13718: loss: 1.0839, policy_loss: 1.0507, value_loss: 0.6024
2024-07-14 06:32:08,745 [INFO    ] __main__: train step 13719: loss: 1.0839, policy_loss: 1.0507, value_loss: 0.6024
2024-07-14 06:32:09,038 [INFO    ] __main__: train step 13720: loss: 1.0839, policy_loss: 1.0506, value_loss: 0.6024
2024-07-14 06:32:09,323 [INFO    ] __main__: train step 13721: loss: 1.0838, policy_loss: 1.0506, value_loss: 0.6024
2024-07-14 06:32:09,610 [INFO    ] __main__: train step 13722: loss: 1.0838, policy_loss: 1.0506, value_loss: 0.6023
2024-07-14 06:32:09,913 [INFO    ] __main__: train step 13723: loss: 1.0838, policy_loss: 1.0506, value_loss: 0.6023
2024-07-14 06:32:10,200 [INFO    ] __main__: train step 13724: loss: 1.0838, policy_loss: 1.0505, value_loss: 0.6023
2024-07-14 06:32:10,487 [INFO    ] __main__: train step 13725: loss: 1.0838, policy_loss: 1.0505, value_loss: 0.6022
2024-07-14 06:32:10,782 [INFO    ] __main__: train step 13726: loss: 1.0838, policy_loss: 1.0505, value_loss: 0.6022
2024-07-14 06:32:11,080 [INFO    ] __main__: train step 13727: loss: 1.0838, policy_loss: 1.0505, value_loss: 0.6022
2024-07-14 06:32:11,378 [INFO    ] __main__: train step 13728: loss: 1.0837, policy_loss: 1.0504, value_loss: 0.6021
2024-07-14 06:32:11,669 [INFO    ] __main__: train step 13729: loss: 1.0837, policy_loss: 1.0504, value_loss: 0.6021
2024-07-14 06:32:11,962 [INFO    ] __main__: train step 13730: loss: 1.0837, policy_loss: 1.0504, value_loss: 0.6021
2024-07-14 06:32:12,251 [INFO    ] __main__: train step 13731: loss: 1.0837, policy_loss: 1.0504, value_loss: 0.6021
2024-07-14 06:32:12,539 [INFO    ] __main__: train step 13732: loss: 1.0837, policy_loss: 1.0503, value_loss: 0.6020
2024-07-14 06:32:14,151 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:32:14,651 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:32:14,724 [INFO    ] __main__: train step 13733: loss: 1.0837, policy_loss: 1.0503, value_loss: 0.6020
2024-07-14 06:32:15,021 [INFO    ] __main__: train step 13734: loss: 1.0837, policy_loss: 1.0503, value_loss: 0.6020
2024-07-14 06:32:15,317 [INFO    ] __main__: train step 13735: loss: 1.0837, policy_loss: 1.0503, value_loss: 0.6019
2024-07-14 06:32:15,613 [INFO    ] __main__: train step 13736: loss: 1.0836, policy_loss: 1.0502, value_loss: 0.6019
2024-07-14 06:32:15,904 [INFO    ] __main__: train step 13737: loss: 1.0836, policy_loss: 1.0502, value_loss: 0.6019
2024-07-14 06:32:16,199 [INFO    ] __main__: train step 13738: loss: 1.0836, policy_loss: 1.0502, value_loss: 0.6018
2024-07-14 06:32:16,501 [INFO    ] __main__: train step 13739: loss: 1.0836, policy_loss: 1.0502, value_loss: 0.6018
2024-07-14 06:32:16,794 [INFO    ] __main__: train step 13740: loss: 1.0836, policy_loss: 1.0501, value_loss: 0.6018
2024-07-14 06:32:17,083 [INFO    ] __main__: train step 13741: loss: 1.0836, policy_loss: 1.0501, value_loss: 0.6018
2024-07-14 06:32:17,380 [INFO    ] __main__: train step 13742: loss: 1.0836, policy_loss: 1.0501, value_loss: 0.6017
2024-07-14 06:32:17,682 [INFO    ] __main__: train step 13743: loss: 1.0836, policy_loss: 1.0501, value_loss: 0.6017
2024-07-14 06:32:17,975 [INFO    ] __main__: train step 13744: loss: 1.0835, policy_loss: 1.0500, value_loss: 0.6017
2024-07-14 06:32:18,270 [INFO    ] __main__: train step 13745: loss: 1.0835, policy_loss: 1.0500, value_loss: 0.6016
2024-07-14 06:32:18,553 [INFO    ] __main__: train step 13746: loss: 1.0835, policy_loss: 1.0500, value_loss: 0.6016
2024-07-14 06:32:18,836 [INFO    ] __main__: train step 13747: loss: 1.0835, policy_loss: 1.0500, value_loss: 0.6016
2024-07-14 06:32:19,128 [INFO    ] __main__: train step 13748: loss: 1.0835, policy_loss: 1.0499, value_loss: 0.6016
2024-07-14 06:32:19,418 [INFO    ] __main__: train step 13749: loss: 1.0835, policy_loss: 1.0499, value_loss: 0.6015
2024-07-14 06:32:21,025 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:32:21,513 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:32:21,582 [INFO    ] __main__: train step 13750: loss: 1.0835, policy_loss: 1.0499, value_loss: 0.6015
2024-07-14 06:32:21,876 [INFO    ] __main__: train step 13751: loss: 1.0835, policy_loss: 1.0499, value_loss: 0.6015
2024-07-14 06:32:22,158 [INFO    ] __main__: train step 13752: loss: 1.0834, policy_loss: 1.0498, value_loss: 0.6014
2024-07-14 06:32:22,454 [INFO    ] __main__: train step 13753: loss: 1.0834, policy_loss: 1.0498, value_loss: 0.6014
2024-07-14 06:32:22,740 [INFO    ] __main__: train step 13754: loss: 1.0834, policy_loss: 1.0498, value_loss: 0.6014
2024-07-14 06:32:23,031 [INFO    ] __main__: train step 13755: loss: 1.0834, policy_loss: 1.0498, value_loss: 0.6013
2024-07-14 06:32:23,332 [INFO    ] __main__: train step 13756: loss: 1.0834, policy_loss: 1.0497, value_loss: 0.6013
2024-07-14 06:32:23,632 [INFO    ] __main__: train step 13757: loss: 1.0834, policy_loss: 1.0497, value_loss: 0.6013
2024-07-14 06:32:23,931 [INFO    ] __main__: train step 13758: loss: 1.0834, policy_loss: 1.0497, value_loss: 0.6013
2024-07-14 06:32:24,227 [INFO    ] __main__: train step 13759: loss: 1.0833, policy_loss: 1.0497, value_loss: 0.6012
2024-07-14 06:32:24,509 [INFO    ] __main__: train step 13760: loss: 1.0833, policy_loss: 1.0496, value_loss: 0.6012
2024-07-14 06:32:24,782 [INFO    ] __main__: train step 13761: loss: 1.0833, policy_loss: 1.0496, value_loss: 0.6012
2024-07-14 06:32:25,074 [INFO    ] __main__: train step 13762: loss: 1.0833, policy_loss: 1.0496, value_loss: 0.6011
2024-07-14 06:32:25,368 [INFO    ] __main__: train step 13763: loss: 1.0833, policy_loss: 1.0496, value_loss: 0.6011
2024-07-14 06:32:25,648 [INFO    ] __main__: train step 13764: loss: 1.0833, policy_loss: 1.0495, value_loss: 0.6011
2024-07-14 06:32:25,934 [INFO    ] __main__: train step 13765: loss: 1.0833, policy_loss: 1.0495, value_loss: 0.6011
2024-07-14 06:32:26,224 [INFO    ] __main__: train step 13766: loss: 1.0833, policy_loss: 1.0495, value_loss: 0.6010
2024-07-14 06:32:27,833 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:32:28,319 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:32:28,389 [INFO    ] __main__: train step 13767: loss: 1.0832, policy_loss: 1.0495, value_loss: 0.6010
2024-07-14 06:32:28,689 [INFO    ] __main__: train step 13768: loss: 1.0832, policy_loss: 1.0494, value_loss: 0.6010
2024-07-14 06:32:28,967 [INFO    ] __main__: train step 13769: loss: 1.0832, policy_loss: 1.0494, value_loss: 0.6009
2024-07-14 06:32:29,258 [INFO    ] __main__: train step 13770: loss: 1.0832, policy_loss: 1.0494, value_loss: 0.6009
2024-07-14 06:32:29,554 [INFO    ] __main__: train step 13771: loss: 1.0832, policy_loss: 1.0494, value_loss: 0.6009
2024-07-14 06:32:29,846 [INFO    ] __main__: train step 13772: loss: 1.0832, policy_loss: 1.0493, value_loss: 0.6009
2024-07-14 06:32:30,132 [INFO    ] __main__: train step 13773: loss: 1.0832, policy_loss: 1.0493, value_loss: 0.6008
2024-07-14 06:32:30,427 [INFO    ] __main__: train step 13774: loss: 1.0832, policy_loss: 1.0493, value_loss: 0.6008
2024-07-14 06:32:30,728 [INFO    ] __main__: train step 13775: loss: 1.0831, policy_loss: 1.0493, value_loss: 0.6008
2024-07-14 06:32:31,014 [INFO    ] __main__: train step 13776: loss: 1.0831, policy_loss: 1.0492, value_loss: 0.6007
2024-07-14 06:32:31,303 [INFO    ] __main__: train step 13777: loss: 1.0831, policy_loss: 1.0492, value_loss: 0.6007
2024-07-14 06:32:31,590 [INFO    ] __main__: train step 13778: loss: 1.0831, policy_loss: 1.0492, value_loss: 0.6007
2024-07-14 06:32:31,876 [INFO    ] __main__: train step 13779: loss: 1.0831, policy_loss: 1.0492, value_loss: 0.6006
2024-07-14 06:32:32,171 [INFO    ] __main__: train step 13780: loss: 1.0831, policy_loss: 1.0491, value_loss: 0.6006
2024-07-14 06:32:32,461 [INFO    ] __main__: train step 13781: loss: 1.0831, policy_loss: 1.0491, value_loss: 0.6006
2024-07-14 06:32:32,745 [INFO    ] __main__: train step 13782: loss: 1.0831, policy_loss: 1.0491, value_loss: 0.6006
2024-07-14 06:32:33,028 [INFO    ] __main__: train step 13783: loss: 1.0830, policy_loss: 1.0491, value_loss: 0.6005
2024-07-14 06:32:34,647 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:32:35,141 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:32:35,217 [INFO    ] __main__: train step 13784: loss: 1.0830, policy_loss: 1.0490, value_loss: 0.6005
2024-07-14 06:32:38,021 [INFO    ] __main__: train step 13785: loss: 1.0830, policy_loss: 1.0490, value_loss: 0.6005
2024-07-14 06:32:38,316 [INFO    ] __main__: train step 13786: loss: 1.0830, policy_loss: 1.0490, value_loss: 0.6004
2024-07-14 06:32:38,615 [INFO    ] __main__: train step 13787: loss: 1.0830, policy_loss: 1.0490, value_loss: 0.6004
2024-07-14 06:32:38,917 [INFO    ] __main__: train step 13788: loss: 1.0830, policy_loss: 1.0490, value_loss: 0.6004
2024-07-14 06:32:39,208 [INFO    ] __main__: train step 13789: loss: 1.0830, policy_loss: 1.0489, value_loss: 0.6004
2024-07-14 06:32:39,496 [INFO    ] __main__: train step 13790: loss: 1.0829, policy_loss: 1.0489, value_loss: 0.6003
2024-07-14 06:32:39,789 [INFO    ] __main__: train step 13791: loss: 1.0829, policy_loss: 1.0489, value_loss: 0.6003
2024-07-14 06:32:40,078 [INFO    ] __main__: train step 13792: loss: 1.0829, policy_loss: 1.0489, value_loss: 0.6003
2024-07-14 06:32:40,377 [INFO    ] __main__: train step 13793: loss: 1.0829, policy_loss: 1.0488, value_loss: 0.6002
2024-07-14 06:32:40,671 [INFO    ] __main__: train step 13794: loss: 1.0829, policy_loss: 1.0488, value_loss: 0.6002
2024-07-14 06:32:40,971 [INFO    ] __main__: train step 13795: loss: 1.0829, policy_loss: 1.0488, value_loss: 0.6002
2024-07-14 06:32:41,265 [INFO    ] __main__: train step 13796: loss: 1.0829, policy_loss: 1.0488, value_loss: 0.6001
2024-07-14 06:32:41,562 [INFO    ] __main__: train step 13797: loss: 1.0829, policy_loss: 1.0487, value_loss: 0.6001
2024-07-14 06:32:41,855 [INFO    ] __main__: train step 13798: loss: 1.0828, policy_loss: 1.0487, value_loss: 0.6001
2024-07-14 06:32:42,151 [INFO    ] __main__: train step 13799: loss: 1.0828, policy_loss: 1.0487, value_loss: 0.6001
2024-07-14 06:32:42,448 [INFO    ] __main__: train step 13800: loss: 1.0828, policy_loss: 1.0487, value_loss: 0.6000
2024-07-14 06:32:44,069 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:32:44,563 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:32:44,631 [INFO    ] __main__: train step 13801: loss: 1.0828, policy_loss: 1.0486, value_loss: 0.6000
2024-07-14 06:32:44,924 [INFO    ] __main__: train step 13802: loss: 1.0828, policy_loss: 1.0486, value_loss: 0.6000
2024-07-14 06:32:45,201 [INFO    ] __main__: train step 13803: loss: 1.0828, policy_loss: 1.0486, value_loss: 0.5999
2024-07-14 06:32:45,485 [INFO    ] __main__: train step 13804: loss: 1.0828, policy_loss: 1.0486, value_loss: 0.5999
2024-07-14 06:32:45,770 [INFO    ] __main__: train step 13805: loss: 1.0828, policy_loss: 1.0485, value_loss: 0.5999
2024-07-14 06:32:46,058 [INFO    ] __main__: train step 13806: loss: 1.0827, policy_loss: 1.0485, value_loss: 0.5999
2024-07-14 06:32:46,350 [INFO    ] __main__: train step 13807: loss: 1.0827, policy_loss: 1.0485, value_loss: 0.5998
2024-07-14 06:32:46,638 [INFO    ] __main__: train step 13808: loss: 1.0827, policy_loss: 1.0485, value_loss: 0.5998
2024-07-14 06:32:46,931 [INFO    ] __main__: train step 13809: loss: 1.0827, policy_loss: 1.0484, value_loss: 0.5998
2024-07-14 06:32:47,228 [INFO    ] __main__: train step 13810: loss: 1.0827, policy_loss: 1.0484, value_loss: 0.5997
2024-07-14 06:32:47,529 [INFO    ] __main__: train step 13811: loss: 1.0827, policy_loss: 1.0484, value_loss: 0.5997
2024-07-14 06:32:47,808 [INFO    ] __main__: train step 13812: loss: 1.0827, policy_loss: 1.0484, value_loss: 0.5997
2024-07-14 06:32:48,107 [INFO    ] __main__: train step 13813: loss: 1.0826, policy_loss: 1.0483, value_loss: 0.5996
2024-07-14 06:32:48,385 [INFO    ] __main__: train step 13814: loss: 1.0826, policy_loss: 1.0483, value_loss: 0.5996
2024-07-14 06:32:48,680 [INFO    ] __main__: train step 13815: loss: 1.0826, policy_loss: 1.0483, value_loss: 0.5996
2024-07-14 06:32:48,969 [INFO    ] __main__: train step 13816: loss: 1.0826, policy_loss: 1.0483, value_loss: 0.5996
2024-07-14 06:32:49,266 [INFO    ] __main__: train step 13817: loss: 1.0826, policy_loss: 1.0482, value_loss: 0.5995
2024-07-14 06:32:50,881 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:32:51,365 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:32:51,434 [INFO    ] __main__: train step 13818: loss: 1.0826, policy_loss: 1.0482, value_loss: 0.5995
2024-07-14 06:32:51,720 [INFO    ] __main__: train step 13819: loss: 1.0826, policy_loss: 1.0482, value_loss: 0.5995
2024-07-14 06:32:51,999 [INFO    ] __main__: train step 13820: loss: 1.0825, policy_loss: 1.0481, value_loss: 0.5994
2024-07-14 06:32:52,282 [INFO    ] __main__: train step 13821: loss: 1.0825, policy_loss: 1.0481, value_loss: 0.5994
2024-07-14 06:32:52,572 [INFO    ] __main__: train step 13822: loss: 1.0825, policy_loss: 1.0481, value_loss: 0.5994
2024-07-14 06:32:52,867 [INFO    ] __main__: train step 13823: loss: 1.0825, policy_loss: 1.0481, value_loss: 0.5994
2024-07-14 06:32:53,153 [INFO    ] __main__: train step 13824: loss: 1.0825, policy_loss: 1.0480, value_loss: 0.5993
2024-07-14 06:32:53,455 [INFO    ] __main__: train step 13825: loss: 1.0825, policy_loss: 1.0480, value_loss: 0.5993
2024-07-14 06:32:53,738 [INFO    ] __main__: train step 13826: loss: 1.0825, policy_loss: 1.0480, value_loss: 0.5993
2024-07-14 06:32:54,041 [INFO    ] __main__: train step 13827: loss: 1.0825, policy_loss: 1.0480, value_loss: 0.5992
2024-07-14 06:32:54,331 [INFO    ] __main__: train step 13828: loss: 1.0824, policy_loss: 1.0479, value_loss: 0.5992
2024-07-14 06:32:54,614 [INFO    ] __main__: train step 13829: loss: 1.0824, policy_loss: 1.0479, value_loss: 0.5992
2024-07-14 06:32:54,904 [INFO    ] __main__: train step 13830: loss: 1.0824, policy_loss: 1.0479, value_loss: 0.5992
2024-07-14 06:32:55,189 [INFO    ] __main__: train step 13831: loss: 1.0824, policy_loss: 1.0479, value_loss: 0.5991
2024-07-14 06:32:55,476 [INFO    ] __main__: train step 13832: loss: 1.0824, policy_loss: 1.0478, value_loss: 0.5991
2024-07-14 06:32:55,763 [INFO    ] __main__: train step 13833: loss: 1.0824, policy_loss: 1.0478, value_loss: 0.5991
2024-07-14 06:32:56,058 [INFO    ] __main__: train step 13834: loss: 1.0824, policy_loss: 1.0478, value_loss: 0.5990
2024-07-14 06:32:57,661 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:32:58,141 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:32:58,213 [INFO    ] __main__: train step 13835: loss: 1.0823, policy_loss: 1.0478, value_loss: 0.5990
2024-07-14 06:32:58,501 [INFO    ] __main__: train step 13836: loss: 1.0823, policy_loss: 1.0477, value_loss: 0.5990
2024-07-14 06:32:58,805 [INFO    ] __main__: train step 13837: loss: 1.0823, policy_loss: 1.0477, value_loss: 0.5990
2024-07-14 06:32:59,100 [INFO    ] __main__: train step 13838: loss: 1.0823, policy_loss: 1.0477, value_loss: 0.5989
2024-07-14 06:32:59,378 [INFO    ] __main__: train step 13839: loss: 1.0823, policy_loss: 1.0477, value_loss: 0.5989
2024-07-14 06:32:59,672 [INFO    ] __main__: train step 13840: loss: 1.0823, policy_loss: 1.0476, value_loss: 0.5989
2024-07-14 06:32:59,966 [INFO    ] __main__: train step 13841: loss: 1.0823, policy_loss: 1.0476, value_loss: 0.5988
2024-07-14 06:33:00,264 [INFO    ] __main__: train step 13842: loss: 1.0823, policy_loss: 1.0476, value_loss: 0.5988
2024-07-14 06:33:00,566 [INFO    ] __main__: train step 13843: loss: 1.0822, policy_loss: 1.0476, value_loss: 0.5988
2024-07-14 06:33:00,862 [INFO    ] __main__: train step 13844: loss: 1.0822, policy_loss: 1.0475, value_loss: 0.5987
2024-07-14 06:33:01,152 [INFO    ] __main__: train step 13845: loss: 1.0822, policy_loss: 1.0475, value_loss: 0.5987
2024-07-14 06:33:01,440 [INFO    ] __main__: train step 13846: loss: 1.0822, policy_loss: 1.0475, value_loss: 0.5987
2024-07-14 06:33:01,722 [INFO    ] __main__: train step 13847: loss: 1.0822, policy_loss: 1.0475, value_loss: 0.5987
2024-07-14 06:33:02,011 [INFO    ] __main__: train step 13848: loss: 1.0822, policy_loss: 1.0474, value_loss: 0.5986
2024-07-14 06:33:02,295 [INFO    ] __main__: train step 13849: loss: 1.0821, policy_loss: 1.0474, value_loss: 0.5986
2024-07-14 06:33:02,581 [INFO    ] __main__: train step 13850: loss: 1.0821, policy_loss: 1.0474, value_loss: 0.5986
2024-07-14 06:33:02,871 [INFO    ] __main__: train step 13851: loss: 1.0821, policy_loss: 1.0474, value_loss: 0.5985
2024-07-14 06:33:04,484 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:33:04,972 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:33:05,040 [INFO    ] __main__: train step 13852: loss: 1.0821, policy_loss: 1.0473, value_loss: 0.5985
2024-07-14 06:33:05,321 [INFO    ] __main__: train step 13853: loss: 1.0821, policy_loss: 1.0473, value_loss: 0.5985
2024-07-14 06:33:05,611 [INFO    ] __main__: train step 13854: loss: 1.0821, policy_loss: 1.0473, value_loss: 0.5985
2024-07-14 06:33:05,910 [INFO    ] __main__: train step 13855: loss: 1.0821, policy_loss: 1.0473, value_loss: 0.5984
2024-07-14 06:33:06,191 [INFO    ] __main__: train step 13856: loss: 1.0820, policy_loss: 1.0472, value_loss: 0.5984
2024-07-14 06:33:06,490 [INFO    ] __main__: train step 13857: loss: 1.0820, policy_loss: 1.0472, value_loss: 0.5984
2024-07-14 06:33:06,777 [INFO    ] __main__: train step 13858: loss: 1.0820, policy_loss: 1.0472, value_loss: 0.5983
2024-07-14 06:33:07,067 [INFO    ] __main__: train step 13859: loss: 1.0820, policy_loss: 1.0472, value_loss: 0.5983
2024-07-14 06:33:07,363 [INFO    ] __main__: train step 13860: loss: 1.0820, policy_loss: 1.0471, value_loss: 0.5983
2024-07-14 06:33:07,659 [INFO    ] __main__: train step 13861: loss: 1.0820, policy_loss: 1.0471, value_loss: 0.5983
2024-07-14 06:33:07,948 [INFO    ] __main__: train step 13862: loss: 1.0820, policy_loss: 1.0471, value_loss: 0.5982
2024-07-14 06:33:08,243 [INFO    ] __main__: train step 13863: loss: 1.0820, policy_loss: 1.0471, value_loss: 0.5982
2024-07-14 06:33:08,539 [INFO    ] __main__: train step 13864: loss: 1.0819, policy_loss: 1.0470, value_loss: 0.5982
2024-07-14 06:33:08,838 [INFO    ] __main__: train step 13865: loss: 1.0819, policy_loss: 1.0470, value_loss: 0.5981
2024-07-14 06:33:09,146 [INFO    ] __main__: train step 13866: loss: 1.0819, policy_loss: 1.0470, value_loss: 0.5981
2024-07-14 06:33:09,444 [INFO    ] __main__: train step 13867: loss: 1.0819, policy_loss: 1.0470, value_loss: 0.5981
2024-07-14 06:33:09,737 [INFO    ] __main__: train step 13868: loss: 1.0819, policy_loss: 1.0469, value_loss: 0.5981
2024-07-14 06:33:11,362 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:33:11,854 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:33:11,923 [INFO    ] __main__: train step 13869: loss: 1.0819, policy_loss: 1.0469, value_loss: 0.5980
2024-07-14 06:33:12,221 [INFO    ] __main__: train step 13870: loss: 1.0819, policy_loss: 1.0469, value_loss: 0.5980
2024-07-14 06:33:12,514 [INFO    ] __main__: train step 13871: loss: 1.0818, policy_loss: 1.0469, value_loss: 0.5980
2024-07-14 06:33:12,802 [INFO    ] __main__: train step 13872: loss: 1.0818, policy_loss: 1.0468, value_loss: 0.5979
2024-07-14 06:33:15,728 [INFO    ] __main__: train step 13873: loss: 1.0818, policy_loss: 1.0468, value_loss: 0.5979
2024-07-14 06:33:16,018 [INFO    ] __main__: train step 13874: loss: 1.0818, policy_loss: 1.0468, value_loss: 0.5979
2024-07-14 06:33:16,310 [INFO    ] __main__: train step 13875: loss: 1.0818, policy_loss: 1.0467, value_loss: 0.5978
2024-07-14 06:33:16,606 [INFO    ] __main__: train step 13876: loss: 1.0818, policy_loss: 1.0467, value_loss: 0.5978
2024-07-14 06:33:16,892 [INFO    ] __main__: train step 13877: loss: 1.0818, policy_loss: 1.0467, value_loss: 0.5978
2024-07-14 06:33:17,196 [INFO    ] __main__: train step 13878: loss: 1.0817, policy_loss: 1.0467, value_loss: 0.5978
2024-07-14 06:33:17,494 [INFO    ] __main__: train step 13879: loss: 1.0817, policy_loss: 1.0466, value_loss: 0.5977
2024-07-14 06:33:17,783 [INFO    ] __main__: train step 13880: loss: 1.0817, policy_loss: 1.0466, value_loss: 0.5977
2024-07-14 06:33:18,072 [INFO    ] __main__: train step 13881: loss: 1.0817, policy_loss: 1.0466, value_loss: 0.5977
2024-07-14 06:33:18,374 [INFO    ] __main__: train step 13882: loss: 1.0817, policy_loss: 1.0466, value_loss: 0.5976
2024-07-14 06:33:18,671 [INFO    ] __main__: train step 13883: loss: 1.0817, policy_loss: 1.0465, value_loss: 0.5976
2024-07-14 06:33:18,961 [INFO    ] __main__: train step 13884: loss: 1.0817, policy_loss: 1.0465, value_loss: 0.5976
2024-07-14 06:33:19,262 [INFO    ] __main__: train step 13885: loss: 1.0816, policy_loss: 1.0465, value_loss: 0.5976
2024-07-14 06:33:20,884 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:33:21,378 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:33:21,451 [INFO    ] __main__: train step 13886: loss: 1.0816, policy_loss: 1.0465, value_loss: 0.5975
2024-07-14 06:33:21,732 [INFO    ] __main__: train step 13887: loss: 1.0816, policy_loss: 1.0464, value_loss: 0.5975
2024-07-14 06:33:22,018 [INFO    ] __main__: train step 13888: loss: 1.0816, policy_loss: 1.0464, value_loss: 0.5975
2024-07-14 06:33:22,310 [INFO    ] __main__: train step 13889: loss: 1.0816, policy_loss: 1.0464, value_loss: 0.5974
2024-07-14 06:33:22,598 [INFO    ] __main__: train step 13890: loss: 1.0816, policy_loss: 1.0464, value_loss: 0.5974
2024-07-14 06:33:22,906 [INFO    ] __main__: train step 13891: loss: 1.0816, policy_loss: 1.0463, value_loss: 0.5974
2024-07-14 06:33:23,203 [INFO    ] __main__: train step 13892: loss: 1.0815, policy_loss: 1.0463, value_loss: 0.5974
2024-07-14 06:33:23,495 [INFO    ] __main__: train step 13893: loss: 1.0815, policy_loss: 1.0463, value_loss: 0.5973
2024-07-14 06:33:23,791 [INFO    ] __main__: train step 13894: loss: 1.0815, policy_loss: 1.0463, value_loss: 0.5973
2024-07-14 06:33:24,090 [INFO    ] __main__: train step 13895: loss: 1.0815, policy_loss: 1.0462, value_loss: 0.5973
2024-07-14 06:33:24,375 [INFO    ] __main__: train step 13896: loss: 1.0815, policy_loss: 1.0462, value_loss: 0.5972
2024-07-14 06:33:24,666 [INFO    ] __main__: train step 13897: loss: 1.0815, policy_loss: 1.0462, value_loss: 0.5972
2024-07-14 06:33:24,954 [INFO    ] __main__: train step 13898: loss: 1.0815, policy_loss: 1.0462, value_loss: 0.5972
2024-07-14 06:33:25,249 [INFO    ] __main__: train step 13899: loss: 1.0815, policy_loss: 1.0461, value_loss: 0.5972
2024-07-14 06:33:25,543 [INFO    ] __main__: train step 13900: loss: 1.0814, policy_loss: 1.0461, value_loss: 0.5971
2024-07-14 06:33:25,831 [INFO    ] __main__: train step 13901: loss: 1.0814, policy_loss: 1.0461, value_loss: 0.5971
2024-07-14 06:33:26,126 [INFO    ] __main__: train step 13902: loss: 1.0814, policy_loss: 1.0461, value_loss: 0.5971
2024-07-14 06:33:27,763 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:33:28,253 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:33:28,324 [INFO    ] __main__: train step 13903: loss: 1.0814, policy_loss: 1.0460, value_loss: 0.5970
2024-07-14 06:33:28,595 [INFO    ] __main__: train step 13904: loss: 1.0814, policy_loss: 1.0460, value_loss: 0.5970
2024-07-14 06:33:28,878 [INFO    ] __main__: train step 13905: loss: 1.0814, policy_loss: 1.0460, value_loss: 0.5970
2024-07-14 06:33:29,163 [INFO    ] __main__: train step 13906: loss: 1.0814, policy_loss: 1.0459, value_loss: 0.5970
2024-07-14 06:33:29,440 [INFO    ] __main__: train step 13907: loss: 1.0813, policy_loss: 1.0459, value_loss: 0.5969
2024-07-14 06:33:29,731 [INFO    ] __main__: train step 13908: loss: 1.0813, policy_loss: 1.0459, value_loss: 0.5969
2024-07-14 06:33:30,034 [INFO    ] __main__: train step 13909: loss: 1.0813, policy_loss: 1.0459, value_loss: 0.5969
2024-07-14 06:33:30,332 [INFO    ] __main__: train step 13910: loss: 1.0813, policy_loss: 1.0458, value_loss: 0.5968
2024-07-14 06:33:30,630 [INFO    ] __main__: train step 13911: loss: 1.0813, policy_loss: 1.0458, value_loss: 0.5968
2024-07-14 06:33:30,922 [INFO    ] __main__: train step 13912: loss: 1.0813, policy_loss: 1.0458, value_loss: 0.5968
2024-07-14 06:33:31,200 [INFO    ] __main__: train step 13913: loss: 1.0812, policy_loss: 1.0458, value_loss: 0.5968
2024-07-14 06:33:31,475 [INFO    ] __main__: train step 13914: loss: 1.0812, policy_loss: 1.0457, value_loss: 0.5967
2024-07-14 06:33:31,772 [INFO    ] __main__: train step 13915: loss: 1.0812, policy_loss: 1.0457, value_loss: 0.5967
2024-07-14 06:33:32,063 [INFO    ] __main__: train step 13916: loss: 1.0812, policy_loss: 1.0457, value_loss: 0.5967
2024-07-14 06:33:32,350 [INFO    ] __main__: train step 13917: loss: 1.0812, policy_loss: 1.0457, value_loss: 0.5966
2024-07-14 06:33:32,645 [INFO    ] __main__: train step 13918: loss: 1.0812, policy_loss: 1.0456, value_loss: 0.5966
2024-07-14 06:33:32,938 [INFO    ] __main__: train step 13919: loss: 1.0812, policy_loss: 1.0456, value_loss: 0.5966
2024-07-14 06:33:34,551 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:33:35,042 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:33:35,112 [INFO    ] __main__: train step 13920: loss: 1.0811, policy_loss: 1.0456, value_loss: 0.5966
2024-07-14 06:33:35,413 [INFO    ] __main__: train step 13921: loss: 1.0811, policy_loss: 1.0456, value_loss: 0.5965
2024-07-14 06:33:35,708 [INFO    ] __main__: train step 13922: loss: 1.0811, policy_loss: 1.0455, value_loss: 0.5965
2024-07-14 06:33:35,995 [INFO    ] __main__: train step 13923: loss: 1.0811, policy_loss: 1.0455, value_loss: 0.5965
2024-07-14 06:33:36,288 [INFO    ] __main__: train step 13924: loss: 1.0811, policy_loss: 1.0455, value_loss: 0.5964
2024-07-14 06:33:36,573 [INFO    ] __main__: train step 13925: loss: 1.0811, policy_loss: 1.0455, value_loss: 0.5964
2024-07-14 06:33:36,859 [INFO    ] __main__: train step 13926: loss: 1.0811, policy_loss: 1.0454, value_loss: 0.5964
2024-07-14 06:33:37,151 [INFO    ] __main__: train step 13927: loss: 1.0810, policy_loss: 1.0454, value_loss: 0.5963
2024-07-14 06:33:37,438 [INFO    ] __main__: train step 13928: loss: 1.0810, policy_loss: 1.0454, value_loss: 0.5963
2024-07-14 06:33:37,722 [INFO    ] __main__: train step 13929: loss: 1.0810, policy_loss: 1.0453, value_loss: 0.5963
2024-07-14 06:33:38,018 [INFO    ] __main__: train step 13930: loss: 1.0810, policy_loss: 1.0453, value_loss: 0.5963
2024-07-14 06:33:38,312 [INFO    ] __main__: train step 13931: loss: 1.0810, policy_loss: 1.0453, value_loss: 0.5962
2024-07-14 06:33:38,614 [INFO    ] __main__: train step 13932: loss: 1.0810, policy_loss: 1.0453, value_loss: 0.5962
2024-07-14 06:33:38,899 [INFO    ] __main__: train step 13933: loss: 1.0810, policy_loss: 1.0452, value_loss: 0.5962
2024-07-14 06:33:39,174 [INFO    ] __main__: train step 13934: loss: 1.0809, policy_loss: 1.0452, value_loss: 0.5961
2024-07-14 06:33:39,464 [INFO    ] __main__: train step 13935: loss: 1.0809, policy_loss: 1.0452, value_loss: 0.5961
2024-07-14 06:33:39,756 [INFO    ] __main__: train step 13936: loss: 1.0809, policy_loss: 1.0452, value_loss: 0.5961
2024-07-14 06:33:41,364 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:33:41,856 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:33:41,926 [INFO    ] __main__: train step 13937: loss: 1.0809, policy_loss: 1.0451, value_loss: 0.5961
2024-07-14 06:33:42,221 [INFO    ] __main__: train step 13938: loss: 1.0809, policy_loss: 1.0451, value_loss: 0.5960
2024-07-14 06:33:42,513 [INFO    ] __main__: train step 13939: loss: 1.0809, policy_loss: 1.0451, value_loss: 0.5960
2024-07-14 06:33:42,813 [INFO    ] __main__: train step 13940: loss: 1.0809, policy_loss: 1.0451, value_loss: 0.5960
2024-07-14 06:33:43,113 [INFO    ] __main__: train step 13941: loss: 1.0808, policy_loss: 1.0450, value_loss: 0.5959
2024-07-14 06:33:43,412 [INFO    ] __main__: train step 13942: loss: 1.0808, policy_loss: 1.0450, value_loss: 0.5959
2024-07-14 06:33:43,704 [INFO    ] __main__: train step 13943: loss: 1.0808, policy_loss: 1.0450, value_loss: 0.5959
2024-07-14 06:33:44,000 [INFO    ] __main__: train step 13944: loss: 1.0808, policy_loss: 1.0450, value_loss: 0.5959
2024-07-14 06:33:44,298 [INFO    ] __main__: train step 13945: loss: 1.0808, policy_loss: 1.0449, value_loss: 0.5958
2024-07-14 06:33:44,581 [INFO    ] __main__: train step 13946: loss: 1.0808, policy_loss: 1.0449, value_loss: 0.5958
2024-07-14 06:33:44,858 [INFO    ] __main__: train step 13947: loss: 1.0807, policy_loss: 1.0449, value_loss: 0.5958
2024-07-14 06:33:45,152 [INFO    ] __main__: train step 13948: loss: 1.0807, policy_loss: 1.0448, value_loss: 0.5957
2024-07-14 06:33:45,452 [INFO    ] __main__: train step 13949: loss: 1.0807, policy_loss: 1.0448, value_loss: 0.5957
2024-07-14 06:33:45,747 [INFO    ] __main__: train step 13950: loss: 1.0807, policy_loss: 1.0448, value_loss: 0.5957
2024-07-14 06:33:46,045 [INFO    ] __main__: train step 13951: loss: 1.0807, policy_loss: 1.0448, value_loss: 0.5957
2024-07-14 06:33:46,338 [INFO    ] __main__: train step 13952: loss: 1.0807, policy_loss: 1.0447, value_loss: 0.5956
2024-07-14 06:33:46,634 [INFO    ] __main__: train step 13953: loss: 1.0807, policy_loss: 1.0447, value_loss: 0.5956
2024-07-14 06:33:48,248 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:33:48,738 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:33:48,811 [INFO    ] __main__: train step 13954: loss: 1.0806, policy_loss: 1.0447, value_loss: 0.5956
2024-07-14 06:33:49,114 [INFO    ] __main__: train step 13955: loss: 1.0806, policy_loss: 1.0447, value_loss: 0.5955
2024-07-14 06:33:49,405 [INFO    ] __main__: train step 13956: loss: 1.0806, policy_loss: 1.0446, value_loss: 0.5955
2024-07-14 06:33:49,705 [INFO    ] __main__: train step 13957: loss: 1.0806, policy_loss: 1.0446, value_loss: 0.5955
2024-07-14 06:33:49,999 [INFO    ] __main__: train step 13958: loss: 1.0806, policy_loss: 1.0446, value_loss: 0.5955
2024-07-14 06:33:50,301 [INFO    ] __main__: train step 13959: loss: 1.0806, policy_loss: 1.0446, value_loss: 0.5954
2024-07-14 06:33:53,217 [INFO    ] __main__: train step 13960: loss: 1.0806, policy_loss: 1.0445, value_loss: 0.5954
2024-07-14 06:33:53,521 [INFO    ] __main__: train step 13961: loss: 1.0805, policy_loss: 1.0445, value_loss: 0.5954
2024-07-14 06:33:53,814 [INFO    ] __main__: train step 13962: loss: 1.0805, policy_loss: 1.0445, value_loss: 0.5953
2024-07-14 06:33:54,127 [INFO    ] __main__: train step 13963: loss: 1.0805, policy_loss: 1.0444, value_loss: 0.5953
2024-07-14 06:33:54,431 [INFO    ] __main__: train step 13964: loss: 1.0805, policy_loss: 1.0444, value_loss: 0.5953
2024-07-14 06:33:54,737 [INFO    ] __main__: train step 13965: loss: 1.0805, policy_loss: 1.0444, value_loss: 0.5953
2024-07-14 06:33:55,036 [INFO    ] __main__: train step 13966: loss: 1.0805, policy_loss: 1.0444, value_loss: 0.5952
2024-07-14 06:33:55,327 [INFO    ] __main__: train step 13967: loss: 1.0805, policy_loss: 1.0443, value_loss: 0.5952
2024-07-14 06:33:55,622 [INFO    ] __main__: train step 13968: loss: 1.0804, policy_loss: 1.0443, value_loss: 0.5952
2024-07-14 06:33:55,921 [INFO    ] __main__: train step 13969: loss: 1.0804, policy_loss: 1.0443, value_loss: 0.5952
2024-07-14 06:33:56,226 [INFO    ] __main__: train step 13970: loss: 1.0804, policy_loss: 1.0443, value_loss: 0.5951
2024-07-14 06:33:57,852 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:33:58,338 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:33:58,407 [INFO    ] __main__: train step 13971: loss: 1.0804, policy_loss: 1.0442, value_loss: 0.5951
2024-07-14 06:33:58,705 [INFO    ] __main__: train step 13972: loss: 1.0804, policy_loss: 1.0442, value_loss: 0.5951
2024-07-14 06:33:59,008 [INFO    ] __main__: train step 13973: loss: 1.0804, policy_loss: 1.0442, value_loss: 0.5950
2024-07-14 06:33:59,309 [INFO    ] __main__: train step 13974: loss: 1.0803, policy_loss: 1.0442, value_loss: 0.5950
2024-07-14 06:33:59,603 [INFO    ] __main__: train step 13975: loss: 1.0803, policy_loss: 1.0441, value_loss: 0.5950
2024-07-14 06:33:59,901 [INFO    ] __main__: train step 13976: loss: 1.0803, policy_loss: 1.0441, value_loss: 0.5950
2024-07-14 06:34:00,207 [INFO    ] __main__: train step 13977: loss: 1.0803, policy_loss: 1.0441, value_loss: 0.5949
2024-07-14 06:34:00,502 [INFO    ] __main__: train step 13978: loss: 1.0803, policy_loss: 1.0440, value_loss: 0.5949
2024-07-14 06:34:00,796 [INFO    ] __main__: train step 13979: loss: 1.0803, policy_loss: 1.0440, value_loss: 0.5949
2024-07-14 06:34:01,068 [INFO    ] __main__: train step 13980: loss: 1.0803, policy_loss: 1.0440, value_loss: 0.5948
2024-07-14 06:34:01,360 [INFO    ] __main__: train step 13981: loss: 1.0802, policy_loss: 1.0440, value_loss: 0.5948
2024-07-14 06:34:01,658 [INFO    ] __main__: train step 13982: loss: 1.0802, policy_loss: 1.0439, value_loss: 0.5948
2024-07-14 06:34:01,930 [INFO    ] __main__: train step 13983: loss: 1.0802, policy_loss: 1.0439, value_loss: 0.5947
2024-07-14 06:34:02,236 [INFO    ] __main__: train step 13984: loss: 1.0802, policy_loss: 1.0439, value_loss: 0.5947
2024-07-14 06:34:02,532 [INFO    ] __main__: train step 13985: loss: 1.0802, policy_loss: 1.0439, value_loss: 0.5947
2024-07-14 06:34:02,842 [INFO    ] __main__: train step 13986: loss: 1.0802, policy_loss: 1.0438, value_loss: 0.5947
2024-07-14 06:34:03,134 [INFO    ] __main__: train step 13987: loss: 1.0801, policy_loss: 1.0438, value_loss: 0.5946
2024-07-14 06:34:04,728 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:34:05,221 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:34:05,296 [INFO    ] __main__: train step 13988: loss: 1.0801, policy_loss: 1.0438, value_loss: 0.5946
2024-07-14 06:34:05,608 [INFO    ] __main__: train step 13989: loss: 1.0801, policy_loss: 1.0438, value_loss: 0.5946
2024-07-14 06:34:05,900 [INFO    ] __main__: train step 13990: loss: 1.0801, policy_loss: 1.0437, value_loss: 0.5945
2024-07-14 06:34:06,197 [INFO    ] __main__: train step 13991: loss: 1.0801, policy_loss: 1.0437, value_loss: 0.5945
2024-07-14 06:34:06,503 [INFO    ] __main__: train step 13992: loss: 1.0801, policy_loss: 1.0437, value_loss: 0.5945
2024-07-14 06:34:06,809 [INFO    ] __main__: train step 13993: loss: 1.0800, policy_loss: 1.0436, value_loss: 0.5945
2024-07-14 06:34:07,089 [INFO    ] __main__: train step 13994: loss: 1.0800, policy_loss: 1.0436, value_loss: 0.5944
2024-07-14 06:34:07,370 [INFO    ] __main__: train step 13995: loss: 1.0800, policy_loss: 1.0436, value_loss: 0.5944
2024-07-14 06:34:07,661 [INFO    ] __main__: train step 13996: loss: 1.0800, policy_loss: 1.0436, value_loss: 0.5944
2024-07-14 06:34:07,938 [INFO    ] __main__: train step 13997: loss: 1.0800, policy_loss: 1.0435, value_loss: 0.5943
2024-07-14 06:34:08,211 [INFO    ] __main__: train step 13998: loss: 1.0800, policy_loss: 1.0435, value_loss: 0.5943
2024-07-14 06:34:08,499 [INFO    ] __main__: train step 13999: loss: 1.0800, policy_loss: 1.0435, value_loss: 0.5943
2024-07-14 06:34:08,791 [INFO    ] __main__: train step 14000: loss: 1.0799, policy_loss: 1.0435, value_loss: 0.5943
2024-07-14 06:34:08,949 [INFO    ] __main__: restored step 13000 for evaluation
2024-07-14 06:34:14,192 [INFO    ] __main__: test network ELO difference from baseline network: +170 (+8/-8) ELO from 32000 self-played games
2024-07-14 06:34:14,194 [INFO    ] __main__: game outcomes: W: 21966, D: 492, L: 9542
2024-07-14 06:34:14,197 [INFO    ] __main__: validation_elo_delta: 170, validation_elo: 2588
2024-07-14 06:34:14,959 [INFO    ] __main__: train step 14001: loss: 1.0799, policy_loss: 1.0434, value_loss: 0.5942
2024-07-14 06:34:15,263 [INFO    ] __main__: train step 14002: loss: 1.0799, policy_loss: 1.0434, value_loss: 0.5942
2024-07-14 06:34:15,562 [INFO    ] __main__: train step 14003: loss: 1.0799, policy_loss: 1.0434, value_loss: 0.5942
2024-07-14 06:34:15,850 [INFO    ] __main__: train step 14004: loss: 1.0799, policy_loss: 1.0434, value_loss: 0.5941
2024-07-14 06:34:17,488 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:34:17,988 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:34:18,083 [INFO    ] __main__: train step 14005: loss: 1.0799, policy_loss: 1.0433, value_loss: 0.5941
2024-07-14 06:34:18,391 [INFO    ] __main__: train step 14006: loss: 1.0798, policy_loss: 1.0433, value_loss: 0.5941
2024-07-14 06:34:18,689 [INFO    ] __main__: train step 14007: loss: 1.0798, policy_loss: 1.0433, value_loss: 0.5941
2024-07-14 06:34:18,981 [INFO    ] __main__: train step 14008: loss: 1.0798, policy_loss: 1.0432, value_loss: 0.5940
2024-07-14 06:34:19,267 [INFO    ] __main__: train step 14009: loss: 1.0798, policy_loss: 1.0432, value_loss: 0.5940
2024-07-14 06:34:19,558 [INFO    ] __main__: train step 14010: loss: 1.0798, policy_loss: 1.0432, value_loss: 0.5940
2024-07-14 06:34:19,850 [INFO    ] __main__: train step 14011: loss: 1.0798, policy_loss: 1.0432, value_loss: 0.5939
2024-07-14 06:34:20,143 [INFO    ] __main__: train step 14012: loss: 1.0797, policy_loss: 1.0431, value_loss: 0.5939
2024-07-14 06:34:20,449 [INFO    ] __main__: train step 14013: loss: 1.0797, policy_loss: 1.0431, value_loss: 0.5939
2024-07-14 06:34:20,748 [INFO    ] __main__: train step 14014: loss: 1.0797, policy_loss: 1.0431, value_loss: 0.5939
2024-07-14 06:34:21,032 [INFO    ] __main__: train step 14015: loss: 1.0797, policy_loss: 1.0431, value_loss: 0.5938
2024-07-14 06:34:21,312 [INFO    ] __main__: train step 14016: loss: 1.0797, policy_loss: 1.0430, value_loss: 0.5938
2024-07-14 06:34:21,599 [INFO    ] __main__: train step 14017: loss: 1.0797, policy_loss: 1.0430, value_loss: 0.5938
2024-07-14 06:34:21,901 [INFO    ] __main__: train step 14018: loss: 1.0797, policy_loss: 1.0430, value_loss: 0.5937
2024-07-14 06:34:22,184 [INFO    ] __main__: train step 14019: loss: 1.0796, policy_loss: 1.0429, value_loss: 0.5937
2024-07-14 06:34:22,463 [INFO    ] __main__: train step 14020: loss: 1.0796, policy_loss: 1.0429, value_loss: 0.5937
2024-07-14 06:34:22,769 [INFO    ] __main__: train step 14021: loss: 1.0796, policy_loss: 1.0429, value_loss: 0.5937
2024-07-14 06:34:24,377 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:34:24,876 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:34:24,948 [INFO    ] __main__: train step 14022: loss: 1.0796, policy_loss: 1.0429, value_loss: 0.5936
2024-07-14 06:34:25,217 [INFO    ] __main__: train step 14023: loss: 1.0796, policy_loss: 1.0428, value_loss: 0.5936
2024-07-14 06:34:25,503 [INFO    ] __main__: train step 14024: loss: 1.0796, policy_loss: 1.0428, value_loss: 0.5936
2024-07-14 06:34:25,794 [INFO    ] __main__: train step 14025: loss: 1.0795, policy_loss: 1.0428, value_loss: 0.5935
2024-07-14 06:34:26,086 [INFO    ] __main__: train step 14026: loss: 1.0795, policy_loss: 1.0428, value_loss: 0.5935
2024-07-14 06:34:26,378 [INFO    ] __main__: train step 14027: loss: 1.0795, policy_loss: 1.0427, value_loss: 0.5935
2024-07-14 06:34:26,658 [INFO    ] __main__: train step 14028: loss: 1.0795, policy_loss: 1.0427, value_loss: 0.5935
2024-07-14 06:34:26,946 [INFO    ] __main__: train step 14029: loss: 1.0795, policy_loss: 1.0427, value_loss: 0.5934
2024-07-14 06:34:27,232 [INFO    ] __main__: train step 14030: loss: 1.0795, policy_loss: 1.0426, value_loss: 0.5934
2024-07-14 06:34:27,525 [INFO    ] __main__: train step 14031: loss: 1.0794, policy_loss: 1.0426, value_loss: 0.5934
2024-07-14 06:34:27,820 [INFO    ] __main__: train step 14032: loss: 1.0794, policy_loss: 1.0426, value_loss: 0.5933
2024-07-14 06:34:28,114 [INFO    ] __main__: train step 14033: loss: 1.0794, policy_loss: 1.0426, value_loss: 0.5933
2024-07-14 06:34:28,394 [INFO    ] __main__: train step 14034: loss: 1.0794, policy_loss: 1.0425, value_loss: 0.5933
2024-07-14 06:34:28,701 [INFO    ] __main__: train step 14035: loss: 1.0794, policy_loss: 1.0425, value_loss: 0.5933
2024-07-14 06:34:28,977 [INFO    ] __main__: train step 14036: loss: 1.0794, policy_loss: 1.0425, value_loss: 0.5932
2024-07-14 06:34:29,252 [INFO    ] __main__: train step 14037: loss: 1.0793, policy_loss: 1.0425, value_loss: 0.5932
2024-07-14 06:34:29,528 [INFO    ] __main__: train step 14038: loss: 1.0793, policy_loss: 1.0424, value_loss: 0.5932
2024-07-14 06:34:31,131 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:34:31,611 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:34:31,684 [INFO    ] __main__: train step 14039: loss: 1.0793, policy_loss: 1.0424, value_loss: 0.5931
2024-07-14 06:34:31,977 [INFO    ] __main__: train step 14040: loss: 1.0793, policy_loss: 1.0424, value_loss: 0.5931
2024-07-14 06:34:32,266 [INFO    ] __main__: train step 14041: loss: 1.0793, policy_loss: 1.0424, value_loss: 0.5931
2024-07-14 06:34:32,548 [INFO    ] __main__: train step 14042: loss: 1.0793, policy_loss: 1.0423, value_loss: 0.5931
2024-07-14 06:34:32,849 [INFO    ] __main__: train step 14043: loss: 1.0792, policy_loss: 1.0423, value_loss: 0.5930
2024-07-14 06:34:33,146 [INFO    ] __main__: train step 14044: loss: 1.0792, policy_loss: 1.0423, value_loss: 0.5930
2024-07-14 06:34:33,436 [INFO    ] __main__: train step 14045: loss: 1.0792, policy_loss: 1.0422, value_loss: 0.5930
2024-07-14 06:34:33,734 [INFO    ] __main__: train step 14046: loss: 1.0792, policy_loss: 1.0422, value_loss: 0.5929
2024-07-14 06:34:34,008 [INFO    ] __main__: train step 14047: loss: 1.0792, policy_loss: 1.0422, value_loss: 0.5929
2024-07-14 06:34:36,144 [INFO    ] __main__: train step 14048: loss: 1.0792, policy_loss: 1.0422, value_loss: 0.5929
2024-07-14 06:34:36,422 [INFO    ] __main__: train step 14049: loss: 1.0791, policy_loss: 1.0421, value_loss: 0.5929
2024-07-14 06:34:36,710 [INFO    ] __main__: train step 14050: loss: 1.0791, policy_loss: 1.0421, value_loss: 0.5928
2024-07-14 06:34:37,002 [INFO    ] __main__: train step 14051: loss: 1.0791, policy_loss: 1.0421, value_loss: 0.5928
2024-07-14 06:34:37,313 [INFO    ] __main__: train step 14052: loss: 1.0791, policy_loss: 1.0421, value_loss: 0.5928
2024-07-14 06:34:37,605 [INFO    ] __main__: train step 14053: loss: 1.0791, policy_loss: 1.0420, value_loss: 0.5927
2024-07-14 06:34:37,896 [INFO    ] __main__: train step 14054: loss: 1.0791, policy_loss: 1.0420, value_loss: 0.5927
2024-07-14 06:34:38,192 [INFO    ] __main__: train step 14055: loss: 1.0791, policy_loss: 1.0420, value_loss: 0.5927
2024-07-14 06:34:39,798 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:34:40,287 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:34:40,361 [INFO    ] __main__: train step 14056: loss: 1.0790, policy_loss: 1.0419, value_loss: 0.5927
2024-07-14 06:34:40,656 [INFO    ] __main__: train step 14057: loss: 1.0790, policy_loss: 1.0419, value_loss: 0.5926
2024-07-14 06:34:40,944 [INFO    ] __main__: train step 14058: loss: 1.0790, policy_loss: 1.0419, value_loss: 0.5926
2024-07-14 06:34:41,233 [INFO    ] __main__: train step 14059: loss: 1.0790, policy_loss: 1.0419, value_loss: 0.5926
2024-07-14 06:34:41,528 [INFO    ] __main__: train step 14060: loss: 1.0790, policy_loss: 1.0418, value_loss: 0.5925
2024-07-14 06:34:41,829 [INFO    ] __main__: train step 14061: loss: 1.0790, policy_loss: 1.0418, value_loss: 0.5925
2024-07-14 06:34:42,132 [INFO    ] __main__: train step 14062: loss: 1.0789, policy_loss: 1.0418, value_loss: 0.5925
2024-07-14 06:34:42,425 [INFO    ] __main__: train step 14063: loss: 1.0789, policy_loss: 1.0418, value_loss: 0.5925
2024-07-14 06:34:42,724 [INFO    ] __main__: train step 14064: loss: 1.0789, policy_loss: 1.0417, value_loss: 0.5924
2024-07-14 06:34:43,020 [INFO    ] __main__: train step 14065: loss: 1.0789, policy_loss: 1.0417, value_loss: 0.5924
2024-07-14 06:34:43,321 [INFO    ] __main__: train step 14066: loss: 1.0789, policy_loss: 1.0417, value_loss: 0.5924
2024-07-14 06:34:43,615 [INFO    ] __main__: train step 14067: loss: 1.0789, policy_loss: 1.0417, value_loss: 0.5923
2024-07-14 06:34:43,928 [INFO    ] __main__: train step 14068: loss: 1.0788, policy_loss: 1.0416, value_loss: 0.5923
2024-07-14 06:34:44,231 [INFO    ] __main__: train step 14069: loss: 1.0788, policy_loss: 1.0416, value_loss: 0.5923
2024-07-14 06:34:44,533 [INFO    ] __main__: train step 14070: loss: 1.0788, policy_loss: 1.0416, value_loss: 0.5923
2024-07-14 06:34:44,831 [INFO    ] __main__: train step 14071: loss: 1.0788, policy_loss: 1.0415, value_loss: 0.5922
2024-07-14 06:34:45,126 [INFO    ] __main__: train step 14072: loss: 1.0788, policy_loss: 1.0415, value_loss: 0.5922
2024-07-14 06:34:46,750 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:34:47,245 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:34:47,312 [INFO    ] __main__: train step 14073: loss: 1.0788, policy_loss: 1.0415, value_loss: 0.5922
2024-07-14 06:34:47,609 [INFO    ] __main__: train step 14074: loss: 1.0787, policy_loss: 1.0415, value_loss: 0.5921
2024-07-14 06:34:47,904 [INFO    ] __main__: train step 14075: loss: 1.0787, policy_loss: 1.0414, value_loss: 0.5921
2024-07-14 06:34:48,189 [INFO    ] __main__: train step 14076: loss: 1.0787, policy_loss: 1.0414, value_loss: 0.5921
2024-07-14 06:34:48,482 [INFO    ] __main__: train step 14077: loss: 1.0787, policy_loss: 1.0414, value_loss: 0.5921
2024-07-14 06:34:48,802 [INFO    ] __main__: train step 14078: loss: 1.0787, policy_loss: 1.0414, value_loss: 0.5920
2024-07-14 06:34:49,098 [INFO    ] __main__: train step 14079: loss: 1.0787, policy_loss: 1.0413, value_loss: 0.5920
2024-07-14 06:34:49,393 [INFO    ] __main__: train step 14080: loss: 1.0787, policy_loss: 1.0413, value_loss: 0.5920
2024-07-14 06:34:49,677 [INFO    ] __main__: train step 14081: loss: 1.0786, policy_loss: 1.0413, value_loss: 0.5919
2024-07-14 06:34:49,971 [INFO    ] __main__: train step 14082: loss: 1.0786, policy_loss: 1.0412, value_loss: 0.5919
2024-07-14 06:34:50,254 [INFO    ] __main__: train step 14083: loss: 1.0786, policy_loss: 1.0412, value_loss: 0.5919
2024-07-14 06:34:50,536 [INFO    ] __main__: train step 14084: loss: 1.0786, policy_loss: 1.0412, value_loss: 0.5919
2024-07-14 06:34:50,820 [INFO    ] __main__: train step 14085: loss: 1.0786, policy_loss: 1.0412, value_loss: 0.5918
2024-07-14 06:34:51,120 [INFO    ] __main__: train step 14086: loss: 1.0786, policy_loss: 1.0411, value_loss: 0.5918
2024-07-14 06:34:51,413 [INFO    ] __main__: train step 14087: loss: 1.0785, policy_loss: 1.0411, value_loss: 0.5918
2024-07-14 06:34:51,710 [INFO    ] __main__: train step 14088: loss: 1.0785, policy_loss: 1.0411, value_loss: 0.5917
2024-07-14 06:34:51,991 [INFO    ] __main__: train step 14089: loss: 1.0785, policy_loss: 1.0411, value_loss: 0.5917
2024-07-14 06:34:53,602 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:34:54,105 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:34:54,176 [INFO    ] __main__: train step 14090: loss: 1.0785, policy_loss: 1.0410, value_loss: 0.5917
2024-07-14 06:34:54,458 [INFO    ] __main__: train step 14091: loss: 1.0785, policy_loss: 1.0410, value_loss: 0.5917
2024-07-14 06:34:54,747 [INFO    ] __main__: train step 14092: loss: 1.0785, policy_loss: 1.0410, value_loss: 0.5916
2024-07-14 06:34:55,037 [INFO    ] __main__: train step 14093: loss: 1.0784, policy_loss: 1.0409, value_loss: 0.5916
2024-07-14 06:34:55,312 [INFO    ] __main__: train step 14094: loss: 1.0784, policy_loss: 1.0409, value_loss: 0.5916
2024-07-14 06:34:55,611 [INFO    ] __main__: train step 14095: loss: 1.0784, policy_loss: 1.0409, value_loss: 0.5915
2024-07-14 06:34:55,910 [INFO    ] __main__: train step 14096: loss: 1.0784, policy_loss: 1.0409, value_loss: 0.5915
2024-07-14 06:34:56,212 [INFO    ] __main__: train step 14097: loss: 1.0784, policy_loss: 1.0408, value_loss: 0.5915
2024-07-14 06:34:56,517 [INFO    ] __main__: train step 14098: loss: 1.0784, policy_loss: 1.0408, value_loss: 0.5915
2024-07-14 06:34:56,810 [INFO    ] __main__: train step 14099: loss: 1.0783, policy_loss: 1.0408, value_loss: 0.5914
2024-07-14 06:34:57,102 [INFO    ] __main__: train step 14100: loss: 1.0783, policy_loss: 1.0408, value_loss: 0.5914
2024-07-14 06:34:57,388 [INFO    ] __main__: train step 14101: loss: 1.0783, policy_loss: 1.0407, value_loss: 0.5914
2024-07-14 06:34:57,686 [INFO    ] __main__: train step 14102: loss: 1.0783, policy_loss: 1.0407, value_loss: 0.5913
2024-07-14 06:34:57,976 [INFO    ] __main__: train step 14103: loss: 1.0783, policy_loss: 1.0407, value_loss: 0.5913
2024-07-14 06:34:58,263 [INFO    ] __main__: train step 14104: loss: 1.0783, policy_loss: 1.0406, value_loss: 0.5913
2024-07-14 06:34:58,569 [INFO    ] __main__: train step 14105: loss: 1.0782, policy_loss: 1.0406, value_loss: 0.5913
2024-07-14 06:34:58,866 [INFO    ] __main__: train step 14106: loss: 1.0782, policy_loss: 1.0406, value_loss: 0.5912
2024-07-14 06:35:00,483 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:35:00,967 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:35:01,038 [INFO    ] __main__: train step 14107: loss: 1.0782, policy_loss: 1.0406, value_loss: 0.5912
2024-07-14 06:35:01,318 [INFO    ] __main__: train step 14108: loss: 1.0782, policy_loss: 1.0405, value_loss: 0.5912
2024-07-14 06:35:01,606 [INFO    ] __main__: train step 14109: loss: 1.0782, policy_loss: 1.0405, value_loss: 0.5911
2024-07-14 06:35:01,904 [INFO    ] __main__: train step 14110: loss: 1.0782, policy_loss: 1.0405, value_loss: 0.5911
2024-07-14 06:35:02,191 [INFO    ] __main__: train step 14111: loss: 1.0781, policy_loss: 1.0405, value_loss: 0.5911
2024-07-14 06:35:02,473 [INFO    ] __main__: train step 14112: loss: 1.0781, policy_loss: 1.0404, value_loss: 0.5910
2024-07-14 06:35:02,762 [INFO    ] __main__: train step 14113: loss: 1.0781, policy_loss: 1.0404, value_loss: 0.5910
2024-07-14 06:35:03,054 [INFO    ] __main__: train step 14114: loss: 1.0781, policy_loss: 1.0404, value_loss: 0.5910
2024-07-14 06:35:03,337 [INFO    ] __main__: train step 14115: loss: 1.0781, policy_loss: 1.0403, value_loss: 0.5910
2024-07-14 06:35:03,630 [INFO    ] __main__: train step 14116: loss: 1.0781, policy_loss: 1.0403, value_loss: 0.5909
2024-07-14 06:35:03,934 [INFO    ] __main__: train step 14117: loss: 1.0780, policy_loss: 1.0403, value_loss: 0.5909
2024-07-14 06:35:04,227 [INFO    ] __main__: train step 14118: loss: 1.0780, policy_loss: 1.0403, value_loss: 0.5909
2024-07-14 06:35:04,520 [INFO    ] __main__: train step 14119: loss: 1.0780, policy_loss: 1.0402, value_loss: 0.5909
2024-07-14 06:35:04,811 [INFO    ] __main__: train step 14120: loss: 1.0780, policy_loss: 1.0402, value_loss: 0.5908
2024-07-14 06:35:05,103 [INFO    ] __main__: train step 14121: loss: 1.0780, policy_loss: 1.0402, value_loss: 0.5908
2024-07-14 06:35:05,400 [INFO    ] __main__: train step 14122: loss: 1.0780, policy_loss: 1.0402, value_loss: 0.5908
2024-07-14 06:35:05,700 [INFO    ] __main__: train step 14123: loss: 1.0779, policy_loss: 1.0401, value_loss: 0.5907
2024-07-14 06:35:07,318 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:35:07,810 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:35:07,878 [INFO    ] __main__: train step 14124: loss: 1.0779, policy_loss: 1.0401, value_loss: 0.5907
2024-07-14 06:35:08,171 [INFO    ] __main__: train step 14125: loss: 1.0779, policy_loss: 1.0401, value_loss: 0.5907
2024-07-14 06:35:08,465 [INFO    ] __main__: train step 14126: loss: 1.0779, policy_loss: 1.0400, value_loss: 0.5907
2024-07-14 06:35:08,758 [INFO    ] __main__: train step 14127: loss: 1.0779, policy_loss: 1.0400, value_loss: 0.5906
2024-07-14 06:35:09,042 [INFO    ] __main__: train step 14128: loss: 1.0779, policy_loss: 1.0400, value_loss: 0.5906
2024-07-14 06:35:09,331 [INFO    ] __main__: train step 14129: loss: 1.0778, policy_loss: 1.0400, value_loss: 0.5906
2024-07-14 06:35:09,625 [INFO    ] __main__: train step 14130: loss: 1.0778, policy_loss: 1.0399, value_loss: 0.5905
2024-07-14 06:35:09,936 [INFO    ] __main__: train step 14131: loss: 1.0778, policy_loss: 1.0399, value_loss: 0.5905
2024-07-14 06:35:10,229 [INFO    ] __main__: train step 14132: loss: 1.0778, policy_loss: 1.0399, value_loss: 0.5905
2024-07-14 06:35:10,530 [INFO    ] __main__: train step 14133: loss: 1.0778, policy_loss: 1.0399, value_loss: 0.5905
2024-07-14 06:35:10,821 [INFO    ] __main__: train step 14134: loss: 1.0778, policy_loss: 1.0398, value_loss: 0.5904
2024-07-14 06:35:11,112 [INFO    ] __main__: train step 14135: loss: 1.0777, policy_loss: 1.0398, value_loss: 0.5904
2024-07-14 06:35:11,412 [INFO    ] __main__: train step 14136: loss: 1.0777, policy_loss: 1.0398, value_loss: 0.5904
2024-07-14 06:35:14,385 [INFO    ] __main__: train step 14137: loss: 1.0777, policy_loss: 1.0397, value_loss: 0.5903
2024-07-14 06:35:14,696 [INFO    ] __main__: train step 14138: loss: 1.0777, policy_loss: 1.0397, value_loss: 0.5903
2024-07-14 06:35:14,999 [INFO    ] __main__: train step 14139: loss: 1.0777, policy_loss: 1.0397, value_loss: 0.5903
2024-07-14 06:35:15,309 [INFO    ] __main__: train step 14140: loss: 1.0777, policy_loss: 1.0397, value_loss: 0.5903
2024-07-14 06:35:16,928 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:35:17,423 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:35:17,491 [INFO    ] __main__: train step 14141: loss: 1.0776, policy_loss: 1.0396, value_loss: 0.5902
2024-07-14 06:35:17,781 [INFO    ] __main__: train step 14142: loss: 1.0776, policy_loss: 1.0396, value_loss: 0.5902
2024-07-14 06:35:18,080 [INFO    ] __main__: train step 14143: loss: 1.0776, policy_loss: 1.0396, value_loss: 0.5902
2024-07-14 06:35:18,378 [INFO    ] __main__: train step 14144: loss: 1.0776, policy_loss: 1.0396, value_loss: 0.5901
2024-07-14 06:35:18,680 [INFO    ] __main__: train step 14145: loss: 1.0776, policy_loss: 1.0395, value_loss: 0.5901
2024-07-14 06:35:18,975 [INFO    ] __main__: train step 14146: loss: 1.0776, policy_loss: 1.0395, value_loss: 0.5901
2024-07-14 06:35:19,278 [INFO    ] __main__: train step 14147: loss: 1.0775, policy_loss: 1.0395, value_loss: 0.5901
2024-07-14 06:35:19,572 [INFO    ] __main__: train step 14148: loss: 1.0775, policy_loss: 1.0394, value_loss: 0.5900
2024-07-14 06:35:19,871 [INFO    ] __main__: train step 14149: loss: 1.0775, policy_loss: 1.0394, value_loss: 0.5900
2024-07-14 06:35:20,175 [INFO    ] __main__: train step 14150: loss: 1.0775, policy_loss: 1.0394, value_loss: 0.5900
2024-07-14 06:35:20,481 [INFO    ] __main__: train step 14151: loss: 1.0775, policy_loss: 1.0394, value_loss: 0.5899
2024-07-14 06:35:20,783 [INFO    ] __main__: train step 14152: loss: 1.0775, policy_loss: 1.0393, value_loss: 0.5899
2024-07-14 06:35:21,080 [INFO    ] __main__: train step 14153: loss: 1.0774, policy_loss: 1.0393, value_loss: 0.5899
2024-07-14 06:35:21,379 [INFO    ] __main__: train step 14154: loss: 1.0774, policy_loss: 1.0393, value_loss: 0.5899
2024-07-14 06:35:21,650 [INFO    ] __main__: train step 14155: loss: 1.0774, policy_loss: 1.0393, value_loss: 0.5898
2024-07-14 06:35:21,931 [INFO    ] __main__: train step 14156: loss: 1.0774, policy_loss: 1.0392, value_loss: 0.5898
2024-07-14 06:35:22,219 [INFO    ] __main__: train step 14157: loss: 1.0774, policy_loss: 1.0392, value_loss: 0.5898
2024-07-14 06:35:23,849 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:35:24,345 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:35:24,414 [INFO    ] __main__: train step 14158: loss: 1.0774, policy_loss: 1.0392, value_loss: 0.5897
2024-07-14 06:35:24,712 [INFO    ] __main__: train step 14159: loss: 1.0773, policy_loss: 1.0391, value_loss: 0.5897
2024-07-14 06:35:25,010 [INFO    ] __main__: train step 14160: loss: 1.0773, policy_loss: 1.0391, value_loss: 0.5897
2024-07-14 06:35:25,306 [INFO    ] __main__: train step 14161: loss: 1.0773, policy_loss: 1.0391, value_loss: 0.5897
2024-07-14 06:35:25,611 [INFO    ] __main__: train step 14162: loss: 1.0773, policy_loss: 1.0391, value_loss: 0.5896
2024-07-14 06:35:25,913 [INFO    ] __main__: train step 14163: loss: 1.0773, policy_loss: 1.0390, value_loss: 0.5896
2024-07-14 06:35:26,208 [INFO    ] __main__: train step 14164: loss: 1.0773, policy_loss: 1.0390, value_loss: 0.5896
2024-07-14 06:35:26,511 [INFO    ] __main__: train step 14165: loss: 1.0772, policy_loss: 1.0390, value_loss: 0.5895
2024-07-14 06:35:26,819 [INFO    ] __main__: train step 14166: loss: 1.0772, policy_loss: 1.0390, value_loss: 0.5895
2024-07-14 06:35:27,124 [INFO    ] __main__: train step 14167: loss: 1.0772, policy_loss: 1.0389, value_loss: 0.5895
2024-07-14 06:35:27,405 [INFO    ] __main__: train step 14168: loss: 1.0772, policy_loss: 1.0389, value_loss: 0.5895
2024-07-14 06:35:27,709 [INFO    ] __main__: train step 14169: loss: 1.0772, policy_loss: 1.0389, value_loss: 0.5894
2024-07-14 06:35:28,014 [INFO    ] __main__: train step 14170: loss: 1.0772, policy_loss: 1.0388, value_loss: 0.5894
2024-07-14 06:35:28,314 [INFO    ] __main__: train step 14171: loss: 1.0771, policy_loss: 1.0388, value_loss: 0.5894
2024-07-14 06:35:28,612 [INFO    ] __main__: train step 14172: loss: 1.0771, policy_loss: 1.0388, value_loss: 0.5893
2024-07-14 06:35:28,900 [INFO    ] __main__: train step 14173: loss: 1.0771, policy_loss: 1.0388, value_loss: 0.5893
2024-07-14 06:35:29,196 [INFO    ] __main__: train step 14174: loss: 1.0771, policy_loss: 1.0387, value_loss: 0.5893
2024-07-14 06:35:30,828 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:35:31,322 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:35:31,391 [INFO    ] __main__: train step 14175: loss: 1.0771, policy_loss: 1.0387, value_loss: 0.5893
2024-07-14 06:35:31,677 [INFO    ] __main__: train step 14176: loss: 1.0771, policy_loss: 1.0387, value_loss: 0.5892
2024-07-14 06:35:31,977 [INFO    ] __main__: train step 14177: loss: 1.0770, policy_loss: 1.0387, value_loss: 0.5892
2024-07-14 06:35:32,271 [INFO    ] __main__: train step 14178: loss: 1.0770, policy_loss: 1.0386, value_loss: 0.5892
2024-07-14 06:35:32,570 [INFO    ] __main__: train step 14179: loss: 1.0770, policy_loss: 1.0386, value_loss: 0.5891
2024-07-14 06:35:32,868 [INFO    ] __main__: train step 14180: loss: 1.0770, policy_loss: 1.0386, value_loss: 0.5891
2024-07-14 06:35:33,160 [INFO    ] __main__: train step 14181: loss: 1.0770, policy_loss: 1.0385, value_loss: 0.5891
2024-07-14 06:35:33,454 [INFO    ] __main__: train step 14182: loss: 1.0770, policy_loss: 1.0385, value_loss: 0.5891
2024-07-14 06:35:33,748 [INFO    ] __main__: train step 14183: loss: 1.0769, policy_loss: 1.0385, value_loss: 0.5890
2024-07-14 06:35:34,034 [INFO    ] __main__: train step 14184: loss: 1.0769, policy_loss: 1.0385, value_loss: 0.5890
2024-07-14 06:35:34,331 [INFO    ] __main__: train step 14185: loss: 1.0769, policy_loss: 1.0384, value_loss: 0.5890
2024-07-14 06:35:34,629 [INFO    ] __main__: train step 14186: loss: 1.0769, policy_loss: 1.0384, value_loss: 0.5889
2024-07-14 06:35:34,927 [INFO    ] __main__: train step 14187: loss: 1.0769, policy_loss: 1.0384, value_loss: 0.5889
2024-07-14 06:35:35,226 [INFO    ] __main__: train step 14188: loss: 1.0769, policy_loss: 1.0384, value_loss: 0.5889
2024-07-14 06:35:35,526 [INFO    ] __main__: train step 14189: loss: 1.0768, policy_loss: 1.0383, value_loss: 0.5889
2024-07-14 06:35:35,823 [INFO    ] __main__: train step 14190: loss: 1.0768, policy_loss: 1.0383, value_loss: 0.5888
2024-07-14 06:35:36,112 [INFO    ] __main__: train step 14191: loss: 1.0768, policy_loss: 1.0383, value_loss: 0.5888
2024-07-14 06:35:37,712 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:35:38,204 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:35:38,272 [INFO    ] __main__: train step 14192: loss: 1.0768, policy_loss: 1.0382, value_loss: 0.5888
2024-07-14 06:35:38,556 [INFO    ] __main__: train step 14193: loss: 1.0768, policy_loss: 1.0382, value_loss: 0.5887
2024-07-14 06:35:38,844 [INFO    ] __main__: train step 14194: loss: 1.0767, policy_loss: 1.0382, value_loss: 0.5887
2024-07-14 06:35:39,126 [INFO    ] __main__: train step 14195: loss: 1.0767, policy_loss: 1.0382, value_loss: 0.5887
2024-07-14 06:35:39,414 [INFO    ] __main__: train step 14196: loss: 1.0767, policy_loss: 1.0381, value_loss: 0.5887
2024-07-14 06:35:39,716 [INFO    ] __main__: train step 14197: loss: 1.0767, policy_loss: 1.0381, value_loss: 0.5886
2024-07-14 06:35:40,018 [INFO    ] __main__: train step 14198: loss: 1.0767, policy_loss: 1.0381, value_loss: 0.5886
2024-07-14 06:35:40,307 [INFO    ] __main__: train step 14199: loss: 1.0767, policy_loss: 1.0381, value_loss: 0.5886
2024-07-14 06:35:40,606 [INFO    ] __main__: train step 14200: loss: 1.0766, policy_loss: 1.0380, value_loss: 0.5885
2024-07-14 06:35:40,897 [INFO    ] __main__: train step 14201: loss: 1.0766, policy_loss: 1.0380, value_loss: 0.5885
2024-07-14 06:35:41,199 [INFO    ] __main__: train step 14202: loss: 1.0766, policy_loss: 1.0380, value_loss: 0.5885
2024-07-14 06:35:41,494 [INFO    ] __main__: train step 14203: loss: 1.0766, policy_loss: 1.0379, value_loss: 0.5885
2024-07-14 06:35:41,794 [INFO    ] __main__: train step 14204: loss: 1.0766, policy_loss: 1.0379, value_loss: 0.5884
2024-07-14 06:35:42,091 [INFO    ] __main__: train step 14205: loss: 1.0766, policy_loss: 1.0379, value_loss: 0.5884
2024-07-14 06:35:42,388 [INFO    ] __main__: train step 14206: loss: 1.0765, policy_loss: 1.0379, value_loss: 0.5884
2024-07-14 06:35:42,671 [INFO    ] __main__: train step 14207: loss: 1.0765, policy_loss: 1.0378, value_loss: 0.5883
2024-07-14 06:35:42,970 [INFO    ] __main__: train step 14208: loss: 1.0765, policy_loss: 1.0378, value_loss: 0.5883
2024-07-14 06:35:44,615 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:35:45,114 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:35:45,185 [INFO    ] __main__: train step 14209: loss: 1.0765, policy_loss: 1.0378, value_loss: 0.5883
2024-07-14 06:35:45,487 [INFO    ] __main__: train step 14210: loss: 1.0765, policy_loss: 1.0377, value_loss: 0.5883
2024-07-14 06:35:45,781 [INFO    ] __main__: train step 14211: loss: 1.0764, policy_loss: 1.0377, value_loss: 0.5882
2024-07-14 06:35:46,051 [INFO    ] __main__: train step 14212: loss: 1.0764, policy_loss: 1.0377, value_loss: 0.5882
2024-07-14 06:35:46,339 [INFO    ] __main__: train step 14213: loss: 1.0764, policy_loss: 1.0377, value_loss: 0.5882
2024-07-14 06:35:46,630 [INFO    ] __main__: train step 14214: loss: 1.0764, policy_loss: 1.0376, value_loss: 0.5881
2024-07-14 06:35:46,928 [INFO    ] __main__: train step 14215: loss: 1.0764, policy_loss: 1.0376, value_loss: 0.5881
2024-07-14 06:35:47,221 [INFO    ] __main__: train step 14216: loss: 1.0764, policy_loss: 1.0376, value_loss: 0.5881
2024-07-14 06:35:47,492 [INFO    ] __main__: train step 14217: loss: 1.0763, policy_loss: 1.0376, value_loss: 0.5881
2024-07-14 06:35:47,803 [INFO    ] __main__: train step 14218: loss: 1.0763, policy_loss: 1.0375, value_loss: 0.5880
2024-07-14 06:35:48,099 [INFO    ] __main__: train step 14219: loss: 1.0763, policy_loss: 1.0375, value_loss: 0.5880
2024-07-14 06:35:48,410 [INFO    ] __main__: train step 14220: loss: 1.0763, policy_loss: 1.0375, value_loss: 0.5880
2024-07-14 06:35:48,705 [INFO    ] __main__: train step 14221: loss: 1.0763, policy_loss: 1.0374, value_loss: 0.5879
2024-07-14 06:35:48,998 [INFO    ] __main__: train step 14222: loss: 1.0763, policy_loss: 1.0374, value_loss: 0.5879
2024-07-14 06:35:51,941 [INFO    ] __main__: train step 14223: loss: 1.0762, policy_loss: 1.0374, value_loss: 0.5879
2024-07-14 06:35:52,242 [INFO    ] __main__: train step 14224: loss: 1.0762, policy_loss: 1.0374, value_loss: 0.5879
2024-07-14 06:35:52,538 [INFO    ] __main__: train step 14225: loss: 1.0762, policy_loss: 1.0373, value_loss: 0.5878
2024-07-14 06:35:54,148 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:35:54,637 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:35:54,707 [INFO    ] __main__: train step 14226: loss: 1.0762, policy_loss: 1.0373, value_loss: 0.5878
2024-07-14 06:35:55,012 [INFO    ] __main__: train step 14227: loss: 1.0762, policy_loss: 1.0373, value_loss: 0.5878
2024-07-14 06:35:55,316 [INFO    ] __main__: train step 14228: loss: 1.0761, policy_loss: 1.0372, value_loss: 0.5877
2024-07-14 06:35:55,607 [INFO    ] __main__: train step 14229: loss: 1.0761, policy_loss: 1.0372, value_loss: 0.5877
2024-07-14 06:35:55,907 [INFO    ] __main__: train step 14230: loss: 1.0761, policy_loss: 1.0372, value_loss: 0.5877
2024-07-14 06:35:56,202 [INFO    ] __main__: train step 14231: loss: 1.0761, policy_loss: 1.0372, value_loss: 0.5877
2024-07-14 06:35:56,496 [INFO    ] __main__: train step 14232: loss: 1.0761, policy_loss: 1.0371, value_loss: 0.5876
2024-07-14 06:35:56,783 [INFO    ] __main__: train step 14233: loss: 1.0761, policy_loss: 1.0371, value_loss: 0.5876
2024-07-14 06:35:57,070 [INFO    ] __main__: train step 14234: loss: 1.0760, policy_loss: 1.0371, value_loss: 0.5876
2024-07-14 06:35:57,365 [INFO    ] __main__: train step 14235: loss: 1.0760, policy_loss: 1.0371, value_loss: 0.5875
2024-07-14 06:35:57,653 [INFO    ] __main__: train step 14236: loss: 1.0760, policy_loss: 1.0370, value_loss: 0.5875
2024-07-14 06:35:57,941 [INFO    ] __main__: train step 14237: loss: 1.0760, policy_loss: 1.0370, value_loss: 0.5875
2024-07-14 06:35:58,227 [INFO    ] __main__: train step 14238: loss: 1.0760, policy_loss: 1.0370, value_loss: 0.5875
2024-07-14 06:35:58,512 [INFO    ] __main__: train step 14239: loss: 1.0759, policy_loss: 1.0369, value_loss: 0.5874
2024-07-14 06:35:58,807 [INFO    ] __main__: train step 14240: loss: 1.0759, policy_loss: 1.0369, value_loss: 0.5874
2024-07-14 06:35:59,094 [INFO    ] __main__: train step 14241: loss: 1.0759, policy_loss: 1.0369, value_loss: 0.5874
2024-07-14 06:35:59,381 [INFO    ] __main__: train step 14242: loss: 1.0759, policy_loss: 1.0369, value_loss: 0.5873
2024-07-14 06:36:01,000 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:36:01,486 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:36:01,557 [INFO    ] __main__: train step 14243: loss: 1.0759, policy_loss: 1.0368, value_loss: 0.5873
2024-07-14 06:36:01,861 [INFO    ] __main__: train step 14244: loss: 1.0759, policy_loss: 1.0368, value_loss: 0.5873
2024-07-14 06:36:02,149 [INFO    ] __main__: train step 14245: loss: 1.0758, policy_loss: 1.0368, value_loss: 0.5873
2024-07-14 06:36:02,436 [INFO    ] __main__: train step 14246: loss: 1.0758, policy_loss: 1.0367, value_loss: 0.5872
2024-07-14 06:36:02,739 [INFO    ] __main__: train step 14247: loss: 1.0758, policy_loss: 1.0367, value_loss: 0.5872
2024-07-14 06:36:03,044 [INFO    ] __main__: train step 14248: loss: 1.0758, policy_loss: 1.0367, value_loss: 0.5872
2024-07-14 06:36:03,345 [INFO    ] __main__: train step 14249: loss: 1.0758, policy_loss: 1.0367, value_loss: 0.5871
2024-07-14 06:36:03,637 [INFO    ] __main__: train step 14250: loss: 1.0758, policy_loss: 1.0366, value_loss: 0.5871
2024-07-14 06:36:03,938 [INFO    ] __main__: train step 14251: loss: 1.0757, policy_loss: 1.0366, value_loss: 0.5871
2024-07-14 06:36:04,232 [INFO    ] __main__: train step 14252: loss: 1.0757, policy_loss: 1.0366, value_loss: 0.5871
2024-07-14 06:36:04,534 [INFO    ] __main__: train step 14253: loss: 1.0757, policy_loss: 1.0366, value_loss: 0.5870
2024-07-14 06:36:04,837 [INFO    ] __main__: train step 14254: loss: 1.0757, policy_loss: 1.0365, value_loss: 0.5870
2024-07-14 06:36:05,136 [INFO    ] __main__: train step 14255: loss: 1.0757, policy_loss: 1.0365, value_loss: 0.5870
2024-07-14 06:36:05,439 [INFO    ] __main__: train step 14256: loss: 1.0756, policy_loss: 1.0365, value_loss: 0.5869
2024-07-14 06:36:05,728 [INFO    ] __main__: train step 14257: loss: 1.0756, policy_loss: 1.0364, value_loss: 0.5869
2024-07-14 06:36:06,029 [INFO    ] __main__: train step 14258: loss: 1.0756, policy_loss: 1.0364, value_loss: 0.5869
2024-07-14 06:36:06,324 [INFO    ] __main__: train step 14259: loss: 1.0756, policy_loss: 1.0364, value_loss: 0.5869
2024-07-14 06:36:07,945 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:36:08,433 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:36:08,501 [INFO    ] __main__: train step 14260: loss: 1.0756, policy_loss: 1.0364, value_loss: 0.5868
2024-07-14 06:36:08,797 [INFO    ] __main__: train step 14261: loss: 1.0756, policy_loss: 1.0363, value_loss: 0.5868
2024-07-14 06:36:09,099 [INFO    ] __main__: train step 14262: loss: 1.0755, policy_loss: 1.0363, value_loss: 0.5868
2024-07-14 06:36:09,396 [INFO    ] __main__: train step 14263: loss: 1.0755, policy_loss: 1.0363, value_loss: 0.5867
2024-07-14 06:36:09,688 [INFO    ] __main__: train step 14264: loss: 1.0755, policy_loss: 1.0362, value_loss: 0.5867
2024-07-14 06:36:09,980 [INFO    ] __main__: train step 14265: loss: 1.0755, policy_loss: 1.0362, value_loss: 0.5867
2024-07-14 06:36:10,283 [INFO    ] __main__: train step 14266: loss: 1.0755, policy_loss: 1.0362, value_loss: 0.5867
2024-07-14 06:36:10,579 [INFO    ] __main__: train step 14267: loss: 1.0755, policy_loss: 1.0362, value_loss: 0.5866
2024-07-14 06:36:10,879 [INFO    ] __main__: train step 14268: loss: 1.0754, policy_loss: 1.0361, value_loss: 0.5866
2024-07-14 06:36:11,174 [INFO    ] __main__: train step 14269: loss: 1.0754, policy_loss: 1.0361, value_loss: 0.5866
2024-07-14 06:36:11,472 [INFO    ] __main__: train step 14270: loss: 1.0754, policy_loss: 1.0361, value_loss: 0.5865
2024-07-14 06:36:11,770 [INFO    ] __main__: train step 14271: loss: 1.0754, policy_loss: 1.0361, value_loss: 0.5865
2024-07-14 06:36:12,065 [INFO    ] __main__: train step 14272: loss: 1.0754, policy_loss: 1.0360, value_loss: 0.5865
2024-07-14 06:36:12,365 [INFO    ] __main__: train step 14273: loss: 1.0753, policy_loss: 1.0360, value_loss: 0.5865
2024-07-14 06:36:12,641 [INFO    ] __main__: train step 14274: loss: 1.0753, policy_loss: 1.0360, value_loss: 0.5864
2024-07-14 06:36:12,933 [INFO    ] __main__: train step 14275: loss: 1.0753, policy_loss: 1.0359, value_loss: 0.5864
2024-07-14 06:36:13,230 [INFO    ] __main__: train step 14276: loss: 1.0753, policy_loss: 1.0359, value_loss: 0.5864
2024-07-14 06:36:14,849 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:36:15,338 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:36:15,406 [INFO    ] __main__: train step 14277: loss: 1.0753, policy_loss: 1.0359, value_loss: 0.5863
2024-07-14 06:36:15,704 [INFO    ] __main__: train step 14278: loss: 1.0753, policy_loss: 1.0359, value_loss: 0.5863
2024-07-14 06:36:15,987 [INFO    ] __main__: train step 14279: loss: 1.0752, policy_loss: 1.0358, value_loss: 0.5863
2024-07-14 06:36:16,279 [INFO    ] __main__: train step 14280: loss: 1.0752, policy_loss: 1.0358, value_loss: 0.5863
2024-07-14 06:36:16,583 [INFO    ] __main__: train step 14281: loss: 1.0752, policy_loss: 1.0358, value_loss: 0.5862
2024-07-14 06:36:16,872 [INFO    ] __main__: train step 14282: loss: 1.0752, policy_loss: 1.0357, value_loss: 0.5862
2024-07-14 06:36:17,152 [INFO    ] __main__: train step 14283: loss: 1.0752, policy_loss: 1.0357, value_loss: 0.5862
2024-07-14 06:36:17,440 [INFO    ] __main__: train step 14284: loss: 1.0751, policy_loss: 1.0357, value_loss: 0.5862
2024-07-14 06:36:17,751 [INFO    ] __main__: train step 14285: loss: 1.0751, policy_loss: 1.0357, value_loss: 0.5861
2024-07-14 06:36:18,053 [INFO    ] __main__: train step 14286: loss: 1.0751, policy_loss: 1.0356, value_loss: 0.5861
2024-07-14 06:36:18,346 [INFO    ] __main__: train step 14287: loss: 1.0751, policy_loss: 1.0356, value_loss: 0.5861
2024-07-14 06:36:18,643 [INFO    ] __main__: train step 14288: loss: 1.0751, policy_loss: 1.0356, value_loss: 0.5860
2024-07-14 06:36:18,931 [INFO    ] __main__: train step 14289: loss: 1.0751, policy_loss: 1.0355, value_loss: 0.5860
2024-07-14 06:36:19,232 [INFO    ] __main__: train step 14290: loss: 1.0750, policy_loss: 1.0355, value_loss: 0.5860
2024-07-14 06:36:19,532 [INFO    ] __main__: train step 14291: loss: 1.0750, policy_loss: 1.0355, value_loss: 0.5860
2024-07-14 06:36:19,834 [INFO    ] __main__: train step 14292: loss: 1.0750, policy_loss: 1.0355, value_loss: 0.5859
2024-07-14 06:36:20,141 [INFO    ] __main__: train step 14293: loss: 1.0750, policy_loss: 1.0354, value_loss: 0.5859
2024-07-14 06:36:21,764 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:36:22,259 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:36:22,329 [INFO    ] __main__: train step 14294: loss: 1.0750, policy_loss: 1.0354, value_loss: 0.5859
2024-07-14 06:36:22,631 [INFO    ] __main__: train step 14295: loss: 1.0750, policy_loss: 1.0354, value_loss: 0.5858
2024-07-14 06:36:22,930 [INFO    ] __main__: train step 14296: loss: 1.0749, policy_loss: 1.0354, value_loss: 0.5858
2024-07-14 06:36:23,228 [INFO    ] __main__: train step 14297: loss: 1.0749, policy_loss: 1.0353, value_loss: 0.5858
2024-07-14 06:36:23,526 [INFO    ] __main__: train step 14298: loss: 1.0749, policy_loss: 1.0353, value_loss: 0.5858
2024-07-14 06:36:23,825 [INFO    ] __main__: train step 14299: loss: 1.0749, policy_loss: 1.0353, value_loss: 0.5857
2024-07-14 06:36:24,126 [INFO    ] __main__: train step 14300: loss: 1.0749, policy_loss: 1.0352, value_loss: 0.5857
2024-07-14 06:36:24,402 [INFO    ] __main__: train step 14301: loss: 1.0748, policy_loss: 1.0352, value_loss: 0.5857
2024-07-14 06:36:24,677 [INFO    ] __main__: train step 14302: loss: 1.0748, policy_loss: 1.0352, value_loss: 0.5856
2024-07-14 06:36:24,949 [INFO    ] __main__: train step 14303: loss: 1.0748, policy_loss: 1.0352, value_loss: 0.5856
2024-07-14 06:36:25,243 [INFO    ] __main__: train step 14304: loss: 1.0748, policy_loss: 1.0351, value_loss: 0.5856
2024-07-14 06:36:25,534 [INFO    ] __main__: train step 14305: loss: 1.0748, policy_loss: 1.0351, value_loss: 0.5856
2024-07-14 06:36:25,845 [INFO    ] __main__: train step 14306: loss: 1.0747, policy_loss: 1.0351, value_loss: 0.5855
2024-07-14 06:36:26,140 [INFO    ] __main__: train step 14307: loss: 1.0747, policy_loss: 1.0350, value_loss: 0.5855
2024-07-14 06:36:26,438 [INFO    ] __main__: train step 14308: loss: 1.0747, policy_loss: 1.0350, value_loss: 0.5855
2024-07-14 06:36:26,728 [INFO    ] __main__: train step 14309: loss: 1.0747, policy_loss: 1.0350, value_loss: 0.5854
2024-07-14 06:36:27,029 [INFO    ] __main__: train step 14310: loss: 1.0747, policy_loss: 1.0350, value_loss: 0.5854
2024-07-14 06:36:31,249 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:36:31,749 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:36:31,820 [INFO    ] __main__: train step 14311: loss: 1.0747, policy_loss: 1.0349, value_loss: 0.5854
2024-07-14 06:36:32,113 [INFO    ] __main__: train step 14312: loss: 1.0746, policy_loss: 1.0349, value_loss: 0.5854
2024-07-14 06:36:32,405 [INFO    ] __main__: train step 14313: loss: 1.0746, policy_loss: 1.0349, value_loss: 0.5853
2024-07-14 06:36:32,685 [INFO    ] __main__: train step 14314: loss: 1.0746, policy_loss: 1.0348, value_loss: 0.5853
2024-07-14 06:36:32,959 [INFO    ] __main__: train step 14315: loss: 1.0746, policy_loss: 1.0348, value_loss: 0.5853
2024-07-14 06:36:33,231 [INFO    ] __main__: train step 14316: loss: 1.0746, policy_loss: 1.0348, value_loss: 0.5852
2024-07-14 06:36:33,503 [INFO    ] __main__: train step 14317: loss: 1.0746, policy_loss: 1.0348, value_loss: 0.5852
2024-07-14 06:36:33,780 [INFO    ] __main__: train step 14318: loss: 1.0745, policy_loss: 1.0347, value_loss: 0.5852
2024-07-14 06:36:34,076 [INFO    ] __main__: train step 14319: loss: 1.0745, policy_loss: 1.0347, value_loss: 0.5852
2024-07-14 06:36:34,379 [INFO    ] __main__: train step 14320: loss: 1.0745, policy_loss: 1.0347, value_loss: 0.5851
2024-07-14 06:36:34,674 [INFO    ] __main__: train step 14321: loss: 1.0745, policy_loss: 1.0347, value_loss: 0.5851
2024-07-14 06:36:34,967 [INFO    ] __main__: train step 14322: loss: 1.0745, policy_loss: 1.0346, value_loss: 0.5851
2024-07-14 06:36:35,268 [INFO    ] __main__: train step 14323: loss: 1.0744, policy_loss: 1.0346, value_loss: 0.5851
2024-07-14 06:36:35,558 [INFO    ] __main__: train step 14324: loss: 1.0744, policy_loss: 1.0346, value_loss: 0.5850
2024-07-14 06:36:35,855 [INFO    ] __main__: train step 14325: loss: 1.0744, policy_loss: 1.0345, value_loss: 0.5850
2024-07-14 06:36:36,150 [INFO    ] __main__: train step 14326: loss: 1.0744, policy_loss: 1.0345, value_loss: 0.5850
2024-07-14 06:36:36,443 [INFO    ] __main__: train step 14327: loss: 1.0744, policy_loss: 1.0345, value_loss: 0.5849
2024-07-14 06:36:38,055 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:36:38,544 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:36:38,613 [INFO    ] __main__: train step 14328: loss: 1.0744, policy_loss: 1.0345, value_loss: 0.5849
2024-07-14 06:36:38,909 [INFO    ] __main__: train step 14329: loss: 1.0743, policy_loss: 1.0344, value_loss: 0.5849
2024-07-14 06:36:39,203 [INFO    ] __main__: train step 14330: loss: 1.0743, policy_loss: 1.0344, value_loss: 0.5849
2024-07-14 06:36:39,487 [INFO    ] __main__: train step 14331: loss: 1.0743, policy_loss: 1.0344, value_loss: 0.5848
2024-07-14 06:36:39,796 [INFO    ] __main__: train step 14332: loss: 1.0743, policy_loss: 1.0343, value_loss: 0.5848
2024-07-14 06:36:40,098 [INFO    ] __main__: train step 14333: loss: 1.0743, policy_loss: 1.0343, value_loss: 0.5848
2024-07-14 06:36:40,392 [INFO    ] __main__: train step 14334: loss: 1.0742, policy_loss: 1.0343, value_loss: 0.5847
2024-07-14 06:36:40,691 [INFO    ] __main__: train step 14335: loss: 1.0742, policy_loss: 1.0343, value_loss: 0.5847
2024-07-14 06:36:40,984 [INFO    ] __main__: train step 14336: loss: 1.0742, policy_loss: 1.0342, value_loss: 0.5847
2024-07-14 06:36:41,265 [INFO    ] __main__: train step 14337: loss: 1.0742, policy_loss: 1.0342, value_loss: 0.5847
2024-07-14 06:36:41,556 [INFO    ] __main__: train step 14338: loss: 1.0742, policy_loss: 1.0342, value_loss: 0.5846
2024-07-14 06:36:41,869 [INFO    ] __main__: train step 14339: loss: 1.0742, policy_loss: 1.0341, value_loss: 0.5846
2024-07-14 06:36:42,166 [INFO    ] __main__: train step 14340: loss: 1.0741, policy_loss: 1.0341, value_loss: 0.5846
2024-07-14 06:36:42,451 [INFO    ] __main__: train step 14341: loss: 1.0741, policy_loss: 1.0341, value_loss: 0.5846
2024-07-14 06:36:42,735 [INFO    ] __main__: train step 14342: loss: 1.0741, policy_loss: 1.0341, value_loss: 0.5845
2024-07-14 06:36:43,021 [INFO    ] __main__: train step 14343: loss: 1.0741, policy_loss: 1.0340, value_loss: 0.5845
2024-07-14 06:36:43,311 [INFO    ] __main__: train step 14344: loss: 1.0741, policy_loss: 1.0340, value_loss: 0.5845
2024-07-14 06:36:44,933 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:36:45,418 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:36:45,492 [INFO    ] __main__: train step 14345: loss: 1.0741, policy_loss: 1.0340, value_loss: 0.5844
2024-07-14 06:36:45,792 [INFO    ] __main__: train step 14346: loss: 1.0740, policy_loss: 1.0340, value_loss: 0.5844
2024-07-14 06:36:46,088 [INFO    ] __main__: train step 14347: loss: 1.0740, policy_loss: 1.0339, value_loss: 0.5844
2024-07-14 06:36:46,370 [INFO    ] __main__: train step 14348: loss: 1.0740, policy_loss: 1.0339, value_loss: 0.5844
2024-07-14 06:36:46,667 [INFO    ] __main__: train step 14349: loss: 1.0740, policy_loss: 1.0339, value_loss: 0.5843
2024-07-14 06:36:46,949 [INFO    ] __main__: train step 14350: loss: 1.0740, policy_loss: 1.0338, value_loss: 0.5843
2024-07-14 06:36:47,234 [INFO    ] __main__: train step 14351: loss: 1.0739, policy_loss: 1.0338, value_loss: 0.5843
2024-07-14 06:36:47,528 [INFO    ] __main__: train step 14352: loss: 1.0739, policy_loss: 1.0338, value_loss: 0.5842
2024-07-14 06:36:47,815 [INFO    ] __main__: train step 14353: loss: 1.0739, policy_loss: 1.0338, value_loss: 0.5842
2024-07-14 06:36:48,108 [INFO    ] __main__: train step 14354: loss: 1.0739, policy_loss: 1.0337, value_loss: 0.5842
2024-07-14 06:36:48,406 [INFO    ] __main__: train step 14355: loss: 1.0739, policy_loss: 1.0337, value_loss: 0.5842
2024-07-14 06:36:48,689 [INFO    ] __main__: train step 14356: loss: 1.0739, policy_loss: 1.0337, value_loss: 0.5841
2024-07-14 06:36:48,983 [INFO    ] __main__: train step 14357: loss: 1.0738, policy_loss: 1.0336, value_loss: 0.5841
2024-07-14 06:36:49,277 [INFO    ] __main__: train step 14358: loss: 1.0738, policy_loss: 1.0336, value_loss: 0.5841
2024-07-14 06:36:49,569 [INFO    ] __main__: train step 14359: loss: 1.0738, policy_loss: 1.0336, value_loss: 0.5840
2024-07-14 06:36:49,861 [INFO    ] __main__: train step 14360: loss: 1.0738, policy_loss: 1.0336, value_loss: 0.5840
2024-07-14 06:36:50,140 [INFO    ] __main__: train step 14361: loss: 1.0738, policy_loss: 1.0335, value_loss: 0.5840
2024-07-14 06:36:51,766 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:36:52,260 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:36:52,331 [INFO    ] __main__: train step 14362: loss: 1.0737, policy_loss: 1.0335, value_loss: 0.5840
2024-07-14 06:36:52,641 [INFO    ] __main__: train step 14363: loss: 1.0737, policy_loss: 1.0335, value_loss: 0.5839
2024-07-14 06:36:52,936 [INFO    ] __main__: train step 14364: loss: 1.0737, policy_loss: 1.0334, value_loss: 0.5839
2024-07-14 06:36:53,236 [INFO    ] __main__: train step 14365: loss: 1.0737, policy_loss: 1.0334, value_loss: 0.5839
2024-07-14 06:36:53,528 [INFO    ] __main__: train step 14366: loss: 1.0737, policy_loss: 1.0334, value_loss: 0.5839
2024-07-14 06:36:53,826 [INFO    ] __main__: train step 14367: loss: 1.0737, policy_loss: 1.0334, value_loss: 0.5838
2024-07-14 06:36:54,121 [INFO    ] __main__: train step 14368: loss: 1.0736, policy_loss: 1.0333, value_loss: 0.5838
2024-07-14 06:36:54,422 [INFO    ] __main__: train step 14369: loss: 1.0736, policy_loss: 1.0333, value_loss: 0.5838
2024-07-14 06:36:54,708 [INFO    ] __main__: train step 14370: loss: 1.0736, policy_loss: 1.0333, value_loss: 0.5837
2024-07-14 06:36:54,996 [INFO    ] __main__: train step 14371: loss: 1.0736, policy_loss: 1.0332, value_loss: 0.5837
2024-07-14 06:36:55,296 [INFO    ] __main__: train step 14372: loss: 1.0736, policy_loss: 1.0332, value_loss: 0.5837
2024-07-14 06:36:55,594 [INFO    ] __main__: train step 14373: loss: 1.0735, policy_loss: 1.0332, value_loss: 0.5837
2024-07-14 06:36:55,900 [INFO    ] __main__: train step 14374: loss: 1.0735, policy_loss: 1.0332, value_loss: 0.5836
2024-07-14 06:36:56,204 [INFO    ] __main__: train step 14375: loss: 1.0735, policy_loss: 1.0331, value_loss: 0.5836
2024-07-14 06:36:56,503 [INFO    ] __main__: train step 14376: loss: 1.0735, policy_loss: 1.0331, value_loss: 0.5836
2024-07-14 06:36:56,810 [INFO    ] __main__: train step 14377: loss: 1.0735, policy_loss: 1.0331, value_loss: 0.5835
2024-07-14 06:36:57,118 [INFO    ] __main__: train step 14378: loss: 1.0735, policy_loss: 1.0331, value_loss: 0.5835
2024-07-14 06:36:58,744 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:36:59,224 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:36:59,295 [INFO    ] __main__: train step 14379: loss: 1.0734, policy_loss: 1.0330, value_loss: 0.5835
2024-07-14 06:36:59,585 [INFO    ] __main__: train step 14380: loss: 1.0734, policy_loss: 1.0330, value_loss: 0.5835
2024-07-14 06:36:59,888 [INFO    ] __main__: train step 14381: loss: 1.0734, policy_loss: 1.0330, value_loss: 0.5834
2024-07-14 06:37:00,177 [INFO    ] __main__: train step 14382: loss: 1.0734, policy_loss: 1.0329, value_loss: 0.5834
2024-07-14 06:37:00,469 [INFO    ] __main__: train step 14383: loss: 1.0734, policy_loss: 1.0329, value_loss: 0.5834
2024-07-14 06:37:00,767 [INFO    ] __main__: train step 14384: loss: 1.0733, policy_loss: 1.0329, value_loss: 0.5833
2024-07-14 06:37:01,070 [INFO    ] __main__: train step 14385: loss: 1.0733, policy_loss: 1.0329, value_loss: 0.5833
2024-07-14 06:37:01,365 [INFO    ] __main__: train step 14386: loss: 1.0733, policy_loss: 1.0328, value_loss: 0.5833
2024-07-14 06:37:01,660 [INFO    ] __main__: train step 14387: loss: 1.0733, policy_loss: 1.0328, value_loss: 0.5833
2024-07-14 06:37:01,952 [INFO    ] __main__: train step 14388: loss: 1.0733, policy_loss: 1.0328, value_loss: 0.5832
2024-07-14 06:37:02,257 [INFO    ] __main__: train step 14389: loss: 1.0732, policy_loss: 1.0327, value_loss: 0.5832
2024-07-14 06:37:02,556 [INFO    ] __main__: train step 14390: loss: 1.0732, policy_loss: 1.0327, value_loss: 0.5832
2024-07-14 06:37:02,851 [INFO    ] __main__: train step 14391: loss: 1.0732, policy_loss: 1.0327, value_loss: 0.5831
2024-07-14 06:37:03,151 [INFO    ] __main__: train step 14392: loss: 1.0732, policy_loss: 1.0327, value_loss: 0.5831
2024-07-14 06:37:03,454 [INFO    ] __main__: train step 14393: loss: 1.0732, policy_loss: 1.0326, value_loss: 0.5831
2024-07-14 06:37:03,752 [INFO    ] __main__: train step 14394: loss: 1.0732, policy_loss: 1.0326, value_loss: 0.5831
2024-07-14 06:37:04,052 [INFO    ] __main__: train step 14395: loss: 1.0731, policy_loss: 1.0326, value_loss: 0.5830
2024-07-14 06:37:05,671 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:37:06,171 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:37:06,241 [INFO    ] __main__: train step 14396: loss: 1.0731, policy_loss: 1.0325, value_loss: 0.5830
2024-07-14 06:37:06,534 [INFO    ] __main__: train step 14397: loss: 1.0731, policy_loss: 1.0325, value_loss: 0.5830
2024-07-14 06:37:06,833 [INFO    ] __main__: train step 14398: loss: 1.0731, policy_loss: 1.0325, value_loss: 0.5830
2024-07-14 06:37:07,116 [INFO    ] __main__: train step 14399: loss: 1.0731, policy_loss: 1.0325, value_loss: 0.5829
2024-07-14 06:37:09,174 [INFO    ] __main__: train step 14400: loss: 1.0730, policy_loss: 1.0324, value_loss: 0.5829
2024-07-14 06:37:09,467 [INFO    ] __main__: train step 14401: loss: 1.0730, policy_loss: 1.0324, value_loss: 0.5829
2024-07-14 06:37:09,763 [INFO    ] __main__: train step 14402: loss: 1.0730, policy_loss: 1.0324, value_loss: 0.5828
2024-07-14 06:37:10,052 [INFO    ] __main__: train step 14403: loss: 1.0730, policy_loss: 1.0323, value_loss: 0.5828
2024-07-14 06:37:10,340 [INFO    ] __main__: train step 14404: loss: 1.0730, policy_loss: 1.0323, value_loss: 0.5828
2024-07-14 06:37:10,618 [INFO    ] __main__: train step 14405: loss: 1.0729, policy_loss: 1.0323, value_loss: 0.5828
2024-07-14 06:37:10,916 [INFO    ] __main__: train step 14406: loss: 1.0729, policy_loss: 1.0323, value_loss: 0.5827
2024-07-14 06:37:11,207 [INFO    ] __main__: train step 14407: loss: 1.0729, policy_loss: 1.0322, value_loss: 0.5827
2024-07-14 06:37:11,495 [INFO    ] __main__: train step 14408: loss: 1.0729, policy_loss: 1.0322, value_loss: 0.5827
2024-07-14 06:37:11,792 [INFO    ] __main__: train step 14409: loss: 1.0729, policy_loss: 1.0322, value_loss: 0.5826
2024-07-14 06:37:12,087 [INFO    ] __main__: train step 14410: loss: 1.0729, policy_loss: 1.0321, value_loss: 0.5826
2024-07-14 06:37:12,386 [INFO    ] __main__: train step 14411: loss: 1.0728, policy_loss: 1.0321, value_loss: 0.5826
2024-07-14 06:37:12,671 [INFO    ] __main__: train step 14412: loss: 1.0728, policy_loss: 1.0321, value_loss: 0.5826
2024-07-14 06:37:14,288 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:37:14,781 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:37:14,849 [INFO    ] __main__: train step 14413: loss: 1.0728, policy_loss: 1.0321, value_loss: 0.5825
2024-07-14 06:37:15,139 [INFO    ] __main__: train step 14414: loss: 1.0728, policy_loss: 1.0320, value_loss: 0.5825
2024-07-14 06:37:15,430 [INFO    ] __main__: train step 14415: loss: 1.0728, policy_loss: 1.0320, value_loss: 0.5825
2024-07-14 06:37:15,709 [INFO    ] __main__: train step 14416: loss: 1.0727, policy_loss: 1.0320, value_loss: 0.5824
2024-07-14 06:37:15,987 [INFO    ] __main__: train step 14417: loss: 1.0727, policy_loss: 1.0319, value_loss: 0.5824
2024-07-14 06:37:16,272 [INFO    ] __main__: train step 14418: loss: 1.0727, policy_loss: 1.0319, value_loss: 0.5824
2024-07-14 06:37:16,555 [INFO    ] __main__: train step 14419: loss: 1.0727, policy_loss: 1.0319, value_loss: 0.5824
2024-07-14 06:37:16,841 [INFO    ] __main__: train step 14420: loss: 1.0727, policy_loss: 1.0319, value_loss: 0.5823
2024-07-14 06:37:17,127 [INFO    ] __main__: train step 14421: loss: 1.0726, policy_loss: 1.0318, value_loss: 0.5823
2024-07-14 06:37:17,425 [INFO    ] __main__: train step 14422: loss: 1.0726, policy_loss: 1.0318, value_loss: 0.5823
2024-07-14 06:37:17,715 [INFO    ] __main__: train step 14423: loss: 1.0726, policy_loss: 1.0318, value_loss: 0.5823
2024-07-14 06:37:18,016 [INFO    ] __main__: train step 14424: loss: 1.0726, policy_loss: 1.0317, value_loss: 0.5822
2024-07-14 06:37:18,308 [INFO    ] __main__: train step 14425: loss: 1.0726, policy_loss: 1.0317, value_loss: 0.5822
2024-07-14 06:37:18,609 [INFO    ] __main__: train step 14426: loss: 1.0725, policy_loss: 1.0317, value_loss: 0.5822
2024-07-14 06:37:18,905 [INFO    ] __main__: train step 14427: loss: 1.0725, policy_loss: 1.0317, value_loss: 0.5821
2024-07-14 06:37:19,211 [INFO    ] __main__: train step 14428: loss: 1.0725, policy_loss: 1.0316, value_loss: 0.5821
2024-07-14 06:37:19,508 [INFO    ] __main__: train step 14429: loss: 1.0725, policy_loss: 1.0316, value_loss: 0.5821
2024-07-14 06:37:21,113 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:37:21,600 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:37:21,669 [INFO    ] __main__: train step 14430: loss: 1.0725, policy_loss: 1.0316, value_loss: 0.5821
2024-07-14 06:37:21,966 [INFO    ] __main__: train step 14431: loss: 1.0725, policy_loss: 1.0315, value_loss: 0.5820
2024-07-14 06:37:22,264 [INFO    ] __main__: train step 14432: loss: 1.0724, policy_loss: 1.0315, value_loss: 0.5820
2024-07-14 06:37:22,552 [INFO    ] __main__: train step 14433: loss: 1.0724, policy_loss: 1.0315, value_loss: 0.5820
2024-07-14 06:37:22,847 [INFO    ] __main__: train step 14434: loss: 1.0724, policy_loss: 1.0315, value_loss: 0.5819
2024-07-14 06:37:23,144 [INFO    ] __main__: train step 14435: loss: 1.0724, policy_loss: 1.0314, value_loss: 0.5819
2024-07-14 06:37:23,446 [INFO    ] __main__: train step 14436: loss: 1.0723, policy_loss: 1.0314, value_loss: 0.5819
2024-07-14 06:37:23,740 [INFO    ] __main__: train step 14437: loss: 1.0723, policy_loss: 1.0314, value_loss: 0.5819
2024-07-14 06:37:24,022 [INFO    ] __main__: train step 14438: loss: 1.0723, policy_loss: 1.0313, value_loss: 0.5818
2024-07-14 06:37:24,318 [INFO    ] __main__: train step 14439: loss: 1.0723, policy_loss: 1.0313, value_loss: 0.5818
2024-07-14 06:37:24,611 [INFO    ] __main__: train step 14440: loss: 1.0723, policy_loss: 1.0313, value_loss: 0.5818
2024-07-14 06:37:24,903 [INFO    ] __main__: train step 14441: loss: 1.0723, policy_loss: 1.0313, value_loss: 0.5817
2024-07-14 06:37:25,201 [INFO    ] __main__: train step 14442: loss: 1.0722, policy_loss: 1.0312, value_loss: 0.5817
2024-07-14 06:37:25,500 [INFO    ] __main__: train step 14443: loss: 1.0722, policy_loss: 1.0312, value_loss: 0.5817
2024-07-14 06:37:25,805 [INFO    ] __main__: train step 14444: loss: 1.0722, policy_loss: 1.0312, value_loss: 0.5817
2024-07-14 06:37:26,090 [INFO    ] __main__: train step 14445: loss: 1.0722, policy_loss: 1.0311, value_loss: 0.5816
2024-07-14 06:37:26,372 [INFO    ] __main__: train step 14446: loss: 1.0722, policy_loss: 1.0311, value_loss: 0.5816
2024-07-14 06:37:27,969 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:37:28,457 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:37:28,529 [INFO    ] __main__: train step 14447: loss: 1.0721, policy_loss: 1.0311, value_loss: 0.5816
2024-07-14 06:37:28,837 [INFO    ] __main__: train step 14448: loss: 1.0721, policy_loss: 1.0311, value_loss: 0.5815
2024-07-14 06:37:29,123 [INFO    ] __main__: train step 14449: loss: 1.0721, policy_loss: 1.0310, value_loss: 0.5815
2024-07-14 06:37:29,407 [INFO    ] __main__: train step 14450: loss: 1.0721, policy_loss: 1.0310, value_loss: 0.5815
2024-07-14 06:37:29,699 [INFO    ] __main__: train step 14451: loss: 1.0721, policy_loss: 1.0310, value_loss: 0.5815
2024-07-14 06:37:29,993 [INFO    ] __main__: train step 14452: loss: 1.0720, policy_loss: 1.0309, value_loss: 0.5814
2024-07-14 06:37:30,281 [INFO    ] __main__: train step 14453: loss: 1.0720, policy_loss: 1.0309, value_loss: 0.5814
2024-07-14 06:37:30,575 [INFO    ] __main__: train step 14454: loss: 1.0720, policy_loss: 1.0309, value_loss: 0.5814
2024-07-14 06:37:30,868 [INFO    ] __main__: train step 14455: loss: 1.0720, policy_loss: 1.0309, value_loss: 0.5813
2024-07-14 06:37:31,158 [INFO    ] __main__: train step 14456: loss: 1.0720, policy_loss: 1.0308, value_loss: 0.5813
2024-07-14 06:37:31,443 [INFO    ] __main__: train step 14457: loss: 1.0719, policy_loss: 1.0308, value_loss: 0.5813
2024-07-14 06:37:31,734 [INFO    ] __main__: train step 14458: loss: 1.0719, policy_loss: 1.0308, value_loss: 0.5813
2024-07-14 06:37:32,025 [INFO    ] __main__: train step 14459: loss: 1.0719, policy_loss: 1.0307, value_loss: 0.5812
2024-07-14 06:37:32,322 [INFO    ] __main__: train step 14460: loss: 1.0719, policy_loss: 1.0307, value_loss: 0.5812
2024-07-14 06:37:32,611 [INFO    ] __main__: train step 14461: loss: 1.0719, policy_loss: 1.0307, value_loss: 0.5812
2024-07-14 06:37:32,889 [INFO    ] __main__: train step 14462: loss: 1.0718, policy_loss: 1.0307, value_loss: 0.5812
2024-07-14 06:37:33,164 [INFO    ] __main__: train step 14463: loss: 1.0718, policy_loss: 1.0306, value_loss: 0.5811
2024-07-14 06:37:34,782 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:37:35,282 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:37:35,354 [INFO    ] __main__: train step 14464: loss: 1.0718, policy_loss: 1.0306, value_loss: 0.5811
2024-07-14 06:37:35,637 [INFO    ] __main__: train step 14465: loss: 1.0718, policy_loss: 1.0306, value_loss: 0.5811
2024-07-14 06:37:35,917 [INFO    ] __main__: train step 14466: loss: 1.0718, policy_loss: 1.0305, value_loss: 0.5810
2024-07-14 06:37:36,213 [INFO    ] __main__: train step 14467: loss: 1.0718, policy_loss: 1.0305, value_loss: 0.5810
2024-07-14 06:37:36,504 [INFO    ] __main__: train step 14468: loss: 1.0717, policy_loss: 1.0305, value_loss: 0.5810
2024-07-14 06:37:36,807 [INFO    ] __main__: train step 14469: loss: 1.0717, policy_loss: 1.0305, value_loss: 0.5810
2024-07-14 06:37:37,086 [INFO    ] __main__: train step 14470: loss: 1.0717, policy_loss: 1.0304, value_loss: 0.5809
2024-07-14 06:37:37,402 [INFO    ] __main__: train step 14471: loss: 1.0717, policy_loss: 1.0304, value_loss: 0.5809
2024-07-14 06:37:37,683 [INFO    ] __main__: train step 14472: loss: 1.0717, policy_loss: 1.0304, value_loss: 0.5809
2024-07-14 06:37:37,972 [INFO    ] __main__: train step 14473: loss: 1.0716, policy_loss: 1.0303, value_loss: 0.5808
2024-07-14 06:37:38,261 [INFO    ] __main__: train step 14474: loss: 1.0716, policy_loss: 1.0303, value_loss: 0.5808
2024-07-14 06:37:38,554 [INFO    ] __main__: train step 14475: loss: 1.0716, policy_loss: 1.0303, value_loss: 0.5808
2024-07-14 06:37:38,840 [INFO    ] __main__: train step 14476: loss: 1.0716, policy_loss: 1.0303, value_loss: 0.5808
2024-07-14 06:37:39,107 [INFO    ] __main__: train step 14477: loss: 1.0716, policy_loss: 1.0302, value_loss: 0.5807
2024-07-14 06:37:39,379 [INFO    ] __main__: train step 14478: loss: 1.0715, policy_loss: 1.0302, value_loss: 0.5807
2024-07-14 06:37:39,647 [INFO    ] __main__: train step 14479: loss: 1.0715, policy_loss: 1.0302, value_loss: 0.5807
2024-07-14 06:37:39,938 [INFO    ] __main__: train step 14480: loss: 1.0715, policy_loss: 1.0301, value_loss: 0.5806
2024-07-14 06:37:41,533 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:37:42,024 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:37:42,096 [INFO    ] __main__: train step 14481: loss: 1.0715, policy_loss: 1.0301, value_loss: 0.5806
2024-07-14 06:37:42,364 [INFO    ] __main__: train step 14482: loss: 1.0715, policy_loss: 1.0301, value_loss: 0.5806
2024-07-14 06:37:42,645 [INFO    ] __main__: train step 14483: loss: 1.0714, policy_loss: 1.0301, value_loss: 0.5806
2024-07-14 06:37:42,933 [INFO    ] __main__: train step 14484: loss: 1.0714, policy_loss: 1.0300, value_loss: 0.5805
2024-07-14 06:37:43,225 [INFO    ] __main__: train step 14485: loss: 1.0714, policy_loss: 1.0300, value_loss: 0.5805
2024-07-14 06:37:43,519 [INFO    ] __main__: train step 14486: loss: 1.0714, policy_loss: 1.0300, value_loss: 0.5805
2024-07-14 06:37:43,806 [INFO    ] __main__: train step 14487: loss: 1.0714, policy_loss: 1.0300, value_loss: 0.5805
2024-07-14 06:37:44,101 [INFO    ] __main__: train step 14488: loss: 1.0714, policy_loss: 1.0299, value_loss: 0.5804
2024-07-14 06:37:44,400 [INFO    ] __main__: train step 14489: loss: 1.0713, policy_loss: 1.0299, value_loss: 0.5804
2024-07-14 06:37:46,484 [INFO    ] __main__: train step 14490: loss: 1.0713, policy_loss: 1.0299, value_loss: 0.5804
2024-07-14 06:37:46,778 [INFO    ] __main__: train step 14491: loss: 1.0713, policy_loss: 1.0298, value_loss: 0.5803
2024-07-14 06:37:47,071 [INFO    ] __main__: train step 14492: loss: 1.0713, policy_loss: 1.0298, value_loss: 0.5803
2024-07-14 06:37:47,366 [INFO    ] __main__: train step 14493: loss: 1.0713, policy_loss: 1.0298, value_loss: 0.5803
2024-07-14 06:37:47,647 [INFO    ] __main__: train step 14494: loss: 1.0712, policy_loss: 1.0297, value_loss: 0.5803
2024-07-14 06:37:47,947 [INFO    ] __main__: train step 14495: loss: 1.0712, policy_loss: 1.0297, value_loss: 0.5802
2024-07-14 06:37:48,233 [INFO    ] __main__: train step 14496: loss: 1.0712, policy_loss: 1.0297, value_loss: 0.5802
2024-07-14 06:37:48,535 [INFO    ] __main__: train step 14497: loss: 1.0712, policy_loss: 1.0297, value_loss: 0.5802
2024-07-14 06:37:50,169 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:37:50,660 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:37:50,730 [INFO    ] __main__: train step 14498: loss: 1.0712, policy_loss: 1.0296, value_loss: 0.5801
2024-07-14 06:37:51,024 [INFO    ] __main__: train step 14499: loss: 1.0711, policy_loss: 1.0296, value_loss: 0.5801
2024-07-14 06:37:51,315 [INFO    ] __main__: train step 14500: loss: 1.0711, policy_loss: 1.0296, value_loss: 0.5801
2024-07-14 06:37:51,608 [INFO    ] __main__: train step 14501: loss: 1.0711, policy_loss: 1.0295, value_loss: 0.5801
2024-07-14 06:37:51,900 [INFO    ] __main__: train step 14502: loss: 1.0711, policy_loss: 1.0295, value_loss: 0.5800
2024-07-14 06:37:52,193 [INFO    ] __main__: train step 14503: loss: 1.0711, policy_loss: 1.0295, value_loss: 0.5800
2024-07-14 06:37:52,494 [INFO    ] __main__: train step 14504: loss: 1.0710, policy_loss: 1.0295, value_loss: 0.5800
2024-07-14 06:37:52,785 [INFO    ] __main__: train step 14505: loss: 1.0710, policy_loss: 1.0294, value_loss: 0.5799
2024-07-14 06:37:53,078 [INFO    ] __main__: train step 14506: loss: 1.0710, policy_loss: 1.0294, value_loss: 0.5799
2024-07-14 06:37:53,374 [INFO    ] __main__: train step 14507: loss: 1.0710, policy_loss: 1.0294, value_loss: 0.5799
2024-07-14 06:37:53,662 [INFO    ] __main__: train step 14508: loss: 1.0710, policy_loss: 1.0294, value_loss: 0.5799
2024-07-14 06:37:53,953 [INFO    ] __main__: train step 14509: loss: 1.0709, policy_loss: 1.0293, value_loss: 0.5798
2024-07-14 06:37:54,250 [INFO    ] __main__: train step 14510: loss: 1.0709, policy_loss: 1.0293, value_loss: 0.5798
2024-07-14 06:37:54,547 [INFO    ] __main__: train step 14511: loss: 1.0709, policy_loss: 1.0293, value_loss: 0.5798
2024-07-14 06:37:54,840 [INFO    ] __main__: train step 14512: loss: 1.0709, policy_loss: 1.0292, value_loss: 0.5797
2024-07-14 06:37:55,127 [INFO    ] __main__: train step 14513: loss: 1.0709, policy_loss: 1.0292, value_loss: 0.5797
2024-07-14 06:37:55,415 [INFO    ] __main__: train step 14514: loss: 1.0708, policy_loss: 1.0292, value_loss: 0.5797
2024-07-14 06:37:57,044 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:37:57,539 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:37:57,610 [INFO    ] __main__: train step 14515: loss: 1.0708, policy_loss: 1.0292, value_loss: 0.5797
2024-07-14 06:37:57,908 [INFO    ] __main__: train step 14516: loss: 1.0708, policy_loss: 1.0291, value_loss: 0.5796
2024-07-14 06:37:58,199 [INFO    ] __main__: train step 14517: loss: 1.0708, policy_loss: 1.0291, value_loss: 0.5796
2024-07-14 06:37:58,480 [INFO    ] __main__: train step 14518: loss: 1.0708, policy_loss: 1.0291, value_loss: 0.5796
2024-07-14 06:37:58,773 [INFO    ] __main__: train step 14519: loss: 1.0708, policy_loss: 1.0290, value_loss: 0.5796
2024-07-14 06:37:59,064 [INFO    ] __main__: train step 14520: loss: 1.0707, policy_loss: 1.0290, value_loss: 0.5795
2024-07-14 06:37:59,353 [INFO    ] __main__: train step 14521: loss: 1.0707, policy_loss: 1.0290, value_loss: 0.5795
2024-07-14 06:37:59,644 [INFO    ] __main__: train step 14522: loss: 1.0707, policy_loss: 1.0290, value_loss: 0.5795
2024-07-14 06:37:59,947 [INFO    ] __main__: train step 14523: loss: 1.0707, policy_loss: 1.0289, value_loss: 0.5794
2024-07-14 06:38:00,241 [INFO    ] __main__: train step 14524: loss: 1.0707, policy_loss: 1.0289, value_loss: 0.5794
2024-07-14 06:38:00,531 [INFO    ] __main__: train step 14525: loss: 1.0706, policy_loss: 1.0289, value_loss: 0.5794
2024-07-14 06:38:00,832 [INFO    ] __main__: train step 14526: loss: 1.0706, policy_loss: 1.0288, value_loss: 0.5794
2024-07-14 06:38:01,123 [INFO    ] __main__: train step 14527: loss: 1.0706, policy_loss: 1.0288, value_loss: 0.5793
2024-07-14 06:38:01,415 [INFO    ] __main__: train step 14528: loss: 1.0706, policy_loss: 1.0288, value_loss: 0.5793
2024-07-14 06:38:01,709 [INFO    ] __main__: train step 14529: loss: 1.0706, policy_loss: 1.0288, value_loss: 0.5793
2024-07-14 06:38:01,996 [INFO    ] __main__: train step 14530: loss: 1.0705, policy_loss: 1.0287, value_loss: 0.5792
2024-07-14 06:38:02,295 [INFO    ] __main__: train step 14531: loss: 1.0705, policy_loss: 1.0287, value_loss: 0.5792
2024-07-14 06:38:03,898 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:38:04,392 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:38:04,463 [INFO    ] __main__: train step 14532: loss: 1.0705, policy_loss: 1.0287, value_loss: 0.5792
2024-07-14 06:38:04,727 [INFO    ] __main__: train step 14533: loss: 1.0705, policy_loss: 1.0286, value_loss: 0.5792
2024-07-14 06:38:05,018 [INFO    ] __main__: train step 14534: loss: 1.0705, policy_loss: 1.0286, value_loss: 0.5791
2024-07-14 06:38:05,312 [INFO    ] __main__: train step 14535: loss: 1.0704, policy_loss: 1.0286, value_loss: 0.5791
2024-07-14 06:38:05,593 [INFO    ] __main__: train step 14536: loss: 1.0704, policy_loss: 1.0286, value_loss: 0.5791
2024-07-14 06:38:05,878 [INFO    ] __main__: train step 14537: loss: 1.0704, policy_loss: 1.0285, value_loss: 0.5791
2024-07-14 06:38:06,167 [INFO    ] __main__: train step 14538: loss: 1.0704, policy_loss: 1.0285, value_loss: 0.5790
2024-07-14 06:38:06,457 [INFO    ] __main__: train step 14539: loss: 1.0704, policy_loss: 1.0285, value_loss: 0.5790
2024-07-14 06:38:06,741 [INFO    ] __main__: train step 14540: loss: 1.0704, policy_loss: 1.0284, value_loss: 0.5790
2024-07-14 06:38:07,031 [INFO    ] __main__: train step 14541: loss: 1.0703, policy_loss: 1.0284, value_loss: 0.5789
2024-07-14 06:38:07,327 [INFO    ] __main__: train step 14542: loss: 1.0703, policy_loss: 1.0284, value_loss: 0.5789
2024-07-14 06:38:07,616 [INFO    ] __main__: train step 14543: loss: 1.0703, policy_loss: 1.0284, value_loss: 0.5789
2024-07-14 06:38:07,902 [INFO    ] __main__: train step 14544: loss: 1.0703, policy_loss: 1.0283, value_loss: 0.5789
2024-07-14 06:38:08,181 [INFO    ] __main__: train step 14545: loss: 1.0702, policy_loss: 1.0283, value_loss: 0.5788
2024-07-14 06:38:08,471 [INFO    ] __main__: train step 14546: loss: 1.0702, policy_loss: 1.0283, value_loss: 0.5788
2024-07-14 06:38:08,764 [INFO    ] __main__: train step 14547: loss: 1.0702, policy_loss: 1.0282, value_loss: 0.5788
2024-07-14 06:38:09,050 [INFO    ] __main__: train step 14548: loss: 1.0702, policy_loss: 1.0282, value_loss: 0.5787
2024-07-14 06:38:10,669 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:38:11,159 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:38:11,227 [INFO    ] __main__: train step 14549: loss: 1.0702, policy_loss: 1.0282, value_loss: 0.5787
2024-07-14 06:38:11,509 [INFO    ] __main__: train step 14550: loss: 1.0702, policy_loss: 1.0282, value_loss: 0.5787
2024-07-14 06:38:11,786 [INFO    ] __main__: train step 14551: loss: 1.0701, policy_loss: 1.0281, value_loss: 0.5787
2024-07-14 06:38:12,068 [INFO    ] __main__: train step 14552: loss: 1.0701, policy_loss: 1.0281, value_loss: 0.5786
2024-07-14 06:38:12,356 [INFO    ] __main__: train step 14553: loss: 1.0701, policy_loss: 1.0281, value_loss: 0.5786
2024-07-14 06:38:12,648 [INFO    ] __main__: train step 14554: loss: 1.0701, policy_loss: 1.0280, value_loss: 0.5786
2024-07-14 06:38:12,936 [INFO    ] __main__: train step 14555: loss: 1.0701, policy_loss: 1.0280, value_loss: 0.5786
2024-07-14 06:38:13,218 [INFO    ] __main__: train step 14556: loss: 1.0700, policy_loss: 1.0280, value_loss: 0.5785
2024-07-14 06:38:13,501 [INFO    ] __main__: train step 14557: loss: 1.0700, policy_loss: 1.0280, value_loss: 0.5785
2024-07-14 06:38:13,791 [INFO    ] __main__: train step 14558: loss: 1.0700, policy_loss: 1.0279, value_loss: 0.5785
2024-07-14 06:38:14,094 [INFO    ] __main__: train step 14559: loss: 1.0700, policy_loss: 1.0279, value_loss: 0.5784
2024-07-14 06:38:14,393 [INFO    ] __main__: train step 14560: loss: 1.0700, policy_loss: 1.0279, value_loss: 0.5784
2024-07-14 06:38:14,679 [INFO    ] __main__: train step 14561: loss: 1.0699, policy_loss: 1.0278, value_loss: 0.5784
2024-07-14 06:38:14,968 [INFO    ] __main__: train step 14562: loss: 1.0699, policy_loss: 1.0278, value_loss: 0.5784
2024-07-14 06:38:15,237 [INFO    ] __main__: train step 14563: loss: 1.0699, policy_loss: 1.0278, value_loss: 0.5783
2024-07-14 06:38:15,530 [INFO    ] __main__: train step 14564: loss: 1.0699, policy_loss: 1.0278, value_loss: 0.5783
2024-07-14 06:38:15,824 [INFO    ] __main__: train step 14565: loss: 1.0699, policy_loss: 1.0277, value_loss: 0.5783
2024-07-14 06:38:17,433 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:38:17,918 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:38:17,989 [INFO    ] __main__: train step 14566: loss: 1.0698, policy_loss: 1.0277, value_loss: 0.5782
2024-07-14 06:38:18,257 [INFO    ] __main__: train step 14567: loss: 1.0698, policy_loss: 1.0277, value_loss: 0.5782
2024-07-14 06:38:18,539 [INFO    ] __main__: train step 14568: loss: 1.0698, policy_loss: 1.0276, value_loss: 0.5782
2024-07-14 06:38:18,819 [INFO    ] __main__: train step 14569: loss: 1.0698, policy_loss: 1.0276, value_loss: 0.5782
2024-07-14 06:38:19,107 [INFO    ] __main__: train step 14570: loss: 1.0698, policy_loss: 1.0276, value_loss: 0.5781
2024-07-14 06:38:19,378 [INFO    ] __main__: train step 14571: loss: 1.0697, policy_loss: 1.0276, value_loss: 0.5781
2024-07-14 06:38:19,644 [INFO    ] __main__: train step 14572: loss: 1.0697, policy_loss: 1.0275, value_loss: 0.5781
2024-07-14 06:38:19,939 [INFO    ] __main__: train step 14573: loss: 1.0697, policy_loss: 1.0275, value_loss: 0.5780
2024-07-14 06:38:20,223 [INFO    ] __main__: train step 14574: loss: 1.0697, policy_loss: 1.0275, value_loss: 0.5780
2024-07-14 06:38:20,516 [INFO    ] __main__: train step 14575: loss: 1.0697, policy_loss: 1.0275, value_loss: 0.5780
2024-07-14 06:38:20,806 [INFO    ] __main__: train step 14576: loss: 1.0696, policy_loss: 1.0274, value_loss: 0.5780
2024-07-14 06:38:21,099 [INFO    ] __main__: train step 14577: loss: 1.0696, policy_loss: 1.0274, value_loss: 0.5779
2024-07-14 06:38:23,219 [INFO    ] __main__: train step 14578: loss: 1.0696, policy_loss: 1.0274, value_loss: 0.5779
2024-07-14 06:38:23,519 [INFO    ] __main__: train step 14579: loss: 1.0696, policy_loss: 1.0273, value_loss: 0.5779
2024-07-14 06:38:23,811 [INFO    ] __main__: train step 14580: loss: 1.0696, policy_loss: 1.0273, value_loss: 0.5779
2024-07-14 06:38:24,083 [INFO    ] __main__: train step 14581: loss: 1.0695, policy_loss: 1.0273, value_loss: 0.5778
2024-07-14 06:38:24,372 [INFO    ] __main__: train step 14582: loss: 1.0695, policy_loss: 1.0273, value_loss: 0.5778
2024-07-14 06:38:26,002 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:38:26,484 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:38:26,552 [INFO    ] __main__: train step 14583: loss: 1.0695, policy_loss: 1.0272, value_loss: 0.5778
2024-07-14 06:38:26,817 [INFO    ] __main__: train step 14584: loss: 1.0695, policy_loss: 1.0272, value_loss: 0.5777
2024-07-14 06:38:27,096 [INFO    ] __main__: train step 14585: loss: 1.0695, policy_loss: 1.0272, value_loss: 0.5777
2024-07-14 06:38:27,369 [INFO    ] __main__: train step 14586: loss: 1.0695, policy_loss: 1.0271, value_loss: 0.5777
2024-07-14 06:38:27,652 [INFO    ] __main__: train step 14587: loss: 1.0694, policy_loss: 1.0271, value_loss: 0.5777
2024-07-14 06:38:27,946 [INFO    ] __main__: train step 14588: loss: 1.0694, policy_loss: 1.0271, value_loss: 0.5776
2024-07-14 06:38:28,240 [INFO    ] __main__: train step 14589: loss: 1.0694, policy_loss: 1.0270, value_loss: 0.5776
2024-07-14 06:38:28,531 [INFO    ] __main__: train step 14590: loss: 1.0694, policy_loss: 1.0270, value_loss: 0.5776
2024-07-14 06:38:28,824 [INFO    ] __main__: train step 14591: loss: 1.0693, policy_loss: 1.0270, value_loss: 0.5775
2024-07-14 06:38:29,113 [INFO    ] __main__: train step 14592: loss: 1.0693, policy_loss: 1.0270, value_loss: 0.5775
2024-07-14 06:38:29,409 [INFO    ] __main__: train step 14593: loss: 1.0693, policy_loss: 1.0269, value_loss: 0.5775
2024-07-14 06:38:29,706 [INFO    ] __main__: train step 14594: loss: 1.0693, policy_loss: 1.0269, value_loss: 0.5775
2024-07-14 06:38:29,971 [INFO    ] __main__: train step 14595: loss: 1.0693, policy_loss: 1.0269, value_loss: 0.5774
2024-07-14 06:38:30,258 [INFO    ] __main__: train step 14596: loss: 1.0693, policy_loss: 1.0268, value_loss: 0.5774
2024-07-14 06:38:30,551 [INFO    ] __main__: train step 14597: loss: 1.0692, policy_loss: 1.0268, value_loss: 0.5774
2024-07-14 06:38:30,851 [INFO    ] __main__: train step 14598: loss: 1.0692, policy_loss: 1.0268, value_loss: 0.5774
2024-07-14 06:38:31,146 [INFO    ] __main__: train step 14599: loss: 1.0692, policy_loss: 1.0268, value_loss: 0.5773
2024-07-14 06:38:32,743 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:38:33,238 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:38:33,308 [INFO    ] __main__: train step 14600: loss: 1.0692, policy_loss: 1.0267, value_loss: 0.5773
2024-07-14 06:38:33,601 [INFO    ] __main__: train step 14601: loss: 1.0692, policy_loss: 1.0267, value_loss: 0.5773
2024-07-14 06:38:33,884 [INFO    ] __main__: train step 14602: loss: 1.0691, policy_loss: 1.0267, value_loss: 0.5772
2024-07-14 06:38:34,164 [INFO    ] __main__: train step 14603: loss: 1.0691, policy_loss: 1.0266, value_loss: 0.5772
2024-07-14 06:38:34,450 [INFO    ] __main__: train step 14604: loss: 1.0691, policy_loss: 1.0266, value_loss: 0.5772
2024-07-14 06:38:34,744 [INFO    ] __main__: train step 14605: loss: 1.0691, policy_loss: 1.0266, value_loss: 0.5772
2024-07-14 06:38:35,033 [INFO    ] __main__: train step 14606: loss: 1.0691, policy_loss: 1.0266, value_loss: 0.5771
2024-07-14 06:38:35,339 [INFO    ] __main__: train step 14607: loss: 1.0690, policy_loss: 1.0265, value_loss: 0.5771
2024-07-14 06:38:35,618 [INFO    ] __main__: train step 14608: loss: 1.0690, policy_loss: 1.0265, value_loss: 0.5771
2024-07-14 06:38:35,915 [INFO    ] __main__: train step 14609: loss: 1.0690, policy_loss: 1.0265, value_loss: 0.5770
2024-07-14 06:38:36,214 [INFO    ] __main__: train step 14610: loss: 1.0690, policy_loss: 1.0264, value_loss: 0.5770
2024-07-14 06:38:36,510 [INFO    ] __main__: train step 14611: loss: 1.0690, policy_loss: 1.0264, value_loss: 0.5770
2024-07-14 06:38:36,800 [INFO    ] __main__: train step 14612: loss: 1.0689, policy_loss: 1.0264, value_loss: 0.5770
2024-07-14 06:38:37,094 [INFO    ] __main__: train step 14613: loss: 1.0689, policy_loss: 1.0264, value_loss: 0.5769
2024-07-14 06:38:37,394 [INFO    ] __main__: train step 14614: loss: 1.0689, policy_loss: 1.0263, value_loss: 0.5769
2024-07-14 06:38:37,667 [INFO    ] __main__: train step 14615: loss: 1.0689, policy_loss: 1.0263, value_loss: 0.5769
2024-07-14 06:38:37,966 [INFO    ] __main__: train step 14616: loss: 1.0689, policy_loss: 1.0263, value_loss: 0.5769
2024-07-14 06:38:39,588 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:38:40,072 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:38:40,144 [INFO    ] __main__: train step 14617: loss: 1.0688, policy_loss: 1.0262, value_loss: 0.5768
2024-07-14 06:38:40,434 [INFO    ] __main__: train step 14618: loss: 1.0688, policy_loss: 1.0262, value_loss: 0.5768
2024-07-14 06:38:40,725 [INFO    ] __main__: train step 14619: loss: 1.0688, policy_loss: 1.0262, value_loss: 0.5768
2024-07-14 06:38:41,005 [INFO    ] __main__: train step 14620: loss: 1.0688, policy_loss: 1.0262, value_loss: 0.5767
2024-07-14 06:38:41,298 [INFO    ] __main__: train step 14621: loss: 1.0688, policy_loss: 1.0261, value_loss: 0.5767
2024-07-14 06:38:41,601 [INFO    ] __main__: train step 14622: loss: 1.0687, policy_loss: 1.0261, value_loss: 0.5767
2024-07-14 06:38:41,907 [INFO    ] __main__: train step 14623: loss: 1.0687, policy_loss: 1.0261, value_loss: 0.5767
2024-07-14 06:38:42,202 [INFO    ] __main__: train step 14624: loss: 1.0687, policy_loss: 1.0260, value_loss: 0.5766
2024-07-14 06:38:42,495 [INFO    ] __main__: train step 14625: loss: 1.0687, policy_loss: 1.0260, value_loss: 0.5766
2024-07-14 06:38:42,780 [INFO    ] __main__: train step 14626: loss: 1.0687, policy_loss: 1.0260, value_loss: 0.5766
2024-07-14 06:38:43,080 [INFO    ] __main__: train step 14627: loss: 1.0686, policy_loss: 1.0260, value_loss: 0.5765
2024-07-14 06:38:43,369 [INFO    ] __main__: train step 14628: loss: 1.0686, policy_loss: 1.0259, value_loss: 0.5765
2024-07-14 06:38:43,675 [INFO    ] __main__: train step 14629: loss: 1.0686, policy_loss: 1.0259, value_loss: 0.5765
2024-07-14 06:38:43,963 [INFO    ] __main__: train step 14630: loss: 1.0686, policy_loss: 1.0259, value_loss: 0.5765
2024-07-14 06:38:44,262 [INFO    ] __main__: train step 14631: loss: 1.0686, policy_loss: 1.0258, value_loss: 0.5764
2024-07-14 06:38:44,560 [INFO    ] __main__: train step 14632: loss: 1.0685, policy_loss: 1.0258, value_loss: 0.5764
2024-07-14 06:38:44,859 [INFO    ] __main__: train step 14633: loss: 1.0685, policy_loss: 1.0258, value_loss: 0.5764
2024-07-14 06:38:46,485 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:38:46,978 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:38:47,048 [INFO    ] __main__: train step 14634: loss: 1.0685, policy_loss: 1.0258, value_loss: 0.5763
2024-07-14 06:38:47,340 [INFO    ] __main__: train step 14635: loss: 1.0685, policy_loss: 1.0257, value_loss: 0.5763
2024-07-14 06:38:47,635 [INFO    ] __main__: train step 14636: loss: 1.0685, policy_loss: 1.0257, value_loss: 0.5763
2024-07-14 06:38:47,920 [INFO    ] __main__: train step 14637: loss: 1.0684, policy_loss: 1.0257, value_loss: 0.5763
2024-07-14 06:38:48,213 [INFO    ] __main__: train step 14638: loss: 1.0684, policy_loss: 1.0256, value_loss: 0.5762
2024-07-14 06:38:48,503 [INFO    ] __main__: train step 14639: loss: 1.0684, policy_loss: 1.0256, value_loss: 0.5762
2024-07-14 06:38:48,797 [INFO    ] __main__: train step 14640: loss: 1.0684, policy_loss: 1.0256, value_loss: 0.5762
2024-07-14 06:38:49,093 [INFO    ] __main__: train step 14641: loss: 1.0684, policy_loss: 1.0256, value_loss: 0.5762
2024-07-14 06:38:49,376 [INFO    ] __main__: train step 14642: loss: 1.0683, policy_loss: 1.0255, value_loss: 0.5761
2024-07-14 06:38:49,667 [INFO    ] __main__: train step 14643: loss: 1.0683, policy_loss: 1.0255, value_loss: 0.5761
2024-07-14 06:38:49,953 [INFO    ] __main__: train step 14644: loss: 1.0683, policy_loss: 1.0255, value_loss: 0.5761
2024-07-14 06:38:50,237 [INFO    ] __main__: train step 14645: loss: 1.0683, policy_loss: 1.0254, value_loss: 0.5760
2024-07-14 06:38:50,522 [INFO    ] __main__: train step 14646: loss: 1.0683, policy_loss: 1.0254, value_loss: 0.5760
2024-07-14 06:38:50,808 [INFO    ] __main__: train step 14647: loss: 1.0682, policy_loss: 1.0254, value_loss: 0.5760
2024-07-14 06:38:51,081 [INFO    ] __main__: train step 14648: loss: 1.0682, policy_loss: 1.0254, value_loss: 0.5760
2024-07-14 06:38:51,358 [INFO    ] __main__: train step 14649: loss: 1.0682, policy_loss: 1.0253, value_loss: 0.5759
2024-07-14 06:38:51,627 [INFO    ] __main__: train step 14650: loss: 1.0682, policy_loss: 1.0253, value_loss: 0.5759
2024-07-14 06:38:53,211 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:38:53,678 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:38:53,750 [INFO    ] __main__: train step 14651: loss: 1.0682, policy_loss: 1.0253, value_loss: 0.5759
2024-07-14 06:38:54,041 [INFO    ] __main__: train step 14652: loss: 1.0681, policy_loss: 1.0252, value_loss: 0.5758
2024-07-14 06:38:54,345 [INFO    ] __main__: train step 14653: loss: 1.0681, policy_loss: 1.0252, value_loss: 0.5758
2024-07-14 06:38:54,635 [INFO    ] __main__: train step 14654: loss: 1.0681, policy_loss: 1.0252, value_loss: 0.5758
2024-07-14 06:38:54,921 [INFO    ] __main__: train step 14655: loss: 1.0681, policy_loss: 1.0252, value_loss: 0.5758
2024-07-14 06:38:55,205 [INFO    ] __main__: train step 14656: loss: 1.0681, policy_loss: 1.0251, value_loss: 0.5757
2024-07-14 06:38:55,490 [INFO    ] __main__: train step 14657: loss: 1.0680, policy_loss: 1.0251, value_loss: 0.5757
2024-07-14 06:38:55,778 [INFO    ] __main__: train step 14658: loss: 1.0680, policy_loss: 1.0251, value_loss: 0.5757
2024-07-14 06:38:56,074 [INFO    ] __main__: train step 14659: loss: 1.0680, policy_loss: 1.0250, value_loss: 0.5756
2024-07-14 06:38:56,365 [INFO    ] __main__: train step 14660: loss: 1.0680, policy_loss: 1.0250, value_loss: 0.5756
2024-07-14 06:38:56,657 [INFO    ] __main__: train step 14661: loss: 1.0680, policy_loss: 1.0250, value_loss: 0.5756
2024-07-14 06:38:56,946 [INFO    ] __main__: train step 14662: loss: 1.0679, policy_loss: 1.0250, value_loss: 0.5756
2024-07-14 06:38:57,231 [INFO    ] __main__: train step 14663: loss: 1.0679, policy_loss: 1.0249, value_loss: 0.5755
2024-07-14 06:38:57,529 [INFO    ] __main__: train step 14664: loss: 1.0679, policy_loss: 1.0249, value_loss: 0.5755
2024-07-14 06:38:57,818 [INFO    ] __main__: train step 14665: loss: 1.0679, policy_loss: 1.0249, value_loss: 0.5755
2024-07-14 06:38:58,109 [INFO    ] __main__: train step 14666: loss: 1.0679, policy_loss: 1.0249, value_loss: 0.5755
2024-07-14 06:39:00,156 [INFO    ] __main__: train step 14667: loss: 1.0678, policy_loss: 1.0248, value_loss: 0.5754
2024-07-14 06:39:01,756 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:39:02,242 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:39:02,313 [INFO    ] __main__: train step 14668: loss: 1.0678, policy_loss: 1.0248, value_loss: 0.5754
2024-07-14 06:39:02,602 [INFO    ] __main__: train step 14669: loss: 1.0678, policy_loss: 1.0248, value_loss: 0.5754
2024-07-14 06:39:02,894 [INFO    ] __main__: train step 14670: loss: 1.0678, policy_loss: 1.0247, value_loss: 0.5753
2024-07-14 06:39:03,186 [INFO    ] __main__: train step 14671: loss: 1.0678, policy_loss: 1.0247, value_loss: 0.5753
2024-07-14 06:39:03,493 [INFO    ] __main__: train step 14672: loss: 1.0677, policy_loss: 1.0247, value_loss: 0.5753
2024-07-14 06:39:03,793 [INFO    ] __main__: train step 14673: loss: 1.0677, policy_loss: 1.0247, value_loss: 0.5753
2024-07-14 06:39:04,084 [INFO    ] __main__: train step 14674: loss: 1.0677, policy_loss: 1.0246, value_loss: 0.5752
2024-07-14 06:39:04,375 [INFO    ] __main__: train step 14675: loss: 1.0677, policy_loss: 1.0246, value_loss: 0.5752
2024-07-14 06:39:04,664 [INFO    ] __main__: train step 14676: loss: 1.0677, policy_loss: 1.0246, value_loss: 0.5752
2024-07-14 06:39:04,967 [INFO    ] __main__: train step 14677: loss: 1.0676, policy_loss: 1.0245, value_loss: 0.5752
2024-07-14 06:39:05,262 [INFO    ] __main__: train step 14678: loss: 1.0676, policy_loss: 1.0245, value_loss: 0.5751
2024-07-14 06:39:05,561 [INFO    ] __main__: train step 14679: loss: 1.0676, policy_loss: 1.0245, value_loss: 0.5751
2024-07-14 06:39:05,867 [INFO    ] __main__: train step 14680: loss: 1.0676, policy_loss: 1.0245, value_loss: 0.5751
2024-07-14 06:39:06,181 [INFO    ] __main__: train step 14681: loss: 1.0676, policy_loss: 1.0244, value_loss: 0.5750
2024-07-14 06:39:06,442 [INFO    ] __main__: train step 14682: loss: 1.0675, policy_loss: 1.0244, value_loss: 0.5750
2024-07-14 06:39:06,739 [INFO    ] __main__: train step 14683: loss: 1.0675, policy_loss: 1.0244, value_loss: 0.5750
2024-07-14 06:39:07,019 [INFO    ] __main__: train step 14684: loss: 1.0675, policy_loss: 1.0243, value_loss: 0.5750
2024-07-14 06:39:08,639 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:39:09,135 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:39:09,205 [INFO    ] __main__: train step 14685: loss: 1.0675, policy_loss: 1.0243, value_loss: 0.5749
2024-07-14 06:39:09,507 [INFO    ] __main__: train step 14686: loss: 1.0675, policy_loss: 1.0243, value_loss: 0.5749
2024-07-14 06:39:09,788 [INFO    ] __main__: train step 14687: loss: 1.0674, policy_loss: 1.0243, value_loss: 0.5749
2024-07-14 06:39:10,073 [INFO    ] __main__: train step 14688: loss: 1.0674, policy_loss: 1.0242, value_loss: 0.5748
2024-07-14 06:39:10,367 [INFO    ] __main__: train step 14689: loss: 1.0674, policy_loss: 1.0242, value_loss: 0.5748
2024-07-14 06:39:10,657 [INFO    ] __main__: train step 14690: loss: 1.0674, policy_loss: 1.0242, value_loss: 0.5748
2024-07-14 06:39:10,948 [INFO    ] __main__: train step 14691: loss: 1.0674, policy_loss: 1.0241, value_loss: 0.5748
2024-07-14 06:39:11,242 [INFO    ] __main__: train step 14692: loss: 1.0673, policy_loss: 1.0241, value_loss: 0.5747
2024-07-14 06:39:11,529 [INFO    ] __main__: train step 14693: loss: 1.0673, policy_loss: 1.0241, value_loss: 0.5747
2024-07-14 06:39:11,824 [INFO    ] __main__: train step 14694: loss: 1.0673, policy_loss: 1.0241, value_loss: 0.5747
2024-07-14 06:39:12,114 [INFO    ] __main__: train step 14695: loss: 1.0673, policy_loss: 1.0240, value_loss: 0.5747
2024-07-14 06:39:12,393 [INFO    ] __main__: train step 14696: loss: 1.0673, policy_loss: 1.0240, value_loss: 0.5746
2024-07-14 06:39:12,688 [INFO    ] __main__: train step 14697: loss: 1.0672, policy_loss: 1.0240, value_loss: 0.5746
2024-07-14 06:39:12,985 [INFO    ] __main__: train step 14698: loss: 1.0672, policy_loss: 1.0239, value_loss: 0.5746
2024-07-14 06:39:13,275 [INFO    ] __main__: train step 14699: loss: 1.0672, policy_loss: 1.0239, value_loss: 0.5745
2024-07-14 06:39:13,570 [INFO    ] __main__: train step 14700: loss: 1.0672, policy_loss: 1.0239, value_loss: 0.5745
2024-07-14 06:39:13,868 [INFO    ] __main__: train step 14701: loss: 1.0672, policy_loss: 1.0239, value_loss: 0.5745
2024-07-14 06:39:15,484 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:39:15,972 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:39:16,042 [INFO    ] __main__: train step 14702: loss: 1.0671, policy_loss: 1.0238, value_loss: 0.5745
2024-07-14 06:39:16,338 [INFO    ] __main__: train step 14703: loss: 1.0671, policy_loss: 1.0238, value_loss: 0.5744
2024-07-14 06:39:16,633 [INFO    ] __main__: train step 14704: loss: 1.0671, policy_loss: 1.0238, value_loss: 0.5744
2024-07-14 06:39:16,933 [INFO    ] __main__: train step 14705: loss: 1.0671, policy_loss: 1.0237, value_loss: 0.5744
2024-07-14 06:39:17,229 [INFO    ] __main__: train step 14706: loss: 1.0671, policy_loss: 1.0237, value_loss: 0.5743
2024-07-14 06:39:17,525 [INFO    ] __main__: train step 14707: loss: 1.0670, policy_loss: 1.0237, value_loss: 0.5743
2024-07-14 06:39:17,808 [INFO    ] __main__: train step 14708: loss: 1.0670, policy_loss: 1.0237, value_loss: 0.5743
2024-07-14 06:39:18,100 [INFO    ] __main__: train step 14709: loss: 1.0670, policy_loss: 1.0236, value_loss: 0.5743
2024-07-14 06:39:18,384 [INFO    ] __main__: train step 14710: loss: 1.0670, policy_loss: 1.0236, value_loss: 0.5742
2024-07-14 06:39:18,689 [INFO    ] __main__: train step 14711: loss: 1.0670, policy_loss: 1.0236, value_loss: 0.5742
2024-07-14 06:39:18,987 [INFO    ] __main__: train step 14712: loss: 1.0669, policy_loss: 1.0235, value_loss: 0.5742
2024-07-14 06:39:19,279 [INFO    ] __main__: train step 14713: loss: 1.0669, policy_loss: 1.0235, value_loss: 0.5741
2024-07-14 06:39:19,574 [INFO    ] __main__: train step 14714: loss: 1.0669, policy_loss: 1.0235, value_loss: 0.5741
2024-07-14 06:39:19,867 [INFO    ] __main__: train step 14715: loss: 1.0669, policy_loss: 1.0235, value_loss: 0.5741
2024-07-14 06:39:20,163 [INFO    ] __main__: train step 14716: loss: 1.0669, policy_loss: 1.0234, value_loss: 0.5741
2024-07-14 06:39:20,455 [INFO    ] __main__: train step 14717: loss: 1.0668, policy_loss: 1.0234, value_loss: 0.5740
2024-07-14 06:39:20,741 [INFO    ] __main__: train step 14718: loss: 1.0668, policy_loss: 1.0234, value_loss: 0.5740
2024-07-14 06:39:22,346 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:39:22,836 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:39:22,905 [INFO    ] __main__: train step 14719: loss: 1.0668, policy_loss: 1.0233, value_loss: 0.5740
2024-07-14 06:39:23,201 [INFO    ] __main__: train step 14720: loss: 1.0668, policy_loss: 1.0233, value_loss: 0.5740
2024-07-14 06:39:23,494 [INFO    ] __main__: train step 14721: loss: 1.0668, policy_loss: 1.0233, value_loss: 0.5739
2024-07-14 06:39:23,788 [INFO    ] __main__: train step 14722: loss: 1.0667, policy_loss: 1.0233, value_loss: 0.5739
2024-07-14 06:39:24,088 [INFO    ] __main__: train step 14723: loss: 1.0667, policy_loss: 1.0232, value_loss: 0.5739
2024-07-14 06:39:24,361 [INFO    ] __main__: train step 14724: loss: 1.0667, policy_loss: 1.0232, value_loss: 0.5738
2024-07-14 06:39:24,650 [INFO    ] __main__: train step 14725: loss: 1.0667, policy_loss: 1.0232, value_loss: 0.5738
2024-07-14 06:39:24,944 [INFO    ] __main__: train step 14726: loss: 1.0667, policy_loss: 1.0231, value_loss: 0.5738
2024-07-14 06:39:25,240 [INFO    ] __main__: train step 14727: loss: 1.0666, policy_loss: 1.0231, value_loss: 0.5738
2024-07-14 06:39:25,536 [INFO    ] __main__: train step 14728: loss: 1.0666, policy_loss: 1.0231, value_loss: 0.5737
2024-07-14 06:39:25,824 [INFO    ] __main__: train step 14729: loss: 1.0666, policy_loss: 1.0231, value_loss: 0.5737
2024-07-14 06:39:26,112 [INFO    ] __main__: train step 14730: loss: 1.0666, policy_loss: 1.0230, value_loss: 0.5737
2024-07-14 06:39:26,398 [INFO    ] __main__: train step 14731: loss: 1.0666, policy_loss: 1.0230, value_loss: 0.5737
2024-07-14 06:39:26,684 [INFO    ] __main__: train step 14732: loss: 1.0665, policy_loss: 1.0230, value_loss: 0.5736
2024-07-14 06:39:26,977 [INFO    ] __main__: train step 14733: loss: 1.0665, policy_loss: 1.0229, value_loss: 0.5736
2024-07-14 06:39:27,276 [INFO    ] __main__: train step 14734: loss: 1.0665, policy_loss: 1.0229, value_loss: 0.5736
2024-07-14 06:39:27,575 [INFO    ] __main__: train step 14735: loss: 1.0665, policy_loss: 1.0229, value_loss: 0.5735
2024-07-14 06:39:29,209 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:39:29,692 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:39:29,765 [INFO    ] __main__: train step 14736: loss: 1.0665, policy_loss: 1.0229, value_loss: 0.5735
2024-07-14 06:39:30,073 [INFO    ] __main__: train step 14737: loss: 1.0664, policy_loss: 1.0228, value_loss: 0.5735
2024-07-14 06:39:30,350 [INFO    ] __main__: train step 14738: loss: 1.0664, policy_loss: 1.0228, value_loss: 0.5735
2024-07-14 06:39:30,645 [INFO    ] __main__: train step 14739: loss: 1.0664, policy_loss: 1.0228, value_loss: 0.5734
2024-07-14 06:39:30,933 [INFO    ] __main__: train step 14740: loss: 1.0664, policy_loss: 1.0228, value_loss: 0.5734
2024-07-14 06:39:31,216 [INFO    ] __main__: train step 14741: loss: 1.0664, policy_loss: 1.0227, value_loss: 0.5734
2024-07-14 06:39:31,517 [INFO    ] __main__: train step 14742: loss: 1.0663, policy_loss: 1.0227, value_loss: 0.5733
2024-07-14 06:39:31,820 [INFO    ] __main__: train step 14743: loss: 1.0663, policy_loss: 1.0227, value_loss: 0.5733
2024-07-14 06:39:32,114 [INFO    ] __main__: train step 14744: loss: 1.0663, policy_loss: 1.0226, value_loss: 0.5733
2024-07-14 06:39:32,409 [INFO    ] __main__: train step 14745: loss: 1.0663, policy_loss: 1.0226, value_loss: 0.5733
2024-07-14 06:39:32,703 [INFO    ] __main__: train step 14746: loss: 1.0662, policy_loss: 1.0226, value_loss: 0.5732
2024-07-14 06:39:32,980 [INFO    ] __main__: train step 14747: loss: 1.0662, policy_loss: 1.0226, value_loss: 0.5732
2024-07-14 06:39:33,269 [INFO    ] __main__: train step 14748: loss: 1.0662, policy_loss: 1.0225, value_loss: 0.5732
2024-07-14 06:39:33,559 [INFO    ] __main__: train step 14749: loss: 1.0662, policy_loss: 1.0225, value_loss: 0.5731
2024-07-14 06:39:33,854 [INFO    ] __main__: train step 14750: loss: 1.0662, policy_loss: 1.0225, value_loss: 0.5731
2024-07-14 06:39:34,134 [INFO    ] __main__: train step 14751: loss: 1.0662, policy_loss: 1.0224, value_loss: 0.5731
2024-07-14 06:39:34,421 [INFO    ] __main__: train step 14752: loss: 1.0661, policy_loss: 1.0224, value_loss: 0.5731
2024-07-14 06:39:36,031 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:39:36,516 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:39:36,584 [INFO    ] __main__: train step 14753: loss: 1.0661, policy_loss: 1.0224, value_loss: 0.5730
2024-07-14 06:39:36,877 [INFO    ] __main__: train step 14754: loss: 1.0661, policy_loss: 1.0224, value_loss: 0.5730
2024-07-14 06:39:37,159 [INFO    ] __main__: train step 14755: loss: 1.0661, policy_loss: 1.0223, value_loss: 0.5730
2024-07-14 06:39:40,031 [INFO    ] __main__: train step 14756: loss: 1.0660, policy_loss: 1.0223, value_loss: 0.5730
2024-07-14 06:39:40,348 [INFO    ] __main__: train step 14757: loss: 1.0660, policy_loss: 1.0223, value_loss: 0.5729
2024-07-14 06:39:40,638 [INFO    ] __main__: train step 14758: loss: 1.0660, policy_loss: 1.0222, value_loss: 0.5729
2024-07-14 06:39:40,932 [INFO    ] __main__: train step 14759: loss: 1.0660, policy_loss: 1.0222, value_loss: 0.5729
2024-07-14 06:39:41,220 [INFO    ] __main__: train step 14760: loss: 1.0660, policy_loss: 1.0222, value_loss: 0.5728
2024-07-14 06:39:41,506 [INFO    ] __main__: train step 14761: loss: 1.0659, policy_loss: 1.0222, value_loss: 0.5728
2024-07-14 06:39:41,806 [INFO    ] __main__: train step 14762: loss: 1.0659, policy_loss: 1.0221, value_loss: 0.5728
2024-07-14 06:39:42,100 [INFO    ] __main__: train step 14763: loss: 1.0659, policy_loss: 1.0221, value_loss: 0.5728
2024-07-14 06:39:42,393 [INFO    ] __main__: train step 14764: loss: 1.0659, policy_loss: 1.0221, value_loss: 0.5727
2024-07-14 06:39:42,689 [INFO    ] __main__: train step 14765: loss: 1.0659, policy_loss: 1.0220, value_loss: 0.5727
2024-07-14 06:39:42,976 [INFO    ] __main__: train step 14766: loss: 1.0658, policy_loss: 1.0220, value_loss: 0.5727
2024-07-14 06:39:43,271 [INFO    ] __main__: train step 14767: loss: 1.0658, policy_loss: 1.0220, value_loss: 0.5726
2024-07-14 06:39:43,568 [INFO    ] __main__: train step 14768: loss: 1.0658, policy_loss: 1.0220, value_loss: 0.5726
2024-07-14 06:39:43,861 [INFO    ] __main__: train step 14769: loss: 1.0658, policy_loss: 1.0219, value_loss: 0.5726
2024-07-14 06:39:45,465 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:39:45,957 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:39:46,026 [INFO    ] __main__: train step 14770: loss: 1.0658, policy_loss: 1.0219, value_loss: 0.5726
2024-07-14 06:39:46,322 [INFO    ] __main__: train step 14771: loss: 1.0657, policy_loss: 1.0219, value_loss: 0.5725
2024-07-14 06:39:46,597 [INFO    ] __main__: train step 14772: loss: 1.0657, policy_loss: 1.0218, value_loss: 0.5725
2024-07-14 06:39:46,884 [INFO    ] __main__: train step 14773: loss: 1.0657, policy_loss: 1.0218, value_loss: 0.5725
2024-07-14 06:39:47,165 [INFO    ] __main__: train step 14774: loss: 1.0657, policy_loss: 1.0218, value_loss: 0.5725
2024-07-14 06:39:47,461 [INFO    ] __main__: train step 14775: loss: 1.0657, policy_loss: 1.0218, value_loss: 0.5724
2024-07-14 06:39:47,751 [INFO    ] __main__: train step 14776: loss: 1.0656, policy_loss: 1.0217, value_loss: 0.5724
2024-07-14 06:39:48,008 [INFO    ] __main__: train step 14777: loss: 1.0656, policy_loss: 1.0217, value_loss: 0.5724
2024-07-14 06:39:48,288 [INFO    ] __main__: train step 14778: loss: 1.0656, policy_loss: 1.0217, value_loss: 0.5723
2024-07-14 06:39:48,575 [INFO    ] __main__: train step 14779: loss: 1.0656, policy_loss: 1.0216, value_loss: 0.5723
2024-07-14 06:39:48,864 [INFO    ] __main__: train step 14780: loss: 1.0656, policy_loss: 1.0216, value_loss: 0.5723
2024-07-14 06:39:49,160 [INFO    ] __main__: train step 14781: loss: 1.0655, policy_loss: 1.0216, value_loss: 0.5723
2024-07-14 06:39:49,448 [INFO    ] __main__: train step 14782: loss: 1.0655, policy_loss: 1.0216, value_loss: 0.5722
2024-07-14 06:39:49,740 [INFO    ] __main__: train step 14783: loss: 1.0655, policy_loss: 1.0215, value_loss: 0.5722
2024-07-14 06:39:50,040 [INFO    ] __main__: train step 14784: loss: 1.0655, policy_loss: 1.0215, value_loss: 0.5722
2024-07-14 06:39:50,331 [INFO    ] __main__: train step 14785: loss: 1.0655, policy_loss: 1.0215, value_loss: 0.5721
2024-07-14 06:39:50,615 [INFO    ] __main__: train step 14786: loss: 1.0654, policy_loss: 1.0214, value_loss: 0.5721
2024-07-14 06:39:52,238 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:39:52,718 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:39:52,786 [INFO    ] __main__: train step 14787: loss: 1.0654, policy_loss: 1.0214, value_loss: 0.5721
2024-07-14 06:39:53,062 [INFO    ] __main__: train step 14788: loss: 1.0654, policy_loss: 1.0214, value_loss: 0.5721
2024-07-14 06:39:53,341 [INFO    ] __main__: train step 14789: loss: 1.0654, policy_loss: 1.0214, value_loss: 0.5720
2024-07-14 06:39:53,614 [INFO    ] __main__: train step 14790: loss: 1.0654, policy_loss: 1.0213, value_loss: 0.5720
2024-07-14 06:39:53,891 [INFO    ] __main__: train step 14791: loss: 1.0653, policy_loss: 1.0213, value_loss: 0.5720
2024-07-14 06:39:54,180 [INFO    ] __main__: train step 14792: loss: 1.0653, policy_loss: 1.0213, value_loss: 0.5720
2024-07-14 06:39:54,488 [INFO    ] __main__: train step 14793: loss: 1.0653, policy_loss: 1.0212, value_loss: 0.5719
2024-07-14 06:39:54,772 [INFO    ] __main__: train step 14794: loss: 1.0653, policy_loss: 1.0212, value_loss: 0.5719
2024-07-14 06:39:55,057 [INFO    ] __main__: train step 14795: loss: 1.0652, policy_loss: 1.0212, value_loss: 0.5719
2024-07-14 06:39:55,343 [INFO    ] __main__: train step 14796: loss: 1.0652, policy_loss: 1.0212, value_loss: 0.5718
2024-07-14 06:39:55,630 [INFO    ] __main__: train step 14797: loss: 1.0652, policy_loss: 1.0211, value_loss: 0.5718
2024-07-14 06:39:55,930 [INFO    ] __main__: train step 14798: loss: 1.0652, policy_loss: 1.0211, value_loss: 0.5718
2024-07-14 06:39:56,223 [INFO    ] __main__: train step 14799: loss: 1.0652, policy_loss: 1.0211, value_loss: 0.5718
2024-07-14 06:39:56,515 [INFO    ] __main__: train step 14800: loss: 1.0651, policy_loss: 1.0210, value_loss: 0.5717
2024-07-14 06:39:56,809 [INFO    ] __main__: train step 14801: loss: 1.0651, policy_loss: 1.0210, value_loss: 0.5717
2024-07-14 06:39:57,105 [INFO    ] __main__: train step 14802: loss: 1.0651, policy_loss: 1.0210, value_loss: 0.5717
2024-07-14 06:39:57,408 [INFO    ] __main__: train step 14803: loss: 1.0651, policy_loss: 1.0210, value_loss: 0.5716
2024-07-14 06:39:59,035 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:39:59,526 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:39:59,602 [INFO    ] __main__: train step 14804: loss: 1.0651, policy_loss: 1.0209, value_loss: 0.5716
2024-07-14 06:39:59,890 [INFO    ] __main__: train step 14805: loss: 1.0650, policy_loss: 1.0209, value_loss: 0.5716
2024-07-14 06:40:00,168 [INFO    ] __main__: train step 14806: loss: 1.0650, policy_loss: 1.0209, value_loss: 0.5716
2024-07-14 06:40:00,464 [INFO    ] __main__: train step 14807: loss: 1.0650, policy_loss: 1.0208, value_loss: 0.5715
2024-07-14 06:40:00,752 [INFO    ] __main__: train step 14808: loss: 1.0650, policy_loss: 1.0208, value_loss: 0.5715
2024-07-14 06:40:01,043 [INFO    ] __main__: train step 14809: loss: 1.0650, policy_loss: 1.0208, value_loss: 0.5715
2024-07-14 06:40:01,345 [INFO    ] __main__: train step 14810: loss: 1.0649, policy_loss: 1.0208, value_loss: 0.5715
2024-07-14 06:40:01,633 [INFO    ] __main__: train step 14811: loss: 1.0649, policy_loss: 1.0207, value_loss: 0.5714
2024-07-14 06:40:01,925 [INFO    ] __main__: train step 14812: loss: 1.0649, policy_loss: 1.0207, value_loss: 0.5714
2024-07-14 06:40:02,213 [INFO    ] __main__: train step 14813: loss: 1.0649, policy_loss: 1.0207, value_loss: 0.5714
2024-07-14 06:40:02,513 [INFO    ] __main__: train step 14814: loss: 1.0649, policy_loss: 1.0206, value_loss: 0.5713
2024-07-14 06:40:02,811 [INFO    ] __main__: train step 14815: loss: 1.0648, policy_loss: 1.0206, value_loss: 0.5713
2024-07-14 06:40:03,100 [INFO    ] __main__: train step 14816: loss: 1.0648, policy_loss: 1.0206, value_loss: 0.5713
2024-07-14 06:40:03,402 [INFO    ] __main__: train step 14817: loss: 1.0648, policy_loss: 1.0206, value_loss: 0.5713
2024-07-14 06:40:03,706 [INFO    ] __main__: train step 14818: loss: 1.0648, policy_loss: 1.0205, value_loss: 0.5712
2024-07-14 06:40:03,997 [INFO    ] __main__: train step 14819: loss: 1.0648, policy_loss: 1.0205, value_loss: 0.5712
2024-07-14 06:40:04,297 [INFO    ] __main__: train step 14820: loss: 1.0647, policy_loss: 1.0205, value_loss: 0.5712
2024-07-14 06:40:05,903 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:40:06,408 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:40:06,479 [INFO    ] __main__: train step 14821: loss: 1.0647, policy_loss: 1.0204, value_loss: 0.5711
2024-07-14 06:40:06,754 [INFO    ] __main__: train step 14822: loss: 1.0647, policy_loss: 1.0204, value_loss: 0.5711
2024-07-14 06:40:07,041 [INFO    ] __main__: train step 14823: loss: 1.0647, policy_loss: 1.0204, value_loss: 0.5711
2024-07-14 06:40:07,329 [INFO    ] __main__: train step 14824: loss: 1.0647, policy_loss: 1.0204, value_loss: 0.5711
2024-07-14 06:40:07,615 [INFO    ] __main__: train step 14825: loss: 1.0646, policy_loss: 1.0203, value_loss: 0.5710
2024-07-14 06:40:07,895 [INFO    ] __main__: train step 14826: loss: 1.0646, policy_loss: 1.0203, value_loss: 0.5710
2024-07-14 06:40:08,177 [INFO    ] __main__: train step 14827: loss: 1.0646, policy_loss: 1.0203, value_loss: 0.5710
2024-07-14 06:40:08,475 [INFO    ] __main__: train step 14828: loss: 1.0646, policy_loss: 1.0202, value_loss: 0.5710
2024-07-14 06:40:08,763 [INFO    ] __main__: train step 14829: loss: 1.0646, policy_loss: 1.0202, value_loss: 0.5709
2024-07-14 06:40:09,048 [INFO    ] __main__: train step 14830: loss: 1.0645, policy_loss: 1.0202, value_loss: 0.5709
2024-07-14 06:40:09,336 [INFO    ] __main__: train step 14831: loss: 1.0645, policy_loss: 1.0202, value_loss: 0.5709
2024-07-14 06:40:09,627 [INFO    ] __main__: train step 14832: loss: 1.0645, policy_loss: 1.0201, value_loss: 0.5708
2024-07-14 06:40:09,911 [INFO    ] __main__: train step 14833: loss: 1.0645, policy_loss: 1.0201, value_loss: 0.5708
2024-07-14 06:40:10,194 [INFO    ] __main__: train step 14834: loss: 1.0644, policy_loss: 1.0201, value_loss: 0.5708
2024-07-14 06:40:10,481 [INFO    ] __main__: train step 14835: loss: 1.0644, policy_loss: 1.0200, value_loss: 0.5708
2024-07-14 06:40:10,758 [INFO    ] __main__: train step 14836: loss: 1.0644, policy_loss: 1.0200, value_loss: 0.5707
2024-07-14 06:40:11,045 [INFO    ] __main__: train step 14837: loss: 1.0644, policy_loss: 1.0200, value_loss: 0.5707
2024-07-14 06:40:12,650 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:40:13,144 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:40:13,217 [INFO    ] __main__: train step 14838: loss: 1.0644, policy_loss: 1.0200, value_loss: 0.5707
2024-07-14 06:40:13,484 [INFO    ] __main__: train step 14839: loss: 1.0643, policy_loss: 1.0199, value_loss: 0.5706
2024-07-14 06:40:13,757 [INFO    ] __main__: train step 14840: loss: 1.0643, policy_loss: 1.0199, value_loss: 0.5706
2024-07-14 06:40:14,061 [INFO    ] __main__: train step 14841: loss: 1.0643, policy_loss: 1.0199, value_loss: 0.5706
2024-07-14 06:40:14,345 [INFO    ] __main__: train step 14842: loss: 1.0643, policy_loss: 1.0198, value_loss: 0.5706
2024-07-14 06:40:16,413 [INFO    ] __main__: train step 14843: loss: 1.0643, policy_loss: 1.0198, value_loss: 0.5705
2024-07-14 06:40:16,702 [INFO    ] __main__: train step 14844: loss: 1.0642, policy_loss: 1.0198, value_loss: 0.5705
2024-07-14 06:40:16,993 [INFO    ] __main__: train step 14845: loss: 1.0642, policy_loss: 1.0198, value_loss: 0.5705
2024-07-14 06:40:17,282 [INFO    ] __main__: train step 14846: loss: 1.0642, policy_loss: 1.0197, value_loss: 0.5705
2024-07-14 06:40:17,575 [INFO    ] __main__: train step 14847: loss: 1.0642, policy_loss: 1.0197, value_loss: 0.5704
2024-07-14 06:40:17,870 [INFO    ] __main__: train step 14848: loss: 1.0641, policy_loss: 1.0197, value_loss: 0.5704
2024-07-14 06:40:18,166 [INFO    ] __main__: train step 14849: loss: 1.0641, policy_loss: 1.0196, value_loss: 0.5704
2024-07-14 06:40:18,457 [INFO    ] __main__: train step 14850: loss: 1.0641, policy_loss: 1.0196, value_loss: 0.5703
2024-07-14 06:40:18,756 [INFO    ] __main__: train step 14851: loss: 1.0641, policy_loss: 1.0196, value_loss: 0.5703
2024-07-14 06:40:19,059 [INFO    ] __main__: train step 14852: loss: 1.0641, policy_loss: 1.0196, value_loss: 0.5703
2024-07-14 06:40:19,369 [INFO    ] __main__: train step 14853: loss: 1.0640, policy_loss: 1.0195, value_loss: 0.5703
2024-07-14 06:40:19,670 [INFO    ] __main__: train step 14854: loss: 1.0640, policy_loss: 1.0195, value_loss: 0.5702
2024-07-14 06:40:21,271 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:40:21,763 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:40:21,839 [INFO    ] __main__: train step 14855: loss: 1.0640, policy_loss: 1.0195, value_loss: 0.5702
2024-07-14 06:40:22,126 [INFO    ] __main__: train step 14856: loss: 1.0640, policy_loss: 1.0194, value_loss: 0.5702
2024-07-14 06:40:22,405 [INFO    ] __main__: train step 14857: loss: 1.0640, policy_loss: 1.0194, value_loss: 0.5702
2024-07-14 06:40:22,688 [INFO    ] __main__: train step 14858: loss: 1.0639, policy_loss: 1.0194, value_loss: 0.5701
2024-07-14 06:40:22,984 [INFO    ] __main__: train step 14859: loss: 1.0639, policy_loss: 1.0194, value_loss: 0.5701
2024-07-14 06:40:23,266 [INFO    ] __main__: train step 14860: loss: 1.0639, policy_loss: 1.0193, value_loss: 0.5701
2024-07-14 06:40:23,561 [INFO    ] __main__: train step 14861: loss: 1.0639, policy_loss: 1.0193, value_loss: 0.5700
2024-07-14 06:40:23,844 [INFO    ] __main__: train step 14862: loss: 1.0639, policy_loss: 1.0193, value_loss: 0.5700
2024-07-14 06:40:24,143 [INFO    ] __main__: train step 14863: loss: 1.0638, policy_loss: 1.0192, value_loss: 0.5700
2024-07-14 06:40:24,430 [INFO    ] __main__: train step 14864: loss: 1.0638, policy_loss: 1.0192, value_loss: 0.5700
2024-07-14 06:40:24,705 [INFO    ] __main__: train step 14865: loss: 1.0638, policy_loss: 1.0192, value_loss: 0.5699
2024-07-14 06:40:24,999 [INFO    ] __main__: train step 14866: loss: 1.0638, policy_loss: 1.0192, value_loss: 0.5699
2024-07-14 06:40:25,290 [INFO    ] __main__: train step 14867: loss: 1.0638, policy_loss: 1.0191, value_loss: 0.5699
2024-07-14 06:40:25,587 [INFO    ] __main__: train step 14868: loss: 1.0637, policy_loss: 1.0191, value_loss: 0.5698
2024-07-14 06:40:25,889 [INFO    ] __main__: train step 14869: loss: 1.0637, policy_loss: 1.0191, value_loss: 0.5698
2024-07-14 06:40:26,182 [INFO    ] __main__: train step 14870: loss: 1.0637, policy_loss: 1.0190, value_loss: 0.5698
2024-07-14 06:40:26,468 [INFO    ] __main__: train step 14871: loss: 1.0637, policy_loss: 1.0190, value_loss: 0.5698
2024-07-14 06:40:28,092 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:40:28,580 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:40:28,649 [INFO    ] __main__: train step 14872: loss: 1.0636, policy_loss: 1.0190, value_loss: 0.5697
2024-07-14 06:40:28,946 [INFO    ] __main__: train step 14873: loss: 1.0636, policy_loss: 1.0190, value_loss: 0.5697
2024-07-14 06:40:29,245 [INFO    ] __main__: train step 14874: loss: 1.0636, policy_loss: 1.0189, value_loss: 0.5697
2024-07-14 06:40:29,531 [INFO    ] __main__: train step 14875: loss: 1.0636, policy_loss: 1.0189, value_loss: 0.5697
2024-07-14 06:40:29,825 [INFO    ] __main__: train step 14876: loss: 1.0636, policy_loss: 1.0189, value_loss: 0.5696
2024-07-14 06:40:30,116 [INFO    ] __main__: train step 14877: loss: 1.0635, policy_loss: 1.0188, value_loss: 0.5696
2024-07-14 06:40:30,413 [INFO    ] __main__: train step 14878: loss: 1.0635, policy_loss: 1.0188, value_loss: 0.5696
2024-07-14 06:40:30,713 [INFO    ] __main__: train step 14879: loss: 1.0635, policy_loss: 1.0188, value_loss: 0.5695
2024-07-14 06:40:30,998 [INFO    ] __main__: train step 14880: loss: 1.0635, policy_loss: 1.0188, value_loss: 0.5695
2024-07-14 06:40:31,293 [INFO    ] __main__: train step 14881: loss: 1.0635, policy_loss: 1.0187, value_loss: 0.5695
2024-07-14 06:40:31,582 [INFO    ] __main__: train step 14882: loss: 1.0634, policy_loss: 1.0187, value_loss: 0.5695
2024-07-14 06:40:31,872 [INFO    ] __main__: train step 14883: loss: 1.0634, policy_loss: 1.0187, value_loss: 0.5694
2024-07-14 06:40:32,175 [INFO    ] __main__: train step 14884: loss: 1.0634, policy_loss: 1.0186, value_loss: 0.5694
2024-07-14 06:40:32,471 [INFO    ] __main__: train step 14885: loss: 1.0634, policy_loss: 1.0186, value_loss: 0.5694
2024-07-14 06:40:32,768 [INFO    ] __main__: train step 14886: loss: 1.0634, policy_loss: 1.0186, value_loss: 0.5694
2024-07-14 06:40:33,050 [INFO    ] __main__: train step 14887: loss: 1.0633, policy_loss: 1.0186, value_loss: 0.5693
2024-07-14 06:40:33,342 [INFO    ] __main__: train step 14888: loss: 1.0633, policy_loss: 1.0185, value_loss: 0.5693
2024-07-14 06:40:34,972 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:40:35,471 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:40:35,544 [INFO    ] __main__: train step 14889: loss: 1.0633, policy_loss: 1.0185, value_loss: 0.5693
2024-07-14 06:40:35,835 [INFO    ] __main__: train step 14890: loss: 1.0633, policy_loss: 1.0185, value_loss: 0.5692
2024-07-14 06:40:36,122 [INFO    ] __main__: train step 14891: loss: 1.0633, policy_loss: 1.0184, value_loss: 0.5692
2024-07-14 06:40:36,407 [INFO    ] __main__: train step 14892: loss: 1.0632, policy_loss: 1.0184, value_loss: 0.5692
2024-07-14 06:40:36,699 [INFO    ] __main__: train step 14893: loss: 1.0632, policy_loss: 1.0184, value_loss: 0.5692
2024-07-14 06:40:36,996 [INFO    ] __main__: train step 14894: loss: 1.0632, policy_loss: 1.0184, value_loss: 0.5691
2024-07-14 06:40:37,288 [INFO    ] __main__: train step 14895: loss: 1.0632, policy_loss: 1.0183, value_loss: 0.5691
2024-07-14 06:40:37,582 [INFO    ] __main__: train step 14896: loss: 1.0631, policy_loss: 1.0183, value_loss: 0.5691
2024-07-14 06:40:37,883 [INFO    ] __main__: train step 14897: loss: 1.0631, policy_loss: 1.0183, value_loss: 0.5690
2024-07-14 06:40:38,179 [INFO    ] __main__: train step 14898: loss: 1.0631, policy_loss: 1.0182, value_loss: 0.5690
2024-07-14 06:40:38,459 [INFO    ] __main__: train step 14899: loss: 1.0631, policy_loss: 1.0182, value_loss: 0.5690
2024-07-14 06:40:38,749 [INFO    ] __main__: train step 14900: loss: 1.0631, policy_loss: 1.0182, value_loss: 0.5690
2024-07-14 06:40:39,043 [INFO    ] __main__: train step 14901: loss: 1.0630, policy_loss: 1.0182, value_loss: 0.5689
2024-07-14 06:40:39,337 [INFO    ] __main__: train step 14902: loss: 1.0630, policy_loss: 1.0181, value_loss: 0.5689
2024-07-14 06:40:39,630 [INFO    ] __main__: train step 14903: loss: 1.0630, policy_loss: 1.0181, value_loss: 0.5689
2024-07-14 06:40:39,926 [INFO    ] __main__: train step 14904: loss: 1.0630, policy_loss: 1.0181, value_loss: 0.5689
2024-07-14 06:40:40,211 [INFO    ] __main__: train step 14905: loss: 1.0630, policy_loss: 1.0180, value_loss: 0.5688
2024-07-14 06:40:41,835 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:40:42,307 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:40:42,379 [INFO    ] __main__: train step 14906: loss: 1.0629, policy_loss: 1.0180, value_loss: 0.5688
2024-07-14 06:40:42,669 [INFO    ] __main__: train step 14907: loss: 1.0629, policy_loss: 1.0180, value_loss: 0.5688
2024-07-14 06:40:42,945 [INFO    ] __main__: train step 14908: loss: 1.0629, policy_loss: 1.0180, value_loss: 0.5687
2024-07-14 06:40:43,233 [INFO    ] __main__: train step 14909: loss: 1.0629, policy_loss: 1.0179, value_loss: 0.5687
2024-07-14 06:40:43,520 [INFO    ] __main__: train step 14910: loss: 1.0628, policy_loss: 1.0179, value_loss: 0.5687
2024-07-14 06:40:43,807 [INFO    ] __main__: train step 14911: loss: 1.0628, policy_loss: 1.0179, value_loss: 0.5687
2024-07-14 06:40:44,103 [INFO    ] __main__: train step 14912: loss: 1.0628, policy_loss: 1.0178, value_loss: 0.5686
2024-07-14 06:40:44,398 [INFO    ] __main__: train step 14913: loss: 1.0628, policy_loss: 1.0178, value_loss: 0.5686
2024-07-14 06:40:44,685 [INFO    ] __main__: train step 14914: loss: 1.0628, policy_loss: 1.0178, value_loss: 0.5686
2024-07-14 06:40:44,970 [INFO    ] __main__: train step 14915: loss: 1.0627, policy_loss: 1.0178, value_loss: 0.5685
2024-07-14 06:40:45,244 [INFO    ] __main__: train step 14916: loss: 1.0627, policy_loss: 1.0177, value_loss: 0.5685
2024-07-14 06:40:45,551 [INFO    ] __main__: train step 14917: loss: 1.0627, policy_loss: 1.0177, value_loss: 0.5685
2024-07-14 06:40:45,846 [INFO    ] __main__: train step 14918: loss: 1.0627, policy_loss: 1.0177, value_loss: 0.5685
2024-07-14 06:40:46,143 [INFO    ] __main__: train step 14919: loss: 1.0627, policy_loss: 1.0176, value_loss: 0.5684
2024-07-14 06:40:46,431 [INFO    ] __main__: train step 14920: loss: 1.0626, policy_loss: 1.0176, value_loss: 0.5684
2024-07-14 06:40:46,716 [INFO    ] __main__: train step 14921: loss: 1.0626, policy_loss: 1.0176, value_loss: 0.5684
2024-07-14 06:40:47,009 [INFO    ] __main__: train step 14922: loss: 1.0626, policy_loss: 1.0176, value_loss: 0.5684
2024-07-14 06:40:48,635 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:40:49,118 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:40:49,189 [INFO    ] __main__: train step 14923: loss: 1.0626, policy_loss: 1.0175, value_loss: 0.5683
2024-07-14 06:40:49,476 [INFO    ] __main__: train step 14924: loss: 1.0626, policy_loss: 1.0175, value_loss: 0.5683
2024-07-14 06:40:49,770 [INFO    ] __main__: train step 14925: loss: 1.0625, policy_loss: 1.0175, value_loss: 0.5683
2024-07-14 06:40:50,059 [INFO    ] __main__: train step 14926: loss: 1.0625, policy_loss: 1.0174, value_loss: 0.5682
2024-07-14 06:40:50,348 [INFO    ] __main__: train step 14927: loss: 1.0625, policy_loss: 1.0174, value_loss: 0.5682
2024-07-14 06:40:50,642 [INFO    ] __main__: train step 14928: loss: 1.0625, policy_loss: 1.0174, value_loss: 0.5682
2024-07-14 06:40:50,933 [INFO    ] __main__: train step 14929: loss: 1.0624, policy_loss: 1.0174, value_loss: 0.5682
2024-07-14 06:40:51,229 [INFO    ] __main__: train step 14930: loss: 1.0624, policy_loss: 1.0173, value_loss: 0.5681
2024-07-14 06:40:51,530 [INFO    ] __main__: train step 14931: loss: 1.0624, policy_loss: 1.0173, value_loss: 0.5681
2024-07-14 06:40:53,551 [INFO    ] __main__: train step 14932: loss: 1.0624, policy_loss: 1.0173, value_loss: 0.5681
2024-07-14 06:40:53,853 [INFO    ] __main__: train step 14933: loss: 1.0624, policy_loss: 1.0172, value_loss: 0.5680
2024-07-14 06:40:54,147 [INFO    ] __main__: train step 14934: loss: 1.0623, policy_loss: 1.0172, value_loss: 0.5680
2024-07-14 06:40:54,442 [INFO    ] __main__: train step 14935: loss: 1.0623, policy_loss: 1.0172, value_loss: 0.5680
2024-07-14 06:40:54,747 [INFO    ] __main__: train step 14936: loss: 1.0623, policy_loss: 1.0172, value_loss: 0.5680
2024-07-14 06:40:55,049 [INFO    ] __main__: train step 14937: loss: 1.0623, policy_loss: 1.0171, value_loss: 0.5679
2024-07-14 06:40:55,338 [INFO    ] __main__: train step 14938: loss: 1.0623, policy_loss: 1.0171, value_loss: 0.5679
2024-07-14 06:40:55,634 [INFO    ] __main__: train step 14939: loss: 1.0622, policy_loss: 1.0171, value_loss: 0.5679
2024-07-14 06:40:57,212 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:40:57,705 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:40:57,773 [INFO    ] __main__: train step 14940: loss: 1.0622, policy_loss: 1.0171, value_loss: 0.5678
2024-07-14 06:40:58,061 [INFO    ] __main__: train step 14941: loss: 1.0622, policy_loss: 1.0170, value_loss: 0.5678
2024-07-14 06:40:58,350 [INFO    ] __main__: train step 14942: loss: 1.0622, policy_loss: 1.0170, value_loss: 0.5678
2024-07-14 06:40:58,644 [INFO    ] __main__: train step 14943: loss: 1.0622, policy_loss: 1.0170, value_loss: 0.5678
2024-07-14 06:40:58,931 [INFO    ] __main__: train step 14944: loss: 1.0621, policy_loss: 1.0169, value_loss: 0.5677
2024-07-14 06:40:59,235 [INFO    ] __main__: train step 14945: loss: 1.0621, policy_loss: 1.0169, value_loss: 0.5677
2024-07-14 06:40:59,525 [INFO    ] __main__: train step 14946: loss: 1.0621, policy_loss: 1.0169, value_loss: 0.5677
2024-07-14 06:40:59,816 [INFO    ] __main__: train step 14947: loss: 1.0621, policy_loss: 1.0169, value_loss: 0.5677
2024-07-14 06:41:00,102 [INFO    ] __main__: train step 14948: loss: 1.0620, policy_loss: 1.0168, value_loss: 0.5676
2024-07-14 06:41:00,385 [INFO    ] __main__: train step 14949: loss: 1.0620, policy_loss: 1.0168, value_loss: 0.5676
2024-07-14 06:41:00,680 [INFO    ] __main__: train step 14950: loss: 1.0620, policy_loss: 1.0168, value_loss: 0.5676
2024-07-14 06:41:00,970 [INFO    ] __main__: train step 14951: loss: 1.0620, policy_loss: 1.0167, value_loss: 0.5675
2024-07-14 06:41:01,266 [INFO    ] __main__: train step 14952: loss: 1.0620, policy_loss: 1.0167, value_loss: 0.5675
2024-07-14 06:41:01,555 [INFO    ] __main__: train step 14953: loss: 1.0619, policy_loss: 1.0167, value_loss: 0.5675
2024-07-14 06:41:01,849 [INFO    ] __main__: train step 14954: loss: 1.0619, policy_loss: 1.0167, value_loss: 0.5675
2024-07-14 06:41:02,148 [INFO    ] __main__: train step 14955: loss: 1.0619, policy_loss: 1.0166, value_loss: 0.5674
2024-07-14 06:41:02,444 [INFO    ] __main__: train step 14956: loss: 1.0619, policy_loss: 1.0166, value_loss: 0.5674
2024-07-14 06:41:04,061 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:41:04,548 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:41:04,620 [INFO    ] __main__: train step 14957: loss: 1.0619, policy_loss: 1.0166, value_loss: 0.5674
2024-07-14 06:41:04,910 [INFO    ] __main__: train step 14958: loss: 1.0618, policy_loss: 1.0165, value_loss: 0.5674
2024-07-14 06:41:05,204 [INFO    ] __main__: train step 14959: loss: 1.0618, policy_loss: 1.0165, value_loss: 0.5673
2024-07-14 06:41:05,496 [INFO    ] __main__: train step 14960: loss: 1.0618, policy_loss: 1.0165, value_loss: 0.5673
2024-07-14 06:41:05,782 [INFO    ] __main__: train step 14961: loss: 1.0618, policy_loss: 1.0165, value_loss: 0.5673
2024-07-14 06:41:06,072 [INFO    ] __main__: train step 14962: loss: 1.0618, policy_loss: 1.0164, value_loss: 0.5672
2024-07-14 06:41:06,368 [INFO    ] __main__: train step 14963: loss: 1.0617, policy_loss: 1.0164, value_loss: 0.5672
2024-07-14 06:41:06,652 [INFO    ] __main__: train step 14964: loss: 1.0617, policy_loss: 1.0164, value_loss: 0.5672
2024-07-14 06:41:06,951 [INFO    ] __main__: train step 14965: loss: 1.0617, policy_loss: 1.0163, value_loss: 0.5672
2024-07-14 06:41:07,239 [INFO    ] __main__: train step 14966: loss: 1.0617, policy_loss: 1.0163, value_loss: 0.5671
2024-07-14 06:41:07,529 [INFO    ] __main__: train step 14967: loss: 1.0616, policy_loss: 1.0163, value_loss: 0.5671
2024-07-14 06:41:07,816 [INFO    ] __main__: train step 14968: loss: 1.0616, policy_loss: 1.0163, value_loss: 0.5671
2024-07-14 06:41:08,119 [INFO    ] __main__: train step 14969: loss: 1.0616, policy_loss: 1.0162, value_loss: 0.5670
2024-07-14 06:41:08,418 [INFO    ] __main__: train step 14970: loss: 1.0616, policy_loss: 1.0162, value_loss: 0.5670
2024-07-14 06:41:08,714 [INFO    ] __main__: train step 14971: loss: 1.0616, policy_loss: 1.0162, value_loss: 0.5670
2024-07-14 06:41:09,003 [INFO    ] __main__: train step 14972: loss: 1.0615, policy_loss: 1.0161, value_loss: 0.5670
2024-07-14 06:41:09,293 [INFO    ] __main__: train step 14973: loss: 1.0615, policy_loss: 1.0161, value_loss: 0.5669
2024-07-14 06:41:10,920 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:41:11,410 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:41:11,478 [INFO    ] __main__: train step 14974: loss: 1.0615, policy_loss: 1.0161, value_loss: 0.5669
2024-07-14 06:41:11,775 [INFO    ] __main__: train step 14975: loss: 1.0615, policy_loss: 1.0161, value_loss: 0.5669
2024-07-14 06:41:12,066 [INFO    ] __main__: train step 14976: loss: 1.0614, policy_loss: 1.0160, value_loss: 0.5668
2024-07-14 06:41:12,360 [INFO    ] __main__: train step 14977: loss: 1.0614, policy_loss: 1.0160, value_loss: 0.5668
2024-07-14 06:41:12,651 [INFO    ] __main__: train step 14978: loss: 1.0614, policy_loss: 1.0160, value_loss: 0.5668
2024-07-14 06:41:12,941 [INFO    ] __main__: train step 14979: loss: 1.0614, policy_loss: 1.0159, value_loss: 0.5668
2024-07-14 06:41:13,229 [INFO    ] __main__: train step 14980: loss: 1.0614, policy_loss: 1.0159, value_loss: 0.5667
2024-07-14 06:41:13,504 [INFO    ] __main__: train step 14981: loss: 1.0613, policy_loss: 1.0159, value_loss: 0.5667
2024-07-14 06:41:13,765 [INFO    ] __main__: train step 14982: loss: 1.0613, policy_loss: 1.0159, value_loss: 0.5667
2024-07-14 06:41:14,058 [INFO    ] __main__: train step 14983: loss: 1.0613, policy_loss: 1.0158, value_loss: 0.5667
2024-07-14 06:41:14,355 [INFO    ] __main__: train step 14984: loss: 1.0613, policy_loss: 1.0158, value_loss: 0.5666
2024-07-14 06:41:14,641 [INFO    ] __main__: train step 14985: loss: 1.0613, policy_loss: 1.0158, value_loss: 0.5666
2024-07-14 06:41:14,928 [INFO    ] __main__: train step 14986: loss: 1.0612, policy_loss: 1.0157, value_loss: 0.5666
2024-07-14 06:41:15,211 [INFO    ] __main__: train step 14987: loss: 1.0612, policy_loss: 1.0157, value_loss: 0.5665
2024-07-14 06:41:15,510 [INFO    ] __main__: train step 14988: loss: 1.0612, policy_loss: 1.0157, value_loss: 0.5665
2024-07-14 06:41:15,803 [INFO    ] __main__: train step 14989: loss: 1.0612, policy_loss: 1.0157, value_loss: 0.5665
2024-07-14 06:41:16,093 [INFO    ] __main__: train step 14990: loss: 1.0612, policy_loss: 1.0156, value_loss: 0.5665
2024-07-14 06:41:17,727 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:41:18,218 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:41:18,289 [INFO    ] __main__: train step 14991: loss: 1.0611, policy_loss: 1.0156, value_loss: 0.5664
2024-07-14 06:41:18,603 [INFO    ] __main__: train step 14992: loss: 1.0611, policy_loss: 1.0156, value_loss: 0.5664
2024-07-14 06:41:18,900 [INFO    ] __main__: train step 14993: loss: 1.0611, policy_loss: 1.0155, value_loss: 0.5664
2024-07-14 06:41:19,193 [INFO    ] __main__: train step 14994: loss: 1.0611, policy_loss: 1.0155, value_loss: 0.5664
2024-07-14 06:41:19,480 [INFO    ] __main__: train step 14995: loss: 1.0610, policy_loss: 1.0155, value_loss: 0.5663
2024-07-14 06:41:19,768 [INFO    ] __main__: train step 14996: loss: 1.0610, policy_loss: 1.0155, value_loss: 0.5663
2024-07-14 06:41:20,068 [INFO    ] __main__: train step 14997: loss: 1.0610, policy_loss: 1.0154, value_loss: 0.5663
2024-07-14 06:41:20,356 [INFO    ] __main__: train step 14998: loss: 1.0610, policy_loss: 1.0154, value_loss: 0.5662
2024-07-14 06:41:20,642 [INFO    ] __main__: train step 14999: loss: 1.0610, policy_loss: 1.0154, value_loss: 0.5662
2024-07-14 06:41:20,913 [INFO    ] __main__: train step 15000: loss: 1.0609, policy_loss: 1.0153, value_loss: 0.5662
2024-07-14 06:41:21,050 [INFO    ] __main__: restored step 14000 for evaluation
2024-07-14 06:41:26,292 [INFO    ] __main__: test network ELO difference from baseline network: +16 (+8/-8) ELO from 32000 self-played games
2024-07-14 06:41:26,294 [INFO    ] __main__: game outcomes: W: 16500, D: 154, L: 15346
2024-07-14 06:41:26,297 [INFO    ] __main__: validation_elo_delta: 16, validation_elo: 2604
2024-07-14 06:41:26,743 [INFO    ] __main__: running self-play game for SVG generation
2024-07-14 06:43:11,238 [INFO    ] __main__: saved self-play game in animations/run2_armageddon/15000.svg
2024-07-14 06:43:11,507 [INFO    ] __main__: train step 15001: loss: 1.0609, policy_loss: 1.0153, value_loss: 0.5662
2024-07-14 06:43:11,762 [INFO    ] __main__: train step 15002: loss: 1.0609, policy_loss: 1.0153, value_loss: 0.5661
2024-07-14 06:43:12,021 [INFO    ] __main__: train step 15003: loss: 1.0609, policy_loss: 1.0153, value_loss: 0.5661
2024-07-14 06:43:12,285 [INFO    ] __main__: train step 15004: loss: 1.0609, policy_loss: 1.0152, value_loss: 0.5661
2024-07-14 06:43:12,569 [INFO    ] __main__: train step 15005: loss: 1.0608, policy_loss: 1.0152, value_loss: 0.5661
2024-07-14 06:43:12,853 [INFO    ] __main__: train step 15006: loss: 1.0608, policy_loss: 1.0152, value_loss: 0.5660
2024-07-14 06:43:13,134 [INFO    ] __main__: train step 15007: loss: 1.0608, policy_loss: 1.0151, value_loss: 0.5660
2024-07-14 06:43:14,746 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:43:15,240 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:43:15,307 [INFO    ] __main__: train step 15008: loss: 1.0608, policy_loss: 1.0151, value_loss: 0.5660
2024-07-14 06:43:15,579 [INFO    ] __main__: train step 15009: loss: 1.0607, policy_loss: 1.0151, value_loss: 0.5659
2024-07-14 06:43:15,852 [INFO    ] __main__: train step 15010: loss: 1.0607, policy_loss: 1.0151, value_loss: 0.5659
2024-07-14 06:43:16,129 [INFO    ] __main__: train step 15011: loss: 1.0607, policy_loss: 1.0150, value_loss: 0.5659
2024-07-14 06:43:16,407 [INFO    ] __main__: train step 15012: loss: 1.0607, policy_loss: 1.0150, value_loss: 0.5659
2024-07-14 06:43:16,681 [INFO    ] __main__: train step 15013: loss: 1.0607, policy_loss: 1.0150, value_loss: 0.5658
2024-07-14 06:43:16,964 [INFO    ] __main__: train step 15014: loss: 1.0606, policy_loss: 1.0149, value_loss: 0.5658
2024-07-14 06:43:17,245 [INFO    ] __main__: train step 15015: loss: 1.0606, policy_loss: 1.0149, value_loss: 0.5658
2024-07-14 06:43:17,528 [INFO    ] __main__: train step 15016: loss: 1.0606, policy_loss: 1.0149, value_loss: 0.5657
2024-07-14 06:43:20,023 [INFO    ] __main__: train step 15017: loss: 1.0606, policy_loss: 1.0149, value_loss: 0.5657
2024-07-14 06:43:20,297 [INFO    ] __main__: train step 15018: loss: 1.0605, policy_loss: 1.0148, value_loss: 0.5657
2024-07-14 06:43:20,578 [INFO    ] __main__: train step 15019: loss: 1.0605, policy_loss: 1.0148, value_loss: 0.5657
2024-07-14 06:43:20,856 [INFO    ] __main__: train step 15020: loss: 1.0605, policy_loss: 1.0148, value_loss: 0.5656
2024-07-14 06:43:21,141 [INFO    ] __main__: train step 15021: loss: 1.0605, policy_loss: 1.0147, value_loss: 0.5656
2024-07-14 06:43:21,430 [INFO    ] __main__: train step 15022: loss: 1.0605, policy_loss: 1.0147, value_loss: 0.5656
2024-07-14 06:43:21,718 [INFO    ] __main__: train step 15023: loss: 1.0604, policy_loss: 1.0147, value_loss: 0.5656
2024-07-14 06:43:21,980 [INFO    ] __main__: train step 15024: loss: 1.0604, policy_loss: 1.0147, value_loss: 0.5655
2024-07-14 06:43:23,584 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:43:24,074 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:43:24,141 [INFO    ] __main__: train step 15025: loss: 1.0604, policy_loss: 1.0146, value_loss: 0.5655
2024-07-14 06:43:24,419 [INFO    ] __main__: train step 15026: loss: 1.0604, policy_loss: 1.0146, value_loss: 0.5655
2024-07-14 06:43:24,700 [INFO    ] __main__: train step 15027: loss: 1.0604, policy_loss: 1.0146, value_loss: 0.5654
2024-07-14 06:43:24,980 [INFO    ] __main__: train step 15028: loss: 1.0603, policy_loss: 1.0145, value_loss: 0.5654
2024-07-14 06:43:25,259 [INFO    ] __main__: train step 15029: loss: 1.0603, policy_loss: 1.0145, value_loss: 0.5654
2024-07-14 06:43:25,550 [INFO    ] __main__: train step 15030: loss: 1.0603, policy_loss: 1.0145, value_loss: 0.5654
2024-07-14 06:43:25,837 [INFO    ] __main__: train step 15031: loss: 1.0603, policy_loss: 1.0145, value_loss: 0.5653
2024-07-14 06:43:26,123 [INFO    ] __main__: train step 15032: loss: 1.0602, policy_loss: 1.0144, value_loss: 0.5653
2024-07-14 06:43:26,416 [INFO    ] __main__: train step 15033: loss: 1.0602, policy_loss: 1.0144, value_loss: 0.5653
2024-07-14 06:43:26,705 [INFO    ] __main__: train step 15034: loss: 1.0602, policy_loss: 1.0144, value_loss: 0.5652
2024-07-14 06:43:26,988 [INFO    ] __main__: train step 15035: loss: 1.0602, policy_loss: 1.0143, value_loss: 0.5652
2024-07-14 06:43:27,287 [INFO    ] __main__: train step 15036: loss: 1.0602, policy_loss: 1.0143, value_loss: 0.5652
2024-07-14 06:43:27,577 [INFO    ] __main__: train step 15037: loss: 1.0601, policy_loss: 1.0143, value_loss: 0.5652
2024-07-14 06:43:27,864 [INFO    ] __main__: train step 15038: loss: 1.0601, policy_loss: 1.0143, value_loss: 0.5651
2024-07-14 06:43:28,153 [INFO    ] __main__: train step 15039: loss: 1.0601, policy_loss: 1.0142, value_loss: 0.5651
2024-07-14 06:43:28,441 [INFO    ] __main__: train step 15040: loss: 1.0601, policy_loss: 1.0142, value_loss: 0.5651
2024-07-14 06:43:28,723 [INFO    ] __main__: train step 15041: loss: 1.0600, policy_loss: 1.0142, value_loss: 0.5651
2024-07-14 06:43:30,319 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:43:30,811 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:43:30,880 [INFO    ] __main__: train step 15042: loss: 1.0600, policy_loss: 1.0141, value_loss: 0.5650
2024-07-14 06:43:31,173 [INFO    ] __main__: train step 15043: loss: 1.0600, policy_loss: 1.0141, value_loss: 0.5650
2024-07-14 06:43:31,458 [INFO    ] __main__: train step 15044: loss: 1.0600, policy_loss: 1.0141, value_loss: 0.5650
2024-07-14 06:43:31,723 [INFO    ] __main__: train step 15045: loss: 1.0600, policy_loss: 1.0141, value_loss: 0.5649
2024-07-14 06:43:32,008 [INFO    ] __main__: train step 15046: loss: 1.0599, policy_loss: 1.0140, value_loss: 0.5649
2024-07-14 06:43:32,302 [INFO    ] __main__: train step 15047: loss: 1.0599, policy_loss: 1.0140, value_loss: 0.5649
2024-07-14 06:43:32,596 [INFO    ] __main__: train step 15048: loss: 1.0599, policy_loss: 1.0140, value_loss: 0.5649
2024-07-14 06:43:32,891 [INFO    ] __main__: train step 15049: loss: 1.0599, policy_loss: 1.0139, value_loss: 0.5648
2024-07-14 06:43:33,176 [INFO    ] __main__: train step 15050: loss: 1.0599, policy_loss: 1.0139, value_loss: 0.5648
2024-07-14 06:43:33,457 [INFO    ] __main__: train step 15051: loss: 1.0598, policy_loss: 1.0139, value_loss: 0.5648
2024-07-14 06:43:33,744 [INFO    ] __main__: train step 15052: loss: 1.0598, policy_loss: 1.0139, value_loss: 0.5648
2024-07-14 06:43:34,029 [INFO    ] __main__: train step 15053: loss: 1.0598, policy_loss: 1.0138, value_loss: 0.5647
2024-07-14 06:43:34,312 [INFO    ] __main__: train step 15054: loss: 1.0598, policy_loss: 1.0138, value_loss: 0.5647
2024-07-14 06:43:34,618 [INFO    ] __main__: train step 15055: loss: 1.0597, policy_loss: 1.0138, value_loss: 0.5647
2024-07-14 06:43:34,910 [INFO    ] __main__: train step 15056: loss: 1.0597, policy_loss: 1.0137, value_loss: 0.5646
2024-07-14 06:43:35,194 [INFO    ] __main__: train step 15057: loss: 1.0597, policy_loss: 1.0137, value_loss: 0.5646
2024-07-14 06:43:35,481 [INFO    ] __main__: train step 15058: loss: 1.0597, policy_loss: 1.0137, value_loss: 0.5646
2024-07-14 06:43:37,081 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:43:37,583 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:43:37,650 [INFO    ] __main__: train step 15059: loss: 1.0597, policy_loss: 1.0137, value_loss: 0.5646
2024-07-14 06:43:37,926 [INFO    ] __main__: train step 15060: loss: 1.0596, policy_loss: 1.0136, value_loss: 0.5645
2024-07-14 06:43:38,188 [INFO    ] __main__: train step 15061: loss: 1.0596, policy_loss: 1.0136, value_loss: 0.5645
2024-07-14 06:43:38,467 [INFO    ] __main__: train step 15062: loss: 1.0596, policy_loss: 1.0136, value_loss: 0.5645
2024-07-14 06:43:38,745 [INFO    ] __main__: train step 15063: loss: 1.0596, policy_loss: 1.0135, value_loss: 0.5644
2024-07-14 06:43:39,026 [INFO    ] __main__: train step 15064: loss: 1.0596, policy_loss: 1.0135, value_loss: 0.5644
2024-07-14 06:43:39,317 [INFO    ] __main__: train step 15065: loss: 1.0595, policy_loss: 1.0135, value_loss: 0.5644
2024-07-14 06:43:39,604 [INFO    ] __main__: train step 15066: loss: 1.0595, policy_loss: 1.0135, value_loss: 0.5644
2024-07-14 06:43:39,888 [INFO    ] __main__: train step 15067: loss: 1.0595, policy_loss: 1.0134, value_loss: 0.5643
2024-07-14 06:43:40,169 [INFO    ] __main__: train step 15068: loss: 1.0595, policy_loss: 1.0134, value_loss: 0.5643
2024-07-14 06:43:40,452 [INFO    ] __main__: train step 15069: loss: 1.0594, policy_loss: 1.0134, value_loss: 0.5643
2024-07-14 06:43:40,740 [INFO    ] __main__: train step 15070: loss: 1.0594, policy_loss: 1.0133, value_loss: 0.5643
2024-07-14 06:43:41,024 [INFO    ] __main__: train step 15071: loss: 1.0594, policy_loss: 1.0133, value_loss: 0.5642
2024-07-14 06:43:41,323 [INFO    ] __main__: train step 15072: loss: 1.0594, policy_loss: 1.0133, value_loss: 0.5642
2024-07-14 06:43:41,622 [INFO    ] __main__: train step 15073: loss: 1.0594, policy_loss: 1.0133, value_loss: 0.5642
2024-07-14 06:43:41,906 [INFO    ] __main__: train step 15074: loss: 1.0593, policy_loss: 1.0132, value_loss: 0.5641
2024-07-14 06:43:42,195 [INFO    ] __main__: train step 15075: loss: 1.0593, policy_loss: 1.0132, value_loss: 0.5641
2024-07-14 06:43:43,806 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:43:44,288 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:43:44,362 [INFO    ] __main__: train step 15076: loss: 1.0593, policy_loss: 1.0132, value_loss: 0.5641
2024-07-14 06:43:44,646 [INFO    ] __main__: train step 15077: loss: 1.0593, policy_loss: 1.0131, value_loss: 0.5641
2024-07-14 06:43:44,936 [INFO    ] __main__: train step 15078: loss: 1.0593, policy_loss: 1.0131, value_loss: 0.5640
2024-07-14 06:43:45,221 [INFO    ] __main__: train step 15079: loss: 1.0592, policy_loss: 1.0131, value_loss: 0.5640
2024-07-14 06:43:45,521 [INFO    ] __main__: train step 15080: loss: 1.0592, policy_loss: 1.0131, value_loss: 0.5640
2024-07-14 06:43:45,810 [INFO    ] __main__: train step 15081: loss: 1.0592, policy_loss: 1.0130, value_loss: 0.5639
2024-07-14 06:43:46,091 [INFO    ] __main__: train step 15082: loss: 1.0592, policy_loss: 1.0130, value_loss: 0.5639
2024-07-14 06:43:46,373 [INFO    ] __main__: train step 15083: loss: 1.0591, policy_loss: 1.0130, value_loss: 0.5639
2024-07-14 06:43:46,665 [INFO    ] __main__: train step 15084: loss: 1.0591, policy_loss: 1.0130, value_loss: 0.5639
2024-07-14 06:43:46,959 [INFO    ] __main__: train step 15085: loss: 1.0591, policy_loss: 1.0129, value_loss: 0.5638
2024-07-14 06:43:47,253 [INFO    ] __main__: train step 15086: loss: 1.0591, policy_loss: 1.0129, value_loss: 0.5638
2024-07-14 06:43:47,528 [INFO    ] __main__: train step 15087: loss: 1.0591, policy_loss: 1.0129, value_loss: 0.5638
2024-07-14 06:43:47,820 [INFO    ] __main__: train step 15088: loss: 1.0590, policy_loss: 1.0128, value_loss: 0.5638
2024-07-14 06:43:48,111 [INFO    ] __main__: train step 15089: loss: 1.0590, policy_loss: 1.0128, value_loss: 0.5637
2024-07-14 06:43:48,396 [INFO    ] __main__: train step 15090: loss: 1.0590, policy_loss: 1.0128, value_loss: 0.5637
2024-07-14 06:43:48,686 [INFO    ] __main__: train step 15091: loss: 1.0590, policy_loss: 1.0128, value_loss: 0.5637
2024-07-14 06:43:48,975 [INFO    ] __main__: train step 15092: loss: 1.0589, policy_loss: 1.0127, value_loss: 0.5637
2024-07-14 06:43:50,583 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:43:51,075 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:43:51,149 [INFO    ] __main__: train step 15093: loss: 1.0589, policy_loss: 1.0127, value_loss: 0.5636
2024-07-14 06:43:51,434 [INFO    ] __main__: train step 15094: loss: 1.0589, policy_loss: 1.0127, value_loss: 0.5636
2024-07-14 06:43:51,726 [INFO    ] __main__: train step 15095: loss: 1.0589, policy_loss: 1.0126, value_loss: 0.5636
2024-07-14 06:43:52,013 [INFO    ] __main__: train step 15096: loss: 1.0589, policy_loss: 1.0126, value_loss: 0.5635
2024-07-14 06:43:52,299 [INFO    ] __main__: train step 15097: loss: 1.0588, policy_loss: 1.0126, value_loss: 0.5635
2024-07-14 06:43:52,587 [INFO    ] __main__: train step 15098: loss: 1.0588, policy_loss: 1.0126, value_loss: 0.5635
2024-07-14 06:43:52,882 [INFO    ] __main__: train step 15099: loss: 1.0588, policy_loss: 1.0125, value_loss: 0.5635
2024-07-14 06:43:53,170 [INFO    ] __main__: train step 15100: loss: 1.0588, policy_loss: 1.0125, value_loss: 0.5634
2024-07-14 06:43:53,471 [INFO    ] __main__: train step 15101: loss: 1.0588, policy_loss: 1.0125, value_loss: 0.5634
2024-07-14 06:43:53,759 [INFO    ] __main__: train step 15102: loss: 1.0587, policy_loss: 1.0124, value_loss: 0.5634
2024-07-14 06:43:54,047 [INFO    ] __main__: train step 15103: loss: 1.0587, policy_loss: 1.0124, value_loss: 0.5634
2024-07-14 06:43:54,346 [INFO    ] __main__: train step 15104: loss: 1.0587, policy_loss: 1.0124, value_loss: 0.5633
2024-07-14 06:43:54,636 [INFO    ] __main__: train step 15105: loss: 1.0587, policy_loss: 1.0123, value_loss: 0.5633
2024-07-14 06:43:54,940 [INFO    ] __main__: train step 15106: loss: 1.0586, policy_loss: 1.0123, value_loss: 0.5633
2024-07-14 06:43:55,230 [INFO    ] __main__: train step 15107: loss: 1.0586, policy_loss: 1.0123, value_loss: 0.5632
2024-07-14 06:43:55,518 [INFO    ] __main__: train step 15108: loss: 1.0586, policy_loss: 1.0123, value_loss: 0.5632
2024-07-14 06:43:55,823 [INFO    ] __main__: train step 15109: loss: 1.0586, policy_loss: 1.0122, value_loss: 0.5632
2024-07-14 06:43:57,409 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:43:57,897 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:43:57,968 [INFO    ] __main__: train step 15110: loss: 1.0586, policy_loss: 1.0122, value_loss: 0.5632
2024-07-14 06:43:58,258 [INFO    ] __main__: train step 15111: loss: 1.0585, policy_loss: 1.0122, value_loss: 0.5631
2024-07-14 06:43:58,542 [INFO    ] __main__: train step 15112: loss: 1.0585, policy_loss: 1.0121, value_loss: 0.5631
2024-07-14 06:43:58,833 [INFO    ] __main__: train step 15113: loss: 1.0585, policy_loss: 1.0121, value_loss: 0.5631
2024-07-14 06:43:59,131 [INFO    ] __main__: train step 15114: loss: 1.0585, policy_loss: 1.0121, value_loss: 0.5630
2024-07-14 06:43:59,427 [INFO    ] __main__: train step 15115: loss: 1.0584, policy_loss: 1.0121, value_loss: 0.5630
2024-07-14 06:43:59,734 [INFO    ] __main__: train step 15116: loss: 1.0584, policy_loss: 1.0120, value_loss: 0.5630
2024-07-14 06:44:00,016 [INFO    ] __main__: train step 15117: loss: 1.0584, policy_loss: 1.0120, value_loss: 0.5630
2024-07-14 06:44:00,277 [INFO    ] __main__: train step 15118: loss: 1.0584, policy_loss: 1.0120, value_loss: 0.5629
2024-07-14 06:44:00,552 [INFO    ] __main__: train step 15119: loss: 1.0584, policy_loss: 1.0119, value_loss: 0.5629
2024-07-14 06:44:03,700 [INFO    ] __main__: train step 15120: loss: 1.0583, policy_loss: 1.0119, value_loss: 0.5629
2024-07-14 06:44:04,006 [INFO    ] __main__: train step 15121: loss: 1.0583, policy_loss: 1.0119, value_loss: 0.5629
2024-07-14 06:44:04,301 [INFO    ] __main__: train step 15122: loss: 1.0583, policy_loss: 1.0119, value_loss: 0.5628
2024-07-14 06:44:04,604 [INFO    ] __main__: train step 15123: loss: 1.0583, policy_loss: 1.0118, value_loss: 0.5628
2024-07-14 06:44:04,889 [INFO    ] __main__: train step 15124: loss: 1.0582, policy_loss: 1.0118, value_loss: 0.5628
2024-07-14 06:44:05,173 [INFO    ] __main__: train step 15125: loss: 1.0582, policy_loss: 1.0118, value_loss: 0.5627
2024-07-14 06:44:05,473 [INFO    ] __main__: train step 15126: loss: 1.0582, policy_loss: 1.0117, value_loss: 0.5627
2024-07-14 06:44:07,099 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:44:07,595 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:44:07,664 [INFO    ] __main__: train step 15127: loss: 1.0582, policy_loss: 1.0117, value_loss: 0.5627
2024-07-14 06:44:07,960 [INFO    ] __main__: train step 15128: loss: 1.0582, policy_loss: 1.0117, value_loss: 0.5627
2024-07-14 06:44:08,261 [INFO    ] __main__: train step 15129: loss: 1.0581, policy_loss: 1.0117, value_loss: 0.5626
2024-07-14 06:44:08,556 [INFO    ] __main__: train step 15130: loss: 1.0581, policy_loss: 1.0116, value_loss: 0.5626
2024-07-14 06:44:08,832 [INFO    ] __main__: train step 15131: loss: 1.0581, policy_loss: 1.0116, value_loss: 0.5626
2024-07-14 06:44:09,124 [INFO    ] __main__: train step 15132: loss: 1.0581, policy_loss: 1.0116, value_loss: 0.5625
2024-07-14 06:44:09,421 [INFO    ] __main__: train step 15133: loss: 1.0580, policy_loss: 1.0115, value_loss: 0.5625
2024-07-14 06:44:09,699 [INFO    ] __main__: train step 15134: loss: 1.0580, policy_loss: 1.0115, value_loss: 0.5625
2024-07-14 06:44:09,987 [INFO    ] __main__: train step 15135: loss: 1.0580, policy_loss: 1.0115, value_loss: 0.5625
2024-07-14 06:44:10,274 [INFO    ] __main__: train step 15136: loss: 1.0580, policy_loss: 1.0115, value_loss: 0.5624
2024-07-14 06:44:10,567 [INFO    ] __main__: train step 15137: loss: 1.0580, policy_loss: 1.0114, value_loss: 0.5624
2024-07-14 06:44:10,851 [INFO    ] __main__: train step 15138: loss: 1.0579, policy_loss: 1.0114, value_loss: 0.5624
2024-07-14 06:44:11,145 [INFO    ] __main__: train step 15139: loss: 1.0579, policy_loss: 1.0114, value_loss: 0.5624
2024-07-14 06:44:11,453 [INFO    ] __main__: train step 15140: loss: 1.0579, policy_loss: 1.0113, value_loss: 0.5623
2024-07-14 06:44:11,740 [INFO    ] __main__: train step 15141: loss: 1.0579, policy_loss: 1.0113, value_loss: 0.5623
2024-07-14 06:44:12,030 [INFO    ] __main__: train step 15142: loss: 1.0578, policy_loss: 1.0113, value_loss: 0.5623
2024-07-14 06:44:12,332 [INFO    ] __main__: train step 15143: loss: 1.0578, policy_loss: 1.0113, value_loss: 0.5622
2024-07-14 06:44:13,953 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:44:14,427 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:44:14,505 [INFO    ] __main__: train step 15144: loss: 1.0578, policy_loss: 1.0112, value_loss: 0.5622
2024-07-14 06:44:14,806 [INFO    ] __main__: train step 15145: loss: 1.0578, policy_loss: 1.0112, value_loss: 0.5622
2024-07-14 06:44:15,093 [INFO    ] __main__: train step 15146: loss: 1.0578, policy_loss: 1.0112, value_loss: 0.5622
2024-07-14 06:44:15,385 [INFO    ] __main__: train step 15147: loss: 1.0577, policy_loss: 1.0111, value_loss: 0.5621
2024-07-14 06:44:15,676 [INFO    ] __main__: train step 15148: loss: 1.0577, policy_loss: 1.0111, value_loss: 0.5621
2024-07-14 06:44:15,964 [INFO    ] __main__: train step 15149: loss: 1.0577, policy_loss: 1.0111, value_loss: 0.5621
2024-07-14 06:44:16,257 [INFO    ] __main__: train step 15150: loss: 1.0577, policy_loss: 1.0111, value_loss: 0.5621
2024-07-14 06:44:16,545 [INFO    ] __main__: train step 15151: loss: 1.0576, policy_loss: 1.0110, value_loss: 0.5620
2024-07-14 06:44:16,832 [INFO    ] __main__: train step 15152: loss: 1.0576, policy_loss: 1.0110, value_loss: 0.5620
2024-07-14 06:44:17,119 [INFO    ] __main__: train step 15153: loss: 1.0576, policy_loss: 1.0110, value_loss: 0.5620
2024-07-14 06:44:17,401 [INFO    ] __main__: train step 15154: loss: 1.0576, policy_loss: 1.0109, value_loss: 0.5619
2024-07-14 06:44:17,683 [INFO    ] __main__: train step 15155: loss: 1.0576, policy_loss: 1.0109, value_loss: 0.5619
2024-07-14 06:44:17,975 [INFO    ] __main__: train step 15156: loss: 1.0575, policy_loss: 1.0109, value_loss: 0.5619
2024-07-14 06:44:18,270 [INFO    ] __main__: train step 15157: loss: 1.0575, policy_loss: 1.0109, value_loss: 0.5619
2024-07-14 06:44:18,556 [INFO    ] __main__: train step 15158: loss: 1.0575, policy_loss: 1.0108, value_loss: 0.5618
2024-07-14 06:44:18,847 [INFO    ] __main__: train step 15159: loss: 1.0575, policy_loss: 1.0108, value_loss: 0.5618
2024-07-14 06:44:19,137 [INFO    ] __main__: train step 15160: loss: 1.0574, policy_loss: 1.0108, value_loss: 0.5618
2024-07-14 06:44:20,744 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:44:21,228 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:44:21,299 [INFO    ] __main__: train step 15161: loss: 1.0574, policy_loss: 1.0107, value_loss: 0.5617
2024-07-14 06:44:21,593 [INFO    ] __main__: train step 15162: loss: 1.0574, policy_loss: 1.0107, value_loss: 0.5617
2024-07-14 06:44:21,888 [INFO    ] __main__: train step 15163: loss: 1.0574, policy_loss: 1.0107, value_loss: 0.5617
2024-07-14 06:44:22,182 [INFO    ] __main__: train step 15164: loss: 1.0574, policy_loss: 1.0107, value_loss: 0.5617
2024-07-14 06:44:22,474 [INFO    ] __main__: train step 15165: loss: 1.0573, policy_loss: 1.0106, value_loss: 0.5616
2024-07-14 06:44:22,764 [INFO    ] __main__: train step 15166: loss: 1.0573, policy_loss: 1.0106, value_loss: 0.5616
2024-07-14 06:44:23,056 [INFO    ] __main__: train step 15167: loss: 1.0573, policy_loss: 1.0106, value_loss: 0.5616
2024-07-14 06:44:23,348 [INFO    ] __main__: train step 15168: loss: 1.0573, policy_loss: 1.0105, value_loss: 0.5616
2024-07-14 06:44:23,649 [INFO    ] __main__: train step 15169: loss: 1.0572, policy_loss: 1.0105, value_loss: 0.5615
2024-07-14 06:44:23,941 [INFO    ] __main__: train step 15170: loss: 1.0572, policy_loss: 1.0105, value_loss: 0.5615
2024-07-14 06:44:24,237 [INFO    ] __main__: train step 15171: loss: 1.0572, policy_loss: 1.0105, value_loss: 0.5615
2024-07-14 06:44:24,530 [INFO    ] __main__: train step 15172: loss: 1.0572, policy_loss: 1.0104, value_loss: 0.5614
2024-07-14 06:44:24,818 [INFO    ] __main__: train step 15173: loss: 1.0572, policy_loss: 1.0104, value_loss: 0.5614
2024-07-14 06:44:25,109 [INFO    ] __main__: train step 15174: loss: 1.0571, policy_loss: 1.0104, value_loss: 0.5614
2024-07-14 06:44:25,392 [INFO    ] __main__: train step 15175: loss: 1.0571, policy_loss: 1.0103, value_loss: 0.5614
2024-07-14 06:44:25,686 [INFO    ] __main__: train step 15176: loss: 1.0571, policy_loss: 1.0103, value_loss: 0.5613
2024-07-14 06:44:25,981 [INFO    ] __main__: train step 15177: loss: 1.0571, policy_loss: 1.0103, value_loss: 0.5613
2024-07-14 06:44:27,591 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:44:28,091 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:44:28,167 [INFO    ] __main__: train step 15178: loss: 1.0571, policy_loss: 1.0103, value_loss: 0.5613
2024-07-14 06:44:28,459 [INFO    ] __main__: train step 15179: loss: 1.0570, policy_loss: 1.0102, value_loss: 0.5613
2024-07-14 06:44:28,762 [INFO    ] __main__: train step 15180: loss: 1.0570, policy_loss: 1.0102, value_loss: 0.5612
2024-07-14 06:44:29,049 [INFO    ] __main__: train step 15181: loss: 1.0570, policy_loss: 1.0102, value_loss: 0.5612
2024-07-14 06:44:29,323 [INFO    ] __main__: train step 15182: loss: 1.0570, policy_loss: 1.0101, value_loss: 0.5612
2024-07-14 06:44:29,610 [INFO    ] __main__: train step 15183: loss: 1.0569, policy_loss: 1.0101, value_loss: 0.5611
2024-07-14 06:44:29,895 [INFO    ] __main__: train step 15184: loss: 1.0569, policy_loss: 1.0101, value_loss: 0.5611
2024-07-14 06:44:30,184 [INFO    ] __main__: train step 15185: loss: 1.0569, policy_loss: 1.0101, value_loss: 0.5611
2024-07-14 06:44:30,476 [INFO    ] __main__: train step 15186: loss: 1.0569, policy_loss: 1.0100, value_loss: 0.5611
2024-07-14 06:44:30,765 [INFO    ] __main__: train step 15187: loss: 1.0569, policy_loss: 1.0100, value_loss: 0.5610
2024-07-14 06:44:31,054 [INFO    ] __main__: train step 15188: loss: 1.0568, policy_loss: 1.0100, value_loss: 0.5610
2024-07-14 06:44:31,339 [INFO    ] __main__: train step 15189: loss: 1.0568, policy_loss: 1.0100, value_loss: 0.5610
2024-07-14 06:44:31,621 [INFO    ] __main__: train step 15190: loss: 1.0568, policy_loss: 1.0099, value_loss: 0.5610
2024-07-14 06:44:31,915 [INFO    ] __main__: train step 15191: loss: 1.0568, policy_loss: 1.0099, value_loss: 0.5609
2024-07-14 06:44:32,216 [INFO    ] __main__: train step 15192: loss: 1.0567, policy_loss: 1.0099, value_loss: 0.5609
2024-07-14 06:44:32,504 [INFO    ] __main__: train step 15193: loss: 1.0567, policy_loss: 1.0098, value_loss: 0.5609
2024-07-14 06:44:32,784 [INFO    ] __main__: train step 15194: loss: 1.0567, policy_loss: 1.0098, value_loss: 0.5608
2024-07-14 06:44:34,397 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:44:34,895 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:44:34,962 [INFO    ] __main__: train step 15195: loss: 1.0567, policy_loss: 1.0098, value_loss: 0.5608
2024-07-14 06:44:35,263 [INFO    ] __main__: train step 15196: loss: 1.0567, policy_loss: 1.0098, value_loss: 0.5608
2024-07-14 06:44:35,557 [INFO    ] __main__: train step 15197: loss: 1.0566, policy_loss: 1.0097, value_loss: 0.5608
2024-07-14 06:44:35,839 [INFO    ] __main__: train step 15198: loss: 1.0566, policy_loss: 1.0097, value_loss: 0.5607
2024-07-14 06:44:36,121 [INFO    ] __main__: train step 15199: loss: 1.0566, policy_loss: 1.0097, value_loss: 0.5607
2024-07-14 06:44:36,409 [INFO    ] __main__: train step 15200: loss: 1.0566, policy_loss: 1.0096, value_loss: 0.5607
2024-07-14 06:44:36,702 [INFO    ] __main__: train step 15201: loss: 1.0566, policy_loss: 1.0096, value_loss: 0.5607
2024-07-14 06:44:36,991 [INFO    ] __main__: train step 15202: loss: 1.0565, policy_loss: 1.0096, value_loss: 0.5606
2024-07-14 06:44:37,279 [INFO    ] __main__: train step 15203: loss: 1.0565, policy_loss: 1.0096, value_loss: 0.5606
2024-07-14 06:44:37,584 [INFO    ] __main__: train step 15204: loss: 1.0565, policy_loss: 1.0095, value_loss: 0.5606
2024-07-14 06:44:37,887 [INFO    ] __main__: train step 15205: loss: 1.0565, policy_loss: 1.0095, value_loss: 0.5605
2024-07-14 06:44:38,154 [INFO    ] __main__: train step 15206: loss: 1.0564, policy_loss: 1.0095, value_loss: 0.5605
2024-07-14 06:44:38,441 [INFO    ] __main__: train step 15207: loss: 1.0564, policy_loss: 1.0094, value_loss: 0.5605
2024-07-14 06:44:38,741 [INFO    ] __main__: train step 15208: loss: 1.0564, policy_loss: 1.0094, value_loss: 0.5605
2024-07-14 06:44:39,033 [INFO    ] __main__: train step 15209: loss: 1.0564, policy_loss: 1.0094, value_loss: 0.5604
2024-07-14 06:44:39,327 [INFO    ] __main__: train step 15210: loss: 1.0564, policy_loss: 1.0094, value_loss: 0.5604
2024-07-14 06:44:39,597 [INFO    ] __main__: train step 15211: loss: 1.0563, policy_loss: 1.0093, value_loss: 0.5604
2024-07-14 06:44:41,218 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:44:41,708 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:44:41,783 [INFO    ] __main__: train step 15212: loss: 1.0563, policy_loss: 1.0093, value_loss: 0.5603
2024-07-14 06:44:42,050 [INFO    ] __main__: train step 15213: loss: 1.0563, policy_loss: 1.0093, value_loss: 0.5603
2024-07-14 06:44:42,318 [INFO    ] __main__: train step 15214: loss: 1.0563, policy_loss: 1.0092, value_loss: 0.5603
2024-07-14 06:44:42,606 [INFO    ] __main__: train step 15215: loss: 1.0562, policy_loss: 1.0092, value_loss: 0.5603
2024-07-14 06:44:42,868 [INFO    ] __main__: train step 15216: loss: 1.0562, policy_loss: 1.0092, value_loss: 0.5602
2024-07-14 06:44:43,161 [INFO    ] __main__: train step 15217: loss: 1.0562, policy_loss: 1.0092, value_loss: 0.5602
2024-07-14 06:44:43,443 [INFO    ] __main__: train step 15218: loss: 1.0562, policy_loss: 1.0091, value_loss: 0.5602
2024-07-14 06:44:43,740 [INFO    ] __main__: train step 15219: loss: 1.0562, policy_loss: 1.0091, value_loss: 0.5602
2024-07-14 06:44:44,029 [INFO    ] __main__: train step 15220: loss: 1.0561, policy_loss: 1.0091, value_loss: 0.5601
2024-07-14 06:44:44,307 [INFO    ] __main__: train step 15221: loss: 1.0561, policy_loss: 1.0090, value_loss: 0.5601
2024-07-14 06:44:44,606 [INFO    ] __main__: train step 15222: loss: 1.0561, policy_loss: 1.0090, value_loss: 0.5601
2024-07-14 06:44:44,875 [INFO    ] __main__: train step 15223: loss: 1.0561, policy_loss: 1.0090, value_loss: 0.5600
2024-07-14 06:44:48,470 [INFO    ] __main__: train step 15224: loss: 1.0560, policy_loss: 1.0090, value_loss: 0.5600
2024-07-14 06:44:48,748 [INFO    ] __main__: train step 15225: loss: 1.0560, policy_loss: 1.0089, value_loss: 0.5600
2024-07-14 06:44:49,033 [INFO    ] __main__: train step 15226: loss: 1.0560, policy_loss: 1.0089, value_loss: 0.5600
2024-07-14 06:44:49,312 [INFO    ] __main__: train step 15227: loss: 1.0560, policy_loss: 1.0089, value_loss: 0.5599
2024-07-14 06:44:49,589 [INFO    ] __main__: train step 15228: loss: 1.0559, policy_loss: 1.0088, value_loss: 0.5599
2024-07-14 06:44:51,201 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:44:51,682 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:44:51,751 [INFO    ] __main__: train step 15229: loss: 1.0559, policy_loss: 1.0088, value_loss: 0.5599
2024-07-14 06:44:52,049 [INFO    ] __main__: train step 15230: loss: 1.0559, policy_loss: 1.0088, value_loss: 0.5599
2024-07-14 06:44:52,335 [INFO    ] __main__: train step 15231: loss: 1.0559, policy_loss: 1.0088, value_loss: 0.5598
2024-07-14 06:44:52,617 [INFO    ] __main__: train step 15232: loss: 1.0559, policy_loss: 1.0087, value_loss: 0.5598
2024-07-14 06:44:52,900 [INFO    ] __main__: train step 15233: loss: 1.0558, policy_loss: 1.0087, value_loss: 0.5598
2024-07-14 06:44:53,192 [INFO    ] __main__: train step 15234: loss: 1.0558, policy_loss: 1.0087, value_loss: 0.5597
2024-07-14 06:44:53,490 [INFO    ] __main__: train step 15235: loss: 1.0558, policy_loss: 1.0086, value_loss: 0.5597
2024-07-14 06:44:53,774 [INFO    ] __main__: train step 15236: loss: 1.0558, policy_loss: 1.0086, value_loss: 0.5597
2024-07-14 06:44:54,058 [INFO    ] __main__: train step 15237: loss: 1.0558, policy_loss: 1.0086, value_loss: 0.5597
2024-07-14 06:44:54,345 [INFO    ] __main__: train step 15238: loss: 1.0557, policy_loss: 1.0086, value_loss: 0.5596
2024-07-14 06:44:54,628 [INFO    ] __main__: train step 15239: loss: 1.0557, policy_loss: 1.0085, value_loss: 0.5596
2024-07-14 06:44:54,910 [INFO    ] __main__: train step 15240: loss: 1.0557, policy_loss: 1.0085, value_loss: 0.5596
2024-07-14 06:44:55,193 [INFO    ] __main__: train step 15241: loss: 1.0557, policy_loss: 1.0085, value_loss: 0.5596
2024-07-14 06:44:55,483 [INFO    ] __main__: train step 15242: loss: 1.0556, policy_loss: 1.0084, value_loss: 0.5595
2024-07-14 06:44:55,768 [INFO    ] __main__: train step 15243: loss: 1.0556, policy_loss: 1.0084, value_loss: 0.5595
2024-07-14 06:44:56,060 [INFO    ] __main__: train step 15244: loss: 1.0556, policy_loss: 1.0084, value_loss: 0.5595
2024-07-14 06:44:56,346 [INFO    ] __main__: train step 15245: loss: 1.0556, policy_loss: 1.0084, value_loss: 0.5594
2024-07-14 06:44:57,939 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:44:58,412 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:44:58,482 [INFO    ] __main__: train step 15246: loss: 1.0555, policy_loss: 1.0083, value_loss: 0.5594
2024-07-14 06:44:58,774 [INFO    ] __main__: train step 15247: loss: 1.0555, policy_loss: 1.0083, value_loss: 0.5594
2024-07-14 06:44:59,060 [INFO    ] __main__: train step 15248: loss: 1.0555, policy_loss: 1.0083, value_loss: 0.5594
2024-07-14 06:44:59,345 [INFO    ] __main__: train step 15249: loss: 1.0555, policy_loss: 1.0082, value_loss: 0.5593
2024-07-14 06:44:59,641 [INFO    ] __main__: train step 15250: loss: 1.0555, policy_loss: 1.0082, value_loss: 0.5593
2024-07-14 06:44:59,935 [INFO    ] __main__: train step 15251: loss: 1.0554, policy_loss: 1.0082, value_loss: 0.5593
2024-07-14 06:45:00,223 [INFO    ] __main__: train step 15252: loss: 1.0554, policy_loss: 1.0082, value_loss: 0.5592
2024-07-14 06:45:00,519 [INFO    ] __main__: train step 15253: loss: 1.0554, policy_loss: 1.0081, value_loss: 0.5592
2024-07-14 06:45:00,794 [INFO    ] __main__: train step 15254: loss: 1.0554, policy_loss: 1.0081, value_loss: 0.5592
2024-07-14 06:45:01,086 [INFO    ] __main__: train step 15255: loss: 1.0554, policy_loss: 1.0081, value_loss: 0.5592
2024-07-14 06:45:01,372 [INFO    ] __main__: train step 15256: loss: 1.0553, policy_loss: 1.0080, value_loss: 0.5591
2024-07-14 06:45:01,655 [INFO    ] __main__: train step 15257: loss: 1.0553, policy_loss: 1.0080, value_loss: 0.5591
2024-07-14 06:45:01,951 [INFO    ] __main__: train step 15258: loss: 1.0553, policy_loss: 1.0080, value_loss: 0.5591
2024-07-14 06:45:02,241 [INFO    ] __main__: train step 15259: loss: 1.0553, policy_loss: 1.0080, value_loss: 0.5591
2024-07-14 06:45:02,516 [INFO    ] __main__: train step 15260: loss: 1.0552, policy_loss: 1.0079, value_loss: 0.5590
2024-07-14 06:45:02,810 [INFO    ] __main__: train step 15261: loss: 1.0552, policy_loss: 1.0079, value_loss: 0.5590
2024-07-14 06:45:03,099 [INFO    ] __main__: train step 15262: loss: 1.0552, policy_loss: 1.0079, value_loss: 0.5590
2024-07-14 06:45:04,720 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:45:05,219 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:45:05,288 [INFO    ] __main__: train step 15263: loss: 1.0552, policy_loss: 1.0078, value_loss: 0.5589
2024-07-14 06:45:05,587 [INFO    ] __main__: train step 15264: loss: 1.0551, policy_loss: 1.0078, value_loss: 0.5589
2024-07-14 06:45:05,886 [INFO    ] __main__: train step 15265: loss: 1.0551, policy_loss: 1.0078, value_loss: 0.5589
2024-07-14 06:45:06,165 [INFO    ] __main__: train step 15266: loss: 1.0551, policy_loss: 1.0078, value_loss: 0.5589
2024-07-14 06:45:06,462 [INFO    ] __main__: train step 15267: loss: 1.0551, policy_loss: 1.0077, value_loss: 0.5588
2024-07-14 06:45:06,756 [INFO    ] __main__: train step 15268: loss: 1.0551, policy_loss: 1.0077, value_loss: 0.5588
2024-07-14 06:45:07,055 [INFO    ] __main__: train step 15269: loss: 1.0550, policy_loss: 1.0077, value_loss: 0.5588
2024-07-14 06:45:07,358 [INFO    ] __main__: train step 15270: loss: 1.0550, policy_loss: 1.0076, value_loss: 0.5588
2024-07-14 06:45:07,649 [INFO    ] __main__: train step 15271: loss: 1.0550, policy_loss: 1.0076, value_loss: 0.5587
2024-07-14 06:45:07,942 [INFO    ] __main__: train step 15272: loss: 1.0550, policy_loss: 1.0076, value_loss: 0.5587
2024-07-14 06:45:08,238 [INFO    ] __main__: train step 15273: loss: 1.0549, policy_loss: 1.0076, value_loss: 0.5587
2024-07-14 06:45:08,528 [INFO    ] __main__: train step 15274: loss: 1.0549, policy_loss: 1.0075, value_loss: 0.5586
2024-07-14 06:45:08,812 [INFO    ] __main__: train step 15275: loss: 1.0549, policy_loss: 1.0075, value_loss: 0.5586
2024-07-14 06:45:09,104 [INFO    ] __main__: train step 15276: loss: 1.0549, policy_loss: 1.0075, value_loss: 0.5586
2024-07-14 06:45:09,391 [INFO    ] __main__: train step 15277: loss: 1.0549, policy_loss: 1.0075, value_loss: 0.5586
2024-07-14 06:45:09,685 [INFO    ] __main__: train step 15278: loss: 1.0548, policy_loss: 1.0074, value_loss: 0.5585
2024-07-14 06:45:09,972 [INFO    ] __main__: train step 15279: loss: 1.0548, policy_loss: 1.0074, value_loss: 0.5585
2024-07-14 06:45:11,557 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:45:12,036 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:45:12,108 [INFO    ] __main__: train step 15280: loss: 1.0548, policy_loss: 1.0074, value_loss: 0.5585
2024-07-14 06:45:12,379 [INFO    ] __main__: train step 15281: loss: 1.0548, policy_loss: 1.0073, value_loss: 0.5585
2024-07-14 06:45:12,632 [INFO    ] __main__: train step 15282: loss: 1.0547, policy_loss: 1.0073, value_loss: 0.5584
2024-07-14 06:45:12,902 [INFO    ] __main__: train step 15283: loss: 1.0547, policy_loss: 1.0073, value_loss: 0.5584
2024-07-14 06:45:13,189 [INFO    ] __main__: train step 15284: loss: 1.0547, policy_loss: 1.0073, value_loss: 0.5584
2024-07-14 06:45:13,477 [INFO    ] __main__: train step 15285: loss: 1.0547, policy_loss: 1.0072, value_loss: 0.5583
2024-07-14 06:45:13,765 [INFO    ] __main__: train step 15286: loss: 1.0547, policy_loss: 1.0072, value_loss: 0.5583
2024-07-14 06:45:14,053 [INFO    ] __main__: train step 15287: loss: 1.0546, policy_loss: 1.0072, value_loss: 0.5583
2024-07-14 06:45:14,343 [INFO    ] __main__: train step 15288: loss: 1.0546, policy_loss: 1.0071, value_loss: 0.5583
2024-07-14 06:45:14,642 [INFO    ] __main__: train step 15289: loss: 1.0546, policy_loss: 1.0071, value_loss: 0.5582
2024-07-14 06:45:14,927 [INFO    ] __main__: train step 15290: loss: 1.0546, policy_loss: 1.0071, value_loss: 0.5582
2024-07-14 06:45:15,216 [INFO    ] __main__: train step 15291: loss: 1.0546, policy_loss: 1.0071, value_loss: 0.5582
2024-07-14 06:45:15,498 [INFO    ] __main__: train step 15292: loss: 1.0545, policy_loss: 1.0070, value_loss: 0.5582
2024-07-14 06:45:15,782 [INFO    ] __main__: train step 15293: loss: 1.0545, policy_loss: 1.0070, value_loss: 0.5581
2024-07-14 06:45:16,080 [INFO    ] __main__: train step 15294: loss: 1.0545, policy_loss: 1.0070, value_loss: 0.5581
2024-07-14 06:45:16,378 [INFO    ] __main__: train step 15295: loss: 1.0545, policy_loss: 1.0069, value_loss: 0.5581
2024-07-14 06:45:16,679 [INFO    ] __main__: train step 15296: loss: 1.0544, policy_loss: 1.0069, value_loss: 0.5581
2024-07-14 06:45:18,291 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:45:18,776 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:45:18,845 [INFO    ] __main__: train step 15297: loss: 1.0544, policy_loss: 1.0069, value_loss: 0.5580
2024-07-14 06:45:19,131 [INFO    ] __main__: train step 15298: loss: 1.0544, policy_loss: 1.0069, value_loss: 0.5580
2024-07-14 06:45:19,424 [INFO    ] __main__: train step 15299: loss: 1.0544, policy_loss: 1.0068, value_loss: 0.5580
2024-07-14 06:45:19,707 [INFO    ] __main__: train step 15300: loss: 1.0543, policy_loss: 1.0068, value_loss: 0.5579
2024-07-14 06:45:19,989 [INFO    ] __main__: train step 15301: loss: 1.0543, policy_loss: 1.0068, value_loss: 0.5579
2024-07-14 06:45:20,270 [INFO    ] __main__: train step 15302: loss: 1.0543, policy_loss: 1.0067, value_loss: 0.5579
2024-07-14 06:45:20,554 [INFO    ] __main__: train step 15303: loss: 1.0543, policy_loss: 1.0067, value_loss: 0.5579
2024-07-14 06:45:20,829 [INFO    ] __main__: train step 15304: loss: 1.0543, policy_loss: 1.0067, value_loss: 0.5578
2024-07-14 06:45:21,109 [INFO    ] __main__: train step 15305: loss: 1.0542, policy_loss: 1.0067, value_loss: 0.5578
2024-07-14 06:45:21,403 [INFO    ] __main__: train step 15306: loss: 1.0542, policy_loss: 1.0066, value_loss: 0.5578
2024-07-14 06:45:21,695 [INFO    ] __main__: train step 15307: loss: 1.0542, policy_loss: 1.0066, value_loss: 0.5578
2024-07-14 06:45:21,975 [INFO    ] __main__: train step 15308: loss: 1.0542, policy_loss: 1.0066, value_loss: 0.5577
2024-07-14 06:45:22,260 [INFO    ] __main__: train step 15309: loss: 1.0541, policy_loss: 1.0065, value_loss: 0.5577
2024-07-14 06:45:22,543 [INFO    ] __main__: train step 15310: loss: 1.0541, policy_loss: 1.0065, value_loss: 0.5577
2024-07-14 06:45:22,838 [INFO    ] __main__: train step 15311: loss: 1.0541, policy_loss: 1.0065, value_loss: 0.5576
2024-07-14 06:45:23,125 [INFO    ] __main__: train step 15312: loss: 1.0541, policy_loss: 1.0065, value_loss: 0.5576
2024-07-14 06:45:23,421 [INFO    ] __main__: train step 15313: loss: 1.0541, policy_loss: 1.0064, value_loss: 0.5576
2024-07-14 06:45:25,034 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:45:25,519 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:45:25,586 [INFO    ] __main__: train step 15314: loss: 1.0540, policy_loss: 1.0064, value_loss: 0.5576
2024-07-14 06:45:25,901 [INFO    ] __main__: train step 15315: loss: 1.0540, policy_loss: 1.0064, value_loss: 0.5575
2024-07-14 06:45:26,196 [INFO    ] __main__: train step 15316: loss: 1.0540, policy_loss: 1.0063, value_loss: 0.5575
2024-07-14 06:45:26,474 [INFO    ] __main__: train step 15317: loss: 1.0540, policy_loss: 1.0063, value_loss: 0.5575
2024-07-14 06:45:26,757 [INFO    ] __main__: train step 15318: loss: 1.0539, policy_loss: 1.0063, value_loss: 0.5575
2024-07-14 06:45:27,050 [INFO    ] __main__: train step 15319: loss: 1.0539, policy_loss: 1.0062, value_loss: 0.5574
2024-07-14 06:45:27,338 [INFO    ] __main__: train step 15320: loss: 1.0539, policy_loss: 1.0062, value_loss: 0.5574
2024-07-14 06:45:27,621 [INFO    ] __main__: train step 15321: loss: 1.0539, policy_loss: 1.0062, value_loss: 0.5574
2024-07-14 06:45:27,913 [INFO    ] __main__: train step 15322: loss: 1.0539, policy_loss: 1.0062, value_loss: 0.5573
2024-07-14 06:45:28,203 [INFO    ] __main__: train step 15323: loss: 1.0538, policy_loss: 1.0061, value_loss: 0.5573
2024-07-14 06:45:28,486 [INFO    ] __main__: train step 15324: loss: 1.0538, policy_loss: 1.0061, value_loss: 0.5573
2024-07-14 06:45:28,771 [INFO    ] __main__: train step 15325: loss: 1.0538, policy_loss: 1.0061, value_loss: 0.5573
2024-07-14 06:45:29,071 [INFO    ] __main__: train step 15326: loss: 1.0538, policy_loss: 1.0060, value_loss: 0.5572
2024-07-14 06:45:29,357 [INFO    ] __main__: train step 15327: loss: 1.0537, policy_loss: 1.0060, value_loss: 0.5572
2024-07-14 06:45:32,559 [INFO    ] __main__: train step 15328: loss: 1.0537, policy_loss: 1.0060, value_loss: 0.5572
2024-07-14 06:45:32,852 [INFO    ] __main__: train step 15329: loss: 1.0537, policy_loss: 1.0060, value_loss: 0.5572
2024-07-14 06:45:33,147 [INFO    ] __main__: train step 15330: loss: 1.0537, policy_loss: 1.0059, value_loss: 0.5571
2024-07-14 06:45:34,756 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:45:35,245 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:45:35,318 [INFO    ] __main__: train step 15331: loss: 1.0537, policy_loss: 1.0059, value_loss: 0.5571
2024-07-14 06:45:35,618 [INFO    ] __main__: train step 15332: loss: 1.0536, policy_loss: 1.0059, value_loss: 0.5571
2024-07-14 06:45:35,899 [INFO    ] __main__: train step 15333: loss: 1.0536, policy_loss: 1.0058, value_loss: 0.5571
2024-07-14 06:45:36,191 [INFO    ] __main__: train step 15334: loss: 1.0536, policy_loss: 1.0058, value_loss: 0.5570
2024-07-14 06:45:36,498 [INFO    ] __main__: train step 15335: loss: 1.0536, policy_loss: 1.0058, value_loss: 0.5570
2024-07-14 06:45:36,786 [INFO    ] __main__: train step 15336: loss: 1.0535, policy_loss: 1.0058, value_loss: 0.5570
2024-07-14 06:45:37,075 [INFO    ] __main__: train step 15337: loss: 1.0535, policy_loss: 1.0057, value_loss: 0.5569
2024-07-14 06:45:37,366 [INFO    ] __main__: train step 15338: loss: 1.0535, policy_loss: 1.0057, value_loss: 0.5569
2024-07-14 06:45:37,653 [INFO    ] __main__: train step 15339: loss: 1.0535, policy_loss: 1.0057, value_loss: 0.5569
2024-07-14 06:45:37,942 [INFO    ] __main__: train step 15340: loss: 1.0535, policy_loss: 1.0057, value_loss: 0.5569
2024-07-14 06:45:38,239 [INFO    ] __main__: train step 15341: loss: 1.0534, policy_loss: 1.0056, value_loss: 0.5568
2024-07-14 06:45:38,538 [INFO    ] __main__: train step 15342: loss: 1.0534, policy_loss: 1.0056, value_loss: 0.5568
2024-07-14 06:45:38,823 [INFO    ] __main__: train step 15343: loss: 1.0534, policy_loss: 1.0056, value_loss: 0.5568
2024-07-14 06:45:39,107 [INFO    ] __main__: train step 15344: loss: 1.0534, policy_loss: 1.0055, value_loss: 0.5567
2024-07-14 06:45:39,389 [INFO    ] __main__: train step 15345: loss: 1.0533, policy_loss: 1.0055, value_loss: 0.5567
2024-07-14 06:45:39,662 [INFO    ] __main__: train step 15346: loss: 1.0533, policy_loss: 1.0055, value_loss: 0.5567
2024-07-14 06:45:39,948 [INFO    ] __main__: train step 15347: loss: 1.0533, policy_loss: 1.0054, value_loss: 0.5567
2024-07-14 06:45:41,545 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:45:42,039 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:45:42,109 [INFO    ] __main__: train step 15348: loss: 1.0533, policy_loss: 1.0054, value_loss: 0.5566
2024-07-14 06:45:42,383 [INFO    ] __main__: train step 15349: loss: 1.0532, policy_loss: 1.0054, value_loss: 0.5566
2024-07-14 06:45:42,649 [INFO    ] __main__: train step 15350: loss: 1.0532, policy_loss: 1.0054, value_loss: 0.5566
2024-07-14 06:45:42,931 [INFO    ] __main__: train step 15351: loss: 1.0532, policy_loss: 1.0053, value_loss: 0.5566
2024-07-14 06:45:43,213 [INFO    ] __main__: train step 15352: loss: 1.0532, policy_loss: 1.0053, value_loss: 0.5565
2024-07-14 06:45:43,496 [INFO    ] __main__: train step 15353: loss: 1.0532, policy_loss: 1.0053, value_loss: 0.5565
2024-07-14 06:45:43,784 [INFO    ] __main__: train step 15354: loss: 1.0531, policy_loss: 1.0052, value_loss: 0.5565
2024-07-14 06:45:44,087 [INFO    ] __main__: train step 15355: loss: 1.0531, policy_loss: 1.0052, value_loss: 0.5565
2024-07-14 06:45:44,381 [INFO    ] __main__: train step 15356: loss: 1.0531, policy_loss: 1.0052, value_loss: 0.5564
2024-07-14 06:45:44,675 [INFO    ] __main__: train step 15357: loss: 1.0531, policy_loss: 1.0052, value_loss: 0.5564
2024-07-14 06:45:44,948 [INFO    ] __main__: train step 15358: loss: 1.0530, policy_loss: 1.0051, value_loss: 0.5564
2024-07-14 06:45:45,236 [INFO    ] __main__: train step 15359: loss: 1.0530, policy_loss: 1.0051, value_loss: 0.5563
2024-07-14 06:45:45,524 [INFO    ] __main__: train step 15360: loss: 1.0530, policy_loss: 1.0051, value_loss: 0.5563
2024-07-14 06:45:45,828 [INFO    ] __main__: train step 15361: loss: 1.0530, policy_loss: 1.0050, value_loss: 0.5563
2024-07-14 06:45:46,121 [INFO    ] __main__: train step 15362: loss: 1.0530, policy_loss: 1.0050, value_loss: 0.5563
2024-07-14 06:45:46,413 [INFO    ] __main__: train step 15363: loss: 1.0529, policy_loss: 1.0050, value_loss: 0.5562
2024-07-14 06:45:46,724 [INFO    ] __main__: train step 15364: loss: 1.0529, policy_loss: 1.0050, value_loss: 0.5562
2024-07-14 06:45:48,339 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:45:48,825 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:45:48,897 [INFO    ] __main__: train step 15365: loss: 1.0529, policy_loss: 1.0049, value_loss: 0.5562
2024-07-14 06:45:49,203 [INFO    ] __main__: train step 15366: loss: 1.0529, policy_loss: 1.0049, value_loss: 0.5562
2024-07-14 06:45:49,506 [INFO    ] __main__: train step 15367: loss: 1.0528, policy_loss: 1.0049, value_loss: 0.5561
2024-07-14 06:45:49,790 [INFO    ] __main__: train step 15368: loss: 1.0528, policy_loss: 1.0049, value_loss: 0.5561
2024-07-14 06:45:50,085 [INFO    ] __main__: train step 15369: loss: 1.0528, policy_loss: 1.0048, value_loss: 0.5561
2024-07-14 06:45:50,382 [INFO    ] __main__: train step 15370: loss: 1.0528, policy_loss: 1.0048, value_loss: 0.5560
2024-07-14 06:45:50,671 [INFO    ] __main__: train step 15371: loss: 1.0528, policy_loss: 1.0048, value_loss: 0.5560
2024-07-14 06:45:50,960 [INFO    ] __main__: train step 15372: loss: 1.0527, policy_loss: 1.0047, value_loss: 0.5560
2024-07-14 06:45:51,261 [INFO    ] __main__: train step 15373: loss: 1.0527, policy_loss: 1.0047, value_loss: 0.5560
2024-07-14 06:45:51,550 [INFO    ] __main__: train step 15374: loss: 1.0527, policy_loss: 1.0047, value_loss: 0.5559
2024-07-14 06:45:51,847 [INFO    ] __main__: train step 15375: loss: 1.0527, policy_loss: 1.0047, value_loss: 0.5559
2024-07-14 06:45:52,139 [INFO    ] __main__: train step 15376: loss: 1.0526, policy_loss: 1.0046, value_loss: 0.5559
2024-07-14 06:45:52,443 [INFO    ] __main__: train step 15377: loss: 1.0526, policy_loss: 1.0046, value_loss: 0.5559
2024-07-14 06:45:52,737 [INFO    ] __main__: train step 15378: loss: 1.0526, policy_loss: 1.0046, value_loss: 0.5558
2024-07-14 06:45:53,038 [INFO    ] __main__: train step 15379: loss: 1.0526, policy_loss: 1.0045, value_loss: 0.5558
2024-07-14 06:45:53,339 [INFO    ] __main__: train step 15380: loss: 1.0525, policy_loss: 1.0045, value_loss: 0.5558
2024-07-14 06:45:53,638 [INFO    ] __main__: train step 15381: loss: 1.0525, policy_loss: 1.0045, value_loss: 0.5557
2024-07-14 06:45:55,242 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:45:55,738 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:45:55,806 [INFO    ] __main__: train step 15382: loss: 1.0525, policy_loss: 1.0045, value_loss: 0.5557
2024-07-14 06:45:56,109 [INFO    ] __main__: train step 15383: loss: 1.0525, policy_loss: 1.0044, value_loss: 0.5557
2024-07-14 06:45:56,397 [INFO    ] __main__: train step 15384: loss: 1.0525, policy_loss: 1.0044, value_loss: 0.5557
2024-07-14 06:45:56,680 [INFO    ] __main__: train step 15385: loss: 1.0524, policy_loss: 1.0044, value_loss: 0.5556
2024-07-14 06:45:56,979 [INFO    ] __main__: train step 15386: loss: 1.0524, policy_loss: 1.0043, value_loss: 0.5556
2024-07-14 06:45:57,264 [INFO    ] __main__: train step 15387: loss: 1.0524, policy_loss: 1.0043, value_loss: 0.5556
2024-07-14 06:45:57,568 [INFO    ] __main__: train step 15388: loss: 1.0524, policy_loss: 1.0043, value_loss: 0.5556
2024-07-14 06:45:57,867 [INFO    ] __main__: train step 15389: loss: 1.0523, policy_loss: 1.0043, value_loss: 0.5555
2024-07-14 06:45:58,188 [INFO    ] __main__: train step 15390: loss: 1.0523, policy_loss: 1.0042, value_loss: 0.5555
2024-07-14 06:45:58,470 [INFO    ] __main__: train step 15391: loss: 1.0523, policy_loss: 1.0042, value_loss: 0.5555
2024-07-14 06:45:58,732 [INFO    ] __main__: train step 15392: loss: 1.0523, policy_loss: 1.0042, value_loss: 0.5554
2024-07-14 06:45:59,000 [INFO    ] __main__: train step 15393: loss: 1.0523, policy_loss: 1.0041, value_loss: 0.5554
2024-07-14 06:45:59,274 [INFO    ] __main__: train step 15394: loss: 1.0522, policy_loss: 1.0041, value_loss: 0.5554
2024-07-14 06:45:59,574 [INFO    ] __main__: train step 15395: loss: 1.0522, policy_loss: 1.0041, value_loss: 0.5554
2024-07-14 06:45:59,868 [INFO    ] __main__: train step 15396: loss: 1.0522, policy_loss: 1.0041, value_loss: 0.5553
2024-07-14 06:46:00,160 [INFO    ] __main__: train step 15397: loss: 1.0522, policy_loss: 1.0040, value_loss: 0.5553
2024-07-14 06:46:00,455 [INFO    ] __main__: train step 15398: loss: 1.0521, policy_loss: 1.0040, value_loss: 0.5553
2024-07-14 06:46:02,080 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:46:02,569 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:46:02,645 [INFO    ] __main__: train step 15399: loss: 1.0521, policy_loss: 1.0040, value_loss: 0.5553
2024-07-14 06:46:02,935 [INFO    ] __main__: train step 15400: loss: 1.0521, policy_loss: 1.0039, value_loss: 0.5552
2024-07-14 06:46:03,236 [INFO    ] __main__: train step 15401: loss: 1.0521, policy_loss: 1.0039, value_loss: 0.5552
2024-07-14 06:46:03,526 [INFO    ] __main__: train step 15402: loss: 1.0520, policy_loss: 1.0039, value_loss: 0.5552
2024-07-14 06:46:03,820 [INFO    ] __main__: train step 15403: loss: 1.0520, policy_loss: 1.0039, value_loss: 0.5552
2024-07-14 06:46:04,128 [INFO    ] __main__: train step 15404: loss: 1.0520, policy_loss: 1.0038, value_loss: 0.5551
2024-07-14 06:46:04,419 [INFO    ] __main__: train step 15405: loss: 1.0520, policy_loss: 1.0038, value_loss: 0.5551
2024-07-14 06:46:04,712 [INFO    ] __main__: train step 15406: loss: 1.0520, policy_loss: 1.0038, value_loss: 0.5551
2024-07-14 06:46:05,010 [INFO    ] __main__: train step 15407: loss: 1.0519, policy_loss: 1.0037, value_loss: 0.5550
2024-07-14 06:46:05,297 [INFO    ] __main__: train step 15408: loss: 1.0519, policy_loss: 1.0037, value_loss: 0.5550
2024-07-14 06:46:05,583 [INFO    ] __main__: train step 15409: loss: 1.0519, policy_loss: 1.0037, value_loss: 0.5550
2024-07-14 06:46:05,877 [INFO    ] __main__: train step 15410: loss: 1.0519, policy_loss: 1.0037, value_loss: 0.5550
2024-07-14 06:46:06,175 [INFO    ] __main__: train step 15411: loss: 1.0518, policy_loss: 1.0036, value_loss: 0.5549
2024-07-14 06:46:06,468 [INFO    ] __main__: train step 15412: loss: 1.0518, policy_loss: 1.0036, value_loss: 0.5549
2024-07-14 06:46:06,767 [INFO    ] __main__: train step 15413: loss: 1.0518, policy_loss: 1.0036, value_loss: 0.5549
2024-07-14 06:46:07,046 [INFO    ] __main__: train step 15414: loss: 1.0518, policy_loss: 1.0035, value_loss: 0.5549
2024-07-14 06:46:07,312 [INFO    ] __main__: train step 15415: loss: 1.0518, policy_loss: 1.0035, value_loss: 0.5548
2024-07-14 06:46:08,894 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:46:09,371 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:46:09,443 [INFO    ] __main__: train step 15416: loss: 1.0517, policy_loss: 1.0035, value_loss: 0.5548
2024-07-14 06:46:09,741 [INFO    ] __main__: train step 15417: loss: 1.0517, policy_loss: 1.0035, value_loss: 0.5548
2024-07-14 06:46:10,037 [INFO    ] __main__: train step 15418: loss: 1.0517, policy_loss: 1.0034, value_loss: 0.5547
2024-07-14 06:46:10,324 [INFO    ] __main__: train step 15419: loss: 1.0517, policy_loss: 1.0034, value_loss: 0.5547
2024-07-14 06:46:10,620 [INFO    ] __main__: train step 15420: loss: 1.0516, policy_loss: 1.0034, value_loss: 0.5547
2024-07-14 06:46:10,907 [INFO    ] __main__: train step 15421: loss: 1.0516, policy_loss: 1.0033, value_loss: 0.5547
2024-07-14 06:46:11,206 [INFO    ] __main__: train step 15422: loss: 1.0516, policy_loss: 1.0033, value_loss: 0.5546
2024-07-14 06:46:11,494 [INFO    ] __main__: train step 15423: loss: 1.0516, policy_loss: 1.0033, value_loss: 0.5546
2024-07-14 06:46:11,786 [INFO    ] __main__: train step 15424: loss: 1.0515, policy_loss: 1.0033, value_loss: 0.5546
2024-07-14 06:46:12,087 [INFO    ] __main__: train step 15425: loss: 1.0515, policy_loss: 1.0032, value_loss: 0.5545
2024-07-14 06:46:12,368 [INFO    ] __main__: train step 15426: loss: 1.0515, policy_loss: 1.0032, value_loss: 0.5545
2024-07-14 06:46:12,632 [INFO    ] __main__: train step 15427: loss: 1.0515, policy_loss: 1.0032, value_loss: 0.5545
2024-07-14 06:46:12,907 [INFO    ] __main__: train step 15428: loss: 1.0515, policy_loss: 1.0031, value_loss: 0.5545
2024-07-14 06:46:13,174 [INFO    ] __main__: train step 15429: loss: 1.0514, policy_loss: 1.0031, value_loss: 0.5544
2024-07-14 06:46:13,461 [INFO    ] __main__: train step 15430: loss: 1.0514, policy_loss: 1.0031, value_loss: 0.5544
2024-07-14 06:46:16,816 [INFO    ] __main__: train step 15431: loss: 1.0514, policy_loss: 1.0031, value_loss: 0.5544
2024-07-14 06:46:17,108 [INFO    ] __main__: train step 15432: loss: 1.0514, policy_loss: 1.0030, value_loss: 0.5544
2024-07-14 06:46:18,730 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:46:19,234 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:46:19,304 [INFO    ] __main__: train step 15433: loss: 1.0513, policy_loss: 1.0030, value_loss: 0.5543
2024-07-14 06:46:19,604 [INFO    ] __main__: train step 15434: loss: 1.0513, policy_loss: 1.0030, value_loss: 0.5543
2024-07-14 06:46:19,902 [INFO    ] __main__: train step 15435: loss: 1.0513, policy_loss: 1.0029, value_loss: 0.5543
2024-07-14 06:46:20,200 [INFO    ] __main__: train step 15436: loss: 1.0513, policy_loss: 1.0029, value_loss: 0.5542
2024-07-14 06:46:20,487 [INFO    ] __main__: train step 15437: loss: 1.0513, policy_loss: 1.0029, value_loss: 0.5542
2024-07-14 06:46:20,784 [INFO    ] __main__: train step 15438: loss: 1.0512, policy_loss: 1.0029, value_loss: 0.5542
2024-07-14 06:46:21,077 [INFO    ] __main__: train step 15439: loss: 1.0512, policy_loss: 1.0028, value_loss: 0.5542
2024-07-14 06:46:21,372 [INFO    ] __main__: train step 15440: loss: 1.0512, policy_loss: 1.0028, value_loss: 0.5541
2024-07-14 06:46:21,682 [INFO    ] __main__: train step 15441: loss: 1.0512, policy_loss: 1.0028, value_loss: 0.5541
2024-07-14 06:46:21,986 [INFO    ] __main__: train step 15442: loss: 1.0511, policy_loss: 1.0027, value_loss: 0.5541
2024-07-14 06:46:22,276 [INFO    ] __main__: train step 15443: loss: 1.0511, policy_loss: 1.0027, value_loss: 0.5541
2024-07-14 06:46:22,572 [INFO    ] __main__: train step 15444: loss: 1.0511, policy_loss: 1.0027, value_loss: 0.5540
2024-07-14 06:46:22,853 [INFO    ] __main__: train step 15445: loss: 1.0511, policy_loss: 1.0027, value_loss: 0.5540
2024-07-14 06:46:23,145 [INFO    ] __main__: train step 15446: loss: 1.0511, policy_loss: 1.0026, value_loss: 0.5540
2024-07-14 06:46:23,427 [INFO    ] __main__: train step 15447: loss: 1.0510, policy_loss: 1.0026, value_loss: 0.5540
2024-07-14 06:46:23,704 [INFO    ] __main__: train step 15448: loss: 1.0510, policy_loss: 1.0026, value_loss: 0.5539
2024-07-14 06:46:23,983 [INFO    ] __main__: train step 15449: loss: 1.0510, policy_loss: 1.0026, value_loss: 0.5539
2024-07-14 06:46:25,574 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:46:26,068 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:46:26,142 [INFO    ] __main__: train step 15450: loss: 1.0510, policy_loss: 1.0025, value_loss: 0.5539
2024-07-14 06:46:26,441 [INFO    ] __main__: train step 15451: loss: 1.0509, policy_loss: 1.0025, value_loss: 0.5538
2024-07-14 06:46:26,729 [INFO    ] __main__: train step 15452: loss: 1.0509, policy_loss: 1.0025, value_loss: 0.5538
2024-07-14 06:46:27,018 [INFO    ] __main__: train step 15453: loss: 1.0509, policy_loss: 1.0024, value_loss: 0.5538
2024-07-14 06:46:27,307 [INFO    ] __main__: train step 15454: loss: 1.0509, policy_loss: 1.0024, value_loss: 0.5538
2024-07-14 06:46:27,593 [INFO    ] __main__: train step 15455: loss: 1.0508, policy_loss: 1.0024, value_loss: 0.5537
2024-07-14 06:46:27,899 [INFO    ] __main__: train step 15456: loss: 1.0508, policy_loss: 1.0024, value_loss: 0.5537
2024-07-14 06:46:28,192 [INFO    ] __main__: train step 15457: loss: 1.0508, policy_loss: 1.0023, value_loss: 0.5537
2024-07-14 06:46:28,500 [INFO    ] __main__: train step 15458: loss: 1.0508, policy_loss: 1.0023, value_loss: 0.5537
2024-07-14 06:46:28,791 [INFO    ] __main__: train step 15459: loss: 1.0508, policy_loss: 1.0023, value_loss: 0.5536
2024-07-14 06:46:29,089 [INFO    ] __main__: train step 15460: loss: 1.0507, policy_loss: 1.0022, value_loss: 0.5536
2024-07-14 06:46:29,400 [INFO    ] __main__: train step 15461: loss: 1.0507, policy_loss: 1.0022, value_loss: 0.5536
2024-07-14 06:46:29,685 [INFO    ] __main__: train step 15462: loss: 1.0507, policy_loss: 1.0022, value_loss: 0.5535
2024-07-14 06:46:29,966 [INFO    ] __main__: train step 15463: loss: 1.0507, policy_loss: 1.0022, value_loss: 0.5535
2024-07-14 06:46:30,254 [INFO    ] __main__: train step 15464: loss: 1.0506, policy_loss: 1.0021, value_loss: 0.5535
2024-07-14 06:46:30,540 [INFO    ] __main__: train step 15465: loss: 1.0506, policy_loss: 1.0021, value_loss: 0.5535
2024-07-14 06:46:30,829 [INFO    ] __main__: train step 15466: loss: 1.0506, policy_loss: 1.0021, value_loss: 0.5534
2024-07-14 06:46:32,466 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:46:32,951 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:46:33,019 [INFO    ] __main__: train step 15467: loss: 1.0506, policy_loss: 1.0020, value_loss: 0.5534
2024-07-14 06:46:33,305 [INFO    ] __main__: train step 15468: loss: 1.0505, policy_loss: 1.0020, value_loss: 0.5534
2024-07-14 06:46:33,591 [INFO    ] __main__: train step 15469: loss: 1.0505, policy_loss: 1.0020, value_loss: 0.5533
2024-07-14 06:46:33,872 [INFO    ] __main__: train step 15470: loss: 1.0505, policy_loss: 1.0020, value_loss: 0.5533
2024-07-14 06:46:34,159 [INFO    ] __main__: train step 15471: loss: 1.0505, policy_loss: 1.0019, value_loss: 0.5533
2024-07-14 06:46:34,434 [INFO    ] __main__: train step 15472: loss: 1.0505, policy_loss: 1.0019, value_loss: 0.5533
2024-07-14 06:46:34,707 [INFO    ] __main__: train step 15473: loss: 1.0504, policy_loss: 1.0019, value_loss: 0.5532
2024-07-14 06:46:34,995 [INFO    ] __main__: train step 15474: loss: 1.0504, policy_loss: 1.0018, value_loss: 0.5532
2024-07-14 06:46:35,280 [INFO    ] __main__: train step 15475: loss: 1.0504, policy_loss: 1.0018, value_loss: 0.5532
2024-07-14 06:46:35,568 [INFO    ] __main__: train step 15476: loss: 1.0504, policy_loss: 1.0018, value_loss: 0.5532
2024-07-14 06:46:35,854 [INFO    ] __main__: train step 15477: loss: 1.0503, policy_loss: 1.0018, value_loss: 0.5531
2024-07-14 06:46:36,145 [INFO    ] __main__: train step 15478: loss: 1.0503, policy_loss: 1.0017, value_loss: 0.5531
2024-07-14 06:46:36,430 [INFO    ] __main__: train step 15479: loss: 1.0503, policy_loss: 1.0017, value_loss: 0.5531
2024-07-14 06:46:36,719 [INFO    ] __main__: train step 15480: loss: 1.0503, policy_loss: 1.0017, value_loss: 0.5530
2024-07-14 06:46:37,011 [INFO    ] __main__: train step 15481: loss: 1.0503, policy_loss: 1.0017, value_loss: 0.5530
2024-07-14 06:46:37,299 [INFO    ] __main__: train step 15482: loss: 1.0502, policy_loss: 1.0016, value_loss: 0.5530
2024-07-14 06:46:37,608 [INFO    ] __main__: train step 15483: loss: 1.0502, policy_loss: 1.0016, value_loss: 0.5530
2024-07-14 06:46:39,229 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:46:39,715 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:46:39,789 [INFO    ] __main__: train step 15484: loss: 1.0502, policy_loss: 1.0016, value_loss: 0.5529
2024-07-14 06:46:40,091 [INFO    ] __main__: train step 15485: loss: 1.0502, policy_loss: 1.0015, value_loss: 0.5529
2024-07-14 06:46:40,381 [INFO    ] __main__: train step 15486: loss: 1.0501, policy_loss: 1.0015, value_loss: 0.5529
2024-07-14 06:46:40,659 [INFO    ] __main__: train step 15487: loss: 1.0501, policy_loss: 1.0015, value_loss: 0.5529
2024-07-14 06:46:40,941 [INFO    ] __main__: train step 15488: loss: 1.0501, policy_loss: 1.0015, value_loss: 0.5528
2024-07-14 06:46:41,231 [INFO    ] __main__: train step 15489: loss: 1.0501, policy_loss: 1.0014, value_loss: 0.5528
2024-07-14 06:46:41,527 [INFO    ] __main__: train step 15490: loss: 1.0500, policy_loss: 1.0014, value_loss: 0.5528
2024-07-14 06:46:41,804 [INFO    ] __main__: train step 15491: loss: 1.0500, policy_loss: 1.0014, value_loss: 0.5527
2024-07-14 06:46:42,096 [INFO    ] __main__: train step 15492: loss: 1.0500, policy_loss: 1.0013, value_loss: 0.5527
2024-07-14 06:46:42,397 [INFO    ] __main__: train step 15493: loss: 1.0500, policy_loss: 1.0013, value_loss: 0.5527
2024-07-14 06:46:42,695 [INFO    ] __main__: train step 15494: loss: 1.0500, policy_loss: 1.0013, value_loss: 0.5527
2024-07-14 06:46:42,987 [INFO    ] __main__: train step 15495: loss: 1.0499, policy_loss: 1.0013, value_loss: 0.5526
2024-07-14 06:46:43,276 [INFO    ] __main__: train step 15496: loss: 1.0499, policy_loss: 1.0012, value_loss: 0.5526
2024-07-14 06:46:43,564 [INFO    ] __main__: train step 15497: loss: 1.0499, policy_loss: 1.0012, value_loss: 0.5526
2024-07-14 06:46:43,841 [INFO    ] __main__: train step 15498: loss: 1.0499, policy_loss: 1.0012, value_loss: 0.5526
2024-07-14 06:46:44,104 [INFO    ] __main__: train step 15499: loss: 1.0498, policy_loss: 1.0011, value_loss: 0.5525
2024-07-14 06:46:44,371 [INFO    ] __main__: train step 15500: loss: 1.0498, policy_loss: 1.0011, value_loss: 0.5525
2024-07-14 06:46:45,993 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:46:46,486 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:46:46,555 [INFO    ] __main__: train step 15501: loss: 1.0498, policy_loss: 1.0011, value_loss: 0.5525
2024-07-14 06:46:46,846 [INFO    ] __main__: train step 15502: loss: 1.0498, policy_loss: 1.0011, value_loss: 0.5525
2024-07-14 06:46:47,136 [INFO    ] __main__: train step 15503: loss: 1.0498, policy_loss: 1.0010, value_loss: 0.5524
2024-07-14 06:46:47,424 [INFO    ] __main__: train step 15504: loss: 1.0497, policy_loss: 1.0010, value_loss: 0.5524
2024-07-14 06:46:47,704 [INFO    ] __main__: train step 15505: loss: 1.0497, policy_loss: 1.0010, value_loss: 0.5524
2024-07-14 06:46:47,994 [INFO    ] __main__: train step 15506: loss: 1.0497, policy_loss: 1.0010, value_loss: 0.5523
2024-07-14 06:46:48,277 [INFO    ] __main__: train step 15507: loss: 1.0497, policy_loss: 1.0009, value_loss: 0.5523
2024-07-14 06:46:48,570 [INFO    ] __main__: train step 15508: loss: 1.0496, policy_loss: 1.0009, value_loss: 0.5523
2024-07-14 06:46:48,852 [INFO    ] __main__: train step 15509: loss: 1.0496, policy_loss: 1.0009, value_loss: 0.5523
2024-07-14 06:46:49,140 [INFO    ] __main__: train step 15510: loss: 1.0496, policy_loss: 1.0008, value_loss: 0.5522
2024-07-14 06:46:49,422 [INFO    ] __main__: train step 15511: loss: 1.0496, policy_loss: 1.0008, value_loss: 0.5522
2024-07-14 06:46:49,713 [INFO    ] __main__: train step 15512: loss: 1.0496, policy_loss: 1.0008, value_loss: 0.5522
2024-07-14 06:46:49,995 [INFO    ] __main__: train step 15513: loss: 1.0495, policy_loss: 1.0008, value_loss: 0.5522
2024-07-14 06:46:50,283 [INFO    ] __main__: train step 15514: loss: 1.0495, policy_loss: 1.0007, value_loss: 0.5521
2024-07-14 06:46:50,566 [INFO    ] __main__: train step 15515: loss: 1.0495, policy_loss: 1.0007, value_loss: 0.5521
2024-07-14 06:46:50,856 [INFO    ] __main__: train step 15516: loss: 1.0495, policy_loss: 1.0007, value_loss: 0.5521
2024-07-14 06:46:51,137 [INFO    ] __main__: train step 15517: loss: 1.0494, policy_loss: 1.0006, value_loss: 0.5520
2024-07-14 06:46:52,728 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:46:53,217 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:46:53,285 [INFO    ] __main__: train step 15518: loss: 1.0494, policy_loss: 1.0006, value_loss: 0.5520
2024-07-14 06:46:53,567 [INFO    ] __main__: train step 15519: loss: 1.0494, policy_loss: 1.0006, value_loss: 0.5520
2024-07-14 06:46:53,851 [INFO    ] __main__: train step 15520: loss: 1.0494, policy_loss: 1.0006, value_loss: 0.5520
2024-07-14 06:46:54,135 [INFO    ] __main__: train step 15521: loss: 1.0494, policy_loss: 1.0005, value_loss: 0.5519
2024-07-14 06:46:54,409 [INFO    ] __main__: train step 15522: loss: 1.0493, policy_loss: 1.0005, value_loss: 0.5519
2024-07-14 06:46:54,703 [INFO    ] __main__: train step 15523: loss: 1.0493, policy_loss: 1.0005, value_loss: 0.5519
2024-07-14 06:46:54,988 [INFO    ] __main__: train step 15524: loss: 1.0493, policy_loss: 1.0004, value_loss: 0.5519
2024-07-14 06:46:55,277 [INFO    ] __main__: train step 15525: loss: 1.0493, policy_loss: 1.0004, value_loss: 0.5518
2024-07-14 06:46:55,559 [INFO    ] __main__: train step 15526: loss: 1.0492, policy_loss: 1.0004, value_loss: 0.5518
2024-07-14 06:46:55,857 [INFO    ] __main__: train step 15527: loss: 1.0492, policy_loss: 1.0004, value_loss: 0.5518
2024-07-14 06:46:56,145 [INFO    ] __main__: train step 15528: loss: 1.0492, policy_loss: 1.0003, value_loss: 0.5517
2024-07-14 06:46:56,414 [INFO    ] __main__: train step 15529: loss: 1.0492, policy_loss: 1.0003, value_loss: 0.5517
2024-07-14 06:46:56,707 [INFO    ] __main__: train step 15530: loss: 1.0491, policy_loss: 1.0003, value_loss: 0.5517
2024-07-14 06:46:57,004 [INFO    ] __main__: train step 15531: loss: 1.0491, policy_loss: 1.0003, value_loss: 0.5517
2024-07-14 06:46:57,300 [INFO    ] __main__: train step 15532: loss: 1.0491, policy_loss: 1.0002, value_loss: 0.5516
2024-07-14 06:47:00,948 [INFO    ] __main__: train step 15533: loss: 1.0491, policy_loss: 1.0002, value_loss: 0.5516
2024-07-14 06:47:01,248 [INFO    ] __main__: train step 15534: loss: 1.0491, policy_loss: 1.0002, value_loss: 0.5516
2024-07-14 06:47:02,862 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:47:03,351 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:47:03,428 [INFO    ] __main__: train step 15535: loss: 1.0490, policy_loss: 1.0001, value_loss: 0.5516
2024-07-14 06:47:03,710 [INFO    ] __main__: train step 15536: loss: 1.0490, policy_loss: 1.0001, value_loss: 0.5515
2024-07-14 06:47:03,995 [INFO    ] __main__: train step 15537: loss: 1.0490, policy_loss: 1.0001, value_loss: 0.5515
2024-07-14 06:47:04,271 [INFO    ] __main__: train step 15538: loss: 1.0490, policy_loss: 1.0001, value_loss: 0.5515
2024-07-14 06:47:04,552 [INFO    ] __main__: train step 15539: loss: 1.0489, policy_loss: 1.0000, value_loss: 0.5514
2024-07-14 06:47:04,856 [INFO    ] __main__: train step 15540: loss: 1.0489, policy_loss: 1.0000, value_loss: 0.5514
2024-07-14 06:47:05,152 [INFO    ] __main__: train step 15541: loss: 1.0489, policy_loss: 1.0000, value_loss: 0.5514
2024-07-14 06:47:05,438 [INFO    ] __main__: train step 15542: loss: 1.0489, policy_loss: 0.9999, value_loss: 0.5514
2024-07-14 06:47:05,728 [INFO    ] __main__: train step 15543: loss: 1.0488, policy_loss: 0.9999, value_loss: 0.5513
2024-07-14 06:47:06,016 [INFO    ] __main__: train step 15544: loss: 1.0488, policy_loss: 0.9999, value_loss: 0.5513
2024-07-14 06:47:06,305 [INFO    ] __main__: train step 15545: loss: 1.0488, policy_loss: 0.9999, value_loss: 0.5513
2024-07-14 06:47:06,598 [INFO    ] __main__: train step 15546: loss: 1.0488, policy_loss: 0.9998, value_loss: 0.5513
2024-07-14 06:47:06,887 [INFO    ] __main__: train step 15547: loss: 1.0487, policy_loss: 0.9998, value_loss: 0.5512
2024-07-14 06:47:07,172 [INFO    ] __main__: train step 15548: loss: 1.0487, policy_loss: 0.9998, value_loss: 0.5512
2024-07-14 06:47:07,467 [INFO    ] __main__: train step 15549: loss: 1.0487, policy_loss: 0.9997, value_loss: 0.5512
2024-07-14 06:47:07,758 [INFO    ] __main__: train step 15550: loss: 1.0487, policy_loss: 0.9997, value_loss: 0.5511
2024-07-14 06:47:08,047 [INFO    ] __main__: train step 15551: loss: 1.0487, policy_loss: 0.9997, value_loss: 0.5511
2024-07-14 06:47:09,658 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:47:10,161 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:47:10,230 [INFO    ] __main__: train step 15552: loss: 1.0486, policy_loss: 0.9997, value_loss: 0.5511
2024-07-14 06:47:10,517 [INFO    ] __main__: train step 15553: loss: 1.0486, policy_loss: 0.9996, value_loss: 0.5511
2024-07-14 06:47:10,808 [INFO    ] __main__: train step 15554: loss: 1.0486, policy_loss: 0.9996, value_loss: 0.5510
2024-07-14 06:47:11,084 [INFO    ] __main__: train step 15555: loss: 1.0486, policy_loss: 0.9996, value_loss: 0.5510
2024-07-14 06:47:11,374 [INFO    ] __main__: train step 15556: loss: 1.0485, policy_loss: 0.9996, value_loss: 0.5510
2024-07-14 06:47:11,658 [INFO    ] __main__: train step 15557: loss: 1.0485, policy_loss: 0.9995, value_loss: 0.5510
2024-07-14 06:47:11,956 [INFO    ] __main__: train step 15558: loss: 1.0485, policy_loss: 0.9995, value_loss: 0.5509
2024-07-14 06:47:12,238 [INFO    ] __main__: train step 15559: loss: 1.0485, policy_loss: 0.9995, value_loss: 0.5509
2024-07-14 06:47:12,525 [INFO    ] __main__: train step 15560: loss: 1.0485, policy_loss: 0.9994, value_loss: 0.5509
2024-07-14 06:47:12,818 [INFO    ] __main__: train step 15561: loss: 1.0484, policy_loss: 0.9994, value_loss: 0.5508
2024-07-14 06:47:13,103 [INFO    ] __main__: train step 15562: loss: 1.0484, policy_loss: 0.9994, value_loss: 0.5508
2024-07-14 06:47:13,396 [INFO    ] __main__: train step 15563: loss: 1.0484, policy_loss: 0.9994, value_loss: 0.5508
2024-07-14 06:47:13,678 [INFO    ] __main__: train step 15564: loss: 1.0484, policy_loss: 0.9993, value_loss: 0.5508
2024-07-14 06:47:13,973 [INFO    ] __main__: train step 15565: loss: 1.0483, policy_loss: 0.9993, value_loss: 0.5507
2024-07-14 06:47:14,261 [INFO    ] __main__: train step 15566: loss: 1.0483, policy_loss: 0.9993, value_loss: 0.5507
2024-07-14 06:47:14,562 [INFO    ] __main__: train step 15567: loss: 1.0483, policy_loss: 0.9992, value_loss: 0.5507
2024-07-14 06:47:14,846 [INFO    ] __main__: train step 15568: loss: 1.0483, policy_loss: 0.9992, value_loss: 0.5506
2024-07-14 06:47:16,476 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:47:16,962 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:47:17,036 [INFO    ] __main__: train step 15569: loss: 1.0482, policy_loss: 0.9992, value_loss: 0.5506
2024-07-14 06:47:17,319 [INFO    ] __main__: train step 15570: loss: 1.0482, policy_loss: 0.9992, value_loss: 0.5506
2024-07-14 06:47:17,604 [INFO    ] __main__: train step 15571: loss: 1.0482, policy_loss: 0.9991, value_loss: 0.5506
2024-07-14 06:47:17,890 [INFO    ] __main__: train step 15572: loss: 1.0482, policy_loss: 0.9991, value_loss: 0.5505
2024-07-14 06:47:18,171 [INFO    ] __main__: train step 15573: loss: 1.0482, policy_loss: 0.9991, value_loss: 0.5505
2024-07-14 06:47:18,464 [INFO    ] __main__: train step 15574: loss: 1.0481, policy_loss: 0.9991, value_loss: 0.5505
2024-07-14 06:47:18,768 [INFO    ] __main__: train step 15575: loss: 1.0481, policy_loss: 0.9990, value_loss: 0.5505
2024-07-14 06:47:19,059 [INFO    ] __main__: train step 15576: loss: 1.0481, policy_loss: 0.9990, value_loss: 0.5504
2024-07-14 06:47:19,361 [INFO    ] __main__: train step 15577: loss: 1.0481, policy_loss: 0.9990, value_loss: 0.5504
2024-07-14 06:47:19,644 [INFO    ] __main__: train step 15578: loss: 1.0480, policy_loss: 0.9989, value_loss: 0.5504
2024-07-14 06:47:19,932 [INFO    ] __main__: train step 15579: loss: 1.0480, policy_loss: 0.9989, value_loss: 0.5503
2024-07-14 06:47:20,230 [INFO    ] __main__: train step 15580: loss: 1.0480, policy_loss: 0.9989, value_loss: 0.5503
2024-07-14 06:47:20,514 [INFO    ] __main__: train step 15581: loss: 1.0480, policy_loss: 0.9989, value_loss: 0.5503
2024-07-14 06:47:20,801 [INFO    ] __main__: train step 15582: loss: 1.0479, policy_loss: 0.9988, value_loss: 0.5503
2024-07-14 06:47:21,097 [INFO    ] __main__: train step 15583: loss: 1.0479, policy_loss: 0.9988, value_loss: 0.5502
2024-07-14 06:47:21,395 [INFO    ] __main__: train step 15584: loss: 1.0479, policy_loss: 0.9988, value_loss: 0.5502
2024-07-14 06:47:21,692 [INFO    ] __main__: train step 15585: loss: 1.0479, policy_loss: 0.9988, value_loss: 0.5502
2024-07-14 06:47:23,310 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:47:23,808 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:47:23,876 [INFO    ] __main__: train step 15586: loss: 1.0478, policy_loss: 0.9987, value_loss: 0.5501
2024-07-14 06:47:24,170 [INFO    ] __main__: train step 15587: loss: 1.0478, policy_loss: 0.9987, value_loss: 0.5501
2024-07-14 06:47:24,465 [INFO    ] __main__: train step 15588: loss: 1.0478, policy_loss: 0.9987, value_loss: 0.5501
2024-07-14 06:47:24,757 [INFO    ] __main__: train step 15589: loss: 1.0478, policy_loss: 0.9986, value_loss: 0.5501
2024-07-14 06:47:25,042 [INFO    ] __main__: train step 15590: loss: 1.0478, policy_loss: 0.9986, value_loss: 0.5500
2024-07-14 06:47:25,331 [INFO    ] __main__: train step 15591: loss: 1.0477, policy_loss: 0.9986, value_loss: 0.5500
2024-07-14 06:47:25,627 [INFO    ] __main__: train step 15592: loss: 1.0477, policy_loss: 0.9986, value_loss: 0.5500
2024-07-14 06:47:25,909 [INFO    ] __main__: train step 15593: loss: 1.0477, policy_loss: 0.9985, value_loss: 0.5500
2024-07-14 06:47:26,180 [INFO    ] __main__: train step 15594: loss: 1.0477, policy_loss: 0.9985, value_loss: 0.5499
2024-07-14 06:47:26,465 [INFO    ] __main__: train step 15595: loss: 1.0476, policy_loss: 0.9985, value_loss: 0.5499
2024-07-14 06:47:26,754 [INFO    ] __main__: train step 15596: loss: 1.0476, policy_loss: 0.9985, value_loss: 0.5499
2024-07-14 06:47:27,040 [INFO    ] __main__: train step 15597: loss: 1.0476, policy_loss: 0.9984, value_loss: 0.5498
2024-07-14 06:47:27,315 [INFO    ] __main__: train step 15598: loss: 1.0476, policy_loss: 0.9984, value_loss: 0.5498
2024-07-14 06:47:27,606 [INFO    ] __main__: train step 15599: loss: 1.0475, policy_loss: 0.9984, value_loss: 0.5498
2024-07-14 06:47:27,895 [INFO    ] __main__: train step 15600: loss: 1.0475, policy_loss: 0.9983, value_loss: 0.5498
2024-07-14 06:47:28,191 [INFO    ] __main__: train step 15601: loss: 1.0475, policy_loss: 0.9983, value_loss: 0.5497
2024-07-14 06:47:28,479 [INFO    ] __main__: train step 15602: loss: 1.0475, policy_loss: 0.9983, value_loss: 0.5497
2024-07-14 06:47:30,103 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:47:30,594 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:47:30,667 [INFO    ] __main__: train step 15603: loss: 1.0475, policy_loss: 0.9983, value_loss: 0.5497
2024-07-14 06:47:30,963 [INFO    ] __main__: train step 15604: loss: 1.0474, policy_loss: 0.9982, value_loss: 0.5496
2024-07-14 06:47:31,244 [INFO    ] __main__: train step 15605: loss: 1.0474, policy_loss: 0.9982, value_loss: 0.5496
2024-07-14 06:47:31,525 [INFO    ] __main__: train step 15606: loss: 1.0474, policy_loss: 0.9982, value_loss: 0.5496
2024-07-14 06:47:31,788 [INFO    ] __main__: train step 15607: loss: 1.0474, policy_loss: 0.9981, value_loss: 0.5496
2024-07-14 06:47:32,057 [INFO    ] __main__: train step 15608: loss: 1.0473, policy_loss: 0.9981, value_loss: 0.5495
2024-07-14 06:47:32,328 [INFO    ] __main__: train step 15609: loss: 1.0473, policy_loss: 0.9981, value_loss: 0.5495
2024-07-14 06:47:32,615 [INFO    ] __main__: train step 15610: loss: 1.0473, policy_loss: 0.9981, value_loss: 0.5495
2024-07-14 06:47:32,910 [INFO    ] __main__: train step 15611: loss: 1.0473, policy_loss: 0.9980, value_loss: 0.5494
2024-07-14 06:47:33,208 [INFO    ] __main__: train step 15612: loss: 1.0472, policy_loss: 0.9980, value_loss: 0.5494
2024-07-14 06:47:33,496 [INFO    ] __main__: train step 15613: loss: 1.0472, policy_loss: 0.9980, value_loss: 0.5494
2024-07-14 06:47:33,812 [INFO    ] __main__: train step 15614: loss: 1.0472, policy_loss: 0.9980, value_loss: 0.5494
2024-07-14 06:47:34,106 [INFO    ] __main__: train step 15615: loss: 1.0472, policy_loss: 0.9979, value_loss: 0.5493
2024-07-14 06:47:34,400 [INFO    ] __main__: train step 15616: loss: 1.0471, policy_loss: 0.9979, value_loss: 0.5493
2024-07-14 06:47:34,692 [INFO    ] __main__: train step 15617: loss: 1.0471, policy_loss: 0.9979, value_loss: 0.5493
2024-07-14 06:47:34,971 [INFO    ] __main__: train step 15618: loss: 1.0471, policy_loss: 0.9978, value_loss: 0.5492
2024-07-14 06:47:35,264 [INFO    ] __main__: train step 15619: loss: 1.0471, policy_loss: 0.9978, value_loss: 0.5492
2024-07-14 06:47:36,884 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:47:37,368 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:47:37,443 [INFO    ] __main__: train step 15620: loss: 1.0471, policy_loss: 0.9978, value_loss: 0.5492
2024-07-14 06:47:37,730 [INFO    ] __main__: train step 15621: loss: 1.0470, policy_loss: 0.9978, value_loss: 0.5492
2024-07-14 06:47:38,011 [INFO    ] __main__: train step 15622: loss: 1.0470, policy_loss: 0.9977, value_loss: 0.5491
2024-07-14 06:47:38,297 [INFO    ] __main__: train step 15623: loss: 1.0470, policy_loss: 0.9977, value_loss: 0.5491
2024-07-14 06:47:38,584 [INFO    ] __main__: train step 15624: loss: 1.0470, policy_loss: 0.9977, value_loss: 0.5491
2024-07-14 06:47:38,874 [INFO    ] __main__: train step 15625: loss: 1.0469, policy_loss: 0.9977, value_loss: 0.5491
2024-07-14 06:47:39,174 [INFO    ] __main__: train step 15626: loss: 1.0469, policy_loss: 0.9976, value_loss: 0.5490
2024-07-14 06:47:39,454 [INFO    ] __main__: train step 15627: loss: 1.0469, policy_loss: 0.9976, value_loss: 0.5490
2024-07-14 06:47:39,762 [INFO    ] __main__: train step 15628: loss: 1.0469, policy_loss: 0.9976, value_loss: 0.5490
2024-07-14 06:47:40,066 [INFO    ] __main__: train step 15629: loss: 1.0468, policy_loss: 0.9976, value_loss: 0.5489
2024-07-14 06:47:40,371 [INFO    ] __main__: train step 15630: loss: 1.0468, policy_loss: 0.9975, value_loss: 0.5489
2024-07-14 06:47:40,667 [INFO    ] __main__: train step 15631: loss: 1.0468, policy_loss: 0.9975, value_loss: 0.5489
2024-07-14 06:47:40,956 [INFO    ] __main__: train step 15632: loss: 1.0468, policy_loss: 0.9975, value_loss: 0.5489
2024-07-14 06:47:41,248 [INFO    ] __main__: train step 15633: loss: 1.0468, policy_loss: 0.9974, value_loss: 0.5488
2024-07-14 06:47:41,536 [INFO    ] __main__: train step 15634: loss: 1.0467, policy_loss: 0.9974, value_loss: 0.5488
2024-07-14 06:47:41,838 [INFO    ] __main__: train step 15635: loss: 1.0467, policy_loss: 0.9974, value_loss: 0.5488
2024-07-14 06:47:42,126 [INFO    ] __main__: train step 15636: loss: 1.0467, policy_loss: 0.9974, value_loss: 0.5488
2024-07-14 06:47:43,750 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:47:44,242 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:47:44,314 [INFO    ] __main__: train step 15637: loss: 1.0467, policy_loss: 0.9973, value_loss: 0.5487
2024-07-14 06:47:47,999 [INFO    ] __main__: train step 15638: loss: 1.0466, policy_loss: 0.9973, value_loss: 0.5487
2024-07-14 06:47:48,295 [INFO    ] __main__: train step 15639: loss: 1.0466, policy_loss: 0.9973, value_loss: 0.5487
2024-07-14 06:47:48,590 [INFO    ] __main__: train step 15640: loss: 1.0466, policy_loss: 0.9973, value_loss: 0.5486
2024-07-14 06:47:48,888 [INFO    ] __main__: train step 15641: loss: 1.0466, policy_loss: 0.9972, value_loss: 0.5486
2024-07-14 06:47:49,178 [INFO    ] __main__: train step 15642: loss: 1.0466, policy_loss: 0.9972, value_loss: 0.5486
2024-07-14 06:47:49,457 [INFO    ] __main__: train step 15643: loss: 1.0465, policy_loss: 0.9972, value_loss: 0.5486
2024-07-14 06:47:49,742 [INFO    ] __main__: train step 15644: loss: 1.0465, policy_loss: 0.9971, value_loss: 0.5485
2024-07-14 06:47:50,040 [INFO    ] __main__: train step 15645: loss: 1.0465, policy_loss: 0.9971, value_loss: 0.5485
2024-07-14 06:47:50,339 [INFO    ] __main__: train step 15646: loss: 1.0465, policy_loss: 0.9971, value_loss: 0.5485
2024-07-14 06:47:50,633 [INFO    ] __main__: train step 15647: loss: 1.0464, policy_loss: 0.9971, value_loss: 0.5484
2024-07-14 06:47:50,931 [INFO    ] __main__: train step 15648: loss: 1.0464, policy_loss: 0.9970, value_loss: 0.5484
2024-07-14 06:47:51,236 [INFO    ] __main__: train step 15649: loss: 1.0464, policy_loss: 0.9970, value_loss: 0.5484
2024-07-14 06:47:51,530 [INFO    ] __main__: train step 15650: loss: 1.0464, policy_loss: 0.9970, value_loss: 0.5484
2024-07-14 06:47:51,823 [INFO    ] __main__: train step 15651: loss: 1.0463, policy_loss: 0.9970, value_loss: 0.5483
2024-07-14 06:47:52,115 [INFO    ] __main__: train step 15652: loss: 1.0463, policy_loss: 0.9969, value_loss: 0.5483
2024-07-14 06:47:52,419 [INFO    ] __main__: train step 15653: loss: 1.0463, policy_loss: 0.9969, value_loss: 0.5483
2024-07-14 06:47:54,049 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:47:54,538 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:47:54,608 [INFO    ] __main__: train step 15654: loss: 1.0463, policy_loss: 0.9969, value_loss: 0.5483
2024-07-14 06:47:54,898 [INFO    ] __main__: train step 15655: loss: 1.0463, policy_loss: 0.9969, value_loss: 0.5482
2024-07-14 06:47:55,185 [INFO    ] __main__: train step 15656: loss: 1.0462, policy_loss: 0.9968, value_loss: 0.5482
2024-07-14 06:47:55,469 [INFO    ] __main__: train step 15657: loss: 1.0462, policy_loss: 0.9968, value_loss: 0.5482
2024-07-14 06:47:55,746 [INFO    ] __main__: train step 15658: loss: 1.0462, policy_loss: 0.9968, value_loss: 0.5481
2024-07-14 06:47:56,036 [INFO    ] __main__: train step 15659: loss: 1.0462, policy_loss: 0.9967, value_loss: 0.5481
2024-07-14 06:47:56,323 [INFO    ] __main__: train step 15660: loss: 1.0461, policy_loss: 0.9967, value_loss: 0.5481
2024-07-14 06:47:56,616 [INFO    ] __main__: train step 15661: loss: 1.0461, policy_loss: 0.9967, value_loss: 0.5481
2024-07-14 06:47:56,896 [INFO    ] __main__: train step 15662: loss: 1.0461, policy_loss: 0.9967, value_loss: 0.5480
2024-07-14 06:47:57,177 [INFO    ] __main__: train step 15663: loss: 1.0461, policy_loss: 0.9966, value_loss: 0.5480
2024-07-14 06:47:57,464 [INFO    ] __main__: train step 15664: loss: 1.0461, policy_loss: 0.9966, value_loss: 0.5480
2024-07-14 06:47:57,736 [INFO    ] __main__: train step 15665: loss: 1.0460, policy_loss: 0.9966, value_loss: 0.5479
2024-07-14 06:47:58,022 [INFO    ] __main__: train step 15666: loss: 1.0460, policy_loss: 0.9966, value_loss: 0.5479
2024-07-14 06:47:58,309 [INFO    ] __main__: train step 15667: loss: 1.0460, policy_loss: 0.9965, value_loss: 0.5479
2024-07-14 06:47:58,598 [INFO    ] __main__: train step 15668: loss: 1.0460, policy_loss: 0.9965, value_loss: 0.5479
2024-07-14 06:47:58,888 [INFO    ] __main__: train step 15669: loss: 1.0459, policy_loss: 0.9965, value_loss: 0.5478
2024-07-14 06:47:59,179 [INFO    ] __main__: train step 15670: loss: 1.0459, policy_loss: 0.9965, value_loss: 0.5478
2024-07-14 06:48:00,808 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:48:01,297 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:48:01,368 [INFO    ] __main__: train step 15671: loss: 1.0459, policy_loss: 0.9964, value_loss: 0.5478
2024-07-14 06:48:01,670 [INFO    ] __main__: train step 15672: loss: 1.0459, policy_loss: 0.9964, value_loss: 0.5477
2024-07-14 06:48:01,966 [INFO    ] __main__: train step 15673: loss: 1.0458, policy_loss: 0.9964, value_loss: 0.5477
2024-07-14 06:48:02,256 [INFO    ] __main__: train step 15674: loss: 1.0458, policy_loss: 0.9963, value_loss: 0.5477
2024-07-14 06:48:02,545 [INFO    ] __main__: train step 15675: loss: 1.0458, policy_loss: 0.9963, value_loss: 0.5477
2024-07-14 06:48:02,835 [INFO    ] __main__: train step 15676: loss: 1.0458, policy_loss: 0.9963, value_loss: 0.5476
2024-07-14 06:48:03,126 [INFO    ] __main__: train step 15677: loss: 1.0458, policy_loss: 0.9963, value_loss: 0.5476
2024-07-14 06:48:03,420 [INFO    ] __main__: train step 15678: loss: 1.0457, policy_loss: 0.9962, value_loss: 0.5476
2024-07-14 06:48:03,705 [INFO    ] __main__: train step 15679: loss: 1.0457, policy_loss: 0.9962, value_loss: 0.5475
2024-07-14 06:48:04,000 [INFO    ] __main__: train step 15680: loss: 1.0457, policy_loss: 0.9962, value_loss: 0.5475
2024-07-14 06:48:04,295 [INFO    ] __main__: train step 15681: loss: 1.0457, policy_loss: 0.9962, value_loss: 0.5475
2024-07-14 06:48:04,596 [INFO    ] __main__: train step 15682: loss: 1.0456, policy_loss: 0.9961, value_loss: 0.5475
2024-07-14 06:48:04,881 [INFO    ] __main__: train step 15683: loss: 1.0456, policy_loss: 0.9961, value_loss: 0.5474
2024-07-14 06:48:05,174 [INFO    ] __main__: train step 15684: loss: 1.0456, policy_loss: 0.9961, value_loss: 0.5474
2024-07-14 06:48:05,467 [INFO    ] __main__: train step 15685: loss: 1.0456, policy_loss: 0.9961, value_loss: 0.5474
2024-07-14 06:48:05,759 [INFO    ] __main__: train step 15686: loss: 1.0456, policy_loss: 0.9960, value_loss: 0.5474
2024-07-14 06:48:06,055 [INFO    ] __main__: train step 15687: loss: 1.0455, policy_loss: 0.9960, value_loss: 0.5473
2024-07-14 06:48:07,678 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:48:08,167 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:48:08,236 [INFO    ] __main__: train step 15688: loss: 1.0455, policy_loss: 0.9960, value_loss: 0.5473
2024-07-14 06:48:08,514 [INFO    ] __main__: train step 15689: loss: 1.0455, policy_loss: 0.9960, value_loss: 0.5473
2024-07-14 06:48:08,809 [INFO    ] __main__: train step 15690: loss: 1.0455, policy_loss: 0.9959, value_loss: 0.5472
2024-07-14 06:48:09,112 [INFO    ] __main__: train step 15691: loss: 1.0454, policy_loss: 0.9959, value_loss: 0.5472
2024-07-14 06:48:09,409 [INFO    ] __main__: train step 15692: loss: 1.0454, policy_loss: 0.9959, value_loss: 0.5472
2024-07-14 06:48:09,719 [INFO    ] __main__: train step 15693: loss: 1.0454, policy_loss: 0.9958, value_loss: 0.5472
2024-07-14 06:48:10,026 [INFO    ] __main__: train step 15694: loss: 1.0454, policy_loss: 0.9958, value_loss: 0.5471
2024-07-14 06:48:10,334 [INFO    ] __main__: train step 15695: loss: 1.0453, policy_loss: 0.9958, value_loss: 0.5471
2024-07-14 06:48:10,625 [INFO    ] __main__: train step 15696: loss: 1.0453, policy_loss: 0.9958, value_loss: 0.5471
2024-07-14 06:48:10,923 [INFO    ] __main__: train step 15697: loss: 1.0453, policy_loss: 0.9957, value_loss: 0.5470
2024-07-14 06:48:11,206 [INFO    ] __main__: train step 15698: loss: 1.0453, policy_loss: 0.9957, value_loss: 0.5470
2024-07-14 06:48:11,489 [INFO    ] __main__: train step 15699: loss: 1.0453, policy_loss: 0.9957, value_loss: 0.5470
2024-07-14 06:48:11,779 [INFO    ] __main__: train step 15700: loss: 1.0452, policy_loss: 0.9957, value_loss: 0.5470
2024-07-14 06:48:12,065 [INFO    ] __main__: train step 15701: loss: 1.0452, policy_loss: 0.9956, value_loss: 0.5469
2024-07-14 06:48:12,358 [INFO    ] __main__: train step 15702: loss: 1.0452, policy_loss: 0.9956, value_loss: 0.5469
2024-07-14 06:48:12,642 [INFO    ] __main__: train step 15703: loss: 1.0452, policy_loss: 0.9956, value_loss: 0.5469
2024-07-14 06:48:12,932 [INFO    ] __main__: train step 15704: loss: 1.0451, policy_loss: 0.9956, value_loss: 0.5468
2024-07-14 06:48:14,556 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:48:15,050 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:48:15,120 [INFO    ] __main__: train step 15705: loss: 1.0451, policy_loss: 0.9955, value_loss: 0.5468
2024-07-14 06:48:15,415 [INFO    ] __main__: train step 15706: loss: 1.0451, policy_loss: 0.9955, value_loss: 0.5468
2024-07-14 06:48:15,707 [INFO    ] __main__: train step 15707: loss: 1.0451, policy_loss: 0.9955, value_loss: 0.5468
2024-07-14 06:48:15,991 [INFO    ] __main__: train step 15708: loss: 1.0450, policy_loss: 0.9954, value_loss: 0.5467
2024-07-14 06:48:16,268 [INFO    ] __main__: train step 15709: loss: 1.0450, policy_loss: 0.9954, value_loss: 0.5467
2024-07-14 06:48:16,562 [INFO    ] __main__: train step 15710: loss: 1.0450, policy_loss: 0.9954, value_loss: 0.5467
2024-07-14 06:48:16,864 [INFO    ] __main__: train step 15711: loss: 1.0450, policy_loss: 0.9954, value_loss: 0.5466
2024-07-14 06:48:17,166 [INFO    ] __main__: train step 15712: loss: 1.0450, policy_loss: 0.9953, value_loss: 0.5466
2024-07-14 06:48:17,458 [INFO    ] __main__: train step 15713: loss: 1.0449, policy_loss: 0.9953, value_loss: 0.5466
2024-07-14 06:48:17,748 [INFO    ] __main__: train step 15714: loss: 1.0449, policy_loss: 0.9953, value_loss: 0.5466
2024-07-14 06:48:18,036 [INFO    ] __main__: train step 15715: loss: 1.0449, policy_loss: 0.9953, value_loss: 0.5465
2024-07-14 06:48:18,330 [INFO    ] __main__: train step 15716: loss: 1.0449, policy_loss: 0.9952, value_loss: 0.5465
2024-07-14 06:48:18,634 [INFO    ] __main__: train step 15717: loss: 1.0448, policy_loss: 0.9952, value_loss: 0.5465
2024-07-14 06:48:18,924 [INFO    ] __main__: train step 15718: loss: 1.0448, policy_loss: 0.9952, value_loss: 0.5464
2024-07-14 06:48:19,218 [INFO    ] __main__: train step 15719: loss: 1.0448, policy_loss: 0.9952, value_loss: 0.5464
2024-07-14 06:48:19,502 [INFO    ] __main__: train step 15720: loss: 1.0448, policy_loss: 0.9951, value_loss: 0.5464
2024-07-14 06:48:19,775 [INFO    ] __main__: train step 15721: loss: 1.0447, policy_loss: 0.9951, value_loss: 0.5464
2024-07-14 06:48:21,380 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:48:21,866 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:48:21,935 [INFO    ] __main__: train step 15722: loss: 1.0447, policy_loss: 0.9951, value_loss: 0.5463
2024-07-14 06:48:22,226 [INFO    ] __main__: train step 15723: loss: 1.0447, policy_loss: 0.9951, value_loss: 0.5463
2024-07-14 06:48:22,515 [INFO    ] __main__: train step 15724: loss: 1.0447, policy_loss: 0.9950, value_loss: 0.5463
2024-07-14 06:48:22,809 [INFO    ] __main__: train step 15725: loss: 1.0447, policy_loss: 0.9950, value_loss: 0.5463
2024-07-14 06:48:23,102 [INFO    ] __main__: train step 15726: loss: 1.0446, policy_loss: 0.9950, value_loss: 0.5462
2024-07-14 06:48:23,387 [INFO    ] __main__: train step 15727: loss: 1.0446, policy_loss: 0.9949, value_loss: 0.5462
2024-07-14 06:48:23,677 [INFO    ] __main__: train step 15728: loss: 1.0446, policy_loss: 0.9949, value_loss: 0.5462
2024-07-14 06:48:23,988 [INFO    ] __main__: train step 15729: loss: 1.0446, policy_loss: 0.9949, value_loss: 0.5461
2024-07-14 06:48:24,276 [INFO    ] __main__: train step 15730: loss: 1.0445, policy_loss: 0.9949, value_loss: 0.5461
2024-07-14 06:48:24,566 [INFO    ] __main__: train step 15731: loss: 1.0445, policy_loss: 0.9948, value_loss: 0.5461
2024-07-14 06:48:24,835 [INFO    ] __main__: train step 15732: loss: 1.0445, policy_loss: 0.9948, value_loss: 0.5461
2024-07-14 06:48:25,126 [INFO    ] __main__: train step 15733: loss: 1.0445, policy_loss: 0.9948, value_loss: 0.5460
2024-07-14 06:48:25,400 [INFO    ] __main__: train step 15734: loss: 1.0444, policy_loss: 0.9948, value_loss: 0.5460
2024-07-14 06:48:25,676 [INFO    ] __main__: train step 15735: loss: 1.0444, policy_loss: 0.9947, value_loss: 0.5460
2024-07-14 06:48:25,965 [INFO    ] __main__: train step 15736: loss: 1.0444, policy_loss: 0.9947, value_loss: 0.5459
2024-07-14 06:48:26,265 [INFO    ] __main__: train step 15737: loss: 1.0444, policy_loss: 0.9947, value_loss: 0.5459
2024-07-14 06:48:26,558 [INFO    ] __main__: train step 15738: loss: 1.0444, policy_loss: 0.9947, value_loss: 0.5459
2024-07-14 06:48:28,194 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:48:28,681 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:48:28,750 [INFO    ] __main__: train step 15739: loss: 1.0443, policy_loss: 0.9946, value_loss: 0.5459
2024-07-14 06:48:32,404 [INFO    ] __main__: train step 15740: loss: 1.0443, policy_loss: 0.9946, value_loss: 0.5458
2024-07-14 06:48:32,701 [INFO    ] __main__: train step 15741: loss: 1.0443, policy_loss: 0.9946, value_loss: 0.5458
2024-07-14 06:48:32,976 [INFO    ] __main__: train step 15742: loss: 1.0443, policy_loss: 0.9946, value_loss: 0.5458
2024-07-14 06:48:33,266 [INFO    ] __main__: train step 15743: loss: 1.0442, policy_loss: 0.9945, value_loss: 0.5457
2024-07-14 06:48:33,564 [INFO    ] __main__: train step 15744: loss: 1.0442, policy_loss: 0.9945, value_loss: 0.5457
2024-07-14 06:48:33,858 [INFO    ] __main__: train step 15745: loss: 1.0442, policy_loss: 0.9945, value_loss: 0.5457
2024-07-14 06:48:34,151 [INFO    ] __main__: train step 15746: loss: 1.0442, policy_loss: 0.9945, value_loss: 0.5457
2024-07-14 06:48:34,441 [INFO    ] __main__: train step 15747: loss: 1.0442, policy_loss: 0.9944, value_loss: 0.5456
2024-07-14 06:48:34,732 [INFO    ] __main__: train step 15748: loss: 1.0441, policy_loss: 0.9944, value_loss: 0.5456
2024-07-14 06:48:35,022 [INFO    ] __main__: train step 15749: loss: 1.0441, policy_loss: 0.9944, value_loss: 0.5456
2024-07-14 06:48:35,310 [INFO    ] __main__: train step 15750: loss: 1.0441, policy_loss: 0.9943, value_loss: 0.5456
2024-07-14 06:48:35,607 [INFO    ] __main__: train step 15751: loss: 1.0441, policy_loss: 0.9943, value_loss: 0.5455
2024-07-14 06:48:35,894 [INFO    ] __main__: train step 15752: loss: 1.0440, policy_loss: 0.9943, value_loss: 0.5455
2024-07-14 06:48:36,186 [INFO    ] __main__: train step 15753: loss: 1.0440, policy_loss: 0.9943, value_loss: 0.5455
2024-07-14 06:48:36,479 [INFO    ] __main__: train step 15754: loss: 1.0440, policy_loss: 0.9942, value_loss: 0.5454
2024-07-14 06:48:36,770 [INFO    ] __main__: train step 15755: loss: 1.0440, policy_loss: 0.9942, value_loss: 0.5454
2024-07-14 06:48:38,405 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:48:38,892 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:48:38,966 [INFO    ] __main__: train step 15756: loss: 1.0440, policy_loss: 0.9942, value_loss: 0.5454
2024-07-14 06:48:39,260 [INFO    ] __main__: train step 15757: loss: 1.0439, policy_loss: 0.9942, value_loss: 0.5454
2024-07-14 06:48:39,548 [INFO    ] __main__: train step 15758: loss: 1.0439, policy_loss: 0.9941, value_loss: 0.5453
2024-07-14 06:48:39,833 [INFO    ] __main__: train step 15759: loss: 1.0439, policy_loss: 0.9941, value_loss: 0.5453
2024-07-14 06:48:40,122 [INFO    ] __main__: train step 15760: loss: 1.0439, policy_loss: 0.9941, value_loss: 0.5453
2024-07-14 06:48:40,413 [INFO    ] __main__: train step 15761: loss: 1.0438, policy_loss: 0.9941, value_loss: 0.5452
2024-07-14 06:48:40,709 [INFO    ] __main__: train step 15762: loss: 1.0438, policy_loss: 0.9940, value_loss: 0.5452
2024-07-14 06:48:41,006 [INFO    ] __main__: train step 15763: loss: 1.0438, policy_loss: 0.9940, value_loss: 0.5452
2024-07-14 06:48:41,305 [INFO    ] __main__: train step 15764: loss: 1.0438, policy_loss: 0.9940, value_loss: 0.5452
2024-07-14 06:48:41,608 [INFO    ] __main__: train step 15765: loss: 1.0438, policy_loss: 0.9940, value_loss: 0.5451
2024-07-14 06:48:41,902 [INFO    ] __main__: train step 15766: loss: 1.0437, policy_loss: 0.9939, value_loss: 0.5451
2024-07-14 06:48:42,187 [INFO    ] __main__: train step 15767: loss: 1.0437, policy_loss: 0.9939, value_loss: 0.5451
2024-07-14 06:48:42,479 [INFO    ] __main__: train step 15768: loss: 1.0437, policy_loss: 0.9939, value_loss: 0.5450
2024-07-14 06:48:42,750 [INFO    ] __main__: train step 15769: loss: 1.0437, policy_loss: 0.9939, value_loss: 0.5450
2024-07-14 06:48:43,029 [INFO    ] __main__: train step 15770: loss: 1.0436, policy_loss: 0.9938, value_loss: 0.5450
2024-07-14 06:48:43,323 [INFO    ] __main__: train step 15771: loss: 1.0436, policy_loss: 0.9938, value_loss: 0.5450
2024-07-14 06:48:43,615 [INFO    ] __main__: train step 15772: loss: 1.0436, policy_loss: 0.9938, value_loss: 0.5449
2024-07-14 06:48:45,244 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:48:45,735 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:48:45,807 [INFO    ] __main__: train step 15773: loss: 1.0436, policy_loss: 0.9938, value_loss: 0.5449
2024-07-14 06:48:46,101 [INFO    ] __main__: train step 15774: loss: 1.0436, policy_loss: 0.9937, value_loss: 0.5449
2024-07-14 06:48:46,389 [INFO    ] __main__: train step 15775: loss: 1.0435, policy_loss: 0.9937, value_loss: 0.5449
2024-07-14 06:48:46,677 [INFO    ] __main__: train step 15776: loss: 1.0435, policy_loss: 0.9937, value_loss: 0.5448
2024-07-14 06:48:46,964 [INFO    ] __main__: train step 15777: loss: 1.0435, policy_loss: 0.9937, value_loss: 0.5448
2024-07-14 06:48:47,248 [INFO    ] __main__: train step 15778: loss: 1.0435, policy_loss: 0.9936, value_loss: 0.5448
2024-07-14 06:48:47,543 [INFO    ] __main__: train step 15779: loss: 1.0434, policy_loss: 0.9936, value_loss: 0.5447
2024-07-14 06:48:47,825 [INFO    ] __main__: train step 15780: loss: 1.0434, policy_loss: 0.9936, value_loss: 0.5447
2024-07-14 06:48:48,114 [INFO    ] __main__: train step 15781: loss: 1.0434, policy_loss: 0.9936, value_loss: 0.5447
2024-07-14 06:48:48,407 [INFO    ] __main__: train step 15782: loss: 1.0434, policy_loss: 0.9935, value_loss: 0.5447
2024-07-14 06:48:48,693 [INFO    ] __main__: train step 15783: loss: 1.0434, policy_loss: 0.9935, value_loss: 0.5446
2024-07-14 06:48:48,998 [INFO    ] __main__: train step 15784: loss: 1.0433, policy_loss: 0.9935, value_loss: 0.5446
2024-07-14 06:48:49,283 [INFO    ] __main__: train step 15785: loss: 1.0433, policy_loss: 0.9935, value_loss: 0.5446
2024-07-14 06:48:49,568 [INFO    ] __main__: train step 15786: loss: 1.0433, policy_loss: 0.9934, value_loss: 0.5445
2024-07-14 06:48:49,860 [INFO    ] __main__: train step 15787: loss: 1.0433, policy_loss: 0.9934, value_loss: 0.5445
2024-07-14 06:48:50,156 [INFO    ] __main__: train step 15788: loss: 1.0433, policy_loss: 0.9934, value_loss: 0.5445
2024-07-14 06:48:50,457 [INFO    ] __main__: train step 15789: loss: 1.0432, policy_loss: 0.9934, value_loss: 0.5445
2024-07-14 06:48:52,066 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:48:52,564 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:48:52,631 [INFO    ] __main__: train step 15790: loss: 1.0432, policy_loss: 0.9933, value_loss: 0.5444
2024-07-14 06:48:52,916 [INFO    ] __main__: train step 15791: loss: 1.0432, policy_loss: 0.9933, value_loss: 0.5444
2024-07-14 06:48:53,217 [INFO    ] __main__: train step 15792: loss: 1.0432, policy_loss: 0.9933, value_loss: 0.5444
2024-07-14 06:48:53,513 [INFO    ] __main__: train step 15793: loss: 1.0431, policy_loss: 0.9933, value_loss: 0.5444
2024-07-14 06:48:53,804 [INFO    ] __main__: train step 15794: loss: 1.0431, policy_loss: 0.9932, value_loss: 0.5443
2024-07-14 06:48:54,103 [INFO    ] __main__: train step 15795: loss: 1.0431, policy_loss: 0.9932, value_loss: 0.5443
2024-07-14 06:48:54,394 [INFO    ] __main__: train step 15796: loss: 1.0431, policy_loss: 0.9932, value_loss: 0.5443
2024-07-14 06:48:54,683 [INFO    ] __main__: train step 15797: loss: 1.0431, policy_loss: 0.9932, value_loss: 0.5442
2024-07-14 06:48:54,971 [INFO    ] __main__: train step 15798: loss: 1.0430, policy_loss: 0.9931, value_loss: 0.5442
2024-07-14 06:48:55,265 [INFO    ] __main__: train step 15799: loss: 1.0430, policy_loss: 0.9931, value_loss: 0.5442
2024-07-14 06:48:55,525 [INFO    ] __main__: train step 15800: loss: 1.0430, policy_loss: 0.9931, value_loss: 0.5442
2024-07-14 06:48:55,771 [INFO    ] __main__: train step 15801: loss: 1.0430, policy_loss: 0.9931, value_loss: 0.5441
2024-07-14 06:48:56,033 [INFO    ] __main__: train step 15802: loss: 1.0430, policy_loss: 0.9930, value_loss: 0.5441
2024-07-14 06:48:56,304 [INFO    ] __main__: train step 15803: loss: 1.0429, policy_loss: 0.9930, value_loss: 0.5441
2024-07-14 06:48:56,572 [INFO    ] __main__: train step 15804: loss: 1.0429, policy_loss: 0.9930, value_loss: 0.5440
2024-07-14 06:48:56,840 [INFO    ] __main__: train step 15805: loss: 1.0429, policy_loss: 0.9930, value_loss: 0.5440
2024-07-14 06:48:57,107 [INFO    ] __main__: train step 15806: loss: 1.0429, policy_loss: 0.9929, value_loss: 0.5440
2024-07-14 06:48:58,695 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:48:59,170 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:48:59,246 [INFO    ] __main__: train step 15807: loss: 1.0428, policy_loss: 0.9929, value_loss: 0.5440
2024-07-14 06:48:59,534 [INFO    ] __main__: train step 15808: loss: 1.0428, policy_loss: 0.9929, value_loss: 0.5439
2024-07-14 06:48:59,822 [INFO    ] __main__: train step 15809: loss: 1.0428, policy_loss: 0.9929, value_loss: 0.5439
2024-07-14 06:49:00,110 [INFO    ] __main__: train step 15810: loss: 1.0428, policy_loss: 0.9928, value_loss: 0.5439
2024-07-14 06:49:00,405 [INFO    ] __main__: train step 15811: loss: 1.0428, policy_loss: 0.9928, value_loss: 0.5439
2024-07-14 06:49:00,698 [INFO    ] __main__: train step 15812: loss: 1.0427, policy_loss: 0.9928, value_loss: 0.5438
2024-07-14 06:49:00,985 [INFO    ] __main__: train step 15813: loss: 1.0427, policy_loss: 0.9928, value_loss: 0.5438
2024-07-14 06:49:01,273 [INFO    ] __main__: train step 15814: loss: 1.0427, policy_loss: 0.9927, value_loss: 0.5438
2024-07-14 06:49:01,557 [INFO    ] __main__: train step 15815: loss: 1.0427, policy_loss: 0.9927, value_loss: 0.5437
2024-07-14 06:49:01,847 [INFO    ] __main__: train step 15816: loss: 1.0427, policy_loss: 0.9927, value_loss: 0.5437
2024-07-14 06:49:02,145 [INFO    ] __main__: train step 15817: loss: 1.0426, policy_loss: 0.9927, value_loss: 0.5437
2024-07-14 06:49:02,435 [INFO    ] __main__: train step 15818: loss: 1.0426, policy_loss: 0.9926, value_loss: 0.5437
2024-07-14 06:49:02,731 [INFO    ] __main__: train step 15819: loss: 1.0426, policy_loss: 0.9926, value_loss: 0.5436
2024-07-14 06:49:03,027 [INFO    ] __main__: train step 15820: loss: 1.0426, policy_loss: 0.9926, value_loss: 0.5436
2024-07-14 06:49:03,328 [INFO    ] __main__: train step 15821: loss: 1.0425, policy_loss: 0.9926, value_loss: 0.5436
2024-07-14 06:49:03,616 [INFO    ] __main__: train step 15822: loss: 1.0425, policy_loss: 0.9925, value_loss: 0.5435
2024-07-14 06:49:03,917 [INFO    ] __main__: train step 15823: loss: 1.0425, policy_loss: 0.9925, value_loss: 0.5435
2024-07-14 06:49:05,522 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:49:06,006 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:49:06,076 [INFO    ] __main__: train step 15824: loss: 1.0425, policy_loss: 0.9925, value_loss: 0.5435
2024-07-14 06:49:06,364 [INFO    ] __main__: train step 15825: loss: 1.0425, policy_loss: 0.9925, value_loss: 0.5435
2024-07-14 06:49:06,651 [INFO    ] __main__: train step 15826: loss: 1.0424, policy_loss: 0.9924, value_loss: 0.5434
2024-07-14 06:49:06,946 [INFO    ] __main__: train step 15827: loss: 1.0424, policy_loss: 0.9924, value_loss: 0.5434
2024-07-14 06:49:07,230 [INFO    ] __main__: train step 15828: loss: 1.0424, policy_loss: 0.9924, value_loss: 0.5434
2024-07-14 06:49:07,518 [INFO    ] __main__: train step 15829: loss: 1.0424, policy_loss: 0.9924, value_loss: 0.5434
2024-07-14 06:49:07,805 [INFO    ] __main__: train step 15830: loss: 1.0424, policy_loss: 0.9923, value_loss: 0.5433
2024-07-14 06:49:08,099 [INFO    ] __main__: train step 15831: loss: 1.0423, policy_loss: 0.9923, value_loss: 0.5433
2024-07-14 06:49:08,390 [INFO    ] __main__: train step 15832: loss: 1.0423, policy_loss: 0.9923, value_loss: 0.5433
2024-07-14 06:49:08,678 [INFO    ] __main__: train step 15833: loss: 1.0423, policy_loss: 0.9923, value_loss: 0.5432
2024-07-14 06:49:08,944 [INFO    ] __main__: train step 15834: loss: 1.0423, policy_loss: 0.9922, value_loss: 0.5432
2024-07-14 06:49:09,239 [INFO    ] __main__: train step 15835: loss: 1.0422, policy_loss: 0.9922, value_loss: 0.5432
2024-07-14 06:49:09,524 [INFO    ] __main__: train step 15836: loss: 1.0422, policy_loss: 0.9922, value_loss: 0.5432
2024-07-14 06:49:09,811 [INFO    ] __main__: train step 15837: loss: 1.0422, policy_loss: 0.9922, value_loss: 0.5431
2024-07-14 06:49:10,085 [INFO    ] __main__: train step 15838: loss: 1.0422, policy_loss: 0.9921, value_loss: 0.5431
2024-07-14 06:49:10,355 [INFO    ] __main__: train step 15839: loss: 1.0422, policy_loss: 0.9921, value_loss: 0.5431
2024-07-14 06:49:10,642 [INFO    ] __main__: train step 15840: loss: 1.0421, policy_loss: 0.9921, value_loss: 0.5430
2024-07-14 06:49:12,261 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:49:12,748 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:49:12,815 [INFO    ] __main__: train step 15841: loss: 1.0421, policy_loss: 0.9921, value_loss: 0.5430
2024-07-14 06:49:13,110 [INFO    ] __main__: train step 15842: loss: 1.0421, policy_loss: 0.9920, value_loss: 0.5430
2024-07-14 06:49:13,401 [INFO    ] __main__: train step 15843: loss: 1.0421, policy_loss: 0.9920, value_loss: 0.5430
2024-07-14 06:49:13,685 [INFO    ] __main__: train step 15844: loss: 1.0421, policy_loss: 0.9920, value_loss: 0.5429
2024-07-14 06:49:17,172 [INFO    ] __main__: train step 15845: loss: 1.0420, policy_loss: 0.9920, value_loss: 0.5429
2024-07-14 06:49:17,463 [INFO    ] __main__: train step 15846: loss: 1.0420, policy_loss: 0.9919, value_loss: 0.5429
2024-07-14 06:49:17,757 [INFO    ] __main__: train step 15847: loss: 1.0420, policy_loss: 0.9919, value_loss: 0.5429
2024-07-14 06:49:18,049 [INFO    ] __main__: train step 15848: loss: 1.0420, policy_loss: 0.9919, value_loss: 0.5428
2024-07-14 06:49:18,346 [INFO    ] __main__: train step 15849: loss: 1.0419, policy_loss: 0.9919, value_loss: 0.5428
2024-07-14 06:49:18,635 [INFO    ] __main__: train step 15850: loss: 1.0419, policy_loss: 0.9918, value_loss: 0.5428
2024-07-14 06:49:18,933 [INFO    ] __main__: train step 15851: loss: 1.0419, policy_loss: 0.9918, value_loss: 0.5427
2024-07-14 06:49:19,230 [INFO    ] __main__: train step 15852: loss: 1.0419, policy_loss: 0.9918, value_loss: 0.5427
2024-07-14 06:49:19,511 [INFO    ] __main__: train step 15853: loss: 1.0419, policy_loss: 0.9918, value_loss: 0.5427
2024-07-14 06:49:19,797 [INFO    ] __main__: train step 15854: loss: 1.0418, policy_loss: 0.9917, value_loss: 0.5427
2024-07-14 06:49:20,080 [INFO    ] __main__: train step 15855: loss: 1.0418, policy_loss: 0.9917, value_loss: 0.5426
2024-07-14 06:49:20,376 [INFO    ] __main__: train step 15856: loss: 1.0418, policy_loss: 0.9917, value_loss: 0.5426
2024-07-14 06:49:20,662 [INFO    ] __main__: train step 15857: loss: 1.0418, policy_loss: 0.9917, value_loss: 0.5426
2024-07-14 06:49:22,260 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:49:22,737 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:49:22,804 [INFO    ] __main__: train step 15858: loss: 1.0418, policy_loss: 0.9916, value_loss: 0.5425
2024-07-14 06:49:23,088 [INFO    ] __main__: train step 15859: loss: 1.0417, policy_loss: 0.9916, value_loss: 0.5425
2024-07-14 06:49:23,373 [INFO    ] __main__: train step 15860: loss: 1.0417, policy_loss: 0.9916, value_loss: 0.5425
2024-07-14 06:49:23,653 [INFO    ] __main__: train step 15861: loss: 1.0417, policy_loss: 0.9916, value_loss: 0.5425
2024-07-14 06:49:23,939 [INFO    ] __main__: train step 15862: loss: 1.0417, policy_loss: 0.9915, value_loss: 0.5424
2024-07-14 06:49:24,230 [INFO    ] __main__: train step 15863: loss: 1.0416, policy_loss: 0.9915, value_loss: 0.5424
2024-07-14 06:49:24,520 [INFO    ] __main__: train step 15864: loss: 1.0416, policy_loss: 0.9915, value_loss: 0.5424
2024-07-14 06:49:24,805 [INFO    ] __main__: train step 15865: loss: 1.0416, policy_loss: 0.9915, value_loss: 0.5424
2024-07-14 06:49:25,100 [INFO    ] __main__: train step 15866: loss: 1.0416, policy_loss: 0.9914, value_loss: 0.5423
2024-07-14 06:49:25,389 [INFO    ] __main__: train step 15867: loss: 1.0416, policy_loss: 0.9914, value_loss: 0.5423
2024-07-14 06:49:25,669 [INFO    ] __main__: train step 15868: loss: 1.0415, policy_loss: 0.9914, value_loss: 0.5423
2024-07-14 06:49:25,941 [INFO    ] __main__: train step 15869: loss: 1.0415, policy_loss: 0.9914, value_loss: 0.5422
2024-07-14 06:49:26,233 [INFO    ] __main__: train step 15870: loss: 1.0415, policy_loss: 0.9913, value_loss: 0.5422
2024-07-14 06:49:26,521 [INFO    ] __main__: train step 15871: loss: 1.0415, policy_loss: 0.9913, value_loss: 0.5422
2024-07-14 06:49:26,809 [INFO    ] __main__: train step 15872: loss: 1.0415, policy_loss: 0.9913, value_loss: 0.5422
2024-07-14 06:49:27,090 [INFO    ] __main__: train step 15873: loss: 1.0414, policy_loss: 0.9913, value_loss: 0.5421
2024-07-14 06:49:27,376 [INFO    ] __main__: train step 15874: loss: 1.0414, policy_loss: 0.9912, value_loss: 0.5421
2024-07-14 06:49:28,996 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:49:29,495 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:49:29,565 [INFO    ] __main__: train step 15875: loss: 1.0414, policy_loss: 0.9912, value_loss: 0.5421
2024-07-14 06:49:29,857 [INFO    ] __main__: train step 15876: loss: 1.0414, policy_loss: 0.9912, value_loss: 0.5420
2024-07-14 06:49:30,146 [INFO    ] __main__: train step 15877: loss: 1.0413, policy_loss: 0.9912, value_loss: 0.5420
2024-07-14 06:49:30,437 [INFO    ] __main__: train step 15878: loss: 1.0413, policy_loss: 0.9911, value_loss: 0.5420
2024-07-14 06:49:30,730 [INFO    ] __main__: train step 15879: loss: 1.0413, policy_loss: 0.9911, value_loss: 0.5420
2024-07-14 06:49:31,020 [INFO    ] __main__: train step 15880: loss: 1.0413, policy_loss: 0.9911, value_loss: 0.5419
2024-07-14 06:49:31,292 [INFO    ] __main__: train step 15881: loss: 1.0413, policy_loss: 0.9911, value_loss: 0.5419
2024-07-14 06:49:31,584 [INFO    ] __main__: train step 15882: loss: 1.0412, policy_loss: 0.9911, value_loss: 0.5419
2024-07-14 06:49:31,873 [INFO    ] __main__: train step 15883: loss: 1.0412, policy_loss: 0.9910, value_loss: 0.5419
2024-07-14 06:49:32,174 [INFO    ] __main__: train step 15884: loss: 1.0412, policy_loss: 0.9910, value_loss: 0.5418
2024-07-14 06:49:32,470 [INFO    ] __main__: train step 15885: loss: 1.0412, policy_loss: 0.9910, value_loss: 0.5418
2024-07-14 06:49:32,754 [INFO    ] __main__: train step 15886: loss: 1.0412, policy_loss: 0.9910, value_loss: 0.5418
2024-07-14 06:49:33,041 [INFO    ] __main__: train step 15887: loss: 1.0411, policy_loss: 0.9909, value_loss: 0.5417
2024-07-14 06:49:33,329 [INFO    ] __main__: train step 15888: loss: 1.0411, policy_loss: 0.9909, value_loss: 0.5417
2024-07-14 06:49:33,612 [INFO    ] __main__: train step 15889: loss: 1.0411, policy_loss: 0.9909, value_loss: 0.5417
2024-07-14 06:49:33,903 [INFO    ] __main__: train step 15890: loss: 1.0411, policy_loss: 0.9909, value_loss: 0.5417
2024-07-14 06:49:34,187 [INFO    ] __main__: train step 15891: loss: 1.0411, policy_loss: 0.9908, value_loss: 0.5416
2024-07-14 06:49:35,808 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:49:36,290 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:49:36,360 [INFO    ] __main__: train step 15892: loss: 1.0410, policy_loss: 0.9908, value_loss: 0.5416
2024-07-14 06:49:36,651 [INFO    ] __main__: train step 15893: loss: 1.0410, policy_loss: 0.9908, value_loss: 0.5416
2024-07-14 06:49:36,937 [INFO    ] __main__: train step 15894: loss: 1.0410, policy_loss: 0.9908, value_loss: 0.5415
2024-07-14 06:49:37,218 [INFO    ] __main__: train step 15895: loss: 1.0410, policy_loss: 0.9907, value_loss: 0.5415
2024-07-14 06:49:37,502 [INFO    ] __main__: train step 15896: loss: 1.0410, policy_loss: 0.9907, value_loss: 0.5415
2024-07-14 06:49:37,790 [INFO    ] __main__: train step 15897: loss: 1.0409, policy_loss: 0.9907, value_loss: 0.5415
2024-07-14 06:49:38,079 [INFO    ] __main__: train step 15898: loss: 1.0409, policy_loss: 0.9907, value_loss: 0.5414
2024-07-14 06:49:38,370 [INFO    ] __main__: train step 15899: loss: 1.0409, policy_loss: 0.9906, value_loss: 0.5414
2024-07-14 06:49:38,666 [INFO    ] __main__: train step 15900: loss: 1.0409, policy_loss: 0.9906, value_loss: 0.5414
2024-07-14 06:49:38,949 [INFO    ] __main__: train step 15901: loss: 1.0408, policy_loss: 0.9906, value_loss: 0.5414
2024-07-14 06:49:39,240 [INFO    ] __main__: train step 15902: loss: 1.0408, policy_loss: 0.9906, value_loss: 0.5413
2024-07-14 06:49:39,540 [INFO    ] __main__: train step 15903: loss: 1.0408, policy_loss: 0.9905, value_loss: 0.5413
2024-07-14 06:49:39,826 [INFO    ] __main__: train step 15904: loss: 1.0408, policy_loss: 0.9905, value_loss: 0.5413
2024-07-14 06:49:40,122 [INFO    ] __main__: train step 15905: loss: 1.0408, policy_loss: 0.9905, value_loss: 0.5412
2024-07-14 06:49:40,409 [INFO    ] __main__: train step 15906: loss: 1.0407, policy_loss: 0.9905, value_loss: 0.5412
2024-07-14 06:49:40,699 [INFO    ] __main__: train step 15907: loss: 1.0407, policy_loss: 0.9904, value_loss: 0.5412
2024-07-14 06:49:41,003 [INFO    ] __main__: train step 15908: loss: 1.0407, policy_loss: 0.9904, value_loss: 0.5412
2024-07-14 06:49:42,612 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:49:43,115 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:49:43,184 [INFO    ] __main__: train step 15909: loss: 1.0407, policy_loss: 0.9904, value_loss: 0.5411
2024-07-14 06:49:43,474 [INFO    ] __main__: train step 15910: loss: 1.0407, policy_loss: 0.9904, value_loss: 0.5411
2024-07-14 06:49:43,751 [INFO    ] __main__: train step 15911: loss: 1.0406, policy_loss: 0.9904, value_loss: 0.5411
2024-07-14 06:49:44,042 [INFO    ] __main__: train step 15912: loss: 1.0406, policy_loss: 0.9903, value_loss: 0.5411
2024-07-14 06:49:44,331 [INFO    ] __main__: train step 15913: loss: 1.0406, policy_loss: 0.9903, value_loss: 0.5410
2024-07-14 06:49:44,621 [INFO    ] __main__: train step 15914: loss: 1.0406, policy_loss: 0.9903, value_loss: 0.5410
2024-07-14 06:49:44,908 [INFO    ] __main__: train step 15915: loss: 1.0406, policy_loss: 0.9903, value_loss: 0.5410
2024-07-14 06:49:45,200 [INFO    ] __main__: train step 15916: loss: 1.0405, policy_loss: 0.9902, value_loss: 0.5409
2024-07-14 06:49:45,475 [INFO    ] __main__: train step 15917: loss: 1.0405, policy_loss: 0.9902, value_loss: 0.5409
2024-07-14 06:49:45,765 [INFO    ] __main__: train step 15918: loss: 1.0405, policy_loss: 0.9902, value_loss: 0.5409
2024-07-14 06:49:46,049 [INFO    ] __main__: train step 15919: loss: 1.0405, policy_loss: 0.9902, value_loss: 0.5409
2024-07-14 06:49:46,337 [INFO    ] __main__: train step 15920: loss: 1.0404, policy_loss: 0.9901, value_loss: 0.5408
2024-07-14 06:49:46,625 [INFO    ] __main__: train step 15921: loss: 1.0404, policy_loss: 0.9901, value_loss: 0.5408
2024-07-14 06:49:46,919 [INFO    ] __main__: train step 15922: loss: 1.0404, policy_loss: 0.9901, value_loss: 0.5408
2024-07-14 06:49:47,204 [INFO    ] __main__: train step 15923: loss: 1.0404, policy_loss: 0.9901, value_loss: 0.5407
2024-07-14 06:49:47,498 [INFO    ] __main__: train step 15924: loss: 1.0404, policy_loss: 0.9900, value_loss: 0.5407
2024-07-14 06:49:47,796 [INFO    ] __main__: train step 15925: loss: 1.0403, policy_loss: 0.9900, value_loss: 0.5407
2024-07-14 06:49:49,440 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:49:49,934 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:49:50,004 [INFO    ] __main__: train step 15926: loss: 1.0403, policy_loss: 0.9900, value_loss: 0.5407
2024-07-14 06:49:50,295 [INFO    ] __main__: train step 15927: loss: 1.0403, policy_loss: 0.9900, value_loss: 0.5406
2024-07-14 06:49:50,586 [INFO    ] __main__: train step 15928: loss: 1.0403, policy_loss: 0.9899, value_loss: 0.5406
2024-07-14 06:49:50,878 [INFO    ] __main__: train step 15929: loss: 1.0403, policy_loss: 0.9899, value_loss: 0.5406
2024-07-14 06:49:51,184 [INFO    ] __main__: train step 15930: loss: 1.0402, policy_loss: 0.9899, value_loss: 0.5406
2024-07-14 06:49:51,491 [INFO    ] __main__: train step 15931: loss: 1.0402, policy_loss: 0.9899, value_loss: 0.5405
2024-07-14 06:49:51,790 [INFO    ] __main__: train step 15932: loss: 1.0402, policy_loss: 0.9898, value_loss: 0.5405
2024-07-14 06:49:52,086 [INFO    ] __main__: train step 15933: loss: 1.0402, policy_loss: 0.9898, value_loss: 0.5405
2024-07-14 06:49:52,387 [INFO    ] __main__: train step 15934: loss: 1.0402, policy_loss: 0.9898, value_loss: 0.5404
2024-07-14 06:49:52,679 [INFO    ] __main__: train step 15935: loss: 1.0401, policy_loss: 0.9898, value_loss: 0.5404
2024-07-14 06:49:52,968 [INFO    ] __main__: train step 15936: loss: 1.0401, policy_loss: 0.9898, value_loss: 0.5404
2024-07-14 06:49:53,256 [INFO    ] __main__: train step 15937: loss: 1.0401, policy_loss: 0.9897, value_loss: 0.5404
2024-07-14 06:49:53,550 [INFO    ] __main__: train step 15938: loss: 1.0401, policy_loss: 0.9897, value_loss: 0.5403
2024-07-14 06:49:53,839 [INFO    ] __main__: train step 15939: loss: 1.0401, policy_loss: 0.9897, value_loss: 0.5403
2024-07-14 06:49:54,129 [INFO    ] __main__: train step 15940: loss: 1.0400, policy_loss: 0.9897, value_loss: 0.5403
2024-07-14 06:49:54,418 [INFO    ] __main__: train step 15941: loss: 1.0400, policy_loss: 0.9896, value_loss: 0.5402
2024-07-14 06:49:54,707 [INFO    ] __main__: train step 15942: loss: 1.0400, policy_loss: 0.9896, value_loss: 0.5402
2024-07-14 06:49:56,329 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:49:56,827 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:49:56,898 [INFO    ] __main__: train step 15943: loss: 1.0400, policy_loss: 0.9896, value_loss: 0.5402
2024-07-14 06:49:57,194 [INFO    ] __main__: train step 15944: loss: 1.0400, policy_loss: 0.9896, value_loss: 0.5402
2024-07-14 06:49:57,488 [INFO    ] __main__: train step 15945: loss: 1.0399, policy_loss: 0.9895, value_loss: 0.5401
2024-07-14 06:49:57,780 [INFO    ] __main__: train step 15946: loss: 1.0399, policy_loss: 0.9895, value_loss: 0.5401
2024-07-14 06:49:58,073 [INFO    ] __main__: train step 15947: loss: 1.0399, policy_loss: 0.9895, value_loss: 0.5401
2024-07-14 06:49:58,368 [INFO    ] __main__: train step 15948: loss: 1.0399, policy_loss: 0.9895, value_loss: 0.5401
2024-07-14 06:50:01,938 [INFO    ] __main__: train step 15949: loss: 1.0399, policy_loss: 0.9894, value_loss: 0.5400
2024-07-14 06:50:02,231 [INFO    ] __main__: train step 15950: loss: 1.0398, policy_loss: 0.9894, value_loss: 0.5400
2024-07-14 06:50:02,526 [INFO    ] __main__: train step 15951: loss: 1.0398, policy_loss: 0.9894, value_loss: 0.5400
2024-07-14 06:50:02,818 [INFO    ] __main__: train step 15952: loss: 1.0398, policy_loss: 0.9894, value_loss: 0.5399
2024-07-14 06:50:03,115 [INFO    ] __main__: train step 15953: loss: 1.0398, policy_loss: 0.9894, value_loss: 0.5399
2024-07-14 06:50:03,402 [INFO    ] __main__: train step 15954: loss: 1.0398, policy_loss: 0.9893, value_loss: 0.5399
2024-07-14 06:50:03,695 [INFO    ] __main__: train step 15955: loss: 1.0397, policy_loss: 0.9893, value_loss: 0.5399
2024-07-14 06:50:03,981 [INFO    ] __main__: train step 15956: loss: 1.0397, policy_loss: 0.9893, value_loss: 0.5398
2024-07-14 06:50:04,278 [INFO    ] __main__: train step 15957: loss: 1.0397, policy_loss: 0.9893, value_loss: 0.5398
2024-07-14 06:50:04,577 [INFO    ] __main__: train step 15958: loss: 1.0397, policy_loss: 0.9892, value_loss: 0.5398
2024-07-14 06:50:04,873 [INFO    ] __main__: train step 15959: loss: 1.0397, policy_loss: 0.9892, value_loss: 0.5398
2024-07-14 06:50:06,482 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:50:06,971 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:50:07,038 [INFO    ] __main__: train step 15960: loss: 1.0396, policy_loss: 0.9892, value_loss: 0.5397
2024-07-14 06:50:07,330 [INFO    ] __main__: train step 15961: loss: 1.0396, policy_loss: 0.9892, value_loss: 0.5397
2024-07-14 06:50:07,614 [INFO    ] __main__: train step 15962: loss: 1.0396, policy_loss: 0.9891, value_loss: 0.5397
2024-07-14 06:50:07,897 [INFO    ] __main__: train step 15963: loss: 1.0396, policy_loss: 0.9891, value_loss: 0.5396
2024-07-14 06:50:08,199 [INFO    ] __main__: train step 15964: loss: 1.0395, policy_loss: 0.9891, value_loss: 0.5396
2024-07-14 06:50:08,498 [INFO    ] __main__: train step 15965: loss: 1.0395, policy_loss: 0.9891, value_loss: 0.5396
2024-07-14 06:50:08,792 [INFO    ] __main__: train step 15966: loss: 1.0395, policy_loss: 0.9890, value_loss: 0.5396
2024-07-14 06:50:09,082 [INFO    ] __main__: train step 15967: loss: 1.0395, policy_loss: 0.9890, value_loss: 0.5395
2024-07-14 06:50:09,378 [INFO    ] __main__: train step 15968: loss: 1.0395, policy_loss: 0.9890, value_loss: 0.5395
2024-07-14 06:50:09,669 [INFO    ] __main__: train step 15969: loss: 1.0395, policy_loss: 0.9890, value_loss: 0.5395
2024-07-14 06:50:09,966 [INFO    ] __main__: train step 15970: loss: 1.0394, policy_loss: 0.9890, value_loss: 0.5395
2024-07-14 06:50:10,257 [INFO    ] __main__: train step 15971: loss: 1.0394, policy_loss: 0.9889, value_loss: 0.5394
2024-07-14 06:50:10,545 [INFO    ] __main__: train step 15972: loss: 1.0394, policy_loss: 0.9889, value_loss: 0.5394
2024-07-14 06:50:10,838 [INFO    ] __main__: train step 15973: loss: 1.0394, policy_loss: 0.9889, value_loss: 0.5394
2024-07-14 06:50:11,128 [INFO    ] __main__: train step 15974: loss: 1.0393, policy_loss: 0.9889, value_loss: 0.5393
2024-07-14 06:50:11,412 [INFO    ] __main__: train step 15975: loss: 1.0393, policy_loss: 0.9888, value_loss: 0.5393
2024-07-14 06:50:11,703 [INFO    ] __main__: train step 15976: loss: 1.0393, policy_loss: 0.9888, value_loss: 0.5393
2024-07-14 06:50:13,315 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:50:13,812 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:50:13,882 [INFO    ] __main__: train step 15977: loss: 1.0393, policy_loss: 0.9888, value_loss: 0.5393
2024-07-14 06:50:14,187 [INFO    ] __main__: train step 15978: loss: 1.0393, policy_loss: 0.9888, value_loss: 0.5392
2024-07-14 06:50:14,464 [INFO    ] __main__: train step 15979: loss: 1.0392, policy_loss: 0.9887, value_loss: 0.5392
2024-07-14 06:50:14,754 [INFO    ] __main__: train step 15980: loss: 1.0392, policy_loss: 0.9887, value_loss: 0.5392
2024-07-14 06:50:15,043 [INFO    ] __main__: train step 15981: loss: 1.0392, policy_loss: 0.9887, value_loss: 0.5392
2024-07-14 06:50:15,358 [INFO    ] __main__: train step 15982: loss: 1.0392, policy_loss: 0.9887, value_loss: 0.5391
2024-07-14 06:50:15,653 [INFO    ] __main__: train step 15983: loss: 1.0392, policy_loss: 0.9887, value_loss: 0.5391
2024-07-14 06:50:15,942 [INFO    ] __main__: train step 15984: loss: 1.0392, policy_loss: 0.9886, value_loss: 0.5391
2024-07-14 06:50:16,226 [INFO    ] __main__: train step 15985: loss: 1.0391, policy_loss: 0.9886, value_loss: 0.5390
2024-07-14 06:50:16,527 [INFO    ] __main__: train step 15986: loss: 1.0391, policy_loss: 0.9886, value_loss: 0.5390
2024-07-14 06:50:16,819 [INFO    ] __main__: train step 15987: loss: 1.0391, policy_loss: 0.9886, value_loss: 0.5390
2024-07-14 06:50:17,095 [INFO    ] __main__: train step 15988: loss: 1.0391, policy_loss: 0.9885, value_loss: 0.5390
2024-07-14 06:50:17,384 [INFO    ] __main__: train step 15989: loss: 1.0391, policy_loss: 0.9885, value_loss: 0.5389
2024-07-14 06:50:17,686 [INFO    ] __main__: train step 15990: loss: 1.0390, policy_loss: 0.9885, value_loss: 0.5389
2024-07-14 06:50:17,979 [INFO    ] __main__: train step 15991: loss: 1.0390, policy_loss: 0.9885, value_loss: 0.5389
2024-07-14 06:50:18,282 [INFO    ] __main__: train step 15992: loss: 1.0390, policy_loss: 0.9884, value_loss: 0.5389
2024-07-14 06:50:18,578 [INFO    ] __main__: train step 15993: loss: 1.0390, policy_loss: 0.9884, value_loss: 0.5388
2024-07-14 06:50:20,215 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:50:20,712 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:50:20,782 [INFO    ] __main__: train step 15994: loss: 1.0390, policy_loss: 0.9884, value_loss: 0.5388
2024-07-14 06:50:21,079 [INFO    ] __main__: train step 15995: loss: 1.0389, policy_loss: 0.9884, value_loss: 0.5388
2024-07-14 06:50:21,366 [INFO    ] __main__: train step 15996: loss: 1.0389, policy_loss: 0.9884, value_loss: 0.5387
2024-07-14 06:50:21,655 [INFO    ] __main__: train step 15997: loss: 1.0389, policy_loss: 0.9883, value_loss: 0.5387
2024-07-14 06:50:21,939 [INFO    ] __main__: train step 15998: loss: 1.0389, policy_loss: 0.9883, value_loss: 0.5387
2024-07-14 06:50:22,233 [INFO    ] __main__: train step 15999: loss: 1.0389, policy_loss: 0.9883, value_loss: 0.5387
2024-07-14 06:50:22,517 [INFO    ] __main__: train step 16000: loss: 1.0388, policy_loss: 0.9883, value_loss: 0.5386
2024-07-14 06:50:22,682 [INFO    ] __main__: restored step 15000 for evaluation
2024-07-14 06:50:27,929 [INFO    ] __main__: test network ELO difference from baseline network: +62 (+8/-8) ELO from 32000 self-played games
2024-07-14 06:50:27,933 [INFO    ] __main__: game outcomes: W: 18230, D: 119, L: 13651
2024-07-14 06:50:27,936 [INFO    ] __main__: validation_elo_delta: 62, validation_elo: 2666
2024-07-14 06:50:28,686 [INFO    ] __main__: train step 16001: loss: 1.0388, policy_loss: 0.9882, value_loss: 0.5386
2024-07-14 06:50:28,977 [INFO    ] __main__: train step 16002: loss: 1.0388, policy_loss: 0.9882, value_loss: 0.5386
2024-07-14 06:50:29,269 [INFO    ] __main__: train step 16003: loss: 1.0388, policy_loss: 0.9882, value_loss: 0.5385
2024-07-14 06:50:29,565 [INFO    ] __main__: train step 16004: loss: 1.0388, policy_loss: 0.9882, value_loss: 0.5385
2024-07-14 06:50:29,852 [INFO    ] __main__: train step 16005: loss: 1.0387, policy_loss: 0.9881, value_loss: 0.5385
2024-07-14 06:50:30,149 [INFO    ] __main__: train step 16006: loss: 1.0387, policy_loss: 0.9881, value_loss: 0.5385
2024-07-14 06:50:30,433 [INFO    ] __main__: train step 16007: loss: 1.0387, policy_loss: 0.9881, value_loss: 0.5384
2024-07-14 06:50:30,725 [INFO    ] __main__: train step 16008: loss: 1.0387, policy_loss: 0.9881, value_loss: 0.5384
2024-07-14 06:50:31,004 [INFO    ] __main__: train step 16009: loss: 1.0387, policy_loss: 0.9881, value_loss: 0.5384
2024-07-14 06:50:31,291 [INFO    ] __main__: train step 16010: loss: 1.0386, policy_loss: 0.9880, value_loss: 0.5384
2024-07-14 06:50:32,902 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:50:33,390 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:50:33,459 [INFO    ] __main__: train step 16011: loss: 1.0386, policy_loss: 0.9880, value_loss: 0.5383
2024-07-14 06:50:33,746 [INFO    ] __main__: train step 16012: loss: 1.0386, policy_loss: 0.9880, value_loss: 0.5383
2024-07-14 06:50:34,025 [INFO    ] __main__: train step 16013: loss: 1.0386, policy_loss: 0.9880, value_loss: 0.5383
2024-07-14 06:50:34,315 [INFO    ] __main__: train step 16014: loss: 1.0386, policy_loss: 0.9879, value_loss: 0.5382
2024-07-14 06:50:34,609 [INFO    ] __main__: train step 16015: loss: 1.0385, policy_loss: 0.9879, value_loss: 0.5382
2024-07-14 06:50:34,906 [INFO    ] __main__: train step 16016: loss: 1.0385, policy_loss: 0.9879, value_loss: 0.5382
2024-07-14 06:50:35,200 [INFO    ] __main__: train step 16017: loss: 1.0385, policy_loss: 0.9879, value_loss: 0.5382
2024-07-14 06:50:35,495 [INFO    ] __main__: train step 16018: loss: 1.0385, policy_loss: 0.9879, value_loss: 0.5381
2024-07-14 06:50:35,788 [INFO    ] __main__: train step 16019: loss: 1.0385, policy_loss: 0.9878, value_loss: 0.5381
2024-07-14 06:50:36,086 [INFO    ] __main__: train step 16020: loss: 1.0384, policy_loss: 0.9878, value_loss: 0.5381
2024-07-14 06:50:36,384 [INFO    ] __main__: train step 16021: loss: 1.0384, policy_loss: 0.9878, value_loss: 0.5381
2024-07-14 06:50:36,669 [INFO    ] __main__: train step 16022: loss: 1.0384, policy_loss: 0.9878, value_loss: 0.5380
2024-07-14 06:50:36,956 [INFO    ] __main__: train step 16023: loss: 1.0384, policy_loss: 0.9877, value_loss: 0.5380
2024-07-14 06:50:37,254 [INFO    ] __main__: train step 16024: loss: 1.0384, policy_loss: 0.9877, value_loss: 0.5380
2024-07-14 06:50:37,545 [INFO    ] __main__: train step 16025: loss: 1.0383, policy_loss: 0.9877, value_loss: 0.5379
2024-07-14 06:50:37,846 [INFO    ] __main__: train step 16026: loss: 1.0383, policy_loss: 0.9877, value_loss: 0.5379
2024-07-14 06:50:38,131 [INFO    ] __main__: train step 16027: loss: 1.0383, policy_loss: 0.9876, value_loss: 0.5379
2024-07-14 06:50:39,756 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:50:40,243 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:50:40,314 [INFO    ] __main__: train step 16028: loss: 1.0383, policy_loss: 0.9876, value_loss: 0.5379
2024-07-14 06:50:40,608 [INFO    ] __main__: train step 16029: loss: 1.0383, policy_loss: 0.9876, value_loss: 0.5378
2024-07-14 06:50:40,897 [INFO    ] __main__: train step 16030: loss: 1.0382, policy_loss: 0.9876, value_loss: 0.5378
2024-07-14 06:50:41,181 [INFO    ] __main__: train step 16031: loss: 1.0382, policy_loss: 0.9876, value_loss: 0.5378
2024-07-14 06:50:41,475 [INFO    ] __main__: train step 16032: loss: 1.0382, policy_loss: 0.9875, value_loss: 0.5378
2024-07-14 06:50:41,759 [INFO    ] __main__: train step 16033: loss: 1.0382, policy_loss: 0.9875, value_loss: 0.5377
2024-07-14 06:50:42,047 [INFO    ] __main__: train step 16034: loss: 1.0382, policy_loss: 0.9875, value_loss: 0.5377
2024-07-14 06:50:42,339 [INFO    ] __main__: train step 16035: loss: 1.0381, policy_loss: 0.9875, value_loss: 0.5377
2024-07-14 06:50:42,635 [INFO    ] __main__: train step 16036: loss: 1.0381, policy_loss: 0.9874, value_loss: 0.5376
2024-07-14 06:50:42,917 [INFO    ] __main__: train step 16037: loss: 1.0381, policy_loss: 0.9874, value_loss: 0.5376
2024-07-14 06:50:43,211 [INFO    ] __main__: train step 16038: loss: 1.0381, policy_loss: 0.9874, value_loss: 0.5376
2024-07-14 06:50:43,501 [INFO    ] __main__: train step 16039: loss: 1.0381, policy_loss: 0.9874, value_loss: 0.5376
2024-07-14 06:50:43,792 [INFO    ] __main__: train step 16040: loss: 1.0380, policy_loss: 0.9874, value_loss: 0.5375
2024-07-14 06:50:44,073 [INFO    ] __main__: train step 16041: loss: 1.0380, policy_loss: 0.9873, value_loss: 0.5375
2024-07-14 06:50:44,360 [INFO    ] __main__: train step 16042: loss: 1.0380, policy_loss: 0.9873, value_loss: 0.5375
2024-07-14 06:50:44,643 [INFO    ] __main__: train step 16043: loss: 1.0380, policy_loss: 0.9873, value_loss: 0.5375
2024-07-14 06:50:44,942 [INFO    ] __main__: train step 16044: loss: 1.0380, policy_loss: 0.9873, value_loss: 0.5374
2024-07-14 06:50:46,557 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:50:47,057 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:50:47,128 [INFO    ] __main__: train step 16045: loss: 1.0379, policy_loss: 0.9872, value_loss: 0.5374
2024-07-14 06:50:47,398 [INFO    ] __main__: train step 16046: loss: 1.0379, policy_loss: 0.9872, value_loss: 0.5374
2024-07-14 06:50:47,676 [INFO    ] __main__: train step 16047: loss: 1.0379, policy_loss: 0.9872, value_loss: 0.5373
2024-07-14 06:50:47,959 [INFO    ] __main__: train step 16048: loss: 1.0379, policy_loss: 0.9872, value_loss: 0.5373
2024-07-14 06:50:48,239 [INFO    ] __main__: train step 16049: loss: 1.0379, policy_loss: 0.9871, value_loss: 0.5373
2024-07-14 06:50:48,523 [INFO    ] __main__: train step 16050: loss: 1.0378, policy_loss: 0.9871, value_loss: 0.5373
2024-07-14 06:50:52,014 [INFO    ] __main__: train step 16051: loss: 1.0378, policy_loss: 0.9871, value_loss: 0.5372
2024-07-14 06:50:52,289 [INFO    ] __main__: train step 16052: loss: 1.0378, policy_loss: 0.9871, value_loss: 0.5372
2024-07-14 06:50:52,565 [INFO    ] __main__: train step 16053: loss: 1.0378, policy_loss: 0.9871, value_loss: 0.5372
2024-07-14 06:50:52,859 [INFO    ] __main__: train step 16054: loss: 1.0378, policy_loss: 0.9870, value_loss: 0.5372
2024-07-14 06:50:53,155 [INFO    ] __main__: train step 16055: loss: 1.0377, policy_loss: 0.9870, value_loss: 0.5371
2024-07-14 06:50:53,440 [INFO    ] __main__: train step 16056: loss: 1.0377, policy_loss: 0.9870, value_loss: 0.5371
2024-07-14 06:50:53,727 [INFO    ] __main__: train step 16057: loss: 1.0377, policy_loss: 0.9870, value_loss: 0.5371
2024-07-14 06:50:54,008 [INFO    ] __main__: train step 16058: loss: 1.0377, policy_loss: 0.9869, value_loss: 0.5370
2024-07-14 06:50:54,297 [INFO    ] __main__: train step 16059: loss: 1.0377, policy_loss: 0.9869, value_loss: 0.5370
2024-07-14 06:50:54,586 [INFO    ] __main__: train step 16060: loss: 1.0376, policy_loss: 0.9869, value_loss: 0.5370
2024-07-14 06:50:54,882 [INFO    ] __main__: train step 16061: loss: 1.0376, policy_loss: 0.9869, value_loss: 0.5370
2024-07-14 06:50:56,489 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:50:56,974 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:50:57,046 [INFO    ] __main__: train step 16062: loss: 1.0376, policy_loss: 0.9869, value_loss: 0.5369
2024-07-14 06:50:57,349 [INFO    ] __main__: train step 16063: loss: 1.0376, policy_loss: 0.9868, value_loss: 0.5369
2024-07-14 06:50:57,648 [INFO    ] __main__: train step 16064: loss: 1.0376, policy_loss: 0.9868, value_loss: 0.5369
2024-07-14 06:50:57,942 [INFO    ] __main__: train step 16065: loss: 1.0375, policy_loss: 0.9868, value_loss: 0.5368
2024-07-14 06:50:58,230 [INFO    ] __main__: train step 16066: loss: 1.0375, policy_loss: 0.9868, value_loss: 0.5368
2024-07-14 06:50:58,524 [INFO    ] __main__: train step 16067: loss: 1.0375, policy_loss: 0.9867, value_loss: 0.5368
2024-07-14 06:50:58,812 [INFO    ] __main__: train step 16068: loss: 1.0375, policy_loss: 0.9867, value_loss: 0.5368
2024-07-14 06:50:59,107 [INFO    ] __main__: train step 16069: loss: 1.0375, policy_loss: 0.9867, value_loss: 0.5367
2024-07-14 06:50:59,404 [INFO    ] __main__: train step 16070: loss: 1.0374, policy_loss: 0.9867, value_loss: 0.5367
2024-07-14 06:50:59,703 [INFO    ] __main__: train step 16071: loss: 1.0374, policy_loss: 0.9867, value_loss: 0.5367
2024-07-14 06:50:59,990 [INFO    ] __main__: train step 16072: loss: 1.0374, policy_loss: 0.9866, value_loss: 0.5367
2024-07-14 06:51:00,299 [INFO    ] __main__: train step 16073: loss: 1.0374, policy_loss: 0.9866, value_loss: 0.5366
2024-07-14 06:51:00,604 [INFO    ] __main__: train step 16074: loss: 1.0374, policy_loss: 0.9866, value_loss: 0.5366
2024-07-14 06:51:00,899 [INFO    ] __main__: train step 16075: loss: 1.0374, policy_loss: 0.9866, value_loss: 0.5366
2024-07-14 06:51:01,202 [INFO    ] __main__: train step 16076: loss: 1.0373, policy_loss: 0.9865, value_loss: 0.5365
2024-07-14 06:51:01,499 [INFO    ] __main__: train step 16077: loss: 1.0373, policy_loss: 0.9865, value_loss: 0.5365
2024-07-14 06:51:01,784 [INFO    ] __main__: train step 16078: loss: 1.0373, policy_loss: 0.9865, value_loss: 0.5365
2024-07-14 06:51:03,395 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:51:03,882 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:51:03,950 [INFO    ] __main__: train step 16079: loss: 1.0373, policy_loss: 0.9865, value_loss: 0.5365
2024-07-14 06:51:04,252 [INFO    ] __main__: train step 16080: loss: 1.0373, policy_loss: 0.9865, value_loss: 0.5364
2024-07-14 06:51:04,564 [INFO    ] __main__: train step 16081: loss: 1.0372, policy_loss: 0.9864, value_loss: 0.5364
2024-07-14 06:51:04,866 [INFO    ] __main__: train step 16082: loss: 1.0372, policy_loss: 0.9864, value_loss: 0.5364
2024-07-14 06:51:05,150 [INFO    ] __main__: train step 16083: loss: 1.0372, policy_loss: 0.9864, value_loss: 0.5364
2024-07-14 06:51:05,433 [INFO    ] __main__: train step 16084: loss: 1.0372, policy_loss: 0.9864, value_loss: 0.5363
2024-07-14 06:51:05,730 [INFO    ] __main__: train step 16085: loss: 1.0372, policy_loss: 0.9863, value_loss: 0.5363
2024-07-14 06:51:06,019 [INFO    ] __main__: train step 16086: loss: 1.0372, policy_loss: 0.9863, value_loss: 0.5363
2024-07-14 06:51:06,305 [INFO    ] __main__: train step 16087: loss: 1.0371, policy_loss: 0.9863, value_loss: 0.5363
2024-07-14 06:51:06,588 [INFO    ] __main__: train step 16088: loss: 1.0371, policy_loss: 0.9863, value_loss: 0.5362
2024-07-14 06:51:06,885 [INFO    ] __main__: train step 16089: loss: 1.0371, policy_loss: 0.9863, value_loss: 0.5362
2024-07-14 06:51:07,173 [INFO    ] __main__: train step 16090: loss: 1.0371, policy_loss: 0.9862, value_loss: 0.5362
2024-07-14 06:51:07,471 [INFO    ] __main__: train step 16091: loss: 1.0371, policy_loss: 0.9862, value_loss: 0.5361
2024-07-14 06:51:07,773 [INFO    ] __main__: train step 16092: loss: 1.0370, policy_loss: 0.9862, value_loss: 0.5361
2024-07-14 06:51:08,068 [INFO    ] __main__: train step 16093: loss: 1.0370, policy_loss: 0.9862, value_loss: 0.5361
2024-07-14 06:51:08,362 [INFO    ] __main__: train step 16094: loss: 1.0370, policy_loss: 0.9861, value_loss: 0.5361
2024-07-14 06:51:08,656 [INFO    ] __main__: train step 16095: loss: 1.0370, policy_loss: 0.9861, value_loss: 0.5360
2024-07-14 06:51:10,290 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:51:10,783 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:51:10,857 [INFO    ] __main__: train step 16096: loss: 1.0370, policy_loss: 0.9861, value_loss: 0.5360
2024-07-14 06:51:11,124 [INFO    ] __main__: train step 16097: loss: 1.0369, policy_loss: 0.9861, value_loss: 0.5360
2024-07-14 06:51:11,409 [INFO    ] __main__: train step 16098: loss: 1.0369, policy_loss: 0.9861, value_loss: 0.5360
2024-07-14 06:51:11,686 [INFO    ] __main__: train step 16099: loss: 1.0369, policy_loss: 0.9860, value_loss: 0.5359
2024-07-14 06:51:11,976 [INFO    ] __main__: train step 16100: loss: 1.0369, policy_loss: 0.9860, value_loss: 0.5359
2024-07-14 06:51:12,271 [INFO    ] __main__: train step 16101: loss: 1.0369, policy_loss: 0.9860, value_loss: 0.5359
2024-07-14 06:51:12,559 [INFO    ] __main__: train step 16102: loss: 1.0368, policy_loss: 0.9860, value_loss: 0.5358
2024-07-14 06:51:12,850 [INFO    ] __main__: train step 16103: loss: 1.0368, policy_loss: 0.9859, value_loss: 0.5358
2024-07-14 06:51:13,133 [INFO    ] __main__: train step 16104: loss: 1.0368, policy_loss: 0.9859, value_loss: 0.5358
2024-07-14 06:51:13,429 [INFO    ] __main__: train step 16105: loss: 1.0368, policy_loss: 0.9859, value_loss: 0.5358
2024-07-14 06:51:13,714 [INFO    ] __main__: train step 16106: loss: 1.0368, policy_loss: 0.9859, value_loss: 0.5357
2024-07-14 06:51:13,993 [INFO    ] __main__: train step 16107: loss: 1.0367, policy_loss: 0.9859, value_loss: 0.5357
2024-07-14 06:51:14,286 [INFO    ] __main__: train step 16108: loss: 1.0367, policy_loss: 0.9858, value_loss: 0.5357
2024-07-14 06:51:14,582 [INFO    ] __main__: train step 16109: loss: 1.0367, policy_loss: 0.9858, value_loss: 0.5357
2024-07-14 06:51:14,865 [INFO    ] __main__: train step 16110: loss: 1.0367, policy_loss: 0.9858, value_loss: 0.5356
2024-07-14 06:51:15,156 [INFO    ] __main__: train step 16111: loss: 1.0367, policy_loss: 0.9858, value_loss: 0.5356
2024-07-14 06:51:15,449 [INFO    ] __main__: train step 16112: loss: 1.0367, policy_loss: 0.9857, value_loss: 0.5356
2024-07-14 06:51:17,065 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:51:17,507 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:51:17,575 [INFO    ] __main__: train step 16113: loss: 1.0366, policy_loss: 0.9857, value_loss: 0.5355
2024-07-14 06:51:17,873 [INFO    ] __main__: train step 16114: loss: 1.0366, policy_loss: 0.9857, value_loss: 0.5355
2024-07-14 06:51:18,143 [INFO    ] __main__: train step 16115: loss: 1.0366, policy_loss: 0.9857, value_loss: 0.5355
2024-07-14 06:51:18,409 [INFO    ] __main__: train step 16116: loss: 1.0366, policy_loss: 0.9857, value_loss: 0.5355
2024-07-14 06:51:18,710 [INFO    ] __main__: train step 16117: loss: 1.0366, policy_loss: 0.9856, value_loss: 0.5354
2024-07-14 06:51:18,997 [INFO    ] __main__: train step 16118: loss: 1.0365, policy_loss: 0.9856, value_loss: 0.5354
2024-07-14 06:51:19,277 [INFO    ] __main__: train step 16119: loss: 1.0365, policy_loss: 0.9856, value_loss: 0.5354
2024-07-14 06:51:19,550 [INFO    ] __main__: train step 16120: loss: 1.0365, policy_loss: 0.9856, value_loss: 0.5354
2024-07-14 06:51:19,841 [INFO    ] __main__: train step 16121: loss: 1.0365, policy_loss: 0.9855, value_loss: 0.5353
2024-07-14 06:51:20,122 [INFO    ] __main__: train step 16122: loss: 1.0365, policy_loss: 0.9855, value_loss: 0.5353
2024-07-14 06:51:20,437 [INFO    ] __main__: train step 16123: loss: 1.0364, policy_loss: 0.9855, value_loss: 0.5353
2024-07-14 06:51:20,729 [INFO    ] __main__: train step 16124: loss: 1.0364, policy_loss: 0.9855, value_loss: 0.5353
2024-07-14 06:51:21,022 [INFO    ] __main__: train step 16125: loss: 1.0364, policy_loss: 0.9855, value_loss: 0.5352
2024-07-14 06:51:21,319 [INFO    ] __main__: train step 16126: loss: 1.0364, policy_loss: 0.9854, value_loss: 0.5352
2024-07-14 06:51:21,617 [INFO    ] __main__: train step 16127: loss: 1.0364, policy_loss: 0.9854, value_loss: 0.5352
2024-07-14 06:51:21,900 [INFO    ] __main__: train step 16128: loss: 1.0364, policy_loss: 0.9854, value_loss: 0.5351
2024-07-14 06:51:22,197 [INFO    ] __main__: train step 16129: loss: 1.0363, policy_loss: 0.9854, value_loss: 0.5351
2024-07-14 06:51:23,822 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:51:24,312 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:51:24,382 [INFO    ] __main__: train step 16130: loss: 1.0363, policy_loss: 0.9854, value_loss: 0.5351
2024-07-14 06:51:24,677 [INFO    ] __main__: train step 16131: loss: 1.0363, policy_loss: 0.9853, value_loss: 0.5351
2024-07-14 06:51:24,976 [INFO    ] __main__: train step 16132: loss: 1.0363, policy_loss: 0.9853, value_loss: 0.5350
2024-07-14 06:51:25,270 [INFO    ] __main__: train step 16133: loss: 1.0363, policy_loss: 0.9853, value_loss: 0.5350
2024-07-14 06:51:25,563 [INFO    ] __main__: train step 16134: loss: 1.0362, policy_loss: 0.9853, value_loss: 0.5350
2024-07-14 06:51:25,856 [INFO    ] __main__: train step 16135: loss: 1.0362, policy_loss: 0.9852, value_loss: 0.5350
2024-07-14 06:51:26,162 [INFO    ] __main__: train step 16136: loss: 1.0362, policy_loss: 0.9852, value_loss: 0.5349
2024-07-14 06:51:26,451 [INFO    ] __main__: train step 16137: loss: 1.0362, policy_loss: 0.9852, value_loss: 0.5349
2024-07-14 06:51:26,740 [INFO    ] __main__: train step 16138: loss: 1.0362, policy_loss: 0.9852, value_loss: 0.5349
2024-07-14 06:51:27,036 [INFO    ] __main__: train step 16139: loss: 1.0361, policy_loss: 0.9852, value_loss: 0.5348
2024-07-14 06:51:27,322 [INFO    ] __main__: train step 16140: loss: 1.0361, policy_loss: 0.9851, value_loss: 0.5348
2024-07-14 06:51:27,623 [INFO    ] __main__: train step 16141: loss: 1.0361, policy_loss: 0.9851, value_loss: 0.5348
2024-07-14 06:51:27,906 [INFO    ] __main__: train step 16142: loss: 1.0361, policy_loss: 0.9851, value_loss: 0.5348
2024-07-14 06:51:28,192 [INFO    ] __main__: train step 16143: loss: 1.0361, policy_loss: 0.9851, value_loss: 0.5347
2024-07-14 06:51:28,485 [INFO    ] __main__: train step 16144: loss: 1.0361, policy_loss: 0.9851, value_loss: 0.5347
2024-07-14 06:51:28,774 [INFO    ] __main__: train step 16145: loss: 1.0360, policy_loss: 0.9850, value_loss: 0.5347
2024-07-14 06:51:29,067 [INFO    ] __main__: train step 16146: loss: 1.0360, policy_loss: 0.9850, value_loss: 0.5347
2024-07-14 06:51:30,679 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:51:31,173 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:51:31,244 [INFO    ] __main__: train step 16147: loss: 1.0360, policy_loss: 0.9850, value_loss: 0.5346
2024-07-14 06:51:31,540 [INFO    ] __main__: train step 16148: loss: 1.0360, policy_loss: 0.9850, value_loss: 0.5346
2024-07-14 06:51:31,831 [INFO    ] __main__: train step 16149: loss: 1.0360, policy_loss: 0.9849, value_loss: 0.5346
2024-07-14 06:51:32,119 [INFO    ] __main__: train step 16150: loss: 1.0359, policy_loss: 0.9849, value_loss: 0.5346
2024-07-14 06:51:32,406 [INFO    ] __main__: train step 16151: loss: 1.0359, policy_loss: 0.9849, value_loss: 0.5345
2024-07-14 06:51:32,693 [INFO    ] __main__: train step 16152: loss: 1.0359, policy_loss: 0.9849, value_loss: 0.5345
2024-07-14 06:51:32,995 [INFO    ] __main__: train step 16153: loss: 1.0359, policy_loss: 0.9849, value_loss: 0.5345
2024-07-14 06:51:33,281 [INFO    ] __main__: train step 16154: loss: 1.0359, policy_loss: 0.9848, value_loss: 0.5344
2024-07-14 06:51:36,799 [INFO    ] __main__: train step 16155: loss: 1.0358, policy_loss: 0.9848, value_loss: 0.5344
2024-07-14 06:51:37,097 [INFO    ] __main__: train step 16156: loss: 1.0358, policy_loss: 0.9848, value_loss: 0.5344
2024-07-14 06:51:37,402 [INFO    ] __main__: train step 16157: loss: 1.0358, policy_loss: 0.9848, value_loss: 0.5344
2024-07-14 06:51:37,701 [INFO    ] __main__: train step 16158: loss: 1.0358, policy_loss: 0.9847, value_loss: 0.5343
2024-07-14 06:51:38,004 [INFO    ] __main__: train step 16159: loss: 1.0358, policy_loss: 0.9847, value_loss: 0.5343
2024-07-14 06:51:38,307 [INFO    ] __main__: train step 16160: loss: 1.0358, policy_loss: 0.9847, value_loss: 0.5343
2024-07-14 06:51:38,592 [INFO    ] __main__: train step 16161: loss: 1.0357, policy_loss: 0.9847, value_loss: 0.5343
2024-07-14 06:51:38,896 [INFO    ] __main__: train step 16162: loss: 1.0357, policy_loss: 0.9847, value_loss: 0.5342
2024-07-14 06:51:39,194 [INFO    ] __main__: train step 16163: loss: 1.0357, policy_loss: 0.9846, value_loss: 0.5342
2024-07-14 06:51:40,815 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:51:41,310 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:51:41,385 [INFO    ] __main__: train step 16164: loss: 1.0357, policy_loss: 0.9846, value_loss: 0.5342
2024-07-14 06:51:41,683 [INFO    ] __main__: train step 16165: loss: 1.0357, policy_loss: 0.9846, value_loss: 0.5342
2024-07-14 06:51:41,991 [INFO    ] __main__: train step 16166: loss: 1.0356, policy_loss: 0.9846, value_loss: 0.5341
2024-07-14 06:51:42,285 [INFO    ] __main__: train step 16167: loss: 1.0356, policy_loss: 0.9845, value_loss: 0.5341
2024-07-14 06:51:42,581 [INFO    ] __main__: train step 16168: loss: 1.0356, policy_loss: 0.9845, value_loss: 0.5341
2024-07-14 06:51:42,874 [INFO    ] __main__: train step 16169: loss: 1.0356, policy_loss: 0.9845, value_loss: 0.5340
2024-07-14 06:51:43,180 [INFO    ] __main__: train step 16170: loss: 1.0356, policy_loss: 0.9845, value_loss: 0.5340
2024-07-14 06:51:43,483 [INFO    ] __main__: train step 16171: loss: 1.0356, policy_loss: 0.9845, value_loss: 0.5340
2024-07-14 06:51:43,784 [INFO    ] __main__: train step 16172: loss: 1.0355, policy_loss: 0.9844, value_loss: 0.5340
2024-07-14 06:51:44,084 [INFO    ] __main__: train step 16173: loss: 1.0355, policy_loss: 0.9844, value_loss: 0.5339
2024-07-14 06:51:44,380 [INFO    ] __main__: train step 16174: loss: 1.0355, policy_loss: 0.9844, value_loss: 0.5339
2024-07-14 06:51:44,694 [INFO    ] __main__: train step 16175: loss: 1.0355, policy_loss: 0.9844, value_loss: 0.5339
2024-07-14 06:51:45,013 [INFO    ] __main__: train step 16176: loss: 1.0355, policy_loss: 0.9844, value_loss: 0.5339
2024-07-14 06:51:45,307 [INFO    ] __main__: train step 16177: loss: 1.0354, policy_loss: 0.9843, value_loss: 0.5338
2024-07-14 06:51:45,610 [INFO    ] __main__: train step 16178: loss: 1.0354, policy_loss: 0.9843, value_loss: 0.5338
2024-07-14 06:51:45,909 [INFO    ] __main__: train step 16179: loss: 1.0354, policy_loss: 0.9843, value_loss: 0.5338
2024-07-14 06:51:46,200 [INFO    ] __main__: train step 16180: loss: 1.0354, policy_loss: 0.9843, value_loss: 0.5338
2024-07-14 06:51:47,819 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:51:48,262 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:51:48,329 [INFO    ] __main__: train step 16181: loss: 1.0354, policy_loss: 0.9843, value_loss: 0.5337
2024-07-14 06:51:48,622 [INFO    ] __main__: train step 16182: loss: 1.0354, policy_loss: 0.9842, value_loss: 0.5337
2024-07-14 06:51:48,925 [INFO    ] __main__: train step 16183: loss: 1.0353, policy_loss: 0.9842, value_loss: 0.5337
2024-07-14 06:51:49,215 [INFO    ] __main__: train step 16184: loss: 1.0353, policy_loss: 0.9842, value_loss: 0.5336
2024-07-14 06:51:49,513 [INFO    ] __main__: train step 16185: loss: 1.0353, policy_loss: 0.9842, value_loss: 0.5336
2024-07-14 06:51:49,812 [INFO    ] __main__: train step 16186: loss: 1.0353, policy_loss: 0.9841, value_loss: 0.5336
2024-07-14 06:51:50,104 [INFO    ] __main__: train step 16187: loss: 1.0353, policy_loss: 0.9841, value_loss: 0.5336
2024-07-14 06:51:50,400 [INFO    ] __main__: train step 16188: loss: 1.0352, policy_loss: 0.9841, value_loss: 0.5335
2024-07-14 06:51:50,683 [INFO    ] __main__: train step 16189: loss: 1.0352, policy_loss: 0.9841, value_loss: 0.5335
2024-07-14 06:51:50,973 [INFO    ] __main__: train step 16190: loss: 1.0352, policy_loss: 0.9841, value_loss: 0.5335
2024-07-14 06:51:51,265 [INFO    ] __main__: train step 16191: loss: 1.0352, policy_loss: 0.9840, value_loss: 0.5335
2024-07-14 06:51:51,562 [INFO    ] __main__: train step 16192: loss: 1.0352, policy_loss: 0.9840, value_loss: 0.5334
2024-07-14 06:51:51,861 [INFO    ] __main__: train step 16193: loss: 1.0352, policy_loss: 0.9840, value_loss: 0.5334
2024-07-14 06:51:52,152 [INFO    ] __main__: train step 16194: loss: 1.0351, policy_loss: 0.9840, value_loss: 0.5334
2024-07-14 06:51:52,444 [INFO    ] __main__: train step 16195: loss: 1.0351, policy_loss: 0.9840, value_loss: 0.5334
2024-07-14 06:51:52,725 [INFO    ] __main__: train step 16196: loss: 1.0351, policy_loss: 0.9839, value_loss: 0.5333
2024-07-14 06:51:53,022 [INFO    ] __main__: train step 16197: loss: 1.0351, policy_loss: 0.9839, value_loss: 0.5333
2024-07-14 06:51:54,618 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:51:55,116 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:51:55,187 [INFO    ] __main__: train step 16198: loss: 1.0351, policy_loss: 0.9839, value_loss: 0.5333
2024-07-14 06:51:55,459 [INFO    ] __main__: train step 16199: loss: 1.0350, policy_loss: 0.9839, value_loss: 0.5332
2024-07-14 06:51:55,726 [INFO    ] __main__: train step 16200: loss: 1.0350, policy_loss: 0.9838, value_loss: 0.5332
2024-07-14 06:51:56,012 [INFO    ] __main__: train step 16201: loss: 1.0350, policy_loss: 0.9838, value_loss: 0.5332
2024-07-14 06:51:56,306 [INFO    ] __main__: train step 16202: loss: 1.0350, policy_loss: 0.9838, value_loss: 0.5332
2024-07-14 06:51:56,599 [INFO    ] __main__: train step 16203: loss: 1.0350, policy_loss: 0.9838, value_loss: 0.5331
2024-07-14 06:51:56,884 [INFO    ] __main__: train step 16204: loss: 1.0350, policy_loss: 0.9838, value_loss: 0.5331
2024-07-14 06:51:57,181 [INFO    ] __main__: train step 16205: loss: 1.0349, policy_loss: 0.9837, value_loss: 0.5331
2024-07-14 06:51:57,476 [INFO    ] __main__: train step 16206: loss: 1.0349, policy_loss: 0.9837, value_loss: 0.5331
2024-07-14 06:51:57,748 [INFO    ] __main__: train step 16207: loss: 1.0349, policy_loss: 0.9837, value_loss: 0.5330
2024-07-14 06:51:58,037 [INFO    ] __main__: train step 16208: loss: 1.0349, policy_loss: 0.9837, value_loss: 0.5330
2024-07-14 06:51:58,330 [INFO    ] __main__: train step 16209: loss: 1.0349, policy_loss: 0.9837, value_loss: 0.5330
2024-07-14 06:51:58,623 [INFO    ] __main__: train step 16210: loss: 1.0348, policy_loss: 0.9836, value_loss: 0.5329
2024-07-14 06:51:58,919 [INFO    ] __main__: train step 16211: loss: 1.0348, policy_loss: 0.9836, value_loss: 0.5329
2024-07-14 06:51:59,206 [INFO    ] __main__: train step 16212: loss: 1.0348, policy_loss: 0.9836, value_loss: 0.5329
2024-07-14 06:51:59,503 [INFO    ] __main__: train step 16213: loss: 1.0348, policy_loss: 0.9836, value_loss: 0.5329
2024-07-14 06:51:59,798 [INFO    ] __main__: train step 16214: loss: 1.0348, policy_loss: 0.9835, value_loss: 0.5328
2024-07-14 06:52:01,411 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:52:01,906 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:52:01,973 [INFO    ] __main__: train step 16215: loss: 1.0347, policy_loss: 0.9835, value_loss: 0.5328
2024-07-14 06:52:02,266 [INFO    ] __main__: train step 16216: loss: 1.0347, policy_loss: 0.9835, value_loss: 0.5328
2024-07-14 06:52:02,565 [INFO    ] __main__: train step 16217: loss: 1.0347, policy_loss: 0.9835, value_loss: 0.5328
2024-07-14 06:52:02,862 [INFO    ] __main__: train step 16218: loss: 1.0347, policy_loss: 0.9835, value_loss: 0.5327
2024-07-14 06:52:03,148 [INFO    ] __main__: train step 16219: loss: 1.0347, policy_loss: 0.9834, value_loss: 0.5327
2024-07-14 06:52:03,445 [INFO    ] __main__: train step 16220: loss: 1.0347, policy_loss: 0.9834, value_loss: 0.5327
2024-07-14 06:52:03,730 [INFO    ] __main__: train step 16221: loss: 1.0346, policy_loss: 0.9834, value_loss: 0.5327
2024-07-14 06:52:04,036 [INFO    ] __main__: train step 16222: loss: 1.0346, policy_loss: 0.9834, value_loss: 0.5326
2024-07-14 06:52:04,345 [INFO    ] __main__: train step 16223: loss: 1.0346, policy_loss: 0.9834, value_loss: 0.5326
2024-07-14 06:52:04,638 [INFO    ] __main__: train step 16224: loss: 1.0346, policy_loss: 0.9833, value_loss: 0.5326
2024-07-14 06:52:04,950 [INFO    ] __main__: train step 16225: loss: 1.0346, policy_loss: 0.9833, value_loss: 0.5325
2024-07-14 06:52:05,245 [INFO    ] __main__: train step 16226: loss: 1.0345, policy_loss: 0.9833, value_loss: 0.5325
2024-07-14 06:52:05,543 [INFO    ] __main__: train step 16227: loss: 1.0345, policy_loss: 0.9833, value_loss: 0.5325
2024-07-14 06:52:05,843 [INFO    ] __main__: train step 16228: loss: 1.0345, policy_loss: 0.9832, value_loss: 0.5325
2024-07-14 06:52:06,137 [INFO    ] __main__: train step 16229: loss: 1.0345, policy_loss: 0.9832, value_loss: 0.5324
2024-07-14 06:52:06,415 [INFO    ] __main__: train step 16230: loss: 1.0345, policy_loss: 0.9832, value_loss: 0.5324
2024-07-14 06:52:06,708 [INFO    ] __main__: train step 16231: loss: 1.0345, policy_loss: 0.9832, value_loss: 0.5324
2024-07-14 06:52:08,334 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:52:08,840 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:52:08,916 [INFO    ] __main__: train step 16232: loss: 1.0344, policy_loss: 0.9832, value_loss: 0.5324
2024-07-14 06:52:09,197 [INFO    ] __main__: train step 16233: loss: 1.0344, policy_loss: 0.9831, value_loss: 0.5323
2024-07-14 06:52:09,504 [INFO    ] __main__: train step 16234: loss: 1.0344, policy_loss: 0.9831, value_loss: 0.5323
2024-07-14 06:52:09,816 [INFO    ] __main__: train step 16235: loss: 1.0344, policy_loss: 0.9831, value_loss: 0.5323
2024-07-14 06:52:10,108 [INFO    ] __main__: train step 16236: loss: 1.0344, policy_loss: 0.9831, value_loss: 0.5322
2024-07-14 06:52:10,413 [INFO    ] __main__: train step 16237: loss: 1.0343, policy_loss: 0.9831, value_loss: 0.5322
2024-07-14 06:52:10,726 [INFO    ] __main__: train step 16238: loss: 1.0343, policy_loss: 0.9830, value_loss: 0.5322
2024-07-14 06:52:11,031 [INFO    ] __main__: train step 16239: loss: 1.0343, policy_loss: 0.9830, value_loss: 0.5322
2024-07-14 06:52:11,341 [INFO    ] __main__: train step 16240: loss: 1.0343, policy_loss: 0.9830, value_loss: 0.5321
2024-07-14 06:52:11,631 [INFO    ] __main__: train step 16241: loss: 1.0343, policy_loss: 0.9830, value_loss: 0.5321
2024-07-14 06:52:11,921 [INFO    ] __main__: train step 16242: loss: 1.0342, policy_loss: 0.9829, value_loss: 0.5321
2024-07-14 06:52:12,214 [INFO    ] __main__: train step 16243: loss: 1.0342, policy_loss: 0.9829, value_loss: 0.5321
2024-07-14 06:52:12,516 [INFO    ] __main__: train step 16244: loss: 1.0342, policy_loss: 0.9829, value_loss: 0.5320
2024-07-14 06:52:12,802 [INFO    ] __main__: train step 16245: loss: 1.0342, policy_loss: 0.9829, value_loss: 0.5320
2024-07-14 06:52:13,096 [INFO    ] __main__: train step 16246: loss: 1.0342, policy_loss: 0.9829, value_loss: 0.5320
2024-07-14 06:52:13,404 [INFO    ] __main__: train step 16247: loss: 1.0342, policy_loss: 0.9828, value_loss: 0.5320
2024-07-14 06:52:13,687 [INFO    ] __main__: train step 16248: loss: 1.0341, policy_loss: 0.9828, value_loss: 0.5319
2024-07-14 06:52:15,308 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:52:15,806 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:52:15,874 [INFO    ] __main__: train step 16249: loss: 1.0341, policy_loss: 0.9828, value_loss: 0.5319
2024-07-14 06:52:16,164 [INFO    ] __main__: train step 16250: loss: 1.0341, policy_loss: 0.9828, value_loss: 0.5319
2024-07-14 06:52:16,467 [INFO    ] __main__: train step 16251: loss: 1.0341, policy_loss: 0.9828, value_loss: 0.5318
2024-07-14 06:52:16,764 [INFO    ] __main__: train step 16252: loss: 1.0341, policy_loss: 0.9827, value_loss: 0.5318
2024-07-14 06:52:17,058 [INFO    ] __main__: train step 16253: loss: 1.0340, policy_loss: 0.9827, value_loss: 0.5318
2024-07-14 06:52:17,350 [INFO    ] __main__: train step 16254: loss: 1.0340, policy_loss: 0.9827, value_loss: 0.5318
2024-07-14 06:52:17,630 [INFO    ] __main__: train step 16255: loss: 1.0340, policy_loss: 0.9827, value_loss: 0.5317
2024-07-14 06:52:17,925 [INFO    ] __main__: train step 16256: loss: 1.0340, policy_loss: 0.9827, value_loss: 0.5317
2024-07-14 06:52:18,230 [INFO    ] __main__: train step 16257: loss: 1.0340, policy_loss: 0.9826, value_loss: 0.5317
2024-07-14 06:52:18,521 [INFO    ] __main__: train step 16258: loss: 1.0340, policy_loss: 0.9826, value_loss: 0.5317
2024-07-14 06:52:18,800 [INFO    ] __main__: train step 16259: loss: 1.0339, policy_loss: 0.9826, value_loss: 0.5316
2024-07-14 06:52:22,315 [INFO    ] __main__: train step 16260: loss: 1.0339, policy_loss: 0.9826, value_loss: 0.5316
2024-07-14 06:52:22,612 [INFO    ] __main__: train step 16261: loss: 1.0339, policy_loss: 0.9825, value_loss: 0.5316
2024-07-14 06:52:22,919 [INFO    ] __main__: train step 16262: loss: 1.0339, policy_loss: 0.9825, value_loss: 0.5316
2024-07-14 06:52:23,212 [INFO    ] __main__: train step 16263: loss: 1.0339, policy_loss: 0.9825, value_loss: 0.5315
2024-07-14 06:52:23,516 [INFO    ] __main__: train step 16264: loss: 1.0339, policy_loss: 0.9825, value_loss: 0.5315
2024-07-14 06:52:23,809 [INFO    ] __main__: train step 16265: loss: 1.0338, policy_loss: 0.9825, value_loss: 0.5315
2024-07-14 06:52:25,403 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:52:25,892 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:52:25,963 [INFO    ] __main__: train step 16266: loss: 1.0338, policy_loss: 0.9824, value_loss: 0.5315
2024-07-14 06:52:26,260 [INFO    ] __main__: train step 16267: loss: 1.0338, policy_loss: 0.9824, value_loss: 0.5314
2024-07-14 06:52:26,549 [INFO    ] __main__: train step 16268: loss: 1.0338, policy_loss: 0.9824, value_loss: 0.5314
2024-07-14 06:52:26,837 [INFO    ] __main__: train step 16269: loss: 1.0338, policy_loss: 0.9824, value_loss: 0.5314
2024-07-14 06:52:27,123 [INFO    ] __main__: train step 16270: loss: 1.0337, policy_loss: 0.9824, value_loss: 0.5313
2024-07-14 06:52:27,420 [INFO    ] __main__: train step 16271: loss: 1.0337, policy_loss: 0.9823, value_loss: 0.5313
2024-07-14 06:52:27,725 [INFO    ] __main__: train step 16272: loss: 1.0337, policy_loss: 0.9823, value_loss: 0.5313
2024-07-14 06:52:28,017 [INFO    ] __main__: train step 16273: loss: 1.0337, policy_loss: 0.9823, value_loss: 0.5313
2024-07-14 06:52:28,308 [INFO    ] __main__: train step 16274: loss: 1.0337, policy_loss: 0.9823, value_loss: 0.5312
2024-07-14 06:52:28,592 [INFO    ] __main__: train step 16275: loss: 1.0337, policy_loss: 0.9823, value_loss: 0.5312
2024-07-14 06:52:28,889 [INFO    ] __main__: train step 16276: loss: 1.0336, policy_loss: 0.9822, value_loss: 0.5312
2024-07-14 06:52:29,167 [INFO    ] __main__: train step 16277: loss: 1.0336, policy_loss: 0.9822, value_loss: 0.5312
2024-07-14 06:52:29,469 [INFO    ] __main__: train step 16278: loss: 1.0336, policy_loss: 0.9822, value_loss: 0.5311
2024-07-14 06:52:29,766 [INFO    ] __main__: train step 16279: loss: 1.0336, policy_loss: 0.9822, value_loss: 0.5311
2024-07-14 06:52:30,064 [INFO    ] __main__: train step 16280: loss: 1.0336, policy_loss: 0.9821, value_loss: 0.5311
2024-07-14 06:52:30,366 [INFO    ] __main__: train step 16281: loss: 1.0335, policy_loss: 0.9821, value_loss: 0.5311
2024-07-14 06:52:30,658 [INFO    ] __main__: train step 16282: loss: 1.0335, policy_loss: 0.9821, value_loss: 0.5310
2024-07-14 06:52:32,265 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:52:32,756 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:52:32,826 [INFO    ] __main__: train step 16283: loss: 1.0335, policy_loss: 0.9821, value_loss: 0.5310
2024-07-14 06:52:33,123 [INFO    ] __main__: train step 16284: loss: 1.0335, policy_loss: 0.9821, value_loss: 0.5310
2024-07-14 06:52:33,413 [INFO    ] __main__: train step 16285: loss: 1.0335, policy_loss: 0.9820, value_loss: 0.5309
2024-07-14 06:52:33,699 [INFO    ] __main__: train step 16286: loss: 1.0334, policy_loss: 0.9820, value_loss: 0.5309
2024-07-14 06:52:33,977 [INFO    ] __main__: train step 16287: loss: 1.0334, policy_loss: 0.9820, value_loss: 0.5309
2024-07-14 06:52:34,262 [INFO    ] __main__: train step 16288: loss: 1.0334, policy_loss: 0.9820, value_loss: 0.5309
2024-07-14 06:52:34,553 [INFO    ] __main__: train step 16289: loss: 1.0334, policy_loss: 0.9820, value_loss: 0.5308
2024-07-14 06:52:34,846 [INFO    ] __main__: train step 16290: loss: 1.0334, policy_loss: 0.9819, value_loss: 0.5308
2024-07-14 06:52:35,144 [INFO    ] __main__: train step 16291: loss: 1.0334, policy_loss: 0.9819, value_loss: 0.5308
2024-07-14 06:52:35,435 [INFO    ] __main__: train step 16292: loss: 1.0333, policy_loss: 0.9819, value_loss: 0.5308
2024-07-14 06:52:35,718 [INFO    ] __main__: train step 16293: loss: 1.0333, policy_loss: 0.9819, value_loss: 0.5307
2024-07-14 06:52:36,011 [INFO    ] __main__: train step 16294: loss: 1.0333, policy_loss: 0.9819, value_loss: 0.5307
2024-07-14 06:52:36,308 [INFO    ] __main__: train step 16295: loss: 1.0333, policy_loss: 0.9818, value_loss: 0.5307
2024-07-14 06:52:36,609 [INFO    ] __main__: train step 16296: loss: 1.0333, policy_loss: 0.9818, value_loss: 0.5307
2024-07-14 06:52:36,901 [INFO    ] __main__: train step 16297: loss: 1.0332, policy_loss: 0.9818, value_loss: 0.5306
2024-07-14 06:52:37,180 [INFO    ] __main__: train step 16298: loss: 1.0332, policy_loss: 0.9818, value_loss: 0.5306
2024-07-14 06:52:37,472 [INFO    ] __main__: train step 16299: loss: 1.0332, policy_loss: 0.9817, value_loss: 0.5306
2024-07-14 06:52:39,087 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:52:39,573 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:52:39,644 [INFO    ] __main__: train step 16300: loss: 1.0332, policy_loss: 0.9817, value_loss: 0.5305
2024-07-14 06:52:39,913 [INFO    ] __main__: train step 16301: loss: 1.0332, policy_loss: 0.9817, value_loss: 0.5305
2024-07-14 06:52:40,205 [INFO    ] __main__: train step 16302: loss: 1.0332, policy_loss: 0.9817, value_loss: 0.5305
2024-07-14 06:52:40,483 [INFO    ] __main__: train step 16303: loss: 1.0331, policy_loss: 0.9817, value_loss: 0.5305
2024-07-14 06:52:40,764 [INFO    ] __main__: train step 16304: loss: 1.0331, policy_loss: 0.9816, value_loss: 0.5304
2024-07-14 06:52:41,056 [INFO    ] __main__: train step 16305: loss: 1.0331, policy_loss: 0.9816, value_loss: 0.5304
2024-07-14 06:52:41,348 [INFO    ] __main__: train step 16306: loss: 1.0331, policy_loss: 0.9816, value_loss: 0.5304
2024-07-14 06:52:41,647 [INFO    ] __main__: train step 16307: loss: 1.0331, policy_loss: 0.9816, value_loss: 0.5304
2024-07-14 06:52:41,940 [INFO    ] __main__: train step 16308: loss: 1.0330, policy_loss: 0.9816, value_loss: 0.5303
2024-07-14 06:52:42,225 [INFO    ] __main__: train step 16309: loss: 1.0330, policy_loss: 0.9815, value_loss: 0.5303
2024-07-14 06:52:42,496 [INFO    ] __main__: train step 16310: loss: 1.0330, policy_loss: 0.9815, value_loss: 0.5303
2024-07-14 06:52:42,763 [INFO    ] __main__: train step 16311: loss: 1.0330, policy_loss: 0.9815, value_loss: 0.5303
2024-07-14 06:52:43,056 [INFO    ] __main__: train step 16312: loss: 1.0330, policy_loss: 0.9815, value_loss: 0.5302
2024-07-14 06:52:43,353 [INFO    ] __main__: train step 16313: loss: 1.0330, policy_loss: 0.9815, value_loss: 0.5302
2024-07-14 06:52:43,641 [INFO    ] __main__: train step 16314: loss: 1.0329, policy_loss: 0.9814, value_loss: 0.5302
2024-07-14 06:52:43,931 [INFO    ] __main__: train step 16315: loss: 1.0329, policy_loss: 0.9814, value_loss: 0.5301
2024-07-14 06:52:44,215 [INFO    ] __main__: train step 16316: loss: 1.0329, policy_loss: 0.9814, value_loss: 0.5301
2024-07-14 06:52:45,822 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:52:46,292 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:52:46,363 [INFO    ] __main__: train step 16317: loss: 1.0329, policy_loss: 0.9814, value_loss: 0.5301
2024-07-14 06:52:46,665 [INFO    ] __main__: train step 16318: loss: 1.0329, policy_loss: 0.9813, value_loss: 0.5301
2024-07-14 06:52:46,978 [INFO    ] __main__: train step 16319: loss: 1.0328, policy_loss: 0.9813, value_loss: 0.5300
2024-07-14 06:52:47,277 [INFO    ] __main__: train step 16320: loss: 1.0328, policy_loss: 0.9813, value_loss: 0.5300
2024-07-14 06:52:47,570 [INFO    ] __main__: train step 16321: loss: 1.0328, policy_loss: 0.9813, value_loss: 0.5300
2024-07-14 06:52:47,867 [INFO    ] __main__: train step 16322: loss: 1.0328, policy_loss: 0.9813, value_loss: 0.5300
2024-07-14 06:52:48,160 [INFO    ] __main__: train step 16323: loss: 1.0328, policy_loss: 0.9812, value_loss: 0.5299
2024-07-14 06:52:48,458 [INFO    ] __main__: train step 16324: loss: 1.0328, policy_loss: 0.9812, value_loss: 0.5299
2024-07-14 06:52:48,765 [INFO    ] __main__: train step 16325: loss: 1.0327, policy_loss: 0.9812, value_loss: 0.5299
2024-07-14 06:52:49,072 [INFO    ] __main__: train step 16326: loss: 1.0327, policy_loss: 0.9812, value_loss: 0.5299
2024-07-14 06:52:49,361 [INFO    ] __main__: train step 16327: loss: 1.0327, policy_loss: 0.9812, value_loss: 0.5298
2024-07-14 06:52:49,658 [INFO    ] __main__: train step 16328: loss: 1.0327, policy_loss: 0.9811, value_loss: 0.5298
2024-07-14 06:52:49,953 [INFO    ] __main__: train step 16329: loss: 1.0327, policy_loss: 0.9811, value_loss: 0.5298
2024-07-14 06:52:50,250 [INFO    ] __main__: train step 16330: loss: 1.0326, policy_loss: 0.9811, value_loss: 0.5297
2024-07-14 06:52:50,542 [INFO    ] __main__: train step 16331: loss: 1.0326, policy_loss: 0.9811, value_loss: 0.5297
2024-07-14 06:52:50,846 [INFO    ] __main__: train step 16332: loss: 1.0326, policy_loss: 0.9811, value_loss: 0.5297
2024-07-14 06:52:51,149 [INFO    ] __main__: train step 16333: loss: 1.0326, policy_loss: 0.9810, value_loss: 0.5297
2024-07-14 06:52:52,774 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:52:53,262 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:52:53,335 [INFO    ] __main__: train step 16334: loss: 1.0326, policy_loss: 0.9810, value_loss: 0.5296
2024-07-14 06:52:53,610 [INFO    ] __main__: train step 16335: loss: 1.0326, policy_loss: 0.9810, value_loss: 0.5296
2024-07-14 06:52:53,882 [INFO    ] __main__: train step 16336: loss: 1.0325, policy_loss: 0.9810, value_loss: 0.5296
2024-07-14 06:52:54,175 [INFO    ] __main__: train step 16337: loss: 1.0325, policy_loss: 0.9810, value_loss: 0.5296
2024-07-14 06:52:54,467 [INFO    ] __main__: train step 16338: loss: 1.0325, policy_loss: 0.9809, value_loss: 0.5295
2024-07-14 06:52:54,740 [INFO    ] __main__: train step 16339: loss: 1.0325, policy_loss: 0.9809, value_loss: 0.5295
2024-07-14 06:52:55,034 [INFO    ] __main__: train step 16340: loss: 1.0325, policy_loss: 0.9809, value_loss: 0.5295
2024-07-14 06:52:55,325 [INFO    ] __main__: train step 16341: loss: 1.0324, policy_loss: 0.9809, value_loss: 0.5295
2024-07-14 06:52:55,620 [INFO    ] __main__: train step 16342: loss: 1.0324, policy_loss: 0.9808, value_loss: 0.5294
2024-07-14 06:52:55,912 [INFO    ] __main__: train step 16343: loss: 1.0324, policy_loss: 0.9808, value_loss: 0.5294
2024-07-14 06:52:56,199 [INFO    ] __main__: train step 16344: loss: 1.0324, policy_loss: 0.9808, value_loss: 0.5294
2024-07-14 06:52:56,494 [INFO    ] __main__: train step 16345: loss: 1.0324, policy_loss: 0.9808, value_loss: 0.5293
2024-07-14 06:52:56,768 [INFO    ] __main__: train step 16346: loss: 1.0323, policy_loss: 0.9808, value_loss: 0.5293
2024-07-14 06:52:57,045 [INFO    ] __main__: train step 16347: loss: 1.0323, policy_loss: 0.9807, value_loss: 0.5293
2024-07-14 06:52:57,321 [INFO    ] __main__: train step 16348: loss: 1.0323, policy_loss: 0.9807, value_loss: 0.5293
2024-07-14 06:52:57,619 [INFO    ] __main__: train step 16349: loss: 1.0323, policy_loss: 0.9807, value_loss: 0.5292
2024-07-14 06:52:57,922 [INFO    ] __main__: train step 16350: loss: 1.0323, policy_loss: 0.9807, value_loss: 0.5292
2024-07-14 06:52:59,554 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:53:00,044 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:53:00,112 [INFO    ] __main__: train step 16351: loss: 1.0323, policy_loss: 0.9807, value_loss: 0.5292
2024-07-14 06:53:00,404 [INFO    ] __main__: train step 16352: loss: 1.0322, policy_loss: 0.9806, value_loss: 0.5292
2024-07-14 06:53:00,704 [INFO    ] __main__: train step 16353: loss: 1.0322, policy_loss: 0.9806, value_loss: 0.5291
2024-07-14 06:53:01,009 [INFO    ] __main__: train step 16354: loss: 1.0322, policy_loss: 0.9806, value_loss: 0.5291
2024-07-14 06:53:01,309 [INFO    ] __main__: train step 16355: loss: 1.0322, policy_loss: 0.9806, value_loss: 0.5291
2024-07-14 06:53:01,615 [INFO    ] __main__: train step 16356: loss: 1.0322, policy_loss: 0.9806, value_loss: 0.5291
2024-07-14 06:53:01,923 [INFO    ] __main__: train step 16357: loss: 1.0322, policy_loss: 0.9805, value_loss: 0.5290
2024-07-14 06:53:02,228 [INFO    ] __main__: train step 16358: loss: 1.0321, policy_loss: 0.9805, value_loss: 0.5290
2024-07-14 06:53:02,533 [INFO    ] __main__: train step 16359: loss: 1.0321, policy_loss: 0.9805, value_loss: 0.5290
2024-07-14 06:53:02,834 [INFO    ] __main__: train step 16360: loss: 1.0321, policy_loss: 0.9805, value_loss: 0.5290
2024-07-14 06:53:06,332 [INFO    ] __main__: train step 16361: loss: 1.0321, policy_loss: 0.9804, value_loss: 0.5289
2024-07-14 06:53:06,633 [INFO    ] __main__: train step 16362: loss: 1.0321, policy_loss: 0.9804, value_loss: 0.5289
2024-07-14 06:53:06,931 [INFO    ] __main__: train step 16363: loss: 1.0320, policy_loss: 0.9804, value_loss: 0.5289
2024-07-14 06:53:07,235 [INFO    ] __main__: train step 16364: loss: 1.0320, policy_loss: 0.9804, value_loss: 0.5288
2024-07-14 06:53:07,535 [INFO    ] __main__: train step 16365: loss: 1.0320, policy_loss: 0.9804, value_loss: 0.5288
2024-07-14 06:53:07,825 [INFO    ] __main__: train step 16366: loss: 1.0320, policy_loss: 0.9803, value_loss: 0.5288
2024-07-14 06:53:08,131 [INFO    ] __main__: train step 16367: loss: 1.0320, policy_loss: 0.9803, value_loss: 0.5288
2024-07-14 06:53:09,740 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:53:10,227 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:53:10,302 [INFO    ] __main__: train step 16368: loss: 1.0320, policy_loss: 0.9803, value_loss: 0.5287
2024-07-14 06:53:10,573 [INFO    ] __main__: train step 16369: loss: 1.0319, policy_loss: 0.9803, value_loss: 0.5287
2024-07-14 06:53:10,841 [INFO    ] __main__: train step 16370: loss: 1.0319, policy_loss: 0.9803, value_loss: 0.5287
2024-07-14 06:53:11,122 [INFO    ] __main__: train step 16371: loss: 1.0319, policy_loss: 0.9802, value_loss: 0.5287
2024-07-14 06:53:11,413 [INFO    ] __main__: train step 16372: loss: 1.0319, policy_loss: 0.9802, value_loss: 0.5286
2024-07-14 06:53:11,713 [INFO    ] __main__: train step 16373: loss: 1.0319, policy_loss: 0.9802, value_loss: 0.5286
2024-07-14 06:53:12,008 [INFO    ] __main__: train step 16374: loss: 1.0318, policy_loss: 0.9802, value_loss: 0.5286
2024-07-14 06:53:12,306 [INFO    ] __main__: train step 16375: loss: 1.0318, policy_loss: 0.9802, value_loss: 0.5286
2024-07-14 06:53:12,610 [INFO    ] __main__: train step 16376: loss: 1.0318, policy_loss: 0.9801, value_loss: 0.5285
2024-07-14 06:53:12,905 [INFO    ] __main__: train step 16377: loss: 1.0318, policy_loss: 0.9801, value_loss: 0.5285
2024-07-14 06:53:13,200 [INFO    ] __main__: train step 16378: loss: 1.0318, policy_loss: 0.9801, value_loss: 0.5285
2024-07-14 06:53:13,487 [INFO    ] __main__: train step 16379: loss: 1.0317, policy_loss: 0.9801, value_loss: 0.5284
2024-07-14 06:53:13,785 [INFO    ] __main__: train step 16380: loss: 1.0317, policy_loss: 0.9800, value_loss: 0.5284
2024-07-14 06:53:14,087 [INFO    ] __main__: train step 16381: loss: 1.0317, policy_loss: 0.9800, value_loss: 0.5284
2024-07-14 06:53:14,371 [INFO    ] __main__: train step 16382: loss: 1.0317, policy_loss: 0.9800, value_loss: 0.5284
2024-07-14 06:53:14,670 [INFO    ] __main__: train step 16383: loss: 1.0317, policy_loss: 0.9800, value_loss: 0.5283
2024-07-14 06:53:14,960 [INFO    ] __main__: train step 16384: loss: 1.0317, policy_loss: 0.9800, value_loss: 0.5283
2024-07-14 06:53:16,569 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:53:17,062 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:53:17,134 [INFO    ] __main__: train step 16385: loss: 1.0316, policy_loss: 0.9799, value_loss: 0.5283
2024-07-14 06:53:17,432 [INFO    ] __main__: train step 16386: loss: 1.0316, policy_loss: 0.9799, value_loss: 0.5283
2024-07-14 06:53:17,713 [INFO    ] __main__: train step 16387: loss: 1.0316, policy_loss: 0.9799, value_loss: 0.5282
2024-07-14 06:53:17,986 [INFO    ] __main__: train step 16388: loss: 1.0316, policy_loss: 0.9799, value_loss: 0.5282
2024-07-14 06:53:18,267 [INFO    ] __main__: train step 16389: loss: 1.0316, policy_loss: 0.9799, value_loss: 0.5282
2024-07-14 06:53:18,569 [INFO    ] __main__: train step 16390: loss: 1.0315, policy_loss: 0.9798, value_loss: 0.5282
2024-07-14 06:53:18,862 [INFO    ] __main__: train step 16391: loss: 1.0315, policy_loss: 0.9798, value_loss: 0.5281
2024-07-14 06:53:19,156 [INFO    ] __main__: train step 16392: loss: 1.0315, policy_loss: 0.9798, value_loss: 0.5281
2024-07-14 06:53:19,451 [INFO    ] __main__: train step 16393: loss: 1.0315, policy_loss: 0.9798, value_loss: 0.5281
2024-07-14 06:53:19,739 [INFO    ] __main__: train step 16394: loss: 1.0315, policy_loss: 0.9798, value_loss: 0.5281
2024-07-14 06:53:20,026 [INFO    ] __main__: train step 16395: loss: 1.0315, policy_loss: 0.9797, value_loss: 0.5280
2024-07-14 06:53:20,305 [INFO    ] __main__: train step 16396: loss: 1.0314, policy_loss: 0.9797, value_loss: 0.5280
2024-07-14 06:53:20,590 [INFO    ] __main__: train step 16397: loss: 1.0314, policy_loss: 0.9797, value_loss: 0.5280
2024-07-14 06:53:20,864 [INFO    ] __main__: train step 16398: loss: 1.0314, policy_loss: 0.9797, value_loss: 0.5279
2024-07-14 06:53:21,137 [INFO    ] __main__: train step 16399: loss: 1.0314, policy_loss: 0.9796, value_loss: 0.5279
2024-07-14 06:53:21,410 [INFO    ] __main__: train step 16400: loss: 1.0314, policy_loss: 0.9796, value_loss: 0.5279
2024-07-14 06:53:21,697 [INFO    ] __main__: train step 16401: loss: 1.0313, policy_loss: 0.9796, value_loss: 0.5279
2024-07-14 06:53:23,303 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:53:23,798 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:53:23,873 [INFO    ] __main__: train step 16402: loss: 1.0313, policy_loss: 0.9796, value_loss: 0.5278
2024-07-14 06:53:24,168 [INFO    ] __main__: train step 16403: loss: 1.0313, policy_loss: 0.9796, value_loss: 0.5278
2024-07-14 06:53:24,462 [INFO    ] __main__: train step 16404: loss: 1.0313, policy_loss: 0.9795, value_loss: 0.5278
2024-07-14 06:53:24,756 [INFO    ] __main__: train step 16405: loss: 1.0313, policy_loss: 0.9795, value_loss: 0.5278
2024-07-14 06:53:25,055 [INFO    ] __main__: train step 16406: loss: 1.0313, policy_loss: 0.9795, value_loss: 0.5277
2024-07-14 06:53:25,357 [INFO    ] __main__: train step 16407: loss: 1.0312, policy_loss: 0.9795, value_loss: 0.5277
2024-07-14 06:53:25,655 [INFO    ] __main__: train step 16408: loss: 1.0312, policy_loss: 0.9795, value_loss: 0.5277
2024-07-14 06:53:25,957 [INFO    ] __main__: train step 16409: loss: 1.0312, policy_loss: 0.9794, value_loss: 0.5277
2024-07-14 06:53:26,245 [INFO    ] __main__: train step 16410: loss: 1.0312, policy_loss: 0.9794, value_loss: 0.5276
2024-07-14 06:53:26,547 [INFO    ] __main__: train step 16411: loss: 1.0312, policy_loss: 0.9794, value_loss: 0.5276
2024-07-14 06:53:26,845 [INFO    ] __main__: train step 16412: loss: 1.0312, policy_loss: 0.9794, value_loss: 0.5276
2024-07-14 06:53:27,137 [INFO    ] __main__: train step 16413: loss: 1.0311, policy_loss: 0.9794, value_loss: 0.5276
2024-07-14 06:53:27,428 [INFO    ] __main__: train step 16414: loss: 1.0311, policy_loss: 0.9793, value_loss: 0.5275
2024-07-14 06:53:27,720 [INFO    ] __main__: train step 16415: loss: 1.0311, policy_loss: 0.9793, value_loss: 0.5275
2024-07-14 06:53:28,026 [INFO    ] __main__: train step 16416: loss: 1.0311, policy_loss: 0.9793, value_loss: 0.5275
2024-07-14 06:53:28,308 [INFO    ] __main__: train step 16417: loss: 1.0311, policy_loss: 0.9793, value_loss: 0.5275
2024-07-14 06:53:28,607 [INFO    ] __main__: train step 16418: loss: 1.0310, policy_loss: 0.9793, value_loss: 0.5274
2024-07-14 06:53:30,218 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:53:30,663 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:53:30,731 [INFO    ] __main__: train step 16419: loss: 1.0310, policy_loss: 0.9792, value_loss: 0.5274
2024-07-14 06:53:31,006 [INFO    ] __main__: train step 16420: loss: 1.0310, policy_loss: 0.9792, value_loss: 0.5274
2024-07-14 06:53:31,304 [INFO    ] __main__: train step 16421: loss: 1.0310, policy_loss: 0.9792, value_loss: 0.5273
2024-07-14 06:53:31,604 [INFO    ] __main__: train step 16422: loss: 1.0310, policy_loss: 0.9792, value_loss: 0.5273
2024-07-14 06:53:31,899 [INFO    ] __main__: train step 16423: loss: 1.0310, policy_loss: 0.9792, value_loss: 0.5273
2024-07-14 06:53:32,168 [INFO    ] __main__: train step 16424: loss: 1.0309, policy_loss: 0.9791, value_loss: 0.5273
2024-07-14 06:53:32,440 [INFO    ] __main__: train step 16425: loss: 1.0309, policy_loss: 0.9791, value_loss: 0.5272
2024-07-14 06:53:32,722 [INFO    ] __main__: train step 16426: loss: 1.0309, policy_loss: 0.9791, value_loss: 0.5272
2024-07-14 06:53:33,023 [INFO    ] __main__: train step 16427: loss: 1.0309, policy_loss: 0.9791, value_loss: 0.5272
2024-07-14 06:53:33,320 [INFO    ] __main__: train step 16428: loss: 1.0309, policy_loss: 0.9790, value_loss: 0.5272
2024-07-14 06:53:33,623 [INFO    ] __main__: train step 16429: loss: 1.0308, policy_loss: 0.9790, value_loss: 0.5271
2024-07-14 06:53:33,912 [INFO    ] __main__: train step 16430: loss: 1.0308, policy_loss: 0.9790, value_loss: 0.5271
2024-07-14 06:53:34,207 [INFO    ] __main__: train step 16431: loss: 1.0308, policy_loss: 0.9790, value_loss: 0.5271
2024-07-14 06:53:34,507 [INFO    ] __main__: train step 16432: loss: 1.0308, policy_loss: 0.9790, value_loss: 0.5271
2024-07-14 06:53:34,797 [INFO    ] __main__: train step 16433: loss: 1.0308, policy_loss: 0.9789, value_loss: 0.5270
2024-07-14 06:53:35,086 [INFO    ] __main__: train step 16434: loss: 1.0308, policy_loss: 0.9789, value_loss: 0.5270
2024-07-14 06:53:35,368 [INFO    ] __main__: train step 16435: loss: 1.0307, policy_loss: 0.9789, value_loss: 0.5270
2024-07-14 06:53:36,944 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:53:37,444 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:53:37,512 [INFO    ] __main__: train step 16436: loss: 1.0307, policy_loss: 0.9789, value_loss: 0.5269
2024-07-14 06:53:37,799 [INFO    ] __main__: train step 16437: loss: 1.0307, policy_loss: 0.9789, value_loss: 0.5269
2024-07-14 06:53:38,085 [INFO    ] __main__: train step 16438: loss: 1.0307, policy_loss: 0.9788, value_loss: 0.5269
2024-07-14 06:53:38,385 [INFO    ] __main__: train step 16439: loss: 1.0307, policy_loss: 0.9788, value_loss: 0.5269
2024-07-14 06:53:38,679 [INFO    ] __main__: train step 16440: loss: 1.0306, policy_loss: 0.9788, value_loss: 0.5268
2024-07-14 06:53:38,971 [INFO    ] __main__: train step 16441: loss: 1.0306, policy_loss: 0.9788, value_loss: 0.5268
2024-07-14 06:53:39,257 [INFO    ] __main__: train step 16442: loss: 1.0306, policy_loss: 0.9788, value_loss: 0.5268
2024-07-14 06:53:39,555 [INFO    ] __main__: train step 16443: loss: 1.0306, policy_loss: 0.9787, value_loss: 0.5268
2024-07-14 06:53:39,852 [INFO    ] __main__: train step 16444: loss: 1.0306, policy_loss: 0.9787, value_loss: 0.5267
2024-07-14 06:53:40,150 [INFO    ] __main__: train step 16445: loss: 1.0306, policy_loss: 0.9787, value_loss: 0.5267
2024-07-14 06:53:40,452 [INFO    ] __main__: train step 16446: loss: 1.0305, policy_loss: 0.9787, value_loss: 0.5267
2024-07-14 06:53:40,742 [INFO    ] __main__: train step 16447: loss: 1.0305, policy_loss: 0.9787, value_loss: 0.5267
2024-07-14 06:53:41,046 [INFO    ] __main__: train step 16448: loss: 1.0305, policy_loss: 0.9786, value_loss: 0.5266
2024-07-14 06:53:41,339 [INFO    ] __main__: train step 16449: loss: 1.0305, policy_loss: 0.9786, value_loss: 0.5266
2024-07-14 06:53:41,650 [INFO    ] __main__: train step 16450: loss: 1.0305, policy_loss: 0.9786, value_loss: 0.5266
2024-07-14 06:53:41,955 [INFO    ] __main__: train step 16451: loss: 1.0304, policy_loss: 0.9786, value_loss: 0.5266
2024-07-14 06:53:42,249 [INFO    ] __main__: train step 16452: loss: 1.0304, policy_loss: 0.9786, value_loss: 0.5265
2024-07-14 06:53:43,878 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:53:44,368 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:53:44,438 [INFO    ] __main__: train step 16453: loss: 1.0304, policy_loss: 0.9785, value_loss: 0.5265
2024-07-14 06:53:44,739 [INFO    ] __main__: train step 16454: loss: 1.0304, policy_loss: 0.9785, value_loss: 0.5265
2024-07-14 06:53:45,042 [INFO    ] __main__: train step 16455: loss: 1.0304, policy_loss: 0.9785, value_loss: 0.5264
2024-07-14 06:53:45,335 [INFO    ] __main__: train step 16456: loss: 1.0304, policy_loss: 0.9785, value_loss: 0.5264
2024-07-14 06:53:45,625 [INFO    ] __main__: train step 16457: loss: 1.0303, policy_loss: 0.9785, value_loss: 0.5264
2024-07-14 06:53:45,909 [INFO    ] __main__: train step 16458: loss: 1.0303, policy_loss: 0.9784, value_loss: 0.5264
2024-07-14 06:53:46,218 [INFO    ] __main__: train step 16459: loss: 1.0303, policy_loss: 0.9784, value_loss: 0.5263
2024-07-14 06:53:46,531 [INFO    ] __main__: train step 16460: loss: 1.0303, policy_loss: 0.9784, value_loss: 0.5263
2024-07-14 06:53:46,824 [INFO    ] __main__: train step 16461: loss: 1.0303, policy_loss: 0.9784, value_loss: 0.5263
2024-07-14 06:53:47,128 [INFO    ] __main__: train step 16462: loss: 1.0303, policy_loss: 0.9784, value_loss: 0.5263
2024-07-14 06:53:47,415 [INFO    ] __main__: train step 16463: loss: 1.0302, policy_loss: 0.9783, value_loss: 0.5262
2024-07-14 06:53:47,698 [INFO    ] __main__: train step 16464: loss: 1.0302, policy_loss: 0.9783, value_loss: 0.5262
2024-07-14 06:53:47,991 [INFO    ] __main__: train step 16465: loss: 1.0302, policy_loss: 0.9783, value_loss: 0.5262
2024-07-14 06:53:51,233 [INFO    ] __main__: train step 16466: loss: 1.0302, policy_loss: 0.9783, value_loss: 0.5262
2024-07-14 06:53:51,533 [INFO    ] __main__: train step 16467: loss: 1.0302, policy_loss: 0.9782, value_loss: 0.5261
2024-07-14 06:53:51,822 [INFO    ] __main__: train step 16468: loss: 1.0301, policy_loss: 0.9782, value_loss: 0.5261
2024-07-14 06:53:52,120 [INFO    ] __main__: train step 16469: loss: 1.0301, policy_loss: 0.9782, value_loss: 0.5261
2024-07-14 06:53:53,764 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:53:54,252 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:53:54,323 [INFO    ] __main__: train step 16470: loss: 1.0301, policy_loss: 0.9782, value_loss: 0.5261
2024-07-14 06:53:54,642 [INFO    ] __main__: train step 16471: loss: 1.0301, policy_loss: 0.9782, value_loss: 0.5260
2024-07-14 06:53:54,939 [INFO    ] __main__: train step 16472: loss: 1.0301, policy_loss: 0.9781, value_loss: 0.5260
2024-07-14 06:53:55,233 [INFO    ] __main__: train step 16473: loss: 1.0301, policy_loss: 0.9781, value_loss: 0.5260
2024-07-14 06:53:55,517 [INFO    ] __main__: train step 16474: loss: 1.0300, policy_loss: 0.9781, value_loss: 0.5260
2024-07-14 06:53:55,811 [INFO    ] __main__: train step 16475: loss: 1.0300, policy_loss: 0.9781, value_loss: 0.5259
2024-07-14 06:53:56,081 [INFO    ] __main__: train step 16476: loss: 1.0300, policy_loss: 0.9781, value_loss: 0.5259
2024-07-14 06:53:56,382 [INFO    ] __main__: train step 16477: loss: 1.0300, policy_loss: 0.9780, value_loss: 0.5259
2024-07-14 06:53:56,682 [INFO    ] __main__: train step 16478: loss: 1.0300, policy_loss: 0.9780, value_loss: 0.5258
2024-07-14 06:53:56,980 [INFO    ] __main__: train step 16479: loss: 1.0300, policy_loss: 0.9780, value_loss: 0.5258
2024-07-14 06:53:57,276 [INFO    ] __main__: train step 16480: loss: 1.0299, policy_loss: 0.9780, value_loss: 0.5258
2024-07-14 06:53:57,572 [INFO    ] __main__: train step 16481: loss: 1.0299, policy_loss: 0.9780, value_loss: 0.5258
2024-07-14 06:53:57,864 [INFO    ] __main__: train step 16482: loss: 1.0299, policy_loss: 0.9779, value_loss: 0.5257
2024-07-14 06:53:58,153 [INFO    ] __main__: train step 16483: loss: 1.0299, policy_loss: 0.9779, value_loss: 0.5257
2024-07-14 06:53:58,449 [INFO    ] __main__: train step 16484: loss: 1.0299, policy_loss: 0.9779, value_loss: 0.5257
2024-07-14 06:53:58,742 [INFO    ] __main__: train step 16485: loss: 1.0298, policy_loss: 0.9779, value_loss: 0.5257
2024-07-14 06:53:59,039 [INFO    ] __main__: train step 16486: loss: 1.0298, policy_loss: 0.9779, value_loss: 0.5256
2024-07-14 06:54:00,622 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:54:01,114 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:54:01,188 [INFO    ] __main__: train step 16487: loss: 1.0298, policy_loss: 0.9778, value_loss: 0.5256
2024-07-14 06:54:01,461 [INFO    ] __main__: train step 16488: loss: 1.0298, policy_loss: 0.9778, value_loss: 0.5256
2024-07-14 06:54:01,749 [INFO    ] __main__: train step 16489: loss: 1.0298, policy_loss: 0.9778, value_loss: 0.5256
2024-07-14 06:54:02,043 [INFO    ] __main__: train step 16490: loss: 1.0298, policy_loss: 0.9778, value_loss: 0.5255
2024-07-14 06:54:02,337 [INFO    ] __main__: train step 16491: loss: 1.0297, policy_loss: 0.9778, value_loss: 0.5255
2024-07-14 06:54:02,635 [INFO    ] __main__: train step 16492: loss: 1.0297, policy_loss: 0.9777, value_loss: 0.5255
2024-07-14 06:54:02,929 [INFO    ] __main__: train step 16493: loss: 1.0297, policy_loss: 0.9777, value_loss: 0.5255
2024-07-14 06:54:03,222 [INFO    ] __main__: train step 16494: loss: 1.0297, policy_loss: 0.9777, value_loss: 0.5254
2024-07-14 06:54:03,501 [INFO    ] __main__: train step 16495: loss: 1.0297, policy_loss: 0.9777, value_loss: 0.5254
2024-07-14 06:54:03,780 [INFO    ] __main__: train step 16496: loss: 1.0297, policy_loss: 0.9777, value_loss: 0.5254
2024-07-14 06:54:04,083 [INFO    ] __main__: train step 16497: loss: 1.0296, policy_loss: 0.9776, value_loss: 0.5254
2024-07-14 06:54:04,376 [INFO    ] __main__: train step 16498: loss: 1.0296, policy_loss: 0.9776, value_loss: 0.5253
2024-07-14 06:54:04,664 [INFO    ] __main__: train step 16499: loss: 1.0296, policy_loss: 0.9776, value_loss: 0.5253
2024-07-14 06:54:04,940 [INFO    ] __main__: train step 16500: loss: 1.0296, policy_loss: 0.9776, value_loss: 0.5253
2024-07-14 06:54:05,242 [INFO    ] __main__: train step 16501: loss: 1.0296, policy_loss: 0.9776, value_loss: 0.5253
2024-07-14 06:54:05,523 [INFO    ] __main__: train step 16502: loss: 1.0295, policy_loss: 0.9775, value_loss: 0.5252
2024-07-14 06:54:05,819 [INFO    ] __main__: train step 16503: loss: 1.0295, policy_loss: 0.9775, value_loss: 0.5252
2024-07-14 06:54:07,425 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:54:07,907 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:54:07,982 [INFO    ] __main__: train step 16504: loss: 1.0295, policy_loss: 0.9775, value_loss: 0.5252
2024-07-14 06:54:08,297 [INFO    ] __main__: train step 16505: loss: 1.0295, policy_loss: 0.9775, value_loss: 0.5251
2024-07-14 06:54:08,592 [INFO    ] __main__: train step 16506: loss: 1.0295, policy_loss: 0.9775, value_loss: 0.5251
2024-07-14 06:54:08,889 [INFO    ] __main__: train step 16507: loss: 1.0295, policy_loss: 0.9774, value_loss: 0.5251
2024-07-14 06:54:09,198 [INFO    ] __main__: train step 16508: loss: 1.0294, policy_loss: 0.9774, value_loss: 0.5251
2024-07-14 06:54:09,492 [INFO    ] __main__: train step 16509: loss: 1.0294, policy_loss: 0.9774, value_loss: 0.5250
2024-07-14 06:54:09,790 [INFO    ] __main__: train step 16510: loss: 1.0294, policy_loss: 0.9774, value_loss: 0.5250
2024-07-14 06:54:10,082 [INFO    ] __main__: train step 16511: loss: 1.0294, policy_loss: 0.9774, value_loss: 0.5250
2024-07-14 06:54:10,379 [INFO    ] __main__: train step 16512: loss: 1.0294, policy_loss: 0.9773, value_loss: 0.5250
2024-07-14 06:54:10,678 [INFO    ] __main__: train step 16513: loss: 1.0294, policy_loss: 0.9773, value_loss: 0.5249
2024-07-14 06:54:10,969 [INFO    ] __main__: train step 16514: loss: 1.0293, policy_loss: 0.9773, value_loss: 0.5249
2024-07-14 06:54:11,254 [INFO    ] __main__: train step 16515: loss: 1.0293, policy_loss: 0.9773, value_loss: 0.5249
2024-07-14 06:54:11,548 [INFO    ] __main__: train step 16516: loss: 1.0293, policy_loss: 0.9773, value_loss: 0.5249
2024-07-14 06:54:11,838 [INFO    ] __main__: train step 16517: loss: 1.0293, policy_loss: 0.9772, value_loss: 0.5248
2024-07-14 06:54:12,136 [INFO    ] __main__: train step 16518: loss: 1.0293, policy_loss: 0.9772, value_loss: 0.5248
2024-07-14 06:54:12,435 [INFO    ] __main__: train step 16519: loss: 1.0292, policy_loss: 0.9772, value_loss: 0.5248
2024-07-14 06:54:12,728 [INFO    ] __main__: train step 16520: loss: 1.0292, policy_loss: 0.9772, value_loss: 0.5248
2024-07-14 06:54:14,359 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:54:14,848 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:54:14,921 [INFO    ] __main__: train step 16521: loss: 1.0292, policy_loss: 0.9772, value_loss: 0.5247
2024-07-14 06:54:15,219 [INFO    ] __main__: train step 16522: loss: 1.0292, policy_loss: 0.9771, value_loss: 0.5247
2024-07-14 06:54:15,515 [INFO    ] __main__: train step 16523: loss: 1.0292, policy_loss: 0.9771, value_loss: 0.5247
2024-07-14 06:54:15,808 [INFO    ] __main__: train step 16524: loss: 1.0292, policy_loss: 0.9771, value_loss: 0.5246
2024-07-14 06:54:16,099 [INFO    ] __main__: train step 16525: loss: 1.0291, policy_loss: 0.9771, value_loss: 0.5246
2024-07-14 06:54:16,399 [INFO    ] __main__: train step 16526: loss: 1.0291, policy_loss: 0.9771, value_loss: 0.5246
2024-07-14 06:54:16,689 [INFO    ] __main__: train step 16527: loss: 1.0291, policy_loss: 0.9770, value_loss: 0.5246
2024-07-14 06:54:16,983 [INFO    ] __main__: train step 16528: loss: 1.0291, policy_loss: 0.9770, value_loss: 0.5245
2024-07-14 06:54:17,276 [INFO    ] __main__: train step 16529: loss: 1.0291, policy_loss: 0.9770, value_loss: 0.5245
2024-07-14 06:54:17,578 [INFO    ] __main__: train step 16530: loss: 1.0291, policy_loss: 0.9770, value_loss: 0.5245
2024-07-14 06:54:17,876 [INFO    ] __main__: train step 16531: loss: 1.0290, policy_loss: 0.9770, value_loss: 0.5245
2024-07-14 06:54:18,171 [INFO    ] __main__: train step 16532: loss: 1.0290, policy_loss: 0.9769, value_loss: 0.5244
2024-07-14 06:54:18,468 [INFO    ] __main__: train step 16533: loss: 1.0290, policy_loss: 0.9769, value_loss: 0.5244
2024-07-14 06:54:18,761 [INFO    ] __main__: train step 16534: loss: 1.0290, policy_loss: 0.9769, value_loss: 0.5244
2024-07-14 06:54:19,062 [INFO    ] __main__: train step 16535: loss: 1.0290, policy_loss: 0.9769, value_loss: 0.5244
2024-07-14 06:54:19,347 [INFO    ] __main__: train step 16536: loss: 1.0290, policy_loss: 0.9769, value_loss: 0.5243
2024-07-14 06:54:19,645 [INFO    ] __main__: train step 16537: loss: 1.0289, policy_loss: 0.9768, value_loss: 0.5243
2024-07-14 06:54:21,282 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:54:21,767 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:54:21,839 [INFO    ] __main__: train step 16538: loss: 1.0289, policy_loss: 0.9768, value_loss: 0.5243
2024-07-14 06:54:22,140 [INFO    ] __main__: train step 16539: loss: 1.0289, policy_loss: 0.9768, value_loss: 0.5243
2024-07-14 06:54:22,422 [INFO    ] __main__: train step 16540: loss: 1.0289, policy_loss: 0.9768, value_loss: 0.5242
2024-07-14 06:54:22,718 [INFO    ] __main__: train step 16541: loss: 1.0289, policy_loss: 0.9768, value_loss: 0.5242
2024-07-14 06:54:23,005 [INFO    ] __main__: train step 16542: loss: 1.0289, policy_loss: 0.9767, value_loss: 0.5242
2024-07-14 06:54:23,298 [INFO    ] __main__: train step 16543: loss: 1.0288, policy_loss: 0.9767, value_loss: 0.5242
2024-07-14 06:54:23,598 [INFO    ] __main__: train step 16544: loss: 1.0288, policy_loss: 0.9767, value_loss: 0.5241
2024-07-14 06:54:23,876 [INFO    ] __main__: train step 16545: loss: 1.0288, policy_loss: 0.9767, value_loss: 0.5241
2024-07-14 06:54:24,166 [INFO    ] __main__: train step 16546: loss: 1.0288, policy_loss: 0.9767, value_loss: 0.5241
2024-07-14 06:54:24,436 [INFO    ] __main__: train step 16547: loss: 1.0288, policy_loss: 0.9767, value_loss: 0.5240
2024-07-14 06:54:24,703 [INFO    ] __main__: train step 16548: loss: 1.0288, policy_loss: 0.9766, value_loss: 0.5240
2024-07-14 06:54:24,974 [INFO    ] __main__: train step 16549: loss: 1.0287, policy_loss: 0.9766, value_loss: 0.5240
2024-07-14 06:54:25,238 [INFO    ] __main__: train step 16550: loss: 1.0287, policy_loss: 0.9766, value_loss: 0.5240
2024-07-14 06:54:25,534 [INFO    ] __main__: train step 16551: loss: 1.0287, policy_loss: 0.9766, value_loss: 0.5239
2024-07-14 06:54:25,831 [INFO    ] __main__: train step 16552: loss: 1.0287, policy_loss: 0.9766, value_loss: 0.5239
2024-07-14 06:54:26,122 [INFO    ] __main__: train step 16553: loss: 1.0287, policy_loss: 0.9765, value_loss: 0.5239
2024-07-14 06:54:26,396 [INFO    ] __main__: train step 16554: loss: 1.0286, policy_loss: 0.9765, value_loss: 0.5239
2024-07-14 06:54:27,986 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:54:28,458 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:54:28,534 [INFO    ] __main__: train step 16555: loss: 1.0286, policy_loss: 0.9765, value_loss: 0.5238
2024-07-14 06:54:28,821 [INFO    ] __main__: train step 16556: loss: 1.0286, policy_loss: 0.9765, value_loss: 0.5238
2024-07-14 06:54:29,115 [INFO    ] __main__: train step 16557: loss: 1.0286, policy_loss: 0.9765, value_loss: 0.5238
2024-07-14 06:54:29,406 [INFO    ] __main__: train step 16558: loss: 1.0286, policy_loss: 0.9764, value_loss: 0.5238
2024-07-14 06:54:29,700 [INFO    ] __main__: train step 16559: loss: 1.0286, policy_loss: 0.9764, value_loss: 0.5237
2024-07-14 06:54:30,002 [INFO    ] __main__: train step 16560: loss: 1.0285, policy_loss: 0.9764, value_loss: 0.5237
2024-07-14 06:54:30,288 [INFO    ] __main__: train step 16561: loss: 1.0285, policy_loss: 0.9764, value_loss: 0.5237
2024-07-14 06:54:30,582 [INFO    ] __main__: train step 16562: loss: 1.0285, policy_loss: 0.9764, value_loss: 0.5237
2024-07-14 06:54:30,873 [INFO    ] __main__: train step 16563: loss: 1.0285, policy_loss: 0.9763, value_loss: 0.5236
2024-07-14 06:54:31,165 [INFO    ] __main__: train step 16564: loss: 1.0285, policy_loss: 0.9763, value_loss: 0.5236
2024-07-14 06:54:31,458 [INFO    ] __main__: train step 16565: loss: 1.0285, policy_loss: 0.9763, value_loss: 0.5236
2024-07-14 06:54:31,751 [INFO    ] __main__: train step 16566: loss: 1.0284, policy_loss: 0.9763, value_loss: 0.5236
2024-07-14 06:54:32,048 [INFO    ] __main__: train step 16567: loss: 1.0284, policy_loss: 0.9763, value_loss: 0.5235
2024-07-14 06:54:35,558 [INFO    ] __main__: train step 16568: loss: 1.0284, policy_loss: 0.9762, value_loss: 0.5235
2024-07-14 06:54:35,846 [INFO    ] __main__: train step 16569: loss: 1.0284, policy_loss: 0.9762, value_loss: 0.5235
2024-07-14 06:54:36,153 [INFO    ] __main__: train step 16570: loss: 1.0284, policy_loss: 0.9762, value_loss: 0.5235
2024-07-14 06:54:36,451 [INFO    ] __main__: train step 16571: loss: 1.0284, policy_loss: 0.9762, value_loss: 0.5234
2024-07-14 06:54:38,095 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:54:38,539 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:54:38,609 [INFO    ] __main__: train step 16572: loss: 1.0283, policy_loss: 0.9762, value_loss: 0.5234
2024-07-14 06:54:38,915 [INFO    ] __main__: train step 16573: loss: 1.0283, policy_loss: 0.9761, value_loss: 0.5234
2024-07-14 06:54:39,211 [INFO    ] __main__: train step 16574: loss: 1.0283, policy_loss: 0.9761, value_loss: 0.5234
2024-07-14 06:54:39,504 [INFO    ] __main__: train step 16575: loss: 1.0283, policy_loss: 0.9761, value_loss: 0.5233
2024-07-14 06:54:39,798 [INFO    ] __main__: train step 16576: loss: 1.0283, policy_loss: 0.9761, value_loss: 0.5233
2024-07-14 06:54:40,100 [INFO    ] __main__: train step 16577: loss: 1.0283, policy_loss: 0.9761, value_loss: 0.5233
2024-07-14 06:54:40,405 [INFO    ] __main__: train step 16578: loss: 1.0282, policy_loss: 0.9760, value_loss: 0.5232
2024-07-14 06:54:40,695 [INFO    ] __main__: train step 16579: loss: 1.0282, policy_loss: 0.9760, value_loss: 0.5232
2024-07-14 06:54:40,979 [INFO    ] __main__: train step 16580: loss: 1.0282, policy_loss: 0.9760, value_loss: 0.5232
2024-07-14 06:54:41,262 [INFO    ] __main__: train step 16581: loss: 1.0282, policy_loss: 0.9760, value_loss: 0.5232
2024-07-14 06:54:41,554 [INFO    ] __main__: train step 16582: loss: 1.0282, policy_loss: 0.9760, value_loss: 0.5231
2024-07-14 06:54:41,845 [INFO    ] __main__: train step 16583: loss: 1.0282, policy_loss: 0.9759, value_loss: 0.5231
2024-07-14 06:54:42,141 [INFO    ] __main__: train step 16584: loss: 1.0281, policy_loss: 0.9759, value_loss: 0.5231
2024-07-14 06:54:42,442 [INFO    ] __main__: train step 16585: loss: 1.0281, policy_loss: 0.9759, value_loss: 0.5231
2024-07-14 06:54:42,753 [INFO    ] __main__: train step 16586: loss: 1.0281, policy_loss: 0.9759, value_loss: 0.5230
2024-07-14 06:54:43,065 [INFO    ] __main__: train step 16587: loss: 1.0281, policy_loss: 0.9759, value_loss: 0.5230
2024-07-14 06:54:43,360 [INFO    ] __main__: train step 16588: loss: 1.0281, policy_loss: 0.9758, value_loss: 0.5230
2024-07-14 06:54:44,987 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:54:45,487 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:54:45,561 [INFO    ] __main__: train step 16589: loss: 1.0280, policy_loss: 0.9758, value_loss: 0.5230
2024-07-14 06:54:45,854 [INFO    ] __main__: train step 16590: loss: 1.0280, policy_loss: 0.9758, value_loss: 0.5229
2024-07-14 06:54:46,149 [INFO    ] __main__: train step 16591: loss: 1.0280, policy_loss: 0.9758, value_loss: 0.5229
2024-07-14 06:54:46,454 [INFO    ] __main__: train step 16592: loss: 1.0280, policy_loss: 0.9758, value_loss: 0.5229
2024-07-14 06:54:46,750 [INFO    ] __main__: train step 16593: loss: 1.0280, policy_loss: 0.9757, value_loss: 0.5229
2024-07-14 06:54:47,054 [INFO    ] __main__: train step 16594: loss: 1.0280, policy_loss: 0.9757, value_loss: 0.5228
2024-07-14 06:54:47,342 [INFO    ] __main__: train step 16595: loss: 1.0279, policy_loss: 0.9757, value_loss: 0.5228
2024-07-14 06:54:47,639 [INFO    ] __main__: train step 16596: loss: 1.0279, policy_loss: 0.9757, value_loss: 0.5228
2024-07-14 06:54:47,937 [INFO    ] __main__: train step 16597: loss: 1.0279, policy_loss: 0.9757, value_loss: 0.5228
2024-07-14 06:54:48,235 [INFO    ] __main__: train step 16598: loss: 1.0279, policy_loss: 0.9756, value_loss: 0.5227
2024-07-14 06:54:48,535 [INFO    ] __main__: train step 16599: loss: 1.0279, policy_loss: 0.9756, value_loss: 0.5227
2024-07-14 06:54:48,838 [INFO    ] __main__: train step 16600: loss: 1.0279, policy_loss: 0.9756, value_loss: 0.5227
2024-07-14 06:54:49,138 [INFO    ] __main__: train step 16601: loss: 1.0278, policy_loss: 0.9756, value_loss: 0.5226
2024-07-14 06:54:49,441 [INFO    ] __main__: train step 16602: loss: 1.0278, policy_loss: 0.9756, value_loss: 0.5226
2024-07-14 06:54:49,728 [INFO    ] __main__: train step 16603: loss: 1.0278, policy_loss: 0.9755, value_loss: 0.5226
2024-07-14 06:54:50,003 [INFO    ] __main__: train step 16604: loss: 1.0278, policy_loss: 0.9755, value_loss: 0.5226
2024-07-14 06:54:50,278 [INFO    ] __main__: train step 16605: loss: 1.0278, policy_loss: 0.9755, value_loss: 0.5225
2024-07-14 06:54:51,872 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:54:52,348 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:54:52,425 [INFO    ] __main__: train step 16606: loss: 1.0278, policy_loss: 0.9755, value_loss: 0.5225
2024-07-14 06:54:52,722 [INFO    ] __main__: train step 16607: loss: 1.0277, policy_loss: 0.9755, value_loss: 0.5225
2024-07-14 06:54:53,000 [INFO    ] __main__: train step 16608: loss: 1.0277, policy_loss: 0.9754, value_loss: 0.5225
2024-07-14 06:54:53,310 [INFO    ] __main__: train step 16609: loss: 1.0277, policy_loss: 0.9754, value_loss: 0.5224
2024-07-14 06:54:53,599 [INFO    ] __main__: train step 16610: loss: 1.0277, policy_loss: 0.9754, value_loss: 0.5224
2024-07-14 06:54:53,898 [INFO    ] __main__: train step 16611: loss: 1.0277, policy_loss: 0.9754, value_loss: 0.5224
2024-07-14 06:54:54,189 [INFO    ] __main__: train step 16612: loss: 1.0276, policy_loss: 0.9754, value_loss: 0.5224
2024-07-14 06:54:54,481 [INFO    ] __main__: train step 16613: loss: 1.0276, policy_loss: 0.9753, value_loss: 0.5223
2024-07-14 06:54:54,788 [INFO    ] __main__: train step 16614: loss: 1.0276, policy_loss: 0.9753, value_loss: 0.5223
2024-07-14 06:54:55,085 [INFO    ] __main__: train step 16615: loss: 1.0276, policy_loss: 0.9753, value_loss: 0.5223
2024-07-14 06:54:55,391 [INFO    ] __main__: train step 16616: loss: 1.0276, policy_loss: 0.9753, value_loss: 0.5223
2024-07-14 06:54:55,682 [INFO    ] __main__: train step 16617: loss: 1.0276, policy_loss: 0.9753, value_loss: 0.5222
2024-07-14 06:54:55,972 [INFO    ] __main__: train step 16618: loss: 1.0275, policy_loss: 0.9752, value_loss: 0.5222
2024-07-14 06:54:56,271 [INFO    ] __main__: train step 16619: loss: 1.0275, policy_loss: 0.9752, value_loss: 0.5222
2024-07-14 06:54:56,556 [INFO    ] __main__: train step 16620: loss: 1.0275, policy_loss: 0.9752, value_loss: 0.5222
2024-07-14 06:54:56,852 [INFO    ] __main__: train step 16621: loss: 1.0275, policy_loss: 0.9752, value_loss: 0.5221
2024-07-14 06:54:57,137 [INFO    ] __main__: train step 16622: loss: 1.0275, policy_loss: 0.9752, value_loss: 0.5221
2024-07-14 06:54:58,742 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:54:59,201 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:54:59,277 [INFO    ] __main__: train step 16623: loss: 1.0275, policy_loss: 0.9751, value_loss: 0.5221
2024-07-14 06:54:59,581 [INFO    ] __main__: train step 16624: loss: 1.0274, policy_loss: 0.9751, value_loss: 0.5221
2024-07-14 06:54:59,903 [INFO    ] __main__: train step 16625: loss: 1.0274, policy_loss: 0.9751, value_loss: 0.5220
2024-07-14 06:55:00,204 [INFO    ] __main__: train step 16626: loss: 1.0274, policy_loss: 0.9751, value_loss: 0.5220
2024-07-14 06:55:00,500 [INFO    ] __main__: train step 16627: loss: 1.0274, policy_loss: 0.9751, value_loss: 0.5220
2024-07-14 06:55:00,807 [INFO    ] __main__: train step 16628: loss: 1.0274, policy_loss: 0.9750, value_loss: 0.5220
2024-07-14 06:55:01,107 [INFO    ] __main__: train step 16629: loss: 1.0274, policy_loss: 0.9750, value_loss: 0.5219
2024-07-14 06:55:01,402 [INFO    ] __main__: train step 16630: loss: 1.0273, policy_loss: 0.9750, value_loss: 0.5219
2024-07-14 06:55:01,695 [INFO    ] __main__: train step 16631: loss: 1.0273, policy_loss: 0.9750, value_loss: 0.5219
2024-07-14 06:55:01,978 [INFO    ] __main__: train step 16632: loss: 1.0273, policy_loss: 0.9750, value_loss: 0.5218
2024-07-14 06:55:02,269 [INFO    ] __main__: train step 16633: loss: 1.0273, policy_loss: 0.9749, value_loss: 0.5218
2024-07-14 06:55:02,569 [INFO    ] __main__: train step 16634: loss: 1.0273, policy_loss: 0.9749, value_loss: 0.5218
2024-07-14 06:55:02,855 [INFO    ] __main__: train step 16635: loss: 1.0272, policy_loss: 0.9749, value_loss: 0.5218
2024-07-14 06:55:03,148 [INFO    ] __main__: train step 16636: loss: 1.0272, policy_loss: 0.9749, value_loss: 0.5217
2024-07-14 06:55:03,437 [INFO    ] __main__: train step 16637: loss: 1.0272, policy_loss: 0.9749, value_loss: 0.5217
2024-07-14 06:55:03,731 [INFO    ] __main__: train step 16638: loss: 1.0272, policy_loss: 0.9748, value_loss: 0.5217
2024-07-14 06:55:04,014 [INFO    ] __main__: train step 16639: loss: 1.0272, policy_loss: 0.9748, value_loss: 0.5217
2024-07-14 06:55:05,656 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:55:06,160 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:55:06,228 [INFO    ] __main__: train step 16640: loss: 1.0272, policy_loss: 0.9748, value_loss: 0.5216
2024-07-14 06:55:06,528 [INFO    ] __main__: train step 16641: loss: 1.0271, policy_loss: 0.9748, value_loss: 0.5216
2024-07-14 06:55:06,831 [INFO    ] __main__: train step 16642: loss: 1.0271, policy_loss: 0.9748, value_loss: 0.5216
2024-07-14 06:55:07,132 [INFO    ] __main__: train step 16643: loss: 1.0271, policy_loss: 0.9747, value_loss: 0.5216
2024-07-14 06:55:07,422 [INFO    ] __main__: train step 16644: loss: 1.0271, policy_loss: 0.9747, value_loss: 0.5215
2024-07-14 06:55:07,717 [INFO    ] __main__: train step 16645: loss: 1.0271, policy_loss: 0.9747, value_loss: 0.5215
2024-07-14 06:55:08,011 [INFO    ] __main__: train step 16646: loss: 1.0271, policy_loss: 0.9747, value_loss: 0.5215
2024-07-14 06:55:08,308 [INFO    ] __main__: train step 16647: loss: 1.0270, policy_loss: 0.9747, value_loss: 0.5215
2024-07-14 06:55:08,610 [INFO    ] __main__: train step 16648: loss: 1.0270, policy_loss: 0.9747, value_loss: 0.5214
2024-07-14 06:55:08,902 [INFO    ] __main__: train step 16649: loss: 1.0270, policy_loss: 0.9746, value_loss: 0.5214
2024-07-14 06:55:09,181 [INFO    ] __main__: train step 16650: loss: 1.0270, policy_loss: 0.9746, value_loss: 0.5214
2024-07-14 06:55:09,483 [INFO    ] __main__: train step 16651: loss: 1.0270, policy_loss: 0.9746, value_loss: 0.5214
2024-07-14 06:55:09,772 [INFO    ] __main__: train step 16652: loss: 1.0270, policy_loss: 0.9746, value_loss: 0.5213
2024-07-14 06:55:10,063 [INFO    ] __main__: train step 16653: loss: 1.0269, policy_loss: 0.9746, value_loss: 0.5213
2024-07-14 06:55:10,354 [INFO    ] __main__: train step 16654: loss: 1.0269, policy_loss: 0.9745, value_loss: 0.5213
2024-07-14 06:55:10,651 [INFO    ] __main__: train step 16655: loss: 1.0269, policy_loss: 0.9745, value_loss: 0.5213
2024-07-14 06:55:10,942 [INFO    ] __main__: train step 16656: loss: 1.0269, policy_loss: 0.9745, value_loss: 0.5212
2024-07-14 06:55:12,557 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:55:13,048 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:55:13,119 [INFO    ] __main__: train step 16657: loss: 1.0269, policy_loss: 0.9745, value_loss: 0.5212
2024-07-14 06:55:13,415 [INFO    ] __main__: train step 16658: loss: 1.0269, policy_loss: 0.9745, value_loss: 0.5212
2024-07-14 06:55:13,708 [INFO    ] __main__: train step 16659: loss: 1.0268, policy_loss: 0.9744, value_loss: 0.5212
2024-07-14 06:55:14,008 [INFO    ] __main__: train step 16660: loss: 1.0268, policy_loss: 0.9744, value_loss: 0.5211
2024-07-14 06:55:14,315 [INFO    ] __main__: train step 16661: loss: 1.0268, policy_loss: 0.9744, value_loss: 0.5211
2024-07-14 06:55:14,611 [INFO    ] __main__: train step 16662: loss: 1.0268, policy_loss: 0.9744, value_loss: 0.5211
2024-07-14 06:55:14,904 [INFO    ] __main__: train step 16663: loss: 1.0268, policy_loss: 0.9744, value_loss: 0.5211
2024-07-14 06:55:15,215 [INFO    ] __main__: train step 16664: loss: 1.0267, policy_loss: 0.9743, value_loss: 0.5210
2024-07-14 06:55:15,514 [INFO    ] __main__: train step 16665: loss: 1.0267, policy_loss: 0.9743, value_loss: 0.5210
2024-07-14 06:55:15,810 [INFO    ] __main__: train step 16666: loss: 1.0267, policy_loss: 0.9743, value_loss: 0.5210
2024-07-14 06:55:16,093 [INFO    ] __main__: train step 16667: loss: 1.0267, policy_loss: 0.9743, value_loss: 0.5209
2024-07-14 06:55:16,399 [INFO    ] __main__: train step 16668: loss: 1.0267, policy_loss: 0.9743, value_loss: 0.5209
2024-07-14 06:55:16,700 [INFO    ] __main__: train step 16669: loss: 1.0267, policy_loss: 0.9742, value_loss: 0.5209
2024-07-14 06:55:16,986 [INFO    ] __main__: train step 16670: loss: 1.0266, policy_loss: 0.9742, value_loss: 0.5209
2024-07-14 06:55:17,282 [INFO    ] __main__: train step 16671: loss: 1.0266, policy_loss: 0.9742, value_loss: 0.5208
2024-07-14 06:55:20,716 [INFO    ] __main__: train step 16672: loss: 1.0266, policy_loss: 0.9742, value_loss: 0.5208
2024-07-14 06:55:21,017 [INFO    ] __main__: train step 16673: loss: 1.0266, policy_loss: 0.9742, value_loss: 0.5208
2024-07-14 06:55:22,600 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:55:23,102 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:55:23,176 [INFO    ] __main__: train step 16674: loss: 1.0266, policy_loss: 0.9741, value_loss: 0.5208
2024-07-14 06:55:23,465 [INFO    ] __main__: train step 16675: loss: 1.0266, policy_loss: 0.9741, value_loss: 0.5207
2024-07-14 06:55:23,752 [INFO    ] __main__: train step 16676: loss: 1.0265, policy_loss: 0.9741, value_loss: 0.5207
2024-07-14 06:55:24,048 [INFO    ] __main__: train step 16677: loss: 1.0265, policy_loss: 0.9741, value_loss: 0.5207
2024-07-14 06:55:24,341 [INFO    ] __main__: train step 16678: loss: 1.0265, policy_loss: 0.9741, value_loss: 0.5207
2024-07-14 06:55:24,631 [INFO    ] __main__: train step 16679: loss: 1.0265, policy_loss: 0.9740, value_loss: 0.5206
2024-07-14 06:55:24,924 [INFO    ] __main__: train step 16680: loss: 1.0265, policy_loss: 0.9740, value_loss: 0.5206
2024-07-14 06:55:25,211 [INFO    ] __main__: train step 16681: loss: 1.0265, policy_loss: 0.9740, value_loss: 0.5206
2024-07-14 06:55:25,511 [INFO    ] __main__: train step 16682: loss: 1.0264, policy_loss: 0.9740, value_loss: 0.5206
2024-07-14 06:55:25,795 [INFO    ] __main__: train step 16683: loss: 1.0264, policy_loss: 0.9740, value_loss: 0.5205
2024-07-14 06:55:26,078 [INFO    ] __main__: train step 16684: loss: 1.0264, policy_loss: 0.9740, value_loss: 0.5205
2024-07-14 06:55:26,374 [INFO    ] __main__: train step 16685: loss: 1.0264, policy_loss: 0.9739, value_loss: 0.5205
2024-07-14 06:55:26,650 [INFO    ] __main__: train step 16686: loss: 1.0264, policy_loss: 0.9739, value_loss: 0.5205
2024-07-14 06:55:26,955 [INFO    ] __main__: train step 16687: loss: 1.0264, policy_loss: 0.9739, value_loss: 0.5204
2024-07-14 06:55:27,250 [INFO    ] __main__: train step 16688: loss: 1.0263, policy_loss: 0.9739, value_loss: 0.5204
2024-07-14 06:55:27,540 [INFO    ] __main__: train step 16689: loss: 1.0263, policy_loss: 0.9739, value_loss: 0.5204
2024-07-14 06:55:27,835 [INFO    ] __main__: train step 16690: loss: 1.0263, policy_loss: 0.9738, value_loss: 0.5204
2024-07-14 06:55:29,463 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:55:29,951 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:55:30,019 [INFO    ] __main__: train step 16691: loss: 1.0263, policy_loss: 0.9738, value_loss: 0.5203
2024-07-14 06:55:30,313 [INFO    ] __main__: train step 16692: loss: 1.0263, policy_loss: 0.9738, value_loss: 0.5203
2024-07-14 06:55:30,599 [INFO    ] __main__: train step 16693: loss: 1.0263, policy_loss: 0.9738, value_loss: 0.5203
2024-07-14 06:55:30,887 [INFO    ] __main__: train step 16694: loss: 1.0262, policy_loss: 0.9738, value_loss: 0.5203
2024-07-14 06:55:31,182 [INFO    ] __main__: train step 16695: loss: 1.0262, policy_loss: 0.9737, value_loss: 0.5202
2024-07-14 06:55:31,472 [INFO    ] __main__: train step 16696: loss: 1.0262, policy_loss: 0.9737, value_loss: 0.5202
2024-07-14 06:55:31,771 [INFO    ] __main__: train step 16697: loss: 1.0262, policy_loss: 0.9737, value_loss: 0.5202
2024-07-14 06:55:32,065 [INFO    ] __main__: train step 16698: loss: 1.0262, policy_loss: 0.9737, value_loss: 0.5202
2024-07-14 06:55:32,373 [INFO    ] __main__: train step 16699: loss: 1.0261, policy_loss: 0.9737, value_loss: 0.5201
2024-07-14 06:55:32,671 [INFO    ] __main__: train step 16700: loss: 1.0261, policy_loss: 0.9736, value_loss: 0.5201
2024-07-14 06:55:32,961 [INFO    ] __main__: train step 16701: loss: 1.0261, policy_loss: 0.9736, value_loss: 0.5201
2024-07-14 06:55:33,250 [INFO    ] __main__: train step 16702: loss: 1.0261, policy_loss: 0.9736, value_loss: 0.5201
2024-07-14 06:55:33,548 [INFO    ] __main__: train step 16703: loss: 1.0261, policy_loss: 0.9736, value_loss: 0.5200
2024-07-14 06:55:33,857 [INFO    ] __main__: train step 16704: loss: 1.0261, policy_loss: 0.9736, value_loss: 0.5200
2024-07-14 06:55:34,160 [INFO    ] __main__: train step 16705: loss: 1.0260, policy_loss: 0.9735, value_loss: 0.5200
2024-07-14 06:55:34,461 [INFO    ] __main__: train step 16706: loss: 1.0260, policy_loss: 0.9735, value_loss: 0.5200
2024-07-14 06:55:34,763 [INFO    ] __main__: train step 16707: loss: 1.0260, policy_loss: 0.9735, value_loss: 0.5199
2024-07-14 06:55:36,395 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:55:36,881 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:55:36,953 [INFO    ] __main__: train step 16708: loss: 1.0260, policy_loss: 0.9735, value_loss: 0.5199
2024-07-14 06:55:37,246 [INFO    ] __main__: train step 16709: loss: 1.0260, policy_loss: 0.9735, value_loss: 0.5199
2024-07-14 06:55:37,544 [INFO    ] __main__: train step 16710: loss: 1.0260, policy_loss: 0.9734, value_loss: 0.5198
2024-07-14 06:55:37,825 [INFO    ] __main__: train step 16711: loss: 1.0259, policy_loss: 0.9734, value_loss: 0.5198
2024-07-14 06:55:38,120 [INFO    ] __main__: train step 16712: loss: 1.0259, policy_loss: 0.9734, value_loss: 0.5198
2024-07-14 06:55:38,432 [INFO    ] __main__: train step 16713: loss: 1.0259, policy_loss: 0.9734, value_loss: 0.5198
2024-07-14 06:55:38,737 [INFO    ] __main__: train step 16714: loss: 1.0259, policy_loss: 0.9734, value_loss: 0.5197
2024-07-14 06:55:39,035 [INFO    ] __main__: train step 16715: loss: 1.0259, policy_loss: 0.9733, value_loss: 0.5197
2024-07-14 06:55:39,312 [INFO    ] __main__: train step 16716: loss: 1.0259, policy_loss: 0.9733, value_loss: 0.5197
2024-07-14 06:55:39,610 [INFO    ] __main__: train step 16717: loss: 1.0258, policy_loss: 0.9733, value_loss: 0.5197
2024-07-14 06:55:39,906 [INFO    ] __main__: train step 16718: loss: 1.0258, policy_loss: 0.9733, value_loss: 0.5196
2024-07-14 06:55:40,193 [INFO    ] __main__: train step 16719: loss: 1.0258, policy_loss: 0.9733, value_loss: 0.5196
2024-07-14 06:55:40,488 [INFO    ] __main__: train step 16720: loss: 1.0258, policy_loss: 0.9732, value_loss: 0.5196
2024-07-14 06:55:40,785 [INFO    ] __main__: train step 16721: loss: 1.0258, policy_loss: 0.9732, value_loss: 0.5196
2024-07-14 06:55:41,069 [INFO    ] __main__: train step 16722: loss: 1.0258, policy_loss: 0.9732, value_loss: 0.5195
2024-07-14 06:55:41,365 [INFO    ] __main__: train step 16723: loss: 1.0257, policy_loss: 0.9732, value_loss: 0.5195
2024-07-14 06:55:41,677 [INFO    ] __main__: train step 16724: loss: 1.0257, policy_loss: 0.9732, value_loss: 0.5195
2024-07-14 06:55:43,301 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:55:43,813 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:55:43,882 [INFO    ] __main__: train step 16725: loss: 1.0257, policy_loss: 0.9731, value_loss: 0.5195
2024-07-14 06:55:44,172 [INFO    ] __main__: train step 16726: loss: 1.0257, policy_loss: 0.9731, value_loss: 0.5194
2024-07-14 06:55:44,458 [INFO    ] __main__: train step 16727: loss: 1.0257, policy_loss: 0.9731, value_loss: 0.5194
2024-07-14 06:55:44,739 [INFO    ] __main__: train step 16728: loss: 1.0257, policy_loss: 0.9731, value_loss: 0.5194
2024-07-14 06:55:45,007 [INFO    ] __main__: train step 16729: loss: 1.0256, policy_loss: 0.9731, value_loss: 0.5194
2024-07-14 06:55:45,303 [INFO    ] __main__: train step 16730: loss: 1.0256, policy_loss: 0.9731, value_loss: 0.5193
2024-07-14 06:55:45,604 [INFO    ] __main__: train step 16731: loss: 1.0256, policy_loss: 0.9730, value_loss: 0.5193
2024-07-14 06:55:45,908 [INFO    ] __main__: train step 16732: loss: 1.0256, policy_loss: 0.9730, value_loss: 0.5193
2024-07-14 06:55:46,185 [INFO    ] __main__: train step 16733: loss: 1.0256, policy_loss: 0.9730, value_loss: 0.5193
2024-07-14 06:55:46,466 [INFO    ] __main__: train step 16734: loss: 1.0256, policy_loss: 0.9730, value_loss: 0.5192
2024-07-14 06:55:46,748 [INFO    ] __main__: train step 16735: loss: 1.0255, policy_loss: 0.9730, value_loss: 0.5192
2024-07-14 06:55:47,037 [INFO    ] __main__: train step 16736: loss: 1.0255, policy_loss: 0.9729, value_loss: 0.5192
2024-07-14 06:55:47,332 [INFO    ] __main__: train step 16737: loss: 1.0255, policy_loss: 0.9729, value_loss: 0.5192
2024-07-14 06:55:47,637 [INFO    ] __main__: train step 16738: loss: 1.0255, policy_loss: 0.9729, value_loss: 0.5191
2024-07-14 06:55:47,952 [INFO    ] __main__: train step 16739: loss: 1.0255, policy_loss: 0.9729, value_loss: 0.5191
2024-07-14 06:55:48,259 [INFO    ] __main__: train step 16740: loss: 1.0254, policy_loss: 0.9729, value_loss: 0.5191
2024-07-14 06:55:48,555 [INFO    ] __main__: train step 16741: loss: 1.0254, policy_loss: 0.9728, value_loss: 0.5191
2024-07-14 06:55:50,165 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:55:50,659 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:55:50,730 [INFO    ] __main__: train step 16742: loss: 1.0254, policy_loss: 0.9728, value_loss: 0.5190
2024-07-14 06:55:50,999 [INFO    ] __main__: train step 16743: loss: 1.0254, policy_loss: 0.9728, value_loss: 0.5190
2024-07-14 06:55:51,272 [INFO    ] __main__: train step 16744: loss: 1.0254, policy_loss: 0.9728, value_loss: 0.5190
2024-07-14 06:55:51,577 [INFO    ] __main__: train step 16745: loss: 1.0254, policy_loss: 0.9728, value_loss: 0.5190
2024-07-14 06:55:51,864 [INFO    ] __main__: train step 16746: loss: 1.0253, policy_loss: 0.9727, value_loss: 0.5189
2024-07-14 06:55:52,160 [INFO    ] __main__: train step 16747: loss: 1.0253, policy_loss: 0.9727, value_loss: 0.5189
2024-07-14 06:55:52,454 [INFO    ] __main__: train step 16748: loss: 1.0253, policy_loss: 0.9727, value_loss: 0.5189
2024-07-14 06:55:52,751 [INFO    ] __main__: train step 16749: loss: 1.0253, policy_loss: 0.9727, value_loss: 0.5189
2024-07-14 06:55:53,051 [INFO    ] __main__: train step 16750: loss: 1.0253, policy_loss: 0.9727, value_loss: 0.5188
2024-07-14 06:55:53,349 [INFO    ] __main__: train step 16751: loss: 1.0253, policy_loss: 0.9726, value_loss: 0.5188
2024-07-14 06:55:53,640 [INFO    ] __main__: train step 16752: loss: 1.0252, policy_loss: 0.9726, value_loss: 0.5188
2024-07-14 06:55:53,935 [INFO    ] __main__: train step 16753: loss: 1.0252, policy_loss: 0.9726, value_loss: 0.5187
2024-07-14 06:55:54,229 [INFO    ] __main__: train step 16754: loss: 1.0252, policy_loss: 0.9726, value_loss: 0.5187
2024-07-14 06:55:54,525 [INFO    ] __main__: train step 16755: loss: 1.0252, policy_loss: 0.9726, value_loss: 0.5187
2024-07-14 06:55:54,826 [INFO    ] __main__: train step 16756: loss: 1.0252, policy_loss: 0.9725, value_loss: 0.5187
2024-07-14 06:55:55,129 [INFO    ] __main__: train step 16757: loss: 1.0252, policy_loss: 0.9725, value_loss: 0.5186
2024-07-14 06:55:55,434 [INFO    ] __main__: train step 16758: loss: 1.0251, policy_loss: 0.9725, value_loss: 0.5186
2024-07-14 06:55:57,060 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:55:57,551 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:55:57,628 [INFO    ] __main__: train step 16759: loss: 1.0251, policy_loss: 0.9725, value_loss: 0.5186
2024-07-14 06:55:57,917 [INFO    ] __main__: train step 16760: loss: 1.0251, policy_loss: 0.9725, value_loss: 0.5186
2024-07-14 06:55:58,223 [INFO    ] __main__: train step 16761: loss: 1.0251, policy_loss: 0.9724, value_loss: 0.5185
2024-07-14 06:55:58,515 [INFO    ] __main__: train step 16762: loss: 1.0251, policy_loss: 0.9724, value_loss: 0.5185
2024-07-14 06:55:58,795 [INFO    ] __main__: train step 16763: loss: 1.0251, policy_loss: 0.9724, value_loss: 0.5185
2024-07-14 06:55:59,092 [INFO    ] __main__: train step 16764: loss: 1.0250, policy_loss: 0.9724, value_loss: 0.5185
2024-07-14 06:55:59,388 [INFO    ] __main__: train step 16765: loss: 1.0250, policy_loss: 0.9724, value_loss: 0.5184
2024-07-14 06:55:59,669 [INFO    ] __main__: train step 16766: loss: 1.0250, policy_loss: 0.9723, value_loss: 0.5184
2024-07-14 06:55:59,965 [INFO    ] __main__: train step 16767: loss: 1.0250, policy_loss: 0.9723, value_loss: 0.5184
2024-07-14 06:56:00,254 [INFO    ] __main__: train step 16768: loss: 1.0250, policy_loss: 0.9723, value_loss: 0.5184
2024-07-14 06:56:00,550 [INFO    ] __main__: train step 16769: loss: 1.0250, policy_loss: 0.9723, value_loss: 0.5183
2024-07-14 06:56:00,844 [INFO    ] __main__: train step 16770: loss: 1.0249, policy_loss: 0.9723, value_loss: 0.5183
2024-07-14 06:56:01,140 [INFO    ] __main__: train step 16771: loss: 1.0249, policy_loss: 0.9723, value_loss: 0.5183
2024-07-14 06:56:01,423 [INFO    ] __main__: train step 16772: loss: 1.0249, policy_loss: 0.9722, value_loss: 0.5183
2024-07-14 06:56:01,716 [INFO    ] __main__: train step 16773: loss: 1.0249, policy_loss: 0.9722, value_loss: 0.5182
2024-07-14 06:56:02,005 [INFO    ] __main__: train step 16774: loss: 1.0249, policy_loss: 0.9722, value_loss: 0.5182
2024-07-14 06:56:02,304 [INFO    ] __main__: train step 16775: loss: 1.0249, policy_loss: 0.9722, value_loss: 0.5182
2024-07-14 06:56:03,930 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:56:04,408 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:56:04,481 [INFO    ] __main__: train step 16776: loss: 1.0248, policy_loss: 0.9722, value_loss: 0.5182
2024-07-14 06:56:04,807 [INFO    ] __main__: train step 16777: loss: 1.0248, policy_loss: 0.9721, value_loss: 0.5181
2024-07-14 06:56:05,099 [INFO    ] __main__: train step 16778: loss: 1.0248, policy_loss: 0.9721, value_loss: 0.5181
2024-07-14 06:56:08,766 [INFO    ] __main__: train step 16779: loss: 1.0248, policy_loss: 0.9721, value_loss: 0.5181
2024-07-14 06:56:09,055 [INFO    ] __main__: train step 16780: loss: 1.0248, policy_loss: 0.9721, value_loss: 0.5181
2024-07-14 06:56:09,353 [INFO    ] __main__: train step 16781: loss: 1.0247, policy_loss: 0.9721, value_loss: 0.5180
2024-07-14 06:56:09,655 [INFO    ] __main__: train step 16782: loss: 1.0247, policy_loss: 0.9720, value_loss: 0.5180
2024-07-14 06:56:09,957 [INFO    ] __main__: train step 16783: loss: 1.0247, policy_loss: 0.9720, value_loss: 0.5180
2024-07-14 06:56:10,255 [INFO    ] __main__: train step 16784: loss: 1.0247, policy_loss: 0.9720, value_loss: 0.5180
2024-07-14 06:56:10,550 [INFO    ] __main__: train step 16785: loss: 1.0247, policy_loss: 0.9720, value_loss: 0.5179
2024-07-14 06:56:10,845 [INFO    ] __main__: train step 16786: loss: 1.0247, policy_loss: 0.9720, value_loss: 0.5179
2024-07-14 06:56:11,151 [INFO    ] __main__: train step 16787: loss: 1.0246, policy_loss: 0.9719, value_loss: 0.5179
2024-07-14 06:56:11,445 [INFO    ] __main__: train step 16788: loss: 1.0246, policy_loss: 0.9719, value_loss: 0.5179
2024-07-14 06:56:11,746 [INFO    ] __main__: train step 16789: loss: 1.0246, policy_loss: 0.9719, value_loss: 0.5178
2024-07-14 06:56:12,059 [INFO    ] __main__: train step 16790: loss: 1.0246, policy_loss: 0.9719, value_loss: 0.5178
2024-07-14 06:56:12,357 [INFO    ] __main__: train step 16791: loss: 1.0246, policy_loss: 0.9719, value_loss: 0.5178
2024-07-14 06:56:12,656 [INFO    ] __main__: train step 16792: loss: 1.0246, policy_loss: 0.9718, value_loss: 0.5178
2024-07-14 06:56:14,294 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:56:14,786 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:56:14,860 [INFO    ] __main__: train step 16793: loss: 1.0245, policy_loss: 0.9718, value_loss: 0.5177
2024-07-14 06:56:15,166 [INFO    ] __main__: train step 16794: loss: 1.0245, policy_loss: 0.9718, value_loss: 0.5177
2024-07-14 06:56:15,460 [INFO    ] __main__: train step 16795: loss: 1.0245, policy_loss: 0.9718, value_loss: 0.5177
2024-07-14 06:56:15,750 [INFO    ] __main__: train step 16796: loss: 1.0245, policy_loss: 0.9718, value_loss: 0.5177
2024-07-14 06:56:16,055 [INFO    ] __main__: train step 16797: loss: 1.0245, policy_loss: 0.9717, value_loss: 0.5176
2024-07-14 06:56:16,356 [INFO    ] __main__: train step 16798: loss: 1.0245, policy_loss: 0.9717, value_loss: 0.5176
2024-07-14 06:56:16,662 [INFO    ] __main__: train step 16799: loss: 1.0244, policy_loss: 0.9717, value_loss: 0.5176
2024-07-14 06:56:16,976 [INFO    ] __main__: train step 16800: loss: 1.0244, policy_loss: 0.9717, value_loss: 0.5176
2024-07-14 06:56:17,265 [INFO    ] __main__: train step 16801: loss: 1.0244, policy_loss: 0.9717, value_loss: 0.5175
2024-07-14 06:56:17,542 [INFO    ] __main__: train step 16802: loss: 1.0244, policy_loss: 0.9717, value_loss: 0.5175
2024-07-14 06:56:17,829 [INFO    ] __main__: train step 16803: loss: 1.0244, policy_loss: 0.9716, value_loss: 0.5175
2024-07-14 06:56:18,120 [INFO    ] __main__: train step 16804: loss: 1.0244, policy_loss: 0.9716, value_loss: 0.5175
2024-07-14 06:56:18,426 [INFO    ] __main__: train step 16805: loss: 1.0243, policy_loss: 0.9716, value_loss: 0.5174
2024-07-14 06:56:18,726 [INFO    ] __main__: train step 16806: loss: 1.0243, policy_loss: 0.9716, value_loss: 0.5174
2024-07-14 06:56:19,018 [INFO    ] __main__: train step 16807: loss: 1.0243, policy_loss: 0.9716, value_loss: 0.5174
2024-07-14 06:56:19,310 [INFO    ] __main__: train step 16808: loss: 1.0243, policy_loss: 0.9715, value_loss: 0.5174
2024-07-14 06:56:19,595 [INFO    ] __main__: train step 16809: loss: 1.0243, policy_loss: 0.9715, value_loss: 0.5173
2024-07-14 06:56:21,233 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:56:21,725 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:56:21,793 [INFO    ] __main__: train step 16810: loss: 1.0243, policy_loss: 0.9715, value_loss: 0.5173
2024-07-14 06:56:22,095 [INFO    ] __main__: train step 16811: loss: 1.0242, policy_loss: 0.9715, value_loss: 0.5173
2024-07-14 06:56:22,382 [INFO    ] __main__: train step 16812: loss: 1.0242, policy_loss: 0.9715, value_loss: 0.5173
2024-07-14 06:56:22,669 [INFO    ] __main__: train step 16813: loss: 1.0242, policy_loss: 0.9714, value_loss: 0.5172
2024-07-14 06:56:22,958 [INFO    ] __main__: train step 16814: loss: 1.0242, policy_loss: 0.9714, value_loss: 0.5172
2024-07-14 06:56:23,249 [INFO    ] __main__: train step 16815: loss: 1.0242, policy_loss: 0.9714, value_loss: 0.5172
2024-07-14 06:56:23,543 [INFO    ] __main__: train step 16816: loss: 1.0242, policy_loss: 0.9714, value_loss: 0.5172
2024-07-14 06:56:23,832 [INFO    ] __main__: train step 16817: loss: 1.0241, policy_loss: 0.9714, value_loss: 0.5171
2024-07-14 06:56:24,117 [INFO    ] __main__: train step 16818: loss: 1.0241, policy_loss: 0.9713, value_loss: 0.5171
2024-07-14 06:56:24,413 [INFO    ] __main__: train step 16819: loss: 1.0241, policy_loss: 0.9713, value_loss: 0.5171
2024-07-14 06:56:24,722 [INFO    ] __main__: train step 16820: loss: 1.0241, policy_loss: 0.9713, value_loss: 0.5171
2024-07-14 06:56:25,027 [INFO    ] __main__: train step 16821: loss: 1.0241, policy_loss: 0.9713, value_loss: 0.5170
2024-07-14 06:56:25,322 [INFO    ] __main__: train step 16822: loss: 1.0241, policy_loss: 0.9713, value_loss: 0.5170
2024-07-14 06:56:25,619 [INFO    ] __main__: train step 16823: loss: 1.0240, policy_loss: 0.9713, value_loss: 0.5170
2024-07-14 06:56:25,910 [INFO    ] __main__: train step 16824: loss: 1.0240, policy_loss: 0.9712, value_loss: 0.5170
2024-07-14 06:56:26,196 [INFO    ] __main__: train step 16825: loss: 1.0240, policy_loss: 0.9712, value_loss: 0.5169
2024-07-14 06:56:26,497 [INFO    ] __main__: train step 16826: loss: 1.0240, policy_loss: 0.9712, value_loss: 0.5169
2024-07-14 06:56:28,129 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:56:28,626 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:56:28,696 [INFO    ] __main__: train step 16827: loss: 1.0240, policy_loss: 0.9712, value_loss: 0.5169
2024-07-14 06:56:28,994 [INFO    ] __main__: train step 16828: loss: 1.0240, policy_loss: 0.9712, value_loss: 0.5168
2024-07-14 06:56:29,285 [INFO    ] __main__: train step 16829: loss: 1.0239, policy_loss: 0.9711, value_loss: 0.5168
2024-07-14 06:56:29,577 [INFO    ] __main__: train step 16830: loss: 1.0239, policy_loss: 0.9711, value_loss: 0.5168
2024-07-14 06:56:29,863 [INFO    ] __main__: train step 16831: loss: 1.0239, policy_loss: 0.9711, value_loss: 0.5168
2024-07-14 06:56:30,170 [INFO    ] __main__: train step 16832: loss: 1.0239, policy_loss: 0.9711, value_loss: 0.5167
2024-07-14 06:56:30,471 [INFO    ] __main__: train step 16833: loss: 1.0239, policy_loss: 0.9711, value_loss: 0.5167
2024-07-14 06:56:30,771 [INFO    ] __main__: train step 16834: loss: 1.0239, policy_loss: 0.9710, value_loss: 0.5167
2024-07-14 06:56:31,070 [INFO    ] __main__: train step 16835: loss: 1.0238, policy_loss: 0.9710, value_loss: 0.5167
2024-07-14 06:56:31,347 [INFO    ] __main__: train step 16836: loss: 1.0238, policy_loss: 0.9710, value_loss: 0.5166
2024-07-14 06:56:31,637 [INFO    ] __main__: train step 16837: loss: 1.0238, policy_loss: 0.9710, value_loss: 0.5166
2024-07-14 06:56:31,931 [INFO    ] __main__: train step 16838: loss: 1.0238, policy_loss: 0.9710, value_loss: 0.5166
2024-07-14 06:56:32,223 [INFO    ] __main__: train step 16839: loss: 1.0238, policy_loss: 0.9709, value_loss: 0.5166
2024-07-14 06:56:32,525 [INFO    ] __main__: train step 16840: loss: 1.0238, policy_loss: 0.9709, value_loss: 0.5165
2024-07-14 06:56:32,833 [INFO    ] __main__: train step 16841: loss: 1.0237, policy_loss: 0.9709, value_loss: 0.5165
2024-07-14 06:56:33,140 [INFO    ] __main__: train step 16842: loss: 1.0237, policy_loss: 0.9709, value_loss: 0.5165
2024-07-14 06:56:33,428 [INFO    ] __main__: train step 16843: loss: 1.0237, policy_loss: 0.9709, value_loss: 0.5165
2024-07-14 06:56:35,027 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:56:35,501 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:56:35,571 [INFO    ] __main__: train step 16844: loss: 1.0237, policy_loss: 0.9708, value_loss: 0.5164
2024-07-14 06:56:35,874 [INFO    ] __main__: train step 16845: loss: 1.0237, policy_loss: 0.9708, value_loss: 0.5164
2024-07-14 06:56:36,171 [INFO    ] __main__: train step 16846: loss: 1.0237, policy_loss: 0.9708, value_loss: 0.5164
2024-07-14 06:56:36,462 [INFO    ] __main__: train step 16847: loss: 1.0236, policy_loss: 0.9708, value_loss: 0.5164
2024-07-14 06:56:36,740 [INFO    ] __main__: train step 16848: loss: 1.0236, policy_loss: 0.9708, value_loss: 0.5163
2024-07-14 06:56:37,025 [INFO    ] __main__: train step 16849: loss: 1.0236, policy_loss: 0.9708, value_loss: 0.5163
2024-07-14 06:56:37,310 [INFO    ] __main__: train step 16850: loss: 1.0236, policy_loss: 0.9707, value_loss: 0.5163
2024-07-14 06:56:37,603 [INFO    ] __main__: train step 16851: loss: 1.0236, policy_loss: 0.9707, value_loss: 0.5163
2024-07-14 06:56:37,905 [INFO    ] __main__: train step 16852: loss: 1.0236, policy_loss: 0.9707, value_loss: 0.5162
2024-07-14 06:56:38,197 [INFO    ] __main__: train step 16853: loss: 1.0235, policy_loss: 0.9707, value_loss: 0.5162
2024-07-14 06:56:38,497 [INFO    ] __main__: train step 16854: loss: 1.0235, policy_loss: 0.9707, value_loss: 0.5162
2024-07-14 06:56:38,789 [INFO    ] __main__: train step 16855: loss: 1.0235, policy_loss: 0.9706, value_loss: 0.5162
2024-07-14 06:56:39,079 [INFO    ] __main__: train step 16856: loss: 1.0235, policy_loss: 0.9706, value_loss: 0.5161
2024-07-14 06:56:39,368 [INFO    ] __main__: train step 16857: loss: 1.0235, policy_loss: 0.9706, value_loss: 0.5161
2024-07-14 06:56:39,675 [INFO    ] __main__: train step 16858: loss: 1.0235, policy_loss: 0.9706, value_loss: 0.5161
2024-07-14 06:56:39,968 [INFO    ] __main__: train step 16859: loss: 1.0234, policy_loss: 0.9706, value_loss: 0.5161
2024-07-14 06:56:40,271 [INFO    ] __main__: train step 16860: loss: 1.0234, policy_loss: 0.9705, value_loss: 0.5160
2024-07-14 06:56:41,892 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:56:42,396 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:56:42,465 [INFO    ] __main__: train step 16861: loss: 1.0234, policy_loss: 0.9705, value_loss: 0.5160
2024-07-14 06:56:42,763 [INFO    ] __main__: train step 16862: loss: 1.0234, policy_loss: 0.9705, value_loss: 0.5160
2024-07-14 06:56:43,054 [INFO    ] __main__: train step 16863: loss: 1.0234, policy_loss: 0.9705, value_loss: 0.5160
2024-07-14 06:56:43,351 [INFO    ] __main__: train step 16864: loss: 1.0234, policy_loss: 0.9705, value_loss: 0.5159
2024-07-14 06:56:43,647 [INFO    ] __main__: train step 16865: loss: 1.0233, policy_loss: 0.9704, value_loss: 0.5159
2024-07-14 06:56:43,944 [INFO    ] __main__: train step 16866: loss: 1.0233, policy_loss: 0.9704, value_loss: 0.5159
2024-07-14 06:56:44,237 [INFO    ] __main__: train step 16867: loss: 1.0233, policy_loss: 0.9704, value_loss: 0.5159
2024-07-14 06:56:44,541 [INFO    ] __main__: train step 16868: loss: 1.0233, policy_loss: 0.9704, value_loss: 0.5158
2024-07-14 06:56:44,838 [INFO    ] __main__: train step 16869: loss: 1.0233, policy_loss: 0.9704, value_loss: 0.5158
2024-07-14 06:56:45,130 [INFO    ] __main__: train step 16870: loss: 1.0233, policy_loss: 0.9704, value_loss: 0.5158
2024-07-14 06:56:45,423 [INFO    ] __main__: train step 16871: loss: 1.0232, policy_loss: 0.9703, value_loss: 0.5158
2024-07-14 06:56:45,702 [INFO    ] __main__: train step 16872: loss: 1.0232, policy_loss: 0.9703, value_loss: 0.5157
2024-07-14 06:56:45,993 [INFO    ] __main__: train step 16873: loss: 1.0232, policy_loss: 0.9703, value_loss: 0.5157
2024-07-14 06:56:46,291 [INFO    ] __main__: train step 16874: loss: 1.0232, policy_loss: 0.9703, value_loss: 0.5157
2024-07-14 06:56:46,592 [INFO    ] __main__: train step 16875: loss: 1.0232, policy_loss: 0.9703, value_loss: 0.5157
2024-07-14 06:56:46,883 [INFO    ] __main__: train step 16876: loss: 1.0231, policy_loss: 0.9702, value_loss: 0.5156
2024-07-14 06:56:47,165 [INFO    ] __main__: train step 16877: loss: 1.0231, policy_loss: 0.9702, value_loss: 0.5156
2024-07-14 06:56:48,761 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:56:49,236 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:56:49,305 [INFO    ] __main__: train step 16878: loss: 1.0231, policy_loss: 0.9702, value_loss: 0.5156
2024-07-14 06:56:49,596 [INFO    ] __main__: train step 16879: loss: 1.0231, policy_loss: 0.9702, value_loss: 0.5156
2024-07-14 06:56:49,887 [INFO    ] __main__: train step 16880: loss: 1.0231, policy_loss: 0.9702, value_loss: 0.5155
2024-07-14 06:56:53,544 [INFO    ] __main__: train step 16881: loss: 1.0231, policy_loss: 0.9701, value_loss: 0.5155
2024-07-14 06:56:53,834 [INFO    ] __main__: train step 16882: loss: 1.0231, policy_loss: 0.9701, value_loss: 0.5155
2024-07-14 06:56:54,142 [INFO    ] __main__: train step 16883: loss: 1.0230, policy_loss: 0.9701, value_loss: 0.5155
2024-07-14 06:56:54,438 [INFO    ] __main__: train step 16884: loss: 1.0230, policy_loss: 0.9701, value_loss: 0.5154
2024-07-14 06:56:54,743 [INFO    ] __main__: train step 16885: loss: 1.0230, policy_loss: 0.9701, value_loss: 0.5154
2024-07-14 06:56:55,048 [INFO    ] __main__: train step 16886: loss: 1.0230, policy_loss: 0.9700, value_loss: 0.5154
2024-07-14 06:56:55,354 [INFO    ] __main__: train step 16887: loss: 1.0230, policy_loss: 0.9700, value_loss: 0.5154
2024-07-14 06:56:55,645 [INFO    ] __main__: train step 16888: loss: 1.0230, policy_loss: 0.9700, value_loss: 0.5153
2024-07-14 06:56:55,922 [INFO    ] __main__: train step 16889: loss: 1.0229, policy_loss: 0.9700, value_loss: 0.5153
2024-07-14 06:56:56,210 [INFO    ] __main__: train step 16890: loss: 1.0229, policy_loss: 0.9700, value_loss: 0.5153
2024-07-14 06:56:56,508 [INFO    ] __main__: train step 16891: loss: 1.0229, policy_loss: 0.9700, value_loss: 0.5153
2024-07-14 06:56:56,808 [INFO    ] __main__: train step 16892: loss: 1.0229, policy_loss: 0.9699, value_loss: 0.5152
2024-07-14 06:56:57,114 [INFO    ] __main__: train step 16893: loss: 1.0229, policy_loss: 0.9699, value_loss: 0.5152
2024-07-14 06:56:57,414 [INFO    ] __main__: train step 16894: loss: 1.0229, policy_loss: 0.9699, value_loss: 0.5152
2024-07-14 06:56:59,051 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:56:59,546 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:56:59,618 [INFO    ] __main__: train step 16895: loss: 1.0228, policy_loss: 0.9699, value_loss: 0.5152
2024-07-14 06:56:59,919 [INFO    ] __main__: train step 16896: loss: 1.0228, policy_loss: 0.9699, value_loss: 0.5151
2024-07-14 06:57:00,215 [INFO    ] __main__: train step 16897: loss: 1.0228, policy_loss: 0.9698, value_loss: 0.5151
2024-07-14 06:57:00,511 [INFO    ] __main__: train step 16898: loss: 1.0228, policy_loss: 0.9698, value_loss: 0.5151
2024-07-14 06:57:00,805 [INFO    ] __main__: train step 16899: loss: 1.0228, policy_loss: 0.9698, value_loss: 0.5151
2024-07-14 06:57:01,102 [INFO    ] __main__: train step 16900: loss: 1.0228, policy_loss: 0.9698, value_loss: 0.5150
2024-07-14 06:57:01,402 [INFO    ] __main__: train step 16901: loss: 1.0227, policy_loss: 0.9698, value_loss: 0.5150
2024-07-14 06:57:01,702 [INFO    ] __main__: train step 16902: loss: 1.0227, policy_loss: 0.9697, value_loss: 0.5150
2024-07-14 06:57:02,006 [INFO    ] __main__: train step 16903: loss: 1.0227, policy_loss: 0.9697, value_loss: 0.5150
2024-07-14 06:57:02,305 [INFO    ] __main__: train step 16904: loss: 1.0227, policy_loss: 0.9697, value_loss: 0.5149
2024-07-14 06:57:02,609 [INFO    ] __main__: train step 16905: loss: 1.0227, policy_loss: 0.9697, value_loss: 0.5149
2024-07-14 06:57:02,914 [INFO    ] __main__: train step 16906: loss: 1.0227, policy_loss: 0.9697, value_loss: 0.5149
2024-07-14 06:57:03,206 [INFO    ] __main__: train step 16907: loss: 1.0226, policy_loss: 0.9697, value_loss: 0.5149
2024-07-14 06:57:03,496 [INFO    ] __main__: train step 16908: loss: 1.0226, policy_loss: 0.9696, value_loss: 0.5148
2024-07-14 06:57:03,792 [INFO    ] __main__: train step 16909: loss: 1.0226, policy_loss: 0.9696, value_loss: 0.5148
2024-07-14 06:57:04,080 [INFO    ] __main__: train step 16910: loss: 1.0226, policy_loss: 0.9696, value_loss: 0.5148
2024-07-14 06:57:04,368 [INFO    ] __main__: train step 16911: loss: 1.0226, policy_loss: 0.9696, value_loss: 0.5148
2024-07-14 06:57:05,997 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:57:06,482 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:57:06,558 [INFO    ] __main__: train step 16912: loss: 1.0226, policy_loss: 0.9696, value_loss: 0.5147
2024-07-14 06:57:06,860 [INFO    ] __main__: train step 16913: loss: 1.0225, policy_loss: 0.9695, value_loss: 0.5147
2024-07-14 06:57:07,152 [INFO    ] __main__: train step 16914: loss: 1.0225, policy_loss: 0.9695, value_loss: 0.5147
2024-07-14 06:57:07,457 [INFO    ] __main__: train step 16915: loss: 1.0225, policy_loss: 0.9695, value_loss: 0.5147
2024-07-14 06:57:07,775 [INFO    ] __main__: train step 16916: loss: 1.0225, policy_loss: 0.9695, value_loss: 0.5146
2024-07-14 06:57:08,062 [INFO    ] __main__: train step 16917: loss: 1.0225, policy_loss: 0.9695, value_loss: 0.5146
2024-07-14 06:57:08,355 [INFO    ] __main__: train step 16918: loss: 1.0225, policy_loss: 0.9694, value_loss: 0.5146
2024-07-14 06:57:08,658 [INFO    ] __main__: train step 16919: loss: 1.0224, policy_loss: 0.9694, value_loss: 0.5146
2024-07-14 06:57:08,955 [INFO    ] __main__: train step 16920: loss: 1.0224, policy_loss: 0.9694, value_loss: 0.5145
2024-07-14 06:57:09,265 [INFO    ] __main__: train step 16921: loss: 1.0224, policy_loss: 0.9694, value_loss: 0.5145
2024-07-14 06:57:09,561 [INFO    ] __main__: train step 16922: loss: 1.0224, policy_loss: 0.9694, value_loss: 0.5145
2024-07-14 06:57:09,862 [INFO    ] __main__: train step 16923: loss: 1.0224, policy_loss: 0.9694, value_loss: 0.5145
2024-07-14 06:57:10,159 [INFO    ] __main__: train step 16924: loss: 1.0224, policy_loss: 0.9693, value_loss: 0.5144
2024-07-14 06:57:10,465 [INFO    ] __main__: train step 16925: loss: 1.0223, policy_loss: 0.9693, value_loss: 0.5144
2024-07-14 06:57:10,768 [INFO    ] __main__: train step 16926: loss: 1.0223, policy_loss: 0.9693, value_loss: 0.5144
2024-07-14 06:57:11,060 [INFO    ] __main__: train step 16927: loss: 1.0223, policy_loss: 0.9693, value_loss: 0.5144
2024-07-14 06:57:11,360 [INFO    ] __main__: train step 16928: loss: 1.0223, policy_loss: 0.9693, value_loss: 0.5143
2024-07-14 06:57:12,977 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:57:13,469 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:57:13,539 [INFO    ] __main__: train step 16929: loss: 1.0223, policy_loss: 0.9692, value_loss: 0.5143
2024-07-14 06:57:13,849 [INFO    ] __main__: train step 16930: loss: 1.0223, policy_loss: 0.9692, value_loss: 0.5143
2024-07-14 06:57:14,154 [INFO    ] __main__: train step 16931: loss: 1.0223, policy_loss: 0.9692, value_loss: 0.5143
2024-07-14 06:57:14,453 [INFO    ] __main__: train step 16932: loss: 1.0222, policy_loss: 0.9692, value_loss: 0.5142
2024-07-14 06:57:14,754 [INFO    ] __main__: train step 16933: loss: 1.0222, policy_loss: 0.9692, value_loss: 0.5142
2024-07-14 06:57:15,058 [INFO    ] __main__: train step 16934: loss: 1.0222, policy_loss: 0.9692, value_loss: 0.5142
2024-07-14 06:57:15,361 [INFO    ] __main__: train step 16935: loss: 1.0222, policy_loss: 0.9691, value_loss: 0.5142
2024-07-14 06:57:15,660 [INFO    ] __main__: train step 16936: loss: 1.0222, policy_loss: 0.9691, value_loss: 0.5141
2024-07-14 06:57:15,963 [INFO    ] __main__: train step 16937: loss: 1.0222, policy_loss: 0.9691, value_loss: 0.5141
2024-07-14 06:57:16,268 [INFO    ] __main__: train step 16938: loss: 1.0221, policy_loss: 0.9691, value_loss: 0.5141
2024-07-14 06:57:16,569 [INFO    ] __main__: train step 16939: loss: 1.0221, policy_loss: 0.9691, value_loss: 0.5141
2024-07-14 06:57:16,857 [INFO    ] __main__: train step 16940: loss: 1.0221, policy_loss: 0.9690, value_loss: 0.5140
2024-07-14 06:57:17,154 [INFO    ] __main__: train step 16941: loss: 1.0221, policy_loss: 0.9690, value_loss: 0.5140
2024-07-14 06:57:17,466 [INFO    ] __main__: train step 16942: loss: 1.0221, policy_loss: 0.9690, value_loss: 0.5140
2024-07-14 06:57:17,757 [INFO    ] __main__: train step 16943: loss: 1.0221, policy_loss: 0.9690, value_loss: 0.5140
2024-07-14 06:57:18,049 [INFO    ] __main__: train step 16944: loss: 1.0220, policy_loss: 0.9690, value_loss: 0.5139
2024-07-14 06:57:18,330 [INFO    ] __main__: train step 16945: loss: 1.0220, policy_loss: 0.9689, value_loss: 0.5139
2024-07-14 06:57:19,951 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:57:20,427 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:57:20,497 [INFO    ] __main__: train step 16946: loss: 1.0220, policy_loss: 0.9689, value_loss: 0.5139
2024-07-14 06:57:20,796 [INFO    ] __main__: train step 16947: loss: 1.0220, policy_loss: 0.9689, value_loss: 0.5139
2024-07-14 06:57:21,090 [INFO    ] __main__: train step 16948: loss: 1.0220, policy_loss: 0.9689, value_loss: 0.5138
2024-07-14 06:57:21,387 [INFO    ] __main__: train step 16949: loss: 1.0220, policy_loss: 0.9689, value_loss: 0.5138
2024-07-14 06:57:21,676 [INFO    ] __main__: train step 16950: loss: 1.0219, policy_loss: 0.9688, value_loss: 0.5138
2024-07-14 06:57:21,971 [INFO    ] __main__: train step 16951: loss: 1.0219, policy_loss: 0.9688, value_loss: 0.5138
2024-07-14 06:57:22,273 [INFO    ] __main__: train step 16952: loss: 1.0219, policy_loss: 0.9688, value_loss: 0.5138
2024-07-14 06:57:22,573 [INFO    ] __main__: train step 16953: loss: 1.0219, policy_loss: 0.9688, value_loss: 0.5137
2024-07-14 06:57:22,870 [INFO    ] __main__: train step 16954: loss: 1.0219, policy_loss: 0.9688, value_loss: 0.5137
2024-07-14 06:57:23,164 [INFO    ] __main__: train step 16955: loss: 1.0219, policy_loss: 0.9688, value_loss: 0.5137
2024-07-14 06:57:23,484 [INFO    ] __main__: train step 16956: loss: 1.0218, policy_loss: 0.9687, value_loss: 0.5137
2024-07-14 06:57:23,781 [INFO    ] __main__: train step 16957: loss: 1.0218, policy_loss: 0.9687, value_loss: 0.5136
2024-07-14 06:57:24,080 [INFO    ] __main__: train step 16958: loss: 1.0218, policy_loss: 0.9687, value_loss: 0.5136
2024-07-14 06:57:24,391 [INFO    ] __main__: train step 16959: loss: 1.0218, policy_loss: 0.9687, value_loss: 0.5136
2024-07-14 06:57:24,699 [INFO    ] __main__: train step 16960: loss: 1.0218, policy_loss: 0.9687, value_loss: 0.5136
2024-07-14 06:57:24,994 [INFO    ] __main__: train step 16961: loss: 1.0218, policy_loss: 0.9686, value_loss: 0.5135
2024-07-14 06:57:25,296 [INFO    ] __main__: train step 16962: loss: 1.0217, policy_loss: 0.9686, value_loss: 0.5135
2024-07-14 06:57:26,928 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:57:27,425 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:57:27,493 [INFO    ] __main__: train step 16963: loss: 1.0217, policy_loss: 0.9686, value_loss: 0.5135
2024-07-14 06:57:27,792 [INFO    ] __main__: train step 16964: loss: 1.0217, policy_loss: 0.9686, value_loss: 0.5135
2024-07-14 06:57:28,089 [INFO    ] __main__: train step 16965: loss: 1.0217, policy_loss: 0.9686, value_loss: 0.5134
2024-07-14 06:57:28,383 [INFO    ] __main__: train step 16966: loss: 1.0217, policy_loss: 0.9685, value_loss: 0.5134
2024-07-14 06:57:28,669 [INFO    ] __main__: train step 16967: loss: 1.0217, policy_loss: 0.9685, value_loss: 0.5134
2024-07-14 06:57:28,971 [INFO    ] __main__: train step 16968: loss: 1.0216, policy_loss: 0.9685, value_loss: 0.5134
2024-07-14 06:57:29,262 [INFO    ] __main__: train step 16969: loss: 1.0216, policy_loss: 0.9685, value_loss: 0.5133
2024-07-14 06:57:29,563 [INFO    ] __main__: train step 16970: loss: 1.0216, policy_loss: 0.9685, value_loss: 0.5133
2024-07-14 06:57:29,858 [INFO    ] __main__: train step 16971: loss: 1.0216, policy_loss: 0.9685, value_loss: 0.5133
2024-07-14 06:57:30,153 [INFO    ] __main__: train step 16972: loss: 1.0216, policy_loss: 0.9684, value_loss: 0.5133
2024-07-14 06:57:30,437 [INFO    ] __main__: train step 16973: loss: 1.0216, policy_loss: 0.9684, value_loss: 0.5132
2024-07-14 06:57:30,729 [INFO    ] __main__: train step 16974: loss: 1.0215, policy_loss: 0.9684, value_loss: 0.5132
2024-07-14 06:57:31,028 [INFO    ] __main__: train step 16975: loss: 1.0215, policy_loss: 0.9684, value_loss: 0.5132
2024-07-14 06:57:31,324 [INFO    ] __main__: train step 16976: loss: 1.0215, policy_loss: 0.9684, value_loss: 0.5132
2024-07-14 06:57:31,610 [INFO    ] __main__: train step 16977: loss: 1.0215, policy_loss: 0.9683, value_loss: 0.5131
2024-07-14 06:57:31,907 [INFO    ] __main__: train step 16978: loss: 1.0215, policy_loss: 0.9683, value_loss: 0.5131
2024-07-14 06:57:32,217 [INFO    ] __main__: train step 16979: loss: 1.0215, policy_loss: 0.9683, value_loss: 0.5131
2024-07-14 06:57:33,844 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:57:34,317 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:57:34,385 [INFO    ] __main__: train step 16980: loss: 1.0214, policy_loss: 0.9683, value_loss: 0.5131
2024-07-14 06:57:34,680 [INFO    ] __main__: train step 16981: loss: 1.0214, policy_loss: 0.9683, value_loss: 0.5130
2024-07-14 06:57:34,974 [INFO    ] __main__: train step 16982: loss: 1.0214, policy_loss: 0.9682, value_loss: 0.5130
2024-07-14 06:57:35,275 [INFO    ] __main__: train step 16983: loss: 1.0214, policy_loss: 0.9682, value_loss: 0.5130
2024-07-14 06:57:35,565 [INFO    ] __main__: train step 16984: loss: 1.0214, policy_loss: 0.9682, value_loss: 0.5130
2024-07-14 06:57:35,852 [INFO    ] __main__: train step 16985: loss: 1.0214, policy_loss: 0.9682, value_loss: 0.5129
2024-07-14 06:57:39,291 [INFO    ] __main__: train step 16986: loss: 1.0213, policy_loss: 0.9682, value_loss: 0.5129
2024-07-14 06:57:39,612 [INFO    ] __main__: train step 16987: loss: 1.0213, policy_loss: 0.9682, value_loss: 0.5129
2024-07-14 06:57:39,908 [INFO    ] __main__: train step 16988: loss: 1.0213, policy_loss: 0.9681, value_loss: 0.5129
2024-07-14 06:57:40,203 [INFO    ] __main__: train step 16989: loss: 1.0213, policy_loss: 0.9681, value_loss: 0.5128
2024-07-14 06:57:40,499 [INFO    ] __main__: train step 16990: loss: 1.0213, policy_loss: 0.9681, value_loss: 0.5128
2024-07-14 06:57:40,801 [INFO    ] __main__: train step 16991: loss: 1.0213, policy_loss: 0.9681, value_loss: 0.5128
2024-07-14 06:57:41,098 [INFO    ] __main__: train step 16992: loss: 1.0212, policy_loss: 0.9681, value_loss: 0.5128
2024-07-14 06:57:41,399 [INFO    ] __main__: train step 16993: loss: 1.0212, policy_loss: 0.9680, value_loss: 0.5127
2024-07-14 06:57:41,701 [INFO    ] __main__: train step 16994: loss: 1.0212, policy_loss: 0.9680, value_loss: 0.5127
2024-07-14 06:57:42,008 [INFO    ] __main__: train step 16995: loss: 1.0212, policy_loss: 0.9680, value_loss: 0.5127
2024-07-14 06:57:42,321 [INFO    ] __main__: train step 16996: loss: 1.0212, policy_loss: 0.9680, value_loss: 0.5127
2024-07-14 06:57:43,952 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:57:44,441 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:57:44,509 [INFO    ] __main__: train step 16997: loss: 1.0212, policy_loss: 0.9680, value_loss: 0.5126
2024-07-14 06:57:44,810 [INFO    ] __main__: train step 16998: loss: 1.0211, policy_loss: 0.9679, value_loss: 0.5126
2024-07-14 06:57:45,098 [INFO    ] __main__: train step 16999: loss: 1.0211, policy_loss: 0.9679, value_loss: 0.5126
2024-07-14 06:57:45,404 [INFO    ] __main__: train step 17000: loss: 1.0211, policy_loss: 0.9679, value_loss: 0.5126
2024-07-14 06:57:45,571 [INFO    ] __main__: restored step 16000 for evaluation
2024-07-14 06:57:50,816 [INFO    ] __main__: test network ELO difference from baseline network: +42 (+8/-8) ELO from 32000 self-played games
2024-07-14 06:57:50,818 [INFO    ] __main__: game outcomes: W: 17368, D: 372, L: 14260
2024-07-14 06:57:50,820 [INFO    ] __main__: validation_elo_delta: 42, validation_elo: 2708
2024-07-14 06:57:51,587 [INFO    ] __main__: train step 17001: loss: 1.0211, policy_loss: 0.9679, value_loss: 0.5125
2024-07-14 06:57:51,865 [INFO    ] __main__: train step 17002: loss: 1.0211, policy_loss: 0.9679, value_loss: 0.5125
2024-07-14 06:57:52,139 [INFO    ] __main__: train step 17003: loss: 1.0211, policy_loss: 0.9679, value_loss: 0.5125
2024-07-14 06:57:52,419 [INFO    ] __main__: train step 17004: loss: 1.0210, policy_loss: 0.9678, value_loss: 0.5125
2024-07-14 06:57:52,687 [INFO    ] __main__: train step 17005: loss: 1.0210, policy_loss: 0.9678, value_loss: 0.5124
2024-07-14 06:57:52,951 [INFO    ] __main__: train step 17006: loss: 1.0210, policy_loss: 0.9678, value_loss: 0.5124
2024-07-14 06:57:53,239 [INFO    ] __main__: train step 17007: loss: 1.0210, policy_loss: 0.9678, value_loss: 0.5124
2024-07-14 06:57:53,527 [INFO    ] __main__: train step 17008: loss: 1.0210, policy_loss: 0.9678, value_loss: 0.5124
2024-07-14 06:57:53,824 [INFO    ] __main__: train step 17009: loss: 1.0210, policy_loss: 0.9677, value_loss: 0.5123
2024-07-14 06:57:54,134 [INFO    ] __main__: train step 17010: loss: 1.0209, policy_loss: 0.9677, value_loss: 0.5123
2024-07-14 06:57:54,421 [INFO    ] __main__: train step 17011: loss: 1.0209, policy_loss: 0.9677, value_loss: 0.5123
2024-07-14 06:57:54,709 [INFO    ] __main__: train step 17012: loss: 1.0209, policy_loss: 0.9677, value_loss: 0.5123
2024-07-14 06:57:54,994 [INFO    ] __main__: train step 17013: loss: 1.0209, policy_loss: 0.9677, value_loss: 0.5122
2024-07-14 06:57:56,593 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:57:57,075 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:57:57,148 [INFO    ] __main__: train step 17014: loss: 1.0209, policy_loss: 0.9676, value_loss: 0.5122
2024-07-14 06:57:57,442 [INFO    ] __main__: train step 17015: loss: 1.0209, policy_loss: 0.9676, value_loss: 0.5122
2024-07-14 06:57:57,718 [INFO    ] __main__: train step 17016: loss: 1.0209, policy_loss: 0.9676, value_loss: 0.5122
2024-07-14 06:57:58,022 [INFO    ] __main__: train step 17017: loss: 1.0208, policy_loss: 0.9676, value_loss: 0.5121
2024-07-14 06:57:58,308 [INFO    ] __main__: train step 17018: loss: 1.0208, policy_loss: 0.9676, value_loss: 0.5121
2024-07-14 06:57:58,603 [INFO    ] __main__: train step 17019: loss: 1.0208, policy_loss: 0.9676, value_loss: 0.5121
2024-07-14 06:57:58,872 [INFO    ] __main__: train step 17020: loss: 1.0208, policy_loss: 0.9675, value_loss: 0.5121
2024-07-14 06:57:59,136 [INFO    ] __main__: train step 17021: loss: 1.0208, policy_loss: 0.9675, value_loss: 0.5120
2024-07-14 06:57:59,428 [INFO    ] __main__: train step 17022: loss: 1.0208, policy_loss: 0.9675, value_loss: 0.5120
2024-07-14 06:57:59,685 [INFO    ] __main__: train step 17023: loss: 1.0207, policy_loss: 0.9675, value_loss: 0.5120
2024-07-14 06:57:59,976 [INFO    ] __main__: train step 17024: loss: 1.0207, policy_loss: 0.9675, value_loss: 0.5120
2024-07-14 06:58:00,250 [INFO    ] __main__: train step 17025: loss: 1.0207, policy_loss: 0.9674, value_loss: 0.5119
2024-07-14 06:58:00,543 [INFO    ] __main__: train step 17026: loss: 1.0207, policy_loss: 0.9674, value_loss: 0.5119
2024-07-14 06:58:00,834 [INFO    ] __main__: train step 17027: loss: 1.0207, policy_loss: 0.9674, value_loss: 0.5119
2024-07-14 06:58:01,124 [INFO    ] __main__: train step 17028: loss: 1.0207, policy_loss: 0.9674, value_loss: 0.5119
2024-07-14 06:58:01,388 [INFO    ] __main__: train step 17029: loss: 1.0206, policy_loss: 0.9674, value_loss: 0.5118
2024-07-14 06:58:01,667 [INFO    ] __main__: train step 17030: loss: 1.0206, policy_loss: 0.9673, value_loss: 0.5118
2024-07-14 06:58:03,281 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:58:03,763 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:58:03,831 [INFO    ] __main__: train step 17031: loss: 1.0206, policy_loss: 0.9673, value_loss: 0.5118
2024-07-14 06:58:04,120 [INFO    ] __main__: train step 17032: loss: 1.0206, policy_loss: 0.9673, value_loss: 0.5118
2024-07-14 06:58:04,394 [INFO    ] __main__: train step 17033: loss: 1.0206, policy_loss: 0.9673, value_loss: 0.5117
2024-07-14 06:58:04,667 [INFO    ] __main__: train step 17034: loss: 1.0206, policy_loss: 0.9673, value_loss: 0.5117
2024-07-14 06:58:04,946 [INFO    ] __main__: train step 17035: loss: 1.0205, policy_loss: 0.9673, value_loss: 0.5117
2024-07-14 06:58:05,244 [INFO    ] __main__: train step 17036: loss: 1.0205, policy_loss: 0.9672, value_loss: 0.5117
2024-07-14 06:58:05,533 [INFO    ] __main__: train step 17037: loss: 1.0205, policy_loss: 0.9672, value_loss: 0.5116
2024-07-14 06:58:05,805 [INFO    ] __main__: train step 17038: loss: 1.0205, policy_loss: 0.9672, value_loss: 0.5116
2024-07-14 06:58:06,072 [INFO    ] __main__: train step 17039: loss: 1.0205, policy_loss: 0.9672, value_loss: 0.5116
2024-07-14 06:58:06,384 [INFO    ] __main__: train step 17040: loss: 1.0205, policy_loss: 0.9672, value_loss: 0.5116
2024-07-14 06:58:06,638 [INFO    ] __main__: train step 17041: loss: 1.0204, policy_loss: 0.9671, value_loss: 0.5115
2024-07-14 06:58:06,894 [INFO    ] __main__: train step 17042: loss: 1.0204, policy_loss: 0.9671, value_loss: 0.5115
2024-07-14 06:58:07,171 [INFO    ] __main__: train step 17043: loss: 1.0204, policy_loss: 0.9671, value_loss: 0.5115
2024-07-14 06:58:07,448 [INFO    ] __main__: train step 17044: loss: 1.0204, policy_loss: 0.9671, value_loss: 0.5115
2024-07-14 06:58:07,725 [INFO    ] __main__: train step 17045: loss: 1.0204, policy_loss: 0.9671, value_loss: 0.5115
2024-07-14 06:58:08,003 [INFO    ] __main__: train step 17046: loss: 1.0204, policy_loss: 0.9670, value_loss: 0.5114
2024-07-14 06:58:08,290 [INFO    ] __main__: train step 17047: loss: 1.0203, policy_loss: 0.9670, value_loss: 0.5114
2024-07-14 06:58:09,912 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:58:10,401 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:58:10,472 [INFO    ] __main__: train step 17048: loss: 1.0203, policy_loss: 0.9670, value_loss: 0.5114
2024-07-14 06:58:10,768 [INFO    ] __main__: train step 17049: loss: 1.0203, policy_loss: 0.9670, value_loss: 0.5114
2024-07-14 06:58:11,068 [INFO    ] __main__: train step 17050: loss: 1.0203, policy_loss: 0.9670, value_loss: 0.5113
2024-07-14 06:58:11,380 [INFO    ] __main__: train step 17051: loss: 1.0203, policy_loss: 0.9670, value_loss: 0.5113
2024-07-14 06:58:11,677 [INFO    ] __main__: train step 17052: loss: 1.0203, policy_loss: 0.9669, value_loss: 0.5113
2024-07-14 06:58:11,964 [INFO    ] __main__: train step 17053: loss: 1.0202, policy_loss: 0.9669, value_loss: 0.5113
2024-07-14 06:58:12,265 [INFO    ] __main__: train step 17054: loss: 1.0202, policy_loss: 0.9669, value_loss: 0.5112
2024-07-14 06:58:12,555 [INFO    ] __main__: train step 17055: loss: 1.0202, policy_loss: 0.9669, value_loss: 0.5112
2024-07-14 06:58:12,850 [INFO    ] __main__: train step 17056: loss: 1.0202, policy_loss: 0.9669, value_loss: 0.5112
2024-07-14 06:58:13,151 [INFO    ] __main__: train step 17057: loss: 1.0202, policy_loss: 0.9668, value_loss: 0.5112
2024-07-14 06:58:13,446 [INFO    ] __main__: train step 17058: loss: 1.0202, policy_loss: 0.9668, value_loss: 0.5111
2024-07-14 06:58:13,737 [INFO    ] __main__: train step 17059: loss: 1.0201, policy_loss: 0.9668, value_loss: 0.5111
2024-07-14 06:58:14,028 [INFO    ] __main__: train step 17060: loss: 1.0201, policy_loss: 0.9668, value_loss: 0.5111
2024-07-14 06:58:14,328 [INFO    ] __main__: train step 17061: loss: 1.0201, policy_loss: 0.9668, value_loss: 0.5111
2024-07-14 06:58:14,636 [INFO    ] __main__: train step 17062: loss: 1.0201, policy_loss: 0.9668, value_loss: 0.5110
2024-07-14 06:58:14,934 [INFO    ] __main__: train step 17063: loss: 1.0201, policy_loss: 0.9667, value_loss: 0.5110
2024-07-14 06:58:15,237 [INFO    ] __main__: train step 17064: loss: 1.0201, policy_loss: 0.9667, value_loss: 0.5110
2024-07-14 06:58:16,854 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:58:17,338 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:58:17,404 [INFO    ] __main__: train step 17065: loss: 1.0200, policy_loss: 0.9667, value_loss: 0.5110
2024-07-14 06:58:17,679 [INFO    ] __main__: train step 17066: loss: 1.0200, policy_loss: 0.9667, value_loss: 0.5109
2024-07-14 06:58:17,943 [INFO    ] __main__: train step 17067: loss: 1.0200, policy_loss: 0.9667, value_loss: 0.5109
2024-07-14 06:58:18,213 [INFO    ] __main__: train step 17068: loss: 1.0200, policy_loss: 0.9666, value_loss: 0.5109
2024-07-14 06:58:18,474 [INFO    ] __main__: train step 17069: loss: 1.0200, policy_loss: 0.9666, value_loss: 0.5109
2024-07-14 06:58:18,778 [INFO    ] __main__: train step 17070: loss: 1.0200, policy_loss: 0.9666, value_loss: 0.5108
2024-07-14 06:58:19,037 [INFO    ] __main__: train step 17071: loss: 1.0200, policy_loss: 0.9666, value_loss: 0.5108
2024-07-14 06:58:19,323 [INFO    ] __main__: train step 17072: loss: 1.0199, policy_loss: 0.9666, value_loss: 0.5108
2024-07-14 06:58:19,605 [INFO    ] __main__: train step 17073: loss: 1.0199, policy_loss: 0.9665, value_loss: 0.5108
2024-07-14 06:58:19,891 [INFO    ] __main__: train step 17074: loss: 1.0199, policy_loss: 0.9665, value_loss: 0.5107
2024-07-14 06:58:20,186 [INFO    ] __main__: train step 17075: loss: 1.0199, policy_loss: 0.9665, value_loss: 0.5107
2024-07-14 06:58:20,461 [INFO    ] __main__: train step 17076: loss: 1.0199, policy_loss: 0.9665, value_loss: 0.5107
2024-07-14 06:58:20,747 [INFO    ] __main__: train step 17077: loss: 1.0199, policy_loss: 0.9665, value_loss: 0.5107
2024-07-14 06:58:21,051 [INFO    ] __main__: train step 17078: loss: 1.0198, policy_loss: 0.9665, value_loss: 0.5106
2024-07-14 06:58:21,338 [INFO    ] __main__: train step 17079: loss: 1.0198, policy_loss: 0.9664, value_loss: 0.5106
2024-07-14 06:58:21,622 [INFO    ] __main__: train step 17080: loss: 1.0198, policy_loss: 0.9664, value_loss: 0.5106
2024-07-14 06:58:21,885 [INFO    ] __main__: train step 17081: loss: 1.0198, policy_loss: 0.9664, value_loss: 0.5106
2024-07-14 06:58:23,450 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:58:23,937 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:58:24,010 [INFO    ] __main__: train step 17082: loss: 1.0198, policy_loss: 0.9664, value_loss: 0.5105
2024-07-14 06:58:24,286 [INFO    ] __main__: train step 17083: loss: 1.0198, policy_loss: 0.9664, value_loss: 0.5105
2024-07-14 06:58:24,561 [INFO    ] __main__: train step 17084: loss: 1.0197, policy_loss: 0.9663, value_loss: 0.5105
2024-07-14 06:58:24,837 [INFO    ] __main__: train step 17085: loss: 1.0197, policy_loss: 0.9663, value_loss: 0.5105
2024-07-14 06:58:25,118 [INFO    ] __main__: train step 17086: loss: 1.0197, policy_loss: 0.9663, value_loss: 0.5104
2024-07-14 06:58:25,381 [INFO    ] __main__: train step 17087: loss: 1.0197, policy_loss: 0.9663, value_loss: 0.5104
2024-07-14 06:58:25,684 [INFO    ] __main__: train step 17088: loss: 1.0197, policy_loss: 0.9663, value_loss: 0.5104
2024-07-14 06:58:28,785 [INFO    ] __main__: train step 17089: loss: 1.0197, policy_loss: 0.9663, value_loss: 0.5104
2024-07-14 06:58:29,060 [INFO    ] __main__: train step 17090: loss: 1.0196, policy_loss: 0.9662, value_loss: 0.5103
2024-07-14 06:58:29,341 [INFO    ] __main__: train step 17091: loss: 1.0196, policy_loss: 0.9662, value_loss: 0.5103
2024-07-14 06:58:29,621 [INFO    ] __main__: train step 17092: loss: 1.0196, policy_loss: 0.9662, value_loss: 0.5103
2024-07-14 06:58:29,903 [INFO    ] __main__: train step 17093: loss: 1.0196, policy_loss: 0.9662, value_loss: 0.5103
2024-07-14 06:58:30,180 [INFO    ] __main__: train step 17094: loss: 1.0196, policy_loss: 0.9662, value_loss: 0.5102
2024-07-14 06:58:30,446 [INFO    ] __main__: train step 17095: loss: 1.0196, policy_loss: 0.9661, value_loss: 0.5102
2024-07-14 06:58:30,721 [INFO    ] __main__: train step 17096: loss: 1.0195, policy_loss: 0.9661, value_loss: 0.5102
2024-07-14 06:58:31,010 [INFO    ] __main__: train step 17097: loss: 1.0195, policy_loss: 0.9661, value_loss: 0.5102
2024-07-14 06:58:31,279 [INFO    ] __main__: train step 17098: loss: 1.0195, policy_loss: 0.9661, value_loss: 0.5101
2024-07-14 06:58:32,851 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:58:33,335 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:58:33,401 [INFO    ] __main__: train step 17099: loss: 1.0195, policy_loss: 0.9661, value_loss: 0.5101
2024-07-14 06:58:33,664 [INFO    ] __main__: train step 17100: loss: 1.0195, policy_loss: 0.9660, value_loss: 0.5101
2024-07-14 06:58:33,947 [INFO    ] __main__: train step 17101: loss: 1.0195, policy_loss: 0.9660, value_loss: 0.5101
2024-07-14 06:58:34,218 [INFO    ] __main__: train step 17102: loss: 1.0194, policy_loss: 0.9660, value_loss: 0.5101
2024-07-14 06:58:34,512 [INFO    ] __main__: train step 17103: loss: 1.0194, policy_loss: 0.9660, value_loss: 0.5100
2024-07-14 06:58:34,806 [INFO    ] __main__: train step 17104: loss: 1.0194, policy_loss: 0.9660, value_loss: 0.5100
2024-07-14 06:58:35,087 [INFO    ] __main__: train step 17105: loss: 1.0194, policy_loss: 0.9660, value_loss: 0.5100
2024-07-14 06:58:35,373 [INFO    ] __main__: train step 17106: loss: 1.0194, policy_loss: 0.9659, value_loss: 0.5100
2024-07-14 06:58:35,658 [INFO    ] __main__: train step 17107: loss: 1.0194, policy_loss: 0.9659, value_loss: 0.5099
2024-07-14 06:58:35,937 [INFO    ] __main__: train step 17108: loss: 1.0194, policy_loss: 0.9659, value_loss: 0.5099
2024-07-14 06:58:36,189 [INFO    ] __main__: train step 17109: loss: 1.0193, policy_loss: 0.9659, value_loss: 0.5099
2024-07-14 06:58:36,430 [INFO    ] __main__: train step 17110: loss: 1.0193, policy_loss: 0.9659, value_loss: 0.5099
2024-07-14 06:58:36,699 [INFO    ] __main__: train step 17111: loss: 1.0193, policy_loss: 0.9658, value_loss: 0.5098
2024-07-14 06:58:36,958 [INFO    ] __main__: train step 17112: loss: 1.0193, policy_loss: 0.9658, value_loss: 0.5098
2024-07-14 06:58:37,234 [INFO    ] __main__: train step 17113: loss: 1.0193, policy_loss: 0.9658, value_loss: 0.5098
2024-07-14 06:58:37,502 [INFO    ] __main__: train step 17114: loss: 1.0193, policy_loss: 0.9658, value_loss: 0.5098
2024-07-14 06:58:37,761 [INFO    ] __main__: train step 17115: loss: 1.0192, policy_loss: 0.9658, value_loss: 0.5097
2024-07-14 06:58:39,359 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:58:39,855 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:58:39,925 [INFO    ] __main__: train step 17116: loss: 1.0192, policy_loss: 0.9658, value_loss: 0.5097
2024-07-14 06:58:40,221 [INFO    ] __main__: train step 17117: loss: 1.0192, policy_loss: 0.9657, value_loss: 0.5097
2024-07-14 06:58:40,514 [INFO    ] __main__: train step 17118: loss: 1.0192, policy_loss: 0.9657, value_loss: 0.5097
2024-07-14 06:58:40,792 [INFO    ] __main__: train step 17119: loss: 1.0192, policy_loss: 0.9657, value_loss: 0.5096
2024-07-14 06:58:41,060 [INFO    ] __main__: train step 17120: loss: 1.0192, policy_loss: 0.9657, value_loss: 0.5096
2024-07-14 06:58:41,326 [INFO    ] __main__: train step 17121: loss: 1.0191, policy_loss: 0.9657, value_loss: 0.5096
2024-07-14 06:58:41,605 [INFO    ] __main__: train step 17122: loss: 1.0191, policy_loss: 0.9656, value_loss: 0.5096
2024-07-14 06:58:41,877 [INFO    ] __main__: train step 17123: loss: 1.0191, policy_loss: 0.9656, value_loss: 0.5095
2024-07-14 06:58:42,166 [INFO    ] __main__: train step 17124: loss: 1.0191, policy_loss: 0.9656, value_loss: 0.5095
2024-07-14 06:58:42,433 [INFO    ] __main__: train step 17125: loss: 1.0191, policy_loss: 0.9656, value_loss: 0.5095
2024-07-14 06:58:42,717 [INFO    ] __main__: train step 17126: loss: 1.0191, policy_loss: 0.9656, value_loss: 0.5095
2024-07-14 06:58:42,984 [INFO    ] __main__: train step 17127: loss: 1.0190, policy_loss: 0.9655, value_loss: 0.5094
2024-07-14 06:58:43,245 [INFO    ] __main__: train step 17128: loss: 1.0190, policy_loss: 0.9655, value_loss: 0.5094
2024-07-14 06:58:43,501 [INFO    ] __main__: train step 17129: loss: 1.0190, policy_loss: 0.9655, value_loss: 0.5094
2024-07-14 06:58:43,766 [INFO    ] __main__: train step 17130: loss: 1.0190, policy_loss: 0.9655, value_loss: 0.5094
2024-07-14 06:58:44,015 [INFO    ] __main__: train step 17131: loss: 1.0190, policy_loss: 0.9655, value_loss: 0.5093
2024-07-14 06:58:44,282 [INFO    ] __main__: train step 17132: loss: 1.0190, policy_loss: 0.9655, value_loss: 0.5093
2024-07-14 06:58:45,988 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:58:46,472 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:58:46,542 [INFO    ] __main__: train step 17133: loss: 1.0189, policy_loss: 0.9654, value_loss: 0.5093
2024-07-14 06:58:46,835 [INFO    ] __main__: train step 17134: loss: 1.0189, policy_loss: 0.9654, value_loss: 0.5093
2024-07-14 06:58:47,097 [INFO    ] __main__: train step 17135: loss: 1.0189, policy_loss: 0.9654, value_loss: 0.5092
2024-07-14 06:58:47,349 [INFO    ] __main__: train step 17136: loss: 1.0189, policy_loss: 0.9654, value_loss: 0.5092
2024-07-14 06:58:47,636 [INFO    ] __main__: train step 17137: loss: 1.0189, policy_loss: 0.9654, value_loss: 0.5092
2024-07-14 06:58:47,903 [INFO    ] __main__: train step 17138: loss: 1.0189, policy_loss: 0.9653, value_loss: 0.5092
2024-07-14 06:58:48,193 [INFO    ] __main__: train step 17139: loss: 1.0188, policy_loss: 0.9653, value_loss: 0.5091
2024-07-14 06:58:48,582 [INFO    ] __main__: train step 17140: loss: 1.0188, policy_loss: 0.9653, value_loss: 0.5091
2024-07-14 06:58:48,854 [INFO    ] __main__: train step 17141: loss: 1.0188, policy_loss: 0.9653, value_loss: 0.5091
2024-07-14 06:58:49,157 [INFO    ] __main__: train step 17142: loss: 1.0188, policy_loss: 0.9653, value_loss: 0.5091
2024-07-14 06:58:49,442 [INFO    ] __main__: train step 17143: loss: 1.0188, policy_loss: 0.9653, value_loss: 0.5090
2024-07-14 06:58:49,713 [INFO    ] __main__: train step 17144: loss: 1.0188, policy_loss: 0.9652, value_loss: 0.5090
2024-07-14 06:58:49,990 [INFO    ] __main__: train step 17145: loss: 1.0187, policy_loss: 0.9652, value_loss: 0.5090
2024-07-14 06:58:50,263 [INFO    ] __main__: train step 17146: loss: 1.0187, policy_loss: 0.9652, value_loss: 0.5090
2024-07-14 06:58:50,567 [INFO    ] __main__: train step 17147: loss: 1.0187, policy_loss: 0.9652, value_loss: 0.5089
2024-07-14 06:58:50,839 [INFO    ] __main__: train step 17148: loss: 1.0187, policy_loss: 0.9652, value_loss: 0.5089
2024-07-14 06:58:51,101 [INFO    ] __main__: train step 17149: loss: 1.0187, policy_loss: 0.9651, value_loss: 0.5089
2024-07-14 06:58:52,690 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:58:53,170 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:58:53,243 [INFO    ] __main__: train step 17150: loss: 1.0187, policy_loss: 0.9651, value_loss: 0.5089
2024-07-14 06:58:53,517 [INFO    ] __main__: train step 17151: loss: 1.0186, policy_loss: 0.9651, value_loss: 0.5089
2024-07-14 06:58:53,788 [INFO    ] __main__: train step 17152: loss: 1.0186, policy_loss: 0.9651, value_loss: 0.5088
2024-07-14 06:58:54,030 [INFO    ] __main__: train step 17153: loss: 1.0186, policy_loss: 0.9651, value_loss: 0.5088
2024-07-14 06:58:54,275 [INFO    ] __main__: train step 17154: loss: 1.0186, policy_loss: 0.9651, value_loss: 0.5088
2024-07-14 06:58:54,553 [INFO    ] __main__: train step 17155: loss: 1.0186, policy_loss: 0.9650, value_loss: 0.5088
2024-07-14 06:58:54,824 [INFO    ] __main__: train step 17156: loss: 1.0186, policy_loss: 0.9650, value_loss: 0.5087
2024-07-14 06:58:55,101 [INFO    ] __main__: train step 17157: loss: 1.0186, policy_loss: 0.9650, value_loss: 0.5087
2024-07-14 06:58:55,374 [INFO    ] __main__: train step 17158: loss: 1.0185, policy_loss: 0.9650, value_loss: 0.5087
2024-07-14 06:58:55,643 [INFO    ] __main__: train step 17159: loss: 1.0185, policy_loss: 0.9650, value_loss: 0.5087
2024-07-14 06:58:55,928 [INFO    ] __main__: train step 17160: loss: 1.0185, policy_loss: 0.9649, value_loss: 0.5086
2024-07-14 06:58:56,240 [INFO    ] __main__: train step 17161: loss: 1.0185, policy_loss: 0.9649, value_loss: 0.5086
2024-07-14 06:58:56,523 [INFO    ] __main__: train step 17162: loss: 1.0185, policy_loss: 0.9649, value_loss: 0.5086
2024-07-14 06:58:56,795 [INFO    ] __main__: train step 17163: loss: 1.0185, policy_loss: 0.9649, value_loss: 0.5086
2024-07-14 06:58:57,080 [INFO    ] __main__: train step 17164: loss: 1.0184, policy_loss: 0.9649, value_loss: 0.5085
2024-07-14 06:58:57,348 [INFO    ] __main__: train step 17165: loss: 1.0184, policy_loss: 0.9648, value_loss: 0.5085
2024-07-14 06:58:57,624 [INFO    ] __main__: train step 17166: loss: 1.0184, policy_loss: 0.9648, value_loss: 0.5085
2024-07-14 06:58:59,225 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:58:59,707 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:58:59,773 [INFO    ] __main__: train step 17167: loss: 1.0184, policy_loss: 0.9648, value_loss: 0.5085
2024-07-14 06:59:00,054 [INFO    ] __main__: train step 17168: loss: 1.0184, policy_loss: 0.9648, value_loss: 0.5084
2024-07-14 06:59:00,342 [INFO    ] __main__: train step 17169: loss: 1.0184, policy_loss: 0.9648, value_loss: 0.5084
2024-07-14 06:59:00,620 [INFO    ] __main__: train step 17170: loss: 1.0183, policy_loss: 0.9648, value_loss: 0.5084
2024-07-14 06:59:00,899 [INFO    ] __main__: train step 17171: loss: 1.0183, policy_loss: 0.9647, value_loss: 0.5084
2024-07-14 06:59:01,180 [INFO    ] __main__: train step 17172: loss: 1.0183, policy_loss: 0.9647, value_loss: 0.5083
2024-07-14 06:59:01,438 [INFO    ] __main__: train step 17173: loss: 1.0183, policy_loss: 0.9647, value_loss: 0.5083
2024-07-14 06:59:01,730 [INFO    ] __main__: train step 17174: loss: 1.0183, policy_loss: 0.9647, value_loss: 0.5083
2024-07-14 06:59:02,008 [INFO    ] __main__: train step 17175: loss: 1.0183, policy_loss: 0.9647, value_loss: 0.5083
2024-07-14 06:59:02,274 [INFO    ] __main__: train step 17176: loss: 1.0182, policy_loss: 0.9646, value_loss: 0.5082
2024-07-14 06:59:02,544 [INFO    ] __main__: train step 17177: loss: 1.0182, policy_loss: 0.9646, value_loss: 0.5082
2024-07-14 06:59:02,800 [INFO    ] __main__: train step 17178: loss: 1.0182, policy_loss: 0.9646, value_loss: 0.5082
2024-07-14 06:59:03,082 [INFO    ] __main__: train step 17179: loss: 1.0182, policy_loss: 0.9646, value_loss: 0.5082
2024-07-14 06:59:03,363 [INFO    ] __main__: train step 17180: loss: 1.0182, policy_loss: 0.9646, value_loss: 0.5081
2024-07-14 06:59:03,654 [INFO    ] __main__: train step 17181: loss: 1.0182, policy_loss: 0.9646, value_loss: 0.5081
2024-07-14 06:59:03,951 [INFO    ] __main__: train step 17182: loss: 1.0182, policy_loss: 0.9645, value_loss: 0.5081
2024-07-14 06:59:04,250 [INFO    ] __main__: train step 17183: loss: 1.0181, policy_loss: 0.9645, value_loss: 0.5081
2024-07-14 06:59:05,880 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:59:06,363 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:59:06,434 [INFO    ] __main__: train step 17184: loss: 1.0181, policy_loss: 0.9645, value_loss: 0.5081
2024-07-14 06:59:06,731 [INFO    ] __main__: train step 17185: loss: 1.0181, policy_loss: 0.9645, value_loss: 0.5080
2024-07-14 06:59:06,986 [INFO    ] __main__: train step 17186: loss: 1.0181, policy_loss: 0.9645, value_loss: 0.5080
2024-07-14 06:59:07,246 [INFO    ] __main__: train step 17187: loss: 1.0181, policy_loss: 0.9645, value_loss: 0.5080
2024-07-14 06:59:07,515 [INFO    ] __main__: train step 17188: loss: 1.0181, policy_loss: 0.9644, value_loss: 0.5080
2024-07-14 06:59:07,786 [INFO    ] __main__: train step 17189: loss: 1.0180, policy_loss: 0.9644, value_loss: 0.5079
2024-07-14 06:59:11,127 [INFO    ] __main__: train step 17190: loss: 1.0180, policy_loss: 0.9644, value_loss: 0.5079
2024-07-14 06:59:11,418 [INFO    ] __main__: train step 17191: loss: 1.0180, policy_loss: 0.9644, value_loss: 0.5079
2024-07-14 06:59:11,692 [INFO    ] __main__: train step 17192: loss: 1.0180, policy_loss: 0.9644, value_loss: 0.5079
2024-07-14 06:59:11,988 [INFO    ] __main__: train step 17193: loss: 1.0180, policy_loss: 0.9643, value_loss: 0.5078
2024-07-14 06:59:12,281 [INFO    ] __main__: train step 17194: loss: 1.0180, policy_loss: 0.9643, value_loss: 0.5078
2024-07-14 06:59:12,571 [INFO    ] __main__: train step 17195: loss: 1.0179, policy_loss: 0.9643, value_loss: 0.5078
2024-07-14 06:59:12,863 [INFO    ] __main__: train step 17196: loss: 1.0179, policy_loss: 0.9643, value_loss: 0.5078
2024-07-14 06:59:13,156 [INFO    ] __main__: train step 17197: loss: 1.0179, policy_loss: 0.9643, value_loss: 0.5077
2024-07-14 06:59:13,443 [INFO    ] __main__: train step 17198: loss: 1.0179, policy_loss: 0.9643, value_loss: 0.5077
2024-07-14 06:59:13,731 [INFO    ] __main__: train step 17199: loss: 1.0179, policy_loss: 0.9642, value_loss: 0.5077
2024-07-14 06:59:14,020 [INFO    ] __main__: train step 17200: loss: 1.0179, policy_loss: 0.9642, value_loss: 0.5077
2024-07-14 06:59:15,654 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:59:16,136 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:59:16,209 [INFO    ] __main__: train step 17201: loss: 1.0179, policy_loss: 0.9642, value_loss: 0.5076
2024-07-14 06:59:16,503 [INFO    ] __main__: train step 17202: loss: 1.0178, policy_loss: 0.9642, value_loss: 0.5076
2024-07-14 06:59:16,797 [INFO    ] __main__: train step 17203: loss: 1.0178, policy_loss: 0.9642, value_loss: 0.5076
2024-07-14 06:59:17,079 [INFO    ] __main__: train step 17204: loss: 1.0178, policy_loss: 0.9641, value_loss: 0.5076
2024-07-14 06:59:17,362 [INFO    ] __main__: train step 17205: loss: 1.0178, policy_loss: 0.9641, value_loss: 0.5075
2024-07-14 06:59:17,665 [INFO    ] __main__: train step 17206: loss: 1.0178, policy_loss: 0.9641, value_loss: 0.5075
2024-07-14 06:59:17,944 [INFO    ] __main__: train step 17207: loss: 1.0178, policy_loss: 0.9641, value_loss: 0.5075
2024-07-14 06:59:18,230 [INFO    ] __main__: train step 17208: loss: 1.0177, policy_loss: 0.9641, value_loss: 0.5075
2024-07-14 06:59:18,518 [INFO    ] __main__: train step 17209: loss: 1.0177, policy_loss: 0.9641, value_loss: 0.5074
2024-07-14 06:59:18,800 [INFO    ] __main__: train step 17210: loss: 1.0177, policy_loss: 0.9640, value_loss: 0.5074
2024-07-14 06:59:19,101 [INFO    ] __main__: train step 17211: loss: 1.0177, policy_loss: 0.9640, value_loss: 0.5074
2024-07-14 06:59:19,365 [INFO    ] __main__: train step 17212: loss: 1.0177, policy_loss: 0.9640, value_loss: 0.5074
2024-07-14 06:59:19,652 [INFO    ] __main__: train step 17213: loss: 1.0177, policy_loss: 0.9640, value_loss: 0.5073
2024-07-14 06:59:19,941 [INFO    ] __main__: train step 17214: loss: 1.0176, policy_loss: 0.9640, value_loss: 0.5073
2024-07-14 06:59:20,227 [INFO    ] __main__: train step 17215: loss: 1.0176, policy_loss: 0.9639, value_loss: 0.5073
2024-07-14 06:59:20,514 [INFO    ] __main__: train step 17216: loss: 1.0176, policy_loss: 0.9639, value_loss: 0.5073
2024-07-14 06:59:20,785 [INFO    ] __main__: train step 17217: loss: 1.0176, policy_loss: 0.9639, value_loss: 0.5072
2024-07-14 06:59:22,397 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:59:22,889 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:59:22,959 [INFO    ] __main__: train step 17218: loss: 1.0176, policy_loss: 0.9639, value_loss: 0.5072
2024-07-14 06:59:23,219 [INFO    ] __main__: train step 17219: loss: 1.0176, policy_loss: 0.9639, value_loss: 0.5072
2024-07-14 06:59:23,481 [INFO    ] __main__: train step 17220: loss: 1.0175, policy_loss: 0.9639, value_loss: 0.5072
2024-07-14 06:59:23,764 [INFO    ] __main__: train step 17221: loss: 1.0175, policy_loss: 0.9638, value_loss: 0.5072
2024-07-14 06:59:24,026 [INFO    ] __main__: train step 17222: loss: 1.0175, policy_loss: 0.9638, value_loss: 0.5071
2024-07-14 06:59:24,341 [INFO    ] __main__: train step 17223: loss: 1.0175, policy_loss: 0.9638, value_loss: 0.5071
2024-07-14 06:59:24,625 [INFO    ] __main__: train step 17224: loss: 1.0175, policy_loss: 0.9638, value_loss: 0.5071
2024-07-14 06:59:24,918 [INFO    ] __main__: train step 17225: loss: 1.0175, policy_loss: 0.9638, value_loss: 0.5071
2024-07-14 06:59:25,207 [INFO    ] __main__: train step 17226: loss: 1.0175, policy_loss: 0.9637, value_loss: 0.5070
2024-07-14 06:59:25,470 [INFO    ] __main__: train step 17227: loss: 1.0174, policy_loss: 0.9637, value_loss: 0.5070
2024-07-14 06:59:25,757 [INFO    ] __main__: train step 17228: loss: 1.0174, policy_loss: 0.9637, value_loss: 0.5070
2024-07-14 06:59:26,041 [INFO    ] __main__: train step 17229: loss: 1.0174, policy_loss: 0.9637, value_loss: 0.5070
2024-07-14 06:59:26,329 [INFO    ] __main__: train step 17230: loss: 1.0174, policy_loss: 0.9637, value_loss: 0.5069
2024-07-14 06:59:26,622 [INFO    ] __main__: train step 17231: loss: 1.0174, policy_loss: 0.9637, value_loss: 0.5069
2024-07-14 06:59:26,925 [INFO    ] __main__: train step 17232: loss: 1.0174, policy_loss: 0.9636, value_loss: 0.5069
2024-07-14 06:59:27,195 [INFO    ] __main__: train step 17233: loss: 1.0173, policy_loss: 0.9636, value_loss: 0.5069
2024-07-14 06:59:27,491 [INFO    ] __main__: train step 17234: loss: 1.0173, policy_loss: 0.9636, value_loss: 0.5068
2024-07-14 06:59:29,118 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:59:29,605 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:59:29,676 [INFO    ] __main__: train step 17235: loss: 1.0173, policy_loss: 0.9636, value_loss: 0.5068
2024-07-14 06:59:29,974 [INFO    ] __main__: train step 17236: loss: 1.0173, policy_loss: 0.9636, value_loss: 0.5068
2024-07-14 06:59:30,264 [INFO    ] __main__: train step 17237: loss: 1.0173, policy_loss: 0.9636, value_loss: 0.5068
2024-07-14 06:59:30,546 [INFO    ] __main__: train step 17238: loss: 1.0173, policy_loss: 0.9635, value_loss: 0.5067
2024-07-14 06:59:30,839 [INFO    ] __main__: train step 17239: loss: 1.0172, policy_loss: 0.9635, value_loss: 0.5067
2024-07-14 06:59:31,136 [INFO    ] __main__: train step 17240: loss: 1.0172, policy_loss: 0.9635, value_loss: 0.5067
2024-07-14 06:59:31,440 [INFO    ] __main__: train step 17241: loss: 1.0172, policy_loss: 0.9635, value_loss: 0.5067
2024-07-14 06:59:31,728 [INFO    ] __main__: train step 17242: loss: 1.0172, policy_loss: 0.9635, value_loss: 0.5066
2024-07-14 06:59:32,035 [INFO    ] __main__: train step 17243: loss: 1.0172, policy_loss: 0.9634, value_loss: 0.5066
2024-07-14 06:59:32,325 [INFO    ] __main__: train step 17244: loss: 1.0172, policy_loss: 0.9634, value_loss: 0.5066
2024-07-14 06:59:32,622 [INFO    ] __main__: train step 17245: loss: 1.0172, policy_loss: 0.9634, value_loss: 0.5066
2024-07-14 06:59:32,914 [INFO    ] __main__: train step 17246: loss: 1.0171, policy_loss: 0.9634, value_loss: 0.5065
2024-07-14 06:59:33,200 [INFO    ] __main__: train step 17247: loss: 1.0171, policy_loss: 0.9634, value_loss: 0.5065
2024-07-14 06:59:33,474 [INFO    ] __main__: train step 17248: loss: 1.0171, policy_loss: 0.9634, value_loss: 0.5065
2024-07-14 06:59:33,764 [INFO    ] __main__: train step 17249: loss: 1.0171, policy_loss: 0.9633, value_loss: 0.5065
2024-07-14 06:59:34,052 [INFO    ] __main__: train step 17250: loss: 1.0171, policy_loss: 0.9633, value_loss: 0.5065
2024-07-14 06:59:34,337 [INFO    ] __main__: train step 17251: loss: 1.0171, policy_loss: 0.9633, value_loss: 0.5064
2024-07-14 06:59:35,944 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:59:36,431 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:59:36,502 [INFO    ] __main__: train step 17252: loss: 1.0170, policy_loss: 0.9633, value_loss: 0.5064
2024-07-14 06:59:36,797 [INFO    ] __main__: train step 17253: loss: 1.0170, policy_loss: 0.9633, value_loss: 0.5064
2024-07-14 06:59:37,100 [INFO    ] __main__: train step 17254: loss: 1.0170, policy_loss: 0.9632, value_loss: 0.5064
2024-07-14 06:59:37,388 [INFO    ] __main__: train step 17255: loss: 1.0170, policy_loss: 0.9632, value_loss: 0.5063
2024-07-14 06:59:37,682 [INFO    ] __main__: train step 17256: loss: 1.0170, policy_loss: 0.9632, value_loss: 0.5063
2024-07-14 06:59:37,977 [INFO    ] __main__: train step 17257: loss: 1.0170, policy_loss: 0.9632, value_loss: 0.5063
2024-07-14 06:59:38,245 [INFO    ] __main__: train step 17258: loss: 1.0170, policy_loss: 0.9632, value_loss: 0.5063
2024-07-14 06:59:38,541 [INFO    ] __main__: train step 17259: loss: 1.0169, policy_loss: 0.9632, value_loss: 0.5062
2024-07-14 06:59:38,838 [INFO    ] __main__: train step 17260: loss: 1.0169, policy_loss: 0.9631, value_loss: 0.5062
2024-07-14 06:59:39,122 [INFO    ] __main__: train step 17261: loss: 1.0169, policy_loss: 0.9631, value_loss: 0.5062
2024-07-14 06:59:39,412 [INFO    ] __main__: train step 17262: loss: 1.0169, policy_loss: 0.9631, value_loss: 0.5062
2024-07-14 06:59:39,719 [INFO    ] __main__: train step 17263: loss: 1.0169, policy_loss: 0.9631, value_loss: 0.5061
2024-07-14 06:59:40,007 [INFO    ] __main__: train step 17264: loss: 1.0169, policy_loss: 0.9631, value_loss: 0.5061
2024-07-14 06:59:40,289 [INFO    ] __main__: train step 17265: loss: 1.0168, policy_loss: 0.9631, value_loss: 0.5061
2024-07-14 06:59:40,584 [INFO    ] __main__: train step 17266: loss: 1.0168, policy_loss: 0.9630, value_loss: 0.5061
2024-07-14 06:59:40,889 [INFO    ] __main__: train step 17267: loss: 1.0168, policy_loss: 0.9630, value_loss: 0.5060
2024-07-14 06:59:41,208 [INFO    ] __main__: train step 17268: loss: 1.0168, policy_loss: 0.9630, value_loss: 0.5060
2024-07-14 06:59:42,847 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:59:43,344 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:59:43,415 [INFO    ] __main__: train step 17269: loss: 1.0168, policy_loss: 0.9630, value_loss: 0.5060
2024-07-14 06:59:43,695 [INFO    ] __main__: train step 17270: loss: 1.0168, policy_loss: 0.9630, value_loss: 0.5060
2024-07-14 06:59:43,994 [INFO    ] __main__: train step 17271: loss: 1.0167, policy_loss: 0.9629, value_loss: 0.5059
2024-07-14 06:59:44,304 [INFO    ] __main__: train step 17272: loss: 1.0167, policy_loss: 0.9629, value_loss: 0.5059
2024-07-14 06:59:44,591 [INFO    ] __main__: train step 17273: loss: 1.0167, policy_loss: 0.9629, value_loss: 0.5059
2024-07-14 06:59:44,876 [INFO    ] __main__: train step 17274: loss: 1.0167, policy_loss: 0.9629, value_loss: 0.5059
2024-07-14 06:59:45,163 [INFO    ] __main__: train step 17275: loss: 1.0167, policy_loss: 0.9629, value_loss: 0.5059
2024-07-14 06:59:45,452 [INFO    ] __main__: train step 17276: loss: 1.0167, policy_loss: 0.9629, value_loss: 0.5058
2024-07-14 06:59:45,741 [INFO    ] __main__: train step 17277: loss: 1.0167, policy_loss: 0.9628, value_loss: 0.5058
2024-07-14 06:59:46,021 [INFO    ] __main__: train step 17278: loss: 1.0166, policy_loss: 0.9628, value_loss: 0.5058
2024-07-14 06:59:46,303 [INFO    ] __main__: train step 17279: loss: 1.0166, policy_loss: 0.9628, value_loss: 0.5058
2024-07-14 06:59:46,581 [INFO    ] __main__: train step 17280: loss: 1.0166, policy_loss: 0.9628, value_loss: 0.5057
2024-07-14 06:59:46,873 [INFO    ] __main__: train step 17281: loss: 1.0166, policy_loss: 0.9628, value_loss: 0.5057
2024-07-14 06:59:47,151 [INFO    ] __main__: train step 17282: loss: 1.0166, policy_loss: 0.9628, value_loss: 0.5057
2024-07-14 06:59:47,447 [INFO    ] __main__: train step 17283: loss: 1.0166, policy_loss: 0.9627, value_loss: 0.5057
2024-07-14 06:59:47,729 [INFO    ] __main__: train step 17284: loss: 1.0166, policy_loss: 0.9627, value_loss: 0.5056
2024-07-14 06:59:48,006 [INFO    ] __main__: train step 17285: loss: 1.0165, policy_loss: 0.9627, value_loss: 0.5056
2024-07-14 06:59:49,645 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 06:59:50,130 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 06:59:50,200 [INFO    ] __main__: train step 17286: loss: 1.0165, policy_loss: 0.9627, value_loss: 0.5056
2024-07-14 06:59:50,481 [INFO    ] __main__: train step 17287: loss: 1.0165, policy_loss: 0.9627, value_loss: 0.5056
2024-07-14 06:59:50,749 [INFO    ] __main__: train step 17288: loss: 1.0165, policy_loss: 0.9627, value_loss: 0.5055
2024-07-14 06:59:51,015 [INFO    ] __main__: train step 17289: loss: 1.0165, policy_loss: 0.9626, value_loss: 0.5055
2024-07-14 06:59:51,307 [INFO    ] __main__: train step 17290: loss: 1.0165, policy_loss: 0.9626, value_loss: 0.5055
2024-07-14 06:59:51,595 [INFO    ] __main__: train step 17291: loss: 1.0164, policy_loss: 0.9626, value_loss: 0.5055
2024-07-14 06:59:51,885 [INFO    ] __main__: train step 17292: loss: 1.0164, policy_loss: 0.9626, value_loss: 0.5054
2024-07-14 06:59:55,424 [INFO    ] __main__: train step 17293: loss: 1.0164, policy_loss: 0.9626, value_loss: 0.5054
2024-07-14 06:59:55,704 [INFO    ] __main__: train step 17294: loss: 1.0164, policy_loss: 0.9625, value_loss: 0.5054
2024-07-14 06:59:55,995 [INFO    ] __main__: train step 17295: loss: 1.0164, policy_loss: 0.9625, value_loss: 0.5054
2024-07-14 06:59:56,285 [INFO    ] __main__: train step 17296: loss: 1.0164, policy_loss: 0.9625, value_loss: 0.5053
2024-07-14 06:59:56,568 [INFO    ] __main__: train step 17297: loss: 1.0164, policy_loss: 0.9625, value_loss: 0.5053
2024-07-14 06:59:56,847 [INFO    ] __main__: train step 17298: loss: 1.0163, policy_loss: 0.9625, value_loss: 0.5053
2024-07-14 06:59:57,108 [INFO    ] __main__: train step 17299: loss: 1.0163, policy_loss: 0.9625, value_loss: 0.5053
2024-07-14 06:59:57,383 [INFO    ] __main__: train step 17300: loss: 1.0163, policy_loss: 0.9624, value_loss: 0.5053
2024-07-14 06:59:57,682 [INFO    ] __main__: train step 17301: loss: 1.0163, policy_loss: 0.9624, value_loss: 0.5052
2024-07-14 06:59:57,975 [INFO    ] __main__: train step 17302: loss: 1.0163, policy_loss: 0.9624, value_loss: 0.5052
2024-07-14 06:59:59,603 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:00:00,088 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:00:00,156 [INFO    ] __main__: train step 17303: loss: 1.0163, policy_loss: 0.9624, value_loss: 0.5052
2024-07-14 07:00:00,421 [INFO    ] __main__: train step 17304: loss: 1.0162, policy_loss: 0.9624, value_loss: 0.5052
2024-07-14 07:00:00,702 [INFO    ] __main__: train step 17305: loss: 1.0162, policy_loss: 0.9623, value_loss: 0.5051
2024-07-14 07:00:01,002 [INFO    ] __main__: train step 17306: loss: 1.0162, policy_loss: 0.9623, value_loss: 0.5051
2024-07-14 07:00:01,297 [INFO    ] __main__: train step 17307: loss: 1.0162, policy_loss: 0.9623, value_loss: 0.5051
2024-07-14 07:00:01,581 [INFO    ] __main__: train step 17308: loss: 1.0162, policy_loss: 0.9623, value_loss: 0.5051
2024-07-14 07:00:01,867 [INFO    ] __main__: train step 17309: loss: 1.0162, policy_loss: 0.9623, value_loss: 0.5050
2024-07-14 07:00:02,158 [INFO    ] __main__: train step 17310: loss: 1.0161, policy_loss: 0.9623, value_loss: 0.5050
2024-07-14 07:00:02,447 [INFO    ] __main__: train step 17311: loss: 1.0161, policy_loss: 0.9622, value_loss: 0.5050
2024-07-14 07:00:02,742 [INFO    ] __main__: train step 17312: loss: 1.0161, policy_loss: 0.9622, value_loss: 0.5050
2024-07-14 07:00:03,026 [INFO    ] __main__: train step 17313: loss: 1.0161, policy_loss: 0.9622, value_loss: 0.5049
2024-07-14 07:00:03,328 [INFO    ] __main__: train step 17314: loss: 1.0161, policy_loss: 0.9622, value_loss: 0.5049
2024-07-14 07:00:03,631 [INFO    ] __main__: train step 17315: loss: 1.0161, policy_loss: 0.9622, value_loss: 0.5049
2024-07-14 07:00:03,931 [INFO    ] __main__: train step 17316: loss: 1.0161, policy_loss: 0.9622, value_loss: 0.5049
2024-07-14 07:00:04,236 [INFO    ] __main__: train step 17317: loss: 1.0160, policy_loss: 0.9621, value_loss: 0.5048
2024-07-14 07:00:04,531 [INFO    ] __main__: train step 17318: loss: 1.0160, policy_loss: 0.9621, value_loss: 0.5048
2024-07-14 07:00:04,788 [INFO    ] __main__: train step 17319: loss: 1.0160, policy_loss: 0.9621, value_loss: 0.5048
2024-07-14 07:00:06,370 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:00:06,840 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:00:06,908 [INFO    ] __main__: train step 17320: loss: 1.0160, policy_loss: 0.9621, value_loss: 0.5048
2024-07-14 07:00:07,171 [INFO    ] __main__: train step 17321: loss: 1.0160, policy_loss: 0.9621, value_loss: 0.5048
2024-07-14 07:00:07,445 [INFO    ] __main__: train step 17322: loss: 1.0160, policy_loss: 0.9621, value_loss: 0.5047
2024-07-14 07:00:07,716 [INFO    ] __main__: train step 17323: loss: 1.0159, policy_loss: 0.9620, value_loss: 0.5047
2024-07-14 07:00:07,988 [INFO    ] __main__: train step 17324: loss: 1.0159, policy_loss: 0.9620, value_loss: 0.5047
2024-07-14 07:00:08,281 [INFO    ] __main__: train step 17325: loss: 1.0159, policy_loss: 0.9620, value_loss: 0.5047
2024-07-14 07:00:08,580 [INFO    ] __main__: train step 17326: loss: 1.0159, policy_loss: 0.9620, value_loss: 0.5046
2024-07-14 07:00:08,869 [INFO    ] __main__: train step 17327: loss: 1.0159, policy_loss: 0.9620, value_loss: 0.5046
2024-07-14 07:00:09,153 [INFO    ] __main__: train step 17328: loss: 1.0159, policy_loss: 0.9619, value_loss: 0.5046
2024-07-14 07:00:09,436 [INFO    ] __main__: train step 17329: loss: 1.0159, policy_loss: 0.9619, value_loss: 0.5046
2024-07-14 07:00:09,736 [INFO    ] __main__: train step 17330: loss: 1.0158, policy_loss: 0.9619, value_loss: 0.5045
2024-07-14 07:00:10,039 [INFO    ] __main__: train step 17331: loss: 1.0158, policy_loss: 0.9619, value_loss: 0.5045
2024-07-14 07:00:10,330 [INFO    ] __main__: train step 17332: loss: 1.0158, policy_loss: 0.9619, value_loss: 0.5045
2024-07-14 07:00:10,622 [INFO    ] __main__: train step 17333: loss: 1.0158, policy_loss: 0.9619, value_loss: 0.5045
2024-07-14 07:00:10,899 [INFO    ] __main__: train step 17334: loss: 1.0158, policy_loss: 0.9618, value_loss: 0.5044
2024-07-14 07:00:11,180 [INFO    ] __main__: train step 17335: loss: 1.0158, policy_loss: 0.9618, value_loss: 0.5044
2024-07-14 07:00:11,463 [INFO    ] __main__: train step 17336: loss: 1.0157, policy_loss: 0.9618, value_loss: 0.5044
2024-07-14 07:00:13,076 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:00:13,553 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:00:13,624 [INFO    ] __main__: train step 17337: loss: 1.0157, policy_loss: 0.9618, value_loss: 0.5044
2024-07-14 07:00:13,894 [INFO    ] __main__: train step 17338: loss: 1.0157, policy_loss: 0.9618, value_loss: 0.5043
2024-07-14 07:00:14,186 [INFO    ] __main__: train step 17339: loss: 1.0157, policy_loss: 0.9618, value_loss: 0.5043
2024-07-14 07:00:14,491 [INFO    ] __main__: train step 17340: loss: 1.0157, policy_loss: 0.9617, value_loss: 0.5043
2024-07-14 07:00:14,781 [INFO    ] __main__: train step 17341: loss: 1.0157, policy_loss: 0.9617, value_loss: 0.5043
2024-07-14 07:00:15,077 [INFO    ] __main__: train step 17342: loss: 1.0157, policy_loss: 0.9617, value_loss: 0.5043
2024-07-14 07:00:15,367 [INFO    ] __main__: train step 17343: loss: 1.0156, policy_loss: 0.9617, value_loss: 0.5042
2024-07-14 07:00:15,665 [INFO    ] __main__: train step 17344: loss: 1.0156, policy_loss: 0.9617, value_loss: 0.5042
2024-07-14 07:00:15,964 [INFO    ] __main__: train step 17345: loss: 1.0156, policy_loss: 0.9616, value_loss: 0.5042
2024-07-14 07:00:16,270 [INFO    ] __main__: train step 17346: loss: 1.0156, policy_loss: 0.9616, value_loss: 0.5042
2024-07-14 07:00:16,569 [INFO    ] __main__: train step 17347: loss: 1.0156, policy_loss: 0.9616, value_loss: 0.5041
2024-07-14 07:00:16,854 [INFO    ] __main__: train step 17348: loss: 1.0156, policy_loss: 0.9616, value_loss: 0.5041
2024-07-14 07:00:17,146 [INFO    ] __main__: train step 17349: loss: 1.0155, policy_loss: 0.9616, value_loss: 0.5041
2024-07-14 07:00:17,441 [INFO    ] __main__: train step 17350: loss: 1.0155, policy_loss: 0.9616, value_loss: 0.5041
2024-07-14 07:00:17,750 [INFO    ] __main__: train step 17351: loss: 1.0155, policy_loss: 0.9615, value_loss: 0.5040
2024-07-14 07:00:18,041 [INFO    ] __main__: train step 17352: loss: 1.0155, policy_loss: 0.9615, value_loss: 0.5040
2024-07-14 07:00:18,318 [INFO    ] __main__: train step 17353: loss: 1.0155, policy_loss: 0.9615, value_loss: 0.5040
2024-07-14 07:00:19,920 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:00:20,404 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:00:20,476 [INFO    ] __main__: train step 17354: loss: 1.0155, policy_loss: 0.9615, value_loss: 0.5040
2024-07-14 07:00:20,765 [INFO    ] __main__: train step 17355: loss: 1.0154, policy_loss: 0.9615, value_loss: 0.5039
2024-07-14 07:00:21,073 [INFO    ] __main__: train step 17356: loss: 1.0154, policy_loss: 0.9615, value_loss: 0.5039
2024-07-14 07:00:21,351 [INFO    ] __main__: train step 17357: loss: 1.0154, policy_loss: 0.9614, value_loss: 0.5039
2024-07-14 07:00:21,623 [INFO    ] __main__: train step 17358: loss: 1.0154, policy_loss: 0.9614, value_loss: 0.5039
2024-07-14 07:00:21,924 [INFO    ] __main__: train step 17359: loss: 1.0154, policy_loss: 0.9614, value_loss: 0.5038
2024-07-14 07:00:22,215 [INFO    ] __main__: train step 17360: loss: 1.0154, policy_loss: 0.9614, value_loss: 0.5038
2024-07-14 07:00:22,511 [INFO    ] __main__: train step 17361: loss: 1.0154, policy_loss: 0.9614, value_loss: 0.5038
2024-07-14 07:00:22,806 [INFO    ] __main__: train step 17362: loss: 1.0153, policy_loss: 0.9613, value_loss: 0.5038
2024-07-14 07:00:23,064 [INFO    ] __main__: train step 17363: loss: 1.0153, policy_loss: 0.9613, value_loss: 0.5037
2024-07-14 07:00:23,329 [INFO    ] __main__: train step 17364: loss: 1.0153, policy_loss: 0.9613, value_loss: 0.5037
2024-07-14 07:00:23,597 [INFO    ] __main__: train step 17365: loss: 1.0153, policy_loss: 0.9613, value_loss: 0.5037
2024-07-14 07:00:23,871 [INFO    ] __main__: train step 17366: loss: 1.0153, policy_loss: 0.9613, value_loss: 0.5037
2024-07-14 07:00:24,156 [INFO    ] __main__: train step 17367: loss: 1.0153, policy_loss: 0.9613, value_loss: 0.5037
2024-07-14 07:00:24,446 [INFO    ] __main__: train step 17368: loss: 1.0153, policy_loss: 0.9612, value_loss: 0.5036
2024-07-14 07:00:24,729 [INFO    ] __main__: train step 17369: loss: 1.0152, policy_loss: 0.9612, value_loss: 0.5036
2024-07-14 07:00:25,016 [INFO    ] __main__: train step 17370: loss: 1.0152, policy_loss: 0.9612, value_loss: 0.5036
2024-07-14 07:00:26,627 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:00:27,098 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:00:27,172 [INFO    ] __main__: train step 17371: loss: 1.0152, policy_loss: 0.9612, value_loss: 0.5036
2024-07-14 07:00:27,454 [INFO    ] __main__: train step 17372: loss: 1.0152, policy_loss: 0.9612, value_loss: 0.5035
2024-07-14 07:00:27,717 [INFO    ] __main__: train step 17373: loss: 1.0152, policy_loss: 0.9612, value_loss: 0.5035
2024-07-14 07:00:28,004 [INFO    ] __main__: train step 17374: loss: 1.0152, policy_loss: 0.9611, value_loss: 0.5035
2024-07-14 07:00:28,280 [INFO    ] __main__: train step 17375: loss: 1.0151, policy_loss: 0.9611, value_loss: 0.5035
2024-07-14 07:00:28,556 [INFO    ] __main__: train step 17376: loss: 1.0151, policy_loss: 0.9611, value_loss: 0.5034
2024-07-14 07:00:28,853 [INFO    ] __main__: train step 17377: loss: 1.0151, policy_loss: 0.9611, value_loss: 0.5034
2024-07-14 07:00:29,126 [INFO    ] __main__: train step 17378: loss: 1.0151, policy_loss: 0.9611, value_loss: 0.5034
2024-07-14 07:00:29,406 [INFO    ] __main__: train step 17379: loss: 1.0151, policy_loss: 0.9611, value_loss: 0.5034
2024-07-14 07:00:29,703 [INFO    ] __main__: train step 17380: loss: 1.0151, policy_loss: 0.9610, value_loss: 0.5033
2024-07-14 07:00:29,991 [INFO    ] __main__: train step 17381: loss: 1.0151, policy_loss: 0.9610, value_loss: 0.5033
2024-07-14 07:00:30,295 [INFO    ] __main__: train step 17382: loss: 1.0150, policy_loss: 0.9610, value_loss: 0.5033
2024-07-14 07:00:30,576 [INFO    ] __main__: train step 17383: loss: 1.0150, policy_loss: 0.9610, value_loss: 0.5033
2024-07-14 07:00:30,846 [INFO    ] __main__: train step 17384: loss: 1.0150, policy_loss: 0.9610, value_loss: 0.5033
2024-07-14 07:00:31,117 [INFO    ] __main__: train step 17385: loss: 1.0150, policy_loss: 0.9609, value_loss: 0.5032
2024-07-14 07:00:31,403 [INFO    ] __main__: train step 17386: loss: 1.0150, policy_loss: 0.9609, value_loss: 0.5032
2024-07-14 07:00:31,698 [INFO    ] __main__: train step 17387: loss: 1.0150, policy_loss: 0.9609, value_loss: 0.5032
2024-07-14 07:00:33,303 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:00:33,787 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:00:33,859 [INFO    ] __main__: train step 17388: loss: 1.0149, policy_loss: 0.9609, value_loss: 0.5032
2024-07-14 07:00:34,136 [INFO    ] __main__: train step 17389: loss: 1.0149, policy_loss: 0.9609, value_loss: 0.5031
2024-07-14 07:00:34,425 [INFO    ] __main__: train step 17390: loss: 1.0149, policy_loss: 0.9609, value_loss: 0.5031
2024-07-14 07:00:34,709 [INFO    ] __main__: train step 17391: loss: 1.0149, policy_loss: 0.9608, value_loss: 0.5031
2024-07-14 07:00:34,997 [INFO    ] __main__: train step 17392: loss: 1.0149, policy_loss: 0.9608, value_loss: 0.5031
2024-07-14 07:00:35,312 [INFO    ] __main__: train step 17393: loss: 1.0149, policy_loss: 0.9608, value_loss: 0.5030
2024-07-14 07:00:35,606 [INFO    ] __main__: train step 17394: loss: 1.0149, policy_loss: 0.9608, value_loss: 0.5030
2024-07-14 07:00:39,221 [INFO    ] __main__: train step 17395: loss: 1.0148, policy_loss: 0.9608, value_loss: 0.5030
2024-07-14 07:00:39,509 [INFO    ] __main__: train step 17396: loss: 1.0148, policy_loss: 0.9608, value_loss: 0.5030
2024-07-14 07:00:39,794 [INFO    ] __main__: train step 17397: loss: 1.0148, policy_loss: 0.9607, value_loss: 0.5029
2024-07-14 07:00:40,109 [INFO    ] __main__: train step 17398: loss: 1.0148, policy_loss: 0.9607, value_loss: 0.5029
2024-07-14 07:00:40,375 [INFO    ] __main__: train step 17399: loss: 1.0148, policy_loss: 0.9607, value_loss: 0.5029
2024-07-14 07:00:40,685 [INFO    ] __main__: train step 17400: loss: 1.0148, policy_loss: 0.9607, value_loss: 0.5029
2024-07-14 07:00:40,981 [INFO    ] __main__: train step 17401: loss: 1.0148, policy_loss: 0.9607, value_loss: 0.5029
2024-07-14 07:00:41,266 [INFO    ] __main__: train step 17402: loss: 1.0147, policy_loss: 0.9607, value_loss: 0.5028
2024-07-14 07:00:41,561 [INFO    ] __main__: train step 17403: loss: 1.0147, policy_loss: 0.9606, value_loss: 0.5028
2024-07-14 07:00:41,828 [INFO    ] __main__: train step 17404: loss: 1.0147, policy_loss: 0.9606, value_loss: 0.5028
2024-07-14 07:00:43,459 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:00:43,951 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:00:44,022 [INFO    ] __main__: train step 17405: loss: 1.0147, policy_loss: 0.9606, value_loss: 0.5028
2024-07-14 07:00:44,323 [INFO    ] __main__: train step 17406: loss: 1.0147, policy_loss: 0.9606, value_loss: 0.5027
2024-07-14 07:00:44,634 [INFO    ] __main__: train step 17407: loss: 1.0147, policy_loss: 0.9606, value_loss: 0.5027
2024-07-14 07:00:44,905 [INFO    ] __main__: train step 17408: loss: 1.0147, policy_loss: 0.9606, value_loss: 0.5027
2024-07-14 07:00:45,175 [INFO    ] __main__: train step 17409: loss: 1.0146, policy_loss: 0.9605, value_loss: 0.5027
2024-07-14 07:00:45,470 [INFO    ] __main__: train step 17410: loss: 1.0146, policy_loss: 0.9605, value_loss: 0.5026
2024-07-14 07:00:45,764 [INFO    ] __main__: train step 17411: loss: 1.0146, policy_loss: 0.9605, value_loss: 0.5026
2024-07-14 07:00:46,065 [INFO    ] __main__: train step 17412: loss: 1.0146, policy_loss: 0.9605, value_loss: 0.5026
2024-07-14 07:00:46,318 [INFO    ] __main__: train step 17413: loss: 1.0146, policy_loss: 0.9605, value_loss: 0.5026
2024-07-14 07:00:46,626 [INFO    ] __main__: train step 17414: loss: 1.0146, policy_loss: 0.9604, value_loss: 0.5025
2024-07-14 07:00:46,902 [INFO    ] __main__: train step 17415: loss: 1.0145, policy_loss: 0.9604, value_loss: 0.5025
2024-07-14 07:00:47,178 [INFO    ] __main__: train step 17416: loss: 1.0145, policy_loss: 0.9604, value_loss: 0.5025
2024-07-14 07:00:47,473 [INFO    ] __main__: train step 17417: loss: 1.0145, policy_loss: 0.9604, value_loss: 0.5025
2024-07-14 07:00:47,769 [INFO    ] __main__: train step 17418: loss: 1.0145, policy_loss: 0.9604, value_loss: 0.5025
2024-07-14 07:00:48,047 [INFO    ] __main__: train step 17419: loss: 1.0145, policy_loss: 0.9604, value_loss: 0.5024
2024-07-14 07:00:48,301 [INFO    ] __main__: train step 17420: loss: 1.0145, policy_loss: 0.9603, value_loss: 0.5024
2024-07-14 07:00:48,567 [INFO    ] __main__: train step 17421: loss: 1.0145, policy_loss: 0.9603, value_loss: 0.5024
2024-07-14 07:00:50,193 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:00:50,678 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:00:50,748 [INFO    ] __main__: train step 17422: loss: 1.0144, policy_loss: 0.9603, value_loss: 0.5024
2024-07-14 07:00:51,031 [INFO    ] __main__: train step 17423: loss: 1.0144, policy_loss: 0.9603, value_loss: 0.5023
2024-07-14 07:00:51,279 [INFO    ] __main__: train step 17424: loss: 1.0144, policy_loss: 0.9603, value_loss: 0.5023
2024-07-14 07:00:51,566 [INFO    ] __main__: train step 17425: loss: 1.0144, policy_loss: 0.9603, value_loss: 0.5023
2024-07-14 07:00:51,833 [INFO    ] __main__: train step 17426: loss: 1.0144, policy_loss: 0.9602, value_loss: 0.5023
2024-07-14 07:00:52,119 [INFO    ] __main__: train step 17427: loss: 1.0144, policy_loss: 0.9602, value_loss: 0.5022
2024-07-14 07:00:52,396 [INFO    ] __main__: train step 17428: loss: 1.0144, policy_loss: 0.9602, value_loss: 0.5022
2024-07-14 07:00:52,705 [INFO    ] __main__: train step 17429: loss: 1.0143, policy_loss: 0.9602, value_loss: 0.5022
2024-07-14 07:00:52,999 [INFO    ] __main__: train step 17430: loss: 1.0143, policy_loss: 0.9602, value_loss: 0.5022
2024-07-14 07:00:53,301 [INFO    ] __main__: train step 17431: loss: 1.0143, policy_loss: 0.9602, value_loss: 0.5021
2024-07-14 07:00:53,596 [INFO    ] __main__: train step 17432: loss: 1.0143, policy_loss: 0.9601, value_loss: 0.5021
2024-07-14 07:00:53,881 [INFO    ] __main__: train step 17433: loss: 1.0143, policy_loss: 0.9601, value_loss: 0.5021
2024-07-14 07:00:54,160 [INFO    ] __main__: train step 17434: loss: 1.0143, policy_loss: 0.9601, value_loss: 0.5021
2024-07-14 07:00:54,450 [INFO    ] __main__: train step 17435: loss: 1.0143, policy_loss: 0.9601, value_loss: 0.5021
2024-07-14 07:00:54,755 [INFO    ] __main__: train step 17436: loss: 1.0142, policy_loss: 0.9601, value_loss: 0.5020
2024-07-14 07:00:55,050 [INFO    ] __main__: train step 17437: loss: 1.0142, policy_loss: 0.9601, value_loss: 0.5020
2024-07-14 07:00:55,351 [INFO    ] __main__: train step 17438: loss: 1.0142, policy_loss: 0.9600, value_loss: 0.5020
2024-07-14 07:00:56,966 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:00:57,417 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:00:57,485 [INFO    ] __main__: train step 17439: loss: 1.0142, policy_loss: 0.9600, value_loss: 0.5020
2024-07-14 07:00:57,774 [INFO    ] __main__: train step 17440: loss: 1.0142, policy_loss: 0.9600, value_loss: 0.5019
2024-07-14 07:00:58,060 [INFO    ] __main__: train step 17441: loss: 1.0142, policy_loss: 0.9600, value_loss: 0.5019
2024-07-14 07:00:58,359 [INFO    ] __main__: train step 17442: loss: 1.0141, policy_loss: 0.9600, value_loss: 0.5019
2024-07-14 07:00:58,658 [INFO    ] __main__: train step 17443: loss: 1.0141, policy_loss: 0.9600, value_loss: 0.5019
2024-07-14 07:00:58,939 [INFO    ] __main__: train step 17444: loss: 1.0141, policy_loss: 0.9599, value_loss: 0.5018
2024-07-14 07:00:59,210 [INFO    ] __main__: train step 17445: loss: 1.0141, policy_loss: 0.9599, value_loss: 0.5018
2024-07-14 07:00:59,491 [INFO    ] __main__: train step 17446: loss: 1.0141, policy_loss: 0.9599, value_loss: 0.5018
2024-07-14 07:00:59,782 [INFO    ] __main__: train step 17447: loss: 1.0141, policy_loss: 0.9599, value_loss: 0.5018
2024-07-14 07:01:00,068 [INFO    ] __main__: train step 17448: loss: 1.0141, policy_loss: 0.9599, value_loss: 0.5017
2024-07-14 07:01:00,357 [INFO    ] __main__: train step 17449: loss: 1.0140, policy_loss: 0.9599, value_loss: 0.5017
2024-07-14 07:01:00,623 [INFO    ] __main__: train step 17450: loss: 1.0140, policy_loss: 0.9598, value_loss: 0.5017
2024-07-14 07:01:00,884 [INFO    ] __main__: train step 17451: loss: 1.0140, policy_loss: 0.9598, value_loss: 0.5017
2024-07-14 07:01:01,165 [INFO    ] __main__: train step 17452: loss: 1.0140, policy_loss: 0.9598, value_loss: 0.5016
2024-07-14 07:01:01,460 [INFO    ] __main__: train step 17453: loss: 1.0140, policy_loss: 0.9598, value_loss: 0.5016
2024-07-14 07:01:01,758 [INFO    ] __main__: train step 17454: loss: 1.0140, policy_loss: 0.9598, value_loss: 0.5016
2024-07-14 07:01:02,044 [INFO    ] __main__: train step 17455: loss: 1.0139, policy_loss: 0.9597, value_loss: 0.5016
2024-07-14 07:01:03,630 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:01:04,105 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:01:04,171 [INFO    ] __main__: train step 17456: loss: 1.0139, policy_loss: 0.9597, value_loss: 0.5016
2024-07-14 07:01:04,471 [INFO    ] __main__: train step 17457: loss: 1.0139, policy_loss: 0.9597, value_loss: 0.5015
2024-07-14 07:01:04,764 [INFO    ] __main__: train step 17458: loss: 1.0139, policy_loss: 0.9597, value_loss: 0.5015
2024-07-14 07:01:05,063 [INFO    ] __main__: train step 17459: loss: 1.0139, policy_loss: 0.9597, value_loss: 0.5015
2024-07-14 07:01:05,337 [INFO    ] __main__: train step 17460: loss: 1.0139, policy_loss: 0.9597, value_loss: 0.5015
2024-07-14 07:01:05,614 [INFO    ] __main__: train step 17461: loss: 1.0138, policy_loss: 0.9596, value_loss: 0.5014
2024-07-14 07:01:05,902 [INFO    ] __main__: train step 17462: loss: 1.0138, policy_loss: 0.9596, value_loss: 0.5014
2024-07-14 07:01:06,195 [INFO    ] __main__: train step 17463: loss: 1.0138, policy_loss: 0.9596, value_loss: 0.5014
2024-07-14 07:01:06,502 [INFO    ] __main__: train step 17464: loss: 1.0138, policy_loss: 0.9596, value_loss: 0.5014
2024-07-14 07:01:06,803 [INFO    ] __main__: train step 17465: loss: 1.0138, policy_loss: 0.9596, value_loss: 0.5013
2024-07-14 07:01:07,069 [INFO    ] __main__: train step 17466: loss: 1.0138, policy_loss: 0.9596, value_loss: 0.5013
2024-07-14 07:01:07,359 [INFO    ] __main__: train step 17467: loss: 1.0138, policy_loss: 0.9595, value_loss: 0.5013
2024-07-14 07:01:07,663 [INFO    ] __main__: train step 17468: loss: 1.0137, policy_loss: 0.9595, value_loss: 0.5013
2024-07-14 07:01:07,968 [INFO    ] __main__: train step 17469: loss: 1.0137, policy_loss: 0.9595, value_loss: 0.5012
2024-07-14 07:01:08,259 [INFO    ] __main__: train step 17470: loss: 1.0137, policy_loss: 0.9595, value_loss: 0.5012
2024-07-14 07:01:08,531 [INFO    ] __main__: train step 17471: loss: 1.0137, policy_loss: 0.9595, value_loss: 0.5012
2024-07-14 07:01:08,790 [INFO    ] __main__: train step 17472: loss: 1.0137, policy_loss: 0.9595, value_loss: 0.5012
2024-07-14 07:01:10,396 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:01:10,883 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:01:10,953 [INFO    ] __main__: train step 17473: loss: 1.0137, policy_loss: 0.9594, value_loss: 0.5011
2024-07-14 07:01:11,256 [INFO    ] __main__: train step 17474: loss: 1.0136, policy_loss: 0.9594, value_loss: 0.5011
2024-07-14 07:01:11,541 [INFO    ] __main__: train step 17475: loss: 1.0136, policy_loss: 0.9594, value_loss: 0.5011
2024-07-14 07:01:11,820 [INFO    ] __main__: train step 17476: loss: 1.0136, policy_loss: 0.9594, value_loss: 0.5011
2024-07-14 07:01:12,097 [INFO    ] __main__: train step 17477: loss: 1.0136, policy_loss: 0.9594, value_loss: 0.5011
2024-07-14 07:01:12,396 [INFO    ] __main__: train step 17478: loss: 1.0136, policy_loss: 0.9593, value_loss: 0.5010
2024-07-14 07:01:12,688 [INFO    ] __main__: train step 17479: loss: 1.0136, policy_loss: 0.9593, value_loss: 0.5010
2024-07-14 07:01:12,984 [INFO    ] __main__: train step 17480: loss: 1.0136, policy_loss: 0.9593, value_loss: 0.5010
2024-07-14 07:01:13,263 [INFO    ] __main__: train step 17481: loss: 1.0135, policy_loss: 0.9593, value_loss: 0.5010
2024-07-14 07:01:13,524 [INFO    ] __main__: train step 17482: loss: 1.0135, policy_loss: 0.9593, value_loss: 0.5009
2024-07-14 07:01:13,819 [INFO    ] __main__: train step 17483: loss: 1.0135, policy_loss: 0.9593, value_loss: 0.5009
2024-07-14 07:01:14,108 [INFO    ] __main__: train step 17484: loss: 1.0135, policy_loss: 0.9592, value_loss: 0.5009
2024-07-14 07:01:14,395 [INFO    ] __main__: train step 17485: loss: 1.0135, policy_loss: 0.9592, value_loss: 0.5009
2024-07-14 07:01:14,702 [INFO    ] __main__: train step 17486: loss: 1.0135, policy_loss: 0.9592, value_loss: 0.5008
2024-07-14 07:01:14,963 [INFO    ] __main__: train step 17487: loss: 1.0135, policy_loss: 0.9592, value_loss: 0.5008
2024-07-14 07:01:15,253 [INFO    ] __main__: train step 17488: loss: 1.0134, policy_loss: 0.9592, value_loss: 0.5008
2024-07-14 07:01:15,529 [INFO    ] __main__: train step 17489: loss: 1.0134, policy_loss: 0.9592, value_loss: 0.5008
2024-07-14 07:01:17,150 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:01:17,624 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:01:17,695 [INFO    ] __main__: train step 17490: loss: 1.0134, policy_loss: 0.9591, value_loss: 0.5008
2024-07-14 07:01:17,973 [INFO    ] __main__: train step 17491: loss: 1.0134, policy_loss: 0.9591, value_loss: 0.5007
2024-07-14 07:01:18,256 [INFO    ] __main__: train step 17492: loss: 1.0134, policy_loss: 0.9591, value_loss: 0.5007
2024-07-14 07:01:18,543 [INFO    ] __main__: train step 17493: loss: 1.0134, policy_loss: 0.9591, value_loss: 0.5007
2024-07-14 07:01:18,831 [INFO    ] __main__: train step 17494: loss: 1.0133, policy_loss: 0.9591, value_loss: 0.5007
2024-07-14 07:01:19,128 [INFO    ] __main__: train step 17495: loss: 1.0133, policy_loss: 0.9591, value_loss: 0.5006
2024-07-14 07:01:19,428 [INFO    ] __main__: train step 17496: loss: 1.0133, policy_loss: 0.9590, value_loss: 0.5006
2024-07-14 07:01:19,713 [INFO    ] __main__: train step 17497: loss: 1.0133, policy_loss: 0.9590, value_loss: 0.5006
2024-07-14 07:01:23,283 [INFO    ] __main__: train step 17498: loss: 1.0133, policy_loss: 0.9590, value_loss: 0.5006
2024-07-14 07:01:23,584 [INFO    ] __main__: train step 17499: loss: 1.0133, policy_loss: 0.9590, value_loss: 0.5005
2024-07-14 07:01:23,889 [INFO    ] __main__: train step 17500: loss: 1.0133, policy_loss: 0.9590, value_loss: 0.5005
2024-07-14 07:01:24,196 [INFO    ] __main__: train step 17501: loss: 1.0132, policy_loss: 0.9590, value_loss: 0.5005
2024-07-14 07:01:24,475 [INFO    ] __main__: train step 17502: loss: 1.0132, policy_loss: 0.9589, value_loss: 0.5005
2024-07-14 07:01:24,764 [INFO    ] __main__: train step 17503: loss: 1.0132, policy_loss: 0.9589, value_loss: 0.5005
2024-07-14 07:01:25,058 [INFO    ] __main__: train step 17504: loss: 1.0132, policy_loss: 0.9589, value_loss: 0.5004
2024-07-14 07:01:25,363 [INFO    ] __main__: train step 17505: loss: 1.0132, policy_loss: 0.9589, value_loss: 0.5004
2024-07-14 07:01:25,664 [INFO    ] __main__: train step 17506: loss: 1.0132, policy_loss: 0.9589, value_loss: 0.5004
2024-07-14 07:01:27,249 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:01:27,742 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:01:27,811 [INFO    ] __main__: train step 17507: loss: 1.0132, policy_loss: 0.9589, value_loss: 0.5004
2024-07-14 07:01:28,093 [INFO    ] __main__: train step 17508: loss: 1.0131, policy_loss: 0.9588, value_loss: 0.5003
2024-07-14 07:01:28,387 [INFO    ] __main__: train step 17509: loss: 1.0131, policy_loss: 0.9588, value_loss: 0.5003
2024-07-14 07:01:28,678 [INFO    ] __main__: train step 17510: loss: 1.0131, policy_loss: 0.9588, value_loss: 0.5003
2024-07-14 07:01:28,966 [INFO    ] __main__: train step 17511: loss: 1.0131, policy_loss: 0.9588, value_loss: 0.5003
2024-07-14 07:01:29,250 [INFO    ] __main__: train step 17512: loss: 1.0131, policy_loss: 0.9588, value_loss: 0.5002
2024-07-14 07:01:29,524 [INFO    ] __main__: train step 17513: loss: 1.0131, policy_loss: 0.9588, value_loss: 0.5002
2024-07-14 07:01:29,809 [INFO    ] __main__: train step 17514: loss: 1.0131, policy_loss: 0.9587, value_loss: 0.5002
2024-07-14 07:01:30,105 [INFO    ] __main__: train step 17515: loss: 1.0130, policy_loss: 0.9587, value_loss: 0.5002
2024-07-14 07:01:30,401 [INFO    ] __main__: train step 17516: loss: 1.0130, policy_loss: 0.9587, value_loss: 0.5002
2024-07-14 07:01:30,676 [INFO    ] __main__: train step 17517: loss: 1.0130, policy_loss: 0.9587, value_loss: 0.5001
2024-07-14 07:01:30,950 [INFO    ] __main__: train step 17518: loss: 1.0130, policy_loss: 0.9587, value_loss: 0.5001
2024-07-14 07:01:31,207 [INFO    ] __main__: train step 17519: loss: 1.0130, policy_loss: 0.9587, value_loss: 0.5001
2024-07-14 07:01:31,484 [INFO    ] __main__: train step 17520: loss: 1.0130, policy_loss: 0.9586, value_loss: 0.5001
2024-07-14 07:01:31,788 [INFO    ] __main__: train step 17521: loss: 1.0130, policy_loss: 0.9586, value_loss: 0.5000
2024-07-14 07:01:32,086 [INFO    ] __main__: train step 17522: loss: 1.0129, policy_loss: 0.9586, value_loss: 0.5000
2024-07-14 07:01:32,387 [INFO    ] __main__: train step 17523: loss: 1.0129, policy_loss: 0.9586, value_loss: 0.5000
2024-07-14 07:01:33,992 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:01:34,475 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:01:34,544 [INFO    ] __main__: train step 17524: loss: 1.0129, policy_loss: 0.9586, value_loss: 0.5000
2024-07-14 07:01:34,834 [INFO    ] __main__: train step 17525: loss: 1.0129, policy_loss: 0.9586, value_loss: 0.4999
2024-07-14 07:01:35,124 [INFO    ] __main__: train step 17526: loss: 1.0129, policy_loss: 0.9585, value_loss: 0.4999
2024-07-14 07:01:35,415 [INFO    ] __main__: train step 17527: loss: 1.0129, policy_loss: 0.9585, value_loss: 0.4999
2024-07-14 07:01:35,685 [INFO    ] __main__: train step 17528: loss: 1.0129, policy_loss: 0.9585, value_loss: 0.4999
2024-07-14 07:01:35,970 [INFO    ] __main__: train step 17529: loss: 1.0128, policy_loss: 0.9585, value_loss: 0.4998
2024-07-14 07:01:36,256 [INFO    ] __main__: train step 17530: loss: 1.0128, policy_loss: 0.9585, value_loss: 0.4998
2024-07-14 07:01:36,559 [INFO    ] __main__: train step 17531: loss: 1.0128, policy_loss: 0.9585, value_loss: 0.4998
2024-07-14 07:01:36,852 [INFO    ] __main__: train step 17532: loss: 1.0128, policy_loss: 0.9584, value_loss: 0.4998
2024-07-14 07:01:37,139 [INFO    ] __main__: train step 17533: loss: 1.0128, policy_loss: 0.9584, value_loss: 0.4998
2024-07-14 07:01:37,426 [INFO    ] __main__: train step 17534: loss: 1.0128, policy_loss: 0.9584, value_loss: 0.4997
2024-07-14 07:01:37,718 [INFO    ] __main__: train step 17535: loss: 1.0128, policy_loss: 0.9584, value_loss: 0.4997
2024-07-14 07:01:38,009 [INFO    ] __main__: train step 17536: loss: 1.0127, policy_loss: 0.9584, value_loss: 0.4997
2024-07-14 07:01:38,307 [INFO    ] __main__: train step 17537: loss: 1.0127, policy_loss: 0.9584, value_loss: 0.4997
2024-07-14 07:01:38,579 [INFO    ] __main__: train step 17538: loss: 1.0127, policy_loss: 0.9583, value_loss: 0.4996
2024-07-14 07:01:38,837 [INFO    ] __main__: train step 17539: loss: 1.0127, policy_loss: 0.9583, value_loss: 0.4996
2024-07-14 07:01:39,106 [INFO    ] __main__: train step 17540: loss: 1.0127, policy_loss: 0.9583, value_loss: 0.4996
2024-07-14 07:01:40,713 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:01:41,193 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:01:41,266 [INFO    ] __main__: train step 17541: loss: 1.0127, policy_loss: 0.9583, value_loss: 0.4996
2024-07-14 07:01:41,567 [INFO    ] __main__: train step 17542: loss: 1.0127, policy_loss: 0.9583, value_loss: 0.4995
2024-07-14 07:01:41,855 [INFO    ] __main__: train step 17543: loss: 1.0126, policy_loss: 0.9583, value_loss: 0.4995
2024-07-14 07:01:42,144 [INFO    ] __main__: train step 17544: loss: 1.0126, policy_loss: 0.9582, value_loss: 0.4995
2024-07-14 07:01:42,446 [INFO    ] __main__: train step 17545: loss: 1.0126, policy_loss: 0.9582, value_loss: 0.4995
2024-07-14 07:01:42,739 [INFO    ] __main__: train step 17546: loss: 1.0126, policy_loss: 0.9582, value_loss: 0.4995
2024-07-14 07:01:43,031 [INFO    ] __main__: train step 17547: loss: 1.0126, policy_loss: 0.9582, value_loss: 0.4994
2024-07-14 07:01:43,324 [INFO    ] __main__: train step 17548: loss: 1.0126, policy_loss: 0.9582, value_loss: 0.4994
2024-07-14 07:01:43,587 [INFO    ] __main__: train step 17549: loss: 1.0126, policy_loss: 0.9582, value_loss: 0.4994
2024-07-14 07:01:43,875 [INFO    ] __main__: train step 17550: loss: 1.0125, policy_loss: 0.9581, value_loss: 0.4994
2024-07-14 07:01:44,178 [INFO    ] __main__: train step 17551: loss: 1.0125, policy_loss: 0.9581, value_loss: 0.4993
2024-07-14 07:01:44,479 [INFO    ] __main__: train step 17552: loss: 1.0125, policy_loss: 0.9581, value_loss: 0.4993
2024-07-14 07:01:44,768 [INFO    ] __main__: train step 17553: loss: 1.0125, policy_loss: 0.9581, value_loss: 0.4993
2024-07-14 07:01:45,053 [INFO    ] __main__: train step 17554: loss: 1.0125, policy_loss: 0.9581, value_loss: 0.4993
2024-07-14 07:01:45,307 [INFO    ] __main__: train step 17555: loss: 1.0125, policy_loss: 0.9581, value_loss: 0.4992
2024-07-14 07:01:45,599 [INFO    ] __main__: train step 17556: loss: 1.0125, policy_loss: 0.9580, value_loss: 0.4992
2024-07-14 07:01:45,893 [INFO    ] __main__: train step 17557: loss: 1.0124, policy_loss: 0.9580, value_loss: 0.4992
2024-07-14 07:01:47,521 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:01:47,992 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:01:48,060 [INFO    ] __main__: train step 17558: loss: 1.0124, policy_loss: 0.9580, value_loss: 0.4992
2024-07-14 07:01:48,348 [INFO    ] __main__: train step 17559: loss: 1.0124, policy_loss: 0.9580, value_loss: 0.4992
2024-07-14 07:01:48,645 [INFO    ] __main__: train step 17560: loss: 1.0124, policy_loss: 0.9580, value_loss: 0.4991
2024-07-14 07:01:48,951 [INFO    ] __main__: train step 17561: loss: 1.0124, policy_loss: 0.9580, value_loss: 0.4991
2024-07-14 07:01:49,250 [INFO    ] __main__: train step 17562: loss: 1.0124, policy_loss: 0.9579, value_loss: 0.4991
2024-07-14 07:01:49,547 [INFO    ] __main__: train step 17563: loss: 1.0124, policy_loss: 0.9579, value_loss: 0.4991
2024-07-14 07:01:49,820 [INFO    ] __main__: train step 17564: loss: 1.0123, policy_loss: 0.9579, value_loss: 0.4990
2024-07-14 07:01:50,115 [INFO    ] __main__: train step 17565: loss: 1.0123, policy_loss: 0.9579, value_loss: 0.4990
2024-07-14 07:01:50,419 [INFO    ] __main__: train step 17566: loss: 1.0123, policy_loss: 0.9579, value_loss: 0.4990
2024-07-14 07:01:50,719 [INFO    ] __main__: train step 17567: loss: 1.0123, policy_loss: 0.9579, value_loss: 0.4990
2024-07-14 07:01:51,014 [INFO    ] __main__: train step 17568: loss: 1.0123, policy_loss: 0.9578, value_loss: 0.4989
2024-07-14 07:01:51,330 [INFO    ] __main__: train step 17569: loss: 1.0123, policy_loss: 0.9578, value_loss: 0.4989
2024-07-14 07:01:51,619 [INFO    ] __main__: train step 17570: loss: 1.0123, policy_loss: 0.9578, value_loss: 0.4989
2024-07-14 07:01:51,915 [INFO    ] __main__: train step 17571: loss: 1.0122, policy_loss: 0.9578, value_loss: 0.4989
2024-07-14 07:01:52,225 [INFO    ] __main__: train step 17572: loss: 1.0122, policy_loss: 0.9578, value_loss: 0.4989
2024-07-14 07:01:52,515 [INFO    ] __main__: train step 17573: loss: 1.0122, policy_loss: 0.9578, value_loss: 0.4988
2024-07-14 07:01:52,797 [INFO    ] __main__: train step 17574: loss: 1.0122, policy_loss: 0.9577, value_loss: 0.4988
2024-07-14 07:01:54,404 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:01:54,866 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:01:54,938 [INFO    ] __main__: train step 17575: loss: 1.0122, policy_loss: 0.9577, value_loss: 0.4988
2024-07-14 07:01:55,234 [INFO    ] __main__: train step 17576: loss: 1.0122, policy_loss: 0.9577, value_loss: 0.4988
2024-07-14 07:01:55,529 [INFO    ] __main__: train step 17577: loss: 1.0122, policy_loss: 0.9577, value_loss: 0.4987
2024-07-14 07:01:55,829 [INFO    ] __main__: train step 17578: loss: 1.0121, policy_loss: 0.9577, value_loss: 0.4987
2024-07-14 07:01:56,091 [INFO    ] __main__: train step 17579: loss: 1.0121, policy_loss: 0.9577, value_loss: 0.4987
2024-07-14 07:01:56,356 [INFO    ] __main__: train step 17580: loss: 1.0121, policy_loss: 0.9576, value_loss: 0.4987
2024-07-14 07:01:56,649 [INFO    ] __main__: train step 17581: loss: 1.0121, policy_loss: 0.9576, value_loss: 0.4986
2024-07-14 07:01:56,949 [INFO    ] __main__: train step 17582: loss: 1.0121, policy_loss: 0.9576, value_loss: 0.4986
2024-07-14 07:01:57,232 [INFO    ] __main__: train step 17583: loss: 1.0121, policy_loss: 0.9576, value_loss: 0.4986
2024-07-14 07:01:57,532 [INFO    ] __main__: train step 17584: loss: 1.0121, policy_loss: 0.9576, value_loss: 0.4986
2024-07-14 07:01:57,826 [INFO    ] __main__: train step 17585: loss: 1.0120, policy_loss: 0.9576, value_loss: 0.4986
2024-07-14 07:01:58,118 [INFO    ] __main__: train step 17586: loss: 1.0120, policy_loss: 0.9575, value_loss: 0.4985
2024-07-14 07:01:58,424 [INFO    ] __main__: train step 17587: loss: 1.0120, policy_loss: 0.9575, value_loss: 0.4985
2024-07-14 07:01:58,705 [INFO    ] __main__: train step 17588: loss: 1.0120, policy_loss: 0.9575, value_loss: 0.4985
2024-07-14 07:01:59,006 [INFO    ] __main__: train step 17589: loss: 1.0120, policy_loss: 0.9575, value_loss: 0.4985
2024-07-14 07:01:59,279 [INFO    ] __main__: train step 17590: loss: 1.0120, policy_loss: 0.9575, value_loss: 0.4984
2024-07-14 07:01:59,561 [INFO    ] __main__: train step 17591: loss: 1.0120, policy_loss: 0.9575, value_loss: 0.4984
2024-07-14 07:02:01,188 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:02:01,667 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:02:01,742 [INFO    ] __main__: train step 17592: loss: 1.0119, policy_loss: 0.9574, value_loss: 0.4984
2024-07-14 07:02:02,038 [INFO    ] __main__: train step 17593: loss: 1.0119, policy_loss: 0.9574, value_loss: 0.4984
2024-07-14 07:02:02,308 [INFO    ] __main__: train step 17594: loss: 1.0119, policy_loss: 0.9574, value_loss: 0.4983
2024-07-14 07:02:02,563 [INFO    ] __main__: train step 17595: loss: 1.0119, policy_loss: 0.9574, value_loss: 0.4983
2024-07-14 07:02:02,841 [INFO    ] __main__: train step 17596: loss: 1.0119, policy_loss: 0.9574, value_loss: 0.4983
2024-07-14 07:02:03,113 [INFO    ] __main__: train step 17597: loss: 1.0119, policy_loss: 0.9574, value_loss: 0.4983
2024-07-14 07:02:03,385 [INFO    ] __main__: train step 17598: loss: 1.0119, policy_loss: 0.9573, value_loss: 0.4983
2024-07-14 07:02:03,658 [INFO    ] __main__: train step 17599: loss: 1.0118, policy_loss: 0.9573, value_loss: 0.4982
2024-07-14 07:02:03,923 [INFO    ] __main__: train step 17600: loss: 1.0118, policy_loss: 0.9573, value_loss: 0.4982
2024-07-14 07:02:04,208 [INFO    ] __main__: train step 17601: loss: 1.0118, policy_loss: 0.9573, value_loss: 0.4982
2024-07-14 07:02:07,305 [INFO    ] __main__: train step 17602: loss: 1.0118, policy_loss: 0.9573, value_loss: 0.4982
2024-07-14 07:02:07,571 [INFO    ] __main__: train step 17603: loss: 1.0118, policy_loss: 0.9573, value_loss: 0.4981
2024-07-14 07:02:07,847 [INFO    ] __main__: train step 17604: loss: 1.0118, policy_loss: 0.9572, value_loss: 0.4981
2024-07-14 07:02:08,143 [INFO    ] __main__: train step 17605: loss: 1.0117, policy_loss: 0.9572, value_loss: 0.4981
2024-07-14 07:02:08,439 [INFO    ] __main__: train step 17606: loss: 1.0117, policy_loss: 0.9572, value_loss: 0.4981
2024-07-14 07:02:08,718 [INFO    ] __main__: train step 17607: loss: 1.0117, policy_loss: 0.9572, value_loss: 0.4980
2024-07-14 07:02:08,991 [INFO    ] __main__: train step 17608: loss: 1.0117, policy_loss: 0.9572, value_loss: 0.4980
2024-07-14 07:02:10,607 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:02:11,085 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:02:11,159 [INFO    ] __main__: train step 17609: loss: 1.0117, policy_loss: 0.9572, value_loss: 0.4980
2024-07-14 07:02:11,451 [INFO    ] __main__: train step 17610: loss: 1.0117, policy_loss: 0.9571, value_loss: 0.4980
2024-07-14 07:02:11,739 [INFO    ] __main__: train step 17611: loss: 1.0117, policy_loss: 0.9571, value_loss: 0.4980
2024-07-14 07:02:12,009 [INFO    ] __main__: train step 17612: loss: 1.0116, policy_loss: 0.9571, value_loss: 0.4979
2024-07-14 07:02:12,273 [INFO    ] __main__: train step 17613: loss: 1.0116, policy_loss: 0.9571, value_loss: 0.4979
2024-07-14 07:02:12,587 [INFO    ] __main__: train step 17614: loss: 1.0116, policy_loss: 0.9571, value_loss: 0.4979
2024-07-14 07:02:12,879 [INFO    ] __main__: train step 17615: loss: 1.0116, policy_loss: 0.9571, value_loss: 0.4979
2024-07-14 07:02:13,176 [INFO    ] __main__: train step 17616: loss: 1.0116, policy_loss: 0.9570, value_loss: 0.4978
2024-07-14 07:02:13,448 [INFO    ] __main__: train step 17617: loss: 1.0116, policy_loss: 0.9570, value_loss: 0.4978
2024-07-14 07:02:13,715 [INFO    ] __main__: train step 17618: loss: 1.0116, policy_loss: 0.9570, value_loss: 0.4978
2024-07-14 07:02:14,001 [INFO    ] __main__: train step 17619: loss: 1.0115, policy_loss: 0.9570, value_loss: 0.4978
2024-07-14 07:02:14,282 [INFO    ] __main__: train step 17620: loss: 1.0115, policy_loss: 0.9570, value_loss: 0.4977
2024-07-14 07:02:14,568 [INFO    ] __main__: train step 17621: loss: 1.0115, policy_loss: 0.9570, value_loss: 0.4977
2024-07-14 07:02:14,857 [INFO    ] __main__: train step 17622: loss: 1.0115, policy_loss: 0.9569, value_loss: 0.4977
2024-07-14 07:02:15,125 [INFO    ] __main__: train step 17623: loss: 1.0115, policy_loss: 0.9569, value_loss: 0.4977
2024-07-14 07:02:15,413 [INFO    ] __main__: train step 17624: loss: 1.0115, policy_loss: 0.9569, value_loss: 0.4977
2024-07-14 07:02:15,693 [INFO    ] __main__: train step 17625: loss: 1.0115, policy_loss: 0.9569, value_loss: 0.4976
2024-07-14 07:02:17,270 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:02:17,761 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:02:17,831 [INFO    ] __main__: train step 17626: loss: 1.0114, policy_loss: 0.9569, value_loss: 0.4976
2024-07-14 07:02:18,114 [INFO    ] __main__: train step 17627: loss: 1.0114, policy_loss: 0.9569, value_loss: 0.4976
2024-07-14 07:02:18,374 [INFO    ] __main__: train step 17628: loss: 1.0114, policy_loss: 0.9568, value_loss: 0.4976
2024-07-14 07:02:18,648 [INFO    ] __main__: train step 17629: loss: 1.0114, policy_loss: 0.9568, value_loss: 0.4975
2024-07-14 07:02:18,915 [INFO    ] __main__: train step 17630: loss: 1.0114, policy_loss: 0.9568, value_loss: 0.4975
2024-07-14 07:02:19,206 [INFO    ] __main__: train step 17631: loss: 1.0114, policy_loss: 0.9568, value_loss: 0.4975
2024-07-14 07:02:19,498 [INFO    ] __main__: train step 17632: loss: 1.0114, policy_loss: 0.9568, value_loss: 0.4975
2024-07-14 07:02:19,773 [INFO    ] __main__: train step 17633: loss: 1.0113, policy_loss: 0.9568, value_loss: 0.4974
2024-07-14 07:02:20,050 [INFO    ] __main__: train step 17634: loss: 1.0113, policy_loss: 0.9568, value_loss: 0.4974
2024-07-14 07:02:20,334 [INFO    ] __main__: train step 17635: loss: 1.0113, policy_loss: 0.9567, value_loss: 0.4974
2024-07-14 07:02:20,625 [INFO    ] __main__: train step 17636: loss: 1.0113, policy_loss: 0.9567, value_loss: 0.4974
2024-07-14 07:02:20,901 [INFO    ] __main__: train step 17637: loss: 1.0113, policy_loss: 0.9567, value_loss: 0.4974
2024-07-14 07:02:21,156 [INFO    ] __main__: train step 17638: loss: 1.0113, policy_loss: 0.9567, value_loss: 0.4973
2024-07-14 07:02:21,406 [INFO    ] __main__: train step 17639: loss: 1.0113, policy_loss: 0.9567, value_loss: 0.4973
2024-07-14 07:02:21,674 [INFO    ] __main__: train step 17640: loss: 1.0112, policy_loss: 0.9567, value_loss: 0.4973
2024-07-14 07:02:21,958 [INFO    ] __main__: train step 17641: loss: 1.0112, policy_loss: 0.9566, value_loss: 0.4973
2024-07-14 07:02:22,227 [INFO    ] __main__: train step 17642: loss: 1.0112, policy_loss: 0.9566, value_loss: 0.4972
2024-07-14 07:02:23,813 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:02:24,301 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:02:24,368 [INFO    ] __main__: train step 17643: loss: 1.0112, policy_loss: 0.9566, value_loss: 0.4972
2024-07-14 07:02:24,641 [INFO    ] __main__: train step 17644: loss: 1.0112, policy_loss: 0.9566, value_loss: 0.4972
2024-07-14 07:02:24,931 [INFO    ] __main__: train step 17645: loss: 1.0112, policy_loss: 0.9566, value_loss: 0.4972
2024-07-14 07:02:25,235 [INFO    ] __main__: train step 17646: loss: 1.0112, policy_loss: 0.9566, value_loss: 0.4971
2024-07-14 07:02:25,519 [INFO    ] __main__: train step 17647: loss: 1.0111, policy_loss: 0.9565, value_loss: 0.4971
2024-07-14 07:02:25,833 [INFO    ] __main__: train step 17648: loss: 1.0111, policy_loss: 0.9565, value_loss: 0.4971
2024-07-14 07:02:26,096 [INFO    ] __main__: train step 17649: loss: 1.0111, policy_loss: 0.9565, value_loss: 0.4971
2024-07-14 07:02:26,380 [INFO    ] __main__: train step 17650: loss: 1.0111, policy_loss: 0.9565, value_loss: 0.4971
2024-07-14 07:02:26,672 [INFO    ] __main__: train step 17651: loss: 1.0111, policy_loss: 0.9565, value_loss: 0.4970
2024-07-14 07:02:26,960 [INFO    ] __main__: train step 17652: loss: 1.0111, policy_loss: 0.9565, value_loss: 0.4970
2024-07-14 07:02:27,255 [INFO    ] __main__: train step 17653: loss: 1.0111, policy_loss: 0.9564, value_loss: 0.4970
2024-07-14 07:02:27,536 [INFO    ] __main__: train step 17654: loss: 1.0110, policy_loss: 0.9564, value_loss: 0.4970
2024-07-14 07:02:27,812 [INFO    ] __main__: train step 17655: loss: 1.0110, policy_loss: 0.9564, value_loss: 0.4969
2024-07-14 07:02:28,099 [INFO    ] __main__: train step 17656: loss: 1.0110, policy_loss: 0.9564, value_loss: 0.4969
2024-07-14 07:02:28,396 [INFO    ] __main__: train step 17657: loss: 1.0110, policy_loss: 0.9564, value_loss: 0.4969
2024-07-14 07:02:28,673 [INFO    ] __main__: train step 17658: loss: 1.0110, policy_loss: 0.9564, value_loss: 0.4969
2024-07-14 07:02:28,963 [INFO    ] __main__: train step 17659: loss: 1.0110, policy_loss: 0.9563, value_loss: 0.4968
2024-07-14 07:02:30,588 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:02:31,058 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:02:31,126 [INFO    ] __main__: train step 17660: loss: 1.0110, policy_loss: 0.9563, value_loss: 0.4968
2024-07-14 07:02:31,385 [INFO    ] __main__: train step 17661: loss: 1.0109, policy_loss: 0.9563, value_loss: 0.4968
2024-07-14 07:02:31,652 [INFO    ] __main__: train step 17662: loss: 1.0109, policy_loss: 0.9563, value_loss: 0.4968
2024-07-14 07:02:31,935 [INFO    ] __main__: train step 17663: loss: 1.0109, policy_loss: 0.9563, value_loss: 0.4968
2024-07-14 07:02:32,222 [INFO    ] __main__: train step 17664: loss: 1.0109, policy_loss: 0.9563, value_loss: 0.4967
2024-07-14 07:02:32,500 [INFO    ] __main__: train step 17665: loss: 1.0109, policy_loss: 0.9562, value_loss: 0.4967
2024-07-14 07:02:32,783 [INFO    ] __main__: train step 17666: loss: 1.0109, policy_loss: 0.9562, value_loss: 0.4967
2024-07-14 07:02:33,071 [INFO    ] __main__: train step 17667: loss: 1.0109, policy_loss: 0.9562, value_loss: 0.4967
2024-07-14 07:02:33,357 [INFO    ] __main__: train step 17668: loss: 1.0108, policy_loss: 0.9562, value_loss: 0.4966
2024-07-14 07:02:33,644 [INFO    ] __main__: train step 17669: loss: 1.0108, policy_loss: 0.9562, value_loss: 0.4966
2024-07-14 07:02:33,934 [INFO    ] __main__: train step 17670: loss: 1.0108, policy_loss: 0.9562, value_loss: 0.4966
2024-07-14 07:02:34,198 [INFO    ] __main__: train step 17671: loss: 1.0108, policy_loss: 0.9561, value_loss: 0.4966
2024-07-14 07:02:34,481 [INFO    ] __main__: train step 17672: loss: 1.0108, policy_loss: 0.9561, value_loss: 0.4965
2024-07-14 07:02:34,768 [INFO    ] __main__: train step 17673: loss: 1.0108, policy_loss: 0.9561, value_loss: 0.4965
2024-07-14 07:02:35,068 [INFO    ] __main__: train step 17674: loss: 1.0108, policy_loss: 0.9561, value_loss: 0.4965
2024-07-14 07:02:35,364 [INFO    ] __main__: train step 17675: loss: 1.0107, policy_loss: 0.9561, value_loss: 0.4965
2024-07-14 07:02:35,629 [INFO    ] __main__: train step 17676: loss: 1.0107, policy_loss: 0.9561, value_loss: 0.4965
2024-07-14 07:02:37,216 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:02:37,701 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:02:37,768 [INFO    ] __main__: train step 17677: loss: 1.0107, policy_loss: 0.9560, value_loss: 0.4964
2024-07-14 07:02:38,054 [INFO    ] __main__: train step 17678: loss: 1.0107, policy_loss: 0.9560, value_loss: 0.4964
2024-07-14 07:02:38,341 [INFO    ] __main__: train step 17679: loss: 1.0107, policy_loss: 0.9560, value_loss: 0.4964
2024-07-14 07:02:38,622 [INFO    ] __main__: train step 17680: loss: 1.0107, policy_loss: 0.9560, value_loss: 0.4964
2024-07-14 07:02:38,899 [INFO    ] __main__: train step 17681: loss: 1.0107, policy_loss: 0.9560, value_loss: 0.4963
2024-07-14 07:02:39,178 [INFO    ] __main__: train step 17682: loss: 1.0106, policy_loss: 0.9560, value_loss: 0.4963
2024-07-14 07:02:39,460 [INFO    ] __main__: train step 17683: loss: 1.0106, policy_loss: 0.9559, value_loss: 0.4963
2024-07-14 07:02:39,753 [INFO    ] __main__: train step 17684: loss: 1.0106, policy_loss: 0.9559, value_loss: 0.4963
2024-07-14 07:02:40,018 [INFO    ] __main__: train step 17685: loss: 1.0106, policy_loss: 0.9559, value_loss: 0.4962
2024-07-14 07:02:40,301 [INFO    ] __main__: train step 17686: loss: 1.0106, policy_loss: 0.9559, value_loss: 0.4962
2024-07-14 07:02:40,589 [INFO    ] __main__: train step 17687: loss: 1.0106, policy_loss: 0.9559, value_loss: 0.4962
2024-07-14 07:02:40,871 [INFO    ] __main__: train step 17688: loss: 1.0105, policy_loss: 0.9559, value_loss: 0.4962
2024-07-14 07:02:41,155 [INFO    ] __main__: train step 17689: loss: 1.0105, policy_loss: 0.9558, value_loss: 0.4962
2024-07-14 07:02:41,444 [INFO    ] __main__: train step 17690: loss: 1.0105, policy_loss: 0.9558, value_loss: 0.4961
2024-07-14 07:02:41,722 [INFO    ] __main__: train step 17691: loss: 1.0105, policy_loss: 0.9558, value_loss: 0.4961
2024-07-14 07:02:42,007 [INFO    ] __main__: train step 17692: loss: 1.0105, policy_loss: 0.9558, value_loss: 0.4961
2024-07-14 07:02:42,299 [INFO    ] __main__: train step 17693: loss: 1.0105, policy_loss: 0.9558, value_loss: 0.4961
2024-07-14 07:02:43,902 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:02:44,389 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:02:44,461 [INFO    ] __main__: train step 17694: loss: 1.0105, policy_loss: 0.9558, value_loss: 0.4960
2024-07-14 07:02:44,750 [INFO    ] __main__: train step 17695: loss: 1.0104, policy_loss: 0.9557, value_loss: 0.4960
2024-07-14 07:02:45,032 [INFO    ] __main__: train step 17696: loss: 1.0104, policy_loss: 0.9557, value_loss: 0.4960
2024-07-14 07:02:45,309 [INFO    ] __main__: train step 17697: loss: 1.0104, policy_loss: 0.9557, value_loss: 0.4960
2024-07-14 07:02:45,603 [INFO    ] __main__: train step 17698: loss: 1.0104, policy_loss: 0.9557, value_loss: 0.4959
2024-07-14 07:02:45,891 [INFO    ] __main__: train step 17699: loss: 1.0104, policy_loss: 0.9557, value_loss: 0.4959
2024-07-14 07:02:46,190 [INFO    ] __main__: train step 17700: loss: 1.0104, policy_loss: 0.9557, value_loss: 0.4959
2024-07-14 07:02:46,483 [INFO    ] __main__: train step 17701: loss: 1.0104, policy_loss: 0.9556, value_loss: 0.4959
2024-07-14 07:02:46,785 [INFO    ] __main__: train step 17702: loss: 1.0103, policy_loss: 0.9556, value_loss: 0.4959
2024-07-14 07:02:47,069 [INFO    ] __main__: train step 17703: loss: 1.0103, policy_loss: 0.9556, value_loss: 0.4958
2024-07-14 07:02:47,363 [INFO    ] __main__: train step 17704: loss: 1.0103, policy_loss: 0.9556, value_loss: 0.4958
2024-07-14 07:02:47,656 [INFO    ] __main__: train step 17705: loss: 1.0103, policy_loss: 0.9556, value_loss: 0.4958
2024-07-14 07:02:47,943 [INFO    ] __main__: train step 17706: loss: 1.0103, policy_loss: 0.9556, value_loss: 0.4958
2024-07-14 07:02:51,444 [INFO    ] __main__: train step 17707: loss: 1.0103, policy_loss: 0.9555, value_loss: 0.4957
2024-07-14 07:02:51,736 [INFO    ] __main__: train step 17708: loss: 1.0103, policy_loss: 0.9555, value_loss: 0.4957
2024-07-14 07:02:52,024 [INFO    ] __main__: train step 17709: loss: 1.0102, policy_loss: 0.9555, value_loss: 0.4957
2024-07-14 07:02:52,321 [INFO    ] __main__: train step 17710: loss: 1.0102, policy_loss: 0.9555, value_loss: 0.4957
2024-07-14 07:02:53,947 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:02:54,424 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:02:54,496 [INFO    ] __main__: train step 17711: loss: 1.0102, policy_loss: 0.9555, value_loss: 0.4957
2024-07-14 07:02:54,771 [INFO    ] __main__: train step 17712: loss: 1.0102, policy_loss: 0.9555, value_loss: 0.4956
2024-07-14 07:02:55,044 [INFO    ] __main__: train step 17713: loss: 1.0102, policy_loss: 0.9554, value_loss: 0.4956
2024-07-14 07:02:55,339 [INFO    ] __main__: train step 17714: loss: 1.0102, policy_loss: 0.9554, value_loss: 0.4956
2024-07-14 07:02:55,620 [INFO    ] __main__: train step 17715: loss: 1.0102, policy_loss: 0.9554, value_loss: 0.4956
2024-07-14 07:02:55,909 [INFO    ] __main__: train step 17716: loss: 1.0101, policy_loss: 0.9554, value_loss: 0.4955
2024-07-14 07:02:56,180 [INFO    ] __main__: train step 17717: loss: 1.0101, policy_loss: 0.9554, value_loss: 0.4955
2024-07-14 07:02:56,464 [INFO    ] __main__: train step 17718: loss: 1.0101, policy_loss: 0.9554, value_loss: 0.4955
2024-07-14 07:02:56,755 [INFO    ] __main__: train step 17719: loss: 1.0101, policy_loss: 0.9553, value_loss: 0.4955
2024-07-14 07:02:57,043 [INFO    ] __main__: train step 17720: loss: 1.0101, policy_loss: 0.9553, value_loss: 0.4954
2024-07-14 07:02:57,322 [INFO    ] __main__: train step 17721: loss: 1.0101, policy_loss: 0.9553, value_loss: 0.4954
2024-07-14 07:02:57,570 [INFO    ] __main__: train step 17722: loss: 1.0101, policy_loss: 0.9553, value_loss: 0.4954
2024-07-14 07:02:57,848 [INFO    ] __main__: train step 17723: loss: 1.0100, policy_loss: 0.9553, value_loss: 0.4954
2024-07-14 07:02:58,136 [INFO    ] __main__: train step 17724: loss: 1.0100, policy_loss: 0.9553, value_loss: 0.4954
2024-07-14 07:02:58,421 [INFO    ] __main__: train step 17725: loss: 1.0100, policy_loss: 0.9552, value_loss: 0.4953
2024-07-14 07:02:58,699 [INFO    ] __main__: train step 17726: loss: 1.0100, policy_loss: 0.9552, value_loss: 0.4953
2024-07-14 07:02:58,959 [INFO    ] __main__: train step 17727: loss: 1.0100, policy_loss: 0.9552, value_loss: 0.4953
2024-07-14 07:03:00,528 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:03:01,006 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:03:01,073 [INFO    ] __main__: train step 17728: loss: 1.0100, policy_loss: 0.9552, value_loss: 0.4953
2024-07-14 07:03:01,343 [INFO    ] __main__: train step 17729: loss: 1.0100, policy_loss: 0.9552, value_loss: 0.4952
2024-07-14 07:03:01,613 [INFO    ] __main__: train step 17730: loss: 1.0099, policy_loss: 0.9552, value_loss: 0.4952
2024-07-14 07:03:01,900 [INFO    ] __main__: train step 17731: loss: 1.0099, policy_loss: 0.9551, value_loss: 0.4952
2024-07-14 07:03:02,206 [INFO    ] __main__: train step 17732: loss: 1.0099, policy_loss: 0.9551, value_loss: 0.4952
2024-07-14 07:03:02,476 [INFO    ] __main__: train step 17733: loss: 1.0099, policy_loss: 0.9551, value_loss: 0.4951
2024-07-14 07:03:02,762 [INFO    ] __main__: train step 17734: loss: 1.0099, policy_loss: 0.9551, value_loss: 0.4951
2024-07-14 07:03:03,063 [INFO    ] __main__: train step 17735: loss: 1.0099, policy_loss: 0.9551, value_loss: 0.4951
2024-07-14 07:03:03,352 [INFO    ] __main__: train step 17736: loss: 1.0099, policy_loss: 0.9551, value_loss: 0.4951
2024-07-14 07:03:03,639 [INFO    ] __main__: train step 17737: loss: 1.0098, policy_loss: 0.9550, value_loss: 0.4951
2024-07-14 07:03:03,893 [INFO    ] __main__: train step 17738: loss: 1.0098, policy_loss: 0.9550, value_loss: 0.4950
2024-07-14 07:03:04,166 [INFO    ] __main__: train step 17739: loss: 1.0098, policy_loss: 0.9550, value_loss: 0.4950
2024-07-14 07:03:04,452 [INFO    ] __main__: train step 17740: loss: 1.0098, policy_loss: 0.9550, value_loss: 0.4950
2024-07-14 07:03:04,735 [INFO    ] __main__: train step 17741: loss: 1.0098, policy_loss: 0.9550, value_loss: 0.4950
2024-07-14 07:03:05,027 [INFO    ] __main__: train step 17742: loss: 1.0098, policy_loss: 0.9550, value_loss: 0.4949
2024-07-14 07:03:05,315 [INFO    ] __main__: train step 17743: loss: 1.0097, policy_loss: 0.9549, value_loss: 0.4949
2024-07-14 07:03:05,610 [INFO    ] __main__: train step 17744: loss: 1.0097, policy_loss: 0.9549, value_loss: 0.4949
2024-07-14 07:03:07,220 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:03:07,709 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:03:07,782 [INFO    ] __main__: train step 17745: loss: 1.0097, policy_loss: 0.9549, value_loss: 0.4949
2024-07-14 07:03:08,084 [INFO    ] __main__: train step 17746: loss: 1.0097, policy_loss: 0.9549, value_loss: 0.4949
2024-07-14 07:03:08,374 [INFO    ] __main__: train step 17747: loss: 1.0097, policy_loss: 0.9549, value_loss: 0.4948
2024-07-14 07:03:08,658 [INFO    ] __main__: train step 17748: loss: 1.0097, policy_loss: 0.9549, value_loss: 0.4948
2024-07-14 07:03:08,913 [INFO    ] __main__: train step 17749: loss: 1.0097, policy_loss: 0.9548, value_loss: 0.4948
2024-07-14 07:03:09,197 [INFO    ] __main__: train step 17750: loss: 1.0096, policy_loss: 0.9548, value_loss: 0.4948
2024-07-14 07:03:09,468 [INFO    ] __main__: train step 17751: loss: 1.0096, policy_loss: 0.9548, value_loss: 0.4947
2024-07-14 07:03:09,770 [INFO    ] __main__: train step 17752: loss: 1.0096, policy_loss: 0.9548, value_loss: 0.4947
2024-07-14 07:03:10,065 [INFO    ] __main__: train step 17753: loss: 1.0096, policy_loss: 0.9548, value_loss: 0.4947
2024-07-14 07:03:10,335 [INFO    ] __main__: train step 17754: loss: 1.0096, policy_loss: 0.9548, value_loss: 0.4947
2024-07-14 07:03:10,602 [INFO    ] __main__: train step 17755: loss: 1.0096, policy_loss: 0.9548, value_loss: 0.4946
2024-07-14 07:03:10,898 [INFO    ] __main__: train step 17756: loss: 1.0096, policy_loss: 0.9547, value_loss: 0.4946
2024-07-14 07:03:11,164 [INFO    ] __main__: train step 17757: loss: 1.0095, policy_loss: 0.9547, value_loss: 0.4946
2024-07-14 07:03:11,445 [INFO    ] __main__: train step 17758: loss: 1.0095, policy_loss: 0.9547, value_loss: 0.4946
2024-07-14 07:03:11,735 [INFO    ] __main__: train step 17759: loss: 1.0095, policy_loss: 0.9547, value_loss: 0.4946
2024-07-14 07:03:12,008 [INFO    ] __main__: train step 17760: loss: 1.0095, policy_loss: 0.9547, value_loss: 0.4945
2024-07-14 07:03:12,289 [INFO    ] __main__: train step 17761: loss: 1.0095, policy_loss: 0.9547, value_loss: 0.4945
2024-07-14 07:03:13,918 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:03:14,412 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:03:14,484 [INFO    ] __main__: train step 17762: loss: 1.0095, policy_loss: 0.9546, value_loss: 0.4945
2024-07-14 07:03:14,757 [INFO    ] __main__: train step 17763: loss: 1.0095, policy_loss: 0.9546, value_loss: 0.4945
2024-07-14 07:03:15,037 [INFO    ] __main__: train step 17764: loss: 1.0094, policy_loss: 0.9546, value_loss: 0.4944
2024-07-14 07:03:15,337 [INFO    ] __main__: train step 17765: loss: 1.0094, policy_loss: 0.9546, value_loss: 0.4944
2024-07-14 07:03:15,620 [INFO    ] __main__: train step 17766: loss: 1.0094, policy_loss: 0.9546, value_loss: 0.4944
2024-07-14 07:03:15,895 [INFO    ] __main__: train step 17767: loss: 1.0094, policy_loss: 0.9546, value_loss: 0.4944
2024-07-14 07:03:16,191 [INFO    ] __main__: train step 17768: loss: 1.0094, policy_loss: 0.9545, value_loss: 0.4943
2024-07-14 07:03:16,502 [INFO    ] __main__: train step 17769: loss: 1.0094, policy_loss: 0.9545, value_loss: 0.4943
2024-07-14 07:03:16,773 [INFO    ] __main__: train step 17770: loss: 1.0094, policy_loss: 0.9545, value_loss: 0.4943
2024-07-14 07:03:17,055 [INFO    ] __main__: train step 17771: loss: 1.0093, policy_loss: 0.9545, value_loss: 0.4943
2024-07-14 07:03:17,343 [INFO    ] __main__: train step 17772: loss: 1.0093, policy_loss: 0.9545, value_loss: 0.4943
2024-07-14 07:03:17,641 [INFO    ] __main__: train step 17773: loss: 1.0093, policy_loss: 0.9545, value_loss: 0.4942
2024-07-14 07:03:17,937 [INFO    ] __main__: train step 17774: loss: 1.0093, policy_loss: 0.9544, value_loss: 0.4942
2024-07-14 07:03:18,217 [INFO    ] __main__: train step 17775: loss: 1.0093, policy_loss: 0.9544, value_loss: 0.4942
2024-07-14 07:03:18,492 [INFO    ] __main__: train step 17776: loss: 1.0093, policy_loss: 0.9544, value_loss: 0.4942
2024-07-14 07:03:18,786 [INFO    ] __main__: train step 17777: loss: 1.0092, policy_loss: 0.9544, value_loss: 0.4941
2024-07-14 07:03:19,072 [INFO    ] __main__: train step 17778: loss: 1.0092, policy_loss: 0.9544, value_loss: 0.4941
2024-07-14 07:03:20,676 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:03:21,167 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:03:21,237 [INFO    ] __main__: train step 17779: loss: 1.0092, policy_loss: 0.9544, value_loss: 0.4941
2024-07-14 07:03:21,501 [INFO    ] __main__: train step 17780: loss: 1.0092, policy_loss: 0.9543, value_loss: 0.4941
2024-07-14 07:03:21,790 [INFO    ] __main__: train step 17781: loss: 1.0092, policy_loss: 0.9543, value_loss: 0.4940
2024-07-14 07:03:22,058 [INFO    ] __main__: train step 17782: loss: 1.0092, policy_loss: 0.9543, value_loss: 0.4940
2024-07-14 07:03:22,361 [INFO    ] __main__: train step 17783: loss: 1.0092, policy_loss: 0.9543, value_loss: 0.4940
2024-07-14 07:03:22,644 [INFO    ] __main__: train step 17784: loss: 1.0091, policy_loss: 0.9543, value_loss: 0.4940
2024-07-14 07:03:22,926 [INFO    ] __main__: train step 17785: loss: 1.0091, policy_loss: 0.9543, value_loss: 0.4940
2024-07-14 07:03:23,212 [INFO    ] __main__: train step 17786: loss: 1.0091, policy_loss: 0.9542, value_loss: 0.4939
2024-07-14 07:03:23,505 [INFO    ] __main__: train step 17787: loss: 1.0091, policy_loss: 0.9542, value_loss: 0.4939
2024-07-14 07:03:23,805 [INFO    ] __main__: train step 17788: loss: 1.0091, policy_loss: 0.9542, value_loss: 0.4939
2024-07-14 07:03:24,098 [INFO    ] __main__: train step 17789: loss: 1.0091, policy_loss: 0.9542, value_loss: 0.4939
2024-07-14 07:03:24,393 [INFO    ] __main__: train step 17790: loss: 1.0091, policy_loss: 0.9542, value_loss: 0.4938
2024-07-14 07:03:24,663 [INFO    ] __main__: train step 17791: loss: 1.0090, policy_loss: 0.9542, value_loss: 0.4938
2024-07-14 07:03:24,966 [INFO    ] __main__: train step 17792: loss: 1.0090, policy_loss: 0.9541, value_loss: 0.4938
2024-07-14 07:03:25,256 [INFO    ] __main__: train step 17793: loss: 1.0090, policy_loss: 0.9541, value_loss: 0.4938
2024-07-14 07:03:25,551 [INFO    ] __main__: train step 17794: loss: 1.0090, policy_loss: 0.9541, value_loss: 0.4938
2024-07-14 07:03:25,855 [INFO    ] __main__: train step 17795: loss: 1.0090, policy_loss: 0.9541, value_loss: 0.4937
2024-07-14 07:03:27,448 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:03:27,922 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:03:27,989 [INFO    ] __main__: train step 17796: loss: 1.0090, policy_loss: 0.9541, value_loss: 0.4937
2024-07-14 07:03:28,286 [INFO    ] __main__: train step 17797: loss: 1.0090, policy_loss: 0.9541, value_loss: 0.4937
2024-07-14 07:03:28,578 [INFO    ] __main__: train step 17798: loss: 1.0089, policy_loss: 0.9540, value_loss: 0.4937
2024-07-14 07:03:28,870 [INFO    ] __main__: train step 17799: loss: 1.0089, policy_loss: 0.9540, value_loss: 0.4936
2024-07-14 07:03:29,138 [INFO    ] __main__: train step 17800: loss: 1.0089, policy_loss: 0.9540, value_loss: 0.4936
2024-07-14 07:03:29,423 [INFO    ] __main__: train step 17801: loss: 1.0089, policy_loss: 0.9540, value_loss: 0.4936
2024-07-14 07:03:29,708 [INFO    ] __main__: train step 17802: loss: 1.0089, policy_loss: 0.9540, value_loss: 0.4936
2024-07-14 07:03:30,008 [INFO    ] __main__: train step 17803: loss: 1.0089, policy_loss: 0.9540, value_loss: 0.4935
2024-07-14 07:03:30,309 [INFO    ] __main__: train step 17804: loss: 1.0089, policy_loss: 0.9539, value_loss: 0.4935
2024-07-14 07:03:30,607 [INFO    ] __main__: train step 17805: loss: 1.0088, policy_loss: 0.9539, value_loss: 0.4935
2024-07-14 07:03:30,872 [INFO    ] __main__: train step 17806: loss: 1.0088, policy_loss: 0.9539, value_loss: 0.4935
2024-07-14 07:03:31,157 [INFO    ] __main__: train step 17807: loss: 1.0088, policy_loss: 0.9539, value_loss: 0.4935
2024-07-14 07:03:31,452 [INFO    ] __main__: train step 17808: loss: 1.0088, policy_loss: 0.9539, value_loss: 0.4934
2024-07-14 07:03:34,956 [INFO    ] __main__: train step 17809: loss: 1.0088, policy_loss: 0.9539, value_loss: 0.4934
2024-07-14 07:03:35,253 [INFO    ] __main__: train step 17810: loss: 1.0088, policy_loss: 0.9538, value_loss: 0.4934
2024-07-14 07:03:35,526 [INFO    ] __main__: train step 17811: loss: 1.0087, policy_loss: 0.9538, value_loss: 0.4934
2024-07-14 07:03:35,793 [INFO    ] __main__: train step 17812: loss: 1.0087, policy_loss: 0.9538, value_loss: 0.4933
2024-07-14 07:03:37,403 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:03:37,894 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:03:37,966 [INFO    ] __main__: train step 17813: loss: 1.0087, policy_loss: 0.9538, value_loss: 0.4933
2024-07-14 07:03:38,272 [INFO    ] __main__: train step 17814: loss: 1.0087, policy_loss: 0.9538, value_loss: 0.4933
2024-07-14 07:03:38,563 [INFO    ] __main__: train step 17815: loss: 1.0087, policy_loss: 0.9538, value_loss: 0.4933
2024-07-14 07:03:38,837 [INFO    ] __main__: train step 17816: loss: 1.0087, policy_loss: 0.9537, value_loss: 0.4933
2024-07-14 07:03:39,128 [INFO    ] __main__: train step 17817: loss: 1.0087, policy_loss: 0.9537, value_loss: 0.4932
2024-07-14 07:03:39,434 [INFO    ] __main__: train step 17818: loss: 1.0086, policy_loss: 0.9537, value_loss: 0.4932
2024-07-14 07:03:39,720 [INFO    ] __main__: train step 17819: loss: 1.0086, policy_loss: 0.9537, value_loss: 0.4932
2024-07-14 07:03:40,015 [INFO    ] __main__: train step 17820: loss: 1.0086, policy_loss: 0.9537, value_loss: 0.4932
2024-07-14 07:03:40,308 [INFO    ] __main__: train step 17821: loss: 1.0086, policy_loss: 0.9537, value_loss: 0.4931
2024-07-14 07:03:40,610 [INFO    ] __main__: train step 17822: loss: 1.0086, policy_loss: 0.9536, value_loss: 0.4931
2024-07-14 07:03:40,913 [INFO    ] __main__: train step 17823: loss: 1.0086, policy_loss: 0.9536, value_loss: 0.4931
2024-07-14 07:03:41,201 [INFO    ] __main__: train step 17824: loss: 1.0086, policy_loss: 0.9536, value_loss: 0.4931
2024-07-14 07:03:41,503 [INFO    ] __main__: train step 17825: loss: 1.0085, policy_loss: 0.9536, value_loss: 0.4931
2024-07-14 07:03:41,797 [INFO    ] __main__: train step 17826: loss: 1.0085, policy_loss: 0.9536, value_loss: 0.4930
2024-07-14 07:03:42,065 [INFO    ] __main__: train step 17827: loss: 1.0085, policy_loss: 0.9536, value_loss: 0.4930
2024-07-14 07:03:42,308 [INFO    ] __main__: train step 17828: loss: 1.0085, policy_loss: 0.9535, value_loss: 0.4930
2024-07-14 07:03:42,561 [INFO    ] __main__: train step 17829: loss: 1.0085, policy_loss: 0.9535, value_loss: 0.4930
2024-07-14 07:03:44,160 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:03:44,636 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:03:44,708 [INFO    ] __main__: train step 17830: loss: 1.0085, policy_loss: 0.9535, value_loss: 0.4929
2024-07-14 07:03:45,003 [INFO    ] __main__: train step 17831: loss: 1.0085, policy_loss: 0.9535, value_loss: 0.4929
2024-07-14 07:03:45,264 [INFO    ] __main__: train step 17832: loss: 1.0084, policy_loss: 0.9535, value_loss: 0.4929
2024-07-14 07:03:45,516 [INFO    ] __main__: train step 17833: loss: 1.0084, policy_loss: 0.9535, value_loss: 0.4929
2024-07-14 07:03:45,798 [INFO    ] __main__: train step 17834: loss: 1.0084, policy_loss: 0.9534, value_loss: 0.4928
2024-07-14 07:03:46,094 [INFO    ] __main__: train step 17835: loss: 1.0084, policy_loss: 0.9534, value_loss: 0.4928
2024-07-14 07:03:46,384 [INFO    ] __main__: train step 17836: loss: 1.0084, policy_loss: 0.9534, value_loss: 0.4928
2024-07-14 07:03:46,678 [INFO    ] __main__: train step 17837: loss: 1.0084, policy_loss: 0.9534, value_loss: 0.4928
2024-07-14 07:03:46,954 [INFO    ] __main__: train step 17838: loss: 1.0084, policy_loss: 0.9534, value_loss: 0.4928
2024-07-14 07:03:47,232 [INFO    ] __main__: train step 17839: loss: 1.0083, policy_loss: 0.9534, value_loss: 0.4927
2024-07-14 07:03:47,521 [INFO    ] __main__: train step 17840: loss: 1.0083, policy_loss: 0.9533, value_loss: 0.4927
2024-07-14 07:03:47,811 [INFO    ] __main__: train step 17841: loss: 1.0083, policy_loss: 0.9533, value_loss: 0.4927
2024-07-14 07:03:48,135 [INFO    ] __main__: train step 17842: loss: 1.0083, policy_loss: 0.9533, value_loss: 0.4927
2024-07-14 07:03:48,428 [INFO    ] __main__: train step 17843: loss: 1.0083, policy_loss: 0.9533, value_loss: 0.4926
2024-07-14 07:03:48,725 [INFO    ] __main__: train step 17844: loss: 1.0083, policy_loss: 0.9533, value_loss: 0.4926
2024-07-14 07:03:49,029 [INFO    ] __main__: train step 17845: loss: 1.0083, policy_loss: 0.9533, value_loss: 0.4926
2024-07-14 07:03:49,328 [INFO    ] __main__: train step 17846: loss: 1.0082, policy_loss: 0.9532, value_loss: 0.4926
2024-07-14 07:03:50,961 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:03:51,431 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:03:51,496 [INFO    ] __main__: train step 17847: loss: 1.0082, policy_loss: 0.9532, value_loss: 0.4926
2024-07-14 07:03:51,770 [INFO    ] __main__: train step 17848: loss: 1.0082, policy_loss: 0.9532, value_loss: 0.4925
2024-07-14 07:03:52,033 [INFO    ] __main__: train step 17849: loss: 1.0082, policy_loss: 0.9532, value_loss: 0.4925
2024-07-14 07:03:52,319 [INFO    ] __main__: train step 17850: loss: 1.0082, policy_loss: 0.9532, value_loss: 0.4925
2024-07-14 07:03:52,592 [INFO    ] __main__: train step 17851: loss: 1.0082, policy_loss: 0.9532, value_loss: 0.4925
2024-07-14 07:03:52,893 [INFO    ] __main__: train step 17852: loss: 1.0082, policy_loss: 0.9531, value_loss: 0.4924
2024-07-14 07:03:53,177 [INFO    ] __main__: train step 17853: loss: 1.0081, policy_loss: 0.9531, value_loss: 0.4924
2024-07-14 07:03:53,457 [INFO    ] __main__: train step 17854: loss: 1.0081, policy_loss: 0.9531, value_loss: 0.4924
2024-07-14 07:03:53,740 [INFO    ] __main__: train step 17855: loss: 1.0081, policy_loss: 0.9531, value_loss: 0.4924
2024-07-14 07:03:54,003 [INFO    ] __main__: train step 17856: loss: 1.0081, policy_loss: 0.9531, value_loss: 0.4923
2024-07-14 07:03:54,290 [INFO    ] __main__: train step 17857: loss: 1.0081, policy_loss: 0.9531, value_loss: 0.4923
2024-07-14 07:03:54,570 [INFO    ] __main__: train step 17858: loss: 1.0081, policy_loss: 0.9530, value_loss: 0.4923
2024-07-14 07:03:54,833 [INFO    ] __main__: train step 17859: loss: 1.0080, policy_loss: 0.9530, value_loss: 0.4923
2024-07-14 07:03:55,125 [INFO    ] __main__: train step 17860: loss: 1.0080, policy_loss: 0.9530, value_loss: 0.4923
2024-07-14 07:03:55,419 [INFO    ] __main__: train step 17861: loss: 1.0080, policy_loss: 0.9530, value_loss: 0.4922
2024-07-14 07:03:55,713 [INFO    ] __main__: train step 17862: loss: 1.0080, policy_loss: 0.9530, value_loss: 0.4922
2024-07-14 07:03:56,022 [INFO    ] __main__: train step 17863: loss: 1.0080, policy_loss: 0.9530, value_loss: 0.4922
2024-07-14 07:03:57,592 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:03:58,031 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:03:58,100 [INFO    ] __main__: train step 17864: loss: 1.0080, policy_loss: 0.9529, value_loss: 0.4922
2024-07-14 07:03:58,376 [INFO    ] __main__: train step 17865: loss: 1.0080, policy_loss: 0.9529, value_loss: 0.4921
2024-07-14 07:03:58,644 [INFO    ] __main__: train step 17866: loss: 1.0079, policy_loss: 0.9529, value_loss: 0.4921
2024-07-14 07:03:58,919 [INFO    ] __main__: train step 17867: loss: 1.0079, policy_loss: 0.9529, value_loss: 0.4921
2024-07-14 07:03:59,190 [INFO    ] __main__: train step 17868: loss: 1.0079, policy_loss: 0.9529, value_loss: 0.4921
2024-07-14 07:03:59,466 [INFO    ] __main__: train step 17869: loss: 1.0079, policy_loss: 0.9529, value_loss: 0.4921
2024-07-14 07:03:59,748 [INFO    ] __main__: train step 17870: loss: 1.0079, policy_loss: 0.9528, value_loss: 0.4920
2024-07-14 07:04:00,006 [INFO    ] __main__: train step 17871: loss: 1.0079, policy_loss: 0.9528, value_loss: 0.4920
2024-07-14 07:04:00,276 [INFO    ] __main__: train step 17872: loss: 1.0078, policy_loss: 0.9528, value_loss: 0.4920
2024-07-14 07:04:00,580 [INFO    ] __main__: train step 17873: loss: 1.0078, policy_loss: 0.9528, value_loss: 0.4920
2024-07-14 07:04:00,864 [INFO    ] __main__: train step 17874: loss: 1.0078, policy_loss: 0.9528, value_loss: 0.4919
2024-07-14 07:04:01,151 [INFO    ] __main__: train step 17875: loss: 1.0078, policy_loss: 0.9528, value_loss: 0.4919
2024-07-14 07:04:01,426 [INFO    ] __main__: train step 17876: loss: 1.0078, policy_loss: 0.9527, value_loss: 0.4919
2024-07-14 07:04:01,714 [INFO    ] __main__: train step 17877: loss: 1.0078, policy_loss: 0.9527, value_loss: 0.4919
2024-07-14 07:04:02,011 [INFO    ] __main__: train step 17878: loss: 1.0078, policy_loss: 0.9527, value_loss: 0.4918
2024-07-14 07:04:02,309 [INFO    ] __main__: train step 17879: loss: 1.0077, policy_loss: 0.9527, value_loss: 0.4918
2024-07-14 07:04:02,617 [INFO    ] __main__: train step 17880: loss: 1.0077, policy_loss: 0.9527, value_loss: 0.4918
2024-07-14 07:04:04,212 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:04:04,675 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:04:04,746 [INFO    ] __main__: train step 17881: loss: 1.0077, policy_loss: 0.9527, value_loss: 0.4918
2024-07-14 07:04:05,029 [INFO    ] __main__: train step 17882: loss: 1.0077, policy_loss: 0.9526, value_loss: 0.4918
2024-07-14 07:04:05,296 [INFO    ] __main__: train step 17883: loss: 1.0077, policy_loss: 0.9526, value_loss: 0.4917
2024-07-14 07:04:05,576 [INFO    ] __main__: train step 17884: loss: 1.0077, policy_loss: 0.9526, value_loss: 0.4917
2024-07-14 07:04:05,841 [INFO    ] __main__: train step 17885: loss: 1.0077, policy_loss: 0.9526, value_loss: 0.4917
2024-07-14 07:04:06,103 [INFO    ] __main__: train step 17886: loss: 1.0076, policy_loss: 0.9526, value_loss: 0.4917
2024-07-14 07:04:06,371 [INFO    ] __main__: train step 17887: loss: 1.0076, policy_loss: 0.9526, value_loss: 0.4916
2024-07-14 07:04:06,640 [INFO    ] __main__: train step 17888: loss: 1.0076, policy_loss: 0.9525, value_loss: 0.4916
2024-07-14 07:04:06,931 [INFO    ] __main__: train step 17889: loss: 1.0076, policy_loss: 0.9525, value_loss: 0.4916
2024-07-14 07:04:07,229 [INFO    ] __main__: train step 17890: loss: 1.0076, policy_loss: 0.9525, value_loss: 0.4916
2024-07-14 07:04:07,511 [INFO    ] __main__: train step 17891: loss: 1.0076, policy_loss: 0.9525, value_loss: 0.4915
2024-07-14 07:04:07,786 [INFO    ] __main__: train step 17892: loss: 1.0075, policy_loss: 0.9525, value_loss: 0.4915
2024-07-14 07:04:08,066 [INFO    ] __main__: train step 17893: loss: 1.0075, policy_loss: 0.9525, value_loss: 0.4915
2024-07-14 07:04:08,350 [INFO    ] __main__: train step 17894: loss: 1.0075, policy_loss: 0.9524, value_loss: 0.4915
2024-07-14 07:04:08,633 [INFO    ] __main__: train step 17895: loss: 1.0075, policy_loss: 0.9524, value_loss: 0.4915
2024-07-14 07:04:08,900 [INFO    ] __main__: train step 17896: loss: 1.0075, policy_loss: 0.9524, value_loss: 0.4914
2024-07-14 07:04:09,179 [INFO    ] __main__: train step 17897: loss: 1.0075, policy_loss: 0.9524, value_loss: 0.4914
2024-07-14 07:04:10,798 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:04:11,277 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:04:11,344 [INFO    ] __main__: train step 17898: loss: 1.0075, policy_loss: 0.9524, value_loss: 0.4914
2024-07-14 07:04:11,615 [INFO    ] __main__: train step 17899: loss: 1.0074, policy_loss: 0.9524, value_loss: 0.4914
2024-07-14 07:04:11,890 [INFO    ] __main__: train step 17900: loss: 1.0074, policy_loss: 0.9523, value_loss: 0.4913
2024-07-14 07:04:12,173 [INFO    ] __main__: train step 17901: loss: 1.0074, policy_loss: 0.9523, value_loss: 0.4913
2024-07-14 07:04:12,442 [INFO    ] __main__: train step 17902: loss: 1.0074, policy_loss: 0.9523, value_loss: 0.4913
2024-07-14 07:04:12,717 [INFO    ] __main__: train step 17903: loss: 1.0074, policy_loss: 0.9523, value_loss: 0.4913
2024-07-14 07:04:12,997 [INFO    ] __main__: train step 17904: loss: 1.0074, policy_loss: 0.9523, value_loss: 0.4913
2024-07-14 07:04:13,278 [INFO    ] __main__: train step 17905: loss: 1.0074, policy_loss: 0.9523, value_loss: 0.4912
2024-07-14 07:04:13,575 [INFO    ] __main__: train step 17906: loss: 1.0073, policy_loss: 0.9522, value_loss: 0.4912
2024-07-14 07:04:13,849 [INFO    ] __main__: train step 17907: loss: 1.0073, policy_loss: 0.9522, value_loss: 0.4912
2024-07-14 07:04:14,111 [INFO    ] __main__: train step 17908: loss: 1.0073, policy_loss: 0.9522, value_loss: 0.4912
2024-07-14 07:04:14,380 [INFO    ] __main__: train step 17909: loss: 1.0073, policy_loss: 0.9522, value_loss: 0.4911
2024-07-14 07:04:14,661 [INFO    ] __main__: train step 17910: loss: 1.0073, policy_loss: 0.9522, value_loss: 0.4911
2024-07-14 07:04:18,267 [INFO    ] __main__: train step 17911: loss: 1.0073, policy_loss: 0.9522, value_loss: 0.4911
2024-07-14 07:04:18,547 [INFO    ] __main__: train step 17912: loss: 1.0073, policy_loss: 0.9521, value_loss: 0.4911
2024-07-14 07:04:18,842 [INFO    ] __main__: train step 17913: loss: 1.0072, policy_loss: 0.9521, value_loss: 0.4910
2024-07-14 07:04:19,140 [INFO    ] __main__: train step 17914: loss: 1.0072, policy_loss: 0.9521, value_loss: 0.4910
2024-07-14 07:04:20,769 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:04:21,234 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:04:21,301 [INFO    ] __main__: train step 17915: loss: 1.0072, policy_loss: 0.9521, value_loss: 0.4910
2024-07-14 07:04:21,562 [INFO    ] __main__: train step 17916: loss: 1.0072, policy_loss: 0.9521, value_loss: 0.4910
2024-07-14 07:04:21,847 [INFO    ] __main__: train step 17917: loss: 1.0072, policy_loss: 0.9521, value_loss: 0.4910
2024-07-14 07:04:22,135 [INFO    ] __main__: train step 17918: loss: 1.0072, policy_loss: 0.9520, value_loss: 0.4909
2024-07-14 07:04:22,423 [INFO    ] __main__: train step 17919: loss: 1.0072, policy_loss: 0.9520, value_loss: 0.4909
2024-07-14 07:04:22,713 [INFO    ] __main__: train step 17920: loss: 1.0071, policy_loss: 0.9520, value_loss: 0.4909
2024-07-14 07:04:23,007 [INFO    ] __main__: train step 17921: loss: 1.0071, policy_loss: 0.9520, value_loss: 0.4909
2024-07-14 07:04:23,286 [INFO    ] __main__: train step 17922: loss: 1.0071, policy_loss: 0.9520, value_loss: 0.4908
2024-07-14 07:04:23,564 [INFO    ] __main__: train step 17923: loss: 1.0071, policy_loss: 0.9520, value_loss: 0.4908
2024-07-14 07:04:23,860 [INFO    ] __main__: train step 17924: loss: 1.0071, policy_loss: 0.9519, value_loss: 0.4908
2024-07-14 07:04:24,154 [INFO    ] __main__: train step 17925: loss: 1.0071, policy_loss: 0.9519, value_loss: 0.4908
2024-07-14 07:04:24,448 [INFO    ] __main__: train step 17926: loss: 1.0070, policy_loss: 0.9519, value_loss: 0.4908
2024-07-14 07:04:24,747 [INFO    ] __main__: train step 17927: loss: 1.0070, policy_loss: 0.9519, value_loss: 0.4907
2024-07-14 07:04:25,037 [INFO    ] __main__: train step 17928: loss: 1.0070, policy_loss: 0.9519, value_loss: 0.4907
2024-07-14 07:04:25,328 [INFO    ] __main__: train step 17929: loss: 1.0070, policy_loss: 0.9519, value_loss: 0.4907
2024-07-14 07:04:25,625 [INFO    ] __main__: train step 17930: loss: 1.0070, policy_loss: 0.9519, value_loss: 0.4907
2024-07-14 07:04:25,928 [INFO    ] __main__: train step 17931: loss: 1.0070, policy_loss: 0.9518, value_loss: 0.4906
2024-07-14 07:04:27,545 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:04:28,031 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:04:28,097 [INFO    ] __main__: train step 17932: loss: 1.0070, policy_loss: 0.9518, value_loss: 0.4906
2024-07-14 07:04:28,394 [INFO    ] __main__: train step 17933: loss: 1.0069, policy_loss: 0.9518, value_loss: 0.4906
2024-07-14 07:04:28,694 [INFO    ] __main__: train step 17934: loss: 1.0069, policy_loss: 0.9518, value_loss: 0.4906
2024-07-14 07:04:29,007 [INFO    ] __main__: train step 17935: loss: 1.0069, policy_loss: 0.9518, value_loss: 0.4905
2024-07-14 07:04:29,289 [INFO    ] __main__: train step 17936: loss: 1.0069, policy_loss: 0.9518, value_loss: 0.4905
2024-07-14 07:04:29,582 [INFO    ] __main__: train step 17937: loss: 1.0069, policy_loss: 0.9517, value_loss: 0.4905
2024-07-14 07:04:29,872 [INFO    ] __main__: train step 17938: loss: 1.0069, policy_loss: 0.9517, value_loss: 0.4905
2024-07-14 07:04:30,166 [INFO    ] __main__: train step 17939: loss: 1.0068, policy_loss: 0.9517, value_loss: 0.4905
2024-07-14 07:04:30,451 [INFO    ] __main__: train step 17940: loss: 1.0068, policy_loss: 0.9517, value_loss: 0.4904
2024-07-14 07:04:30,745 [INFO    ] __main__: train step 17941: loss: 1.0068, policy_loss: 0.9517, value_loss: 0.4904
2024-07-14 07:04:31,035 [INFO    ] __main__: train step 17942: loss: 1.0068, policy_loss: 0.9516, value_loss: 0.4904
2024-07-14 07:04:31,321 [INFO    ] __main__: train step 17943: loss: 1.0068, policy_loss: 0.9516, value_loss: 0.4904
2024-07-14 07:04:31,616 [INFO    ] __main__: train step 17944: loss: 1.0068, policy_loss: 0.9516, value_loss: 0.4903
2024-07-14 07:04:31,907 [INFO    ] __main__: train step 17945: loss: 1.0068, policy_loss: 0.9516, value_loss: 0.4903
2024-07-14 07:04:32,201 [INFO    ] __main__: train step 17946: loss: 1.0067, policy_loss: 0.9516, value_loss: 0.4903
2024-07-14 07:04:32,486 [INFO    ] __main__: train step 17947: loss: 1.0067, policy_loss: 0.9516, value_loss: 0.4903
2024-07-14 07:04:32,801 [INFO    ] __main__: train step 17948: loss: 1.0067, policy_loss: 0.9515, value_loss: 0.4903
2024-07-14 07:04:34,395 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:04:34,886 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:04:34,957 [INFO    ] __main__: train step 17949: loss: 1.0067, policy_loss: 0.9515, value_loss: 0.4902
2024-07-14 07:04:35,261 [INFO    ] __main__: train step 17950: loss: 1.0067, policy_loss: 0.9515, value_loss: 0.4902
2024-07-14 07:04:35,542 [INFO    ] __main__: train step 17951: loss: 1.0067, policy_loss: 0.9515, value_loss: 0.4902
2024-07-14 07:04:35,812 [INFO    ] __main__: train step 17952: loss: 1.0066, policy_loss: 0.9515, value_loss: 0.4902
2024-07-14 07:04:36,081 [INFO    ] __main__: train step 17953: loss: 1.0066, policy_loss: 0.9515, value_loss: 0.4901
2024-07-14 07:04:36,380 [INFO    ] __main__: train step 17954: loss: 1.0066, policy_loss: 0.9514, value_loss: 0.4901
2024-07-14 07:04:36,670 [INFO    ] __main__: train step 17955: loss: 1.0066, policy_loss: 0.9514, value_loss: 0.4901
2024-07-14 07:04:36,960 [INFO    ] __main__: train step 17956: loss: 1.0066, policy_loss: 0.9514, value_loss: 0.4901
2024-07-14 07:04:37,257 [INFO    ] __main__: train step 17957: loss: 1.0066, policy_loss: 0.9514, value_loss: 0.4900
2024-07-14 07:04:37,515 [INFO    ] __main__: train step 17958: loss: 1.0066, policy_loss: 0.9514, value_loss: 0.4900
2024-07-14 07:04:37,802 [INFO    ] __main__: train step 17959: loss: 1.0065, policy_loss: 0.9514, value_loss: 0.4900
2024-07-14 07:04:38,105 [INFO    ] __main__: train step 17960: loss: 1.0065, policy_loss: 0.9513, value_loss: 0.4900
2024-07-14 07:04:38,388 [INFO    ] __main__: train step 17961: loss: 1.0065, policy_loss: 0.9513, value_loss: 0.4900
2024-07-14 07:04:38,688 [INFO    ] __main__: train step 17962: loss: 1.0065, policy_loss: 0.9513, value_loss: 0.4899
2024-07-14 07:04:38,976 [INFO    ] __main__: train step 17963: loss: 1.0065, policy_loss: 0.9513, value_loss: 0.4899
2024-07-14 07:04:39,274 [INFO    ] __main__: train step 17964: loss: 1.0065, policy_loss: 0.9513, value_loss: 0.4899
2024-07-14 07:04:39,562 [INFO    ] __main__: train step 17965: loss: 1.0065, policy_loss: 0.9513, value_loss: 0.4899
2024-07-14 07:04:41,187 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:04:41,676 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:04:41,746 [INFO    ] __main__: train step 17966: loss: 1.0064, policy_loss: 0.9512, value_loss: 0.4898
2024-07-14 07:04:42,049 [INFO    ] __main__: train step 17967: loss: 1.0064, policy_loss: 0.9512, value_loss: 0.4898
2024-07-14 07:04:42,332 [INFO    ] __main__: train step 17968: loss: 1.0064, policy_loss: 0.9512, value_loss: 0.4898
2024-07-14 07:04:42,594 [INFO    ] __main__: train step 17969: loss: 1.0064, policy_loss: 0.9512, value_loss: 0.4898
2024-07-14 07:04:42,868 [INFO    ] __main__: train step 17970: loss: 1.0064, policy_loss: 0.9512, value_loss: 0.4898
2024-07-14 07:04:43,172 [INFO    ] __main__: train step 17971: loss: 1.0064, policy_loss: 0.9512, value_loss: 0.4897
2024-07-14 07:04:43,466 [INFO    ] __main__: train step 17972: loss: 1.0063, policy_loss: 0.9511, value_loss: 0.4897
2024-07-14 07:04:43,725 [INFO    ] __main__: train step 17973: loss: 1.0063, policy_loss: 0.9511, value_loss: 0.4897
2024-07-14 07:04:43,991 [INFO    ] __main__: train step 17974: loss: 1.0063, policy_loss: 0.9511, value_loss: 0.4897
2024-07-14 07:04:44,300 [INFO    ] __main__: train step 17975: loss: 1.0063, policy_loss: 0.9511, value_loss: 0.4896
2024-07-14 07:04:44,610 [INFO    ] __main__: train step 17976: loss: 1.0063, policy_loss: 0.9511, value_loss: 0.4896
2024-07-14 07:04:44,903 [INFO    ] __main__: train step 17977: loss: 1.0063, policy_loss: 0.9511, value_loss: 0.4896
2024-07-14 07:04:45,201 [INFO    ] __main__: train step 17978: loss: 1.0063, policy_loss: 0.9510, value_loss: 0.4896
2024-07-14 07:04:45,488 [INFO    ] __main__: train step 17979: loss: 1.0062, policy_loss: 0.9510, value_loss: 0.4896
2024-07-14 07:04:45,794 [INFO    ] __main__: train step 17980: loss: 1.0062, policy_loss: 0.9510, value_loss: 0.4895
2024-07-14 07:04:46,090 [INFO    ] __main__: train step 17981: loss: 1.0062, policy_loss: 0.9510, value_loss: 0.4895
2024-07-14 07:04:46,381 [INFO    ] __main__: train step 17982: loss: 1.0062, policy_loss: 0.9510, value_loss: 0.4895
2024-07-14 07:04:48,004 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:04:48,482 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:04:48,554 [INFO    ] __main__: train step 17983: loss: 1.0062, policy_loss: 0.9510, value_loss: 0.4895
2024-07-14 07:04:48,812 [INFO    ] __main__: train step 17984: loss: 1.0062, policy_loss: 0.9509, value_loss: 0.4894
2024-07-14 07:04:49,089 [INFO    ] __main__: train step 17985: loss: 1.0062, policy_loss: 0.9509, value_loss: 0.4894
2024-07-14 07:04:49,382 [INFO    ] __main__: train step 17986: loss: 1.0061, policy_loss: 0.9509, value_loss: 0.4894
2024-07-14 07:04:49,673 [INFO    ] __main__: train step 17987: loss: 1.0061, policy_loss: 0.9509, value_loss: 0.4894
2024-07-14 07:04:49,948 [INFO    ] __main__: train step 17988: loss: 1.0061, policy_loss: 0.9509, value_loss: 0.4894
2024-07-14 07:04:50,223 [INFO    ] __main__: train step 17989: loss: 1.0061, policy_loss: 0.9509, value_loss: 0.4893
2024-07-14 07:04:50,529 [INFO    ] __main__: train step 17990: loss: 1.0061, policy_loss: 0.9508, value_loss: 0.4893
2024-07-14 07:04:50,835 [INFO    ] __main__: train step 17991: loss: 1.0061, policy_loss: 0.9508, value_loss: 0.4893
2024-07-14 07:04:51,131 [INFO    ] __main__: train step 17992: loss: 1.0060, policy_loss: 0.9508, value_loss: 0.4893
2024-07-14 07:04:51,424 [INFO    ] __main__: train step 17993: loss: 1.0060, policy_loss: 0.9508, value_loss: 0.4892
2024-07-14 07:04:51,698 [INFO    ] __main__: train step 17994: loss: 1.0060, policy_loss: 0.9508, value_loss: 0.4892
2024-07-14 07:04:51,987 [INFO    ] __main__: train step 17995: loss: 1.0060, policy_loss: 0.9508, value_loss: 0.4892
2024-07-14 07:04:52,288 [INFO    ] __main__: train step 17996: loss: 1.0060, policy_loss: 0.9507, value_loss: 0.4892
2024-07-14 07:04:52,592 [INFO    ] __main__: train step 17997: loss: 1.0060, policy_loss: 0.9507, value_loss: 0.4892
2024-07-14 07:04:52,873 [INFO    ] __main__: train step 17998: loss: 1.0060, policy_loss: 0.9507, value_loss: 0.4891
2024-07-14 07:04:53,138 [INFO    ] __main__: train step 17999: loss: 1.0059, policy_loss: 0.9507, value_loss: 0.4891
2024-07-14 07:04:54,751 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:04:55,225 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:04:55,297 [INFO    ] __main__: train step 18000: loss: 1.0059, policy_loss: 0.9507, value_loss: 0.4891
2024-07-14 07:04:55,452 [INFO    ] __main__: restored step 17000 for evaluation
2024-07-14 07:05:00,696 [INFO    ] __main__: test network ELO difference from baseline network: +36 (+8/-8) ELO from 32000 self-played games
2024-07-14 07:05:00,699 [INFO    ] __main__: game outcomes: W: 17229, D: 271, L: 14500
2024-07-14 07:05:00,701 [INFO    ] __main__: validation_elo_delta: 36, validation_elo: 2744
2024-07-14 07:05:01,428 [INFO    ] __main__: train step 18001: loss: 1.0059, policy_loss: 0.9507, value_loss: 0.4891
2024-07-14 07:05:01,717 [INFO    ] __main__: train step 18002: loss: 1.0059, policy_loss: 0.9506, value_loss: 0.4890
2024-07-14 07:05:02,008 [INFO    ] __main__: train step 18003: loss: 1.0059, policy_loss: 0.9506, value_loss: 0.4890
2024-07-14 07:05:02,304 [INFO    ] __main__: train step 18004: loss: 1.0059, policy_loss: 0.9506, value_loss: 0.4890
2024-07-14 07:05:02,562 [INFO    ] __main__: train step 18005: loss: 1.0058, policy_loss: 0.9506, value_loss: 0.4890
2024-07-14 07:05:02,827 [INFO    ] __main__: train step 18006: loss: 1.0058, policy_loss: 0.9506, value_loss: 0.4889
2024-07-14 07:05:03,105 [INFO    ] __main__: train step 18007: loss: 1.0058, policy_loss: 0.9506, value_loss: 0.4889
2024-07-14 07:05:03,407 [INFO    ] __main__: train step 18008: loss: 1.0058, policy_loss: 0.9505, value_loss: 0.4889
2024-07-14 07:05:03,704 [INFO    ] __main__: train step 18009: loss: 1.0058, policy_loss: 0.9505, value_loss: 0.4889
2024-07-14 07:05:04,021 [INFO    ] __main__: train step 18010: loss: 1.0058, policy_loss: 0.9505, value_loss: 0.4889
2024-07-14 07:05:04,316 [INFO    ] __main__: train step 18011: loss: 1.0058, policy_loss: 0.9505, value_loss: 0.4888
2024-07-14 07:05:04,597 [INFO    ] __main__: train step 18012: loss: 1.0057, policy_loss: 0.9505, value_loss: 0.4888
2024-07-14 07:05:04,892 [INFO    ] __main__: train step 18013: loss: 1.0057, policy_loss: 0.9505, value_loss: 0.4888
2024-07-14 07:05:05,191 [INFO    ] __main__: train step 18014: loss: 1.0057, policy_loss: 0.9504, value_loss: 0.4888
2024-07-14 07:05:08,722 [INFO    ] __main__: train step 18015: loss: 1.0057, policy_loss: 0.9504, value_loss: 0.4887
2024-07-14 07:05:09,004 [INFO    ] __main__: train step 18016: loss: 1.0057, policy_loss: 0.9504, value_loss: 0.4887
2024-07-14 07:05:10,602 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:05:11,081 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:05:11,155 [INFO    ] __main__: train step 18017: loss: 1.0057, policy_loss: 0.9504, value_loss: 0.4887
2024-07-14 07:05:11,452 [INFO    ] __main__: train step 18018: loss: 1.0056, policy_loss: 0.9504, value_loss: 0.4887
2024-07-14 07:05:11,750 [INFO    ] __main__: train step 18019: loss: 1.0056, policy_loss: 0.9504, value_loss: 0.4887
2024-07-14 07:05:12,045 [INFO    ] __main__: train step 18020: loss: 1.0056, policy_loss: 0.9503, value_loss: 0.4886
2024-07-14 07:05:12,329 [INFO    ] __main__: train step 18021: loss: 1.0056, policy_loss: 0.9503, value_loss: 0.4886
2024-07-14 07:05:12,622 [INFO    ] __main__: train step 18022: loss: 1.0056, policy_loss: 0.9503, value_loss: 0.4886
2024-07-14 07:05:12,912 [INFO    ] __main__: train step 18023: loss: 1.0056, policy_loss: 0.9503, value_loss: 0.4886
2024-07-14 07:05:13,216 [INFO    ] __main__: train step 18024: loss: 1.0056, policy_loss: 0.9503, value_loss: 0.4885
2024-07-14 07:05:13,522 [INFO    ] __main__: train step 18025: loss: 1.0055, policy_loss: 0.9503, value_loss: 0.4885
2024-07-14 07:05:13,820 [INFO    ] __main__: train step 18026: loss: 1.0055, policy_loss: 0.9502, value_loss: 0.4885
2024-07-14 07:05:14,105 [INFO    ] __main__: train step 18027: loss: 1.0055, policy_loss: 0.9502, value_loss: 0.4885
2024-07-14 07:05:14,390 [INFO    ] __main__: train step 18028: loss: 1.0055, policy_loss: 0.9502, value_loss: 0.4885
2024-07-14 07:05:14,695 [INFO    ] __main__: train step 18029: loss: 1.0055, policy_loss: 0.9502, value_loss: 0.4884
2024-07-14 07:05:14,996 [INFO    ] __main__: train step 18030: loss: 1.0055, policy_loss: 0.9502, value_loss: 0.4884
2024-07-14 07:05:15,280 [INFO    ] __main__: train step 18031: loss: 1.0055, policy_loss: 0.9502, value_loss: 0.4884
2024-07-14 07:05:15,571 [INFO    ] __main__: train step 18032: loss: 1.0054, policy_loss: 0.9501, value_loss: 0.4884
2024-07-14 07:05:15,842 [INFO    ] __main__: train step 18033: loss: 1.0054, policy_loss: 0.9501, value_loss: 0.4883
2024-07-14 07:05:17,466 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:05:17,951 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:05:18,020 [INFO    ] __main__: train step 18034: loss: 1.0054, policy_loss: 0.9501, value_loss: 0.4883
2024-07-14 07:05:18,309 [INFO    ] __main__: train step 18035: loss: 1.0054, policy_loss: 0.9501, value_loss: 0.4883
2024-07-14 07:05:18,594 [INFO    ] __main__: train step 18036: loss: 1.0054, policy_loss: 0.9501, value_loss: 0.4883
2024-07-14 07:05:18,881 [INFO    ] __main__: train step 18037: loss: 1.0054, policy_loss: 0.9501, value_loss: 0.4883
2024-07-14 07:05:19,171 [INFO    ] __main__: train step 18038: loss: 1.0053, policy_loss: 0.9500, value_loss: 0.4882
2024-07-14 07:05:19,464 [INFO    ] __main__: train step 18039: loss: 1.0053, policy_loss: 0.9500, value_loss: 0.4882
2024-07-14 07:05:19,759 [INFO    ] __main__: train step 18040: loss: 1.0053, policy_loss: 0.9500, value_loss: 0.4882
2024-07-14 07:05:20,057 [INFO    ] __main__: train step 18041: loss: 1.0053, policy_loss: 0.9500, value_loss: 0.4882
2024-07-14 07:05:20,321 [INFO    ] __main__: train step 18042: loss: 1.0053, policy_loss: 0.9500, value_loss: 0.4881
2024-07-14 07:05:20,597 [INFO    ] __main__: train step 18043: loss: 1.0053, policy_loss: 0.9500, value_loss: 0.4881
2024-07-14 07:05:20,904 [INFO    ] __main__: train step 18044: loss: 1.0053, policy_loss: 0.9499, value_loss: 0.4881
2024-07-14 07:05:21,185 [INFO    ] __main__: train step 18045: loss: 1.0052, policy_loss: 0.9499, value_loss: 0.4881
2024-07-14 07:05:21,477 [INFO    ] __main__: train step 18046: loss: 1.0052, policy_loss: 0.9499, value_loss: 0.4881
2024-07-14 07:05:21,760 [INFO    ] __main__: train step 18047: loss: 1.0052, policy_loss: 0.9499, value_loss: 0.4880
2024-07-14 07:05:22,050 [INFO    ] __main__: train step 18048: loss: 1.0052, policy_loss: 0.9499, value_loss: 0.4880
2024-07-14 07:05:22,337 [INFO    ] __main__: train step 18049: loss: 1.0052, policy_loss: 0.9499, value_loss: 0.4880
2024-07-14 07:05:22,638 [INFO    ] __main__: train step 18050: loss: 1.0052, policy_loss: 0.9498, value_loss: 0.4880
2024-07-14 07:05:24,271 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:05:24,753 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:05:24,817 [INFO    ] __main__: train step 18051: loss: 1.0051, policy_loss: 0.9498, value_loss: 0.4879
2024-07-14 07:05:25,080 [INFO    ] __main__: train step 18052: loss: 1.0051, policy_loss: 0.9498, value_loss: 0.4879
2024-07-14 07:05:25,364 [INFO    ] __main__: train step 18053: loss: 1.0051, policy_loss: 0.9498, value_loss: 0.4879
2024-07-14 07:05:25,663 [INFO    ] __main__: train step 18054: loss: 1.0051, policy_loss: 0.9498, value_loss: 0.4879
2024-07-14 07:05:25,959 [INFO    ] __main__: train step 18055: loss: 1.0051, policy_loss: 0.9497, value_loss: 0.4879
2024-07-14 07:05:26,262 [INFO    ] __main__: train step 18056: loss: 1.0051, policy_loss: 0.9497, value_loss: 0.4878
2024-07-14 07:05:26,533 [INFO    ] __main__: train step 18057: loss: 1.0051, policy_loss: 0.9497, value_loss: 0.4878
2024-07-14 07:05:26,814 [INFO    ] __main__: train step 18058: loss: 1.0050, policy_loss: 0.9497, value_loss: 0.4878
2024-07-14 07:05:27,105 [INFO    ] __main__: train step 18059: loss: 1.0050, policy_loss: 0.9497, value_loss: 0.4878
2024-07-14 07:05:27,399 [INFO    ] __main__: train step 18060: loss: 1.0050, policy_loss: 0.9497, value_loss: 0.4877
2024-07-14 07:05:27,691 [INFO    ] __main__: train step 18061: loss: 1.0050, policy_loss: 0.9496, value_loss: 0.4877
2024-07-14 07:05:27,992 [INFO    ] __main__: train step 18062: loss: 1.0050, policy_loss: 0.9496, value_loss: 0.4877
2024-07-14 07:05:28,265 [INFO    ] __main__: train step 18063: loss: 1.0050, policy_loss: 0.9496, value_loss: 0.4877
2024-07-14 07:05:28,554 [INFO    ] __main__: train step 18064: loss: 1.0050, policy_loss: 0.9496, value_loss: 0.4877
2024-07-14 07:05:28,842 [INFO    ] __main__: train step 18065: loss: 1.0049, policy_loss: 0.9496, value_loss: 0.4876
2024-07-14 07:05:29,136 [INFO    ] __main__: train step 18066: loss: 1.0049, policy_loss: 0.9496, value_loss: 0.4876
2024-07-14 07:05:29,429 [INFO    ] __main__: train step 18067: loss: 1.0049, policy_loss: 0.9495, value_loss: 0.4876
2024-07-14 07:05:31,034 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:05:31,517 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:05:31,588 [INFO    ] __main__: train step 18068: loss: 1.0049, policy_loss: 0.9495, value_loss: 0.4876
2024-07-14 07:05:31,880 [INFO    ] __main__: train step 18069: loss: 1.0049, policy_loss: 0.9495, value_loss: 0.4875
2024-07-14 07:05:32,175 [INFO    ] __main__: train step 18070: loss: 1.0049, policy_loss: 0.9495, value_loss: 0.4875
2024-07-14 07:05:32,473 [INFO    ] __main__: train step 18071: loss: 1.0048, policy_loss: 0.9495, value_loss: 0.4875
2024-07-14 07:05:32,758 [INFO    ] __main__: train step 18072: loss: 1.0048, policy_loss: 0.9495, value_loss: 0.4875
2024-07-14 07:05:33,033 [INFO    ] __main__: train step 18073: loss: 1.0048, policy_loss: 0.9494, value_loss: 0.4875
2024-07-14 07:05:33,330 [INFO    ] __main__: train step 18074: loss: 1.0048, policy_loss: 0.9494, value_loss: 0.4874
2024-07-14 07:05:33,629 [INFO    ] __main__: train step 18075: loss: 1.0048, policy_loss: 0.9494, value_loss: 0.4874
2024-07-14 07:05:33,931 [INFO    ] __main__: train step 18076: loss: 1.0048, policy_loss: 0.9494, value_loss: 0.4874
2024-07-14 07:05:34,230 [INFO    ] __main__: train step 18077: loss: 1.0048, policy_loss: 0.9494, value_loss: 0.4874
2024-07-14 07:05:34,510 [INFO    ] __main__: train step 18078: loss: 1.0047, policy_loss: 0.9494, value_loss: 0.4873
2024-07-14 07:05:34,801 [INFO    ] __main__: train step 18079: loss: 1.0047, policy_loss: 0.9493, value_loss: 0.4873
2024-07-14 07:05:35,097 [INFO    ] __main__: train step 18080: loss: 1.0047, policy_loss: 0.9493, value_loss: 0.4873
2024-07-14 07:05:35,383 [INFO    ] __main__: train step 18081: loss: 1.0047, policy_loss: 0.9493, value_loss: 0.4873
2024-07-14 07:05:35,662 [INFO    ] __main__: train step 18082: loss: 1.0047, policy_loss: 0.9493, value_loss: 0.4873
2024-07-14 07:05:35,926 [INFO    ] __main__: train step 18083: loss: 1.0047, policy_loss: 0.9493, value_loss: 0.4872
2024-07-14 07:05:36,223 [INFO    ] __main__: train step 18084: loss: 1.0046, policy_loss: 0.9493, value_loss: 0.4872
2024-07-14 07:05:37,842 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:05:38,328 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:05:38,399 [INFO    ] __main__: train step 18085: loss: 1.0046, policy_loss: 0.9492, value_loss: 0.4872
2024-07-14 07:05:38,691 [INFO    ] __main__: train step 18086: loss: 1.0046, policy_loss: 0.9492, value_loss: 0.4872
2024-07-14 07:05:38,971 [INFO    ] __main__: train step 18087: loss: 1.0046, policy_loss: 0.9492, value_loss: 0.4871
2024-07-14 07:05:39,254 [INFO    ] __main__: train step 18088: loss: 1.0046, policy_loss: 0.9492, value_loss: 0.4871
2024-07-14 07:05:39,542 [INFO    ] __main__: train step 18089: loss: 1.0046, policy_loss: 0.9492, value_loss: 0.4871
2024-07-14 07:05:39,842 [INFO    ] __main__: train step 18090: loss: 1.0046, policy_loss: 0.9492, value_loss: 0.4871
2024-07-14 07:05:40,141 [INFO    ] __main__: train step 18091: loss: 1.0045, policy_loss: 0.9491, value_loss: 0.4871
2024-07-14 07:05:40,439 [INFO    ] __main__: train step 18092: loss: 1.0045, policy_loss: 0.9491, value_loss: 0.4870
2024-07-14 07:05:40,736 [INFO    ] __main__: train step 18093: loss: 1.0045, policy_loss: 0.9491, value_loss: 0.4870
2024-07-14 07:05:41,018 [INFO    ] __main__: train step 18094: loss: 1.0045, policy_loss: 0.9491, value_loss: 0.4870
2024-07-14 07:05:41,317 [INFO    ] __main__: train step 18095: loss: 1.0045, policy_loss: 0.9491, value_loss: 0.4870
2024-07-14 07:05:41,605 [INFO    ] __main__: train step 18096: loss: 1.0045, policy_loss: 0.9491, value_loss: 0.4869
2024-07-14 07:05:41,909 [INFO    ] __main__: train step 18097: loss: 1.0044, policy_loss: 0.9490, value_loss: 0.4869
2024-07-14 07:05:42,209 [INFO    ] __main__: train step 18098: loss: 1.0044, policy_loss: 0.9490, value_loss: 0.4869
2024-07-14 07:05:42,475 [INFO    ] __main__: train step 18099: loss: 1.0044, policy_loss: 0.9490, value_loss: 0.4869
2024-07-14 07:05:42,767 [INFO    ] __main__: train step 18100: loss: 1.0044, policy_loss: 0.9490, value_loss: 0.4869
2024-07-14 07:05:43,056 [INFO    ] __main__: train step 18101: loss: 1.0044, policy_loss: 0.9490, value_loss: 0.4868
2024-07-14 07:05:44,686 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:05:45,151 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:05:45,221 [INFO    ] __main__: train step 18102: loss: 1.0044, policy_loss: 0.9490, value_loss: 0.4868
2024-07-14 07:05:45,501 [INFO    ] __main__: train step 18103: loss: 1.0044, policy_loss: 0.9489, value_loss: 0.4868
2024-07-14 07:05:45,749 [INFO    ] __main__: train step 18104: loss: 1.0043, policy_loss: 0.9489, value_loss: 0.4868
2024-07-14 07:05:46,021 [INFO    ] __main__: train step 18105: loss: 1.0043, policy_loss: 0.9489, value_loss: 0.4867
2024-07-14 07:05:46,324 [INFO    ] __main__: train step 18106: loss: 1.0043, policy_loss: 0.9489, value_loss: 0.4867
2024-07-14 07:05:46,629 [INFO    ] __main__: train step 18107: loss: 1.0043, policy_loss: 0.9489, value_loss: 0.4867
2024-07-14 07:05:46,921 [INFO    ] __main__: train step 18108: loss: 1.0043, policy_loss: 0.9489, value_loss: 0.4867
2024-07-14 07:05:47,208 [INFO    ] __main__: train step 18109: loss: 1.0043, policy_loss: 0.9488, value_loss: 0.4866
2024-07-14 07:05:47,473 [INFO    ] __main__: train step 18110: loss: 1.0042, policy_loss: 0.9488, value_loss: 0.4866
2024-07-14 07:05:47,742 [INFO    ] __main__: train step 18111: loss: 1.0042, policy_loss: 0.9488, value_loss: 0.4866
2024-07-14 07:05:48,039 [INFO    ] __main__: train step 18112: loss: 1.0042, policy_loss: 0.9488, value_loss: 0.4866
2024-07-14 07:05:48,346 [INFO    ] __main__: train step 18113: loss: 1.0042, policy_loss: 0.9488, value_loss: 0.4866
2024-07-14 07:05:48,640 [INFO    ] __main__: train step 18114: loss: 1.0042, policy_loss: 0.9488, value_loss: 0.4865
2024-07-14 07:05:48,933 [INFO    ] __main__: train step 18115: loss: 1.0042, policy_loss: 0.9487, value_loss: 0.4865
2024-07-14 07:05:49,218 [INFO    ] __main__: train step 18116: loss: 1.0042, policy_loss: 0.9487, value_loss: 0.4865
2024-07-14 07:05:49,521 [INFO    ] __main__: train step 18117: loss: 1.0041, policy_loss: 0.9487, value_loss: 0.4865
2024-07-14 07:05:52,797 [INFO    ] __main__: train step 18118: loss: 1.0041, policy_loss: 0.9487, value_loss: 0.4864
2024-07-14 07:05:54,411 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:05:54,901 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:05:54,971 [INFO    ] __main__: train step 18119: loss: 1.0041, policy_loss: 0.9487, value_loss: 0.4864
2024-07-14 07:05:55,264 [INFO    ] __main__: train step 18120: loss: 1.0041, policy_loss: 0.9487, value_loss: 0.4864
2024-07-14 07:05:55,548 [INFO    ] __main__: train step 18121: loss: 1.0041, policy_loss: 0.9486, value_loss: 0.4864
2024-07-14 07:05:55,827 [INFO    ] __main__: train step 18122: loss: 1.0041, policy_loss: 0.9486, value_loss: 0.4864
2024-07-14 07:05:56,115 [INFO    ] __main__: train step 18123: loss: 1.0040, policy_loss: 0.9486, value_loss: 0.4863
2024-07-14 07:05:56,404 [INFO    ] __main__: train step 18124: loss: 1.0040, policy_loss: 0.9486, value_loss: 0.4863
2024-07-14 07:05:56,721 [INFO    ] __main__: train step 18125: loss: 1.0040, policy_loss: 0.9486, value_loss: 0.4863
2024-07-14 07:05:57,018 [INFO    ] __main__: train step 18126: loss: 1.0040, policy_loss: 0.9485, value_loss: 0.4863
2024-07-14 07:05:57,323 [INFO    ] __main__: train step 18127: loss: 1.0040, policy_loss: 0.9485, value_loss: 0.4863
2024-07-14 07:05:57,590 [INFO    ] __main__: train step 18128: loss: 1.0040, policy_loss: 0.9485, value_loss: 0.4862
2024-07-14 07:05:57,884 [INFO    ] __main__: train step 18129: loss: 1.0040, policy_loss: 0.9485, value_loss: 0.4862
2024-07-14 07:05:58,160 [INFO    ] __main__: train step 18130: loss: 1.0039, policy_loss: 0.9485, value_loss: 0.4862
2024-07-14 07:05:58,425 [INFO    ] __main__: train step 18131: loss: 1.0039, policy_loss: 0.9485, value_loss: 0.4862
2024-07-14 07:05:58,709 [INFO    ] __main__: train step 18132: loss: 1.0039, policy_loss: 0.9484, value_loss: 0.4861
2024-07-14 07:05:59,007 [INFO    ] __main__: train step 18133: loss: 1.0039, policy_loss: 0.9484, value_loss: 0.4861
2024-07-14 07:05:59,301 [INFO    ] __main__: train step 18134: loss: 1.0039, policy_loss: 0.9484, value_loss: 0.4861
2024-07-14 07:05:59,593 [INFO    ] __main__: train step 18135: loss: 1.0039, policy_loss: 0.9484, value_loss: 0.4861
2024-07-14 07:06:01,203 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:06:01,695 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:06:01,767 [INFO    ] __main__: train step 18136: loss: 1.0039, policy_loss: 0.9484, value_loss: 0.4861
2024-07-14 07:06:02,081 [INFO    ] __main__: train step 18137: loss: 1.0038, policy_loss: 0.9484, value_loss: 0.4860
2024-07-14 07:06:02,375 [INFO    ] __main__: train step 18138: loss: 1.0038, policy_loss: 0.9483, value_loss: 0.4860
2024-07-14 07:06:02,653 [INFO    ] __main__: train step 18139: loss: 1.0038, policy_loss: 0.9483, value_loss: 0.4860
2024-07-14 07:06:02,928 [INFO    ] __main__: train step 18140: loss: 1.0038, policy_loss: 0.9483, value_loss: 0.4860
2024-07-14 07:06:03,177 [INFO    ] __main__: train step 18141: loss: 1.0038, policy_loss: 0.9483, value_loss: 0.4859
2024-07-14 07:06:03,420 [INFO    ] __main__: train step 18142: loss: 1.0038, policy_loss: 0.9483, value_loss: 0.4859
2024-07-14 07:06:03,709 [INFO    ] __main__: train step 18143: loss: 1.0038, policy_loss: 0.9483, value_loss: 0.4859
2024-07-14 07:06:03,985 [INFO    ] __main__: train step 18144: loss: 1.0037, policy_loss: 0.9483, value_loss: 0.4859
2024-07-14 07:06:04,279 [INFO    ] __main__: train step 18145: loss: 1.0037, policy_loss: 0.9482, value_loss: 0.4859
2024-07-14 07:06:04,568 [INFO    ] __main__: train step 18146: loss: 1.0037, policy_loss: 0.9482, value_loss: 0.4858
2024-07-14 07:06:04,855 [INFO    ] __main__: train step 18147: loss: 1.0037, policy_loss: 0.9482, value_loss: 0.4858
2024-07-14 07:06:05,148 [INFO    ] __main__: train step 18148: loss: 1.0037, policy_loss: 0.9482, value_loss: 0.4858
2024-07-14 07:06:05,443 [INFO    ] __main__: train step 18149: loss: 1.0037, policy_loss: 0.9482, value_loss: 0.4858
2024-07-14 07:06:05,748 [INFO    ] __main__: train step 18150: loss: 1.0037, policy_loss: 0.9482, value_loss: 0.4857
2024-07-14 07:06:06,051 [INFO    ] __main__: train step 18151: loss: 1.0036, policy_loss: 0.9481, value_loss: 0.4857
2024-07-14 07:06:06,321 [INFO    ] __main__: train step 18152: loss: 1.0036, policy_loss: 0.9481, value_loss: 0.4857
2024-07-14 07:06:07,934 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:06:08,393 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:06:08,464 [INFO    ] __main__: train step 18153: loss: 1.0036, policy_loss: 0.9481, value_loss: 0.4857
2024-07-14 07:06:08,765 [INFO    ] __main__: train step 18154: loss: 1.0036, policy_loss: 0.9481, value_loss: 0.4857
2024-07-14 07:06:09,035 [INFO    ] __main__: train step 18155: loss: 1.0036, policy_loss: 0.9481, value_loss: 0.4856
2024-07-14 07:06:09,338 [INFO    ] __main__: train step 18156: loss: 1.0036, policy_loss: 0.9481, value_loss: 0.4856
2024-07-14 07:06:09,626 [INFO    ] __main__: train step 18157: loss: 1.0035, policy_loss: 0.9480, value_loss: 0.4856
2024-07-14 07:06:09,919 [INFO    ] __main__: train step 18158: loss: 1.0035, policy_loss: 0.9480, value_loss: 0.4856
2024-07-14 07:06:10,216 [INFO    ] __main__: train step 18159: loss: 1.0035, policy_loss: 0.9480, value_loss: 0.4855
2024-07-14 07:06:10,516 [INFO    ] __main__: train step 18160: loss: 1.0035, policy_loss: 0.9480, value_loss: 0.4855
2024-07-14 07:06:10,806 [INFO    ] __main__: train step 18161: loss: 1.0035, policy_loss: 0.9480, value_loss: 0.4855
2024-07-14 07:06:11,107 [INFO    ] __main__: train step 18162: loss: 1.0035, policy_loss: 0.9480, value_loss: 0.4855
2024-07-14 07:06:11,404 [INFO    ] __main__: train step 18163: loss: 1.0035, policy_loss: 0.9479, value_loss: 0.4855
2024-07-14 07:06:11,687 [INFO    ] __main__: train step 18164: loss: 1.0034, policy_loss: 0.9479, value_loss: 0.4854
2024-07-14 07:06:11,983 [INFO    ] __main__: train step 18165: loss: 1.0034, policy_loss: 0.9479, value_loss: 0.4854
2024-07-14 07:06:12,291 [INFO    ] __main__: train step 18166: loss: 1.0034, policy_loss: 0.9479, value_loss: 0.4854
2024-07-14 07:06:12,622 [INFO    ] __main__: train step 18167: loss: 1.0034, policy_loss: 0.9479, value_loss: 0.4854
2024-07-14 07:06:12,893 [INFO    ] __main__: train step 18168: loss: 1.0034, policy_loss: 0.9478, value_loss: 0.4854
2024-07-14 07:06:13,189 [INFO    ] __main__: train step 18169: loss: 1.0034, policy_loss: 0.9478, value_loss: 0.4853
2024-07-14 07:06:14,812 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:06:15,287 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:06:15,364 [INFO    ] __main__: train step 18170: loss: 1.0033, policy_loss: 0.9478, value_loss: 0.4853
2024-07-14 07:06:15,666 [INFO    ] __main__: train step 18171: loss: 1.0033, policy_loss: 0.9478, value_loss: 0.4853
2024-07-14 07:06:15,954 [INFO    ] __main__: train step 18172: loss: 1.0033, policy_loss: 0.9478, value_loss: 0.4853
2024-07-14 07:06:16,239 [INFO    ] __main__: train step 18173: loss: 1.0033, policy_loss: 0.9478, value_loss: 0.4852
2024-07-14 07:06:16,525 [INFO    ] __main__: train step 18174: loss: 1.0033, policy_loss: 0.9477, value_loss: 0.4852
2024-07-14 07:06:16,832 [INFO    ] __main__: train step 18175: loss: 1.0033, policy_loss: 0.9477, value_loss: 0.4852
2024-07-14 07:06:17,135 [INFO    ] __main__: train step 18176: loss: 1.0033, policy_loss: 0.9477, value_loss: 0.4852
2024-07-14 07:06:17,430 [INFO    ] __main__: train step 18177: loss: 1.0032, policy_loss: 0.9477, value_loss: 0.4852
2024-07-14 07:06:17,709 [INFO    ] __main__: train step 18178: loss: 1.0032, policy_loss: 0.9477, value_loss: 0.4851
2024-07-14 07:06:17,973 [INFO    ] __main__: train step 18179: loss: 1.0032, policy_loss: 0.9477, value_loss: 0.4851
2024-07-14 07:06:18,267 [INFO    ] __main__: train step 18180: loss: 1.0032, policy_loss: 0.9476, value_loss: 0.4851
2024-07-14 07:06:18,567 [INFO    ] __main__: train step 18181: loss: 1.0032, policy_loss: 0.9476, value_loss: 0.4851
2024-07-14 07:06:18,848 [INFO    ] __main__: train step 18182: loss: 1.0032, policy_loss: 0.9476, value_loss: 0.4850
2024-07-14 07:06:19,130 [INFO    ] __main__: train step 18183: loss: 1.0032, policy_loss: 0.9476, value_loss: 0.4850
2024-07-14 07:06:19,429 [INFO    ] __main__: train step 18184: loss: 1.0031, policy_loss: 0.9476, value_loss: 0.4850
2024-07-14 07:06:19,738 [INFO    ] __main__: train step 18185: loss: 1.0031, policy_loss: 0.9476, value_loss: 0.4850
2024-07-14 07:06:20,048 [INFO    ] __main__: train step 18186: loss: 1.0031, policy_loss: 0.9475, value_loss: 0.4850
2024-07-14 07:06:21,671 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:06:22,138 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:06:22,209 [INFO    ] __main__: train step 18187: loss: 1.0031, policy_loss: 0.9475, value_loss: 0.4849
2024-07-14 07:06:22,517 [INFO    ] __main__: train step 18188: loss: 1.0031, policy_loss: 0.9475, value_loss: 0.4849
2024-07-14 07:06:22,821 [INFO    ] __main__: train step 18189: loss: 1.0031, policy_loss: 0.9475, value_loss: 0.4849
2024-07-14 07:06:23,116 [INFO    ] __main__: train step 18190: loss: 1.0030, policy_loss: 0.9475, value_loss: 0.4849
2024-07-14 07:06:23,410 [INFO    ] __main__: train step 18191: loss: 1.0030, policy_loss: 0.9475, value_loss: 0.4848
2024-07-14 07:06:23,703 [INFO    ] __main__: train step 18192: loss: 1.0030, policy_loss: 0.9474, value_loss: 0.4848
2024-07-14 07:06:23,989 [INFO    ] __main__: train step 18193: loss: 1.0030, policy_loss: 0.9474, value_loss: 0.4848
2024-07-14 07:06:24,293 [INFO    ] __main__: train step 18194: loss: 1.0030, policy_loss: 0.9474, value_loss: 0.4848
2024-07-14 07:06:24,591 [INFO    ] __main__: train step 18195: loss: 1.0030, policy_loss: 0.9474, value_loss: 0.4848
2024-07-14 07:06:24,883 [INFO    ] __main__: train step 18196: loss: 1.0030, policy_loss: 0.9474, value_loss: 0.4847
2024-07-14 07:06:25,187 [INFO    ] __main__: train step 18197: loss: 1.0029, policy_loss: 0.9474, value_loss: 0.4847
2024-07-14 07:06:25,491 [INFO    ] __main__: train step 18198: loss: 1.0029, policy_loss: 0.9473, value_loss: 0.4847
2024-07-14 07:06:25,788 [INFO    ] __main__: train step 18199: loss: 1.0029, policy_loss: 0.9473, value_loss: 0.4847
2024-07-14 07:06:26,086 [INFO    ] __main__: train step 18200: loss: 1.0029, policy_loss: 0.9473, value_loss: 0.4847
2024-07-14 07:06:26,376 [INFO    ] __main__: train step 18201: loss: 1.0029, policy_loss: 0.9473, value_loss: 0.4846
2024-07-14 07:06:26,663 [INFO    ] __main__: train step 18202: loss: 1.0029, policy_loss: 0.9473, value_loss: 0.4846
2024-07-14 07:06:26,957 [INFO    ] __main__: train step 18203: loss: 1.0028, policy_loss: 0.9473, value_loss: 0.4846
2024-07-14 07:06:28,583 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:06:29,069 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:06:29,142 [INFO    ] __main__: train step 18204: loss: 1.0028, policy_loss: 0.9472, value_loss: 0.4846
2024-07-14 07:06:29,437 [INFO    ] __main__: train step 18205: loss: 1.0028, policy_loss: 0.9472, value_loss: 0.4845
2024-07-14 07:06:29,725 [INFO    ] __main__: train step 18206: loss: 1.0028, policy_loss: 0.9472, value_loss: 0.4845
2024-07-14 07:06:30,030 [INFO    ] __main__: train step 18207: loss: 1.0028, policy_loss: 0.9472, value_loss: 0.4845
2024-07-14 07:06:30,333 [INFO    ] __main__: train step 18208: loss: 1.0028, policy_loss: 0.9472, value_loss: 0.4845
2024-07-14 07:06:30,633 [INFO    ] __main__: train step 18209: loss: 1.0028, policy_loss: 0.9472, value_loss: 0.4845
2024-07-14 07:06:30,915 [INFO    ] __main__: train step 18210: loss: 1.0027, policy_loss: 0.9471, value_loss: 0.4844
2024-07-14 07:06:31,190 [INFO    ] __main__: train step 18211: loss: 1.0027, policy_loss: 0.9471, value_loss: 0.4844
2024-07-14 07:06:31,476 [INFO    ] __main__: train step 18212: loss: 1.0027, policy_loss: 0.9471, value_loss: 0.4844
2024-07-14 07:06:31,771 [INFO    ] __main__: train step 18213: loss: 1.0027, policy_loss: 0.9471, value_loss: 0.4844
2024-07-14 07:06:32,062 [INFO    ] __main__: train step 18214: loss: 1.0027, policy_loss: 0.9471, value_loss: 0.4843
2024-07-14 07:06:32,363 [INFO    ] __main__: train step 18215: loss: 1.0027, policy_loss: 0.9471, value_loss: 0.4843
2024-07-14 07:06:32,652 [INFO    ] __main__: train step 18216: loss: 1.0027, policy_loss: 0.9470, value_loss: 0.4843
2024-07-14 07:06:32,946 [INFO    ] __main__: train step 18217: loss: 1.0026, policy_loss: 0.9470, value_loss: 0.4843
2024-07-14 07:06:33,230 [INFO    ] __main__: train step 18218: loss: 1.0026, policy_loss: 0.9470, value_loss: 0.4843
2024-07-14 07:06:33,525 [INFO    ] __main__: train step 18219: loss: 1.0026, policy_loss: 0.9470, value_loss: 0.4842
2024-07-14 07:06:33,813 [INFO    ] __main__: train step 18220: loss: 1.0026, policy_loss: 0.9470, value_loss: 0.4842
2024-07-14 07:06:35,397 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:06:35,869 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:06:35,941 [INFO    ] __main__: train step 18221: loss: 1.0026, policy_loss: 0.9469, value_loss: 0.4842
2024-07-14 07:06:39,470 [INFO    ] __main__: train step 18222: loss: 1.0026, policy_loss: 0.9469, value_loss: 0.4842
2024-07-14 07:06:39,746 [INFO    ] __main__: train step 18223: loss: 1.0025, policy_loss: 0.9469, value_loss: 0.4842
2024-07-14 07:06:40,040 [INFO    ] __main__: train step 18224: loss: 1.0025, policy_loss: 0.9469, value_loss: 0.4841
2024-07-14 07:06:40,342 [INFO    ] __main__: train step 18225: loss: 1.0025, policy_loss: 0.9469, value_loss: 0.4841
2024-07-14 07:06:40,634 [INFO    ] __main__: train step 18226: loss: 1.0025, policy_loss: 0.9469, value_loss: 0.4841
2024-07-14 07:06:40,931 [INFO    ] __main__: train step 18227: loss: 1.0025, policy_loss: 0.9468, value_loss: 0.4841
2024-07-14 07:06:41,230 [INFO    ] __main__: train step 18228: loss: 1.0025, policy_loss: 0.9468, value_loss: 0.4840
2024-07-14 07:06:41,522 [INFO    ] __main__: train step 18229: loss: 1.0025, policy_loss: 0.9468, value_loss: 0.4840
2024-07-14 07:06:41,824 [INFO    ] __main__: train step 18230: loss: 1.0024, policy_loss: 0.9468, value_loss: 0.4840
2024-07-14 07:06:42,134 [INFO    ] __main__: train step 18231: loss: 1.0024, policy_loss: 0.9468, value_loss: 0.4840
2024-07-14 07:06:42,403 [INFO    ] __main__: train step 18232: loss: 1.0024, policy_loss: 0.9468, value_loss: 0.4840
2024-07-14 07:06:42,687 [INFO    ] __main__: train step 18233: loss: 1.0024, policy_loss: 0.9467, value_loss: 0.4839
2024-07-14 07:06:42,979 [INFO    ] __main__: train step 18234: loss: 1.0024, policy_loss: 0.9467, value_loss: 0.4839
2024-07-14 07:06:43,271 [INFO    ] __main__: train step 18235: loss: 1.0024, policy_loss: 0.9467, value_loss: 0.4839
2024-07-14 07:06:43,559 [INFO    ] __main__: train step 18236: loss: 1.0023, policy_loss: 0.9467, value_loss: 0.4839
2024-07-14 07:06:43,852 [INFO    ] __main__: train step 18237: loss: 1.0023, policy_loss: 0.9467, value_loss: 0.4839
2024-07-14 07:06:45,476 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:06:45,953 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:06:46,021 [INFO    ] __main__: train step 18238: loss: 1.0023, policy_loss: 0.9467, value_loss: 0.4838
2024-07-14 07:06:46,310 [INFO    ] __main__: train step 18239: loss: 1.0023, policy_loss: 0.9466, value_loss: 0.4838
2024-07-14 07:06:46,585 [INFO    ] __main__: train step 18240: loss: 1.0023, policy_loss: 0.9466, value_loss: 0.4838
2024-07-14 07:06:46,840 [INFO    ] __main__: train step 18241: loss: 1.0023, policy_loss: 0.9466, value_loss: 0.4838
2024-07-14 07:06:47,112 [INFO    ] __main__: train step 18242: loss: 1.0023, policy_loss: 0.9466, value_loss: 0.4837
2024-07-14 07:06:47,377 [INFO    ] __main__: train step 18243: loss: 1.0022, policy_loss: 0.9466, value_loss: 0.4837
2024-07-14 07:06:47,645 [INFO    ] __main__: train step 18244: loss: 1.0022, policy_loss: 0.9466, value_loss: 0.4837
2024-07-14 07:06:47,934 [INFO    ] __main__: train step 18245: loss: 1.0022, policy_loss: 0.9465, value_loss: 0.4837
2024-07-14 07:06:48,206 [INFO    ] __main__: train step 18246: loss: 1.0022, policy_loss: 0.9465, value_loss: 0.4837
2024-07-14 07:06:48,478 [INFO    ] __main__: train step 18247: loss: 1.0022, policy_loss: 0.9465, value_loss: 0.4836
2024-07-14 07:06:48,764 [INFO    ] __main__: train step 18248: loss: 1.0022, policy_loss: 0.9465, value_loss: 0.4836
2024-07-14 07:06:49,042 [INFO    ] __main__: train step 18249: loss: 1.0022, policy_loss: 0.9465, value_loss: 0.4836
2024-07-14 07:06:49,325 [INFO    ] __main__: train step 18250: loss: 1.0021, policy_loss: 0.9465, value_loss: 0.4836
2024-07-14 07:06:49,608 [INFO    ] __main__: train step 18251: loss: 1.0021, policy_loss: 0.9464, value_loss: 0.4836
2024-07-14 07:06:49,890 [INFO    ] __main__: train step 18252: loss: 1.0021, policy_loss: 0.9464, value_loss: 0.4835
2024-07-14 07:06:50,170 [INFO    ] __main__: train step 18253: loss: 1.0021, policy_loss: 0.9464, value_loss: 0.4835
2024-07-14 07:06:50,443 [INFO    ] __main__: train step 18254: loss: 1.0021, policy_loss: 0.9464, value_loss: 0.4835
2024-07-14 07:06:52,039 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:06:52,523 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:06:52,592 [INFO    ] __main__: train step 18255: loss: 1.0021, policy_loss: 0.9464, value_loss: 0.4835
2024-07-14 07:06:52,869 [INFO    ] __main__: train step 18256: loss: 1.0020, policy_loss: 0.9464, value_loss: 0.4834
2024-07-14 07:06:53,144 [INFO    ] __main__: train step 18257: loss: 1.0020, policy_loss: 0.9463, value_loss: 0.4834
2024-07-14 07:06:53,432 [INFO    ] __main__: train step 18258: loss: 1.0020, policy_loss: 0.9463, value_loss: 0.4834
2024-07-14 07:06:53,713 [INFO    ] __main__: train step 18259: loss: 1.0020, policy_loss: 0.9463, value_loss: 0.4834
2024-07-14 07:06:53,960 [INFO    ] __main__: train step 18260: loss: 1.0020, policy_loss: 0.9463, value_loss: 0.4834
2024-07-14 07:06:54,233 [INFO    ] __main__: train step 18261: loss: 1.0020, policy_loss: 0.9463, value_loss: 0.4833
2024-07-14 07:06:54,499 [INFO    ] __main__: train step 18262: loss: 1.0020, policy_loss: 0.9463, value_loss: 0.4833
2024-07-14 07:06:54,810 [INFO    ] __main__: train step 18263: loss: 1.0019, policy_loss: 0.9462, value_loss: 0.4833
2024-07-14 07:06:55,088 [INFO    ] __main__: train step 18264: loss: 1.0019, policy_loss: 0.9462, value_loss: 0.4833
2024-07-14 07:06:55,379 [INFO    ] __main__: train step 18265: loss: 1.0019, policy_loss: 0.9462, value_loss: 0.4833
2024-07-14 07:06:55,656 [INFO    ] __main__: train step 18266: loss: 1.0019, policy_loss: 0.9462, value_loss: 0.4832
2024-07-14 07:06:55,955 [INFO    ] __main__: train step 18267: loss: 1.0019, policy_loss: 0.9462, value_loss: 0.4832
2024-07-14 07:06:56,220 [INFO    ] __main__: train step 18268: loss: 1.0019, policy_loss: 0.9462, value_loss: 0.4832
2024-07-14 07:06:56,471 [INFO    ] __main__: train step 18269: loss: 1.0019, policy_loss: 0.9461, value_loss: 0.4832
2024-07-14 07:06:56,758 [INFO    ] __main__: train step 18270: loss: 1.0018, policy_loss: 0.9461, value_loss: 0.4831
2024-07-14 07:06:57,049 [INFO    ] __main__: train step 18271: loss: 1.0018, policy_loss: 0.9461, value_loss: 0.4831
2024-07-14 07:06:58,653 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:06:59,137 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:06:59,205 [INFO    ] __main__: train step 18272: loss: 1.0018, policy_loss: 0.9461, value_loss: 0.4831
2024-07-14 07:06:59,478 [INFO    ] __main__: train step 18273: loss: 1.0018, policy_loss: 0.9461, value_loss: 0.4831
2024-07-14 07:06:59,740 [INFO    ] __main__: train step 18274: loss: 1.0018, policy_loss: 0.9461, value_loss: 0.4831
2024-07-14 07:06:59,991 [INFO    ] __main__: train step 18275: loss: 1.0018, policy_loss: 0.9460, value_loss: 0.4830
2024-07-14 07:07:00,247 [INFO    ] __main__: train step 18276: loss: 1.0018, policy_loss: 0.9460, value_loss: 0.4830
2024-07-14 07:07:00,518 [INFO    ] __main__: train step 18277: loss: 1.0017, policy_loss: 0.9460, value_loss: 0.4830
2024-07-14 07:07:00,808 [INFO    ] __main__: train step 18278: loss: 1.0017, policy_loss: 0.9460, value_loss: 0.4830
2024-07-14 07:07:01,086 [INFO    ] __main__: train step 18279: loss: 1.0017, policy_loss: 0.9460, value_loss: 0.4830
2024-07-14 07:07:01,342 [INFO    ] __main__: train step 18280: loss: 1.0017, policy_loss: 0.9460, value_loss: 0.4829
2024-07-14 07:07:01,602 [INFO    ] __main__: train step 18281: loss: 1.0017, policy_loss: 0.9459, value_loss: 0.4829
2024-07-14 07:07:01,873 [INFO    ] __main__: train step 18282: loss: 1.0017, policy_loss: 0.9459, value_loss: 0.4829
2024-07-14 07:07:02,121 [INFO    ] __main__: train step 18283: loss: 1.0017, policy_loss: 0.9459, value_loss: 0.4829
2024-07-14 07:07:02,386 [INFO    ] __main__: train step 18284: loss: 1.0016, policy_loss: 0.9459, value_loss: 0.4829
2024-07-14 07:07:02,655 [INFO    ] __main__: train step 18285: loss: 1.0016, policy_loss: 0.9459, value_loss: 0.4828
2024-07-14 07:07:02,937 [INFO    ] __main__: train step 18286: loss: 1.0016, policy_loss: 0.9458, value_loss: 0.4828
2024-07-14 07:07:03,190 [INFO    ] __main__: train step 18287: loss: 1.0016, policy_loss: 0.9458, value_loss: 0.4828
2024-07-14 07:07:03,432 [INFO    ] __main__: train step 18288: loss: 1.0016, policy_loss: 0.9458, value_loss: 0.4828
2024-07-14 07:07:05,022 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:07:05,506 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:07:05,572 [INFO    ] __main__: train step 18289: loss: 1.0016, policy_loss: 0.9458, value_loss: 0.4827
2024-07-14 07:07:05,842 [INFO    ] __main__: train step 18290: loss: 1.0015, policy_loss: 0.9458, value_loss: 0.4827
2024-07-14 07:07:06,116 [INFO    ] __main__: train step 18291: loss: 1.0015, policy_loss: 0.9458, value_loss: 0.4827
2024-07-14 07:07:06,396 [INFO    ] __main__: train step 18292: loss: 1.0015, policy_loss: 0.9457, value_loss: 0.4827
2024-07-14 07:07:06,670 [INFO    ] __main__: train step 18293: loss: 1.0015, policy_loss: 0.9457, value_loss: 0.4827
2024-07-14 07:07:06,939 [INFO    ] __main__: train step 18294: loss: 1.0015, policy_loss: 0.9457, value_loss: 0.4826
2024-07-14 07:07:07,198 [INFO    ] __main__: train step 18295: loss: 1.0015, policy_loss: 0.9457, value_loss: 0.4826
2024-07-14 07:07:07,477 [INFO    ] __main__: train step 18296: loss: 1.0015, policy_loss: 0.9457, value_loss: 0.4826
2024-07-14 07:07:07,763 [INFO    ] __main__: train step 18297: loss: 1.0014, policy_loss: 0.9457, value_loss: 0.4826
2024-07-14 07:07:08,048 [INFO    ] __main__: train step 18298: loss: 1.0014, policy_loss: 0.9456, value_loss: 0.4826
2024-07-14 07:07:08,328 [INFO    ] __main__: train step 18299: loss: 1.0014, policy_loss: 0.9456, value_loss: 0.4825
2024-07-14 07:07:08,595 [INFO    ] __main__: train step 18300: loss: 1.0014, policy_loss: 0.9456, value_loss: 0.4825
2024-07-14 07:07:08,853 [INFO    ] __main__: train step 18301: loss: 1.0014, policy_loss: 0.9456, value_loss: 0.4825
2024-07-14 07:07:09,129 [INFO    ] __main__: train step 18302: loss: 1.0014, policy_loss: 0.9456, value_loss: 0.4825
2024-07-14 07:07:09,396 [INFO    ] __main__: train step 18303: loss: 1.0014, policy_loss: 0.9456, value_loss: 0.4824
2024-07-14 07:07:09,647 [INFO    ] __main__: train step 18304: loss: 1.0013, policy_loss: 0.9455, value_loss: 0.4824
2024-07-14 07:07:09,910 [INFO    ] __main__: train step 18305: loss: 1.0013, policy_loss: 0.9455, value_loss: 0.4824
2024-07-14 07:07:11,487 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:07:11,945 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:07:12,014 [INFO    ] __main__: train step 18306: loss: 1.0013, policy_loss: 0.9455, value_loss: 0.4824
2024-07-14 07:07:12,278 [INFO    ] __main__: train step 18307: loss: 1.0013, policy_loss: 0.9455, value_loss: 0.4824
2024-07-14 07:07:12,526 [INFO    ] __main__: train step 18308: loss: 1.0013, policy_loss: 0.9455, value_loss: 0.4823
2024-07-14 07:07:12,810 [INFO    ] __main__: train step 18309: loss: 1.0013, policy_loss: 0.9455, value_loss: 0.4823
2024-07-14 07:07:13,107 [INFO    ] __main__: train step 18310: loss: 1.0013, policy_loss: 0.9454, value_loss: 0.4823
2024-07-14 07:07:13,382 [INFO    ] __main__: train step 18311: loss: 1.0012, policy_loss: 0.9454, value_loss: 0.4823
2024-07-14 07:07:13,639 [INFO    ] __main__: train step 18312: loss: 1.0012, policy_loss: 0.9454, value_loss: 0.4823
2024-07-14 07:07:13,912 [INFO    ] __main__: train step 18313: loss: 1.0012, policy_loss: 0.9454, value_loss: 0.4822
2024-07-14 07:07:14,185 [INFO    ] __main__: train step 18314: loss: 1.0012, policy_loss: 0.9454, value_loss: 0.4822
2024-07-14 07:07:14,476 [INFO    ] __main__: train step 18315: loss: 1.0012, policy_loss: 0.9454, value_loss: 0.4822
2024-07-14 07:07:14,753 [INFO    ] __main__: train step 18316: loss: 1.0012, policy_loss: 0.9453, value_loss: 0.4822
2024-07-14 07:07:15,039 [INFO    ] __main__: train step 18317: loss: 1.0011, policy_loss: 0.9453, value_loss: 0.4822
2024-07-14 07:07:15,317 [INFO    ] __main__: train step 18318: loss: 1.0011, policy_loss: 0.9453, value_loss: 0.4821
2024-07-14 07:07:15,598 [INFO    ] __main__: train step 18319: loss: 1.0011, policy_loss: 0.9453, value_loss: 0.4821
2024-07-14 07:07:15,875 [INFO    ] __main__: train step 18320: loss: 1.0011, policy_loss: 0.9453, value_loss: 0.4821
2024-07-14 07:07:16,160 [INFO    ] __main__: train step 18321: loss: 1.0011, policy_loss: 0.9453, value_loss: 0.4821
2024-07-14 07:07:16,431 [INFO    ] __main__: train step 18322: loss: 1.0011, policy_loss: 0.9452, value_loss: 0.4820
2024-07-14 07:07:18,022 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:07:18,489 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:07:18,556 [INFO    ] __main__: train step 18323: loss: 1.0011, policy_loss: 0.9452, value_loss: 0.4820
2024-07-14 07:07:18,828 [INFO    ] __main__: train step 18324: loss: 1.0010, policy_loss: 0.9452, value_loss: 0.4820
2024-07-14 07:07:22,180 [INFO    ] __main__: train step 18325: loss: 1.0010, policy_loss: 0.9452, value_loss: 0.4820
2024-07-14 07:07:22,441 [INFO    ] __main__: train step 18326: loss: 1.0010, policy_loss: 0.9452, value_loss: 0.4820
2024-07-14 07:07:22,699 [INFO    ] __main__: train step 18327: loss: 1.0010, policy_loss: 0.9452, value_loss: 0.4819
2024-07-14 07:07:22,966 [INFO    ] __main__: train step 18328: loss: 1.0010, policy_loss: 0.9451, value_loss: 0.4819
2024-07-14 07:07:23,249 [INFO    ] __main__: train step 18329: loss: 1.0010, policy_loss: 0.9451, value_loss: 0.4819
2024-07-14 07:07:23,541 [INFO    ] __main__: train step 18330: loss: 1.0010, policy_loss: 0.9451, value_loss: 0.4819
2024-07-14 07:07:23,820 [INFO    ] __main__: train step 18331: loss: 1.0009, policy_loss: 0.9451, value_loss: 0.4819
2024-07-14 07:07:24,100 [INFO    ] __main__: train step 18332: loss: 1.0009, policy_loss: 0.9451, value_loss: 0.4818
2024-07-14 07:07:24,383 [INFO    ] __main__: train step 18333: loss: 1.0009, policy_loss: 0.9451, value_loss: 0.4818
2024-07-14 07:07:24,649 [INFO    ] __main__: train step 18334: loss: 1.0009, policy_loss: 0.9450, value_loss: 0.4818
2024-07-14 07:07:24,924 [INFO    ] __main__: train step 18335: loss: 1.0009, policy_loss: 0.9450, value_loss: 0.4818
2024-07-14 07:07:25,179 [INFO    ] __main__: train step 18336: loss: 1.0009, policy_loss: 0.9450, value_loss: 0.4817
2024-07-14 07:07:25,446 [INFO    ] __main__: train step 18337: loss: 1.0008, policy_loss: 0.9450, value_loss: 0.4817
2024-07-14 07:07:25,700 [INFO    ] __main__: train step 18338: loss: 1.0008, policy_loss: 0.9450, value_loss: 0.4817
2024-07-14 07:07:25,954 [INFO    ] __main__: train step 18339: loss: 1.0008, policy_loss: 0.9449, value_loss: 0.4817
2024-07-14 07:07:27,498 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:07:27,964 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:07:28,031 [INFO    ] __main__: train step 18340: loss: 1.0008, policy_loss: 0.9449, value_loss: 0.4817
2024-07-14 07:07:28,291 [INFO    ] __main__: train step 18341: loss: 1.0008, policy_loss: 0.9449, value_loss: 0.4816
2024-07-14 07:07:28,569 [INFO    ] __main__: train step 18342: loss: 1.0008, policy_loss: 0.9449, value_loss: 0.4816
2024-07-14 07:07:28,852 [INFO    ] __main__: train step 18343: loss: 1.0008, policy_loss: 0.9449, value_loss: 0.4816
2024-07-14 07:07:29,120 [INFO    ] __main__: train step 18344: loss: 1.0007, policy_loss: 0.9449, value_loss: 0.4816
2024-07-14 07:07:29,409 [INFO    ] __main__: train step 18345: loss: 1.0007, policy_loss: 0.9448, value_loss: 0.4816
2024-07-14 07:07:29,661 [INFO    ] __main__: train step 18346: loss: 1.0007, policy_loss: 0.9448, value_loss: 0.4815
2024-07-14 07:07:29,922 [INFO    ] __main__: train step 18347: loss: 1.0007, policy_loss: 0.9448, value_loss: 0.4815
2024-07-14 07:07:30,180 [INFO    ] __main__: train step 18348: loss: 1.0007, policy_loss: 0.9448, value_loss: 0.4815
2024-07-14 07:07:30,420 [INFO    ] __main__: train step 18349: loss: 1.0007, policy_loss: 0.9448, value_loss: 0.4815
2024-07-14 07:07:30,680 [INFO    ] __main__: train step 18350: loss: 1.0007, policy_loss: 0.9448, value_loss: 0.4815
2024-07-14 07:07:30,940 [INFO    ] __main__: train step 18351: loss: 1.0006, policy_loss: 0.9447, value_loss: 0.4814
2024-07-14 07:07:31,217 [INFO    ] __main__: train step 18352: loss: 1.0006, policy_loss: 0.9447, value_loss: 0.4814
2024-07-14 07:07:31,479 [INFO    ] __main__: train step 18353: loss: 1.0006, policy_loss: 0.9447, value_loss: 0.4814
2024-07-14 07:07:31,720 [INFO    ] __main__: train step 18354: loss: 1.0006, policy_loss: 0.9447, value_loss: 0.4814
2024-07-14 07:07:31,965 [INFO    ] __main__: train step 18355: loss: 1.0006, policy_loss: 0.9447, value_loss: 0.4813
2024-07-14 07:07:32,239 [INFO    ] __main__: train step 18356: loss: 1.0006, policy_loss: 0.9447, value_loss: 0.4813
2024-07-14 07:07:33,825 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:07:34,310 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:07:34,384 [INFO    ] __main__: train step 18357: loss: 1.0006, policy_loss: 0.9446, value_loss: 0.4813
2024-07-14 07:07:34,634 [INFO    ] __main__: train step 18358: loss: 1.0005, policy_loss: 0.9446, value_loss: 0.4813
2024-07-14 07:07:34,907 [INFO    ] __main__: train step 18359: loss: 1.0005, policy_loss: 0.9446, value_loss: 0.4813
2024-07-14 07:07:35,186 [INFO    ] __main__: train step 18360: loss: 1.0005, policy_loss: 0.9446, value_loss: 0.4812
2024-07-14 07:07:35,450 [INFO    ] __main__: train step 18361: loss: 1.0005, policy_loss: 0.9446, value_loss: 0.4812
2024-07-14 07:07:35,718 [INFO    ] __main__: train step 18362: loss: 1.0005, policy_loss: 0.9446, value_loss: 0.4812
2024-07-14 07:07:35,980 [INFO    ] __main__: train step 18363: loss: 1.0005, policy_loss: 0.9445, value_loss: 0.4812
2024-07-14 07:07:36,239 [INFO    ] __main__: train step 18364: loss: 1.0005, policy_loss: 0.9445, value_loss: 0.4812
2024-07-14 07:07:36,506 [INFO    ] __main__: train step 18365: loss: 1.0004, policy_loss: 0.9445, value_loss: 0.4811
2024-07-14 07:07:36,787 [INFO    ] __main__: train step 18366: loss: 1.0004, policy_loss: 0.9445, value_loss: 0.4811
2024-07-14 07:07:37,062 [INFO    ] __main__: train step 18367: loss: 1.0004, policy_loss: 0.9445, value_loss: 0.4811
2024-07-14 07:07:37,330 [INFO    ] __main__: train step 18368: loss: 1.0004, policy_loss: 0.9445, value_loss: 0.4811
2024-07-14 07:07:37,598 [INFO    ] __main__: train step 18369: loss: 1.0004, policy_loss: 0.9444, value_loss: 0.4811
2024-07-14 07:07:37,868 [INFO    ] __main__: train step 18370: loss: 1.0004, policy_loss: 0.9444, value_loss: 0.4810
2024-07-14 07:07:38,167 [INFO    ] __main__: train step 18371: loss: 1.0004, policy_loss: 0.9444, value_loss: 0.4810
2024-07-14 07:07:38,457 [INFO    ] __main__: train step 18372: loss: 1.0003, policy_loss: 0.9444, value_loss: 0.4810
2024-07-14 07:07:38,744 [INFO    ] __main__: train step 18373: loss: 1.0003, policy_loss: 0.9444, value_loss: 0.4810
2024-07-14 07:07:40,337 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:07:40,814 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:07:40,885 [INFO    ] __main__: train step 18374: loss: 1.0003, policy_loss: 0.9444, value_loss: 0.4809
2024-07-14 07:07:41,154 [INFO    ] __main__: train step 18375: loss: 1.0003, policy_loss: 0.9443, value_loss: 0.4809
2024-07-14 07:07:41,440 [INFO    ] __main__: train step 18376: loss: 1.0003, policy_loss: 0.9443, value_loss: 0.4809
2024-07-14 07:07:41,704 [INFO    ] __main__: train step 18377: loss: 1.0003, policy_loss: 0.9443, value_loss: 0.4809
2024-07-14 07:07:41,974 [INFO    ] __main__: train step 18378: loss: 1.0003, policy_loss: 0.9443, value_loss: 0.4809
2024-07-14 07:07:42,231 [INFO    ] __main__: train step 18379: loss: 1.0002, policy_loss: 0.9443, value_loss: 0.4808
2024-07-14 07:07:42,504 [INFO    ] __main__: train step 18380: loss: 1.0002, policy_loss: 0.9443, value_loss: 0.4808
2024-07-14 07:07:42,780 [INFO    ] __main__: train step 18381: loss: 1.0002, policy_loss: 0.9442, value_loss: 0.4808
2024-07-14 07:07:43,071 [INFO    ] __main__: train step 18382: loss: 1.0002, policy_loss: 0.9442, value_loss: 0.4808
2024-07-14 07:07:43,354 [INFO    ] __main__: train step 18383: loss: 1.0002, policy_loss: 0.9442, value_loss: 0.4808
2024-07-14 07:07:43,631 [INFO    ] __main__: train step 18384: loss: 1.0002, policy_loss: 0.9442, value_loss: 0.4807
2024-07-14 07:07:43,906 [INFO    ] __main__: train step 18385: loss: 1.0001, policy_loss: 0.9442, value_loss: 0.4807
2024-07-14 07:07:44,163 [INFO    ] __main__: train step 18386: loss: 1.0001, policy_loss: 0.9442, value_loss: 0.4807
2024-07-14 07:07:44,443 [INFO    ] __main__: train step 18387: loss: 1.0001, policy_loss: 0.9441, value_loss: 0.4807
2024-07-14 07:07:44,713 [INFO    ] __main__: train step 18388: loss: 1.0001, policy_loss: 0.9441, value_loss: 0.4807
2024-07-14 07:07:44,968 [INFO    ] __main__: train step 18389: loss: 1.0001, policy_loss: 0.9441, value_loss: 0.4806
2024-07-14 07:07:45,224 [INFO    ] __main__: train step 18390: loss: 1.0001, policy_loss: 0.9441, value_loss: 0.4806
2024-07-14 07:07:46,804 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:07:47,272 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:07:47,348 [INFO    ] __main__: train step 18391: loss: 1.0001, policy_loss: 0.9441, value_loss: 0.4806
2024-07-14 07:07:47,626 [INFO    ] __main__: train step 18392: loss: 1.0000, policy_loss: 0.9441, value_loss: 0.4806
2024-07-14 07:07:47,873 [INFO    ] __main__: train step 18393: loss: 1.0000, policy_loss: 0.9440, value_loss: 0.4805
2024-07-14 07:07:48,150 [INFO    ] __main__: train step 18394: loss: 1.0000, policy_loss: 0.9440, value_loss: 0.4805
2024-07-14 07:07:48,427 [INFO    ] __main__: train step 18395: loss: 1.0000, policy_loss: 0.9440, value_loss: 0.4805
2024-07-14 07:07:48,727 [INFO    ] __main__: train step 18396: loss: 1.0000, policy_loss: 0.9440, value_loss: 0.4805
2024-07-14 07:07:49,016 [INFO    ] __main__: train step 18397: loss: 1.0000, policy_loss: 0.9440, value_loss: 0.4805
2024-07-14 07:07:49,306 [INFO    ] __main__: train step 18398: loss: 1.0000, policy_loss: 0.9440, value_loss: 0.4804
2024-07-14 07:07:49,608 [INFO    ] __main__: train step 18399: loss: 0.9999, policy_loss: 0.9439, value_loss: 0.4804
2024-07-14 07:07:49,900 [INFO    ] __main__: train step 18400: loss: 0.9999, policy_loss: 0.9439, value_loss: 0.4804
2024-07-14 07:07:50,204 [INFO    ] __main__: train step 18401: loss: 0.9999, policy_loss: 0.9439, value_loss: 0.4804
2024-07-14 07:07:50,499 [INFO    ] __main__: train step 18402: loss: 0.9999, policy_loss: 0.9439, value_loss: 0.4804
2024-07-14 07:07:50,789 [INFO    ] __main__: train step 18403: loss: 0.9999, policy_loss: 0.9439, value_loss: 0.4803
2024-07-14 07:07:51,076 [INFO    ] __main__: train step 18404: loss: 0.9999, policy_loss: 0.9439, value_loss: 0.4803
2024-07-14 07:07:51,364 [INFO    ] __main__: train step 18405: loss: 0.9998, policy_loss: 0.9438, value_loss: 0.4803
2024-07-14 07:07:51,662 [INFO    ] __main__: train step 18406: loss: 0.9998, policy_loss: 0.9438, value_loss: 0.4803
2024-07-14 07:07:51,954 [INFO    ] __main__: train step 18407: loss: 0.9998, policy_loss: 0.9438, value_loss: 0.4803
2024-07-14 07:07:53,577 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:07:54,069 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:07:54,142 [INFO    ] __main__: train step 18408: loss: 0.9998, policy_loss: 0.9438, value_loss: 0.4802
2024-07-14 07:07:54,438 [INFO    ] __main__: train step 18409: loss: 0.9998, policy_loss: 0.9438, value_loss: 0.4802
2024-07-14 07:07:54,733 [INFO    ] __main__: train step 18410: loss: 0.9998, policy_loss: 0.9438, value_loss: 0.4802
2024-07-14 07:07:55,021 [INFO    ] __main__: train step 18411: loss: 0.9998, policy_loss: 0.9437, value_loss: 0.4802
2024-07-14 07:07:55,306 [INFO    ] __main__: train step 18412: loss: 0.9997, policy_loss: 0.9437, value_loss: 0.4801
2024-07-14 07:07:55,590 [INFO    ] __main__: train step 18413: loss: 0.9997, policy_loss: 0.9437, value_loss: 0.4801
2024-07-14 07:07:55,882 [INFO    ] __main__: train step 18414: loss: 0.9997, policy_loss: 0.9437, value_loss: 0.4801
2024-07-14 07:07:56,167 [INFO    ] __main__: train step 18415: loss: 0.9997, policy_loss: 0.9437, value_loss: 0.4801
2024-07-14 07:07:56,458 [INFO    ] __main__: train step 18416: loss: 0.9997, policy_loss: 0.9437, value_loss: 0.4801
2024-07-14 07:07:56,762 [INFO    ] __main__: train step 18417: loss: 0.9997, policy_loss: 0.9436, value_loss: 0.4800
2024-07-14 07:07:57,055 [INFO    ] __main__: train step 18418: loss: 0.9997, policy_loss: 0.9436, value_loss: 0.4800
2024-07-14 07:07:57,353 [INFO    ] __main__: train step 18419: loss: 0.9996, policy_loss: 0.9436, value_loss: 0.4800
2024-07-14 07:07:57,649 [INFO    ] __main__: train step 18420: loss: 0.9996, policy_loss: 0.9436, value_loss: 0.4800
2024-07-14 07:07:57,931 [INFO    ] __main__: train step 18421: loss: 0.9996, policy_loss: 0.9436, value_loss: 0.4800
2024-07-14 07:07:58,210 [INFO    ] __main__: train step 18422: loss: 0.9996, policy_loss: 0.9436, value_loss: 0.4799
2024-07-14 07:07:58,501 [INFO    ] __main__: train step 18423: loss: 0.9996, policy_loss: 0.9435, value_loss: 0.4799
2024-07-14 07:07:58,792 [INFO    ] __main__: train step 18424: loss: 0.9996, policy_loss: 0.9435, value_loss: 0.4799
2024-07-14 07:08:00,408 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:08:00,898 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:08:00,970 [INFO    ] __main__: train step 18425: loss: 0.9996, policy_loss: 0.9435, value_loss: 0.4799
2024-07-14 07:08:01,263 [INFO    ] __main__: train step 18426: loss: 0.9995, policy_loss: 0.9435, value_loss: 0.4799
2024-07-14 07:08:01,545 [INFO    ] __main__: train step 18427: loss: 0.9995, policy_loss: 0.9435, value_loss: 0.4798
2024-07-14 07:08:04,221 [INFO    ] __main__: train step 18428: loss: 0.9995, policy_loss: 0.9434, value_loss: 0.4798
2024-07-14 07:08:04,518 [INFO    ] __main__: train step 18429: loss: 0.9995, policy_loss: 0.9434, value_loss: 0.4798
2024-07-14 07:08:04,799 [INFO    ] __main__: train step 18430: loss: 0.9995, policy_loss: 0.9434, value_loss: 0.4798
2024-07-14 07:08:05,085 [INFO    ] __main__: train step 18431: loss: 0.9995, policy_loss: 0.9434, value_loss: 0.4797
2024-07-14 07:08:05,385 [INFO    ] __main__: train step 18432: loss: 0.9994, policy_loss: 0.9434, value_loss: 0.4797
2024-07-14 07:08:05,697 [INFO    ] __main__: train step 18433: loss: 0.9994, policy_loss: 0.9434, value_loss: 0.4797
2024-07-14 07:08:05,995 [INFO    ] __main__: train step 18434: loss: 0.9994, policy_loss: 0.9433, value_loss: 0.4797
2024-07-14 07:08:06,285 [INFO    ] __main__: train step 18435: loss: 0.9994, policy_loss: 0.9433, value_loss: 0.4797
2024-07-14 07:08:06,552 [INFO    ] __main__: train step 18436: loss: 0.9994, policy_loss: 0.9433, value_loss: 0.4796
2024-07-14 07:08:06,854 [INFO    ] __main__: train step 18437: loss: 0.9994, policy_loss: 0.9433, value_loss: 0.4796
2024-07-14 07:08:07,128 [INFO    ] __main__: train step 18438: loss: 0.9994, policy_loss: 0.9433, value_loss: 0.4796
2024-07-14 07:08:07,421 [INFO    ] __main__: train step 18439: loss: 0.9993, policy_loss: 0.9433, value_loss: 0.4796
2024-07-14 07:08:07,715 [INFO    ] __main__: train step 18440: loss: 0.9993, policy_loss: 0.9432, value_loss: 0.4796
2024-07-14 07:08:07,992 [INFO    ] __main__: train step 18441: loss: 0.9993, policy_loss: 0.9432, value_loss: 0.4795
2024-07-14 07:08:09,527 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:08:09,991 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:08:10,057 [INFO    ] __main__: train step 18442: loss: 0.9993, policy_loss: 0.9432, value_loss: 0.4795
2024-07-14 07:08:10,337 [INFO    ] __main__: train step 18443: loss: 0.9993, policy_loss: 0.9432, value_loss: 0.4795
2024-07-14 07:08:10,607 [INFO    ] __main__: train step 18444: loss: 0.9993, policy_loss: 0.9432, value_loss: 0.4795
2024-07-14 07:08:10,888 [INFO    ] __main__: train step 18445: loss: 0.9993, policy_loss: 0.9432, value_loss: 0.4795
2024-07-14 07:08:11,159 [INFO    ] __main__: train step 18446: loss: 0.9992, policy_loss: 0.9431, value_loss: 0.4794
2024-07-14 07:08:11,437 [INFO    ] __main__: train step 18447: loss: 0.9992, policy_loss: 0.9431, value_loss: 0.4794
2024-07-14 07:08:11,706 [INFO    ] __main__: train step 18448: loss: 0.9992, policy_loss: 0.9431, value_loss: 0.4794
2024-07-14 07:08:11,981 [INFO    ] __main__: train step 18449: loss: 0.9992, policy_loss: 0.9431, value_loss: 0.4794
2024-07-14 07:08:12,266 [INFO    ] __main__: train step 18450: loss: 0.9992, policy_loss: 0.9431, value_loss: 0.4794
2024-07-14 07:08:12,545 [INFO    ] __main__: train step 18451: loss: 0.9992, policy_loss: 0.9431, value_loss: 0.4793
2024-07-14 07:08:12,819 [INFO    ] __main__: train step 18452: loss: 0.9991, policy_loss: 0.9430, value_loss: 0.4793
2024-07-14 07:08:13,099 [INFO    ] __main__: train step 18453: loss: 0.9991, policy_loss: 0.9430, value_loss: 0.4793
2024-07-14 07:08:13,370 [INFO    ] __main__: train step 18454: loss: 0.9991, policy_loss: 0.9430, value_loss: 0.4793
2024-07-14 07:08:13,652 [INFO    ] __main__: train step 18455: loss: 0.9991, policy_loss: 0.9430, value_loss: 0.4792
2024-07-14 07:08:13,926 [INFO    ] __main__: train step 18456: loss: 0.9991, policy_loss: 0.9430, value_loss: 0.4792
2024-07-14 07:08:14,207 [INFO    ] __main__: train step 18457: loss: 0.9991, policy_loss: 0.9430, value_loss: 0.4792
2024-07-14 07:08:14,487 [INFO    ] __main__: train step 18458: loss: 0.9991, policy_loss: 0.9429, value_loss: 0.4792
2024-07-14 07:08:16,065 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:08:16,529 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:08:16,597 [INFO    ] __main__: train step 18459: loss: 0.9990, policy_loss: 0.9429, value_loss: 0.4792
2024-07-14 07:08:16,879 [INFO    ] __main__: train step 18460: loss: 0.9990, policy_loss: 0.9429, value_loss: 0.4791
2024-07-14 07:08:17,151 [INFO    ] __main__: train step 18461: loss: 0.9990, policy_loss: 0.9429, value_loss: 0.4791
2024-07-14 07:08:17,426 [INFO    ] __main__: train step 18462: loss: 0.9990, policy_loss: 0.9429, value_loss: 0.4791
2024-07-14 07:08:17,704 [INFO    ] __main__: train step 18463: loss: 0.9990, policy_loss: 0.9429, value_loss: 0.4791
2024-07-14 07:08:17,986 [INFO    ] __main__: train step 18464: loss: 0.9990, policy_loss: 0.9428, value_loss: 0.4791
2024-07-14 07:08:18,264 [INFO    ] __main__: train step 18465: loss: 0.9990, policy_loss: 0.9428, value_loss: 0.4790
2024-07-14 07:08:18,533 [INFO    ] __main__: train step 18466: loss: 0.9989, policy_loss: 0.9428, value_loss: 0.4790
2024-07-14 07:08:18,819 [INFO    ] __main__: train step 18467: loss: 0.9989, policy_loss: 0.9428, value_loss: 0.4790
2024-07-14 07:08:19,099 [INFO    ] __main__: train step 18468: loss: 0.9989, policy_loss: 0.9428, value_loss: 0.4790
2024-07-14 07:08:19,378 [INFO    ] __main__: train step 18469: loss: 0.9989, policy_loss: 0.9428, value_loss: 0.4790
2024-07-14 07:08:19,655 [INFO    ] __main__: train step 18470: loss: 0.9989, policy_loss: 0.9427, value_loss: 0.4789
2024-07-14 07:08:19,930 [INFO    ] __main__: train step 18471: loss: 0.9989, policy_loss: 0.9427, value_loss: 0.4789
2024-07-14 07:08:20,204 [INFO    ] __main__: train step 18472: loss: 0.9989, policy_loss: 0.9427, value_loss: 0.4789
2024-07-14 07:08:20,480 [INFO    ] __main__: train step 18473: loss: 0.9988, policy_loss: 0.9427, value_loss: 0.4789
2024-07-14 07:08:20,769 [INFO    ] __main__: train step 18474: loss: 0.9988, policy_loss: 0.9427, value_loss: 0.4789
2024-07-14 07:08:21,046 [INFO    ] __main__: train step 18475: loss: 0.9988, policy_loss: 0.9427, value_loss: 0.4788
2024-07-14 07:08:22,632 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:08:23,112 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:08:23,185 [INFO    ] __main__: train step 18476: loss: 0.9988, policy_loss: 0.9426, value_loss: 0.4788
2024-07-14 07:08:23,463 [INFO    ] __main__: train step 18477: loss: 0.9988, policy_loss: 0.9426, value_loss: 0.4788
2024-07-14 07:08:23,743 [INFO    ] __main__: train step 18478: loss: 0.9988, policy_loss: 0.9426, value_loss: 0.4788
2024-07-14 07:08:24,025 [INFO    ] __main__: train step 18479: loss: 0.9988, policy_loss: 0.9426, value_loss: 0.4787
2024-07-14 07:08:24,299 [INFO    ] __main__: train step 18480: loss: 0.9987, policy_loss: 0.9426, value_loss: 0.4787
2024-07-14 07:08:24,583 [INFO    ] __main__: train step 18481: loss: 0.9987, policy_loss: 0.9426, value_loss: 0.4787
2024-07-14 07:08:24,857 [INFO    ] __main__: train step 18482: loss: 0.9987, policy_loss: 0.9425, value_loss: 0.4787
2024-07-14 07:08:25,134 [INFO    ] __main__: train step 18483: loss: 0.9987, policy_loss: 0.9425, value_loss: 0.4787
2024-07-14 07:08:25,414 [INFO    ] __main__: train step 18484: loss: 0.9987, policy_loss: 0.9425, value_loss: 0.4786
2024-07-14 07:08:25,679 [INFO    ] __main__: train step 18485: loss: 0.9987, policy_loss: 0.9425, value_loss: 0.4786
2024-07-14 07:08:25,945 [INFO    ] __main__: train step 18486: loss: 0.9987, policy_loss: 0.9425, value_loss: 0.4786
2024-07-14 07:08:26,209 [INFO    ] __main__: train step 18487: loss: 0.9986, policy_loss: 0.9425, value_loss: 0.4786
2024-07-14 07:08:26,482 [INFO    ] __main__: train step 18488: loss: 0.9986, policy_loss: 0.9424, value_loss: 0.4786
2024-07-14 07:08:26,758 [INFO    ] __main__: train step 18489: loss: 0.9986, policy_loss: 0.9424, value_loss: 0.4785
2024-07-14 07:08:27,012 [INFO    ] __main__: train step 18490: loss: 0.9986, policy_loss: 0.9424, value_loss: 0.4785
2024-07-14 07:08:27,295 [INFO    ] __main__: train step 18491: loss: 0.9986, policy_loss: 0.9424, value_loss: 0.4785
2024-07-14 07:08:27,583 [INFO    ] __main__: train step 18492: loss: 0.9986, policy_loss: 0.9424, value_loss: 0.4785
2024-07-14 07:08:29,196 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:08:29,683 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:08:29,755 [INFO    ] __main__: train step 18493: loss: 0.9985, policy_loss: 0.9424, value_loss: 0.4785
2024-07-14 07:08:30,045 [INFO    ] __main__: train step 18494: loss: 0.9985, policy_loss: 0.9423, value_loss: 0.4784
2024-07-14 07:08:30,342 [INFO    ] __main__: train step 18495: loss: 0.9985, policy_loss: 0.9423, value_loss: 0.4784
2024-07-14 07:08:30,637 [INFO    ] __main__: train step 18496: loss: 0.9985, policy_loss: 0.9423, value_loss: 0.4784
2024-07-14 07:08:30,917 [INFO    ] __main__: train step 18497: loss: 0.9985, policy_loss: 0.9423, value_loss: 0.4784
2024-07-14 07:08:31,216 [INFO    ] __main__: train step 18498: loss: 0.9985, policy_loss: 0.9423, value_loss: 0.4784
2024-07-14 07:08:31,517 [INFO    ] __main__: train step 18499: loss: 0.9985, policy_loss: 0.9423, value_loss: 0.4783
2024-07-14 07:08:31,790 [INFO    ] __main__: train step 18500: loss: 0.9984, policy_loss: 0.9422, value_loss: 0.4783
2024-07-14 07:08:32,076 [INFO    ] __main__: train step 18501: loss: 0.9984, policy_loss: 0.9422, value_loss: 0.4783
2024-07-14 07:08:32,377 [INFO    ] __main__: train step 18502: loss: 0.9984, policy_loss: 0.9422, value_loss: 0.4783
2024-07-14 07:08:32,674 [INFO    ] __main__: train step 18503: loss: 0.9984, policy_loss: 0.9422, value_loss: 0.4782
2024-07-14 07:08:32,972 [INFO    ] __main__: train step 18504: loss: 0.9984, policy_loss: 0.9422, value_loss: 0.4782
2024-07-14 07:08:33,270 [INFO    ] __main__: train step 18505: loss: 0.9984, policy_loss: 0.9422, value_loss: 0.4782
2024-07-14 07:08:33,556 [INFO    ] __main__: train step 18506: loss: 0.9983, policy_loss: 0.9421, value_loss: 0.4782
2024-07-14 07:08:33,849 [INFO    ] __main__: train step 18507: loss: 0.9983, policy_loss: 0.9421, value_loss: 0.4782
2024-07-14 07:08:34,148 [INFO    ] __main__: train step 18508: loss: 0.9983, policy_loss: 0.9421, value_loss: 0.4781
2024-07-14 07:08:34,444 [INFO    ] __main__: train step 18509: loss: 0.9983, policy_loss: 0.9421, value_loss: 0.4781
2024-07-14 07:08:36,069 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:08:36,549 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:08:36,618 [INFO    ] __main__: train step 18510: loss: 0.9983, policy_loss: 0.9421, value_loss: 0.4781
2024-07-14 07:08:36,879 [INFO    ] __main__: train step 18511: loss: 0.9983, policy_loss: 0.9421, value_loss: 0.4781
2024-07-14 07:08:37,138 [INFO    ] __main__: train step 18512: loss: 0.9983, policy_loss: 0.9420, value_loss: 0.4781
2024-07-14 07:08:37,416 [INFO    ] __main__: train step 18513: loss: 0.9982, policy_loss: 0.9420, value_loss: 0.4780
2024-07-14 07:08:37,717 [INFO    ] __main__: train step 18514: loss: 0.9982, policy_loss: 0.9420, value_loss: 0.4780
2024-07-14 07:08:38,020 [INFO    ] __main__: train step 18515: loss: 0.9982, policy_loss: 0.9420, value_loss: 0.4780
2024-07-14 07:08:38,310 [INFO    ] __main__: train step 18516: loss: 0.9982, policy_loss: 0.9420, value_loss: 0.4780
2024-07-14 07:08:38,566 [INFO    ] __main__: train step 18517: loss: 0.9982, policy_loss: 0.9420, value_loss: 0.4780
2024-07-14 07:08:38,851 [INFO    ] __main__: train step 18518: loss: 0.9982, policy_loss: 0.9419, value_loss: 0.4779
2024-07-14 07:08:39,156 [INFO    ] __main__: train step 18519: loss: 0.9982, policy_loss: 0.9419, value_loss: 0.4779
2024-07-14 07:08:39,455 [INFO    ] __main__: train step 18520: loss: 0.9981, policy_loss: 0.9419, value_loss: 0.4779
2024-07-14 07:08:39,753 [INFO    ] __main__: train step 18521: loss: 0.9981, policy_loss: 0.9419, value_loss: 0.4779
2024-07-14 07:08:40,049 [INFO    ] __main__: train step 18522: loss: 0.9981, policy_loss: 0.9419, value_loss: 0.4779
2024-07-14 07:08:40,329 [INFO    ] __main__: train step 18523: loss: 0.9981, policy_loss: 0.9418, value_loss: 0.4778
2024-07-14 07:08:40,631 [INFO    ] __main__: train step 18524: loss: 0.9981, policy_loss: 0.9418, value_loss: 0.4778
2024-07-14 07:08:40,950 [INFO    ] __main__: train step 18525: loss: 0.9981, policy_loss: 0.9418, value_loss: 0.4778
2024-07-14 07:08:41,254 [INFO    ] __main__: train step 18526: loss: 0.9981, policy_loss: 0.9418, value_loss: 0.4778
2024-07-14 07:08:42,873 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:08:43,347 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:08:43,417 [INFO    ] __main__: train step 18527: loss: 0.9980, policy_loss: 0.9418, value_loss: 0.4777
2024-07-14 07:08:43,681 [INFO    ] __main__: train step 18528: loss: 0.9980, policy_loss: 0.9418, value_loss: 0.4777
2024-07-14 07:08:43,980 [INFO    ] __main__: train step 18529: loss: 0.9980, policy_loss: 0.9417, value_loss: 0.4777
2024-07-14 07:08:44,281 [INFO    ] __main__: train step 18530: loss: 0.9980, policy_loss: 0.9417, value_loss: 0.4777
2024-07-14 07:08:44,586 [INFO    ] __main__: train step 18531: loss: 0.9980, policy_loss: 0.9417, value_loss: 0.4777
2024-07-14 07:08:44,887 [INFO    ] __main__: train step 18532: loss: 0.9980, policy_loss: 0.9417, value_loss: 0.4776
2024-07-14 07:08:45,188 [INFO    ] __main__: train step 18533: loss: 0.9979, policy_loss: 0.9417, value_loss: 0.4776
2024-07-14 07:08:48,451 [INFO    ] __main__: train step 18534: loss: 0.9979, policy_loss: 0.9417, value_loss: 0.4776
2024-07-14 07:08:48,721 [INFO    ] __main__: train step 18535: loss: 0.9979, policy_loss: 0.9416, value_loss: 0.4776
2024-07-14 07:08:49,005 [INFO    ] __main__: train step 18536: loss: 0.9979, policy_loss: 0.9416, value_loss: 0.4776
2024-07-14 07:08:49,312 [INFO    ] __main__: train step 18537: loss: 0.9979, policy_loss: 0.9416, value_loss: 0.4775
2024-07-14 07:08:49,606 [INFO    ] __main__: train step 18538: loss: 0.9979, policy_loss: 0.9416, value_loss: 0.4775
2024-07-14 07:08:49,906 [INFO    ] __main__: train step 18539: loss: 0.9979, policy_loss: 0.9416, value_loss: 0.4775
2024-07-14 07:08:50,192 [INFO    ] __main__: train step 18540: loss: 0.9978, policy_loss: 0.9416, value_loss: 0.4775
2024-07-14 07:08:50,460 [INFO    ] __main__: train step 18541: loss: 0.9978, policy_loss: 0.9415, value_loss: 0.4775
2024-07-14 07:08:50,763 [INFO    ] __main__: train step 18542: loss: 0.9978, policy_loss: 0.9415, value_loss: 0.4774
2024-07-14 07:08:51,052 [INFO    ] __main__: train step 18543: loss: 0.9978, policy_loss: 0.9415, value_loss: 0.4774
2024-07-14 07:08:52,663 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:08:53,139 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:08:53,209 [INFO    ] __main__: train step 18544: loss: 0.9978, policy_loss: 0.9415, value_loss: 0.4774
2024-07-14 07:08:53,509 [INFO    ] __main__: train step 18545: loss: 0.9978, policy_loss: 0.9415, value_loss: 0.4774
2024-07-14 07:08:53,790 [INFO    ] __main__: train step 18546: loss: 0.9977, policy_loss: 0.9415, value_loss: 0.4774
2024-07-14 07:08:54,075 [INFO    ] __main__: train step 18547: loss: 0.9977, policy_loss: 0.9414, value_loss: 0.4773
2024-07-14 07:08:54,375 [INFO    ] __main__: train step 18548: loss: 0.9977, policy_loss: 0.9414, value_loss: 0.4773
2024-07-14 07:08:54,649 [INFO    ] __main__: train step 18549: loss: 0.9977, policy_loss: 0.9414, value_loss: 0.4773
2024-07-14 07:08:54,928 [INFO    ] __main__: train step 18550: loss: 0.9977, policy_loss: 0.9414, value_loss: 0.4773
2024-07-14 07:08:55,221 [INFO    ] __main__: train step 18551: loss: 0.9977, policy_loss: 0.9414, value_loss: 0.4773
2024-07-14 07:08:55,488 [INFO    ] __main__: train step 18552: loss: 0.9977, policy_loss: 0.9414, value_loss: 0.4772
2024-07-14 07:08:55,781 [INFO    ] __main__: train step 18553: loss: 0.9976, policy_loss: 0.9413, value_loss: 0.4772
2024-07-14 07:08:56,075 [INFO    ] __main__: train step 18554: loss: 0.9976, policy_loss: 0.9413, value_loss: 0.4772
2024-07-14 07:08:56,384 [INFO    ] __main__: train step 18555: loss: 0.9976, policy_loss: 0.9413, value_loss: 0.4772
2024-07-14 07:08:56,681 [INFO    ] __main__: train step 18556: loss: 0.9976, policy_loss: 0.9413, value_loss: 0.4771
2024-07-14 07:08:56,979 [INFO    ] __main__: train step 18557: loss: 0.9976, policy_loss: 0.9413, value_loss: 0.4771
2024-07-14 07:08:57,270 [INFO    ] __main__: train step 18558: loss: 0.9976, policy_loss: 0.9412, value_loss: 0.4771
2024-07-14 07:08:57,546 [INFO    ] __main__: train step 18559: loss: 0.9976, policy_loss: 0.9412, value_loss: 0.4771
2024-07-14 07:08:57,821 [INFO    ] __main__: train step 18560: loss: 0.9975, policy_loss: 0.9412, value_loss: 0.4771
2024-07-14 07:08:59,427 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:08:59,892 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:08:59,962 [INFO    ] __main__: train step 18561: loss: 0.9975, policy_loss: 0.9412, value_loss: 0.4770
2024-07-14 07:09:00,239 [INFO    ] __main__: train step 18562: loss: 0.9975, policy_loss: 0.9412, value_loss: 0.4770
2024-07-14 07:09:00,503 [INFO    ] __main__: train step 18563: loss: 0.9975, policy_loss: 0.9412, value_loss: 0.4770
2024-07-14 07:09:00,756 [INFO    ] __main__: train step 18564: loss: 0.9975, policy_loss: 0.9411, value_loss: 0.4770
2024-07-14 07:09:01,008 [INFO    ] __main__: train step 18565: loss: 0.9975, policy_loss: 0.9411, value_loss: 0.4770
2024-07-14 07:09:01,291 [INFO    ] __main__: train step 18566: loss: 0.9974, policy_loss: 0.9411, value_loss: 0.4769
2024-07-14 07:09:01,580 [INFO    ] __main__: train step 18567: loss: 0.9974, policy_loss: 0.9411, value_loss: 0.4769
2024-07-14 07:09:01,861 [INFO    ] __main__: train step 18568: loss: 0.9974, policy_loss: 0.9411, value_loss: 0.4769
2024-07-14 07:09:02,152 [INFO    ] __main__: train step 18569: loss: 0.9974, policy_loss: 0.9411, value_loss: 0.4769
2024-07-14 07:09:02,432 [INFO    ] __main__: train step 18570: loss: 0.9974, policy_loss: 0.9410, value_loss: 0.4769
2024-07-14 07:09:02,715 [INFO    ] __main__: train step 18571: loss: 0.9974, policy_loss: 0.9410, value_loss: 0.4768
2024-07-14 07:09:02,991 [INFO    ] __main__: train step 18572: loss: 0.9974, policy_loss: 0.9410, value_loss: 0.4768
2024-07-14 07:09:03,271 [INFO    ] __main__: train step 18573: loss: 0.9973, policy_loss: 0.9410, value_loss: 0.4768
2024-07-14 07:09:03,568 [INFO    ] __main__: train step 18574: loss: 0.9973, policy_loss: 0.9410, value_loss: 0.4768
2024-07-14 07:09:03,836 [INFO    ] __main__: train step 18575: loss: 0.9973, policy_loss: 0.9410, value_loss: 0.4768
2024-07-14 07:09:04,109 [INFO    ] __main__: train step 18576: loss: 0.9973, policy_loss: 0.9409, value_loss: 0.4767
2024-07-14 07:09:04,387 [INFO    ] __main__: train step 18577: loss: 0.9973, policy_loss: 0.9409, value_loss: 0.4767
2024-07-14 07:09:05,972 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:09:06,439 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:09:06,528 [INFO    ] __main__: train step 18578: loss: 0.9973, policy_loss: 0.9409, value_loss: 0.4767
2024-07-14 07:09:06,813 [INFO    ] __main__: train step 18579: loss: 0.9972, policy_loss: 0.9409, value_loss: 0.4767
2024-07-14 07:09:07,086 [INFO    ] __main__: train step 18580: loss: 0.9972, policy_loss: 0.9409, value_loss: 0.4767
2024-07-14 07:09:07,343 [INFO    ] __main__: train step 18581: loss: 0.9972, policy_loss: 0.9408, value_loss: 0.4766
2024-07-14 07:09:07,622 [INFO    ] __main__: train step 18582: loss: 0.9972, policy_loss: 0.9408, value_loss: 0.4766
2024-07-14 07:09:07,898 [INFO    ] __main__: train step 18583: loss: 0.9972, policy_loss: 0.9408, value_loss: 0.4766
2024-07-14 07:09:08,188 [INFO    ] __main__: train step 18584: loss: 0.9972, policy_loss: 0.9408, value_loss: 0.4766
2024-07-14 07:09:08,472 [INFO    ] __main__: train step 18585: loss: 0.9972, policy_loss: 0.9408, value_loss: 0.4766
2024-07-14 07:09:08,754 [INFO    ] __main__: train step 18586: loss: 0.9971, policy_loss: 0.9408, value_loss: 0.4765
2024-07-14 07:09:09,032 [INFO    ] __main__: train step 18587: loss: 0.9971, policy_loss: 0.9407, value_loss: 0.4765
2024-07-14 07:09:09,309 [INFO    ] __main__: train step 18588: loss: 0.9971, policy_loss: 0.9407, value_loss: 0.4765
2024-07-14 07:09:09,611 [INFO    ] __main__: train step 18589: loss: 0.9971, policy_loss: 0.9407, value_loss: 0.4765
2024-07-14 07:09:09,896 [INFO    ] __main__: train step 18590: loss: 0.9971, policy_loss: 0.9407, value_loss: 0.4764
2024-07-14 07:09:10,185 [INFO    ] __main__: train step 18591: loss: 0.9971, policy_loss: 0.9407, value_loss: 0.4764
2024-07-14 07:09:10,459 [INFO    ] __main__: train step 18592: loss: 0.9970, policy_loss: 0.9407, value_loss: 0.4764
2024-07-14 07:09:10,728 [INFO    ] __main__: train step 18593: loss: 0.9970, policy_loss: 0.9406, value_loss: 0.4764
2024-07-14 07:09:11,005 [INFO    ] __main__: train step 18594: loss: 0.9970, policy_loss: 0.9406, value_loss: 0.4764
2024-07-14 07:09:12,572 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:09:13,067 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:09:13,136 [INFO    ] __main__: train step 18595: loss: 0.9970, policy_loss: 0.9406, value_loss: 0.4763
2024-07-14 07:09:13,412 [INFO    ] __main__: train step 18596: loss: 0.9970, policy_loss: 0.9406, value_loss: 0.4763
2024-07-14 07:09:13,697 [INFO    ] __main__: train step 18597: loss: 0.9970, policy_loss: 0.9406, value_loss: 0.4763
2024-07-14 07:09:13,944 [INFO    ] __main__: train step 18598: loss: 0.9970, policy_loss: 0.9406, value_loss: 0.4763
2024-07-14 07:09:14,204 [INFO    ] __main__: train step 18599: loss: 0.9969, policy_loss: 0.9405, value_loss: 0.4763
2024-07-14 07:09:14,485 [INFO    ] __main__: train step 18600: loss: 0.9969, policy_loss: 0.9405, value_loss: 0.4762
2024-07-14 07:09:14,768 [INFO    ] __main__: train step 18601: loss: 0.9969, policy_loss: 0.9405, value_loss: 0.4762
2024-07-14 07:09:15,040 [INFO    ] __main__: train step 18602: loss: 0.9969, policy_loss: 0.9405, value_loss: 0.4762
2024-07-14 07:09:15,319 [INFO    ] __main__: train step 18603: loss: 0.9969, policy_loss: 0.9405, value_loss: 0.4762
2024-07-14 07:09:15,579 [INFO    ] __main__: train step 18604: loss: 0.9969, policy_loss: 0.9404, value_loss: 0.4762
2024-07-14 07:09:15,844 [INFO    ] __main__: train step 18605: loss: 0.9968, policy_loss: 0.9404, value_loss: 0.4761
2024-07-14 07:09:16,121 [INFO    ] __main__: train step 18606: loss: 0.9968, policy_loss: 0.9404, value_loss: 0.4761
2024-07-14 07:09:16,402 [INFO    ] __main__: train step 18607: loss: 0.9968, policy_loss: 0.9404, value_loss: 0.4761
2024-07-14 07:09:16,685 [INFO    ] __main__: train step 18608: loss: 0.9968, policy_loss: 0.9404, value_loss: 0.4761
2024-07-14 07:09:16,973 [INFO    ] __main__: train step 18609: loss: 0.9968, policy_loss: 0.9404, value_loss: 0.4761
2024-07-14 07:09:17,250 [INFO    ] __main__: train step 18610: loss: 0.9968, policy_loss: 0.9403, value_loss: 0.4760
2024-07-14 07:09:17,517 [INFO    ] __main__: train step 18611: loss: 0.9967, policy_loss: 0.9403, value_loss: 0.4760
2024-07-14 07:09:19,120 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:09:19,582 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:09:19,661 [INFO    ] __main__: train step 18612: loss: 0.9967, policy_loss: 0.9403, value_loss: 0.4760
2024-07-14 07:09:19,935 [INFO    ] __main__: train step 18613: loss: 0.9967, policy_loss: 0.9403, value_loss: 0.4760
2024-07-14 07:09:20,209 [INFO    ] __main__: train step 18614: loss: 0.9967, policy_loss: 0.9403, value_loss: 0.4760
2024-07-14 07:09:20,490 [INFO    ] __main__: train step 18615: loss: 0.9967, policy_loss: 0.9403, value_loss: 0.4759
2024-07-14 07:09:20,754 [INFO    ] __main__: train step 18616: loss: 0.9967, policy_loss: 0.9402, value_loss: 0.4759
2024-07-14 07:09:21,014 [INFO    ] __main__: train step 18617: loss: 0.9967, policy_loss: 0.9402, value_loss: 0.4759
2024-07-14 07:09:21,293 [INFO    ] __main__: train step 18618: loss: 0.9966, policy_loss: 0.9402, value_loss: 0.4759
2024-07-14 07:09:21,570 [INFO    ] __main__: train step 18619: loss: 0.9966, policy_loss: 0.9402, value_loss: 0.4758
2024-07-14 07:09:21,854 [INFO    ] __main__: train step 18620: loss: 0.9966, policy_loss: 0.9402, value_loss: 0.4758
2024-07-14 07:09:22,138 [INFO    ] __main__: train step 18621: loss: 0.9966, policy_loss: 0.9402, value_loss: 0.4758
2024-07-14 07:09:22,415 [INFO    ] __main__: train step 18622: loss: 0.9966, policy_loss: 0.9401, value_loss: 0.4758
2024-07-14 07:09:22,689 [INFO    ] __main__: train step 18623: loss: 0.9966, policy_loss: 0.9401, value_loss: 0.4758
2024-07-14 07:09:22,981 [INFO    ] __main__: train step 18624: loss: 0.9966, policy_loss: 0.9401, value_loss: 0.4757
2024-07-14 07:09:23,270 [INFO    ] __main__: train step 18625: loss: 0.9965, policy_loss: 0.9401, value_loss: 0.4757
2024-07-14 07:09:23,563 [INFO    ] __main__: train step 18626: loss: 0.9965, policy_loss: 0.9401, value_loss: 0.4757
2024-07-14 07:09:23,855 [INFO    ] __main__: train step 18627: loss: 0.9965, policy_loss: 0.9400, value_loss: 0.4757
2024-07-14 07:09:24,118 [INFO    ] __main__: train step 18628: loss: 0.9965, policy_loss: 0.9400, value_loss: 0.4757
2024-07-14 07:09:25,682 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:09:26,151 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:09:26,220 [INFO    ] __main__: train step 18629: loss: 0.9965, policy_loss: 0.9400, value_loss: 0.4756
2024-07-14 07:09:26,507 [INFO    ] __main__: train step 18630: loss: 0.9965, policy_loss: 0.9400, value_loss: 0.4756
2024-07-14 07:09:26,789 [INFO    ] __main__: train step 18631: loss: 0.9964, policy_loss: 0.9400, value_loss: 0.4756
2024-07-14 07:09:27,073 [INFO    ] __main__: train step 18632: loss: 0.9964, policy_loss: 0.9400, value_loss: 0.4756
2024-07-14 07:09:27,360 [INFO    ] __main__: train step 18633: loss: 0.9964, policy_loss: 0.9399, value_loss: 0.4756
2024-07-14 07:09:27,645 [INFO    ] __main__: train step 18634: loss: 0.9964, policy_loss: 0.9399, value_loss: 0.4755
2024-07-14 07:09:27,942 [INFO    ] __main__: train step 18635: loss: 0.9964, policy_loss: 0.9399, value_loss: 0.4755
2024-07-14 07:09:28,245 [INFO    ] __main__: train step 18636: loss: 0.9964, policy_loss: 0.9399, value_loss: 0.4755
2024-07-14 07:09:31,077 [INFO    ] __main__: train step 18637: loss: 0.9963, policy_loss: 0.9399, value_loss: 0.4755
2024-07-14 07:09:31,381 [INFO    ] __main__: train step 18638: loss: 0.9963, policy_loss: 0.9399, value_loss: 0.4755
2024-07-14 07:09:31,673 [INFO    ] __main__: train step 18639: loss: 0.9963, policy_loss: 0.9398, value_loss: 0.4754
2024-07-14 07:09:31,938 [INFO    ] __main__: train step 18640: loss: 0.9963, policy_loss: 0.9398, value_loss: 0.4754
2024-07-14 07:09:32,215 [INFO    ] __main__: train step 18641: loss: 0.9963, policy_loss: 0.9398, value_loss: 0.4754
2024-07-14 07:09:32,495 [INFO    ] __main__: train step 18642: loss: 0.9963, policy_loss: 0.9398, value_loss: 0.4754
2024-07-14 07:09:32,794 [INFO    ] __main__: train step 18643: loss: 0.9962, policy_loss: 0.9398, value_loss: 0.4754
2024-07-14 07:09:33,078 [INFO    ] __main__: train step 18644: loss: 0.9962, policy_loss: 0.9397, value_loss: 0.4753
2024-07-14 07:09:33,355 [INFO    ] __main__: train step 18645: loss: 0.9962, policy_loss: 0.9397, value_loss: 0.4753
2024-07-14 07:09:34,926 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:09:35,386 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:09:35,460 [INFO    ] __main__: train step 18646: loss: 0.9962, policy_loss: 0.9397, value_loss: 0.4753
2024-07-14 07:09:35,735 [INFO    ] __main__: train step 18647: loss: 0.9962, policy_loss: 0.9397, value_loss: 0.4753
2024-07-14 07:09:36,016 [INFO    ] __main__: train step 18648: loss: 0.9962, policy_loss: 0.9397, value_loss: 0.4752
2024-07-14 07:09:36,304 [INFO    ] __main__: train step 18649: loss: 0.9962, policy_loss: 0.9397, value_loss: 0.4752
2024-07-14 07:09:36,603 [INFO    ] __main__: train step 18650: loss: 0.9961, policy_loss: 0.9396, value_loss: 0.4752
2024-07-14 07:09:36,908 [INFO    ] __main__: train step 18651: loss: 0.9961, policy_loss: 0.9396, value_loss: 0.4752
2024-07-14 07:09:37,205 [INFO    ] __main__: train step 18652: loss: 0.9961, policy_loss: 0.9396, value_loss: 0.4752
2024-07-14 07:09:37,485 [INFO    ] __main__: train step 18653: loss: 0.9961, policy_loss: 0.9396, value_loss: 0.4751
2024-07-14 07:09:37,762 [INFO    ] __main__: train step 18654: loss: 0.9961, policy_loss: 0.9396, value_loss: 0.4751
2024-07-14 07:09:38,057 [INFO    ] __main__: train step 18655: loss: 0.9961, policy_loss: 0.9396, value_loss: 0.4751
2024-07-14 07:09:38,348 [INFO    ] __main__: train step 18656: loss: 0.9960, policy_loss: 0.9395, value_loss: 0.4751
2024-07-14 07:09:38,642 [INFO    ] __main__: train step 18657: loss: 0.9960, policy_loss: 0.9395, value_loss: 0.4751
2024-07-14 07:09:38,927 [INFO    ] __main__: train step 18658: loss: 0.9960, policy_loss: 0.9395, value_loss: 0.4750
2024-07-14 07:09:39,214 [INFO    ] __main__: train step 18659: loss: 0.9960, policy_loss: 0.9395, value_loss: 0.4750
2024-07-14 07:09:39,494 [INFO    ] __main__: train step 18660: loss: 0.9960, policy_loss: 0.9395, value_loss: 0.4750
2024-07-14 07:09:39,778 [INFO    ] __main__: train step 18661: loss: 0.9960, policy_loss: 0.9394, value_loss: 0.4750
2024-07-14 07:09:40,068 [INFO    ] __main__: train step 18662: loss: 0.9960, policy_loss: 0.9394, value_loss: 0.4750
2024-07-14 07:09:41,639 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:09:42,093 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:09:42,165 [INFO    ] __main__: train step 18663: loss: 0.9959, policy_loss: 0.9394, value_loss: 0.4749
2024-07-14 07:09:42,425 [INFO    ] __main__: train step 18664: loss: 0.9959, policy_loss: 0.9394, value_loss: 0.4749
2024-07-14 07:09:42,710 [INFO    ] __main__: train step 18665: loss: 0.9959, policy_loss: 0.9394, value_loss: 0.4749
2024-07-14 07:09:42,985 [INFO    ] __main__: train step 18666: loss: 0.9959, policy_loss: 0.9394, value_loss: 0.4749
2024-07-14 07:09:43,278 [INFO    ] __main__: train step 18667: loss: 0.9959, policy_loss: 0.9393, value_loss: 0.4749
2024-07-14 07:09:43,568 [INFO    ] __main__: train step 18668: loss: 0.9959, policy_loss: 0.9393, value_loss: 0.4748
2024-07-14 07:09:43,859 [INFO    ] __main__: train step 18669: loss: 0.9958, policy_loss: 0.9393, value_loss: 0.4748
2024-07-14 07:09:44,141 [INFO    ] __main__: train step 18670: loss: 0.9958, policy_loss: 0.9393, value_loss: 0.4748
2024-07-14 07:09:44,420 [INFO    ] __main__: train step 18671: loss: 0.9958, policy_loss: 0.9393, value_loss: 0.4748
2024-07-14 07:09:44,699 [INFO    ] __main__: train step 18672: loss: 0.9958, policy_loss: 0.9393, value_loss: 0.4748
2024-07-14 07:09:44,977 [INFO    ] __main__: train step 18673: loss: 0.9958, policy_loss: 0.9392, value_loss: 0.4747
2024-07-14 07:09:45,260 [INFO    ] __main__: train step 18674: loss: 0.9958, policy_loss: 0.9392, value_loss: 0.4747
2024-07-14 07:09:45,547 [INFO    ] __main__: train step 18675: loss: 0.9958, policy_loss: 0.9392, value_loss: 0.4747
2024-07-14 07:09:45,823 [INFO    ] __main__: train step 18676: loss: 0.9957, policy_loss: 0.9392, value_loss: 0.4747
2024-07-14 07:09:46,108 [INFO    ] __main__: train step 18677: loss: 0.9957, policy_loss: 0.9392, value_loss: 0.4747
2024-07-14 07:09:46,401 [INFO    ] __main__: train step 18678: loss: 0.9957, policy_loss: 0.9392, value_loss: 0.4746
2024-07-14 07:09:46,697 [INFO    ] __main__: train step 18679: loss: 0.9957, policy_loss: 0.9391, value_loss: 0.4746
2024-07-14 07:09:48,298 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:09:48,773 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:09:48,845 [INFO    ] __main__: train step 18680: loss: 0.9957, policy_loss: 0.9391, value_loss: 0.4746
2024-07-14 07:09:49,142 [INFO    ] __main__: train step 18681: loss: 0.9957, policy_loss: 0.9391, value_loss: 0.4746
2024-07-14 07:09:49,437 [INFO    ] __main__: train step 18682: loss: 0.9956, policy_loss: 0.9391, value_loss: 0.4746
2024-07-14 07:09:49,726 [INFO    ] __main__: train step 18683: loss: 0.9956, policy_loss: 0.9391, value_loss: 0.4745
2024-07-14 07:09:49,993 [INFO    ] __main__: train step 18684: loss: 0.9956, policy_loss: 0.9390, value_loss: 0.4745
2024-07-14 07:09:50,292 [INFO    ] __main__: train step 18685: loss: 0.9956, policy_loss: 0.9390, value_loss: 0.4745
2024-07-14 07:09:50,584 [INFO    ] __main__: train step 18686: loss: 0.9956, policy_loss: 0.9390, value_loss: 0.4745
2024-07-14 07:09:50,846 [INFO    ] __main__: train step 18687: loss: 0.9956, policy_loss: 0.9390, value_loss: 0.4745
2024-07-14 07:09:51,146 [INFO    ] __main__: train step 18688: loss: 0.9956, policy_loss: 0.9390, value_loss: 0.4744
2024-07-14 07:09:51,440 [INFO    ] __main__: train step 18689: loss: 0.9955, policy_loss: 0.9390, value_loss: 0.4744
2024-07-14 07:09:51,721 [INFO    ] __main__: train step 18690: loss: 0.9955, policy_loss: 0.9389, value_loss: 0.4744
2024-07-14 07:09:52,001 [INFO    ] __main__: train step 18691: loss: 0.9955, policy_loss: 0.9389, value_loss: 0.4744
2024-07-14 07:09:52,283 [INFO    ] __main__: train step 18692: loss: 0.9955, policy_loss: 0.9389, value_loss: 0.4744
2024-07-14 07:09:52,591 [INFO    ] __main__: train step 18693: loss: 0.9955, policy_loss: 0.9389, value_loss: 0.4743
2024-07-14 07:09:52,884 [INFO    ] __main__: train step 18694: loss: 0.9955, policy_loss: 0.9389, value_loss: 0.4743
2024-07-14 07:09:53,184 [INFO    ] __main__: train step 18695: loss: 0.9954, policy_loss: 0.9389, value_loss: 0.4743
2024-07-14 07:09:53,483 [INFO    ] __main__: train step 18696: loss: 0.9954, policy_loss: 0.9388, value_loss: 0.4743
2024-07-14 07:09:55,062 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:09:55,498 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:09:55,566 [INFO    ] __main__: train step 18697: loss: 0.9954, policy_loss: 0.9388, value_loss: 0.4743
2024-07-14 07:09:55,863 [INFO    ] __main__: train step 18698: loss: 0.9954, policy_loss: 0.9388, value_loss: 0.4742
2024-07-14 07:09:56,154 [INFO    ] __main__: train step 18699: loss: 0.9954, policy_loss: 0.9388, value_loss: 0.4742
2024-07-14 07:09:56,473 [INFO    ] __main__: train step 18700: loss: 0.9954, policy_loss: 0.9388, value_loss: 0.4742
2024-07-14 07:09:56,751 [INFO    ] __main__: train step 18701: loss: 0.9954, policy_loss: 0.9388, value_loss: 0.4742
2024-07-14 07:09:57,052 [INFO    ] __main__: train step 18702: loss: 0.9953, policy_loss: 0.9387, value_loss: 0.4741
2024-07-14 07:09:57,338 [INFO    ] __main__: train step 18703: loss: 0.9953, policy_loss: 0.9387, value_loss: 0.4741
2024-07-14 07:09:57,649 [INFO    ] __main__: train step 18704: loss: 0.9953, policy_loss: 0.9387, value_loss: 0.4741
2024-07-14 07:09:57,962 [INFO    ] __main__: train step 18705: loss: 0.9953, policy_loss: 0.9387, value_loss: 0.4741
2024-07-14 07:09:58,257 [INFO    ] __main__: train step 18706: loss: 0.9953, policy_loss: 0.9387, value_loss: 0.4741
2024-07-14 07:09:58,550 [INFO    ] __main__: train step 18707: loss: 0.9953, policy_loss: 0.9386, value_loss: 0.4740
2024-07-14 07:09:58,851 [INFO    ] __main__: train step 18708: loss: 0.9952, policy_loss: 0.9386, value_loss: 0.4740
2024-07-14 07:09:59,165 [INFO    ] __main__: train step 18709: loss: 0.9952, policy_loss: 0.9386, value_loss: 0.4740
2024-07-14 07:09:59,475 [INFO    ] __main__: train step 18710: loss: 0.9952, policy_loss: 0.9386, value_loss: 0.4740
2024-07-14 07:09:59,771 [INFO    ] __main__: train step 18711: loss: 0.9952, policy_loss: 0.9386, value_loss: 0.4740
2024-07-14 07:10:00,069 [INFO    ] __main__: train step 18712: loss: 0.9952, policy_loss: 0.9386, value_loss: 0.4739
2024-07-14 07:10:00,359 [INFO    ] __main__: train step 18713: loss: 0.9952, policy_loss: 0.9385, value_loss: 0.4739
2024-07-14 07:10:02,016 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:10:02,473 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:10:02,557 [INFO    ] __main__: train step 18714: loss: 0.9952, policy_loss: 0.9385, value_loss: 0.4739
2024-07-14 07:10:02,858 [INFO    ] __main__: train step 18715: loss: 0.9951, policy_loss: 0.9385, value_loss: 0.4739
2024-07-14 07:10:03,184 [INFO    ] __main__: train step 18716: loss: 0.9951, policy_loss: 0.9385, value_loss: 0.4739
2024-07-14 07:10:03,484 [INFO    ] __main__: train step 18717: loss: 0.9951, policy_loss: 0.9385, value_loss: 0.4738
2024-07-14 07:10:03,764 [INFO    ] __main__: train step 18718: loss: 0.9951, policy_loss: 0.9385, value_loss: 0.4738
2024-07-14 07:10:04,051 [INFO    ] __main__: train step 18719: loss: 0.9951, policy_loss: 0.9384, value_loss: 0.4738
2024-07-14 07:10:04,345 [INFO    ] __main__: train step 18720: loss: 0.9951, policy_loss: 0.9384, value_loss: 0.4738
2024-07-14 07:10:04,646 [INFO    ] __main__: train step 18721: loss: 0.9950, policy_loss: 0.9384, value_loss: 0.4738
2024-07-14 07:10:04,951 [INFO    ] __main__: train step 18722: loss: 0.9950, policy_loss: 0.9384, value_loss: 0.4737
2024-07-14 07:10:05,261 [INFO    ] __main__: train step 18723: loss: 0.9950, policy_loss: 0.9384, value_loss: 0.4737
2024-07-14 07:10:05,551 [INFO    ] __main__: train step 18724: loss: 0.9950, policy_loss: 0.9384, value_loss: 0.4737
2024-07-14 07:10:05,860 [INFO    ] __main__: train step 18725: loss: 0.9950, policy_loss: 0.9383, value_loss: 0.4737
2024-07-14 07:10:06,152 [INFO    ] __main__: train step 18726: loss: 0.9950, policy_loss: 0.9383, value_loss: 0.4737
2024-07-14 07:10:06,476 [INFO    ] __main__: train step 18727: loss: 0.9949, policy_loss: 0.9383, value_loss: 0.4736
2024-07-14 07:10:06,794 [INFO    ] __main__: train step 18728: loss: 0.9949, policy_loss: 0.9383, value_loss: 0.4736
2024-07-14 07:10:07,099 [INFO    ] __main__: train step 18729: loss: 0.9949, policy_loss: 0.9383, value_loss: 0.4736
2024-07-14 07:10:07,400 [INFO    ] __main__: train step 18730: loss: 0.9949, policy_loss: 0.9382, value_loss: 0.4736
2024-07-14 07:10:09,027 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:10:09,519 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:10:09,591 [INFO    ] __main__: train step 18731: loss: 0.9949, policy_loss: 0.9382, value_loss: 0.4736
2024-07-14 07:10:09,848 [INFO    ] __main__: train step 18732: loss: 0.9949, policy_loss: 0.9382, value_loss: 0.4735
2024-07-14 07:10:10,114 [INFO    ] __main__: train step 18733: loss: 0.9949, policy_loss: 0.9382, value_loss: 0.4735
2024-07-14 07:10:10,375 [INFO    ] __main__: train step 18734: loss: 0.9948, policy_loss: 0.9382, value_loss: 0.4735
2024-07-14 07:10:10,669 [INFO    ] __main__: train step 18735: loss: 0.9948, policy_loss: 0.9382, value_loss: 0.4735
2024-07-14 07:10:10,942 [INFO    ] __main__: train step 18736: loss: 0.9948, policy_loss: 0.9381, value_loss: 0.4735
2024-07-14 07:10:11,243 [INFO    ] __main__: train step 18737: loss: 0.9948, policy_loss: 0.9381, value_loss: 0.4734
2024-07-14 07:10:11,546 [INFO    ] __main__: train step 18738: loss: 0.9948, policy_loss: 0.9381, value_loss: 0.4734
2024-07-14 07:10:11,849 [INFO    ] __main__: train step 18739: loss: 0.9948, policy_loss: 0.9381, value_loss: 0.4734
2024-07-14 07:10:12,162 [INFO    ] __main__: train step 18740: loss: 0.9947, policy_loss: 0.9381, value_loss: 0.4734
2024-07-14 07:10:16,079 [INFO    ] __main__: train step 18741: loss: 0.9947, policy_loss: 0.9381, value_loss: 0.4734
2024-07-14 07:10:16,394 [INFO    ] __main__: train step 18742: loss: 0.9947, policy_loss: 0.9380, value_loss: 0.4733
2024-07-14 07:10:16,692 [INFO    ] __main__: train step 18743: loss: 0.9947, policy_loss: 0.9380, value_loss: 0.4733
2024-07-14 07:10:16,981 [INFO    ] __main__: train step 18744: loss: 0.9947, policy_loss: 0.9380, value_loss: 0.4733
2024-07-14 07:10:17,280 [INFO    ] __main__: train step 18745: loss: 0.9947, policy_loss: 0.9380, value_loss: 0.4733
2024-07-14 07:10:17,559 [INFO    ] __main__: train step 18746: loss: 0.9947, policy_loss: 0.9380, value_loss: 0.4733
2024-07-14 07:10:17,844 [INFO    ] __main__: train step 18747: loss: 0.9946, policy_loss: 0.9380, value_loss: 0.4732
2024-07-14 07:10:19,464 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:10:19,939 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:10:20,005 [INFO    ] __main__: train step 18748: loss: 0.9946, policy_loss: 0.9379, value_loss: 0.4732
2024-07-14 07:10:20,285 [INFO    ] __main__: train step 18749: loss: 0.9946, policy_loss: 0.9379, value_loss: 0.4732
2024-07-14 07:10:20,585 [INFO    ] __main__: train step 18750: loss: 0.9946, policy_loss: 0.9379, value_loss: 0.4732
2024-07-14 07:10:20,873 [INFO    ] __main__: train step 18751: loss: 0.9946, policy_loss: 0.9379, value_loss: 0.4732
2024-07-14 07:10:21,181 [INFO    ] __main__: train step 18752: loss: 0.9946, policy_loss: 0.9379, value_loss: 0.4731
2024-07-14 07:10:21,475 [INFO    ] __main__: train step 18753: loss: 0.9945, policy_loss: 0.9378, value_loss: 0.4731
2024-07-14 07:10:21,746 [INFO    ] __main__: train step 18754: loss: 0.9945, policy_loss: 0.9378, value_loss: 0.4731
2024-07-14 07:10:22,038 [INFO    ] __main__: train step 18755: loss: 0.9945, policy_loss: 0.9378, value_loss: 0.4731
2024-07-14 07:10:22,316 [INFO    ] __main__: train step 18756: loss: 0.9945, policy_loss: 0.9378, value_loss: 0.4731
2024-07-14 07:10:22,623 [INFO    ] __main__: train step 18757: loss: 0.9945, policy_loss: 0.9378, value_loss: 0.4730
2024-07-14 07:10:22,921 [INFO    ] __main__: train step 18758: loss: 0.9945, policy_loss: 0.9378, value_loss: 0.4730
2024-07-14 07:10:23,219 [INFO    ] __main__: train step 18759: loss: 0.9945, policy_loss: 0.9377, value_loss: 0.4730
2024-07-14 07:10:23,486 [INFO    ] __main__: train step 18760: loss: 0.9944, policy_loss: 0.9377, value_loss: 0.4730
2024-07-14 07:10:23,770 [INFO    ] __main__: train step 18761: loss: 0.9944, policy_loss: 0.9377, value_loss: 0.4730
2024-07-14 07:10:24,074 [INFO    ] __main__: train step 18762: loss: 0.9944, policy_loss: 0.9377, value_loss: 0.4729
2024-07-14 07:10:24,350 [INFO    ] __main__: train step 18763: loss: 0.9944, policy_loss: 0.9377, value_loss: 0.4729
2024-07-14 07:10:24,644 [INFO    ] __main__: train step 18764: loss: 0.9944, policy_loss: 0.9377, value_loss: 0.4729
2024-07-14 07:10:26,229 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:10:26,705 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:10:26,777 [INFO    ] __main__: train step 18765: loss: 0.9944, policy_loss: 0.9376, value_loss: 0.4729
2024-07-14 07:10:27,073 [INFO    ] __main__: train step 18766: loss: 0.9943, policy_loss: 0.9376, value_loss: 0.4729
2024-07-14 07:10:27,364 [INFO    ] __main__: train step 18767: loss: 0.9943, policy_loss: 0.9376, value_loss: 0.4728
2024-07-14 07:10:27,644 [INFO    ] __main__: train step 18768: loss: 0.9943, policy_loss: 0.9376, value_loss: 0.4728
2024-07-14 07:10:27,940 [INFO    ] __main__: train step 18769: loss: 0.9943, policy_loss: 0.9376, value_loss: 0.4728
2024-07-14 07:10:28,242 [INFO    ] __main__: train step 18770: loss: 0.9943, policy_loss: 0.9376, value_loss: 0.4728
2024-07-14 07:10:28,534 [INFO    ] __main__: train step 18771: loss: 0.9943, policy_loss: 0.9375, value_loss: 0.4728
2024-07-14 07:10:28,830 [INFO    ] __main__: train step 18772: loss: 0.9943, policy_loss: 0.9375, value_loss: 0.4727
2024-07-14 07:10:29,126 [INFO    ] __main__: train step 18773: loss: 0.9942, policy_loss: 0.9375, value_loss: 0.4727
2024-07-14 07:10:29,420 [INFO    ] __main__: train step 18774: loss: 0.9942, policy_loss: 0.9375, value_loss: 0.4727
2024-07-14 07:10:29,710 [INFO    ] __main__: train step 18775: loss: 0.9942, policy_loss: 0.9375, value_loss: 0.4727
2024-07-14 07:10:29,999 [INFO    ] __main__: train step 18776: loss: 0.9942, policy_loss: 0.9374, value_loss: 0.4726
2024-07-14 07:10:30,298 [INFO    ] __main__: train step 18777: loss: 0.9942, policy_loss: 0.9374, value_loss: 0.4726
2024-07-14 07:10:30,593 [INFO    ] __main__: train step 18778: loss: 0.9942, policy_loss: 0.9374, value_loss: 0.4726
2024-07-14 07:10:30,886 [INFO    ] __main__: train step 18779: loss: 0.9941, policy_loss: 0.9374, value_loss: 0.4726
2024-07-14 07:10:31,184 [INFO    ] __main__: train step 18780: loss: 0.9941, policy_loss: 0.9374, value_loss: 0.4726
2024-07-14 07:10:31,466 [INFO    ] __main__: train step 18781: loss: 0.9941, policy_loss: 0.9374, value_loss: 0.4725
2024-07-14 07:10:33,085 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:10:33,580 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:10:33,652 [INFO    ] __main__: train step 18782: loss: 0.9941, policy_loss: 0.9373, value_loss: 0.4725
2024-07-14 07:10:33,918 [INFO    ] __main__: train step 18783: loss: 0.9941, policy_loss: 0.9373, value_loss: 0.4725
2024-07-14 07:10:34,183 [INFO    ] __main__: train step 18784: loss: 0.9941, policy_loss: 0.9373, value_loss: 0.4725
2024-07-14 07:10:34,458 [INFO    ] __main__: train step 18785: loss: 0.9941, policy_loss: 0.9373, value_loss: 0.4725
2024-07-14 07:10:34,744 [INFO    ] __main__: train step 18786: loss: 0.9940, policy_loss: 0.9373, value_loss: 0.4724
2024-07-14 07:10:35,044 [INFO    ] __main__: train step 18787: loss: 0.9940, policy_loss: 0.9373, value_loss: 0.4724
2024-07-14 07:10:35,323 [INFO    ] __main__: train step 18788: loss: 0.9940, policy_loss: 0.9372, value_loss: 0.4724
2024-07-14 07:10:35,616 [INFO    ] __main__: train step 18789: loss: 0.9940, policy_loss: 0.9372, value_loss: 0.4724
2024-07-14 07:10:35,913 [INFO    ] __main__: train step 18790: loss: 0.9940, policy_loss: 0.9372, value_loss: 0.4724
2024-07-14 07:10:36,225 [INFO    ] __main__: train step 18791: loss: 0.9940, policy_loss: 0.9372, value_loss: 0.4723
2024-07-14 07:10:36,524 [INFO    ] __main__: train step 18792: loss: 0.9939, policy_loss: 0.9372, value_loss: 0.4723
2024-07-14 07:10:36,808 [INFO    ] __main__: train step 18793: loss: 0.9939, policy_loss: 0.9372, value_loss: 0.4723
2024-07-14 07:10:37,081 [INFO    ] __main__: train step 18794: loss: 0.9939, policy_loss: 0.9371, value_loss: 0.4723
2024-07-14 07:10:37,343 [INFO    ] __main__: train step 18795: loss: 0.9939, policy_loss: 0.9371, value_loss: 0.4723
2024-07-14 07:10:37,630 [INFO    ] __main__: train step 18796: loss: 0.9939, policy_loss: 0.9371, value_loss: 0.4722
2024-07-14 07:10:37,913 [INFO    ] __main__: train step 18797: loss: 0.9939, policy_loss: 0.9371, value_loss: 0.4722
2024-07-14 07:10:38,188 [INFO    ] __main__: train step 18798: loss: 0.9939, policy_loss: 0.9371, value_loss: 0.4722
2024-07-14 07:10:39,820 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:10:40,308 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:10:40,384 [INFO    ] __main__: train step 18799: loss: 0.9938, policy_loss: 0.9370, value_loss: 0.4722
2024-07-14 07:10:40,634 [INFO    ] __main__: train step 18800: loss: 0.9938, policy_loss: 0.9370, value_loss: 0.4722
2024-07-14 07:10:40,931 [INFO    ] __main__: train step 18801: loss: 0.9938, policy_loss: 0.9370, value_loss: 0.4721
2024-07-14 07:10:41,244 [INFO    ] __main__: train step 18802: loss: 0.9938, policy_loss: 0.9370, value_loss: 0.4721
2024-07-14 07:10:41,548 [INFO    ] __main__: train step 18803: loss: 0.9938, policy_loss: 0.9370, value_loss: 0.4721
2024-07-14 07:10:41,861 [INFO    ] __main__: train step 18804: loss: 0.9938, policy_loss: 0.9370, value_loss: 0.4721
2024-07-14 07:10:42,156 [INFO    ] __main__: train step 18805: loss: 0.9937, policy_loss: 0.9369, value_loss: 0.4721
2024-07-14 07:10:42,454 [INFO    ] __main__: train step 18806: loss: 0.9937, policy_loss: 0.9369, value_loss: 0.4720
2024-07-14 07:10:42,752 [INFO    ] __main__: train step 18807: loss: 0.9937, policy_loss: 0.9369, value_loss: 0.4720
2024-07-14 07:10:43,069 [INFO    ] __main__: train step 18808: loss: 0.9937, policy_loss: 0.9369, value_loss: 0.4720
2024-07-14 07:10:43,347 [INFO    ] __main__: train step 18809: loss: 0.9937, policy_loss: 0.9369, value_loss: 0.4720
2024-07-14 07:10:43,638 [INFO    ] __main__: train step 18810: loss: 0.9937, policy_loss: 0.9369, value_loss: 0.4720
2024-07-14 07:10:43,946 [INFO    ] __main__: train step 18811: loss: 0.9937, policy_loss: 0.9368, value_loss: 0.4719
2024-07-14 07:10:44,254 [INFO    ] __main__: train step 18812: loss: 0.9936, policy_loss: 0.9368, value_loss: 0.4719
2024-07-14 07:10:44,549 [INFO    ] __main__: train step 18813: loss: 0.9936, policy_loss: 0.9368, value_loss: 0.4719
2024-07-14 07:10:44,845 [INFO    ] __main__: train step 18814: loss: 0.9936, policy_loss: 0.9368, value_loss: 0.4719
2024-07-14 07:10:45,149 [INFO    ] __main__: train step 18815: loss: 0.9936, policy_loss: 0.9368, value_loss: 0.4719
2024-07-14 07:10:46,800 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:10:47,253 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:10:47,335 [INFO    ] __main__: train step 18816: loss: 0.9936, policy_loss: 0.9368, value_loss: 0.4718
2024-07-14 07:10:47,648 [INFO    ] __main__: train step 18817: loss: 0.9936, policy_loss: 0.9367, value_loss: 0.4718
2024-07-14 07:10:47,972 [INFO    ] __main__: train step 18818: loss: 0.9935, policy_loss: 0.9367, value_loss: 0.4718
2024-07-14 07:10:48,288 [INFO    ] __main__: train step 18819: loss: 0.9935, policy_loss: 0.9367, value_loss: 0.4718
2024-07-14 07:10:48,589 [INFO    ] __main__: train step 18820: loss: 0.9935, policy_loss: 0.9367, value_loss: 0.4718
2024-07-14 07:10:48,887 [INFO    ] __main__: train step 18821: loss: 0.9935, policy_loss: 0.9367, value_loss: 0.4717
2024-07-14 07:10:49,184 [INFO    ] __main__: train step 18822: loss: 0.9935, policy_loss: 0.9366, value_loss: 0.4717
2024-07-14 07:10:49,465 [INFO    ] __main__: train step 18823: loss: 0.9935, policy_loss: 0.9366, value_loss: 0.4717
2024-07-14 07:10:49,746 [INFO    ] __main__: train step 18824: loss: 0.9935, policy_loss: 0.9366, value_loss: 0.4717
2024-07-14 07:10:50,039 [INFO    ] __main__: train step 18825: loss: 0.9934, policy_loss: 0.9366, value_loss: 0.4717
2024-07-14 07:10:50,345 [INFO    ] __main__: train step 18826: loss: 0.9934, policy_loss: 0.9366, value_loss: 0.4716
2024-07-14 07:10:50,622 [INFO    ] __main__: train step 18827: loss: 0.9934, policy_loss: 0.9366, value_loss: 0.4716
2024-07-14 07:10:50,888 [INFO    ] __main__: train step 18828: loss: 0.9934, policy_loss: 0.9365, value_loss: 0.4716
2024-07-14 07:10:51,185 [INFO    ] __main__: train step 18829: loss: 0.9934, policy_loss: 0.9365, value_loss: 0.4716
2024-07-14 07:10:51,485 [INFO    ] __main__: train step 18830: loss: 0.9934, policy_loss: 0.9365, value_loss: 0.4716
2024-07-14 07:10:51,784 [INFO    ] __main__: train step 18831: loss: 0.9934, policy_loss: 0.9365, value_loss: 0.4715
2024-07-14 07:10:52,092 [INFO    ] __main__: train step 18832: loss: 0.9933, policy_loss: 0.9365, value_loss: 0.4715
2024-07-14 07:10:53,714 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:10:54,196 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:10:54,265 [INFO    ] __main__: train step 18833: loss: 0.9933, policy_loss: 0.9365, value_loss: 0.4715
2024-07-14 07:10:54,545 [INFO    ] __main__: train step 18834: loss: 0.9933, policy_loss: 0.9364, value_loss: 0.4715
2024-07-14 07:10:54,860 [INFO    ] __main__: train step 18835: loss: 0.9933, policy_loss: 0.9364, value_loss: 0.4715
2024-07-14 07:10:55,179 [INFO    ] __main__: train step 18836: loss: 0.9933, policy_loss: 0.9364, value_loss: 0.4714
2024-07-14 07:10:55,461 [INFO    ] __main__: train step 18837: loss: 0.9933, policy_loss: 0.9364, value_loss: 0.4714
2024-07-14 07:10:55,747 [INFO    ] __main__: train step 18838: loss: 0.9932, policy_loss: 0.9364, value_loss: 0.4714
2024-07-14 07:10:56,045 [INFO    ] __main__: train step 18839: loss: 0.9932, policy_loss: 0.9364, value_loss: 0.4714
2024-07-14 07:10:56,366 [INFO    ] __main__: train step 18840: loss: 0.9932, policy_loss: 0.9363, value_loss: 0.4714
2024-07-14 07:10:56,666 [INFO    ] __main__: train step 18841: loss: 0.9932, policy_loss: 0.9363, value_loss: 0.4713
2024-07-14 07:10:56,942 [INFO    ] __main__: train step 18842: loss: 0.9932, policy_loss: 0.9363, value_loss: 0.4713
2024-07-14 07:10:57,221 [INFO    ] __main__: train step 18843: loss: 0.9932, policy_loss: 0.9363, value_loss: 0.4713
2024-07-14 07:10:57,495 [INFO    ] __main__: train step 18844: loss: 0.9931, policy_loss: 0.9363, value_loss: 0.4713
2024-07-14 07:11:01,185 [INFO    ] __main__: train step 18845: loss: 0.9931, policy_loss: 0.9363, value_loss: 0.4713
2024-07-14 07:11:01,496 [INFO    ] __main__: train step 18846: loss: 0.9931, policy_loss: 0.9362, value_loss: 0.4712
2024-07-14 07:11:01,794 [INFO    ] __main__: train step 18847: loss: 0.9931, policy_loss: 0.9362, value_loss: 0.4712
2024-07-14 07:11:02,083 [INFO    ] __main__: train step 18848: loss: 0.9931, policy_loss: 0.9362, value_loss: 0.4712
2024-07-14 07:11:02,375 [INFO    ] __main__: train step 18849: loss: 0.9931, policy_loss: 0.9362, value_loss: 0.4712
2024-07-14 07:11:03,989 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:11:04,466 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:11:04,544 [INFO    ] __main__: train step 18850: loss: 0.9931, policy_loss: 0.9362, value_loss: 0.4712
2024-07-14 07:11:04,869 [INFO    ] __main__: train step 18851: loss: 0.9930, policy_loss: 0.9361, value_loss: 0.4711
2024-07-14 07:11:05,153 [INFO    ] __main__: train step 18852: loss: 0.9930, policy_loss: 0.9361, value_loss: 0.4711
2024-07-14 07:11:05,420 [INFO    ] __main__: train step 18853: loss: 0.9930, policy_loss: 0.9361, value_loss: 0.4711
2024-07-14 07:11:05,721 [INFO    ] __main__: train step 18854: loss: 0.9930, policy_loss: 0.9361, value_loss: 0.4711
2024-07-14 07:11:06,018 [INFO    ] __main__: train step 18855: loss: 0.9930, policy_loss: 0.9361, value_loss: 0.4711
2024-07-14 07:11:06,285 [INFO    ] __main__: train step 18856: loss: 0.9930, policy_loss: 0.9361, value_loss: 0.4710
2024-07-14 07:11:06,544 [INFO    ] __main__: train step 18857: loss: 0.9929, policy_loss: 0.9360, value_loss: 0.4710
2024-07-14 07:11:06,852 [INFO    ] __main__: train step 18858: loss: 0.9929, policy_loss: 0.9360, value_loss: 0.4710
2024-07-14 07:11:07,136 [INFO    ] __main__: train step 18859: loss: 0.9929, policy_loss: 0.9360, value_loss: 0.4710
2024-07-14 07:11:07,399 [INFO    ] __main__: train step 18860: loss: 0.9929, policy_loss: 0.9360, value_loss: 0.4710
2024-07-14 07:11:07,657 [INFO    ] __main__: train step 18861: loss: 0.9929, policy_loss: 0.9360, value_loss: 0.4709
2024-07-14 07:11:07,914 [INFO    ] __main__: train step 18862: loss: 0.9929, policy_loss: 0.9360, value_loss: 0.4709
2024-07-14 07:11:08,182 [INFO    ] __main__: train step 18863: loss: 0.9929, policy_loss: 0.9359, value_loss: 0.4709
2024-07-14 07:11:08,451 [INFO    ] __main__: train step 18864: loss: 0.9928, policy_loss: 0.9359, value_loss: 0.4709
2024-07-14 07:11:08,706 [INFO    ] __main__: train step 18865: loss: 0.9928, policy_loss: 0.9359, value_loss: 0.4709
2024-07-14 07:11:08,956 [INFO    ] __main__: train step 18866: loss: 0.9928, policy_loss: 0.9359, value_loss: 0.4708
2024-07-14 07:11:10,541 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:11:10,996 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:11:11,063 [INFO    ] __main__: train step 18867: loss: 0.9928, policy_loss: 0.9359, value_loss: 0.4708
2024-07-14 07:11:11,341 [INFO    ] __main__: train step 18868: loss: 0.9928, policy_loss: 0.9358, value_loss: 0.4708
2024-07-14 07:11:11,613 [INFO    ] __main__: train step 18869: loss: 0.9928, policy_loss: 0.9358, value_loss: 0.4708
2024-07-14 07:11:11,878 [INFO    ] __main__: train step 18870: loss: 0.9927, policy_loss: 0.9358, value_loss: 0.4708
2024-07-14 07:11:12,144 [INFO    ] __main__: train step 18871: loss: 0.9927, policy_loss: 0.9358, value_loss: 0.4707
2024-07-14 07:11:12,404 [INFO    ] __main__: train step 18872: loss: 0.9927, policy_loss: 0.9358, value_loss: 0.4707
2024-07-14 07:11:12,678 [INFO    ] __main__: train step 18873: loss: 0.9927, policy_loss: 0.9358, value_loss: 0.4707
2024-07-14 07:11:12,950 [INFO    ] __main__: train step 18874: loss: 0.9927, policy_loss: 0.9357, value_loss: 0.4707
2024-07-14 07:11:13,202 [INFO    ] __main__: train step 18875: loss: 0.9927, policy_loss: 0.9357, value_loss: 0.4707
2024-07-14 07:11:13,477 [INFO    ] __main__: train step 18876: loss: 0.9927, policy_loss: 0.9357, value_loss: 0.4706
2024-07-14 07:11:13,750 [INFO    ] __main__: train step 18877: loss: 0.9926, policy_loss: 0.9357, value_loss: 0.4706
2024-07-14 07:11:14,024 [INFO    ] __main__: train step 18878: loss: 0.9926, policy_loss: 0.9357, value_loss: 0.4706
2024-07-14 07:11:14,270 [INFO    ] __main__: train step 18879: loss: 0.9926, policy_loss: 0.9357, value_loss: 0.4706
2024-07-14 07:11:14,528 [INFO    ] __main__: train step 18880: loss: 0.9926, policy_loss: 0.9356, value_loss: 0.4706
2024-07-14 07:11:14,780 [INFO    ] __main__: train step 18881: loss: 0.9926, policy_loss: 0.9356, value_loss: 0.4705
2024-07-14 07:11:15,043 [INFO    ] __main__: train step 18882: loss: 0.9926, policy_loss: 0.9356, value_loss: 0.4705
2024-07-14 07:11:15,313 [INFO    ] __main__: train step 18883: loss: 0.9925, policy_loss: 0.9356, value_loss: 0.4705
2024-07-14 07:11:16,899 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:11:17,381 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:11:17,448 [INFO    ] __main__: train step 18884: loss: 0.9925, policy_loss: 0.9356, value_loss: 0.4705
2024-07-14 07:11:17,706 [INFO    ] __main__: train step 18885: loss: 0.9925, policy_loss: 0.9355, value_loss: 0.4705
2024-07-14 07:11:17,969 [INFO    ] __main__: train step 18886: loss: 0.9925, policy_loss: 0.9355, value_loss: 0.4704
2024-07-14 07:11:18,229 [INFO    ] __main__: train step 18887: loss: 0.9925, policy_loss: 0.9355, value_loss: 0.4704
2024-07-14 07:11:18,497 [INFO    ] __main__: train step 18888: loss: 0.9925, policy_loss: 0.9355, value_loss: 0.4704
2024-07-14 07:11:18,777 [INFO    ] __main__: train step 18889: loss: 0.9924, policy_loss: 0.9355, value_loss: 0.4704
2024-07-14 07:11:19,038 [INFO    ] __main__: train step 18890: loss: 0.9924, policy_loss: 0.9355, value_loss: 0.4704
2024-07-14 07:11:19,305 [INFO    ] __main__: train step 18891: loss: 0.9924, policy_loss: 0.9354, value_loss: 0.4703
2024-07-14 07:11:19,559 [INFO    ] __main__: train step 18892: loss: 0.9924, policy_loss: 0.9354, value_loss: 0.4703
2024-07-14 07:11:19,834 [INFO    ] __main__: train step 18893: loss: 0.9924, policy_loss: 0.9354, value_loss: 0.4703
2024-07-14 07:11:20,113 [INFO    ] __main__: train step 18894: loss: 0.9924, policy_loss: 0.9354, value_loss: 0.4703
2024-07-14 07:11:20,374 [INFO    ] __main__: train step 18895: loss: 0.9924, policy_loss: 0.9354, value_loss: 0.4703
2024-07-14 07:11:20,666 [INFO    ] __main__: train step 18896: loss: 0.9923, policy_loss: 0.9354, value_loss: 0.4702
2024-07-14 07:11:20,935 [INFO    ] __main__: train step 18897: loss: 0.9923, policy_loss: 0.9353, value_loss: 0.4702
2024-07-14 07:11:21,192 [INFO    ] __main__: train step 18898: loss: 0.9923, policy_loss: 0.9353, value_loss: 0.4702
2024-07-14 07:11:21,425 [INFO    ] __main__: train step 18899: loss: 0.9923, policy_loss: 0.9353, value_loss: 0.4702
2024-07-14 07:11:21,680 [INFO    ] __main__: train step 18900: loss: 0.9923, policy_loss: 0.9353, value_loss: 0.4702
2024-07-14 07:11:23,253 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:11:23,721 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:11:23,790 [INFO    ] __main__: train step 18901: loss: 0.9923, policy_loss: 0.9353, value_loss: 0.4701
2024-07-14 07:11:24,045 [INFO    ] __main__: train step 18902: loss: 0.9922, policy_loss: 0.9352, value_loss: 0.4701
2024-07-14 07:11:24,298 [INFO    ] __main__: train step 18903: loss: 0.9922, policy_loss: 0.9352, value_loss: 0.4701
2024-07-14 07:11:24,564 [INFO    ] __main__: train step 18904: loss: 0.9922, policy_loss: 0.9352, value_loss: 0.4701
2024-07-14 07:11:24,842 [INFO    ] __main__: train step 18905: loss: 0.9922, policy_loss: 0.9352, value_loss: 0.4701
2024-07-14 07:11:25,130 [INFO    ] __main__: train step 18906: loss: 0.9922, policy_loss: 0.9352, value_loss: 0.4700
2024-07-14 07:11:25,403 [INFO    ] __main__: train step 18907: loss: 0.9922, policy_loss: 0.9352, value_loss: 0.4700
2024-07-14 07:11:25,684 [INFO    ] __main__: train step 18908: loss: 0.9921, policy_loss: 0.9351, value_loss: 0.4700
2024-07-14 07:11:25,944 [INFO    ] __main__: train step 18909: loss: 0.9921, policy_loss: 0.9351, value_loss: 0.4700
2024-07-14 07:11:26,208 [INFO    ] __main__: train step 18910: loss: 0.9921, policy_loss: 0.9351, value_loss: 0.4700
2024-07-14 07:11:26,444 [INFO    ] __main__: train step 18911: loss: 0.9921, policy_loss: 0.9351, value_loss: 0.4699
2024-07-14 07:11:26,706 [INFO    ] __main__: train step 18912: loss: 0.9921, policy_loss: 0.9351, value_loss: 0.4699
2024-07-14 07:11:26,958 [INFO    ] __main__: train step 18913: loss: 0.9921, policy_loss: 0.9351, value_loss: 0.4699
2024-07-14 07:11:27,209 [INFO    ] __main__: train step 18914: loss: 0.9921, policy_loss: 0.9350, value_loss: 0.4699
2024-07-14 07:11:27,480 [INFO    ] __main__: train step 18915: loss: 0.9920, policy_loss: 0.9350, value_loss: 0.4699
2024-07-14 07:11:27,732 [INFO    ] __main__: train step 18916: loss: 0.9920, policy_loss: 0.9350, value_loss: 0.4698
2024-07-14 07:11:28,002 [INFO    ] __main__: train step 18917: loss: 0.9920, policy_loss: 0.9350, value_loss: 0.4698
2024-07-14 07:11:29,592 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:11:30,048 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:11:30,117 [INFO    ] __main__: train step 18918: loss: 0.9920, policy_loss: 0.9350, value_loss: 0.4698
2024-07-14 07:11:30,372 [INFO    ] __main__: train step 18919: loss: 0.9920, policy_loss: 0.9349, value_loss: 0.4698
2024-07-14 07:11:30,643 [INFO    ] __main__: train step 18920: loss: 0.9920, policy_loss: 0.9349, value_loss: 0.4698
2024-07-14 07:11:30,911 [INFO    ] __main__: train step 18921: loss: 0.9919, policy_loss: 0.9349, value_loss: 0.4697
2024-07-14 07:11:31,180 [INFO    ] __main__: train step 18922: loss: 0.9919, policy_loss: 0.9349, value_loss: 0.4697
2024-07-14 07:11:31,440 [INFO    ] __main__: train step 18923: loss: 0.9919, policy_loss: 0.9349, value_loss: 0.4697
2024-07-14 07:11:31,726 [INFO    ] __main__: train step 18924: loss: 0.9919, policy_loss: 0.9349, value_loss: 0.4697
2024-07-14 07:11:31,995 [INFO    ] __main__: train step 18925: loss: 0.9919, policy_loss: 0.9348, value_loss: 0.4697
2024-07-14 07:11:32,235 [INFO    ] __main__: train step 18926: loss: 0.9919, policy_loss: 0.9348, value_loss: 0.4696
2024-07-14 07:11:32,496 [INFO    ] __main__: train step 18927: loss: 0.9919, policy_loss: 0.9348, value_loss: 0.4696
2024-07-14 07:11:32,767 [INFO    ] __main__: train step 18928: loss: 0.9918, policy_loss: 0.9348, value_loss: 0.4696
2024-07-14 07:11:33,020 [INFO    ] __main__: train step 18929: loss: 0.9918, policy_loss: 0.9348, value_loss: 0.4696
2024-07-14 07:11:33,281 [INFO    ] __main__: train step 18930: loss: 0.9918, policy_loss: 0.9348, value_loss: 0.4696
2024-07-14 07:11:33,568 [INFO    ] __main__: train step 18931: loss: 0.9918, policy_loss: 0.9347, value_loss: 0.4695
2024-07-14 07:11:33,853 [INFO    ] __main__: train step 18932: loss: 0.9918, policy_loss: 0.9347, value_loss: 0.4695
2024-07-14 07:11:34,131 [INFO    ] __main__: train step 18933: loss: 0.9918, policy_loss: 0.9347, value_loss: 0.4695
2024-07-14 07:11:34,387 [INFO    ] __main__: train step 18934: loss: 0.9917, policy_loss: 0.9347, value_loss: 0.4695
2024-07-14 07:11:35,996 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:11:36,446 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:11:36,522 [INFO    ] __main__: train step 18935: loss: 0.9917, policy_loss: 0.9347, value_loss: 0.4695
2024-07-14 07:11:36,770 [INFO    ] __main__: train step 18936: loss: 0.9917, policy_loss: 0.9347, value_loss: 0.4695
2024-07-14 07:11:37,052 [INFO    ] __main__: train step 18937: loss: 0.9917, policy_loss: 0.9346, value_loss: 0.4694
2024-07-14 07:11:37,311 [INFO    ] __main__: train step 18938: loss: 0.9917, policy_loss: 0.9346, value_loss: 0.4694
2024-07-14 07:11:37,577 [INFO    ] __main__: train step 18939: loss: 0.9917, policy_loss: 0.9346, value_loss: 0.4694
2024-07-14 07:11:37,834 [INFO    ] __main__: train step 18940: loss: 0.9917, policy_loss: 0.9346, value_loss: 0.4694
2024-07-14 07:11:38,127 [INFO    ] __main__: train step 18941: loss: 0.9916, policy_loss: 0.9346, value_loss: 0.4694
2024-07-14 07:11:38,380 [INFO    ] __main__: train step 18942: loss: 0.9916, policy_loss: 0.9345, value_loss: 0.4693
2024-07-14 07:11:38,642 [INFO    ] __main__: train step 18943: loss: 0.9916, policy_loss: 0.9345, value_loss: 0.4693
2024-07-14 07:11:38,895 [INFO    ] __main__: train step 18944: loss: 0.9916, policy_loss: 0.9345, value_loss: 0.4693
2024-07-14 07:11:39,176 [INFO    ] __main__: train step 18945: loss: 0.9916, policy_loss: 0.9345, value_loss: 0.4693
2024-07-14 07:11:39,444 [INFO    ] __main__: train step 18946: loss: 0.9916, policy_loss: 0.9345, value_loss: 0.4693
2024-07-14 07:11:39,732 [INFO    ] __main__: train step 18947: loss: 0.9915, policy_loss: 0.9345, value_loss: 0.4692
2024-07-14 07:11:39,998 [INFO    ] __main__: train step 18948: loss: 0.9915, policy_loss: 0.9344, value_loss: 0.4692
2024-07-14 07:11:42,949 [INFO    ] __main__: train step 18949: loss: 0.9915, policy_loss: 0.9344, value_loss: 0.4692
2024-07-14 07:11:43,237 [INFO    ] __main__: train step 18950: loss: 0.9915, policy_loss: 0.9344, value_loss: 0.4692
2024-07-14 07:11:43,505 [INFO    ] __main__: train step 18951: loss: 0.9915, policy_loss: 0.9344, value_loss: 0.4692
2024-07-14 07:11:45,118 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:11:45,577 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:11:45,649 [INFO    ] __main__: train step 18952: loss: 0.9915, policy_loss: 0.9344, value_loss: 0.4691
2024-07-14 07:11:45,920 [INFO    ] __main__: train step 18953: loss: 0.9915, policy_loss: 0.9344, value_loss: 0.4691
2024-07-14 07:11:46,186 [INFO    ] __main__: train step 18954: loss: 0.9914, policy_loss: 0.9343, value_loss: 0.4691
2024-07-14 07:11:46,449 [INFO    ] __main__: train step 18955: loss: 0.9914, policy_loss: 0.9343, value_loss: 0.4691
2024-07-14 07:11:46,726 [INFO    ] __main__: train step 18956: loss: 0.9914, policy_loss: 0.9343, value_loss: 0.4691
2024-07-14 07:11:46,999 [INFO    ] __main__: train step 18957: loss: 0.9914, policy_loss: 0.9343, value_loss: 0.4690
2024-07-14 07:11:47,284 [INFO    ] __main__: train step 18958: loss: 0.9914, policy_loss: 0.9343, value_loss: 0.4690
2024-07-14 07:11:47,563 [INFO    ] __main__: train step 18959: loss: 0.9914, policy_loss: 0.9343, value_loss: 0.4690
2024-07-14 07:11:47,839 [INFO    ] __main__: train step 18960: loss: 0.9913, policy_loss: 0.9342, value_loss: 0.4690
2024-07-14 07:11:48,103 [INFO    ] __main__: train step 18961: loss: 0.9913, policy_loss: 0.9342, value_loss: 0.4690
2024-07-14 07:11:48,360 [INFO    ] __main__: train step 18962: loss: 0.9913, policy_loss: 0.9342, value_loss: 0.4689
2024-07-14 07:11:48,622 [INFO    ] __main__: train step 18963: loss: 0.9913, policy_loss: 0.9342, value_loss: 0.4689
2024-07-14 07:11:48,912 [INFO    ] __main__: train step 18964: loss: 0.9913, policy_loss: 0.9342, value_loss: 0.4689
2024-07-14 07:11:49,192 [INFO    ] __main__: train step 18965: loss: 0.9913, policy_loss: 0.9341, value_loss: 0.4689
2024-07-14 07:11:49,477 [INFO    ] __main__: train step 18966: loss: 0.9913, policy_loss: 0.9341, value_loss: 0.4689
2024-07-14 07:11:49,741 [INFO    ] __main__: train step 18967: loss: 0.9912, policy_loss: 0.9341, value_loss: 0.4688
2024-07-14 07:11:50,012 [INFO    ] __main__: train step 18968: loss: 0.9912, policy_loss: 0.9341, value_loss: 0.4688
2024-07-14 07:11:51,605 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:11:52,060 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:11:52,129 [INFO    ] __main__: train step 18969: loss: 0.9912, policy_loss: 0.9341, value_loss: 0.4688
2024-07-14 07:11:52,401 [INFO    ] __main__: train step 18970: loss: 0.9912, policy_loss: 0.9341, value_loss: 0.4688
2024-07-14 07:11:52,678 [INFO    ] __main__: train step 18971: loss: 0.9912, policy_loss: 0.9340, value_loss: 0.4688
2024-07-14 07:11:52,973 [INFO    ] __main__: train step 18972: loss: 0.9912, policy_loss: 0.9340, value_loss: 0.4687
2024-07-14 07:11:53,241 [INFO    ] __main__: train step 18973: loss: 0.9911, policy_loss: 0.9340, value_loss: 0.4687
2024-07-14 07:11:53,497 [INFO    ] __main__: train step 18974: loss: 0.9911, policy_loss: 0.9340, value_loss: 0.4687
2024-07-14 07:11:53,757 [INFO    ] __main__: train step 18975: loss: 0.9911, policy_loss: 0.9340, value_loss: 0.4687
2024-07-14 07:11:54,041 [INFO    ] __main__: train step 18976: loss: 0.9911, policy_loss: 0.9340, value_loss: 0.4687
2024-07-14 07:11:54,295 [INFO    ] __main__: train step 18977: loss: 0.9911, policy_loss: 0.9339, value_loss: 0.4686
2024-07-14 07:11:54,542 [INFO    ] __main__: train step 18978: loss: 0.9911, policy_loss: 0.9339, value_loss: 0.4686
2024-07-14 07:11:54,825 [INFO    ] __main__: train step 18979: loss: 0.9911, policy_loss: 0.9339, value_loss: 0.4686
2024-07-14 07:11:55,101 [INFO    ] __main__: train step 18980: loss: 0.9910, policy_loss: 0.9339, value_loss: 0.4686
2024-07-14 07:11:55,385 [INFO    ] __main__: train step 18981: loss: 0.9910, policy_loss: 0.9339, value_loss: 0.4686
2024-07-14 07:11:55,638 [INFO    ] __main__: train step 18982: loss: 0.9910, policy_loss: 0.9339, value_loss: 0.4685
2024-07-14 07:11:55,905 [INFO    ] __main__: train step 18983: loss: 0.9910, policy_loss: 0.9338, value_loss: 0.4685
2024-07-14 07:11:56,167 [INFO    ] __main__: train step 18984: loss: 0.9910, policy_loss: 0.9338, value_loss: 0.4685
2024-07-14 07:11:56,436 [INFO    ] __main__: train step 18985: loss: 0.9910, policy_loss: 0.9338, value_loss: 0.4685
2024-07-14 07:11:58,001 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:11:58,467 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:11:58,534 [INFO    ] __main__: train step 18986: loss: 0.9910, policy_loss: 0.9338, value_loss: 0.4685
2024-07-14 07:11:58,802 [INFO    ] __main__: train step 18987: loss: 0.9909, policy_loss: 0.9338, value_loss: 0.4685
2024-07-14 07:11:59,077 [INFO    ] __main__: train step 18988: loss: 0.9909, policy_loss: 0.9337, value_loss: 0.4684
2024-07-14 07:11:59,342 [INFO    ] __main__: train step 18989: loss: 0.9909, policy_loss: 0.9337, value_loss: 0.4684
2024-07-14 07:11:59,598 [INFO    ] __main__: train step 18990: loss: 0.9909, policy_loss: 0.9337, value_loss: 0.4684
2024-07-14 07:11:59,854 [INFO    ] __main__: train step 18991: loss: 0.9909, policy_loss: 0.9337, value_loss: 0.4684
2024-07-14 07:12:00,142 [INFO    ] __main__: train step 18992: loss: 0.9909, policy_loss: 0.9337, value_loss: 0.4684
2024-07-14 07:12:00,409 [INFO    ] __main__: train step 18993: loss: 0.9908, policy_loss: 0.9337, value_loss: 0.4683
2024-07-14 07:12:00,672 [INFO    ] __main__: train step 18994: loss: 0.9908, policy_loss: 0.9336, value_loss: 0.4683
2024-07-14 07:12:00,970 [INFO    ] __main__: train step 18995: loss: 0.9908, policy_loss: 0.9336, value_loss: 0.4683
2024-07-14 07:12:01,244 [INFO    ] __main__: train step 18996: loss: 0.9908, policy_loss: 0.9336, value_loss: 0.4683
2024-07-14 07:12:01,494 [INFO    ] __main__: train step 18997: loss: 0.9908, policy_loss: 0.9336, value_loss: 0.4683
2024-07-14 07:12:01,784 [INFO    ] __main__: train step 18998: loss: 0.9908, policy_loss: 0.9336, value_loss: 0.4682
2024-07-14 07:12:02,066 [INFO    ] __main__: train step 18999: loss: 0.9908, policy_loss: 0.9336, value_loss: 0.4682
2024-07-14 07:12:02,375 [INFO    ] __main__: train step 19000: loss: 0.9907, policy_loss: 0.9335, value_loss: 0.4682
2024-07-14 07:12:02,529 [INFO    ] __main__: restored step 18000 for evaluation
2024-07-14 07:12:07,764 [INFO    ] __main__: test network ELO difference from baseline network: +32 (+8/-8) ELO from 32000 self-played games
2024-07-14 07:12:07,767 [INFO    ] __main__: game outcomes: W: 17034, D: 376, L: 14590
2024-07-14 07:12:07,771 [INFO    ] __main__: validation_elo_delta: 32, validation_elo: 2776
2024-07-14 07:12:08,491 [INFO    ] __main__: train step 19001: loss: 0.9907, policy_loss: 0.9335, value_loss: 0.4682
2024-07-14 07:12:08,776 [INFO    ] __main__: train step 19002: loss: 0.9907, policy_loss: 0.9335, value_loss: 0.4682
2024-07-14 07:12:10,335 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:12:10,834 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:12:10,901 [INFO    ] __main__: train step 19003: loss: 0.9907, policy_loss: 0.9335, value_loss: 0.4681
2024-07-14 07:12:11,198 [INFO    ] __main__: train step 19004: loss: 0.9907, policy_loss: 0.9335, value_loss: 0.4681
2024-07-14 07:12:11,487 [INFO    ] __main__: train step 19005: loss: 0.9907, policy_loss: 0.9335, value_loss: 0.4681
2024-07-14 07:12:11,770 [INFO    ] __main__: train step 19006: loss: 0.9906, policy_loss: 0.9334, value_loss: 0.4681
2024-07-14 07:12:12,066 [INFO    ] __main__: train step 19007: loss: 0.9906, policy_loss: 0.9334, value_loss: 0.4681
2024-07-14 07:12:12,376 [INFO    ] __main__: train step 19008: loss: 0.9906, policy_loss: 0.9334, value_loss: 0.4680
2024-07-14 07:12:12,665 [INFO    ] __main__: train step 19009: loss: 0.9906, policy_loss: 0.9334, value_loss: 0.4680
2024-07-14 07:12:12,980 [INFO    ] __main__: train step 19010: loss: 0.9906, policy_loss: 0.9334, value_loss: 0.4680
2024-07-14 07:12:13,291 [INFO    ] __main__: train step 19011: loss: 0.9906, policy_loss: 0.9333, value_loss: 0.4680
2024-07-14 07:12:13,602 [INFO    ] __main__: train step 19012: loss: 0.9906, policy_loss: 0.9333, value_loss: 0.4680
2024-07-14 07:12:13,928 [INFO    ] __main__: train step 19013: loss: 0.9905, policy_loss: 0.9333, value_loss: 0.4679
2024-07-14 07:12:14,225 [INFO    ] __main__: train step 19014: loss: 0.9905, policy_loss: 0.9333, value_loss: 0.4679
2024-07-14 07:12:14,559 [INFO    ] __main__: train step 19015: loss: 0.9905, policy_loss: 0.9333, value_loss: 0.4679
2024-07-14 07:12:14,880 [INFO    ] __main__: train step 19016: loss: 0.9905, policy_loss: 0.9333, value_loss: 0.4679
2024-07-14 07:12:15,190 [INFO    ] __main__: train step 19017: loss: 0.9905, policy_loss: 0.9332, value_loss: 0.4679
2024-07-14 07:12:15,507 [INFO    ] __main__: train step 19018: loss: 0.9905, policy_loss: 0.9332, value_loss: 0.4679
2024-07-14 07:12:15,826 [INFO    ] __main__: train step 19019: loss: 0.9905, policy_loss: 0.9332, value_loss: 0.4678
2024-07-14 07:12:17,471 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:12:17,951 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:12:18,016 [INFO    ] __main__: train step 19020: loss: 0.9904, policy_loss: 0.9332, value_loss: 0.4678
2024-07-14 07:12:18,304 [INFO    ] __main__: train step 19021: loss: 0.9904, policy_loss: 0.9332, value_loss: 0.4678
2024-07-14 07:12:18,594 [INFO    ] __main__: train step 19022: loss: 0.9904, policy_loss: 0.9332, value_loss: 0.4678
2024-07-14 07:12:18,873 [INFO    ] __main__: train step 19023: loss: 0.9904, policy_loss: 0.9331, value_loss: 0.4678
2024-07-14 07:12:19,162 [INFO    ] __main__: train step 19024: loss: 0.9904, policy_loss: 0.9331, value_loss: 0.4677
2024-07-14 07:12:19,437 [INFO    ] __main__: train step 19025: loss: 0.9904, policy_loss: 0.9331, value_loss: 0.4677
2024-07-14 07:12:19,736 [INFO    ] __main__: train step 19026: loss: 0.9904, policy_loss: 0.9331, value_loss: 0.4677
2024-07-14 07:12:20,031 [INFO    ] __main__: train step 19027: loss: 0.9903, policy_loss: 0.9331, value_loss: 0.4677
2024-07-14 07:12:20,336 [INFO    ] __main__: train step 19028: loss: 0.9903, policy_loss: 0.9331, value_loss: 0.4677
2024-07-14 07:12:20,638 [INFO    ] __main__: train step 19029: loss: 0.9903, policy_loss: 0.9330, value_loss: 0.4676
2024-07-14 07:12:20,952 [INFO    ] __main__: train step 19030: loss: 0.9903, policy_loss: 0.9330, value_loss: 0.4676
2024-07-14 07:12:21,282 [INFO    ] __main__: train step 19031: loss: 0.9903, policy_loss: 0.9330, value_loss: 0.4676
2024-07-14 07:12:21,584 [INFO    ] __main__: train step 19032: loss: 0.9903, policy_loss: 0.9330, value_loss: 0.4676
2024-07-14 07:12:21,903 [INFO    ] __main__: train step 19033: loss: 0.9902, policy_loss: 0.9330, value_loss: 0.4676
2024-07-14 07:12:22,211 [INFO    ] __main__: train step 19034: loss: 0.9902, policy_loss: 0.9330, value_loss: 0.4675
2024-07-14 07:12:22,505 [INFO    ] __main__: train step 19035: loss: 0.9902, policy_loss: 0.9329, value_loss: 0.4675
2024-07-14 07:12:22,803 [INFO    ] __main__: train step 19036: loss: 0.9902, policy_loss: 0.9329, value_loss: 0.4675
2024-07-14 07:12:24,438 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:12:24,913 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:12:24,988 [INFO    ] __main__: train step 19037: loss: 0.9902, policy_loss: 0.9329, value_loss: 0.4675
2024-07-14 07:12:25,293 [INFO    ] __main__: train step 19038: loss: 0.9902, policy_loss: 0.9329, value_loss: 0.4675
2024-07-14 07:12:25,596 [INFO    ] __main__: train step 19039: loss: 0.9902, policy_loss: 0.9329, value_loss: 0.4674
2024-07-14 07:12:25,898 [INFO    ] __main__: train step 19040: loss: 0.9901, policy_loss: 0.9329, value_loss: 0.4674
2024-07-14 07:12:26,167 [INFO    ] __main__: train step 19041: loss: 0.9901, policy_loss: 0.9328, value_loss: 0.4674
2024-07-14 07:12:26,463 [INFO    ] __main__: train step 19042: loss: 0.9901, policy_loss: 0.9328, value_loss: 0.4674
2024-07-14 07:12:26,759 [INFO    ] __main__: train step 19043: loss: 0.9901, policy_loss: 0.9328, value_loss: 0.4674
2024-07-14 07:12:27,057 [INFO    ] __main__: train step 19044: loss: 0.9901, policy_loss: 0.9328, value_loss: 0.4674
2024-07-14 07:12:27,359 [INFO    ] __main__: train step 19045: loss: 0.9901, policy_loss: 0.9328, value_loss: 0.4673
2024-07-14 07:12:27,667 [INFO    ] __main__: train step 19046: loss: 0.9901, policy_loss: 0.9327, value_loss: 0.4673
2024-07-14 07:12:27,973 [INFO    ] __main__: train step 19047: loss: 0.9900, policy_loss: 0.9327, value_loss: 0.4673
2024-07-14 07:12:28,275 [INFO    ] __main__: train step 19048: loss: 0.9900, policy_loss: 0.9327, value_loss: 0.4673
2024-07-14 07:12:28,582 [INFO    ] __main__: train step 19049: loss: 0.9900, policy_loss: 0.9327, value_loss: 0.4673
2024-07-14 07:12:28,894 [INFO    ] __main__: train step 19050: loss: 0.9900, policy_loss: 0.9327, value_loss: 0.4672
2024-07-14 07:12:29,209 [INFO    ] __main__: train step 19051: loss: 0.9900, policy_loss: 0.9327, value_loss: 0.4672
2024-07-14 07:12:29,515 [INFO    ] __main__: train step 19052: loss: 0.9900, policy_loss: 0.9326, value_loss: 0.4672
2024-07-14 07:12:35,318 [INFO    ] __main__: train step 19053: loss: 0.9900, policy_loss: 0.9326, value_loss: 0.4672
2024-07-14 07:12:36,970 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:12:37,400 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:12:37,467 [INFO    ] __main__: train step 19054: loss: 0.9899, policy_loss: 0.9326, value_loss: 0.4672
2024-07-14 07:12:37,796 [INFO    ] __main__: train step 19055: loss: 0.9899, policy_loss: 0.9326, value_loss: 0.4671
2024-07-14 07:12:38,126 [INFO    ] __main__: train step 19056: loss: 0.9899, policy_loss: 0.9326, value_loss: 0.4671
2024-07-14 07:12:38,476 [INFO    ] __main__: train step 19057: loss: 0.9899, policy_loss: 0.9326, value_loss: 0.4671
2024-07-14 07:12:38,783 [INFO    ] __main__: train step 19058: loss: 0.9899, policy_loss: 0.9325, value_loss: 0.4671
2024-07-14 07:12:39,075 [INFO    ] __main__: train step 19059: loss: 0.9899, policy_loss: 0.9325, value_loss: 0.4671
2024-07-14 07:12:39,372 [INFO    ] __main__: train step 19060: loss: 0.9899, policy_loss: 0.9325, value_loss: 0.4671
2024-07-14 07:12:39,705 [INFO    ] __main__: train step 19061: loss: 0.9898, policy_loss: 0.9325, value_loss: 0.4670
2024-07-14 07:12:40,021 [INFO    ] __main__: train step 19062: loss: 0.9898, policy_loss: 0.9325, value_loss: 0.4670
2024-07-14 07:12:40,348 [INFO    ] __main__: train step 19063: loss: 0.9898, policy_loss: 0.9325, value_loss: 0.4670
2024-07-14 07:12:40,677 [INFO    ] __main__: train step 19064: loss: 0.9898, policy_loss: 0.9324, value_loss: 0.4670
2024-07-14 07:12:40,996 [INFO    ] __main__: train step 19065: loss: 0.9898, policy_loss: 0.9324, value_loss: 0.4670
2024-07-14 07:12:41,312 [INFO    ] __main__: train step 19066: loss: 0.9898, policy_loss: 0.9324, value_loss: 0.4669
2024-07-14 07:12:41,628 [INFO    ] __main__: train step 19067: loss: 0.9898, policy_loss: 0.9324, value_loss: 0.4669
2024-07-14 07:12:41,946 [INFO    ] __main__: train step 19068: loss: 0.9897, policy_loss: 0.9324, value_loss: 0.4669
2024-07-14 07:12:42,211 [INFO    ] __main__: train step 19069: loss: 0.9897, policy_loss: 0.9324, value_loss: 0.4669
2024-07-14 07:12:42,515 [INFO    ] __main__: train step 19070: loss: 0.9897, policy_loss: 0.9323, value_loss: 0.4669
2024-07-14 07:12:44,168 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:12:44,640 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:12:44,711 [INFO    ] __main__: train step 19071: loss: 0.9897, policy_loss: 0.9323, value_loss: 0.4668
2024-07-14 07:12:45,047 [INFO    ] __main__: train step 19072: loss: 0.9897, policy_loss: 0.9323, value_loss: 0.4668
2024-07-14 07:12:45,366 [INFO    ] __main__: train step 19073: loss: 0.9897, policy_loss: 0.9323, value_loss: 0.4668
2024-07-14 07:12:45,677 [INFO    ] __main__: train step 19074: loss: 0.9896, policy_loss: 0.9323, value_loss: 0.4668
2024-07-14 07:12:46,008 [INFO    ] __main__: train step 19075: loss: 0.9896, policy_loss: 0.9322, value_loss: 0.4668
2024-07-14 07:12:46,323 [INFO    ] __main__: train step 19076: loss: 0.9896, policy_loss: 0.9322, value_loss: 0.4667
2024-07-14 07:12:46,637 [INFO    ] __main__: train step 19077: loss: 0.9896, policy_loss: 0.9322, value_loss: 0.4667
2024-07-14 07:12:46,933 [INFO    ] __main__: train step 19078: loss: 0.9896, policy_loss: 0.9322, value_loss: 0.4667
2024-07-14 07:12:47,254 [INFO    ] __main__: train step 19079: loss: 0.9896, policy_loss: 0.9322, value_loss: 0.4667
2024-07-14 07:12:47,574 [INFO    ] __main__: train step 19080: loss: 0.9896, policy_loss: 0.9322, value_loss: 0.4667
2024-07-14 07:12:47,911 [INFO    ] __main__: train step 19081: loss: 0.9895, policy_loss: 0.9321, value_loss: 0.4666
2024-07-14 07:12:48,250 [INFO    ] __main__: train step 19082: loss: 0.9895, policy_loss: 0.9321, value_loss: 0.4666
2024-07-14 07:12:48,560 [INFO    ] __main__: train step 19083: loss: 0.9895, policy_loss: 0.9321, value_loss: 0.4666
2024-07-14 07:12:48,886 [INFO    ] __main__: train step 19084: loss: 0.9895, policy_loss: 0.9321, value_loss: 0.4666
2024-07-14 07:12:49,210 [INFO    ] __main__: train step 19085: loss: 0.9895, policy_loss: 0.9321, value_loss: 0.4666
2024-07-14 07:12:49,536 [INFO    ] __main__: train step 19086: loss: 0.9895, policy_loss: 0.9321, value_loss: 0.4666
2024-07-14 07:12:49,858 [INFO    ] __main__: train step 19087: loss: 0.9895, policy_loss: 0.9320, value_loss: 0.4665
2024-07-14 07:12:51,481 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:12:51,894 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:12:51,964 [INFO    ] __main__: train step 19088: loss: 0.9894, policy_loss: 0.9320, value_loss: 0.4665
2024-07-14 07:12:52,295 [INFO    ] __main__: train step 19089: loss: 0.9894, policy_loss: 0.9320, value_loss: 0.4665
2024-07-14 07:12:52,614 [INFO    ] __main__: train step 19090: loss: 0.9894, policy_loss: 0.9320, value_loss: 0.4665
2024-07-14 07:12:52,929 [INFO    ] __main__: train step 19091: loss: 0.9894, policy_loss: 0.9320, value_loss: 0.4665
2024-07-14 07:12:53,211 [INFO    ] __main__: train step 19092: loss: 0.9894, policy_loss: 0.9320, value_loss: 0.4664
2024-07-14 07:12:53,519 [INFO    ] __main__: train step 19093: loss: 0.9894, policy_loss: 0.9319, value_loss: 0.4664
2024-07-14 07:12:53,854 [INFO    ] __main__: train step 19094: loss: 0.9894, policy_loss: 0.9319, value_loss: 0.4664
2024-07-14 07:12:54,170 [INFO    ] __main__: train step 19095: loss: 0.9893, policy_loss: 0.9319, value_loss: 0.4664
2024-07-14 07:12:54,469 [INFO    ] __main__: train step 19096: loss: 0.9893, policy_loss: 0.9319, value_loss: 0.4664
2024-07-14 07:12:54,785 [INFO    ] __main__: train step 19097: loss: 0.9893, policy_loss: 0.9319, value_loss: 0.4663
2024-07-14 07:12:55,092 [INFO    ] __main__: train step 19098: loss: 0.9893, policy_loss: 0.9319, value_loss: 0.4663
2024-07-14 07:12:55,391 [INFO    ] __main__: train step 19099: loss: 0.9893, policy_loss: 0.9318, value_loss: 0.4663
2024-07-14 07:12:55,717 [INFO    ] __main__: train step 19100: loss: 0.9893, policy_loss: 0.9318, value_loss: 0.4663
2024-07-14 07:12:56,022 [INFO    ] __main__: train step 19101: loss: 0.9892, policy_loss: 0.9318, value_loss: 0.4663
2024-07-14 07:12:56,329 [INFO    ] __main__: train step 19102: loss: 0.9892, policy_loss: 0.9318, value_loss: 0.4663
2024-07-14 07:12:56,615 [INFO    ] __main__: train step 19103: loss: 0.9892, policy_loss: 0.9318, value_loss: 0.4662
2024-07-14 07:12:56,904 [INFO    ] __main__: train step 19104: loss: 0.9892, policy_loss: 0.9318, value_loss: 0.4662
2024-07-14 07:12:58,544 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:12:59,030 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:12:59,100 [INFO    ] __main__: train step 19105: loss: 0.9892, policy_loss: 0.9317, value_loss: 0.4662
2024-07-14 07:12:59,386 [INFO    ] __main__: train step 19106: loss: 0.9892, policy_loss: 0.9317, value_loss: 0.4662
2024-07-14 07:12:59,660 [INFO    ] __main__: train step 19107: loss: 0.9892, policy_loss: 0.9317, value_loss: 0.4662
2024-07-14 07:12:59,948 [INFO    ] __main__: train step 19108: loss: 0.9891, policy_loss: 0.9317, value_loss: 0.4661
2024-07-14 07:13:00,244 [INFO    ] __main__: train step 19109: loss: 0.9891, policy_loss: 0.9317, value_loss: 0.4661
2024-07-14 07:13:00,542 [INFO    ] __main__: train step 19110: loss: 0.9891, policy_loss: 0.9317, value_loss: 0.4661
2024-07-14 07:13:00,855 [INFO    ] __main__: train step 19111: loss: 0.9891, policy_loss: 0.9316, value_loss: 0.4661
2024-07-14 07:13:01,125 [INFO    ] __main__: train step 19112: loss: 0.9891, policy_loss: 0.9316, value_loss: 0.4661
2024-07-14 07:13:01,394 [INFO    ] __main__: train step 19113: loss: 0.9891, policy_loss: 0.9316, value_loss: 0.4660
2024-07-14 07:13:01,655 [INFO    ] __main__: train step 19114: loss: 0.9891, policy_loss: 0.9316, value_loss: 0.4660
2024-07-14 07:13:01,956 [INFO    ] __main__: train step 19115: loss: 0.9890, policy_loss: 0.9316, value_loss: 0.4660
2024-07-14 07:13:02,257 [INFO    ] __main__: train step 19116: loss: 0.9890, policy_loss: 0.9315, value_loss: 0.4660
2024-07-14 07:13:02,558 [INFO    ] __main__: train step 19117: loss: 0.9890, policy_loss: 0.9315, value_loss: 0.4660
2024-07-14 07:13:02,817 [INFO    ] __main__: train step 19118: loss: 0.9890, policy_loss: 0.9315, value_loss: 0.4660
2024-07-14 07:13:03,112 [INFO    ] __main__: train step 19119: loss: 0.9890, policy_loss: 0.9315, value_loss: 0.4659
2024-07-14 07:13:03,400 [INFO    ] __main__: train step 19120: loss: 0.9890, policy_loss: 0.9315, value_loss: 0.4659
2024-07-14 07:13:03,691 [INFO    ] __main__: train step 19121: loss: 0.9890, policy_loss: 0.9315, value_loss: 0.4659
2024-07-14 07:13:05,329 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:13:05,802 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:13:05,867 [INFO    ] __main__: train step 19122: loss: 0.9889, policy_loss: 0.9314, value_loss: 0.4659
2024-07-14 07:13:06,144 [INFO    ] __main__: train step 19123: loss: 0.9889, policy_loss: 0.9314, value_loss: 0.4659
2024-07-14 07:13:06,441 [INFO    ] __main__: train step 19124: loss: 0.9889, policy_loss: 0.9314, value_loss: 0.4658
2024-07-14 07:13:06,733 [INFO    ] __main__: train step 19125: loss: 0.9889, policy_loss: 0.9314, value_loss: 0.4658
2024-07-14 07:13:07,037 [INFO    ] __main__: train step 19126: loss: 0.9889, policy_loss: 0.9314, value_loss: 0.4658
2024-07-14 07:13:07,358 [INFO    ] __main__: train step 19127: loss: 0.9889, policy_loss: 0.9314, value_loss: 0.4658
2024-07-14 07:13:07,639 [INFO    ] __main__: train step 19128: loss: 0.9889, policy_loss: 0.9313, value_loss: 0.4658
2024-07-14 07:13:07,944 [INFO    ] __main__: train step 19129: loss: 0.9888, policy_loss: 0.9313, value_loss: 0.4657
2024-07-14 07:13:08,246 [INFO    ] __main__: train step 19130: loss: 0.9888, policy_loss: 0.9313, value_loss: 0.4657
2024-07-14 07:13:08,542 [INFO    ] __main__: train step 19131: loss: 0.9888, policy_loss: 0.9313, value_loss: 0.4657
2024-07-14 07:13:08,850 [INFO    ] __main__: train step 19132: loss: 0.9888, policy_loss: 0.9313, value_loss: 0.4657
2024-07-14 07:13:09,129 [INFO    ] __main__: train step 19133: loss: 0.9888, policy_loss: 0.9313, value_loss: 0.4657
2024-07-14 07:13:09,431 [INFO    ] __main__: train step 19134: loss: 0.9888, policy_loss: 0.9312, value_loss: 0.4656
2024-07-14 07:13:09,714 [INFO    ] __main__: train step 19135: loss: 0.9888, policy_loss: 0.9312, value_loss: 0.4656
2024-07-14 07:13:09,998 [INFO    ] __main__: train step 19136: loss: 0.9887, policy_loss: 0.9312, value_loss: 0.4656
2024-07-14 07:13:10,285 [INFO    ] __main__: train step 19137: loss: 0.9887, policy_loss: 0.9312, value_loss: 0.4656
2024-07-14 07:13:10,577 [INFO    ] __main__: train step 19138: loss: 0.9887, policy_loss: 0.9312, value_loss: 0.4656
2024-07-14 07:13:12,213 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:13:12,703 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:13:12,773 [INFO    ] __main__: train step 19139: loss: 0.9887, policy_loss: 0.9312, value_loss: 0.4656
2024-07-14 07:13:13,080 [INFO    ] __main__: train step 19140: loss: 0.9887, policy_loss: 0.9311, value_loss: 0.4655
2024-07-14 07:13:13,381 [INFO    ] __main__: train step 19141: loss: 0.9887, policy_loss: 0.9311, value_loss: 0.4655
2024-07-14 07:13:13,640 [INFO    ] __main__: train step 19142: loss: 0.9887, policy_loss: 0.9311, value_loss: 0.4655
2024-07-14 07:13:13,916 [INFO    ] __main__: train step 19143: loss: 0.9886, policy_loss: 0.9311, value_loss: 0.4655
2024-07-14 07:13:14,211 [INFO    ] __main__: train step 19144: loss: 0.9886, policy_loss: 0.9311, value_loss: 0.4655
2024-07-14 07:13:14,509 [INFO    ] __main__: train step 19145: loss: 0.9886, policy_loss: 0.9311, value_loss: 0.4654
2024-07-14 07:13:14,810 [INFO    ] __main__: train step 19146: loss: 0.9886, policy_loss: 0.9310, value_loss: 0.4654
2024-07-14 07:13:15,100 [INFO    ] __main__: train step 19147: loss: 0.9886, policy_loss: 0.9310, value_loss: 0.4654
2024-07-14 07:13:15,406 [INFO    ] __main__: train step 19148: loss: 0.9886, policy_loss: 0.9310, value_loss: 0.4654
2024-07-14 07:13:15,714 [INFO    ] __main__: train step 19149: loss: 0.9886, policy_loss: 0.9310, value_loss: 0.4654
2024-07-14 07:13:16,014 [INFO    ] __main__: train step 19150: loss: 0.9885, policy_loss: 0.9310, value_loss: 0.4653
2024-07-14 07:13:16,324 [INFO    ] __main__: train step 19151: loss: 0.9885, policy_loss: 0.9310, value_loss: 0.4653
2024-07-14 07:13:16,636 [INFO    ] __main__: train step 19152: loss: 0.9885, policy_loss: 0.9309, value_loss: 0.4653
2024-07-14 07:13:16,921 [INFO    ] __main__: train step 19153: loss: 0.9885, policy_loss: 0.9309, value_loss: 0.4653
2024-07-14 07:13:17,216 [INFO    ] __main__: train step 19154: loss: 0.9885, policy_loss: 0.9309, value_loss: 0.4653
2024-07-14 07:13:17,530 [INFO    ] __main__: train step 19155: loss: 0.9885, policy_loss: 0.9309, value_loss: 0.4653
2024-07-14 07:13:22,382 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:13:22,838 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:13:22,909 [INFO    ] __main__: train step 19156: loss: 0.9885, policy_loss: 0.9309, value_loss: 0.4652
2024-07-14 07:13:23,239 [INFO    ] __main__: train step 19157: loss: 0.9884, policy_loss: 0.9308, value_loss: 0.4652
2024-07-14 07:13:23,515 [INFO    ] __main__: train step 19158: loss: 0.9884, policy_loss: 0.9308, value_loss: 0.4652
2024-07-14 07:13:23,804 [INFO    ] __main__: train step 19159: loss: 0.9884, policy_loss: 0.9308, value_loss: 0.4652
2024-07-14 07:13:24,098 [INFO    ] __main__: train step 19160: loss: 0.9884, policy_loss: 0.9308, value_loss: 0.4652
2024-07-14 07:13:24,401 [INFO    ] __main__: train step 19161: loss: 0.9884, policy_loss: 0.9308, value_loss: 0.4651
2024-07-14 07:13:24,698 [INFO    ] __main__: train step 19162: loss: 0.9884, policy_loss: 0.9308, value_loss: 0.4651
2024-07-14 07:13:25,010 [INFO    ] __main__: train step 19163: loss: 0.9884, policy_loss: 0.9307, value_loss: 0.4651
2024-07-14 07:13:25,309 [INFO    ] __main__: train step 19164: loss: 0.9883, policy_loss: 0.9307, value_loss: 0.4651
2024-07-14 07:13:25,617 [INFO    ] __main__: train step 19165: loss: 0.9883, policy_loss: 0.9307, value_loss: 0.4651
2024-07-14 07:13:25,914 [INFO    ] __main__: train step 19166: loss: 0.9883, policy_loss: 0.9307, value_loss: 0.4651
2024-07-14 07:13:26,233 [INFO    ] __main__: train step 19167: loss: 0.9883, policy_loss: 0.9307, value_loss: 0.4650
2024-07-14 07:13:26,535 [INFO    ] __main__: train step 19168: loss: 0.9883, policy_loss: 0.9307, value_loss: 0.4650
2024-07-14 07:13:26,838 [INFO    ] __main__: train step 19169: loss: 0.9883, policy_loss: 0.9306, value_loss: 0.4650
2024-07-14 07:13:27,142 [INFO    ] __main__: train step 19170: loss: 0.9883, policy_loss: 0.9306, value_loss: 0.4650
2024-07-14 07:13:27,453 [INFO    ] __main__: train step 19171: loss: 0.9882, policy_loss: 0.9306, value_loss: 0.4650
2024-07-14 07:13:27,764 [INFO    ] __main__: train step 19172: loss: 0.9882, policy_loss: 0.9306, value_loss: 0.4649
2024-07-14 07:13:29,382 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:13:29,848 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:13:29,914 [INFO    ] __main__: train step 19173: loss: 0.9882, policy_loss: 0.9306, value_loss: 0.4649
2024-07-14 07:13:30,204 [INFO    ] __main__: train step 19174: loss: 0.9882, policy_loss: 0.9306, value_loss: 0.4649
2024-07-14 07:13:30,494 [INFO    ] __main__: train step 19175: loss: 0.9882, policy_loss: 0.9305, value_loss: 0.4649
2024-07-14 07:13:30,786 [INFO    ] __main__: train step 19176: loss: 0.9882, policy_loss: 0.9305, value_loss: 0.4649
2024-07-14 07:13:31,105 [INFO    ] __main__: train step 19177: loss: 0.9881, policy_loss: 0.9305, value_loss: 0.4649
2024-07-14 07:13:31,396 [INFO    ] __main__: train step 19178: loss: 0.9881, policy_loss: 0.9305, value_loss: 0.4648
2024-07-14 07:13:31,678 [INFO    ] __main__: train step 19179: loss: 0.9881, policy_loss: 0.9305, value_loss: 0.4648
2024-07-14 07:13:31,980 [INFO    ] __main__: train step 19180: loss: 0.9881, policy_loss: 0.9305, value_loss: 0.4648
2024-07-14 07:13:32,291 [INFO    ] __main__: train step 19181: loss: 0.9881, policy_loss: 0.9304, value_loss: 0.4648
2024-07-14 07:13:32,596 [INFO    ] __main__: train step 19182: loss: 0.9881, policy_loss: 0.9304, value_loss: 0.4648
2024-07-14 07:13:32,904 [INFO    ] __main__: train step 19183: loss: 0.9881, policy_loss: 0.9304, value_loss: 0.4647
2024-07-14 07:13:33,186 [INFO    ] __main__: train step 19184: loss: 0.9880, policy_loss: 0.9304, value_loss: 0.4647
2024-07-14 07:13:33,487 [INFO    ] __main__: train step 19185: loss: 0.9880, policy_loss: 0.9304, value_loss: 0.4647
2024-07-14 07:13:33,785 [INFO    ] __main__: train step 19186: loss: 0.9880, policy_loss: 0.9303, value_loss: 0.4647
2024-07-14 07:13:34,083 [INFO    ] __main__: train step 19187: loss: 0.9880, policy_loss: 0.9303, value_loss: 0.4647
2024-07-14 07:13:34,372 [INFO    ] __main__: train step 19188: loss: 0.9880, policy_loss: 0.9303, value_loss: 0.4646
2024-07-14 07:13:34,679 [INFO    ] __main__: train step 19189: loss: 0.9880, policy_loss: 0.9303, value_loss: 0.4646
2024-07-14 07:13:36,289 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:13:36,771 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:13:36,844 [INFO    ] __main__: train step 19190: loss: 0.9880, policy_loss: 0.9303, value_loss: 0.4646
2024-07-14 07:13:37,140 [INFO    ] __main__: train step 19191: loss: 0.9879, policy_loss: 0.9303, value_loss: 0.4646
2024-07-14 07:13:37,451 [INFO    ] __main__: train step 19192: loss: 0.9879, policy_loss: 0.9302, value_loss: 0.4646
2024-07-14 07:13:37,751 [INFO    ] __main__: train step 19193: loss: 0.9879, policy_loss: 0.9302, value_loss: 0.4646
2024-07-14 07:13:38,077 [INFO    ] __main__: train step 19194: loss: 0.9879, policy_loss: 0.9302, value_loss: 0.4645
2024-07-14 07:13:38,384 [INFO    ] __main__: train step 19195: loss: 0.9879, policy_loss: 0.9302, value_loss: 0.4645
2024-07-14 07:13:38,680 [INFO    ] __main__: train step 19196: loss: 0.9879, policy_loss: 0.9302, value_loss: 0.4645
2024-07-14 07:13:38,990 [INFO    ] __main__: train step 19197: loss: 0.9879, policy_loss: 0.9302, value_loss: 0.4645
2024-07-14 07:13:39,299 [INFO    ] __main__: train step 19198: loss: 0.9878, policy_loss: 0.9301, value_loss: 0.4645
2024-07-14 07:13:39,586 [INFO    ] __main__: train step 19199: loss: 0.9878, policy_loss: 0.9301, value_loss: 0.4644
2024-07-14 07:13:39,870 [INFO    ] __main__: train step 19200: loss: 0.9878, policy_loss: 0.9301, value_loss: 0.4644
2024-07-14 07:13:40,170 [INFO    ] __main__: train step 19201: loss: 0.9878, policy_loss: 0.9301, value_loss: 0.4644
2024-07-14 07:13:40,456 [INFO    ] __main__: train step 19202: loss: 0.9878, policy_loss: 0.9301, value_loss: 0.4644
2024-07-14 07:13:40,753 [INFO    ] __main__: train step 19203: loss: 0.9878, policy_loss: 0.9301, value_loss: 0.4644
2024-07-14 07:13:41,028 [INFO    ] __main__: train step 19204: loss: 0.9878, policy_loss: 0.9300, value_loss: 0.4643
2024-07-14 07:13:41,309 [INFO    ] __main__: train step 19205: loss: 0.9877, policy_loss: 0.9300, value_loss: 0.4643
2024-07-14 07:13:41,616 [INFO    ] __main__: train step 19206: loss: 0.9877, policy_loss: 0.9300, value_loss: 0.4643
2024-07-14 07:13:43,248 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:13:43,717 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:13:43,783 [INFO    ] __main__: train step 19207: loss: 0.9877, policy_loss: 0.9300, value_loss: 0.4643
2024-07-14 07:13:44,102 [INFO    ] __main__: train step 19208: loss: 0.9877, policy_loss: 0.9300, value_loss: 0.4643
2024-07-14 07:13:44,379 [INFO    ] __main__: train step 19209: loss: 0.9877, policy_loss: 0.9300, value_loss: 0.4643
2024-07-14 07:13:44,678 [INFO    ] __main__: train step 19210: loss: 0.9877, policy_loss: 0.9299, value_loss: 0.4642
2024-07-14 07:13:44,962 [INFO    ] __main__: train step 19211: loss: 0.9877, policy_loss: 0.9299, value_loss: 0.4642
2024-07-14 07:13:45,259 [INFO    ] __main__: train step 19212: loss: 0.9876, policy_loss: 0.9299, value_loss: 0.4642
2024-07-14 07:13:45,569 [INFO    ] __main__: train step 19213: loss: 0.9876, policy_loss: 0.9299, value_loss: 0.4642
2024-07-14 07:13:45,855 [INFO    ] __main__: train step 19214: loss: 0.9876, policy_loss: 0.9299, value_loss: 0.4642
2024-07-14 07:13:46,151 [INFO    ] __main__: train step 19215: loss: 0.9876, policy_loss: 0.9299, value_loss: 0.4641
2024-07-14 07:13:46,446 [INFO    ] __main__: train step 19216: loss: 0.9876, policy_loss: 0.9298, value_loss: 0.4641
2024-07-14 07:13:46,739 [INFO    ] __main__: train step 19217: loss: 0.9876, policy_loss: 0.9298, value_loss: 0.4641
2024-07-14 07:13:47,047 [INFO    ] __main__: train step 19218: loss: 0.9876, policy_loss: 0.9298, value_loss: 0.4641
2024-07-14 07:13:47,352 [INFO    ] __main__: train step 19219: loss: 0.9875, policy_loss: 0.9298, value_loss: 0.4641
2024-07-14 07:13:47,676 [INFO    ] __main__: train step 19220: loss: 0.9875, policy_loss: 0.9298, value_loss: 0.4641
2024-07-14 07:13:47,964 [INFO    ] __main__: train step 19221: loss: 0.9875, policy_loss: 0.9297, value_loss: 0.4640
2024-07-14 07:13:48,315 [INFO    ] __main__: train step 19222: loss: 0.9875, policy_loss: 0.9297, value_loss: 0.4640
2024-07-14 07:13:48,629 [INFO    ] __main__: train step 19223: loss: 0.9875, policy_loss: 0.9297, value_loss: 0.4640
2024-07-14 07:13:50,266 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:13:50,745 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:13:50,818 [INFO    ] __main__: train step 19224: loss: 0.9875, policy_loss: 0.9297, value_loss: 0.4640
2024-07-14 07:13:51,114 [INFO    ] __main__: train step 19225: loss: 0.9875, policy_loss: 0.9297, value_loss: 0.4640
2024-07-14 07:13:51,434 [INFO    ] __main__: train step 19226: loss: 0.9874, policy_loss: 0.9297, value_loss: 0.4639
2024-07-14 07:13:51,720 [INFO    ] __main__: train step 19227: loss: 0.9874, policy_loss: 0.9296, value_loss: 0.4639
2024-07-14 07:13:52,016 [INFO    ] __main__: train step 19228: loss: 0.9874, policy_loss: 0.9296, value_loss: 0.4639
2024-07-14 07:13:52,283 [INFO    ] __main__: train step 19229: loss: 0.9874, policy_loss: 0.9296, value_loss: 0.4639
2024-07-14 07:13:52,579 [INFO    ] __main__: train step 19230: loss: 0.9874, policy_loss: 0.9296, value_loss: 0.4639
2024-07-14 07:13:52,863 [INFO    ] __main__: train step 19231: loss: 0.9874, policy_loss: 0.9296, value_loss: 0.4638
2024-07-14 07:13:53,153 [INFO    ] __main__: train step 19232: loss: 0.9873, policy_loss: 0.9296, value_loss: 0.4638
2024-07-14 07:13:53,439 [INFO    ] __main__: train step 19233: loss: 0.9873, policy_loss: 0.9295, value_loss: 0.4638
2024-07-14 07:13:53,732 [INFO    ] __main__: train step 19234: loss: 0.9873, policy_loss: 0.9295, value_loss: 0.4638
2024-07-14 07:13:54,023 [INFO    ] __main__: train step 19235: loss: 0.9873, policy_loss: 0.9295, value_loss: 0.4638
2024-07-14 07:13:54,307 [INFO    ] __main__: train step 19236: loss: 0.9873, policy_loss: 0.9295, value_loss: 0.4638
2024-07-14 07:13:54,597 [INFO    ] __main__: train step 19237: loss: 0.9873, policy_loss: 0.9295, value_loss: 0.4637
2024-07-14 07:13:54,874 [INFO    ] __main__: train step 19238: loss: 0.9873, policy_loss: 0.9295, value_loss: 0.4637
2024-07-14 07:13:55,168 [INFO    ] __main__: train step 19239: loss: 0.9872, policy_loss: 0.9294, value_loss: 0.4637
2024-07-14 07:13:55,452 [INFO    ] __main__: train step 19240: loss: 0.9872, policy_loss: 0.9294, value_loss: 0.4637
2024-07-14 07:13:57,064 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:13:57,533 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:13:57,608 [INFO    ] __main__: train step 19241: loss: 0.9872, policy_loss: 0.9294, value_loss: 0.4637
2024-07-14 07:13:57,891 [INFO    ] __main__: train step 19242: loss: 0.9872, policy_loss: 0.9294, value_loss: 0.4636
2024-07-14 07:13:58,158 [INFO    ] __main__: train step 19243: loss: 0.9872, policy_loss: 0.9294, value_loss: 0.4636
2024-07-14 07:13:58,435 [INFO    ] __main__: train step 19244: loss: 0.9872, policy_loss: 0.9294, value_loss: 0.4636
2024-07-14 07:13:58,729 [INFO    ] __main__: train step 19245: loss: 0.9872, policy_loss: 0.9293, value_loss: 0.4636
2024-07-14 07:13:59,036 [INFO    ] __main__: train step 19246: loss: 0.9872, policy_loss: 0.9293, value_loss: 0.4636
2024-07-14 07:13:59,331 [INFO    ] __main__: train step 19247: loss: 0.9871, policy_loss: 0.9293, value_loss: 0.4636
2024-07-14 07:13:59,635 [INFO    ] __main__: train step 19248: loss: 0.9871, policy_loss: 0.9293, value_loss: 0.4635
2024-07-14 07:13:59,951 [INFO    ] __main__: train step 19249: loss: 0.9871, policy_loss: 0.9293, value_loss: 0.4635
2024-07-14 07:14:00,224 [INFO    ] __main__: train step 19250: loss: 0.9871, policy_loss: 0.9293, value_loss: 0.4635
2024-07-14 07:14:00,507 [INFO    ] __main__: train step 19251: loss: 0.9871, policy_loss: 0.9292, value_loss: 0.4635
2024-07-14 07:14:00,819 [INFO    ] __main__: train step 19252: loss: 0.9871, policy_loss: 0.9292, value_loss: 0.4635
2024-07-14 07:14:01,130 [INFO    ] __main__: train step 19253: loss: 0.9870, policy_loss: 0.9292, value_loss: 0.4634
2024-07-14 07:14:01,436 [INFO    ] __main__: train step 19254: loss: 0.9870, policy_loss: 0.9292, value_loss: 0.4634
2024-07-14 07:14:01,741 [INFO    ] __main__: train step 19255: loss: 0.9870, policy_loss: 0.9292, value_loss: 0.4634
2024-07-14 07:14:02,022 [INFO    ] __main__: train step 19256: loss: 0.9870, policy_loss: 0.9291, value_loss: 0.4634
2024-07-14 07:14:02,323 [INFO    ] __main__: train step 19257: loss: 0.9870, policy_loss: 0.9291, value_loss: 0.4634
2024-07-14 07:14:03,964 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:14:04,455 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:14:04,523 [INFO    ] __main__: train step 19258: loss: 0.9870, policy_loss: 0.9291, value_loss: 0.4634
2024-07-14 07:14:04,801 [INFO    ] __main__: train step 19259: loss: 0.9870, policy_loss: 0.9291, value_loss: 0.4633
2024-07-14 07:14:08,360 [INFO    ] __main__: train step 19260: loss: 0.9870, policy_loss: 0.9291, value_loss: 0.4633
2024-07-14 07:14:08,664 [INFO    ] __main__: train step 19261: loss: 0.9869, policy_loss: 0.9291, value_loss: 0.4633
2024-07-14 07:14:08,972 [INFO    ] __main__: train step 19262: loss: 0.9869, policy_loss: 0.9290, value_loss: 0.4633
2024-07-14 07:14:09,291 [INFO    ] __main__: train step 19263: loss: 0.9869, policy_loss: 0.9290, value_loss: 0.4633
2024-07-14 07:14:09,597 [INFO    ] __main__: train step 19264: loss: 0.9869, policy_loss: 0.9290, value_loss: 0.4632
2024-07-14 07:14:09,887 [INFO    ] __main__: train step 19265: loss: 0.9869, policy_loss: 0.9290, value_loss: 0.4632
2024-07-14 07:14:10,191 [INFO    ] __main__: train step 19266: loss: 0.9869, policy_loss: 0.9290, value_loss: 0.4632
2024-07-14 07:14:10,496 [INFO    ] __main__: train step 19267: loss: 0.9869, policy_loss: 0.9290, value_loss: 0.4632
2024-07-14 07:14:10,797 [INFO    ] __main__: train step 19268: loss: 0.9868, policy_loss: 0.9289, value_loss: 0.4632
2024-07-14 07:14:11,091 [INFO    ] __main__: train step 19269: loss: 0.9868, policy_loss: 0.9289, value_loss: 0.4632
2024-07-14 07:14:11,356 [INFO    ] __main__: train step 19270: loss: 0.9868, policy_loss: 0.9289, value_loss: 0.4631
2024-07-14 07:14:11,629 [INFO    ] __main__: train step 19271: loss: 0.9868, policy_loss: 0.9289, value_loss: 0.4631
2024-07-14 07:14:11,910 [INFO    ] __main__: train step 19272: loss: 0.9868, policy_loss: 0.9289, value_loss: 0.4631
2024-07-14 07:14:12,238 [INFO    ] __main__: train step 19273: loss: 0.9868, policy_loss: 0.9289, value_loss: 0.4631
2024-07-14 07:14:12,538 [INFO    ] __main__: train step 19274: loss: 0.9868, policy_loss: 0.9288, value_loss: 0.4631
2024-07-14 07:14:14,150 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:14:14,593 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:14:14,669 [INFO    ] __main__: train step 19275: loss: 0.9867, policy_loss: 0.9288, value_loss: 0.4631
2024-07-14 07:14:14,944 [INFO    ] __main__: train step 19276: loss: 0.9867, policy_loss: 0.9288, value_loss: 0.4630
2024-07-14 07:14:15,237 [INFO    ] __main__: train step 19277: loss: 0.9867, policy_loss: 0.9288, value_loss: 0.4630
2024-07-14 07:14:15,535 [INFO    ] __main__: train step 19278: loss: 0.9867, policy_loss: 0.9288, value_loss: 0.4630
2024-07-14 07:14:15,827 [INFO    ] __main__: train step 19279: loss: 0.9867, policy_loss: 0.9288, value_loss: 0.4630
2024-07-14 07:14:16,123 [INFO    ] __main__: train step 19280: loss: 0.9867, policy_loss: 0.9287, value_loss: 0.4630
2024-07-14 07:14:16,416 [INFO    ] __main__: train step 19281: loss: 0.9867, policy_loss: 0.9287, value_loss: 0.4629
2024-07-14 07:14:16,735 [INFO    ] __main__: train step 19282: loss: 0.9866, policy_loss: 0.9287, value_loss: 0.4629
2024-07-14 07:14:17,035 [INFO    ] __main__: train step 19283: loss: 0.9866, policy_loss: 0.9287, value_loss: 0.4629
2024-07-14 07:14:17,340 [INFO    ] __main__: train step 19284: loss: 0.9866, policy_loss: 0.9287, value_loss: 0.4629
2024-07-14 07:14:17,635 [INFO    ] __main__: train step 19285: loss: 0.9866, policy_loss: 0.9287, value_loss: 0.4629
2024-07-14 07:14:17,933 [INFO    ] __main__: train step 19286: loss: 0.9866, policy_loss: 0.9286, value_loss: 0.4629
2024-07-14 07:14:18,223 [INFO    ] __main__: train step 19287: loss: 0.9866, policy_loss: 0.9286, value_loss: 0.4628
2024-07-14 07:14:18,537 [INFO    ] __main__: train step 19288: loss: 0.9866, policy_loss: 0.9286, value_loss: 0.4628
2024-07-14 07:14:18,856 [INFO    ] __main__: train step 19289: loss: 0.9865, policy_loss: 0.9286, value_loss: 0.4628
2024-07-14 07:14:19,129 [INFO    ] __main__: train step 19290: loss: 0.9865, policy_loss: 0.9286, value_loss: 0.4628
2024-07-14 07:14:19,423 [INFO    ] __main__: train step 19291: loss: 0.9865, policy_loss: 0.9285, value_loss: 0.4628
2024-07-14 07:14:21,033 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:14:21,516 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:14:21,590 [INFO    ] __main__: train step 19292: loss: 0.9865, policy_loss: 0.9285, value_loss: 0.4627
2024-07-14 07:14:21,893 [INFO    ] __main__: train step 19293: loss: 0.9865, policy_loss: 0.9285, value_loss: 0.4627
2024-07-14 07:14:22,190 [INFO    ] __main__: train step 19294: loss: 0.9865, policy_loss: 0.9285, value_loss: 0.4627
2024-07-14 07:14:22,455 [INFO    ] __main__: train step 19295: loss: 0.9865, policy_loss: 0.9285, value_loss: 0.4627
2024-07-14 07:14:22,735 [INFO    ] __main__: train step 19296: loss: 0.9864, policy_loss: 0.9285, value_loss: 0.4627
2024-07-14 07:14:23,019 [INFO    ] __main__: train step 19297: loss: 0.9864, policy_loss: 0.9284, value_loss: 0.4627
2024-07-14 07:14:23,316 [INFO    ] __main__: train step 19298: loss: 0.9864, policy_loss: 0.9284, value_loss: 0.4626
2024-07-14 07:14:23,618 [INFO    ] __main__: train step 19299: loss: 0.9864, policy_loss: 0.9284, value_loss: 0.4626
2024-07-14 07:14:23,885 [INFO    ] __main__: train step 19300: loss: 0.9864, policy_loss: 0.9284, value_loss: 0.4626
2024-07-14 07:14:24,162 [INFO    ] __main__: train step 19301: loss: 0.9864, policy_loss: 0.9284, value_loss: 0.4626
2024-07-14 07:14:24,451 [INFO    ] __main__: train step 19302: loss: 0.9864, policy_loss: 0.9284, value_loss: 0.4626
2024-07-14 07:14:24,764 [INFO    ] __main__: train step 19303: loss: 0.9863, policy_loss: 0.9283, value_loss: 0.4625
2024-07-14 07:14:25,062 [INFO    ] __main__: train step 19304: loss: 0.9863, policy_loss: 0.9283, value_loss: 0.4625
2024-07-14 07:14:25,350 [INFO    ] __main__: train step 19305: loss: 0.9863, policy_loss: 0.9283, value_loss: 0.4625
2024-07-14 07:14:25,649 [INFO    ] __main__: train step 19306: loss: 0.9863, policy_loss: 0.9283, value_loss: 0.4625
2024-07-14 07:14:25,956 [INFO    ] __main__: train step 19307: loss: 0.9863, policy_loss: 0.9283, value_loss: 0.4625
2024-07-14 07:14:26,261 [INFO    ] __main__: train step 19308: loss: 0.9863, policy_loss: 0.9283, value_loss: 0.4625
2024-07-14 07:14:27,898 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:14:28,382 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:14:28,449 [INFO    ] __main__: train step 19309: loss: 0.9863, policy_loss: 0.9282, value_loss: 0.4624
2024-07-14 07:14:28,729 [INFO    ] __main__: train step 19310: loss: 0.9862, policy_loss: 0.9282, value_loss: 0.4624
2024-07-14 07:14:29,028 [INFO    ] __main__: train step 19311: loss: 0.9862, policy_loss: 0.9282, value_loss: 0.4624
2024-07-14 07:14:29,301 [INFO    ] __main__: train step 19312: loss: 0.9862, policy_loss: 0.9282, value_loss: 0.4624
2024-07-14 07:14:29,584 [INFO    ] __main__: train step 19313: loss: 0.9862, policy_loss: 0.9282, value_loss: 0.4624
2024-07-14 07:14:29,896 [INFO    ] __main__: train step 19314: loss: 0.9862, policy_loss: 0.9282, value_loss: 0.4624
2024-07-14 07:14:30,190 [INFO    ] __main__: train step 19315: loss: 0.9862, policy_loss: 0.9281, value_loss: 0.4623
2024-07-14 07:14:30,485 [INFO    ] __main__: train step 19316: loss: 0.9862, policy_loss: 0.9281, value_loss: 0.4623
2024-07-14 07:14:30,763 [INFO    ] __main__: train step 19317: loss: 0.9861, policy_loss: 0.9281, value_loss: 0.4623
2024-07-14 07:14:31,041 [INFO    ] __main__: train step 19318: loss: 0.9861, policy_loss: 0.9281, value_loss: 0.4623
2024-07-14 07:14:31,339 [INFO    ] __main__: train step 19319: loss: 0.9861, policy_loss: 0.9281, value_loss: 0.4623
2024-07-14 07:14:31,603 [INFO    ] __main__: train step 19320: loss: 0.9861, policy_loss: 0.9280, value_loss: 0.4622
2024-07-14 07:14:31,895 [INFO    ] __main__: train step 19321: loss: 0.9861, policy_loss: 0.9280, value_loss: 0.4622
2024-07-14 07:14:32,190 [INFO    ] __main__: train step 19322: loss: 0.9861, policy_loss: 0.9280, value_loss: 0.4622
2024-07-14 07:14:32,492 [INFO    ] __main__: train step 19323: loss: 0.9861, policy_loss: 0.9280, value_loss: 0.4622
2024-07-14 07:14:32,788 [INFO    ] __main__: train step 19324: loss: 0.9860, policy_loss: 0.9280, value_loss: 0.4622
2024-07-14 07:14:33,085 [INFO    ] __main__: train step 19325: loss: 0.9860, policy_loss: 0.9280, value_loss: 0.4622
2024-07-14 07:14:34,706 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:14:35,181 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:14:35,249 [INFO    ] __main__: train step 19326: loss: 0.9860, policy_loss: 0.9279, value_loss: 0.4621
2024-07-14 07:14:35,532 [INFO    ] __main__: train step 19327: loss: 0.9860, policy_loss: 0.9279, value_loss: 0.4621
2024-07-14 07:14:35,837 [INFO    ] __main__: train step 19328: loss: 0.9860, policy_loss: 0.9279, value_loss: 0.4621
2024-07-14 07:14:36,138 [INFO    ] __main__: train step 19329: loss: 0.9860, policy_loss: 0.9279, value_loss: 0.4621
2024-07-14 07:14:36,434 [INFO    ] __main__: train step 19330: loss: 0.9860, policy_loss: 0.9279, value_loss: 0.4621
2024-07-14 07:14:36,721 [INFO    ] __main__: train step 19331: loss: 0.9859, policy_loss: 0.9279, value_loss: 0.4621
2024-07-14 07:14:37,005 [INFO    ] __main__: train step 19332: loss: 0.9859, policy_loss: 0.9278, value_loss: 0.4620
2024-07-14 07:14:37,301 [INFO    ] __main__: train step 19333: loss: 0.9859, policy_loss: 0.9278, value_loss: 0.4620
2024-07-14 07:14:37,607 [INFO    ] __main__: train step 19334: loss: 0.9859, policy_loss: 0.9278, value_loss: 0.4620
2024-07-14 07:14:37,895 [INFO    ] __main__: train step 19335: loss: 0.9859, policy_loss: 0.9278, value_loss: 0.4620
2024-07-14 07:14:38,182 [INFO    ] __main__: train step 19336: loss: 0.9859, policy_loss: 0.9278, value_loss: 0.4620
2024-07-14 07:14:38,458 [INFO    ] __main__: train step 19337: loss: 0.9859, policy_loss: 0.9278, value_loss: 0.4620
2024-07-14 07:14:38,749 [INFO    ] __main__: train step 19338: loss: 0.9859, policy_loss: 0.9277, value_loss: 0.4619
2024-07-14 07:14:39,057 [INFO    ] __main__: train step 19339: loss: 0.9858, policy_loss: 0.9277, value_loss: 0.4619
2024-07-14 07:14:39,369 [INFO    ] __main__: train step 19340: loss: 0.9858, policy_loss: 0.9277, value_loss: 0.4619
2024-07-14 07:14:39,656 [INFO    ] __main__: train step 19341: loss: 0.9858, policy_loss: 0.9277, value_loss: 0.4619
2024-07-14 07:14:39,932 [INFO    ] __main__: train step 19342: loss: 0.9858, policy_loss: 0.9277, value_loss: 0.4619
2024-07-14 07:14:41,554 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:14:42,051 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:14:42,121 [INFO    ] __main__: train step 19343: loss: 0.9858, policy_loss: 0.9276, value_loss: 0.4618
2024-07-14 07:14:42,422 [INFO    ] __main__: train step 19344: loss: 0.9858, policy_loss: 0.9276, value_loss: 0.4618
2024-07-14 07:14:42,702 [INFO    ] __main__: train step 19345: loss: 0.9858, policy_loss: 0.9276, value_loss: 0.4618
2024-07-14 07:14:42,968 [INFO    ] __main__: train step 19346: loss: 0.9857, policy_loss: 0.9276, value_loss: 0.4618
2024-07-14 07:14:43,267 [INFO    ] __main__: train step 19347: loss: 0.9857, policy_loss: 0.9276, value_loss: 0.4618
2024-07-14 07:14:43,569 [INFO    ] __main__: train step 19348: loss: 0.9857, policy_loss: 0.9276, value_loss: 0.4618
2024-07-14 07:14:43,872 [INFO    ] __main__: train step 19349: loss: 0.9857, policy_loss: 0.9275, value_loss: 0.4617
2024-07-14 07:14:44,148 [INFO    ] __main__: train step 19350: loss: 0.9857, policy_loss: 0.9275, value_loss: 0.4617
2024-07-14 07:14:44,422 [INFO    ] __main__: train step 19351: loss: 0.9857, policy_loss: 0.9275, value_loss: 0.4617
2024-07-14 07:14:44,692 [INFO    ] __main__: train step 19352: loss: 0.9857, policy_loss: 0.9275, value_loss: 0.4617
2024-07-14 07:14:44,999 [INFO    ] __main__: train step 19353: loss: 0.9856, policy_loss: 0.9275, value_loss: 0.4617
2024-07-14 07:14:45,293 [INFO    ] __main__: train step 19354: loss: 0.9856, policy_loss: 0.9275, value_loss: 0.4617
2024-07-14 07:14:45,582 [INFO    ] __main__: train step 19355: loss: 0.9856, policy_loss: 0.9274, value_loss: 0.4616
2024-07-14 07:14:45,884 [INFO    ] __main__: train step 19356: loss: 0.9856, policy_loss: 0.9274, value_loss: 0.4616
2024-07-14 07:14:46,155 [INFO    ] __main__: train step 19357: loss: 0.9856, policy_loss: 0.9274, value_loss: 0.4616
2024-07-14 07:14:46,458 [INFO    ] __main__: train step 19358: loss: 0.9856, policy_loss: 0.9274, value_loss: 0.4616
2024-07-14 07:14:46,759 [INFO    ] __main__: train step 19359: loss: 0.9856, policy_loss: 0.9274, value_loss: 0.4616
2024-07-14 07:14:48,386 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:14:48,823 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:14:48,899 [INFO    ] __main__: train step 19360: loss: 0.9855, policy_loss: 0.9274, value_loss: 0.4616
2024-07-14 07:14:49,172 [INFO    ] __main__: train step 19361: loss: 0.9855, policy_loss: 0.9273, value_loss: 0.4615
2024-07-14 07:14:49,455 [INFO    ] __main__: train step 19362: loss: 0.9855, policy_loss: 0.9273, value_loss: 0.4615
2024-07-14 07:14:49,752 [INFO    ] __main__: train step 19363: loss: 0.9855, policy_loss: 0.9273, value_loss: 0.4615
2024-07-14 07:14:53,314 [INFO    ] __main__: train step 19364: loss: 0.9855, policy_loss: 0.9273, value_loss: 0.4615
2024-07-14 07:14:53,629 [INFO    ] __main__: train step 19365: loss: 0.9855, policy_loss: 0.9273, value_loss: 0.4615
2024-07-14 07:14:53,915 [INFO    ] __main__: train step 19366: loss: 0.9855, policy_loss: 0.9273, value_loss: 0.4614
2024-07-14 07:14:54,187 [INFO    ] __main__: train step 19367: loss: 0.9855, policy_loss: 0.9272, value_loss: 0.4614
2024-07-14 07:14:54,480 [INFO    ] __main__: train step 19368: loss: 0.9854, policy_loss: 0.9272, value_loss: 0.4614
2024-07-14 07:14:54,775 [INFO    ] __main__: train step 19369: loss: 0.9854, policy_loss: 0.9272, value_loss: 0.4614
2024-07-14 07:14:55,079 [INFO    ] __main__: train step 19370: loss: 0.9854, policy_loss: 0.9272, value_loss: 0.4614
2024-07-14 07:14:55,381 [INFO    ] __main__: train step 19371: loss: 0.9854, policy_loss: 0.9272, value_loss: 0.4614
2024-07-14 07:14:55,682 [INFO    ] __main__: train step 19372: loss: 0.9854, policy_loss: 0.9271, value_loss: 0.4613
2024-07-14 07:14:55,987 [INFO    ] __main__: train step 19373: loss: 0.9854, policy_loss: 0.9271, value_loss: 0.4613
2024-07-14 07:14:56,286 [INFO    ] __main__: train step 19374: loss: 0.9854, policy_loss: 0.9271, value_loss: 0.4613
2024-07-14 07:14:56,580 [INFO    ] __main__: train step 19375: loss: 0.9853, policy_loss: 0.9271, value_loss: 0.4613
2024-07-14 07:14:56,889 [INFO    ] __main__: train step 19376: loss: 0.9853, policy_loss: 0.9271, value_loss: 0.4613
2024-07-14 07:14:58,526 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:14:58,985 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:14:59,055 [INFO    ] __main__: train step 19377: loss: 0.9853, policy_loss: 0.9271, value_loss: 0.4613
2024-07-14 07:14:59,329 [INFO    ] __main__: train step 19378: loss: 0.9853, policy_loss: 0.9270, value_loss: 0.4612
2024-07-14 07:14:59,636 [INFO    ] __main__: train step 19379: loss: 0.9853, policy_loss: 0.9270, value_loss: 0.4612
2024-07-14 07:14:59,947 [INFO    ] __main__: train step 19380: loss: 0.9853, policy_loss: 0.9270, value_loss: 0.4612
2024-07-14 07:15:00,204 [INFO    ] __main__: train step 19381: loss: 0.9853, policy_loss: 0.9270, value_loss: 0.4612
2024-07-14 07:15:00,470 [INFO    ] __main__: train step 19382: loss: 0.9853, policy_loss: 0.9270, value_loss: 0.4612
2024-07-14 07:15:00,777 [INFO    ] __main__: train step 19383: loss: 0.9852, policy_loss: 0.9270, value_loss: 0.4612
2024-07-14 07:15:01,071 [INFO    ] __main__: train step 19384: loss: 0.9852, policy_loss: 0.9269, value_loss: 0.4611
2024-07-14 07:15:01,371 [INFO    ] __main__: train step 19385: loss: 0.9852, policy_loss: 0.9269, value_loss: 0.4611
2024-07-14 07:15:01,663 [INFO    ] __main__: train step 19386: loss: 0.9852, policy_loss: 0.9269, value_loss: 0.4611
2024-07-14 07:15:01,940 [INFO    ] __main__: train step 19387: loss: 0.9852, policy_loss: 0.9269, value_loss: 0.4611
2024-07-14 07:15:02,216 [INFO    ] __main__: train step 19388: loss: 0.9852, policy_loss: 0.9269, value_loss: 0.4611
2024-07-14 07:15:02,515 [INFO    ] __main__: train step 19389: loss: 0.9852, policy_loss: 0.9269, value_loss: 0.4611
2024-07-14 07:15:02,807 [INFO    ] __main__: train step 19390: loss: 0.9851, policy_loss: 0.9268, value_loss: 0.4610
2024-07-14 07:15:03,086 [INFO    ] __main__: train step 19391: loss: 0.9851, policy_loss: 0.9268, value_loss: 0.4610
2024-07-14 07:15:03,381 [INFO    ] __main__: train step 19392: loss: 0.9851, policy_loss: 0.9268, value_loss: 0.4610
2024-07-14 07:15:03,660 [INFO    ] __main__: train step 19393: loss: 0.9851, policy_loss: 0.9268, value_loss: 0.4610
2024-07-14 07:15:05,292 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:15:05,753 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:15:05,821 [INFO    ] __main__: train step 19394: loss: 0.9851, policy_loss: 0.9268, value_loss: 0.4610
2024-07-14 07:15:06,138 [INFO    ] __main__: train step 19395: loss: 0.9851, policy_loss: 0.9268, value_loss: 0.4609
2024-07-14 07:15:06,433 [INFO    ] __main__: train step 19396: loss: 0.9851, policy_loss: 0.9267, value_loss: 0.4609
2024-07-14 07:15:06,735 [INFO    ] __main__: train step 19397: loss: 0.9850, policy_loss: 0.9267, value_loss: 0.4609
2024-07-14 07:15:07,030 [INFO    ] __main__: train step 19398: loss: 0.9850, policy_loss: 0.9267, value_loss: 0.4609
2024-07-14 07:15:07,323 [INFO    ] __main__: train step 19399: loss: 0.9850, policy_loss: 0.9267, value_loss: 0.4609
2024-07-14 07:15:07,621 [INFO    ] __main__: train step 19400: loss: 0.9850, policy_loss: 0.9267, value_loss: 0.4609
2024-07-14 07:15:07,916 [INFO    ] __main__: train step 19401: loss: 0.9850, policy_loss: 0.9266, value_loss: 0.4608
2024-07-14 07:15:08,184 [INFO    ] __main__: train step 19402: loss: 0.9850, policy_loss: 0.9266, value_loss: 0.4608
2024-07-14 07:15:08,472 [INFO    ] __main__: train step 19403: loss: 0.9850, policy_loss: 0.9266, value_loss: 0.4608
2024-07-14 07:15:08,773 [INFO    ] __main__: train step 19404: loss: 0.9850, policy_loss: 0.9266, value_loss: 0.4608
2024-07-14 07:15:09,070 [INFO    ] __main__: train step 19405: loss: 0.9849, policy_loss: 0.9266, value_loss: 0.4608
2024-07-14 07:15:09,375 [INFO    ] __main__: train step 19406: loss: 0.9849, policy_loss: 0.9266, value_loss: 0.4608
2024-07-14 07:15:09,654 [INFO    ] __main__: train step 19407: loss: 0.9849, policy_loss: 0.9265, value_loss: 0.4607
2024-07-14 07:15:09,945 [INFO    ] __main__: train step 19408: loss: 0.9849, policy_loss: 0.9265, value_loss: 0.4607
2024-07-14 07:15:10,234 [INFO    ] __main__: train step 19409: loss: 0.9849, policy_loss: 0.9265, value_loss: 0.4607
2024-07-14 07:15:10,526 [INFO    ] __main__: train step 19410: loss: 0.9849, policy_loss: 0.9265, value_loss: 0.4607
2024-07-14 07:15:12,152 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:15:12,621 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:15:12,700 [INFO    ] __main__: train step 19411: loss: 0.9849, policy_loss: 0.9265, value_loss: 0.4607
2024-07-14 07:15:12,983 [INFO    ] __main__: train step 19412: loss: 0.9848, policy_loss: 0.9265, value_loss: 0.4607
2024-07-14 07:15:13,265 [INFO    ] __main__: train step 19413: loss: 0.9848, policy_loss: 0.9264, value_loss: 0.4606
2024-07-14 07:15:13,574 [INFO    ] __main__: train step 19414: loss: 0.9848, policy_loss: 0.9264, value_loss: 0.4606
2024-07-14 07:15:13,873 [INFO    ] __main__: train step 19415: loss: 0.9848, policy_loss: 0.9264, value_loss: 0.4606
2024-07-14 07:15:14,174 [INFO    ] __main__: train step 19416: loss: 0.9848, policy_loss: 0.9264, value_loss: 0.4606
2024-07-14 07:15:14,477 [INFO    ] __main__: train step 19417: loss: 0.9848, policy_loss: 0.9264, value_loss: 0.4606
2024-07-14 07:15:14,754 [INFO    ] __main__: train step 19418: loss: 0.9848, policy_loss: 0.9264, value_loss: 0.4606
2024-07-14 07:15:15,038 [INFO    ] __main__: train step 19419: loss: 0.9847, policy_loss: 0.9263, value_loss: 0.4605
2024-07-14 07:15:15,309 [INFO    ] __main__: train step 19420: loss: 0.9847, policy_loss: 0.9263, value_loss: 0.4605
2024-07-14 07:15:15,605 [INFO    ] __main__: train step 19421: loss: 0.9847, policy_loss: 0.9263, value_loss: 0.4605
2024-07-14 07:15:15,888 [INFO    ] __main__: train step 19422: loss: 0.9847, policy_loss: 0.9263, value_loss: 0.4605
2024-07-14 07:15:16,164 [INFO    ] __main__: train step 19423: loss: 0.9847, policy_loss: 0.9263, value_loss: 0.4605
2024-07-14 07:15:16,459 [INFO    ] __main__: train step 19424: loss: 0.9847, policy_loss: 0.9263, value_loss: 0.4605
2024-07-14 07:15:16,779 [INFO    ] __main__: train step 19425: loss: 0.9847, policy_loss: 0.9262, value_loss: 0.4604
2024-07-14 07:15:17,080 [INFO    ] __main__: train step 19426: loss: 0.9847, policy_loss: 0.9262, value_loss: 0.4604
2024-07-14 07:15:17,371 [INFO    ] __main__: train step 19427: loss: 0.9846, policy_loss: 0.9262, value_loss: 0.4604
2024-07-14 07:15:18,975 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:15:19,417 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:15:19,485 [INFO    ] __main__: train step 19428: loss: 0.9846, policy_loss: 0.9262, value_loss: 0.4604
2024-07-14 07:15:19,795 [INFO    ] __main__: train step 19429: loss: 0.9846, policy_loss: 0.9262, value_loss: 0.4604
2024-07-14 07:15:20,081 [INFO    ] __main__: train step 19430: loss: 0.9846, policy_loss: 0.9262, value_loss: 0.4603
2024-07-14 07:15:20,378 [INFO    ] __main__: train step 19431: loss: 0.9846, policy_loss: 0.9261, value_loss: 0.4603
2024-07-14 07:15:20,659 [INFO    ] __main__: train step 19432: loss: 0.9846, policy_loss: 0.9261, value_loss: 0.4603
2024-07-14 07:15:20,940 [INFO    ] __main__: train step 19433: loss: 0.9846, policy_loss: 0.9261, value_loss: 0.4603
2024-07-14 07:15:21,247 [INFO    ] __main__: train step 19434: loss: 0.9845, policy_loss: 0.9261, value_loss: 0.4603
2024-07-14 07:15:21,547 [INFO    ] __main__: train step 19435: loss: 0.9845, policy_loss: 0.9261, value_loss: 0.4603
2024-07-14 07:15:21,848 [INFO    ] __main__: train step 19436: loss: 0.9845, policy_loss: 0.9260, value_loss: 0.4602
2024-07-14 07:15:22,152 [INFO    ] __main__: train step 19437: loss: 0.9845, policy_loss: 0.9260, value_loss: 0.4602
2024-07-14 07:15:22,438 [INFO    ] __main__: train step 19438: loss: 0.9845, policy_loss: 0.9260, value_loss: 0.4602
2024-07-14 07:15:22,731 [INFO    ] __main__: train step 19439: loss: 0.9845, policy_loss: 0.9260, value_loss: 0.4602
2024-07-14 07:15:23,032 [INFO    ] __main__: train step 19440: loss: 0.9845, policy_loss: 0.9260, value_loss: 0.4602
2024-07-14 07:15:23,336 [INFO    ] __main__: train step 19441: loss: 0.9844, policy_loss: 0.9260, value_loss: 0.4602
2024-07-14 07:15:23,644 [INFO    ] __main__: train step 19442: loss: 0.9844, policy_loss: 0.9259, value_loss: 0.4601
2024-07-14 07:15:23,918 [INFO    ] __main__: train step 19443: loss: 0.9844, policy_loss: 0.9259, value_loss: 0.4601
2024-07-14 07:15:24,223 [INFO    ] __main__: train step 19444: loss: 0.9844, policy_loss: 0.9259, value_loss: 0.4601
2024-07-14 07:15:25,849 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:15:26,320 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:15:26,392 [INFO    ] __main__: train step 19445: loss: 0.9844, policy_loss: 0.9259, value_loss: 0.4601
2024-07-14 07:15:26,678 [INFO    ] __main__: train step 19446: loss: 0.9844, policy_loss: 0.9259, value_loss: 0.4601
2024-07-14 07:15:26,957 [INFO    ] __main__: train step 19447: loss: 0.9844, policy_loss: 0.9259, value_loss: 0.4601
2024-07-14 07:15:27,249 [INFO    ] __main__: train step 19448: loss: 0.9844, policy_loss: 0.9258, value_loss: 0.4600
2024-07-14 07:15:27,545 [INFO    ] __main__: train step 19449: loss: 0.9843, policy_loss: 0.9258, value_loss: 0.4600
2024-07-14 07:15:27,836 [INFO    ] __main__: train step 19450: loss: 0.9843, policy_loss: 0.9258, value_loss: 0.4600
2024-07-14 07:15:28,126 [INFO    ] __main__: train step 19451: loss: 0.9843, policy_loss: 0.9258, value_loss: 0.4600
2024-07-14 07:15:28,434 [INFO    ] __main__: train step 19452: loss: 0.9843, policy_loss: 0.9258, value_loss: 0.4600
2024-07-14 07:15:28,718 [INFO    ] __main__: train step 19453: loss: 0.9843, policy_loss: 0.9258, value_loss: 0.4600
2024-07-14 07:15:28,996 [INFO    ] __main__: train step 19454: loss: 0.9843, policy_loss: 0.9257, value_loss: 0.4599
2024-07-14 07:15:29,296 [INFO    ] __main__: train step 19455: loss: 0.9843, policy_loss: 0.9257, value_loss: 0.4599
2024-07-14 07:15:29,597 [INFO    ] __main__: train step 19456: loss: 0.9842, policy_loss: 0.9257, value_loss: 0.4599
2024-07-14 07:15:29,898 [INFO    ] __main__: train step 19457: loss: 0.9842, policy_loss: 0.9257, value_loss: 0.4599
2024-07-14 07:15:30,207 [INFO    ] __main__: train step 19458: loss: 0.9842, policy_loss: 0.9257, value_loss: 0.4599
2024-07-14 07:15:30,481 [INFO    ] __main__: train step 19459: loss: 0.9842, policy_loss: 0.9257, value_loss: 0.4599
2024-07-14 07:15:30,781 [INFO    ] __main__: train step 19460: loss: 0.9842, policy_loss: 0.9256, value_loss: 0.4598
2024-07-14 07:15:31,085 [INFO    ] __main__: train step 19461: loss: 0.9842, policy_loss: 0.9256, value_loss: 0.4598
2024-07-14 07:15:32,703 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:15:33,197 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:15:33,262 [INFO    ] __main__: train step 19462: loss: 0.9842, policy_loss: 0.9256, value_loss: 0.4598
2024-07-14 07:15:33,539 [INFO    ] __main__: train step 19463: loss: 0.9841, policy_loss: 0.9256, value_loss: 0.4598
2024-07-14 07:15:33,844 [INFO    ] __main__: train step 19464: loss: 0.9841, policy_loss: 0.9256, value_loss: 0.4598
2024-07-14 07:15:34,129 [INFO    ] __main__: train step 19465: loss: 0.9841, policy_loss: 0.9256, value_loss: 0.4598
2024-07-14 07:15:34,429 [INFO    ] __main__: train step 19466: loss: 0.9841, policy_loss: 0.9255, value_loss: 0.4597
2024-07-14 07:15:37,945 [INFO    ] __main__: train step 19467: loss: 0.9841, policy_loss: 0.9255, value_loss: 0.4597
2024-07-14 07:15:38,242 [INFO    ] __main__: train step 19468: loss: 0.9841, policy_loss: 0.9255, value_loss: 0.4597
2024-07-14 07:15:38,541 [INFO    ] __main__: train step 19469: loss: 0.9841, policy_loss: 0.9255, value_loss: 0.4597
2024-07-14 07:15:38,834 [INFO    ] __main__: train step 19470: loss: 0.9841, policy_loss: 0.9255, value_loss: 0.4597
2024-07-14 07:15:39,145 [INFO    ] __main__: train step 19471: loss: 0.9840, policy_loss: 0.9254, value_loss: 0.4597
2024-07-14 07:15:39,440 [INFO    ] __main__: train step 19472: loss: 0.9840, policy_loss: 0.9254, value_loss: 0.4596
2024-07-14 07:15:39,719 [INFO    ] __main__: train step 19473: loss: 0.9840, policy_loss: 0.9254, value_loss: 0.4596
2024-07-14 07:15:40,014 [INFO    ] __main__: train step 19474: loss: 0.9840, policy_loss: 0.9254, value_loss: 0.4596
2024-07-14 07:15:40,311 [INFO    ] __main__: train step 19475: loss: 0.9840, policy_loss: 0.9254, value_loss: 0.4596
2024-07-14 07:15:40,609 [INFO    ] __main__: train step 19476: loss: 0.9840, policy_loss: 0.9254, value_loss: 0.4596
2024-07-14 07:15:40,908 [INFO    ] __main__: train step 19477: loss: 0.9840, policy_loss: 0.9253, value_loss: 0.4596
2024-07-14 07:15:41,204 [INFO    ] __main__: train step 19478: loss: 0.9839, policy_loss: 0.9253, value_loss: 0.4595
2024-07-14 07:15:42,810 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:15:43,283 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:15:43,353 [INFO    ] __main__: train step 19479: loss: 0.9839, policy_loss: 0.9253, value_loss: 0.4595
2024-07-14 07:15:43,617 [INFO    ] __main__: train step 19480: loss: 0.9839, policy_loss: 0.9253, value_loss: 0.4595
2024-07-14 07:15:43,885 [INFO    ] __main__: train step 19481: loss: 0.9839, policy_loss: 0.9253, value_loss: 0.4595
2024-07-14 07:15:44,160 [INFO    ] __main__: train step 19482: loss: 0.9839, policy_loss: 0.9253, value_loss: 0.4595
2024-07-14 07:15:44,422 [INFO    ] __main__: train step 19483: loss: 0.9839, policy_loss: 0.9252, value_loss: 0.4594
2024-07-14 07:15:44,695 [INFO    ] __main__: train step 19484: loss: 0.9839, policy_loss: 0.9252, value_loss: 0.4594
2024-07-14 07:15:44,989 [INFO    ] __main__: train step 19485: loss: 0.9838, policy_loss: 0.9252, value_loss: 0.4594
2024-07-14 07:15:45,303 [INFO    ] __main__: train step 19486: loss: 0.9838, policy_loss: 0.9252, value_loss: 0.4594
2024-07-14 07:15:45,605 [INFO    ] __main__: train step 19487: loss: 0.9838, policy_loss: 0.9252, value_loss: 0.4594
2024-07-14 07:15:45,881 [INFO    ] __main__: train step 19488: loss: 0.9838, policy_loss: 0.9252, value_loss: 0.4594
2024-07-14 07:15:46,178 [INFO    ] __main__: train step 19489: loss: 0.9838, policy_loss: 0.9251, value_loss: 0.4593
2024-07-14 07:15:46,479 [INFO    ] __main__: train step 19490: loss: 0.9838, policy_loss: 0.9251, value_loss: 0.4593
2024-07-14 07:15:46,759 [INFO    ] __main__: train step 19491: loss: 0.9838, policy_loss: 0.9251, value_loss: 0.4593
2024-07-14 07:15:47,035 [INFO    ] __main__: train step 19492: loss: 0.9837, policy_loss: 0.9251, value_loss: 0.4593
2024-07-14 07:15:47,318 [INFO    ] __main__: train step 19493: loss: 0.9837, policy_loss: 0.9251, value_loss: 0.4593
2024-07-14 07:15:47,586 [INFO    ] __main__: train step 19494: loss: 0.9837, policy_loss: 0.9250, value_loss: 0.4593
2024-07-14 07:15:47,873 [INFO    ] __main__: train step 19495: loss: 0.9837, policy_loss: 0.9250, value_loss: 0.4592
2024-07-14 07:15:49,505 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:15:49,956 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:15:50,024 [INFO    ] __main__: train step 19496: loss: 0.9837, policy_loss: 0.9250, value_loss: 0.4592
2024-07-14 07:15:50,327 [INFO    ] __main__: train step 19497: loss: 0.9837, policy_loss: 0.9250, value_loss: 0.4592
2024-07-14 07:15:50,622 [INFO    ] __main__: train step 19498: loss: 0.9837, policy_loss: 0.9250, value_loss: 0.4592
2024-07-14 07:15:50,934 [INFO    ] __main__: train step 19499: loss: 0.9837, policy_loss: 0.9250, value_loss: 0.4592
2024-07-14 07:15:51,236 [INFO    ] __main__: train step 19500: loss: 0.9836, policy_loss: 0.9249, value_loss: 0.4592
2024-07-14 07:15:51,535 [INFO    ] __main__: train step 19501: loss: 0.9836, policy_loss: 0.9249, value_loss: 0.4591
2024-07-14 07:15:51,831 [INFO    ] __main__: train step 19502: loss: 0.9836, policy_loss: 0.9249, value_loss: 0.4591
2024-07-14 07:15:52,121 [INFO    ] __main__: train step 19503: loss: 0.9836, policy_loss: 0.9249, value_loss: 0.4591
2024-07-14 07:15:52,398 [INFO    ] __main__: train step 19504: loss: 0.9836, policy_loss: 0.9249, value_loss: 0.4591
2024-07-14 07:15:52,705 [INFO    ] __main__: train step 19505: loss: 0.9836, policy_loss: 0.9249, value_loss: 0.4591
2024-07-14 07:15:53,016 [INFO    ] __main__: train step 19506: loss: 0.9836, policy_loss: 0.9248, value_loss: 0.4591
2024-07-14 07:15:53,336 [INFO    ] __main__: train step 19507: loss: 0.9835, policy_loss: 0.9248, value_loss: 0.4590
2024-07-14 07:15:53,637 [INFO    ] __main__: train step 19508: loss: 0.9835, policy_loss: 0.9248, value_loss: 0.4590
2024-07-14 07:15:53,946 [INFO    ] __main__: train step 19509: loss: 0.9835, policy_loss: 0.9248, value_loss: 0.4590
2024-07-14 07:15:54,251 [INFO    ] __main__: train step 19510: loss: 0.9835, policy_loss: 0.9248, value_loss: 0.4590
2024-07-14 07:15:54,556 [INFO    ] __main__: train step 19511: loss: 0.9835, policy_loss: 0.9248, value_loss: 0.4590
2024-07-14 07:15:54,858 [INFO    ] __main__: train step 19512: loss: 0.9835, policy_loss: 0.9247, value_loss: 0.4590
2024-07-14 07:15:56,453 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:15:56,929 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:15:57,008 [INFO    ] __main__: train step 19513: loss: 0.9835, policy_loss: 0.9247, value_loss: 0.4589
2024-07-14 07:15:57,307 [INFO    ] __main__: train step 19514: loss: 0.9834, policy_loss: 0.9247, value_loss: 0.4589
2024-07-14 07:15:57,606 [INFO    ] __main__: train step 19515: loss: 0.9834, policy_loss: 0.9247, value_loss: 0.4589
2024-07-14 07:15:57,922 [INFO    ] __main__: train step 19516: loss: 0.9834, policy_loss: 0.9247, value_loss: 0.4589
2024-07-14 07:15:58,211 [INFO    ] __main__: train step 19517: loss: 0.9834, policy_loss: 0.9246, value_loss: 0.4589
2024-07-14 07:15:58,499 [INFO    ] __main__: train step 19518: loss: 0.9834, policy_loss: 0.9246, value_loss: 0.4589
2024-07-14 07:15:58,820 [INFO    ] __main__: train step 19519: loss: 0.9834, policy_loss: 0.9246, value_loss: 0.4588
2024-07-14 07:15:59,132 [INFO    ] __main__: train step 19520: loss: 0.9834, policy_loss: 0.9246, value_loss: 0.4588
2024-07-14 07:15:59,433 [INFO    ] __main__: train step 19521: loss: 0.9833, policy_loss: 0.9246, value_loss: 0.4588
2024-07-14 07:15:59,726 [INFO    ] __main__: train step 19522: loss: 0.9833, policy_loss: 0.9246, value_loss: 0.4588
2024-07-14 07:16:00,024 [INFO    ] __main__: train step 19523: loss: 0.9833, policy_loss: 0.9245, value_loss: 0.4588
2024-07-14 07:16:00,316 [INFO    ] __main__: train step 19524: loss: 0.9833, policy_loss: 0.9245, value_loss: 0.4587
2024-07-14 07:16:00,617 [INFO    ] __main__: train step 19525: loss: 0.9833, policy_loss: 0.9245, value_loss: 0.4587
2024-07-14 07:16:00,923 [INFO    ] __main__: train step 19526: loss: 0.9833, policy_loss: 0.9245, value_loss: 0.4587
2024-07-14 07:16:01,229 [INFO    ] __main__: train step 19527: loss: 0.9833, policy_loss: 0.9245, value_loss: 0.4587
2024-07-14 07:16:01,520 [INFO    ] __main__: train step 19528: loss: 0.9832, policy_loss: 0.9245, value_loss: 0.4587
2024-07-14 07:16:01,812 [INFO    ] __main__: train step 19529: loss: 0.9832, policy_loss: 0.9244, value_loss: 0.4587
2024-07-14 07:16:03,425 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:16:03,919 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:16:03,984 [INFO    ] __main__: train step 19530: loss: 0.9832, policy_loss: 0.9244, value_loss: 0.4586
2024-07-14 07:16:04,273 [INFO    ] __main__: train step 19531: loss: 0.9832, policy_loss: 0.9244, value_loss: 0.4586
2024-07-14 07:16:04,559 [INFO    ] __main__: train step 19532: loss: 0.9832, policy_loss: 0.9244, value_loss: 0.4586
2024-07-14 07:16:04,858 [INFO    ] __main__: train step 19533: loss: 0.9832, policy_loss: 0.9244, value_loss: 0.4586
2024-07-14 07:16:05,168 [INFO    ] __main__: train step 19534: loss: 0.9832, policy_loss: 0.9243, value_loss: 0.4586
2024-07-14 07:16:05,474 [INFO    ] __main__: train step 19535: loss: 0.9832, policy_loss: 0.9243, value_loss: 0.4586
2024-07-14 07:16:05,760 [INFO    ] __main__: train step 19536: loss: 0.9831, policy_loss: 0.9243, value_loss: 0.4585
2024-07-14 07:16:06,040 [INFO    ] __main__: train step 19537: loss: 0.9831, policy_loss: 0.9243, value_loss: 0.4585
2024-07-14 07:16:06,331 [INFO    ] __main__: train step 19538: loss: 0.9831, policy_loss: 0.9243, value_loss: 0.4585
2024-07-14 07:16:06,627 [INFO    ] __main__: train step 19539: loss: 0.9831, policy_loss: 0.9243, value_loss: 0.4585
2024-07-14 07:16:06,930 [INFO    ] __main__: train step 19540: loss: 0.9831, policy_loss: 0.9242, value_loss: 0.4585
2024-07-14 07:16:07,240 [INFO    ] __main__: train step 19541: loss: 0.9831, policy_loss: 0.9242, value_loss: 0.4585
2024-07-14 07:16:07,525 [INFO    ] __main__: train step 19542: loss: 0.9831, policy_loss: 0.9242, value_loss: 0.4584
2024-07-14 07:16:07,832 [INFO    ] __main__: train step 19543: loss: 0.9830, policy_loss: 0.9242, value_loss: 0.4584
2024-07-14 07:16:08,139 [INFO    ] __main__: train step 19544: loss: 0.9830, policy_loss: 0.9242, value_loss: 0.4584
2024-07-14 07:16:08,442 [INFO    ] __main__: train step 19545: loss: 0.9830, policy_loss: 0.9242, value_loss: 0.4584
2024-07-14 07:16:08,742 [INFO    ] __main__: train step 19546: loss: 0.9830, policy_loss: 0.9241, value_loss: 0.4584
2024-07-14 07:16:10,348 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:16:10,853 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:16:10,922 [INFO    ] __main__: train step 19547: loss: 0.9830, policy_loss: 0.9241, value_loss: 0.4584
2024-07-14 07:16:11,215 [INFO    ] __main__: train step 19548: loss: 0.9830, policy_loss: 0.9241, value_loss: 0.4583
2024-07-14 07:16:11,514 [INFO    ] __main__: train step 19549: loss: 0.9830, policy_loss: 0.9241, value_loss: 0.4583
2024-07-14 07:16:11,814 [INFO    ] __main__: train step 19550: loss: 0.9829, policy_loss: 0.9241, value_loss: 0.4583
2024-07-14 07:16:12,133 [INFO    ] __main__: train step 19551: loss: 0.9829, policy_loss: 0.9241, value_loss: 0.4583
2024-07-14 07:16:12,439 [INFO    ] __main__: train step 19552: loss: 0.9829, policy_loss: 0.9240, value_loss: 0.4583
2024-07-14 07:16:12,746 [INFO    ] __main__: train step 19553: loss: 0.9829, policy_loss: 0.9240, value_loss: 0.4583
2024-07-14 07:16:13,042 [INFO    ] __main__: train step 19554: loss: 0.9829, policy_loss: 0.9240, value_loss: 0.4582
2024-07-14 07:16:13,347 [INFO    ] __main__: train step 19555: loss: 0.9829, policy_loss: 0.9240, value_loss: 0.4582
2024-07-14 07:16:13,641 [INFO    ] __main__: train step 19556: loss: 0.9829, policy_loss: 0.9240, value_loss: 0.4582
2024-07-14 07:16:13,917 [INFO    ] __main__: train step 19557: loss: 0.9828, policy_loss: 0.9240, value_loss: 0.4582
2024-07-14 07:16:14,214 [INFO    ] __main__: train step 19558: loss: 0.9828, policy_loss: 0.9239, value_loss: 0.4582
2024-07-14 07:16:14,502 [INFO    ] __main__: train step 19559: loss: 0.9828, policy_loss: 0.9239, value_loss: 0.4582
2024-07-14 07:16:14,802 [INFO    ] __main__: train step 19560: loss: 0.9828, policy_loss: 0.9239, value_loss: 0.4581
2024-07-14 07:16:15,105 [INFO    ] __main__: train step 19561: loss: 0.9828, policy_loss: 0.9239, value_loss: 0.4581
2024-07-14 07:16:15,417 [INFO    ] __main__: train step 19562: loss: 0.9828, policy_loss: 0.9239, value_loss: 0.4581
2024-07-14 07:16:15,707 [INFO    ] __main__: train step 19563: loss: 0.9828, policy_loss: 0.9238, value_loss: 0.4581
2024-07-14 07:16:17,333 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:16:17,803 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:16:17,874 [INFO    ] __main__: train step 19564: loss: 0.9828, policy_loss: 0.9238, value_loss: 0.4581
2024-07-14 07:16:18,171 [INFO    ] __main__: train step 19565: loss: 0.9827, policy_loss: 0.9238, value_loss: 0.4581
2024-07-14 07:16:18,442 [INFO    ] __main__: train step 19566: loss: 0.9827, policy_loss: 0.9238, value_loss: 0.4580
2024-07-14 07:16:18,733 [INFO    ] __main__: train step 19567: loss: 0.9827, policy_loss: 0.9238, value_loss: 0.4580
2024-07-14 07:16:19,041 [INFO    ] __main__: train step 19568: loss: 0.9827, policy_loss: 0.9238, value_loss: 0.4580
2024-07-14 07:16:19,347 [INFO    ] __main__: train step 19569: loss: 0.9827, policy_loss: 0.9237, value_loss: 0.4580
2024-07-14 07:16:22,904 [INFO    ] __main__: train step 19570: loss: 0.9827, policy_loss: 0.9237, value_loss: 0.4580
2024-07-14 07:16:23,187 [INFO    ] __main__: train step 19571: loss: 0.9827, policy_loss: 0.9237, value_loss: 0.4580
2024-07-14 07:16:23,465 [INFO    ] __main__: train step 19572: loss: 0.9826, policy_loss: 0.9237, value_loss: 0.4579
2024-07-14 07:16:23,759 [INFO    ] __main__: train step 19573: loss: 0.9826, policy_loss: 0.9237, value_loss: 0.4579
2024-07-14 07:16:24,043 [INFO    ] __main__: train step 19574: loss: 0.9826, policy_loss: 0.9237, value_loss: 0.4579
2024-07-14 07:16:24,354 [INFO    ] __main__: train step 19575: loss: 0.9826, policy_loss: 0.9236, value_loss: 0.4579
2024-07-14 07:16:24,652 [INFO    ] __main__: train step 19576: loss: 0.9826, policy_loss: 0.9236, value_loss: 0.4579
2024-07-14 07:16:24,924 [INFO    ] __main__: train step 19577: loss: 0.9826, policy_loss: 0.9236, value_loss: 0.4579
2024-07-14 07:16:25,190 [INFO    ] __main__: train step 19578: loss: 0.9826, policy_loss: 0.9236, value_loss: 0.4578
2024-07-14 07:16:25,495 [INFO    ] __main__: train step 19579: loss: 0.9825, policy_loss: 0.9236, value_loss: 0.4578
2024-07-14 07:16:25,790 [INFO    ] __main__: train step 19580: loss: 0.9825, policy_loss: 0.9236, value_loss: 0.4578
2024-07-14 07:16:27,422 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:16:27,913 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:16:27,983 [INFO    ] __main__: train step 19581: loss: 0.9825, policy_loss: 0.9235, value_loss: 0.4578
2024-07-14 07:16:28,262 [INFO    ] __main__: train step 19582: loss: 0.9825, policy_loss: 0.9235, value_loss: 0.4578
2024-07-14 07:16:28,563 [INFO    ] __main__: train step 19583: loss: 0.9825, policy_loss: 0.9235, value_loss: 0.4577
2024-07-14 07:16:28,864 [INFO    ] __main__: train step 19584: loss: 0.9825, policy_loss: 0.9235, value_loss: 0.4577
2024-07-14 07:16:29,158 [INFO    ] __main__: train step 19585: loss: 0.9825, policy_loss: 0.9235, value_loss: 0.4577
2024-07-14 07:16:29,458 [INFO    ] __main__: train step 19586: loss: 0.9824, policy_loss: 0.9234, value_loss: 0.4577
2024-07-14 07:16:29,749 [INFO    ] __main__: train step 19587: loss: 0.9824, policy_loss: 0.9234, value_loss: 0.4577
2024-07-14 07:16:30,040 [INFO    ] __main__: train step 19588: loss: 0.9824, policy_loss: 0.9234, value_loss: 0.4577
2024-07-14 07:16:30,334 [INFO    ] __main__: train step 19589: loss: 0.9824, policy_loss: 0.9234, value_loss: 0.4576
2024-07-14 07:16:30,632 [INFO    ] __main__: train step 19590: loss: 0.9824, policy_loss: 0.9234, value_loss: 0.4576
2024-07-14 07:16:30,931 [INFO    ] __main__: train step 19591: loss: 0.9824, policy_loss: 0.9234, value_loss: 0.4576
2024-07-14 07:16:31,224 [INFO    ] __main__: train step 19592: loss: 0.9824, policy_loss: 0.9233, value_loss: 0.4576
2024-07-14 07:16:31,513 [INFO    ] __main__: train step 19593: loss: 0.9823, policy_loss: 0.9233, value_loss: 0.4576
2024-07-14 07:16:31,810 [INFO    ] __main__: train step 19594: loss: 0.9823, policy_loss: 0.9233, value_loss: 0.4576
2024-07-14 07:16:32,129 [INFO    ] __main__: train step 19595: loss: 0.9823, policy_loss: 0.9233, value_loss: 0.4576
2024-07-14 07:16:32,432 [INFO    ] __main__: train step 19596: loss: 0.9823, policy_loss: 0.9233, value_loss: 0.4575
2024-07-14 07:16:32,747 [INFO    ] __main__: train step 19597: loss: 0.9823, policy_loss: 0.9233, value_loss: 0.4575
2024-07-14 07:16:34,374 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:16:34,853 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:16:34,925 [INFO    ] __main__: train step 19598: loss: 0.9823, policy_loss: 0.9232, value_loss: 0.4575
2024-07-14 07:16:35,229 [INFO    ] __main__: train step 19599: loss: 0.9823, policy_loss: 0.9232, value_loss: 0.4575
2024-07-14 07:16:35,524 [INFO    ] __main__: train step 19600: loss: 0.9822, policy_loss: 0.9232, value_loss: 0.4575
2024-07-14 07:16:35,822 [INFO    ] __main__: train step 19601: loss: 0.9822, policy_loss: 0.9232, value_loss: 0.4575
2024-07-14 07:16:36,114 [INFO    ] __main__: train step 19602: loss: 0.9822, policy_loss: 0.9232, value_loss: 0.4574
2024-07-14 07:16:36,409 [INFO    ] __main__: train step 19603: loss: 0.9822, policy_loss: 0.9231, value_loss: 0.4574
2024-07-14 07:16:36,710 [INFO    ] __main__: train step 19604: loss: 0.9822, policy_loss: 0.9231, value_loss: 0.4574
2024-07-14 07:16:37,016 [INFO    ] __main__: train step 19605: loss: 0.9822, policy_loss: 0.9231, value_loss: 0.4574
2024-07-14 07:16:37,331 [INFO    ] __main__: train step 19606: loss: 0.9822, policy_loss: 0.9231, value_loss: 0.4574
2024-07-14 07:16:37,622 [INFO    ] __main__: train step 19607: loss: 0.9821, policy_loss: 0.9231, value_loss: 0.4573
2024-07-14 07:16:37,927 [INFO    ] __main__: train step 19608: loss: 0.9821, policy_loss: 0.9231, value_loss: 0.4573
2024-07-14 07:16:38,217 [INFO    ] __main__: train step 19609: loss: 0.9821, policy_loss: 0.9230, value_loss: 0.4573
2024-07-14 07:16:38,512 [INFO    ] __main__: train step 19610: loss: 0.9821, policy_loss: 0.9230, value_loss: 0.4573
2024-07-14 07:16:38,813 [INFO    ] __main__: train step 19611: loss: 0.9821, policy_loss: 0.9230, value_loss: 0.4573
2024-07-14 07:16:39,098 [INFO    ] __main__: train step 19612: loss: 0.9821, policy_loss: 0.9230, value_loss: 0.4573
2024-07-14 07:16:39,395 [INFO    ] __main__: train step 19613: loss: 0.9821, policy_loss: 0.9230, value_loss: 0.4573
2024-07-14 07:16:39,674 [INFO    ] __main__: train step 19614: loss: 0.9820, policy_loss: 0.9229, value_loss: 0.4572
2024-07-14 07:16:41,316 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:16:41,801 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:16:41,875 [INFO    ] __main__: train step 19615: loss: 0.9820, policy_loss: 0.9229, value_loss: 0.4572
2024-07-14 07:16:42,170 [INFO    ] __main__: train step 19616: loss: 0.9820, policy_loss: 0.9229, value_loss: 0.4572
2024-07-14 07:16:42,465 [INFO    ] __main__: train step 19617: loss: 0.9820, policy_loss: 0.9229, value_loss: 0.4572
2024-07-14 07:16:42,768 [INFO    ] __main__: train step 19618: loss: 0.9820, policy_loss: 0.9229, value_loss: 0.4572
2024-07-14 07:16:43,083 [INFO    ] __main__: train step 19619: loss: 0.9820, policy_loss: 0.9229, value_loss: 0.4571
2024-07-14 07:16:43,388 [INFO    ] __main__: train step 19620: loss: 0.9820, policy_loss: 0.9228, value_loss: 0.4571
2024-07-14 07:16:43,694 [INFO    ] __main__: train step 19621: loss: 0.9819, policy_loss: 0.9228, value_loss: 0.4571
2024-07-14 07:16:43,979 [INFO    ] __main__: train step 19622: loss: 0.9819, policy_loss: 0.9228, value_loss: 0.4571
2024-07-14 07:16:44,277 [INFO    ] __main__: train step 19623: loss: 0.9819, policy_loss: 0.9228, value_loss: 0.4571
2024-07-14 07:16:44,586 [INFO    ] __main__: train step 19624: loss: 0.9819, policy_loss: 0.9228, value_loss: 0.4571
2024-07-14 07:16:44,888 [INFO    ] __main__: train step 19625: loss: 0.9819, policy_loss: 0.9228, value_loss: 0.4570
2024-07-14 07:16:45,192 [INFO    ] __main__: train step 19626: loss: 0.9819, policy_loss: 0.9227, value_loss: 0.4570
2024-07-14 07:16:45,473 [INFO    ] __main__: train step 19627: loss: 0.9819, policy_loss: 0.9227, value_loss: 0.4570
2024-07-14 07:16:45,767 [INFO    ] __main__: train step 19628: loss: 0.9818, policy_loss: 0.9227, value_loss: 0.4570
2024-07-14 07:16:46,086 [INFO    ] __main__: train step 19629: loss: 0.9818, policy_loss: 0.9227, value_loss: 0.4570
2024-07-14 07:16:46,376 [INFO    ] __main__: train step 19630: loss: 0.9818, policy_loss: 0.9227, value_loss: 0.4570
2024-07-14 07:16:46,653 [INFO    ] __main__: train step 19631: loss: 0.9818, policy_loss: 0.9226, value_loss: 0.4569
2024-07-14 07:16:48,256 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:16:48,735 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:16:48,802 [INFO    ] __main__: train step 19632: loss: 0.9818, policy_loss: 0.9226, value_loss: 0.4569
2024-07-14 07:16:49,102 [INFO    ] __main__: train step 19633: loss: 0.9818, policy_loss: 0.9226, value_loss: 0.4569
2024-07-14 07:16:49,390 [INFO    ] __main__: train step 19634: loss: 0.9818, policy_loss: 0.9226, value_loss: 0.4569
2024-07-14 07:16:49,684 [INFO    ] __main__: train step 19635: loss: 0.9818, policy_loss: 0.9226, value_loss: 0.4569
2024-07-14 07:16:49,958 [INFO    ] __main__: train step 19636: loss: 0.9817, policy_loss: 0.9226, value_loss: 0.4569
2024-07-14 07:16:50,238 [INFO    ] __main__: train step 19637: loss: 0.9817, policy_loss: 0.9225, value_loss: 0.4568
2024-07-14 07:16:50,527 [INFO    ] __main__: train step 19638: loss: 0.9817, policy_loss: 0.9225, value_loss: 0.4568
2024-07-14 07:16:50,835 [INFO    ] __main__: train step 19639: loss: 0.9817, policy_loss: 0.9225, value_loss: 0.4568
2024-07-14 07:16:51,130 [INFO    ] __main__: train step 19640: loss: 0.9817, policy_loss: 0.9225, value_loss: 0.4568
2024-07-14 07:16:51,433 [INFO    ] __main__: train step 19641: loss: 0.9817, policy_loss: 0.9225, value_loss: 0.4568
2024-07-14 07:16:51,718 [INFO    ] __main__: train step 19642: loss: 0.9817, policy_loss: 0.9225, value_loss: 0.4568
2024-07-14 07:16:51,995 [INFO    ] __main__: train step 19643: loss: 0.9816, policy_loss: 0.9224, value_loss: 0.4567
2024-07-14 07:16:52,288 [INFO    ] __main__: train step 19644: loss: 0.9816, policy_loss: 0.9224, value_loss: 0.4567
2024-07-14 07:16:52,596 [INFO    ] __main__: train step 19645: loss: 0.9816, policy_loss: 0.9224, value_loss: 0.4567
2024-07-14 07:16:52,902 [INFO    ] __main__: train step 19646: loss: 0.9816, policy_loss: 0.9224, value_loss: 0.4567
2024-07-14 07:16:53,202 [INFO    ] __main__: train step 19647: loss: 0.9816, policy_loss: 0.9224, value_loss: 0.4567
2024-07-14 07:16:53,488 [INFO    ] __main__: train step 19648: loss: 0.9816, policy_loss: 0.9223, value_loss: 0.4567
2024-07-14 07:16:55,102 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:16:55,566 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:16:55,636 [INFO    ] __main__: train step 19649: loss: 0.9815, policy_loss: 0.9223, value_loss: 0.4566
2024-07-14 07:16:55,942 [INFO    ] __main__: train step 19650: loss: 0.9815, policy_loss: 0.9223, value_loss: 0.4566
2024-07-14 07:16:56,232 [INFO    ] __main__: train step 19651: loss: 0.9815, policy_loss: 0.9223, value_loss: 0.4566
2024-07-14 07:16:56,517 [INFO    ] __main__: train step 19652: loss: 0.9815, policy_loss: 0.9223, value_loss: 0.4566
2024-07-14 07:16:56,828 [INFO    ] __main__: train step 19653: loss: 0.9815, policy_loss: 0.9223, value_loss: 0.4566
2024-07-14 07:16:57,131 [INFO    ] __main__: train step 19654: loss: 0.9815, policy_loss: 0.9222, value_loss: 0.4566
2024-07-14 07:16:57,434 [INFO    ] __main__: train step 19655: loss: 0.9815, policy_loss: 0.9222, value_loss: 0.4565
2024-07-14 07:16:57,741 [INFO    ] __main__: train step 19656: loss: 0.9815, policy_loss: 0.9222, value_loss: 0.4565
2024-07-14 07:16:58,026 [INFO    ] __main__: train step 19657: loss: 0.9814, policy_loss: 0.9222, value_loss: 0.4565
2024-07-14 07:16:58,336 [INFO    ] __main__: train step 19658: loss: 0.9814, policy_loss: 0.9222, value_loss: 0.4565
2024-07-14 07:16:58,634 [INFO    ] __main__: train step 19659: loss: 0.9814, policy_loss: 0.9222, value_loss: 0.4565
2024-07-14 07:16:58,930 [INFO    ] __main__: train step 19660: loss: 0.9814, policy_loss: 0.9221, value_loss: 0.4565
2024-07-14 07:16:59,233 [INFO    ] __main__: train step 19661: loss: 0.9814, policy_loss: 0.9221, value_loss: 0.4564
2024-07-14 07:16:59,525 [INFO    ] __main__: train step 19662: loss: 0.9814, policy_loss: 0.9221, value_loss: 0.4564
2024-07-14 07:16:59,809 [INFO    ] __main__: train step 19663: loss: 0.9813, policy_loss: 0.9221, value_loss: 0.4564
2024-07-14 07:17:00,113 [INFO    ] __main__: train step 19664: loss: 0.9813, policy_loss: 0.9221, value_loss: 0.4564
2024-07-14 07:17:00,425 [INFO    ] __main__: train step 19665: loss: 0.9813, policy_loss: 0.9220, value_loss: 0.4564
2024-07-14 07:17:02,073 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:17:02,560 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:17:02,628 [INFO    ] __main__: train step 19666: loss: 0.9813, policy_loss: 0.9220, value_loss: 0.4564
2024-07-14 07:17:02,909 [INFO    ] __main__: train step 19667: loss: 0.9813, policy_loss: 0.9220, value_loss: 0.4563
2024-07-14 07:17:03,183 [INFO    ] __main__: train step 19668: loss: 0.9813, policy_loss: 0.9220, value_loss: 0.4563
2024-07-14 07:17:03,443 [INFO    ] __main__: train step 19669: loss: 0.9813, policy_loss: 0.9220, value_loss: 0.4563
2024-07-14 07:17:03,738 [INFO    ] __main__: train step 19670: loss: 0.9812, policy_loss: 0.9220, value_loss: 0.4563
2024-07-14 07:17:04,042 [INFO    ] __main__: train step 19671: loss: 0.9812, policy_loss: 0.9219, value_loss: 0.4563
2024-07-14 07:17:07,534 [INFO    ] __main__: train step 19672: loss: 0.9812, policy_loss: 0.9219, value_loss: 0.4563
2024-07-14 07:17:07,800 [INFO    ] __main__: train step 19673: loss: 0.9812, policy_loss: 0.9219, value_loss: 0.4562
2024-07-14 07:17:08,072 [INFO    ] __main__: train step 19674: loss: 0.9812, policy_loss: 0.9219, value_loss: 0.4562
2024-07-14 07:17:08,347 [INFO    ] __main__: train step 19675: loss: 0.9812, policy_loss: 0.9219, value_loss: 0.4562
2024-07-14 07:17:08,631 [INFO    ] __main__: train step 19676: loss: 0.9812, policy_loss: 0.9219, value_loss: 0.4562
2024-07-14 07:17:08,906 [INFO    ] __main__: train step 19677: loss: 0.9811, policy_loss: 0.9218, value_loss: 0.4562
2024-07-14 07:17:09,209 [INFO    ] __main__: train step 19678: loss: 0.9811, policy_loss: 0.9218, value_loss: 0.4562
2024-07-14 07:17:09,527 [INFO    ] __main__: train step 19679: loss: 0.9811, policy_loss: 0.9218, value_loss: 0.4561
2024-07-14 07:17:09,830 [INFO    ] __main__: train step 19680: loss: 0.9811, policy_loss: 0.9218, value_loss: 0.4561
2024-07-14 07:17:10,130 [INFO    ] __main__: train step 19681: loss: 0.9811, policy_loss: 0.9218, value_loss: 0.4561
2024-07-14 07:17:10,428 [INFO    ] __main__: train step 19682: loss: 0.9811, policy_loss: 0.9217, value_loss: 0.4561
2024-07-14 07:17:12,022 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:17:12,493 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:17:12,564 [INFO    ] __main__: train step 19683: loss: 0.9811, policy_loss: 0.9217, value_loss: 0.4561
2024-07-14 07:17:12,859 [INFO    ] __main__: train step 19684: loss: 0.9811, policy_loss: 0.9217, value_loss: 0.4561
2024-07-14 07:17:13,155 [INFO    ] __main__: train step 19685: loss: 0.9810, policy_loss: 0.9217, value_loss: 0.4560
2024-07-14 07:17:13,461 [INFO    ] __main__: train step 19686: loss: 0.9810, policy_loss: 0.9217, value_loss: 0.4560
2024-07-14 07:17:13,740 [INFO    ] __main__: train step 19687: loss: 0.9810, policy_loss: 0.9217, value_loss: 0.4560
2024-07-14 07:17:14,033 [INFO    ] __main__: train step 19688: loss: 0.9810, policy_loss: 0.9216, value_loss: 0.4560
2024-07-14 07:17:14,333 [INFO    ] __main__: train step 19689: loss: 0.9810, policy_loss: 0.9216, value_loss: 0.4560
2024-07-14 07:17:14,619 [INFO    ] __main__: train step 19690: loss: 0.9810, policy_loss: 0.9216, value_loss: 0.4560
2024-07-14 07:17:14,923 [INFO    ] __main__: train step 19691: loss: 0.9810, policy_loss: 0.9216, value_loss: 0.4559
2024-07-14 07:17:15,217 [INFO    ] __main__: train step 19692: loss: 0.9809, policy_loss: 0.9216, value_loss: 0.4559
2024-07-14 07:17:15,495 [INFO    ] __main__: train step 19693: loss: 0.9809, policy_loss: 0.9216, value_loss: 0.4559
2024-07-14 07:17:15,787 [INFO    ] __main__: train step 19694: loss: 0.9809, policy_loss: 0.9215, value_loss: 0.4559
2024-07-14 07:17:16,090 [INFO    ] __main__: train step 19695: loss: 0.9809, policy_loss: 0.9215, value_loss: 0.4559
2024-07-14 07:17:16,385 [INFO    ] __main__: train step 19696: loss: 0.9809, policy_loss: 0.9215, value_loss: 0.4559
2024-07-14 07:17:16,678 [INFO    ] __main__: train step 19697: loss: 0.9809, policy_loss: 0.9215, value_loss: 0.4558
2024-07-14 07:17:16,948 [INFO    ] __main__: train step 19698: loss: 0.9808, policy_loss: 0.9215, value_loss: 0.4558
2024-07-14 07:17:17,210 [INFO    ] __main__: train step 19699: loss: 0.9808, policy_loss: 0.9214, value_loss: 0.4558
2024-07-14 07:17:18,773 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:17:19,249 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:17:19,320 [INFO    ] __main__: train step 19700: loss: 0.9808, policy_loss: 0.9214, value_loss: 0.4558
2024-07-14 07:17:19,621 [INFO    ] __main__: train step 19701: loss: 0.9808, policy_loss: 0.9214, value_loss: 0.4558
2024-07-14 07:17:19,932 [INFO    ] __main__: train step 19702: loss: 0.9808, policy_loss: 0.9214, value_loss: 0.4558
2024-07-14 07:17:20,220 [INFO    ] __main__: train step 19703: loss: 0.9808, policy_loss: 0.9214, value_loss: 0.4557
2024-07-14 07:17:20,510 [INFO    ] __main__: train step 19704: loss: 0.9808, policy_loss: 0.9214, value_loss: 0.4557
2024-07-14 07:17:20,812 [INFO    ] __main__: train step 19705: loss: 0.9808, policy_loss: 0.9213, value_loss: 0.4557
2024-07-14 07:17:21,114 [INFO    ] __main__: train step 19706: loss: 0.9807, policy_loss: 0.9213, value_loss: 0.4557
2024-07-14 07:17:21,419 [INFO    ] __main__: train step 19707: loss: 0.9807, policy_loss: 0.9213, value_loss: 0.4557
2024-07-14 07:17:21,722 [INFO    ] __main__: train step 19708: loss: 0.9807, policy_loss: 0.9213, value_loss: 0.4557
2024-07-14 07:17:22,002 [INFO    ] __main__: train step 19709: loss: 0.9807, policy_loss: 0.9213, value_loss: 0.4556
2024-07-14 07:17:22,295 [INFO    ] __main__: train step 19710: loss: 0.9807, policy_loss: 0.9212, value_loss: 0.4556
2024-07-14 07:17:22,585 [INFO    ] __main__: train step 19711: loss: 0.9807, policy_loss: 0.9212, value_loss: 0.4556
2024-07-14 07:17:22,882 [INFO    ] __main__: train step 19712: loss: 0.9806, policy_loss: 0.9212, value_loss: 0.4556
2024-07-14 07:17:23,165 [INFO    ] __main__: train step 19713: loss: 0.9806, policy_loss: 0.9212, value_loss: 0.4556
2024-07-14 07:17:23,426 [INFO    ] __main__: train step 19714: loss: 0.9806, policy_loss: 0.9212, value_loss: 0.4556
2024-07-14 07:17:23,700 [INFO    ] __main__: train step 19715: loss: 0.9806, policy_loss: 0.9212, value_loss: 0.4555
2024-07-14 07:17:23,998 [INFO    ] __main__: train step 19716: loss: 0.9806, policy_loss: 0.9211, value_loss: 0.4555
2024-07-14 07:17:25,634 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:17:26,121 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:17:26,190 [INFO    ] __main__: train step 19717: loss: 0.9806, policy_loss: 0.9211, value_loss: 0.4555
2024-07-14 07:17:26,465 [INFO    ] __main__: train step 19718: loss: 0.9806, policy_loss: 0.9211, value_loss: 0.4555
2024-07-14 07:17:26,734 [INFO    ] __main__: train step 19719: loss: 0.9806, policy_loss: 0.9211, value_loss: 0.4555
2024-07-14 07:17:27,028 [INFO    ] __main__: train step 19720: loss: 0.9805, policy_loss: 0.9211, value_loss: 0.4555
2024-07-14 07:17:27,323 [INFO    ] __main__: train step 19721: loss: 0.9805, policy_loss: 0.9211, value_loss: 0.4554
2024-07-14 07:17:27,615 [INFO    ] __main__: train step 19722: loss: 0.9805, policy_loss: 0.9210, value_loss: 0.4554
2024-07-14 07:17:27,915 [INFO    ] __main__: train step 19723: loss: 0.9805, policy_loss: 0.9210, value_loss: 0.4554
2024-07-14 07:17:28,191 [INFO    ] __main__: train step 19724: loss: 0.9805, policy_loss: 0.9210, value_loss: 0.4554
2024-07-14 07:17:28,478 [INFO    ] __main__: train step 19725: loss: 0.9805, policy_loss: 0.9210, value_loss: 0.4554
2024-07-14 07:17:28,785 [INFO    ] __main__: train step 19726: loss: 0.9805, policy_loss: 0.9210, value_loss: 0.4554
2024-07-14 07:17:29,088 [INFO    ] __main__: train step 19727: loss: 0.9804, policy_loss: 0.9209, value_loss: 0.4553
2024-07-14 07:17:29,382 [INFO    ] __main__: train step 19728: loss: 0.9804, policy_loss: 0.9209, value_loss: 0.4553
2024-07-14 07:17:29,694 [INFO    ] __main__: train step 19729: loss: 0.9804, policy_loss: 0.9209, value_loss: 0.4553
2024-07-14 07:17:29,982 [INFO    ] __main__: train step 19730: loss: 0.9804, policy_loss: 0.9209, value_loss: 0.4553
2024-07-14 07:17:30,287 [INFO    ] __main__: train step 19731: loss: 0.9804, policy_loss: 0.9209, value_loss: 0.4553
2024-07-14 07:17:30,586 [INFO    ] __main__: train step 19732: loss: 0.9804, policy_loss: 0.9209, value_loss: 0.4553
2024-07-14 07:17:30,896 [INFO    ] __main__: train step 19733: loss: 0.9804, policy_loss: 0.9208, value_loss: 0.4552
2024-07-14 07:17:32,510 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:17:33,009 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:17:33,077 [INFO    ] __main__: train step 19734: loss: 0.9803, policy_loss: 0.9208, value_loss: 0.4552
2024-07-14 07:17:33,368 [INFO    ] __main__: train step 19735: loss: 0.9803, policy_loss: 0.9208, value_loss: 0.4552
2024-07-14 07:17:33,653 [INFO    ] __main__: train step 19736: loss: 0.9803, policy_loss: 0.9208, value_loss: 0.4552
2024-07-14 07:17:33,964 [INFO    ] __main__: train step 19737: loss: 0.9803, policy_loss: 0.9208, value_loss: 0.4552
2024-07-14 07:17:34,280 [INFO    ] __main__: train step 19738: loss: 0.9803, policy_loss: 0.9207, value_loss: 0.4552
2024-07-14 07:17:34,577 [INFO    ] __main__: train step 19739: loss: 0.9803, policy_loss: 0.9207, value_loss: 0.4551
2024-07-14 07:17:34,840 [INFO    ] __main__: train step 19740: loss: 0.9802, policy_loss: 0.9207, value_loss: 0.4551
2024-07-14 07:17:35,138 [INFO    ] __main__: train step 19741: loss: 0.9802, policy_loss: 0.9207, value_loss: 0.4551
2024-07-14 07:17:35,433 [INFO    ] __main__: train step 19742: loss: 0.9802, policy_loss: 0.9207, value_loss: 0.4551
2024-07-14 07:17:35,740 [INFO    ] __main__: train step 19743: loss: 0.9802, policy_loss: 0.9207, value_loss: 0.4551
2024-07-14 07:17:36,040 [INFO    ] __main__: train step 19744: loss: 0.9802, policy_loss: 0.9206, value_loss: 0.4551
2024-07-14 07:17:36,316 [INFO    ] __main__: train step 19745: loss: 0.9802, policy_loss: 0.9206, value_loss: 0.4550
2024-07-14 07:17:36,616 [INFO    ] __main__: train step 19746: loss: 0.9802, policy_loss: 0.9206, value_loss: 0.4550
2024-07-14 07:17:36,923 [INFO    ] __main__: train step 19747: loss: 0.9801, policy_loss: 0.9206, value_loss: 0.4550
2024-07-14 07:17:37,214 [INFO    ] __main__: train step 19748: loss: 0.9801, policy_loss: 0.9206, value_loss: 0.4550
2024-07-14 07:17:37,517 [INFO    ] __main__: train step 19749: loss: 0.9801, policy_loss: 0.9205, value_loss: 0.4550
2024-07-14 07:17:37,795 [INFO    ] __main__: train step 19750: loss: 0.9801, policy_loss: 0.9205, value_loss: 0.4550
2024-07-14 07:17:39,393 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:17:39,866 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:17:39,935 [INFO    ] __main__: train step 19751: loss: 0.9801, policy_loss: 0.9205, value_loss: 0.4549
2024-07-14 07:17:40,236 [INFO    ] __main__: train step 19752: loss: 0.9801, policy_loss: 0.9205, value_loss: 0.4549
2024-07-14 07:17:40,528 [INFO    ] __main__: train step 19753: loss: 0.9801, policy_loss: 0.9205, value_loss: 0.4549
2024-07-14 07:17:40,800 [INFO    ] __main__: train step 19754: loss: 0.9800, policy_loss: 0.9205, value_loss: 0.4549
2024-07-14 07:17:41,073 [INFO    ] __main__: train step 19755: loss: 0.9800, policy_loss: 0.9204, value_loss: 0.4549
2024-07-14 07:17:41,369 [INFO    ] __main__: train step 19756: loss: 0.9800, policy_loss: 0.9204, value_loss: 0.4549
2024-07-14 07:17:41,659 [INFO    ] __main__: train step 19757: loss: 0.9800, policy_loss: 0.9204, value_loss: 0.4548
2024-07-14 07:17:41,958 [INFO    ] __main__: train step 19758: loss: 0.9800, policy_loss: 0.9204, value_loss: 0.4548
2024-07-14 07:17:42,257 [INFO    ] __main__: train step 19759: loss: 0.9800, policy_loss: 0.9204, value_loss: 0.4548
2024-07-14 07:17:42,541 [INFO    ] __main__: train step 19760: loss: 0.9800, policy_loss: 0.9203, value_loss: 0.4548
2024-07-14 07:17:42,825 [INFO    ] __main__: train step 19761: loss: 0.9799, policy_loss: 0.9203, value_loss: 0.4548
2024-07-14 07:17:43,118 [INFO    ] __main__: train step 19762: loss: 0.9799, policy_loss: 0.9203, value_loss: 0.4548
2024-07-14 07:17:43,409 [INFO    ] __main__: train step 19763: loss: 0.9799, policy_loss: 0.9203, value_loss: 0.4548
2024-07-14 07:17:43,708 [INFO    ] __main__: train step 19764: loss: 0.9799, policy_loss: 0.9203, value_loss: 0.4547
2024-07-14 07:17:43,986 [INFO    ] __main__: train step 19765: loss: 0.9799, policy_loss: 0.9203, value_loss: 0.4547
2024-07-14 07:17:44,262 [INFO    ] __main__: train step 19766: loss: 0.9799, policy_loss: 0.9202, value_loss: 0.4547
2024-07-14 07:17:44,566 [INFO    ] __main__: train step 19767: loss: 0.9799, policy_loss: 0.9202, value_loss: 0.4547
2024-07-14 07:17:46,194 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:17:46,681 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:17:46,751 [INFO    ] __main__: train step 19768: loss: 0.9798, policy_loss: 0.9202, value_loss: 0.4547
2024-07-14 07:17:47,044 [INFO    ] __main__: train step 19769: loss: 0.9798, policy_loss: 0.9202, value_loss: 0.4547
2024-07-14 07:17:47,300 [INFO    ] __main__: train step 19770: loss: 0.9798, policy_loss: 0.9202, value_loss: 0.4546
2024-07-14 07:17:47,574 [INFO    ] __main__: train step 19771: loss: 0.9798, policy_loss: 0.9202, value_loss: 0.4546
2024-07-14 07:17:47,866 [INFO    ] __main__: train step 19772: loss: 0.9798, policy_loss: 0.9201, value_loss: 0.4546
2024-07-14 07:17:48,166 [INFO    ] __main__: train step 19773: loss: 0.9798, policy_loss: 0.9201, value_loss: 0.4546
2024-07-14 07:17:48,455 [INFO    ] __main__: train step 19774: loss: 0.9798, policy_loss: 0.9201, value_loss: 0.4546
2024-07-14 07:17:48,740 [INFO    ] __main__: train step 19775: loss: 0.9797, policy_loss: 0.9201, value_loss: 0.4546
2024-07-14 07:17:52,135 [INFO    ] __main__: train step 19776: loss: 0.9797, policy_loss: 0.9201, value_loss: 0.4545
2024-07-14 07:17:52,414 [INFO    ] __main__: train step 19777: loss: 0.9797, policy_loss: 0.9200, value_loss: 0.4545
2024-07-14 07:17:52,697 [INFO    ] __main__: train step 19778: loss: 0.9797, policy_loss: 0.9200, value_loss: 0.4545
2024-07-14 07:17:53,000 [INFO    ] __main__: train step 19779: loss: 0.9797, policy_loss: 0.9200, value_loss: 0.4545
2024-07-14 07:17:53,289 [INFO    ] __main__: train step 19780: loss: 0.9797, policy_loss: 0.9200, value_loss: 0.4545
2024-07-14 07:17:53,579 [INFO    ] __main__: train step 19781: loss: 0.9797, policy_loss: 0.9200, value_loss: 0.4545
2024-07-14 07:17:53,881 [INFO    ] __main__: train step 19782: loss: 0.9796, policy_loss: 0.9200, value_loss: 0.4544
2024-07-14 07:17:54,163 [INFO    ] __main__: train step 19783: loss: 0.9796, policy_loss: 0.9199, value_loss: 0.4544
2024-07-14 07:17:54,460 [INFO    ] __main__: train step 19784: loss: 0.9796, policy_loss: 0.9199, value_loss: 0.4544
2024-07-14 07:17:56,076 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:17:56,561 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:17:56,629 [INFO    ] __main__: train step 19785: loss: 0.9796, policy_loss: 0.9199, value_loss: 0.4544
2024-07-14 07:17:56,920 [INFO    ] __main__: train step 19786: loss: 0.9796, policy_loss: 0.9199, value_loss: 0.4544
2024-07-14 07:17:57,206 [INFO    ] __main__: train step 19787: loss: 0.9796, policy_loss: 0.9199, value_loss: 0.4544
2024-07-14 07:17:57,502 [INFO    ] __main__: train step 19788: loss: 0.9796, policy_loss: 0.9199, value_loss: 0.4543
2024-07-14 07:17:57,798 [INFO    ] __main__: train step 19789: loss: 0.9795, policy_loss: 0.9198, value_loss: 0.4543
2024-07-14 07:17:58,085 [INFO    ] __main__: train step 19790: loss: 0.9795, policy_loss: 0.9198, value_loss: 0.4543
2024-07-14 07:17:58,378 [INFO    ] __main__: train step 19791: loss: 0.9795, policy_loss: 0.9198, value_loss: 0.4543
2024-07-14 07:17:58,681 [INFO    ] __main__: train step 19792: loss: 0.9795, policy_loss: 0.9198, value_loss: 0.4543
2024-07-14 07:17:58,979 [INFO    ] __main__: train step 19793: loss: 0.9795, policy_loss: 0.9198, value_loss: 0.4543
2024-07-14 07:17:59,274 [INFO    ] __main__: train step 19794: loss: 0.9795, policy_loss: 0.9197, value_loss: 0.4542
2024-07-14 07:17:59,557 [INFO    ] __main__: train step 19795: loss: 0.9795, policy_loss: 0.9197, value_loss: 0.4542
2024-07-14 07:17:59,841 [INFO    ] __main__: train step 19796: loss: 0.9794, policy_loss: 0.9197, value_loss: 0.4542
2024-07-14 07:18:00,164 [INFO    ] __main__: train step 19797: loss: 0.9794, policy_loss: 0.9197, value_loss: 0.4542
2024-07-14 07:18:00,466 [INFO    ] __main__: train step 19798: loss: 0.9794, policy_loss: 0.9197, value_loss: 0.4542
2024-07-14 07:18:00,763 [INFO    ] __main__: train step 19799: loss: 0.9794, policy_loss: 0.9197, value_loss: 0.4542
2024-07-14 07:18:01,058 [INFO    ] __main__: train step 19800: loss: 0.9794, policy_loss: 0.9196, value_loss: 0.4541
2024-07-14 07:18:01,328 [INFO    ] __main__: train step 19801: loss: 0.9794, policy_loss: 0.9196, value_loss: 0.4541
2024-07-14 07:18:02,952 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:18:03,374 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:18:03,441 [INFO    ] __main__: train step 19802: loss: 0.9794, policy_loss: 0.9196, value_loss: 0.4541
2024-07-14 07:18:03,736 [INFO    ] __main__: train step 19803: loss: 0.9793, policy_loss: 0.9196, value_loss: 0.4541
2024-07-14 07:18:04,028 [INFO    ] __main__: train step 19804: loss: 0.9793, policy_loss: 0.9196, value_loss: 0.4541
2024-07-14 07:18:04,305 [INFO    ] __main__: train step 19805: loss: 0.9793, policy_loss: 0.9195, value_loss: 0.4541
2024-07-14 07:18:04,594 [INFO    ] __main__: train step 19806: loss: 0.9793, policy_loss: 0.9195, value_loss: 0.4540
2024-07-14 07:18:04,883 [INFO    ] __main__: train step 19807: loss: 0.9793, policy_loss: 0.9195, value_loss: 0.4540
2024-07-14 07:18:05,179 [INFO    ] __main__: train step 19808: loss: 0.9793, policy_loss: 0.9195, value_loss: 0.4540
2024-07-14 07:18:05,476 [INFO    ] __main__: train step 19809: loss: 0.9792, policy_loss: 0.9195, value_loss: 0.4540
2024-07-14 07:18:05,772 [INFO    ] __main__: train step 19810: loss: 0.9792, policy_loss: 0.9195, value_loss: 0.4540
2024-07-14 07:18:06,055 [INFO    ] __main__: train step 19811: loss: 0.9792, policy_loss: 0.9194, value_loss: 0.4540
2024-07-14 07:18:06,358 [INFO    ] __main__: train step 19812: loss: 0.9792, policy_loss: 0.9194, value_loss: 0.4539
2024-07-14 07:18:06,651 [INFO    ] __main__: train step 19813: loss: 0.9792, policy_loss: 0.9194, value_loss: 0.4539
2024-07-14 07:18:06,954 [INFO    ] __main__: train step 19814: loss: 0.9792, policy_loss: 0.9194, value_loss: 0.4539
2024-07-14 07:18:07,256 [INFO    ] __main__: train step 19815: loss: 0.9792, policy_loss: 0.9194, value_loss: 0.4539
2024-07-14 07:18:07,565 [INFO    ] __main__: train step 19816: loss: 0.9791, policy_loss: 0.9193, value_loss: 0.4539
2024-07-14 07:18:07,856 [INFO    ] __main__: train step 19817: loss: 0.9791, policy_loss: 0.9193, value_loss: 0.4539
2024-07-14 07:18:08,165 [INFO    ] __main__: train step 19818: loss: 0.9791, policy_loss: 0.9193, value_loss: 0.4538
2024-07-14 07:18:09,791 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:18:10,281 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:18:10,347 [INFO    ] __main__: train step 19819: loss: 0.9791, policy_loss: 0.9193, value_loss: 0.4538
2024-07-14 07:18:10,630 [INFO    ] __main__: train step 19820: loss: 0.9791, policy_loss: 0.9193, value_loss: 0.4538
2024-07-14 07:18:10,915 [INFO    ] __main__: train step 19821: loss: 0.9791, policy_loss: 0.9193, value_loss: 0.4538
2024-07-14 07:18:11,202 [INFO    ] __main__: train step 19822: loss: 0.9791, policy_loss: 0.9192, value_loss: 0.4538
2024-07-14 07:18:11,498 [INFO    ] __main__: train step 19823: loss: 0.9790, policy_loss: 0.9192, value_loss: 0.4538
2024-07-14 07:18:11,793 [INFO    ] __main__: train step 19824: loss: 0.9790, policy_loss: 0.9192, value_loss: 0.4537
2024-07-14 07:18:12,067 [INFO    ] __main__: train step 19825: loss: 0.9790, policy_loss: 0.9192, value_loss: 0.4537
2024-07-14 07:18:12,376 [INFO    ] __main__: train step 19826: loss: 0.9790, policy_loss: 0.9192, value_loss: 0.4537
2024-07-14 07:18:12,673 [INFO    ] __main__: train step 19827: loss: 0.9790, policy_loss: 0.9191, value_loss: 0.4537
2024-07-14 07:18:12,995 [INFO    ] __main__: train step 19828: loss: 0.9790, policy_loss: 0.9191, value_loss: 0.4537
2024-07-14 07:18:13,301 [INFO    ] __main__: train step 19829: loss: 0.9790, policy_loss: 0.9191, value_loss: 0.4537
2024-07-14 07:18:13,588 [INFO    ] __main__: train step 19830: loss: 0.9789, policy_loss: 0.9191, value_loss: 0.4537
2024-07-14 07:18:13,884 [INFO    ] __main__: train step 19831: loss: 0.9789, policy_loss: 0.9191, value_loss: 0.4536
2024-07-14 07:18:14,184 [INFO    ] __main__: train step 19832: loss: 0.9789, policy_loss: 0.9191, value_loss: 0.4536
2024-07-14 07:18:14,485 [INFO    ] __main__: train step 19833: loss: 0.9789, policy_loss: 0.9190, value_loss: 0.4536
2024-07-14 07:18:14,788 [INFO    ] __main__: train step 19834: loss: 0.9789, policy_loss: 0.9190, value_loss: 0.4536
2024-07-14 07:18:15,091 [INFO    ] __main__: train step 19835: loss: 0.9789, policy_loss: 0.9190, value_loss: 0.4536
2024-07-14 07:18:16,704 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:18:17,196 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:18:17,265 [INFO    ] __main__: train step 19836: loss: 0.9789, policy_loss: 0.9190, value_loss: 0.4536
2024-07-14 07:18:17,566 [INFO    ] __main__: train step 19837: loss: 0.9788, policy_loss: 0.9190, value_loss: 0.4535
2024-07-14 07:18:17,858 [INFO    ] __main__: train step 19838: loss: 0.9788, policy_loss: 0.9189, value_loss: 0.4535
2024-07-14 07:18:18,161 [INFO    ] __main__: train step 19839: loss: 0.9788, policy_loss: 0.9189, value_loss: 0.4535
2024-07-14 07:18:18,456 [INFO    ] __main__: train step 19840: loss: 0.9788, policy_loss: 0.9189, value_loss: 0.4535
2024-07-14 07:18:18,750 [INFO    ] __main__: train step 19841: loss: 0.9788, policy_loss: 0.9189, value_loss: 0.4535
2024-07-14 07:18:19,058 [INFO    ] __main__: train step 19842: loss: 0.9788, policy_loss: 0.9189, value_loss: 0.4535
2024-07-14 07:18:19,359 [INFO    ] __main__: train step 19843: loss: 0.9788, policy_loss: 0.9189, value_loss: 0.4534
2024-07-14 07:18:19,658 [INFO    ] __main__: train step 19844: loss: 0.9787, policy_loss: 0.9188, value_loss: 0.4534
2024-07-14 07:18:19,926 [INFO    ] __main__: train step 19845: loss: 0.9787, policy_loss: 0.9188, value_loss: 0.4534
2024-07-14 07:18:20,207 [INFO    ] __main__: train step 19846: loss: 0.9787, policy_loss: 0.9188, value_loss: 0.4534
2024-07-14 07:18:20,497 [INFO    ] __main__: train step 19847: loss: 0.9787, policy_loss: 0.9188, value_loss: 0.4534
2024-07-14 07:18:20,804 [INFO    ] __main__: train step 19848: loss: 0.9787, policy_loss: 0.9188, value_loss: 0.4534
2024-07-14 07:18:21,102 [INFO    ] __main__: train step 19849: loss: 0.9787, policy_loss: 0.9187, value_loss: 0.4533
2024-07-14 07:18:21,413 [INFO    ] __main__: train step 19850: loss: 0.9787, policy_loss: 0.9187, value_loss: 0.4533
2024-07-14 07:18:21,699 [INFO    ] __main__: train step 19851: loss: 0.9786, policy_loss: 0.9187, value_loss: 0.4533
2024-07-14 07:18:21,971 [INFO    ] __main__: train step 19852: loss: 0.9786, policy_loss: 0.9187, value_loss: 0.4533
2024-07-14 07:18:23,597 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:18:24,081 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:18:24,150 [INFO    ] __main__: train step 19853: loss: 0.9786, policy_loss: 0.9187, value_loss: 0.4533
2024-07-14 07:18:24,449 [INFO    ] __main__: train step 19854: loss: 0.9786, policy_loss: 0.9187, value_loss: 0.4533
2024-07-14 07:18:24,732 [INFO    ] __main__: train step 19855: loss: 0.9786, policy_loss: 0.9186, value_loss: 0.4532
2024-07-14 07:18:25,006 [INFO    ] __main__: train step 19856: loss: 0.9786, policy_loss: 0.9186, value_loss: 0.4532
2024-07-14 07:18:25,299 [INFO    ] __main__: train step 19857: loss: 0.9786, policy_loss: 0.9186, value_loss: 0.4532
2024-07-14 07:18:25,602 [INFO    ] __main__: train step 19858: loss: 0.9785, policy_loss: 0.9186, value_loss: 0.4532
2024-07-14 07:18:25,902 [INFO    ] __main__: train step 19859: loss: 0.9785, policy_loss: 0.9186, value_loss: 0.4532
2024-07-14 07:18:26,202 [INFO    ] __main__: train step 19860: loss: 0.9785, policy_loss: 0.9186, value_loss: 0.4532
2024-07-14 07:18:26,470 [INFO    ] __main__: train step 19861: loss: 0.9785, policy_loss: 0.9185, value_loss: 0.4531
2024-07-14 07:18:26,758 [INFO    ] __main__: train step 19862: loss: 0.9785, policy_loss: 0.9185, value_loss: 0.4531
2024-07-14 07:18:27,054 [INFO    ] __main__: train step 19863: loss: 0.9785, policy_loss: 0.9185, value_loss: 0.4531
2024-07-14 07:18:27,357 [INFO    ] __main__: train step 19864: loss: 0.9785, policy_loss: 0.9185, value_loss: 0.4531
2024-07-14 07:18:27,653 [INFO    ] __main__: train step 19865: loss: 0.9784, policy_loss: 0.9185, value_loss: 0.4531
2024-07-14 07:18:27,925 [INFO    ] __main__: train step 19866: loss: 0.9784, policy_loss: 0.9184, value_loss: 0.4531
2024-07-14 07:18:28,209 [INFO    ] __main__: train step 19867: loss: 0.9784, policy_loss: 0.9184, value_loss: 0.4531
2024-07-14 07:18:28,510 [INFO    ] __main__: train step 19868: loss: 0.9784, policy_loss: 0.9184, value_loss: 0.4530
2024-07-14 07:18:28,812 [INFO    ] __main__: train step 19869: loss: 0.9784, policy_loss: 0.9184, value_loss: 0.4530
2024-07-14 07:18:30,415 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:18:30,902 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:18:30,970 [INFO    ] __main__: train step 19870: loss: 0.9784, policy_loss: 0.9184, value_loss: 0.4530
2024-07-14 07:18:31,265 [INFO    ] __main__: train step 19871: loss: 0.9783, policy_loss: 0.9183, value_loss: 0.4530
2024-07-14 07:18:31,546 [INFO    ] __main__: train step 19872: loss: 0.9783, policy_loss: 0.9183, value_loss: 0.4530
2024-07-14 07:18:31,845 [INFO    ] __main__: train step 19873: loss: 0.9783, policy_loss: 0.9183, value_loss: 0.4530
2024-07-14 07:18:32,134 [INFO    ] __main__: train step 19874: loss: 0.9783, policy_loss: 0.9183, value_loss: 0.4529
2024-07-14 07:18:32,424 [INFO    ] __main__: train step 19875: loss: 0.9783, policy_loss: 0.9183, value_loss: 0.4529
2024-07-14 07:18:32,709 [INFO    ] __main__: train step 19876: loss: 0.9783, policy_loss: 0.9183, value_loss: 0.4529
2024-07-14 07:18:32,999 [INFO    ] __main__: train step 19877: loss: 0.9783, policy_loss: 0.9182, value_loss: 0.4529
2024-07-14 07:18:33,288 [INFO    ] __main__: train step 19878: loss: 0.9782, policy_loss: 0.9182, value_loss: 0.4529
2024-07-14 07:18:33,591 [INFO    ] __main__: train step 19879: loss: 0.9782, policy_loss: 0.9182, value_loss: 0.4529
2024-07-14 07:18:37,029 [INFO    ] __main__: train step 19880: loss: 0.9782, policy_loss: 0.9182, value_loss: 0.4528
2024-07-14 07:18:37,328 [INFO    ] __main__: train step 19881: loss: 0.9782, policy_loss: 0.9182, value_loss: 0.4528
2024-07-14 07:18:37,616 [INFO    ] __main__: train step 19882: loss: 0.9782, policy_loss: 0.9181, value_loss: 0.4528
2024-07-14 07:18:37,886 [INFO    ] __main__: train step 19883: loss: 0.9782, policy_loss: 0.9181, value_loss: 0.4528
2024-07-14 07:18:38,169 [INFO    ] __main__: train step 19884: loss: 0.9782, policy_loss: 0.9181, value_loss: 0.4528
2024-07-14 07:18:38,465 [INFO    ] __main__: train step 19885: loss: 0.9781, policy_loss: 0.9181, value_loss: 0.4528
2024-07-14 07:18:38,771 [INFO    ] __main__: train step 19886: loss: 0.9781, policy_loss: 0.9181, value_loss: 0.4527
2024-07-14 07:18:40,364 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:18:40,850 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:18:40,916 [INFO    ] __main__: train step 19887: loss: 0.9781, policy_loss: 0.9181, value_loss: 0.4527
2024-07-14 07:18:41,191 [INFO    ] __main__: train step 19888: loss: 0.9781, policy_loss: 0.9180, value_loss: 0.4527
2024-07-14 07:18:41,488 [INFO    ] __main__: train step 19889: loss: 0.9781, policy_loss: 0.9180, value_loss: 0.4527
2024-07-14 07:18:41,776 [INFO    ] __main__: train step 19890: loss: 0.9781, policy_loss: 0.9180, value_loss: 0.4527
2024-07-14 07:18:42,066 [INFO    ] __main__: train step 19891: loss: 0.9781, policy_loss: 0.9180, value_loss: 0.4527
2024-07-14 07:18:42,317 [INFO    ] __main__: train step 19892: loss: 0.9780, policy_loss: 0.9180, value_loss: 0.4526
2024-07-14 07:18:42,588 [INFO    ] __main__: train step 19893: loss: 0.9780, policy_loss: 0.9180, value_loss: 0.4526
2024-07-14 07:18:42,886 [INFO    ] __main__: train step 19894: loss: 0.9780, policy_loss: 0.9179, value_loss: 0.4526
2024-07-14 07:18:43,171 [INFO    ] __main__: train step 19895: loss: 0.9780, policy_loss: 0.9179, value_loss: 0.4526
2024-07-14 07:18:43,463 [INFO    ] __main__: train step 19896: loss: 0.9780, policy_loss: 0.9179, value_loss: 0.4526
2024-07-14 07:18:43,768 [INFO    ] __main__: train step 19897: loss: 0.9780, policy_loss: 0.9179, value_loss: 0.4526
2024-07-14 07:18:44,060 [INFO    ] __main__: train step 19898: loss: 0.9780, policy_loss: 0.9179, value_loss: 0.4525
2024-07-14 07:18:44,358 [INFO    ] __main__: train step 19899: loss: 0.9779, policy_loss: 0.9178, value_loss: 0.4525
2024-07-14 07:18:44,672 [INFO    ] __main__: train step 19900: loss: 0.9779, policy_loss: 0.9178, value_loss: 0.4525
2024-07-14 07:18:44,984 [INFO    ] __main__: train step 19901: loss: 0.9779, policy_loss: 0.9178, value_loss: 0.4525
2024-07-14 07:18:45,264 [INFO    ] __main__: train step 19902: loss: 0.9779, policy_loss: 0.9178, value_loss: 0.4525
2024-07-14 07:18:45,558 [INFO    ] __main__: train step 19903: loss: 0.9779, policy_loss: 0.9178, value_loss: 0.4525
2024-07-14 07:18:47,209 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:18:47,700 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:18:47,769 [INFO    ] __main__: train step 19904: loss: 0.9779, policy_loss: 0.9178, value_loss: 0.4524
2024-07-14 07:18:48,071 [INFO    ] __main__: train step 19905: loss: 0.9779, policy_loss: 0.9177, value_loss: 0.4524
2024-07-14 07:18:48,375 [INFO    ] __main__: train step 19906: loss: 0.9778, policy_loss: 0.9177, value_loss: 0.4524
2024-07-14 07:18:48,643 [INFO    ] __main__: train step 19907: loss: 0.9778, policy_loss: 0.9177, value_loss: 0.4524
2024-07-14 07:18:48,918 [INFO    ] __main__: train step 19908: loss: 0.9778, policy_loss: 0.9177, value_loss: 0.4524
2024-07-14 07:18:49,201 [INFO    ] __main__: train step 19909: loss: 0.9778, policy_loss: 0.9177, value_loss: 0.4524
2024-07-14 07:18:49,468 [INFO    ] __main__: train step 19910: loss: 0.9778, policy_loss: 0.9176, value_loss: 0.4524
2024-07-14 07:18:49,760 [INFO    ] __main__: train step 19911: loss: 0.9778, policy_loss: 0.9176, value_loss: 0.4523
2024-07-14 07:18:50,041 [INFO    ] __main__: train step 19912: loss: 0.9778, policy_loss: 0.9176, value_loss: 0.4523
2024-07-14 07:18:50,351 [INFO    ] __main__: train step 19913: loss: 0.9777, policy_loss: 0.9176, value_loss: 0.4523
2024-07-14 07:18:50,654 [INFO    ] __main__: train step 19914: loss: 0.9777, policy_loss: 0.9176, value_loss: 0.4523
2024-07-14 07:18:50,949 [INFO    ] __main__: train step 19915: loss: 0.9777, policy_loss: 0.9176, value_loss: 0.4523
2024-07-14 07:18:51,247 [INFO    ] __main__: train step 19916: loss: 0.9777, policy_loss: 0.9175, value_loss: 0.4523
2024-07-14 07:18:51,552 [INFO    ] __main__: train step 19917: loss: 0.9777, policy_loss: 0.9175, value_loss: 0.4522
2024-07-14 07:18:51,854 [INFO    ] __main__: train step 19918: loss: 0.9777, policy_loss: 0.9175, value_loss: 0.4522
2024-07-14 07:18:52,151 [INFO    ] __main__: train step 19919: loss: 0.9776, policy_loss: 0.9175, value_loss: 0.4522
2024-07-14 07:18:52,473 [INFO    ] __main__: train step 19920: loss: 0.9776, policy_loss: 0.9175, value_loss: 0.4522
2024-07-14 07:18:54,119 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:18:54,613 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:18:54,681 [INFO    ] __main__: train step 19921: loss: 0.9776, policy_loss: 0.9174, value_loss: 0.4522
2024-07-14 07:18:54,957 [INFO    ] __main__: train step 19922: loss: 0.9776, policy_loss: 0.9174, value_loss: 0.4522
2024-07-14 07:18:55,251 [INFO    ] __main__: train step 19923: loss: 0.9776, policy_loss: 0.9174, value_loss: 0.4521
2024-07-14 07:18:55,549 [INFO    ] __main__: train step 19924: loss: 0.9776, policy_loss: 0.9174, value_loss: 0.4521
2024-07-14 07:18:55,854 [INFO    ] __main__: train step 19925: loss: 0.9776, policy_loss: 0.9174, value_loss: 0.4521
2024-07-14 07:18:56,165 [INFO    ] __main__: train step 19926: loss: 0.9775, policy_loss: 0.9174, value_loss: 0.4521
2024-07-14 07:18:56,461 [INFO    ] __main__: train step 19927: loss: 0.9775, policy_loss: 0.9173, value_loss: 0.4521
2024-07-14 07:18:56,726 [INFO    ] __main__: train step 19928: loss: 0.9775, policy_loss: 0.9173, value_loss: 0.4521
2024-07-14 07:18:57,025 [INFO    ] __main__: train step 19929: loss: 0.9775, policy_loss: 0.9173, value_loss: 0.4520
2024-07-14 07:18:57,318 [INFO    ] __main__: train step 19930: loss: 0.9775, policy_loss: 0.9173, value_loss: 0.4520
2024-07-14 07:18:57,623 [INFO    ] __main__: train step 19931: loss: 0.9775, policy_loss: 0.9173, value_loss: 0.4520
2024-07-14 07:18:57,906 [INFO    ] __main__: train step 19932: loss: 0.9775, policy_loss: 0.9172, value_loss: 0.4520
2024-07-14 07:18:58,190 [INFO    ] __main__: train step 19933: loss: 0.9774, policy_loss: 0.9172, value_loss: 0.4520
2024-07-14 07:18:58,487 [INFO    ] __main__: train step 19934: loss: 0.9774, policy_loss: 0.9172, value_loss: 0.4520
2024-07-14 07:18:58,790 [INFO    ] __main__: train step 19935: loss: 0.9774, policy_loss: 0.9172, value_loss: 0.4519
2024-07-14 07:18:59,088 [INFO    ] __main__: train step 19936: loss: 0.9774, policy_loss: 0.9172, value_loss: 0.4519
2024-07-14 07:18:59,373 [INFO    ] __main__: train step 19937: loss: 0.9774, policy_loss: 0.9172, value_loss: 0.4519
2024-07-14 07:19:01,028 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:19:01,487 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:19:01,554 [INFO    ] __main__: train step 19938: loss: 0.9774, policy_loss: 0.9171, value_loss: 0.4519
2024-07-14 07:19:01,833 [INFO    ] __main__: train step 19939: loss: 0.9774, policy_loss: 0.9171, value_loss: 0.4519
2024-07-14 07:19:02,126 [INFO    ] __main__: train step 19940: loss: 0.9773, policy_loss: 0.9171, value_loss: 0.4519
2024-07-14 07:19:02,402 [INFO    ] __main__: train step 19941: loss: 0.9773, policy_loss: 0.9171, value_loss: 0.4518
2024-07-14 07:19:02,667 [INFO    ] __main__: train step 19942: loss: 0.9773, policy_loss: 0.9171, value_loss: 0.4518
2024-07-14 07:19:02,957 [INFO    ] __main__: train step 19943: loss: 0.9773, policy_loss: 0.9170, value_loss: 0.4518
2024-07-14 07:19:03,264 [INFO    ] __main__: train step 19944: loss: 0.9773, policy_loss: 0.9170, value_loss: 0.4518
2024-07-14 07:19:03,574 [INFO    ] __main__: train step 19945: loss: 0.9773, policy_loss: 0.9170, value_loss: 0.4518
2024-07-14 07:19:03,863 [INFO    ] __main__: train step 19946: loss: 0.9773, policy_loss: 0.9170, value_loss: 0.4518
2024-07-14 07:19:04,132 [INFO    ] __main__: train step 19947: loss: 0.9772, policy_loss: 0.9170, value_loss: 0.4517
2024-07-14 07:19:04,410 [INFO    ] __main__: train step 19948: loss: 0.9772, policy_loss: 0.9170, value_loss: 0.4517
2024-07-14 07:19:04,680 [INFO    ] __main__: train step 19949: loss: 0.9772, policy_loss: 0.9169, value_loss: 0.4517
2024-07-14 07:19:04,962 [INFO    ] __main__: train step 19950: loss: 0.9772, policy_loss: 0.9169, value_loss: 0.4517
2024-07-14 07:19:05,243 [INFO    ] __main__: train step 19951: loss: 0.9772, policy_loss: 0.9169, value_loss: 0.4517
2024-07-14 07:19:05,487 [INFO    ] __main__: train step 19952: loss: 0.9772, policy_loss: 0.9169, value_loss: 0.4517
2024-07-14 07:19:05,751 [INFO    ] __main__: train step 19953: loss: 0.9771, policy_loss: 0.9169, value_loss: 0.4516
2024-07-14 07:19:06,012 [INFO    ] __main__: train step 19954: loss: 0.9771, policy_loss: 0.9169, value_loss: 0.4516
2024-07-14 07:19:07,606 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:19:08,080 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:19:08,147 [INFO    ] __main__: train step 19955: loss: 0.9771, policy_loss: 0.9168, value_loss: 0.4516
2024-07-14 07:19:08,428 [INFO    ] __main__: train step 19956: loss: 0.9771, policy_loss: 0.9168, value_loss: 0.4516
2024-07-14 07:19:08,697 [INFO    ] __main__: train step 19957: loss: 0.9771, policy_loss: 0.9168, value_loss: 0.4516
2024-07-14 07:19:08,978 [INFO    ] __main__: train step 19958: loss: 0.9771, policy_loss: 0.9168, value_loss: 0.4516
2024-07-14 07:19:09,240 [INFO    ] __main__: train step 19959: loss: 0.9771, policy_loss: 0.9168, value_loss: 0.4516
2024-07-14 07:19:09,525 [INFO    ] __main__: train step 19960: loss: 0.9770, policy_loss: 0.9167, value_loss: 0.4515
2024-07-14 07:19:09,832 [INFO    ] __main__: train step 19961: loss: 0.9770, policy_loss: 0.9167, value_loss: 0.4515
2024-07-14 07:19:10,138 [INFO    ] __main__: train step 19962: loss: 0.9770, policy_loss: 0.9167, value_loss: 0.4515
2024-07-14 07:19:10,437 [INFO    ] __main__: train step 19963: loss: 0.9770, policy_loss: 0.9167, value_loss: 0.4515
2024-07-14 07:19:10,713 [INFO    ] __main__: train step 19964: loss: 0.9770, policy_loss: 0.9167, value_loss: 0.4515
2024-07-14 07:19:10,993 [INFO    ] __main__: train step 19965: loss: 0.9770, policy_loss: 0.9167, value_loss: 0.4515
2024-07-14 07:19:11,281 [INFO    ] __main__: train step 19966: loss: 0.9770, policy_loss: 0.9166, value_loss: 0.4514
2024-07-14 07:19:11,572 [INFO    ] __main__: train step 19967: loss: 0.9769, policy_loss: 0.9166, value_loss: 0.4514
2024-07-14 07:19:11,880 [INFO    ] __main__: train step 19968: loss: 0.9769, policy_loss: 0.9166, value_loss: 0.4514
2024-07-14 07:19:12,170 [INFO    ] __main__: train step 19969: loss: 0.9769, policy_loss: 0.9166, value_loss: 0.4514
2024-07-14 07:19:12,456 [INFO    ] __main__: train step 19970: loss: 0.9769, policy_loss: 0.9166, value_loss: 0.4514
2024-07-14 07:19:12,761 [INFO    ] __main__: train step 19971: loss: 0.9769, policy_loss: 0.9165, value_loss: 0.4514
2024-07-14 07:19:14,407 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:19:14,897 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:19:14,969 [INFO    ] __main__: train step 19972: loss: 0.9769, policy_loss: 0.9165, value_loss: 0.4513
2024-07-14 07:19:15,253 [INFO    ] __main__: train step 19973: loss: 0.9769, policy_loss: 0.9165, value_loss: 0.4513
2024-07-14 07:19:15,558 [INFO    ] __main__: train step 19974: loss: 0.9768, policy_loss: 0.9165, value_loss: 0.4513
2024-07-14 07:19:15,856 [INFO    ] __main__: train step 19975: loss: 0.9768, policy_loss: 0.9165, value_loss: 0.4513
2024-07-14 07:19:16,152 [INFO    ] __main__: train step 19976: loss: 0.9768, policy_loss: 0.9165, value_loss: 0.4513
2024-07-14 07:19:16,449 [INFO    ] __main__: train step 19977: loss: 0.9768, policy_loss: 0.9164, value_loss: 0.4513
2024-07-14 07:19:16,736 [INFO    ] __main__: train step 19978: loss: 0.9768, policy_loss: 0.9164, value_loss: 0.4512
2024-07-14 07:19:17,033 [INFO    ] __main__: train step 19979: loss: 0.9768, policy_loss: 0.9164, value_loss: 0.4512
2024-07-14 07:19:17,325 [INFO    ] __main__: train step 19980: loss: 0.9768, policy_loss: 0.9164, value_loss: 0.4512
2024-07-14 07:19:17,638 [INFO    ] __main__: train step 19981: loss: 0.9767, policy_loss: 0.9164, value_loss: 0.4512
2024-07-14 07:19:17,943 [INFO    ] __main__: train step 19982: loss: 0.9767, policy_loss: 0.9163, value_loss: 0.4512
2024-07-14 07:19:21,494 [INFO    ] __main__: train step 19983: loss: 0.9767, policy_loss: 0.9163, value_loss: 0.4512
2024-07-14 07:19:21,794 [INFO    ] __main__: train step 19984: loss: 0.9767, policy_loss: 0.9163, value_loss: 0.4512
2024-07-14 07:19:22,099 [INFO    ] __main__: train step 19985: loss: 0.9767, policy_loss: 0.9163, value_loss: 0.4511
2024-07-14 07:19:22,390 [INFO    ] __main__: train step 19986: loss: 0.9767, policy_loss: 0.9163, value_loss: 0.4511
2024-07-14 07:19:22,672 [INFO    ] __main__: train step 19987: loss: 0.9767, policy_loss: 0.9163, value_loss: 0.4511
2024-07-14 07:19:22,972 [INFO    ] __main__: train step 19988: loss: 0.9766, policy_loss: 0.9162, value_loss: 0.4511
2024-07-14 07:19:24,577 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:19:25,035 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:19:25,103 [INFO    ] __main__: train step 19989: loss: 0.9766, policy_loss: 0.9162, value_loss: 0.4511
2024-07-14 07:19:25,387 [INFO    ] __main__: train step 19990: loss: 0.9766, policy_loss: 0.9162, value_loss: 0.4511
2024-07-14 07:19:25,657 [INFO    ] __main__: train step 19991: loss: 0.9766, policy_loss: 0.9162, value_loss: 0.4510
2024-07-14 07:19:25,962 [INFO    ] __main__: train step 19992: loss: 0.9766, policy_loss: 0.9162, value_loss: 0.4510
2024-07-14 07:19:26,256 [INFO    ] __main__: train step 19993: loss: 0.9766, policy_loss: 0.9161, value_loss: 0.4510
2024-07-14 07:19:26,536 [INFO    ] __main__: train step 19994: loss: 0.9766, policy_loss: 0.9161, value_loss: 0.4510
2024-07-14 07:19:26,824 [INFO    ] __main__: train step 19995: loss: 0.9765, policy_loss: 0.9161, value_loss: 0.4510
2024-07-14 07:19:27,130 [INFO    ] __main__: train step 19996: loss: 0.9765, policy_loss: 0.9161, value_loss: 0.4510
2024-07-14 07:19:27,429 [INFO    ] __main__: train step 19997: loss: 0.9765, policy_loss: 0.9161, value_loss: 0.4509
2024-07-14 07:19:27,739 [INFO    ] __main__: train step 19998: loss: 0.9765, policy_loss: 0.9161, value_loss: 0.4509
2024-07-14 07:19:28,037 [INFO    ] __main__: train step 19999: loss: 0.9765, policy_loss: 0.9160, value_loss: 0.4509
2024-07-14 07:19:28,345 [INFO    ] __main__: train step 20000: loss: 0.9765, policy_loss: 0.9160, value_loss: 0.4509
2024-07-14 07:19:28,509 [INFO    ] __main__: restored step 19000 for evaluation
2024-07-14 07:19:33,747 [INFO    ] __main__: test network ELO difference from baseline network: +106 (+8/-8) ELO from 32000 self-played games
2024-07-14 07:19:33,750 [INFO    ] __main__: game outcomes: W: 19459, D: 1088, L: 11453
2024-07-14 07:19:33,752 [INFO    ] __main__: validation_elo_delta: 106, validation_elo: 2882
2024-07-14 07:19:34,229 [INFO    ] __main__: running self-play game for SVG generation
2024-07-14 07:24:11,287 [INFO    ] __main__: saved self-play game in animations/run2_armageddon/20000.svg
2024-07-14 07:24:11,566 [INFO    ] __main__: train step 20001: loss: 0.9764, policy_loss: 0.9160, value_loss: 0.4509
2024-07-14 07:24:11,831 [INFO    ] __main__: train step 20002: loss: 0.9764, policy_loss: 0.9160, value_loss: 0.4509
2024-07-14 07:24:12,125 [INFO    ] __main__: train step 20003: loss: 0.9764, policy_loss: 0.9160, value_loss: 0.4509
2024-07-14 07:24:12,405 [INFO    ] __main__: train step 20004: loss: 0.9764, policy_loss: 0.9159, value_loss: 0.4508
2024-07-14 07:24:12,665 [INFO    ] __main__: train step 20005: loss: 0.9764, policy_loss: 0.9159, value_loss: 0.4508
2024-07-14 07:24:14,269 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:24:14,762 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:24:14,832 [INFO    ] __main__: train step 20006: loss: 0.9764, policy_loss: 0.9159, value_loss: 0.4508
2024-07-14 07:24:15,123 [INFO    ] __main__: train step 20007: loss: 0.9764, policy_loss: 0.9159, value_loss: 0.4508
2024-07-14 07:24:15,409 [INFO    ] __main__: train step 20008: loss: 0.9763, policy_loss: 0.9159, value_loss: 0.4508
2024-07-14 07:24:15,700 [INFO    ] __main__: train step 20009: loss: 0.9763, policy_loss: 0.9159, value_loss: 0.4508
2024-07-14 07:24:15,991 [INFO    ] __main__: train step 20010: loss: 0.9763, policy_loss: 0.9158, value_loss: 0.4507
2024-07-14 07:24:16,287 [INFO    ] __main__: train step 20011: loss: 0.9763, policy_loss: 0.9158, value_loss: 0.4507
2024-07-14 07:24:16,595 [INFO    ] __main__: train step 20012: loss: 0.9763, policy_loss: 0.9158, value_loss: 0.4507
2024-07-14 07:24:16,928 [INFO    ] __main__: train step 20013: loss: 0.9763, policy_loss: 0.9158, value_loss: 0.4507
2024-07-14 07:24:17,226 [INFO    ] __main__: train step 20014: loss: 0.9763, policy_loss: 0.9158, value_loss: 0.4507
2024-07-14 07:24:17,521 [INFO    ] __main__: train step 20015: loss: 0.9762, policy_loss: 0.9157, value_loss: 0.4507
2024-07-14 07:24:17,816 [INFO    ] __main__: train step 20016: loss: 0.9762, policy_loss: 0.9157, value_loss: 0.4506
2024-07-14 07:24:18,128 [INFO    ] __main__: train step 20017: loss: 0.9762, policy_loss: 0.9157, value_loss: 0.4506
2024-07-14 07:24:18,452 [INFO    ] __main__: train step 20018: loss: 0.9762, policy_loss: 0.9157, value_loss: 0.4506
2024-07-14 07:24:18,791 [INFO    ] __main__: train step 20019: loss: 0.9762, policy_loss: 0.9157, value_loss: 0.4506
2024-07-14 07:24:19,116 [INFO    ] __main__: train step 20020: loss: 0.9762, policy_loss: 0.9157, value_loss: 0.4506
2024-07-14 07:24:19,440 [INFO    ] __main__: train step 20021: loss: 0.9762, policy_loss: 0.9156, value_loss: 0.4506
2024-07-14 07:24:19,760 [INFO    ] __main__: train step 20022: loss: 0.9761, policy_loss: 0.9156, value_loss: 0.4505
2024-07-14 07:24:21,405 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:24:21,876 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:24:21,946 [INFO    ] __main__: train step 20023: loss: 0.9761, policy_loss: 0.9156, value_loss: 0.4505
2024-07-14 07:24:22,245 [INFO    ] __main__: train step 20024: loss: 0.9761, policy_loss: 0.9156, value_loss: 0.4505
2024-07-14 07:24:22,537 [INFO    ] __main__: train step 20025: loss: 0.9761, policy_loss: 0.9156, value_loss: 0.4505
2024-07-14 07:24:22,837 [INFO    ] __main__: train step 20026: loss: 0.9761, policy_loss: 0.9155, value_loss: 0.4505
2024-07-14 07:24:23,144 [INFO    ] __main__: train step 20027: loss: 0.9761, policy_loss: 0.9155, value_loss: 0.4505
2024-07-14 07:24:23,431 [INFO    ] __main__: train step 20028: loss: 0.9760, policy_loss: 0.9155, value_loss: 0.4504
2024-07-14 07:24:23,732 [INFO    ] __main__: train step 20029: loss: 0.9760, policy_loss: 0.9155, value_loss: 0.4504
2024-07-14 07:24:24,024 [INFO    ] __main__: train step 20030: loss: 0.9760, policy_loss: 0.9155, value_loss: 0.4504
2024-07-14 07:24:24,328 [INFO    ] __main__: train step 20031: loss: 0.9760, policy_loss: 0.9155, value_loss: 0.4504
2024-07-14 07:24:24,627 [INFO    ] __main__: train step 20032: loss: 0.9760, policy_loss: 0.9154, value_loss: 0.4504
2024-07-14 07:24:24,937 [INFO    ] __main__: train step 20033: loss: 0.9760, policy_loss: 0.9154, value_loss: 0.4504
2024-07-14 07:24:25,229 [INFO    ] __main__: train step 20034: loss: 0.9760, policy_loss: 0.9154, value_loss: 0.4504
2024-07-14 07:24:25,524 [INFO    ] __main__: train step 20035: loss: 0.9759, policy_loss: 0.9154, value_loss: 0.4503
2024-07-14 07:24:25,838 [INFO    ] __main__: train step 20036: loss: 0.9759, policy_loss: 0.9154, value_loss: 0.4503
2024-07-14 07:24:26,141 [INFO    ] __main__: train step 20037: loss: 0.9759, policy_loss: 0.9153, value_loss: 0.4503
2024-07-14 07:24:26,443 [INFO    ] __main__: train step 20038: loss: 0.9759, policy_loss: 0.9153, value_loss: 0.4503
2024-07-14 07:24:26,734 [INFO    ] __main__: train step 20039: loss: 0.9759, policy_loss: 0.9153, value_loss: 0.4503
2024-07-14 07:24:28,381 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:24:28,863 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:24:28,934 [INFO    ] __main__: train step 20040: loss: 0.9759, policy_loss: 0.9153, value_loss: 0.4503
2024-07-14 07:24:29,249 [INFO    ] __main__: train step 20041: loss: 0.9759, policy_loss: 0.9153, value_loss: 0.4502
2024-07-14 07:24:29,558 [INFO    ] __main__: train step 20042: loss: 0.9758, policy_loss: 0.9153, value_loss: 0.4502
2024-07-14 07:24:29,852 [INFO    ] __main__: train step 20043: loss: 0.9758, policy_loss: 0.9152, value_loss: 0.4502
2024-07-14 07:24:30,157 [INFO    ] __main__: train step 20044: loss: 0.9758, policy_loss: 0.9152, value_loss: 0.4502
2024-07-14 07:24:30,423 [INFO    ] __main__: train step 20045: loss: 0.9758, policy_loss: 0.9152, value_loss: 0.4502
2024-07-14 07:24:30,705 [INFO    ] __main__: train step 20046: loss: 0.9758, policy_loss: 0.9152, value_loss: 0.4502
2024-07-14 07:24:31,012 [INFO    ] __main__: train step 20047: loss: 0.9758, policy_loss: 0.9152, value_loss: 0.4501
2024-07-14 07:24:31,319 [INFO    ] __main__: train step 20048: loss: 0.9758, policy_loss: 0.9151, value_loss: 0.4501
2024-07-14 07:24:31,631 [INFO    ] __main__: train step 20049: loss: 0.9757, policy_loss: 0.9151, value_loss: 0.4501
2024-07-14 07:24:31,949 [INFO    ] __main__: train step 20050: loss: 0.9757, policy_loss: 0.9151, value_loss: 0.4501
2024-07-14 07:24:32,245 [INFO    ] __main__: train step 20051: loss: 0.9757, policy_loss: 0.9151, value_loss: 0.4501
2024-07-14 07:24:32,550 [INFO    ] __main__: train step 20052: loss: 0.9757, policy_loss: 0.9151, value_loss: 0.4501
2024-07-14 07:24:32,866 [INFO    ] __main__: train step 20053: loss: 0.9757, policy_loss: 0.9151, value_loss: 0.4500
2024-07-14 07:24:33,166 [INFO    ] __main__: train step 20054: loss: 0.9757, policy_loss: 0.9150, value_loss: 0.4500
2024-07-14 07:24:33,487 [INFO    ] __main__: train step 20055: loss: 0.9757, policy_loss: 0.9150, value_loss: 0.4500
2024-07-14 07:24:33,765 [INFO    ] __main__: train step 20056: loss: 0.9756, policy_loss: 0.9150, value_loss: 0.4500
2024-07-14 07:24:35,395 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:24:35,872 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:24:35,951 [INFO    ] __main__: train step 20057: loss: 0.9756, policy_loss: 0.9150, value_loss: 0.4500
2024-07-14 07:24:36,263 [INFO    ] __main__: train step 20058: loss: 0.9756, policy_loss: 0.9150, value_loss: 0.4500
2024-07-14 07:24:36,543 [INFO    ] __main__: train step 20059: loss: 0.9756, policy_loss: 0.9149, value_loss: 0.4500
2024-07-14 07:24:36,854 [INFO    ] __main__: train step 20060: loss: 0.9756, policy_loss: 0.9149, value_loss: 0.4499
2024-07-14 07:24:37,157 [INFO    ] __main__: train step 20061: loss: 0.9756, policy_loss: 0.9149, value_loss: 0.4499
2024-07-14 07:24:37,489 [INFO    ] __main__: train step 20062: loss: 0.9755, policy_loss: 0.9149, value_loss: 0.4499
2024-07-14 07:24:37,783 [INFO    ] __main__: train step 20063: loss: 0.9755, policy_loss: 0.9149, value_loss: 0.4499
2024-07-14 07:24:38,086 [INFO    ] __main__: train step 20064: loss: 0.9755, policy_loss: 0.9149, value_loss: 0.4499
2024-07-14 07:24:38,371 [INFO    ] __main__: train step 20065: loss: 0.9755, policy_loss: 0.9148, value_loss: 0.4499
2024-07-14 07:24:38,626 [INFO    ] __main__: train step 20066: loss: 0.9755, policy_loss: 0.9148, value_loss: 0.4498
2024-07-14 07:24:38,910 [INFO    ] __main__: train step 20067: loss: 0.9755, policy_loss: 0.9148, value_loss: 0.4498
2024-07-14 07:24:39,200 [INFO    ] __main__: train step 20068: loss: 0.9755, policy_loss: 0.9148, value_loss: 0.4498
2024-07-14 07:24:39,482 [INFO    ] __main__: train step 20069: loss: 0.9754, policy_loss: 0.9148, value_loss: 0.4498
2024-07-14 07:24:39,785 [INFO    ] __main__: train step 20070: loss: 0.9754, policy_loss: 0.9147, value_loss: 0.4498
2024-07-14 07:24:40,073 [INFO    ] __main__: train step 20071: loss: 0.9754, policy_loss: 0.9147, value_loss: 0.4498
2024-07-14 07:24:40,388 [INFO    ] __main__: train step 20072: loss: 0.9754, policy_loss: 0.9147, value_loss: 0.4497
2024-07-14 07:24:40,647 [INFO    ] __main__: train step 20073: loss: 0.9754, policy_loss: 0.9147, value_loss: 0.4497
2024-07-14 07:24:42,268 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:24:42,769 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:24:42,841 [INFO    ] __main__: train step 20074: loss: 0.9754, policy_loss: 0.9147, value_loss: 0.4497
2024-07-14 07:24:43,147 [INFO    ] __main__: train step 20075: loss: 0.9754, policy_loss: 0.9147, value_loss: 0.4497
2024-07-14 07:24:43,467 [INFO    ] __main__: train step 20076: loss: 0.9753, policy_loss: 0.9146, value_loss: 0.4497
2024-07-14 07:24:43,767 [INFO    ] __main__: train step 20077: loss: 0.9753, policy_loss: 0.9146, value_loss: 0.4497
2024-07-14 07:24:44,038 [INFO    ] __main__: train step 20078: loss: 0.9753, policy_loss: 0.9146, value_loss: 0.4496
2024-07-14 07:24:44,338 [INFO    ] __main__: train step 20079: loss: 0.9753, policy_loss: 0.9146, value_loss: 0.4496
2024-07-14 07:24:44,644 [INFO    ] __main__: train step 20080: loss: 0.9753, policy_loss: 0.9146, value_loss: 0.4496
2024-07-14 07:24:44,955 [INFO    ] __main__: train step 20081: loss: 0.9753, policy_loss: 0.9145, value_loss: 0.4496
2024-07-14 07:24:45,238 [INFO    ] __main__: train step 20082: loss: 0.9752, policy_loss: 0.9145, value_loss: 0.4496
2024-07-14 07:24:45,520 [INFO    ] __main__: train step 20083: loss: 0.9752, policy_loss: 0.9145, value_loss: 0.4496
2024-07-14 07:24:45,802 [INFO    ] __main__: train step 20084: loss: 0.9752, policy_loss: 0.9145, value_loss: 0.4496
2024-07-14 07:24:46,087 [INFO    ] __main__: train step 20085: loss: 0.9752, policy_loss: 0.9145, value_loss: 0.4495
2024-07-14 07:24:46,353 [INFO    ] __main__: train step 20086: loss: 0.9752, policy_loss: 0.9145, value_loss: 0.4495
2024-07-14 07:24:46,615 [INFO    ] __main__: train step 20087: loss: 0.9752, policy_loss: 0.9144, value_loss: 0.4495
2024-07-14 07:24:46,884 [INFO    ] __main__: train step 20088: loss: 0.9752, policy_loss: 0.9144, value_loss: 0.4495
2024-07-14 07:24:47,183 [INFO    ] __main__: train step 20089: loss: 0.9751, policy_loss: 0.9144, value_loss: 0.4495
2024-07-14 07:24:47,449 [INFO    ] __main__: train step 20090: loss: 0.9751, policy_loss: 0.9144, value_loss: 0.4495
2024-07-14 07:24:49,068 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:24:49,546 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:24:49,614 [INFO    ] __main__: train step 20091: loss: 0.9751, policy_loss: 0.9144, value_loss: 0.4494
2024-07-14 07:24:49,894 [INFO    ] __main__: train step 20092: loss: 0.9751, policy_loss: 0.9143, value_loss: 0.4494
2024-07-14 07:24:50,171 [INFO    ] __main__: train step 20093: loss: 0.9751, policy_loss: 0.9143, value_loss: 0.4494
2024-07-14 07:24:50,449 [INFO    ] __main__: train step 20094: loss: 0.9751, policy_loss: 0.9143, value_loss: 0.4494
2024-07-14 07:24:50,784 [INFO    ] __main__: train step 20095: loss: 0.9751, policy_loss: 0.9143, value_loss: 0.4494
2024-07-14 07:24:51,089 [INFO    ] __main__: train step 20096: loss: 0.9750, policy_loss: 0.9143, value_loss: 0.4494
2024-07-14 07:24:51,387 [INFO    ] __main__: train step 20097: loss: 0.9750, policy_loss: 0.9143, value_loss: 0.4493
2024-07-14 07:24:51,701 [INFO    ] __main__: train step 20098: loss: 0.9750, policy_loss: 0.9142, value_loss: 0.4493
2024-07-14 07:24:51,999 [INFO    ] __main__: train step 20099: loss: 0.9750, policy_loss: 0.9142, value_loss: 0.4493
2024-07-14 07:24:52,326 [INFO    ] __main__: train step 20100: loss: 0.9750, policy_loss: 0.9142, value_loss: 0.4493
2024-07-14 07:24:52,612 [INFO    ] __main__: train step 20101: loss: 0.9750, policy_loss: 0.9142, value_loss: 0.4493
2024-07-14 07:24:52,884 [INFO    ] __main__: train step 20102: loss: 0.9750, policy_loss: 0.9142, value_loss: 0.4493
2024-07-14 07:24:53,186 [INFO    ] __main__: train step 20103: loss: 0.9749, policy_loss: 0.9141, value_loss: 0.4492
2024-07-14 07:24:53,467 [INFO    ] __main__: train step 20104: loss: 0.9749, policy_loss: 0.9141, value_loss: 0.4492
2024-07-14 07:24:53,784 [INFO    ] __main__: train step 20105: loss: 0.9749, policy_loss: 0.9141, value_loss: 0.4492
2024-07-14 07:24:54,084 [INFO    ] __main__: train step 20106: loss: 0.9749, policy_loss: 0.9141, value_loss: 0.4492
2024-07-14 07:24:54,392 [INFO    ] __main__: train step 20107: loss: 0.9749, policy_loss: 0.9141, value_loss: 0.4492
2024-07-14 07:24:56,032 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:24:56,476 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:24:56,546 [INFO    ] __main__: train step 20108: loss: 0.9749, policy_loss: 0.9141, value_loss: 0.4492
2024-07-14 07:24:56,857 [INFO    ] __main__: train step 20109: loss: 0.9748, policy_loss: 0.9140, value_loss: 0.4492
2024-07-14 07:24:57,183 [INFO    ] __main__: train step 20110: loss: 0.9748, policy_loss: 0.9140, value_loss: 0.4491
2024-07-14 07:24:57,485 [INFO    ] __main__: train step 20111: loss: 0.9748, policy_loss: 0.9140, value_loss: 0.4491
2024-07-14 07:24:57,787 [INFO    ] __main__: train step 20112: loss: 0.9748, policy_loss: 0.9140, value_loss: 0.4491
2024-07-14 07:24:58,083 [INFO    ] __main__: train step 20113: loss: 0.9748, policy_loss: 0.9140, value_loss: 0.4491
2024-07-14 07:24:58,360 [INFO    ] __main__: train step 20114: loss: 0.9748, policy_loss: 0.9139, value_loss: 0.4491
2024-07-14 07:24:58,646 [INFO    ] __main__: train step 20115: loss: 0.9748, policy_loss: 0.9139, value_loss: 0.4491
2024-07-14 07:24:58,939 [INFO    ] __main__: train step 20116: loss: 0.9747, policy_loss: 0.9139, value_loss: 0.4490
2024-07-14 07:24:59,218 [INFO    ] __main__: train step 20117: loss: 0.9747, policy_loss: 0.9139, value_loss: 0.4490
2024-07-14 07:24:59,524 [INFO    ] __main__: train step 20118: loss: 0.9747, policy_loss: 0.9139, value_loss: 0.4490
2024-07-14 07:24:59,820 [INFO    ] __main__: train step 20119: loss: 0.9747, policy_loss: 0.9139, value_loss: 0.4490
2024-07-14 07:25:00,126 [INFO    ] __main__: train step 20120: loss: 0.9747, policy_loss: 0.9138, value_loss: 0.4490
2024-07-14 07:25:00,427 [INFO    ] __main__: train step 20121: loss: 0.9747, policy_loss: 0.9138, value_loss: 0.4490
2024-07-14 07:25:00,690 [INFO    ] __main__: train step 20122: loss: 0.9747, policy_loss: 0.9138, value_loss: 0.4489
2024-07-14 07:25:00,978 [INFO    ] __main__: train step 20123: loss: 0.9746, policy_loss: 0.9138, value_loss: 0.4489
2024-07-14 07:25:01,253 [INFO    ] __main__: train step 20124: loss: 0.9746, policy_loss: 0.9138, value_loss: 0.4489
2024-07-14 07:25:02,852 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:25:03,344 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:25:03,420 [INFO    ] __main__: train step 20125: loss: 0.9746, policy_loss: 0.9137, value_loss: 0.4489
2024-07-14 07:25:03,675 [INFO    ] __main__: train step 20126: loss: 0.9746, policy_loss: 0.9137, value_loss: 0.4489
2024-07-14 07:25:08,374 [INFO    ] __main__: train step 20127: loss: 0.9746, policy_loss: 0.9137, value_loss: 0.4489
2024-07-14 07:25:08,643 [INFO    ] __main__: train step 20128: loss: 0.9746, policy_loss: 0.9137, value_loss: 0.4488
2024-07-14 07:25:08,950 [INFO    ] __main__: train step 20129: loss: 0.9746, policy_loss: 0.9137, value_loss: 0.4488
2024-07-14 07:25:09,253 [INFO    ] __main__: train step 20130: loss: 0.9745, policy_loss: 0.9137, value_loss: 0.4488
2024-07-14 07:25:09,531 [INFO    ] __main__: train step 20131: loss: 0.9745, policy_loss: 0.9136, value_loss: 0.4488
2024-07-14 07:25:09,850 [INFO    ] __main__: train step 20132: loss: 0.9745, policy_loss: 0.9136, value_loss: 0.4488
2024-07-14 07:25:10,136 [INFO    ] __main__: train step 20133: loss: 0.9745, policy_loss: 0.9136, value_loss: 0.4488
2024-07-14 07:25:10,398 [INFO    ] __main__: train step 20134: loss: 0.9745, policy_loss: 0.9136, value_loss: 0.4488
2024-07-14 07:25:10,687 [INFO    ] __main__: train step 20135: loss: 0.9745, policy_loss: 0.9136, value_loss: 0.4487
2024-07-14 07:25:10,960 [INFO    ] __main__: train step 20136: loss: 0.9744, policy_loss: 0.9135, value_loss: 0.4487
2024-07-14 07:25:11,242 [INFO    ] __main__: train step 20137: loss: 0.9744, policy_loss: 0.9135, value_loss: 0.4487
2024-07-14 07:25:11,538 [INFO    ] __main__: train step 20138: loss: 0.9744, policy_loss: 0.9135, value_loss: 0.4487
2024-07-14 07:25:11,822 [INFO    ] __main__: train step 20139: loss: 0.9744, policy_loss: 0.9135, value_loss: 0.4487
2024-07-14 07:25:12,093 [INFO    ] __main__: train step 20140: loss: 0.9744, policy_loss: 0.9135, value_loss: 0.4487
2024-07-14 07:25:12,349 [INFO    ] __main__: train step 20141: loss: 0.9744, policy_loss: 0.9135, value_loss: 0.4486
2024-07-14 07:25:13,956 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:25:14,419 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:25:14,487 [INFO    ] __main__: train step 20142: loss: 0.9744, policy_loss: 0.9134, value_loss: 0.4486
2024-07-14 07:25:14,759 [INFO    ] __main__: train step 20143: loss: 0.9743, policy_loss: 0.9134, value_loss: 0.4486
2024-07-14 07:25:15,032 [INFO    ] __main__: train step 20144: loss: 0.9743, policy_loss: 0.9134, value_loss: 0.4486
2024-07-14 07:25:15,303 [INFO    ] __main__: train step 20145: loss: 0.9743, policy_loss: 0.9134, value_loss: 0.4486
2024-07-14 07:25:15,576 [INFO    ] __main__: train step 20146: loss: 0.9743, policy_loss: 0.9134, value_loss: 0.4486
2024-07-14 07:25:15,857 [INFO    ] __main__: train step 20147: loss: 0.9743, policy_loss: 0.9133, value_loss: 0.4485
2024-07-14 07:25:16,130 [INFO    ] __main__: train step 20148: loss: 0.9743, policy_loss: 0.9133, value_loss: 0.4485
2024-07-14 07:25:16,426 [INFO    ] __main__: train step 20149: loss: 0.9743, policy_loss: 0.9133, value_loss: 0.4485
2024-07-14 07:25:16,686 [INFO    ] __main__: train step 20150: loss: 0.9742, policy_loss: 0.9133, value_loss: 0.4485
2024-07-14 07:25:16,984 [INFO    ] __main__: train step 20151: loss: 0.9742, policy_loss: 0.9133, value_loss: 0.4485
2024-07-14 07:25:17,275 [INFO    ] __main__: train step 20152: loss: 0.9742, policy_loss: 0.9133, value_loss: 0.4485
2024-07-14 07:25:17,558 [INFO    ] __main__: train step 20153: loss: 0.9742, policy_loss: 0.9132, value_loss: 0.4484
2024-07-14 07:25:17,859 [INFO    ] __main__: train step 20154: loss: 0.9742, policy_loss: 0.9132, value_loss: 0.4484
2024-07-14 07:25:18,149 [INFO    ] __main__: train step 20155: loss: 0.9742, policy_loss: 0.9132, value_loss: 0.4484
2024-07-14 07:25:18,435 [INFO    ] __main__: train step 20156: loss: 0.9742, policy_loss: 0.9132, value_loss: 0.4484
2024-07-14 07:25:18,721 [INFO    ] __main__: train step 20157: loss: 0.9741, policy_loss: 0.9132, value_loss: 0.4484
2024-07-14 07:25:19,000 [INFO    ] __main__: train step 20158: loss: 0.9741, policy_loss: 0.9131, value_loss: 0.4484
2024-07-14 07:25:20,599 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:25:21,078 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:25:21,151 [INFO    ] __main__: train step 20159: loss: 0.9741, policy_loss: 0.9131, value_loss: 0.4484
2024-07-14 07:25:21,454 [INFO    ] __main__: train step 20160: loss: 0.9741, policy_loss: 0.9131, value_loss: 0.4483
2024-07-14 07:25:21,733 [INFO    ] __main__: train step 20161: loss: 0.9741, policy_loss: 0.9131, value_loss: 0.4483
2024-07-14 07:25:22,037 [INFO    ] __main__: train step 20162: loss: 0.9741, policy_loss: 0.9131, value_loss: 0.4483
2024-07-14 07:25:22,327 [INFO    ] __main__: train step 20163: loss: 0.9740, policy_loss: 0.9131, value_loss: 0.4483
2024-07-14 07:25:22,614 [INFO    ] __main__: train step 20164: loss: 0.9740, policy_loss: 0.9130, value_loss: 0.4483
2024-07-14 07:25:22,894 [INFO    ] __main__: train step 20165: loss: 0.9740, policy_loss: 0.9130, value_loss: 0.4483
2024-07-14 07:25:23,171 [INFO    ] __main__: train step 20166: loss: 0.9740, policy_loss: 0.9130, value_loss: 0.4482
2024-07-14 07:25:23,450 [INFO    ] __main__: train step 20167: loss: 0.9740, policy_loss: 0.9130, value_loss: 0.4482
2024-07-14 07:25:23,721 [INFO    ] __main__: train step 20168: loss: 0.9740, policy_loss: 0.9130, value_loss: 0.4482
2024-07-14 07:25:23,991 [INFO    ] __main__: train step 20169: loss: 0.9740, policy_loss: 0.9129, value_loss: 0.4482
2024-07-14 07:25:24,267 [INFO    ] __main__: train step 20170: loss: 0.9739, policy_loss: 0.9129, value_loss: 0.4482
2024-07-14 07:25:24,557 [INFO    ] __main__: train step 20171: loss: 0.9739, policy_loss: 0.9129, value_loss: 0.4482
2024-07-14 07:25:24,845 [INFO    ] __main__: train step 20172: loss: 0.9739, policy_loss: 0.9129, value_loss: 0.4481
2024-07-14 07:25:25,131 [INFO    ] __main__: train step 20173: loss: 0.9739, policy_loss: 0.9129, value_loss: 0.4481
2024-07-14 07:25:25,421 [INFO    ] __main__: train step 20174: loss: 0.9739, policy_loss: 0.9129, value_loss: 0.4481
2024-07-14 07:25:25,689 [INFO    ] __main__: train step 20175: loss: 0.9739, policy_loss: 0.9128, value_loss: 0.4481
2024-07-14 07:25:27,265 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:25:27,726 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:25:27,794 [INFO    ] __main__: train step 20176: loss: 0.9739, policy_loss: 0.9128, value_loss: 0.4481
2024-07-14 07:25:28,085 [INFO    ] __main__: train step 20177: loss: 0.9738, policy_loss: 0.9128, value_loss: 0.4481
2024-07-14 07:25:28,362 [INFO    ] __main__: train step 20178: loss: 0.9738, policy_loss: 0.9128, value_loss: 0.4480
2024-07-14 07:25:28,670 [INFO    ] __main__: train step 20179: loss: 0.9738, policy_loss: 0.9128, value_loss: 0.4480
2024-07-14 07:25:28,947 [INFO    ] __main__: train step 20180: loss: 0.9738, policy_loss: 0.9127, value_loss: 0.4480
2024-07-14 07:25:29,239 [INFO    ] __main__: train step 20181: loss: 0.9738, policy_loss: 0.9127, value_loss: 0.4480
2024-07-14 07:25:29,531 [INFO    ] __main__: train step 20182: loss: 0.9738, policy_loss: 0.9127, value_loss: 0.4480
2024-07-14 07:25:29,825 [INFO    ] __main__: train step 20183: loss: 0.9737, policy_loss: 0.9127, value_loss: 0.4480
2024-07-14 07:25:30,108 [INFO    ] __main__: train step 20184: loss: 0.9737, policy_loss: 0.9127, value_loss: 0.4480
2024-07-14 07:25:30,414 [INFO    ] __main__: train step 20185: loss: 0.9737, policy_loss: 0.9127, value_loss: 0.4479
2024-07-14 07:25:30,682 [INFO    ] __main__: train step 20186: loss: 0.9737, policy_loss: 0.9126, value_loss: 0.4479
2024-07-14 07:25:30,970 [INFO    ] __main__: train step 20187: loss: 0.9737, policy_loss: 0.9126, value_loss: 0.4479
2024-07-14 07:25:31,250 [INFO    ] __main__: train step 20188: loss: 0.9737, policy_loss: 0.9126, value_loss: 0.4479
2024-07-14 07:25:31,523 [INFO    ] __main__: train step 20189: loss: 0.9737, policy_loss: 0.9126, value_loss: 0.4479
2024-07-14 07:25:31,824 [INFO    ] __main__: train step 20190: loss: 0.9736, policy_loss: 0.9126, value_loss: 0.4479
2024-07-14 07:25:32,084 [INFO    ] __main__: train step 20191: loss: 0.9736, policy_loss: 0.9125, value_loss: 0.4478
2024-07-14 07:25:32,369 [INFO    ] __main__: train step 20192: loss: 0.9736, policy_loss: 0.9125, value_loss: 0.4478
2024-07-14 07:25:33,999 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:25:34,484 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:25:34,554 [INFO    ] __main__: train step 20193: loss: 0.9736, policy_loss: 0.9125, value_loss: 0.4478
2024-07-14 07:25:34,847 [INFO    ] __main__: train step 20194: loss: 0.9736, policy_loss: 0.9125, value_loss: 0.4478
2024-07-14 07:25:35,135 [INFO    ] __main__: train step 20195: loss: 0.9736, policy_loss: 0.9125, value_loss: 0.4478
2024-07-14 07:25:35,440 [INFO    ] __main__: train step 20196: loss: 0.9736, policy_loss: 0.9125, value_loss: 0.4478
2024-07-14 07:25:35,731 [INFO    ] __main__: train step 20197: loss: 0.9735, policy_loss: 0.9124, value_loss: 0.4477
2024-07-14 07:25:36,014 [INFO    ] __main__: train step 20198: loss: 0.9735, policy_loss: 0.9124, value_loss: 0.4477
2024-07-14 07:25:36,289 [INFO    ] __main__: train step 20199: loss: 0.9735, policy_loss: 0.9124, value_loss: 0.4477
2024-07-14 07:25:36,584 [INFO    ] __main__: train step 20200: loss: 0.9735, policy_loss: 0.9124, value_loss: 0.4477
2024-07-14 07:25:36,885 [INFO    ] __main__: train step 20201: loss: 0.9735, policy_loss: 0.9124, value_loss: 0.4477
2024-07-14 07:25:37,196 [INFO    ] __main__: train step 20202: loss: 0.9735, policy_loss: 0.9123, value_loss: 0.4477
2024-07-14 07:25:37,482 [INFO    ] __main__: train step 20203: loss: 0.9734, policy_loss: 0.9123, value_loss: 0.4476
2024-07-14 07:25:37,750 [INFO    ] __main__: train step 20204: loss: 0.9734, policy_loss: 0.9123, value_loss: 0.4476
2024-07-14 07:25:38,058 [INFO    ] __main__: train step 20205: loss: 0.9734, policy_loss: 0.9123, value_loss: 0.4476
2024-07-14 07:25:38,361 [INFO    ] __main__: train step 20206: loss: 0.9734, policy_loss: 0.9123, value_loss: 0.4476
2024-07-14 07:25:38,634 [INFO    ] __main__: train step 20207: loss: 0.9734, policy_loss: 0.9123, value_loss: 0.4476
2024-07-14 07:25:38,932 [INFO    ] __main__: train step 20208: loss: 0.9734, policy_loss: 0.9122, value_loss: 0.4476
2024-07-14 07:25:39,233 [INFO    ] __main__: train step 20209: loss: 0.9734, policy_loss: 0.9122, value_loss: 0.4475
2024-07-14 07:25:40,892 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:25:41,338 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:25:41,414 [INFO    ] __main__: train step 20210: loss: 0.9733, policy_loss: 0.9122, value_loss: 0.4475
2024-07-14 07:25:41,715 [INFO    ] __main__: train step 20211: loss: 0.9733, policy_loss: 0.9122, value_loss: 0.4475
2024-07-14 07:25:41,979 [INFO    ] __main__: train step 20212: loss: 0.9733, policy_loss: 0.9122, value_loss: 0.4475
2024-07-14 07:25:42,265 [INFO    ] __main__: train step 20213: loss: 0.9733, policy_loss: 0.9121, value_loss: 0.4475
2024-07-14 07:25:42,535 [INFO    ] __main__: train step 20214: loss: 0.9733, policy_loss: 0.9121, value_loss: 0.4475
2024-07-14 07:25:42,858 [INFO    ] __main__: train step 20215: loss: 0.9733, policy_loss: 0.9121, value_loss: 0.4474
2024-07-14 07:25:43,146 [INFO    ] __main__: train step 20216: loss: 0.9732, policy_loss: 0.9121, value_loss: 0.4474
2024-07-14 07:25:43,444 [INFO    ] __main__: train step 20217: loss: 0.9732, policy_loss: 0.9121, value_loss: 0.4474
2024-07-14 07:25:43,744 [INFO    ] __main__: train step 20218: loss: 0.9732, policy_loss: 0.9121, value_loss: 0.4474
2024-07-14 07:25:44,037 [INFO    ] __main__: train step 20219: loss: 0.9732, policy_loss: 0.9120, value_loss: 0.4474
2024-07-14 07:25:44,338 [INFO    ] __main__: train step 20220: loss: 0.9732, policy_loss: 0.9120, value_loss: 0.4474
2024-07-14 07:25:44,612 [INFO    ] __main__: train step 20221: loss: 0.9732, policy_loss: 0.9120, value_loss: 0.4474
2024-07-14 07:25:44,904 [INFO    ] __main__: train step 20222: loss: 0.9732, policy_loss: 0.9120, value_loss: 0.4473
2024-07-14 07:25:45,185 [INFO    ] __main__: train step 20223: loss: 0.9731, policy_loss: 0.9120, value_loss: 0.4473
2024-07-14 07:25:45,486 [INFO    ] __main__: train step 20224: loss: 0.9731, policy_loss: 0.9119, value_loss: 0.4473
2024-07-14 07:25:45,776 [INFO    ] __main__: train step 20225: loss: 0.9731, policy_loss: 0.9119, value_loss: 0.4473
2024-07-14 07:25:46,066 [INFO    ] __main__: train step 20226: loss: 0.9731, policy_loss: 0.9119, value_loss: 0.4473
2024-07-14 07:25:47,681 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:25:48,169 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:25:48,251 [INFO    ] __main__: train step 20227: loss: 0.9731, policy_loss: 0.9119, value_loss: 0.4473
2024-07-14 07:25:48,564 [INFO    ] __main__: train step 20228: loss: 0.9731, policy_loss: 0.9119, value_loss: 0.4472
2024-07-14 07:25:48,896 [INFO    ] __main__: train step 20229: loss: 0.9730, policy_loss: 0.9119, value_loss: 0.4472
2024-07-14 07:25:49,181 [INFO    ] __main__: train step 20230: loss: 0.9730, policy_loss: 0.9118, value_loss: 0.4472
2024-07-14 07:25:49,493 [INFO    ] __main__: train step 20231: loss: 0.9730, policy_loss: 0.9118, value_loss: 0.4472
2024-07-14 07:25:49,788 [INFO    ] __main__: train step 20232: loss: 0.9730, policy_loss: 0.9118, value_loss: 0.4472
2024-07-14 07:25:50,084 [INFO    ] __main__: train step 20233: loss: 0.9730, policy_loss: 0.9118, value_loss: 0.4472
2024-07-14 07:25:50,350 [INFO    ] __main__: train step 20234: loss: 0.9730, policy_loss: 0.9118, value_loss: 0.4471
2024-07-14 07:25:50,627 [INFO    ] __main__: train step 20235: loss: 0.9730, policy_loss: 0.9117, value_loss: 0.4471
2024-07-14 07:25:50,933 [INFO    ] __main__: train step 20236: loss: 0.9729, policy_loss: 0.9117, value_loss: 0.4471
2024-07-14 07:25:51,237 [INFO    ] __main__: train step 20237: loss: 0.9729, policy_loss: 0.9117, value_loss: 0.4471
2024-07-14 07:25:51,531 [INFO    ] __main__: train step 20238: loss: 0.9729, policy_loss: 0.9117, value_loss: 0.4471
2024-07-14 07:25:51,819 [INFO    ] __main__: train step 20239: loss: 0.9729, policy_loss: 0.9117, value_loss: 0.4471
2024-07-14 07:25:52,140 [INFO    ] __main__: train step 20240: loss: 0.9729, policy_loss: 0.9117, value_loss: 0.4470
2024-07-14 07:25:52,449 [INFO    ] __main__: train step 20241: loss: 0.9729, policy_loss: 0.9116, value_loss: 0.4470
2024-07-14 07:25:52,747 [INFO    ] __main__: train step 20242: loss: 0.9729, policy_loss: 0.9116, value_loss: 0.4470
2024-07-14 07:25:53,043 [INFO    ] __main__: train step 20243: loss: 0.9728, policy_loss: 0.9116, value_loss: 0.4470
2024-07-14 07:25:54,670 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:25:55,094 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:25:55,162 [INFO    ] __main__: train step 20244: loss: 0.9728, policy_loss: 0.9116, value_loss: 0.4470
2024-07-14 07:25:55,490 [INFO    ] __main__: train step 20245: loss: 0.9728, policy_loss: 0.9116, value_loss: 0.4470
2024-07-14 07:25:55,779 [INFO    ] __main__: train step 20246: loss: 0.9728, policy_loss: 0.9115, value_loss: 0.4470
2024-07-14 07:25:56,066 [INFO    ] __main__: train step 20247: loss: 0.9728, policy_loss: 0.9115, value_loss: 0.4469
2024-07-14 07:25:56,397 [INFO    ] __main__: train step 20248: loss: 0.9728, policy_loss: 0.9115, value_loss: 0.4469
2024-07-14 07:25:56,694 [INFO    ] __main__: train step 20249: loss: 0.9727, policy_loss: 0.9115, value_loss: 0.4469
2024-07-14 07:25:56,981 [INFO    ] __main__: train step 20250: loss: 0.9727, policy_loss: 0.9115, value_loss: 0.4469
2024-07-14 07:26:03,498 [INFO    ] __main__: train step 20251: loss: 0.9727, policy_loss: 0.9115, value_loss: 0.4469
2024-07-14 07:26:03,819 [INFO    ] __main__: train step 20252: loss: 0.9727, policy_loss: 0.9114, value_loss: 0.4469
2024-07-14 07:26:04,128 [INFO    ] __main__: train step 20253: loss: 0.9727, policy_loss: 0.9114, value_loss: 0.4468
2024-07-14 07:26:04,430 [INFO    ] __main__: train step 20254: loss: 0.9727, policy_loss: 0.9114, value_loss: 0.4468
2024-07-14 07:26:04,734 [INFO    ] __main__: train step 20255: loss: 0.9726, policy_loss: 0.9114, value_loss: 0.4468
2024-07-14 07:26:05,030 [INFO    ] __main__: train step 20256: loss: 0.9726, policy_loss: 0.9114, value_loss: 0.4468
2024-07-14 07:26:05,325 [INFO    ] __main__: train step 20257: loss: 0.9726, policy_loss: 0.9113, value_loss: 0.4468
2024-07-14 07:26:05,615 [INFO    ] __main__: train step 20258: loss: 0.9726, policy_loss: 0.9113, value_loss: 0.4468
2024-07-14 07:26:05,909 [INFO    ] __main__: train step 20259: loss: 0.9726, policy_loss: 0.9113, value_loss: 0.4467
2024-07-14 07:26:06,211 [INFO    ] __main__: train step 20260: loss: 0.9726, policy_loss: 0.9113, value_loss: 0.4467
2024-07-14 07:26:07,891 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:26:08,365 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:26:08,438 [INFO    ] __main__: train step 20261: loss: 0.9726, policy_loss: 0.9113, value_loss: 0.4467
2024-07-14 07:26:08,784 [INFO    ] __main__: train step 20262: loss: 0.9725, policy_loss: 0.9113, value_loss: 0.4467
2024-07-14 07:26:09,066 [INFO    ] __main__: train step 20263: loss: 0.9725, policy_loss: 0.9112, value_loss: 0.4467
2024-07-14 07:26:09,353 [INFO    ] __main__: train step 20264: loss: 0.9725, policy_loss: 0.9112, value_loss: 0.4467
2024-07-14 07:26:09,650 [INFO    ] __main__: train step 20265: loss: 0.9725, policy_loss: 0.9112, value_loss: 0.4466
2024-07-14 07:26:09,965 [INFO    ] __main__: train step 20266: loss: 0.9725, policy_loss: 0.9112, value_loss: 0.4466
2024-07-14 07:26:10,288 [INFO    ] __main__: train step 20267: loss: 0.9725, policy_loss: 0.9112, value_loss: 0.4466
2024-07-14 07:26:10,605 [INFO    ] __main__: train step 20268: loss: 0.9725, policy_loss: 0.9111, value_loss: 0.4466
2024-07-14 07:26:10,930 [INFO    ] __main__: train step 20269: loss: 0.9724, policy_loss: 0.9111, value_loss: 0.4466
2024-07-14 07:26:11,244 [INFO    ] __main__: train step 20270: loss: 0.9724, policy_loss: 0.9111, value_loss: 0.4466
2024-07-14 07:26:11,562 [INFO    ] __main__: train step 20271: loss: 0.9724, policy_loss: 0.9111, value_loss: 0.4465
2024-07-14 07:26:11,881 [INFO    ] __main__: train step 20272: loss: 0.9724, policy_loss: 0.9111, value_loss: 0.4465
2024-07-14 07:26:12,216 [INFO    ] __main__: train step 20273: loss: 0.9724, policy_loss: 0.9111, value_loss: 0.4465
2024-07-14 07:26:12,501 [INFO    ] __main__: train step 20274: loss: 0.9724, policy_loss: 0.9110, value_loss: 0.4465
2024-07-14 07:26:12,817 [INFO    ] __main__: train step 20275: loss: 0.9723, policy_loss: 0.9110, value_loss: 0.4465
2024-07-14 07:26:13,138 [INFO    ] __main__: train step 20276: loss: 0.9723, policy_loss: 0.9110, value_loss: 0.4465
2024-07-14 07:26:13,458 [INFO    ] __main__: train step 20277: loss: 0.9723, policy_loss: 0.9110, value_loss: 0.4464
2024-07-14 07:26:15,098 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:26:15,579 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:26:15,645 [INFO    ] __main__: train step 20278: loss: 0.9723, policy_loss: 0.9110, value_loss: 0.4464
2024-07-14 07:26:15,947 [INFO    ] __main__: train step 20279: loss: 0.9723, policy_loss: 0.9109, value_loss: 0.4464
2024-07-14 07:26:16,256 [INFO    ] __main__: train step 20280: loss: 0.9723, policy_loss: 0.9109, value_loss: 0.4464
2024-07-14 07:26:16,551 [INFO    ] __main__: train step 20281: loss: 0.9723, policy_loss: 0.9109, value_loss: 0.4464
2024-07-14 07:26:16,854 [INFO    ] __main__: train step 20282: loss: 0.9722, policy_loss: 0.9109, value_loss: 0.4464
2024-07-14 07:26:17,178 [INFO    ] __main__: train step 20283: loss: 0.9722, policy_loss: 0.9109, value_loss: 0.4463
2024-07-14 07:26:17,483 [INFO    ] __main__: train step 20284: loss: 0.9722, policy_loss: 0.9109, value_loss: 0.4463
2024-07-14 07:26:17,790 [INFO    ] __main__: train step 20285: loss: 0.9722, policy_loss: 0.9108, value_loss: 0.4463
2024-07-14 07:26:18,093 [INFO    ] __main__: train step 20286: loss: 0.9722, policy_loss: 0.9108, value_loss: 0.4463
2024-07-14 07:26:18,395 [INFO    ] __main__: train step 20287: loss: 0.9722, policy_loss: 0.9108, value_loss: 0.4463
2024-07-14 07:26:18,723 [INFO    ] __main__: train step 20288: loss: 0.9721, policy_loss: 0.9108, value_loss: 0.4463
2024-07-14 07:26:19,022 [INFO    ] __main__: train step 20289: loss: 0.9721, policy_loss: 0.9108, value_loss: 0.4463
2024-07-14 07:26:19,332 [INFO    ] __main__: train step 20290: loss: 0.9721, policy_loss: 0.9107, value_loss: 0.4462
2024-07-14 07:26:19,635 [INFO    ] __main__: train step 20291: loss: 0.9721, policy_loss: 0.9107, value_loss: 0.4462
2024-07-14 07:26:19,938 [INFO    ] __main__: train step 20292: loss: 0.9721, policy_loss: 0.9107, value_loss: 0.4462
2024-07-14 07:26:20,245 [INFO    ] __main__: train step 20293: loss: 0.9721, policy_loss: 0.9107, value_loss: 0.4462
2024-07-14 07:26:20,538 [INFO    ] __main__: train step 20294: loss: 0.9721, policy_loss: 0.9107, value_loss: 0.4462
2024-07-14 07:26:22,179 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:26:22,658 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:26:22,726 [INFO    ] __main__: train step 20295: loss: 0.9720, policy_loss: 0.9107, value_loss: 0.4462
2024-07-14 07:26:23,015 [INFO    ] __main__: train step 20296: loss: 0.9720, policy_loss: 0.9106, value_loss: 0.4461
2024-07-14 07:26:23,313 [INFO    ] __main__: train step 20297: loss: 0.9720, policy_loss: 0.9106, value_loss: 0.4461
2024-07-14 07:26:23,580 [INFO    ] __main__: train step 20298: loss: 0.9720, policy_loss: 0.9106, value_loss: 0.4461
2024-07-14 07:26:23,852 [INFO    ] __main__: train step 20299: loss: 0.9720, policy_loss: 0.9106, value_loss: 0.4461
2024-07-14 07:26:24,156 [INFO    ] __main__: train step 20300: loss: 0.9720, policy_loss: 0.9106, value_loss: 0.4461
2024-07-14 07:26:24,452 [INFO    ] __main__: train step 20301: loss: 0.9719, policy_loss: 0.9106, value_loss: 0.4461
2024-07-14 07:26:24,752 [INFO    ] __main__: train step 20302: loss: 0.9719, policy_loss: 0.9105, value_loss: 0.4460
2024-07-14 07:26:25,048 [INFO    ] __main__: train step 20303: loss: 0.9719, policy_loss: 0.9105, value_loss: 0.4460
2024-07-14 07:26:25,315 [INFO    ] __main__: train step 20304: loss: 0.9719, policy_loss: 0.9105, value_loss: 0.4460
2024-07-14 07:26:25,602 [INFO    ] __main__: train step 20305: loss: 0.9719, policy_loss: 0.9105, value_loss: 0.4460
2024-07-14 07:26:25,912 [INFO    ] __main__: train step 20306: loss: 0.9719, policy_loss: 0.9105, value_loss: 0.4460
2024-07-14 07:26:26,224 [INFO    ] __main__: train step 20307: loss: 0.9719, policy_loss: 0.9104, value_loss: 0.4460
2024-07-14 07:26:26,533 [INFO    ] __main__: train step 20308: loss: 0.9718, policy_loss: 0.9104, value_loss: 0.4459
2024-07-14 07:26:26,833 [INFO    ] __main__: train step 20309: loss: 0.9718, policy_loss: 0.9104, value_loss: 0.4459
2024-07-14 07:26:27,114 [INFO    ] __main__: train step 20310: loss: 0.9718, policy_loss: 0.9104, value_loss: 0.4459
2024-07-14 07:26:27,394 [INFO    ] __main__: train step 20311: loss: 0.9718, policy_loss: 0.9104, value_loss: 0.4459
2024-07-14 07:26:28,999 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:26:29,487 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:26:29,558 [INFO    ] __main__: train step 20312: loss: 0.9718, policy_loss: 0.9104, value_loss: 0.4459
2024-07-14 07:26:29,870 [INFO    ] __main__: train step 20313: loss: 0.9718, policy_loss: 0.9103, value_loss: 0.4459
2024-07-14 07:26:30,163 [INFO    ] __main__: train step 20314: loss: 0.9718, policy_loss: 0.9103, value_loss: 0.4458
2024-07-14 07:26:30,453 [INFO    ] __main__: train step 20315: loss: 0.9717, policy_loss: 0.9103, value_loss: 0.4458
2024-07-14 07:26:30,776 [INFO    ] __main__: train step 20316: loss: 0.9717, policy_loss: 0.9103, value_loss: 0.4458
2024-07-14 07:26:31,072 [INFO    ] __main__: train step 20317: loss: 0.9717, policy_loss: 0.9103, value_loss: 0.4458
2024-07-14 07:26:31,390 [INFO    ] __main__: train step 20318: loss: 0.9717, policy_loss: 0.9103, value_loss: 0.4458
2024-07-14 07:26:31,665 [INFO    ] __main__: train step 20319: loss: 0.9717, policy_loss: 0.9102, value_loss: 0.4458
2024-07-14 07:26:31,971 [INFO    ] __main__: train step 20320: loss: 0.9717, policy_loss: 0.9102, value_loss: 0.4457
2024-07-14 07:26:32,275 [INFO    ] __main__: train step 20321: loss: 0.9716, policy_loss: 0.9102, value_loss: 0.4457
2024-07-14 07:26:32,570 [INFO    ] __main__: train step 20322: loss: 0.9716, policy_loss: 0.9102, value_loss: 0.4457
2024-07-14 07:26:32,866 [INFO    ] __main__: train step 20323: loss: 0.9716, policy_loss: 0.9102, value_loss: 0.4457
2024-07-14 07:26:33,179 [INFO    ] __main__: train step 20324: loss: 0.9716, policy_loss: 0.9101, value_loss: 0.4457
2024-07-14 07:26:33,480 [INFO    ] __main__: train step 20325: loss: 0.9716, policy_loss: 0.9101, value_loss: 0.4457
2024-07-14 07:26:33,791 [INFO    ] __main__: train step 20326: loss: 0.9716, policy_loss: 0.9101, value_loss: 0.4457
2024-07-14 07:26:34,104 [INFO    ] __main__: train step 20327: loss: 0.9716, policy_loss: 0.9101, value_loss: 0.4456
2024-07-14 07:26:34,420 [INFO    ] __main__: train step 20328: loss: 0.9715, policy_loss: 0.9101, value_loss: 0.4456
2024-07-14 07:26:36,086 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:26:36,565 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:26:36,636 [INFO    ] __main__: train step 20329: loss: 0.9715, policy_loss: 0.9101, value_loss: 0.4456
2024-07-14 07:26:36,958 [INFO    ] __main__: train step 20330: loss: 0.9715, policy_loss: 0.9100, value_loss: 0.4456
2024-07-14 07:26:37,288 [INFO    ] __main__: train step 20331: loss: 0.9715, policy_loss: 0.9100, value_loss: 0.4456
2024-07-14 07:26:37,628 [INFO    ] __main__: train step 20332: loss: 0.9715, policy_loss: 0.9100, value_loss: 0.4456
2024-07-14 07:26:37,951 [INFO    ] __main__: train step 20333: loss: 0.9715, policy_loss: 0.9100, value_loss: 0.4455
2024-07-14 07:26:38,260 [INFO    ] __main__: train step 20334: loss: 0.9714, policy_loss: 0.9100, value_loss: 0.4455
2024-07-14 07:26:38,567 [INFO    ] __main__: train step 20335: loss: 0.9714, policy_loss: 0.9099, value_loss: 0.4455
2024-07-14 07:26:38,844 [INFO    ] __main__: train step 20336: loss: 0.9714, policy_loss: 0.9099, value_loss: 0.4455
2024-07-14 07:26:39,144 [INFO    ] __main__: train step 20337: loss: 0.9714, policy_loss: 0.9099, value_loss: 0.4455
2024-07-14 07:26:39,444 [INFO    ] __main__: train step 20338: loss: 0.9714, policy_loss: 0.9099, value_loss: 0.4455
2024-07-14 07:26:39,737 [INFO    ] __main__: train step 20339: loss: 0.9714, policy_loss: 0.9099, value_loss: 0.4454
2024-07-14 07:26:40,039 [INFO    ] __main__: train step 20340: loss: 0.9714, policy_loss: 0.9099, value_loss: 0.4454
2024-07-14 07:26:40,346 [INFO    ] __main__: train step 20341: loss: 0.9713, policy_loss: 0.9098, value_loss: 0.4454
2024-07-14 07:26:40,651 [INFO    ] __main__: train step 20342: loss: 0.9713, policy_loss: 0.9098, value_loss: 0.4454
2024-07-14 07:26:40,981 [INFO    ] __main__: train step 20343: loss: 0.9713, policy_loss: 0.9098, value_loss: 0.4454
2024-07-14 07:26:41,289 [INFO    ] __main__: train step 20344: loss: 0.9713, policy_loss: 0.9098, value_loss: 0.4454
2024-07-14 07:26:41,624 [INFO    ] __main__: train step 20345: loss: 0.9713, policy_loss: 0.9098, value_loss: 0.4453
2024-07-14 07:26:43,297 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:26:43,793 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:26:43,867 [INFO    ] __main__: train step 20346: loss: 0.9713, policy_loss: 0.9098, value_loss: 0.4453
2024-07-14 07:26:44,189 [INFO    ] __main__: train step 20347: loss: 0.9713, policy_loss: 0.9097, value_loss: 0.4453
2024-07-14 07:26:44,475 [INFO    ] __main__: train step 20348: loss: 0.9712, policy_loss: 0.9097, value_loss: 0.4453
2024-07-14 07:26:44,794 [INFO    ] __main__: train step 20349: loss: 0.9712, policy_loss: 0.9097, value_loss: 0.4453
2024-07-14 07:26:45,097 [INFO    ] __main__: train step 20350: loss: 0.9712, policy_loss: 0.9097, value_loss: 0.4453
2024-07-14 07:26:45,386 [INFO    ] __main__: train step 20351: loss: 0.9712, policy_loss: 0.9097, value_loss: 0.4452
2024-07-14 07:26:45,702 [INFO    ] __main__: train step 20352: loss: 0.9712, policy_loss: 0.9096, value_loss: 0.4452
2024-07-14 07:26:46,012 [INFO    ] __main__: train step 20353: loss: 0.9712, policy_loss: 0.9096, value_loss: 0.4452
2024-07-14 07:26:46,316 [INFO    ] __main__: train step 20354: loss: 0.9711, policy_loss: 0.9096, value_loss: 0.4452
2024-07-14 07:26:46,618 [INFO    ] __main__: train step 20355: loss: 0.9711, policy_loss: 0.9096, value_loss: 0.4452
2024-07-14 07:26:46,918 [INFO    ] __main__: train step 20356: loss: 0.9711, policy_loss: 0.9096, value_loss: 0.4452
2024-07-14 07:26:47,252 [INFO    ] __main__: train step 20357: loss: 0.9711, policy_loss: 0.9096, value_loss: 0.4451
2024-07-14 07:26:47,568 [INFO    ] __main__: train step 20358: loss: 0.9711, policy_loss: 0.9095, value_loss: 0.4451
2024-07-14 07:26:47,868 [INFO    ] __main__: train step 20359: loss: 0.9711, policy_loss: 0.9095, value_loss: 0.4451
2024-07-14 07:26:48,173 [INFO    ] __main__: train step 20360: loss: 0.9711, policy_loss: 0.9095, value_loss: 0.4451
2024-07-14 07:26:48,446 [INFO    ] __main__: train step 20361: loss: 0.9710, policy_loss: 0.9095, value_loss: 0.4451
2024-07-14 07:26:48,726 [INFO    ] __main__: train step 20362: loss: 0.9710, policy_loss: 0.9095, value_loss: 0.4451
2024-07-14 07:26:50,366 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:26:50,848 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:26:50,923 [INFO    ] __main__: train step 20363: loss: 0.9710, policy_loss: 0.9095, value_loss: 0.4450
2024-07-14 07:26:51,212 [INFO    ] __main__: train step 20364: loss: 0.9710, policy_loss: 0.9094, value_loss: 0.4450
2024-07-14 07:26:51,493 [INFO    ] __main__: train step 20365: loss: 0.9710, policy_loss: 0.9094, value_loss: 0.4450
2024-07-14 07:26:51,807 [INFO    ] __main__: train step 20366: loss: 0.9710, policy_loss: 0.9094, value_loss: 0.4450
2024-07-14 07:26:52,103 [INFO    ] __main__: train step 20367: loss: 0.9710, policy_loss: 0.9094, value_loss: 0.4450
2024-07-14 07:26:52,410 [INFO    ] __main__: train step 20368: loss: 0.9709, policy_loss: 0.9094, value_loss: 0.4450
2024-07-14 07:26:52,700 [INFO    ] __main__: train step 20369: loss: 0.9709, policy_loss: 0.9093, value_loss: 0.4450
2024-07-14 07:26:53,002 [INFO    ] __main__: train step 20370: loss: 0.9709, policy_loss: 0.9093, value_loss: 0.4449
2024-07-14 07:26:53,307 [INFO    ] __main__: train step 20371: loss: 0.9709, policy_loss: 0.9093, value_loss: 0.4449
2024-07-14 07:26:53,609 [INFO    ] __main__: train step 20372: loss: 0.9709, policy_loss: 0.9093, value_loss: 0.4449
2024-07-14 07:26:53,908 [INFO    ] __main__: train step 20373: loss: 0.9709, policy_loss: 0.9093, value_loss: 0.4449
2024-07-14 07:26:54,185 [INFO    ] __main__: train step 20374: loss: 0.9708, policy_loss: 0.9093, value_loss: 0.4449
2024-07-14 07:26:54,494 [INFO    ] __main__: train step 20375: loss: 0.9708, policy_loss: 0.9092, value_loss: 0.4449
2024-07-14 07:26:54,785 [INFO    ] __main__: train step 20376: loss: 0.9708, policy_loss: 0.9092, value_loss: 0.4448
2024-07-14 07:26:55,075 [INFO    ] __main__: train step 20377: loss: 0.9708, policy_loss: 0.9092, value_loss: 0.4448
2024-07-14 07:26:55,409 [INFO    ] __main__: train step 20378: loss: 0.9708, policy_loss: 0.9092, value_loss: 0.4448
2024-07-14 07:27:00,253 [INFO    ] __main__: train step 20379: loss: 0.9708, policy_loss: 0.9092, value_loss: 0.4448
2024-07-14 07:27:01,885 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:27:02,351 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:27:02,424 [INFO    ] __main__: train step 20380: loss: 0.9708, policy_loss: 0.9092, value_loss: 0.4448
2024-07-14 07:27:02,710 [INFO    ] __main__: train step 20381: loss: 0.9707, policy_loss: 0.9091, value_loss: 0.4448
2024-07-14 07:27:03,005 [INFO    ] __main__: train step 20382: loss: 0.9707, policy_loss: 0.9091, value_loss: 0.4447
2024-07-14 07:27:03,293 [INFO    ] __main__: train step 20383: loss: 0.9707, policy_loss: 0.9091, value_loss: 0.4447
2024-07-14 07:27:03,568 [INFO    ] __main__: train step 20384: loss: 0.9707, policy_loss: 0.9091, value_loss: 0.4447
2024-07-14 07:27:03,868 [INFO    ] __main__: train step 20385: loss: 0.9707, policy_loss: 0.9091, value_loss: 0.4447
2024-07-14 07:27:04,165 [INFO    ] __main__: train step 20386: loss: 0.9707, policy_loss: 0.9091, value_loss: 0.4447
2024-07-14 07:27:04,458 [INFO    ] __main__: train step 20387: loss: 0.9706, policy_loss: 0.9090, value_loss: 0.4447
2024-07-14 07:27:04,778 [INFO    ] __main__: train step 20388: loss: 0.9706, policy_loss: 0.9090, value_loss: 0.4446
2024-07-14 07:27:05,082 [INFO    ] __main__: train step 20389: loss: 0.9706, policy_loss: 0.9090, value_loss: 0.4446
2024-07-14 07:27:05,347 [INFO    ] __main__: train step 20390: loss: 0.9706, policy_loss: 0.9090, value_loss: 0.4446
2024-07-14 07:27:05,607 [INFO    ] __main__: train step 20391: loss: 0.9706, policy_loss: 0.9090, value_loss: 0.4446
2024-07-14 07:27:05,870 [INFO    ] __main__: train step 20392: loss: 0.9706, policy_loss: 0.9089, value_loss: 0.4446
2024-07-14 07:27:06,164 [INFO    ] __main__: train step 20393: loss: 0.9706, policy_loss: 0.9089, value_loss: 0.4446
2024-07-14 07:27:06,451 [INFO    ] __main__: train step 20394: loss: 0.9705, policy_loss: 0.9089, value_loss: 0.4445
2024-07-14 07:27:06,728 [INFO    ] __main__: train step 20395: loss: 0.9705, policy_loss: 0.9089, value_loss: 0.4445
2024-07-14 07:27:06,997 [INFO    ] __main__: train step 20396: loss: 0.9705, policy_loss: 0.9089, value_loss: 0.4445
2024-07-14 07:27:08,624 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:27:09,103 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:27:09,173 [INFO    ] __main__: train step 20397: loss: 0.9705, policy_loss: 0.9089, value_loss: 0.4445
2024-07-14 07:27:09,459 [INFO    ] __main__: train step 20398: loss: 0.9705, policy_loss: 0.9088, value_loss: 0.4445
2024-07-14 07:27:09,746 [INFO    ] __main__: train step 20399: loss: 0.9705, policy_loss: 0.9088, value_loss: 0.4445
2024-07-14 07:27:10,036 [INFO    ] __main__: train step 20400: loss: 0.9705, policy_loss: 0.9088, value_loss: 0.4444
2024-07-14 07:27:10,332 [INFO    ] __main__: train step 20401: loss: 0.9704, policy_loss: 0.9088, value_loss: 0.4444
2024-07-14 07:27:10,631 [INFO    ] __main__: train step 20402: loss: 0.9704, policy_loss: 0.9088, value_loss: 0.4444
2024-07-14 07:27:10,935 [INFO    ] __main__: train step 20403: loss: 0.9704, policy_loss: 0.9088, value_loss: 0.4444
2024-07-14 07:27:11,234 [INFO    ] __main__: train step 20404: loss: 0.9704, policy_loss: 0.9087, value_loss: 0.4444
2024-07-14 07:27:11,514 [INFO    ] __main__: train step 20405: loss: 0.9704, policy_loss: 0.9087, value_loss: 0.4444
2024-07-14 07:27:11,798 [INFO    ] __main__: train step 20406: loss: 0.9704, policy_loss: 0.9087, value_loss: 0.4443
2024-07-14 07:27:12,096 [INFO    ] __main__: train step 20407: loss: 0.9704, policy_loss: 0.9087, value_loss: 0.4443
2024-07-14 07:27:12,392 [INFO    ] __main__: train step 20408: loss: 0.9703, policy_loss: 0.9087, value_loss: 0.4443
2024-07-14 07:27:12,685 [INFO    ] __main__: train step 20409: loss: 0.9703, policy_loss: 0.9087, value_loss: 0.4443
2024-07-14 07:27:12,989 [INFO    ] __main__: train step 20410: loss: 0.9703, policy_loss: 0.9086, value_loss: 0.4443
2024-07-14 07:27:13,235 [INFO    ] __main__: train step 20411: loss: 0.9703, policy_loss: 0.9086, value_loss: 0.4443
2024-07-14 07:27:13,510 [INFO    ] __main__: train step 20412: loss: 0.9703, policy_loss: 0.9086, value_loss: 0.4443
2024-07-14 07:27:13,809 [INFO    ] __main__: train step 20413: loss: 0.9703, policy_loss: 0.9086, value_loss: 0.4442
2024-07-14 07:27:15,423 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:27:15,894 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:27:15,961 [INFO    ] __main__: train step 20414: loss: 0.9702, policy_loss: 0.9086, value_loss: 0.4442
2024-07-14 07:27:16,252 [INFO    ] __main__: train step 20415: loss: 0.9702, policy_loss: 0.9085, value_loss: 0.4442
2024-07-14 07:27:16,562 [INFO    ] __main__: train step 20416: loss: 0.9702, policy_loss: 0.9085, value_loss: 0.4442
2024-07-14 07:27:16,853 [INFO    ] __main__: train step 20417: loss: 0.9702, policy_loss: 0.9085, value_loss: 0.4442
2024-07-14 07:27:17,165 [INFO    ] __main__: train step 20418: loss: 0.9702, policy_loss: 0.9085, value_loss: 0.4442
2024-07-14 07:27:17,481 [INFO    ] __main__: train step 20419: loss: 0.9702, policy_loss: 0.9085, value_loss: 0.4441
2024-07-14 07:27:17,782 [INFO    ] __main__: train step 20420: loss: 0.9702, policy_loss: 0.9085, value_loss: 0.4441
2024-07-14 07:27:18,073 [INFO    ] __main__: train step 20421: loss: 0.9701, policy_loss: 0.9084, value_loss: 0.4441
2024-07-14 07:27:18,345 [INFO    ] __main__: train step 20422: loss: 0.9701, policy_loss: 0.9084, value_loss: 0.4441
2024-07-14 07:27:18,661 [INFO    ] __main__: train step 20423: loss: 0.9701, policy_loss: 0.9084, value_loss: 0.4441
2024-07-14 07:27:18,960 [INFO    ] __main__: train step 20424: loss: 0.9701, policy_loss: 0.9084, value_loss: 0.4441
2024-07-14 07:27:19,272 [INFO    ] __main__: train step 20425: loss: 0.9701, policy_loss: 0.9084, value_loss: 0.4440
2024-07-14 07:27:19,564 [INFO    ] __main__: train step 20426: loss: 0.9701, policy_loss: 0.9084, value_loss: 0.4440
2024-07-14 07:27:19,845 [INFO    ] __main__: train step 20427: loss: 0.9701, policy_loss: 0.9083, value_loss: 0.4440
2024-07-14 07:27:20,130 [INFO    ] __main__: train step 20428: loss: 0.9700, policy_loss: 0.9083, value_loss: 0.4440
2024-07-14 07:27:20,405 [INFO    ] __main__: train step 20429: loss: 0.9700, policy_loss: 0.9083, value_loss: 0.4440
2024-07-14 07:27:20,699 [INFO    ] __main__: train step 20430: loss: 0.9700, policy_loss: 0.9083, value_loss: 0.4440
2024-07-14 07:27:22,337 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:27:22,798 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:27:22,867 [INFO    ] __main__: train step 20431: loss: 0.9700, policy_loss: 0.9083, value_loss: 0.4439
2024-07-14 07:27:23,158 [INFO    ] __main__: train step 20432: loss: 0.9700, policy_loss: 0.9082, value_loss: 0.4439
2024-07-14 07:27:23,448 [INFO    ] __main__: train step 20433: loss: 0.9700, policy_loss: 0.9082, value_loss: 0.4439
2024-07-14 07:27:23,741 [INFO    ] __main__: train step 20434: loss: 0.9700, policy_loss: 0.9082, value_loss: 0.4439
2024-07-14 07:27:24,032 [INFO    ] __main__: train step 20435: loss: 0.9699, policy_loss: 0.9082, value_loss: 0.4439
2024-07-14 07:27:24,321 [INFO    ] __main__: train step 20436: loss: 0.9699, policy_loss: 0.9082, value_loss: 0.4439
2024-07-14 07:27:24,613 [INFO    ] __main__: train step 20437: loss: 0.9699, policy_loss: 0.9082, value_loss: 0.4438
2024-07-14 07:27:24,928 [INFO    ] __main__: train step 20438: loss: 0.9699, policy_loss: 0.9081, value_loss: 0.4438
2024-07-14 07:27:25,229 [INFO    ] __main__: train step 20439: loss: 0.9699, policy_loss: 0.9081, value_loss: 0.4438
2024-07-14 07:27:25,532 [INFO    ] __main__: train step 20440: loss: 0.9699, policy_loss: 0.9081, value_loss: 0.4438
2024-07-14 07:27:25,850 [INFO    ] __main__: train step 20441: loss: 0.9698, policy_loss: 0.9081, value_loss: 0.4438
2024-07-14 07:27:26,165 [INFO    ] __main__: train step 20442: loss: 0.9698, policy_loss: 0.9081, value_loss: 0.4438
2024-07-14 07:27:26,466 [INFO    ] __main__: train step 20443: loss: 0.9698, policy_loss: 0.9081, value_loss: 0.4437
2024-07-14 07:27:26,761 [INFO    ] __main__: train step 20444: loss: 0.9698, policy_loss: 0.9080, value_loss: 0.4437
2024-07-14 07:27:27,048 [INFO    ] __main__: train step 20445: loss: 0.9698, policy_loss: 0.9080, value_loss: 0.4437
2024-07-14 07:27:27,342 [INFO    ] __main__: train step 20446: loss: 0.9698, policy_loss: 0.9080, value_loss: 0.4437
2024-07-14 07:27:27,644 [INFO    ] __main__: train step 20447: loss: 0.9698, policy_loss: 0.9080, value_loss: 0.4437
2024-07-14 07:27:29,267 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:27:29,714 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:27:29,789 [INFO    ] __main__: train step 20448: loss: 0.9697, policy_loss: 0.9080, value_loss: 0.4437
2024-07-14 07:27:30,084 [INFO    ] __main__: train step 20449: loss: 0.9697, policy_loss: 0.9080, value_loss: 0.4437
2024-07-14 07:27:30,381 [INFO    ] __main__: train step 20450: loss: 0.9697, policy_loss: 0.9079, value_loss: 0.4436
2024-07-14 07:27:30,665 [INFO    ] __main__: train step 20451: loss: 0.9697, policy_loss: 0.9079, value_loss: 0.4436
2024-07-14 07:27:30,940 [INFO    ] __main__: train step 20452: loss: 0.9697, policy_loss: 0.9079, value_loss: 0.4436
2024-07-14 07:27:31,195 [INFO    ] __main__: train step 20453: loss: 0.9697, policy_loss: 0.9079, value_loss: 0.4436
2024-07-14 07:27:31,463 [INFO    ] __main__: train step 20454: loss: 0.9697, policy_loss: 0.9079, value_loss: 0.4436
2024-07-14 07:27:31,745 [INFO    ] __main__: train step 20455: loss: 0.9696, policy_loss: 0.9078, value_loss: 0.4436
2024-07-14 07:27:32,046 [INFO    ] __main__: train step 20456: loss: 0.9696, policy_loss: 0.9078, value_loss: 0.4435
2024-07-14 07:27:32,363 [INFO    ] __main__: train step 20457: loss: 0.9696, policy_loss: 0.9078, value_loss: 0.4435
2024-07-14 07:27:32,624 [INFO    ] __main__: train step 20458: loss: 0.9696, policy_loss: 0.9078, value_loss: 0.4435
2024-07-14 07:27:32,916 [INFO    ] __main__: train step 20459: loss: 0.9696, policy_loss: 0.9078, value_loss: 0.4435
2024-07-14 07:27:33,208 [INFO    ] __main__: train step 20460: loss: 0.9696, policy_loss: 0.9078, value_loss: 0.4435
2024-07-14 07:27:33,508 [INFO    ] __main__: train step 20461: loss: 0.9695, policy_loss: 0.9077, value_loss: 0.4435
2024-07-14 07:27:33,815 [INFO    ] __main__: train step 20462: loss: 0.9695, policy_loss: 0.9077, value_loss: 0.4434
2024-07-14 07:27:34,130 [INFO    ] __main__: train step 20463: loss: 0.9695, policy_loss: 0.9077, value_loss: 0.4434
2024-07-14 07:27:34,426 [INFO    ] __main__: train step 20464: loss: 0.9695, policy_loss: 0.9077, value_loss: 0.4434
2024-07-14 07:27:36,034 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:27:36,504 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:27:36,572 [INFO    ] __main__: train step 20465: loss: 0.9695, policy_loss: 0.9077, value_loss: 0.4434
2024-07-14 07:27:36,867 [INFO    ] __main__: train step 20466: loss: 0.9695, policy_loss: 0.9077, value_loss: 0.4434
2024-07-14 07:27:37,185 [INFO    ] __main__: train step 20467: loss: 0.9695, policy_loss: 0.9076, value_loss: 0.4434
2024-07-14 07:27:37,441 [INFO    ] __main__: train step 20468: loss: 0.9694, policy_loss: 0.9076, value_loss: 0.4433
2024-07-14 07:27:37,737 [INFO    ] __main__: train step 20469: loss: 0.9694, policy_loss: 0.9076, value_loss: 0.4433
2024-07-14 07:27:38,041 [INFO    ] __main__: train step 20470: loss: 0.9694, policy_loss: 0.9076, value_loss: 0.4433
2024-07-14 07:27:38,341 [INFO    ] __main__: train step 20471: loss: 0.9694, policy_loss: 0.9076, value_loss: 0.4433
2024-07-14 07:27:38,651 [INFO    ] __main__: train step 20472: loss: 0.9694, policy_loss: 0.9076, value_loss: 0.4433
2024-07-14 07:27:38,920 [INFO    ] __main__: train step 20473: loss: 0.9694, policy_loss: 0.9075, value_loss: 0.4433
2024-07-14 07:27:39,207 [INFO    ] __main__: train step 20474: loss: 0.9694, policy_loss: 0.9075, value_loss: 0.4432
2024-07-14 07:27:39,523 [INFO    ] __main__: train step 20475: loss: 0.9693, policy_loss: 0.9075, value_loss: 0.4432
2024-07-14 07:27:39,828 [INFO    ] __main__: train step 20476: loss: 0.9693, policy_loss: 0.9075, value_loss: 0.4432
2024-07-14 07:27:40,132 [INFO    ] __main__: train step 20477: loss: 0.9693, policy_loss: 0.9075, value_loss: 0.4432
2024-07-14 07:27:40,423 [INFO    ] __main__: train step 20478: loss: 0.9693, policy_loss: 0.9075, value_loss: 0.4432
2024-07-14 07:27:40,733 [INFO    ] __main__: train step 20479: loss: 0.9693, policy_loss: 0.9074, value_loss: 0.4432
2024-07-14 07:27:41,030 [INFO    ] __main__: train step 20480: loss: 0.9693, policy_loss: 0.9074, value_loss: 0.4431
2024-07-14 07:27:41,314 [INFO    ] __main__: train step 20481: loss: 0.9693, policy_loss: 0.9074, value_loss: 0.4431
2024-07-14 07:27:42,942 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:27:43,398 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:27:43,471 [INFO    ] __main__: train step 20482: loss: 0.9692, policy_loss: 0.9074, value_loss: 0.4431
2024-07-14 07:27:43,767 [INFO    ] __main__: train step 20483: loss: 0.9692, policy_loss: 0.9074, value_loss: 0.4431
2024-07-14 07:27:44,058 [INFO    ] __main__: train step 20484: loss: 0.9692, policy_loss: 0.9074, value_loss: 0.4431
2024-07-14 07:27:44,339 [INFO    ] __main__: train step 20485: loss: 0.9692, policy_loss: 0.9073, value_loss: 0.4431
2024-07-14 07:27:44,617 [INFO    ] __main__: train step 20486: loss: 0.9692, policy_loss: 0.9073, value_loss: 0.4431
2024-07-14 07:27:44,906 [INFO    ] __main__: train step 20487: loss: 0.9692, policy_loss: 0.9073, value_loss: 0.4430
2024-07-14 07:27:45,193 [INFO    ] __main__: train step 20488: loss: 0.9692, policy_loss: 0.9073, value_loss: 0.4430
2024-07-14 07:27:45,487 [INFO    ] __main__: train step 20489: loss: 0.9691, policy_loss: 0.9073, value_loss: 0.4430
2024-07-14 07:27:45,786 [INFO    ] __main__: train step 20490: loss: 0.9691, policy_loss: 0.9073, value_loss: 0.4430
2024-07-14 07:27:46,095 [INFO    ] __main__: train step 20491: loss: 0.9691, policy_loss: 0.9072, value_loss: 0.4430
2024-07-14 07:27:46,400 [INFO    ] __main__: train step 20492: loss: 0.9691, policy_loss: 0.9072, value_loss: 0.4430
2024-07-14 07:27:46,679 [INFO    ] __main__: train step 20493: loss: 0.9691, policy_loss: 0.9072, value_loss: 0.4429
2024-07-14 07:27:46,979 [INFO    ] __main__: train step 20494: loss: 0.9691, policy_loss: 0.9072, value_loss: 0.4429
2024-07-14 07:27:47,290 [INFO    ] __main__: train step 20495: loss: 0.9690, policy_loss: 0.9072, value_loss: 0.4429
2024-07-14 07:27:47,580 [INFO    ] __main__: train step 20496: loss: 0.9690, policy_loss: 0.9071, value_loss: 0.4429
2024-07-14 07:27:47,885 [INFO    ] __main__: train step 20497: loss: 0.9690, policy_loss: 0.9071, value_loss: 0.4429
2024-07-14 07:27:48,202 [INFO    ] __main__: train step 20498: loss: 0.9690, policy_loss: 0.9071, value_loss: 0.4429
2024-07-14 07:27:49,789 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:27:50,247 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:27:50,315 [INFO    ] __main__: train step 20499: loss: 0.9690, policy_loss: 0.9071, value_loss: 0.4428
2024-07-14 07:27:50,617 [INFO    ] __main__: train step 20500: loss: 0.9690, policy_loss: 0.9071, value_loss: 0.4428
2024-07-14 07:27:50,917 [INFO    ] __main__: train step 20501: loss: 0.9690, policy_loss: 0.9071, value_loss: 0.4428
2024-07-14 07:27:51,204 [INFO    ] __main__: train step 20502: loss: 0.9689, policy_loss: 0.9070, value_loss: 0.4428
2024-07-14 07:27:51,478 [INFO    ] __main__: train step 20503: loss: 0.9689, policy_loss: 0.9070, value_loss: 0.4428
2024-07-14 07:27:51,772 [INFO    ] __main__: train step 20504: loss: 0.9689, policy_loss: 0.9070, value_loss: 0.4428
2024-07-14 07:27:52,073 [INFO    ] __main__: train step 20505: loss: 0.9689, policy_loss: 0.9070, value_loss: 0.4427
2024-07-14 07:27:52,366 [INFO    ] __main__: train step 20506: loss: 0.9689, policy_loss: 0.9070, value_loss: 0.4427
2024-07-14 07:27:52,665 [INFO    ] __main__: train step 20507: loss: 0.9689, policy_loss: 0.9070, value_loss: 0.4427
2024-07-14 07:27:57,469 [INFO    ] __main__: train step 20508: loss: 0.9689, policy_loss: 0.9069, value_loss: 0.4427
2024-07-14 07:27:57,761 [INFO    ] __main__: train step 20509: loss: 0.9688, policy_loss: 0.9069, value_loss: 0.4427
2024-07-14 07:27:58,059 [INFO    ] __main__: train step 20510: loss: 0.9688, policy_loss: 0.9069, value_loss: 0.4427
2024-07-14 07:27:58,352 [INFO    ] __main__: train step 20511: loss: 0.9688, policy_loss: 0.9069, value_loss: 0.4426
2024-07-14 07:27:58,645 [INFO    ] __main__: train step 20512: loss: 0.9688, policy_loss: 0.9069, value_loss: 0.4426
2024-07-14 07:27:58,949 [INFO    ] __main__: train step 20513: loss: 0.9688, policy_loss: 0.9069, value_loss: 0.4426
2024-07-14 07:27:59,265 [INFO    ] __main__: train step 20514: loss: 0.9688, policy_loss: 0.9068, value_loss: 0.4426
2024-07-14 07:27:59,561 [INFO    ] __main__: train step 20515: loss: 0.9688, policy_loss: 0.9068, value_loss: 0.4426
2024-07-14 07:28:01,189 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:28:01,659 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:28:01,726 [INFO    ] __main__: train step 20516: loss: 0.9687, policy_loss: 0.9068, value_loss: 0.4426
2024-07-14 07:28:02,035 [INFO    ] __main__: train step 20517: loss: 0.9687, policy_loss: 0.9068, value_loss: 0.4425
2024-07-14 07:28:02,333 [INFO    ] __main__: train step 20518: loss: 0.9687, policy_loss: 0.9068, value_loss: 0.4425
2024-07-14 07:28:02,600 [INFO    ] __main__: train step 20519: loss: 0.9687, policy_loss: 0.9068, value_loss: 0.4425
2024-07-14 07:28:02,860 [INFO    ] __main__: train step 20520: loss: 0.9687, policy_loss: 0.9067, value_loss: 0.4425
2024-07-14 07:28:03,136 [INFO    ] __main__: train step 20521: loss: 0.9687, policy_loss: 0.9067, value_loss: 0.4425
2024-07-14 07:28:03,430 [INFO    ] __main__: train step 20522: loss: 0.9686, policy_loss: 0.9067, value_loss: 0.4425
2024-07-14 07:28:03,734 [INFO    ] __main__: train step 20523: loss: 0.9686, policy_loss: 0.9067, value_loss: 0.4424
2024-07-14 07:28:04,015 [INFO    ] __main__: train step 20524: loss: 0.9686, policy_loss: 0.9067, value_loss: 0.4424
2024-07-14 07:28:04,308 [INFO    ] __main__: train step 20525: loss: 0.9686, policy_loss: 0.9067, value_loss: 0.4424
2024-07-14 07:28:04,605 [INFO    ] __main__: train step 20526: loss: 0.9686, policy_loss: 0.9066, value_loss: 0.4424
2024-07-14 07:28:04,902 [INFO    ] __main__: train step 20527: loss: 0.9686, policy_loss: 0.9066, value_loss: 0.4424
2024-07-14 07:28:05,196 [INFO    ] __main__: train step 20528: loss: 0.9686, policy_loss: 0.9066, value_loss: 0.4424
2024-07-14 07:28:05,504 [INFO    ] __main__: train step 20529: loss: 0.9685, policy_loss: 0.9066, value_loss: 0.4424
2024-07-14 07:28:05,782 [INFO    ] __main__: train step 20530: loss: 0.9685, policy_loss: 0.9066, value_loss: 0.4423
2024-07-14 07:28:06,091 [INFO    ] __main__: train step 20531: loss: 0.9685, policy_loss: 0.9066, value_loss: 0.4423
2024-07-14 07:28:06,409 [INFO    ] __main__: train step 20532: loss: 0.9685, policy_loss: 0.9065, value_loss: 0.4423
2024-07-14 07:28:08,018 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:28:08,516 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:28:08,588 [INFO    ] __main__: train step 20533: loss: 0.9685, policy_loss: 0.9065, value_loss: 0.4423
2024-07-14 07:28:08,887 [INFO    ] __main__: train step 20534: loss: 0.9685, policy_loss: 0.9065, value_loss: 0.4423
2024-07-14 07:28:09,139 [INFO    ] __main__: train step 20535: loss: 0.9685, policy_loss: 0.9065, value_loss: 0.4423
2024-07-14 07:28:09,432 [INFO    ] __main__: train step 20536: loss: 0.9684, policy_loss: 0.9065, value_loss: 0.4422
2024-07-14 07:28:09,727 [INFO    ] __main__: train step 20537: loss: 0.9684, policy_loss: 0.9065, value_loss: 0.4422
2024-07-14 07:28:10,021 [INFO    ] __main__: train step 20538: loss: 0.9684, policy_loss: 0.9064, value_loss: 0.4422
2024-07-14 07:28:10,325 [INFO    ] __main__: train step 20539: loss: 0.9684, policy_loss: 0.9064, value_loss: 0.4422
2024-07-14 07:28:10,594 [INFO    ] __main__: train step 20540: loss: 0.9684, policy_loss: 0.9064, value_loss: 0.4422
2024-07-14 07:28:10,895 [INFO    ] __main__: train step 20541: loss: 0.9684, policy_loss: 0.9064, value_loss: 0.4422
2024-07-14 07:28:11,177 [INFO    ] __main__: train step 20542: loss: 0.9684, policy_loss: 0.9064, value_loss: 0.4421
2024-07-14 07:28:11,456 [INFO    ] __main__: train step 20543: loss: 0.9683, policy_loss: 0.9063, value_loss: 0.4421
2024-07-14 07:28:11,754 [INFO    ] __main__: train step 20544: loss: 0.9683, policy_loss: 0.9063, value_loss: 0.4421
2024-07-14 07:28:12,053 [INFO    ] __main__: train step 20545: loss: 0.9683, policy_loss: 0.9063, value_loss: 0.4421
2024-07-14 07:28:12,322 [INFO    ] __main__: train step 20546: loss: 0.9683, policy_loss: 0.9063, value_loss: 0.4421
2024-07-14 07:28:12,617 [INFO    ] __main__: train step 20547: loss: 0.9683, policy_loss: 0.9063, value_loss: 0.4421
2024-07-14 07:28:12,918 [INFO    ] __main__: train step 20548: loss: 0.9683, policy_loss: 0.9063, value_loss: 0.4420
2024-07-14 07:28:13,227 [INFO    ] __main__: train step 20549: loss: 0.9683, policy_loss: 0.9062, value_loss: 0.4420
2024-07-14 07:28:14,883 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:28:15,372 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:28:15,444 [INFO    ] __main__: train step 20550: loss: 0.9682, policy_loss: 0.9062, value_loss: 0.4420
2024-07-14 07:28:15,738 [INFO    ] __main__: train step 20551: loss: 0.9682, policy_loss: 0.9062, value_loss: 0.4420
2024-07-14 07:28:16,030 [INFO    ] __main__: train step 20552: loss: 0.9682, policy_loss: 0.9062, value_loss: 0.4420
2024-07-14 07:28:16,328 [INFO    ] __main__: train step 20553: loss: 0.9682, policy_loss: 0.9062, value_loss: 0.4420
2024-07-14 07:28:16,636 [INFO    ] __main__: train step 20554: loss: 0.9682, policy_loss: 0.9062, value_loss: 0.4419
2024-07-14 07:28:16,916 [INFO    ] __main__: train step 20555: loss: 0.9682, policy_loss: 0.9061, value_loss: 0.4419
2024-07-14 07:28:17,211 [INFO    ] __main__: train step 20556: loss: 0.9682, policy_loss: 0.9061, value_loss: 0.4419
2024-07-14 07:28:17,505 [INFO    ] __main__: train step 20557: loss: 0.9681, policy_loss: 0.9061, value_loss: 0.4419
2024-07-14 07:28:17,782 [INFO    ] __main__: train step 20558: loss: 0.9681, policy_loss: 0.9061, value_loss: 0.4419
2024-07-14 07:28:18,068 [INFO    ] __main__: train step 20559: loss: 0.9681, policy_loss: 0.9061, value_loss: 0.4419
2024-07-14 07:28:18,352 [INFO    ] __main__: train step 20560: loss: 0.9681, policy_loss: 0.9061, value_loss: 0.4419
2024-07-14 07:28:18,639 [INFO    ] __main__: train step 20561: loss: 0.9681, policy_loss: 0.9060, value_loss: 0.4418
2024-07-14 07:28:18,932 [INFO    ] __main__: train step 20562: loss: 0.9681, policy_loss: 0.9060, value_loss: 0.4418
2024-07-14 07:28:19,230 [INFO    ] __main__: train step 20563: loss: 0.9681, policy_loss: 0.9060, value_loss: 0.4418
2024-07-14 07:28:19,532 [INFO    ] __main__: train step 20564: loss: 0.9680, policy_loss: 0.9060, value_loss: 0.4418
2024-07-14 07:28:19,836 [INFO    ] __main__: train step 20565: loss: 0.9680, policy_loss: 0.9060, value_loss: 0.4418
2024-07-14 07:28:20,129 [INFO    ] __main__: train step 20566: loss: 0.9680, policy_loss: 0.9060, value_loss: 0.4418
2024-07-14 07:28:21,743 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:28:22,215 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:28:22,283 [INFO    ] __main__: train step 20567: loss: 0.9680, policy_loss: 0.9059, value_loss: 0.4417
2024-07-14 07:28:22,575 [INFO    ] __main__: train step 20568: loss: 0.9680, policy_loss: 0.9059, value_loss: 0.4417
2024-07-14 07:28:22,907 [INFO    ] __main__: train step 20569: loss: 0.9680, policy_loss: 0.9059, value_loss: 0.4417
2024-07-14 07:28:23,176 [INFO    ] __main__: train step 20570: loss: 0.9680, policy_loss: 0.9059, value_loss: 0.4417
2024-07-14 07:28:23,458 [INFO    ] __main__: train step 20571: loss: 0.9679, policy_loss: 0.9059, value_loss: 0.4417
2024-07-14 07:28:23,770 [INFO    ] __main__: train step 20572: loss: 0.9679, policy_loss: 0.9059, value_loss: 0.4417
2024-07-14 07:28:24,083 [INFO    ] __main__: train step 20573: loss: 0.9679, policy_loss: 0.9058, value_loss: 0.4416
2024-07-14 07:28:24,391 [INFO    ] __main__: train step 20574: loss: 0.9679, policy_loss: 0.9058, value_loss: 0.4416
2024-07-14 07:28:24,683 [INFO    ] __main__: train step 20575: loss: 0.9679, policy_loss: 0.9058, value_loss: 0.4416
2024-07-14 07:28:24,962 [INFO    ] __main__: train step 20576: loss: 0.9679, policy_loss: 0.9058, value_loss: 0.4416
2024-07-14 07:28:25,256 [INFO    ] __main__: train step 20577: loss: 0.9678, policy_loss: 0.9058, value_loss: 0.4416
2024-07-14 07:28:25,560 [INFO    ] __main__: train step 20578: loss: 0.9678, policy_loss: 0.9058, value_loss: 0.4416
2024-07-14 07:28:25,879 [INFO    ] __main__: train step 20579: loss: 0.9678, policy_loss: 0.9057, value_loss: 0.4415
2024-07-14 07:28:26,182 [INFO    ] __main__: train step 20580: loss: 0.9678, policy_loss: 0.9057, value_loss: 0.4415
2024-07-14 07:28:26,481 [INFO    ] __main__: train step 20581: loss: 0.9678, policy_loss: 0.9057, value_loss: 0.4415
2024-07-14 07:28:26,790 [INFO    ] __main__: train step 20582: loss: 0.9678, policy_loss: 0.9057, value_loss: 0.4415
2024-07-14 07:28:27,080 [INFO    ] __main__: train step 20583: loss: 0.9678, policy_loss: 0.9057, value_loss: 0.4415
2024-07-14 07:28:28,680 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:28:29,146 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:28:29,228 [INFO    ] __main__: train step 20584: loss: 0.9677, policy_loss: 0.9057, value_loss: 0.4415
2024-07-14 07:28:29,489 [INFO    ] __main__: train step 20585: loss: 0.9677, policy_loss: 0.9056, value_loss: 0.4414
2024-07-14 07:28:29,786 [INFO    ] __main__: train step 20586: loss: 0.9677, policy_loss: 0.9056, value_loss: 0.4414
2024-07-14 07:28:30,082 [INFO    ] __main__: train step 20587: loss: 0.9677, policy_loss: 0.9056, value_loss: 0.4414
2024-07-14 07:28:30,375 [INFO    ] __main__: train step 20588: loss: 0.9677, policy_loss: 0.9056, value_loss: 0.4414
2024-07-14 07:28:30,678 [INFO    ] __main__: train step 20589: loss: 0.9677, policy_loss: 0.9056, value_loss: 0.4414
2024-07-14 07:28:30,967 [INFO    ] __main__: train step 20590: loss: 0.9677, policy_loss: 0.9056, value_loss: 0.4414
2024-07-14 07:28:31,233 [INFO    ] __main__: train step 20591: loss: 0.9676, policy_loss: 0.9055, value_loss: 0.4414
2024-07-14 07:28:31,544 [INFO    ] __main__: train step 20592: loss: 0.9676, policy_loss: 0.9055, value_loss: 0.4413
2024-07-14 07:28:31,857 [INFO    ] __main__: train step 20593: loss: 0.9676, policy_loss: 0.9055, value_loss: 0.4413
2024-07-14 07:28:32,159 [INFO    ] __main__: train step 20594: loss: 0.9676, policy_loss: 0.9055, value_loss: 0.4413
2024-07-14 07:28:32,450 [INFO    ] __main__: train step 20595: loss: 0.9676, policy_loss: 0.9055, value_loss: 0.4413
2024-07-14 07:28:32,744 [INFO    ] __main__: train step 20596: loss: 0.9676, policy_loss: 0.9055, value_loss: 0.4413
2024-07-14 07:28:33,046 [INFO    ] __main__: train step 20597: loss: 0.9676, policy_loss: 0.9054, value_loss: 0.4413
2024-07-14 07:28:33,342 [INFO    ] __main__: train step 20598: loss: 0.9675, policy_loss: 0.9054, value_loss: 0.4412
2024-07-14 07:28:33,634 [INFO    ] __main__: train step 20599: loss: 0.9675, policy_loss: 0.9054, value_loss: 0.4412
2024-07-14 07:28:33,939 [INFO    ] __main__: train step 20600: loss: 0.9675, policy_loss: 0.9054, value_loss: 0.4412
2024-07-14 07:28:35,568 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:28:36,035 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:28:36,102 [INFO    ] __main__: train step 20601: loss: 0.9675, policy_loss: 0.9054, value_loss: 0.4412
2024-07-14 07:28:36,398 [INFO    ] __main__: train step 20602: loss: 0.9675, policy_loss: 0.9054, value_loss: 0.4412
2024-07-14 07:28:36,676 [INFO    ] __main__: train step 20603: loss: 0.9675, policy_loss: 0.9053, value_loss: 0.4412
2024-07-14 07:28:36,977 [INFO    ] __main__: train step 20604: loss: 0.9675, policy_loss: 0.9053, value_loss: 0.4411
2024-07-14 07:28:37,259 [INFO    ] __main__: train step 20605: loss: 0.9674, policy_loss: 0.9053, value_loss: 0.4411
2024-07-14 07:28:37,552 [INFO    ] __main__: train step 20606: loss: 0.9674, policy_loss: 0.9053, value_loss: 0.4411
2024-07-14 07:28:37,853 [INFO    ] __main__: train step 20607: loss: 0.9674, policy_loss: 0.9053, value_loss: 0.4411
2024-07-14 07:28:38,160 [INFO    ] __main__: train step 20608: loss: 0.9674, policy_loss: 0.9053, value_loss: 0.4411
2024-07-14 07:28:38,457 [INFO    ] __main__: train step 20609: loss: 0.9674, policy_loss: 0.9052, value_loss: 0.4411
2024-07-14 07:28:38,750 [INFO    ] __main__: train step 20610: loss: 0.9674, policy_loss: 0.9052, value_loss: 0.4410
2024-07-14 07:28:39,041 [INFO    ] __main__: train step 20611: loss: 0.9674, policy_loss: 0.9052, value_loss: 0.4410
2024-07-14 07:28:39,315 [INFO    ] __main__: train step 20612: loss: 0.9673, policy_loss: 0.9052, value_loss: 0.4410
2024-07-14 07:28:39,587 [INFO    ] __main__: train step 20613: loss: 0.9673, policy_loss: 0.9052, value_loss: 0.4410
2024-07-14 07:28:39,871 [INFO    ] __main__: train step 20614: loss: 0.9673, policy_loss: 0.9052, value_loss: 0.4410
2024-07-14 07:28:40,157 [INFO    ] __main__: train step 20615: loss: 0.9673, policy_loss: 0.9051, value_loss: 0.4410
2024-07-14 07:28:40,446 [INFO    ] __main__: train step 20616: loss: 0.9673, policy_loss: 0.9051, value_loss: 0.4410
2024-07-14 07:28:40,734 [INFO    ] __main__: train step 20617: loss: 0.9673, policy_loss: 0.9051, value_loss: 0.4409
2024-07-14 07:28:42,354 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:28:42,847 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:28:42,916 [INFO    ] __main__: train step 20618: loss: 0.9673, policy_loss: 0.9051, value_loss: 0.4409
2024-07-14 07:28:43,213 [INFO    ] __main__: train step 20619: loss: 0.9673, policy_loss: 0.9051, value_loss: 0.4409
2024-07-14 07:28:43,515 [INFO    ] __main__: train step 20620: loss: 0.9672, policy_loss: 0.9051, value_loss: 0.4409
2024-07-14 07:28:43,782 [INFO    ] __main__: train step 20621: loss: 0.9672, policy_loss: 0.9050, value_loss: 0.4409
2024-07-14 07:28:44,074 [INFO    ] __main__: train step 20622: loss: 0.9672, policy_loss: 0.9050, value_loss: 0.4409
2024-07-14 07:28:44,368 [INFO    ] __main__: train step 20623: loss: 0.9672, policy_loss: 0.9050, value_loss: 0.4408
2024-07-14 07:28:44,656 [INFO    ] __main__: train step 20624: loss: 0.9672, policy_loss: 0.9050, value_loss: 0.4408
2024-07-14 07:28:44,954 [INFO    ] __main__: train step 20625: loss: 0.9672, policy_loss: 0.9050, value_loss: 0.4408
2024-07-14 07:28:45,244 [INFO    ] __main__: train step 20626: loss: 0.9671, policy_loss: 0.9050, value_loss: 0.4408
2024-07-14 07:28:45,550 [INFO    ] __main__: train step 20627: loss: 0.9671, policy_loss: 0.9049, value_loss: 0.4408
2024-07-14 07:28:45,858 [INFO    ] __main__: train step 20628: loss: 0.9671, policy_loss: 0.9049, value_loss: 0.4408
2024-07-14 07:28:46,156 [INFO    ] __main__: train step 20629: loss: 0.9671, policy_loss: 0.9049, value_loss: 0.4407
2024-07-14 07:28:46,456 [INFO    ] __main__: train step 20630: loss: 0.9671, policy_loss: 0.9049, value_loss: 0.4407
2024-07-14 07:28:46,752 [INFO    ] __main__: train step 20631: loss: 0.9671, policy_loss: 0.9049, value_loss: 0.4407
2024-07-14 07:28:47,069 [INFO    ] __main__: train step 20632: loss: 0.9671, policy_loss: 0.9049, value_loss: 0.4407
2024-07-14 07:28:47,359 [INFO    ] __main__: train step 20633: loss: 0.9671, policy_loss: 0.9048, value_loss: 0.4407
2024-07-14 07:28:47,652 [INFO    ] __main__: train step 20634: loss: 0.9670, policy_loss: 0.9048, value_loss: 0.4407
2024-07-14 07:28:49,282 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:28:49,754 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:28:49,826 [INFO    ] __main__: train step 20635: loss: 0.9670, policy_loss: 0.9048, value_loss: 0.4407
2024-07-14 07:28:50,127 [INFO    ] __main__: train step 20636: loss: 0.9670, policy_loss: 0.9048, value_loss: 0.4406
2024-07-14 07:28:54,778 [INFO    ] __main__: train step 20637: loss: 0.9670, policy_loss: 0.9048, value_loss: 0.4406
2024-07-14 07:28:55,090 [INFO    ] __main__: train step 20638: loss: 0.9670, policy_loss: 0.9048, value_loss: 0.4406
2024-07-14 07:28:55,389 [INFO    ] __main__: train step 20639: loss: 0.9670, policy_loss: 0.9047, value_loss: 0.4406
2024-07-14 07:28:55,698 [INFO    ] __main__: train step 20640: loss: 0.9670, policy_loss: 0.9047, value_loss: 0.4406
2024-07-14 07:28:56,001 [INFO    ] __main__: train step 20641: loss: 0.9669, policy_loss: 0.9047, value_loss: 0.4406
2024-07-14 07:28:56,315 [INFO    ] __main__: train step 20642: loss: 0.9669, policy_loss: 0.9047, value_loss: 0.4405
2024-07-14 07:28:56,602 [INFO    ] __main__: train step 20643: loss: 0.9669, policy_loss: 0.9047, value_loss: 0.4405
2024-07-14 07:28:56,883 [INFO    ] __main__: train step 20644: loss: 0.9669, policy_loss: 0.9047, value_loss: 0.4405
2024-07-14 07:28:57,183 [INFO    ] __main__: train step 20645: loss: 0.9669, policy_loss: 0.9046, value_loss: 0.4405
2024-07-14 07:28:57,488 [INFO    ] __main__: train step 20646: loss: 0.9669, policy_loss: 0.9046, value_loss: 0.4405
2024-07-14 07:28:57,793 [INFO    ] __main__: train step 20647: loss: 0.9669, policy_loss: 0.9046, value_loss: 0.4405
2024-07-14 07:28:58,058 [INFO    ] __main__: train step 20648: loss: 0.9668, policy_loss: 0.9046, value_loss: 0.4404
2024-07-14 07:28:58,340 [INFO    ] __main__: train step 20649: loss: 0.9668, policy_loss: 0.9046, value_loss: 0.4404
2024-07-14 07:28:58,625 [INFO    ] __main__: train step 20650: loss: 0.9668, policy_loss: 0.9046, value_loss: 0.4404
2024-07-14 07:28:58,935 [INFO    ] __main__: train step 20651: loss: 0.9668, policy_loss: 0.9045, value_loss: 0.4404
2024-07-14 07:29:00,570 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:29:01,057 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:29:01,121 [INFO    ] __main__: train step 20652: loss: 0.9668, policy_loss: 0.9045, value_loss: 0.4404
2024-07-14 07:29:01,377 [INFO    ] __main__: train step 20653: loss: 0.9668, policy_loss: 0.9045, value_loss: 0.4404
2024-07-14 07:29:01,650 [INFO    ] __main__: train step 20654: loss: 0.9668, policy_loss: 0.9045, value_loss: 0.4404
2024-07-14 07:29:01,944 [INFO    ] __main__: train step 20655: loss: 0.9667, policy_loss: 0.9045, value_loss: 0.4403
2024-07-14 07:29:02,235 [INFO    ] __main__: train step 20656: loss: 0.9667, policy_loss: 0.9045, value_loss: 0.4403
2024-07-14 07:29:02,529 [INFO    ] __main__: train step 20657: loss: 0.9667, policy_loss: 0.9044, value_loss: 0.4403
2024-07-14 07:29:02,819 [INFO    ] __main__: train step 20658: loss: 0.9667, policy_loss: 0.9044, value_loss: 0.4403
2024-07-14 07:29:03,119 [INFO    ] __main__: train step 20659: loss: 0.9667, policy_loss: 0.9044, value_loss: 0.4403
2024-07-14 07:29:03,417 [INFO    ] __main__: train step 20660: loss: 0.9667, policy_loss: 0.9044, value_loss: 0.4403
2024-07-14 07:29:03,702 [INFO    ] __main__: train step 20661: loss: 0.9667, policy_loss: 0.9044, value_loss: 0.4402
2024-07-14 07:29:04,004 [INFO    ] __main__: train step 20662: loss: 0.9666, policy_loss: 0.9044, value_loss: 0.4402
2024-07-14 07:29:04,303 [INFO    ] __main__: train step 20663: loss: 0.9666, policy_loss: 0.9043, value_loss: 0.4402
2024-07-14 07:29:04,593 [INFO    ] __main__: train step 20664: loss: 0.9666, policy_loss: 0.9043, value_loss: 0.4402
2024-07-14 07:29:04,891 [INFO    ] __main__: train step 20665: loss: 0.9666, policy_loss: 0.9043, value_loss: 0.4402
2024-07-14 07:29:05,192 [INFO    ] __main__: train step 20666: loss: 0.9666, policy_loss: 0.9043, value_loss: 0.4402
2024-07-14 07:29:05,498 [INFO    ] __main__: train step 20667: loss: 0.9666, policy_loss: 0.9043, value_loss: 0.4401
2024-07-14 07:29:05,805 [INFO    ] __main__: train step 20668: loss: 0.9666, policy_loss: 0.9043, value_loss: 0.4401
2024-07-14 07:29:07,427 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:29:07,908 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:29:07,975 [INFO    ] __main__: train step 20669: loss: 0.9665, policy_loss: 0.9042, value_loss: 0.4401
2024-07-14 07:29:08,248 [INFO    ] __main__: train step 20670: loss: 0.9665, policy_loss: 0.9042, value_loss: 0.4401
2024-07-14 07:29:08,544 [INFO    ] __main__: train step 20671: loss: 0.9665, policy_loss: 0.9042, value_loss: 0.4401
2024-07-14 07:29:08,850 [INFO    ] __main__: train step 20672: loss: 0.9665, policy_loss: 0.9042, value_loss: 0.4401
2024-07-14 07:29:09,127 [INFO    ] __main__: train step 20673: loss: 0.9665, policy_loss: 0.9042, value_loss: 0.4401
2024-07-14 07:29:09,440 [INFO    ] __main__: train step 20674: loss: 0.9665, policy_loss: 0.9042, value_loss: 0.4400
2024-07-14 07:29:09,725 [INFO    ] __main__: train step 20675: loss: 0.9665, policy_loss: 0.9041, value_loss: 0.4400
2024-07-14 07:29:10,037 [INFO    ] __main__: train step 20676: loss: 0.9664, policy_loss: 0.9041, value_loss: 0.4400
2024-07-14 07:29:10,347 [INFO    ] __main__: train step 20677: loss: 0.9664, policy_loss: 0.9041, value_loss: 0.4400
2024-07-14 07:29:10,630 [INFO    ] __main__: train step 20678: loss: 0.9664, policy_loss: 0.9041, value_loss: 0.4400
2024-07-14 07:29:10,902 [INFO    ] __main__: train step 20679: loss: 0.9664, policy_loss: 0.9041, value_loss: 0.4400
2024-07-14 07:29:11,193 [INFO    ] __main__: train step 20680: loss: 0.9664, policy_loss: 0.9041, value_loss: 0.4399
2024-07-14 07:29:11,497 [INFO    ] __main__: train step 20681: loss: 0.9664, policy_loss: 0.9040, value_loss: 0.4399
2024-07-14 07:29:11,807 [INFO    ] __main__: train step 20682: loss: 0.9664, policy_loss: 0.9040, value_loss: 0.4399
2024-07-14 07:29:12,113 [INFO    ] __main__: train step 20683: loss: 0.9664, policy_loss: 0.9040, value_loss: 0.4399
2024-07-14 07:29:12,374 [INFO    ] __main__: train step 20684: loss: 0.9663, policy_loss: 0.9040, value_loss: 0.4399
2024-07-14 07:29:12,662 [INFO    ] __main__: train step 20685: loss: 0.9663, policy_loss: 0.9040, value_loss: 0.4399
2024-07-14 07:29:14,268 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:29:14,764 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:29:14,834 [INFO    ] __main__: train step 20686: loss: 0.9663, policy_loss: 0.9040, value_loss: 0.4398
2024-07-14 07:29:15,128 [INFO    ] __main__: train step 20687: loss: 0.9663, policy_loss: 0.9039, value_loss: 0.4398
2024-07-14 07:29:15,417 [INFO    ] __main__: train step 20688: loss: 0.9663, policy_loss: 0.9039, value_loss: 0.4398
2024-07-14 07:29:15,689 [INFO    ] __main__: train step 20689: loss: 0.9663, policy_loss: 0.9039, value_loss: 0.4398
2024-07-14 07:29:15,980 [INFO    ] __main__: train step 20690: loss: 0.9663, policy_loss: 0.9039, value_loss: 0.4398
2024-07-14 07:29:16,271 [INFO    ] __main__: train step 20691: loss: 0.9662, policy_loss: 0.9039, value_loss: 0.4398
2024-07-14 07:29:16,565 [INFO    ] __main__: train step 20692: loss: 0.9662, policy_loss: 0.9039, value_loss: 0.4398
2024-07-14 07:29:16,868 [INFO    ] __main__: train step 20693: loss: 0.9662, policy_loss: 0.9038, value_loss: 0.4397
2024-07-14 07:29:17,130 [INFO    ] __main__: train step 20694: loss: 0.9662, policy_loss: 0.9038, value_loss: 0.4397
2024-07-14 07:29:17,423 [INFO    ] __main__: train step 20695: loss: 0.9662, policy_loss: 0.9038, value_loss: 0.4397
2024-07-14 07:29:17,716 [INFO    ] __main__: train step 20696: loss: 0.9662, policy_loss: 0.9038, value_loss: 0.4397
2024-07-14 07:29:18,024 [INFO    ] __main__: train step 20697: loss: 0.9662, policy_loss: 0.9038, value_loss: 0.4397
2024-07-14 07:29:18,340 [INFO    ] __main__: train step 20698: loss: 0.9661, policy_loss: 0.9038, value_loss: 0.4397
2024-07-14 07:29:18,627 [INFO    ] __main__: train step 20699: loss: 0.9661, policy_loss: 0.9038, value_loss: 0.4396
2024-07-14 07:29:18,917 [INFO    ] __main__: train step 20700: loss: 0.9661, policy_loss: 0.9037, value_loss: 0.4396
2024-07-14 07:29:19,218 [INFO    ] __main__: train step 20701: loss: 0.9661, policy_loss: 0.9037, value_loss: 0.4396
2024-07-14 07:29:19,509 [INFO    ] __main__: train step 20702: loss: 0.9661, policy_loss: 0.9037, value_loss: 0.4396
2024-07-14 07:29:21,140 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:29:21,608 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:29:21,674 [INFO    ] __main__: train step 20703: loss: 0.9661, policy_loss: 0.9037, value_loss: 0.4396
2024-07-14 07:29:21,960 [INFO    ] __main__: train step 20704: loss: 0.9661, policy_loss: 0.9037, value_loss: 0.4396
2024-07-14 07:29:22,255 [INFO    ] __main__: train step 20705: loss: 0.9660, policy_loss: 0.9037, value_loss: 0.4395
2024-07-14 07:29:22,549 [INFO    ] __main__: train step 20706: loss: 0.9660, policy_loss: 0.9036, value_loss: 0.4395
2024-07-14 07:29:22,846 [INFO    ] __main__: train step 20707: loss: 0.9660, policy_loss: 0.9036, value_loss: 0.4395
2024-07-14 07:29:23,149 [INFO    ] __main__: train step 20708: loss: 0.9660, policy_loss: 0.9036, value_loss: 0.4395
2024-07-14 07:29:23,434 [INFO    ] __main__: train step 20709: loss: 0.9660, policy_loss: 0.9036, value_loss: 0.4395
2024-07-14 07:29:23,730 [INFO    ] __main__: train step 20710: loss: 0.9660, policy_loss: 0.9036, value_loss: 0.4395
2024-07-14 07:29:24,028 [INFO    ] __main__: train step 20711: loss: 0.9660, policy_loss: 0.9036, value_loss: 0.4395
2024-07-14 07:29:24,335 [INFO    ] __main__: train step 20712: loss: 0.9659, policy_loss: 0.9035, value_loss: 0.4394
2024-07-14 07:29:24,636 [INFO    ] __main__: train step 20713: loss: 0.9659, policy_loss: 0.9035, value_loss: 0.4394
2024-07-14 07:29:24,954 [INFO    ] __main__: train step 20714: loss: 0.9659, policy_loss: 0.9035, value_loss: 0.4394
2024-07-14 07:29:25,225 [INFO    ] __main__: train step 20715: loss: 0.9659, policy_loss: 0.9035, value_loss: 0.4394
2024-07-14 07:29:25,512 [INFO    ] __main__: train step 20716: loss: 0.9659, policy_loss: 0.9035, value_loss: 0.4394
2024-07-14 07:29:25,825 [INFO    ] __main__: train step 20717: loss: 0.9659, policy_loss: 0.9035, value_loss: 0.4394
2024-07-14 07:29:26,121 [INFO    ] __main__: train step 20718: loss: 0.9659, policy_loss: 0.9034, value_loss: 0.4393
2024-07-14 07:29:26,415 [INFO    ] __main__: train step 20719: loss: 0.9658, policy_loss: 0.9034, value_loss: 0.4393
2024-07-14 07:29:28,036 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:29:28,490 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:29:28,558 [INFO    ] __main__: train step 20720: loss: 0.9658, policy_loss: 0.9034, value_loss: 0.4393
2024-07-14 07:29:28,858 [INFO    ] __main__: train step 20721: loss: 0.9658, policy_loss: 0.9034, value_loss: 0.4393
2024-07-14 07:29:29,157 [INFO    ] __main__: train step 20722: loss: 0.9658, policy_loss: 0.9034, value_loss: 0.4393
2024-07-14 07:29:29,451 [INFO    ] __main__: train step 20723: loss: 0.9658, policy_loss: 0.9034, value_loss: 0.4393
2024-07-14 07:29:29,721 [INFO    ] __main__: train step 20724: loss: 0.9658, policy_loss: 0.9033, value_loss: 0.4392
2024-07-14 07:29:30,011 [INFO    ] __main__: train step 20725: loss: 0.9658, policy_loss: 0.9033, value_loss: 0.4392
2024-07-14 07:29:30,307 [INFO    ] __main__: train step 20726: loss: 0.9658, policy_loss: 0.9033, value_loss: 0.4392
2024-07-14 07:29:30,601 [INFO    ] __main__: train step 20727: loss: 0.9657, policy_loss: 0.9033, value_loss: 0.4392
2024-07-14 07:29:30,899 [INFO    ] __main__: train step 20728: loss: 0.9657, policy_loss: 0.9033, value_loss: 0.4392
2024-07-14 07:29:31,181 [INFO    ] __main__: train step 20729: loss: 0.9657, policy_loss: 0.9033, value_loss: 0.4392
2024-07-14 07:29:31,460 [INFO    ] __main__: train step 20730: loss: 0.9657, policy_loss: 0.9032, value_loss: 0.4392
2024-07-14 07:29:31,753 [INFO    ] __main__: train step 20731: loss: 0.9657, policy_loss: 0.9032, value_loss: 0.4391
2024-07-14 07:29:32,051 [INFO    ] __main__: train step 20732: loss: 0.9657, policy_loss: 0.9032, value_loss: 0.4391
2024-07-14 07:29:32,350 [INFO    ] __main__: train step 20733: loss: 0.9657, policy_loss: 0.9032, value_loss: 0.4391
2024-07-14 07:29:32,635 [INFO    ] __main__: train step 20734: loss: 0.9656, policy_loss: 0.9032, value_loss: 0.4391
2024-07-14 07:29:32,916 [INFO    ] __main__: train step 20735: loss: 0.9656, policy_loss: 0.9032, value_loss: 0.4391
2024-07-14 07:29:33,206 [INFO    ] __main__: train step 20736: loss: 0.9656, policy_loss: 0.9031, value_loss: 0.4391
2024-07-14 07:29:34,825 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:29:35,298 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:29:35,367 [INFO    ] __main__: train step 20737: loss: 0.9656, policy_loss: 0.9031, value_loss: 0.4390
2024-07-14 07:29:35,670 [INFO    ] __main__: train step 20738: loss: 0.9656, policy_loss: 0.9031, value_loss: 0.4390
2024-07-14 07:29:35,942 [INFO    ] __main__: train step 20739: loss: 0.9656, policy_loss: 0.9031, value_loss: 0.4390
2024-07-14 07:29:36,231 [INFO    ] __main__: train step 20740: loss: 0.9656, policy_loss: 0.9031, value_loss: 0.4390
2024-07-14 07:29:36,521 [INFO    ] __main__: train step 20741: loss: 0.9655, policy_loss: 0.9031, value_loss: 0.4390
2024-07-14 07:29:36,809 [INFO    ] __main__: train step 20742: loss: 0.9655, policy_loss: 0.9030, value_loss: 0.4390
2024-07-14 07:29:37,109 [INFO    ] __main__: train step 20743: loss: 0.9655, policy_loss: 0.9030, value_loss: 0.4390
2024-07-14 07:29:37,372 [INFO    ] __main__: train step 20744: loss: 0.9655, policy_loss: 0.9030, value_loss: 0.4389
2024-07-14 07:29:37,637 [INFO    ] __main__: train step 20745: loss: 0.9655, policy_loss: 0.9030, value_loss: 0.4389
2024-07-14 07:29:37,905 [INFO    ] __main__: train step 20746: loss: 0.9655, policy_loss: 0.9030, value_loss: 0.4389
2024-07-14 07:29:38,171 [INFO    ] __main__: train step 20747: loss: 0.9655, policy_loss: 0.9030, value_loss: 0.4389
2024-07-14 07:29:38,454 [INFO    ] __main__: train step 20748: loss: 0.9654, policy_loss: 0.9029, value_loss: 0.4389
2024-07-14 07:29:38,752 [INFO    ] __main__: train step 20749: loss: 0.9654, policy_loss: 0.9029, value_loss: 0.4389
2024-07-14 07:29:39,031 [INFO    ] __main__: train step 20750: loss: 0.9654, policy_loss: 0.9029, value_loss: 0.4388
2024-07-14 07:29:39,308 [INFO    ] __main__: train step 20751: loss: 0.9654, policy_loss: 0.9029, value_loss: 0.4388
2024-07-14 07:29:39,608 [INFO    ] __main__: train step 20752: loss: 0.9654, policy_loss: 0.9029, value_loss: 0.4388
2024-07-14 07:29:39,908 [INFO    ] __main__: train step 20753: loss: 0.9654, policy_loss: 0.9029, value_loss: 0.4388
2024-07-14 07:29:41,515 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:29:41,995 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:29:42,074 [INFO    ] __main__: train step 20754: loss: 0.9654, policy_loss: 0.9029, value_loss: 0.4388
2024-07-14 07:29:42,352 [INFO    ] __main__: train step 20755: loss: 0.9653, policy_loss: 0.9028, value_loss: 0.4388
2024-07-14 07:29:42,644 [INFO    ] __main__: train step 20756: loss: 0.9653, policy_loss: 0.9028, value_loss: 0.4387
2024-07-14 07:29:42,936 [INFO    ] __main__: train step 20757: loss: 0.9653, policy_loss: 0.9028, value_loss: 0.4387
2024-07-14 07:29:43,216 [INFO    ] __main__: train step 20758: loss: 0.9653, policy_loss: 0.9028, value_loss: 0.4387
2024-07-14 07:29:43,518 [INFO    ] __main__: train step 20759: loss: 0.9653, policy_loss: 0.9028, value_loss: 0.4387
2024-07-14 07:29:43,784 [INFO    ] __main__: train step 20760: loss: 0.9653, policy_loss: 0.9028, value_loss: 0.4387
2024-07-14 07:29:44,075 [INFO    ] __main__: train step 20761: loss: 0.9653, policy_loss: 0.9027, value_loss: 0.4387
2024-07-14 07:29:44,373 [INFO    ] __main__: train step 20762: loss: 0.9652, policy_loss: 0.9027, value_loss: 0.4387
2024-07-14 07:29:44,667 [INFO    ] __main__: train step 20763: loss: 0.9652, policy_loss: 0.9027, value_loss: 0.4386
2024-07-14 07:29:44,999 [INFO    ] __main__: train step 20764: loss: 0.9652, policy_loss: 0.9027, value_loss: 0.4386
2024-07-14 07:29:45,285 [INFO    ] __main__: train step 20765: loss: 0.9652, policy_loss: 0.9027, value_loss: 0.4386
2024-07-14 07:29:45,592 [INFO    ] __main__: train step 20766: loss: 0.9652, policy_loss: 0.9027, value_loss: 0.4386
2024-07-14 07:29:50,296 [INFO    ] __main__: train step 20767: loss: 0.9652, policy_loss: 0.9026, value_loss: 0.4386
2024-07-14 07:29:50,602 [INFO    ] __main__: train step 20768: loss: 0.9652, policy_loss: 0.9026, value_loss: 0.4386
2024-07-14 07:29:50,901 [INFO    ] __main__: train step 20769: loss: 0.9652, policy_loss: 0.9026, value_loss: 0.4385
2024-07-14 07:29:51,203 [INFO    ] __main__: train step 20770: loss: 0.9651, policy_loss: 0.9026, value_loss: 0.4385
2024-07-14 07:29:52,791 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:29:53,258 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:29:53,326 [INFO    ] __main__: train step 20771: loss: 0.9651, policy_loss: 0.9026, value_loss: 0.4385
2024-07-14 07:29:53,620 [INFO    ] __main__: train step 20772: loss: 0.9651, policy_loss: 0.9026, value_loss: 0.4385
2024-07-14 07:29:53,909 [INFO    ] __main__: train step 20773: loss: 0.9651, policy_loss: 0.9025, value_loss: 0.4385
2024-07-14 07:29:54,200 [INFO    ] __main__: train step 20774: loss: 0.9651, policy_loss: 0.9025, value_loss: 0.4385
2024-07-14 07:29:54,477 [INFO    ] __main__: train step 20775: loss: 0.9651, policy_loss: 0.9025, value_loss: 0.4384
2024-07-14 07:29:54,770 [INFO    ] __main__: train step 20776: loss: 0.9651, policy_loss: 0.9025, value_loss: 0.4384
2024-07-14 07:29:55,069 [INFO    ] __main__: train step 20777: loss: 0.9650, policy_loss: 0.9025, value_loss: 0.4384
2024-07-14 07:29:55,372 [INFO    ] __main__: train step 20778: loss: 0.9650, policy_loss: 0.9025, value_loss: 0.4384
2024-07-14 07:29:55,671 [INFO    ] __main__: train step 20779: loss: 0.9650, policy_loss: 0.9024, value_loss: 0.4384
2024-07-14 07:29:55,950 [INFO    ] __main__: train step 20780: loss: 0.9650, policy_loss: 0.9024, value_loss: 0.4384
2024-07-14 07:29:56,226 [INFO    ] __main__: train step 20781: loss: 0.9650, policy_loss: 0.9024, value_loss: 0.4384
2024-07-14 07:29:56,498 [INFO    ] __main__: train step 20782: loss: 0.9650, policy_loss: 0.9024, value_loss: 0.4383
2024-07-14 07:29:56,792 [INFO    ] __main__: train step 20783: loss: 0.9650, policy_loss: 0.9024, value_loss: 0.4383
2024-07-14 07:29:57,083 [INFO    ] __main__: train step 20784: loss: 0.9649, policy_loss: 0.9024, value_loss: 0.4383
2024-07-14 07:29:57,384 [INFO    ] __main__: train step 20785: loss: 0.9649, policy_loss: 0.9023, value_loss: 0.4383
2024-07-14 07:29:57,655 [INFO    ] __main__: train step 20786: loss: 0.9649, policy_loss: 0.9023, value_loss: 0.4383
2024-07-14 07:29:57,946 [INFO    ] __main__: train step 20787: loss: 0.9649, policy_loss: 0.9023, value_loss: 0.4383
2024-07-14 07:29:59,549 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:30:00,016 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:30:00,084 [INFO    ] __main__: train step 20788: loss: 0.9649, policy_loss: 0.9023, value_loss: 0.4382
2024-07-14 07:30:00,382 [INFO    ] __main__: train step 20789: loss: 0.9649, policy_loss: 0.9023, value_loss: 0.4382
2024-07-14 07:30:00,669 [INFO    ] __main__: train step 20790: loss: 0.9649, policy_loss: 0.9023, value_loss: 0.4382
2024-07-14 07:30:00,954 [INFO    ] __main__: train step 20791: loss: 0.9648, policy_loss: 0.9022, value_loss: 0.4382
2024-07-14 07:30:01,251 [INFO    ] __main__: train step 20792: loss: 0.9648, policy_loss: 0.9022, value_loss: 0.4382
2024-07-14 07:30:01,550 [INFO    ] __main__: train step 20793: loss: 0.9648, policy_loss: 0.9022, value_loss: 0.4382
2024-07-14 07:30:01,846 [INFO    ] __main__: train step 20794: loss: 0.9648, policy_loss: 0.9022, value_loss: 0.4381
2024-07-14 07:30:02,138 [INFO    ] __main__: train step 20795: loss: 0.9648, policy_loss: 0.9022, value_loss: 0.4381
2024-07-14 07:30:02,426 [INFO    ] __main__: train step 20796: loss: 0.9648, policy_loss: 0.9022, value_loss: 0.4381
2024-07-14 07:30:02,712 [INFO    ] __main__: train step 20797: loss: 0.9648, policy_loss: 0.9021, value_loss: 0.4381
2024-07-14 07:30:03,020 [INFO    ] __main__: train step 20798: loss: 0.9647, policy_loss: 0.9021, value_loss: 0.4381
2024-07-14 07:30:03,314 [INFO    ] __main__: train step 20799: loss: 0.9647, policy_loss: 0.9021, value_loss: 0.4381
2024-07-14 07:30:03,604 [INFO    ] __main__: train step 20800: loss: 0.9647, policy_loss: 0.9021, value_loss: 0.4381
2024-07-14 07:30:03,884 [INFO    ] __main__: train step 20801: loss: 0.9647, policy_loss: 0.9021, value_loss: 0.4380
2024-07-14 07:30:04,165 [INFO    ] __main__: train step 20802: loss: 0.9647, policy_loss: 0.9021, value_loss: 0.4380
2024-07-14 07:30:04,474 [INFO    ] __main__: train step 20803: loss: 0.9647, policy_loss: 0.9020, value_loss: 0.4380
2024-07-14 07:30:04,775 [INFO    ] __main__: train step 20804: loss: 0.9646, policy_loss: 0.9020, value_loss: 0.4380
2024-07-14 07:30:06,420 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:30:06,906 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:30:06,984 [INFO    ] __main__: train step 20805: loss: 0.9646, policy_loss: 0.9020, value_loss: 0.4380
2024-07-14 07:30:07,260 [INFO    ] __main__: train step 20806: loss: 0.9646, policy_loss: 0.9020, value_loss: 0.4380
2024-07-14 07:30:07,551 [INFO    ] __main__: train step 20807: loss: 0.9646, policy_loss: 0.9020, value_loss: 0.4379
2024-07-14 07:30:07,842 [INFO    ] __main__: train step 20808: loss: 0.9646, policy_loss: 0.9020, value_loss: 0.4379
2024-07-14 07:30:08,140 [INFO    ] __main__: train step 20809: loss: 0.9646, policy_loss: 0.9019, value_loss: 0.4379
2024-07-14 07:30:08,438 [INFO    ] __main__: train step 20810: loss: 0.9646, policy_loss: 0.9019, value_loss: 0.4379
2024-07-14 07:30:08,715 [INFO    ] __main__: train step 20811: loss: 0.9645, policy_loss: 0.9019, value_loss: 0.4379
2024-07-14 07:30:09,006 [INFO    ] __main__: train step 20812: loss: 0.9645, policy_loss: 0.9019, value_loss: 0.4379
2024-07-14 07:30:09,297 [INFO    ] __main__: train step 20813: loss: 0.9645, policy_loss: 0.9019, value_loss: 0.4378
2024-07-14 07:30:09,609 [INFO    ] __main__: train step 20814: loss: 0.9645, policy_loss: 0.9019, value_loss: 0.4378
2024-07-14 07:30:09,916 [INFO    ] __main__: train step 20815: loss: 0.9645, policy_loss: 0.9018, value_loss: 0.4378
2024-07-14 07:30:10,194 [INFO    ] __main__: train step 20816: loss: 0.9645, policy_loss: 0.9018, value_loss: 0.4378
2024-07-14 07:30:10,485 [INFO    ] __main__: train step 20817: loss: 0.9645, policy_loss: 0.9018, value_loss: 0.4378
2024-07-14 07:30:10,787 [INFO    ] __main__: train step 20818: loss: 0.9644, policy_loss: 0.9018, value_loss: 0.4378
2024-07-14 07:30:11,085 [INFO    ] __main__: train step 20819: loss: 0.9644, policy_loss: 0.9018, value_loss: 0.4378
2024-07-14 07:30:11,379 [INFO    ] __main__: train step 20820: loss: 0.9644, policy_loss: 0.9018, value_loss: 0.4377
2024-07-14 07:30:11,661 [INFO    ] __main__: train step 20821: loss: 0.9644, policy_loss: 0.9017, value_loss: 0.4377
2024-07-14 07:30:13,259 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:30:13,699 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:30:13,762 [INFO    ] __main__: train step 20822: loss: 0.9644, policy_loss: 0.9017, value_loss: 0.4377
2024-07-14 07:30:14,034 [INFO    ] __main__: train step 20823: loss: 0.9644, policy_loss: 0.9017, value_loss: 0.4377
2024-07-14 07:30:14,309 [INFO    ] __main__: train step 20824: loss: 0.9644, policy_loss: 0.9017, value_loss: 0.4377
2024-07-14 07:30:14,596 [INFO    ] __main__: train step 20825: loss: 0.9644, policy_loss: 0.9017, value_loss: 0.4377
2024-07-14 07:30:14,884 [INFO    ] __main__: train step 20826: loss: 0.9643, policy_loss: 0.9017, value_loss: 0.4376
2024-07-14 07:30:15,156 [INFO    ] __main__: train step 20827: loss: 0.9643, policy_loss: 0.9016, value_loss: 0.4376
2024-07-14 07:30:15,455 [INFO    ] __main__: train step 20828: loss: 0.9643, policy_loss: 0.9016, value_loss: 0.4376
2024-07-14 07:30:15,767 [INFO    ] __main__: train step 20829: loss: 0.9643, policy_loss: 0.9016, value_loss: 0.4376
2024-07-14 07:30:16,070 [INFO    ] __main__: train step 20830: loss: 0.9643, policy_loss: 0.9016, value_loss: 0.4376
2024-07-14 07:30:16,348 [INFO    ] __main__: train step 20831: loss: 0.9643, policy_loss: 0.9016, value_loss: 0.4376
2024-07-14 07:30:16,637 [INFO    ] __main__: train step 20832: loss: 0.9643, policy_loss: 0.9016, value_loss: 0.4376
2024-07-14 07:30:16,929 [INFO    ] __main__: train step 20833: loss: 0.9642, policy_loss: 0.9015, value_loss: 0.4375
2024-07-14 07:30:17,244 [INFO    ] __main__: train step 20834: loss: 0.9642, policy_loss: 0.9015, value_loss: 0.4375
2024-07-14 07:30:17,544 [INFO    ] __main__: train step 20835: loss: 0.9642, policy_loss: 0.9015, value_loss: 0.4375
2024-07-14 07:30:17,828 [INFO    ] __main__: train step 20836: loss: 0.9642, policy_loss: 0.9015, value_loss: 0.4375
2024-07-14 07:30:18,104 [INFO    ] __main__: train step 20837: loss: 0.9642, policy_loss: 0.9015, value_loss: 0.4375
2024-07-14 07:30:18,373 [INFO    ] __main__: train step 20838: loss: 0.9642, policy_loss: 0.9015, value_loss: 0.4375
2024-07-14 07:30:19,991 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:30:20,464 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:30:20,532 [INFO    ] __main__: train step 20839: loss: 0.9642, policy_loss: 0.9014, value_loss: 0.4374
2024-07-14 07:30:20,797 [INFO    ] __main__: train step 20840: loss: 0.9641, policy_loss: 0.9014, value_loss: 0.4374
2024-07-14 07:30:21,088 [INFO    ] __main__: train step 20841: loss: 0.9641, policy_loss: 0.9014, value_loss: 0.4374
2024-07-14 07:30:21,385 [INFO    ] __main__: train step 20842: loss: 0.9641, policy_loss: 0.9014, value_loss: 0.4374
2024-07-14 07:30:21,675 [INFO    ] __main__: train step 20843: loss: 0.9641, policy_loss: 0.9014, value_loss: 0.4374
2024-07-14 07:30:21,991 [INFO    ] __main__: train step 20844: loss: 0.9641, policy_loss: 0.9014, value_loss: 0.4374
2024-07-14 07:30:22,292 [INFO    ] __main__: train step 20845: loss: 0.9641, policy_loss: 0.9013, value_loss: 0.4373
2024-07-14 07:30:22,593 [INFO    ] __main__: train step 20846: loss: 0.9641, policy_loss: 0.9013, value_loss: 0.4373
2024-07-14 07:30:22,876 [INFO    ] __main__: train step 20847: loss: 0.9640, policy_loss: 0.9013, value_loss: 0.4373
2024-07-14 07:30:23,147 [INFO    ] __main__: train step 20848: loss: 0.9640, policy_loss: 0.9013, value_loss: 0.4373
2024-07-14 07:30:23,413 [INFO    ] __main__: train step 20849: loss: 0.9640, policy_loss: 0.9013, value_loss: 0.4373
2024-07-14 07:30:23,684 [INFO    ] __main__: train step 20850: loss: 0.9640, policy_loss: 0.9013, value_loss: 0.4373
2024-07-14 07:30:23,984 [INFO    ] __main__: train step 20851: loss: 0.9640, policy_loss: 0.9012, value_loss: 0.4373
2024-07-14 07:30:24,248 [INFO    ] __main__: train step 20852: loss: 0.9640, policy_loss: 0.9012, value_loss: 0.4372
2024-07-14 07:30:24,533 [INFO    ] __main__: train step 20853: loss: 0.9640, policy_loss: 0.9012, value_loss: 0.4372
2024-07-14 07:30:24,839 [INFO    ] __main__: train step 20854: loss: 0.9639, policy_loss: 0.9012, value_loss: 0.4372
2024-07-14 07:30:25,129 [INFO    ] __main__: train step 20855: loss: 0.9639, policy_loss: 0.9012, value_loss: 0.4372
2024-07-14 07:30:26,740 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:30:27,221 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:30:27,292 [INFO    ] __main__: train step 20856: loss: 0.9639, policy_loss: 0.9012, value_loss: 0.4372
2024-07-14 07:30:27,565 [INFO    ] __main__: train step 20857: loss: 0.9639, policy_loss: 0.9012, value_loss: 0.4372
2024-07-14 07:30:27,835 [INFO    ] __main__: train step 20858: loss: 0.9639, policy_loss: 0.9011, value_loss: 0.4371
2024-07-14 07:30:28,134 [INFO    ] __main__: train step 20859: loss: 0.9639, policy_loss: 0.9011, value_loss: 0.4371
2024-07-14 07:30:28,440 [INFO    ] __main__: train step 20860: loss: 0.9639, policy_loss: 0.9011, value_loss: 0.4371
2024-07-14 07:30:28,721 [INFO    ] __main__: train step 20861: loss: 0.9638, policy_loss: 0.9011, value_loss: 0.4371
2024-07-14 07:30:29,006 [INFO    ] __main__: train step 20862: loss: 0.9638, policy_loss: 0.9011, value_loss: 0.4371
2024-07-14 07:30:29,272 [INFO    ] __main__: train step 20863: loss: 0.9638, policy_loss: 0.9011, value_loss: 0.4371
2024-07-14 07:30:29,571 [INFO    ] __main__: train step 20864: loss: 0.9638, policy_loss: 0.9010, value_loss: 0.4371
2024-07-14 07:30:29,897 [INFO    ] __main__: train step 20865: loss: 0.9638, policy_loss: 0.9010, value_loss: 0.4370
2024-07-14 07:30:30,208 [INFO    ] __main__: train step 20866: loss: 0.9638, policy_loss: 0.9010, value_loss: 0.4370
2024-07-14 07:30:30,516 [INFO    ] __main__: train step 20867: loss: 0.9638, policy_loss: 0.9010, value_loss: 0.4370
2024-07-14 07:30:30,815 [INFO    ] __main__: train step 20868: loss: 0.9638, policy_loss: 0.9010, value_loss: 0.4370
2024-07-14 07:30:31,093 [INFO    ] __main__: train step 20869: loss: 0.9637, policy_loss: 0.9010, value_loss: 0.4370
2024-07-14 07:30:31,395 [INFO    ] __main__: train step 20870: loss: 0.9637, policy_loss: 0.9009, value_loss: 0.4370
2024-07-14 07:30:31,699 [INFO    ] __main__: train step 20871: loss: 0.9637, policy_loss: 0.9009, value_loss: 0.4369
2024-07-14 07:30:31,997 [INFO    ] __main__: train step 20872: loss: 0.9637, policy_loss: 0.9009, value_loss: 0.4369
2024-07-14 07:30:33,618 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:30:34,099 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:30:34,169 [INFO    ] __main__: train step 20873: loss: 0.9637, policy_loss: 0.9009, value_loss: 0.4369
2024-07-14 07:30:34,451 [INFO    ] __main__: train step 20874: loss: 0.9637, policy_loss: 0.9009, value_loss: 0.4369
2024-07-14 07:30:34,747 [INFO    ] __main__: train step 20875: loss: 0.9637, policy_loss: 0.9009, value_loss: 0.4369
2024-07-14 07:30:35,038 [INFO    ] __main__: train step 20876: loss: 0.9636, policy_loss: 0.9008, value_loss: 0.4369
2024-07-14 07:30:35,312 [INFO    ] __main__: train step 20877: loss: 0.9636, policy_loss: 0.9008, value_loss: 0.4368
2024-07-14 07:30:35,583 [INFO    ] __main__: train step 20878: loss: 0.9636, policy_loss: 0.9008, value_loss: 0.4368
2024-07-14 07:30:35,876 [INFO    ] __main__: train step 20879: loss: 0.9636, policy_loss: 0.9008, value_loss: 0.4368
2024-07-14 07:30:36,170 [INFO    ] __main__: train step 20880: loss: 0.9636, policy_loss: 0.9008, value_loss: 0.4368
2024-07-14 07:30:36,475 [INFO    ] __main__: train step 20881: loss: 0.9636, policy_loss: 0.9008, value_loss: 0.4368
2024-07-14 07:30:36,773 [INFO    ] __main__: train step 20882: loss: 0.9636, policy_loss: 0.9007, value_loss: 0.4368
2024-07-14 07:30:37,045 [INFO    ] __main__: train step 20883: loss: 0.9635, policy_loss: 0.9007, value_loss: 0.4368
2024-07-14 07:30:37,322 [INFO    ] __main__: train step 20884: loss: 0.9635, policy_loss: 0.9007, value_loss: 0.4367
2024-07-14 07:30:37,614 [INFO    ] __main__: train step 20885: loss: 0.9635, policy_loss: 0.9007, value_loss: 0.4367
2024-07-14 07:30:37,905 [INFO    ] __main__: train step 20886: loss: 0.9635, policy_loss: 0.9007, value_loss: 0.4367
2024-07-14 07:30:38,202 [INFO    ] __main__: train step 20887: loss: 0.9635, policy_loss: 0.9007, value_loss: 0.4367
2024-07-14 07:30:38,488 [INFO    ] __main__: train step 20888: loss: 0.9635, policy_loss: 0.9006, value_loss: 0.4367
2024-07-14 07:30:38,786 [INFO    ] __main__: train step 20889: loss: 0.9635, policy_loss: 0.9006, value_loss: 0.4367
2024-07-14 07:30:40,417 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:30:40,906 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:30:40,979 [INFO    ] __main__: train step 20890: loss: 0.9634, policy_loss: 0.9006, value_loss: 0.4366
2024-07-14 07:30:41,273 [INFO    ] __main__: train step 20891: loss: 0.9634, policy_loss: 0.9006, value_loss: 0.4366
2024-07-14 07:30:41,563 [INFO    ] __main__: train step 20892: loss: 0.9634, policy_loss: 0.9006, value_loss: 0.4366
2024-07-14 07:30:41,828 [INFO    ] __main__: train step 20893: loss: 0.9634, policy_loss: 0.9006, value_loss: 0.4366
2024-07-14 07:30:42,120 [INFO    ] __main__: train step 20894: loss: 0.9634, policy_loss: 0.9005, value_loss: 0.4366
2024-07-14 07:30:46,746 [INFO    ] __main__: train step 20895: loss: 0.9634, policy_loss: 0.9005, value_loss: 0.4366
2024-07-14 07:30:47,047 [INFO    ] __main__: train step 20896: loss: 0.9634, policy_loss: 0.9005, value_loss: 0.4366
2024-07-14 07:30:47,350 [INFO    ] __main__: train step 20897: loss: 0.9633, policy_loss: 0.9005, value_loss: 0.4365
2024-07-14 07:30:47,649 [INFO    ] __main__: train step 20898: loss: 0.9633, policy_loss: 0.9005, value_loss: 0.4365
2024-07-14 07:30:47,935 [INFO    ] __main__: train step 20899: loss: 0.9633, policy_loss: 0.9005, value_loss: 0.4365
2024-07-14 07:30:48,216 [INFO    ] __main__: train step 20900: loss: 0.9633, policy_loss: 0.9005, value_loss: 0.4365
2024-07-14 07:30:48,500 [INFO    ] __main__: train step 20901: loss: 0.9633, policy_loss: 0.9004, value_loss: 0.4365
2024-07-14 07:30:48,794 [INFO    ] __main__: train step 20902: loss: 0.9633, policy_loss: 0.9004, value_loss: 0.4365
2024-07-14 07:30:49,099 [INFO    ] __main__: train step 20903: loss: 0.9633, policy_loss: 0.9004, value_loss: 0.4364
2024-07-14 07:30:49,400 [INFO    ] __main__: train step 20904: loss: 0.9632, policy_loss: 0.9004, value_loss: 0.4364
2024-07-14 07:30:49,686 [INFO    ] __main__: train step 20905: loss: 0.9632, policy_loss: 0.9004, value_loss: 0.4364
2024-07-14 07:30:49,980 [INFO    ] __main__: train step 20906: loss: 0.9632, policy_loss: 0.9004, value_loss: 0.4364
2024-07-14 07:30:51,598 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:30:52,068 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:30:52,138 [INFO    ] __main__: train step 20907: loss: 0.9632, policy_loss: 0.9003, value_loss: 0.4364
2024-07-14 07:30:52,425 [INFO    ] __main__: train step 20908: loss: 0.9632, policy_loss: 0.9003, value_loss: 0.4364
2024-07-14 07:30:52,686 [INFO    ] __main__: train step 20909: loss: 0.9632, policy_loss: 0.9003, value_loss: 0.4363
2024-07-14 07:30:52,978 [INFO    ] __main__: train step 20910: loss: 0.9632, policy_loss: 0.9003, value_loss: 0.4363
2024-07-14 07:30:53,268 [INFO    ] __main__: train step 20911: loss: 0.9632, policy_loss: 0.9003, value_loss: 0.4363
2024-07-14 07:30:53,574 [INFO    ] __main__: train step 20912: loss: 0.9631, policy_loss: 0.9003, value_loss: 0.4363
2024-07-14 07:30:53,872 [INFO    ] __main__: train step 20913: loss: 0.9631, policy_loss: 0.9002, value_loss: 0.4363
2024-07-14 07:30:54,163 [INFO    ] __main__: train step 20914: loss: 0.9631, policy_loss: 0.9002, value_loss: 0.4363
2024-07-14 07:30:54,440 [INFO    ] __main__: train step 20915: loss: 0.9631, policy_loss: 0.9002, value_loss: 0.4363
2024-07-14 07:30:54,725 [INFO    ] __main__: train step 20916: loss: 0.9631, policy_loss: 0.9002, value_loss: 0.4362
2024-07-14 07:30:55,034 [INFO    ] __main__: train step 20917: loss: 0.9631, policy_loss: 0.9002, value_loss: 0.4362
2024-07-14 07:30:55,334 [INFO    ] __main__: train step 20918: loss: 0.9631, policy_loss: 0.9002, value_loss: 0.4362
2024-07-14 07:30:55,638 [INFO    ] __main__: train step 20919: loss: 0.9630, policy_loss: 0.9001, value_loss: 0.4362
2024-07-14 07:30:55,933 [INFO    ] __main__: train step 20920: loss: 0.9630, policy_loss: 0.9001, value_loss: 0.4362
2024-07-14 07:30:56,234 [INFO    ] __main__: train step 20921: loss: 0.9630, policy_loss: 0.9001, value_loss: 0.4362
2024-07-14 07:30:56,538 [INFO    ] __main__: train step 20922: loss: 0.9630, policy_loss: 0.9001, value_loss: 0.4361
2024-07-14 07:30:56,846 [INFO    ] __main__: train step 20923: loss: 0.9630, policy_loss: 0.9001, value_loss: 0.4361
2024-07-14 07:30:58,478 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:30:58,967 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:30:59,041 [INFO    ] __main__: train step 20924: loss: 0.9630, policy_loss: 0.9001, value_loss: 0.4361
2024-07-14 07:30:59,330 [INFO    ] __main__: train step 20925: loss: 0.9630, policy_loss: 0.9000, value_loss: 0.4361
2024-07-14 07:30:59,639 [INFO    ] __main__: train step 20926: loss: 0.9629, policy_loss: 0.9000, value_loss: 0.4361
2024-07-14 07:30:59,938 [INFO    ] __main__: train step 20927: loss: 0.9629, policy_loss: 0.9000, value_loss: 0.4361
2024-07-14 07:31:00,232 [INFO    ] __main__: train step 20928: loss: 0.9629, policy_loss: 0.9000, value_loss: 0.4361
2024-07-14 07:31:00,532 [INFO    ] __main__: train step 20929: loss: 0.9629, policy_loss: 0.9000, value_loss: 0.4360
2024-07-14 07:31:00,834 [INFO    ] __main__: train step 20930: loss: 0.9629, policy_loss: 0.9000, value_loss: 0.4360
2024-07-14 07:31:01,122 [INFO    ] __main__: train step 20931: loss: 0.9629, policy_loss: 0.9000, value_loss: 0.4360
2024-07-14 07:31:01,422 [INFO    ] __main__: train step 20932: loss: 0.9629, policy_loss: 0.8999, value_loss: 0.4360
2024-07-14 07:31:01,705 [INFO    ] __main__: train step 20933: loss: 0.9628, policy_loss: 0.8999, value_loss: 0.4360
2024-07-14 07:31:02,011 [INFO    ] __main__: train step 20934: loss: 0.9628, policy_loss: 0.8999, value_loss: 0.4360
2024-07-14 07:31:02,289 [INFO    ] __main__: train step 20935: loss: 0.9628, policy_loss: 0.8999, value_loss: 0.4359
2024-07-14 07:31:02,572 [INFO    ] __main__: train step 20936: loss: 0.9628, policy_loss: 0.8999, value_loss: 0.4359
2024-07-14 07:31:02,881 [INFO    ] __main__: train step 20937: loss: 0.9628, policy_loss: 0.8999, value_loss: 0.4359
2024-07-14 07:31:03,172 [INFO    ] __main__: train step 20938: loss: 0.9628, policy_loss: 0.8998, value_loss: 0.4359
2024-07-14 07:31:03,470 [INFO    ] __main__: train step 20939: loss: 0.9628, policy_loss: 0.8998, value_loss: 0.4359
2024-07-14 07:31:03,753 [INFO    ] __main__: train step 20940: loss: 0.9628, policy_loss: 0.8998, value_loss: 0.4359
2024-07-14 07:31:05,336 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:31:05,823 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:31:05,892 [INFO    ] __main__: train step 20941: loss: 0.9627, policy_loss: 0.8998, value_loss: 0.4359
2024-07-14 07:31:06,186 [INFO    ] __main__: train step 20942: loss: 0.9627, policy_loss: 0.8998, value_loss: 0.4358
2024-07-14 07:31:06,503 [INFO    ] __main__: train step 20943: loss: 0.9627, policy_loss: 0.8998, value_loss: 0.4358
2024-07-14 07:31:06,811 [INFO    ] __main__: train step 20944: loss: 0.9627, policy_loss: 0.8997, value_loss: 0.4358
2024-07-14 07:31:07,102 [INFO    ] __main__: train step 20945: loss: 0.9627, policy_loss: 0.8997, value_loss: 0.4358
2024-07-14 07:31:07,369 [INFO    ] __main__: train step 20946: loss: 0.9627, policy_loss: 0.8997, value_loss: 0.4358
2024-07-14 07:31:07,636 [INFO    ] __main__: train step 20947: loss: 0.9627, policy_loss: 0.8997, value_loss: 0.4358
2024-07-14 07:31:07,920 [INFO    ] __main__: train step 20948: loss: 0.9626, policy_loss: 0.8997, value_loss: 0.4357
2024-07-14 07:31:08,231 [INFO    ] __main__: train step 20949: loss: 0.9626, policy_loss: 0.8997, value_loss: 0.4357
2024-07-14 07:31:08,513 [INFO    ] __main__: train step 20950: loss: 0.9626, policy_loss: 0.8996, value_loss: 0.4357
2024-07-14 07:31:08,772 [INFO    ] __main__: train step 20951: loss: 0.9626, policy_loss: 0.8996, value_loss: 0.4357
2024-07-14 07:31:09,047 [INFO    ] __main__: train step 20952: loss: 0.9626, policy_loss: 0.8996, value_loss: 0.4357
2024-07-14 07:31:09,333 [INFO    ] __main__: train step 20953: loss: 0.9626, policy_loss: 0.8996, value_loss: 0.4357
2024-07-14 07:31:09,628 [INFO    ] __main__: train step 20954: loss: 0.9626, policy_loss: 0.8996, value_loss: 0.4357
2024-07-14 07:31:09,930 [INFO    ] __main__: train step 20955: loss: 0.9625, policy_loss: 0.8996, value_loss: 0.4356
2024-07-14 07:31:10,197 [INFO    ] __main__: train step 20956: loss: 0.9625, policy_loss: 0.8996, value_loss: 0.4356
2024-07-14 07:31:10,470 [INFO    ] __main__: train step 20957: loss: 0.9625, policy_loss: 0.8995, value_loss: 0.4356
2024-07-14 07:31:12,060 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:31:12,545 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:31:12,620 [INFO    ] __main__: train step 20958: loss: 0.9625, policy_loss: 0.8995, value_loss: 0.4356
2024-07-14 07:31:12,915 [INFO    ] __main__: train step 20959: loss: 0.9625, policy_loss: 0.8995, value_loss: 0.4356
2024-07-14 07:31:13,202 [INFO    ] __main__: train step 20960: loss: 0.9625, policy_loss: 0.8995, value_loss: 0.4356
2024-07-14 07:31:13,499 [INFO    ] __main__: train step 20961: loss: 0.9625, policy_loss: 0.8995, value_loss: 0.4355
2024-07-14 07:31:13,802 [INFO    ] __main__: train step 20962: loss: 0.9624, policy_loss: 0.8995, value_loss: 0.4355
2024-07-14 07:31:14,091 [INFO    ] __main__: train step 20963: loss: 0.9624, policy_loss: 0.8994, value_loss: 0.4355
2024-07-14 07:31:14,396 [INFO    ] __main__: train step 20964: loss: 0.9624, policy_loss: 0.8994, value_loss: 0.4355
2024-07-14 07:31:14,706 [INFO    ] __main__: train step 20965: loss: 0.9624, policy_loss: 0.8994, value_loss: 0.4355
2024-07-14 07:31:14,989 [INFO    ] __main__: train step 20966: loss: 0.9624, policy_loss: 0.8994, value_loss: 0.4355
2024-07-14 07:31:15,282 [INFO    ] __main__: train step 20967: loss: 0.9624, policy_loss: 0.8994, value_loss: 0.4354
2024-07-14 07:31:15,577 [INFO    ] __main__: train step 20968: loss: 0.9624, policy_loss: 0.8994, value_loss: 0.4354
2024-07-14 07:31:15,881 [INFO    ] __main__: train step 20969: loss: 0.9623, policy_loss: 0.8993, value_loss: 0.4354
2024-07-14 07:31:16,183 [INFO    ] __main__: train step 20970: loss: 0.9623, policy_loss: 0.8993, value_loss: 0.4354
2024-07-14 07:31:16,471 [INFO    ] __main__: train step 20971: loss: 0.9623, policy_loss: 0.8993, value_loss: 0.4354
2024-07-14 07:31:16,760 [INFO    ] __main__: train step 20972: loss: 0.9623, policy_loss: 0.8993, value_loss: 0.4354
2024-07-14 07:31:17,058 [INFO    ] __main__: train step 20973: loss: 0.9623, policy_loss: 0.8993, value_loss: 0.4354
2024-07-14 07:31:17,345 [INFO    ] __main__: train step 20974: loss: 0.9623, policy_loss: 0.8993, value_loss: 0.4353
2024-07-14 07:31:18,955 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:31:19,429 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:31:19,500 [INFO    ] __main__: train step 20975: loss: 0.9623, policy_loss: 0.8992, value_loss: 0.4353
2024-07-14 07:31:19,794 [INFO    ] __main__: train step 20976: loss: 0.9622, policy_loss: 0.8992, value_loss: 0.4353
2024-07-14 07:31:20,073 [INFO    ] __main__: train step 20977: loss: 0.9622, policy_loss: 0.8992, value_loss: 0.4353
2024-07-14 07:31:20,375 [INFO    ] __main__: train step 20978: loss: 0.9622, policy_loss: 0.8992, value_loss: 0.4353
2024-07-14 07:31:20,663 [INFO    ] __main__: train step 20979: loss: 0.9622, policy_loss: 0.8992, value_loss: 0.4353
2024-07-14 07:31:20,964 [INFO    ] __main__: train step 20980: loss: 0.9622, policy_loss: 0.8992, value_loss: 0.4352
2024-07-14 07:31:21,244 [INFO    ] __main__: train step 20981: loss: 0.9622, policy_loss: 0.8991, value_loss: 0.4352
2024-07-14 07:31:21,509 [INFO    ] __main__: train step 20982: loss: 0.9622, policy_loss: 0.8991, value_loss: 0.4352
2024-07-14 07:31:21,804 [INFO    ] __main__: train step 20983: loss: 0.9622, policy_loss: 0.8991, value_loss: 0.4352
2024-07-14 07:31:22,083 [INFO    ] __main__: train step 20984: loss: 0.9621, policy_loss: 0.8991, value_loss: 0.4352
2024-07-14 07:31:22,384 [INFO    ] __main__: train step 20985: loss: 0.9621, policy_loss: 0.8991, value_loss: 0.4352
2024-07-14 07:31:22,663 [INFO    ] __main__: train step 20986: loss: 0.9621, policy_loss: 0.8991, value_loss: 0.4352
2024-07-14 07:31:22,944 [INFO    ] __main__: train step 20987: loss: 0.9621, policy_loss: 0.8990, value_loss: 0.4351
2024-07-14 07:31:23,224 [INFO    ] __main__: train step 20988: loss: 0.9621, policy_loss: 0.8990, value_loss: 0.4351
2024-07-14 07:31:23,524 [INFO    ] __main__: train step 20989: loss: 0.9621, policy_loss: 0.8990, value_loss: 0.4351
2024-07-14 07:31:23,826 [INFO    ] __main__: train step 20990: loss: 0.9621, policy_loss: 0.8990, value_loss: 0.4351
2024-07-14 07:31:24,127 [INFO    ] __main__: train step 20991: loss: 0.9620, policy_loss: 0.8990, value_loss: 0.4351
2024-07-14 07:31:25,749 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:31:26,209 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:31:26,279 [INFO    ] __main__: train step 20992: loss: 0.9620, policy_loss: 0.8990, value_loss: 0.4351
2024-07-14 07:31:26,578 [INFO    ] __main__: train step 20993: loss: 0.9620, policy_loss: 0.8989, value_loss: 0.4350
2024-07-14 07:31:26,867 [INFO    ] __main__: train step 20994: loss: 0.9620, policy_loss: 0.8989, value_loss: 0.4350
2024-07-14 07:31:27,164 [INFO    ] __main__: train step 20995: loss: 0.9620, policy_loss: 0.8989, value_loss: 0.4350
2024-07-14 07:31:27,449 [INFO    ] __main__: train step 20996: loss: 0.9620, policy_loss: 0.8989, value_loss: 0.4350
2024-07-14 07:31:27,725 [INFO    ] __main__: train step 20997: loss: 0.9620, policy_loss: 0.8989, value_loss: 0.4350
2024-07-14 07:31:28,008 [INFO    ] __main__: train step 20998: loss: 0.9619, policy_loss: 0.8989, value_loss: 0.4350
2024-07-14 07:31:28,311 [INFO    ] __main__: train step 20999: loss: 0.9619, policy_loss: 0.8989, value_loss: 0.4350
2024-07-14 07:31:28,610 [INFO    ] __main__: train step 21000: loss: 0.9619, policy_loss: 0.8988, value_loss: 0.4349
2024-07-14 07:31:28,773 [INFO    ] __main__: restored step 20000 for evaluation
2024-07-14 07:31:34,021 [INFO    ] __main__: test network ELO difference from baseline network: +42 (+8/-8) ELO from 32000 self-played games
2024-07-14 07:31:34,024 [INFO    ] __main__: game outcomes: W: 17469, D: 195, L: 14336
2024-07-14 07:31:34,026 [INFO    ] __main__: validation_elo_delta: 42, validation_elo: 2924
2024-07-14 07:31:34,784 [INFO    ] __main__: train step 21001: loss: 0.9619, policy_loss: 0.8988, value_loss: 0.4349
2024-07-14 07:31:35,093 [INFO    ] __main__: train step 21002: loss: 0.9619, policy_loss: 0.8988, value_loss: 0.4349
2024-07-14 07:31:35,384 [INFO    ] __main__: train step 21003: loss: 0.9619, policy_loss: 0.8988, value_loss: 0.4349
2024-07-14 07:31:35,647 [INFO    ] __main__: train step 21004: loss: 0.9619, policy_loss: 0.8988, value_loss: 0.4349
2024-07-14 07:31:35,942 [INFO    ] __main__: train step 21005: loss: 0.9618, policy_loss: 0.8988, value_loss: 0.4349
2024-07-14 07:31:36,248 [INFO    ] __main__: train step 21006: loss: 0.9618, policy_loss: 0.8987, value_loss: 0.4348
2024-07-14 07:31:36,550 [INFO    ] __main__: train step 21007: loss: 0.9618, policy_loss: 0.8987, value_loss: 0.4348
2024-07-14 07:31:36,858 [INFO    ] __main__: train step 21008: loss: 0.9618, policy_loss: 0.8987, value_loss: 0.4348
2024-07-14 07:31:38,488 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:31:38,951 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:31:39,024 [INFO    ] __main__: train step 21009: loss: 0.9618, policy_loss: 0.8987, value_loss: 0.4348
2024-07-14 07:31:39,301 [INFO    ] __main__: train step 21010: loss: 0.9618, policy_loss: 0.8987, value_loss: 0.4348
2024-07-14 07:31:39,601 [INFO    ] __main__: train step 21011: loss: 0.9618, policy_loss: 0.8987, value_loss: 0.4348
2024-07-14 07:31:39,894 [INFO    ] __main__: train step 21012: loss: 0.9617, policy_loss: 0.8986, value_loss: 0.4347
2024-07-14 07:31:40,187 [INFO    ] __main__: train step 21013: loss: 0.9617, policy_loss: 0.8986, value_loss: 0.4347
2024-07-14 07:31:40,466 [INFO    ] __main__: train step 21014: loss: 0.9617, policy_loss: 0.8986, value_loss: 0.4347
2024-07-14 07:31:40,766 [INFO    ] __main__: train step 21015: loss: 0.9617, policy_loss: 0.8986, value_loss: 0.4347
2024-07-14 07:31:41,065 [INFO    ] __main__: train step 21016: loss: 0.9617, policy_loss: 0.8986, value_loss: 0.4347
2024-07-14 07:31:41,377 [INFO    ] __main__: train step 21017: loss: 0.9617, policy_loss: 0.8986, value_loss: 0.4347
2024-07-14 07:31:41,663 [INFO    ] __main__: train step 21018: loss: 0.9617, policy_loss: 0.8985, value_loss: 0.4347
2024-07-14 07:31:41,925 [INFO    ] __main__: train step 21019: loss: 0.9616, policy_loss: 0.8985, value_loss: 0.4346
2024-07-14 07:31:42,193 [INFO    ] __main__: train step 21020: loss: 0.9616, policy_loss: 0.8985, value_loss: 0.4346
2024-07-14 07:31:46,845 [INFO    ] __main__: train step 21021: loss: 0.9616, policy_loss: 0.8985, value_loss: 0.4346
2024-07-14 07:31:47,122 [INFO    ] __main__: train step 21022: loss: 0.9616, policy_loss: 0.8985, value_loss: 0.4346
2024-07-14 07:31:47,400 [INFO    ] __main__: train step 21023: loss: 0.9616, policy_loss: 0.8985, value_loss: 0.4346
2024-07-14 07:31:47,665 [INFO    ] __main__: train step 21024: loss: 0.9616, policy_loss: 0.8985, value_loss: 0.4346
2024-07-14 07:31:47,939 [INFO    ] __main__: train step 21025: loss: 0.9616, policy_loss: 0.8984, value_loss: 0.4345
2024-07-14 07:31:49,527 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:31:49,997 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:31:50,068 [INFO    ] __main__: train step 21026: loss: 0.9616, policy_loss: 0.8984, value_loss: 0.4345
2024-07-14 07:31:50,338 [INFO    ] __main__: train step 21027: loss: 0.9615, policy_loss: 0.8984, value_loss: 0.4345
2024-07-14 07:31:50,619 [INFO    ] __main__: train step 21028: loss: 0.9615, policy_loss: 0.8984, value_loss: 0.4345
2024-07-14 07:31:50,917 [INFO    ] __main__: train step 21029: loss: 0.9615, policy_loss: 0.8984, value_loss: 0.4345
2024-07-14 07:31:51,196 [INFO    ] __main__: train step 21030: loss: 0.9615, policy_loss: 0.8984, value_loss: 0.4345
2024-07-14 07:31:51,502 [INFO    ] __main__: train step 21031: loss: 0.9615, policy_loss: 0.8983, value_loss: 0.4345
2024-07-14 07:31:51,794 [INFO    ] __main__: train step 21032: loss: 0.9615, policy_loss: 0.8983, value_loss: 0.4344
2024-07-14 07:31:52,094 [INFO    ] __main__: train step 21033: loss: 0.9615, policy_loss: 0.8983, value_loss: 0.4344
2024-07-14 07:31:52,397 [INFO    ] __main__: train step 21034: loss: 0.9614, policy_loss: 0.8983, value_loss: 0.4344
2024-07-14 07:31:52,695 [INFO    ] __main__: train step 21035: loss: 0.9614, policy_loss: 0.8983, value_loss: 0.4344
2024-07-14 07:31:52,979 [INFO    ] __main__: train step 21036: loss: 0.9614, policy_loss: 0.8983, value_loss: 0.4344
2024-07-14 07:31:53,279 [INFO    ] __main__: train step 21037: loss: 0.9614, policy_loss: 0.8982, value_loss: 0.4344
2024-07-14 07:31:53,577 [INFO    ] __main__: train step 21038: loss: 0.9614, policy_loss: 0.8982, value_loss: 0.4343
2024-07-14 07:31:53,874 [INFO    ] __main__: train step 21039: loss: 0.9614, policy_loss: 0.8982, value_loss: 0.4343
2024-07-14 07:31:54,178 [INFO    ] __main__: train step 21040: loss: 0.9614, policy_loss: 0.8982, value_loss: 0.4343
2024-07-14 07:31:54,453 [INFO    ] __main__: train step 21041: loss: 0.9613, policy_loss: 0.8982, value_loss: 0.4343
2024-07-14 07:31:54,742 [INFO    ] __main__: train step 21042: loss: 0.9613, policy_loss: 0.8982, value_loss: 0.4343
2024-07-14 07:31:56,356 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:31:56,849 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:31:56,919 [INFO    ] __main__: train step 21043: loss: 0.9613, policy_loss: 0.8981, value_loss: 0.4343
2024-07-14 07:31:57,221 [INFO    ] __main__: train step 21044: loss: 0.9613, policy_loss: 0.8981, value_loss: 0.4343
2024-07-14 07:31:57,495 [INFO    ] __main__: train step 21045: loss: 0.9613, policy_loss: 0.8981, value_loss: 0.4342
2024-07-14 07:31:57,778 [INFO    ] __main__: train step 21046: loss: 0.9613, policy_loss: 0.8981, value_loss: 0.4342
2024-07-14 07:31:58,064 [INFO    ] __main__: train step 21047: loss: 0.9613, policy_loss: 0.8981, value_loss: 0.4342
2024-07-14 07:31:58,367 [INFO    ] __main__: train step 21048: loss: 0.9612, policy_loss: 0.8981, value_loss: 0.4342
2024-07-14 07:31:58,668 [INFO    ] __main__: train step 21049: loss: 0.9612, policy_loss: 0.8980, value_loss: 0.4342
2024-07-14 07:31:58,952 [INFO    ] __main__: train step 21050: loss: 0.9612, policy_loss: 0.8980, value_loss: 0.4342
2024-07-14 07:31:59,235 [INFO    ] __main__: train step 21051: loss: 0.9612, policy_loss: 0.8980, value_loss: 0.4341
2024-07-14 07:31:59,523 [INFO    ] __main__: train step 21052: loss: 0.9612, policy_loss: 0.8980, value_loss: 0.4341
2024-07-14 07:31:59,821 [INFO    ] __main__: train step 21053: loss: 0.9612, policy_loss: 0.8980, value_loss: 0.4341
2024-07-14 07:32:00,116 [INFO    ] __main__: train step 21054: loss: 0.9612, policy_loss: 0.8980, value_loss: 0.4341
2024-07-14 07:32:00,410 [INFO    ] __main__: train step 21055: loss: 0.9611, policy_loss: 0.8979, value_loss: 0.4341
2024-07-14 07:32:00,701 [INFO    ] __main__: train step 21056: loss: 0.9611, policy_loss: 0.8979, value_loss: 0.4341
2024-07-14 07:32:00,987 [INFO    ] __main__: train step 21057: loss: 0.9611, policy_loss: 0.8979, value_loss: 0.4340
2024-07-14 07:32:01,287 [INFO    ] __main__: train step 21058: loss: 0.9611, policy_loss: 0.8979, value_loss: 0.4340
2024-07-14 07:32:01,598 [INFO    ] __main__: train step 21059: loss: 0.9611, policy_loss: 0.8979, value_loss: 0.4340
2024-07-14 07:32:03,233 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:32:03,711 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:32:03,784 [INFO    ] __main__: train step 21060: loss: 0.9611, policy_loss: 0.8979, value_loss: 0.4340
2024-07-14 07:32:04,054 [INFO    ] __main__: train step 21061: loss: 0.9611, policy_loss: 0.8979, value_loss: 0.4340
2024-07-14 07:32:04,350 [INFO    ] __main__: train step 21062: loss: 0.9610, policy_loss: 0.8978, value_loss: 0.4340
2024-07-14 07:32:04,622 [INFO    ] __main__: train step 21063: loss: 0.9610, policy_loss: 0.8978, value_loss: 0.4340
2024-07-14 07:32:04,901 [INFO    ] __main__: train step 21064: loss: 0.9610, policy_loss: 0.8978, value_loss: 0.4339
2024-07-14 07:32:05,214 [INFO    ] __main__: train step 21065: loss: 0.9610, policy_loss: 0.8978, value_loss: 0.4339
2024-07-14 07:32:05,479 [INFO    ] __main__: train step 21066: loss: 0.9610, policy_loss: 0.8978, value_loss: 0.4339
2024-07-14 07:32:05,775 [INFO    ] __main__: train step 21067: loss: 0.9610, policy_loss: 0.8978, value_loss: 0.4339
2024-07-14 07:32:06,067 [INFO    ] __main__: train step 21068: loss: 0.9610, policy_loss: 0.8977, value_loss: 0.4339
2024-07-14 07:32:06,374 [INFO    ] __main__: train step 21069: loss: 0.9609, policy_loss: 0.8977, value_loss: 0.4339
2024-07-14 07:32:06,670 [INFO    ] __main__: train step 21070: loss: 0.9609, policy_loss: 0.8977, value_loss: 0.4338
2024-07-14 07:32:06,960 [INFO    ] __main__: train step 21071: loss: 0.9609, policy_loss: 0.8977, value_loss: 0.4338
2024-07-14 07:32:07,261 [INFO    ] __main__: train step 21072: loss: 0.9609, policy_loss: 0.8977, value_loss: 0.4338
2024-07-14 07:32:07,567 [INFO    ] __main__: train step 21073: loss: 0.9609, policy_loss: 0.8977, value_loss: 0.4338
2024-07-14 07:32:07,878 [INFO    ] __main__: train step 21074: loss: 0.9609, policy_loss: 0.8976, value_loss: 0.4338
2024-07-14 07:32:08,184 [INFO    ] __main__: train step 21075: loss: 0.9609, policy_loss: 0.8976, value_loss: 0.4338
2024-07-14 07:32:08,481 [INFO    ] __main__: train step 21076: loss: 0.9608, policy_loss: 0.8976, value_loss: 0.4337
2024-07-14 07:32:10,097 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:32:10,578 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:32:10,647 [INFO    ] __main__: train step 21077: loss: 0.9608, policy_loss: 0.8976, value_loss: 0.4337
2024-07-14 07:32:10,942 [INFO    ] __main__: train step 21078: loss: 0.9608, policy_loss: 0.8976, value_loss: 0.4337
2024-07-14 07:32:11,244 [INFO    ] __main__: train step 21079: loss: 0.9608, policy_loss: 0.8976, value_loss: 0.4337
2024-07-14 07:32:11,524 [INFO    ] __main__: train step 21080: loss: 0.9608, policy_loss: 0.8975, value_loss: 0.4337
2024-07-14 07:32:11,820 [INFO    ] __main__: train step 21081: loss: 0.9608, policy_loss: 0.8975, value_loss: 0.4337
2024-07-14 07:32:12,122 [INFO    ] __main__: train step 21082: loss: 0.9607, policy_loss: 0.8975, value_loss: 0.4337
2024-07-14 07:32:12,430 [INFO    ] __main__: train step 21083: loss: 0.9607, policy_loss: 0.8975, value_loss: 0.4336
2024-07-14 07:32:12,734 [INFO    ] __main__: train step 21084: loss: 0.9607, policy_loss: 0.8975, value_loss: 0.4336
2024-07-14 07:32:13,021 [INFO    ] __main__: train step 21085: loss: 0.9607, policy_loss: 0.8975, value_loss: 0.4336
2024-07-14 07:32:13,315 [INFO    ] __main__: train step 21086: loss: 0.9607, policy_loss: 0.8974, value_loss: 0.4336
2024-07-14 07:32:13,610 [INFO    ] __main__: train step 21087: loss: 0.9607, policy_loss: 0.8974, value_loss: 0.4336
2024-07-14 07:32:13,910 [INFO    ] __main__: train step 21088: loss: 0.9607, policy_loss: 0.8974, value_loss: 0.4336
2024-07-14 07:32:14,226 [INFO    ] __main__: train step 21089: loss: 0.9606, policy_loss: 0.8974, value_loss: 0.4335
2024-07-14 07:32:14,515 [INFO    ] __main__: train step 21090: loss: 0.9606, policy_loss: 0.8974, value_loss: 0.4335
2024-07-14 07:32:14,778 [INFO    ] __main__: train step 21091: loss: 0.9606, policy_loss: 0.8974, value_loss: 0.4335
2024-07-14 07:32:15,070 [INFO    ] __main__: train step 21092: loss: 0.9606, policy_loss: 0.8973, value_loss: 0.4335
2024-07-14 07:32:15,391 [INFO    ] __main__: train step 21093: loss: 0.9606, policy_loss: 0.8973, value_loss: 0.4335
2024-07-14 07:32:17,035 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:32:17,521 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:32:17,599 [INFO    ] __main__: train step 21094: loss: 0.9606, policy_loss: 0.8973, value_loss: 0.4335
2024-07-14 07:32:17,873 [INFO    ] __main__: train step 21095: loss: 0.9606, policy_loss: 0.8973, value_loss: 0.4334
2024-07-14 07:32:18,170 [INFO    ] __main__: train step 21096: loss: 0.9605, policy_loss: 0.8973, value_loss: 0.4334
2024-07-14 07:32:18,447 [INFO    ] __main__: train step 21097: loss: 0.9605, policy_loss: 0.8973, value_loss: 0.4334
2024-07-14 07:32:18,762 [INFO    ] __main__: train step 21098: loss: 0.9605, policy_loss: 0.8972, value_loss: 0.4334
2024-07-14 07:32:19,061 [INFO    ] __main__: train step 21099: loss: 0.9605, policy_loss: 0.8972, value_loss: 0.4334
2024-07-14 07:32:19,328 [INFO    ] __main__: train step 21100: loss: 0.9605, policy_loss: 0.8972, value_loss: 0.4334
2024-07-14 07:32:19,629 [INFO    ] __main__: train step 21101: loss: 0.9605, policy_loss: 0.8972, value_loss: 0.4334
2024-07-14 07:32:19,930 [INFO    ] __main__: train step 21102: loss: 0.9605, policy_loss: 0.8972, value_loss: 0.4333
2024-07-14 07:32:20,221 [INFO    ] __main__: train step 21103: loss: 0.9604, policy_loss: 0.8972, value_loss: 0.4333
2024-07-14 07:32:20,513 [INFO    ] __main__: train step 21104: loss: 0.9604, policy_loss: 0.8972, value_loss: 0.4333
2024-07-14 07:32:20,817 [INFO    ] __main__: train step 21105: loss: 0.9604, policy_loss: 0.8971, value_loss: 0.4333
2024-07-14 07:32:21,082 [INFO    ] __main__: train step 21106: loss: 0.9604, policy_loss: 0.8971, value_loss: 0.4333
2024-07-14 07:32:21,370 [INFO    ] __main__: train step 21107: loss: 0.9604, policy_loss: 0.8971, value_loss: 0.4333
2024-07-14 07:32:21,648 [INFO    ] __main__: train step 21108: loss: 0.9604, policy_loss: 0.8971, value_loss: 0.4332
2024-07-14 07:32:21,941 [INFO    ] __main__: train step 21109: loss: 0.9604, policy_loss: 0.8971, value_loss: 0.4332
2024-07-14 07:32:22,232 [INFO    ] __main__: train step 21110: loss: 0.9603, policy_loss: 0.8971, value_loss: 0.4332
2024-07-14 07:32:23,842 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:32:24,324 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:32:24,395 [INFO    ] __main__: train step 21111: loss: 0.9603, policy_loss: 0.8970, value_loss: 0.4332
2024-07-14 07:32:24,658 [INFO    ] __main__: train step 21112: loss: 0.9603, policy_loss: 0.8970, value_loss: 0.4332
2024-07-14 07:32:24,914 [INFO    ] __main__: train step 21113: loss: 0.9603, policy_loss: 0.8970, value_loss: 0.4332
2024-07-14 07:32:25,192 [INFO    ] __main__: train step 21114: loss: 0.9603, policy_loss: 0.8970, value_loss: 0.4332
2024-07-14 07:32:25,473 [INFO    ] __main__: train step 21115: loss: 0.9603, policy_loss: 0.8970, value_loss: 0.4331
2024-07-14 07:32:25,775 [INFO    ] __main__: train step 21116: loss: 0.9603, policy_loss: 0.8970, value_loss: 0.4331
2024-07-14 07:32:26,063 [INFO    ] __main__: train step 21117: loss: 0.9602, policy_loss: 0.8969, value_loss: 0.4331
2024-07-14 07:32:26,360 [INFO    ] __main__: train step 21118: loss: 0.9602, policy_loss: 0.8969, value_loss: 0.4331
2024-07-14 07:32:26,652 [INFO    ] __main__: train step 21119: loss: 0.9602, policy_loss: 0.8969, value_loss: 0.4331
2024-07-14 07:32:26,964 [INFO    ] __main__: train step 21120: loss: 0.9602, policy_loss: 0.8969, value_loss: 0.4331
2024-07-14 07:32:27,229 [INFO    ] __main__: train step 21121: loss: 0.9602, policy_loss: 0.8969, value_loss: 0.4330
2024-07-14 07:32:27,518 [INFO    ] __main__: train step 21122: loss: 0.9602, policy_loss: 0.8969, value_loss: 0.4330
2024-07-14 07:32:27,811 [INFO    ] __main__: train step 21123: loss: 0.9602, policy_loss: 0.8968, value_loss: 0.4330
2024-07-14 07:32:28,119 [INFO    ] __main__: train step 21124: loss: 0.9601, policy_loss: 0.8968, value_loss: 0.4330
2024-07-14 07:32:28,434 [INFO    ] __main__: train step 21125: loss: 0.9601, policy_loss: 0.8968, value_loss: 0.4330
2024-07-14 07:32:28,724 [INFO    ] __main__: train step 21126: loss: 0.9601, policy_loss: 0.8968, value_loss: 0.4330
2024-07-14 07:32:29,006 [INFO    ] __main__: train step 21127: loss: 0.9601, policy_loss: 0.8968, value_loss: 0.4329
2024-07-14 07:32:30,638 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:32:31,117 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:32:31,191 [INFO    ] __main__: train step 21128: loss: 0.9601, policy_loss: 0.8968, value_loss: 0.4329
2024-07-14 07:32:31,469 [INFO    ] __main__: train step 21129: loss: 0.9601, policy_loss: 0.8967, value_loss: 0.4329
2024-07-14 07:32:31,749 [INFO    ] __main__: train step 21130: loss: 0.9601, policy_loss: 0.8967, value_loss: 0.4329
2024-07-14 07:32:32,014 [INFO    ] __main__: train step 21131: loss: 0.9600, policy_loss: 0.8967, value_loss: 0.4329
2024-07-14 07:32:32,281 [INFO    ] __main__: train step 21132: loss: 0.9600, policy_loss: 0.8967, value_loss: 0.4329
2024-07-14 07:32:32,554 [INFO    ] __main__: train step 21133: loss: 0.9600, policy_loss: 0.8967, value_loss: 0.4329
2024-07-14 07:32:32,831 [INFO    ] __main__: train step 21134: loss: 0.9600, policy_loss: 0.8967, value_loss: 0.4328
2024-07-14 07:32:33,113 [INFO    ] __main__: train step 21135: loss: 0.9600, policy_loss: 0.8966, value_loss: 0.4328
2024-07-14 07:32:33,402 [INFO    ] __main__: train step 21136: loss: 0.9600, policy_loss: 0.8966, value_loss: 0.4328
2024-07-14 07:32:33,671 [INFO    ] __main__: train step 21137: loss: 0.9600, policy_loss: 0.8966, value_loss: 0.4328
2024-07-14 07:32:33,973 [INFO    ] __main__: train step 21138: loss: 0.9599, policy_loss: 0.8966, value_loss: 0.4328
2024-07-14 07:32:34,261 [INFO    ] __main__: train step 21139: loss: 0.9599, policy_loss: 0.8966, value_loss: 0.4328
2024-07-14 07:32:34,560 [INFO    ] __main__: train step 21140: loss: 0.9599, policy_loss: 0.8966, value_loss: 0.4327
2024-07-14 07:32:34,889 [INFO    ] __main__: train step 21141: loss: 0.9599, policy_loss: 0.8966, value_loss: 0.4327
2024-07-14 07:32:35,182 [INFO    ] __main__: train step 21142: loss: 0.9599, policy_loss: 0.8965, value_loss: 0.4327
2024-07-14 07:32:35,475 [INFO    ] __main__: train step 21143: loss: 0.9599, policy_loss: 0.8965, value_loss: 0.4327
2024-07-14 07:32:35,771 [INFO    ] __main__: train step 21144: loss: 0.9599, policy_loss: 0.8965, value_loss: 0.4327
2024-07-14 07:32:37,407 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:32:37,896 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:32:37,965 [INFO    ] __main__: train step 21145: loss: 0.9598, policy_loss: 0.8965, value_loss: 0.4327
2024-07-14 07:32:38,248 [INFO    ] __main__: train step 21146: loss: 0.9598, policy_loss: 0.8965, value_loss: 0.4327
2024-07-14 07:32:38,521 [INFO    ] __main__: train step 21147: loss: 0.9598, policy_loss: 0.8965, value_loss: 0.4326
2024-07-14 07:32:38,794 [INFO    ] __main__: train step 21148: loss: 0.9598, policy_loss: 0.8964, value_loss: 0.4326
2024-07-14 07:32:39,090 [INFO    ] __main__: train step 21149: loss: 0.9598, policy_loss: 0.8964, value_loss: 0.4326
2024-07-14 07:32:43,529 [INFO    ] __main__: train step 21150: loss: 0.9598, policy_loss: 0.8964, value_loss: 0.4326
2024-07-14 07:32:43,826 [INFO    ] __main__: train step 21151: loss: 0.9598, policy_loss: 0.8964, value_loss: 0.4326
2024-07-14 07:32:44,120 [INFO    ] __main__: train step 21152: loss: 0.9597, policy_loss: 0.8964, value_loss: 0.4326
2024-07-14 07:32:44,419 [INFO    ] __main__: train step 21153: loss: 0.9597, policy_loss: 0.8964, value_loss: 0.4325
2024-07-14 07:32:44,710 [INFO    ] __main__: train step 21154: loss: 0.9597, policy_loss: 0.8963, value_loss: 0.4325
2024-07-14 07:32:44,992 [INFO    ] __main__: train step 21155: loss: 0.9597, policy_loss: 0.8963, value_loss: 0.4325
2024-07-14 07:32:45,268 [INFO    ] __main__: train step 21156: loss: 0.9597, policy_loss: 0.8963, value_loss: 0.4325
2024-07-14 07:32:45,560 [INFO    ] __main__: train step 21157: loss: 0.9597, policy_loss: 0.8963, value_loss: 0.4325
2024-07-14 07:32:45,855 [INFO    ] __main__: train step 21158: loss: 0.9597, policy_loss: 0.8963, value_loss: 0.4325
2024-07-14 07:32:46,143 [INFO    ] __main__: train step 21159: loss: 0.9596, policy_loss: 0.8963, value_loss: 0.4324
2024-07-14 07:32:46,437 [INFO    ] __main__: train step 21160: loss: 0.9596, policy_loss: 0.8962, value_loss: 0.4324
2024-07-14 07:32:46,724 [INFO    ] __main__: train step 21161: loss: 0.9596, policy_loss: 0.8962, value_loss: 0.4324
2024-07-14 07:32:48,377 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:32:48,865 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:32:48,937 [INFO    ] __main__: train step 21162: loss: 0.9596, policy_loss: 0.8962, value_loss: 0.4324
2024-07-14 07:32:49,200 [INFO    ] __main__: train step 21163: loss: 0.9596, policy_loss: 0.8962, value_loss: 0.4324
2024-07-14 07:32:49,473 [INFO    ] __main__: train step 21164: loss: 0.9596, policy_loss: 0.8962, value_loss: 0.4324
2024-07-14 07:32:49,753 [INFO    ] __main__: train step 21165: loss: 0.9596, policy_loss: 0.8962, value_loss: 0.4324
2024-07-14 07:32:50,053 [INFO    ] __main__: train step 21166: loss: 0.9595, policy_loss: 0.8961, value_loss: 0.4323
2024-07-14 07:32:50,351 [INFO    ] __main__: train step 21167: loss: 0.9595, policy_loss: 0.8961, value_loss: 0.4323
2024-07-14 07:32:50,626 [INFO    ] __main__: train step 21168: loss: 0.9595, policy_loss: 0.8961, value_loss: 0.4323
2024-07-14 07:32:50,924 [INFO    ] __main__: train step 21169: loss: 0.9595, policy_loss: 0.8961, value_loss: 0.4323
2024-07-14 07:32:51,214 [INFO    ] __main__: train step 21170: loss: 0.9595, policy_loss: 0.8961, value_loss: 0.4323
2024-07-14 07:32:51,507 [INFO    ] __main__: train step 21171: loss: 0.9595, policy_loss: 0.8961, value_loss: 0.4323
2024-07-14 07:32:51,794 [INFO    ] __main__: train step 21172: loss: 0.9595, policy_loss: 0.8961, value_loss: 0.4322
2024-07-14 07:32:52,088 [INFO    ] __main__: train step 21173: loss: 0.9594, policy_loss: 0.8960, value_loss: 0.4322
2024-07-14 07:32:52,378 [INFO    ] __main__: train step 21174: loss: 0.9594, policy_loss: 0.8960, value_loss: 0.4322
2024-07-14 07:32:52,703 [INFO    ] __main__: train step 21175: loss: 0.9594, policy_loss: 0.8960, value_loss: 0.4322
2024-07-14 07:32:52,998 [INFO    ] __main__: train step 21176: loss: 0.9594, policy_loss: 0.8960, value_loss: 0.4322
2024-07-14 07:32:53,289 [INFO    ] __main__: train step 21177: loss: 0.9594, policy_loss: 0.8960, value_loss: 0.4322
2024-07-14 07:32:53,578 [INFO    ] __main__: train step 21178: loss: 0.9594, policy_loss: 0.8960, value_loss: 0.4322
2024-07-14 07:32:55,207 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:32:55,687 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:32:55,762 [INFO    ] __main__: train step 21179: loss: 0.9594, policy_loss: 0.8959, value_loss: 0.4321
2024-07-14 07:32:56,068 [INFO    ] __main__: train step 21180: loss: 0.9593, policy_loss: 0.8959, value_loss: 0.4321
2024-07-14 07:32:56,350 [INFO    ] __main__: train step 21181: loss: 0.9593, policy_loss: 0.8959, value_loss: 0.4321
2024-07-14 07:32:56,654 [INFO    ] __main__: train step 21182: loss: 0.9593, policy_loss: 0.8959, value_loss: 0.4321
2024-07-14 07:32:56,957 [INFO    ] __main__: train step 21183: loss: 0.9593, policy_loss: 0.8959, value_loss: 0.4321
2024-07-14 07:32:57,270 [INFO    ] __main__: train step 21184: loss: 0.9593, policy_loss: 0.8959, value_loss: 0.4321
2024-07-14 07:32:57,585 [INFO    ] __main__: train step 21185: loss: 0.9593, policy_loss: 0.8958, value_loss: 0.4320
2024-07-14 07:32:57,886 [INFO    ] __main__: train step 21186: loss: 0.9593, policy_loss: 0.8958, value_loss: 0.4320
2024-07-14 07:32:58,184 [INFO    ] __main__: train step 21187: loss: 0.9592, policy_loss: 0.8958, value_loss: 0.4320
2024-07-14 07:32:58,492 [INFO    ] __main__: train step 21188: loss: 0.9592, policy_loss: 0.8958, value_loss: 0.4320
2024-07-14 07:32:58,793 [INFO    ] __main__: train step 21189: loss: 0.9592, policy_loss: 0.8958, value_loss: 0.4320
2024-07-14 07:32:59,087 [INFO    ] __main__: train step 21190: loss: 0.9592, policy_loss: 0.8958, value_loss: 0.4320
2024-07-14 07:32:59,393 [INFO    ] __main__: train step 21191: loss: 0.9592, policy_loss: 0.8957, value_loss: 0.4319
2024-07-14 07:32:59,679 [INFO    ] __main__: train step 21192: loss: 0.9592, policy_loss: 0.8957, value_loss: 0.4319
2024-07-14 07:32:59,988 [INFO    ] __main__: train step 21193: loss: 0.9592, policy_loss: 0.8957, value_loss: 0.4319
2024-07-14 07:33:00,285 [INFO    ] __main__: train step 21194: loss: 0.9591, policy_loss: 0.8957, value_loss: 0.4319
2024-07-14 07:33:00,566 [INFO    ] __main__: train step 21195: loss: 0.9591, policy_loss: 0.8957, value_loss: 0.4319
2024-07-14 07:33:02,149 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:33:02,631 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:33:02,696 [INFO    ] __main__: train step 21196: loss: 0.9591, policy_loss: 0.8957, value_loss: 0.4319
2024-07-14 07:33:02,979 [INFO    ] __main__: train step 21197: loss: 0.9591, policy_loss: 0.8957, value_loss: 0.4319
2024-07-14 07:33:03,249 [INFO    ] __main__: train step 21198: loss: 0.9591, policy_loss: 0.8956, value_loss: 0.4318
2024-07-14 07:33:03,549 [INFO    ] __main__: train step 21199: loss: 0.9591, policy_loss: 0.8956, value_loss: 0.4318
2024-07-14 07:33:03,847 [INFO    ] __main__: train step 21200: loss: 0.9591, policy_loss: 0.8956, value_loss: 0.4318
2024-07-14 07:33:04,149 [INFO    ] __main__: train step 21201: loss: 0.9590, policy_loss: 0.8956, value_loss: 0.4318
2024-07-14 07:33:04,451 [INFO    ] __main__: train step 21202: loss: 0.9590, policy_loss: 0.8956, value_loss: 0.4318
2024-07-14 07:33:04,751 [INFO    ] __main__: train step 21203: loss: 0.9590, policy_loss: 0.8956, value_loss: 0.4318
2024-07-14 07:33:05,084 [INFO    ] __main__: train step 21204: loss: 0.9590, policy_loss: 0.8955, value_loss: 0.4317
2024-07-14 07:33:05,379 [INFO    ] __main__: train step 21205: loss: 0.9590, policy_loss: 0.8955, value_loss: 0.4317
2024-07-14 07:33:05,691 [INFO    ] __main__: train step 21206: loss: 0.9590, policy_loss: 0.8955, value_loss: 0.4317
2024-07-14 07:33:05,996 [INFO    ] __main__: train step 21207: loss: 0.9590, policy_loss: 0.8955, value_loss: 0.4317
2024-07-14 07:33:06,287 [INFO    ] __main__: train step 21208: loss: 0.9589, policy_loss: 0.8955, value_loss: 0.4317
2024-07-14 07:33:06,594 [INFO    ] __main__: train step 21209: loss: 0.9589, policy_loss: 0.8955, value_loss: 0.4317
2024-07-14 07:33:06,892 [INFO    ] __main__: train step 21210: loss: 0.9589, policy_loss: 0.8954, value_loss: 0.4316
2024-07-14 07:33:07,163 [INFO    ] __main__: train step 21211: loss: 0.9589, policy_loss: 0.8954, value_loss: 0.4316
2024-07-14 07:33:07,440 [INFO    ] __main__: train step 21212: loss: 0.9589, policy_loss: 0.8954, value_loss: 0.4316
2024-07-14 07:33:09,062 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:33:09,544 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:33:09,615 [INFO    ] __main__: train step 21213: loss: 0.9589, policy_loss: 0.8954, value_loss: 0.4316
2024-07-14 07:33:09,913 [INFO    ] __main__: train step 21214: loss: 0.9589, policy_loss: 0.8954, value_loss: 0.4316
2024-07-14 07:33:10,213 [INFO    ] __main__: train step 21215: loss: 0.9588, policy_loss: 0.8954, value_loss: 0.4316
2024-07-14 07:33:10,534 [INFO    ] __main__: train step 21216: loss: 0.9588, policy_loss: 0.8953, value_loss: 0.4316
2024-07-14 07:33:10,838 [INFO    ] __main__: train step 21217: loss: 0.9588, policy_loss: 0.8953, value_loss: 0.4315
2024-07-14 07:33:11,130 [INFO    ] __main__: train step 21218: loss: 0.9588, policy_loss: 0.8953, value_loss: 0.4315
2024-07-14 07:33:11,441 [INFO    ] __main__: train step 21219: loss: 0.9588, policy_loss: 0.8953, value_loss: 0.4315
2024-07-14 07:33:11,743 [INFO    ] __main__: train step 21220: loss: 0.9588, policy_loss: 0.8953, value_loss: 0.4315
2024-07-14 07:33:12,047 [INFO    ] __main__: train step 21221: loss: 0.9588, policy_loss: 0.8953, value_loss: 0.4315
2024-07-14 07:33:12,342 [INFO    ] __main__: train step 21222: loss: 0.9587, policy_loss: 0.8952, value_loss: 0.4315
2024-07-14 07:33:12,648 [INFO    ] __main__: train step 21223: loss: 0.9587, policy_loss: 0.8952, value_loss: 0.4314
2024-07-14 07:33:12,934 [INFO    ] __main__: train step 21224: loss: 0.9587, policy_loss: 0.8952, value_loss: 0.4314
2024-07-14 07:33:13,238 [INFO    ] __main__: train step 21225: loss: 0.9587, policy_loss: 0.8952, value_loss: 0.4314
2024-07-14 07:33:13,558 [INFO    ] __main__: train step 21226: loss: 0.9587, policy_loss: 0.8952, value_loss: 0.4314
2024-07-14 07:33:13,922 [INFO    ] __main__: train step 21227: loss: 0.9587, policy_loss: 0.8952, value_loss: 0.4314
2024-07-14 07:33:14,286 [INFO    ] __main__: train step 21228: loss: 0.9587, policy_loss: 0.8952, value_loss: 0.4314
2024-07-14 07:33:14,584 [INFO    ] __main__: train step 21229: loss: 0.9586, policy_loss: 0.8951, value_loss: 0.4314
2024-07-14 07:33:16,222 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:33:16,702 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:33:16,784 [INFO    ] __main__: train step 21230: loss: 0.9586, policy_loss: 0.8951, value_loss: 0.4313
2024-07-14 07:33:17,085 [INFO    ] __main__: train step 21231: loss: 0.9586, policy_loss: 0.8951, value_loss: 0.4313
2024-07-14 07:33:17,371 [INFO    ] __main__: train step 21232: loss: 0.9586, policy_loss: 0.8951, value_loss: 0.4313
2024-07-14 07:33:17,688 [INFO    ] __main__: train step 21233: loss: 0.9586, policy_loss: 0.8951, value_loss: 0.4313
2024-07-14 07:33:17,992 [INFO    ] __main__: train step 21234: loss: 0.9586, policy_loss: 0.8951, value_loss: 0.4313
2024-07-14 07:33:18,297 [INFO    ] __main__: train step 21235: loss: 0.9586, policy_loss: 0.8950, value_loss: 0.4313
2024-07-14 07:33:18,584 [INFO    ] __main__: train step 21236: loss: 0.9585, policy_loss: 0.8950, value_loss: 0.4312
2024-07-14 07:33:18,884 [INFO    ] __main__: train step 21237: loss: 0.9585, policy_loss: 0.8950, value_loss: 0.4312
2024-07-14 07:33:19,190 [INFO    ] __main__: train step 21238: loss: 0.9585, policy_loss: 0.8950, value_loss: 0.4312
2024-07-14 07:33:19,482 [INFO    ] __main__: train step 21239: loss: 0.9585, policy_loss: 0.8950, value_loss: 0.4312
2024-07-14 07:33:19,791 [INFO    ] __main__: train step 21240: loss: 0.9585, policy_loss: 0.8950, value_loss: 0.4312
2024-07-14 07:33:20,086 [INFO    ] __main__: train step 21241: loss: 0.9585, policy_loss: 0.8949, value_loss: 0.4312
2024-07-14 07:33:20,384 [INFO    ] __main__: train step 21242: loss: 0.9584, policy_loss: 0.8949, value_loss: 0.4311
2024-07-14 07:33:20,669 [INFO    ] __main__: train step 21243: loss: 0.9584, policy_loss: 0.8949, value_loss: 0.4311
2024-07-14 07:33:20,983 [INFO    ] __main__: train step 21244: loss: 0.9584, policy_loss: 0.8949, value_loss: 0.4311
2024-07-14 07:33:21,284 [INFO    ] __main__: train step 21245: loss: 0.9584, policy_loss: 0.8949, value_loss: 0.4311
2024-07-14 07:33:21,586 [INFO    ] __main__: train step 21246: loss: 0.9584, policy_loss: 0.8949, value_loss: 0.4311
2024-07-14 07:33:23,213 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:33:23,687 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:33:23,753 [INFO    ] __main__: train step 21247: loss: 0.9584, policy_loss: 0.8948, value_loss: 0.4311
2024-07-14 07:33:24,056 [INFO    ] __main__: train step 21248: loss: 0.9584, policy_loss: 0.8948, value_loss: 0.4310
2024-07-14 07:33:24,362 [INFO    ] __main__: train step 21249: loss: 0.9583, policy_loss: 0.8948, value_loss: 0.4310
2024-07-14 07:33:24,617 [INFO    ] __main__: train step 21250: loss: 0.9583, policy_loss: 0.8948, value_loss: 0.4310
2024-07-14 07:33:24,870 [INFO    ] __main__: train step 21251: loss: 0.9583, policy_loss: 0.8948, value_loss: 0.4310
2024-07-14 07:33:25,146 [INFO    ] __main__: train step 21252: loss: 0.9583, policy_loss: 0.8948, value_loss: 0.4310
2024-07-14 07:33:25,422 [INFO    ] __main__: train step 21253: loss: 0.9583, policy_loss: 0.8947, value_loss: 0.4310
2024-07-14 07:33:25,706 [INFO    ] __main__: train step 21254: loss: 0.9583, policy_loss: 0.8947, value_loss: 0.4310
2024-07-14 07:33:25,980 [INFO    ] __main__: train step 21255: loss: 0.9583, policy_loss: 0.8947, value_loss: 0.4309
2024-07-14 07:33:26,255 [INFO    ] __main__: train step 21256: loss: 0.9582, policy_loss: 0.8947, value_loss: 0.4309
2024-07-14 07:33:26,530 [INFO    ] __main__: train step 21257: loss: 0.9582, policy_loss: 0.8947, value_loss: 0.4309
2024-07-14 07:33:26,830 [INFO    ] __main__: train step 21258: loss: 0.9582, policy_loss: 0.8947, value_loss: 0.4309
2024-07-14 07:33:27,103 [INFO    ] __main__: train step 21259: loss: 0.9582, policy_loss: 0.8947, value_loss: 0.4309
2024-07-14 07:33:27,389 [INFO    ] __main__: train step 21260: loss: 0.9582, policy_loss: 0.8946, value_loss: 0.4309
2024-07-14 07:33:27,666 [INFO    ] __main__: train step 21261: loss: 0.9582, policy_loss: 0.8946, value_loss: 0.4308
2024-07-14 07:33:27,953 [INFO    ] __main__: train step 21262: loss: 0.9582, policy_loss: 0.8946, value_loss: 0.4308
2024-07-14 07:33:28,245 [INFO    ] __main__: train step 21263: loss: 0.9581, policy_loss: 0.8946, value_loss: 0.4308
2024-07-14 07:33:29,857 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:33:30,315 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:33:30,385 [INFO    ] __main__: train step 21264: loss: 0.9581, policy_loss: 0.8946, value_loss: 0.4308
2024-07-14 07:33:30,667 [INFO    ] __main__: train step 21265: loss: 0.9581, policy_loss: 0.8946, value_loss: 0.4308
2024-07-14 07:33:30,937 [INFO    ] __main__: train step 21266: loss: 0.9581, policy_loss: 0.8945, value_loss: 0.4308
2024-07-14 07:33:31,239 [INFO    ] __main__: train step 21267: loss: 0.9581, policy_loss: 0.8945, value_loss: 0.4307
2024-07-14 07:33:31,528 [INFO    ] __main__: train step 21268: loss: 0.9581, policy_loss: 0.8945, value_loss: 0.4307
2024-07-14 07:33:31,836 [INFO    ] __main__: train step 21269: loss: 0.9581, policy_loss: 0.8945, value_loss: 0.4307
2024-07-14 07:33:32,141 [INFO    ] __main__: train step 21270: loss: 0.9580, policy_loss: 0.8945, value_loss: 0.4307
2024-07-14 07:33:32,402 [INFO    ] __main__: train step 21271: loss: 0.9580, policy_loss: 0.8945, value_loss: 0.4307
2024-07-14 07:33:32,671 [INFO    ] __main__: train step 21272: loss: 0.9580, policy_loss: 0.8944, value_loss: 0.4307
2024-07-14 07:33:32,967 [INFO    ] __main__: train step 21273: loss: 0.9580, policy_loss: 0.8944, value_loss: 0.4307
2024-07-14 07:33:33,255 [INFO    ] __main__: train step 21274: loss: 0.9580, policy_loss: 0.8944, value_loss: 0.4306
2024-07-14 07:33:33,560 [INFO    ] __main__: train step 21275: loss: 0.9580, policy_loss: 0.8944, value_loss: 0.4306
2024-07-14 07:33:33,823 [INFO    ] __main__: train step 21276: loss: 0.9579, policy_loss: 0.8944, value_loss: 0.4306
2024-07-14 07:33:34,137 [INFO    ] __main__: train step 21277: loss: 0.9579, policy_loss: 0.8944, value_loss: 0.4306
2024-07-14 07:33:34,422 [INFO    ] __main__: train step 21278: loss: 0.9579, policy_loss: 0.8943, value_loss: 0.4306
2024-07-14 07:33:34,722 [INFO    ] __main__: train step 21279: loss: 0.9579, policy_loss: 0.8943, value_loss: 0.4306
2024-07-14 07:33:39,467 [INFO    ] __main__: train step 21280: loss: 0.9579, policy_loss: 0.8943, value_loss: 0.4305
2024-07-14 07:33:41,060 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:33:41,570 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:33:41,655 [INFO    ] __main__: train step 21281: loss: 0.9579, policy_loss: 0.8943, value_loss: 0.4305
2024-07-14 07:33:41,947 [INFO    ] __main__: train step 21282: loss: 0.9579, policy_loss: 0.8943, value_loss: 0.4305
2024-07-14 07:33:42,264 [INFO    ] __main__: train step 21283: loss: 0.9578, policy_loss: 0.8943, value_loss: 0.4305
2024-07-14 07:33:42,540 [INFO    ] __main__: train step 21284: loss: 0.9578, policy_loss: 0.8942, value_loss: 0.4305
2024-07-14 07:33:42,846 [INFO    ] __main__: train step 21285: loss: 0.9578, policy_loss: 0.8942, value_loss: 0.4305
2024-07-14 07:33:43,147 [INFO    ] __main__: train step 21286: loss: 0.9578, policy_loss: 0.8942, value_loss: 0.4304
2024-07-14 07:33:43,449 [INFO    ] __main__: train step 21287: loss: 0.9578, policy_loss: 0.8942, value_loss: 0.4304
2024-07-14 07:33:43,746 [INFO    ] __main__: train step 21288: loss: 0.9578, policy_loss: 0.8942, value_loss: 0.4304
2024-07-14 07:33:44,022 [INFO    ] __main__: train step 21289: loss: 0.9578, policy_loss: 0.8942, value_loss: 0.4304
2024-07-14 07:33:44,328 [INFO    ] __main__: train step 21290: loss: 0.9577, policy_loss: 0.8941, value_loss: 0.4304
2024-07-14 07:33:44,644 [INFO    ] __main__: train step 21291: loss: 0.9577, policy_loss: 0.8941, value_loss: 0.4304
2024-07-14 07:33:44,948 [INFO    ] __main__: train step 21292: loss: 0.9577, policy_loss: 0.8941, value_loss: 0.4304
2024-07-14 07:33:45,235 [INFO    ] __main__: train step 21293: loss: 0.9577, policy_loss: 0.8941, value_loss: 0.4303
2024-07-14 07:33:45,533 [INFO    ] __main__: train step 21294: loss: 0.9577, policy_loss: 0.8941, value_loss: 0.4303
2024-07-14 07:33:45,827 [INFO    ] __main__: train step 21295: loss: 0.9577, policy_loss: 0.8941, value_loss: 0.4303
2024-07-14 07:33:46,107 [INFO    ] __main__: train step 21296: loss: 0.9577, policy_loss: 0.8941, value_loss: 0.4303
2024-07-14 07:33:46,403 [INFO    ] __main__: train step 21297: loss: 0.9576, policy_loss: 0.8940, value_loss: 0.4303
2024-07-14 07:33:48,004 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:33:48,475 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:33:48,547 [INFO    ] __main__: train step 21298: loss: 0.9576, policy_loss: 0.8940, value_loss: 0.4303
2024-07-14 07:33:48,851 [INFO    ] __main__: train step 21299: loss: 0.9576, policy_loss: 0.8940, value_loss: 0.4302
2024-07-14 07:33:49,147 [INFO    ] __main__: train step 21300: loss: 0.9576, policy_loss: 0.8940, value_loss: 0.4302
2024-07-14 07:33:49,443 [INFO    ] __main__: train step 21301: loss: 0.9576, policy_loss: 0.8940, value_loss: 0.4302
2024-07-14 07:33:49,729 [INFO    ] __main__: train step 21302: loss: 0.9576, policy_loss: 0.8940, value_loss: 0.4302
2024-07-14 07:33:50,009 [INFO    ] __main__: train step 21303: loss: 0.9575, policy_loss: 0.8939, value_loss: 0.4302
2024-07-14 07:33:50,286 [INFO    ] __main__: train step 21304: loss: 0.9575, policy_loss: 0.8939, value_loss: 0.4302
2024-07-14 07:33:50,583 [INFO    ] __main__: train step 21305: loss: 0.9575, policy_loss: 0.8939, value_loss: 0.4301
2024-07-14 07:33:50,856 [INFO    ] __main__: train step 21306: loss: 0.9575, policy_loss: 0.8939, value_loss: 0.4301
2024-07-14 07:33:51,167 [INFO    ] __main__: train step 21307: loss: 0.9575, policy_loss: 0.8939, value_loss: 0.4301
2024-07-14 07:33:51,455 [INFO    ] __main__: train step 21308: loss: 0.9575, policy_loss: 0.8939, value_loss: 0.4301
2024-07-14 07:33:51,759 [INFO    ] __main__: train step 21309: loss: 0.9575, policy_loss: 0.8938, value_loss: 0.4301
2024-07-14 07:33:52,040 [INFO    ] __main__: train step 21310: loss: 0.9574, policy_loss: 0.8938, value_loss: 0.4301
2024-07-14 07:33:52,330 [INFO    ] __main__: train step 21311: loss: 0.9574, policy_loss: 0.8938, value_loss: 0.4301
2024-07-14 07:33:52,638 [INFO    ] __main__: train step 21312: loss: 0.9574, policy_loss: 0.8938, value_loss: 0.4300
2024-07-14 07:33:52,933 [INFO    ] __main__: train step 21313: loss: 0.9574, policy_loss: 0.8938, value_loss: 0.4300
2024-07-14 07:33:53,235 [INFO    ] __main__: train step 21314: loss: 0.9574, policy_loss: 0.8938, value_loss: 0.4300
2024-07-14 07:33:54,869 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:33:55,343 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:33:55,419 [INFO    ] __main__: train step 21315: loss: 0.9574, policy_loss: 0.8937, value_loss: 0.4300
2024-07-14 07:33:55,733 [INFO    ] __main__: train step 21316: loss: 0.9574, policy_loss: 0.8937, value_loss: 0.4300
2024-07-14 07:33:56,025 [INFO    ] __main__: train step 21317: loss: 0.9573, policy_loss: 0.8937, value_loss: 0.4300
2024-07-14 07:33:56,320 [INFO    ] __main__: train step 21318: loss: 0.9573, policy_loss: 0.8937, value_loss: 0.4299
2024-07-14 07:33:56,585 [INFO    ] __main__: train step 21319: loss: 0.9573, policy_loss: 0.8937, value_loss: 0.4299
2024-07-14 07:33:56,848 [INFO    ] __main__: train step 21320: loss: 0.9573, policy_loss: 0.8937, value_loss: 0.4299
2024-07-14 07:33:57,121 [INFO    ] __main__: train step 21321: loss: 0.9573, policy_loss: 0.8936, value_loss: 0.4299
2024-07-14 07:33:57,447 [INFO    ] __main__: train step 21322: loss: 0.9573, policy_loss: 0.8936, value_loss: 0.4299
2024-07-14 07:33:57,747 [INFO    ] __main__: train step 21323: loss: 0.9573, policy_loss: 0.8936, value_loss: 0.4299
2024-07-14 07:33:58,054 [INFO    ] __main__: train step 21324: loss: 0.9572, policy_loss: 0.8936, value_loss: 0.4298
2024-07-14 07:33:58,322 [INFO    ] __main__: train step 21325: loss: 0.9572, policy_loss: 0.8936, value_loss: 0.4298
2024-07-14 07:33:58,625 [INFO    ] __main__: train step 21326: loss: 0.9572, policy_loss: 0.8936, value_loss: 0.4298
2024-07-14 07:33:58,916 [INFO    ] __main__: train step 21327: loss: 0.9572, policy_loss: 0.8935, value_loss: 0.4298
2024-07-14 07:33:59,186 [INFO    ] __main__: train step 21328: loss: 0.9572, policy_loss: 0.8935, value_loss: 0.4298
2024-07-14 07:33:59,447 [INFO    ] __main__: train step 21329: loss: 0.9572, policy_loss: 0.8935, value_loss: 0.4298
2024-07-14 07:33:59,723 [INFO    ] __main__: train step 21330: loss: 0.9571, policy_loss: 0.8935, value_loss: 0.4298
2024-07-14 07:33:59,985 [INFO    ] __main__: train step 21331: loss: 0.9571, policy_loss: 0.8935, value_loss: 0.4297
2024-07-14 07:34:01,606 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:34:02,068 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:34:02,138 [INFO    ] __main__: train step 21332: loss: 0.9571, policy_loss: 0.8935, value_loss: 0.4297
2024-07-14 07:34:02,447 [INFO    ] __main__: train step 21333: loss: 0.9571, policy_loss: 0.8935, value_loss: 0.4297
2024-07-14 07:34:02,736 [INFO    ] __main__: train step 21334: loss: 0.9571, policy_loss: 0.8934, value_loss: 0.4297
2024-07-14 07:34:03,031 [INFO    ] __main__: train step 21335: loss: 0.9571, policy_loss: 0.8934, value_loss: 0.4297
2024-07-14 07:34:03,338 [INFO    ] __main__: train step 21336: loss: 0.9571, policy_loss: 0.8934, value_loss: 0.4297
2024-07-14 07:34:03,653 [INFO    ] __main__: train step 21337: loss: 0.9570, policy_loss: 0.8934, value_loss: 0.4296
2024-07-14 07:34:03,986 [INFO    ] __main__: train step 21338: loss: 0.9570, policy_loss: 0.8934, value_loss: 0.4296
2024-07-14 07:34:04,286 [INFO    ] __main__: train step 21339: loss: 0.9570, policy_loss: 0.8934, value_loss: 0.4296
2024-07-14 07:34:04,588 [INFO    ] __main__: train step 21340: loss: 0.9570, policy_loss: 0.8933, value_loss: 0.4296
2024-07-14 07:34:04,889 [INFO    ] __main__: train step 21341: loss: 0.9570, policy_loss: 0.8933, value_loss: 0.4296
2024-07-14 07:34:05,186 [INFO    ] __main__: train step 21342: loss: 0.9570, policy_loss: 0.8933, value_loss: 0.4296
2024-07-14 07:34:05,486 [INFO    ] __main__: train step 21343: loss: 0.9570, policy_loss: 0.8933, value_loss: 0.4296
2024-07-14 07:34:05,785 [INFO    ] __main__: train step 21344: loss: 0.9569, policy_loss: 0.8933, value_loss: 0.4295
2024-07-14 07:34:06,041 [INFO    ] __main__: train step 21345: loss: 0.9569, policy_loss: 0.8933, value_loss: 0.4295
2024-07-14 07:34:06,307 [INFO    ] __main__: train step 21346: loss: 0.9569, policy_loss: 0.8932, value_loss: 0.4295
2024-07-14 07:34:06,583 [INFO    ] __main__: train step 21347: loss: 0.9569, policy_loss: 0.8932, value_loss: 0.4295
2024-07-14 07:34:06,883 [INFO    ] __main__: train step 21348: loss: 0.9569, policy_loss: 0.8932, value_loss: 0.4295
2024-07-14 07:34:08,487 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:34:08,964 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:34:09,035 [INFO    ] __main__: train step 21349: loss: 0.9569, policy_loss: 0.8932, value_loss: 0.4295
2024-07-14 07:34:09,323 [INFO    ] __main__: train step 21350: loss: 0.9569, policy_loss: 0.8932, value_loss: 0.4294
2024-07-14 07:34:09,612 [INFO    ] __main__: train step 21351: loss: 0.9568, policy_loss: 0.8932, value_loss: 0.4294
2024-07-14 07:34:09,898 [INFO    ] __main__: train step 21352: loss: 0.9568, policy_loss: 0.8931, value_loss: 0.4294
2024-07-14 07:34:10,186 [INFO    ] __main__: train step 21353: loss: 0.9568, policy_loss: 0.8931, value_loss: 0.4294
2024-07-14 07:34:10,503 [INFO    ] __main__: train step 21354: loss: 0.9568, policy_loss: 0.8931, value_loss: 0.4294
2024-07-14 07:34:10,789 [INFO    ] __main__: train step 21355: loss: 0.9568, policy_loss: 0.8931, value_loss: 0.4294
2024-07-14 07:34:11,076 [INFO    ] __main__: train step 21356: loss: 0.9568, policy_loss: 0.8931, value_loss: 0.4293
2024-07-14 07:34:11,359 [INFO    ] __main__: train step 21357: loss: 0.9568, policy_loss: 0.8931, value_loss: 0.4293
2024-07-14 07:34:11,651 [INFO    ] __main__: train step 21358: loss: 0.9567, policy_loss: 0.8931, value_loss: 0.4293
2024-07-14 07:34:11,948 [INFO    ] __main__: train step 21359: loss: 0.9567, policy_loss: 0.8930, value_loss: 0.4293
2024-07-14 07:34:12,242 [INFO    ] __main__: train step 21360: loss: 0.9567, policy_loss: 0.8930, value_loss: 0.4293
2024-07-14 07:34:12,543 [INFO    ] __main__: train step 21361: loss: 0.9567, policy_loss: 0.8930, value_loss: 0.4293
2024-07-14 07:34:12,879 [INFO    ] __main__: train step 21362: loss: 0.9567, policy_loss: 0.8930, value_loss: 0.4293
2024-07-14 07:34:13,165 [INFO    ] __main__: train step 21363: loss: 0.9567, policy_loss: 0.8930, value_loss: 0.4292
2024-07-14 07:34:13,467 [INFO    ] __main__: train step 21364: loss: 0.9566, policy_loss: 0.8930, value_loss: 0.4292
2024-07-14 07:34:13,769 [INFO    ] __main__: train step 21365: loss: 0.9566, policy_loss: 0.8929, value_loss: 0.4292
2024-07-14 07:34:15,404 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:34:15,897 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:34:15,970 [INFO    ] __main__: train step 21366: loss: 0.9566, policy_loss: 0.8929, value_loss: 0.4292
2024-07-14 07:34:16,246 [INFO    ] __main__: train step 21367: loss: 0.9566, policy_loss: 0.8929, value_loss: 0.4292
2024-07-14 07:34:16,523 [INFO    ] __main__: train step 21368: loss: 0.9566, policy_loss: 0.8929, value_loss: 0.4292
2024-07-14 07:34:16,810 [INFO    ] __main__: train step 21369: loss: 0.9566, policy_loss: 0.8929, value_loss: 0.4291
2024-07-14 07:34:17,105 [INFO    ] __main__: train step 21370: loss: 0.9566, policy_loss: 0.8929, value_loss: 0.4291
2024-07-14 07:34:17,398 [INFO    ] __main__: train step 21371: loss: 0.9565, policy_loss: 0.8928, value_loss: 0.4291
2024-07-14 07:34:17,689 [INFO    ] __main__: train step 21372: loss: 0.9565, policy_loss: 0.8928, value_loss: 0.4291
2024-07-14 07:34:17,998 [INFO    ] __main__: train step 21373: loss: 0.9565, policy_loss: 0.8928, value_loss: 0.4291
2024-07-14 07:34:18,306 [INFO    ] __main__: train step 21374: loss: 0.9565, policy_loss: 0.8928, value_loss: 0.4291
2024-07-14 07:34:18,605 [INFO    ] __main__: train step 21375: loss: 0.9565, policy_loss: 0.8928, value_loss: 0.4290
2024-07-14 07:34:18,907 [INFO    ] __main__: train step 21376: loss: 0.9565, policy_loss: 0.8928, value_loss: 0.4290
2024-07-14 07:34:19,218 [INFO    ] __main__: train step 21377: loss: 0.9565, policy_loss: 0.8927, value_loss: 0.4290
2024-07-14 07:34:19,508 [INFO    ] __main__: train step 21378: loss: 0.9564, policy_loss: 0.8927, value_loss: 0.4290
2024-07-14 07:34:19,782 [INFO    ] __main__: train step 21379: loss: 0.9564, policy_loss: 0.8927, value_loss: 0.4290
2024-07-14 07:34:20,075 [INFO    ] __main__: train step 21380: loss: 0.9564, policy_loss: 0.8927, value_loss: 0.4290
2024-07-14 07:34:20,371 [INFO    ] __main__: train step 21381: loss: 0.9564, policy_loss: 0.8927, value_loss: 0.4289
2024-07-14 07:34:20,643 [INFO    ] __main__: train step 21382: loss: 0.9564, policy_loss: 0.8927, value_loss: 0.4289
2024-07-14 07:34:22,239 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:34:22,716 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:34:22,786 [INFO    ] __main__: train step 21383: loss: 0.9564, policy_loss: 0.8926, value_loss: 0.4289
2024-07-14 07:34:23,071 [INFO    ] __main__: train step 21384: loss: 0.9563, policy_loss: 0.8926, value_loss: 0.4289
2024-07-14 07:34:23,369 [INFO    ] __main__: train step 21385: loss: 0.9563, policy_loss: 0.8926, value_loss: 0.4289
2024-07-14 07:34:23,674 [INFO    ] __main__: train step 21386: loss: 0.9563, policy_loss: 0.8926, value_loss: 0.4289
2024-07-14 07:34:23,964 [INFO    ] __main__: train step 21387: loss: 0.9563, policy_loss: 0.8926, value_loss: 0.4288
2024-07-14 07:34:24,267 [INFO    ] __main__: train step 21388: loss: 0.9563, policy_loss: 0.8926, value_loss: 0.4288
2024-07-14 07:34:24,569 [INFO    ] __main__: train step 21389: loss: 0.9563, policy_loss: 0.8925, value_loss: 0.4288
2024-07-14 07:34:24,870 [INFO    ] __main__: train step 21390: loss: 0.9563, policy_loss: 0.8925, value_loss: 0.4288
2024-07-14 07:34:25,156 [INFO    ] __main__: train step 21391: loss: 0.9562, policy_loss: 0.8925, value_loss: 0.4288
2024-07-14 07:34:25,431 [INFO    ] __main__: train step 21392: loss: 0.9562, policy_loss: 0.8925, value_loss: 0.4288
2024-07-14 07:34:25,731 [INFO    ] __main__: train step 21393: loss: 0.9562, policy_loss: 0.8925, value_loss: 0.4288
2024-07-14 07:34:26,030 [INFO    ] __main__: train step 21394: loss: 0.9562, policy_loss: 0.8925, value_loss: 0.4287
2024-07-14 07:34:26,328 [INFO    ] __main__: train step 21395: loss: 0.9562, policy_loss: 0.8925, value_loss: 0.4287
2024-07-14 07:34:26,615 [INFO    ] __main__: train step 21396: loss: 0.9562, policy_loss: 0.8924, value_loss: 0.4287
2024-07-14 07:34:26,906 [INFO    ] __main__: train step 21397: loss: 0.9561, policy_loss: 0.8924, value_loss: 0.4287
2024-07-14 07:34:27,203 [INFO    ] __main__: train step 21398: loss: 0.9561, policy_loss: 0.8924, value_loss: 0.4287
2024-07-14 07:34:27,458 [INFO    ] __main__: train step 21399: loss: 0.9561, policy_loss: 0.8924, value_loss: 0.4287
2024-07-14 07:34:29,055 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:34:29,520 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:34:29,594 [INFO    ] __main__: train step 21400: loss: 0.9561, policy_loss: 0.8924, value_loss: 0.4286
2024-07-14 07:34:29,889 [INFO    ] __main__: train step 21401: loss: 0.9561, policy_loss: 0.8924, value_loss: 0.4286
2024-07-14 07:34:30,184 [INFO    ] __main__: train step 21402: loss: 0.9561, policy_loss: 0.8923, value_loss: 0.4286
2024-07-14 07:34:30,473 [INFO    ] __main__: train step 21403: loss: 0.9561, policy_loss: 0.8923, value_loss: 0.4286
2024-07-14 07:34:30,750 [INFO    ] __main__: train step 21404: loss: 0.9560, policy_loss: 0.8923, value_loss: 0.4286
2024-07-14 07:34:31,015 [INFO    ] __main__: train step 21405: loss: 0.9560, policy_loss: 0.8923, value_loss: 0.4286
2024-07-14 07:34:31,332 [INFO    ] __main__: train step 21406: loss: 0.9560, policy_loss: 0.8923, value_loss: 0.4285
2024-07-14 07:34:35,818 [INFO    ] __main__: train step 21407: loss: 0.9560, policy_loss: 0.8923, value_loss: 0.4285
2024-07-14 07:34:36,122 [INFO    ] __main__: train step 21408: loss: 0.9560, policy_loss: 0.8922, value_loss: 0.4285
2024-07-14 07:34:36,415 [INFO    ] __main__: train step 21409: loss: 0.9560, policy_loss: 0.8922, value_loss: 0.4285
2024-07-14 07:34:36,710 [INFO    ] __main__: train step 21410: loss: 0.9560, policy_loss: 0.8922, value_loss: 0.4285
2024-07-14 07:34:37,007 [INFO    ] __main__: train step 21411: loss: 0.9559, policy_loss: 0.8922, value_loss: 0.4285
2024-07-14 07:34:37,301 [INFO    ] __main__: train step 21412: loss: 0.9559, policy_loss: 0.8922, value_loss: 0.4284
2024-07-14 07:34:37,591 [INFO    ] __main__: train step 21413: loss: 0.9559, policy_loss: 0.8922, value_loss: 0.4284
2024-07-14 07:34:37,898 [INFO    ] __main__: train step 21414: loss: 0.9559, policy_loss: 0.8921, value_loss: 0.4284
2024-07-14 07:34:38,214 [INFO    ] __main__: train step 21415: loss: 0.9559, policy_loss: 0.8921, value_loss: 0.4284
2024-07-14 07:34:38,526 [INFO    ] __main__: train step 21416: loss: 0.9559, policy_loss: 0.8921, value_loss: 0.4284
2024-07-14 07:34:40,151 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:34:40,646 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:34:40,716 [INFO    ] __main__: train step 21417: loss: 0.9558, policy_loss: 0.8921, value_loss: 0.4284
2024-07-14 07:34:41,028 [INFO    ] __main__: train step 21418: loss: 0.9558, policy_loss: 0.8921, value_loss: 0.4283
2024-07-14 07:34:41,317 [INFO    ] __main__: train step 21419: loss: 0.9558, policy_loss: 0.8921, value_loss: 0.4283
2024-07-14 07:34:41,621 [INFO    ] __main__: train step 21420: loss: 0.9558, policy_loss: 0.8921, value_loss: 0.4283
2024-07-14 07:34:41,931 [INFO    ] __main__: train step 21421: loss: 0.9558, policy_loss: 0.8920, value_loss: 0.4283
2024-07-14 07:34:42,226 [INFO    ] __main__: train step 21422: loss: 0.9558, policy_loss: 0.8920, value_loss: 0.4283
2024-07-14 07:34:42,530 [INFO    ] __main__: train step 21423: loss: 0.9558, policy_loss: 0.8920, value_loss: 0.4283
2024-07-14 07:34:42,828 [INFO    ] __main__: train step 21424: loss: 0.9557, policy_loss: 0.8920, value_loss: 0.4282
2024-07-14 07:34:43,134 [INFO    ] __main__: train step 21425: loss: 0.9557, policy_loss: 0.8920, value_loss: 0.4282
2024-07-14 07:34:43,435 [INFO    ] __main__: train step 21426: loss: 0.9557, policy_loss: 0.8920, value_loss: 0.4282
2024-07-14 07:34:43,744 [INFO    ] __main__: train step 21427: loss: 0.9557, policy_loss: 0.8919, value_loss: 0.4282
2024-07-14 07:34:44,043 [INFO    ] __main__: train step 21428: loss: 0.9557, policy_loss: 0.8919, value_loss: 0.4282
2024-07-14 07:34:44,339 [INFO    ] __main__: train step 21429: loss: 0.9557, policy_loss: 0.8919, value_loss: 0.4282
2024-07-14 07:34:44,652 [INFO    ] __main__: train step 21430: loss: 0.9556, policy_loss: 0.8919, value_loss: 0.4281
2024-07-14 07:34:44,957 [INFO    ] __main__: train step 21431: loss: 0.9556, policy_loss: 0.8919, value_loss: 0.4281
2024-07-14 07:34:45,268 [INFO    ] __main__: train step 21432: loss: 0.9556, policy_loss: 0.8919, value_loss: 0.4281
2024-07-14 07:34:45,532 [INFO    ] __main__: train step 21433: loss: 0.9556, policy_loss: 0.8918, value_loss: 0.4281
2024-07-14 07:34:47,160 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:34:47,616 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:34:47,682 [INFO    ] __main__: train step 21434: loss: 0.9556, policy_loss: 0.8918, value_loss: 0.4281
2024-07-14 07:34:47,971 [INFO    ] __main__: train step 21435: loss: 0.9556, policy_loss: 0.8918, value_loss: 0.4281
2024-07-14 07:34:48,270 [INFO    ] __main__: train step 21436: loss: 0.9556, policy_loss: 0.8918, value_loss: 0.4280
2024-07-14 07:34:48,542 [INFO    ] __main__: train step 21437: loss: 0.9555, policy_loss: 0.8918, value_loss: 0.4280
2024-07-14 07:34:48,811 [INFO    ] __main__: train step 21438: loss: 0.9555, policy_loss: 0.8918, value_loss: 0.4280
2024-07-14 07:34:49,106 [INFO    ] __main__: train step 21439: loss: 0.9555, policy_loss: 0.8918, value_loss: 0.4280
2024-07-14 07:34:49,405 [INFO    ] __main__: train step 21440: loss: 0.9555, policy_loss: 0.8917, value_loss: 0.4280
2024-07-14 07:34:49,694 [INFO    ] __main__: train step 21441: loss: 0.9555, policy_loss: 0.8917, value_loss: 0.4280
2024-07-14 07:34:49,981 [INFO    ] __main__: train step 21442: loss: 0.9555, policy_loss: 0.8917, value_loss: 0.4279
2024-07-14 07:34:50,308 [INFO    ] __main__: train step 21443: loss: 0.9554, policy_loss: 0.8917, value_loss: 0.4279
2024-07-14 07:34:50,607 [INFO    ] __main__: train step 21444: loss: 0.9554, policy_loss: 0.8917, value_loss: 0.4279
2024-07-14 07:34:50,917 [INFO    ] __main__: train step 21445: loss: 0.9554, policy_loss: 0.8917, value_loss: 0.4279
2024-07-14 07:34:51,230 [INFO    ] __main__: train step 21446: loss: 0.9554, policy_loss: 0.8916, value_loss: 0.4279
2024-07-14 07:34:51,519 [INFO    ] __main__: train step 21447: loss: 0.9554, policy_loss: 0.8916, value_loss: 0.4279
2024-07-14 07:34:51,815 [INFO    ] __main__: train step 21448: loss: 0.9554, policy_loss: 0.8916, value_loss: 0.4279
2024-07-14 07:34:52,111 [INFO    ] __main__: train step 21449: loss: 0.9554, policy_loss: 0.8916, value_loss: 0.4278
2024-07-14 07:34:52,424 [INFO    ] __main__: train step 21450: loss: 0.9553, policy_loss: 0.8916, value_loss: 0.4278
2024-07-14 07:34:54,053 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:34:54,523 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:34:54,593 [INFO    ] __main__: train step 21451: loss: 0.9553, policy_loss: 0.8916, value_loss: 0.4278
2024-07-14 07:34:54,932 [INFO    ] __main__: train step 21452: loss: 0.9553, policy_loss: 0.8915, value_loss: 0.4278
2024-07-14 07:34:55,225 [INFO    ] __main__: train step 21453: loss: 0.9553, policy_loss: 0.8915, value_loss: 0.4278
2024-07-14 07:34:55,529 [INFO    ] __main__: train step 21454: loss: 0.9553, policy_loss: 0.8915, value_loss: 0.4278
2024-07-14 07:34:55,829 [INFO    ] __main__: train step 21455: loss: 0.9553, policy_loss: 0.8915, value_loss: 0.4277
2024-07-14 07:34:56,134 [INFO    ] __main__: train step 21456: loss: 0.9552, policy_loss: 0.8915, value_loss: 0.4277
2024-07-14 07:34:56,432 [INFO    ] __main__: train step 21457: loss: 0.9552, policy_loss: 0.8915, value_loss: 0.4277
2024-07-14 07:34:56,718 [INFO    ] __main__: train step 21458: loss: 0.9552, policy_loss: 0.8914, value_loss: 0.4277
2024-07-14 07:34:57,028 [INFO    ] __main__: train step 21459: loss: 0.9552, policy_loss: 0.8914, value_loss: 0.4277
2024-07-14 07:34:57,328 [INFO    ] __main__: train step 21460: loss: 0.9552, policy_loss: 0.8914, value_loss: 0.4277
2024-07-14 07:34:57,624 [INFO    ] __main__: train step 21461: loss: 0.9552, policy_loss: 0.8914, value_loss: 0.4276
2024-07-14 07:34:57,925 [INFO    ] __main__: train step 21462: loss: 0.9552, policy_loss: 0.8914, value_loss: 0.4276
2024-07-14 07:34:58,207 [INFO    ] __main__: train step 21463: loss: 0.9551, policy_loss: 0.8914, value_loss: 0.4276
2024-07-14 07:34:58,492 [INFO    ] __main__: train step 21464: loss: 0.9551, policy_loss: 0.8914, value_loss: 0.4276
2024-07-14 07:34:58,800 [INFO    ] __main__: train step 21465: loss: 0.9551, policy_loss: 0.8913, value_loss: 0.4276
2024-07-14 07:34:59,121 [INFO    ] __main__: train step 21466: loss: 0.9551, policy_loss: 0.8913, value_loss: 0.4276
2024-07-14 07:34:59,421 [INFO    ] __main__: train step 21467: loss: 0.9551, policy_loss: 0.8913, value_loss: 0.4275
2024-07-14 07:35:01,068 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:35:01,532 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:35:01,611 [INFO    ] __main__: train step 21468: loss: 0.9551, policy_loss: 0.8913, value_loss: 0.4275
2024-07-14 07:35:01,904 [INFO    ] __main__: train step 21469: loss: 0.9550, policy_loss: 0.8913, value_loss: 0.4275
2024-07-14 07:35:02,198 [INFO    ] __main__: train step 21470: loss: 0.9550, policy_loss: 0.8913, value_loss: 0.4275
2024-07-14 07:35:02,492 [INFO    ] __main__: train step 21471: loss: 0.9550, policy_loss: 0.8912, value_loss: 0.4275
2024-07-14 07:35:02,784 [INFO    ] __main__: train step 21472: loss: 0.9550, policy_loss: 0.8912, value_loss: 0.4275
2024-07-14 07:35:03,077 [INFO    ] __main__: train step 21473: loss: 0.9550, policy_loss: 0.8912, value_loss: 0.4274
2024-07-14 07:35:03,370 [INFO    ] __main__: train step 21474: loss: 0.9550, policy_loss: 0.8912, value_loss: 0.4274
2024-07-14 07:35:03,660 [INFO    ] __main__: train step 21475: loss: 0.9550, policy_loss: 0.8912, value_loss: 0.4274
2024-07-14 07:35:03,955 [INFO    ] __main__: train step 21476: loss: 0.9549, policy_loss: 0.8912, value_loss: 0.4274
2024-07-14 07:35:04,268 [INFO    ] __main__: train step 21477: loss: 0.9549, policy_loss: 0.8911, value_loss: 0.4274
2024-07-14 07:35:04,542 [INFO    ] __main__: train step 21478: loss: 0.9549, policy_loss: 0.8911, value_loss: 0.4274
2024-07-14 07:35:04,824 [INFO    ] __main__: train step 21479: loss: 0.9549, policy_loss: 0.8911, value_loss: 0.4273
2024-07-14 07:35:05,115 [INFO    ] __main__: train step 21480: loss: 0.9549, policy_loss: 0.8911, value_loss: 0.4273
2024-07-14 07:35:05,402 [INFO    ] __main__: train step 21481: loss: 0.9549, policy_loss: 0.8911, value_loss: 0.4273
2024-07-14 07:35:05,690 [INFO    ] __main__: train step 21482: loss: 0.9548, policy_loss: 0.8911, value_loss: 0.4273
2024-07-14 07:35:05,978 [INFO    ] __main__: train step 21483: loss: 0.9548, policy_loss: 0.8911, value_loss: 0.4273
2024-07-14 07:35:06,280 [INFO    ] __main__: train step 21484: loss: 0.9548, policy_loss: 0.8910, value_loss: 0.4273
2024-07-14 07:35:07,900 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:35:08,395 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:35:08,468 [INFO    ] __main__: train step 21485: loss: 0.9548, policy_loss: 0.8910, value_loss: 0.4272
2024-07-14 07:35:08,756 [INFO    ] __main__: train step 21486: loss: 0.9548, policy_loss: 0.8910, value_loss: 0.4272
2024-07-14 07:35:09,045 [INFO    ] __main__: train step 21487: loss: 0.9548, policy_loss: 0.8910, value_loss: 0.4272
2024-07-14 07:35:09,303 [INFO    ] __main__: train step 21488: loss: 0.9548, policy_loss: 0.8910, value_loss: 0.4272
2024-07-14 07:35:09,597 [INFO    ] __main__: train step 21489: loss: 0.9547, policy_loss: 0.8910, value_loss: 0.4272
2024-07-14 07:35:09,886 [INFO    ] __main__: train step 21490: loss: 0.9547, policy_loss: 0.8909, value_loss: 0.4272
2024-07-14 07:35:10,171 [INFO    ] __main__: train step 21491: loss: 0.9547, policy_loss: 0.8909, value_loss: 0.4271
2024-07-14 07:35:10,463 [INFO    ] __main__: train step 21492: loss: 0.9547, policy_loss: 0.8909, value_loss: 0.4271
2024-07-14 07:35:10,785 [INFO    ] __main__: train step 21493: loss: 0.9547, policy_loss: 0.8909, value_loss: 0.4271
2024-07-14 07:35:11,069 [INFO    ] __main__: train step 21494: loss: 0.9547, policy_loss: 0.8909, value_loss: 0.4271
2024-07-14 07:35:11,341 [INFO    ] __main__: train step 21495: loss: 0.9546, policy_loss: 0.8909, value_loss: 0.4271
2024-07-14 07:35:11,630 [INFO    ] __main__: train step 21496: loss: 0.9546, policy_loss: 0.8908, value_loss: 0.4271
2024-07-14 07:35:11,913 [INFO    ] __main__: train step 21497: loss: 0.9546, policy_loss: 0.8908, value_loss: 0.4270
2024-07-14 07:35:12,222 [INFO    ] __main__: train step 21498: loss: 0.9546, policy_loss: 0.8908, value_loss: 0.4270
2024-07-14 07:35:12,531 [INFO    ] __main__: train step 21499: loss: 0.9546, policy_loss: 0.8908, value_loss: 0.4270
2024-07-14 07:35:12,822 [INFO    ] __main__: train step 21500: loss: 0.9546, policy_loss: 0.8908, value_loss: 0.4270
2024-07-14 07:35:13,118 [INFO    ] __main__: train step 21501: loss: 0.9546, policy_loss: 0.8908, value_loss: 0.4270
2024-07-14 07:35:14,767 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:35:15,247 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:35:15,329 [INFO    ] __main__: train step 21502: loss: 0.9545, policy_loss: 0.8908, value_loss: 0.4270
2024-07-14 07:35:15,595 [INFO    ] __main__: train step 21503: loss: 0.9545, policy_loss: 0.8907, value_loss: 0.4269
2024-07-14 07:35:15,880 [INFO    ] __main__: train step 21504: loss: 0.9545, policy_loss: 0.8907, value_loss: 0.4269
2024-07-14 07:35:16,166 [INFO    ] __main__: train step 21505: loss: 0.9545, policy_loss: 0.8907, value_loss: 0.4269
2024-07-14 07:35:16,468 [INFO    ] __main__: train step 21506: loss: 0.9545, policy_loss: 0.8907, value_loss: 0.4269
2024-07-14 07:35:16,760 [INFO    ] __main__: train step 21507: loss: 0.9545, policy_loss: 0.8907, value_loss: 0.4269
2024-07-14 07:35:17,049 [INFO    ] __main__: train step 21508: loss: 0.9544, policy_loss: 0.8907, value_loss: 0.4269
2024-07-14 07:35:17,332 [INFO    ] __main__: train step 21509: loss: 0.9544, policy_loss: 0.8906, value_loss: 0.4268
2024-07-14 07:35:17,632 [INFO    ] __main__: train step 21510: loss: 0.9544, policy_loss: 0.8906, value_loss: 0.4268
2024-07-14 07:35:17,930 [INFO    ] __main__: train step 21511: loss: 0.9544, policy_loss: 0.8906, value_loss: 0.4268
2024-07-14 07:35:18,232 [INFO    ] __main__: train step 21512: loss: 0.9544, policy_loss: 0.8906, value_loss: 0.4268
2024-07-14 07:35:18,500 [INFO    ] __main__: train step 21513: loss: 0.9544, policy_loss: 0.8906, value_loss: 0.4268
2024-07-14 07:35:18,781 [INFO    ] __main__: train step 21514: loss: 0.9544, policy_loss: 0.8906, value_loss: 0.4268
2024-07-14 07:35:19,074 [INFO    ] __main__: train step 21515: loss: 0.9543, policy_loss: 0.8905, value_loss: 0.4267
2024-07-14 07:35:19,377 [INFO    ] __main__: train step 21516: loss: 0.9543, policy_loss: 0.8905, value_loss: 0.4267
2024-07-14 07:35:19,668 [INFO    ] __main__: train step 21517: loss: 0.9543, policy_loss: 0.8905, value_loss: 0.4267
2024-07-14 07:35:19,960 [INFO    ] __main__: train step 21518: loss: 0.9543, policy_loss: 0.8905, value_loss: 0.4267
2024-07-14 07:35:21,578 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:35:22,066 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:35:22,137 [INFO    ] __main__: train step 21519: loss: 0.9543, policy_loss: 0.8905, value_loss: 0.4267
2024-07-14 07:35:22,410 [INFO    ] __main__: train step 21520: loss: 0.9543, policy_loss: 0.8905, value_loss: 0.4267
2024-07-14 07:35:22,679 [INFO    ] __main__: train step 21521: loss: 0.9543, policy_loss: 0.8905, value_loss: 0.4267
2024-07-14 07:35:22,978 [INFO    ] __main__: train step 21522: loss: 0.9542, policy_loss: 0.8904, value_loss: 0.4266
2024-07-14 07:35:23,283 [INFO    ] __main__: train step 21523: loss: 0.9542, policy_loss: 0.8904, value_loss: 0.4266
2024-07-14 07:35:23,589 [INFO    ] __main__: train step 21524: loss: 0.9542, policy_loss: 0.8904, value_loss: 0.4266
2024-07-14 07:35:23,897 [INFO    ] __main__: train step 21525: loss: 0.9542, policy_loss: 0.8904, value_loss: 0.4266
2024-07-14 07:35:24,217 [INFO    ] __main__: train step 21526: loss: 0.9542, policy_loss: 0.8904, value_loss: 0.4266
2024-07-14 07:35:24,521 [INFO    ] __main__: train step 21527: loss: 0.9542, policy_loss: 0.8904, value_loss: 0.4266
2024-07-14 07:35:24,824 [INFO    ] __main__: train step 21528: loss: 0.9541, policy_loss: 0.8903, value_loss: 0.4265
2024-07-14 07:35:25,109 [INFO    ] __main__: train step 21529: loss: 0.9541, policy_loss: 0.8903, value_loss: 0.4265
2024-07-14 07:35:25,435 [INFO    ] __main__: train step 21530: loss: 0.9541, policy_loss: 0.8903, value_loss: 0.4265
2024-07-14 07:35:25,750 [INFO    ] __main__: train step 21531: loss: 0.9541, policy_loss: 0.8903, value_loss: 0.4265
2024-07-14 07:35:26,067 [INFO    ] __main__: train step 21532: loss: 0.9541, policy_loss: 0.8903, value_loss: 0.4265
2024-07-14 07:35:30,824 [INFO    ] __main__: train step 21533: loss: 0.9541, policy_loss: 0.8903, value_loss: 0.4265
2024-07-14 07:35:31,126 [INFO    ] __main__: train step 21534: loss: 0.9541, policy_loss: 0.8903, value_loss: 0.4264
2024-07-14 07:35:31,436 [INFO    ] __main__: train step 21535: loss: 0.9540, policy_loss: 0.8902, value_loss: 0.4264
2024-07-14 07:35:33,040 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:35:33,520 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:35:33,588 [INFO    ] __main__: train step 21536: loss: 0.9540, policy_loss: 0.8902, value_loss: 0.4264
2024-07-14 07:35:33,903 [INFO    ] __main__: train step 21537: loss: 0.9540, policy_loss: 0.8902, value_loss: 0.4264
2024-07-14 07:35:34,205 [INFO    ] __main__: train step 21538: loss: 0.9540, policy_loss: 0.8902, value_loss: 0.4264
2024-07-14 07:35:34,499 [INFO    ] __main__: train step 21539: loss: 0.9540, policy_loss: 0.8902, value_loss: 0.4264
2024-07-14 07:35:34,789 [INFO    ] __main__: train step 21540: loss: 0.9540, policy_loss: 0.8902, value_loss: 0.4263
2024-07-14 07:35:35,088 [INFO    ] __main__: train step 21541: loss: 0.9539, policy_loss: 0.8901, value_loss: 0.4263
2024-07-14 07:35:35,382 [INFO    ] __main__: train step 21542: loss: 0.9539, policy_loss: 0.8901, value_loss: 0.4263
2024-07-14 07:35:35,672 [INFO    ] __main__: train step 21543: loss: 0.9539, policy_loss: 0.8901, value_loss: 0.4263
2024-07-14 07:35:35,956 [INFO    ] __main__: train step 21544: loss: 0.9539, policy_loss: 0.8901, value_loss: 0.4263
2024-07-14 07:35:36,225 [INFO    ] __main__: train step 21545: loss: 0.9539, policy_loss: 0.8901, value_loss: 0.4263
2024-07-14 07:35:36,505 [INFO    ] __main__: train step 21546: loss: 0.9539, policy_loss: 0.8901, value_loss: 0.4262
2024-07-14 07:35:36,800 [INFO    ] __main__: train step 21547: loss: 0.9539, policy_loss: 0.8900, value_loss: 0.4262
2024-07-14 07:35:37,106 [INFO    ] __main__: train step 21548: loss: 0.9538, policy_loss: 0.8900, value_loss: 0.4262
2024-07-14 07:35:37,415 [INFO    ] __main__: train step 21549: loss: 0.9538, policy_loss: 0.8900, value_loss: 0.4262
2024-07-14 07:35:37,727 [INFO    ] __main__: train step 21550: loss: 0.9538, policy_loss: 0.8900, value_loss: 0.4262
2024-07-14 07:35:38,001 [INFO    ] __main__: train step 21551: loss: 0.9538, policy_loss: 0.8900, value_loss: 0.4262
2024-07-14 07:35:38,313 [INFO    ] __main__: train step 21552: loss: 0.9538, policy_loss: 0.8900, value_loss: 0.4261
2024-07-14 07:35:39,943 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:35:40,401 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:35:40,469 [INFO    ] __main__: train step 21553: loss: 0.9538, policy_loss: 0.8900, value_loss: 0.4261
2024-07-14 07:35:40,767 [INFO    ] __main__: train step 21554: loss: 0.9537, policy_loss: 0.8899, value_loss: 0.4261
2024-07-14 07:35:41,085 [INFO    ] __main__: train step 21555: loss: 0.9537, policy_loss: 0.8899, value_loss: 0.4261
2024-07-14 07:35:41,384 [INFO    ] __main__: train step 21556: loss: 0.9537, policy_loss: 0.8899, value_loss: 0.4261
2024-07-14 07:35:41,676 [INFO    ] __main__: train step 21557: loss: 0.9537, policy_loss: 0.8899, value_loss: 0.4261
2024-07-14 07:35:41,990 [INFO    ] __main__: train step 21558: loss: 0.9537, policy_loss: 0.8899, value_loss: 0.4260
2024-07-14 07:35:42,322 [INFO    ] __main__: train step 21559: loss: 0.9537, policy_loss: 0.8899, value_loss: 0.4260
2024-07-14 07:35:42,636 [INFO    ] __main__: train step 21560: loss: 0.9537, policy_loss: 0.8898, value_loss: 0.4260
2024-07-14 07:35:42,930 [INFO    ] __main__: train step 21561: loss: 0.9536, policy_loss: 0.8898, value_loss: 0.4260
2024-07-14 07:35:43,219 [INFO    ] __main__: train step 21562: loss: 0.9536, policy_loss: 0.8898, value_loss: 0.4260
2024-07-14 07:35:43,522 [INFO    ] __main__: train step 21563: loss: 0.9536, policy_loss: 0.8898, value_loss: 0.4260
2024-07-14 07:35:43,846 [INFO    ] __main__: train step 21564: loss: 0.9536, policy_loss: 0.8898, value_loss: 0.4259
2024-07-14 07:35:44,140 [INFO    ] __main__: train step 21565: loss: 0.9536, policy_loss: 0.8898, value_loss: 0.4259
2024-07-14 07:35:44,430 [INFO    ] __main__: train step 21566: loss: 0.9536, policy_loss: 0.8897, value_loss: 0.4259
2024-07-14 07:35:44,724 [INFO    ] __main__: train step 21567: loss: 0.9535, policy_loss: 0.8897, value_loss: 0.4259
2024-07-14 07:35:45,028 [INFO    ] __main__: train step 21568: loss: 0.9535, policy_loss: 0.8897, value_loss: 0.4259
2024-07-14 07:35:45,343 [INFO    ] __main__: train step 21569: loss: 0.9535, policy_loss: 0.8897, value_loss: 0.4259
2024-07-14 07:35:46,952 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:35:47,425 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:35:47,496 [INFO    ] __main__: train step 21570: loss: 0.9535, policy_loss: 0.8897, value_loss: 0.4258
2024-07-14 07:35:47,774 [INFO    ] __main__: train step 21571: loss: 0.9535, policy_loss: 0.8897, value_loss: 0.4258
2024-07-14 07:35:48,063 [INFO    ] __main__: train step 21572: loss: 0.9535, policy_loss: 0.8897, value_loss: 0.4258
2024-07-14 07:35:48,365 [INFO    ] __main__: train step 21573: loss: 0.9535, policy_loss: 0.8896, value_loss: 0.4258
2024-07-14 07:35:48,669 [INFO    ] __main__: train step 21574: loss: 0.9534, policy_loss: 0.8896, value_loss: 0.4258
2024-07-14 07:35:48,951 [INFO    ] __main__: train step 21575: loss: 0.9534, policy_loss: 0.8896, value_loss: 0.4258
2024-07-14 07:35:49,218 [INFO    ] __main__: train step 21576: loss: 0.9534, policy_loss: 0.8896, value_loss: 0.4257
2024-07-14 07:35:49,523 [INFO    ] __main__: train step 21577: loss: 0.9534, policy_loss: 0.8896, value_loss: 0.4257
2024-07-14 07:35:49,828 [INFO    ] __main__: train step 21578: loss: 0.9534, policy_loss: 0.8896, value_loss: 0.4257
2024-07-14 07:35:50,145 [INFO    ] __main__: train step 21579: loss: 0.9534, policy_loss: 0.8895, value_loss: 0.4257
2024-07-14 07:35:50,434 [INFO    ] __main__: train step 21580: loss: 0.9533, policy_loss: 0.8895, value_loss: 0.4257
2024-07-14 07:35:50,733 [INFO    ] __main__: train step 21581: loss: 0.9533, policy_loss: 0.8895, value_loss: 0.4257
2024-07-14 07:35:51,031 [INFO    ] __main__: train step 21582: loss: 0.9533, policy_loss: 0.8895, value_loss: 0.4256
2024-07-14 07:35:51,340 [INFO    ] __main__: train step 21583: loss: 0.9533, policy_loss: 0.8895, value_loss: 0.4256
2024-07-14 07:35:51,641 [INFO    ] __main__: train step 21584: loss: 0.9533, policy_loss: 0.8895, value_loss: 0.4256
2024-07-14 07:35:51,952 [INFO    ] __main__: train step 21585: loss: 0.9533, policy_loss: 0.8894, value_loss: 0.4256
2024-07-14 07:35:52,225 [INFO    ] __main__: train step 21586: loss: 0.9533, policy_loss: 0.8894, value_loss: 0.4256
2024-07-14 07:35:53,825 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:35:54,270 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:35:54,335 [INFO    ] __main__: train step 21587: loss: 0.9532, policy_loss: 0.8894, value_loss: 0.4256
2024-07-14 07:35:54,632 [INFO    ] __main__: train step 21588: loss: 0.9532, policy_loss: 0.8894, value_loss: 0.4255
2024-07-14 07:35:54,933 [INFO    ] __main__: train step 21589: loss: 0.9532, policy_loss: 0.8894, value_loss: 0.4255
2024-07-14 07:35:55,234 [INFO    ] __main__: train step 21590: loss: 0.9532, policy_loss: 0.8894, value_loss: 0.4255
2024-07-14 07:35:55,513 [INFO    ] __main__: train step 21591: loss: 0.9532, policy_loss: 0.8894, value_loss: 0.4255
2024-07-14 07:35:55,828 [INFO    ] __main__: train step 21592: loss: 0.9532, policy_loss: 0.8893, value_loss: 0.4255
2024-07-14 07:35:56,139 [INFO    ] __main__: train step 21593: loss: 0.9531, policy_loss: 0.8893, value_loss: 0.4255
2024-07-14 07:35:56,453 [INFO    ] __main__: train step 21594: loss: 0.9531, policy_loss: 0.8893, value_loss: 0.4254
2024-07-14 07:35:56,727 [INFO    ] __main__: train step 21595: loss: 0.9531, policy_loss: 0.8893, value_loss: 0.4254
2024-07-14 07:35:56,990 [INFO    ] __main__: train step 21596: loss: 0.9531, policy_loss: 0.8893, value_loss: 0.4254
2024-07-14 07:35:57,263 [INFO    ] __main__: train step 21597: loss: 0.9531, policy_loss: 0.8893, value_loss: 0.4254
2024-07-14 07:35:57,574 [INFO    ] __main__: train step 21598: loss: 0.9531, policy_loss: 0.8892, value_loss: 0.4254
2024-07-14 07:35:57,891 [INFO    ] __main__: train step 21599: loss: 0.9531, policy_loss: 0.8892, value_loss: 0.4254
2024-07-14 07:35:58,187 [INFO    ] __main__: train step 21600: loss: 0.9530, policy_loss: 0.8892, value_loss: 0.4254
2024-07-14 07:35:58,490 [INFO    ] __main__: train step 21601: loss: 0.9530, policy_loss: 0.8892, value_loss: 0.4253
2024-07-14 07:35:58,785 [INFO    ] __main__: train step 21602: loss: 0.9530, policy_loss: 0.8892, value_loss: 0.4253
2024-07-14 07:35:59,092 [INFO    ] __main__: train step 21603: loss: 0.9530, policy_loss: 0.8892, value_loss: 0.4253
2024-07-14 07:36:00,726 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:36:01,191 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:36:01,261 [INFO    ] __main__: train step 21604: loss: 0.9530, policy_loss: 0.8892, value_loss: 0.4253
2024-07-14 07:36:01,532 [INFO    ] __main__: train step 21605: loss: 0.9530, policy_loss: 0.8891, value_loss: 0.4253
2024-07-14 07:36:01,781 [INFO    ] __main__: train step 21606: loss: 0.9529, policy_loss: 0.8891, value_loss: 0.4253
2024-07-14 07:36:02,083 [INFO    ] __main__: train step 21607: loss: 0.9529, policy_loss: 0.8891, value_loss: 0.4252
2024-07-14 07:36:02,377 [INFO    ] __main__: train step 21608: loss: 0.9529, policy_loss: 0.8891, value_loss: 0.4252
2024-07-14 07:36:02,670 [INFO    ] __main__: train step 21609: loss: 0.9529, policy_loss: 0.8891, value_loss: 0.4252
2024-07-14 07:36:02,970 [INFO    ] __main__: train step 21610: loss: 0.9529, policy_loss: 0.8891, value_loss: 0.4252
2024-07-14 07:36:03,306 [INFO    ] __main__: train step 21611: loss: 0.9529, policy_loss: 0.8890, value_loss: 0.4252
2024-07-14 07:36:03,583 [INFO    ] __main__: train step 21612: loss: 0.9529, policy_loss: 0.8890, value_loss: 0.4252
2024-07-14 07:36:03,861 [INFO    ] __main__: train step 21613: loss: 0.9528, policy_loss: 0.8890, value_loss: 0.4251
2024-07-14 07:36:04,139 [INFO    ] __main__: train step 21614: loss: 0.9528, policy_loss: 0.8890, value_loss: 0.4251
2024-07-14 07:36:04,423 [INFO    ] __main__: train step 21615: loss: 0.9528, policy_loss: 0.8890, value_loss: 0.4251
2024-07-14 07:36:04,705 [INFO    ] __main__: train step 21616: loss: 0.9528, policy_loss: 0.8890, value_loss: 0.4251
2024-07-14 07:36:04,987 [INFO    ] __main__: train step 21617: loss: 0.9528, policy_loss: 0.8889, value_loss: 0.4251
2024-07-14 07:36:05,276 [INFO    ] __main__: train step 21618: loss: 0.9528, policy_loss: 0.8889, value_loss: 0.4251
2024-07-14 07:36:05,543 [INFO    ] __main__: train step 21619: loss: 0.9527, policy_loss: 0.8889, value_loss: 0.4250
2024-07-14 07:36:05,840 [INFO    ] __main__: train step 21620: loss: 0.9527, policy_loss: 0.8889, value_loss: 0.4250
2024-07-14 07:36:07,476 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:36:07,952 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:36:08,024 [INFO    ] __main__: train step 21621: loss: 0.9527, policy_loss: 0.8889, value_loss: 0.4250
2024-07-14 07:36:08,320 [INFO    ] __main__: train step 21622: loss: 0.9527, policy_loss: 0.8889, value_loss: 0.4250
2024-07-14 07:36:08,620 [INFO    ] __main__: train step 21623: loss: 0.9527, policy_loss: 0.8889, value_loss: 0.4250
2024-07-14 07:36:08,922 [INFO    ] __main__: train step 21624: loss: 0.9527, policy_loss: 0.8888, value_loss: 0.4250
2024-07-14 07:36:09,240 [INFO    ] __main__: train step 21625: loss: 0.9527, policy_loss: 0.8888, value_loss: 0.4249
2024-07-14 07:36:09,534 [INFO    ] __main__: train step 21626: loss: 0.9526, policy_loss: 0.8888, value_loss: 0.4249
2024-07-14 07:36:09,824 [INFO    ] __main__: train step 21627: loss: 0.9526, policy_loss: 0.8888, value_loss: 0.4249
2024-07-14 07:36:10,111 [INFO    ] __main__: train step 21628: loss: 0.9526, policy_loss: 0.8888, value_loss: 0.4249
2024-07-14 07:36:10,403 [INFO    ] __main__: train step 21629: loss: 0.9526, policy_loss: 0.8888, value_loss: 0.4249
2024-07-14 07:36:10,681 [INFO    ] __main__: train step 21630: loss: 0.9526, policy_loss: 0.8887, value_loss: 0.4249
2024-07-14 07:36:10,996 [INFO    ] __main__: train step 21631: loss: 0.9526, policy_loss: 0.8887, value_loss: 0.4248
2024-07-14 07:36:11,304 [INFO    ] __main__: train step 21632: loss: 0.9526, policy_loss: 0.8887, value_loss: 0.4248
2024-07-14 07:36:11,608 [INFO    ] __main__: train step 21633: loss: 0.9525, policy_loss: 0.8887, value_loss: 0.4248
2024-07-14 07:36:11,914 [INFO    ] __main__: train step 21634: loss: 0.9525, policy_loss: 0.8887, value_loss: 0.4248
2024-07-14 07:36:12,205 [INFO    ] __main__: train step 21635: loss: 0.9525, policy_loss: 0.8887, value_loss: 0.4248
2024-07-14 07:36:12,500 [INFO    ] __main__: train step 21636: loss: 0.9525, policy_loss: 0.8887, value_loss: 0.4248
2024-07-14 07:36:12,775 [INFO    ] __main__: train step 21637: loss: 0.9525, policy_loss: 0.8886, value_loss: 0.4247
2024-07-14 07:36:14,365 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:36:14,850 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:36:14,919 [INFO    ] __main__: train step 21638: loss: 0.9525, policy_loss: 0.8886, value_loss: 0.4247
2024-07-14 07:36:15,214 [INFO    ] __main__: train step 21639: loss: 0.9524, policy_loss: 0.8886, value_loss: 0.4247
2024-07-14 07:36:15,510 [INFO    ] __main__: train step 21640: loss: 0.9524, policy_loss: 0.8886, value_loss: 0.4247
2024-07-14 07:36:15,803 [INFO    ] __main__: train step 21641: loss: 0.9524, policy_loss: 0.8886, value_loss: 0.4247
2024-07-14 07:36:16,070 [INFO    ] __main__: train step 21642: loss: 0.9524, policy_loss: 0.8886, value_loss: 0.4247
2024-07-14 07:36:16,366 [INFO    ] __main__: train step 21643: loss: 0.9524, policy_loss: 0.8885, value_loss: 0.4246
2024-07-14 07:36:16,666 [INFO    ] __main__: train step 21644: loss: 0.9524, policy_loss: 0.8885, value_loss: 0.4246
2024-07-14 07:36:16,945 [INFO    ] __main__: train step 21645: loss: 0.9524, policy_loss: 0.8885, value_loss: 0.4246
2024-07-14 07:36:17,223 [INFO    ] __main__: train step 21646: loss: 0.9523, policy_loss: 0.8885, value_loss: 0.4246
2024-07-14 07:36:17,498 [INFO    ] __main__: train step 21647: loss: 0.9523, policy_loss: 0.8885, value_loss: 0.4246
2024-07-14 07:36:17,772 [INFO    ] __main__: train step 21648: loss: 0.9523, policy_loss: 0.8885, value_loss: 0.4246
2024-07-14 07:36:18,064 [INFO    ] __main__: train step 21649: loss: 0.9523, policy_loss: 0.8885, value_loss: 0.4246
2024-07-14 07:36:18,364 [INFO    ] __main__: train step 21650: loss: 0.9523, policy_loss: 0.8884, value_loss: 0.4245
2024-07-14 07:36:18,657 [INFO    ] __main__: train step 21651: loss: 0.9523, policy_loss: 0.8884, value_loss: 0.4245
2024-07-14 07:36:18,950 [INFO    ] __main__: train step 21652: loss: 0.9522, policy_loss: 0.8884, value_loss: 0.4245
2024-07-14 07:36:19,246 [INFO    ] __main__: train step 21653: loss: 0.9522, policy_loss: 0.8884, value_loss: 0.4245
2024-07-14 07:36:19,532 [INFO    ] __main__: train step 21654: loss: 0.9522, policy_loss: 0.8884, value_loss: 0.4245
2024-07-14 07:36:21,147 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:36:21,635 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:36:21,710 [INFO    ] __main__: train step 21655: loss: 0.9522, policy_loss: 0.8884, value_loss: 0.4245
2024-07-14 07:36:22,023 [INFO    ] __main__: train step 21656: loss: 0.9522, policy_loss: 0.8883, value_loss: 0.4244
2024-07-14 07:36:22,286 [INFO    ] __main__: train step 21657: loss: 0.9522, policy_loss: 0.8883, value_loss: 0.4244
2024-07-14 07:36:22,567 [INFO    ] __main__: train step 21658: loss: 0.9522, policy_loss: 0.8883, value_loss: 0.4244
2024-07-14 07:36:22,855 [INFO    ] __main__: train step 21659: loss: 0.9521, policy_loss: 0.8883, value_loss: 0.4244
2024-07-14 07:36:27,464 [INFO    ] __main__: train step 21660: loss: 0.9521, policy_loss: 0.8883, value_loss: 0.4244
2024-07-14 07:36:27,772 [INFO    ] __main__: train step 21661: loss: 0.9521, policy_loss: 0.8883, value_loss: 0.4244
2024-07-14 07:36:28,069 [INFO    ] __main__: train step 21662: loss: 0.9521, policy_loss: 0.8882, value_loss: 0.4243
2024-07-14 07:36:28,370 [INFO    ] __main__: train step 21663: loss: 0.9521, policy_loss: 0.8882, value_loss: 0.4243
2024-07-14 07:36:28,651 [INFO    ] __main__: train step 21664: loss: 0.9521, policy_loss: 0.8882, value_loss: 0.4243
2024-07-14 07:36:28,959 [INFO    ] __main__: train step 21665: loss: 0.9520, policy_loss: 0.8882, value_loss: 0.4243
2024-07-14 07:36:29,261 [INFO    ] __main__: train step 21666: loss: 0.9520, policy_loss: 0.8882, value_loss: 0.4243
2024-07-14 07:36:29,576 [INFO    ] __main__: train step 21667: loss: 0.9520, policy_loss: 0.8882, value_loss: 0.4243
2024-07-14 07:36:29,850 [INFO    ] __main__: train step 21668: loss: 0.9520, policy_loss: 0.8882, value_loss: 0.4242
2024-07-14 07:36:30,157 [INFO    ] __main__: train step 21669: loss: 0.9520, policy_loss: 0.8881, value_loss: 0.4242
2024-07-14 07:36:30,440 [INFO    ] __main__: train step 21670: loss: 0.9520, policy_loss: 0.8881, value_loss: 0.4242
2024-07-14 07:36:30,743 [INFO    ] __main__: train step 21671: loss: 0.9520, policy_loss: 0.8881, value_loss: 0.4242
2024-07-14 07:36:32,362 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:36:32,836 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:36:32,901 [INFO    ] __main__: train step 21672: loss: 0.9519, policy_loss: 0.8881, value_loss: 0.4242
2024-07-14 07:36:33,179 [INFO    ] __main__: train step 21673: loss: 0.9519, policy_loss: 0.8881, value_loss: 0.4242
2024-07-14 07:36:33,459 [INFO    ] __main__: train step 21674: loss: 0.9519, policy_loss: 0.8881, value_loss: 0.4241
2024-07-14 07:36:33,748 [INFO    ] __main__: train step 21675: loss: 0.9519, policy_loss: 0.8880, value_loss: 0.4241
2024-07-14 07:36:34,040 [INFO    ] __main__: train step 21676: loss: 0.9519, policy_loss: 0.8880, value_loss: 0.4241
2024-07-14 07:36:34,340 [INFO    ] __main__: train step 21677: loss: 0.9519, policy_loss: 0.8880, value_loss: 0.4241
2024-07-14 07:36:34,632 [INFO    ] __main__: train step 21678: loss: 0.9518, policy_loss: 0.8880, value_loss: 0.4241
2024-07-14 07:36:34,910 [INFO    ] __main__: train step 21679: loss: 0.9518, policy_loss: 0.8880, value_loss: 0.4241
2024-07-14 07:36:35,193 [INFO    ] __main__: train step 21680: loss: 0.9518, policy_loss: 0.8880, value_loss: 0.4240
2024-07-14 07:36:35,480 [INFO    ] __main__: train step 21681: loss: 0.9518, policy_loss: 0.8880, value_loss: 0.4240
2024-07-14 07:36:35,785 [INFO    ] __main__: train step 21682: loss: 0.9518, policy_loss: 0.8879, value_loss: 0.4240
2024-07-14 07:36:36,097 [INFO    ] __main__: train step 21683: loss: 0.9518, policy_loss: 0.8879, value_loss: 0.4240
2024-07-14 07:36:36,392 [INFO    ] __main__: train step 21684: loss: 0.9518, policy_loss: 0.8879, value_loss: 0.4240
2024-07-14 07:36:36,697 [INFO    ] __main__: train step 21685: loss: 0.9517, policy_loss: 0.8879, value_loss: 0.4240
2024-07-14 07:36:37,007 [INFO    ] __main__: train step 21686: loss: 0.9517, policy_loss: 0.8879, value_loss: 0.4239
2024-07-14 07:36:37,316 [INFO    ] __main__: train step 21687: loss: 0.9517, policy_loss: 0.8879, value_loss: 0.4239
2024-07-14 07:36:37,624 [INFO    ] __main__: train step 21688: loss: 0.9517, policy_loss: 0.8878, value_loss: 0.4239
2024-07-14 07:36:39,218 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:36:39,697 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:36:39,770 [INFO    ] __main__: train step 21689: loss: 0.9517, policy_loss: 0.8878, value_loss: 0.4239
2024-07-14 07:36:40,076 [INFO    ] __main__: train step 21690: loss: 0.9517, policy_loss: 0.8878, value_loss: 0.4239
2024-07-14 07:36:40,362 [INFO    ] __main__: train step 21691: loss: 0.9517, policy_loss: 0.8878, value_loss: 0.4239
2024-07-14 07:36:40,632 [INFO    ] __main__: train step 21692: loss: 0.9516, policy_loss: 0.8878, value_loss: 0.4238
2024-07-14 07:36:40,899 [INFO    ] __main__: train step 21693: loss: 0.9516, policy_loss: 0.8878, value_loss: 0.4238
2024-07-14 07:36:41,184 [INFO    ] __main__: train step 21694: loss: 0.9516, policy_loss: 0.8878, value_loss: 0.4238
2024-07-14 07:36:41,473 [INFO    ] __main__: train step 21695: loss: 0.9516, policy_loss: 0.8877, value_loss: 0.4238
2024-07-14 07:36:41,789 [INFO    ] __main__: train step 21696: loss: 0.9516, policy_loss: 0.8877, value_loss: 0.4238
2024-07-14 07:36:42,092 [INFO    ] __main__: train step 21697: loss: 0.9516, policy_loss: 0.8877, value_loss: 0.4238
2024-07-14 07:36:42,380 [INFO    ] __main__: train step 21698: loss: 0.9515, policy_loss: 0.8877, value_loss: 0.4238
2024-07-14 07:36:42,653 [INFO    ] __main__: train step 21699: loss: 0.9515, policy_loss: 0.8877, value_loss: 0.4237
2024-07-14 07:36:42,952 [INFO    ] __main__: train step 21700: loss: 0.9515, policy_loss: 0.8877, value_loss: 0.4237
2024-07-14 07:36:43,251 [INFO    ] __main__: train step 21701: loss: 0.9515, policy_loss: 0.8876, value_loss: 0.4237
2024-07-14 07:36:43,556 [INFO    ] __main__: train step 21702: loss: 0.9515, policy_loss: 0.8876, value_loss: 0.4237
2024-07-14 07:36:43,845 [INFO    ] __main__: train step 21703: loss: 0.9515, policy_loss: 0.8876, value_loss: 0.4237
2024-07-14 07:36:44,123 [INFO    ] __main__: train step 21704: loss: 0.9515, policy_loss: 0.8876, value_loss: 0.4237
2024-07-14 07:36:44,416 [INFO    ] __main__: train step 21705: loss: 0.9514, policy_loss: 0.8876, value_loss: 0.4236
2024-07-14 07:36:46,074 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:36:46,546 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:36:46,621 [INFO    ] __main__: train step 21706: loss: 0.9514, policy_loss: 0.8876, value_loss: 0.4236
2024-07-14 07:36:46,893 [INFO    ] __main__: train step 21707: loss: 0.9514, policy_loss: 0.8876, value_loss: 0.4236
2024-07-14 07:36:47,170 [INFO    ] __main__: train step 21708: loss: 0.9514, policy_loss: 0.8875, value_loss: 0.4236
2024-07-14 07:36:47,462 [INFO    ] __main__: train step 21709: loss: 0.9514, policy_loss: 0.8875, value_loss: 0.4236
2024-07-14 07:36:47,766 [INFO    ] __main__: train step 21710: loss: 0.9514, policy_loss: 0.8875, value_loss: 0.4236
2024-07-14 07:36:48,067 [INFO    ] __main__: train step 21711: loss: 0.9513, policy_loss: 0.8875, value_loss: 0.4235
2024-07-14 07:36:48,339 [INFO    ] __main__: train step 21712: loss: 0.9513, policy_loss: 0.8875, value_loss: 0.4235
2024-07-14 07:36:48,623 [INFO    ] __main__: train step 21713: loss: 0.9513, policy_loss: 0.8875, value_loss: 0.4235
2024-07-14 07:36:48,925 [INFO    ] __main__: train step 21714: loss: 0.9513, policy_loss: 0.8874, value_loss: 0.4235
2024-07-14 07:36:49,222 [INFO    ] __main__: train step 21715: loss: 0.9513, policy_loss: 0.8874, value_loss: 0.4235
2024-07-14 07:36:49,525 [INFO    ] __main__: train step 21716: loss: 0.9513, policy_loss: 0.8874, value_loss: 0.4235
2024-07-14 07:36:49,811 [INFO    ] __main__: train step 21717: loss: 0.9513, policy_loss: 0.8874, value_loss: 0.4234
2024-07-14 07:36:50,110 [INFO    ] __main__: train step 21718: loss: 0.9512, policy_loss: 0.8874, value_loss: 0.4234
2024-07-14 07:36:50,412 [INFO    ] __main__: train step 21719: loss: 0.9512, policy_loss: 0.8874, value_loss: 0.4234
2024-07-14 07:36:50,711 [INFO    ] __main__: train step 21720: loss: 0.9512, policy_loss: 0.8874, value_loss: 0.4234
2024-07-14 07:36:51,012 [INFO    ] __main__: train step 21721: loss: 0.9512, policy_loss: 0.8873, value_loss: 0.4234
2024-07-14 07:36:51,304 [INFO    ] __main__: train step 21722: loss: 0.9512, policy_loss: 0.8873, value_loss: 0.4234
2024-07-14 07:36:52,922 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:36:53,393 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:36:53,466 [INFO    ] __main__: train step 21723: loss: 0.9512, policy_loss: 0.8873, value_loss: 0.4233
2024-07-14 07:36:53,761 [INFO    ] __main__: train step 21724: loss: 0.9512, policy_loss: 0.8873, value_loss: 0.4233
2024-07-14 07:36:54,058 [INFO    ] __main__: train step 21725: loss: 0.9511, policy_loss: 0.8873, value_loss: 0.4233
2024-07-14 07:36:54,353 [INFO    ] __main__: train step 21726: loss: 0.9511, policy_loss: 0.8873, value_loss: 0.4233
2024-07-14 07:36:54,631 [INFO    ] __main__: train step 21727: loss: 0.9511, policy_loss: 0.8872, value_loss: 0.4233
2024-07-14 07:36:54,923 [INFO    ] __main__: train step 21728: loss: 0.9511, policy_loss: 0.8872, value_loss: 0.4233
2024-07-14 07:36:55,206 [INFO    ] __main__: train step 21729: loss: 0.9511, policy_loss: 0.8872, value_loss: 0.4232
2024-07-14 07:36:55,499 [INFO    ] __main__: train step 21730: loss: 0.9511, policy_loss: 0.8872, value_loss: 0.4232
2024-07-14 07:36:55,807 [INFO    ] __main__: train step 21731: loss: 0.9510, policy_loss: 0.8872, value_loss: 0.4232
2024-07-14 07:36:56,104 [INFO    ] __main__: train step 21732: loss: 0.9510, policy_loss: 0.8872, value_loss: 0.4232
2024-07-14 07:36:56,390 [INFO    ] __main__: train step 21733: loss: 0.9510, policy_loss: 0.8872, value_loss: 0.4232
2024-07-14 07:36:56,678 [INFO    ] __main__: train step 21734: loss: 0.9510, policy_loss: 0.8871, value_loss: 0.4232
2024-07-14 07:36:56,971 [INFO    ] __main__: train step 21735: loss: 0.9510, policy_loss: 0.8871, value_loss: 0.4231
2024-07-14 07:36:57,275 [INFO    ] __main__: train step 21736: loss: 0.9510, policy_loss: 0.8871, value_loss: 0.4231
2024-07-14 07:36:57,575 [INFO    ] __main__: train step 21737: loss: 0.9510, policy_loss: 0.8871, value_loss: 0.4231
2024-07-14 07:36:57,870 [INFO    ] __main__: train step 21738: loss: 0.9509, policy_loss: 0.8871, value_loss: 0.4231
2024-07-14 07:36:58,155 [INFO    ] __main__: train step 21739: loss: 0.9509, policy_loss: 0.8871, value_loss: 0.4231
2024-07-14 07:36:59,759 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:37:00,231 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:37:00,301 [INFO    ] __main__: train step 21740: loss: 0.9509, policy_loss: 0.8870, value_loss: 0.4231
2024-07-14 07:37:00,570 [INFO    ] __main__: train step 21741: loss: 0.9509, policy_loss: 0.8870, value_loss: 0.4231
2024-07-14 07:37:00,827 [INFO    ] __main__: train step 21742: loss: 0.9509, policy_loss: 0.8870, value_loss: 0.4230
2024-07-14 07:37:01,112 [INFO    ] __main__: train step 21743: loss: 0.9509, policy_loss: 0.8870, value_loss: 0.4230
2024-07-14 07:37:01,396 [INFO    ] __main__: train step 21744: loss: 0.9509, policy_loss: 0.8870, value_loss: 0.4230
2024-07-14 07:37:01,689 [INFO    ] __main__: train step 21745: loss: 0.9508, policy_loss: 0.8870, value_loss: 0.4230
2024-07-14 07:37:01,990 [INFO    ] __main__: train step 21746: loss: 0.9508, policy_loss: 0.8870, value_loss: 0.4230
2024-07-14 07:37:02,276 [INFO    ] __main__: train step 21747: loss: 0.9508, policy_loss: 0.8869, value_loss: 0.4230
2024-07-14 07:37:02,582 [INFO    ] __main__: train step 21748: loss: 0.9508, policy_loss: 0.8869, value_loss: 0.4229
2024-07-14 07:37:02,898 [INFO    ] __main__: train step 21749: loss: 0.9508, policy_loss: 0.8869, value_loss: 0.4229
2024-07-14 07:37:03,188 [INFO    ] __main__: train step 21750: loss: 0.9508, policy_loss: 0.8869, value_loss: 0.4229
2024-07-14 07:37:03,488 [INFO    ] __main__: train step 21751: loss: 0.9507, policy_loss: 0.8869, value_loss: 0.4229
2024-07-14 07:37:03,790 [INFO    ] __main__: train step 21752: loss: 0.9507, policy_loss: 0.8869, value_loss: 0.4229
2024-07-14 07:37:04,063 [INFO    ] __main__: train step 21753: loss: 0.9507, policy_loss: 0.8868, value_loss: 0.4229
2024-07-14 07:37:04,342 [INFO    ] __main__: train step 21754: loss: 0.9507, policy_loss: 0.8868, value_loss: 0.4228
2024-07-14 07:37:04,634 [INFO    ] __main__: train step 21755: loss: 0.9507, policy_loss: 0.8868, value_loss: 0.4228
2024-07-14 07:37:04,942 [INFO    ] __main__: train step 21756: loss: 0.9507, policy_loss: 0.8868, value_loss: 0.4228
2024-07-14 07:37:06,559 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:37:07,039 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:37:07,112 [INFO    ] __main__: train step 21757: loss: 0.9507, policy_loss: 0.8868, value_loss: 0.4228
2024-07-14 07:37:07,396 [INFO    ] __main__: train step 21758: loss: 0.9506, policy_loss: 0.8868, value_loss: 0.4228
2024-07-14 07:37:07,682 [INFO    ] __main__: train step 21759: loss: 0.9506, policy_loss: 0.8868, value_loss: 0.4228
2024-07-14 07:37:07,976 [INFO    ] __main__: train step 21760: loss: 0.9506, policy_loss: 0.8867, value_loss: 0.4227
2024-07-14 07:37:08,270 [INFO    ] __main__: train step 21761: loss: 0.9506, policy_loss: 0.8867, value_loss: 0.4227
2024-07-14 07:37:08,546 [INFO    ] __main__: train step 21762: loss: 0.9506, policy_loss: 0.8867, value_loss: 0.4227
2024-07-14 07:37:08,841 [INFO    ] __main__: train step 21763: loss: 0.9506, policy_loss: 0.8867, value_loss: 0.4227
2024-07-14 07:37:09,129 [INFO    ] __main__: train step 21764: loss: 0.9505, policy_loss: 0.8867, value_loss: 0.4227
2024-07-14 07:37:09,437 [INFO    ] __main__: train step 21765: loss: 0.9505, policy_loss: 0.8867, value_loss: 0.4227
2024-07-14 07:37:09,735 [INFO    ] __main__: train step 21766: loss: 0.9505, policy_loss: 0.8866, value_loss: 0.4226
2024-07-14 07:37:10,043 [INFO    ] __main__: train step 21767: loss: 0.9505, policy_loss: 0.8866, value_loss: 0.4226
2024-07-14 07:37:10,311 [INFO    ] __main__: train step 21768: loss: 0.9505, policy_loss: 0.8866, value_loss: 0.4226
2024-07-14 07:37:10,599 [INFO    ] __main__: train step 21769: loss: 0.9505, policy_loss: 0.8866, value_loss: 0.4226
2024-07-14 07:37:10,898 [INFO    ] __main__: train step 21770: loss: 0.9505, policy_loss: 0.8866, value_loss: 0.4226
2024-07-14 07:37:11,184 [INFO    ] __main__: train step 21771: loss: 0.9504, policy_loss: 0.8866, value_loss: 0.4226
2024-07-14 07:37:11,488 [INFO    ] __main__: train step 21772: loss: 0.9504, policy_loss: 0.8866, value_loss: 0.4225
2024-07-14 07:37:11,790 [INFO    ] __main__: train step 21773: loss: 0.9504, policy_loss: 0.8865, value_loss: 0.4225
2024-07-14 07:37:13,363 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:37:13,830 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:37:13,898 [INFO    ] __main__: train step 21774: loss: 0.9504, policy_loss: 0.8865, value_loss: 0.4225
2024-07-14 07:37:14,181 [INFO    ] __main__: train step 21775: loss: 0.9504, policy_loss: 0.8865, value_loss: 0.4225
2024-07-14 07:37:14,475 [INFO    ] __main__: train step 21776: loss: 0.9504, policy_loss: 0.8865, value_loss: 0.4225
2024-07-14 07:37:14,760 [INFO    ] __main__: train step 21777: loss: 0.9504, policy_loss: 0.8865, value_loss: 0.4225
2024-07-14 07:37:15,031 [INFO    ] __main__: train step 21778: loss: 0.9503, policy_loss: 0.8865, value_loss: 0.4225
2024-07-14 07:37:15,306 [INFO    ] __main__: train step 21779: loss: 0.9503, policy_loss: 0.8864, value_loss: 0.4224
2024-07-14 07:37:15,584 [INFO    ] __main__: train step 21780: loss: 0.9503, policy_loss: 0.8864, value_loss: 0.4224
2024-07-14 07:37:15,871 [INFO    ] __main__: train step 21781: loss: 0.9503, policy_loss: 0.8864, value_loss: 0.4224
2024-07-14 07:37:16,159 [INFO    ] __main__: train step 21782: loss: 0.9503, policy_loss: 0.8864, value_loss: 0.4224
2024-07-14 07:37:16,458 [INFO    ] __main__: train step 21783: loss: 0.9503, policy_loss: 0.8864, value_loss: 0.4224
2024-07-14 07:37:16,744 [INFO    ] __main__: train step 21784: loss: 0.9503, policy_loss: 0.8864, value_loss: 0.4224
2024-07-14 07:37:17,044 [INFO    ] __main__: train step 21785: loss: 0.9502, policy_loss: 0.8864, value_loss: 0.4223
2024-07-14 07:37:17,354 [INFO    ] __main__: train step 21786: loss: 0.9502, policy_loss: 0.8863, value_loss: 0.4223
2024-07-14 07:37:22,159 [INFO    ] __main__: train step 21787: loss: 0.9502, policy_loss: 0.8863, value_loss: 0.4223
2024-07-14 07:37:22,459 [INFO    ] __main__: train step 21788: loss: 0.9502, policy_loss: 0.8863, value_loss: 0.4223
2024-07-14 07:37:22,756 [INFO    ] __main__: train step 21789: loss: 0.9502, policy_loss: 0.8863, value_loss: 0.4223
2024-07-14 07:37:23,050 [INFO    ] __main__: train step 21790: loss: 0.9502, policy_loss: 0.8863, value_loss: 0.4223
2024-07-14 07:37:24,681 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:37:25,169 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:37:25,240 [INFO    ] __main__: train step 21791: loss: 0.9501, policy_loss: 0.8863, value_loss: 0.4222
2024-07-14 07:37:25,534 [INFO    ] __main__: train step 21792: loss: 0.9501, policy_loss: 0.8862, value_loss: 0.4222
2024-07-14 07:37:25,815 [INFO    ] __main__: train step 21793: loss: 0.9501, policy_loss: 0.8862, value_loss: 0.4222
2024-07-14 07:37:26,077 [INFO    ] __main__: train step 21794: loss: 0.9501, policy_loss: 0.8862, value_loss: 0.4222
2024-07-14 07:37:26,346 [INFO    ] __main__: train step 21795: loss: 0.9501, policy_loss: 0.8862, value_loss: 0.4222
2024-07-14 07:37:26,616 [INFO    ] __main__: train step 21796: loss: 0.9501, policy_loss: 0.8862, value_loss: 0.4222
2024-07-14 07:37:26,890 [INFO    ] __main__: train step 21797: loss: 0.9501, policy_loss: 0.8862, value_loss: 0.4221
2024-07-14 07:37:27,166 [INFO    ] __main__: train step 21798: loss: 0.9500, policy_loss: 0.8862, value_loss: 0.4221
2024-07-14 07:37:27,458 [INFO    ] __main__: train step 21799: loss: 0.9500, policy_loss: 0.8861, value_loss: 0.4221
2024-07-14 07:37:27,725 [INFO    ] __main__: train step 21800: loss: 0.9500, policy_loss: 0.8861, value_loss: 0.4221
2024-07-14 07:37:27,996 [INFO    ] __main__: train step 21801: loss: 0.9500, policy_loss: 0.8861, value_loss: 0.4221
2024-07-14 07:37:28,275 [INFO    ] __main__: train step 21802: loss: 0.9500, policy_loss: 0.8861, value_loss: 0.4221
2024-07-14 07:37:28,555 [INFO    ] __main__: train step 21803: loss: 0.9500, policy_loss: 0.8861, value_loss: 0.4220
2024-07-14 07:37:28,825 [INFO    ] __main__: train step 21804: loss: 0.9500, policy_loss: 0.8861, value_loss: 0.4220
2024-07-14 07:37:29,102 [INFO    ] __main__: train step 21805: loss: 0.9499, policy_loss: 0.8861, value_loss: 0.4220
2024-07-14 07:37:29,393 [INFO    ] __main__: train step 21806: loss: 0.9499, policy_loss: 0.8860, value_loss: 0.4220
2024-07-14 07:37:29,649 [INFO    ] __main__: train step 21807: loss: 0.9499, policy_loss: 0.8860, value_loss: 0.4220
2024-07-14 07:37:31,253 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:37:31,744 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:37:31,812 [INFO    ] __main__: train step 21808: loss: 0.9499, policy_loss: 0.8860, value_loss: 0.4220
2024-07-14 07:37:32,088 [INFO    ] __main__: train step 21809: loss: 0.9499, policy_loss: 0.8860, value_loss: 0.4219
2024-07-14 07:37:32,377 [INFO    ] __main__: train step 21810: loss: 0.9499, policy_loss: 0.8860, value_loss: 0.4219
2024-07-14 07:37:32,667 [INFO    ] __main__: train step 21811: loss: 0.9498, policy_loss: 0.8860, value_loss: 0.4219
2024-07-14 07:37:32,964 [INFO    ] __main__: train step 21812: loss: 0.9498, policy_loss: 0.8859, value_loss: 0.4219
2024-07-14 07:37:33,244 [INFO    ] __main__: train step 21813: loss: 0.9498, policy_loss: 0.8859, value_loss: 0.4219
2024-07-14 07:37:33,540 [INFO    ] __main__: train step 21814: loss: 0.9498, policy_loss: 0.8859, value_loss: 0.4219
2024-07-14 07:37:33,816 [INFO    ] __main__: train step 21815: loss: 0.9498, policy_loss: 0.8859, value_loss: 0.4219
2024-07-14 07:37:34,111 [INFO    ] __main__: train step 21816: loss: 0.9498, policy_loss: 0.8859, value_loss: 0.4218
2024-07-14 07:37:34,411 [INFO    ] __main__: train step 21817: loss: 0.9498, policy_loss: 0.8859, value_loss: 0.4218
2024-07-14 07:37:34,704 [INFO    ] __main__: train step 21818: loss: 0.9497, policy_loss: 0.8859, value_loss: 0.4218
2024-07-14 07:37:35,000 [INFO    ] __main__: train step 21819: loss: 0.9497, policy_loss: 0.8858, value_loss: 0.4218
2024-07-14 07:37:35,280 [INFO    ] __main__: train step 21820: loss: 0.9497, policy_loss: 0.8858, value_loss: 0.4218
2024-07-14 07:37:35,546 [INFO    ] __main__: train step 21821: loss: 0.9497, policy_loss: 0.8858, value_loss: 0.4218
2024-07-14 07:37:35,823 [INFO    ] __main__: train step 21822: loss: 0.9497, policy_loss: 0.8858, value_loss: 0.4217
2024-07-14 07:37:36,124 [INFO    ] __main__: train step 21823: loss: 0.9497, policy_loss: 0.8858, value_loss: 0.4217
2024-07-14 07:37:36,418 [INFO    ] __main__: train step 21824: loss: 0.9497, policy_loss: 0.8858, value_loss: 0.4217
2024-07-14 07:37:38,043 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:37:38,523 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:37:38,593 [INFO    ] __main__: train step 21825: loss: 0.9496, policy_loss: 0.8858, value_loss: 0.4217
2024-07-14 07:37:38,897 [INFO    ] __main__: train step 21826: loss: 0.9496, policy_loss: 0.8857, value_loss: 0.4217
2024-07-14 07:37:39,189 [INFO    ] __main__: train step 21827: loss: 0.9496, policy_loss: 0.8857, value_loss: 0.4217
2024-07-14 07:37:39,479 [INFO    ] __main__: train step 21828: loss: 0.9496, policy_loss: 0.8857, value_loss: 0.4216
2024-07-14 07:37:39,771 [INFO    ] __main__: train step 21829: loss: 0.9496, policy_loss: 0.8857, value_loss: 0.4216
2024-07-14 07:37:40,021 [INFO    ] __main__: train step 21830: loss: 0.9496, policy_loss: 0.8857, value_loss: 0.4216
2024-07-14 07:37:40,299 [INFO    ] __main__: train step 21831: loss: 0.9496, policy_loss: 0.8857, value_loss: 0.4216
2024-07-14 07:37:40,593 [INFO    ] __main__: train step 21832: loss: 0.9495, policy_loss: 0.8856, value_loss: 0.4216
2024-07-14 07:37:40,894 [INFO    ] __main__: train step 21833: loss: 0.9495, policy_loss: 0.8856, value_loss: 0.4216
2024-07-14 07:37:41,179 [INFO    ] __main__: train step 21834: loss: 0.9495, policy_loss: 0.8856, value_loss: 0.4215
2024-07-14 07:37:41,462 [INFO    ] __main__: train step 21835: loss: 0.9495, policy_loss: 0.8856, value_loss: 0.4215
2024-07-14 07:37:41,734 [INFO    ] __main__: train step 21836: loss: 0.9495, policy_loss: 0.8856, value_loss: 0.4215
2024-07-14 07:37:42,023 [INFO    ] __main__: train step 21837: loss: 0.9495, policy_loss: 0.8856, value_loss: 0.4215
2024-07-14 07:37:42,328 [INFO    ] __main__: train step 21838: loss: 0.9494, policy_loss: 0.8856, value_loss: 0.4215
2024-07-14 07:37:42,638 [INFO    ] __main__: train step 21839: loss: 0.9494, policy_loss: 0.8855, value_loss: 0.4215
2024-07-14 07:37:42,940 [INFO    ] __main__: train step 21840: loss: 0.9494, policy_loss: 0.8855, value_loss: 0.4214
2024-07-14 07:37:43,231 [INFO    ] __main__: train step 21841: loss: 0.9494, policy_loss: 0.8855, value_loss: 0.4214
2024-07-14 07:37:44,855 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:37:45,330 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:37:45,418 [INFO    ] __main__: train step 21842: loss: 0.9494, policy_loss: 0.8855, value_loss: 0.4214
2024-07-14 07:37:45,700 [INFO    ] __main__: train step 21843: loss: 0.9494, policy_loss: 0.8855, value_loss: 0.4214
2024-07-14 07:37:45,998 [INFO    ] __main__: train step 21844: loss: 0.9494, policy_loss: 0.8855, value_loss: 0.4214
2024-07-14 07:37:46,281 [INFO    ] __main__: train step 21845: loss: 0.9493, policy_loss: 0.8855, value_loss: 0.4214
2024-07-14 07:37:46,565 [INFO    ] __main__: train step 21846: loss: 0.9493, policy_loss: 0.8854, value_loss: 0.4214
2024-07-14 07:37:46,847 [INFO    ] __main__: train step 21847: loss: 0.9493, policy_loss: 0.8854, value_loss: 0.4213
2024-07-14 07:37:47,149 [INFO    ] __main__: train step 21848: loss: 0.9493, policy_loss: 0.8854, value_loss: 0.4213
2024-07-14 07:37:47,445 [INFO    ] __main__: train step 21849: loss: 0.9493, policy_loss: 0.8854, value_loss: 0.4213
2024-07-14 07:37:47,741 [INFO    ] __main__: train step 21850: loss: 0.9493, policy_loss: 0.8854, value_loss: 0.4213
2024-07-14 07:37:48,020 [INFO    ] __main__: train step 21851: loss: 0.9493, policy_loss: 0.8854, value_loss: 0.4213
2024-07-14 07:37:48,307 [INFO    ] __main__: train step 21852: loss: 0.9492, policy_loss: 0.8853, value_loss: 0.4213
2024-07-14 07:37:48,607 [INFO    ] __main__: train step 21853: loss: 0.9492, policy_loss: 0.8853, value_loss: 0.4212
2024-07-14 07:37:48,907 [INFO    ] __main__: train step 21854: loss: 0.9492, policy_loss: 0.8853, value_loss: 0.4212
2024-07-14 07:37:49,205 [INFO    ] __main__: train step 21855: loss: 0.9492, policy_loss: 0.8853, value_loss: 0.4212
2024-07-14 07:37:49,474 [INFO    ] __main__: train step 21856: loss: 0.9492, policy_loss: 0.8853, value_loss: 0.4212
2024-07-14 07:37:49,767 [INFO    ] __main__: train step 21857: loss: 0.9492, policy_loss: 0.8853, value_loss: 0.4212
2024-07-14 07:37:50,056 [INFO    ] __main__: train step 21858: loss: 0.9492, policy_loss: 0.8853, value_loss: 0.4212
2024-07-14 07:37:51,687 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:37:52,161 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:37:52,226 [INFO    ] __main__: train step 21859: loss: 0.9491, policy_loss: 0.8852, value_loss: 0.4211
2024-07-14 07:37:52,505 [INFO    ] __main__: train step 21860: loss: 0.9491, policy_loss: 0.8852, value_loss: 0.4211
2024-07-14 07:37:52,779 [INFO    ] __main__: train step 21861: loss: 0.9491, policy_loss: 0.8852, value_loss: 0.4211
2024-07-14 07:37:53,048 [INFO    ] __main__: train step 21862: loss: 0.9491, policy_loss: 0.8852, value_loss: 0.4211
2024-07-14 07:37:53,317 [INFO    ] __main__: train step 21863: loss: 0.9491, policy_loss: 0.8852, value_loss: 0.4211
2024-07-14 07:37:53,585 [INFO    ] __main__: train step 21864: loss: 0.9491, policy_loss: 0.8852, value_loss: 0.4211
2024-07-14 07:37:53,859 [INFO    ] __main__: train step 21865: loss: 0.9490, policy_loss: 0.8852, value_loss: 0.4210
2024-07-14 07:37:54,128 [INFO    ] __main__: train step 21866: loss: 0.9490, policy_loss: 0.8851, value_loss: 0.4210
2024-07-14 07:37:54,413 [INFO    ] __main__: train step 21867: loss: 0.9490, policy_loss: 0.8851, value_loss: 0.4210
2024-07-14 07:37:54,697 [INFO    ] __main__: train step 21868: loss: 0.9490, policy_loss: 0.8851, value_loss: 0.4210
2024-07-14 07:37:54,985 [INFO    ] __main__: train step 21869: loss: 0.9490, policy_loss: 0.8851, value_loss: 0.4210
2024-07-14 07:37:55,263 [INFO    ] __main__: train step 21870: loss: 0.9490, policy_loss: 0.8851, value_loss: 0.4210
2024-07-14 07:37:55,559 [INFO    ] __main__: train step 21871: loss: 0.9490, policy_loss: 0.8851, value_loss: 0.4209
2024-07-14 07:37:55,853 [INFO    ] __main__: train step 21872: loss: 0.9489, policy_loss: 0.8850, value_loss: 0.4209
2024-07-14 07:37:56,140 [INFO    ] __main__: train step 21873: loss: 0.9489, policy_loss: 0.8850, value_loss: 0.4209
2024-07-14 07:37:56,428 [INFO    ] __main__: train step 21874: loss: 0.9489, policy_loss: 0.8850, value_loss: 0.4209
2024-07-14 07:37:56,720 [INFO    ] __main__: train step 21875: loss: 0.9489, policy_loss: 0.8850, value_loss: 0.4209
2024-07-14 07:37:58,308 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:37:58,784 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:37:58,850 [INFO    ] __main__: train step 21876: loss: 0.9489, policy_loss: 0.8850, value_loss: 0.4209
2024-07-14 07:37:59,131 [INFO    ] __main__: train step 21877: loss: 0.9489, policy_loss: 0.8850, value_loss: 0.4209
2024-07-14 07:37:59,418 [INFO    ] __main__: train step 21878: loss: 0.9489, policy_loss: 0.8850, value_loss: 0.4208
2024-07-14 07:37:59,715 [INFO    ] __main__: train step 21879: loss: 0.9488, policy_loss: 0.8849, value_loss: 0.4208
2024-07-14 07:38:00,011 [INFO    ] __main__: train step 21880: loss: 0.9488, policy_loss: 0.8849, value_loss: 0.4208
2024-07-14 07:38:00,300 [INFO    ] __main__: train step 21881: loss: 0.9488, policy_loss: 0.8849, value_loss: 0.4208
2024-07-14 07:38:00,593 [INFO    ] __main__: train step 21882: loss: 0.9488, policy_loss: 0.8849, value_loss: 0.4208
2024-07-14 07:38:00,893 [INFO    ] __main__: train step 21883: loss: 0.9488, policy_loss: 0.8849, value_loss: 0.4208
2024-07-14 07:38:01,206 [INFO    ] __main__: train step 21884: loss: 0.9488, policy_loss: 0.8849, value_loss: 0.4207
2024-07-14 07:38:01,498 [INFO    ] __main__: train step 21885: loss: 0.9488, policy_loss: 0.8849, value_loss: 0.4207
2024-07-14 07:38:01,779 [INFO    ] __main__: train step 21886: loss: 0.9487, policy_loss: 0.8848, value_loss: 0.4207
2024-07-14 07:38:02,077 [INFO    ] __main__: train step 21887: loss: 0.9487, policy_loss: 0.8848, value_loss: 0.4207
2024-07-14 07:38:02,370 [INFO    ] __main__: train step 21888: loss: 0.9487, policy_loss: 0.8848, value_loss: 0.4207
2024-07-14 07:38:02,636 [INFO    ] __main__: train step 21889: loss: 0.9487, policy_loss: 0.8848, value_loss: 0.4207
2024-07-14 07:38:02,908 [INFO    ] __main__: train step 21890: loss: 0.9487, policy_loss: 0.8848, value_loss: 0.4206
2024-07-14 07:38:03,184 [INFO    ] __main__: train step 21891: loss: 0.9487, policy_loss: 0.8848, value_loss: 0.4206
2024-07-14 07:38:03,484 [INFO    ] __main__: train step 21892: loss: 0.9486, policy_loss: 0.8847, value_loss: 0.4206
2024-07-14 07:38:05,107 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:38:05,613 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:38:05,684 [INFO    ] __main__: train step 21893: loss: 0.9486, policy_loss: 0.8847, value_loss: 0.4206
2024-07-14 07:38:05,996 [INFO    ] __main__: train step 21894: loss: 0.9486, policy_loss: 0.8847, value_loss: 0.4206
2024-07-14 07:38:06,298 [INFO    ] __main__: train step 21895: loss: 0.9486, policy_loss: 0.8847, value_loss: 0.4206
2024-07-14 07:38:06,608 [INFO    ] __main__: train step 21896: loss: 0.9486, policy_loss: 0.8847, value_loss: 0.4205
2024-07-14 07:38:06,929 [INFO    ] __main__: train step 21897: loss: 0.9486, policy_loss: 0.8847, value_loss: 0.4205
2024-07-14 07:38:07,228 [INFO    ] __main__: train step 21898: loss: 0.9486, policy_loss: 0.8847, value_loss: 0.4205
2024-07-14 07:38:07,529 [INFO    ] __main__: train step 21899: loss: 0.9485, policy_loss: 0.8846, value_loss: 0.4205
2024-07-14 07:38:07,826 [INFO    ] __main__: train step 21900: loss: 0.9485, policy_loss: 0.8846, value_loss: 0.4205
2024-07-14 07:38:08,116 [INFO    ] __main__: train step 21901: loss: 0.9485, policy_loss: 0.8846, value_loss: 0.4205
2024-07-14 07:38:08,416 [INFO    ] __main__: train step 21902: loss: 0.9485, policy_loss: 0.8846, value_loss: 0.4204
2024-07-14 07:38:08,698 [INFO    ] __main__: train step 21903: loss: 0.9485, policy_loss: 0.8846, value_loss: 0.4204
2024-07-14 07:38:08,996 [INFO    ] __main__: train step 21904: loss: 0.9485, policy_loss: 0.8846, value_loss: 0.4204
2024-07-14 07:38:09,306 [INFO    ] __main__: train step 21905: loss: 0.9485, policy_loss: 0.8846, value_loss: 0.4204
2024-07-14 07:38:09,599 [INFO    ] __main__: train step 21906: loss: 0.9484, policy_loss: 0.8845, value_loss: 0.4204
2024-07-14 07:38:09,911 [INFO    ] __main__: train step 21907: loss: 0.9484, policy_loss: 0.8845, value_loss: 0.4204
2024-07-14 07:38:10,194 [INFO    ] __main__: train step 21908: loss: 0.9484, policy_loss: 0.8845, value_loss: 0.4203
2024-07-14 07:38:10,492 [INFO    ] __main__: train step 21909: loss: 0.9484, policy_loss: 0.8845, value_loss: 0.4203
2024-07-14 07:38:12,105 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:38:12,594 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:38:12,658 [INFO    ] __main__: train step 21910: loss: 0.9484, policy_loss: 0.8845, value_loss: 0.4203
2024-07-14 07:38:12,966 [INFO    ] __main__: train step 21911: loss: 0.9484, policy_loss: 0.8845, value_loss: 0.4203
2024-07-14 07:38:13,260 [INFO    ] __main__: train step 21912: loss: 0.9484, policy_loss: 0.8844, value_loss: 0.4203
2024-07-14 07:38:13,543 [INFO    ] __main__: train step 21913: loss: 0.9483, policy_loss: 0.8844, value_loss: 0.4203
2024-07-14 07:38:13,847 [INFO    ] __main__: train step 21914: loss: 0.9483, policy_loss: 0.8844, value_loss: 0.4203
2024-07-14 07:38:14,181 [INFO    ] __main__: train step 21915: loss: 0.9483, policy_loss: 0.8844, value_loss: 0.4202
2024-07-14 07:38:18,084 [INFO    ] __main__: train step 21916: loss: 0.9483, policy_loss: 0.8844, value_loss: 0.4202
2024-07-14 07:38:18,386 [INFO    ] __main__: train step 21917: loss: 0.9483, policy_loss: 0.8844, value_loss: 0.4202
2024-07-14 07:38:18,706 [INFO    ] __main__: train step 21918: loss: 0.9483, policy_loss: 0.8844, value_loss: 0.4202
2024-07-14 07:38:19,027 [INFO    ] __main__: train step 21919: loss: 0.9482, policy_loss: 0.8843, value_loss: 0.4202
2024-07-14 07:38:19,362 [INFO    ] __main__: train step 21920: loss: 0.9482, policy_loss: 0.8843, value_loss: 0.4202
2024-07-14 07:38:19,666 [INFO    ] __main__: train step 21921: loss: 0.9482, policy_loss: 0.8843, value_loss: 0.4201
2024-07-14 07:38:19,966 [INFO    ] __main__: train step 21922: loss: 0.9482, policy_loss: 0.8843, value_loss: 0.4201
2024-07-14 07:38:20,273 [INFO    ] __main__: train step 21923: loss: 0.9482, policy_loss: 0.8843, value_loss: 0.4201
2024-07-14 07:38:20,585 [INFO    ] __main__: train step 21924: loss: 0.9482, policy_loss: 0.8843, value_loss: 0.4201
2024-07-14 07:38:20,883 [INFO    ] __main__: train step 21925: loss: 0.9482, policy_loss: 0.8843, value_loss: 0.4201
2024-07-14 07:38:21,204 [INFO    ] __main__: train step 21926: loss: 0.9481, policy_loss: 0.8842, value_loss: 0.4201
2024-07-14 07:38:22,846 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:38:23,293 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:38:23,363 [INFO    ] __main__: train step 21927: loss: 0.9481, policy_loss: 0.8842, value_loss: 0.4200
2024-07-14 07:38:23,669 [INFO    ] __main__: train step 21928: loss: 0.9481, policy_loss: 0.8842, value_loss: 0.4200
2024-07-14 07:38:23,954 [INFO    ] __main__: train step 21929: loss: 0.9481, policy_loss: 0.8842, value_loss: 0.4200
2024-07-14 07:38:24,249 [INFO    ] __main__: train step 21930: loss: 0.9481, policy_loss: 0.8842, value_loss: 0.4200
2024-07-14 07:38:24,553 [INFO    ] __main__: train step 21931: loss: 0.9481, policy_loss: 0.8842, value_loss: 0.4200
2024-07-14 07:38:24,836 [INFO    ] __main__: train step 21932: loss: 0.9481, policy_loss: 0.8841, value_loss: 0.4200
2024-07-14 07:38:25,141 [INFO    ] __main__: train step 21933: loss: 0.9480, policy_loss: 0.8841, value_loss: 0.4199
2024-07-14 07:38:25,442 [INFO    ] __main__: train step 21934: loss: 0.9480, policy_loss: 0.8841, value_loss: 0.4199
2024-07-14 07:38:25,774 [INFO    ] __main__: train step 21935: loss: 0.9480, policy_loss: 0.8841, value_loss: 0.4199
2024-07-14 07:38:26,069 [INFO    ] __main__: train step 21936: loss: 0.9480, policy_loss: 0.8841, value_loss: 0.4199
2024-07-14 07:38:26,340 [INFO    ] __main__: train step 21937: loss: 0.9480, policy_loss: 0.8841, value_loss: 0.4199
2024-07-14 07:38:26,656 [INFO    ] __main__: train step 21938: loss: 0.9480, policy_loss: 0.8841, value_loss: 0.4199
2024-07-14 07:38:26,971 [INFO    ] __main__: train step 21939: loss: 0.9480, policy_loss: 0.8840, value_loss: 0.4199
2024-07-14 07:38:27,283 [INFO    ] __main__: train step 21940: loss: 0.9479, policy_loss: 0.8840, value_loss: 0.4198
2024-07-14 07:38:27,587 [INFO    ] __main__: train step 21941: loss: 0.9479, policy_loss: 0.8840, value_loss: 0.4198
2024-07-14 07:38:27,883 [INFO    ] __main__: train step 21942: loss: 0.9479, policy_loss: 0.8840, value_loss: 0.4198
2024-07-14 07:38:28,186 [INFO    ] __main__: train step 21943: loss: 0.9479, policy_loss: 0.8840, value_loss: 0.4198
2024-07-14 07:38:29,823 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:38:30,247 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:38:30,319 [INFO    ] __main__: train step 21944: loss: 0.9479, policy_loss: 0.8840, value_loss: 0.4198
2024-07-14 07:38:30,631 [INFO    ] __main__: train step 21945: loss: 0.9479, policy_loss: 0.8840, value_loss: 0.4198
2024-07-14 07:38:30,953 [INFO    ] __main__: train step 21946: loss: 0.9478, policy_loss: 0.8839, value_loss: 0.4197
2024-07-14 07:38:31,284 [INFO    ] __main__: train step 21947: loss: 0.9478, policy_loss: 0.8839, value_loss: 0.4197
2024-07-14 07:38:31,584 [INFO    ] __main__: train step 21948: loss: 0.9478, policy_loss: 0.8839, value_loss: 0.4197
2024-07-14 07:38:31,862 [INFO    ] __main__: train step 21949: loss: 0.9478, policy_loss: 0.8839, value_loss: 0.4197
2024-07-14 07:38:32,151 [INFO    ] __main__: train step 21950: loss: 0.9478, policy_loss: 0.8839, value_loss: 0.4197
2024-07-14 07:38:32,442 [INFO    ] __main__: train step 21951: loss: 0.9478, policy_loss: 0.8839, value_loss: 0.4197
2024-07-14 07:38:32,756 [INFO    ] __main__: train step 21952: loss: 0.9478, policy_loss: 0.8839, value_loss: 0.4196
2024-07-14 07:38:33,050 [INFO    ] __main__: train step 21953: loss: 0.9477, policy_loss: 0.8838, value_loss: 0.4196
2024-07-14 07:38:33,339 [INFO    ] __main__: train step 21954: loss: 0.9477, policy_loss: 0.8838, value_loss: 0.4196
2024-07-14 07:38:33,636 [INFO    ] __main__: train step 21955: loss: 0.9477, policy_loss: 0.8838, value_loss: 0.4196
2024-07-14 07:38:33,948 [INFO    ] __main__: train step 21956: loss: 0.9477, policy_loss: 0.8838, value_loss: 0.4196
2024-07-14 07:38:34,238 [INFO    ] __main__: train step 21957: loss: 0.9477, policy_loss: 0.8838, value_loss: 0.4196
2024-07-14 07:38:34,532 [INFO    ] __main__: train step 21958: loss: 0.9477, policy_loss: 0.8838, value_loss: 0.4195
2024-07-14 07:38:34,840 [INFO    ] __main__: train step 21959: loss: 0.9477, policy_loss: 0.8837, value_loss: 0.4195
2024-07-14 07:38:35,126 [INFO    ] __main__: train step 21960: loss: 0.9476, policy_loss: 0.8837, value_loss: 0.4195
2024-07-14 07:38:36,752 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:38:37,259 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:38:37,337 [INFO    ] __main__: train step 21961: loss: 0.9476, policy_loss: 0.8837, value_loss: 0.4195
2024-07-14 07:38:37,637 [INFO    ] __main__: train step 21962: loss: 0.9476, policy_loss: 0.8837, value_loss: 0.4195
2024-07-14 07:38:37,926 [INFO    ] __main__: train step 21963: loss: 0.9476, policy_loss: 0.8837, value_loss: 0.4195
2024-07-14 07:38:38,218 [INFO    ] __main__: train step 21964: loss: 0.9476, policy_loss: 0.8837, value_loss: 0.4194
2024-07-14 07:38:38,487 [INFO    ] __main__: train step 21965: loss: 0.9476, policy_loss: 0.8837, value_loss: 0.4194
2024-07-14 07:38:38,778 [INFO    ] __main__: train step 21966: loss: 0.9476, policy_loss: 0.8836, value_loss: 0.4194
2024-07-14 07:38:39,079 [INFO    ] __main__: train step 21967: loss: 0.9475, policy_loss: 0.8836, value_loss: 0.4194
2024-07-14 07:38:39,376 [INFO    ] __main__: train step 21968: loss: 0.9475, policy_loss: 0.8836, value_loss: 0.4194
2024-07-14 07:38:39,657 [INFO    ] __main__: train step 21969: loss: 0.9475, policy_loss: 0.8836, value_loss: 0.4194
2024-07-14 07:38:39,988 [INFO    ] __main__: train step 21970: loss: 0.9475, policy_loss: 0.8836, value_loss: 0.4194
2024-07-14 07:38:40,276 [INFO    ] __main__: train step 21971: loss: 0.9475, policy_loss: 0.8836, value_loss: 0.4193
2024-07-14 07:38:40,553 [INFO    ] __main__: train step 21972: loss: 0.9475, policy_loss: 0.8836, value_loss: 0.4193
2024-07-14 07:38:40,836 [INFO    ] __main__: train step 21973: loss: 0.9474, policy_loss: 0.8835, value_loss: 0.4193
2024-07-14 07:38:41,144 [INFO    ] __main__: train step 21974: loss: 0.9474, policy_loss: 0.8835, value_loss: 0.4193
2024-07-14 07:38:41,422 [INFO    ] __main__: train step 21975: loss: 0.9474, policy_loss: 0.8835, value_loss: 0.4193
2024-07-14 07:38:41,706 [INFO    ] __main__: train step 21976: loss: 0.9474, policy_loss: 0.8835, value_loss: 0.4193
2024-07-14 07:38:41,997 [INFO    ] __main__: train step 21977: loss: 0.9474, policy_loss: 0.8835, value_loss: 0.4192
2024-07-14 07:38:43,597 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:38:44,083 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:38:44,151 [INFO    ] __main__: train step 21978: loss: 0.9474, policy_loss: 0.8835, value_loss: 0.4192
2024-07-14 07:38:44,445 [INFO    ] __main__: train step 21979: loss: 0.9474, policy_loss: 0.8834, value_loss: 0.4192
2024-07-14 07:38:44,759 [INFO    ] __main__: train step 21980: loss: 0.9473, policy_loss: 0.8834, value_loss: 0.4192
2024-07-14 07:38:45,032 [INFO    ] __main__: train step 21981: loss: 0.9473, policy_loss: 0.8834, value_loss: 0.4192
2024-07-14 07:38:45,336 [INFO    ] __main__: train step 21982: loss: 0.9473, policy_loss: 0.8834, value_loss: 0.4192
2024-07-14 07:38:45,612 [INFO    ] __main__: train step 21983: loss: 0.9473, policy_loss: 0.8834, value_loss: 0.4191
2024-07-14 07:38:45,885 [INFO    ] __main__: train step 21984: loss: 0.9473, policy_loss: 0.8834, value_loss: 0.4191
2024-07-14 07:38:46,149 [INFO    ] __main__: train step 21985: loss: 0.9473, policy_loss: 0.8834, value_loss: 0.4191
2024-07-14 07:38:46,434 [INFO    ] __main__: train step 21986: loss: 0.9473, policy_loss: 0.8833, value_loss: 0.4191
2024-07-14 07:38:46,726 [INFO    ] __main__: train step 21987: loss: 0.9472, policy_loss: 0.8833, value_loss: 0.4191
2024-07-14 07:38:46,990 [INFO    ] __main__: train step 21988: loss: 0.9472, policy_loss: 0.8833, value_loss: 0.4191
2024-07-14 07:38:47,270 [INFO    ] __main__: train step 21989: loss: 0.9472, policy_loss: 0.8833, value_loss: 0.4190
2024-07-14 07:38:47,545 [INFO    ] __main__: train step 21990: loss: 0.9472, policy_loss: 0.8833, value_loss: 0.4190
2024-07-14 07:38:47,825 [INFO    ] __main__: train step 21991: loss: 0.9472, policy_loss: 0.8833, value_loss: 0.4190
2024-07-14 07:38:48,111 [INFO    ] __main__: train step 21992: loss: 0.9472, policy_loss: 0.8833, value_loss: 0.4190
2024-07-14 07:38:48,383 [INFO    ] __main__: train step 21993: loss: 0.9472, policy_loss: 0.8832, value_loss: 0.4190
2024-07-14 07:38:48,640 [INFO    ] __main__: train step 21994: loss: 0.9471, policy_loss: 0.8832, value_loss: 0.4190
2024-07-14 07:38:50,234 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:38:50,710 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:38:50,774 [INFO    ] __main__: train step 21995: loss: 0.9471, policy_loss: 0.8832, value_loss: 0.4190
2024-07-14 07:38:51,054 [INFO    ] __main__: train step 21996: loss: 0.9471, policy_loss: 0.8832, value_loss: 0.4189
2024-07-14 07:38:51,346 [INFO    ] __main__: train step 21997: loss: 0.9471, policy_loss: 0.8832, value_loss: 0.4189
2024-07-14 07:38:51,599 [INFO    ] __main__: train step 21998: loss: 0.9471, policy_loss: 0.8832, value_loss: 0.4189
2024-07-14 07:38:51,871 [INFO    ] __main__: train step 21999: loss: 0.9471, policy_loss: 0.8832, value_loss: 0.4189
2024-07-14 07:38:52,161 [INFO    ] __main__: train step 22000: loss: 0.9471, policy_loss: 0.8831, value_loss: 0.4189
2024-07-14 07:38:52,296 [INFO    ] __main__: restored step 21000 for evaluation
2024-07-14 07:38:57,549 [INFO    ] __main__: test network ELO difference from baseline network: +26 (+8/-8) ELO from 32000 self-played games
2024-07-14 07:38:57,551 [INFO    ] __main__: game outcomes: W: 16824, D: 254, L: 14922
2024-07-14 07:38:57,555 [INFO    ] __main__: validation_elo_delta: 26, validation_elo: 2950
2024-07-14 07:38:58,283 [INFO    ] __main__: train step 22001: loss: 0.9470, policy_loss: 0.8831, value_loss: 0.4189
2024-07-14 07:38:58,574 [INFO    ] __main__: train step 22002: loss: 0.9470, policy_loss: 0.8831, value_loss: 0.4188
2024-07-14 07:38:58,884 [INFO    ] __main__: train step 22003: loss: 0.9470, policy_loss: 0.8831, value_loss: 0.4188
2024-07-14 07:38:59,185 [INFO    ] __main__: train step 22004: loss: 0.9470, policy_loss: 0.8831, value_loss: 0.4188
2024-07-14 07:38:59,463 [INFO    ] __main__: train step 22005: loss: 0.9470, policy_loss: 0.8831, value_loss: 0.4188
2024-07-14 07:38:59,754 [INFO    ] __main__: train step 22006: loss: 0.9470, policy_loss: 0.8830, value_loss: 0.4188
2024-07-14 07:39:00,068 [INFO    ] __main__: train step 22007: loss: 0.9470, policy_loss: 0.8830, value_loss: 0.4188
2024-07-14 07:39:00,353 [INFO    ] __main__: train step 22008: loss: 0.9469, policy_loss: 0.8830, value_loss: 0.4187
2024-07-14 07:39:00,644 [INFO    ] __main__: train step 22009: loss: 0.9469, policy_loss: 0.8830, value_loss: 0.4187
2024-07-14 07:39:00,930 [INFO    ] __main__: train step 22010: loss: 0.9469, policy_loss: 0.8830, value_loss: 0.4187
2024-07-14 07:39:01,229 [INFO    ] __main__: train step 22011: loss: 0.9469, policy_loss: 0.8830, value_loss: 0.4187
2024-07-14 07:39:02,832 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:39:03,319 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:39:03,388 [INFO    ] __main__: train step 22012: loss: 0.9469, policy_loss: 0.8830, value_loss: 0.4187
2024-07-14 07:39:03,644 [INFO    ] __main__: train step 22013: loss: 0.9469, policy_loss: 0.8829, value_loss: 0.4187
2024-07-14 07:39:03,968 [INFO    ] __main__: train step 22014: loss: 0.9468, policy_loss: 0.8829, value_loss: 0.4187
2024-07-14 07:39:04,248 [INFO    ] __main__: train step 22015: loss: 0.9468, policy_loss: 0.8829, value_loss: 0.4186
2024-07-14 07:39:04,560 [INFO    ] __main__: train step 22016: loss: 0.9468, policy_loss: 0.8829, value_loss: 0.4186
2024-07-14 07:39:04,871 [INFO    ] __main__: train step 22017: loss: 0.9468, policy_loss: 0.8829, value_loss: 0.4186
2024-07-14 07:39:05,171 [INFO    ] __main__: train step 22018: loss: 0.9468, policy_loss: 0.8829, value_loss: 0.4186
2024-07-14 07:39:05,484 [INFO    ] __main__: train step 22019: loss: 0.9468, policy_loss: 0.8829, value_loss: 0.4186
2024-07-14 07:39:05,796 [INFO    ] __main__: train step 22020: loss: 0.9468, policy_loss: 0.8828, value_loss: 0.4186
2024-07-14 07:39:06,099 [INFO    ] __main__: train step 22021: loss: 0.9467, policy_loss: 0.8828, value_loss: 0.4185
2024-07-14 07:39:06,393 [INFO    ] __main__: train step 22022: loss: 0.9467, policy_loss: 0.8828, value_loss: 0.4185
2024-07-14 07:39:06,699 [INFO    ] __main__: train step 22023: loss: 0.9467, policy_loss: 0.8828, value_loss: 0.4185
2024-07-14 07:39:06,987 [INFO    ] __main__: train step 22024: loss: 0.9467, policy_loss: 0.8828, value_loss: 0.4185
2024-07-14 07:39:07,313 [INFO    ] __main__: train step 22025: loss: 0.9467, policy_loss: 0.8828, value_loss: 0.4185
2024-07-14 07:39:07,612 [INFO    ] __main__: train step 22026: loss: 0.9467, policy_loss: 0.8828, value_loss: 0.4185
2024-07-14 07:39:07,936 [INFO    ] __main__: train step 22027: loss: 0.9467, policy_loss: 0.8827, value_loss: 0.4184
2024-07-14 07:39:08,239 [INFO    ] __main__: train step 22028: loss: 0.9466, policy_loss: 0.8827, value_loss: 0.4184
2024-07-14 07:39:09,888 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:39:10,363 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:39:10,444 [INFO    ] __main__: train step 22029: loss: 0.9466, policy_loss: 0.8827, value_loss: 0.4184
2024-07-14 07:39:10,735 [INFO    ] __main__: train step 22030: loss: 0.9466, policy_loss: 0.8827, value_loss: 0.4184
2024-07-14 07:39:11,053 [INFO    ] __main__: train step 22031: loss: 0.9466, policy_loss: 0.8827, value_loss: 0.4184
2024-07-14 07:39:11,343 [INFO    ] __main__: train step 22032: loss: 0.9466, policy_loss: 0.8827, value_loss: 0.4184
2024-07-14 07:39:11,649 [INFO    ] __main__: train step 22033: loss: 0.9466, policy_loss: 0.8826, value_loss: 0.4183
2024-07-14 07:39:11,932 [INFO    ] __main__: train step 22034: loss: 0.9466, policy_loss: 0.8826, value_loss: 0.4183
2024-07-14 07:39:12,238 [INFO    ] __main__: train step 22035: loss: 0.9465, policy_loss: 0.8826, value_loss: 0.4183
2024-07-14 07:39:12,511 [INFO    ] __main__: train step 22036: loss: 0.9465, policy_loss: 0.8826, value_loss: 0.4183
2024-07-14 07:39:12,791 [INFO    ] __main__: train step 22037: loss: 0.9465, policy_loss: 0.8826, value_loss: 0.4183
2024-07-14 07:39:13,079 [INFO    ] __main__: train step 22038: loss: 0.9465, policy_loss: 0.8826, value_loss: 0.4183
2024-07-14 07:39:13,378 [INFO    ] __main__: train step 22039: loss: 0.9465, policy_loss: 0.8826, value_loss: 0.4183
2024-07-14 07:39:13,675 [INFO    ] __main__: train step 22040: loss: 0.9465, policy_loss: 0.8825, value_loss: 0.4182
2024-07-14 07:39:13,962 [INFO    ] __main__: train step 22041: loss: 0.9465, policy_loss: 0.8825, value_loss: 0.4182
2024-07-14 07:39:14,242 [INFO    ] __main__: train step 22042: loss: 0.9464, policy_loss: 0.8825, value_loss: 0.4182
2024-07-14 07:39:14,531 [INFO    ] __main__: train step 22043: loss: 0.9464, policy_loss: 0.8825, value_loss: 0.4182
2024-07-14 07:39:14,812 [INFO    ] __main__: train step 22044: loss: 0.9464, policy_loss: 0.8825, value_loss: 0.4182
2024-07-14 07:39:20,543 [INFO    ] __main__: train step 22045: loss: 0.9464, policy_loss: 0.8825, value_loss: 0.4182
2024-07-14 07:39:22,194 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:39:22,663 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:39:22,755 [INFO    ] __main__: train step 22046: loss: 0.9464, policy_loss: 0.8825, value_loss: 0.4181
2024-07-14 07:39:23,056 [INFO    ] __main__: train step 22047: loss: 0.9464, policy_loss: 0.8824, value_loss: 0.4181
2024-07-14 07:39:23,329 [INFO    ] __main__: train step 22048: loss: 0.9464, policy_loss: 0.8824, value_loss: 0.4181
2024-07-14 07:39:23,621 [INFO    ] __main__: train step 22049: loss: 0.9463, policy_loss: 0.8824, value_loss: 0.4181
2024-07-14 07:39:23,898 [INFO    ] __main__: train step 22050: loss: 0.9463, policy_loss: 0.8824, value_loss: 0.4181
2024-07-14 07:39:24,186 [INFO    ] __main__: train step 22051: loss: 0.9463, policy_loss: 0.8824, value_loss: 0.4181
2024-07-14 07:39:24,491 [INFO    ] __main__: train step 22052: loss: 0.9463, policy_loss: 0.8824, value_loss: 0.4181
2024-07-14 07:39:24,796 [INFO    ] __main__: train step 22053: loss: 0.9463, policy_loss: 0.8824, value_loss: 0.4180
2024-07-14 07:39:25,091 [INFO    ] __main__: train step 22054: loss: 0.9463, policy_loss: 0.8823, value_loss: 0.4180
2024-07-14 07:39:25,389 [INFO    ] __main__: train step 22055: loss: 0.9463, policy_loss: 0.8823, value_loss: 0.4180
2024-07-14 07:39:25,667 [INFO    ] __main__: train step 22056: loss: 0.9462, policy_loss: 0.8823, value_loss: 0.4180
2024-07-14 07:39:25,984 [INFO    ] __main__: train step 22057: loss: 0.9462, policy_loss: 0.8823, value_loss: 0.4180
2024-07-14 07:39:26,289 [INFO    ] __main__: train step 22058: loss: 0.9462, policy_loss: 0.8823, value_loss: 0.4180
2024-07-14 07:39:26,585 [INFO    ] __main__: train step 22059: loss: 0.9462, policy_loss: 0.8823, value_loss: 0.4179
2024-07-14 07:39:26,885 [INFO    ] __main__: train step 22060: loss: 0.9462, policy_loss: 0.8822, value_loss: 0.4179
2024-07-14 07:39:27,182 [INFO    ] __main__: train step 22061: loss: 0.9462, policy_loss: 0.8822, value_loss: 0.4179
2024-07-14 07:39:27,493 [INFO    ] __main__: train step 22062: loss: 0.9462, policy_loss: 0.8822, value_loss: 0.4179
2024-07-14 07:39:29,135 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:39:29,609 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:39:29,683 [INFO    ] __main__: train step 22063: loss: 0.9461, policy_loss: 0.8822, value_loss: 0.4179
2024-07-14 07:39:29,982 [INFO    ] __main__: train step 22064: loss: 0.9461, policy_loss: 0.8822, value_loss: 0.4179
2024-07-14 07:39:30,292 [INFO    ] __main__: train step 22065: loss: 0.9461, policy_loss: 0.8822, value_loss: 0.4178
2024-07-14 07:39:30,601 [INFO    ] __main__: train step 22066: loss: 0.9461, policy_loss: 0.8822, value_loss: 0.4178
2024-07-14 07:39:30,889 [INFO    ] __main__: train step 22067: loss: 0.9461, policy_loss: 0.8821, value_loss: 0.4178
2024-07-14 07:39:31,187 [INFO    ] __main__: train step 22068: loss: 0.9461, policy_loss: 0.8821, value_loss: 0.4178
2024-07-14 07:39:31,488 [INFO    ] __main__: train step 22069: loss: 0.9461, policy_loss: 0.8821, value_loss: 0.4178
2024-07-14 07:39:31,802 [INFO    ] __main__: train step 22070: loss: 0.9460, policy_loss: 0.8821, value_loss: 0.4178
2024-07-14 07:39:32,085 [INFO    ] __main__: train step 22071: loss: 0.9460, policy_loss: 0.8821, value_loss: 0.4177
2024-07-14 07:39:32,363 [INFO    ] __main__: train step 22072: loss: 0.9460, policy_loss: 0.8821, value_loss: 0.4177
2024-07-14 07:39:32,671 [INFO    ] __main__: train step 22073: loss: 0.9460, policy_loss: 0.8821, value_loss: 0.4177
2024-07-14 07:39:32,978 [INFO    ] __main__: train step 22074: loss: 0.9460, policy_loss: 0.8820, value_loss: 0.4177
2024-07-14 07:39:33,287 [INFO    ] __main__: train step 22075: loss: 0.9460, policy_loss: 0.8820, value_loss: 0.4177
2024-07-14 07:39:33,583 [INFO    ] __main__: train step 22076: loss: 0.9459, policy_loss: 0.8820, value_loss: 0.4177
2024-07-14 07:39:33,887 [INFO    ] __main__: train step 22077: loss: 0.9459, policy_loss: 0.8820, value_loss: 0.4177
2024-07-14 07:39:34,187 [INFO    ] __main__: train step 22078: loss: 0.9459, policy_loss: 0.8820, value_loss: 0.4176
2024-07-14 07:39:34,489 [INFO    ] __main__: train step 22079: loss: 0.9459, policy_loss: 0.8820, value_loss: 0.4176
2024-07-14 07:39:36,110 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:39:36,555 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:39:36,624 [INFO    ] __main__: train step 22080: loss: 0.9459, policy_loss: 0.8820, value_loss: 0.4176
2024-07-14 07:39:36,955 [INFO    ] __main__: train step 22081: loss: 0.9459, policy_loss: 0.8819, value_loss: 0.4176
2024-07-14 07:39:37,256 [INFO    ] __main__: train step 22082: loss: 0.9459, policy_loss: 0.8819, value_loss: 0.4176
2024-07-14 07:39:37,560 [INFO    ] __main__: train step 22083: loss: 0.9458, policy_loss: 0.8819, value_loss: 0.4176
2024-07-14 07:39:37,860 [INFO    ] __main__: train step 22084: loss: 0.9458, policy_loss: 0.8819, value_loss: 0.4175
2024-07-14 07:39:38,159 [INFO    ] __main__: train step 22085: loss: 0.9458, policy_loss: 0.8819, value_loss: 0.4175
2024-07-14 07:39:38,456 [INFO    ] __main__: train step 22086: loss: 0.9458, policy_loss: 0.8819, value_loss: 0.4175
2024-07-14 07:39:38,763 [INFO    ] __main__: train step 22087: loss: 0.9458, policy_loss: 0.8819, value_loss: 0.4175
2024-07-14 07:39:39,080 [INFO    ] __main__: train step 22088: loss: 0.9458, policy_loss: 0.8818, value_loss: 0.4175
2024-07-14 07:39:39,373 [INFO    ] __main__: train step 22089: loss: 0.9458, policy_loss: 0.8818, value_loss: 0.4175
2024-07-14 07:39:39,684 [INFO    ] __main__: train step 22090: loss: 0.9457, policy_loss: 0.8818, value_loss: 0.4174
2024-07-14 07:39:39,979 [INFO    ] __main__: train step 22091: loss: 0.9457, policy_loss: 0.8818, value_loss: 0.4174
2024-07-14 07:39:40,298 [INFO    ] __main__: train step 22092: loss: 0.9457, policy_loss: 0.8818, value_loss: 0.4174
2024-07-14 07:39:40,621 [INFO    ] __main__: train step 22093: loss: 0.9457, policy_loss: 0.8818, value_loss: 0.4174
2024-07-14 07:39:40,948 [INFO    ] __main__: train step 22094: loss: 0.9457, policy_loss: 0.8818, value_loss: 0.4174
2024-07-14 07:39:41,265 [INFO    ] __main__: train step 22095: loss: 0.9457, policy_loss: 0.8817, value_loss: 0.4174
2024-07-14 07:39:41,579 [INFO    ] __main__: train step 22096: loss: 0.9457, policy_loss: 0.8817, value_loss: 0.4173
2024-07-14 07:39:43,229 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:39:43,671 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:39:43,751 [INFO    ] __main__: train step 22097: loss: 0.9456, policy_loss: 0.8817, value_loss: 0.4173
2024-07-14 07:39:44,078 [INFO    ] __main__: train step 22098: loss: 0.9456, policy_loss: 0.8817, value_loss: 0.4173
2024-07-14 07:39:44,399 [INFO    ] __main__: train step 22099: loss: 0.9456, policy_loss: 0.8817, value_loss: 0.4173
2024-07-14 07:39:44,698 [INFO    ] __main__: train step 22100: loss: 0.9456, policy_loss: 0.8817, value_loss: 0.4173
2024-07-14 07:39:44,995 [INFO    ] __main__: train step 22101: loss: 0.9456, policy_loss: 0.8817, value_loss: 0.4173
2024-07-14 07:39:45,315 [INFO    ] __main__: train step 22102: loss: 0.9456, policy_loss: 0.8816, value_loss: 0.4173
2024-07-14 07:39:45,632 [INFO    ] __main__: train step 22103: loss: 0.9456, policy_loss: 0.8816, value_loss: 0.4172
2024-07-14 07:39:45,963 [INFO    ] __main__: train step 22104: loss: 0.9455, policy_loss: 0.8816, value_loss: 0.4172
2024-07-14 07:39:46,266 [INFO    ] __main__: train step 22105: loss: 0.9455, policy_loss: 0.8816, value_loss: 0.4172
2024-07-14 07:39:46,584 [INFO    ] __main__: train step 22106: loss: 0.9455, policy_loss: 0.8816, value_loss: 0.4172
2024-07-14 07:39:46,908 [INFO    ] __main__: train step 22107: loss: 0.9455, policy_loss: 0.8816, value_loss: 0.4172
2024-07-14 07:39:47,225 [INFO    ] __main__: train step 22108: loss: 0.9455, policy_loss: 0.8815, value_loss: 0.4172
2024-07-14 07:39:47,543 [INFO    ] __main__: train step 22109: loss: 0.9455, policy_loss: 0.8815, value_loss: 0.4171
2024-07-14 07:39:47,859 [INFO    ] __main__: train step 22110: loss: 0.9455, policy_loss: 0.8815, value_loss: 0.4171
2024-07-14 07:39:48,151 [INFO    ] __main__: train step 22111: loss: 0.9454, policy_loss: 0.8815, value_loss: 0.4171
2024-07-14 07:39:48,461 [INFO    ] __main__: train step 22112: loss: 0.9454, policy_loss: 0.8815, value_loss: 0.4171
2024-07-14 07:39:48,786 [INFO    ] __main__: train step 22113: loss: 0.9454, policy_loss: 0.8815, value_loss: 0.4171
2024-07-14 07:39:50,449 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:39:50,895 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:39:50,981 [INFO    ] __main__: train step 22114: loss: 0.9454, policy_loss: 0.8815, value_loss: 0.4171
2024-07-14 07:39:51,322 [INFO    ] __main__: train step 22115: loss: 0.9454, policy_loss: 0.8814, value_loss: 0.4170
2024-07-14 07:39:51,640 [INFO    ] __main__: train step 22116: loss: 0.9454, policy_loss: 0.8814, value_loss: 0.4170
2024-07-14 07:39:51,965 [INFO    ] __main__: train step 22117: loss: 0.9454, policy_loss: 0.8814, value_loss: 0.4170
2024-07-14 07:39:52,272 [INFO    ] __main__: train step 22118: loss: 0.9453, policy_loss: 0.8814, value_loss: 0.4170
2024-07-14 07:39:52,586 [INFO    ] __main__: train step 22119: loss: 0.9453, policy_loss: 0.8814, value_loss: 0.4170
2024-07-14 07:39:52,895 [INFO    ] __main__: train step 22120: loss: 0.9453, policy_loss: 0.8814, value_loss: 0.4170
2024-07-14 07:39:53,205 [INFO    ] __main__: train step 22121: loss: 0.9453, policy_loss: 0.8814, value_loss: 0.4170
2024-07-14 07:39:53,523 [INFO    ] __main__: train step 22122: loss: 0.9453, policy_loss: 0.8813, value_loss: 0.4169
2024-07-14 07:39:53,831 [INFO    ] __main__: train step 22123: loss: 0.9453, policy_loss: 0.8813, value_loss: 0.4169
2024-07-14 07:39:54,122 [INFO    ] __main__: train step 22124: loss: 0.9453, policy_loss: 0.8813, value_loss: 0.4169
2024-07-14 07:39:54,430 [INFO    ] __main__: train step 22125: loss: 0.9452, policy_loss: 0.8813, value_loss: 0.4169
2024-07-14 07:39:54,733 [INFO    ] __main__: train step 22126: loss: 0.9452, policy_loss: 0.8813, value_loss: 0.4169
2024-07-14 07:39:55,040 [INFO    ] __main__: train step 22127: loss: 0.9452, policy_loss: 0.8813, value_loss: 0.4169
2024-07-14 07:39:55,359 [INFO    ] __main__: train step 22128: loss: 0.9452, policy_loss: 0.8813, value_loss: 0.4168
2024-07-14 07:39:55,654 [INFO    ] __main__: train step 22129: loss: 0.9452, policy_loss: 0.8812, value_loss: 0.4168
2024-07-14 07:39:55,959 [INFO    ] __main__: train step 22130: loss: 0.9452, policy_loss: 0.8812, value_loss: 0.4168
2024-07-14 07:39:57,606 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:39:58,079 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:39:58,146 [INFO    ] __main__: train step 22131: loss: 0.9452, policy_loss: 0.8812, value_loss: 0.4168
2024-07-14 07:39:58,431 [INFO    ] __main__: train step 22132: loss: 0.9451, policy_loss: 0.8812, value_loss: 0.4168
2024-07-14 07:39:58,739 [INFO    ] __main__: train step 22133: loss: 0.9451, policy_loss: 0.8812, value_loss: 0.4168
2024-07-14 07:39:59,030 [INFO    ] __main__: train step 22134: loss: 0.9451, policy_loss: 0.8812, value_loss: 0.4167
2024-07-14 07:39:59,329 [INFO    ] __main__: train step 22135: loss: 0.9451, policy_loss: 0.8812, value_loss: 0.4167
2024-07-14 07:39:59,636 [INFO    ] __main__: train step 22136: loss: 0.9451, policy_loss: 0.8811, value_loss: 0.4167
2024-07-14 07:40:00,008 [INFO    ] __main__: train step 22137: loss: 0.9451, policy_loss: 0.8811, value_loss: 0.4167
2024-07-14 07:40:00,313 [INFO    ] __main__: train step 22138: loss: 0.9451, policy_loss: 0.8811, value_loss: 0.4167
2024-07-14 07:40:00,618 [INFO    ] __main__: train step 22139: loss: 0.9450, policy_loss: 0.8811, value_loss: 0.4167
2024-07-14 07:40:00,954 [INFO    ] __main__: train step 22140: loss: 0.9450, policy_loss: 0.8811, value_loss: 0.4167
2024-07-14 07:40:01,304 [INFO    ] __main__: train step 22141: loss: 0.9450, policy_loss: 0.8811, value_loss: 0.4166
2024-07-14 07:40:01,630 [INFO    ] __main__: train step 22142: loss: 0.9450, policy_loss: 0.8811, value_loss: 0.4166
2024-07-14 07:40:01,996 [INFO    ] __main__: train step 22143: loss: 0.9450, policy_loss: 0.8810, value_loss: 0.4166
2024-07-14 07:40:02,300 [INFO    ] __main__: train step 22144: loss: 0.9450, policy_loss: 0.8810, value_loss: 0.4166
2024-07-14 07:40:02,614 [INFO    ] __main__: train step 22145: loss: 0.9450, policy_loss: 0.8810, value_loss: 0.4166
2024-07-14 07:40:02,916 [INFO    ] __main__: train step 22146: loss: 0.9449, policy_loss: 0.8810, value_loss: 0.4166
2024-07-14 07:40:03,226 [INFO    ] __main__: train step 22147: loss: 0.9449, policy_loss: 0.8810, value_loss: 0.4165
2024-07-14 07:40:04,873 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:40:05,355 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:40:05,430 [INFO    ] __main__: train step 22148: loss: 0.9449, policy_loss: 0.8810, value_loss: 0.4165
2024-07-14 07:40:05,699 [INFO    ] __main__: train step 22149: loss: 0.9449, policy_loss: 0.8810, value_loss: 0.4165
2024-07-14 07:40:05,999 [INFO    ] __main__: train step 22150: loss: 0.9449, policy_loss: 0.8809, value_loss: 0.4165
2024-07-14 07:40:06,312 [INFO    ] __main__: train step 22151: loss: 0.9449, policy_loss: 0.8809, value_loss: 0.4165
2024-07-14 07:40:06,608 [INFO    ] __main__: train step 22152: loss: 0.9449, policy_loss: 0.8809, value_loss: 0.4165
2024-07-14 07:40:06,897 [INFO    ] __main__: train step 22153: loss: 0.9448, policy_loss: 0.8809, value_loss: 0.4164
2024-07-14 07:40:07,197 [INFO    ] __main__: train step 22154: loss: 0.9448, policy_loss: 0.8809, value_loss: 0.4164
2024-07-14 07:40:07,508 [INFO    ] __main__: train step 22155: loss: 0.9448, policy_loss: 0.8809, value_loss: 0.4164
2024-07-14 07:40:07,821 [INFO    ] __main__: train step 22156: loss: 0.9448, policy_loss: 0.8809, value_loss: 0.4164
2024-07-14 07:40:08,141 [INFO    ] __main__: train step 22157: loss: 0.9448, policy_loss: 0.8808, value_loss: 0.4164
2024-07-14 07:40:08,449 [INFO    ] __main__: train step 22158: loss: 0.9448, policy_loss: 0.8808, value_loss: 0.4164
2024-07-14 07:40:08,766 [INFO    ] __main__: train step 22159: loss: 0.9448, policy_loss: 0.8808, value_loss: 0.4164
2024-07-14 07:40:09,067 [INFO    ] __main__: train step 22160: loss: 0.9447, policy_loss: 0.8808, value_loss: 0.4163
2024-07-14 07:40:09,372 [INFO    ] __main__: train step 22161: loss: 0.9447, policy_loss: 0.8808, value_loss: 0.4163
2024-07-14 07:40:09,661 [INFO    ] __main__: train step 22162: loss: 0.9447, policy_loss: 0.8808, value_loss: 0.4163
2024-07-14 07:40:09,942 [INFO    ] __main__: train step 22163: loss: 0.9447, policy_loss: 0.8808, value_loss: 0.4163
2024-07-14 07:40:10,263 [INFO    ] __main__: train step 22164: loss: 0.9447, policy_loss: 0.8807, value_loss: 0.4163
2024-07-14 07:40:11,886 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:40:12,356 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:40:12,426 [INFO    ] __main__: train step 22165: loss: 0.9447, policy_loss: 0.8807, value_loss: 0.4163
2024-07-14 07:40:12,723 [INFO    ] __main__: train step 22166: loss: 0.9447, policy_loss: 0.8807, value_loss: 0.4162
2024-07-14 07:40:13,048 [INFO    ] __main__: train step 22167: loss: 0.9446, policy_loss: 0.8807, value_loss: 0.4162
2024-07-14 07:40:13,337 [INFO    ] __main__: train step 22168: loss: 0.9446, policy_loss: 0.8807, value_loss: 0.4162
2024-07-14 07:40:13,637 [INFO    ] __main__: train step 22169: loss: 0.9446, policy_loss: 0.8807, value_loss: 0.4162
2024-07-14 07:40:13,943 [INFO    ] __main__: train step 22170: loss: 0.9446, policy_loss: 0.8806, value_loss: 0.4162
2024-07-14 07:40:14,241 [INFO    ] __main__: train step 22171: loss: 0.9446, policy_loss: 0.8806, value_loss: 0.4162
2024-07-14 07:40:19,024 [INFO    ] __main__: train step 22172: loss: 0.9446, policy_loss: 0.8806, value_loss: 0.4162
2024-07-14 07:40:19,344 [INFO    ] __main__: train step 22173: loss: 0.9446, policy_loss: 0.8806, value_loss: 0.4161
2024-07-14 07:40:19,654 [INFO    ] __main__: train step 22174: loss: 0.9445, policy_loss: 0.8806, value_loss: 0.4161
2024-07-14 07:40:19,969 [INFO    ] __main__: train step 22175: loss: 0.9445, policy_loss: 0.8806, value_loss: 0.4161
2024-07-14 07:40:20,280 [INFO    ] __main__: train step 22176: loss: 0.9445, policy_loss: 0.8806, value_loss: 0.4161
2024-07-14 07:40:20,592 [INFO    ] __main__: train step 22177: loss: 0.9445, policy_loss: 0.8806, value_loss: 0.4161
2024-07-14 07:40:20,878 [INFO    ] __main__: train step 22178: loss: 0.9445, policy_loss: 0.8805, value_loss: 0.4161
2024-07-14 07:40:21,169 [INFO    ] __main__: train step 22179: loss: 0.9445, policy_loss: 0.8805, value_loss: 0.4160
2024-07-14 07:40:21,463 [INFO    ] __main__: train step 22180: loss: 0.9445, policy_loss: 0.8805, value_loss: 0.4160
2024-07-14 07:40:21,780 [INFO    ] __main__: train step 22181: loss: 0.9444, policy_loss: 0.8805, value_loss: 0.4160
2024-07-14 07:40:23,408 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:40:23,875 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:40:23,955 [INFO    ] __main__: train step 22182: loss: 0.9444, policy_loss: 0.8805, value_loss: 0.4160
2024-07-14 07:40:24,233 [INFO    ] __main__: train step 22183: loss: 0.9444, policy_loss: 0.8805, value_loss: 0.4160
2024-07-14 07:40:24,521 [INFO    ] __main__: train step 22184: loss: 0.9444, policy_loss: 0.8805, value_loss: 0.4160
2024-07-14 07:40:24,832 [INFO    ] __main__: train step 22185: loss: 0.9444, policy_loss: 0.8804, value_loss: 0.4159
2024-07-14 07:40:25,145 [INFO    ] __main__: train step 22186: loss: 0.9444, policy_loss: 0.8804, value_loss: 0.4159
2024-07-14 07:40:25,458 [INFO    ] __main__: train step 22187: loss: 0.9444, policy_loss: 0.8804, value_loss: 0.4159
2024-07-14 07:40:25,772 [INFO    ] __main__: train step 22188: loss: 0.9443, policy_loss: 0.8804, value_loss: 0.4159
2024-07-14 07:40:26,072 [INFO    ] __main__: train step 22189: loss: 0.9443, policy_loss: 0.8804, value_loss: 0.4159
2024-07-14 07:40:26,387 [INFO    ] __main__: train step 22190: loss: 0.9443, policy_loss: 0.8804, value_loss: 0.4159
2024-07-14 07:40:26,715 [INFO    ] __main__: train step 22191: loss: 0.9443, policy_loss: 0.8804, value_loss: 0.4159
2024-07-14 07:40:27,042 [INFO    ] __main__: train step 22192: loss: 0.9443, policy_loss: 0.8803, value_loss: 0.4158
2024-07-14 07:40:27,352 [INFO    ] __main__: train step 22193: loss: 0.9443, policy_loss: 0.8803, value_loss: 0.4158
2024-07-14 07:40:27,636 [INFO    ] __main__: train step 22194: loss: 0.9443, policy_loss: 0.8803, value_loss: 0.4158
2024-07-14 07:40:27,942 [INFO    ] __main__: train step 22195: loss: 0.9442, policy_loss: 0.8803, value_loss: 0.4158
2024-07-14 07:40:28,250 [INFO    ] __main__: train step 22196: loss: 0.9442, policy_loss: 0.8803, value_loss: 0.4158
2024-07-14 07:40:28,545 [INFO    ] __main__: train step 22197: loss: 0.9442, policy_loss: 0.8803, value_loss: 0.4158
2024-07-14 07:40:28,860 [INFO    ] __main__: train step 22198: loss: 0.9442, policy_loss: 0.8803, value_loss: 0.4157
2024-07-14 07:40:30,517 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:40:30,978 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:40:31,050 [INFO    ] __main__: train step 22199: loss: 0.9442, policy_loss: 0.8802, value_loss: 0.4157
2024-07-14 07:40:31,361 [INFO    ] __main__: train step 22200: loss: 0.9442, policy_loss: 0.8802, value_loss: 0.4157
2024-07-14 07:40:31,661 [INFO    ] __main__: train step 22201: loss: 0.9442, policy_loss: 0.8802, value_loss: 0.4157
2024-07-14 07:40:31,993 [INFO    ] __main__: train step 22202: loss: 0.9442, policy_loss: 0.8802, value_loss: 0.4157
2024-07-14 07:40:32,274 [INFO    ] __main__: train step 22203: loss: 0.9441, policy_loss: 0.8802, value_loss: 0.4157
2024-07-14 07:40:32,564 [INFO    ] __main__: train step 22204: loss: 0.9441, policy_loss: 0.8802, value_loss: 0.4157
2024-07-14 07:40:32,849 [INFO    ] __main__: train step 22205: loss: 0.9441, policy_loss: 0.8802, value_loss: 0.4156
2024-07-14 07:40:33,128 [INFO    ] __main__: train step 22206: loss: 0.9441, policy_loss: 0.8801, value_loss: 0.4156
2024-07-14 07:40:33,430 [INFO    ] __main__: train step 22207: loss: 0.9441, policy_loss: 0.8801, value_loss: 0.4156
2024-07-14 07:40:33,738 [INFO    ] __main__: train step 22208: loss: 0.9441, policy_loss: 0.8801, value_loss: 0.4156
2024-07-14 07:40:34,055 [INFO    ] __main__: train step 22209: loss: 0.9441, policy_loss: 0.8801, value_loss: 0.4156
2024-07-14 07:40:34,374 [INFO    ] __main__: train step 22210: loss: 0.9440, policy_loss: 0.8801, value_loss: 0.4156
2024-07-14 07:40:34,672 [INFO    ] __main__: train step 22211: loss: 0.9440, policy_loss: 0.8801, value_loss: 0.4155
2024-07-14 07:40:34,980 [INFO    ] __main__: train step 22212: loss: 0.9440, policy_loss: 0.8800, value_loss: 0.4155
2024-07-14 07:40:35,289 [INFO    ] __main__: train step 22213: loss: 0.9440, policy_loss: 0.8800, value_loss: 0.4155
2024-07-14 07:40:35,622 [INFO    ] __main__: train step 22214: loss: 0.9440, policy_loss: 0.8800, value_loss: 0.4155
2024-07-14 07:40:35,936 [INFO    ] __main__: train step 22215: loss: 0.9440, policy_loss: 0.8800, value_loss: 0.4155
2024-07-14 07:40:37,580 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:40:38,066 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:40:38,143 [INFO    ] __main__: train step 22216: loss: 0.9440, policy_loss: 0.8800, value_loss: 0.4155
2024-07-14 07:40:38,441 [INFO    ] __main__: train step 22217: loss: 0.9439, policy_loss: 0.8800, value_loss: 0.4155
2024-07-14 07:40:38,751 [INFO    ] __main__: train step 22218: loss: 0.9439, policy_loss: 0.8800, value_loss: 0.4154
2024-07-14 07:40:39,053 [INFO    ] __main__: train step 22219: loss: 0.9439, policy_loss: 0.8799, value_loss: 0.4154
2024-07-14 07:40:39,362 [INFO    ] __main__: train step 22220: loss: 0.9439, policy_loss: 0.8799, value_loss: 0.4154
2024-07-14 07:40:39,671 [INFO    ] __main__: train step 22221: loss: 0.9439, policy_loss: 0.8799, value_loss: 0.4154
2024-07-14 07:40:39,976 [INFO    ] __main__: train step 22222: loss: 0.9439, policy_loss: 0.8799, value_loss: 0.4154
2024-07-14 07:40:40,274 [INFO    ] __main__: train step 22223: loss: 0.9439, policy_loss: 0.8799, value_loss: 0.4154
2024-07-14 07:40:40,566 [INFO    ] __main__: train step 22224: loss: 0.9438, policy_loss: 0.8799, value_loss: 0.4153
2024-07-14 07:40:40,871 [INFO    ] __main__: train step 22225: loss: 0.9438, policy_loss: 0.8799, value_loss: 0.4153
2024-07-14 07:40:41,179 [INFO    ] __main__: train step 22226: loss: 0.9438, policy_loss: 0.8798, value_loss: 0.4153
2024-07-14 07:40:41,474 [INFO    ] __main__: train step 22227: loss: 0.9438, policy_loss: 0.8798, value_loss: 0.4153
2024-07-14 07:40:41,780 [INFO    ] __main__: train step 22228: loss: 0.9438, policy_loss: 0.8798, value_loss: 0.4153
2024-07-14 07:40:42,076 [INFO    ] __main__: train step 22229: loss: 0.9438, policy_loss: 0.8798, value_loss: 0.4153
2024-07-14 07:40:42,380 [INFO    ] __main__: train step 22230: loss: 0.9438, policy_loss: 0.8798, value_loss: 0.4152
2024-07-14 07:40:42,707 [INFO    ] __main__: train step 22231: loss: 0.9437, policy_loss: 0.8798, value_loss: 0.4152
2024-07-14 07:40:43,032 [INFO    ] __main__: train step 22232: loss: 0.9437, policy_loss: 0.8798, value_loss: 0.4152
2024-07-14 07:40:44,677 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:40:45,129 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:40:45,197 [INFO    ] __main__: train step 22233: loss: 0.9437, policy_loss: 0.8797, value_loss: 0.4152
2024-07-14 07:40:45,482 [INFO    ] __main__: train step 22234: loss: 0.9437, policy_loss: 0.8797, value_loss: 0.4152
2024-07-14 07:40:45,802 [INFO    ] __main__: train step 22235: loss: 0.9437, policy_loss: 0.8797, value_loss: 0.4152
2024-07-14 07:40:46,116 [INFO    ] __main__: train step 22236: loss: 0.9437, policy_loss: 0.8797, value_loss: 0.4152
2024-07-14 07:40:46,412 [INFO    ] __main__: train step 22237: loss: 0.9437, policy_loss: 0.8797, value_loss: 0.4151
2024-07-14 07:40:46,717 [INFO    ] __main__: train step 22238: loss: 0.9436, policy_loss: 0.8797, value_loss: 0.4151
2024-07-14 07:40:47,017 [INFO    ] __main__: train step 22239: loss: 0.9436, policy_loss: 0.8797, value_loss: 0.4151
2024-07-14 07:40:47,318 [INFO    ] __main__: train step 22240: loss: 0.9436, policy_loss: 0.8796, value_loss: 0.4151
2024-07-14 07:40:47,635 [INFO    ] __main__: train step 22241: loss: 0.9436, policy_loss: 0.8796, value_loss: 0.4151
2024-07-14 07:40:47,948 [INFO    ] __main__: train step 22242: loss: 0.9436, policy_loss: 0.8796, value_loss: 0.4151
2024-07-14 07:40:48,258 [INFO    ] __main__: train step 22243: loss: 0.9436, policy_loss: 0.8796, value_loss: 0.4150
2024-07-14 07:40:48,562 [INFO    ] __main__: train step 22244: loss: 0.9436, policy_loss: 0.8796, value_loss: 0.4150
2024-07-14 07:40:48,870 [INFO    ] __main__: train step 22245: loss: 0.9436, policy_loss: 0.8796, value_loss: 0.4150
2024-07-14 07:40:49,176 [INFO    ] __main__: train step 22246: loss: 0.9435, policy_loss: 0.8796, value_loss: 0.4150
2024-07-14 07:40:49,477 [INFO    ] __main__: train step 22247: loss: 0.9435, policy_loss: 0.8795, value_loss: 0.4150
2024-07-14 07:40:49,761 [INFO    ] __main__: train step 22248: loss: 0.9435, policy_loss: 0.8795, value_loss: 0.4150
2024-07-14 07:40:50,068 [INFO    ] __main__: train step 22249: loss: 0.9435, policy_loss: 0.8795, value_loss: 0.4150
2024-07-14 07:40:51,718 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:40:52,201 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:40:52,277 [INFO    ] __main__: train step 22250: loss: 0.9435, policy_loss: 0.8795, value_loss: 0.4149
2024-07-14 07:40:52,578 [INFO    ] __main__: train step 22251: loss: 0.9435, policy_loss: 0.8795, value_loss: 0.4149
2024-07-14 07:40:52,873 [INFO    ] __main__: train step 22252: loss: 0.9435, policy_loss: 0.8795, value_loss: 0.4149
2024-07-14 07:40:53,164 [INFO    ] __main__: train step 22253: loss: 0.9434, policy_loss: 0.8795, value_loss: 0.4149
2024-07-14 07:40:53,485 [INFO    ] __main__: train step 22254: loss: 0.9434, policy_loss: 0.8794, value_loss: 0.4149
2024-07-14 07:40:53,783 [INFO    ] __main__: train step 22255: loss: 0.9434, policy_loss: 0.8794, value_loss: 0.4149
2024-07-14 07:40:54,089 [INFO    ] __main__: train step 22256: loss: 0.9434, policy_loss: 0.8794, value_loss: 0.4148
2024-07-14 07:40:54,389 [INFO    ] __main__: train step 22257: loss: 0.9434, policy_loss: 0.8794, value_loss: 0.4148
2024-07-14 07:40:54,661 [INFO    ] __main__: train step 22258: loss: 0.9434, policy_loss: 0.8794, value_loss: 0.4148
2024-07-14 07:40:54,965 [INFO    ] __main__: train step 22259: loss: 0.9434, policy_loss: 0.8794, value_loss: 0.4148
2024-07-14 07:40:55,271 [INFO    ] __main__: train step 22260: loss: 0.9433, policy_loss: 0.8794, value_loss: 0.4148
2024-07-14 07:40:55,586 [INFO    ] __main__: train step 22261: loss: 0.9433, policy_loss: 0.8793, value_loss: 0.4148
2024-07-14 07:40:55,869 [INFO    ] __main__: train step 22262: loss: 0.9433, policy_loss: 0.8793, value_loss: 0.4148
2024-07-14 07:40:56,150 [INFO    ] __main__: train step 22263: loss: 0.9433, policy_loss: 0.8793, value_loss: 0.4147
2024-07-14 07:40:56,428 [INFO    ] __main__: train step 22264: loss: 0.9433, policy_loss: 0.8793, value_loss: 0.4147
2024-07-14 07:40:56,729 [INFO    ] __main__: train step 22265: loss: 0.9433, policy_loss: 0.8793, value_loss: 0.4147
2024-07-14 07:40:57,044 [INFO    ] __main__: train step 22266: loss: 0.9433, policy_loss: 0.8793, value_loss: 0.4147
2024-07-14 07:40:58,670 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:40:59,148 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:40:59,225 [INFO    ] __main__: train step 22267: loss: 0.9432, policy_loss: 0.8793, value_loss: 0.4147
2024-07-14 07:40:59,523 [INFO    ] __main__: train step 22268: loss: 0.9432, policy_loss: 0.8792, value_loss: 0.4147
2024-07-14 07:40:59,821 [INFO    ] __main__: train step 22269: loss: 0.9432, policy_loss: 0.8792, value_loss: 0.4147
2024-07-14 07:41:00,118 [INFO    ] __main__: train step 22270: loss: 0.9432, policy_loss: 0.8792, value_loss: 0.4146
2024-07-14 07:41:00,418 [INFO    ] __main__: train step 22271: loss: 0.9432, policy_loss: 0.8792, value_loss: 0.4146
2024-07-14 07:41:00,720 [INFO    ] __main__: train step 22272: loss: 0.9432, policy_loss: 0.8792, value_loss: 0.4146
2024-07-14 07:41:01,039 [INFO    ] __main__: train step 22273: loss: 0.9432, policy_loss: 0.8792, value_loss: 0.4146
2024-07-14 07:41:01,348 [INFO    ] __main__: train step 22274: loss: 0.9431, policy_loss: 0.8792, value_loss: 0.4146
2024-07-14 07:41:01,665 [INFO    ] __main__: train step 22275: loss: 0.9431, policy_loss: 0.8791, value_loss: 0.4146
2024-07-14 07:41:01,988 [INFO    ] __main__: train step 22276: loss: 0.9431, policy_loss: 0.8791, value_loss: 0.4145
2024-07-14 07:41:02,307 [INFO    ] __main__: train step 22277: loss: 0.9431, policy_loss: 0.8791, value_loss: 0.4145
2024-07-14 07:41:02,614 [INFO    ] __main__: train step 22278: loss: 0.9431, policy_loss: 0.8791, value_loss: 0.4145
2024-07-14 07:41:02,940 [INFO    ] __main__: train step 22279: loss: 0.9431, policy_loss: 0.8791, value_loss: 0.4145
2024-07-14 07:41:03,269 [INFO    ] __main__: train step 22280: loss: 0.9431, policy_loss: 0.8791, value_loss: 0.4145
2024-07-14 07:41:03,591 [INFO    ] __main__: train step 22281: loss: 0.9430, policy_loss: 0.8791, value_loss: 0.4145
2024-07-14 07:41:03,893 [INFO    ] __main__: train step 22282: loss: 0.9430, policy_loss: 0.8790, value_loss: 0.4144
2024-07-14 07:41:04,192 [INFO    ] __main__: train step 22283: loss: 0.9430, policy_loss: 0.8790, value_loss: 0.4144
2024-07-14 07:41:05,827 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:41:06,283 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:41:06,351 [INFO    ] __main__: train step 22284: loss: 0.9430, policy_loss: 0.8790, value_loss: 0.4144
2024-07-14 07:41:06,676 [INFO    ] __main__: train step 22285: loss: 0.9430, policy_loss: 0.8790, value_loss: 0.4144
2024-07-14 07:41:06,973 [INFO    ] __main__: train step 22286: loss: 0.9430, policy_loss: 0.8790, value_loss: 0.4144
2024-07-14 07:41:07,299 [INFO    ] __main__: train step 22287: loss: 0.9430, policy_loss: 0.8790, value_loss: 0.4144
2024-07-14 07:41:07,613 [INFO    ] __main__: train step 22288: loss: 0.9429, policy_loss: 0.8790, value_loss: 0.4144
2024-07-14 07:41:07,946 [INFO    ] __main__: train step 22289: loss: 0.9429, policy_loss: 0.8789, value_loss: 0.4143
2024-07-14 07:41:08,274 [INFO    ] __main__: train step 22290: loss: 0.9429, policy_loss: 0.8789, value_loss: 0.4143
2024-07-14 07:41:08,592 [INFO    ] __main__: train step 22291: loss: 0.9429, policy_loss: 0.8789, value_loss: 0.4143
2024-07-14 07:41:08,910 [INFO    ] __main__: train step 22292: loss: 0.9429, policy_loss: 0.8789, value_loss: 0.4143
2024-07-14 07:41:09,221 [INFO    ] __main__: train step 22293: loss: 0.9429, policy_loss: 0.8789, value_loss: 0.4143
2024-07-14 07:41:09,539 [INFO    ] __main__: train step 22294: loss: 0.9429, policy_loss: 0.8789, value_loss: 0.4143
2024-07-14 07:41:09,872 [INFO    ] __main__: train step 22295: loss: 0.9429, policy_loss: 0.8789, value_loss: 0.4142
2024-07-14 07:41:10,222 [INFO    ] __main__: train step 22296: loss: 0.9428, policy_loss: 0.8789, value_loss: 0.4142
2024-07-14 07:41:10,524 [INFO    ] __main__: train step 22297: loss: 0.9428, policy_loss: 0.8788, value_loss: 0.4142
2024-07-14 07:41:10,859 [INFO    ] __main__: train step 22298: loss: 0.9428, policy_loss: 0.8788, value_loss: 0.4142
2024-07-14 07:41:11,174 [INFO    ] __main__: train step 22299: loss: 0.9428, policy_loss: 0.8788, value_loss: 0.4142
2024-07-14 07:41:11,491 [INFO    ] __main__: train step 22300: loss: 0.9428, policy_loss: 0.8788, value_loss: 0.4142
2024-07-14 07:41:13,121 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:41:13,569 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:41:13,636 [INFO    ] __main__: train step 22301: loss: 0.9428, policy_loss: 0.8788, value_loss: 0.4142
2024-07-14 07:41:18,876 [INFO    ] __main__: train step 22302: loss: 0.9428, policy_loss: 0.8788, value_loss: 0.4141
2024-07-14 07:41:19,172 [INFO    ] __main__: train step 22303: loss: 0.9427, policy_loss: 0.8788, value_loss: 0.4141
2024-07-14 07:41:19,459 [INFO    ] __main__: train step 22304: loss: 0.9427, policy_loss: 0.8787, value_loss: 0.4141
2024-07-14 07:41:19,736 [INFO    ] __main__: train step 22305: loss: 0.9427, policy_loss: 0.8787, value_loss: 0.4141
2024-07-14 07:41:20,008 [INFO    ] __main__: train step 22306: loss: 0.9427, policy_loss: 0.8787, value_loss: 0.4141
2024-07-14 07:41:20,293 [INFO    ] __main__: train step 22307: loss: 0.9427, policy_loss: 0.8787, value_loss: 0.4141
2024-07-14 07:41:20,569 [INFO    ] __main__: train step 22308: loss: 0.9427, policy_loss: 0.8787, value_loss: 0.4140
2024-07-14 07:41:20,867 [INFO    ] __main__: train step 22309: loss: 0.9427, policy_loss: 0.8787, value_loss: 0.4140
2024-07-14 07:41:21,142 [INFO    ] __main__: train step 22310: loss: 0.9426, policy_loss: 0.8787, value_loss: 0.4140
2024-07-14 07:41:21,426 [INFO    ] __main__: train step 22311: loss: 0.9426, policy_loss: 0.8786, value_loss: 0.4140
2024-07-14 07:41:21,728 [INFO    ] __main__: train step 22312: loss: 0.9426, policy_loss: 0.8786, value_loss: 0.4140
2024-07-14 07:41:22,032 [INFO    ] __main__: train step 22313: loss: 0.9426, policy_loss: 0.8786, value_loss: 0.4140
2024-07-14 07:41:22,332 [INFO    ] __main__: train step 22314: loss: 0.9426, policy_loss: 0.8786, value_loss: 0.4140
2024-07-14 07:41:22,630 [INFO    ] __main__: train step 22315: loss: 0.9426, policy_loss: 0.8786, value_loss: 0.4139
2024-07-14 07:41:22,938 [INFO    ] __main__: train step 22316: loss: 0.9426, policy_loss: 0.8786, value_loss: 0.4139
2024-07-14 07:41:23,224 [INFO    ] __main__: train step 22317: loss: 0.9425, policy_loss: 0.8786, value_loss: 0.4139
2024-07-14 07:41:24,825 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:41:25,307 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:41:25,377 [INFO    ] __main__: train step 22318: loss: 0.9425, policy_loss: 0.8785, value_loss: 0.4139
2024-07-14 07:41:25,672 [INFO    ] __main__: train step 22319: loss: 0.9425, policy_loss: 0.8785, value_loss: 0.4139
2024-07-14 07:41:25,948 [INFO    ] __main__: train step 22320: loss: 0.9425, policy_loss: 0.8785, value_loss: 0.4139
2024-07-14 07:41:26,231 [INFO    ] __main__: train step 22321: loss: 0.9425, policy_loss: 0.8785, value_loss: 0.4138
2024-07-14 07:41:26,533 [INFO    ] __main__: train step 22322: loss: 0.9425, policy_loss: 0.8785, value_loss: 0.4138
2024-07-14 07:41:26,830 [INFO    ] __main__: train step 22323: loss: 0.9425, policy_loss: 0.8785, value_loss: 0.4138
2024-07-14 07:41:27,132 [INFO    ] __main__: train step 22324: loss: 0.9425, policy_loss: 0.8785, value_loss: 0.4138
2024-07-14 07:41:27,426 [INFO    ] __main__: train step 22325: loss: 0.9424, policy_loss: 0.8784, value_loss: 0.4138
2024-07-14 07:41:27,720 [INFO    ] __main__: train step 22326: loss: 0.9424, policy_loss: 0.8784, value_loss: 0.4138
2024-07-14 07:41:28,020 [INFO    ] __main__: train step 22327: loss: 0.9424, policy_loss: 0.8784, value_loss: 0.4138
2024-07-14 07:41:28,318 [INFO    ] __main__: train step 22328: loss: 0.9424, policy_loss: 0.8784, value_loss: 0.4137
2024-07-14 07:41:28,629 [INFO    ] __main__: train step 22329: loss: 0.9424, policy_loss: 0.8784, value_loss: 0.4137
2024-07-14 07:41:28,925 [INFO    ] __main__: train step 22330: loss: 0.9424, policy_loss: 0.8784, value_loss: 0.4137
2024-07-14 07:41:29,228 [INFO    ] __main__: train step 22331: loss: 0.9424, policy_loss: 0.8784, value_loss: 0.4137
2024-07-14 07:41:29,533 [INFO    ] __main__: train step 22332: loss: 0.9423, policy_loss: 0.8783, value_loss: 0.4137
2024-07-14 07:41:29,835 [INFO    ] __main__: train step 22333: loss: 0.9423, policy_loss: 0.8783, value_loss: 0.4137
2024-07-14 07:41:30,135 [INFO    ] __main__: train step 22334: loss: 0.9423, policy_loss: 0.8783, value_loss: 0.4136
2024-07-14 07:41:31,751 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:41:32,230 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:41:32,297 [INFO    ] __main__: train step 22335: loss: 0.9423, policy_loss: 0.8783, value_loss: 0.4136
2024-07-14 07:41:32,566 [INFO    ] __main__: train step 22336: loss: 0.9423, policy_loss: 0.8783, value_loss: 0.4136
2024-07-14 07:41:32,862 [INFO    ] __main__: train step 22337: loss: 0.9423, policy_loss: 0.8783, value_loss: 0.4136
2024-07-14 07:41:33,151 [INFO    ] __main__: train step 22338: loss: 0.9423, policy_loss: 0.8783, value_loss: 0.4136
2024-07-14 07:41:33,450 [INFO    ] __main__: train step 22339: loss: 0.9422, policy_loss: 0.8782, value_loss: 0.4136
2024-07-14 07:41:33,754 [INFO    ] __main__: train step 22340: loss: 0.9422, policy_loss: 0.8782, value_loss: 0.4136
2024-07-14 07:41:34,044 [INFO    ] __main__: train step 22341: loss: 0.9422, policy_loss: 0.8782, value_loss: 0.4135
2024-07-14 07:41:34,315 [INFO    ] __main__: train step 22342: loss: 0.9422, policy_loss: 0.8782, value_loss: 0.4135
2024-07-14 07:41:34,588 [INFO    ] __main__: train step 22343: loss: 0.9422, policy_loss: 0.8782, value_loss: 0.4135
2024-07-14 07:41:34,888 [INFO    ] __main__: train step 22344: loss: 0.9422, policy_loss: 0.8782, value_loss: 0.4135
2024-07-14 07:41:35,182 [INFO    ] __main__: train step 22345: loss: 0.9422, policy_loss: 0.8782, value_loss: 0.4135
2024-07-14 07:41:35,481 [INFO    ] __main__: train step 22346: loss: 0.9422, policy_loss: 0.8782, value_loss: 0.4135
2024-07-14 07:41:35,769 [INFO    ] __main__: train step 22347: loss: 0.9421, policy_loss: 0.8781, value_loss: 0.4134
2024-07-14 07:41:36,066 [INFO    ] __main__: train step 22348: loss: 0.9421, policy_loss: 0.8781, value_loss: 0.4134
2024-07-14 07:41:36,379 [INFO    ] __main__: train step 22349: loss: 0.9421, policy_loss: 0.8781, value_loss: 0.4134
2024-07-14 07:41:36,683 [INFO    ] __main__: train step 22350: loss: 0.9421, policy_loss: 0.8781, value_loss: 0.4134
2024-07-14 07:41:36,995 [INFO    ] __main__: train step 22351: loss: 0.9421, policy_loss: 0.8781, value_loss: 0.4134
2024-07-14 07:41:38,630 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:41:39,106 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:41:39,175 [INFO    ] __main__: train step 22352: loss: 0.9421, policy_loss: 0.8781, value_loss: 0.4134
2024-07-14 07:41:39,457 [INFO    ] __main__: train step 22353: loss: 0.9421, policy_loss: 0.8781, value_loss: 0.4134
2024-07-14 07:41:39,761 [INFO    ] __main__: train step 22354: loss: 0.9420, policy_loss: 0.8780, value_loss: 0.4133
2024-07-14 07:41:40,057 [INFO    ] __main__: train step 22355: loss: 0.9420, policy_loss: 0.8780, value_loss: 0.4133
2024-07-14 07:41:40,360 [INFO    ] __main__: train step 22356: loss: 0.9420, policy_loss: 0.8780, value_loss: 0.4133
2024-07-14 07:41:40,632 [INFO    ] __main__: train step 22357: loss: 0.9420, policy_loss: 0.8780, value_loss: 0.4133
2024-07-14 07:41:40,911 [INFO    ] __main__: train step 22358: loss: 0.9420, policy_loss: 0.8780, value_loss: 0.4133
2024-07-14 07:41:41,202 [INFO    ] __main__: train step 22359: loss: 0.9420, policy_loss: 0.8780, value_loss: 0.4133
2024-07-14 07:41:41,512 [INFO    ] __main__: train step 22360: loss: 0.9420, policy_loss: 0.8780, value_loss: 0.4132
2024-07-14 07:41:41,804 [INFO    ] __main__: train step 22361: loss: 0.9419, policy_loss: 0.8779, value_loss: 0.4132
2024-07-14 07:41:42,107 [INFO    ] __main__: train step 22362: loss: 0.9419, policy_loss: 0.8779, value_loss: 0.4132
2024-07-14 07:41:42,420 [INFO    ] __main__: train step 22363: loss: 0.9419, policy_loss: 0.8779, value_loss: 0.4132
2024-07-14 07:41:42,718 [INFO    ] __main__: train step 22364: loss: 0.9419, policy_loss: 0.8779, value_loss: 0.4132
2024-07-14 07:41:43,026 [INFO    ] __main__: train step 22365: loss: 0.9419, policy_loss: 0.8779, value_loss: 0.4132
2024-07-14 07:41:43,331 [INFO    ] __main__: train step 22366: loss: 0.9419, policy_loss: 0.8779, value_loss: 0.4132
2024-07-14 07:41:43,636 [INFO    ] __main__: train step 22367: loss: 0.9419, policy_loss: 0.8779, value_loss: 0.4131
2024-07-14 07:41:43,936 [INFO    ] __main__: train step 22368: loss: 0.9419, policy_loss: 0.8778, value_loss: 0.4131
2024-07-14 07:41:45,591 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:41:46,066 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:41:46,146 [INFO    ] __main__: train step 22369: loss: 0.9418, policy_loss: 0.8778, value_loss: 0.4131
2024-07-14 07:41:46,460 [INFO    ] __main__: train step 22370: loss: 0.9418, policy_loss: 0.8778, value_loss: 0.4131
2024-07-14 07:41:46,774 [INFO    ] __main__: train step 22371: loss: 0.9418, policy_loss: 0.8778, value_loss: 0.4131
2024-07-14 07:41:47,063 [INFO    ] __main__: train step 22372: loss: 0.9418, policy_loss: 0.8778, value_loss: 0.4131
2024-07-14 07:41:47,377 [INFO    ] __main__: train step 22373: loss: 0.9418, policy_loss: 0.8778, value_loss: 0.4130
2024-07-14 07:41:47,685 [INFO    ] __main__: train step 22374: loss: 0.9418, policy_loss: 0.8778, value_loss: 0.4130
2024-07-14 07:41:47,980 [INFO    ] __main__: train step 22375: loss: 0.9418, policy_loss: 0.8777, value_loss: 0.4130
2024-07-14 07:41:48,279 [INFO    ] __main__: train step 22376: loss: 0.9417, policy_loss: 0.8777, value_loss: 0.4130
2024-07-14 07:41:48,584 [INFO    ] __main__: train step 22377: loss: 0.9417, policy_loss: 0.8777, value_loss: 0.4130
2024-07-14 07:41:48,885 [INFO    ] __main__: train step 22378: loss: 0.9417, policy_loss: 0.8777, value_loss: 0.4130
2024-07-14 07:41:49,200 [INFO    ] __main__: train step 22379: loss: 0.9417, policy_loss: 0.8777, value_loss: 0.4130
2024-07-14 07:41:49,498 [INFO    ] __main__: train step 22380: loss: 0.9417, policy_loss: 0.8777, value_loss: 0.4129
2024-07-14 07:41:49,815 [INFO    ] __main__: train step 22381: loss: 0.9417, policy_loss: 0.8777, value_loss: 0.4129
2024-07-14 07:41:50,126 [INFO    ] __main__: train step 22382: loss: 0.9417, policy_loss: 0.8776, value_loss: 0.4129
2024-07-14 07:41:50,430 [INFO    ] __main__: train step 22383: loss: 0.9416, policy_loss: 0.8776, value_loss: 0.4129
2024-07-14 07:41:50,730 [INFO    ] __main__: train step 22384: loss: 0.9416, policy_loss: 0.8776, value_loss: 0.4129
2024-07-14 07:41:51,040 [INFO    ] __main__: train step 22385: loss: 0.9416, policy_loss: 0.8776, value_loss: 0.4129
2024-07-14 07:41:52,665 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:41:53,149 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:41:53,223 [INFO    ] __main__: train step 22386: loss: 0.9416, policy_loss: 0.8776, value_loss: 0.4129
2024-07-14 07:41:53,524 [INFO    ] __main__: train step 22387: loss: 0.9416, policy_loss: 0.8776, value_loss: 0.4128
2024-07-14 07:41:53,832 [INFO    ] __main__: train step 22388: loss: 0.9416, policy_loss: 0.8776, value_loss: 0.4128
2024-07-14 07:41:54,142 [INFO    ] __main__: train step 22389: loss: 0.9416, policy_loss: 0.8775, value_loss: 0.4128
2024-07-14 07:41:54,452 [INFO    ] __main__: train step 22390: loss: 0.9416, policy_loss: 0.8775, value_loss: 0.4128
2024-07-14 07:41:54,759 [INFO    ] __main__: train step 22391: loss: 0.9415, policy_loss: 0.8775, value_loss: 0.4128
2024-07-14 07:41:55,060 [INFO    ] __main__: train step 22392: loss: 0.9415, policy_loss: 0.8775, value_loss: 0.4128
2024-07-14 07:41:55,338 [INFO    ] __main__: train step 22393: loss: 0.9415, policy_loss: 0.8775, value_loss: 0.4127
2024-07-14 07:41:55,633 [INFO    ] __main__: train step 22394: loss: 0.9415, policy_loss: 0.8775, value_loss: 0.4127
2024-07-14 07:41:55,938 [INFO    ] __main__: train step 22395: loss: 0.9415, policy_loss: 0.8775, value_loss: 0.4127
2024-07-14 07:41:56,218 [INFO    ] __main__: train step 22396: loss: 0.9415, policy_loss: 0.8775, value_loss: 0.4127
2024-07-14 07:41:56,515 [INFO    ] __main__: train step 22397: loss: 0.9415, policy_loss: 0.8774, value_loss: 0.4127
2024-07-14 07:41:56,856 [INFO    ] __main__: train step 22398: loss: 0.9414, policy_loss: 0.8774, value_loss: 0.4127
2024-07-14 07:41:57,175 [INFO    ] __main__: train step 22399: loss: 0.9414, policy_loss: 0.8774, value_loss: 0.4127
2024-07-14 07:41:57,477 [INFO    ] __main__: train step 22400: loss: 0.9414, policy_loss: 0.8774, value_loss: 0.4126
2024-07-14 07:41:57,792 [INFO    ] __main__: train step 22401: loss: 0.9414, policy_loss: 0.8774, value_loss: 0.4126
2024-07-14 07:41:58,092 [INFO    ] __main__: train step 22402: loss: 0.9414, policy_loss: 0.8774, value_loss: 0.4126
2024-07-14 07:41:59,722 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:42:00,178 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:42:00,247 [INFO    ] __main__: train step 22403: loss: 0.9414, policy_loss: 0.8774, value_loss: 0.4126
2024-07-14 07:42:00,543 [INFO    ] __main__: train step 22404: loss: 0.9414, policy_loss: 0.8773, value_loss: 0.4126
2024-07-14 07:42:00,828 [INFO    ] __main__: train step 22405: loss: 0.9414, policy_loss: 0.8773, value_loss: 0.4126
2024-07-14 07:42:01,140 [INFO    ] __main__: train step 22406: loss: 0.9413, policy_loss: 0.8773, value_loss: 0.4125
2024-07-14 07:42:01,458 [INFO    ] __main__: train step 22407: loss: 0.9413, policy_loss: 0.8773, value_loss: 0.4125
2024-07-14 07:42:01,777 [INFO    ] __main__: train step 22408: loss: 0.9413, policy_loss: 0.8773, value_loss: 0.4125
2024-07-14 07:42:02,086 [INFO    ] __main__: train step 22409: loss: 0.9413, policy_loss: 0.8773, value_loss: 0.4125
2024-07-14 07:42:02,393 [INFO    ] __main__: train step 22410: loss: 0.9413, policy_loss: 0.8773, value_loss: 0.4125
2024-07-14 07:42:02,711 [INFO    ] __main__: train step 22411: loss: 0.9413, policy_loss: 0.8772, value_loss: 0.4125
2024-07-14 07:42:03,030 [INFO    ] __main__: train step 22412: loss: 0.9413, policy_loss: 0.8772, value_loss: 0.4125
2024-07-14 07:42:03,360 [INFO    ] __main__: train step 22413: loss: 0.9412, policy_loss: 0.8772, value_loss: 0.4124
2024-07-14 07:42:03,654 [INFO    ] __main__: train step 22414: loss: 0.9412, policy_loss: 0.8772, value_loss: 0.4124
2024-07-14 07:42:03,969 [INFO    ] __main__: train step 22415: loss: 0.9412, policy_loss: 0.8772, value_loss: 0.4124
2024-07-14 07:42:04,291 [INFO    ] __main__: train step 22416: loss: 0.9412, policy_loss: 0.8772, value_loss: 0.4124
2024-07-14 07:42:04,640 [INFO    ] __main__: train step 22417: loss: 0.9412, policy_loss: 0.8772, value_loss: 0.4124
2024-07-14 07:42:04,974 [INFO    ] __main__: train step 22418: loss: 0.9412, policy_loss: 0.8772, value_loss: 0.4124
2024-07-14 07:42:05,279 [INFO    ] __main__: train step 22419: loss: 0.9412, policy_loss: 0.8771, value_loss: 0.4124
2024-07-14 07:42:06,881 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:42:07,338 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:42:07,414 [INFO    ] __main__: train step 22420: loss: 0.9412, policy_loss: 0.8771, value_loss: 0.4123
2024-07-14 07:42:07,741 [INFO    ] __main__: train step 22421: loss: 0.9411, policy_loss: 0.8771, value_loss: 0.4123
2024-07-14 07:42:08,058 [INFO    ] __main__: train step 22422: loss: 0.9411, policy_loss: 0.8771, value_loss: 0.4123
2024-07-14 07:42:08,390 [INFO    ] __main__: train step 22423: loss: 0.9411, policy_loss: 0.8771, value_loss: 0.4123
2024-07-14 07:42:08,673 [INFO    ] __main__: train step 22424: loss: 0.9411, policy_loss: 0.8771, value_loss: 0.4123
2024-07-14 07:42:08,991 [INFO    ] __main__: train step 22425: loss: 0.9411, policy_loss: 0.8771, value_loss: 0.4123
2024-07-14 07:42:09,315 [INFO    ] __main__: train step 22426: loss: 0.9411, policy_loss: 0.8770, value_loss: 0.4122
2024-07-14 07:42:09,630 [INFO    ] __main__: train step 22427: loss: 0.9411, policy_loss: 0.8770, value_loss: 0.4122
2024-07-14 07:42:09,929 [INFO    ] __main__: train step 22428: loss: 0.9410, policy_loss: 0.8770, value_loss: 0.4122
2024-07-14 07:42:15,654 [INFO    ] __main__: train step 22429: loss: 0.9410, policy_loss: 0.8770, value_loss: 0.4122
2024-07-14 07:42:16,022 [INFO    ] __main__: train step 22430: loss: 0.9410, policy_loss: 0.8770, value_loss: 0.4122
2024-07-14 07:42:16,334 [INFO    ] __main__: train step 22431: loss: 0.9410, policy_loss: 0.8770, value_loss: 0.4122
2024-07-14 07:42:16,625 [INFO    ] __main__: train step 22432: loss: 0.9410, policy_loss: 0.8770, value_loss: 0.4122
2024-07-14 07:42:16,932 [INFO    ] __main__: train step 22433: loss: 0.9410, policy_loss: 0.8769, value_loss: 0.4121
2024-07-14 07:42:17,242 [INFO    ] __main__: train step 22434: loss: 0.9410, policy_loss: 0.8769, value_loss: 0.4121
2024-07-14 07:42:17,612 [INFO    ] __main__: train step 22435: loss: 0.9410, policy_loss: 0.8769, value_loss: 0.4121
2024-07-14 07:42:17,883 [INFO    ] __main__: train step 22436: loss: 0.9409, policy_loss: 0.8769, value_loss: 0.4121
2024-07-14 07:42:19,499 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:42:20,004 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:42:20,074 [INFO    ] __main__: train step 22437: loss: 0.9409, policy_loss: 0.8769, value_loss: 0.4121
2024-07-14 07:42:20,371 [INFO    ] __main__: train step 22438: loss: 0.9409, policy_loss: 0.8769, value_loss: 0.4121
2024-07-14 07:42:20,672 [INFO    ] __main__: train step 22439: loss: 0.9409, policy_loss: 0.8769, value_loss: 0.4120
2024-07-14 07:42:20,958 [INFO    ] __main__: train step 22440: loss: 0.9409, policy_loss: 0.8769, value_loss: 0.4120
2024-07-14 07:42:21,244 [INFO    ] __main__: train step 22441: loss: 0.9409, policy_loss: 0.8768, value_loss: 0.4120
2024-07-14 07:42:21,552 [INFO    ] __main__: train step 22442: loss: 0.9409, policy_loss: 0.8768, value_loss: 0.4120
2024-07-14 07:42:21,859 [INFO    ] __main__: train step 22443: loss: 0.9408, policy_loss: 0.8768, value_loss: 0.4120
2024-07-14 07:42:22,155 [INFO    ] __main__: train step 22444: loss: 0.9408, policy_loss: 0.8768, value_loss: 0.4120
2024-07-14 07:42:22,450 [INFO    ] __main__: train step 22445: loss: 0.9408, policy_loss: 0.8768, value_loss: 0.4120
2024-07-14 07:42:22,745 [INFO    ] __main__: train step 22446: loss: 0.9408, policy_loss: 0.8768, value_loss: 0.4119
2024-07-14 07:42:23,053 [INFO    ] __main__: train step 22447: loss: 0.9408, policy_loss: 0.8768, value_loss: 0.4119
2024-07-14 07:42:23,358 [INFO    ] __main__: train step 22448: loss: 0.9408, policy_loss: 0.8767, value_loss: 0.4119
2024-07-14 07:42:23,650 [INFO    ] __main__: train step 22449: loss: 0.9408, policy_loss: 0.8767, value_loss: 0.4119
2024-07-14 07:42:23,945 [INFO    ] __main__: train step 22450: loss: 0.9408, policy_loss: 0.8767, value_loss: 0.4119
2024-07-14 07:42:24,259 [INFO    ] __main__: train step 22451: loss: 0.9407, policy_loss: 0.8767, value_loss: 0.4119
2024-07-14 07:42:24,539 [INFO    ] __main__: train step 22452: loss: 0.9407, policy_loss: 0.8767, value_loss: 0.4119
2024-07-14 07:42:24,843 [INFO    ] __main__: train step 22453: loss: 0.9407, policy_loss: 0.8767, value_loss: 0.4118
2024-07-14 07:42:26,492 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:42:26,968 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:42:27,039 [INFO    ] __main__: train step 22454: loss: 0.9407, policy_loss: 0.8767, value_loss: 0.4118
2024-07-14 07:42:27,343 [INFO    ] __main__: train step 22455: loss: 0.9407, policy_loss: 0.8766, value_loss: 0.4118
2024-07-14 07:42:27,630 [INFO    ] __main__: train step 22456: loss: 0.9407, policy_loss: 0.8766, value_loss: 0.4118
2024-07-14 07:42:27,920 [INFO    ] __main__: train step 22457: loss: 0.9407, policy_loss: 0.8766, value_loss: 0.4118
2024-07-14 07:42:28,213 [INFO    ] __main__: train step 22458: loss: 0.9407, policy_loss: 0.8766, value_loss: 0.4118
2024-07-14 07:42:28,522 [INFO    ] __main__: train step 22459: loss: 0.9406, policy_loss: 0.8766, value_loss: 0.4117
2024-07-14 07:42:28,825 [INFO    ] __main__: train step 22460: loss: 0.9406, policy_loss: 0.8766, value_loss: 0.4117
2024-07-14 07:42:29,122 [INFO    ] __main__: train step 22461: loss: 0.9406, policy_loss: 0.8766, value_loss: 0.4117
2024-07-14 07:42:29,410 [INFO    ] __main__: train step 22462: loss: 0.9406, policy_loss: 0.8766, value_loss: 0.4117
2024-07-14 07:42:29,708 [INFO    ] __main__: train step 22463: loss: 0.9406, policy_loss: 0.8765, value_loss: 0.4117
2024-07-14 07:42:30,022 [INFO    ] __main__: train step 22464: loss: 0.9406, policy_loss: 0.8765, value_loss: 0.4117
2024-07-14 07:42:30,331 [INFO    ] __main__: train step 22465: loss: 0.9406, policy_loss: 0.8765, value_loss: 0.4117
2024-07-14 07:42:30,627 [INFO    ] __main__: train step 22466: loss: 0.9405, policy_loss: 0.8765, value_loss: 0.4116
2024-07-14 07:42:30,923 [INFO    ] __main__: train step 22467: loss: 0.9405, policy_loss: 0.8765, value_loss: 0.4116
2024-07-14 07:42:31,217 [INFO    ] __main__: train step 22468: loss: 0.9405, policy_loss: 0.8765, value_loss: 0.4116
2024-07-14 07:42:31,520 [INFO    ] __main__: train step 22469: loss: 0.9405, policy_loss: 0.8765, value_loss: 0.4116
2024-07-14 07:42:31,810 [INFO    ] __main__: train step 22470: loss: 0.9405, policy_loss: 0.8764, value_loss: 0.4116
2024-07-14 07:42:33,454 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:42:33,884 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:42:33,953 [INFO    ] __main__: train step 22471: loss: 0.9405, policy_loss: 0.8764, value_loss: 0.4116
2024-07-14 07:42:34,267 [INFO    ] __main__: train step 22472: loss: 0.9405, policy_loss: 0.8764, value_loss: 0.4115
2024-07-14 07:42:34,584 [INFO    ] __main__: train step 22473: loss: 0.9405, policy_loss: 0.8764, value_loss: 0.4115
2024-07-14 07:42:34,868 [INFO    ] __main__: train step 22474: loss: 0.9404, policy_loss: 0.8764, value_loss: 0.4115
2024-07-14 07:42:35,168 [INFO    ] __main__: train step 22475: loss: 0.9404, policy_loss: 0.8764, value_loss: 0.4115
2024-07-14 07:42:35,472 [INFO    ] __main__: train step 22476: loss: 0.9404, policy_loss: 0.8764, value_loss: 0.4115
2024-07-14 07:42:35,770 [INFO    ] __main__: train step 22477: loss: 0.9404, policy_loss: 0.8763, value_loss: 0.4115
2024-07-14 07:42:36,085 [INFO    ] __main__: train step 22478: loss: 0.9404, policy_loss: 0.8763, value_loss: 0.4115
2024-07-14 07:42:36,382 [INFO    ] __main__: train step 22479: loss: 0.9404, policy_loss: 0.8763, value_loss: 0.4114
2024-07-14 07:42:36,659 [INFO    ] __main__: train step 22480: loss: 0.9404, policy_loss: 0.8763, value_loss: 0.4114
2024-07-14 07:42:36,958 [INFO    ] __main__: train step 22481: loss: 0.9403, policy_loss: 0.8763, value_loss: 0.4114
2024-07-14 07:42:37,254 [INFO    ] __main__: train step 22482: loss: 0.9403, policy_loss: 0.8763, value_loss: 0.4114
2024-07-14 07:42:37,553 [INFO    ] __main__: train step 22483: loss: 0.9403, policy_loss: 0.8763, value_loss: 0.4114
2024-07-14 07:42:37,852 [INFO    ] __main__: train step 22484: loss: 0.9403, policy_loss: 0.8763, value_loss: 0.4114
2024-07-14 07:42:38,163 [INFO    ] __main__: train step 22485: loss: 0.9403, policy_loss: 0.8762, value_loss: 0.4114
2024-07-14 07:42:38,427 [INFO    ] __main__: train step 22486: loss: 0.9403, policy_loss: 0.8762, value_loss: 0.4113
2024-07-14 07:42:38,735 [INFO    ] __main__: train step 22487: loss: 0.9403, policy_loss: 0.8762, value_loss: 0.4113
2024-07-14 07:42:40,389 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:42:40,876 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:42:40,948 [INFO    ] __main__: train step 22488: loss: 0.9403, policy_loss: 0.8762, value_loss: 0.4113
2024-07-14 07:42:41,269 [INFO    ] __main__: train step 22489: loss: 0.9402, policy_loss: 0.8762, value_loss: 0.4113
2024-07-14 07:42:41,577 [INFO    ] __main__: train step 22490: loss: 0.9402, policy_loss: 0.8762, value_loss: 0.4113
2024-07-14 07:42:41,898 [INFO    ] __main__: train step 22491: loss: 0.9402, policy_loss: 0.8762, value_loss: 0.4113
2024-07-14 07:42:42,218 [INFO    ] __main__: train step 22492: loss: 0.9402, policy_loss: 0.8761, value_loss: 0.4113
2024-07-14 07:42:42,529 [INFO    ] __main__: train step 22493: loss: 0.9402, policy_loss: 0.8761, value_loss: 0.4112
2024-07-14 07:42:42,821 [INFO    ] __main__: train step 22494: loss: 0.9402, policy_loss: 0.8761, value_loss: 0.4112
2024-07-14 07:42:43,115 [INFO    ] __main__: train step 22495: loss: 0.9402, policy_loss: 0.8761, value_loss: 0.4112
2024-07-14 07:42:43,411 [INFO    ] __main__: train step 22496: loss: 0.9402, policy_loss: 0.8761, value_loss: 0.4112
2024-07-14 07:42:43,702 [INFO    ] __main__: train step 22497: loss: 0.9401, policy_loss: 0.8761, value_loss: 0.4112
2024-07-14 07:42:44,020 [INFO    ] __main__: train step 22498: loss: 0.9401, policy_loss: 0.8761, value_loss: 0.4112
2024-07-14 07:42:44,318 [INFO    ] __main__: train step 22499: loss: 0.9401, policy_loss: 0.8760, value_loss: 0.4111
2024-07-14 07:42:44,616 [INFO    ] __main__: train step 22500: loss: 0.9401, policy_loss: 0.8760, value_loss: 0.4111
2024-07-14 07:42:44,917 [INFO    ] __main__: train step 22501: loss: 0.9401, policy_loss: 0.8760, value_loss: 0.4111
2024-07-14 07:42:45,227 [INFO    ] __main__: train step 22502: loss: 0.9401, policy_loss: 0.8760, value_loss: 0.4111
2024-07-14 07:42:45,535 [INFO    ] __main__: train step 22503: loss: 0.9401, policy_loss: 0.8760, value_loss: 0.4111
2024-07-14 07:42:45,858 [INFO    ] __main__: train step 22504: loss: 0.9400, policy_loss: 0.8760, value_loss: 0.4111
2024-07-14 07:42:47,486 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:42:47,924 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:42:47,990 [INFO    ] __main__: train step 22505: loss: 0.9400, policy_loss: 0.8760, value_loss: 0.4111
2024-07-14 07:42:48,298 [INFO    ] __main__: train step 22506: loss: 0.9400, policy_loss: 0.8760, value_loss: 0.4110
2024-07-14 07:42:48,630 [INFO    ] __main__: train step 22507: loss: 0.9400, policy_loss: 0.8759, value_loss: 0.4110
2024-07-14 07:42:48,958 [INFO    ] __main__: train step 22508: loss: 0.9400, policy_loss: 0.8759, value_loss: 0.4110
2024-07-14 07:42:49,256 [INFO    ] __main__: train step 22509: loss: 0.9400, policy_loss: 0.8759, value_loss: 0.4110
2024-07-14 07:42:49,552 [INFO    ] __main__: train step 22510: loss: 0.9400, policy_loss: 0.8759, value_loss: 0.4110
2024-07-14 07:42:49,855 [INFO    ] __main__: train step 22511: loss: 0.9400, policy_loss: 0.8759, value_loss: 0.4110
2024-07-14 07:42:50,168 [INFO    ] __main__: train step 22512: loss: 0.9399, policy_loss: 0.8759, value_loss: 0.4110
2024-07-14 07:42:50,482 [INFO    ] __main__: train step 22513: loss: 0.9399, policy_loss: 0.8759, value_loss: 0.4109
2024-07-14 07:42:50,797 [INFO    ] __main__: train step 22514: loss: 0.9399, policy_loss: 0.8758, value_loss: 0.4109
2024-07-14 07:42:51,099 [INFO    ] __main__: train step 22515: loss: 0.9399, policy_loss: 0.8758, value_loss: 0.4109
2024-07-14 07:42:51,400 [INFO    ] __main__: train step 22516: loss: 0.9399, policy_loss: 0.8758, value_loss: 0.4109
2024-07-14 07:42:51,700 [INFO    ] __main__: train step 22517: loss: 0.9399, policy_loss: 0.8758, value_loss: 0.4109
2024-07-14 07:42:52,033 [INFO    ] __main__: train step 22518: loss: 0.9399, policy_loss: 0.8758, value_loss: 0.4109
2024-07-14 07:42:52,341 [INFO    ] __main__: train step 22519: loss: 0.9398, policy_loss: 0.8758, value_loss: 0.4108
2024-07-14 07:42:52,643 [INFO    ] __main__: train step 22520: loss: 0.9398, policy_loss: 0.8758, value_loss: 0.4108
2024-07-14 07:42:52,954 [INFO    ] __main__: train step 22521: loss: 0.9398, policy_loss: 0.8757, value_loss: 0.4108
2024-07-14 07:42:54,613 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:42:55,042 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:42:55,139 [INFO    ] __main__: train step 22522: loss: 0.9398, policy_loss: 0.8757, value_loss: 0.4108
2024-07-14 07:42:55,464 [INFO    ] __main__: train step 22523: loss: 0.9398, policy_loss: 0.8757, value_loss: 0.4108
2024-07-14 07:42:55,788 [INFO    ] __main__: train step 22524: loss: 0.9398, policy_loss: 0.8757, value_loss: 0.4108
2024-07-14 07:42:56,112 [INFO    ] __main__: train step 22525: loss: 0.9398, policy_loss: 0.8757, value_loss: 0.4108
2024-07-14 07:42:56,429 [INFO    ] __main__: train step 22526: loss: 0.9398, policy_loss: 0.8757, value_loss: 0.4107
2024-07-14 07:42:56,758 [INFO    ] __main__: train step 22527: loss: 0.9397, policy_loss: 0.8757, value_loss: 0.4107
2024-07-14 07:42:57,077 [INFO    ] __main__: train step 22528: loss: 0.9397, policy_loss: 0.8757, value_loss: 0.4107
2024-07-14 07:42:57,387 [INFO    ] __main__: train step 22529: loss: 0.9397, policy_loss: 0.8756, value_loss: 0.4107
2024-07-14 07:42:57,706 [INFO    ] __main__: train step 22530: loss: 0.9397, policy_loss: 0.8756, value_loss: 0.4107
2024-07-14 07:42:58,071 [INFO    ] __main__: train step 22531: loss: 0.9397, policy_loss: 0.8756, value_loss: 0.4107
2024-07-14 07:42:58,395 [INFO    ] __main__: train step 22532: loss: 0.9397, policy_loss: 0.8756, value_loss: 0.4107
2024-07-14 07:42:58,700 [INFO    ] __main__: train step 22533: loss: 0.9397, policy_loss: 0.8756, value_loss: 0.4106
2024-07-14 07:42:58,985 [INFO    ] __main__: train step 22534: loss: 0.9397, policy_loss: 0.8756, value_loss: 0.4106
2024-07-14 07:42:59,278 [INFO    ] __main__: train step 22535: loss: 0.9396, policy_loss: 0.8756, value_loss: 0.4106
2024-07-14 07:42:59,565 [INFO    ] __main__: train step 22536: loss: 0.9396, policy_loss: 0.8755, value_loss: 0.4106
2024-07-14 07:42:59,866 [INFO    ] __main__: train step 22537: loss: 0.9396, policy_loss: 0.8755, value_loss: 0.4106
2024-07-14 07:43:00,190 [INFO    ] __main__: train step 22538: loss: 0.9396, policy_loss: 0.8755, value_loss: 0.4106
2024-07-14 07:43:01,822 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:43:02,268 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:43:02,342 [INFO    ] __main__: train step 22539: loss: 0.9396, policy_loss: 0.8755, value_loss: 0.4105
2024-07-14 07:43:02,664 [INFO    ] __main__: train step 22540: loss: 0.9396, policy_loss: 0.8755, value_loss: 0.4105
2024-07-14 07:43:02,991 [INFO    ] __main__: train step 22541: loss: 0.9396, policy_loss: 0.8755, value_loss: 0.4105
2024-07-14 07:43:03,298 [INFO    ] __main__: train step 22542: loss: 0.9395, policy_loss: 0.8755, value_loss: 0.4105
2024-07-14 07:43:03,596 [INFO    ] __main__: train step 22543: loss: 0.9395, policy_loss: 0.8755, value_loss: 0.4105
2024-07-14 07:43:03,907 [INFO    ] __main__: train step 22544: loss: 0.9395, policy_loss: 0.8754, value_loss: 0.4105
2024-07-14 07:43:04,197 [INFO    ] __main__: train step 22545: loss: 0.9395, policy_loss: 0.8754, value_loss: 0.4105
2024-07-14 07:43:04,484 [INFO    ] __main__: train step 22546: loss: 0.9395, policy_loss: 0.8754, value_loss: 0.4104
2024-07-14 07:43:04,777 [INFO    ] __main__: train step 22547: loss: 0.9395, policy_loss: 0.8754, value_loss: 0.4104
2024-07-14 07:43:05,098 [INFO    ] __main__: train step 22548: loss: 0.9395, policy_loss: 0.8754, value_loss: 0.4104
2024-07-14 07:43:05,385 [INFO    ] __main__: train step 22549: loss: 0.9395, policy_loss: 0.8754, value_loss: 0.4104
2024-07-14 07:43:05,678 [INFO    ] __main__: train step 22550: loss: 0.9394, policy_loss: 0.8754, value_loss: 0.4104
2024-07-14 07:43:05,985 [INFO    ] __main__: train step 22551: loss: 0.9394, policy_loss: 0.8753, value_loss: 0.4104
2024-07-14 07:43:06,294 [INFO    ] __main__: train step 22552: loss: 0.9394, policy_loss: 0.8753, value_loss: 0.4104
2024-07-14 07:43:06,625 [INFO    ] __main__: train step 22553: loss: 0.9394, policy_loss: 0.8753, value_loss: 0.4103
2024-07-14 07:43:06,928 [INFO    ] __main__: train step 22554: loss: 0.9394, policy_loss: 0.8753, value_loss: 0.4103
2024-07-14 07:43:07,224 [INFO    ] __main__: train step 22555: loss: 0.9394, policy_loss: 0.8753, value_loss: 0.4103
2024-07-14 07:43:08,862 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:43:09,287 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:43:09,356 [INFO    ] __main__: train step 22556: loss: 0.9394, policy_loss: 0.8753, value_loss: 0.4103
2024-07-14 07:43:16,737 [INFO    ] __main__: train step 22557: loss: 0.9394, policy_loss: 0.8753, value_loss: 0.4103
2024-07-14 07:43:17,079 [INFO    ] __main__: train step 22558: loss: 0.9393, policy_loss: 0.8753, value_loss: 0.4103
2024-07-14 07:43:17,386 [INFO    ] __main__: train step 22559: loss: 0.9393, policy_loss: 0.8752, value_loss: 0.4103
2024-07-14 07:43:17,712 [INFO    ] __main__: train step 22560: loss: 0.9393, policy_loss: 0.8752, value_loss: 0.4102
2024-07-14 07:43:18,033 [INFO    ] __main__: train step 22561: loss: 0.9393, policy_loss: 0.8752, value_loss: 0.4102
2024-07-14 07:43:18,341 [INFO    ] __main__: train step 22562: loss: 0.9393, policy_loss: 0.8752, value_loss: 0.4102
2024-07-14 07:43:18,638 [INFO    ] __main__: train step 22563: loss: 0.9393, policy_loss: 0.8752, value_loss: 0.4102
2024-07-14 07:43:18,948 [INFO    ] __main__: train step 22564: loss: 0.9393, policy_loss: 0.8752, value_loss: 0.4102
2024-07-14 07:43:19,264 [INFO    ] __main__: train step 22565: loss: 0.9393, policy_loss: 0.8752, value_loss: 0.4102
2024-07-14 07:43:19,559 [INFO    ] __main__: train step 22566: loss: 0.9392, policy_loss: 0.8751, value_loss: 0.4101
2024-07-14 07:43:19,870 [INFO    ] __main__: train step 22567: loss: 0.9392, policy_loss: 0.8751, value_loss: 0.4101
2024-07-14 07:43:20,183 [INFO    ] __main__: train step 22568: loss: 0.9392, policy_loss: 0.8751, value_loss: 0.4101
2024-07-14 07:43:20,500 [INFO    ] __main__: train step 22569: loss: 0.9392, policy_loss: 0.8751, value_loss: 0.4101
2024-07-14 07:43:20,785 [INFO    ] __main__: train step 22570: loss: 0.9392, policy_loss: 0.8751, value_loss: 0.4101
2024-07-14 07:43:21,104 [INFO    ] __main__: train step 22571: loss: 0.9392, policy_loss: 0.8751, value_loss: 0.4101
2024-07-14 07:43:21,438 [INFO    ] __main__: train step 22572: loss: 0.9392, policy_loss: 0.8751, value_loss: 0.4101
2024-07-14 07:43:23,094 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:43:23,529 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:43:23,598 [INFO    ] __main__: train step 22573: loss: 0.9392, policy_loss: 0.8751, value_loss: 0.4100
2024-07-14 07:43:23,890 [INFO    ] __main__: train step 22574: loss: 0.9391, policy_loss: 0.8750, value_loss: 0.4100
2024-07-14 07:43:24,182 [INFO    ] __main__: train step 22575: loss: 0.9391, policy_loss: 0.8750, value_loss: 0.4100
2024-07-14 07:43:24,496 [INFO    ] __main__: train step 22576: loss: 0.9391, policy_loss: 0.8750, value_loss: 0.4100
2024-07-14 07:43:24,821 [INFO    ] __main__: train step 22577: loss: 0.9391, policy_loss: 0.8750, value_loss: 0.4100
2024-07-14 07:43:25,143 [INFO    ] __main__: train step 22578: loss: 0.9391, policy_loss: 0.8750, value_loss: 0.4100
2024-07-14 07:43:25,461 [INFO    ] __main__: train step 22579: loss: 0.9391, policy_loss: 0.8750, value_loss: 0.4100
2024-07-14 07:43:25,759 [INFO    ] __main__: train step 22580: loss: 0.9391, policy_loss: 0.8750, value_loss: 0.4099
2024-07-14 07:43:26,042 [INFO    ] __main__: train step 22581: loss: 0.9391, policy_loss: 0.8749, value_loss: 0.4099
2024-07-14 07:43:26,342 [INFO    ] __main__: train step 22582: loss: 0.9390, policy_loss: 0.8749, value_loss: 0.4099
2024-07-14 07:43:26,654 [INFO    ] __main__: train step 22583: loss: 0.9390, policy_loss: 0.8749, value_loss: 0.4099
2024-07-14 07:43:26,971 [INFO    ] __main__: train step 22584: loss: 0.9390, policy_loss: 0.8749, value_loss: 0.4099
2024-07-14 07:43:27,284 [INFO    ] __main__: train step 22585: loss: 0.9390, policy_loss: 0.8749, value_loss: 0.4099
2024-07-14 07:43:27,600 [INFO    ] __main__: train step 22586: loss: 0.9390, policy_loss: 0.8749, value_loss: 0.4099
2024-07-14 07:43:27,900 [INFO    ] __main__: train step 22587: loss: 0.9390, policy_loss: 0.8749, value_loss: 0.4098
2024-07-14 07:43:28,208 [INFO    ] __main__: train step 22588: loss: 0.9390, policy_loss: 0.8749, value_loss: 0.4098
2024-07-14 07:43:28,522 [INFO    ] __main__: train step 22589: loss: 0.9390, policy_loss: 0.8748, value_loss: 0.4098
2024-07-14 07:43:30,174 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:43:30,611 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:43:30,684 [INFO    ] __main__: train step 22590: loss: 0.9389, policy_loss: 0.8748, value_loss: 0.4098
2024-07-14 07:43:30,992 [INFO    ] __main__: train step 22591: loss: 0.9389, policy_loss: 0.8748, value_loss: 0.4098
2024-07-14 07:43:31,293 [INFO    ] __main__: train step 22592: loss: 0.9389, policy_loss: 0.8748, value_loss: 0.4098
2024-07-14 07:43:31,598 [INFO    ] __main__: train step 22593: loss: 0.9389, policy_loss: 0.8748, value_loss: 0.4098
2024-07-14 07:43:31,925 [INFO    ] __main__: train step 22594: loss: 0.9389, policy_loss: 0.8748, value_loss: 0.4097
2024-07-14 07:43:32,237 [INFO    ] __main__: train step 22595: loss: 0.9389, policy_loss: 0.8748, value_loss: 0.4097
2024-07-14 07:43:32,548 [INFO    ] __main__: train step 22596: loss: 0.9389, policy_loss: 0.8747, value_loss: 0.4097
2024-07-14 07:43:32,866 [INFO    ] __main__: train step 22597: loss: 0.9389, policy_loss: 0.8747, value_loss: 0.4097
2024-07-14 07:43:33,179 [INFO    ] __main__: train step 22598: loss: 0.9388, policy_loss: 0.8747, value_loss: 0.4097
2024-07-14 07:43:33,470 [INFO    ] __main__: train step 22599: loss: 0.9388, policy_loss: 0.8747, value_loss: 0.4097
2024-07-14 07:43:33,778 [INFO    ] __main__: train step 22600: loss: 0.9388, policy_loss: 0.8747, value_loss: 0.4096
2024-07-14 07:43:34,096 [INFO    ] __main__: train step 22601: loss: 0.9388, policy_loss: 0.8747, value_loss: 0.4096
2024-07-14 07:43:34,415 [INFO    ] __main__: train step 22602: loss: 0.9388, policy_loss: 0.8747, value_loss: 0.4096
2024-07-14 07:43:34,726 [INFO    ] __main__: train step 22603: loss: 0.9388, policy_loss: 0.8747, value_loss: 0.4096
2024-07-14 07:43:35,034 [INFO    ] __main__: train step 22604: loss: 0.9388, policy_loss: 0.8746, value_loss: 0.4096
2024-07-14 07:43:35,358 [INFO    ] __main__: train step 22605: loss: 0.9387, policy_loss: 0.8746, value_loss: 0.4096
2024-07-14 07:43:35,671 [INFO    ] __main__: train step 22606: loss: 0.9387, policy_loss: 0.8746, value_loss: 0.4096
2024-07-14 07:43:37,285 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:43:37,694 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:43:37,765 [INFO    ] __main__: train step 22607: loss: 0.9387, policy_loss: 0.8746, value_loss: 0.4095
2024-07-14 07:43:38,066 [INFO    ] __main__: train step 22608: loss: 0.9387, policy_loss: 0.8746, value_loss: 0.4095
2024-07-14 07:43:38,358 [INFO    ] __main__: train step 22609: loss: 0.9387, policy_loss: 0.8746, value_loss: 0.4095
2024-07-14 07:43:38,661 [INFO    ] __main__: train step 22610: loss: 0.9387, policy_loss: 0.8746, value_loss: 0.4095
2024-07-14 07:43:38,973 [INFO    ] __main__: train step 22611: loss: 0.9387, policy_loss: 0.8745, value_loss: 0.4095
2024-07-14 07:43:39,292 [INFO    ] __main__: train step 22612: loss: 0.9387, policy_loss: 0.8745, value_loss: 0.4095
2024-07-14 07:43:39,606 [INFO    ] __main__: train step 22613: loss: 0.9386, policy_loss: 0.8745, value_loss: 0.4095
2024-07-14 07:43:39,917 [INFO    ] __main__: train step 22614: loss: 0.9386, policy_loss: 0.8745, value_loss: 0.4094
2024-07-14 07:43:40,191 [INFO    ] __main__: train step 22615: loss: 0.9386, policy_loss: 0.8745, value_loss: 0.4094
2024-07-14 07:43:40,475 [INFO    ] __main__: train step 22616: loss: 0.9386, policy_loss: 0.8745, value_loss: 0.4094
2024-07-14 07:43:40,784 [INFO    ] __main__: train step 22617: loss: 0.9386, policy_loss: 0.8745, value_loss: 0.4094
2024-07-14 07:43:41,080 [INFO    ] __main__: train step 22618: loss: 0.9386, policy_loss: 0.8745, value_loss: 0.4094
2024-07-14 07:43:41,384 [INFO    ] __main__: train step 22619: loss: 0.9386, policy_loss: 0.8744, value_loss: 0.4094
2024-07-14 07:43:41,674 [INFO    ] __main__: train step 22620: loss: 0.9386, policy_loss: 0.8744, value_loss: 0.4094
2024-07-14 07:43:41,999 [INFO    ] __main__: train step 22621: loss: 0.9385, policy_loss: 0.8744, value_loss: 0.4093
2024-07-14 07:43:42,327 [INFO    ] __main__: train step 22622: loss: 0.9385, policy_loss: 0.8744, value_loss: 0.4093
2024-07-14 07:43:42,652 [INFO    ] __main__: train step 22623: loss: 0.9385, policy_loss: 0.8744, value_loss: 0.4093
2024-07-14 07:43:44,296 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:43:44,731 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:43:44,798 [INFO    ] __main__: train step 22624: loss: 0.9385, policy_loss: 0.8744, value_loss: 0.4093
2024-07-14 07:43:45,119 [INFO    ] __main__: train step 22625: loss: 0.9385, policy_loss: 0.8744, value_loss: 0.4093
2024-07-14 07:43:45,453 [INFO    ] __main__: train step 22626: loss: 0.9385, policy_loss: 0.8743, value_loss: 0.4093
2024-07-14 07:43:45,798 [INFO    ] __main__: train step 22627: loss: 0.9385, policy_loss: 0.8743, value_loss: 0.4093
2024-07-14 07:43:46,102 [INFO    ] __main__: train step 22628: loss: 0.9385, policy_loss: 0.8743, value_loss: 0.4092
2024-07-14 07:43:46,386 [INFO    ] __main__: train step 22629: loss: 0.9384, policy_loss: 0.8743, value_loss: 0.4092
2024-07-14 07:43:46,703 [INFO    ] __main__: train step 22630: loss: 0.9384, policy_loss: 0.8743, value_loss: 0.4092
2024-07-14 07:43:47,015 [INFO    ] __main__: train step 22631: loss: 0.9384, policy_loss: 0.8743, value_loss: 0.4092
2024-07-14 07:43:47,316 [INFO    ] __main__: train step 22632: loss: 0.9384, policy_loss: 0.8743, value_loss: 0.4092
2024-07-14 07:43:47,629 [INFO    ] __main__: train step 22633: loss: 0.9384, policy_loss: 0.8743, value_loss: 0.4092
2024-07-14 07:43:47,985 [INFO    ] __main__: train step 22634: loss: 0.9384, policy_loss: 0.8742, value_loss: 0.4092
2024-07-14 07:43:48,330 [INFO    ] __main__: train step 22635: loss: 0.9384, policy_loss: 0.8742, value_loss: 0.4091
2024-07-14 07:43:48,655 [INFO    ] __main__: train step 22636: loss: 0.9384, policy_loss: 0.8742, value_loss: 0.4091
2024-07-14 07:43:48,967 [INFO    ] __main__: train step 22637: loss: 0.9383, policy_loss: 0.8742, value_loss: 0.4091
2024-07-14 07:43:49,278 [INFO    ] __main__: train step 22638: loss: 0.9383, policy_loss: 0.8742, value_loss: 0.4091
2024-07-14 07:43:49,587 [INFO    ] __main__: train step 22639: loss: 0.9383, policy_loss: 0.8742, value_loss: 0.4091
2024-07-14 07:43:49,909 [INFO    ] __main__: train step 22640: loss: 0.9383, policy_loss: 0.8742, value_loss: 0.4091
2024-07-14 07:43:51,577 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:43:52,028 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:43:52,099 [INFO    ] __main__: train step 22641: loss: 0.9383, policy_loss: 0.8742, value_loss: 0.4090
2024-07-14 07:43:52,421 [INFO    ] __main__: train step 22642: loss: 0.9383, policy_loss: 0.8741, value_loss: 0.4090
2024-07-14 07:43:52,712 [INFO    ] __main__: train step 22643: loss: 0.9383, policy_loss: 0.8741, value_loss: 0.4090
2024-07-14 07:43:52,995 [INFO    ] __main__: train step 22644: loss: 0.9383, policy_loss: 0.8741, value_loss: 0.4090
2024-07-14 07:43:53,306 [INFO    ] __main__: train step 22645: loss: 0.9382, policy_loss: 0.8741, value_loss: 0.4090
2024-07-14 07:43:53,612 [INFO    ] __main__: train step 22646: loss: 0.9382, policy_loss: 0.8741, value_loss: 0.4090
2024-07-14 07:43:53,937 [INFO    ] __main__: train step 22647: loss: 0.9382, policy_loss: 0.8741, value_loss: 0.4090
2024-07-14 07:43:54,251 [INFO    ] __main__: train step 22648: loss: 0.9382, policy_loss: 0.8741, value_loss: 0.4089
2024-07-14 07:43:54,539 [INFO    ] __main__: train step 22649: loss: 0.9382, policy_loss: 0.8741, value_loss: 0.4089
2024-07-14 07:43:54,840 [INFO    ] __main__: train step 22650: loss: 0.9382, policy_loss: 0.8740, value_loss: 0.4089
2024-07-14 07:43:55,147 [INFO    ] __main__: train step 22651: loss: 0.9382, policy_loss: 0.8740, value_loss: 0.4089
2024-07-14 07:43:55,462 [INFO    ] __main__: train step 22652: loss: 0.9382, policy_loss: 0.8740, value_loss: 0.4089
2024-07-14 07:43:55,773 [INFO    ] __main__: train step 22653: loss: 0.9381, policy_loss: 0.8740, value_loss: 0.4089
2024-07-14 07:43:56,042 [INFO    ] __main__: train step 22654: loss: 0.9381, policy_loss: 0.8740, value_loss: 0.4089
2024-07-14 07:43:56,342 [INFO    ] __main__: train step 22655: loss: 0.9381, policy_loss: 0.8740, value_loss: 0.4088
2024-07-14 07:43:56,659 [INFO    ] __main__: train step 22656: loss: 0.9381, policy_loss: 0.8740, value_loss: 0.4088
2024-07-14 07:43:56,977 [INFO    ] __main__: train step 22657: loss: 0.9381, policy_loss: 0.8739, value_loss: 0.4088
2024-07-14 07:43:58,627 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:43:59,070 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:43:59,141 [INFO    ] __main__: train step 22658: loss: 0.9381, policy_loss: 0.8739, value_loss: 0.4088
2024-07-14 07:43:59,455 [INFO    ] __main__: train step 22659: loss: 0.9381, policy_loss: 0.8739, value_loss: 0.4088
2024-07-14 07:43:59,780 [INFO    ] __main__: train step 22660: loss: 0.9381, policy_loss: 0.8739, value_loss: 0.4088
2024-07-14 07:44:00,103 [INFO    ] __main__: train step 22661: loss: 0.9381, policy_loss: 0.8739, value_loss: 0.4088
2024-07-14 07:44:00,432 [INFO    ] __main__: train step 22662: loss: 0.9380, policy_loss: 0.8739, value_loss: 0.4087
2024-07-14 07:44:00,733 [INFO    ] __main__: train step 22663: loss: 0.9380, policy_loss: 0.8739, value_loss: 0.4087
2024-07-14 07:44:01,051 [INFO    ] __main__: train step 22664: loss: 0.9380, policy_loss: 0.8739, value_loss: 0.4087
2024-07-14 07:44:01,368 [INFO    ] __main__: train step 22665: loss: 0.9380, policy_loss: 0.8738, value_loss: 0.4087
2024-07-14 07:44:01,676 [INFO    ] __main__: train step 22666: loss: 0.9380, policy_loss: 0.8738, value_loss: 0.4087
2024-07-14 07:44:01,984 [INFO    ] __main__: train step 22667: loss: 0.9380, policy_loss: 0.8738, value_loss: 0.4087
2024-07-14 07:44:02,286 [INFO    ] __main__: train step 22668: loss: 0.9380, policy_loss: 0.8738, value_loss: 0.4087
2024-07-14 07:44:02,613 [INFO    ] __main__: train step 22669: loss: 0.9380, policy_loss: 0.8738, value_loss: 0.4086
2024-07-14 07:44:02,940 [INFO    ] __main__: train step 22670: loss: 0.9379, policy_loss: 0.8738, value_loss: 0.4086
2024-07-14 07:44:03,250 [INFO    ] __main__: train step 22671: loss: 0.9379, policy_loss: 0.8738, value_loss: 0.4086
2024-07-14 07:44:03,624 [INFO    ] __main__: train step 22672: loss: 0.9379, policy_loss: 0.8738, value_loss: 0.4086
2024-07-14 07:44:03,958 [INFO    ] __main__: train step 22673: loss: 0.9379, policy_loss: 0.8737, value_loss: 0.4086
2024-07-14 07:44:04,312 [INFO    ] __main__: train step 22674: loss: 0.9379, policy_loss: 0.8737, value_loss: 0.4086
2024-07-14 07:44:05,969 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:44:06,401 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:44:06,477 [INFO    ] __main__: train step 22675: loss: 0.9379, policy_loss: 0.8737, value_loss: 0.4086
2024-07-14 07:44:06,799 [INFO    ] __main__: train step 22676: loss: 0.9379, policy_loss: 0.8737, value_loss: 0.4085
2024-07-14 07:44:07,102 [INFO    ] __main__: train step 22677: loss: 0.9379, policy_loss: 0.8737, value_loss: 0.4085
2024-07-14 07:44:07,405 [INFO    ] __main__: train step 22678: loss: 0.9378, policy_loss: 0.8737, value_loss: 0.4085
2024-07-14 07:44:07,720 [INFO    ] __main__: train step 22679: loss: 0.9378, policy_loss: 0.8737, value_loss: 0.4085
2024-07-14 07:44:08,030 [INFO    ] __main__: train step 22680: loss: 0.9378, policy_loss: 0.8736, value_loss: 0.4085
2024-07-14 07:44:08,344 [INFO    ] __main__: train step 22681: loss: 0.9378, policy_loss: 0.8736, value_loss: 0.4085
2024-07-14 07:44:08,628 [INFO    ] __main__: train step 22682: loss: 0.9378, policy_loss: 0.8736, value_loss: 0.4085
2024-07-14 07:44:08,924 [INFO    ] __main__: train step 22683: loss: 0.9378, policy_loss: 0.8736, value_loss: 0.4084
2024-07-14 07:44:09,235 [INFO    ] __main__: train step 22684: loss: 0.9378, policy_loss: 0.8736, value_loss: 0.4084
2024-07-14 07:44:09,541 [INFO    ] __main__: train step 22685: loss: 0.9378, policy_loss: 0.8736, value_loss: 0.4084
2024-07-14 07:44:14,359 [INFO    ] __main__: train step 22686: loss: 0.9377, policy_loss: 0.8736, value_loss: 0.4084
2024-07-14 07:44:14,662 [INFO    ] __main__: train step 22687: loss: 0.9377, policy_loss: 0.8736, value_loss: 0.4084
2024-07-14 07:44:14,987 [INFO    ] __main__: train step 22688: loss: 0.9377, policy_loss: 0.8735, value_loss: 0.4084
2024-07-14 07:44:15,267 [INFO    ] __main__: train step 22689: loss: 0.9377, policy_loss: 0.8735, value_loss: 0.4084
2024-07-14 07:44:15,550 [INFO    ] __main__: train step 22690: loss: 0.9377, policy_loss: 0.8735, value_loss: 0.4083
2024-07-14 07:44:15,862 [INFO    ] __main__: train step 22691: loss: 0.9377, policy_loss: 0.8735, value_loss: 0.4083
2024-07-14 07:44:17,496 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:44:17,938 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:44:18,012 [INFO    ] __main__: train step 22692: loss: 0.9377, policy_loss: 0.8735, value_loss: 0.4083
2024-07-14 07:44:18,276 [INFO    ] __main__: train step 22693: loss: 0.9377, policy_loss: 0.8735, value_loss: 0.4083
2024-07-14 07:44:18,548 [INFO    ] __main__: train step 22694: loss: 0.9376, policy_loss: 0.8735, value_loss: 0.4083
2024-07-14 07:44:18,835 [INFO    ] __main__: train step 22695: loss: 0.9376, policy_loss: 0.8735, value_loss: 0.4083
2024-07-14 07:44:19,153 [INFO    ] __main__: train step 22696: loss: 0.9376, policy_loss: 0.8734, value_loss: 0.4083
2024-07-14 07:44:19,453 [INFO    ] __main__: train step 22697: loss: 0.9376, policy_loss: 0.8734, value_loss: 0.4082
2024-07-14 07:44:19,752 [INFO    ] __main__: train step 22698: loss: 0.9376, policy_loss: 0.8734, value_loss: 0.4082
2024-07-14 07:44:20,057 [INFO    ] __main__: train step 22699: loss: 0.9376, policy_loss: 0.8734, value_loss: 0.4082
2024-07-14 07:44:20,360 [INFO    ] __main__: train step 22700: loss: 0.9376, policy_loss: 0.8734, value_loss: 0.4082
2024-07-14 07:44:20,686 [INFO    ] __main__: train step 22701: loss: 0.9376, policy_loss: 0.8734, value_loss: 0.4082
2024-07-14 07:44:21,002 [INFO    ] __main__: train step 22702: loss: 0.9376, policy_loss: 0.8734, value_loss: 0.4082
2024-07-14 07:44:21,323 [INFO    ] __main__: train step 22703: loss: 0.9375, policy_loss: 0.8734, value_loss: 0.4082
2024-07-14 07:44:21,614 [INFO    ] __main__: train step 22704: loss: 0.9375, policy_loss: 0.8733, value_loss: 0.4081
2024-07-14 07:44:21,929 [INFO    ] __main__: train step 22705: loss: 0.9375, policy_loss: 0.8733, value_loss: 0.4081
2024-07-14 07:44:22,233 [INFO    ] __main__: train step 22706: loss: 0.9375, policy_loss: 0.8733, value_loss: 0.4081
2024-07-14 07:44:22,543 [INFO    ] __main__: train step 22707: loss: 0.9375, policy_loss: 0.8733, value_loss: 0.4081
2024-07-14 07:44:22,856 [INFO    ] __main__: train step 22708: loss: 0.9375, policy_loss: 0.8733, value_loss: 0.4081
2024-07-14 07:44:24,451 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:44:24,880 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:44:24,953 [INFO    ] __main__: train step 22709: loss: 0.9375, policy_loss: 0.8733, value_loss: 0.4081
2024-07-14 07:44:25,254 [INFO    ] __main__: train step 22710: loss: 0.9375, policy_loss: 0.8733, value_loss: 0.4081
2024-07-14 07:44:25,562 [INFO    ] __main__: train step 22711: loss: 0.9374, policy_loss: 0.8732, value_loss: 0.4080
2024-07-14 07:44:25,857 [INFO    ] __main__: train step 22712: loss: 0.9374, policy_loss: 0.8732, value_loss: 0.4080
2024-07-14 07:44:26,159 [INFO    ] __main__: train step 22713: loss: 0.9374, policy_loss: 0.8732, value_loss: 0.4080
2024-07-14 07:44:26,471 [INFO    ] __main__: train step 22714: loss: 0.9374, policy_loss: 0.8732, value_loss: 0.4080
2024-07-14 07:44:26,777 [INFO    ] __main__: train step 22715: loss: 0.9374, policy_loss: 0.8732, value_loss: 0.4080
2024-07-14 07:44:27,088 [INFO    ] __main__: train step 22716: loss: 0.9374, policy_loss: 0.8732, value_loss: 0.4080
2024-07-14 07:44:27,398 [INFO    ] __main__: train step 22717: loss: 0.9374, policy_loss: 0.8732, value_loss: 0.4080
2024-07-14 07:44:27,686 [INFO    ] __main__: train step 22718: loss: 0.9374, policy_loss: 0.8732, value_loss: 0.4079
2024-07-14 07:44:27,968 [INFO    ] __main__: train step 22719: loss: 0.9373, policy_loss: 0.8731, value_loss: 0.4079
2024-07-14 07:44:28,274 [INFO    ] __main__: train step 22720: loss: 0.9373, policy_loss: 0.8731, value_loss: 0.4079
2024-07-14 07:44:28,592 [INFO    ] __main__: train step 22721: loss: 0.9373, policy_loss: 0.8731, value_loss: 0.4079
2024-07-14 07:44:28,895 [INFO    ] __main__: train step 22722: loss: 0.9373, policy_loss: 0.8731, value_loss: 0.4079
2024-07-14 07:44:29,216 [INFO    ] __main__: train step 22723: loss: 0.9373, policy_loss: 0.8731, value_loss: 0.4079
2024-07-14 07:44:29,510 [INFO    ] __main__: train step 22724: loss: 0.9373, policy_loss: 0.8731, value_loss: 0.4079
2024-07-14 07:44:29,822 [INFO    ] __main__: train step 22725: loss: 0.9373, policy_loss: 0.8731, value_loss: 0.4078
2024-07-14 07:44:31,462 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:44:31,907 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:44:31,973 [INFO    ] __main__: train step 22726: loss: 0.9373, policy_loss: 0.8731, value_loss: 0.4078
2024-07-14 07:44:32,308 [INFO    ] __main__: train step 22727: loss: 0.9373, policy_loss: 0.8730, value_loss: 0.4078
2024-07-14 07:44:32,618 [INFO    ] __main__: train step 22728: loss: 0.9372, policy_loss: 0.8730, value_loss: 0.4078
2024-07-14 07:44:32,926 [INFO    ] __main__: train step 22729: loss: 0.9372, policy_loss: 0.8730, value_loss: 0.4078
2024-07-14 07:44:33,226 [INFO    ] __main__: train step 22730: loss: 0.9372, policy_loss: 0.8730, value_loss: 0.4078
2024-07-14 07:44:33,537 [INFO    ] __main__: train step 22731: loss: 0.9372, policy_loss: 0.8730, value_loss: 0.4078
2024-07-14 07:44:33,856 [INFO    ] __main__: train step 22732: loss: 0.9372, policy_loss: 0.8730, value_loss: 0.4077
2024-07-14 07:44:34,166 [INFO    ] __main__: train step 22733: loss: 0.9372, policy_loss: 0.8730, value_loss: 0.4077
2024-07-14 07:44:34,454 [INFO    ] __main__: train step 22734: loss: 0.9372, policy_loss: 0.8730, value_loss: 0.4077
2024-07-14 07:44:34,754 [INFO    ] __main__: train step 22735: loss: 0.9372, policy_loss: 0.8729, value_loss: 0.4077
2024-07-14 07:44:35,050 [INFO    ] __main__: train step 22736: loss: 0.9371, policy_loss: 0.8729, value_loss: 0.4077
2024-07-14 07:44:35,391 [INFO    ] __main__: train step 22737: loss: 0.9371, policy_loss: 0.8729, value_loss: 0.4077
2024-07-14 07:44:35,707 [INFO    ] __main__: train step 22738: loss: 0.9371, policy_loss: 0.8729, value_loss: 0.4077
2024-07-14 07:44:35,999 [INFO    ] __main__: train step 22739: loss: 0.9371, policy_loss: 0.8729, value_loss: 0.4076
2024-07-14 07:44:36,310 [INFO    ] __main__: train step 22740: loss: 0.9371, policy_loss: 0.8729, value_loss: 0.4076
2024-07-14 07:44:36,627 [INFO    ] __main__: train step 22741: loss: 0.9371, policy_loss: 0.8729, value_loss: 0.4076
2024-07-14 07:44:36,944 [INFO    ] __main__: train step 22742: loss: 0.9371, policy_loss: 0.8729, value_loss: 0.4076
2024-07-14 07:44:38,579 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:44:39,002 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:44:39,073 [INFO    ] __main__: train step 22743: loss: 0.9371, policy_loss: 0.8728, value_loss: 0.4076
2024-07-14 07:44:39,376 [INFO    ] __main__: train step 22744: loss: 0.9370, policy_loss: 0.8728, value_loss: 0.4076
2024-07-14 07:44:39,676 [INFO    ] __main__: train step 22745: loss: 0.9370, policy_loss: 0.8728, value_loss: 0.4076
2024-07-14 07:44:40,010 [INFO    ] __main__: train step 22746: loss: 0.9370, policy_loss: 0.8728, value_loss: 0.4075
2024-07-14 07:44:40,330 [INFO    ] __main__: train step 22747: loss: 0.9370, policy_loss: 0.8728, value_loss: 0.4075
2024-07-14 07:44:40,625 [INFO    ] __main__: train step 22748: loss: 0.9370, policy_loss: 0.8728, value_loss: 0.4075
2024-07-14 07:44:40,923 [INFO    ] __main__: train step 22749: loss: 0.9370, policy_loss: 0.8728, value_loss: 0.4075
2024-07-14 07:44:41,215 [INFO    ] __main__: train step 22750: loss: 0.9370, policy_loss: 0.8728, value_loss: 0.4075
2024-07-14 07:44:41,532 [INFO    ] __main__: train step 22751: loss: 0.9370, policy_loss: 0.8727, value_loss: 0.4075
2024-07-14 07:44:41,831 [INFO    ] __main__: train step 22752: loss: 0.9370, policy_loss: 0.8727, value_loss: 0.4074
2024-07-14 07:44:42,146 [INFO    ] __main__: train step 22753: loss: 0.9369, policy_loss: 0.8727, value_loss: 0.4074
2024-07-14 07:44:42,466 [INFO    ] __main__: train step 22754: loss: 0.9369, policy_loss: 0.8727, value_loss: 0.4074
2024-07-14 07:44:42,784 [INFO    ] __main__: train step 22755: loss: 0.9369, policy_loss: 0.8727, value_loss: 0.4074
2024-07-14 07:44:43,091 [INFO    ] __main__: train step 22756: loss: 0.9369, policy_loss: 0.8727, value_loss: 0.4074
2024-07-14 07:44:43,407 [INFO    ] __main__: train step 22757: loss: 0.9369, policy_loss: 0.8727, value_loss: 0.4074
2024-07-14 07:44:43,721 [INFO    ] __main__: train step 22758: loss: 0.9369, policy_loss: 0.8727, value_loss: 0.4074
2024-07-14 07:44:44,010 [INFO    ] __main__: train step 22759: loss: 0.9369, policy_loss: 0.8726, value_loss: 0.4073
2024-07-14 07:44:45,643 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:44:46,070 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:44:46,139 [INFO    ] __main__: train step 22760: loss: 0.9369, policy_loss: 0.8726, value_loss: 0.4073
2024-07-14 07:44:46,451 [INFO    ] __main__: train step 22761: loss: 0.9368, policy_loss: 0.8726, value_loss: 0.4073
2024-07-14 07:44:46,774 [INFO    ] __main__: train step 22762: loss: 0.9368, policy_loss: 0.8726, value_loss: 0.4073
2024-07-14 07:44:47,071 [INFO    ] __main__: train step 22763: loss: 0.9368, policy_loss: 0.8726, value_loss: 0.4073
2024-07-14 07:44:47,381 [INFO    ] __main__: train step 22764: loss: 0.9368, policy_loss: 0.8726, value_loss: 0.4073
2024-07-14 07:44:47,681 [INFO    ] __main__: train step 22765: loss: 0.9368, policy_loss: 0.8726, value_loss: 0.4073
2024-07-14 07:44:47,995 [INFO    ] __main__: train step 22766: loss: 0.9368, policy_loss: 0.8725, value_loss: 0.4072
2024-07-14 07:44:48,339 [INFO    ] __main__: train step 22767: loss: 0.9368, policy_loss: 0.8725, value_loss: 0.4072
2024-07-14 07:44:48,641 [INFO    ] __main__: train step 22768: loss: 0.9368, policy_loss: 0.8725, value_loss: 0.4072
2024-07-14 07:44:48,952 [INFO    ] __main__: train step 22769: loss: 0.9368, policy_loss: 0.8725, value_loss: 0.4072
2024-07-14 07:44:49,268 [INFO    ] __main__: train step 22770: loss: 0.9367, policy_loss: 0.8725, value_loss: 0.4072
2024-07-14 07:44:49,583 [INFO    ] __main__: train step 22771: loss: 0.9367, policy_loss: 0.8725, value_loss: 0.4072
2024-07-14 07:44:49,889 [INFO    ] __main__: train step 22772: loss: 0.9367, policy_loss: 0.8725, value_loss: 0.4072
2024-07-14 07:44:50,187 [INFO    ] __main__: train step 22773: loss: 0.9367, policy_loss: 0.8725, value_loss: 0.4072
2024-07-14 07:44:50,491 [INFO    ] __main__: train step 22774: loss: 0.9367, policy_loss: 0.8724, value_loss: 0.4071
2024-07-14 07:44:50,799 [INFO    ] __main__: train step 22775: loss: 0.9367, policy_loss: 0.8724, value_loss: 0.4071
2024-07-14 07:44:51,111 [INFO    ] __main__: train step 22776: loss: 0.9367, policy_loss: 0.8724, value_loss: 0.4071
2024-07-14 07:44:52,760 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:44:53,175 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:44:53,240 [INFO    ] __main__: train step 22777: loss: 0.9367, policy_loss: 0.8724, value_loss: 0.4071
2024-07-14 07:44:53,555 [INFO    ] __main__: train step 22778: loss: 0.9366, policy_loss: 0.8724, value_loss: 0.4071
2024-07-14 07:44:53,853 [INFO    ] __main__: train step 22779: loss: 0.9366, policy_loss: 0.8724, value_loss: 0.4071
2024-07-14 07:44:54,160 [INFO    ] __main__: train step 22780: loss: 0.9366, policy_loss: 0.8724, value_loss: 0.4071
2024-07-14 07:44:54,475 [INFO    ] __main__: train step 22781: loss: 0.9366, policy_loss: 0.8724, value_loss: 0.4070
2024-07-14 07:44:54,776 [INFO    ] __main__: train step 22782: loss: 0.9366, policy_loss: 0.8723, value_loss: 0.4070
2024-07-14 07:44:55,071 [INFO    ] __main__: train step 22783: loss: 0.9366, policy_loss: 0.8723, value_loss: 0.4070
2024-07-14 07:44:55,373 [INFO    ] __main__: train step 22784: loss: 0.9366, policy_loss: 0.8723, value_loss: 0.4070
2024-07-14 07:44:55,656 [INFO    ] __main__: train step 22785: loss: 0.9366, policy_loss: 0.8723, value_loss: 0.4070
2024-07-14 07:44:55,970 [INFO    ] __main__: train step 22786: loss: 0.9365, policy_loss: 0.8723, value_loss: 0.4070
2024-07-14 07:44:56,280 [INFO    ] __main__: train step 22787: loss: 0.9365, policy_loss: 0.8723, value_loss: 0.4070
2024-07-14 07:44:56,564 [INFO    ] __main__: train step 22788: loss: 0.9365, policy_loss: 0.8723, value_loss: 0.4069
2024-07-14 07:44:56,859 [INFO    ] __main__: train step 22789: loss: 0.9365, policy_loss: 0.8723, value_loss: 0.4069
2024-07-14 07:44:57,174 [INFO    ] __main__: train step 22790: loss: 0.9365, policy_loss: 0.8722, value_loss: 0.4069
2024-07-14 07:44:57,496 [INFO    ] __main__: train step 22791: loss: 0.9365, policy_loss: 0.8722, value_loss: 0.4069
2024-07-14 07:44:57,827 [INFO    ] __main__: train step 22792: loss: 0.9365, policy_loss: 0.8722, value_loss: 0.4069
2024-07-14 07:44:58,152 [INFO    ] __main__: train step 22793: loss: 0.9365, policy_loss: 0.8722, value_loss: 0.4069
2024-07-14 07:44:59,789 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:45:00,207 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:45:00,275 [INFO    ] __main__: train step 22794: loss: 0.9365, policy_loss: 0.8722, value_loss: 0.4069
2024-07-14 07:45:00,593 [INFO    ] __main__: train step 22795: loss: 0.9364, policy_loss: 0.8722, value_loss: 0.4068
2024-07-14 07:45:00,900 [INFO    ] __main__: train step 22796: loss: 0.9364, policy_loss: 0.8722, value_loss: 0.4068
2024-07-14 07:45:01,184 [INFO    ] __main__: train step 22797: loss: 0.9364, policy_loss: 0.8722, value_loss: 0.4068
2024-07-14 07:45:01,484 [INFO    ] __main__: train step 22798: loss: 0.9364, policy_loss: 0.8721, value_loss: 0.4068
2024-07-14 07:45:01,810 [INFO    ] __main__: train step 22799: loss: 0.9364, policy_loss: 0.8721, value_loss: 0.4068
2024-07-14 07:45:02,124 [INFO    ] __main__: train step 22800: loss: 0.9364, policy_loss: 0.8721, value_loss: 0.4068
2024-07-14 07:45:02,439 [INFO    ] __main__: train step 22801: loss: 0.9364, policy_loss: 0.8721, value_loss: 0.4068
2024-07-14 07:45:02,756 [INFO    ] __main__: train step 22802: loss: 0.9364, policy_loss: 0.8721, value_loss: 0.4067
2024-07-14 07:45:03,062 [INFO    ] __main__: train step 22803: loss: 0.9364, policy_loss: 0.8721, value_loss: 0.4067
2024-07-14 07:45:03,378 [INFO    ] __main__: train step 22804: loss: 0.9363, policy_loss: 0.8721, value_loss: 0.4067
2024-07-14 07:45:03,693 [INFO    ] __main__: train step 22805: loss: 0.9363, policy_loss: 0.8721, value_loss: 0.4067
2024-07-14 07:45:04,002 [INFO    ] __main__: train step 22806: loss: 0.9363, policy_loss: 0.8720, value_loss: 0.4067
2024-07-14 07:45:04,298 [INFO    ] __main__: train step 22807: loss: 0.9363, policy_loss: 0.8720, value_loss: 0.4067
2024-07-14 07:45:04,590 [INFO    ] __main__: train step 22808: loss: 0.9363, policy_loss: 0.8720, value_loss: 0.4067
2024-07-14 07:45:04,903 [INFO    ] __main__: train step 22809: loss: 0.9363, policy_loss: 0.8720, value_loss: 0.4066
2024-07-14 07:45:05,209 [INFO    ] __main__: train step 22810: loss: 0.9363, policy_loss: 0.8720, value_loss: 0.4066
2024-07-14 07:45:06,827 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:45:07,251 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:45:07,322 [INFO    ] __main__: train step 22811: loss: 0.9363, policy_loss: 0.8720, value_loss: 0.4066
2024-07-14 07:45:07,618 [INFO    ] __main__: train step 22812: loss: 0.9363, policy_loss: 0.8720, value_loss: 0.4066
2024-07-14 07:45:07,925 [INFO    ] __main__: train step 22813: loss: 0.9362, policy_loss: 0.8720, value_loss: 0.4066
2024-07-14 07:45:12,771 [INFO    ] __main__: train step 22814: loss: 0.9362, policy_loss: 0.8719, value_loss: 0.4066
2024-07-14 07:45:13,104 [INFO    ] __main__: train step 22815: loss: 0.9362, policy_loss: 0.8719, value_loss: 0.4066
2024-07-14 07:45:13,381 [INFO    ] __main__: train step 22816: loss: 0.9362, policy_loss: 0.8719, value_loss: 0.4065
2024-07-14 07:45:13,655 [INFO    ] __main__: train step 22817: loss: 0.9362, policy_loss: 0.8719, value_loss: 0.4065
2024-07-14 07:45:13,947 [INFO    ] __main__: train step 22818: loss: 0.9362, policy_loss: 0.8719, value_loss: 0.4065
2024-07-14 07:45:14,250 [INFO    ] __main__: train step 22819: loss: 0.9362, policy_loss: 0.8719, value_loss: 0.4065
2024-07-14 07:45:14,576 [INFO    ] __main__: train step 22820: loss: 0.9362, policy_loss: 0.8719, value_loss: 0.4065
2024-07-14 07:45:14,852 [INFO    ] __main__: train step 22821: loss: 0.9361, policy_loss: 0.8719, value_loss: 0.4065
2024-07-14 07:45:15,120 [INFO    ] __main__: train step 22822: loss: 0.9361, policy_loss: 0.8718, value_loss: 0.4065
2024-07-14 07:45:15,412 [INFO    ] __main__: train step 22823: loss: 0.9361, policy_loss: 0.8718, value_loss: 0.4064
2024-07-14 07:45:15,708 [INFO    ] __main__: train step 22824: loss: 0.9361, policy_loss: 0.8718, value_loss: 0.4064
2024-07-14 07:45:16,023 [INFO    ] __main__: train step 22825: loss: 0.9361, policy_loss: 0.8718, value_loss: 0.4064
2024-07-14 07:45:16,331 [INFO    ] __main__: train step 22826: loss: 0.9361, policy_loss: 0.8718, value_loss: 0.4064
2024-07-14 07:45:16,618 [INFO    ] __main__: train step 22827: loss: 0.9361, policy_loss: 0.8718, value_loss: 0.4064
2024-07-14 07:45:18,246 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:45:18,679 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:45:18,752 [INFO    ] __main__: train step 22828: loss: 0.9361, policy_loss: 0.8718, value_loss: 0.4064
2024-07-14 07:45:19,060 [INFO    ] __main__: train step 22829: loss: 0.9361, policy_loss: 0.8718, value_loss: 0.4064
2024-07-14 07:45:19,368 [INFO    ] __main__: train step 22830: loss: 0.9360, policy_loss: 0.8718, value_loss: 0.4063
2024-07-14 07:45:19,677 [INFO    ] __main__: train step 22831: loss: 0.9360, policy_loss: 0.8717, value_loss: 0.4063
2024-07-14 07:45:19,977 [INFO    ] __main__: train step 22832: loss: 0.9360, policy_loss: 0.8717, value_loss: 0.4063
2024-07-14 07:45:20,295 [INFO    ] __main__: train step 22833: loss: 0.9360, policy_loss: 0.8717, value_loss: 0.4063
2024-07-14 07:45:20,621 [INFO    ] __main__: train step 22834: loss: 0.9360, policy_loss: 0.8717, value_loss: 0.4063
2024-07-14 07:45:20,939 [INFO    ] __main__: train step 22835: loss: 0.9360, policy_loss: 0.8717, value_loss: 0.4063
2024-07-14 07:45:21,236 [INFO    ] __main__: train step 22836: loss: 0.9360, policy_loss: 0.8717, value_loss: 0.4063
2024-07-14 07:45:21,551 [INFO    ] __main__: train step 22837: loss: 0.9360, policy_loss: 0.8717, value_loss: 0.4062
2024-07-14 07:45:21,887 [INFO    ] __main__: train step 22838: loss: 0.9360, policy_loss: 0.8717, value_loss: 0.4062
2024-07-14 07:45:22,191 [INFO    ] __main__: train step 22839: loss: 0.9359, policy_loss: 0.8716, value_loss: 0.4062
2024-07-14 07:45:22,505 [INFO    ] __main__: train step 22840: loss: 0.9359, policy_loss: 0.8716, value_loss: 0.4062
2024-07-14 07:45:22,827 [INFO    ] __main__: train step 22841: loss: 0.9359, policy_loss: 0.8716, value_loss: 0.4062
2024-07-14 07:45:23,143 [INFO    ] __main__: train step 22842: loss: 0.9359, policy_loss: 0.8716, value_loss: 0.4062
2024-07-14 07:45:23,452 [INFO    ] __main__: train step 22843: loss: 0.9359, policy_loss: 0.8716, value_loss: 0.4062
2024-07-14 07:45:23,774 [INFO    ] __main__: train step 22844: loss: 0.9359, policy_loss: 0.8716, value_loss: 0.4062
2024-07-14 07:45:25,391 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:45:25,821 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:45:25,886 [INFO    ] __main__: train step 22845: loss: 0.9359, policy_loss: 0.8716, value_loss: 0.4061
2024-07-14 07:45:26,191 [INFO    ] __main__: train step 22846: loss: 0.9359, policy_loss: 0.8716, value_loss: 0.4061
2024-07-14 07:45:26,485 [INFO    ] __main__: train step 22847: loss: 0.9359, policy_loss: 0.8715, value_loss: 0.4061
2024-07-14 07:45:26,782 [INFO    ] __main__: train step 22848: loss: 0.9358, policy_loss: 0.8715, value_loss: 0.4061
2024-07-14 07:45:27,096 [INFO    ] __main__: train step 22849: loss: 0.9358, policy_loss: 0.8715, value_loss: 0.4061
2024-07-14 07:45:27,401 [INFO    ] __main__: train step 22850: loss: 0.9358, policy_loss: 0.8715, value_loss: 0.4061
2024-07-14 07:45:27,721 [INFO    ] __main__: train step 22851: loss: 0.9358, policy_loss: 0.8715, value_loss: 0.4061
2024-07-14 07:45:28,033 [INFO    ] __main__: train step 22852: loss: 0.9358, policy_loss: 0.8715, value_loss: 0.4060
2024-07-14 07:45:28,348 [INFO    ] __main__: train step 22853: loss: 0.9358, policy_loss: 0.8715, value_loss: 0.4060
2024-07-14 07:45:28,664 [INFO    ] __main__: train step 22854: loss: 0.9358, policy_loss: 0.8715, value_loss: 0.4060
2024-07-14 07:45:28,979 [INFO    ] __main__: train step 22855: loss: 0.9358, policy_loss: 0.8714, value_loss: 0.4060
2024-07-14 07:45:29,274 [INFO    ] __main__: train step 22856: loss: 0.9358, policy_loss: 0.8714, value_loss: 0.4060
2024-07-14 07:45:29,580 [INFO    ] __main__: train step 22857: loss: 0.9357, policy_loss: 0.8714, value_loss: 0.4060
2024-07-14 07:45:29,891 [INFO    ] __main__: train step 22858: loss: 0.9357, policy_loss: 0.8714, value_loss: 0.4060
2024-07-14 07:45:30,218 [INFO    ] __main__: train step 22859: loss: 0.9357, policy_loss: 0.8714, value_loss: 0.4059
2024-07-14 07:45:30,538 [INFO    ] __main__: train step 22860: loss: 0.9357, policy_loss: 0.8714, value_loss: 0.4059
2024-07-14 07:45:30,837 [INFO    ] __main__: train step 22861: loss: 0.9357, policy_loss: 0.8714, value_loss: 0.4059
2024-07-14 07:45:32,457 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:45:32,887 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:45:32,956 [INFO    ] __main__: train step 22862: loss: 0.9357, policy_loss: 0.8714, value_loss: 0.4059
2024-07-14 07:45:33,255 [INFO    ] __main__: train step 22863: loss: 0.9357, policy_loss: 0.8713, value_loss: 0.4059
2024-07-14 07:45:33,570 [INFO    ] __main__: train step 22864: loss: 0.9357, policy_loss: 0.8713, value_loss: 0.4059
2024-07-14 07:45:33,866 [INFO    ] __main__: train step 22865: loss: 0.9357, policy_loss: 0.8713, value_loss: 0.4059
2024-07-14 07:45:34,152 [INFO    ] __main__: train step 22866: loss: 0.9356, policy_loss: 0.8713, value_loss: 0.4058
2024-07-14 07:45:34,457 [INFO    ] __main__: train step 22867: loss: 0.9356, policy_loss: 0.8713, value_loss: 0.4058
2024-07-14 07:45:34,772 [INFO    ] __main__: train step 22868: loss: 0.9356, policy_loss: 0.8713, value_loss: 0.4058
2024-07-14 07:45:35,091 [INFO    ] __main__: train step 22869: loss: 0.9356, policy_loss: 0.8713, value_loss: 0.4058
2024-07-14 07:45:35,404 [INFO    ] __main__: train step 22870: loss: 0.9356, policy_loss: 0.8713, value_loss: 0.4058
2024-07-14 07:45:35,680 [INFO    ] __main__: train step 22871: loss: 0.9356, policy_loss: 0.8713, value_loss: 0.4058
2024-07-14 07:45:35,980 [INFO    ] __main__: train step 22872: loss: 0.9356, policy_loss: 0.8712, value_loss: 0.4058
2024-07-14 07:45:36,272 [INFO    ] __main__: train step 22873: loss: 0.9356, policy_loss: 0.8712, value_loss: 0.4057
2024-07-14 07:45:36,583 [INFO    ] __main__: train step 22874: loss: 0.9356, policy_loss: 0.8712, value_loss: 0.4057
2024-07-14 07:45:36,889 [INFO    ] __main__: train step 22875: loss: 0.9355, policy_loss: 0.8712, value_loss: 0.4057
2024-07-14 07:45:37,196 [INFO    ] __main__: train step 22876: loss: 0.9355, policy_loss: 0.8712, value_loss: 0.4057
2024-07-14 07:45:37,489 [INFO    ] __main__: train step 22877: loss: 0.9355, policy_loss: 0.8712, value_loss: 0.4057
2024-07-14 07:45:37,798 [INFO    ] __main__: train step 22878: loss: 0.9355, policy_loss: 0.8712, value_loss: 0.4057
2024-07-14 07:45:39,444 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:45:39,878 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:45:39,948 [INFO    ] __main__: train step 22879: loss: 0.9355, policy_loss: 0.8712, value_loss: 0.4057
2024-07-14 07:45:40,248 [INFO    ] __main__: train step 22880: loss: 0.9355, policy_loss: 0.8711, value_loss: 0.4057
2024-07-14 07:45:40,564 [INFO    ] __main__: train step 22881: loss: 0.9355, policy_loss: 0.8711, value_loss: 0.4056
2024-07-14 07:45:40,863 [INFO    ] __main__: train step 22882: loss: 0.9355, policy_loss: 0.8711, value_loss: 0.4056
2024-07-14 07:45:41,188 [INFO    ] __main__: train step 22883: loss: 0.9355, policy_loss: 0.8711, value_loss: 0.4056
2024-07-14 07:45:41,498 [INFO    ] __main__: train step 22884: loss: 0.9354, policy_loss: 0.8711, value_loss: 0.4056
2024-07-14 07:45:41,811 [INFO    ] __main__: train step 22885: loss: 0.9354, policy_loss: 0.8711, value_loss: 0.4056
2024-07-14 07:45:42,118 [INFO    ] __main__: train step 22886: loss: 0.9354, policy_loss: 0.8711, value_loss: 0.4056
2024-07-14 07:45:42,396 [INFO    ] __main__: train step 22887: loss: 0.9354, policy_loss: 0.8711, value_loss: 0.4056
2024-07-14 07:45:42,672 [INFO    ] __main__: train step 22888: loss: 0.9354, policy_loss: 0.8710, value_loss: 0.4055
2024-07-14 07:45:42,978 [INFO    ] __main__: train step 22889: loss: 0.9354, policy_loss: 0.8710, value_loss: 0.4055
2024-07-14 07:45:43,278 [INFO    ] __main__: train step 22890: loss: 0.9354, policy_loss: 0.8710, value_loss: 0.4055
2024-07-14 07:45:43,568 [INFO    ] __main__: train step 22891: loss: 0.9354, policy_loss: 0.8710, value_loss: 0.4055
2024-07-14 07:45:43,893 [INFO    ] __main__: train step 22892: loss: 0.9354, policy_loss: 0.8710, value_loss: 0.4055
2024-07-14 07:45:44,207 [INFO    ] __main__: train step 22893: loss: 0.9353, policy_loss: 0.8710, value_loss: 0.4055
2024-07-14 07:45:44,529 [INFO    ] __main__: train step 22894: loss: 0.9353, policy_loss: 0.8710, value_loss: 0.4055
2024-07-14 07:45:44,851 [INFO    ] __main__: train step 22895: loss: 0.9353, policy_loss: 0.8710, value_loss: 0.4054
2024-07-14 07:45:46,484 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:45:46,967 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:45:47,034 [INFO    ] __main__: train step 22896: loss: 0.9353, policy_loss: 0.8710, value_loss: 0.4054
2024-07-14 07:45:47,340 [INFO    ] __main__: train step 22897: loss: 0.9353, policy_loss: 0.8709, value_loss: 0.4054
2024-07-14 07:45:47,648 [INFO    ] __main__: train step 22898: loss: 0.9353, policy_loss: 0.8709, value_loss: 0.4054
2024-07-14 07:45:47,955 [INFO    ] __main__: train step 22899: loss: 0.9353, policy_loss: 0.8709, value_loss: 0.4054
2024-07-14 07:45:48,268 [INFO    ] __main__: train step 22900: loss: 0.9353, policy_loss: 0.8709, value_loss: 0.4054
2024-07-14 07:45:48,572 [INFO    ] __main__: train step 22901: loss: 0.9353, policy_loss: 0.8709, value_loss: 0.4054
2024-07-14 07:45:48,880 [INFO    ] __main__: train step 22902: loss: 0.9352, policy_loss: 0.8709, value_loss: 0.4053
2024-07-14 07:45:49,176 [INFO    ] __main__: train step 22903: loss: 0.9352, policy_loss: 0.8709, value_loss: 0.4053
2024-07-14 07:45:49,484 [INFO    ] __main__: train step 22904: loss: 0.9352, policy_loss: 0.8709, value_loss: 0.4053
2024-07-14 07:45:49,805 [INFO    ] __main__: train step 22905: loss: 0.9352, policy_loss: 0.8708, value_loss: 0.4053
2024-07-14 07:45:50,103 [INFO    ] __main__: train step 22906: loss: 0.9352, policy_loss: 0.8708, value_loss: 0.4053
2024-07-14 07:45:50,404 [INFO    ] __main__: train step 22907: loss: 0.9352, policy_loss: 0.8708, value_loss: 0.4053
2024-07-14 07:45:50,711 [INFO    ] __main__: train step 22908: loss: 0.9352, policy_loss: 0.8708, value_loss: 0.4053
2024-07-14 07:45:51,021 [INFO    ] __main__: train step 22909: loss: 0.9352, policy_loss: 0.8708, value_loss: 0.4053
2024-07-14 07:45:51,327 [INFO    ] __main__: train step 22910: loss: 0.9352, policy_loss: 0.8708, value_loss: 0.4052
2024-07-14 07:45:51,616 [INFO    ] __main__: train step 22911: loss: 0.9352, policy_loss: 0.8708, value_loss: 0.4052
2024-07-14 07:45:51,892 [INFO    ] __main__: train step 22912: loss: 0.9351, policy_loss: 0.8708, value_loss: 0.4052
2024-07-14 07:45:53,499 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:45:53,927 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:45:53,995 [INFO    ] __main__: train step 22913: loss: 0.9351, policy_loss: 0.8707, value_loss: 0.4052
2024-07-14 07:45:54,311 [INFO    ] __main__: train step 22914: loss: 0.9351, policy_loss: 0.8707, value_loss: 0.4052
2024-07-14 07:45:54,607 [INFO    ] __main__: train step 22915: loss: 0.9351, policy_loss: 0.8707, value_loss: 0.4052
2024-07-14 07:45:54,913 [INFO    ] __main__: train step 22916: loss: 0.9351, policy_loss: 0.8707, value_loss: 0.4052
2024-07-14 07:45:55,226 [INFO    ] __main__: train step 22917: loss: 0.9351, policy_loss: 0.8707, value_loss: 0.4051
2024-07-14 07:45:55,527 [INFO    ] __main__: train step 22918: loss: 0.9351, policy_loss: 0.8707, value_loss: 0.4051
2024-07-14 07:45:55,826 [INFO    ] __main__: train step 22919: loss: 0.9351, policy_loss: 0.8707, value_loss: 0.4051
2024-07-14 07:45:56,125 [INFO    ] __main__: train step 22920: loss: 0.9351, policy_loss: 0.8707, value_loss: 0.4051
2024-07-14 07:45:56,387 [INFO    ] __main__: train step 22921: loss: 0.9350, policy_loss: 0.8707, value_loss: 0.4051
2024-07-14 07:45:56,661 [INFO    ] __main__: train step 22922: loss: 0.9350, policy_loss: 0.8706, value_loss: 0.4051
2024-07-14 07:45:56,948 [INFO    ] __main__: train step 22923: loss: 0.9350, policy_loss: 0.8706, value_loss: 0.4051
2024-07-14 07:45:57,264 [INFO    ] __main__: train step 22924: loss: 0.9350, policy_loss: 0.8706, value_loss: 0.4050
2024-07-14 07:45:57,569 [INFO    ] __main__: train step 22925: loss: 0.9350, policy_loss: 0.8706, value_loss: 0.4050
2024-07-14 07:45:57,871 [INFO    ] __main__: train step 22926: loss: 0.9350, policy_loss: 0.8706, value_loss: 0.4050
2024-07-14 07:45:58,163 [INFO    ] __main__: train step 22927: loss: 0.9350, policy_loss: 0.8706, value_loss: 0.4050
2024-07-14 07:45:58,467 [INFO    ] __main__: train step 22928: loss: 0.9350, policy_loss: 0.8706, value_loss: 0.4050
2024-07-14 07:45:58,780 [INFO    ] __main__: train step 22929: loss: 0.9350, policy_loss: 0.8706, value_loss: 0.4050
2024-07-14 07:46:00,435 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:46:00,886 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:46:00,961 [INFO    ] __main__: train step 22930: loss: 0.9349, policy_loss: 0.8705, value_loss: 0.4050
2024-07-14 07:46:01,264 [INFO    ] __main__: train step 22931: loss: 0.9349, policy_loss: 0.8705, value_loss: 0.4049
2024-07-14 07:46:01,567 [INFO    ] __main__: train step 22932: loss: 0.9349, policy_loss: 0.8705, value_loss: 0.4049
2024-07-14 07:46:01,874 [INFO    ] __main__: train step 22933: loss: 0.9349, policy_loss: 0.8705, value_loss: 0.4049
2024-07-14 07:46:02,200 [INFO    ] __main__: train step 22934: loss: 0.9349, policy_loss: 0.8705, value_loss: 0.4049
2024-07-14 07:46:02,490 [INFO    ] __main__: train step 22935: loss: 0.9349, policy_loss: 0.8705, value_loss: 0.4049
2024-07-14 07:46:02,780 [INFO    ] __main__: train step 22936: loss: 0.9349, policy_loss: 0.8705, value_loss: 0.4049
2024-07-14 07:46:03,066 [INFO    ] __main__: train step 22937: loss: 0.9349, policy_loss: 0.8705, value_loss: 0.4049
2024-07-14 07:46:03,342 [INFO    ] __main__: train step 22938: loss: 0.9349, policy_loss: 0.8704, value_loss: 0.4048
2024-07-14 07:46:03,630 [INFO    ] __main__: train step 22939: loss: 0.9348, policy_loss: 0.8704, value_loss: 0.4048
2024-07-14 07:46:08,508 [INFO    ] __main__: train step 22940: loss: 0.9348, policy_loss: 0.8704, value_loss: 0.4048
2024-07-14 07:46:08,782 [INFO    ] __main__: train step 22941: loss: 0.9348, policy_loss: 0.8704, value_loss: 0.4048
2024-07-14 07:46:09,070 [INFO    ] __main__: train step 22942: loss: 0.9348, policy_loss: 0.8704, value_loss: 0.4048
2024-07-14 07:46:09,384 [INFO    ] __main__: train step 22943: loss: 0.9348, policy_loss: 0.8704, value_loss: 0.4048
2024-07-14 07:46:09,684 [INFO    ] __main__: train step 22944: loss: 0.9348, policy_loss: 0.8704, value_loss: 0.4048
2024-07-14 07:46:09,987 [INFO    ] __main__: train step 22945: loss: 0.9348, policy_loss: 0.8704, value_loss: 0.4048
2024-07-14 07:46:10,297 [INFO    ] __main__: train step 22946: loss: 0.9348, policy_loss: 0.8704, value_loss: 0.4047
2024-07-14 07:46:11,930 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:46:12,351 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:46:12,420 [INFO    ] __main__: train step 22947: loss: 0.9348, policy_loss: 0.8703, value_loss: 0.4047
2024-07-14 07:46:12,723 [INFO    ] __main__: train step 22948: loss: 0.9348, policy_loss: 0.8703, value_loss: 0.4047
2024-07-14 07:46:13,032 [INFO    ] __main__: train step 22949: loss: 0.9347, policy_loss: 0.8703, value_loss: 0.4047
2024-07-14 07:46:13,355 [INFO    ] __main__: train step 22950: loss: 0.9347, policy_loss: 0.8703, value_loss: 0.4047
2024-07-14 07:46:13,658 [INFO    ] __main__: train step 22951: loss: 0.9347, policy_loss: 0.8703, value_loss: 0.4047
2024-07-14 07:46:13,942 [INFO    ] __main__: train step 22952: loss: 0.9347, policy_loss: 0.8703, value_loss: 0.4047
2024-07-14 07:46:14,235 [INFO    ] __main__: train step 22953: loss: 0.9347, policy_loss: 0.8703, value_loss: 0.4046
2024-07-14 07:46:14,539 [INFO    ] __main__: train step 22954: loss: 0.9347, policy_loss: 0.8703, value_loss: 0.4046
2024-07-14 07:46:14,848 [INFO    ] __main__: train step 22955: loss: 0.9347, policy_loss: 0.8702, value_loss: 0.4046
2024-07-14 07:46:15,142 [INFO    ] __main__: train step 22956: loss: 0.9347, policy_loss: 0.8702, value_loss: 0.4046
2024-07-14 07:46:15,433 [INFO    ] __main__: train step 22957: loss: 0.9347, policy_loss: 0.8702, value_loss: 0.4046
2024-07-14 07:46:15,731 [INFO    ] __main__: train step 22958: loss: 0.9346, policy_loss: 0.8702, value_loss: 0.4046
2024-07-14 07:46:16,043 [INFO    ] __main__: train step 22959: loss: 0.9346, policy_loss: 0.8702, value_loss: 0.4046
2024-07-14 07:46:16,335 [INFO    ] __main__: train step 22960: loss: 0.9346, policy_loss: 0.8702, value_loss: 0.4045
2024-07-14 07:46:16,620 [INFO    ] __main__: train step 22961: loss: 0.9346, policy_loss: 0.8702, value_loss: 0.4045
2024-07-14 07:46:16,893 [INFO    ] __main__: train step 22962: loss: 0.9346, policy_loss: 0.8702, value_loss: 0.4045
2024-07-14 07:46:17,157 [INFO    ] __main__: train step 22963: loss: 0.9346, policy_loss: 0.8702, value_loss: 0.4045
2024-07-14 07:46:18,759 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:46:19,175 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:46:19,241 [INFO    ] __main__: train step 22964: loss: 0.9346, policy_loss: 0.8701, value_loss: 0.4045
2024-07-14 07:46:19,513 [INFO    ] __main__: train step 22965: loss: 0.9346, policy_loss: 0.8701, value_loss: 0.4045
2024-07-14 07:46:19,789 [INFO    ] __main__: train step 22966: loss: 0.9346, policy_loss: 0.8701, value_loss: 0.4045
2024-07-14 07:46:20,077 [INFO    ] __main__: train step 22967: loss: 0.9345, policy_loss: 0.8701, value_loss: 0.4045
2024-07-14 07:46:20,382 [INFO    ] __main__: train step 22968: loss: 0.9345, policy_loss: 0.8701, value_loss: 0.4044
2024-07-14 07:46:20,677 [INFO    ] __main__: train step 22969: loss: 0.9345, policy_loss: 0.8701, value_loss: 0.4044
2024-07-14 07:46:20,985 [INFO    ] __main__: train step 22970: loss: 0.9345, policy_loss: 0.8701, value_loss: 0.4044
2024-07-14 07:46:21,283 [INFO    ] __main__: train step 22971: loss: 0.9345, policy_loss: 0.8701, value_loss: 0.4044
2024-07-14 07:46:21,562 [INFO    ] __main__: train step 22972: loss: 0.9345, policy_loss: 0.8700, value_loss: 0.4044
2024-07-14 07:46:21,860 [INFO    ] __main__: train step 22973: loss: 0.9345, policy_loss: 0.8700, value_loss: 0.4044
2024-07-14 07:46:22,159 [INFO    ] __main__: train step 22974: loss: 0.9345, policy_loss: 0.8700, value_loss: 0.4044
2024-07-14 07:46:22,443 [INFO    ] __main__: train step 22975: loss: 0.9345, policy_loss: 0.8700, value_loss: 0.4043
2024-07-14 07:46:22,734 [INFO    ] __main__: train step 22976: loss: 0.9345, policy_loss: 0.8700, value_loss: 0.4043
2024-07-14 07:46:23,017 [INFO    ] __main__: train step 22977: loss: 0.9344, policy_loss: 0.8700, value_loss: 0.4043
2024-07-14 07:46:23,286 [INFO    ] __main__: train step 22978: loss: 0.9344, policy_loss: 0.8700, value_loss: 0.4043
2024-07-14 07:46:23,564 [INFO    ] __main__: train step 22979: loss: 0.9344, policy_loss: 0.8700, value_loss: 0.4043
2024-07-14 07:46:23,847 [INFO    ] __main__: train step 22980: loss: 0.9344, policy_loss: 0.8700, value_loss: 0.4043
2024-07-14 07:46:25,451 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:46:25,938 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:46:26,012 [INFO    ] __main__: train step 22981: loss: 0.9344, policy_loss: 0.8699, value_loss: 0.4043
2024-07-14 07:46:26,325 [INFO    ] __main__: train step 22982: loss: 0.9344, policy_loss: 0.8699, value_loss: 0.4043
2024-07-14 07:46:26,597 [INFO    ] __main__: train step 22983: loss: 0.9344, policy_loss: 0.8699, value_loss: 0.4042
2024-07-14 07:46:26,928 [INFO    ] __main__: train step 22984: loss: 0.9344, policy_loss: 0.8699, value_loss: 0.4042
2024-07-14 07:46:27,239 [INFO    ] __main__: train step 22985: loss: 0.9344, policy_loss: 0.8699, value_loss: 0.4042
2024-07-14 07:46:27,551 [INFO    ] __main__: train step 22986: loss: 0.9343, policy_loss: 0.8699, value_loss: 0.4042
2024-07-14 07:46:27,845 [INFO    ] __main__: train step 22987: loss: 0.9343, policy_loss: 0.8699, value_loss: 0.4042
2024-07-14 07:46:28,122 [INFO    ] __main__: train step 22988: loss: 0.9343, policy_loss: 0.8699, value_loss: 0.4042
2024-07-14 07:46:28,435 [INFO    ] __main__: train step 22989: loss: 0.9343, policy_loss: 0.8698, value_loss: 0.4042
2024-07-14 07:46:28,748 [INFO    ] __main__: train step 22990: loss: 0.9343, policy_loss: 0.8698, value_loss: 0.4041
2024-07-14 07:46:29,051 [INFO    ] __main__: train step 22991: loss: 0.9343, policy_loss: 0.8698, value_loss: 0.4041
2024-07-14 07:46:29,364 [INFO    ] __main__: train step 22992: loss: 0.9343, policy_loss: 0.8698, value_loss: 0.4041
2024-07-14 07:46:29,658 [INFO    ] __main__: train step 22993: loss: 0.9343, policy_loss: 0.8698, value_loss: 0.4041
2024-07-14 07:46:29,963 [INFO    ] __main__: train step 22994: loss: 0.9343, policy_loss: 0.8698, value_loss: 0.4041
2024-07-14 07:46:30,275 [INFO    ] __main__: train step 22995: loss: 0.9343, policy_loss: 0.8698, value_loss: 0.4041
2024-07-14 07:46:30,583 [INFO    ] __main__: train step 22996: loss: 0.9342, policy_loss: 0.8698, value_loss: 0.4041
2024-07-14 07:46:30,898 [INFO    ] __main__: train step 22997: loss: 0.9342, policy_loss: 0.8698, value_loss: 0.4040
2024-07-14 07:46:32,537 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:46:32,987 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:46:33,053 [INFO    ] __main__: train step 22998: loss: 0.9342, policy_loss: 0.8697, value_loss: 0.4040
2024-07-14 07:46:33,359 [INFO    ] __main__: train step 22999: loss: 0.9342, policy_loss: 0.8697, value_loss: 0.4040
2024-07-14 07:46:33,666 [INFO    ] __main__: train step 23000: loss: 0.9342, policy_loss: 0.8697, value_loss: 0.4040
2024-07-14 07:46:33,831 [INFO    ] __main__: restored step 22000 for evaluation
2024-07-14 07:46:39,078 [INFO    ] __main__: test network ELO difference from baseline network: +18 (+8/-8) ELO from 32000 self-played games
2024-07-14 07:46:39,086 [INFO    ] __main__: game outcomes: W: 16541, D: 314, L: 15145
2024-07-14 07:46:39,090 [INFO    ] __main__: validation_elo_delta: 18, validation_elo: 2968
2024-07-14 07:46:39,865 [INFO    ] __main__: train step 23001: loss: 0.9342, policy_loss: 0.8697, value_loss: 0.4040
2024-07-14 07:46:40,161 [INFO    ] __main__: train step 23002: loss: 0.9342, policy_loss: 0.8697, value_loss: 0.4040
2024-07-14 07:46:40,475 [INFO    ] __main__: train step 23003: loss: 0.9342, policy_loss: 0.8697, value_loss: 0.4040
2024-07-14 07:46:40,767 [INFO    ] __main__: train step 23004: loss: 0.9342, policy_loss: 0.8697, value_loss: 0.4040
2024-07-14 07:46:41,078 [INFO    ] __main__: train step 23005: loss: 0.9342, policy_loss: 0.8697, value_loss: 0.4039
2024-07-14 07:46:41,391 [INFO    ] __main__: train step 23006: loss: 0.9341, policy_loss: 0.8697, value_loss: 0.4039
2024-07-14 07:46:41,698 [INFO    ] __main__: train step 23007: loss: 0.9341, policy_loss: 0.8696, value_loss: 0.4039
2024-07-14 07:46:42,009 [INFO    ] __main__: train step 23008: loss: 0.9341, policy_loss: 0.8696, value_loss: 0.4039
2024-07-14 07:46:42,326 [INFO    ] __main__: train step 23009: loss: 0.9341, policy_loss: 0.8696, value_loss: 0.4039
2024-07-14 07:46:42,610 [INFO    ] __main__: train step 23010: loss: 0.9341, policy_loss: 0.8696, value_loss: 0.4039
2024-07-14 07:46:42,923 [INFO    ] __main__: train step 23011: loss: 0.9341, policy_loss: 0.8696, value_loss: 0.4039
2024-07-14 07:46:43,217 [INFO    ] __main__: train step 23012: loss: 0.9341, policy_loss: 0.8696, value_loss: 0.4038
2024-07-14 07:46:43,532 [INFO    ] __main__: train step 23013: loss: 0.9341, policy_loss: 0.8696, value_loss: 0.4038
2024-07-14 07:46:43,830 [INFO    ] __main__: train step 23014: loss: 0.9341, policy_loss: 0.8696, value_loss: 0.4038
2024-07-14 07:46:45,450 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:46:45,880 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:46:45,948 [INFO    ] __main__: train step 23015: loss: 0.9340, policy_loss: 0.8695, value_loss: 0.4038
2024-07-14 07:46:46,218 [INFO    ] __main__: train step 23016: loss: 0.9340, policy_loss: 0.8695, value_loss: 0.4038
2024-07-14 07:46:46,514 [INFO    ] __main__: train step 23017: loss: 0.9340, policy_loss: 0.8695, value_loss: 0.4038
2024-07-14 07:46:46,817 [INFO    ] __main__: train step 23018: loss: 0.9340, policy_loss: 0.8695, value_loss: 0.4038
2024-07-14 07:46:47,094 [INFO    ] __main__: train step 23019: loss: 0.9340, policy_loss: 0.8695, value_loss: 0.4038
2024-07-14 07:46:47,407 [INFO    ] __main__: train step 23020: loss: 0.9340, policy_loss: 0.8695, value_loss: 0.4037
2024-07-14 07:46:47,706 [INFO    ] __main__: train step 23021: loss: 0.9340, policy_loss: 0.8695, value_loss: 0.4037
2024-07-14 07:46:48,015 [INFO    ] __main__: train step 23022: loss: 0.9340, policy_loss: 0.8695, value_loss: 0.4037
2024-07-14 07:46:48,324 [INFO    ] __main__: train step 23023: loss: 0.9340, policy_loss: 0.8695, value_loss: 0.4037
2024-07-14 07:46:48,647 [INFO    ] __main__: train step 23024: loss: 0.9340, policy_loss: 0.8694, value_loss: 0.4037
2024-07-14 07:46:48,951 [INFO    ] __main__: train step 23025: loss: 0.9339, policy_loss: 0.8694, value_loss: 0.4037
2024-07-14 07:46:49,250 [INFO    ] __main__: train step 23026: loss: 0.9339, policy_loss: 0.8694, value_loss: 0.4037
2024-07-14 07:46:49,526 [INFO    ] __main__: train step 23027: loss: 0.9339, policy_loss: 0.8694, value_loss: 0.4036
2024-07-14 07:46:49,818 [INFO    ] __main__: train step 23028: loss: 0.9339, policy_loss: 0.8694, value_loss: 0.4036
2024-07-14 07:46:50,115 [INFO    ] __main__: train step 23029: loss: 0.9339, policy_loss: 0.8694, value_loss: 0.4036
2024-07-14 07:46:50,388 [INFO    ] __main__: train step 23030: loss: 0.9339, policy_loss: 0.8694, value_loss: 0.4036
2024-07-14 07:46:50,660 [INFO    ] __main__: train step 23031: loss: 0.9339, policy_loss: 0.8694, value_loss: 0.4036
2024-07-14 07:46:52,293 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:46:52,715 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:46:52,789 [INFO    ] __main__: train step 23032: loss: 0.9339, policy_loss: 0.8693, value_loss: 0.4036
2024-07-14 07:46:53,071 [INFO    ] __main__: train step 23033: loss: 0.9339, policy_loss: 0.8693, value_loss: 0.4036
2024-07-14 07:46:53,342 [INFO    ] __main__: train step 23034: loss: 0.9339, policy_loss: 0.8693, value_loss: 0.4035
2024-07-14 07:46:53,603 [INFO    ] __main__: train step 23035: loss: 0.9338, policy_loss: 0.8693, value_loss: 0.4035
2024-07-14 07:46:53,897 [INFO    ] __main__: train step 23036: loss: 0.9338, policy_loss: 0.8693, value_loss: 0.4035
2024-07-14 07:46:54,195 [INFO    ] __main__: train step 23037: loss: 0.9338, policy_loss: 0.8693, value_loss: 0.4035
2024-07-14 07:46:54,504 [INFO    ] __main__: train step 23038: loss: 0.9338, policy_loss: 0.8693, value_loss: 0.4035
2024-07-14 07:46:54,811 [INFO    ] __main__: train step 23039: loss: 0.9338, policy_loss: 0.8693, value_loss: 0.4035
2024-07-14 07:46:55,116 [INFO    ] __main__: train step 23040: loss: 0.9338, policy_loss: 0.8693, value_loss: 0.4035
2024-07-14 07:46:55,423 [INFO    ] __main__: train step 23041: loss: 0.9338, policy_loss: 0.8692, value_loss: 0.4035
2024-07-14 07:46:55,746 [INFO    ] __main__: train step 23042: loss: 0.9338, policy_loss: 0.8692, value_loss: 0.4034
2024-07-14 07:46:56,058 [INFO    ] __main__: train step 23043: loss: 0.9338, policy_loss: 0.8692, value_loss: 0.4034
2024-07-14 07:46:56,347 [INFO    ] __main__: train step 23044: loss: 0.9337, policy_loss: 0.8692, value_loss: 0.4034
2024-07-14 07:46:56,623 [INFO    ] __main__: train step 23045: loss: 0.9337, policy_loss: 0.8692, value_loss: 0.4034
2024-07-14 07:46:56,948 [INFO    ] __main__: train step 23046: loss: 0.9337, policy_loss: 0.8692, value_loss: 0.4034
2024-07-14 07:46:57,251 [INFO    ] __main__: train step 23047: loss: 0.9337, policy_loss: 0.8692, value_loss: 0.4034
2024-07-14 07:46:57,578 [INFO    ] __main__: train step 23048: loss: 0.9337, policy_loss: 0.8692, value_loss: 0.4034
2024-07-14 07:46:59,186 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:46:59,606 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:46:59,672 [INFO    ] __main__: train step 23049: loss: 0.9337, policy_loss: 0.8692, value_loss: 0.4033
2024-07-14 07:46:59,946 [INFO    ] __main__: train step 23050: loss: 0.9337, policy_loss: 0.8691, value_loss: 0.4033
2024-07-14 07:47:00,241 [INFO    ] __main__: train step 23051: loss: 0.9337, policy_loss: 0.8691, value_loss: 0.4033
2024-07-14 07:47:00,546 [INFO    ] __main__: train step 23052: loss: 0.9337, policy_loss: 0.8691, value_loss: 0.4033
2024-07-14 07:47:00,849 [INFO    ] __main__: train step 23053: loss: 0.9337, policy_loss: 0.8691, value_loss: 0.4033
2024-07-14 07:47:01,167 [INFO    ] __main__: train step 23054: loss: 0.9336, policy_loss: 0.8691, value_loss: 0.4033
2024-07-14 07:47:01,462 [INFO    ] __main__: train step 23055: loss: 0.9336, policy_loss: 0.8691, value_loss: 0.4033
2024-07-14 07:47:01,772 [INFO    ] __main__: train step 23056: loss: 0.9336, policy_loss: 0.8691, value_loss: 0.4033
2024-07-14 07:47:02,074 [INFO    ] __main__: train step 23057: loss: 0.9336, policy_loss: 0.8691, value_loss: 0.4032
2024-07-14 07:47:02,372 [INFO    ] __main__: train step 23058: loss: 0.9336, policy_loss: 0.8691, value_loss: 0.4032
2024-07-14 07:47:02,665 [INFO    ] __main__: train step 23059: loss: 0.9336, policy_loss: 0.8690, value_loss: 0.4032
2024-07-14 07:47:02,961 [INFO    ] __main__: train step 23060: loss: 0.9336, policy_loss: 0.8690, value_loss: 0.4032
2024-07-14 07:47:03,251 [INFO    ] __main__: train step 23061: loss: 0.9336, policy_loss: 0.8690, value_loss: 0.4032
2024-07-14 07:47:03,544 [INFO    ] __main__: train step 23062: loss: 0.9336, policy_loss: 0.8690, value_loss: 0.4032
2024-07-14 07:47:03,839 [INFO    ] __main__: train step 23063: loss: 0.9336, policy_loss: 0.8690, value_loss: 0.4032
2024-07-14 07:47:04,149 [INFO    ] __main__: train step 23064: loss: 0.9335, policy_loss: 0.8690, value_loss: 0.4031
2024-07-14 07:47:04,447 [INFO    ] __main__: train step 23065: loss: 0.9335, policy_loss: 0.8690, value_loss: 0.4031
2024-07-14 07:47:06,058 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:47:06,485 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:47:06,551 [INFO    ] __main__: train step 23066: loss: 0.9335, policy_loss: 0.8690, value_loss: 0.4031
2024-07-14 07:47:06,861 [INFO    ] __main__: train step 23067: loss: 0.9335, policy_loss: 0.8689, value_loss: 0.4031
2024-07-14 07:47:07,167 [INFO    ] __main__: train step 23068: loss: 0.9335, policy_loss: 0.8689, value_loss: 0.4031
2024-07-14 07:47:11,456 [INFO    ] __main__: train step 23069: loss: 0.9335, policy_loss: 0.8689, value_loss: 0.4031
2024-07-14 07:47:11,774 [INFO    ] __main__: train step 23070: loss: 0.9335, policy_loss: 0.8689, value_loss: 0.4031
2024-07-14 07:47:12,081 [INFO    ] __main__: train step 23071: loss: 0.9335, policy_loss: 0.8689, value_loss: 0.4031
2024-07-14 07:47:12,397 [INFO    ] __main__: train step 23072: loss: 0.9335, policy_loss: 0.8689, value_loss: 0.4030
2024-07-14 07:47:12,687 [INFO    ] __main__: train step 23073: loss: 0.9335, policy_loss: 0.8689, value_loss: 0.4030
2024-07-14 07:47:12,983 [INFO    ] __main__: train step 23074: loss: 0.9334, policy_loss: 0.8689, value_loss: 0.4030
2024-07-14 07:47:13,288 [INFO    ] __main__: train step 23075: loss: 0.9334, policy_loss: 0.8689, value_loss: 0.4030
2024-07-14 07:47:13,597 [INFO    ] __main__: train step 23076: loss: 0.9334, policy_loss: 0.8688, value_loss: 0.4030
2024-07-14 07:47:13,888 [INFO    ] __main__: train step 23077: loss: 0.9334, policy_loss: 0.8688, value_loss: 0.4030
2024-07-14 07:47:14,205 [INFO    ] __main__: train step 23078: loss: 0.9334, policy_loss: 0.8688, value_loss: 0.4030
2024-07-14 07:47:14,499 [INFO    ] __main__: train step 23079: loss: 0.9334, policy_loss: 0.8688, value_loss: 0.4029
2024-07-14 07:47:14,817 [INFO    ] __main__: train step 23080: loss: 0.9334, policy_loss: 0.8688, value_loss: 0.4029
2024-07-14 07:47:15,107 [INFO    ] __main__: train step 23081: loss: 0.9334, policy_loss: 0.8688, value_loss: 0.4029
2024-07-14 07:47:15,431 [INFO    ] __main__: train step 23082: loss: 0.9334, policy_loss: 0.8688, value_loss: 0.4029
2024-07-14 07:47:17,036 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:47:17,471 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:47:17,541 [INFO    ] __main__: train step 23083: loss: 0.9334, policy_loss: 0.8688, value_loss: 0.4029
2024-07-14 07:47:17,846 [INFO    ] __main__: train step 23084: loss: 0.9333, policy_loss: 0.8688, value_loss: 0.4029
2024-07-14 07:47:18,147 [INFO    ] __main__: train step 23085: loss: 0.9333, policy_loss: 0.8687, value_loss: 0.4029
2024-07-14 07:47:18,449 [INFO    ] __main__: train step 23086: loss: 0.9333, policy_loss: 0.8687, value_loss: 0.4029
2024-07-14 07:47:18,747 [INFO    ] __main__: train step 23087: loss: 0.9333, policy_loss: 0.8687, value_loss: 0.4028
2024-07-14 07:47:19,040 [INFO    ] __main__: train step 23088: loss: 0.9333, policy_loss: 0.8687, value_loss: 0.4028
2024-07-14 07:47:19,344 [INFO    ] __main__: train step 23089: loss: 0.9333, policy_loss: 0.8687, value_loss: 0.4028
2024-07-14 07:47:19,650 [INFO    ] __main__: train step 23090: loss: 0.9333, policy_loss: 0.8687, value_loss: 0.4028
2024-07-14 07:47:19,955 [INFO    ] __main__: train step 23091: loss: 0.9333, policy_loss: 0.8687, value_loss: 0.4028
2024-07-14 07:47:20,239 [INFO    ] __main__: train step 23092: loss: 0.9333, policy_loss: 0.8687, value_loss: 0.4028
2024-07-14 07:47:20,531 [INFO    ] __main__: train step 23093: loss: 0.9333, policy_loss: 0.8687, value_loss: 0.4028
2024-07-14 07:47:20,827 [INFO    ] __main__: train step 23094: loss: 0.9332, policy_loss: 0.8686, value_loss: 0.4027
2024-07-14 07:47:21,132 [INFO    ] __main__: train step 23095: loss: 0.9332, policy_loss: 0.8686, value_loss: 0.4027
2024-07-14 07:47:21,444 [INFO    ] __main__: train step 23096: loss: 0.9332, policy_loss: 0.8686, value_loss: 0.4027
2024-07-14 07:47:21,753 [INFO    ] __main__: train step 23097: loss: 0.9332, policy_loss: 0.8686, value_loss: 0.4027
2024-07-14 07:47:22,066 [INFO    ] __main__: train step 23098: loss: 0.9332, policy_loss: 0.8686, value_loss: 0.4027
2024-07-14 07:47:22,366 [INFO    ] __main__: train step 23099: loss: 0.9332, policy_loss: 0.8686, value_loss: 0.4027
2024-07-14 07:47:24,002 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:47:24,421 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:47:24,492 [INFO    ] __main__: train step 23100: loss: 0.9332, policy_loss: 0.8686, value_loss: 0.4027
2024-07-14 07:47:24,820 [INFO    ] __main__: train step 23101: loss: 0.9332, policy_loss: 0.8686, value_loss: 0.4027
2024-07-14 07:47:25,109 [INFO    ] __main__: train step 23102: loss: 0.9332, policy_loss: 0.8686, value_loss: 0.4026
2024-07-14 07:47:25,412 [INFO    ] __main__: train step 23103: loss: 0.9332, policy_loss: 0.8685, value_loss: 0.4026
2024-07-14 07:47:25,698 [INFO    ] __main__: train step 23104: loss: 0.9331, policy_loss: 0.8685, value_loss: 0.4026
2024-07-14 07:47:26,007 [INFO    ] __main__: train step 23105: loss: 0.9331, policy_loss: 0.8685, value_loss: 0.4026
2024-07-14 07:47:26,308 [INFO    ] __main__: train step 23106: loss: 0.9331, policy_loss: 0.8685, value_loss: 0.4026
2024-07-14 07:47:26,619 [INFO    ] __main__: train step 23107: loss: 0.9331, policy_loss: 0.8685, value_loss: 0.4026
2024-07-14 07:47:26,906 [INFO    ] __main__: train step 23108: loss: 0.9331, policy_loss: 0.8685, value_loss: 0.4026
2024-07-14 07:47:27,204 [INFO    ] __main__: train step 23109: loss: 0.9331, policy_loss: 0.8685, value_loss: 0.4025
2024-07-14 07:47:27,511 [INFO    ] __main__: train step 23110: loss: 0.9331, policy_loss: 0.8685, value_loss: 0.4025
2024-07-14 07:47:27,832 [INFO    ] __main__: train step 23111: loss: 0.9331, policy_loss: 0.8685, value_loss: 0.4025
2024-07-14 07:47:28,126 [INFO    ] __main__: train step 23112: loss: 0.9331, policy_loss: 0.8684, value_loss: 0.4025
2024-07-14 07:47:28,418 [INFO    ] __main__: train step 23113: loss: 0.9331, policy_loss: 0.8684, value_loss: 0.4025
2024-07-14 07:47:28,779 [INFO    ] __main__: train step 23114: loss: 0.9331, policy_loss: 0.8684, value_loss: 0.4025
2024-07-14 07:47:29,088 [INFO    ] __main__: train step 23115: loss: 0.9330, policy_loss: 0.8684, value_loss: 0.4025
2024-07-14 07:47:29,406 [INFO    ] __main__: train step 23116: loss: 0.9330, policy_loss: 0.8684, value_loss: 0.4025
2024-07-14 07:47:31,020 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:47:31,448 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:47:31,519 [INFO    ] __main__: train step 23117: loss: 0.9330, policy_loss: 0.8684, value_loss: 0.4024
2024-07-14 07:47:31,828 [INFO    ] __main__: train step 23118: loss: 0.9330, policy_loss: 0.8684, value_loss: 0.4024
2024-07-14 07:47:32,155 [INFO    ] __main__: train step 23119: loss: 0.9330, policy_loss: 0.8684, value_loss: 0.4024
2024-07-14 07:47:32,469 [INFO    ] __main__: train step 23120: loss: 0.9330, policy_loss: 0.8683, value_loss: 0.4024
2024-07-14 07:47:32,758 [INFO    ] __main__: train step 23121: loss: 0.9330, policy_loss: 0.8683, value_loss: 0.4024
2024-07-14 07:47:33,056 [INFO    ] __main__: train step 23122: loss: 0.9330, policy_loss: 0.8683, value_loss: 0.4024
2024-07-14 07:47:33,366 [INFO    ] __main__: train step 23123: loss: 0.9330, policy_loss: 0.8683, value_loss: 0.4024
2024-07-14 07:47:33,652 [INFO    ] __main__: train step 23124: loss: 0.9330, policy_loss: 0.8683, value_loss: 0.4024
2024-07-14 07:47:33,954 [INFO    ] __main__: train step 23125: loss: 0.9329, policy_loss: 0.8683, value_loss: 0.4023
2024-07-14 07:47:34,254 [INFO    ] __main__: train step 23126: loss: 0.9329, policy_loss: 0.8683, value_loss: 0.4023
2024-07-14 07:47:34,545 [INFO    ] __main__: train step 23127: loss: 0.9329, policy_loss: 0.8683, value_loss: 0.4023
2024-07-14 07:47:34,855 [INFO    ] __main__: train step 23128: loss: 0.9329, policy_loss: 0.8683, value_loss: 0.4023
2024-07-14 07:47:35,155 [INFO    ] __main__: train step 23129: loss: 0.9329, policy_loss: 0.8682, value_loss: 0.4023
2024-07-14 07:47:35,459 [INFO    ] __main__: train step 23130: loss: 0.9329, policy_loss: 0.8682, value_loss: 0.4023
2024-07-14 07:47:35,763 [INFO    ] __main__: train step 23131: loss: 0.9329, policy_loss: 0.8682, value_loss: 0.4023
2024-07-14 07:47:36,076 [INFO    ] __main__: train step 23132: loss: 0.9329, policy_loss: 0.8682, value_loss: 0.4022
2024-07-14 07:47:36,365 [INFO    ] __main__: train step 23133: loss: 0.9329, policy_loss: 0.8682, value_loss: 0.4022
2024-07-14 07:47:37,990 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:47:38,423 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:47:38,492 [INFO    ] __main__: train step 23134: loss: 0.9329, policy_loss: 0.8682, value_loss: 0.4022
2024-07-14 07:47:38,791 [INFO    ] __main__: train step 23135: loss: 0.9328, policy_loss: 0.8682, value_loss: 0.4022
2024-07-14 07:47:39,078 [INFO    ] __main__: train step 23136: loss: 0.9328, policy_loss: 0.8682, value_loss: 0.4022
2024-07-14 07:47:39,403 [INFO    ] __main__: train step 23137: loss: 0.9328, policy_loss: 0.8682, value_loss: 0.4022
2024-07-14 07:47:39,689 [INFO    ] __main__: train step 23138: loss: 0.9328, policy_loss: 0.8681, value_loss: 0.4022
2024-07-14 07:47:39,994 [INFO    ] __main__: train step 23139: loss: 0.9328, policy_loss: 0.8681, value_loss: 0.4022
2024-07-14 07:47:40,288 [INFO    ] __main__: train step 23140: loss: 0.9328, policy_loss: 0.8681, value_loss: 0.4021
2024-07-14 07:47:40,602 [INFO    ] __main__: train step 23141: loss: 0.9328, policy_loss: 0.8681, value_loss: 0.4021
2024-07-14 07:47:40,893 [INFO    ] __main__: train step 23142: loss: 0.9328, policy_loss: 0.8681, value_loss: 0.4021
2024-07-14 07:47:41,196 [INFO    ] __main__: train step 23143: loss: 0.9328, policy_loss: 0.8681, value_loss: 0.4021
2024-07-14 07:47:41,505 [INFO    ] __main__: train step 23144: loss: 0.9328, policy_loss: 0.8681, value_loss: 0.4021
2024-07-14 07:47:41,812 [INFO    ] __main__: train step 23145: loss: 0.9327, policy_loss: 0.8681, value_loss: 0.4021
2024-07-14 07:47:42,124 [INFO    ] __main__: train step 23146: loss: 0.9327, policy_loss: 0.8681, value_loss: 0.4021
2024-07-14 07:47:42,416 [INFO    ] __main__: train step 23147: loss: 0.9327, policy_loss: 0.8680, value_loss: 0.4020
2024-07-14 07:47:42,676 [INFO    ] __main__: train step 23148: loss: 0.9327, policy_loss: 0.8680, value_loss: 0.4020
2024-07-14 07:47:42,984 [INFO    ] __main__: train step 23149: loss: 0.9327, policy_loss: 0.8680, value_loss: 0.4020
2024-07-14 07:47:43,307 [INFO    ] __main__: train step 23150: loss: 0.9327, policy_loss: 0.8680, value_loss: 0.4020
2024-07-14 07:47:44,953 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:47:45,369 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:47:45,436 [INFO    ] __main__: train step 23151: loss: 0.9327, policy_loss: 0.8680, value_loss: 0.4020
2024-07-14 07:47:45,717 [INFO    ] __main__: train step 23152: loss: 0.9327, policy_loss: 0.8680, value_loss: 0.4020
2024-07-14 07:47:46,011 [INFO    ] __main__: train step 23153: loss: 0.9327, policy_loss: 0.8680, value_loss: 0.4020
2024-07-14 07:47:46,308 [INFO    ] __main__: train step 23154: loss: 0.9327, policy_loss: 0.8680, value_loss: 0.4020
2024-07-14 07:47:46,599 [INFO    ] __main__: train step 23155: loss: 0.9326, policy_loss: 0.8680, value_loss: 0.4019
2024-07-14 07:47:46,908 [INFO    ] __main__: train step 23156: loss: 0.9326, policy_loss: 0.8679, value_loss: 0.4019
2024-07-14 07:47:47,178 [INFO    ] __main__: train step 23157: loss: 0.9326, policy_loss: 0.8679, value_loss: 0.4019
2024-07-14 07:47:47,478 [INFO    ] __main__: train step 23158: loss: 0.9326, policy_loss: 0.8679, value_loss: 0.4019
2024-07-14 07:47:47,794 [INFO    ] __main__: train step 23159: loss: 0.9326, policy_loss: 0.8679, value_loss: 0.4019
2024-07-14 07:47:48,105 [INFO    ] __main__: train step 23160: loss: 0.9326, policy_loss: 0.8679, value_loss: 0.4019
2024-07-14 07:47:48,407 [INFO    ] __main__: train step 23161: loss: 0.9326, policy_loss: 0.8679, value_loss: 0.4019
2024-07-14 07:47:48,685 [INFO    ] __main__: train step 23162: loss: 0.9326, policy_loss: 0.8679, value_loss: 0.4019
2024-07-14 07:47:48,968 [INFO    ] __main__: train step 23163: loss: 0.9326, policy_loss: 0.8679, value_loss: 0.4018
2024-07-14 07:47:49,259 [INFO    ] __main__: train step 23164: loss: 0.9326, policy_loss: 0.8679, value_loss: 0.4018
2024-07-14 07:47:49,552 [INFO    ] __main__: train step 23165: loss: 0.9326, policy_loss: 0.8678, value_loss: 0.4018
2024-07-14 07:47:49,845 [INFO    ] __main__: train step 23166: loss: 0.9325, policy_loss: 0.8678, value_loss: 0.4018
2024-07-14 07:47:50,150 [INFO    ] __main__: train step 23167: loss: 0.9325, policy_loss: 0.8678, value_loss: 0.4018
2024-07-14 07:47:51,765 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:47:52,188 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:47:52,256 [INFO    ] __main__: train step 23168: loss: 0.9325, policy_loss: 0.8678, value_loss: 0.4018
2024-07-14 07:47:52,579 [INFO    ] __main__: train step 23169: loss: 0.9325, policy_loss: 0.8678, value_loss: 0.4018
2024-07-14 07:47:52,890 [INFO    ] __main__: train step 23170: loss: 0.9325, policy_loss: 0.8678, value_loss: 0.4017
2024-07-14 07:47:53,197 [INFO    ] __main__: train step 23171: loss: 0.9325, policy_loss: 0.8678, value_loss: 0.4017
2024-07-14 07:47:53,455 [INFO    ] __main__: train step 23172: loss: 0.9325, policy_loss: 0.8678, value_loss: 0.4017
2024-07-14 07:47:53,730 [INFO    ] __main__: train step 23173: loss: 0.9325, policy_loss: 0.8678, value_loss: 0.4017
2024-07-14 07:47:54,026 [INFO    ] __main__: train step 23174: loss: 0.9325, policy_loss: 0.8677, value_loss: 0.4017
2024-07-14 07:47:54,335 [INFO    ] __main__: train step 23175: loss: 0.9325, policy_loss: 0.8677, value_loss: 0.4017
2024-07-14 07:47:54,645 [INFO    ] __main__: train step 23176: loss: 0.9325, policy_loss: 0.8677, value_loss: 0.4017
2024-07-14 07:47:54,953 [INFO    ] __main__: train step 23177: loss: 0.9324, policy_loss: 0.8677, value_loss: 0.4017
2024-07-14 07:47:55,230 [INFO    ] __main__: train step 23178: loss: 0.9324, policy_loss: 0.8677, value_loss: 0.4016
2024-07-14 07:47:55,519 [INFO    ] __main__: train step 23179: loss: 0.9324, policy_loss: 0.8677, value_loss: 0.4016
2024-07-14 07:47:55,831 [INFO    ] __main__: train step 23180: loss: 0.9324, policy_loss: 0.8677, value_loss: 0.4016
2024-07-14 07:47:56,133 [INFO    ] __main__: train step 23181: loss: 0.9324, policy_loss: 0.8677, value_loss: 0.4016
2024-07-14 07:47:56,445 [INFO    ] __main__: train step 23182: loss: 0.9324, policy_loss: 0.8677, value_loss: 0.4016
2024-07-14 07:47:56,739 [INFO    ] __main__: train step 23183: loss: 0.9324, policy_loss: 0.8676, value_loss: 0.4016
2024-07-14 07:47:57,040 [INFO    ] __main__: train step 23184: loss: 0.9324, policy_loss: 0.8676, value_loss: 0.4016
2024-07-14 07:47:58,676 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:47:59,087 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:47:59,156 [INFO    ] __main__: train step 23185: loss: 0.9324, policy_loss: 0.8676, value_loss: 0.4016
2024-07-14 07:47:59,459 [INFO    ] __main__: train step 23186: loss: 0.9324, policy_loss: 0.8676, value_loss: 0.4015
2024-07-14 07:47:59,730 [INFO    ] __main__: train step 23187: loss: 0.9323, policy_loss: 0.8676, value_loss: 0.4015
2024-07-14 07:48:00,031 [INFO    ] __main__: train step 23188: loss: 0.9323, policy_loss: 0.8676, value_loss: 0.4015
2024-07-14 07:48:00,340 [INFO    ] __main__: train step 23189: loss: 0.9323, policy_loss: 0.8676, value_loss: 0.4015
2024-07-14 07:48:00,634 [INFO    ] __main__: train step 23190: loss: 0.9323, policy_loss: 0.8676, value_loss: 0.4015
2024-07-14 07:48:00,942 [INFO    ] __main__: train step 23191: loss: 0.9323, policy_loss: 0.8676, value_loss: 0.4015
2024-07-14 07:48:01,231 [INFO    ] __main__: train step 23192: loss: 0.9323, policy_loss: 0.8675, value_loss: 0.4015
2024-07-14 07:48:01,516 [INFO    ] __main__: train step 23193: loss: 0.9323, policy_loss: 0.8675, value_loss: 0.4015
2024-07-14 07:48:01,815 [INFO    ] __main__: train step 23194: loss: 0.9323, policy_loss: 0.8675, value_loss: 0.4014
2024-07-14 07:48:02,116 [INFO    ] __main__: train step 23195: loss: 0.9323, policy_loss: 0.8675, value_loss: 0.4014
2024-07-14 07:48:02,419 [INFO    ] __main__: train step 23196: loss: 0.9323, policy_loss: 0.8675, value_loss: 0.4014
2024-07-14 07:48:02,719 [INFO    ] __main__: train step 23197: loss: 0.9323, policy_loss: 0.8675, value_loss: 0.4014
2024-07-14 07:48:07,341 [INFO    ] __main__: train step 23198: loss: 0.9322, policy_loss: 0.8675, value_loss: 0.4014
2024-07-14 07:48:07,625 [INFO    ] __main__: train step 23199: loss: 0.9322, policy_loss: 0.8675, value_loss: 0.4014
2024-07-14 07:48:07,917 [INFO    ] __main__: train step 23200: loss: 0.9322, policy_loss: 0.8675, value_loss: 0.4014
2024-07-14 07:48:08,226 [INFO    ] __main__: train step 23201: loss: 0.9322, policy_loss: 0.8674, value_loss: 0.4013
2024-07-14 07:48:09,864 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:48:10,280 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:48:10,348 [INFO    ] __main__: train step 23202: loss: 0.9322, policy_loss: 0.8674, value_loss: 0.4013
2024-07-14 07:48:10,607 [INFO    ] __main__: train step 23203: loss: 0.9322, policy_loss: 0.8674, value_loss: 0.4013
2024-07-14 07:48:10,890 [INFO    ] __main__: train step 23204: loss: 0.9322, policy_loss: 0.8674, value_loss: 0.4013
2024-07-14 07:48:11,183 [INFO    ] __main__: train step 23205: loss: 0.9322, policy_loss: 0.8674, value_loss: 0.4013
2024-07-14 07:48:11,474 [INFO    ] __main__: train step 23206: loss: 0.9322, policy_loss: 0.8674, value_loss: 0.4013
2024-07-14 07:48:11,775 [INFO    ] __main__: train step 23207: loss: 0.9322, policy_loss: 0.8674, value_loss: 0.4013
2024-07-14 07:48:12,083 [INFO    ] __main__: train step 23208: loss: 0.9321, policy_loss: 0.8674, value_loss: 0.4013
2024-07-14 07:48:12,385 [INFO    ] __main__: train step 23209: loss: 0.9321, policy_loss: 0.8674, value_loss: 0.4012
2024-07-14 07:48:12,678 [INFO    ] __main__: train step 23210: loss: 0.9321, policy_loss: 0.8673, value_loss: 0.4012
2024-07-14 07:48:12,980 [INFO    ] __main__: train step 23211: loss: 0.9321, policy_loss: 0.8673, value_loss: 0.4012
2024-07-14 07:48:13,299 [INFO    ] __main__: train step 23212: loss: 0.9321, policy_loss: 0.8673, value_loss: 0.4012
2024-07-14 07:48:13,601 [INFO    ] __main__: train step 23213: loss: 0.9321, policy_loss: 0.8673, value_loss: 0.4012
2024-07-14 07:48:13,901 [INFO    ] __main__: train step 23214: loss: 0.9321, policy_loss: 0.8673, value_loss: 0.4012
2024-07-14 07:48:14,192 [INFO    ] __main__: train step 23215: loss: 0.9321, policy_loss: 0.8673, value_loss: 0.4012
2024-07-14 07:48:14,493 [INFO    ] __main__: train step 23216: loss: 0.9321, policy_loss: 0.8673, value_loss: 0.4012
2024-07-14 07:48:14,799 [INFO    ] __main__: train step 23217: loss: 0.9321, policy_loss: 0.8673, value_loss: 0.4011
2024-07-14 07:48:15,111 [INFO    ] __main__: train step 23218: loss: 0.9321, policy_loss: 0.8673, value_loss: 0.4011
2024-07-14 07:48:16,743 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:48:17,172 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:48:17,244 [INFO    ] __main__: train step 23219: loss: 0.9320, policy_loss: 0.8673, value_loss: 0.4011
2024-07-14 07:48:17,516 [INFO    ] __main__: train step 23220: loss: 0.9320, policy_loss: 0.8672, value_loss: 0.4011
2024-07-14 07:48:17,792 [INFO    ] __main__: train step 23221: loss: 0.9320, policy_loss: 0.8672, value_loss: 0.4011
2024-07-14 07:48:18,078 [INFO    ] __main__: train step 23222: loss: 0.9320, policy_loss: 0.8672, value_loss: 0.4011
2024-07-14 07:48:18,405 [INFO    ] __main__: train step 23223: loss: 0.9320, policy_loss: 0.8672, value_loss: 0.4011
2024-07-14 07:48:18,692 [INFO    ] __main__: train step 23224: loss: 0.9320, policy_loss: 0.8672, value_loss: 0.4010
2024-07-14 07:48:18,987 [INFO    ] __main__: train step 23225: loss: 0.9320, policy_loss: 0.8672, value_loss: 0.4010
2024-07-14 07:48:19,296 [INFO    ] __main__: train step 23226: loss: 0.9320, policy_loss: 0.8672, value_loss: 0.4010
2024-07-14 07:48:19,598 [INFO    ] __main__: train step 23227: loss: 0.9320, policy_loss: 0.8672, value_loss: 0.4010
2024-07-14 07:48:19,908 [INFO    ] __main__: train step 23228: loss: 0.9320, policy_loss: 0.8672, value_loss: 0.4010
2024-07-14 07:48:20,187 [INFO    ] __main__: train step 23229: loss: 0.9320, policy_loss: 0.8671, value_loss: 0.4010
2024-07-14 07:48:20,449 [INFO    ] __main__: train step 23230: loss: 0.9319, policy_loss: 0.8671, value_loss: 0.4010
2024-07-14 07:48:20,729 [INFO    ] __main__: train step 23231: loss: 0.9319, policy_loss: 0.8671, value_loss: 0.4010
2024-07-14 07:48:21,030 [INFO    ] __main__: train step 23232: loss: 0.9319, policy_loss: 0.8671, value_loss: 0.4009
2024-07-14 07:48:21,335 [INFO    ] __main__: train step 23233: loss: 0.9319, policy_loss: 0.8671, value_loss: 0.4009
2024-07-14 07:48:21,636 [INFO    ] __main__: train step 23234: loss: 0.9319, policy_loss: 0.8671, value_loss: 0.4009
2024-07-14 07:48:21,918 [INFO    ] __main__: train step 23235: loss: 0.9319, policy_loss: 0.8671, value_loss: 0.4009
2024-07-14 07:48:23,482 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:48:23,911 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:48:23,979 [INFO    ] __main__: train step 23236: loss: 0.9319, policy_loss: 0.8671, value_loss: 0.4009
2024-07-14 07:48:24,279 [INFO    ] __main__: train step 23237: loss: 0.9319, policy_loss: 0.8671, value_loss: 0.4009
2024-07-14 07:48:24,579 [INFO    ] __main__: train step 23238: loss: 0.9319, policy_loss: 0.8670, value_loss: 0.4009
2024-07-14 07:48:24,895 [INFO    ] __main__: train step 23239: loss: 0.9319, policy_loss: 0.8670, value_loss: 0.4009
2024-07-14 07:48:25,181 [INFO    ] __main__: train step 23240: loss: 0.9318, policy_loss: 0.8670, value_loss: 0.4008
2024-07-14 07:48:25,465 [INFO    ] __main__: train step 23241: loss: 0.9318, policy_loss: 0.8670, value_loss: 0.4008
2024-07-14 07:48:25,776 [INFO    ] __main__: train step 23242: loss: 0.9318, policy_loss: 0.8670, value_loss: 0.4008
2024-07-14 07:48:26,076 [INFO    ] __main__: train step 23243: loss: 0.9318, policy_loss: 0.8670, value_loss: 0.4008
2024-07-14 07:48:26,375 [INFO    ] __main__: train step 23244: loss: 0.9318, policy_loss: 0.8670, value_loss: 0.4008
2024-07-14 07:48:26,668 [INFO    ] __main__: train step 23245: loss: 0.9318, policy_loss: 0.8670, value_loss: 0.4008
2024-07-14 07:48:26,963 [INFO    ] __main__: train step 23246: loss: 0.9318, policy_loss: 0.8670, value_loss: 0.4008
2024-07-14 07:48:27,281 [INFO    ] __main__: train step 23247: loss: 0.9318, policy_loss: 0.8670, value_loss: 0.4007
2024-07-14 07:48:27,556 [INFO    ] __main__: train step 23248: loss: 0.9318, policy_loss: 0.8669, value_loss: 0.4007
2024-07-14 07:48:27,832 [INFO    ] __main__: train step 23249: loss: 0.9318, policy_loss: 0.8669, value_loss: 0.4007
2024-07-14 07:48:28,106 [INFO    ] __main__: train step 23250: loss: 0.9318, policy_loss: 0.8669, value_loss: 0.4007
2024-07-14 07:48:28,362 [INFO    ] __main__: train step 23251: loss: 0.9317, policy_loss: 0.8669, value_loss: 0.4007
2024-07-14 07:48:28,644 [INFO    ] __main__: train step 23252: loss: 0.9317, policy_loss: 0.8669, value_loss: 0.4007
2024-07-14 07:48:30,253 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:48:30,665 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:48:30,731 [INFO    ] __main__: train step 23253: loss: 0.9317, policy_loss: 0.8669, value_loss: 0.4007
2024-07-14 07:48:30,996 [INFO    ] __main__: train step 23254: loss: 0.9317, policy_loss: 0.8669, value_loss: 0.4007
2024-07-14 07:48:31,249 [INFO    ] __main__: train step 23255: loss: 0.9317, policy_loss: 0.8669, value_loss: 0.4006
2024-07-14 07:48:31,513 [INFO    ] __main__: train step 23256: loss: 0.9317, policy_loss: 0.8669, value_loss: 0.4006
2024-07-14 07:48:31,763 [INFO    ] __main__: train step 23257: loss: 0.9317, policy_loss: 0.8668, value_loss: 0.4006
2024-07-14 07:48:32,028 [INFO    ] __main__: train step 23258: loss: 0.9317, policy_loss: 0.8668, value_loss: 0.4006
2024-07-14 07:48:32,325 [INFO    ] __main__: train step 23259: loss: 0.9317, policy_loss: 0.8668, value_loss: 0.4006
2024-07-14 07:48:32,628 [INFO    ] __main__: train step 23260: loss: 0.9317, policy_loss: 0.8668, value_loss: 0.4006
2024-07-14 07:48:32,921 [INFO    ] __main__: train step 23261: loss: 0.9317, policy_loss: 0.8668, value_loss: 0.4006
2024-07-14 07:48:33,183 [INFO    ] __main__: train step 23262: loss: 0.9316, policy_loss: 0.8668, value_loss: 0.4006
2024-07-14 07:48:33,446 [INFO    ] __main__: train step 23263: loss: 0.9316, policy_loss: 0.8668, value_loss: 0.4005
2024-07-14 07:48:33,754 [INFO    ] __main__: train step 23264: loss: 0.9316, policy_loss: 0.8668, value_loss: 0.4005
2024-07-14 07:48:34,051 [INFO    ] __main__: train step 23265: loss: 0.9316, policy_loss: 0.8668, value_loss: 0.4005
2024-07-14 07:48:34,343 [INFO    ] __main__: train step 23266: loss: 0.9316, policy_loss: 0.8667, value_loss: 0.4005
2024-07-14 07:48:34,606 [INFO    ] __main__: train step 23267: loss: 0.9316, policy_loss: 0.8667, value_loss: 0.4005
2024-07-14 07:48:34,889 [INFO    ] __main__: train step 23268: loss: 0.9316, policy_loss: 0.8667, value_loss: 0.4005
2024-07-14 07:48:35,173 [INFO    ] __main__: train step 23269: loss: 0.9316, policy_loss: 0.8667, value_loss: 0.4005
2024-07-14 07:48:36,773 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:48:37,242 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:48:37,313 [INFO    ] __main__: train step 23270: loss: 0.9316, policy_loss: 0.8667, value_loss: 0.4004
2024-07-14 07:48:37,637 [INFO    ] __main__: train step 23271: loss: 0.9316, policy_loss: 0.8667, value_loss: 0.4004
2024-07-14 07:48:37,941 [INFO    ] __main__: train step 23272: loss: 0.9316, policy_loss: 0.8667, value_loss: 0.4004
2024-07-14 07:48:38,257 [INFO    ] __main__: train step 23273: loss: 0.9315, policy_loss: 0.8667, value_loss: 0.4004
2024-07-14 07:48:38,557 [INFO    ] __main__: train step 23274: loss: 0.9315, policy_loss: 0.8667, value_loss: 0.4004
2024-07-14 07:48:38,864 [INFO    ] __main__: train step 23275: loss: 0.9315, policy_loss: 0.8667, value_loss: 0.4004
2024-07-14 07:48:39,161 [INFO    ] __main__: train step 23276: loss: 0.9315, policy_loss: 0.8666, value_loss: 0.4004
2024-07-14 07:48:39,440 [INFO    ] __main__: train step 23277: loss: 0.9315, policy_loss: 0.8666, value_loss: 0.4004
2024-07-14 07:48:39,712 [INFO    ] __main__: train step 23278: loss: 0.9315, policy_loss: 0.8666, value_loss: 0.4003
2024-07-14 07:48:39,988 [INFO    ] __main__: train step 23279: loss: 0.9315, policy_loss: 0.8666, value_loss: 0.4003
2024-07-14 07:48:40,270 [INFO    ] __main__: train step 23280: loss: 0.9315, policy_loss: 0.8666, value_loss: 0.4003
2024-07-14 07:48:40,565 [INFO    ] __main__: train step 23281: loss: 0.9315, policy_loss: 0.8666, value_loss: 0.4003
2024-07-14 07:48:40,865 [INFO    ] __main__: train step 23282: loss: 0.9315, policy_loss: 0.8666, value_loss: 0.4003
2024-07-14 07:48:41,149 [INFO    ] __main__: train step 23283: loss: 0.9315, policy_loss: 0.8666, value_loss: 0.4003
2024-07-14 07:48:41,436 [INFO    ] __main__: train step 23284: loss: 0.9314, policy_loss: 0.8666, value_loss: 0.4003
2024-07-14 07:48:41,718 [INFO    ] __main__: train step 23285: loss: 0.9314, policy_loss: 0.8665, value_loss: 0.4003
2024-07-14 07:48:42,052 [INFO    ] __main__: train step 23286: loss: 0.9314, policy_loss: 0.8665, value_loss: 0.4002
2024-07-14 07:48:43,695 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:48:44,139 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:48:44,204 [INFO    ] __main__: train step 23287: loss: 0.9314, policy_loss: 0.8665, value_loss: 0.4002
2024-07-14 07:48:44,460 [INFO    ] __main__: train step 23288: loss: 0.9314, policy_loss: 0.8665, value_loss: 0.4002
2024-07-14 07:48:44,734 [INFO    ] __main__: train step 23289: loss: 0.9314, policy_loss: 0.8665, value_loss: 0.4002
2024-07-14 07:48:45,025 [INFO    ] __main__: train step 23290: loss: 0.9314, policy_loss: 0.8665, value_loss: 0.4002
2024-07-14 07:48:45,320 [INFO    ] __main__: train step 23291: loss: 0.9314, policy_loss: 0.8665, value_loss: 0.4002
2024-07-14 07:48:45,618 [INFO    ] __main__: train step 23292: loss: 0.9314, policy_loss: 0.8665, value_loss: 0.4002
2024-07-14 07:48:45,918 [INFO    ] __main__: train step 23293: loss: 0.9314, policy_loss: 0.8665, value_loss: 0.4002
2024-07-14 07:48:46,224 [INFO    ] __main__: train step 23294: loss: 0.9314, policy_loss: 0.8665, value_loss: 0.4001
2024-07-14 07:48:46,525 [INFO    ] __main__: train step 23295: loss: 0.9313, policy_loss: 0.8664, value_loss: 0.4001
2024-07-14 07:48:46,824 [INFO    ] __main__: train step 23296: loss: 0.9313, policy_loss: 0.8664, value_loss: 0.4001
2024-07-14 07:48:47,139 [INFO    ] __main__: train step 23297: loss: 0.9313, policy_loss: 0.8664, value_loss: 0.4001
2024-07-14 07:48:47,432 [INFO    ] __main__: train step 23298: loss: 0.9313, policy_loss: 0.8664, value_loss: 0.4001
2024-07-14 07:48:47,732 [INFO    ] __main__: train step 23299: loss: 0.9313, policy_loss: 0.8664, value_loss: 0.4001
2024-07-14 07:48:48,022 [INFO    ] __main__: train step 23300: loss: 0.9313, policy_loss: 0.8664, value_loss: 0.4001
2024-07-14 07:48:48,324 [INFO    ] __main__: train step 23301: loss: 0.9313, policy_loss: 0.8664, value_loss: 0.4001
2024-07-14 07:48:48,632 [INFO    ] __main__: train step 23302: loss: 0.9313, policy_loss: 0.8664, value_loss: 0.4000
2024-07-14 07:48:48,939 [INFO    ] __main__: train step 23303: loss: 0.9313, policy_loss: 0.8664, value_loss: 0.4000
2024-07-14 07:48:50,558 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:48:50,986 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:48:51,050 [INFO    ] __main__: train step 23304: loss: 0.9313, policy_loss: 0.8663, value_loss: 0.4000
2024-07-14 07:48:51,345 [INFO    ] __main__: train step 23305: loss: 0.9313, policy_loss: 0.8663, value_loss: 0.4000
2024-07-14 07:48:51,639 [INFO    ] __main__: train step 23306: loss: 0.9313, policy_loss: 0.8663, value_loss: 0.4000
2024-07-14 07:48:51,932 [INFO    ] __main__: train step 23307: loss: 0.9312, policy_loss: 0.8663, value_loss: 0.4000
2024-07-14 07:48:52,219 [INFO    ] __main__: train step 23308: loss: 0.9312, policy_loss: 0.8663, value_loss: 0.4000
2024-07-14 07:48:52,530 [INFO    ] __main__: train step 23309: loss: 0.9312, policy_loss: 0.8663, value_loss: 0.3999
2024-07-14 07:48:52,853 [INFO    ] __main__: train step 23310: loss: 0.9312, policy_loss: 0.8663, value_loss: 0.3999
2024-07-14 07:48:53,166 [INFO    ] __main__: train step 23311: loss: 0.9312, policy_loss: 0.8663, value_loss: 0.3999
2024-07-14 07:48:53,432 [INFO    ] __main__: train step 23312: loss: 0.9312, policy_loss: 0.8663, value_loss: 0.3999
2024-07-14 07:48:53,722 [INFO    ] __main__: train step 23313: loss: 0.9312, policy_loss: 0.8663, value_loss: 0.3999
2024-07-14 07:48:54,028 [INFO    ] __main__: train step 23314: loss: 0.9312, policy_loss: 0.8662, value_loss: 0.3999
2024-07-14 07:48:54,333 [INFO    ] __main__: train step 23315: loss: 0.9312, policy_loss: 0.8662, value_loss: 0.3999
2024-07-14 07:48:54,644 [INFO    ] __main__: train step 23316: loss: 0.9312, policy_loss: 0.8662, value_loss: 0.3999
2024-07-14 07:48:54,943 [INFO    ] __main__: train step 23317: loss: 0.9312, policy_loss: 0.8662, value_loss: 0.3998
2024-07-14 07:48:55,219 [INFO    ] __main__: train step 23318: loss: 0.9311, policy_loss: 0.8662, value_loss: 0.3998
2024-07-14 07:48:55,490 [INFO    ] __main__: train step 23319: loss: 0.9311, policy_loss: 0.8662, value_loss: 0.3998
2024-07-14 07:48:55,773 [INFO    ] __main__: train step 23320: loss: 0.9311, policy_loss: 0.8662, value_loss: 0.3998
2024-07-14 07:48:57,402 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:48:57,822 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:48:57,893 [INFO    ] __main__: train step 23321: loss: 0.9311, policy_loss: 0.8662, value_loss: 0.3998
2024-07-14 07:48:58,198 [INFO    ] __main__: train step 23322: loss: 0.9311, policy_loss: 0.8662, value_loss: 0.3998
2024-07-14 07:48:58,492 [INFO    ] __main__: train step 23323: loss: 0.9311, policy_loss: 0.8662, value_loss: 0.3998
2024-07-14 07:48:58,782 [INFO    ] __main__: train step 23324: loss: 0.9311, policy_loss: 0.8661, value_loss: 0.3998
2024-07-14 07:48:59,058 [INFO    ] __main__: train step 23325: loss: 0.9311, policy_loss: 0.8661, value_loss: 0.3997
2024-07-14 07:49:03,844 [INFO    ] __main__: train step 23326: loss: 0.9311, policy_loss: 0.8661, value_loss: 0.3997
2024-07-14 07:49:04,146 [INFO    ] __main__: train step 23327: loss: 0.9311, policy_loss: 0.8661, value_loss: 0.3997
2024-07-14 07:49:04,447 [INFO    ] __main__: train step 23328: loss: 0.9311, policy_loss: 0.8661, value_loss: 0.3997
2024-07-14 07:49:04,752 [INFO    ] __main__: train step 23329: loss: 0.9310, policy_loss: 0.8661, value_loss: 0.3997
2024-07-14 07:49:05,059 [INFO    ] __main__: train step 23330: loss: 0.9310, policy_loss: 0.8661, value_loss: 0.3997
2024-07-14 07:49:05,363 [INFO    ] __main__: train step 23331: loss: 0.9310, policy_loss: 0.8661, value_loss: 0.3997
2024-07-14 07:49:05,672 [INFO    ] __main__: train step 23332: loss: 0.9310, policy_loss: 0.8661, value_loss: 0.3997
2024-07-14 07:49:05,976 [INFO    ] __main__: train step 23333: loss: 0.9310, policy_loss: 0.8660, value_loss: 0.3996
2024-07-14 07:49:06,292 [INFO    ] __main__: train step 23334: loss: 0.9310, policy_loss: 0.8660, value_loss: 0.3996
2024-07-14 07:49:06,576 [INFO    ] __main__: train step 23335: loss: 0.9310, policy_loss: 0.8660, value_loss: 0.3996
2024-07-14 07:49:06,889 [INFO    ] __main__: train step 23336: loss: 0.9310, policy_loss: 0.8660, value_loss: 0.3996
2024-07-14 07:49:07,183 [INFO    ] __main__: train step 23337: loss: 0.9310, policy_loss: 0.8660, value_loss: 0.3996
2024-07-14 07:49:08,790 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:49:09,217 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:49:09,282 [INFO    ] __main__: train step 23338: loss: 0.9310, policy_loss: 0.8660, value_loss: 0.3996
2024-07-14 07:49:09,574 [INFO    ] __main__: train step 23339: loss: 0.9310, policy_loss: 0.8660, value_loss: 0.3996
2024-07-14 07:49:09,879 [INFO    ] __main__: train step 23340: loss: 0.9309, policy_loss: 0.8660, value_loss: 0.3995
2024-07-14 07:49:10,185 [INFO    ] __main__: train step 23341: loss: 0.9309, policy_loss: 0.8660, value_loss: 0.3995
2024-07-14 07:49:10,479 [INFO    ] __main__: train step 23342: loss: 0.9309, policy_loss: 0.8660, value_loss: 0.3995
2024-07-14 07:49:10,777 [INFO    ] __main__: train step 23343: loss: 0.9309, policy_loss: 0.8659, value_loss: 0.3995
2024-07-14 07:49:11,091 [INFO    ] __main__: train step 23344: loss: 0.9309, policy_loss: 0.8659, value_loss: 0.3995
2024-07-14 07:49:11,392 [INFO    ] __main__: train step 23345: loss: 0.9309, policy_loss: 0.8659, value_loss: 0.3995
2024-07-14 07:49:11,685 [INFO    ] __main__: train step 23346: loss: 0.9309, policy_loss: 0.8659, value_loss: 0.3995
2024-07-14 07:49:11,993 [INFO    ] __main__: train step 23347: loss: 0.9309, policy_loss: 0.8659, value_loss: 0.3995
2024-07-14 07:49:12,305 [INFO    ] __main__: train step 23348: loss: 0.9309, policy_loss: 0.8659, value_loss: 0.3994
2024-07-14 07:49:12,577 [INFO    ] __main__: train step 23349: loss: 0.9309, policy_loss: 0.8659, value_loss: 0.3994
2024-07-14 07:49:12,866 [INFO    ] __main__: train step 23350: loss: 0.9309, policy_loss: 0.8659, value_loss: 0.3994
2024-07-14 07:49:13,158 [INFO    ] __main__: train step 23351: loss: 0.9308, policy_loss: 0.8659, value_loss: 0.3994
2024-07-14 07:49:13,465 [INFO    ] __main__: train step 23352: loss: 0.9308, policy_loss: 0.8659, value_loss: 0.3994
2024-07-14 07:49:13,785 [INFO    ] __main__: train step 23353: loss: 0.9308, policy_loss: 0.8658, value_loss: 0.3994
2024-07-14 07:49:14,070 [INFO    ] __main__: train step 23354: loss: 0.9308, policy_loss: 0.8658, value_loss: 0.3994
2024-07-14 07:49:15,711 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:49:16,136 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:49:16,202 [INFO    ] __main__: train step 23355: loss: 0.9308, policy_loss: 0.8658, value_loss: 0.3994
2024-07-14 07:49:16,510 [INFO    ] __main__: train step 23356: loss: 0.9308, policy_loss: 0.8658, value_loss: 0.3993
2024-07-14 07:49:16,818 [INFO    ] __main__: train step 23357: loss: 0.9308, policy_loss: 0.8658, value_loss: 0.3993
2024-07-14 07:49:17,112 [INFO    ] __main__: train step 23358: loss: 0.9308, policy_loss: 0.8658, value_loss: 0.3993
2024-07-14 07:49:17,418 [INFO    ] __main__: train step 23359: loss: 0.9308, policy_loss: 0.8658, value_loss: 0.3993
2024-07-14 07:49:17,718 [INFO    ] __main__: train step 23360: loss: 0.9308, policy_loss: 0.8658, value_loss: 0.3993
2024-07-14 07:49:18,026 [INFO    ] __main__: train step 23361: loss: 0.9308, policy_loss: 0.8658, value_loss: 0.3993
2024-07-14 07:49:18,332 [INFO    ] __main__: train step 23362: loss: 0.9308, policy_loss: 0.8658, value_loss: 0.3993
2024-07-14 07:49:18,621 [INFO    ] __main__: train step 23363: loss: 0.9307, policy_loss: 0.8657, value_loss: 0.3993
2024-07-14 07:49:18,948 [INFO    ] __main__: train step 23364: loss: 0.9307, policy_loss: 0.8657, value_loss: 0.3992
2024-07-14 07:49:19,249 [INFO    ] __main__: train step 23365: loss: 0.9307, policy_loss: 0.8657, value_loss: 0.3992
2024-07-14 07:49:19,550 [INFO    ] __main__: train step 23366: loss: 0.9307, policy_loss: 0.8657, value_loss: 0.3992
2024-07-14 07:49:19,855 [INFO    ] __main__: train step 23367: loss: 0.9307, policy_loss: 0.8657, value_loss: 0.3992
2024-07-14 07:49:20,158 [INFO    ] __main__: train step 23368: loss: 0.9307, policy_loss: 0.8657, value_loss: 0.3992
2024-07-14 07:49:20,472 [INFO    ] __main__: train step 23369: loss: 0.9307, policy_loss: 0.8657, value_loss: 0.3992
2024-07-14 07:49:20,812 [INFO    ] __main__: train step 23370: loss: 0.9307, policy_loss: 0.8657, value_loss: 0.3992
2024-07-14 07:49:21,126 [INFO    ] __main__: train step 23371: loss: 0.9307, policy_loss: 0.8657, value_loss: 0.3992
2024-07-14 07:49:22,754 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:49:23,190 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:49:23,253 [INFO    ] __main__: train step 23372: loss: 0.9307, policy_loss: 0.8657, value_loss: 0.3991
2024-07-14 07:49:23,546 [INFO    ] __main__: train step 23373: loss: 0.9307, policy_loss: 0.8656, value_loss: 0.3991
2024-07-14 07:49:23,848 [INFO    ] __main__: train step 23374: loss: 0.9307, policy_loss: 0.8656, value_loss: 0.3991
2024-07-14 07:49:24,157 [INFO    ] __main__: train step 23375: loss: 0.9306, policy_loss: 0.8656, value_loss: 0.3991
2024-07-14 07:49:24,486 [INFO    ] __main__: train step 23376: loss: 0.9306, policy_loss: 0.8656, value_loss: 0.3991
2024-07-14 07:49:24,784 [INFO    ] __main__: train step 23377: loss: 0.9306, policy_loss: 0.8656, value_loss: 0.3991
2024-07-14 07:49:25,084 [INFO    ] __main__: train step 23378: loss: 0.9306, policy_loss: 0.8656, value_loss: 0.3991
2024-07-14 07:49:25,390 [INFO    ] __main__: train step 23379: loss: 0.9306, policy_loss: 0.8656, value_loss: 0.3990
2024-07-14 07:49:25,688 [INFO    ] __main__: train step 23380: loss: 0.9306, policy_loss: 0.8656, value_loss: 0.3990
2024-07-14 07:49:25,990 [INFO    ] __main__: train step 23381: loss: 0.9306, policy_loss: 0.8656, value_loss: 0.3990
2024-07-14 07:49:26,295 [INFO    ] __main__: train step 23382: loss: 0.9306, policy_loss: 0.8655, value_loss: 0.3990
2024-07-14 07:49:26,607 [INFO    ] __main__: train step 23383: loss: 0.9306, policy_loss: 0.8655, value_loss: 0.3990
2024-07-14 07:49:26,912 [INFO    ] __main__: train step 23384: loss: 0.9306, policy_loss: 0.8655, value_loss: 0.3990
2024-07-14 07:49:27,222 [INFO    ] __main__: train step 23385: loss: 0.9306, policy_loss: 0.8655, value_loss: 0.3990
2024-07-14 07:49:27,518 [INFO    ] __main__: train step 23386: loss: 0.9305, policy_loss: 0.8655, value_loss: 0.3990
2024-07-14 07:49:27,830 [INFO    ] __main__: train step 23387: loss: 0.9305, policy_loss: 0.8655, value_loss: 0.3989
2024-07-14 07:49:28,121 [INFO    ] __main__: train step 23388: loss: 0.9305, policy_loss: 0.8655, value_loss: 0.3989
2024-07-14 07:49:29,740 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:49:30,156 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:49:30,226 [INFO    ] __main__: train step 23389: loss: 0.9305, policy_loss: 0.8655, value_loss: 0.3989
2024-07-14 07:49:30,519 [INFO    ] __main__: train step 23390: loss: 0.9305, policy_loss: 0.8655, value_loss: 0.3989
2024-07-14 07:49:30,823 [INFO    ] __main__: train step 23391: loss: 0.9305, policy_loss: 0.8655, value_loss: 0.3989
2024-07-14 07:49:31,137 [INFO    ] __main__: train step 23392: loss: 0.9305, policy_loss: 0.8654, value_loss: 0.3989
2024-07-14 07:49:31,430 [INFO    ] __main__: train step 23393: loss: 0.9305, policy_loss: 0.8654, value_loss: 0.3989
2024-07-14 07:49:31,727 [INFO    ] __main__: train step 23394: loss: 0.9305, policy_loss: 0.8654, value_loss: 0.3989
2024-07-14 07:49:32,029 [INFO    ] __main__: train step 23395: loss: 0.9305, policy_loss: 0.8654, value_loss: 0.3988
2024-07-14 07:49:32,342 [INFO    ] __main__: train step 23396: loss: 0.9305, policy_loss: 0.8654, value_loss: 0.3988
2024-07-14 07:49:32,615 [INFO    ] __main__: train step 23397: loss: 0.9305, policy_loss: 0.8654, value_loss: 0.3988
2024-07-14 07:49:32,918 [INFO    ] __main__: train step 23398: loss: 0.9304, policy_loss: 0.8654, value_loss: 0.3988
2024-07-14 07:49:33,209 [INFO    ] __main__: train step 23399: loss: 0.9304, policy_loss: 0.8654, value_loss: 0.3988
2024-07-14 07:49:33,513 [INFO    ] __main__: train step 23400: loss: 0.9304, policy_loss: 0.8654, value_loss: 0.3988
2024-07-14 07:49:33,809 [INFO    ] __main__: train step 23401: loss: 0.9304, policy_loss: 0.8654, value_loss: 0.3988
2024-07-14 07:49:34,102 [INFO    ] __main__: train step 23402: loss: 0.9304, policy_loss: 0.8653, value_loss: 0.3988
2024-07-14 07:49:34,393 [INFO    ] __main__: train step 23403: loss: 0.9304, policy_loss: 0.8653, value_loss: 0.3987
2024-07-14 07:49:34,675 [INFO    ] __main__: train step 23404: loss: 0.9304, policy_loss: 0.8653, value_loss: 0.3987
2024-07-14 07:49:34,979 [INFO    ] __main__: train step 23405: loss: 0.9304, policy_loss: 0.8653, value_loss: 0.3987
2024-07-14 07:49:36,605 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:49:37,024 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:49:37,089 [INFO    ] __main__: train step 23406: loss: 0.9304, policy_loss: 0.8653, value_loss: 0.3987
2024-07-14 07:49:37,386 [INFO    ] __main__: train step 23407: loss: 0.9304, policy_loss: 0.8653, value_loss: 0.3987
2024-07-14 07:49:37,652 [INFO    ] __main__: train step 23408: loss: 0.9304, policy_loss: 0.8653, value_loss: 0.3987
2024-07-14 07:49:37,960 [INFO    ] __main__: train step 23409: loss: 0.9304, policy_loss: 0.8653, value_loss: 0.3987
2024-07-14 07:49:38,263 [INFO    ] __main__: train step 23410: loss: 0.9303, policy_loss: 0.8653, value_loss: 0.3987
2024-07-14 07:49:38,568 [INFO    ] __main__: train step 23411: loss: 0.9303, policy_loss: 0.8653, value_loss: 0.3986
2024-07-14 07:49:38,882 [INFO    ] __main__: train step 23412: loss: 0.9303, policy_loss: 0.8652, value_loss: 0.3986
2024-07-14 07:49:39,189 [INFO    ] __main__: train step 23413: loss: 0.9303, policy_loss: 0.8652, value_loss: 0.3986
2024-07-14 07:49:39,485 [INFO    ] __main__: train step 23414: loss: 0.9303, policy_loss: 0.8652, value_loss: 0.3986
2024-07-14 07:49:39,803 [INFO    ] __main__: train step 23415: loss: 0.9303, policy_loss: 0.8652, value_loss: 0.3986
2024-07-14 07:49:40,113 [INFO    ] __main__: train step 23416: loss: 0.9303, policy_loss: 0.8652, value_loss: 0.3986
2024-07-14 07:49:40,423 [INFO    ] __main__: train step 23417: loss: 0.9303, policy_loss: 0.8652, value_loss: 0.3986
2024-07-14 07:49:40,716 [INFO    ] __main__: train step 23418: loss: 0.9303, policy_loss: 0.8652, value_loss: 0.3986
2024-07-14 07:49:41,026 [INFO    ] __main__: train step 23419: loss: 0.9303, policy_loss: 0.8652, value_loss: 0.3985
2024-07-14 07:49:41,336 [INFO    ] __main__: train step 23420: loss: 0.9303, policy_loss: 0.8652, value_loss: 0.3985
2024-07-14 07:49:41,636 [INFO    ] __main__: train step 23421: loss: 0.9303, policy_loss: 0.8652, value_loss: 0.3985
2024-07-14 07:49:41,942 [INFO    ] __main__: train step 23422: loss: 0.9302, policy_loss: 0.8651, value_loss: 0.3985
2024-07-14 07:49:43,569 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:49:43,938 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:49:44,005 [INFO    ] __main__: train step 23423: loss: 0.9302, policy_loss: 0.8651, value_loss: 0.3985
2024-07-14 07:49:44,295 [INFO    ] __main__: train step 23424: loss: 0.9302, policy_loss: 0.8651, value_loss: 0.3985
2024-07-14 07:49:44,605 [INFO    ] __main__: train step 23425: loss: 0.9302, policy_loss: 0.8651, value_loss: 0.3985
2024-07-14 07:49:44,915 [INFO    ] __main__: train step 23426: loss: 0.9302, policy_loss: 0.8651, value_loss: 0.3985
2024-07-14 07:49:45,234 [INFO    ] __main__: train step 23427: loss: 0.9302, policy_loss: 0.8651, value_loss: 0.3984
2024-07-14 07:49:45,516 [INFO    ] __main__: train step 23428: loss: 0.9302, policy_loss: 0.8651, value_loss: 0.3984
2024-07-14 07:49:45,786 [INFO    ] __main__: train step 23429: loss: 0.9302, policy_loss: 0.8651, value_loss: 0.3984
2024-07-14 07:49:46,051 [INFO    ] __main__: train step 23430: loss: 0.9302, policy_loss: 0.8651, value_loss: 0.3984
2024-07-14 07:49:46,374 [INFO    ] __main__: train step 23431: loss: 0.9302, policy_loss: 0.8651, value_loss: 0.3984
2024-07-14 07:49:46,691 [INFO    ] __main__: train step 23432: loss: 0.9302, policy_loss: 0.8650, value_loss: 0.3984
2024-07-14 07:49:47,023 [INFO    ] __main__: train step 23433: loss: 0.9301, policy_loss: 0.8650, value_loss: 0.3984
2024-07-14 07:49:47,305 [INFO    ] __main__: train step 23434: loss: 0.9301, policy_loss: 0.8650, value_loss: 0.3984
2024-07-14 07:49:47,611 [INFO    ] __main__: train step 23435: loss: 0.9301, policy_loss: 0.8650, value_loss: 0.3983
2024-07-14 07:49:47,939 [INFO    ] __main__: train step 23436: loss: 0.9301, policy_loss: 0.8650, value_loss: 0.3983
2024-07-14 07:49:48,251 [INFO    ] __main__: train step 23437: loss: 0.9301, policy_loss: 0.8650, value_loss: 0.3983
2024-07-14 07:49:48,538 [INFO    ] __main__: train step 23438: loss: 0.9301, policy_loss: 0.8650, value_loss: 0.3983
2024-07-14 07:49:48,848 [INFO    ] __main__: train step 23439: loss: 0.9301, policy_loss: 0.8650, value_loss: 0.3983
2024-07-14 07:49:50,478 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:49:50,941 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:49:51,013 [INFO    ] __main__: train step 23440: loss: 0.9301, policy_loss: 0.8650, value_loss: 0.3983
2024-07-14 07:49:51,325 [INFO    ] __main__: train step 23441: loss: 0.9301, policy_loss: 0.8650, value_loss: 0.3983
2024-07-14 07:49:51,632 [INFO    ] __main__: train step 23442: loss: 0.9301, policy_loss: 0.8649, value_loss: 0.3983
2024-07-14 07:49:51,932 [INFO    ] __main__: train step 23443: loss: 0.9301, policy_loss: 0.8649, value_loss: 0.3982
2024-07-14 07:49:52,233 [INFO    ] __main__: train step 23444: loss: 0.9301, policy_loss: 0.8649, value_loss: 0.3982
2024-07-14 07:49:52,551 [INFO    ] __main__: train step 23445: loss: 0.9300, policy_loss: 0.8649, value_loss: 0.3982
2024-07-14 07:49:52,861 [INFO    ] __main__: train step 23446: loss: 0.9300, policy_loss: 0.8649, value_loss: 0.3982
2024-07-14 07:49:53,176 [INFO    ] __main__: train step 23447: loss: 0.9300, policy_loss: 0.8649, value_loss: 0.3982
2024-07-14 07:49:53,487 [INFO    ] __main__: train step 23448: loss: 0.9300, policy_loss: 0.8649, value_loss: 0.3982
2024-07-14 07:49:53,800 [INFO    ] __main__: train step 23449: loss: 0.9300, policy_loss: 0.8649, value_loss: 0.3982
2024-07-14 07:49:54,103 [INFO    ] __main__: train step 23450: loss: 0.9300, policy_loss: 0.8649, value_loss: 0.3981
2024-07-14 07:49:54,420 [INFO    ] __main__: train step 23451: loss: 0.9300, policy_loss: 0.8649, value_loss: 0.3981
2024-07-14 07:49:54,719 [INFO    ] __main__: train step 23452: loss: 0.9300, policy_loss: 0.8648, value_loss: 0.3981
2024-07-14 07:49:55,010 [INFO    ] __main__: train step 23453: loss: 0.9300, policy_loss: 0.8648, value_loss: 0.3981
2024-07-14 07:49:59,799 [INFO    ] __main__: train step 23454: loss: 0.9300, policy_loss: 0.8648, value_loss: 0.3981
2024-07-14 07:50:00,117 [INFO    ] __main__: train step 23455: loss: 0.9300, policy_loss: 0.8648, value_loss: 0.3981
2024-07-14 07:50:00,424 [INFO    ] __main__: train step 23456: loss: 0.9300, policy_loss: 0.8648, value_loss: 0.3981
2024-07-14 07:50:02,044 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:50:02,471 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:50:02,537 [INFO    ] __main__: train step 23457: loss: 0.9299, policy_loss: 0.8648, value_loss: 0.3981
2024-07-14 07:50:02,829 [INFO    ] __main__: train step 23458: loss: 0.9299, policy_loss: 0.8648, value_loss: 0.3981
2024-07-14 07:50:03,105 [INFO    ] __main__: train step 23459: loss: 0.9299, policy_loss: 0.8648, value_loss: 0.3980
2024-07-14 07:50:03,376 [INFO    ] __main__: train step 23460: loss: 0.9299, policy_loss: 0.8648, value_loss: 0.3980
2024-07-14 07:50:03,644 [INFO    ] __main__: train step 23461: loss: 0.9299, policy_loss: 0.8648, value_loss: 0.3980
2024-07-14 07:50:03,940 [INFO    ] __main__: train step 23462: loss: 0.9299, policy_loss: 0.8647, value_loss: 0.3980
2024-07-14 07:50:04,231 [INFO    ] __main__: train step 23463: loss: 0.9299, policy_loss: 0.8647, value_loss: 0.3980
2024-07-14 07:50:04,515 [INFO    ] __main__: train step 23464: loss: 0.9299, policy_loss: 0.8647, value_loss: 0.3980
2024-07-14 07:50:04,809 [INFO    ] __main__: train step 23465: loss: 0.9299, policy_loss: 0.8647, value_loss: 0.3980
2024-07-14 07:50:05,083 [INFO    ] __main__: train step 23466: loss: 0.9299, policy_loss: 0.8647, value_loss: 0.3979
2024-07-14 07:50:05,390 [INFO    ] __main__: train step 23467: loss: 0.9299, policy_loss: 0.8647, value_loss: 0.3979
2024-07-14 07:50:05,685 [INFO    ] __main__: train step 23468: loss: 0.9299, policy_loss: 0.8647, value_loss: 0.3979
2024-07-14 07:50:05,994 [INFO    ] __main__: train step 23469: loss: 0.9299, policy_loss: 0.8647, value_loss: 0.3979
2024-07-14 07:50:06,289 [INFO    ] __main__: train step 23470: loss: 0.9298, policy_loss: 0.8647, value_loss: 0.3979
2024-07-14 07:50:06,585 [INFO    ] __main__: train step 23471: loss: 0.9298, policy_loss: 0.8647, value_loss: 0.3979
2024-07-14 07:50:06,878 [INFO    ] __main__: train step 23472: loss: 0.9298, policy_loss: 0.8646, value_loss: 0.3979
2024-07-14 07:50:07,161 [INFO    ] __main__: train step 23473: loss: 0.9298, policy_loss: 0.8646, value_loss: 0.3979
2024-07-14 07:50:08,768 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:50:09,191 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:50:09,259 [INFO    ] __main__: train step 23474: loss: 0.9298, policy_loss: 0.8646, value_loss: 0.3979
2024-07-14 07:50:09,542 [INFO    ] __main__: train step 23475: loss: 0.9298, policy_loss: 0.8646, value_loss: 0.3978
2024-07-14 07:50:09,836 [INFO    ] __main__: train step 23476: loss: 0.9298, policy_loss: 0.8646, value_loss: 0.3978
2024-07-14 07:50:10,138 [INFO    ] __main__: train step 23477: loss: 0.9298, policy_loss: 0.8646, value_loss: 0.3978
2024-07-14 07:50:10,423 [INFO    ] __main__: train step 23478: loss: 0.9298, policy_loss: 0.8646, value_loss: 0.3978
2024-07-14 07:50:10,713 [INFO    ] __main__: train step 23479: loss: 0.9298, policy_loss: 0.8646, value_loss: 0.3978
2024-07-14 07:50:10,999 [INFO    ] __main__: train step 23480: loss: 0.9298, policy_loss: 0.8646, value_loss: 0.3978
2024-07-14 07:50:11,284 [INFO    ] __main__: train step 23481: loss: 0.9298, policy_loss: 0.8646, value_loss: 0.3978
2024-07-14 07:50:11,585 [INFO    ] __main__: train step 23482: loss: 0.9297, policy_loss: 0.8645, value_loss: 0.3977
2024-07-14 07:50:11,869 [INFO    ] __main__: train step 23483: loss: 0.9297, policy_loss: 0.8645, value_loss: 0.3977
2024-07-14 07:50:12,166 [INFO    ] __main__: train step 23484: loss: 0.9297, policy_loss: 0.8645, value_loss: 0.3977
2024-07-14 07:50:12,501 [INFO    ] __main__: train step 23485: loss: 0.9297, policy_loss: 0.8645, value_loss: 0.3977
2024-07-14 07:50:12,790 [INFO    ] __main__: train step 23486: loss: 0.9297, policy_loss: 0.8645, value_loss: 0.3977
2024-07-14 07:50:13,084 [INFO    ] __main__: train step 23487: loss: 0.9297, policy_loss: 0.8645, value_loss: 0.3977
2024-07-14 07:50:13,375 [INFO    ] __main__: train step 23488: loss: 0.9297, policy_loss: 0.8645, value_loss: 0.3977
2024-07-14 07:50:13,669 [INFO    ] __main__: train step 23489: loss: 0.9297, policy_loss: 0.8645, value_loss: 0.3977
2024-07-14 07:50:13,946 [INFO    ] __main__: train step 23490: loss: 0.9297, policy_loss: 0.8645, value_loss: 0.3976
2024-07-14 07:50:15,571 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:50:16,012 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:50:16,081 [INFO    ] __main__: train step 23491: loss: 0.9297, policy_loss: 0.8645, value_loss: 0.3976
2024-07-14 07:50:16,378 [INFO    ] __main__: train step 23492: loss: 0.9297, policy_loss: 0.8644, value_loss: 0.3976
2024-07-14 07:50:16,685 [INFO    ] __main__: train step 23493: loss: 0.9297, policy_loss: 0.8644, value_loss: 0.3976
2024-07-14 07:50:16,967 [INFO    ] __main__: train step 23494: loss: 0.9296, policy_loss: 0.8644, value_loss: 0.3976
2024-07-14 07:50:17,259 [INFO    ] __main__: train step 23495: loss: 0.9296, policy_loss: 0.8644, value_loss: 0.3976
2024-07-14 07:50:17,563 [INFO    ] __main__: train step 23496: loss: 0.9296, policy_loss: 0.8644, value_loss: 0.3976
2024-07-14 07:50:17,846 [INFO    ] __main__: train step 23497: loss: 0.9296, policy_loss: 0.8644, value_loss: 0.3976
2024-07-14 07:50:18,150 [INFO    ] __main__: train step 23498: loss: 0.9296, policy_loss: 0.8644, value_loss: 0.3975
2024-07-14 07:50:18,435 [INFO    ] __main__: train step 23499: loss: 0.9296, policy_loss: 0.8644, value_loss: 0.3975
2024-07-14 07:50:18,740 [INFO    ] __main__: train step 23500: loss: 0.9296, policy_loss: 0.8644, value_loss: 0.3975
2024-07-14 07:50:19,056 [INFO    ] __main__: train step 23501: loss: 0.9296, policy_loss: 0.8644, value_loss: 0.3975
2024-07-14 07:50:19,344 [INFO    ] __main__: train step 23502: loss: 0.9296, policy_loss: 0.8644, value_loss: 0.3975
2024-07-14 07:50:19,642 [INFO    ] __main__: train step 23503: loss: 0.9296, policy_loss: 0.8643, value_loss: 0.3975
2024-07-14 07:50:19,948 [INFO    ] __main__: train step 23504: loss: 0.9296, policy_loss: 0.8643, value_loss: 0.3975
2024-07-14 07:50:20,245 [INFO    ] __main__: train step 23505: loss: 0.9296, policy_loss: 0.8643, value_loss: 0.3975
2024-07-14 07:50:20,534 [INFO    ] __main__: train step 23506: loss: 0.9295, policy_loss: 0.8643, value_loss: 0.3974
2024-07-14 07:50:20,827 [INFO    ] __main__: train step 23507: loss: 0.9295, policy_loss: 0.8643, value_loss: 0.3974
2024-07-14 07:50:22,463 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:50:22,893 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:50:22,958 [INFO    ] __main__: train step 23508: loss: 0.9295, policy_loss: 0.8643, value_loss: 0.3974
2024-07-14 07:50:23,264 [INFO    ] __main__: train step 23509: loss: 0.9295, policy_loss: 0.8643, value_loss: 0.3974
2024-07-14 07:50:23,553 [INFO    ] __main__: train step 23510: loss: 0.9295, policy_loss: 0.8643, value_loss: 0.3974
2024-07-14 07:50:23,846 [INFO    ] __main__: train step 23511: loss: 0.9295, policy_loss: 0.8643, value_loss: 0.3974
2024-07-14 07:50:24,145 [INFO    ] __main__: train step 23512: loss: 0.9295, policy_loss: 0.8643, value_loss: 0.3974
2024-07-14 07:50:24,436 [INFO    ] __main__: train step 23513: loss: 0.9295, policy_loss: 0.8642, value_loss: 0.3974
2024-07-14 07:50:24,728 [INFO    ] __main__: train step 23514: loss: 0.9295, policy_loss: 0.8642, value_loss: 0.3973
2024-07-14 07:50:25,020 [INFO    ] __main__: train step 23515: loss: 0.9295, policy_loss: 0.8642, value_loss: 0.3973
2024-07-14 07:50:25,328 [INFO    ] __main__: train step 23516: loss: 0.9295, policy_loss: 0.8642, value_loss: 0.3973
2024-07-14 07:50:25,630 [INFO    ] __main__: train step 23517: loss: 0.9295, policy_loss: 0.8642, value_loss: 0.3973
2024-07-14 07:50:25,920 [INFO    ] __main__: train step 23518: loss: 0.9294, policy_loss: 0.8642, value_loss: 0.3973
2024-07-14 07:50:26,218 [INFO    ] __main__: train step 23519: loss: 0.9294, policy_loss: 0.8642, value_loss: 0.3973
2024-07-14 07:50:26,520 [INFO    ] __main__: train step 23520: loss: 0.9294, policy_loss: 0.8642, value_loss: 0.3973
2024-07-14 07:50:26,824 [INFO    ] __main__: train step 23521: loss: 0.9294, policy_loss: 0.8642, value_loss: 0.3973
2024-07-14 07:50:27,134 [INFO    ] __main__: train step 23522: loss: 0.9294, policy_loss: 0.8642, value_loss: 0.3972
2024-07-14 07:50:27,443 [INFO    ] __main__: train step 23523: loss: 0.9294, policy_loss: 0.8641, value_loss: 0.3972
2024-07-14 07:50:27,728 [INFO    ] __main__: train step 23524: loss: 0.9294, policy_loss: 0.8641, value_loss: 0.3972
2024-07-14 07:50:29,333 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:50:29,788 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:50:29,850 [INFO    ] __main__: train step 23525: loss: 0.9294, policy_loss: 0.8641, value_loss: 0.3972
2024-07-14 07:50:30,145 [INFO    ] __main__: train step 23526: loss: 0.9294, policy_loss: 0.8641, value_loss: 0.3972
2024-07-14 07:50:30,443 [INFO    ] __main__: train step 23527: loss: 0.9294, policy_loss: 0.8641, value_loss: 0.3972
2024-07-14 07:50:30,741 [INFO    ] __main__: train step 23528: loss: 0.9294, policy_loss: 0.8641, value_loss: 0.3972
2024-07-14 07:50:31,038 [INFO    ] __main__: train step 23529: loss: 0.9294, policy_loss: 0.8641, value_loss: 0.3972
2024-07-14 07:50:31,306 [INFO    ] __main__: train step 23530: loss: 0.9294, policy_loss: 0.8641, value_loss: 0.3971
2024-07-14 07:50:31,573 [INFO    ] __main__: train step 23531: loss: 0.9293, policy_loss: 0.8641, value_loss: 0.3971
2024-07-14 07:50:31,838 [INFO    ] __main__: train step 23532: loss: 0.9293, policy_loss: 0.8641, value_loss: 0.3971
2024-07-14 07:50:32,120 [INFO    ] __main__: train step 23533: loss: 0.9293, policy_loss: 0.8640, value_loss: 0.3971
2024-07-14 07:50:32,419 [INFO    ] __main__: train step 23534: loss: 0.9293, policy_loss: 0.8640, value_loss: 0.3971
2024-07-14 07:50:32,692 [INFO    ] __main__: train step 23535: loss: 0.9293, policy_loss: 0.8640, value_loss: 0.3971
2024-07-14 07:50:32,974 [INFO    ] __main__: train step 23536: loss: 0.9293, policy_loss: 0.8640, value_loss: 0.3971
2024-07-14 07:50:33,268 [INFO    ] __main__: train step 23537: loss: 0.9293, policy_loss: 0.8640, value_loss: 0.3971
2024-07-14 07:50:33,550 [INFO    ] __main__: train step 23538: loss: 0.9293, policy_loss: 0.8640, value_loss: 0.3971
2024-07-14 07:50:33,848 [INFO    ] __main__: train step 23539: loss: 0.9293, policy_loss: 0.8640, value_loss: 0.3970
2024-07-14 07:50:34,122 [INFO    ] __main__: train step 23540: loss: 0.9293, policy_loss: 0.8640, value_loss: 0.3970
2024-07-14 07:50:34,393 [INFO    ] __main__: train step 23541: loss: 0.9293, policy_loss: 0.8640, value_loss: 0.3970
2024-07-14 07:50:36,012 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:50:36,485 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:50:36,553 [INFO    ] __main__: train step 23542: loss: 0.9293, policy_loss: 0.8640, value_loss: 0.3970
2024-07-14 07:50:36,875 [INFO    ] __main__: train step 23543: loss: 0.9292, policy_loss: 0.8640, value_loss: 0.3970
2024-07-14 07:50:37,193 [INFO    ] __main__: train step 23544: loss: 0.9292, policy_loss: 0.8639, value_loss: 0.3970
2024-07-14 07:50:37,496 [INFO    ] __main__: train step 23545: loss: 0.9292, policy_loss: 0.8639, value_loss: 0.3970
2024-07-14 07:50:37,786 [INFO    ] __main__: train step 23546: loss: 0.9292, policy_loss: 0.8639, value_loss: 0.3970
2024-07-14 07:50:38,084 [INFO    ] __main__: train step 23547: loss: 0.9292, policy_loss: 0.8639, value_loss: 0.3969
2024-07-14 07:50:38,391 [INFO    ] __main__: train step 23548: loss: 0.9292, policy_loss: 0.8639, value_loss: 0.3969
2024-07-14 07:50:38,674 [INFO    ] __main__: train step 23549: loss: 0.9292, policy_loss: 0.8639, value_loss: 0.3969
2024-07-14 07:50:38,959 [INFO    ] __main__: train step 23550: loss: 0.9292, policy_loss: 0.8639, value_loss: 0.3969
2024-07-14 07:50:39,233 [INFO    ] __main__: train step 23551: loss: 0.9292, policy_loss: 0.8639, value_loss: 0.3969
2024-07-14 07:50:39,508 [INFO    ] __main__: train step 23552: loss: 0.9292, policy_loss: 0.8639, value_loss: 0.3969
2024-07-14 07:50:39,761 [INFO    ] __main__: train step 23553: loss: 0.9292, policy_loss: 0.8639, value_loss: 0.3969
2024-07-14 07:50:40,038 [INFO    ] __main__: train step 23554: loss: 0.9292, policy_loss: 0.8638, value_loss: 0.3969
2024-07-14 07:50:40,320 [INFO    ] __main__: train step 23555: loss: 0.9292, policy_loss: 0.8638, value_loss: 0.3968
2024-07-14 07:50:40,605 [INFO    ] __main__: train step 23556: loss: 0.9291, policy_loss: 0.8638, value_loss: 0.3968
2024-07-14 07:50:40,881 [INFO    ] __main__: train step 23557: loss: 0.9291, policy_loss: 0.8638, value_loss: 0.3968
2024-07-14 07:50:41,182 [INFO    ] __main__: train step 23558: loss: 0.9291, policy_loss: 0.8638, value_loss: 0.3968
2024-07-14 07:50:42,770 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:50:43,250 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:50:43,324 [INFO    ] __main__: train step 23559: loss: 0.9291, policy_loss: 0.8638, value_loss: 0.3968
2024-07-14 07:50:43,635 [INFO    ] __main__: train step 23560: loss: 0.9291, policy_loss: 0.8638, value_loss: 0.3968
2024-07-14 07:50:43,955 [INFO    ] __main__: train step 23561: loss: 0.9291, policy_loss: 0.8638, value_loss: 0.3968
2024-07-14 07:50:44,245 [INFO    ] __main__: train step 23562: loss: 0.9291, policy_loss: 0.8638, value_loss: 0.3968
2024-07-14 07:50:44,525 [INFO    ] __main__: train step 23563: loss: 0.9291, policy_loss: 0.8638, value_loss: 0.3967
2024-07-14 07:50:44,828 [INFO    ] __main__: train step 23564: loss: 0.9291, policy_loss: 0.8638, value_loss: 0.3967
2024-07-14 07:50:45,109 [INFO    ] __main__: train step 23565: loss: 0.9291, policy_loss: 0.8637, value_loss: 0.3967
2024-07-14 07:50:45,396 [INFO    ] __main__: train step 23566: loss: 0.9291, policy_loss: 0.8637, value_loss: 0.3967
2024-07-14 07:50:45,682 [INFO    ] __main__: train step 23567: loss: 0.9291, policy_loss: 0.8637, value_loss: 0.3967
2024-07-14 07:50:45,985 [INFO    ] __main__: train step 23568: loss: 0.9291, policy_loss: 0.8637, value_loss: 0.3967
2024-07-14 07:50:46,260 [INFO    ] __main__: train step 23569: loss: 0.9290, policy_loss: 0.8637, value_loss: 0.3967
2024-07-14 07:50:46,548 [INFO    ] __main__: train step 23570: loss: 0.9290, policy_loss: 0.8637, value_loss: 0.3967
2024-07-14 07:50:46,852 [INFO    ] __main__: train step 23571: loss: 0.9290, policy_loss: 0.8637, value_loss: 0.3966
2024-07-14 07:50:47,153 [INFO    ] __main__: train step 23572: loss: 0.9290, policy_loss: 0.8637, value_loss: 0.3966
2024-07-14 07:50:47,454 [INFO    ] __main__: train step 23573: loss: 0.9290, policy_loss: 0.8637, value_loss: 0.3966
2024-07-14 07:50:47,756 [INFO    ] __main__: train step 23574: loss: 0.9290, policy_loss: 0.8637, value_loss: 0.3966
2024-07-14 07:50:48,042 [INFO    ] __main__: train step 23575: loss: 0.9290, policy_loss: 0.8636, value_loss: 0.3966
2024-07-14 07:50:49,634 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:50:50,072 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:50:50,143 [INFO    ] __main__: train step 23576: loss: 0.9290, policy_loss: 0.8636, value_loss: 0.3966
2024-07-14 07:50:50,437 [INFO    ] __main__: train step 23577: loss: 0.9290, policy_loss: 0.8636, value_loss: 0.3966
2024-07-14 07:50:50,730 [INFO    ] __main__: train step 23578: loss: 0.9290, policy_loss: 0.8636, value_loss: 0.3966
2024-07-14 07:50:51,016 [INFO    ] __main__: train step 23579: loss: 0.9290, policy_loss: 0.8636, value_loss: 0.3965
2024-07-14 07:50:51,293 [INFO    ] __main__: train step 23580: loss: 0.9290, policy_loss: 0.8636, value_loss: 0.3965
2024-07-14 07:50:51,576 [INFO    ] __main__: train step 23581: loss: 0.9289, policy_loss: 0.8636, value_loss: 0.3965
2024-07-14 07:50:51,862 [INFO    ] __main__: train step 23582: loss: 0.9289, policy_loss: 0.8636, value_loss: 0.3965
2024-07-14 07:50:52,131 [INFO    ] __main__: train step 23583: loss: 0.9289, policy_loss: 0.8636, value_loss: 0.3965
2024-07-14 07:50:52,407 [INFO    ] __main__: train step 23584: loss: 0.9289, policy_loss: 0.8636, value_loss: 0.3965
2024-07-14 07:50:56,967 [INFO    ] __main__: train step 23585: loss: 0.9289, policy_loss: 0.8635, value_loss: 0.3965
2024-07-14 07:50:57,257 [INFO    ] __main__: train step 23586: loss: 0.9289, policy_loss: 0.8635, value_loss: 0.3965
2024-07-14 07:50:57,546 [INFO    ] __main__: train step 23587: loss: 0.9289, policy_loss: 0.8635, value_loss: 0.3964
2024-07-14 07:50:57,842 [INFO    ] __main__: train step 23588: loss: 0.9289, policy_loss: 0.8635, value_loss: 0.3964
2024-07-14 07:50:58,143 [INFO    ] __main__: train step 23589: loss: 0.9289, policy_loss: 0.8635, value_loss: 0.3964
2024-07-14 07:50:58,422 [INFO    ] __main__: train step 23590: loss: 0.9289, policy_loss: 0.8635, value_loss: 0.3964
2024-07-14 07:50:58,687 [INFO    ] __main__: train step 23591: loss: 0.9289, policy_loss: 0.8635, value_loss: 0.3964
2024-07-14 07:50:58,953 [INFO    ] __main__: train step 23592: loss: 0.9289, policy_loss: 0.8635, value_loss: 0.3964
2024-07-14 07:51:00,546 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:51:00,957 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:51:01,031 [INFO    ] __main__: train step 23593: loss: 0.9289, policy_loss: 0.8635, value_loss: 0.3964
2024-07-14 07:51:01,305 [INFO    ] __main__: train step 23594: loss: 0.9288, policy_loss: 0.8635, value_loss: 0.3964
2024-07-14 07:51:01,562 [INFO    ] __main__: train step 23595: loss: 0.9288, policy_loss: 0.8635, value_loss: 0.3963
2024-07-14 07:51:01,842 [INFO    ] __main__: train step 23596: loss: 0.9288, policy_loss: 0.8634, value_loss: 0.3963
2024-07-14 07:51:02,102 [INFO    ] __main__: train step 23597: loss: 0.9288, policy_loss: 0.8634, value_loss: 0.3963
2024-07-14 07:51:02,384 [INFO    ] __main__: train step 23598: loss: 0.9288, policy_loss: 0.8634, value_loss: 0.3963
2024-07-14 07:51:02,659 [INFO    ] __main__: train step 23599: loss: 0.9288, policy_loss: 0.8634, value_loss: 0.3963
2024-07-14 07:51:02,907 [INFO    ] __main__: train step 23600: loss: 0.9288, policy_loss: 0.8634, value_loss: 0.3963
2024-07-14 07:51:03,166 [INFO    ] __main__: train step 23601: loss: 0.9288, policy_loss: 0.8634, value_loss: 0.3963
2024-07-14 07:51:03,422 [INFO    ] __main__: train step 23602: loss: 0.9288, policy_loss: 0.8634, value_loss: 0.3963
2024-07-14 07:51:03,683 [INFO    ] __main__: train step 23603: loss: 0.9288, policy_loss: 0.8634, value_loss: 0.3963
2024-07-14 07:51:03,931 [INFO    ] __main__: train step 23604: loss: 0.9288, policy_loss: 0.8634, value_loss: 0.3962
2024-07-14 07:51:04,204 [INFO    ] __main__: train step 23605: loss: 0.9288, policy_loss: 0.8634, value_loss: 0.3962
2024-07-14 07:51:04,477 [INFO    ] __main__: train step 23606: loss: 0.9288, policy_loss: 0.8633, value_loss: 0.3962
2024-07-14 07:51:04,745 [INFO    ] __main__: train step 23607: loss: 0.9287, policy_loss: 0.8633, value_loss: 0.3962
2024-07-14 07:51:05,015 [INFO    ] __main__: train step 23608: loss: 0.9287, policy_loss: 0.8633, value_loss: 0.3962
2024-07-14 07:51:05,290 [INFO    ] __main__: train step 23609: loss: 0.9287, policy_loss: 0.8633, value_loss: 0.3962
2024-07-14 07:51:06,882 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:51:07,296 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:51:07,360 [INFO    ] __main__: train step 23610: loss: 0.9287, policy_loss: 0.8633, value_loss: 0.3962
2024-07-14 07:51:07,632 [INFO    ] __main__: train step 23611: loss: 0.9287, policy_loss: 0.8633, value_loss: 0.3962
2024-07-14 07:51:07,893 [INFO    ] __main__: train step 23612: loss: 0.9287, policy_loss: 0.8633, value_loss: 0.3961
2024-07-14 07:51:08,160 [INFO    ] __main__: train step 23613: loss: 0.9287, policy_loss: 0.8633, value_loss: 0.3961
2024-07-14 07:51:08,422 [INFO    ] __main__: train step 23614: loss: 0.9287, policy_loss: 0.8633, value_loss: 0.3961
2024-07-14 07:51:08,699 [INFO    ] __main__: train step 23615: loss: 0.9287, policy_loss: 0.8633, value_loss: 0.3961
2024-07-14 07:51:08,973 [INFO    ] __main__: train step 23616: loss: 0.9287, policy_loss: 0.8633, value_loss: 0.3961
2024-07-14 07:51:09,239 [INFO    ] __main__: train step 23617: loss: 0.9287, policy_loss: 0.8632, value_loss: 0.3961
2024-07-14 07:51:09,502 [INFO    ] __main__: train step 23618: loss: 0.9287, policy_loss: 0.8632, value_loss: 0.3961
2024-07-14 07:51:09,752 [INFO    ] __main__: train step 23619: loss: 0.9287, policy_loss: 0.8632, value_loss: 0.3961
2024-07-14 07:51:10,054 [INFO    ] __main__: train step 23620: loss: 0.9286, policy_loss: 0.8632, value_loss: 0.3960
2024-07-14 07:51:10,362 [INFO    ] __main__: train step 23621: loss: 0.9286, policy_loss: 0.8632, value_loss: 0.3960
2024-07-14 07:51:10,666 [INFO    ] __main__: train step 23622: loss: 0.9286, policy_loss: 0.8632, value_loss: 0.3960
2024-07-14 07:51:10,952 [INFO    ] __main__: train step 23623: loss: 0.9286, policy_loss: 0.8632, value_loss: 0.3960
2024-07-14 07:51:11,227 [INFO    ] __main__: train step 23624: loss: 0.9286, policy_loss: 0.8632, value_loss: 0.3960
2024-07-14 07:51:11,493 [INFO    ] __main__: train step 23625: loss: 0.9286, policy_loss: 0.8632, value_loss: 0.3960
2024-07-14 07:51:11,752 [INFO    ] __main__: train step 23626: loss: 0.9286, policy_loss: 0.8632, value_loss: 0.3960
2024-07-14 07:51:13,354 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:51:13,802 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:51:13,868 [INFO    ] __main__: train step 23627: loss: 0.9286, policy_loss: 0.8631, value_loss: 0.3960
2024-07-14 07:51:14,163 [INFO    ] __main__: train step 23628: loss: 0.9286, policy_loss: 0.8631, value_loss: 0.3959
2024-07-14 07:51:14,473 [INFO    ] __main__: train step 23629: loss: 0.9286, policy_loss: 0.8631, value_loss: 0.3959
2024-07-14 07:51:14,733 [INFO    ] __main__: train step 23630: loss: 0.9286, policy_loss: 0.8631, value_loss: 0.3959
2024-07-14 07:51:15,011 [INFO    ] __main__: train step 23631: loss: 0.9286, policy_loss: 0.8631, value_loss: 0.3959
2024-07-14 07:51:15,281 [INFO    ] __main__: train step 23632: loss: 0.9285, policy_loss: 0.8631, value_loss: 0.3959
2024-07-14 07:51:15,542 [INFO    ] __main__: train step 23633: loss: 0.9285, policy_loss: 0.8631, value_loss: 0.3959
2024-07-14 07:51:15,832 [INFO    ] __main__: train step 23634: loss: 0.9285, policy_loss: 0.8631, value_loss: 0.3959
2024-07-14 07:51:16,118 [INFO    ] __main__: train step 23635: loss: 0.9285, policy_loss: 0.8631, value_loss: 0.3959
2024-07-14 07:51:16,382 [INFO    ] __main__: train step 23636: loss: 0.9285, policy_loss: 0.8631, value_loss: 0.3958
2024-07-14 07:51:16,661 [INFO    ] __main__: train step 23637: loss: 0.9285, policy_loss: 0.8631, value_loss: 0.3958
2024-07-14 07:51:16,928 [INFO    ] __main__: train step 23638: loss: 0.9285, policy_loss: 0.8630, value_loss: 0.3958
2024-07-14 07:51:17,236 [INFO    ] __main__: train step 23639: loss: 0.9285, policy_loss: 0.8630, value_loss: 0.3958
2024-07-14 07:51:17,551 [INFO    ] __main__: train step 23640: loss: 0.9285, policy_loss: 0.8630, value_loss: 0.3958
2024-07-14 07:51:17,854 [INFO    ] __main__: train step 23641: loss: 0.9285, policy_loss: 0.8630, value_loss: 0.3958
2024-07-14 07:51:18,140 [INFO    ] __main__: train step 23642: loss: 0.9285, policy_loss: 0.8630, value_loss: 0.3958
2024-07-14 07:51:18,413 [INFO    ] __main__: train step 23643: loss: 0.9285, policy_loss: 0.8630, value_loss: 0.3958
2024-07-14 07:51:20,020 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:51:20,432 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:51:20,495 [INFO    ] __main__: train step 23644: loss: 0.9285, policy_loss: 0.8630, value_loss: 0.3957
2024-07-14 07:51:20,777 [INFO    ] __main__: train step 23645: loss: 0.9284, policy_loss: 0.8630, value_loss: 0.3957
2024-07-14 07:51:21,049 [INFO    ] __main__: train step 23646: loss: 0.9284, policy_loss: 0.8630, value_loss: 0.3957
2024-07-14 07:51:21,320 [INFO    ] __main__: train step 23647: loss: 0.9284, policy_loss: 0.8630, value_loss: 0.3957
2024-07-14 07:51:21,599 [INFO    ] __main__: train step 23648: loss: 0.9284, policy_loss: 0.8629, value_loss: 0.3957
2024-07-14 07:51:21,867 [INFO    ] __main__: train step 23649: loss: 0.9284, policy_loss: 0.8629, value_loss: 0.3957
2024-07-14 07:51:22,148 [INFO    ] __main__: train step 23650: loss: 0.9284, policy_loss: 0.8629, value_loss: 0.3957
2024-07-14 07:51:22,418 [INFO    ] __main__: train step 23651: loss: 0.9284, policy_loss: 0.8629, value_loss: 0.3957
2024-07-14 07:51:22,697 [INFO    ] __main__: train step 23652: loss: 0.9284, policy_loss: 0.8629, value_loss: 0.3956
2024-07-14 07:51:22,979 [INFO    ] __main__: train step 23653: loss: 0.9284, policy_loss: 0.8629, value_loss: 0.3956
2024-07-14 07:51:23,270 [INFO    ] __main__: train step 23654: loss: 0.9284, policy_loss: 0.8629, value_loss: 0.3956
2024-07-14 07:51:23,563 [INFO    ] __main__: train step 23655: loss: 0.9284, policy_loss: 0.8629, value_loss: 0.3956
2024-07-14 07:51:23,864 [INFO    ] __main__: train step 23656: loss: 0.9284, policy_loss: 0.8629, value_loss: 0.3956
2024-07-14 07:51:24,138 [INFO    ] __main__: train step 23657: loss: 0.9284, policy_loss: 0.8629, value_loss: 0.3956
2024-07-14 07:51:24,430 [INFO    ] __main__: train step 23658: loss: 0.9283, policy_loss: 0.8629, value_loss: 0.3956
2024-07-14 07:51:24,705 [INFO    ] __main__: train step 23659: loss: 0.9283, policy_loss: 0.8628, value_loss: 0.3956
2024-07-14 07:51:24,978 [INFO    ] __main__: train step 23660: loss: 0.9283, policy_loss: 0.8628, value_loss: 0.3956
2024-07-14 07:51:26,598 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:51:27,038 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:51:27,120 [INFO    ] __main__: train step 23661: loss: 0.9283, policy_loss: 0.8628, value_loss: 0.3955
2024-07-14 07:51:27,458 [INFO    ] __main__: train step 23662: loss: 0.9283, policy_loss: 0.8628, value_loss: 0.3955
2024-07-14 07:51:27,743 [INFO    ] __main__: train step 23663: loss: 0.9283, policy_loss: 0.8628, value_loss: 0.3955
2024-07-14 07:51:28,011 [INFO    ] __main__: train step 23664: loss: 0.9283, policy_loss: 0.8628, value_loss: 0.3955
2024-07-14 07:51:28,259 [INFO    ] __main__: train step 23665: loss: 0.9283, policy_loss: 0.8628, value_loss: 0.3955
2024-07-14 07:51:28,545 [INFO    ] __main__: train step 23666: loss: 0.9283, policy_loss: 0.8628, value_loss: 0.3955
2024-07-14 07:51:28,819 [INFO    ] __main__: train step 23667: loss: 0.9283, policy_loss: 0.8628, value_loss: 0.3955
2024-07-14 07:51:29,088 [INFO    ] __main__: train step 23668: loss: 0.9283, policy_loss: 0.8628, value_loss: 0.3955
2024-07-14 07:51:29,365 [INFO    ] __main__: train step 23669: loss: 0.9283, policy_loss: 0.8627, value_loss: 0.3954
2024-07-14 07:51:29,650 [INFO    ] __main__: train step 23670: loss: 0.9283, policy_loss: 0.8627, value_loss: 0.3954
2024-07-14 07:51:29,938 [INFO    ] __main__: train step 23671: loss: 0.9282, policy_loss: 0.8627, value_loss: 0.3954
2024-07-14 07:51:30,221 [INFO    ] __main__: train step 23672: loss: 0.9282, policy_loss: 0.8627, value_loss: 0.3954
2024-07-14 07:51:30,507 [INFO    ] __main__: train step 23673: loss: 0.9282, policy_loss: 0.8627, value_loss: 0.3954
2024-07-14 07:51:30,801 [INFO    ] __main__: train step 23674: loss: 0.9282, policy_loss: 0.8627, value_loss: 0.3954
2024-07-14 07:51:31,106 [INFO    ] __main__: train step 23675: loss: 0.9282, policy_loss: 0.8627, value_loss: 0.3954
2024-07-14 07:51:31,395 [INFO    ] __main__: train step 23676: loss: 0.9282, policy_loss: 0.8627, value_loss: 0.3954
2024-07-14 07:51:31,691 [INFO    ] __main__: train step 23677: loss: 0.9282, policy_loss: 0.8627, value_loss: 0.3953
2024-07-14 07:51:33,301 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:51:33,751 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:51:33,821 [INFO    ] __main__: train step 23678: loss: 0.9282, policy_loss: 0.8627, value_loss: 0.3953
2024-07-14 07:51:34,108 [INFO    ] __main__: train step 23679: loss: 0.9282, policy_loss: 0.8627, value_loss: 0.3953
2024-07-14 07:51:34,391 [INFO    ] __main__: train step 23680: loss: 0.9282, policy_loss: 0.8626, value_loss: 0.3953
2024-07-14 07:51:34,662 [INFO    ] __main__: train step 23681: loss: 0.9282, policy_loss: 0.8626, value_loss: 0.3953
2024-07-14 07:51:34,938 [INFO    ] __main__: train step 23682: loss: 0.9282, policy_loss: 0.8626, value_loss: 0.3953
2024-07-14 07:51:35,226 [INFO    ] __main__: train step 23683: loss: 0.9282, policy_loss: 0.8626, value_loss: 0.3953
2024-07-14 07:51:35,503 [INFO    ] __main__: train step 23684: loss: 0.9282, policy_loss: 0.8626, value_loss: 0.3953
2024-07-14 07:51:35,788 [INFO    ] __main__: train step 23685: loss: 0.9281, policy_loss: 0.8626, value_loss: 0.3952
2024-07-14 07:51:36,088 [INFO    ] __main__: train step 23686: loss: 0.9281, policy_loss: 0.8626, value_loss: 0.3952
2024-07-14 07:51:36,372 [INFO    ] __main__: train step 23687: loss: 0.9281, policy_loss: 0.8626, value_loss: 0.3952
2024-07-14 07:51:36,655 [INFO    ] __main__: train step 23688: loss: 0.9281, policy_loss: 0.8626, value_loss: 0.3952
2024-07-14 07:51:36,963 [INFO    ] __main__: train step 23689: loss: 0.9281, policy_loss: 0.8626, value_loss: 0.3952
2024-07-14 07:51:37,266 [INFO    ] __main__: train step 23690: loss: 0.9281, policy_loss: 0.8626, value_loss: 0.3952
2024-07-14 07:51:37,564 [INFO    ] __main__: train step 23691: loss: 0.9281, policy_loss: 0.8625, value_loss: 0.3952
2024-07-14 07:51:37,879 [INFO    ] __main__: train step 23692: loss: 0.9281, policy_loss: 0.8625, value_loss: 0.3952
2024-07-14 07:51:38,179 [INFO    ] __main__: train step 23693: loss: 0.9281, policy_loss: 0.8625, value_loss: 0.3952
2024-07-14 07:51:38,483 [INFO    ] __main__: train step 23694: loss: 0.9281, policy_loss: 0.8625, value_loss: 0.3951
2024-07-14 07:51:40,112 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:51:40,552 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:51:40,618 [INFO    ] __main__: train step 23695: loss: 0.9281, policy_loss: 0.8625, value_loss: 0.3951
2024-07-14 07:51:40,916 [INFO    ] __main__: train step 23696: loss: 0.9281, policy_loss: 0.8625, value_loss: 0.3951
2024-07-14 07:51:41,243 [INFO    ] __main__: train step 23697: loss: 0.9281, policy_loss: 0.8625, value_loss: 0.3951
2024-07-14 07:51:41,538 [INFO    ] __main__: train step 23698: loss: 0.9280, policy_loss: 0.8625, value_loss: 0.3951
2024-07-14 07:51:41,816 [INFO    ] __main__: train step 23699: loss: 0.9280, policy_loss: 0.8625, value_loss: 0.3951
2024-07-14 07:51:42,110 [INFO    ] __main__: train step 23700: loss: 0.9280, policy_loss: 0.8625, value_loss: 0.3951
2024-07-14 07:51:42,396 [INFO    ] __main__: train step 23701: loss: 0.9280, policy_loss: 0.8625, value_loss: 0.3951
2024-07-14 07:51:42,702 [INFO    ] __main__: train step 23702: loss: 0.9280, policy_loss: 0.8624, value_loss: 0.3950
2024-07-14 07:51:43,007 [INFO    ] __main__: train step 23703: loss: 0.9280, policy_loss: 0.8624, value_loss: 0.3950
2024-07-14 07:51:43,306 [INFO    ] __main__: train step 23704: loss: 0.9280, policy_loss: 0.8624, value_loss: 0.3950
2024-07-14 07:51:43,608 [INFO    ] __main__: train step 23705: loss: 0.9280, policy_loss: 0.8624, value_loss: 0.3950
2024-07-14 07:51:43,924 [INFO    ] __main__: train step 23706: loss: 0.9280, policy_loss: 0.8624, value_loss: 0.3950
2024-07-14 07:51:44,233 [INFO    ] __main__: train step 23707: loss: 0.9280, policy_loss: 0.8624, value_loss: 0.3950
2024-07-14 07:51:44,525 [INFO    ] __main__: train step 23708: loss: 0.9280, policy_loss: 0.8624, value_loss: 0.3950
2024-07-14 07:51:44,826 [INFO    ] __main__: train step 23709: loss: 0.9280, policy_loss: 0.8624, value_loss: 0.3950
2024-07-14 07:51:45,098 [INFO    ] __main__: train step 23710: loss: 0.9280, policy_loss: 0.8624, value_loss: 0.3949
2024-07-14 07:51:45,382 [INFO    ] __main__: train step 23711: loss: 0.9280, policy_loss: 0.8624, value_loss: 0.3949
2024-07-14 07:51:54,047 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:51:54,503 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:51:54,575 [INFO    ] __main__: train step 23712: loss: 0.9279, policy_loss: 0.8624, value_loss: 0.3949
2024-07-14 07:51:54,912 [INFO    ] __main__: train step 23713: loss: 0.9279, policy_loss: 0.8623, value_loss: 0.3949
2024-07-14 07:51:55,205 [INFO    ] __main__: train step 23714: loss: 0.9279, policy_loss: 0.8623, value_loss: 0.3949
2024-07-14 07:51:55,508 [INFO    ] __main__: train step 23715: loss: 0.9279, policy_loss: 0.8623, value_loss: 0.3949
2024-07-14 07:51:55,803 [INFO    ] __main__: train step 23716: loss: 0.9279, policy_loss: 0.8623, value_loss: 0.3949
2024-07-14 07:51:56,105 [INFO    ] __main__: train step 23717: loss: 0.9279, policy_loss: 0.8623, value_loss: 0.3949
2024-07-14 07:51:56,418 [INFO    ] __main__: train step 23718: loss: 0.9279, policy_loss: 0.8623, value_loss: 0.3949
2024-07-14 07:51:56,731 [INFO    ] __main__: train step 23719: loss: 0.9279, policy_loss: 0.8623, value_loss: 0.3948
2024-07-14 07:51:57,015 [INFO    ] __main__: train step 23720: loss: 0.9279, policy_loss: 0.8623, value_loss: 0.3948
2024-07-14 07:51:57,316 [INFO    ] __main__: train step 23721: loss: 0.9279, policy_loss: 0.8623, value_loss: 0.3948
2024-07-14 07:51:57,638 [INFO    ] __main__: train step 23722: loss: 0.9279, policy_loss: 0.8623, value_loss: 0.3948
2024-07-14 07:51:57,951 [INFO    ] __main__: train step 23723: loss: 0.9279, policy_loss: 0.8622, value_loss: 0.3948
2024-07-14 07:51:58,251 [INFO    ] __main__: train step 23724: loss: 0.9279, policy_loss: 0.8622, value_loss: 0.3948
2024-07-14 07:51:58,526 [INFO    ] __main__: train step 23725: loss: 0.9278, policy_loss: 0.8622, value_loss: 0.3948
2024-07-14 07:51:58,813 [INFO    ] __main__: train step 23726: loss: 0.9278, policy_loss: 0.8622, value_loss: 0.3948
2024-07-14 07:51:59,117 [INFO    ] __main__: train step 23727: loss: 0.9278, policy_loss: 0.8622, value_loss: 0.3947
2024-07-14 07:51:59,421 [INFO    ] __main__: train step 23728: loss: 0.9278, policy_loss: 0.8622, value_loss: 0.3947
2024-07-14 07:52:01,061 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:52:01,500 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:52:01,568 [INFO    ] __main__: train step 23729: loss: 0.9278, policy_loss: 0.8622, value_loss: 0.3947
2024-07-14 07:52:01,859 [INFO    ] __main__: train step 23730: loss: 0.9278, policy_loss: 0.8622, value_loss: 0.3947
2024-07-14 07:52:02,158 [INFO    ] __main__: train step 23731: loss: 0.9278, policy_loss: 0.8622, value_loss: 0.3947
2024-07-14 07:52:02,453 [INFO    ] __main__: train step 23732: loss: 0.9278, policy_loss: 0.8622, value_loss: 0.3947
2024-07-14 07:52:02,750 [INFO    ] __main__: train step 23733: loss: 0.9278, policy_loss: 0.8622, value_loss: 0.3947
2024-07-14 07:52:03,063 [INFO    ] __main__: train step 23734: loss: 0.9278, policy_loss: 0.8621, value_loss: 0.3947
2024-07-14 07:52:03,344 [INFO    ] __main__: train step 23735: loss: 0.9278, policy_loss: 0.8621, value_loss: 0.3946
2024-07-14 07:52:03,644 [INFO    ] __main__: train step 23736: loss: 0.9278, policy_loss: 0.8621, value_loss: 0.3946
2024-07-14 07:52:03,957 [INFO    ] __main__: train step 23737: loss: 0.9278, policy_loss: 0.8621, value_loss: 0.3946
2024-07-14 07:52:04,264 [INFO    ] __main__: train step 23738: loss: 0.9278, policy_loss: 0.8621, value_loss: 0.3946
2024-07-14 07:52:04,567 [INFO    ] __main__: train step 23739: loss: 0.9277, policy_loss: 0.8621, value_loss: 0.3946
2024-07-14 07:52:04,852 [INFO    ] __main__: train step 23740: loss: 0.9277, policy_loss: 0.8621, value_loss: 0.3946
2024-07-14 07:52:05,155 [INFO    ] __main__: train step 23741: loss: 0.9277, policy_loss: 0.8621, value_loss: 0.3946
2024-07-14 07:52:05,463 [INFO    ] __main__: train step 23742: loss: 0.9277, policy_loss: 0.8621, value_loss: 0.3946
2024-07-14 07:52:05,782 [INFO    ] __main__: train step 23743: loss: 0.9277, policy_loss: 0.8621, value_loss: 0.3946
2024-07-14 07:52:06,087 [INFO    ] __main__: train step 23744: loss: 0.9277, policy_loss: 0.8621, value_loss: 0.3945
2024-07-14 07:52:06,376 [INFO    ] __main__: train step 23745: loss: 0.9277, policy_loss: 0.8620, value_loss: 0.3945
2024-07-14 07:52:07,964 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:52:08,390 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:52:08,455 [INFO    ] __main__: train step 23746: loss: 0.9277, policy_loss: 0.8620, value_loss: 0.3945
2024-07-14 07:52:08,731 [INFO    ] __main__: train step 23747: loss: 0.9277, policy_loss: 0.8620, value_loss: 0.3945
2024-07-14 07:52:09,012 [INFO    ] __main__: train step 23748: loss: 0.9277, policy_loss: 0.8620, value_loss: 0.3945
2024-07-14 07:52:09,293 [INFO    ] __main__: train step 23749: loss: 0.9277, policy_loss: 0.8620, value_loss: 0.3945
2024-07-14 07:52:09,589 [INFO    ] __main__: train step 23750: loss: 0.9277, policy_loss: 0.8620, value_loss: 0.3945
2024-07-14 07:52:09,900 [INFO    ] __main__: train step 23751: loss: 0.9277, policy_loss: 0.8620, value_loss: 0.3945
2024-07-14 07:52:10,193 [INFO    ] __main__: train step 23752: loss: 0.9276, policy_loss: 0.8620, value_loss: 0.3944
2024-07-14 07:52:10,501 [INFO    ] __main__: train step 23753: loss: 0.9276, policy_loss: 0.8620, value_loss: 0.3944
2024-07-14 07:52:10,807 [INFO    ] __main__: train step 23754: loss: 0.9276, policy_loss: 0.8620, value_loss: 0.3944
2024-07-14 07:52:11,190 [INFO    ] __main__: train step 23755: loss: 0.9276, policy_loss: 0.8620, value_loss: 0.3944
2024-07-14 07:52:11,491 [INFO    ] __main__: train step 23756: loss: 0.9276, policy_loss: 0.8619, value_loss: 0.3944
2024-07-14 07:52:11,791 [INFO    ] __main__: train step 23757: loss: 0.9276, policy_loss: 0.8619, value_loss: 0.3944
2024-07-14 07:52:12,100 [INFO    ] __main__: train step 23758: loss: 0.9276, policy_loss: 0.8619, value_loss: 0.3944
2024-07-14 07:52:12,399 [INFO    ] __main__: train step 23759: loss: 0.9276, policy_loss: 0.8619, value_loss: 0.3944
2024-07-14 07:52:12,702 [INFO    ] __main__: train step 23760: loss: 0.9276, policy_loss: 0.8619, value_loss: 0.3943
2024-07-14 07:52:13,049 [INFO    ] __main__: train step 23761: loss: 0.9276, policy_loss: 0.8619, value_loss: 0.3943
2024-07-14 07:52:13,346 [INFO    ] __main__: train step 23762: loss: 0.9276, policy_loss: 0.8619, value_loss: 0.3943
2024-07-14 07:52:14,955 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:52:15,417 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:52:15,490 [INFO    ] __main__: train step 23763: loss: 0.9276, policy_loss: 0.8619, value_loss: 0.3943
2024-07-14 07:52:15,799 [INFO    ] __main__: train step 23764: loss: 0.9276, policy_loss: 0.8619, value_loss: 0.3943
2024-07-14 07:52:16,109 [INFO    ] __main__: train step 23765: loss: 0.9276, policy_loss: 0.8619, value_loss: 0.3943
2024-07-14 07:52:16,404 [INFO    ] __main__: train step 23766: loss: 0.9276, policy_loss: 0.8619, value_loss: 0.3943
2024-07-14 07:52:16,710 [INFO    ] __main__: train step 23767: loss: 0.9275, policy_loss: 0.8618, value_loss: 0.3943
2024-07-14 07:52:17,012 [INFO    ] __main__: train step 23768: loss: 0.9275, policy_loss: 0.8618, value_loss: 0.3943
2024-07-14 07:52:17,312 [INFO    ] __main__: train step 23769: loss: 0.9275, policy_loss: 0.8618, value_loss: 0.3942
2024-07-14 07:52:17,635 [INFO    ] __main__: train step 23770: loss: 0.9275, policy_loss: 0.8618, value_loss: 0.3942
2024-07-14 07:52:17,901 [INFO    ] __main__: train step 23771: loss: 0.9275, policy_loss: 0.8618, value_loss: 0.3942
2024-07-14 07:52:18,188 [INFO    ] __main__: train step 23772: loss: 0.9275, policy_loss: 0.8618, value_loss: 0.3942
2024-07-14 07:52:18,493 [INFO    ] __main__: train step 23773: loss: 0.9275, policy_loss: 0.8618, value_loss: 0.3942
2024-07-14 07:52:18,796 [INFO    ] __main__: train step 23774: loss: 0.9275, policy_loss: 0.8618, value_loss: 0.3942
2024-07-14 07:52:19,069 [INFO    ] __main__: train step 23775: loss: 0.9275, policy_loss: 0.8618, value_loss: 0.3942
2024-07-14 07:52:19,375 [INFO    ] __main__: train step 23776: loss: 0.9275, policy_loss: 0.8618, value_loss: 0.3942
2024-07-14 07:52:19,640 [INFO    ] __main__: train step 23777: loss: 0.9275, policy_loss: 0.8618, value_loss: 0.3941
2024-07-14 07:52:19,915 [INFO    ] __main__: train step 23778: loss: 0.9275, policy_loss: 0.8617, value_loss: 0.3941
2024-07-14 07:52:20,195 [INFO    ] __main__: train step 23779: loss: 0.9275, policy_loss: 0.8617, value_loss: 0.3941
2024-07-14 07:52:21,804 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:52:22,231 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:52:22,297 [INFO    ] __main__: train step 23780: loss: 0.9275, policy_loss: 0.8617, value_loss: 0.3941
2024-07-14 07:52:22,582 [INFO    ] __main__: train step 23781: loss: 0.9274, policy_loss: 0.8617, value_loss: 0.3941
2024-07-14 07:52:22,850 [INFO    ] __main__: train step 23782: loss: 0.9274, policy_loss: 0.8617, value_loss: 0.3941
2024-07-14 07:52:23,134 [INFO    ] __main__: train step 23783: loss: 0.9274, policy_loss: 0.8617, value_loss: 0.3941
2024-07-14 07:52:23,418 [INFO    ] __main__: train step 23784: loss: 0.9274, policy_loss: 0.8617, value_loss: 0.3941
2024-07-14 07:52:23,720 [INFO    ] __main__: train step 23785: loss: 0.9274, policy_loss: 0.8617, value_loss: 0.3940
2024-07-14 07:52:24,018 [INFO    ] __main__: train step 23786: loss: 0.9274, policy_loss: 0.8617, value_loss: 0.3940
2024-07-14 07:52:24,300 [INFO    ] __main__: train step 23787: loss: 0.9274, policy_loss: 0.8617, value_loss: 0.3940
2024-07-14 07:52:24,574 [INFO    ] __main__: train step 23788: loss: 0.9274, policy_loss: 0.8617, value_loss: 0.3940
2024-07-14 07:52:24,898 [INFO    ] __main__: train step 23789: loss: 0.9274, policy_loss: 0.8617, value_loss: 0.3940
2024-07-14 07:52:25,199 [INFO    ] __main__: train step 23790: loss: 0.9274, policy_loss: 0.8616, value_loss: 0.3940
2024-07-14 07:52:25,495 [INFO    ] __main__: train step 23791: loss: 0.9274, policy_loss: 0.8616, value_loss: 0.3940
2024-07-14 07:52:25,795 [INFO    ] __main__: train step 23792: loss: 0.9274, policy_loss: 0.8616, value_loss: 0.3940
2024-07-14 07:52:26,080 [INFO    ] __main__: train step 23793: loss: 0.9274, policy_loss: 0.8616, value_loss: 0.3940
2024-07-14 07:52:26,350 [INFO    ] __main__: train step 23794: loss: 0.9274, policy_loss: 0.8616, value_loss: 0.3939
2024-07-14 07:52:26,682 [INFO    ] __main__: train step 23795: loss: 0.9273, policy_loss: 0.8616, value_loss: 0.3939
2024-07-14 07:52:26,980 [INFO    ] __main__: train step 23796: loss: 0.9273, policy_loss: 0.8616, value_loss: 0.3939
2024-07-14 07:52:28,605 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:52:29,055 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:52:29,117 [INFO    ] __main__: train step 23797: loss: 0.9273, policy_loss: 0.8616, value_loss: 0.3939
2024-07-14 07:52:29,384 [INFO    ] __main__: train step 23798: loss: 0.9273, policy_loss: 0.8616, value_loss: 0.3939
2024-07-14 07:52:29,677 [INFO    ] __main__: train step 23799: loss: 0.9273, policy_loss: 0.8616, value_loss: 0.3939
2024-07-14 07:52:29,972 [INFO    ] __main__: train step 23800: loss: 0.9273, policy_loss: 0.8616, value_loss: 0.3939
2024-07-14 07:52:30,276 [INFO    ] __main__: train step 23801: loss: 0.9273, policy_loss: 0.8615, value_loss: 0.3939
2024-07-14 07:52:30,547 [INFO    ] __main__: train step 23802: loss: 0.9273, policy_loss: 0.8615, value_loss: 0.3938
2024-07-14 07:52:30,842 [INFO    ] __main__: train step 23803: loss: 0.9273, policy_loss: 0.8615, value_loss: 0.3938
2024-07-14 07:52:31,142 [INFO    ] __main__: train step 23804: loss: 0.9273, policy_loss: 0.8615, value_loss: 0.3938
2024-07-14 07:52:31,438 [INFO    ] __main__: train step 23805: loss: 0.9273, policy_loss: 0.8615, value_loss: 0.3938
2024-07-14 07:52:31,737 [INFO    ] __main__: train step 23806: loss: 0.9273, policy_loss: 0.8615, value_loss: 0.3938
2024-07-14 07:52:32,055 [INFO    ] __main__: train step 23807: loss: 0.9273, policy_loss: 0.8615, value_loss: 0.3938
2024-07-14 07:52:32,339 [INFO    ] __main__: train step 23808: loss: 0.9273, policy_loss: 0.8615, value_loss: 0.3938
2024-07-14 07:52:32,617 [INFO    ] __main__: train step 23809: loss: 0.9272, policy_loss: 0.8615, value_loss: 0.3938
2024-07-14 07:52:32,912 [INFO    ] __main__: train step 23810: loss: 0.9272, policy_loss: 0.8615, value_loss: 0.3938
2024-07-14 07:52:33,197 [INFO    ] __main__: train step 23811: loss: 0.9272, policy_loss: 0.8615, value_loss: 0.3937
2024-07-14 07:52:33,497 [INFO    ] __main__: train step 23812: loss: 0.9272, policy_loss: 0.8614, value_loss: 0.3937
2024-07-14 07:52:33,799 [INFO    ] __main__: train step 23813: loss: 0.9272, policy_loss: 0.8614, value_loss: 0.3937
2024-07-14 07:52:35,415 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:52:35,849 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:52:35,914 [INFO    ] __main__: train step 23814: loss: 0.9272, policy_loss: 0.8614, value_loss: 0.3937
2024-07-14 07:52:36,213 [INFO    ] __main__: train step 23815: loss: 0.9272, policy_loss: 0.8614, value_loss: 0.3937
2024-07-14 07:52:36,512 [INFO    ] __main__: train step 23816: loss: 0.9272, policy_loss: 0.8614, value_loss: 0.3937
2024-07-14 07:52:36,799 [INFO    ] __main__: train step 23817: loss: 0.9272, policy_loss: 0.8614, value_loss: 0.3937
2024-07-14 07:52:37,085 [INFO    ] __main__: train step 23818: loss: 0.9272, policy_loss: 0.8614, value_loss: 0.3937
2024-07-14 07:52:37,390 [INFO    ] __main__: train step 23819: loss: 0.9272, policy_loss: 0.8614, value_loss: 0.3936
2024-07-14 07:52:37,702 [INFO    ] __main__: train step 23820: loss: 0.9272, policy_loss: 0.8614, value_loss: 0.3936
2024-07-14 07:52:38,007 [INFO    ] __main__: train step 23821: loss: 0.9272, policy_loss: 0.8614, value_loss: 0.3936
2024-07-14 07:52:38,319 [INFO    ] __main__: train step 23822: loss: 0.9272, policy_loss: 0.8614, value_loss: 0.3936
2024-07-14 07:52:38,620 [INFO    ] __main__: train step 23823: loss: 0.9272, policy_loss: 0.8613, value_loss: 0.3936
2024-07-14 07:52:38,883 [INFO    ] __main__: train step 23824: loss: 0.9271, policy_loss: 0.8613, value_loss: 0.3936
2024-07-14 07:52:39,180 [INFO    ] __main__: train step 23825: loss: 0.9271, policy_loss: 0.8613, value_loss: 0.3936
2024-07-14 07:52:39,495 [INFO    ] __main__: train step 23826: loss: 0.9271, policy_loss: 0.8613, value_loss: 0.3936
2024-07-14 07:52:39,809 [INFO    ] __main__: train step 23827: loss: 0.9271, policy_loss: 0.8613, value_loss: 0.3936
2024-07-14 07:52:40,096 [INFO    ] __main__: train step 23828: loss: 0.9271, policy_loss: 0.8613, value_loss: 0.3935
2024-07-14 07:52:40,377 [INFO    ] __main__: train step 23829: loss: 0.9271, policy_loss: 0.8613, value_loss: 0.3935
2024-07-14 07:52:40,662 [INFO    ] __main__: train step 23830: loss: 0.9271, policy_loss: 0.8613, value_loss: 0.3935
2024-07-14 07:52:42,256 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:52:42,682 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:52:42,755 [INFO    ] __main__: train step 23831: loss: 0.9271, policy_loss: 0.8613, value_loss: 0.3935
2024-07-14 07:52:43,065 [INFO    ] __main__: train step 23832: loss: 0.9271, policy_loss: 0.8613, value_loss: 0.3935
2024-07-14 07:52:43,321 [INFO    ] __main__: train step 23833: loss: 0.9271, policy_loss: 0.8613, value_loss: 0.3935
2024-07-14 07:52:43,593 [INFO    ] __main__: train step 23834: loss: 0.9271, policy_loss: 0.8613, value_loss: 0.3935
2024-07-14 07:52:43,872 [INFO    ] __main__: train step 23835: loss: 0.9271, policy_loss: 0.8612, value_loss: 0.3935
2024-07-14 07:52:44,165 [INFO    ] __main__: train step 23836: loss: 0.9271, policy_loss: 0.8612, value_loss: 0.3934
2024-07-14 07:52:44,473 [INFO    ] __main__: train step 23837: loss: 0.9271, policy_loss: 0.8612, value_loss: 0.3934
2024-07-14 07:52:49,132 [INFO    ] __main__: train step 23838: loss: 0.9270, policy_loss: 0.8612, value_loss: 0.3934
2024-07-14 07:52:49,432 [INFO    ] __main__: train step 23839: loss: 0.9270, policy_loss: 0.8612, value_loss: 0.3934
2024-07-14 07:52:49,720 [INFO    ] __main__: train step 23840: loss: 0.9270, policy_loss: 0.8612, value_loss: 0.3934
2024-07-14 07:52:50,013 [INFO    ] __main__: train step 23841: loss: 0.9270, policy_loss: 0.8612, value_loss: 0.3934
2024-07-14 07:52:50,304 [INFO    ] __main__: train step 23842: loss: 0.9270, policy_loss: 0.8612, value_loss: 0.3934
2024-07-14 07:52:50,621 [INFO    ] __main__: train step 23843: loss: 0.9270, policy_loss: 0.8612, value_loss: 0.3934
2024-07-14 07:52:50,946 [INFO    ] __main__: train step 23844: loss: 0.9270, policy_loss: 0.8612, value_loss: 0.3933
2024-07-14 07:52:51,257 [INFO    ] __main__: train step 23845: loss: 0.9270, policy_loss: 0.8612, value_loss: 0.3933
2024-07-14 07:52:51,540 [INFO    ] __main__: train step 23846: loss: 0.9270, policy_loss: 0.8611, value_loss: 0.3933
2024-07-14 07:52:51,838 [INFO    ] __main__: train step 23847: loss: 0.9270, policy_loss: 0.8611, value_loss: 0.3933
2024-07-14 07:52:53,445 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:52:53,866 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:52:53,937 [INFO    ] __main__: train step 23848: loss: 0.9270, policy_loss: 0.8611, value_loss: 0.3933
2024-07-14 07:52:54,235 [INFO    ] __main__: train step 23849: loss: 0.9270, policy_loss: 0.8611, value_loss: 0.3933
2024-07-14 07:52:54,519 [INFO    ] __main__: train step 23850: loss: 0.9270, policy_loss: 0.8611, value_loss: 0.3933
2024-07-14 07:52:54,798 [INFO    ] __main__: train step 23851: loss: 0.9270, policy_loss: 0.8611, value_loss: 0.3933
2024-07-14 07:52:55,091 [INFO    ] __main__: train step 23852: loss: 0.9269, policy_loss: 0.8611, value_loss: 0.3933
2024-07-14 07:52:55,399 [INFO    ] __main__: train step 23853: loss: 0.9269, policy_loss: 0.8611, value_loss: 0.3932
2024-07-14 07:52:55,699 [INFO    ] __main__: train step 23854: loss: 0.9269, policy_loss: 0.8611, value_loss: 0.3932
2024-07-14 07:52:56,003 [INFO    ] __main__: train step 23855: loss: 0.9269, policy_loss: 0.8611, value_loss: 0.3932
2024-07-14 07:52:56,300 [INFO    ] __main__: train step 23856: loss: 0.9269, policy_loss: 0.8611, value_loss: 0.3932
2024-07-14 07:52:56,583 [INFO    ] __main__: train step 23857: loss: 0.9269, policy_loss: 0.8610, value_loss: 0.3932
2024-07-14 07:52:56,899 [INFO    ] __main__: train step 23858: loss: 0.9269, policy_loss: 0.8610, value_loss: 0.3932
2024-07-14 07:52:57,202 [INFO    ] __main__: train step 23859: loss: 0.9269, policy_loss: 0.8610, value_loss: 0.3932
2024-07-14 07:52:57,513 [INFO    ] __main__: train step 23860: loss: 0.9269, policy_loss: 0.8610, value_loss: 0.3932
2024-07-14 07:52:57,789 [INFO    ] __main__: train step 23861: loss: 0.9269, policy_loss: 0.8610, value_loss: 0.3931
2024-07-14 07:52:58,067 [INFO    ] __main__: train step 23862: loss: 0.9269, policy_loss: 0.8610, value_loss: 0.3931
2024-07-14 07:52:58,364 [INFO    ] __main__: train step 23863: loss: 0.9269, policy_loss: 0.8610, value_loss: 0.3931
2024-07-14 07:52:58,658 [INFO    ] __main__: train step 23864: loss: 0.9269, policy_loss: 0.8610, value_loss: 0.3931
2024-07-14 07:53:00,288 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:53:00,703 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:53:00,782 [INFO    ] __main__: train step 23865: loss: 0.9269, policy_loss: 0.8610, value_loss: 0.3931
2024-07-14 07:53:01,068 [INFO    ] __main__: train step 23866: loss: 0.9269, policy_loss: 0.8610, value_loss: 0.3931
2024-07-14 07:53:01,355 [INFO    ] __main__: train step 23867: loss: 0.9268, policy_loss: 0.8610, value_loss: 0.3931
2024-07-14 07:53:01,669 [INFO    ] __main__: train step 23868: loss: 0.9268, policy_loss: 0.8610, value_loss: 0.3931
2024-07-14 07:53:01,988 [INFO    ] __main__: train step 23869: loss: 0.9268, policy_loss: 0.8609, value_loss: 0.3931
2024-07-14 07:53:02,300 [INFO    ] __main__: train step 23870: loss: 0.9268, policy_loss: 0.8609, value_loss: 0.3930
2024-07-14 07:53:02,600 [INFO    ] __main__: train step 23871: loss: 0.9268, policy_loss: 0.8609, value_loss: 0.3930
2024-07-14 07:53:02,867 [INFO    ] __main__: train step 23872: loss: 0.9268, policy_loss: 0.8609, value_loss: 0.3930
2024-07-14 07:53:03,137 [INFO    ] __main__: train step 23873: loss: 0.9268, policy_loss: 0.8609, value_loss: 0.3930
2024-07-14 07:53:03,419 [INFO    ] __main__: train step 23874: loss: 0.9268, policy_loss: 0.8609, value_loss: 0.3930
2024-07-14 07:53:03,686 [INFO    ] __main__: train step 23875: loss: 0.9268, policy_loss: 0.8609, value_loss: 0.3930
2024-07-14 07:53:03,958 [INFO    ] __main__: train step 23876: loss: 0.9268, policy_loss: 0.8609, value_loss: 0.3930
2024-07-14 07:53:04,247 [INFO    ] __main__: train step 23877: loss: 0.9268, policy_loss: 0.8609, value_loss: 0.3930
2024-07-14 07:53:04,526 [INFO    ] __main__: train step 23878: loss: 0.9268, policy_loss: 0.8609, value_loss: 0.3929
2024-07-14 07:53:04,830 [INFO    ] __main__: train step 23879: loss: 0.9268, policy_loss: 0.8609, value_loss: 0.3929
2024-07-14 07:53:05,143 [INFO    ] __main__: train step 23880: loss: 0.9268, policy_loss: 0.8608, value_loss: 0.3929
2024-07-14 07:53:05,451 [INFO    ] __main__: train step 23881: loss: 0.9267, policy_loss: 0.8608, value_loss: 0.3929
2024-07-14 07:53:07,044 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:53:07,479 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:53:07,552 [INFO    ] __main__: train step 23882: loss: 0.9267, policy_loss: 0.8608, value_loss: 0.3929
2024-07-14 07:53:07,861 [INFO    ] __main__: train step 23883: loss: 0.9267, policy_loss: 0.8608, value_loss: 0.3929
2024-07-14 07:53:08,134 [INFO    ] __main__: train step 23884: loss: 0.9267, policy_loss: 0.8608, value_loss: 0.3929
2024-07-14 07:53:08,444 [INFO    ] __main__: train step 23885: loss: 0.9267, policy_loss: 0.8608, value_loss: 0.3929
2024-07-14 07:53:08,739 [INFO    ] __main__: train step 23886: loss: 0.9267, policy_loss: 0.8608, value_loss: 0.3929
2024-07-14 07:53:09,037 [INFO    ] __main__: train step 23887: loss: 0.9267, policy_loss: 0.8608, value_loss: 0.3928
2024-07-14 07:53:09,337 [INFO    ] __main__: train step 23888: loss: 0.9267, policy_loss: 0.8608, value_loss: 0.3928
2024-07-14 07:53:09,643 [INFO    ] __main__: train step 23889: loss: 0.9267, policy_loss: 0.8608, value_loss: 0.3928
2024-07-14 07:53:09,952 [INFO    ] __main__: train step 23890: loss: 0.9267, policy_loss: 0.8608, value_loss: 0.3928
2024-07-14 07:53:10,267 [INFO    ] __main__: train step 23891: loss: 0.9267, policy_loss: 0.8607, value_loss: 0.3928
2024-07-14 07:53:10,580 [INFO    ] __main__: train step 23892: loss: 0.9267, policy_loss: 0.8607, value_loss: 0.3928
2024-07-14 07:53:10,856 [INFO    ] __main__: train step 23893: loss: 0.9267, policy_loss: 0.8607, value_loss: 0.3928
2024-07-14 07:53:11,158 [INFO    ] __main__: train step 23894: loss: 0.9267, policy_loss: 0.8607, value_loss: 0.3928
2024-07-14 07:53:11,465 [INFO    ] __main__: train step 23895: loss: 0.9266, policy_loss: 0.8607, value_loss: 0.3927
2024-07-14 07:53:11,775 [INFO    ] __main__: train step 23896: loss: 0.9266, policy_loss: 0.8607, value_loss: 0.3927
2024-07-14 07:53:12,063 [INFO    ] __main__: train step 23897: loss: 0.9266, policy_loss: 0.8607, value_loss: 0.3927
2024-07-14 07:53:12,349 [INFO    ] __main__: train step 23898: loss: 0.9266, policy_loss: 0.8607, value_loss: 0.3927
2024-07-14 07:53:13,970 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:53:14,406 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:53:14,474 [INFO    ] __main__: train step 23899: loss: 0.9266, policy_loss: 0.8607, value_loss: 0.3927
2024-07-14 07:53:14,783 [INFO    ] __main__: train step 23900: loss: 0.9266, policy_loss: 0.8607, value_loss: 0.3927
2024-07-14 07:53:15,092 [INFO    ] __main__: train step 23901: loss: 0.9266, policy_loss: 0.8607, value_loss: 0.3927
2024-07-14 07:53:15,404 [INFO    ] __main__: train step 23902: loss: 0.9266, policy_loss: 0.8607, value_loss: 0.3927
2024-07-14 07:53:15,690 [INFO    ] __main__: train step 23903: loss: 0.9266, policy_loss: 0.8606, value_loss: 0.3927
2024-07-14 07:53:15,992 [INFO    ] __main__: train step 23904: loss: 0.9266, policy_loss: 0.8606, value_loss: 0.3926
2024-07-14 07:53:16,292 [INFO    ] __main__: train step 23905: loss: 0.9266, policy_loss: 0.8606, value_loss: 0.3926
2024-07-14 07:53:16,603 [INFO    ] __main__: train step 23906: loss: 0.9266, policy_loss: 0.8606, value_loss: 0.3926
2024-07-14 07:53:16,907 [INFO    ] __main__: train step 23907: loss: 0.9266, policy_loss: 0.8606, value_loss: 0.3926
2024-07-14 07:53:17,202 [INFO    ] __main__: train step 23908: loss: 0.9266, policy_loss: 0.8606, value_loss: 0.3926
2024-07-14 07:53:17,508 [INFO    ] __main__: train step 23909: loss: 0.9266, policy_loss: 0.8606, value_loss: 0.3926
2024-07-14 07:53:17,825 [INFO    ] __main__: train step 23910: loss: 0.9265, policy_loss: 0.8606, value_loss: 0.3926
2024-07-14 07:53:18,128 [INFO    ] __main__: train step 23911: loss: 0.9265, policy_loss: 0.8606, value_loss: 0.3926
2024-07-14 07:53:18,434 [INFO    ] __main__: train step 23912: loss: 0.9265, policy_loss: 0.8606, value_loss: 0.3925
2024-07-14 07:53:18,717 [INFO    ] __main__: train step 23913: loss: 0.9265, policy_loss: 0.8606, value_loss: 0.3925
2024-07-14 07:53:18,999 [INFO    ] __main__: train step 23914: loss: 0.9265, policy_loss: 0.8605, value_loss: 0.3925
2024-07-14 07:53:19,308 [INFO    ] __main__: train step 23915: loss: 0.9265, policy_loss: 0.8605, value_loss: 0.3925
2024-07-14 07:53:20,927 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:53:21,350 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:53:21,420 [INFO    ] __main__: train step 23916: loss: 0.9265, policy_loss: 0.8605, value_loss: 0.3925
2024-07-14 07:53:21,715 [INFO    ] __main__: train step 23917: loss: 0.9265, policy_loss: 0.8605, value_loss: 0.3925
2024-07-14 07:53:22,006 [INFO    ] __main__: train step 23918: loss: 0.9265, policy_loss: 0.8605, value_loss: 0.3925
2024-07-14 07:53:22,304 [INFO    ] __main__: train step 23919: loss: 0.9265, policy_loss: 0.8605, value_loss: 0.3925
2024-07-14 07:53:22,612 [INFO    ] __main__: train step 23920: loss: 0.9265, policy_loss: 0.8605, value_loss: 0.3924
2024-07-14 07:53:22,930 [INFO    ] __main__: train step 23921: loss: 0.9265, policy_loss: 0.8605, value_loss: 0.3924
2024-07-14 07:53:23,225 [INFO    ] __main__: train step 23922: loss: 0.9265, policy_loss: 0.8605, value_loss: 0.3924
2024-07-14 07:53:23,504 [INFO    ] __main__: train step 23923: loss: 0.9265, policy_loss: 0.8605, value_loss: 0.3924
2024-07-14 07:53:23,804 [INFO    ] __main__: train step 23924: loss: 0.9265, policy_loss: 0.8605, value_loss: 0.3924
2024-07-14 07:53:24,119 [INFO    ] __main__: train step 23925: loss: 0.9264, policy_loss: 0.8605, value_loss: 0.3924
2024-07-14 07:53:24,419 [INFO    ] __main__: train step 23926: loss: 0.9264, policy_loss: 0.8604, value_loss: 0.3924
2024-07-14 07:53:24,732 [INFO    ] __main__: train step 23927: loss: 0.9264, policy_loss: 0.8604, value_loss: 0.3924
2024-07-14 07:53:25,045 [INFO    ] __main__: train step 23928: loss: 0.9264, policy_loss: 0.8604, value_loss: 0.3924
2024-07-14 07:53:25,333 [INFO    ] __main__: train step 23929: loss: 0.9264, policy_loss: 0.8604, value_loss: 0.3923
2024-07-14 07:53:25,634 [INFO    ] __main__: train step 23930: loss: 0.9264, policy_loss: 0.8604, value_loss: 0.3923
2024-07-14 07:53:25,950 [INFO    ] __main__: train step 23931: loss: 0.9264, policy_loss: 0.8604, value_loss: 0.3923
2024-07-14 07:53:26,275 [INFO    ] __main__: train step 23932: loss: 0.9264, policy_loss: 0.8604, value_loss: 0.3923
2024-07-14 07:53:27,894 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:53:28,348 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:53:28,421 [INFO    ] __main__: train step 23933: loss: 0.9264, policy_loss: 0.8604, value_loss: 0.3923
2024-07-14 07:53:28,721 [INFO    ] __main__: train step 23934: loss: 0.9264, policy_loss: 0.8604, value_loss: 0.3923
2024-07-14 07:53:29,025 [INFO    ] __main__: train step 23935: loss: 0.9264, policy_loss: 0.8604, value_loss: 0.3923
2024-07-14 07:53:29,340 [INFO    ] __main__: train step 23936: loss: 0.9264, policy_loss: 0.8604, value_loss: 0.3923
2024-07-14 07:53:29,640 [INFO    ] __main__: train step 23937: loss: 0.9264, policy_loss: 0.8604, value_loss: 0.3923
2024-07-14 07:53:29,933 [INFO    ] __main__: train step 23938: loss: 0.9264, policy_loss: 0.8603, value_loss: 0.3922
2024-07-14 07:53:30,224 [INFO    ] __main__: train step 23939: loss: 0.9264, policy_loss: 0.8603, value_loss: 0.3922
2024-07-14 07:53:30,532 [INFO    ] __main__: train step 23940: loss: 0.9263, policy_loss: 0.8603, value_loss: 0.3922
2024-07-14 07:53:30,840 [INFO    ] __main__: train step 23941: loss: 0.9263, policy_loss: 0.8603, value_loss: 0.3922
2024-07-14 07:53:31,154 [INFO    ] __main__: train step 23942: loss: 0.9263, policy_loss: 0.8603, value_loss: 0.3922
2024-07-14 07:53:31,437 [INFO    ] __main__: train step 23943: loss: 0.9263, policy_loss: 0.8603, value_loss: 0.3922
2024-07-14 07:53:31,762 [INFO    ] __main__: train step 23944: loss: 0.9263, policy_loss: 0.8603, value_loss: 0.3922
2024-07-14 07:53:32,075 [INFO    ] __main__: train step 23945: loss: 0.9263, policy_loss: 0.8603, value_loss: 0.3922
2024-07-14 07:53:32,394 [INFO    ] __main__: train step 23946: loss: 0.9263, policy_loss: 0.8603, value_loss: 0.3921
2024-07-14 07:53:32,705 [INFO    ] __main__: train step 23947: loss: 0.9263, policy_loss: 0.8603, value_loss: 0.3921
2024-07-14 07:53:32,982 [INFO    ] __main__: train step 23948: loss: 0.9263, policy_loss: 0.8603, value_loss: 0.3921
2024-07-14 07:53:33,247 [INFO    ] __main__: train step 23949: loss: 0.9263, policy_loss: 0.8603, value_loss: 0.3921
2024-07-14 07:53:34,855 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:53:35,299 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:53:35,370 [INFO    ] __main__: train step 23950: loss: 0.9263, policy_loss: 0.8602, value_loss: 0.3921
2024-07-14 07:53:35,681 [INFO    ] __main__: train step 23951: loss: 0.9263, policy_loss: 0.8602, value_loss: 0.3921
2024-07-14 07:53:35,972 [INFO    ] __main__: train step 23952: loss: 0.9263, policy_loss: 0.8602, value_loss: 0.3921
2024-07-14 07:53:36,254 [INFO    ] __main__: train step 23953: loss: 0.9263, policy_loss: 0.8602, value_loss: 0.3921
2024-07-14 07:53:36,526 [INFO    ] __main__: train step 23954: loss: 0.9263, policy_loss: 0.8602, value_loss: 0.3921
2024-07-14 07:53:36,825 [INFO    ] __main__: train step 23955: loss: 0.9263, policy_loss: 0.8602, value_loss: 0.3920
2024-07-14 07:53:37,128 [INFO    ] __main__: train step 23956: loss: 0.9262, policy_loss: 0.8602, value_loss: 0.3920
2024-07-14 07:53:37,453 [INFO    ] __main__: train step 23957: loss: 0.9262, policy_loss: 0.8602, value_loss: 0.3920
2024-07-14 07:53:37,745 [INFO    ] __main__: train step 23958: loss: 0.9262, policy_loss: 0.8602, value_loss: 0.3920
2024-07-14 07:53:38,045 [INFO    ] __main__: train step 23959: loss: 0.9262, policy_loss: 0.8602, value_loss: 0.3920
2024-07-14 07:53:38,355 [INFO    ] __main__: train step 23960: loss: 0.9262, policy_loss: 0.8602, value_loss: 0.3920
2024-07-14 07:53:38,654 [INFO    ] __main__: train step 23961: loss: 0.9262, policy_loss: 0.8601, value_loss: 0.3920
2024-07-14 07:53:38,969 [INFO    ] __main__: train step 23962: loss: 0.9262, policy_loss: 0.8601, value_loss: 0.3920
2024-07-14 07:53:39,260 [INFO    ] __main__: train step 23963: loss: 0.9262, policy_loss: 0.8601, value_loss: 0.3919
2024-07-14 07:53:39,555 [INFO    ] __main__: train step 23964: loss: 0.9262, policy_loss: 0.8601, value_loss: 0.3919
2024-07-14 07:53:39,862 [INFO    ] __main__: train step 23965: loss: 0.9262, policy_loss: 0.8601, value_loss: 0.3919
2024-07-14 07:53:44,618 [INFO    ] __main__: train step 23966: loss: 0.9262, policy_loss: 0.8601, value_loss: 0.3919
2024-07-14 07:53:46,239 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:53:46,671 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:53:46,740 [INFO    ] __main__: train step 23967: loss: 0.9262, policy_loss: 0.8601, value_loss: 0.3919
2024-07-14 07:53:47,026 [INFO    ] __main__: train step 23968: loss: 0.9262, policy_loss: 0.8601, value_loss: 0.3919
2024-07-14 07:53:47,311 [INFO    ] __main__: train step 23969: loss: 0.9262, policy_loss: 0.8601, value_loss: 0.3919
2024-07-14 07:53:47,606 [INFO    ] __main__: train step 23970: loss: 0.9262, policy_loss: 0.8601, value_loss: 0.3919
2024-07-14 07:53:47,905 [INFO    ] __main__: train step 23971: loss: 0.9261, policy_loss: 0.8601, value_loss: 0.3919
2024-07-14 07:53:48,206 [INFO    ] __main__: train step 23972: loss: 0.9261, policy_loss: 0.8601, value_loss: 0.3918
2024-07-14 07:53:48,513 [INFO    ] __main__: train step 23973: loss: 0.9261, policy_loss: 0.8600, value_loss: 0.3918
2024-07-14 07:53:48,823 [INFO    ] __main__: train step 23974: loss: 0.9261, policy_loss: 0.8600, value_loss: 0.3918
2024-07-14 07:53:49,125 [INFO    ] __main__: train step 23975: loss: 0.9261, policy_loss: 0.8600, value_loss: 0.3918
2024-07-14 07:53:49,427 [INFO    ] __main__: train step 23976: loss: 0.9261, policy_loss: 0.8600, value_loss: 0.3918
2024-07-14 07:53:49,732 [INFO    ] __main__: train step 23977: loss: 0.9261, policy_loss: 0.8600, value_loss: 0.3918
2024-07-14 07:53:50,036 [INFO    ] __main__: train step 23978: loss: 0.9261, policy_loss: 0.8600, value_loss: 0.3918
2024-07-14 07:53:50,319 [INFO    ] __main__: train step 23979: loss: 0.9261, policy_loss: 0.8600, value_loss: 0.3918
2024-07-14 07:53:50,605 [INFO    ] __main__: train step 23980: loss: 0.9261, policy_loss: 0.8600, value_loss: 0.3918
2024-07-14 07:53:50,912 [INFO    ] __main__: train step 23981: loss: 0.9261, policy_loss: 0.8600, value_loss: 0.3917
2024-07-14 07:53:51,207 [INFO    ] __main__: train step 23982: loss: 0.9261, policy_loss: 0.8600, value_loss: 0.3917
2024-07-14 07:53:51,516 [INFO    ] __main__: train step 23983: loss: 0.9261, policy_loss: 0.8600, value_loss: 0.3917
2024-07-14 07:53:53,131 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:53:53,575 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:53:53,647 [INFO    ] __main__: train step 23984: loss: 0.9261, policy_loss: 0.8600, value_loss: 0.3917
2024-07-14 07:53:53,946 [INFO    ] __main__: train step 23985: loss: 0.9261, policy_loss: 0.8599, value_loss: 0.3917
2024-07-14 07:53:54,241 [INFO    ] __main__: train step 23986: loss: 0.9260, policy_loss: 0.8599, value_loss: 0.3917
2024-07-14 07:53:54,542 [INFO    ] __main__: train step 23987: loss: 0.9260, policy_loss: 0.8599, value_loss: 0.3917
2024-07-14 07:53:54,846 [INFO    ] __main__: train step 23988: loss: 0.9260, policy_loss: 0.8599, value_loss: 0.3917
2024-07-14 07:53:55,134 [INFO    ] __main__: train step 23989: loss: 0.9260, policy_loss: 0.8599, value_loss: 0.3916
2024-07-14 07:53:55,431 [INFO    ] __main__: train step 23990: loss: 0.9260, policy_loss: 0.8599, value_loss: 0.3916
2024-07-14 07:53:55,740 [INFO    ] __main__: train step 23991: loss: 0.9260, policy_loss: 0.8599, value_loss: 0.3916
2024-07-14 07:53:56,056 [INFO    ] __main__: train step 23992: loss: 0.9260, policy_loss: 0.8599, value_loss: 0.3916
2024-07-14 07:53:56,370 [INFO    ] __main__: train step 23993: loss: 0.9260, policy_loss: 0.8599, value_loss: 0.3916
2024-07-14 07:53:56,673 [INFO    ] __main__: train step 23994: loss: 0.9260, policy_loss: 0.8599, value_loss: 0.3916
2024-07-14 07:53:56,963 [INFO    ] __main__: train step 23995: loss: 0.9260, policy_loss: 0.8599, value_loss: 0.3916
2024-07-14 07:53:57,259 [INFO    ] __main__: train step 23996: loss: 0.9260, policy_loss: 0.8598, value_loss: 0.3916
2024-07-14 07:53:57,557 [INFO    ] __main__: train step 23997: loss: 0.9260, policy_loss: 0.8598, value_loss: 0.3915
2024-07-14 07:53:57,854 [INFO    ] __main__: train step 23998: loss: 0.9260, policy_loss: 0.8598, value_loss: 0.3915
2024-07-14 07:53:58,158 [INFO    ] __main__: train step 23999: loss: 0.9260, policy_loss: 0.8598, value_loss: 0.3915
2024-07-14 07:53:58,446 [INFO    ] __main__: train step 24000: loss: 0.9260, policy_loss: 0.8598, value_loss: 0.3915
2024-07-14 07:53:58,586 [INFO    ] __main__: restored step 23000 for evaluation
2024-07-14 07:54:03,852 [INFO    ] __main__: test network ELO difference from baseline network: +14 (+8/-8) ELO from 32000 self-played games
2024-07-14 07:54:03,855 [INFO    ] __main__: game outcomes: W: 16471, D: 133, L: 15396
2024-07-14 07:54:03,857 [INFO    ] __main__: validation_elo_delta: 14, validation_elo: 2982
2024-07-14 07:54:05,966 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:54:06,433 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:54:06,503 [INFO    ] __main__: train step 24001: loss: 0.9259, policy_loss: 0.8598, value_loss: 0.3915
2024-07-14 07:54:06,816 [INFO    ] __main__: train step 24002: loss: 0.9259, policy_loss: 0.8598, value_loss: 0.3915
2024-07-14 07:54:07,125 [INFO    ] __main__: train step 24003: loss: 0.9259, policy_loss: 0.8598, value_loss: 0.3915
2024-07-14 07:54:07,420 [INFO    ] __main__: train step 24004: loss: 0.9259, policy_loss: 0.8598, value_loss: 0.3915
2024-07-14 07:54:07,709 [INFO    ] __main__: train step 24005: loss: 0.9259, policy_loss: 0.8598, value_loss: 0.3915
2024-07-14 07:54:07,983 [INFO    ] __main__: train step 24006: loss: 0.9259, policy_loss: 0.8598, value_loss: 0.3914
2024-07-14 07:54:08,267 [INFO    ] __main__: train step 24007: loss: 0.9259, policy_loss: 0.8598, value_loss: 0.3914
2024-07-14 07:54:08,565 [INFO    ] __main__: train step 24008: loss: 0.9259, policy_loss: 0.8597, value_loss: 0.3914
2024-07-14 07:54:08,872 [INFO    ] __main__: train step 24009: loss: 0.9259, policy_loss: 0.8597, value_loss: 0.3914
2024-07-14 07:54:09,176 [INFO    ] __main__: train step 24010: loss: 0.9259, policy_loss: 0.8597, value_loss: 0.3914
2024-07-14 07:54:09,442 [INFO    ] __main__: train step 24011: loss: 0.9259, policy_loss: 0.8597, value_loss: 0.3914
2024-07-14 07:54:09,720 [INFO    ] __main__: train step 24012: loss: 0.9259, policy_loss: 0.8597, value_loss: 0.3914
2024-07-14 07:54:10,010 [INFO    ] __main__: train step 24013: loss: 0.9259, policy_loss: 0.8597, value_loss: 0.3914
2024-07-14 07:54:10,319 [INFO    ] __main__: train step 24014: loss: 0.9259, policy_loss: 0.8597, value_loss: 0.3914
2024-07-14 07:54:10,634 [INFO    ] __main__: train step 24015: loss: 0.9259, policy_loss: 0.8597, value_loss: 0.3913
2024-07-14 07:54:10,900 [INFO    ] __main__: train step 24016: loss: 0.9258, policy_loss: 0.8597, value_loss: 0.3913
2024-07-14 07:54:11,163 [INFO    ] __main__: train step 24017: loss: 0.9258, policy_loss: 0.8597, value_loss: 0.3913
2024-07-14 07:54:12,766 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:54:13,190 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:54:13,253 [INFO    ] __main__: train step 24018: loss: 0.9258, policy_loss: 0.8597, value_loss: 0.3913
2024-07-14 07:54:13,529 [INFO    ] __main__: train step 24019: loss: 0.9258, policy_loss: 0.8597, value_loss: 0.3913
2024-07-14 07:54:13,804 [INFO    ] __main__: train step 24020: loss: 0.9258, policy_loss: 0.8596, value_loss: 0.3913
2024-07-14 07:54:14,076 [INFO    ] __main__: train step 24021: loss: 0.9258, policy_loss: 0.8596, value_loss: 0.3913
2024-07-14 07:54:14,346 [INFO    ] __main__: train step 24022: loss: 0.9258, policy_loss: 0.8596, value_loss: 0.3913
2024-07-14 07:54:14,648 [INFO    ] __main__: train step 24023: loss: 0.9258, policy_loss: 0.8596, value_loss: 0.3913
2024-07-14 07:54:14,952 [INFO    ] __main__: train step 24024: loss: 0.9258, policy_loss: 0.8596, value_loss: 0.3912
2024-07-14 07:54:15,257 [INFO    ] __main__: train step 24025: loss: 0.9258, policy_loss: 0.8596, value_loss: 0.3912
2024-07-14 07:54:15,557 [INFO    ] __main__: train step 24026: loss: 0.9258, policy_loss: 0.8596, value_loss: 0.3912
2024-07-14 07:54:15,854 [INFO    ] __main__: train step 24027: loss: 0.9258, policy_loss: 0.8596, value_loss: 0.3912
2024-07-14 07:54:16,158 [INFO    ] __main__: train step 24028: loss: 0.9258, policy_loss: 0.8596, value_loss: 0.3912
2024-07-14 07:54:16,456 [INFO    ] __main__: train step 24029: loss: 0.9258, policy_loss: 0.8596, value_loss: 0.3912
2024-07-14 07:54:16,764 [INFO    ] __main__: train step 24030: loss: 0.9258, policy_loss: 0.8596, value_loss: 0.3912
2024-07-14 07:54:17,069 [INFO    ] __main__: train step 24031: loss: 0.9258, policy_loss: 0.8595, value_loss: 0.3912
2024-07-14 07:54:17,352 [INFO    ] __main__: train step 24032: loss: 0.9257, policy_loss: 0.8595, value_loss: 0.3911
2024-07-14 07:54:17,639 [INFO    ] __main__: train step 24033: loss: 0.9257, policy_loss: 0.8595, value_loss: 0.3911
2024-07-14 07:54:17,946 [INFO    ] __main__: train step 24034: loss: 0.9257, policy_loss: 0.8595, value_loss: 0.3911
2024-07-14 07:54:19,614 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:54:20,039 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:54:20,116 [INFO    ] __main__: train step 24035: loss: 0.9257, policy_loss: 0.8595, value_loss: 0.3911
2024-07-14 07:54:20,419 [INFO    ] __main__: train step 24036: loss: 0.9257, policy_loss: 0.8595, value_loss: 0.3911
2024-07-14 07:54:20,701 [INFO    ] __main__: train step 24037: loss: 0.9257, policy_loss: 0.8595, value_loss: 0.3911
2024-07-14 07:54:21,000 [INFO    ] __main__: train step 24038: loss: 0.9257, policy_loss: 0.8595, value_loss: 0.3911
2024-07-14 07:54:21,300 [INFO    ] __main__: train step 24039: loss: 0.9257, policy_loss: 0.8595, value_loss: 0.3911
2024-07-14 07:54:21,611 [INFO    ] __main__: train step 24040: loss: 0.9257, policy_loss: 0.8595, value_loss: 0.3911
2024-07-14 07:54:21,912 [INFO    ] __main__: train step 24041: loss: 0.9257, policy_loss: 0.8595, value_loss: 0.3910
2024-07-14 07:54:22,193 [INFO    ] __main__: train step 24042: loss: 0.9257, policy_loss: 0.8595, value_loss: 0.3910
2024-07-14 07:54:22,497 [INFO    ] __main__: train step 24043: loss: 0.9257, policy_loss: 0.8595, value_loss: 0.3910
2024-07-14 07:54:22,787 [INFO    ] __main__: train step 24044: loss: 0.9257, policy_loss: 0.8594, value_loss: 0.3910
2024-07-14 07:54:23,091 [INFO    ] __main__: train step 24045: loss: 0.9257, policy_loss: 0.8594, value_loss: 0.3910
2024-07-14 07:54:23,404 [INFO    ] __main__: train step 24046: loss: 0.9257, policy_loss: 0.8594, value_loss: 0.3910
2024-07-14 07:54:23,700 [INFO    ] __main__: train step 24047: loss: 0.9256, policy_loss: 0.8594, value_loss: 0.3910
2024-07-14 07:54:23,961 [INFO    ] __main__: train step 24048: loss: 0.9256, policy_loss: 0.8594, value_loss: 0.3910
2024-07-14 07:54:24,263 [INFO    ] __main__: train step 24049: loss: 0.9256, policy_loss: 0.8594, value_loss: 0.3909
2024-07-14 07:54:24,560 [INFO    ] __main__: train step 24050: loss: 0.9256, policy_loss: 0.8594, value_loss: 0.3909
2024-07-14 07:54:24,881 [INFO    ] __main__: train step 24051: loss: 0.9256, policy_loss: 0.8594, value_loss: 0.3909
2024-07-14 07:54:26,480 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:54:26,907 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:54:26,972 [INFO    ] __main__: train step 24052: loss: 0.9256, policy_loss: 0.8594, value_loss: 0.3909
2024-07-14 07:54:27,261 [INFO    ] __main__: train step 24053: loss: 0.9256, policy_loss: 0.8594, value_loss: 0.3909
2024-07-14 07:54:27,580 [INFO    ] __main__: train step 24054: loss: 0.9256, policy_loss: 0.8594, value_loss: 0.3909
2024-07-14 07:54:27,890 [INFO    ] __main__: train step 24055: loss: 0.9256, policy_loss: 0.8593, value_loss: 0.3909
2024-07-14 07:54:28,181 [INFO    ] __main__: train step 24056: loss: 0.9256, policy_loss: 0.8593, value_loss: 0.3909
2024-07-14 07:54:28,470 [INFO    ] __main__: train step 24057: loss: 0.9256, policy_loss: 0.8593, value_loss: 0.3909
2024-07-14 07:54:28,772 [INFO    ] __main__: train step 24058: loss: 0.9256, policy_loss: 0.8593, value_loss: 0.3908
2024-07-14 07:54:29,080 [INFO    ] __main__: train step 24059: loss: 0.9256, policy_loss: 0.8593, value_loss: 0.3908
2024-07-14 07:54:29,375 [INFO    ] __main__: train step 24060: loss: 0.9256, policy_loss: 0.8593, value_loss: 0.3908
2024-07-14 07:54:29,682 [INFO    ] __main__: train step 24061: loss: 0.9256, policy_loss: 0.8593, value_loss: 0.3908
2024-07-14 07:54:29,991 [INFO    ] __main__: train step 24062: loss: 0.9255, policy_loss: 0.8593, value_loss: 0.3908
2024-07-14 07:54:30,289 [INFO    ] __main__: train step 24063: loss: 0.9255, policy_loss: 0.8593, value_loss: 0.3908
2024-07-14 07:54:30,592 [INFO    ] __main__: train step 24064: loss: 0.9255, policy_loss: 0.8593, value_loss: 0.3908
2024-07-14 07:54:30,898 [INFO    ] __main__: train step 24065: loss: 0.9255, policy_loss: 0.8593, value_loss: 0.3908
2024-07-14 07:54:31,215 [INFO    ] __main__: train step 24066: loss: 0.9255, policy_loss: 0.8593, value_loss: 0.3908
2024-07-14 07:54:31,540 [INFO    ] __main__: train step 24067: loss: 0.9255, policy_loss: 0.8592, value_loss: 0.3907
2024-07-14 07:54:31,855 [INFO    ] __main__: train step 24068: loss: 0.9255, policy_loss: 0.8592, value_loss: 0.3907
2024-07-14 07:54:33,479 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:54:33,905 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:54:33,975 [INFO    ] __main__: train step 24069: loss: 0.9255, policy_loss: 0.8592, value_loss: 0.3907
2024-07-14 07:54:34,276 [INFO    ] __main__: train step 24070: loss: 0.9255, policy_loss: 0.8592, value_loss: 0.3907
2024-07-14 07:54:34,573 [INFO    ] __main__: train step 24071: loss: 0.9255, policy_loss: 0.8592, value_loss: 0.3907
2024-07-14 07:54:34,853 [INFO    ] __main__: train step 24072: loss: 0.9255, policy_loss: 0.8592, value_loss: 0.3907
2024-07-14 07:54:35,154 [INFO    ] __main__: train step 24073: loss: 0.9255, policy_loss: 0.8592, value_loss: 0.3907
2024-07-14 07:54:35,461 [INFO    ] __main__: train step 24074: loss: 0.9255, policy_loss: 0.8592, value_loss: 0.3907
2024-07-14 07:54:35,758 [INFO    ] __main__: train step 24075: loss: 0.9255, policy_loss: 0.8592, value_loss: 0.3906
2024-07-14 07:54:36,063 [INFO    ] __main__: train step 24076: loss: 0.9255, policy_loss: 0.8592, value_loss: 0.3906
2024-07-14 07:54:36,335 [INFO    ] __main__: train step 24077: loss: 0.9254, policy_loss: 0.8592, value_loss: 0.3906
2024-07-14 07:54:36,600 [INFO    ] __main__: train step 24078: loss: 0.9254, policy_loss: 0.8592, value_loss: 0.3906
2024-07-14 07:54:36,890 [INFO    ] __main__: train step 24079: loss: 0.9254, policy_loss: 0.8591, value_loss: 0.3906
2024-07-14 07:54:37,188 [INFO    ] __main__: train step 24080: loss: 0.9254, policy_loss: 0.8591, value_loss: 0.3906
2024-07-14 07:54:37,465 [INFO    ] __main__: train step 24081: loss: 0.9254, policy_loss: 0.8591, value_loss: 0.3906
2024-07-14 07:54:37,746 [INFO    ] __main__: train step 24082: loss: 0.9254, policy_loss: 0.8591, value_loss: 0.3906
2024-07-14 07:54:38,025 [INFO    ] __main__: train step 24083: loss: 0.9254, policy_loss: 0.8591, value_loss: 0.3906
2024-07-14 07:54:38,294 [INFO    ] __main__: train step 24084: loss: 0.9254, policy_loss: 0.8591, value_loss: 0.3905
2024-07-14 07:54:38,571 [INFO    ] __main__: train step 24085: loss: 0.9254, policy_loss: 0.8591, value_loss: 0.3905
2024-07-14 07:54:40,188 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:54:40,609 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:54:40,677 [INFO    ] __main__: train step 24086: loss: 0.9254, policy_loss: 0.8591, value_loss: 0.3905
2024-07-14 07:54:40,963 [INFO    ] __main__: train step 24087: loss: 0.9254, policy_loss: 0.8591, value_loss: 0.3905
2024-07-14 07:54:41,265 [INFO    ] __main__: train step 24088: loss: 0.9254, policy_loss: 0.8591, value_loss: 0.3905
2024-07-14 07:54:41,567 [INFO    ] __main__: train step 24089: loss: 0.9254, policy_loss: 0.8591, value_loss: 0.3905
2024-07-14 07:54:41,878 [INFO    ] __main__: train step 24090: loss: 0.9254, policy_loss: 0.8591, value_loss: 0.3905
2024-07-14 07:54:42,188 [INFO    ] __main__: train step 24091: loss: 0.9254, policy_loss: 0.8591, value_loss: 0.3905
2024-07-14 07:54:45,974 [INFO    ] __main__: train step 24092: loss: 0.9254, policy_loss: 0.8590, value_loss: 0.3905
2024-07-14 07:54:46,272 [INFO    ] __main__: train step 24093: loss: 0.9254, policy_loss: 0.8590, value_loss: 0.3904
2024-07-14 07:54:46,576 [INFO    ] __main__: train step 24094: loss: 0.9253, policy_loss: 0.8590, value_loss: 0.3904
2024-07-14 07:54:46,884 [INFO    ] __main__: train step 24095: loss: 0.9253, policy_loss: 0.8590, value_loss: 0.3904
2024-07-14 07:54:47,179 [INFO    ] __main__: train step 24096: loss: 0.9253, policy_loss: 0.8590, value_loss: 0.3904
2024-07-14 07:54:47,489 [INFO    ] __main__: train step 24097: loss: 0.9253, policy_loss: 0.8590, value_loss: 0.3904
2024-07-14 07:54:47,766 [INFO    ] __main__: train step 24098: loss: 0.9253, policy_loss: 0.8590, value_loss: 0.3904
2024-07-14 07:54:48,079 [INFO    ] __main__: train step 24099: loss: 0.9253, policy_loss: 0.8590, value_loss: 0.3904
2024-07-14 07:54:48,385 [INFO    ] __main__: train step 24100: loss: 0.9253, policy_loss: 0.8590, value_loss: 0.3904
2024-07-14 07:54:48,686 [INFO    ] __main__: train step 24101: loss: 0.9253, policy_loss: 0.8590, value_loss: 0.3903
2024-07-14 07:54:48,996 [INFO    ] __main__: train step 24102: loss: 0.9253, policy_loss: 0.8590, value_loss: 0.3903
2024-07-14 07:54:50,606 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:54:51,044 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:54:51,109 [INFO    ] __main__: train step 24103: loss: 0.9253, policy_loss: 0.8590, value_loss: 0.3903
2024-07-14 07:54:51,410 [INFO    ] __main__: train step 24104: loss: 0.9253, policy_loss: 0.8589, value_loss: 0.3903
2024-07-14 07:54:51,693 [INFO    ] __main__: train step 24105: loss: 0.9253, policy_loss: 0.8589, value_loss: 0.3903
2024-07-14 07:54:51,990 [INFO    ] __main__: train step 24106: loss: 0.9253, policy_loss: 0.8589, value_loss: 0.3903
2024-07-14 07:54:52,285 [INFO    ] __main__: train step 24107: loss: 0.9253, policy_loss: 0.8589, value_loss: 0.3903
2024-07-14 07:54:52,569 [INFO    ] __main__: train step 24108: loss: 0.9253, policy_loss: 0.8589, value_loss: 0.3903
2024-07-14 07:54:52,867 [INFO    ] __main__: train step 24109: loss: 0.9253, policy_loss: 0.8589, value_loss: 0.3903
2024-07-14 07:54:53,135 [INFO    ] __main__: train step 24110: loss: 0.9252, policy_loss: 0.8589, value_loss: 0.3902
2024-07-14 07:54:53,410 [INFO    ] __main__: train step 24111: loss: 0.9252, policy_loss: 0.8589, value_loss: 0.3902
2024-07-14 07:54:53,722 [INFO    ] __main__: train step 24112: loss: 0.9252, policy_loss: 0.8589, value_loss: 0.3902
2024-07-14 07:54:54,005 [INFO    ] __main__: train step 24113: loss: 0.9252, policy_loss: 0.8589, value_loss: 0.3902
2024-07-14 07:54:54,295 [INFO    ] __main__: train step 24114: loss: 0.9252, policy_loss: 0.8589, value_loss: 0.3902
2024-07-14 07:54:54,599 [INFO    ] __main__: train step 24115: loss: 0.9252, policy_loss: 0.8589, value_loss: 0.3902
2024-07-14 07:54:54,904 [INFO    ] __main__: train step 24116: loss: 0.9252, policy_loss: 0.8588, value_loss: 0.3902
2024-07-14 07:54:55,214 [INFO    ] __main__: train step 24117: loss: 0.9252, policy_loss: 0.8588, value_loss: 0.3902
2024-07-14 07:54:55,493 [INFO    ] __main__: train step 24118: loss: 0.9252, policy_loss: 0.8588, value_loss: 0.3902
2024-07-14 07:54:55,801 [INFO    ] __main__: train step 24119: loss: 0.9252, policy_loss: 0.8588, value_loss: 0.3901
2024-07-14 07:54:57,435 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:54:57,873 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:54:57,944 [INFO    ] __main__: train step 24120: loss: 0.9252, policy_loss: 0.8588, value_loss: 0.3901
2024-07-14 07:54:58,254 [INFO    ] __main__: train step 24121: loss: 0.9252, policy_loss: 0.8588, value_loss: 0.3901
2024-07-14 07:54:58,557 [INFO    ] __main__: train step 24122: loss: 0.9252, policy_loss: 0.8588, value_loss: 0.3901
2024-07-14 07:54:58,839 [INFO    ] __main__: train step 24123: loss: 0.9252, policy_loss: 0.8588, value_loss: 0.3901
2024-07-14 07:54:59,132 [INFO    ] __main__: train step 24124: loss: 0.9252, policy_loss: 0.8588, value_loss: 0.3901
2024-07-14 07:54:59,430 [INFO    ] __main__: train step 24125: loss: 0.9252, policy_loss: 0.8588, value_loss: 0.3901
2024-07-14 07:54:59,737 [INFO    ] __main__: train step 24126: loss: 0.9251, policy_loss: 0.8588, value_loss: 0.3901
2024-07-14 07:55:00,050 [INFO    ] __main__: train step 24127: loss: 0.9251, policy_loss: 0.8588, value_loss: 0.3900
2024-07-14 07:55:00,345 [INFO    ] __main__: train step 24128: loss: 0.9251, policy_loss: 0.8587, value_loss: 0.3900
2024-07-14 07:55:00,642 [INFO    ] __main__: train step 24129: loss: 0.9251, policy_loss: 0.8587, value_loss: 0.3900
2024-07-14 07:55:00,945 [INFO    ] __main__: train step 24130: loss: 0.9251, policy_loss: 0.8587, value_loss: 0.3900
2024-07-14 07:55:01,256 [INFO    ] __main__: train step 24131: loss: 0.9251, policy_loss: 0.8587, value_loss: 0.3900
2024-07-14 07:55:01,563 [INFO    ] __main__: train step 24132: loss: 0.9251, policy_loss: 0.8587, value_loss: 0.3900
2024-07-14 07:55:01,841 [INFO    ] __main__: train step 24133: loss: 0.9251, policy_loss: 0.8587, value_loss: 0.3900
2024-07-14 07:55:02,141 [INFO    ] __main__: train step 24134: loss: 0.9251, policy_loss: 0.8587, value_loss: 0.3900
2024-07-14 07:55:02,457 [INFO    ] __main__: train step 24135: loss: 0.9251, policy_loss: 0.8587, value_loss: 0.3900
2024-07-14 07:55:02,776 [INFO    ] __main__: train step 24136: loss: 0.9251, policy_loss: 0.8587, value_loss: 0.3899
2024-07-14 07:55:04,426 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:55:04,890 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:55:04,959 [INFO    ] __main__: train step 24137: loss: 0.9251, policy_loss: 0.8587, value_loss: 0.3899
2024-07-14 07:55:05,261 [INFO    ] __main__: train step 24138: loss: 0.9251, policy_loss: 0.8587, value_loss: 0.3899
2024-07-14 07:55:05,573 [INFO    ] __main__: train step 24139: loss: 0.9251, policy_loss: 0.8587, value_loss: 0.3899
2024-07-14 07:55:05,873 [INFO    ] __main__: train step 24140: loss: 0.9251, policy_loss: 0.8587, value_loss: 0.3899
2024-07-14 07:55:06,166 [INFO    ] __main__: train step 24141: loss: 0.9251, policy_loss: 0.8586, value_loss: 0.3899
2024-07-14 07:55:06,453 [INFO    ] __main__: train step 24142: loss: 0.9250, policy_loss: 0.8586, value_loss: 0.3899
2024-07-14 07:55:06,732 [INFO    ] __main__: train step 24143: loss: 0.9250, policy_loss: 0.8586, value_loss: 0.3899
2024-07-14 07:55:07,000 [INFO    ] __main__: train step 24144: loss: 0.9250, policy_loss: 0.8586, value_loss: 0.3899
2024-07-14 07:55:07,275 [INFO    ] __main__: train step 24145: loss: 0.9250, policy_loss: 0.8586, value_loss: 0.3898
2024-07-14 07:55:07,560 [INFO    ] __main__: train step 24146: loss: 0.9250, policy_loss: 0.8586, value_loss: 0.3898
2024-07-14 07:55:07,871 [INFO    ] __main__: train step 24147: loss: 0.9250, policy_loss: 0.8586, value_loss: 0.3898
2024-07-14 07:55:08,166 [INFO    ] __main__: train step 24148: loss: 0.9250, policy_loss: 0.8586, value_loss: 0.3898
2024-07-14 07:55:08,431 [INFO    ] __main__: train step 24149: loss: 0.9250, policy_loss: 0.8586, value_loss: 0.3898
2024-07-14 07:55:08,710 [INFO    ] __main__: train step 24150: loss: 0.9250, policy_loss: 0.8586, value_loss: 0.3898
2024-07-14 07:55:08,997 [INFO    ] __main__: train step 24151: loss: 0.9250, policy_loss: 0.8586, value_loss: 0.3898
2024-07-14 07:55:09,301 [INFO    ] __main__: train step 24152: loss: 0.9250, policy_loss: 0.8586, value_loss: 0.3898
2024-07-14 07:55:09,617 [INFO    ] __main__: train step 24153: loss: 0.9250, policy_loss: 0.8585, value_loss: 0.3897
2024-07-14 07:55:11,236 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:55:11,669 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:55:11,737 [INFO    ] __main__: train step 24154: loss: 0.9250, policy_loss: 0.8585, value_loss: 0.3897
2024-07-14 07:55:12,035 [INFO    ] __main__: train step 24155: loss: 0.9250, policy_loss: 0.8585, value_loss: 0.3897
2024-07-14 07:55:12,341 [INFO    ] __main__: train step 24156: loss: 0.9250, policy_loss: 0.8585, value_loss: 0.3897
2024-07-14 07:55:12,612 [INFO    ] __main__: train step 24157: loss: 0.9250, policy_loss: 0.8585, value_loss: 0.3897
2024-07-14 07:55:12,905 [INFO    ] __main__: train step 24158: loss: 0.9249, policy_loss: 0.8585, value_loss: 0.3897
2024-07-14 07:55:13,201 [INFO    ] __main__: train step 24159: loss: 0.9249, policy_loss: 0.8585, value_loss: 0.3897
2024-07-14 07:55:13,511 [INFO    ] __main__: train step 24160: loss: 0.9249, policy_loss: 0.8585, value_loss: 0.3897
2024-07-14 07:55:13,822 [INFO    ] __main__: train step 24161: loss: 0.9249, policy_loss: 0.8585, value_loss: 0.3897
2024-07-14 07:55:14,136 [INFO    ] __main__: train step 24162: loss: 0.9249, policy_loss: 0.8585, value_loss: 0.3896
2024-07-14 07:55:14,422 [INFO    ] __main__: train step 24163: loss: 0.9249, policy_loss: 0.8585, value_loss: 0.3896
2024-07-14 07:55:14,714 [INFO    ] __main__: train step 24164: loss: 0.9249, policy_loss: 0.8585, value_loss: 0.3896
2024-07-14 07:55:15,041 [INFO    ] __main__: train step 24165: loss: 0.9249, policy_loss: 0.8584, value_loss: 0.3896
2024-07-14 07:55:15,362 [INFO    ] __main__: train step 24166: loss: 0.9249, policy_loss: 0.8584, value_loss: 0.3896
2024-07-14 07:55:15,660 [INFO    ] __main__: train step 24167: loss: 0.9249, policy_loss: 0.8584, value_loss: 0.3896
2024-07-14 07:55:15,965 [INFO    ] __main__: train step 24168: loss: 0.9249, policy_loss: 0.8584, value_loss: 0.3896
2024-07-14 07:55:16,251 [INFO    ] __main__: train step 24169: loss: 0.9249, policy_loss: 0.8584, value_loss: 0.3896
2024-07-14 07:55:16,531 [INFO    ] __main__: train step 24170: loss: 0.9249, policy_loss: 0.8584, value_loss: 0.3896
2024-07-14 07:55:18,142 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:55:18,557 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:55:18,628 [INFO    ] __main__: train step 24171: loss: 0.9249, policy_loss: 0.8584, value_loss: 0.3895
2024-07-14 07:55:18,924 [INFO    ] __main__: train step 24172: loss: 0.9249, policy_loss: 0.8584, value_loss: 0.3895
2024-07-14 07:55:19,202 [INFO    ] __main__: train step 24173: loss: 0.9249, policy_loss: 0.8584, value_loss: 0.3895
2024-07-14 07:55:19,466 [INFO    ] __main__: train step 24174: loss: 0.9248, policy_loss: 0.8584, value_loss: 0.3895
2024-07-14 07:55:19,767 [INFO    ] __main__: train step 24175: loss: 0.9248, policy_loss: 0.8584, value_loss: 0.3895
2024-07-14 07:55:20,073 [INFO    ] __main__: train step 24176: loss: 0.9248, policy_loss: 0.8584, value_loss: 0.3895
2024-07-14 07:55:20,386 [INFO    ] __main__: train step 24177: loss: 0.9248, policy_loss: 0.8584, value_loss: 0.3895
2024-07-14 07:55:20,701 [INFO    ] __main__: train step 24178: loss: 0.9248, policy_loss: 0.8583, value_loss: 0.3895
2024-07-14 07:55:21,029 [INFO    ] __main__: train step 24179: loss: 0.9248, policy_loss: 0.8583, value_loss: 0.3894
2024-07-14 07:55:21,346 [INFO    ] __main__: train step 24180: loss: 0.9248, policy_loss: 0.8583, value_loss: 0.3894
2024-07-14 07:55:21,650 [INFO    ] __main__: train step 24181: loss: 0.9248, policy_loss: 0.8583, value_loss: 0.3894
2024-07-14 07:55:21,962 [INFO    ] __main__: train step 24182: loss: 0.9248, policy_loss: 0.8583, value_loss: 0.3894
2024-07-14 07:55:22,267 [INFO    ] __main__: train step 24183: loss: 0.9248, policy_loss: 0.8583, value_loss: 0.3894
2024-07-14 07:55:22,542 [INFO    ] __main__: train step 24184: loss: 0.9248, policy_loss: 0.8583, value_loss: 0.3894
2024-07-14 07:55:22,852 [INFO    ] __main__: train step 24185: loss: 0.9248, policy_loss: 0.8583, value_loss: 0.3894
2024-07-14 07:55:23,163 [INFO    ] __main__: train step 24186: loss: 0.9248, policy_loss: 0.8583, value_loss: 0.3894
2024-07-14 07:55:23,464 [INFO    ] __main__: train step 24187: loss: 0.9248, policy_loss: 0.8583, value_loss: 0.3894
2024-07-14 07:55:25,094 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:55:25,531 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:55:25,600 [INFO    ] __main__: train step 24188: loss: 0.9248, policy_loss: 0.8583, value_loss: 0.3893
2024-07-14 07:55:25,876 [INFO    ] __main__: train step 24189: loss: 0.9247, policy_loss: 0.8583, value_loss: 0.3893
2024-07-14 07:55:26,173 [INFO    ] __main__: train step 24190: loss: 0.9247, policy_loss: 0.8582, value_loss: 0.3893
2024-07-14 07:55:26,476 [INFO    ] __main__: train step 24191: loss: 0.9247, policy_loss: 0.8582, value_loss: 0.3893
2024-07-14 07:55:26,774 [INFO    ] __main__: train step 24192: loss: 0.9247, policy_loss: 0.8582, value_loss: 0.3893
2024-07-14 07:55:27,086 [INFO    ] __main__: train step 24193: loss: 0.9247, policy_loss: 0.8582, value_loss: 0.3893
2024-07-14 07:55:27,381 [INFO    ] __main__: train step 24194: loss: 0.9247, policy_loss: 0.8582, value_loss: 0.3893
2024-07-14 07:55:27,691 [INFO    ] __main__: train step 24195: loss: 0.9247, policy_loss: 0.8582, value_loss: 0.3893
2024-07-14 07:55:28,002 [INFO    ] __main__: train step 24196: loss: 0.9247, policy_loss: 0.8582, value_loss: 0.3893
2024-07-14 07:55:28,319 [INFO    ] __main__: train step 24197: loss: 0.9247, policy_loss: 0.8582, value_loss: 0.3892
2024-07-14 07:55:28,623 [INFO    ] __main__: train step 24198: loss: 0.9247, policy_loss: 0.8582, value_loss: 0.3892
2024-07-14 07:55:28,917 [INFO    ] __main__: train step 24199: loss: 0.9247, policy_loss: 0.8582, value_loss: 0.3892
2024-07-14 07:55:29,200 [INFO    ] __main__: train step 24200: loss: 0.9247, policy_loss: 0.8582, value_loss: 0.3892
2024-07-14 07:55:29,494 [INFO    ] __main__: train step 24201: loss: 0.9247, policy_loss: 0.8582, value_loss: 0.3892
2024-07-14 07:55:29,827 [INFO    ] __main__: train step 24202: loss: 0.9247, policy_loss: 0.8581, value_loss: 0.3892
2024-07-14 07:55:30,153 [INFO    ] __main__: train step 24203: loss: 0.9247, policy_loss: 0.8581, value_loss: 0.3892
2024-07-14 07:55:30,457 [INFO    ] __main__: train step 24204: loss: 0.9247, policy_loss: 0.8581, value_loss: 0.3892
2024-07-14 07:55:32,089 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:55:32,505 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:55:32,578 [INFO    ] __main__: train step 24205: loss: 0.9246, policy_loss: 0.8581, value_loss: 0.3892
2024-07-14 07:55:32,894 [INFO    ] __main__: train step 24206: loss: 0.9246, policy_loss: 0.8581, value_loss: 0.3891
2024-07-14 07:55:33,199 [INFO    ] __main__: train step 24207: loss: 0.9246, policy_loss: 0.8581, value_loss: 0.3891
2024-07-14 07:55:33,491 [INFO    ] __main__: train step 24208: loss: 0.9246, policy_loss: 0.8581, value_loss: 0.3891
2024-07-14 07:55:33,780 [INFO    ] __main__: train step 24209: loss: 0.9246, policy_loss: 0.8581, value_loss: 0.3891
2024-07-14 07:55:34,085 [INFO    ] __main__: train step 24210: loss: 0.9246, policy_loss: 0.8581, value_loss: 0.3891
2024-07-14 07:55:34,389 [INFO    ] __main__: train step 24211: loss: 0.9246, policy_loss: 0.8581, value_loss: 0.3891
2024-07-14 07:55:34,678 [INFO    ] __main__: train step 24212: loss: 0.9246, policy_loss: 0.8581, value_loss: 0.3891
2024-07-14 07:55:34,999 [INFO    ] __main__: train step 24213: loss: 0.9246, policy_loss: 0.8581, value_loss: 0.3891
2024-07-14 07:55:35,287 [INFO    ] __main__: train step 24214: loss: 0.9246, policy_loss: 0.8580, value_loss: 0.3890
2024-07-14 07:55:35,596 [INFO    ] __main__: train step 24215: loss: 0.9246, policy_loss: 0.8580, value_loss: 0.3890
2024-07-14 07:55:35,915 [INFO    ] __main__: train step 24216: loss: 0.9246, policy_loss: 0.8580, value_loss: 0.3890
2024-07-14 07:55:36,226 [INFO    ] __main__: train step 24217: loss: 0.9246, policy_loss: 0.8580, value_loss: 0.3890
2024-07-14 07:55:36,533 [INFO    ] __main__: train step 24218: loss: 0.9246, policy_loss: 0.8580, value_loss: 0.3890
2024-07-14 07:55:41,179 [INFO    ] __main__: train step 24219: loss: 0.9246, policy_loss: 0.8580, value_loss: 0.3890
2024-07-14 07:55:41,469 [INFO    ] __main__: train step 24220: loss: 0.9246, policy_loss: 0.8580, value_loss: 0.3890
2024-07-14 07:55:41,745 [INFO    ] __main__: train step 24221: loss: 0.9245, policy_loss: 0.8580, value_loss: 0.3890
2024-07-14 07:55:43,336 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:55:43,773 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:55:43,842 [INFO    ] __main__: train step 24222: loss: 0.9245, policy_loss: 0.8580, value_loss: 0.3890
2024-07-14 07:55:44,137 [INFO    ] __main__: train step 24223: loss: 0.9245, policy_loss: 0.8580, value_loss: 0.3889
2024-07-14 07:55:44,439 [INFO    ] __main__: train step 24224: loss: 0.9245, policy_loss: 0.8580, value_loss: 0.3889
2024-07-14 07:55:44,719 [INFO    ] __main__: train step 24225: loss: 0.9245, policy_loss: 0.8580, value_loss: 0.3889
2024-07-14 07:55:45,022 [INFO    ] __main__: train step 24226: loss: 0.9245, policy_loss: 0.8580, value_loss: 0.3889
2024-07-14 07:55:45,330 [INFO    ] __main__: train step 24227: loss: 0.9245, policy_loss: 0.8579, value_loss: 0.3889
2024-07-14 07:55:45,635 [INFO    ] __main__: train step 24228: loss: 0.9245, policy_loss: 0.8579, value_loss: 0.3889
2024-07-14 07:55:45,931 [INFO    ] __main__: train step 24229: loss: 0.9245, policy_loss: 0.8579, value_loss: 0.3889
2024-07-14 07:55:46,234 [INFO    ] __main__: train step 24230: loss: 0.9245, policy_loss: 0.8579, value_loss: 0.3889
2024-07-14 07:55:46,542 [INFO    ] __main__: train step 24231: loss: 0.9245, policy_loss: 0.8579, value_loss: 0.3889
2024-07-14 07:55:46,851 [INFO    ] __main__: train step 24232: loss: 0.9245, policy_loss: 0.8579, value_loss: 0.3888
2024-07-14 07:55:47,149 [INFO    ] __main__: train step 24233: loss: 0.9245, policy_loss: 0.8579, value_loss: 0.3888
2024-07-14 07:55:47,460 [INFO    ] __main__: train step 24234: loss: 0.9245, policy_loss: 0.8579, value_loss: 0.3888
2024-07-14 07:55:47,741 [INFO    ] __main__: train step 24235: loss: 0.9245, policy_loss: 0.8579, value_loss: 0.3888
2024-07-14 07:55:48,043 [INFO    ] __main__: train step 24236: loss: 0.9245, policy_loss: 0.8579, value_loss: 0.3888
2024-07-14 07:55:48,360 [INFO    ] __main__: train step 24237: loss: 0.9244, policy_loss: 0.8579, value_loss: 0.3888
2024-07-14 07:55:48,675 [INFO    ] __main__: train step 24238: loss: 0.9244, policy_loss: 0.8579, value_loss: 0.3888
2024-07-14 07:55:50,299 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:55:50,732 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:55:50,800 [INFO    ] __main__: train step 24239: loss: 0.9244, policy_loss: 0.8578, value_loss: 0.3888
2024-07-14 07:55:51,087 [INFO    ] __main__: train step 24240: loss: 0.9244, policy_loss: 0.8578, value_loss: 0.3888
2024-07-14 07:55:51,381 [INFO    ] __main__: train step 24241: loss: 0.9244, policy_loss: 0.8578, value_loss: 0.3887
2024-07-14 07:55:51,676 [INFO    ] __main__: train step 24242: loss: 0.9244, policy_loss: 0.8578, value_loss: 0.3887
2024-07-14 07:55:51,978 [INFO    ] __main__: train step 24243: loss: 0.9244, policy_loss: 0.8578, value_loss: 0.3887
2024-07-14 07:55:52,258 [INFO    ] __main__: train step 24244: loss: 0.9244, policy_loss: 0.8578, value_loss: 0.3887
2024-07-14 07:55:52,569 [INFO    ] __main__: train step 24245: loss: 0.9244, policy_loss: 0.8578, value_loss: 0.3887
2024-07-14 07:55:52,856 [INFO    ] __main__: train step 24246: loss: 0.9244, policy_loss: 0.8578, value_loss: 0.3887
2024-07-14 07:55:53,147 [INFO    ] __main__: train step 24247: loss: 0.9244, policy_loss: 0.8578, value_loss: 0.3887
2024-07-14 07:55:53,437 [INFO    ] __main__: train step 24248: loss: 0.9244, policy_loss: 0.8578, value_loss: 0.3887
2024-07-14 07:55:53,728 [INFO    ] __main__: train step 24249: loss: 0.9244, policy_loss: 0.8578, value_loss: 0.3886
2024-07-14 07:55:54,024 [INFO    ] __main__: train step 24250: loss: 0.9244, policy_loss: 0.8578, value_loss: 0.3886
2024-07-14 07:55:54,320 [INFO    ] __main__: train step 24251: loss: 0.9244, policy_loss: 0.8578, value_loss: 0.3886
2024-07-14 07:55:54,635 [INFO    ] __main__: train step 24252: loss: 0.9244, policy_loss: 0.8577, value_loss: 0.3886
2024-07-14 07:55:54,953 [INFO    ] __main__: train step 24253: loss: 0.9244, policy_loss: 0.8577, value_loss: 0.3886
2024-07-14 07:55:55,271 [INFO    ] __main__: train step 24254: loss: 0.9243, policy_loss: 0.8577, value_loss: 0.3886
2024-07-14 07:55:55,581 [INFO    ] __main__: train step 24255: loss: 0.9243, policy_loss: 0.8577, value_loss: 0.3886
2024-07-14 07:55:57,194 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:55:57,618 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:55:57,685 [INFO    ] __main__: train step 24256: loss: 0.9243, policy_loss: 0.8577, value_loss: 0.3886
2024-07-14 07:55:57,987 [INFO    ] __main__: train step 24257: loss: 0.9243, policy_loss: 0.8577, value_loss: 0.3886
2024-07-14 07:55:58,283 [INFO    ] __main__: train step 24258: loss: 0.9243, policy_loss: 0.8577, value_loss: 0.3885
2024-07-14 07:55:58,577 [INFO    ] __main__: train step 24259: loss: 0.9243, policy_loss: 0.8577, value_loss: 0.3885
2024-07-14 07:55:58,842 [INFO    ] __main__: train step 24260: loss: 0.9243, policy_loss: 0.8577, value_loss: 0.3885
2024-07-14 07:55:59,112 [INFO    ] __main__: train step 24261: loss: 0.9243, policy_loss: 0.8577, value_loss: 0.3885
2024-07-14 07:55:59,421 [INFO    ] __main__: train step 24262: loss: 0.9243, policy_loss: 0.8577, value_loss: 0.3885
2024-07-14 07:55:59,704 [INFO    ] __main__: train step 24263: loss: 0.9243, policy_loss: 0.8577, value_loss: 0.3885
2024-07-14 07:55:59,988 [INFO    ] __main__: train step 24264: loss: 0.9243, policy_loss: 0.8576, value_loss: 0.3885
2024-07-14 07:56:00,290 [INFO    ] __main__: train step 24265: loss: 0.9243, policy_loss: 0.8576, value_loss: 0.3885
2024-07-14 07:56:00,573 [INFO    ] __main__: train step 24266: loss: 0.9243, policy_loss: 0.8576, value_loss: 0.3885
2024-07-14 07:56:00,874 [INFO    ] __main__: train step 24267: loss: 0.9243, policy_loss: 0.8576, value_loss: 0.3884
2024-07-14 07:56:01,174 [INFO    ] __main__: train step 24268: loss: 0.9243, policy_loss: 0.8576, value_loss: 0.3884
2024-07-14 07:56:01,479 [INFO    ] __main__: train step 24269: loss: 0.9243, policy_loss: 0.8576, value_loss: 0.3884
2024-07-14 07:56:01,778 [INFO    ] __main__: train step 24270: loss: 0.9242, policy_loss: 0.8576, value_loss: 0.3884
2024-07-14 07:56:02,065 [INFO    ] __main__: train step 24271: loss: 0.9242, policy_loss: 0.8576, value_loss: 0.3884
2024-07-14 07:56:02,344 [INFO    ] __main__: train step 24272: loss: 0.9242, policy_loss: 0.8576, value_loss: 0.3884
2024-07-14 07:56:03,973 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:56:04,409 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:56:04,477 [INFO    ] __main__: train step 24273: loss: 0.9242, policy_loss: 0.8576, value_loss: 0.3884
2024-07-14 07:56:04,777 [INFO    ] __main__: train step 24274: loss: 0.9242, policy_loss: 0.8576, value_loss: 0.3884
2024-07-14 07:56:05,077 [INFO    ] __main__: train step 24275: loss: 0.9242, policy_loss: 0.8576, value_loss: 0.3883
2024-07-14 07:56:05,377 [INFO    ] __main__: train step 24276: loss: 0.9242, policy_loss: 0.8576, value_loss: 0.3883
2024-07-14 07:56:05,677 [INFO    ] __main__: train step 24277: loss: 0.9242, policy_loss: 0.8575, value_loss: 0.3883
2024-07-14 07:56:05,986 [INFO    ] __main__: train step 24278: loss: 0.9242, policy_loss: 0.8575, value_loss: 0.3883
2024-07-14 07:56:06,296 [INFO    ] __main__: train step 24279: loss: 0.9242, policy_loss: 0.8575, value_loss: 0.3883
2024-07-14 07:56:06,586 [INFO    ] __main__: train step 24280: loss: 0.9242, policy_loss: 0.8575, value_loss: 0.3883
2024-07-14 07:56:06,866 [INFO    ] __main__: train step 24281: loss: 0.9242, policy_loss: 0.8575, value_loss: 0.3883
2024-07-14 07:56:07,165 [INFO    ] __main__: train step 24282: loss: 0.9242, policy_loss: 0.8575, value_loss: 0.3883
2024-07-14 07:56:07,470 [INFO    ] __main__: train step 24283: loss: 0.9242, policy_loss: 0.8575, value_loss: 0.3883
2024-07-14 07:56:07,782 [INFO    ] __main__: train step 24284: loss: 0.9242, policy_loss: 0.8575, value_loss: 0.3882
2024-07-14 07:56:08,069 [INFO    ] __main__: train step 24285: loss: 0.9242, policy_loss: 0.8575, value_loss: 0.3882
2024-07-14 07:56:08,363 [INFO    ] __main__: train step 24286: loss: 0.9241, policy_loss: 0.8575, value_loss: 0.3882
2024-07-14 07:56:08,655 [INFO    ] __main__: train step 24287: loss: 0.9241, policy_loss: 0.8575, value_loss: 0.3882
2024-07-14 07:56:08,965 [INFO    ] __main__: train step 24288: loss: 0.9241, policy_loss: 0.8575, value_loss: 0.3882
2024-07-14 07:56:09,275 [INFO    ] __main__: train step 24289: loss: 0.9241, policy_loss: 0.8574, value_loss: 0.3882
2024-07-14 07:56:10,914 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:56:11,345 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:56:11,409 [INFO    ] __main__: train step 24290: loss: 0.9241, policy_loss: 0.8574, value_loss: 0.3882
2024-07-14 07:56:11,705 [INFO    ] __main__: train step 24291: loss: 0.9241, policy_loss: 0.8574, value_loss: 0.3882
2024-07-14 07:56:12,021 [INFO    ] __main__: train step 24292: loss: 0.9241, policy_loss: 0.8574, value_loss: 0.3882
2024-07-14 07:56:12,327 [INFO    ] __main__: train step 24293: loss: 0.9241, policy_loss: 0.8574, value_loss: 0.3881
2024-07-14 07:56:12,625 [INFO    ] __main__: train step 24294: loss: 0.9241, policy_loss: 0.8574, value_loss: 0.3881
2024-07-14 07:56:12,914 [INFO    ] __main__: train step 24295: loss: 0.9241, policy_loss: 0.8574, value_loss: 0.3881
2024-07-14 07:56:13,198 [INFO    ] __main__: train step 24296: loss: 0.9241, policy_loss: 0.8574, value_loss: 0.3881
2024-07-14 07:56:13,487 [INFO    ] __main__: train step 24297: loss: 0.9241, policy_loss: 0.8574, value_loss: 0.3881
2024-07-14 07:56:13,793 [INFO    ] __main__: train step 24298: loss: 0.9241, policy_loss: 0.8574, value_loss: 0.3881
2024-07-14 07:56:14,104 [INFO    ] __main__: train step 24299: loss: 0.9241, policy_loss: 0.8574, value_loss: 0.3881
2024-07-14 07:56:14,404 [INFO    ] __main__: train step 24300: loss: 0.9241, policy_loss: 0.8574, value_loss: 0.3881
2024-07-14 07:56:14,696 [INFO    ] __main__: train step 24301: loss: 0.9241, policy_loss: 0.8574, value_loss: 0.3881
2024-07-14 07:56:15,004 [INFO    ] __main__: train step 24302: loss: 0.9240, policy_loss: 0.8573, value_loss: 0.3880
2024-07-14 07:56:15,301 [INFO    ] __main__: train step 24303: loss: 0.9240, policy_loss: 0.8573, value_loss: 0.3880
2024-07-14 07:56:15,601 [INFO    ] __main__: train step 24304: loss: 0.9240, policy_loss: 0.8573, value_loss: 0.3880
2024-07-14 07:56:15,880 [INFO    ] __main__: train step 24305: loss: 0.9240, policy_loss: 0.8573, value_loss: 0.3880
2024-07-14 07:56:16,154 [INFO    ] __main__: train step 24306: loss: 0.9240, policy_loss: 0.8573, value_loss: 0.3880
2024-07-14 07:56:17,772 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:56:18,142 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:56:18,207 [INFO    ] __main__: train step 24307: loss: 0.9240, policy_loss: 0.8573, value_loss: 0.3880
2024-07-14 07:56:18,500 [INFO    ] __main__: train step 24308: loss: 0.9240, policy_loss: 0.8573, value_loss: 0.3880
2024-07-14 07:56:18,808 [INFO    ] __main__: train step 24309: loss: 0.9240, policy_loss: 0.8573, value_loss: 0.3880
2024-07-14 07:56:19,092 [INFO    ] __main__: train step 24310: loss: 0.9240, policy_loss: 0.8573, value_loss: 0.3879
2024-07-14 07:56:19,398 [INFO    ] __main__: train step 24311: loss: 0.9240, policy_loss: 0.8573, value_loss: 0.3879
2024-07-14 07:56:19,695 [INFO    ] __main__: train step 24312: loss: 0.9240, policy_loss: 0.8573, value_loss: 0.3879
2024-07-14 07:56:19,992 [INFO    ] __main__: train step 24313: loss: 0.9240, policy_loss: 0.8573, value_loss: 0.3879
2024-07-14 07:56:20,297 [INFO    ] __main__: train step 24314: loss: 0.9240, policy_loss: 0.8572, value_loss: 0.3879
2024-07-14 07:56:20,602 [INFO    ] __main__: train step 24315: loss: 0.9240, policy_loss: 0.8572, value_loss: 0.3879
2024-07-14 07:56:20,881 [INFO    ] __main__: train step 24316: loss: 0.9240, policy_loss: 0.8572, value_loss: 0.3879
2024-07-14 07:56:21,167 [INFO    ] __main__: train step 24317: loss: 0.9240, policy_loss: 0.8572, value_loss: 0.3879
2024-07-14 07:56:21,466 [INFO    ] __main__: train step 24318: loss: 0.9239, policy_loss: 0.8572, value_loss: 0.3879
2024-07-14 07:56:21,772 [INFO    ] __main__: train step 24319: loss: 0.9239, policy_loss: 0.8572, value_loss: 0.3878
2024-07-14 07:56:22,082 [INFO    ] __main__: train step 24320: loss: 0.9239, policy_loss: 0.8572, value_loss: 0.3878
2024-07-14 07:56:22,376 [INFO    ] __main__: train step 24321: loss: 0.9239, policy_loss: 0.8572, value_loss: 0.3878
2024-07-14 07:56:22,645 [INFO    ] __main__: train step 24322: loss: 0.9239, policy_loss: 0.8572, value_loss: 0.3878
2024-07-14 07:56:22,932 [INFO    ] __main__: train step 24323: loss: 0.9239, policy_loss: 0.8572, value_loss: 0.3878
2024-07-14 07:56:24,565 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:56:24,988 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:56:25,060 [INFO    ] __main__: train step 24324: loss: 0.9239, policy_loss: 0.8572, value_loss: 0.3878
2024-07-14 07:56:25,372 [INFO    ] __main__: train step 24325: loss: 0.9239, policy_loss: 0.8572, value_loss: 0.3878
2024-07-14 07:56:25,664 [INFO    ] __main__: train step 24326: loss: 0.9239, policy_loss: 0.8572, value_loss: 0.3878
2024-07-14 07:56:25,958 [INFO    ] __main__: train step 24327: loss: 0.9239, policy_loss: 0.8571, value_loss: 0.3878
2024-07-14 07:56:26,256 [INFO    ] __main__: train step 24328: loss: 0.9239, policy_loss: 0.8571, value_loss: 0.3877
2024-07-14 07:56:26,564 [INFO    ] __main__: train step 24329: loss: 0.9239, policy_loss: 0.8571, value_loss: 0.3877
2024-07-14 07:56:26,874 [INFO    ] __main__: train step 24330: loss: 0.9239, policy_loss: 0.8571, value_loss: 0.3877
2024-07-14 07:56:27,190 [INFO    ] __main__: train step 24331: loss: 0.9239, policy_loss: 0.8571, value_loss: 0.3877
2024-07-14 07:56:27,489 [INFO    ] __main__: train step 24332: loss: 0.9239, policy_loss: 0.8571, value_loss: 0.3877
2024-07-14 07:56:27,786 [INFO    ] __main__: train step 24333: loss: 0.9239, policy_loss: 0.8571, value_loss: 0.3877
2024-07-14 07:56:28,097 [INFO    ] __main__: train step 24334: loss: 0.9238, policy_loss: 0.8571, value_loss: 0.3877
2024-07-14 07:56:28,410 [INFO    ] __main__: train step 24335: loss: 0.9238, policy_loss: 0.8571, value_loss: 0.3877
2024-07-14 07:56:28,712 [INFO    ] __main__: train step 24336: loss: 0.9238, policy_loss: 0.8571, value_loss: 0.3876
2024-07-14 07:56:28,986 [INFO    ] __main__: train step 24337: loss: 0.9238, policy_loss: 0.8571, value_loss: 0.3876
2024-07-14 07:56:29,282 [INFO    ] __main__: train step 24338: loss: 0.9238, policy_loss: 0.8571, value_loss: 0.3876
2024-07-14 07:56:29,582 [INFO    ] __main__: train step 24339: loss: 0.9238, policy_loss: 0.8570, value_loss: 0.3876
2024-07-14 07:56:29,893 [INFO    ] __main__: train step 24340: loss: 0.9238, policy_loss: 0.8570, value_loss: 0.3876
2024-07-14 07:56:31,524 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:56:31,963 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:56:32,026 [INFO    ] __main__: train step 24341: loss: 0.9238, policy_loss: 0.8570, value_loss: 0.3876
2024-07-14 07:56:32,331 [INFO    ] __main__: train step 24342: loss: 0.9238, policy_loss: 0.8570, value_loss: 0.3876
2024-07-14 07:56:32,625 [INFO    ] __main__: train step 24343: loss: 0.9238, policy_loss: 0.8570, value_loss: 0.3876
2024-07-14 07:56:32,931 [INFO    ] __main__: train step 24344: loss: 0.9238, policy_loss: 0.8570, value_loss: 0.3876
2024-07-14 07:56:33,255 [INFO    ] __main__: train step 24345: loss: 0.9238, policy_loss: 0.8570, value_loss: 0.3875
2024-07-14 07:56:33,522 [INFO    ] __main__: train step 24346: loss: 0.9238, policy_loss: 0.8570, value_loss: 0.3875
2024-07-14 07:56:33,806 [INFO    ] __main__: train step 24347: loss: 0.9238, policy_loss: 0.8570, value_loss: 0.3875
2024-07-14 07:56:37,618 [INFO    ] __main__: train step 24348: loss: 0.9238, policy_loss: 0.8570, value_loss: 0.3875
2024-07-14 07:56:37,931 [INFO    ] __main__: train step 24349: loss: 0.9238, policy_loss: 0.8570, value_loss: 0.3875
2024-07-14 07:56:38,241 [INFO    ] __main__: train step 24350: loss: 0.9237, policy_loss: 0.8570, value_loss: 0.3875
2024-07-14 07:56:38,510 [INFO    ] __main__: train step 24351: loss: 0.9237, policy_loss: 0.8569, value_loss: 0.3875
2024-07-14 07:56:38,789 [INFO    ] __main__: train step 24352: loss: 0.9237, policy_loss: 0.8569, value_loss: 0.3875
2024-07-14 07:56:39,081 [INFO    ] __main__: train step 24353: loss: 0.9237, policy_loss: 0.8569, value_loss: 0.3875
2024-07-14 07:56:39,391 [INFO    ] __main__: train step 24354: loss: 0.9237, policy_loss: 0.8569, value_loss: 0.3874
2024-07-14 07:56:39,703 [INFO    ] __main__: train step 24355: loss: 0.9237, policy_loss: 0.8569, value_loss: 0.3874
2024-07-14 07:56:40,002 [INFO    ] __main__: train step 24356: loss: 0.9237, policy_loss: 0.8569, value_loss: 0.3874
2024-07-14 07:56:40,282 [INFO    ] __main__: train step 24357: loss: 0.9237, policy_loss: 0.8569, value_loss: 0.3874
2024-07-14 07:56:41,897 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:56:42,319 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:56:42,383 [INFO    ] __main__: train step 24358: loss: 0.9237, policy_loss: 0.8569, value_loss: 0.3874
2024-07-14 07:56:42,692 [INFO    ] __main__: train step 24359: loss: 0.9237, policy_loss: 0.8569, value_loss: 0.3874
2024-07-14 07:56:42,982 [INFO    ] __main__: train step 24360: loss: 0.9237, policy_loss: 0.8569, value_loss: 0.3874
2024-07-14 07:56:43,252 [INFO    ] __main__: train step 24361: loss: 0.9237, policy_loss: 0.8569, value_loss: 0.3874
2024-07-14 07:56:43,550 [INFO    ] __main__: train step 24362: loss: 0.9237, policy_loss: 0.8569, value_loss: 0.3874
2024-07-14 07:56:43,861 [INFO    ] __main__: train step 24363: loss: 0.9237, policy_loss: 0.8569, value_loss: 0.3873
2024-07-14 07:56:44,168 [INFO    ] __main__: train step 24364: loss: 0.9237, policy_loss: 0.8568, value_loss: 0.3873
2024-07-14 07:56:44,472 [INFO    ] __main__: train step 24365: loss: 0.9237, policy_loss: 0.8568, value_loss: 0.3873
2024-07-14 07:56:44,767 [INFO    ] __main__: train step 24366: loss: 0.9236, policy_loss: 0.8568, value_loss: 0.3873
2024-07-14 07:56:45,074 [INFO    ] __main__: train step 24367: loss: 0.9236, policy_loss: 0.8568, value_loss: 0.3873
2024-07-14 07:56:45,380 [INFO    ] __main__: train step 24368: loss: 0.9236, policy_loss: 0.8568, value_loss: 0.3873
2024-07-14 07:56:45,675 [INFO    ] __main__: train step 24369: loss: 0.9236, policy_loss: 0.8568, value_loss: 0.3873
2024-07-14 07:56:45,973 [INFO    ] __main__: train step 24370: loss: 0.9236, policy_loss: 0.8568, value_loss: 0.3873
2024-07-14 07:56:46,248 [INFO    ] __main__: train step 24371: loss: 0.9236, policy_loss: 0.8568, value_loss: 0.3872
2024-07-14 07:56:46,526 [INFO    ] __main__: train step 24372: loss: 0.9236, policy_loss: 0.8568, value_loss: 0.3872
2024-07-14 07:56:46,809 [INFO    ] __main__: train step 24373: loss: 0.9236, policy_loss: 0.8568, value_loss: 0.3872
2024-07-14 07:56:47,093 [INFO    ] __main__: train step 24374: loss: 0.9236, policy_loss: 0.8568, value_loss: 0.3872
2024-07-14 07:56:48,695 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:56:49,123 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:56:49,188 [INFO    ] __main__: train step 24375: loss: 0.9236, policy_loss: 0.8568, value_loss: 0.3872
2024-07-14 07:56:49,492 [INFO    ] __main__: train step 24376: loss: 0.9236, policy_loss: 0.8567, value_loss: 0.3872
2024-07-14 07:56:49,787 [INFO    ] __main__: train step 24377: loss: 0.9236, policy_loss: 0.8567, value_loss: 0.3872
2024-07-14 07:56:50,082 [INFO    ] __main__: train step 24378: loss: 0.9236, policy_loss: 0.8567, value_loss: 0.3872
2024-07-14 07:56:50,388 [INFO    ] __main__: train step 24379: loss: 0.9236, policy_loss: 0.8567, value_loss: 0.3872
2024-07-14 07:56:50,704 [INFO    ] __main__: train step 24380: loss: 0.9236, policy_loss: 0.8567, value_loss: 0.3871
2024-07-14 07:56:50,986 [INFO    ] __main__: train step 24381: loss: 0.9235, policy_loss: 0.8567, value_loss: 0.3871
2024-07-14 07:56:51,286 [INFO    ] __main__: train step 24382: loss: 0.9235, policy_loss: 0.8567, value_loss: 0.3871
2024-07-14 07:56:51,595 [INFO    ] __main__: train step 24383: loss: 0.9235, policy_loss: 0.8567, value_loss: 0.3871
2024-07-14 07:56:51,914 [INFO    ] __main__: train step 24384: loss: 0.9235, policy_loss: 0.8567, value_loss: 0.3871
2024-07-14 07:56:52,217 [INFO    ] __main__: train step 24385: loss: 0.9235, policy_loss: 0.8567, value_loss: 0.3871
2024-07-14 07:56:52,523 [INFO    ] __main__: train step 24386: loss: 0.9235, policy_loss: 0.8567, value_loss: 0.3871
2024-07-14 07:56:52,810 [INFO    ] __main__: train step 24387: loss: 0.9235, policy_loss: 0.8567, value_loss: 0.3871
2024-07-14 07:56:53,134 [INFO    ] __main__: train step 24388: loss: 0.9235, policy_loss: 0.8566, value_loss: 0.3871
2024-07-14 07:56:53,438 [INFO    ] __main__: train step 24389: loss: 0.9235, policy_loss: 0.8566, value_loss: 0.3870
2024-07-14 07:56:53,753 [INFO    ] __main__: train step 24390: loss: 0.9235, policy_loss: 0.8566, value_loss: 0.3870
2024-07-14 07:56:54,040 [INFO    ] __main__: train step 24391: loss: 0.9235, policy_loss: 0.8566, value_loss: 0.3870
2024-07-14 07:56:55,651 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:56:56,086 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:56:56,156 [INFO    ] __main__: train step 24392: loss: 0.9235, policy_loss: 0.8566, value_loss: 0.3870
2024-07-14 07:56:56,443 [INFO    ] __main__: train step 24393: loss: 0.9235, policy_loss: 0.8566, value_loss: 0.3870
2024-07-14 07:56:56,742 [INFO    ] __main__: train step 24394: loss: 0.9235, policy_loss: 0.8566, value_loss: 0.3870
2024-07-14 07:56:57,054 [INFO    ] __main__: train step 24395: loss: 0.9235, policy_loss: 0.8566, value_loss: 0.3870
2024-07-14 07:56:57,337 [INFO    ] __main__: train step 24396: loss: 0.9234, policy_loss: 0.8566, value_loss: 0.3870
2024-07-14 07:56:57,616 [INFO    ] __main__: train step 24397: loss: 0.9234, policy_loss: 0.8566, value_loss: 0.3870
2024-07-14 07:56:57,918 [INFO    ] __main__: train step 24398: loss: 0.9234, policy_loss: 0.8566, value_loss: 0.3869
2024-07-14 07:56:58,217 [INFO    ] __main__: train step 24399: loss: 0.9234, policy_loss: 0.8566, value_loss: 0.3869
2024-07-14 07:56:58,520 [INFO    ] __main__: train step 24400: loss: 0.9234, policy_loss: 0.8565, value_loss: 0.3869
2024-07-14 07:56:58,814 [INFO    ] __main__: train step 24401: loss: 0.9234, policy_loss: 0.8565, value_loss: 0.3869
2024-07-14 07:56:59,107 [INFO    ] __main__: train step 24402: loss: 0.9234, policy_loss: 0.8565, value_loss: 0.3869
2024-07-14 07:56:59,408 [INFO    ] __main__: train step 24403: loss: 0.9234, policy_loss: 0.8565, value_loss: 0.3869
2024-07-14 07:56:59,695 [INFO    ] __main__: train step 24404: loss: 0.9234, policy_loss: 0.8565, value_loss: 0.3869
2024-07-14 07:57:00,002 [INFO    ] __main__: train step 24405: loss: 0.9234, policy_loss: 0.8565, value_loss: 0.3869
2024-07-14 07:57:00,296 [INFO    ] __main__: train step 24406: loss: 0.9234, policy_loss: 0.8565, value_loss: 0.3869
2024-07-14 07:57:00,555 [INFO    ] __main__: train step 24407: loss: 0.9234, policy_loss: 0.8565, value_loss: 0.3868
2024-07-14 07:57:00,866 [INFO    ] __main__: train step 24408: loss: 0.9234, policy_loss: 0.8565, value_loss: 0.3868
2024-07-14 07:57:02,484 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:57:02,905 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:57:02,971 [INFO    ] __main__: train step 24409: loss: 0.9234, policy_loss: 0.8565, value_loss: 0.3868
2024-07-14 07:57:03,279 [INFO    ] __main__: train step 24410: loss: 0.9234, policy_loss: 0.8565, value_loss: 0.3868
2024-07-14 07:57:03,548 [INFO    ] __main__: train step 24411: loss: 0.9234, policy_loss: 0.8565, value_loss: 0.3868
2024-07-14 07:57:03,826 [INFO    ] __main__: train step 24412: loss: 0.9233, policy_loss: 0.8565, value_loss: 0.3868
2024-07-14 07:57:04,123 [INFO    ] __main__: train step 24413: loss: 0.9233, policy_loss: 0.8564, value_loss: 0.3868
2024-07-14 07:57:04,430 [INFO    ] __main__: train step 24414: loss: 0.9233, policy_loss: 0.8564, value_loss: 0.3868
2024-07-14 07:57:04,736 [INFO    ] __main__: train step 24415: loss: 0.9233, policy_loss: 0.8564, value_loss: 0.3867
2024-07-14 07:57:05,003 [INFO    ] __main__: train step 24416: loss: 0.9233, policy_loss: 0.8564, value_loss: 0.3867
2024-07-14 07:57:05,287 [INFO    ] __main__: train step 24417: loss: 0.9233, policy_loss: 0.8564, value_loss: 0.3867
2024-07-14 07:57:05,577 [INFO    ] __main__: train step 24418: loss: 0.9233, policy_loss: 0.8564, value_loss: 0.3867
2024-07-14 07:57:05,877 [INFO    ] __main__: train step 24419: loss: 0.9233, policy_loss: 0.8564, value_loss: 0.3867
2024-07-14 07:57:06,177 [INFO    ] __main__: train step 24420: loss: 0.9233, policy_loss: 0.8564, value_loss: 0.3867
2024-07-14 07:57:06,466 [INFO    ] __main__: train step 24421: loss: 0.9233, policy_loss: 0.8564, value_loss: 0.3867
2024-07-14 07:57:06,733 [INFO    ] __main__: train step 24422: loss: 0.9233, policy_loss: 0.8564, value_loss: 0.3867
2024-07-14 07:57:07,006 [INFO    ] __main__: train step 24423: loss: 0.9233, policy_loss: 0.8564, value_loss: 0.3867
2024-07-14 07:57:07,276 [INFO    ] __main__: train step 24424: loss: 0.9233, policy_loss: 0.8564, value_loss: 0.3866
2024-07-14 07:57:07,569 [INFO    ] __main__: train step 24425: loss: 0.9233, policy_loss: 0.8563, value_loss: 0.3866
2024-07-14 07:57:09,173 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:57:09,585 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:57:09,655 [INFO    ] __main__: train step 24426: loss: 0.9233, policy_loss: 0.8563, value_loss: 0.3866
2024-07-14 07:57:09,934 [INFO    ] __main__: train step 24427: loss: 0.9233, policy_loss: 0.8563, value_loss: 0.3866
2024-07-14 07:57:10,224 [INFO    ] __main__: train step 24428: loss: 0.9232, policy_loss: 0.8563, value_loss: 0.3866
2024-07-14 07:57:10,524 [INFO    ] __main__: train step 24429: loss: 0.9232, policy_loss: 0.8563, value_loss: 0.3866
2024-07-14 07:57:10,818 [INFO    ] __main__: train step 24430: loss: 0.9232, policy_loss: 0.8563, value_loss: 0.3866
2024-07-14 07:57:11,123 [INFO    ] __main__: train step 24431: loss: 0.9232, policy_loss: 0.8563, value_loss: 0.3866
2024-07-14 07:57:11,417 [INFO    ] __main__: train step 24432: loss: 0.9232, policy_loss: 0.8563, value_loss: 0.3866
2024-07-14 07:57:11,698 [INFO    ] __main__: train step 24433: loss: 0.9232, policy_loss: 0.8563, value_loss: 0.3865
2024-07-14 07:57:12,021 [INFO    ] __main__: train step 24434: loss: 0.9232, policy_loss: 0.8563, value_loss: 0.3865
2024-07-14 07:57:12,324 [INFO    ] __main__: train step 24435: loss: 0.9232, policy_loss: 0.8563, value_loss: 0.3865
2024-07-14 07:57:12,628 [INFO    ] __main__: train step 24436: loss: 0.9232, policy_loss: 0.8563, value_loss: 0.3865
2024-07-14 07:57:12,933 [INFO    ] __main__: train step 24437: loss: 0.9232, policy_loss: 0.8562, value_loss: 0.3865
2024-07-14 07:57:13,243 [INFO    ] __main__: train step 24438: loss: 0.9232, policy_loss: 0.8562, value_loss: 0.3865
2024-07-14 07:57:13,542 [INFO    ] __main__: train step 24439: loss: 0.9232, policy_loss: 0.8562, value_loss: 0.3865
2024-07-14 07:57:13,850 [INFO    ] __main__: train step 24440: loss: 0.9232, policy_loss: 0.8562, value_loss: 0.3865
2024-07-14 07:57:14,140 [INFO    ] __main__: train step 24441: loss: 0.9232, policy_loss: 0.8562, value_loss: 0.3865
2024-07-14 07:57:14,446 [INFO    ] __main__: train step 24442: loss: 0.9232, policy_loss: 0.8562, value_loss: 0.3864
2024-07-14 07:57:16,041 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:57:16,474 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:57:16,536 [INFO    ] __main__: train step 24443: loss: 0.9231, policy_loss: 0.8562, value_loss: 0.3864
2024-07-14 07:57:16,833 [INFO    ] __main__: train step 24444: loss: 0.9231, policy_loss: 0.8562, value_loss: 0.3864
2024-07-14 07:57:17,132 [INFO    ] __main__: train step 24445: loss: 0.9231, policy_loss: 0.8562, value_loss: 0.3864
2024-07-14 07:57:17,443 [INFO    ] __main__: train step 24446: loss: 0.9231, policy_loss: 0.8562, value_loss: 0.3864
2024-07-14 07:57:17,736 [INFO    ] __main__: train step 24447: loss: 0.9231, policy_loss: 0.8562, value_loss: 0.3864
2024-07-14 07:57:18,027 [INFO    ] __main__: train step 24448: loss: 0.9231, policy_loss: 0.8562, value_loss: 0.3864
2024-07-14 07:57:18,330 [INFO    ] __main__: train step 24449: loss: 0.9231, policy_loss: 0.8561, value_loss: 0.3864
2024-07-14 07:57:18,635 [INFO    ] __main__: train step 24450: loss: 0.9231, policy_loss: 0.8561, value_loss: 0.3864
2024-07-14 07:57:18,936 [INFO    ] __main__: train step 24451: loss: 0.9231, policy_loss: 0.8561, value_loss: 0.3863
2024-07-14 07:57:19,228 [INFO    ] __main__: train step 24452: loss: 0.9231, policy_loss: 0.8561, value_loss: 0.3863
2024-07-14 07:57:19,531 [INFO    ] __main__: train step 24453: loss: 0.9231, policy_loss: 0.8561, value_loss: 0.3863
2024-07-14 07:57:19,831 [INFO    ] __main__: train step 24454: loss: 0.9231, policy_loss: 0.8561, value_loss: 0.3863
2024-07-14 07:57:20,136 [INFO    ] __main__: train step 24455: loss: 0.9231, policy_loss: 0.8561, value_loss: 0.3863
2024-07-14 07:57:20,456 [INFO    ] __main__: train step 24456: loss: 0.9231, policy_loss: 0.8561, value_loss: 0.3863
2024-07-14 07:57:20,765 [INFO    ] __main__: train step 24457: loss: 0.9231, policy_loss: 0.8561, value_loss: 0.3863
2024-07-14 07:57:21,042 [INFO    ] __main__: train step 24458: loss: 0.9231, policy_loss: 0.8561, value_loss: 0.3863
2024-07-14 07:57:21,331 [INFO    ] __main__: train step 24459: loss: 0.9230, policy_loss: 0.8561, value_loss: 0.3863
2024-07-14 07:57:22,944 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:57:23,380 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:57:23,445 [INFO    ] __main__: train step 24460: loss: 0.9230, policy_loss: 0.8561, value_loss: 0.3862
2024-07-14 07:57:23,747 [INFO    ] __main__: train step 24461: loss: 0.9230, policy_loss: 0.8561, value_loss: 0.3862
2024-07-14 07:57:24,054 [INFO    ] __main__: train step 24462: loss: 0.9230, policy_loss: 0.8560, value_loss: 0.3862
2024-07-14 07:57:24,335 [INFO    ] __main__: train step 24463: loss: 0.9230, policy_loss: 0.8560, value_loss: 0.3862
2024-07-14 07:57:24,607 [INFO    ] __main__: train step 24464: loss: 0.9230, policy_loss: 0.8560, value_loss: 0.3862
2024-07-14 07:57:24,888 [INFO    ] __main__: train step 24465: loss: 0.9230, policy_loss: 0.8560, value_loss: 0.3862
2024-07-14 07:57:25,190 [INFO    ] __main__: train step 24466: loss: 0.9230, policy_loss: 0.8560, value_loss: 0.3862
2024-07-14 07:57:25,494 [INFO    ] __main__: train step 24467: loss: 0.9230, policy_loss: 0.8560, value_loss: 0.3862
2024-07-14 07:57:25,803 [INFO    ] __main__: train step 24468: loss: 0.9230, policy_loss: 0.8560, value_loss: 0.3862
2024-07-14 07:57:26,073 [INFO    ] __main__: train step 24469: loss: 0.9230, policy_loss: 0.8560, value_loss: 0.3861
2024-07-14 07:57:26,379 [INFO    ] __main__: train step 24470: loss: 0.9230, policy_loss: 0.8560, value_loss: 0.3861
2024-07-14 07:57:26,682 [INFO    ] __main__: train step 24471: loss: 0.9230, policy_loss: 0.8560, value_loss: 0.3861
2024-07-14 07:57:26,998 [INFO    ] __main__: train step 24472: loss: 0.9230, policy_loss: 0.8560, value_loss: 0.3861
2024-07-14 07:57:27,297 [INFO    ] __main__: train step 24473: loss: 0.9230, policy_loss: 0.8560, value_loss: 0.3861
2024-07-14 07:57:27,587 [INFO    ] __main__: train step 24474: loss: 0.9230, policy_loss: 0.8559, value_loss: 0.3861
2024-07-14 07:57:27,890 [INFO    ] __main__: train step 24475: loss: 0.9229, policy_loss: 0.8559, value_loss: 0.3861
2024-07-14 07:57:28,189 [INFO    ] __main__: train step 24476: loss: 0.9229, policy_loss: 0.8559, value_loss: 0.3861
2024-07-14 07:57:33,769 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:57:34,219 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:57:34,285 [INFO    ] __main__: train step 24477: loss: 0.9229, policy_loss: 0.8559, value_loss: 0.3860
2024-07-14 07:57:34,583 [INFO    ] __main__: train step 24478: loss: 0.9229, policy_loss: 0.8559, value_loss: 0.3860
2024-07-14 07:57:34,886 [INFO    ] __main__: train step 24479: loss: 0.9229, policy_loss: 0.8559, value_loss: 0.3860
2024-07-14 07:57:35,186 [INFO    ] __main__: train step 24480: loss: 0.9229, policy_loss: 0.8559, value_loss: 0.3860
2024-07-14 07:57:35,473 [INFO    ] __main__: train step 24481: loss: 0.9229, policy_loss: 0.8559, value_loss: 0.3860
2024-07-14 07:57:35,763 [INFO    ] __main__: train step 24482: loss: 0.9229, policy_loss: 0.8559, value_loss: 0.3860
2024-07-14 07:57:36,066 [INFO    ] __main__: train step 24483: loss: 0.9229, policy_loss: 0.8559, value_loss: 0.3860
2024-07-14 07:57:36,373 [INFO    ] __main__: train step 24484: loss: 0.9229, policy_loss: 0.8559, value_loss: 0.3860
2024-07-14 07:57:36,668 [INFO    ] __main__: train step 24485: loss: 0.9229, policy_loss: 0.8559, value_loss: 0.3860
2024-07-14 07:57:36,943 [INFO    ] __main__: train step 24486: loss: 0.9229, policy_loss: 0.8558, value_loss: 0.3859
2024-07-14 07:57:37,228 [INFO    ] __main__: train step 24487: loss: 0.9229, policy_loss: 0.8558, value_loss: 0.3859
2024-07-14 07:57:37,524 [INFO    ] __main__: train step 24488: loss: 0.9229, policy_loss: 0.8558, value_loss: 0.3859
2024-07-14 07:57:37,830 [INFO    ] __main__: train step 24489: loss: 0.9229, policy_loss: 0.8558, value_loss: 0.3859
2024-07-14 07:57:38,135 [INFO    ] __main__: train step 24490: loss: 0.9228, policy_loss: 0.8558, value_loss: 0.3859
2024-07-14 07:57:38,426 [INFO    ] __main__: train step 24491: loss: 0.9228, policy_loss: 0.8558, value_loss: 0.3859
2024-07-14 07:57:38,699 [INFO    ] __main__: train step 24492: loss: 0.9228, policy_loss: 0.8558, value_loss: 0.3859
2024-07-14 07:57:38,979 [INFO    ] __main__: train step 24493: loss: 0.9228, policy_loss: 0.8558, value_loss: 0.3859
2024-07-14 07:57:40,563 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:57:40,985 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:57:41,050 [INFO    ] __main__: train step 24494: loss: 0.9228, policy_loss: 0.8558, value_loss: 0.3859
2024-07-14 07:57:41,350 [INFO    ] __main__: train step 24495: loss: 0.9228, policy_loss: 0.8558, value_loss: 0.3858
2024-07-14 07:57:41,623 [INFO    ] __main__: train step 24496: loss: 0.9228, policy_loss: 0.8558, value_loss: 0.3858
2024-07-14 07:57:41,926 [INFO    ] __main__: train step 24497: loss: 0.9228, policy_loss: 0.8558, value_loss: 0.3858
2024-07-14 07:57:42,215 [INFO    ] __main__: train step 24498: loss: 0.9228, policy_loss: 0.8557, value_loss: 0.3858
2024-07-14 07:57:42,535 [INFO    ] __main__: train step 24499: loss: 0.9228, policy_loss: 0.8557, value_loss: 0.3858
2024-07-14 07:57:42,838 [INFO    ] __main__: train step 24500: loss: 0.9228, policy_loss: 0.8557, value_loss: 0.3858
2024-07-14 07:57:43,137 [INFO    ] __main__: train step 24501: loss: 0.9228, policy_loss: 0.8557, value_loss: 0.3858
2024-07-14 07:57:43,413 [INFO    ] __main__: train step 24502: loss: 0.9228, policy_loss: 0.8557, value_loss: 0.3858
2024-07-14 07:57:43,683 [INFO    ] __main__: train step 24503: loss: 0.9228, policy_loss: 0.8557, value_loss: 0.3858
2024-07-14 07:57:43,972 [INFO    ] __main__: train step 24504: loss: 0.9228, policy_loss: 0.8557, value_loss: 0.3857
2024-07-14 07:57:44,267 [INFO    ] __main__: train step 24505: loss: 0.9227, policy_loss: 0.8557, value_loss: 0.3857
2024-07-14 07:57:44,559 [INFO    ] __main__: train step 24506: loss: 0.9227, policy_loss: 0.8557, value_loss: 0.3857
2024-07-14 07:57:44,874 [INFO    ] __main__: train step 24507: loss: 0.9227, policy_loss: 0.8557, value_loss: 0.3857
2024-07-14 07:57:45,159 [INFO    ] __main__: train step 24508: loss: 0.9227, policy_loss: 0.8557, value_loss: 0.3857
2024-07-14 07:57:45,465 [INFO    ] __main__: train step 24509: loss: 0.9227, policy_loss: 0.8557, value_loss: 0.3857
2024-07-14 07:57:45,760 [INFO    ] __main__: train step 24510: loss: 0.9227, policy_loss: 0.8556, value_loss: 0.3857
2024-07-14 07:57:47,377 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:57:47,826 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:57:47,892 [INFO    ] __main__: train step 24511: loss: 0.9227, policy_loss: 0.8556, value_loss: 0.3857
2024-07-14 07:57:48,177 [INFO    ] __main__: train step 24512: loss: 0.9227, policy_loss: 0.8556, value_loss: 0.3856
2024-07-14 07:57:48,472 [INFO    ] __main__: train step 24513: loss: 0.9227, policy_loss: 0.8556, value_loss: 0.3856
2024-07-14 07:57:48,779 [INFO    ] __main__: train step 24514: loss: 0.9227, policy_loss: 0.8556, value_loss: 0.3856
2024-07-14 07:57:49,085 [INFO    ] __main__: train step 24515: loss: 0.9227, policy_loss: 0.8556, value_loss: 0.3856
2024-07-14 07:57:49,387 [INFO    ] __main__: train step 24516: loss: 0.9227, policy_loss: 0.8556, value_loss: 0.3856
2024-07-14 07:57:49,660 [INFO    ] __main__: train step 24517: loss: 0.9227, policy_loss: 0.8556, value_loss: 0.3856
2024-07-14 07:57:49,949 [INFO    ] __main__: train step 24518: loss: 0.9227, policy_loss: 0.8556, value_loss: 0.3856
2024-07-14 07:57:50,241 [INFO    ] __main__: train step 24519: loss: 0.9227, policy_loss: 0.8556, value_loss: 0.3856
2024-07-14 07:57:50,546 [INFO    ] __main__: train step 24520: loss: 0.9226, policy_loss: 0.8556, value_loss: 0.3856
2024-07-14 07:57:50,857 [INFO    ] __main__: train step 24521: loss: 0.9226, policy_loss: 0.8556, value_loss: 0.3855
2024-07-14 07:57:51,142 [INFO    ] __main__: train step 24522: loss: 0.9226, policy_loss: 0.8556, value_loss: 0.3855
2024-07-14 07:57:51,443 [INFO    ] __main__: train step 24523: loss: 0.9226, policy_loss: 0.8555, value_loss: 0.3855
2024-07-14 07:57:51,778 [INFO    ] __main__: train step 24524: loss: 0.9226, policy_loss: 0.8555, value_loss: 0.3855
2024-07-14 07:57:52,082 [INFO    ] __main__: train step 24525: loss: 0.9226, policy_loss: 0.8555, value_loss: 0.3855
2024-07-14 07:57:52,389 [INFO    ] __main__: train step 24526: loss: 0.9226, policy_loss: 0.8555, value_loss: 0.3855
2024-07-14 07:57:52,716 [INFO    ] __main__: train step 24527: loss: 0.9226, policy_loss: 0.8555, value_loss: 0.3855
2024-07-14 07:57:54,336 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:57:54,737 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:57:54,803 [INFO    ] __main__: train step 24528: loss: 0.9226, policy_loss: 0.8555, value_loss: 0.3855
2024-07-14 07:57:55,128 [INFO    ] __main__: train step 24529: loss: 0.9226, policy_loss: 0.8555, value_loss: 0.3855
2024-07-14 07:57:55,450 [INFO    ] __main__: train step 24530: loss: 0.9226, policy_loss: 0.8555, value_loss: 0.3854
2024-07-14 07:57:55,748 [INFO    ] __main__: train step 24531: loss: 0.9226, policy_loss: 0.8555, value_loss: 0.3854
2024-07-14 07:57:56,019 [INFO    ] __main__: train step 24532: loss: 0.9226, policy_loss: 0.8555, value_loss: 0.3854
2024-07-14 07:57:56,322 [INFO    ] __main__: train step 24533: loss: 0.9226, policy_loss: 0.8555, value_loss: 0.3854
2024-07-14 07:57:56,637 [INFO    ] __main__: train step 24534: loss: 0.9226, policy_loss: 0.8555, value_loss: 0.3854
2024-07-14 07:57:56,946 [INFO    ] __main__: train step 24535: loss: 0.9226, policy_loss: 0.8554, value_loss: 0.3854
2024-07-14 07:57:57,296 [INFO    ] __main__: train step 24536: loss: 0.9225, policy_loss: 0.8554, value_loss: 0.3854
2024-07-14 07:57:57,588 [INFO    ] __main__: train step 24537: loss: 0.9225, policy_loss: 0.8554, value_loss: 0.3854
2024-07-14 07:57:57,894 [INFO    ] __main__: train step 24538: loss: 0.9225, policy_loss: 0.8554, value_loss: 0.3854
2024-07-14 07:57:58,196 [INFO    ] __main__: train step 24539: loss: 0.9225, policy_loss: 0.8554, value_loss: 0.3853
2024-07-14 07:57:58,489 [INFO    ] __main__: train step 24540: loss: 0.9225, policy_loss: 0.8554, value_loss: 0.3853
2024-07-14 07:57:58,797 [INFO    ] __main__: train step 24541: loss: 0.9225, policy_loss: 0.8554, value_loss: 0.3853
2024-07-14 07:57:59,099 [INFO    ] __main__: train step 24542: loss: 0.9225, policy_loss: 0.8554, value_loss: 0.3853
2024-07-14 07:57:59,401 [INFO    ] __main__: train step 24543: loss: 0.9225, policy_loss: 0.8554, value_loss: 0.3853
2024-07-14 07:57:59,690 [INFO    ] __main__: train step 24544: loss: 0.9225, policy_loss: 0.8554, value_loss: 0.3853
2024-07-14 07:58:01,299 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:58:01,720 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:58:01,789 [INFO    ] __main__: train step 24545: loss: 0.9225, policy_loss: 0.8554, value_loss: 0.3853
2024-07-14 07:58:02,078 [INFO    ] __main__: train step 24546: loss: 0.9225, policy_loss: 0.8554, value_loss: 0.3853
2024-07-14 07:58:02,377 [INFO    ] __main__: train step 24547: loss: 0.9225, policy_loss: 0.8553, value_loss: 0.3853
2024-07-14 07:58:02,667 [INFO    ] __main__: train step 24548: loss: 0.9225, policy_loss: 0.8553, value_loss: 0.3852
2024-07-14 07:58:02,988 [INFO    ] __main__: train step 24549: loss: 0.9225, policy_loss: 0.8553, value_loss: 0.3852
2024-07-14 07:58:03,296 [INFO    ] __main__: train step 24550: loss: 0.9225, policy_loss: 0.8553, value_loss: 0.3852
2024-07-14 07:58:03,586 [INFO    ] __main__: train step 24551: loss: 0.9224, policy_loss: 0.8553, value_loss: 0.3852
2024-07-14 07:58:03,862 [INFO    ] __main__: train step 24552: loss: 0.9224, policy_loss: 0.8553, value_loss: 0.3852
2024-07-14 07:58:04,145 [INFO    ] __main__: train step 24553: loss: 0.9224, policy_loss: 0.8553, value_loss: 0.3852
2024-07-14 07:58:04,452 [INFO    ] __main__: train step 24554: loss: 0.9224, policy_loss: 0.8553, value_loss: 0.3852
2024-07-14 07:58:04,773 [INFO    ] __main__: train step 24555: loss: 0.9224, policy_loss: 0.8553, value_loss: 0.3852
2024-07-14 07:58:05,089 [INFO    ] __main__: train step 24556: loss: 0.9224, policy_loss: 0.8553, value_loss: 0.3851
2024-07-14 07:58:05,395 [INFO    ] __main__: train step 24557: loss: 0.9224, policy_loss: 0.8553, value_loss: 0.3851
2024-07-14 07:58:05,672 [INFO    ] __main__: train step 24558: loss: 0.9224, policy_loss: 0.8553, value_loss: 0.3851
2024-07-14 07:58:05,984 [INFO    ] __main__: train step 24559: loss: 0.9224, policy_loss: 0.8553, value_loss: 0.3851
2024-07-14 07:58:06,292 [INFO    ] __main__: train step 24560: loss: 0.9224, policy_loss: 0.8552, value_loss: 0.3851
2024-07-14 07:58:06,596 [INFO    ] __main__: train step 24561: loss: 0.9224, policy_loss: 0.8552, value_loss: 0.3851
2024-07-14 07:58:08,221 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:58:08,654 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:58:08,723 [INFO    ] __main__: train step 24562: loss: 0.9224, policy_loss: 0.8552, value_loss: 0.3851
2024-07-14 07:58:09,016 [INFO    ] __main__: train step 24563: loss: 0.9224, policy_loss: 0.8552, value_loss: 0.3851
2024-07-14 07:58:09,320 [INFO    ] __main__: train step 24564: loss: 0.9224, policy_loss: 0.8552, value_loss: 0.3851
2024-07-14 07:58:09,618 [INFO    ] __main__: train step 24565: loss: 0.9224, policy_loss: 0.8552, value_loss: 0.3850
2024-07-14 07:58:09,926 [INFO    ] __main__: train step 24566: loss: 0.9223, policy_loss: 0.8552, value_loss: 0.3850
2024-07-14 07:58:10,217 [INFO    ] __main__: train step 24567: loss: 0.9223, policy_loss: 0.8552, value_loss: 0.3850
2024-07-14 07:58:10,529 [INFO    ] __main__: train step 24568: loss: 0.9223, policy_loss: 0.8552, value_loss: 0.3850
2024-07-14 07:58:10,830 [INFO    ] __main__: train step 24569: loss: 0.9223, policy_loss: 0.8552, value_loss: 0.3850
2024-07-14 07:58:11,139 [INFO    ] __main__: train step 24570: loss: 0.9223, policy_loss: 0.8552, value_loss: 0.3850
2024-07-14 07:58:11,450 [INFO    ] __main__: train step 24571: loss: 0.9223, policy_loss: 0.8552, value_loss: 0.3850
2024-07-14 07:58:11,737 [INFO    ] __main__: train step 24572: loss: 0.9223, policy_loss: 0.8551, value_loss: 0.3850
2024-07-14 07:58:12,039 [INFO    ] __main__: train step 24573: loss: 0.9223, policy_loss: 0.8551, value_loss: 0.3850
2024-07-14 07:58:12,344 [INFO    ] __main__: train step 24574: loss: 0.9223, policy_loss: 0.8551, value_loss: 0.3849
2024-07-14 07:58:12,655 [INFO    ] __main__: train step 24575: loss: 0.9223, policy_loss: 0.8551, value_loss: 0.3849
2024-07-14 07:58:12,965 [INFO    ] __main__: train step 24576: loss: 0.9223, policy_loss: 0.8551, value_loss: 0.3849
2024-07-14 07:58:13,287 [INFO    ] __main__: train step 24577: loss: 0.9223, policy_loss: 0.8551, value_loss: 0.3849
2024-07-14 07:58:13,568 [INFO    ] __main__: train step 24578: loss: 0.9223, policy_loss: 0.8551, value_loss: 0.3849
2024-07-14 07:58:15,198 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:58:15,630 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:58:15,703 [INFO    ] __main__: train step 24579: loss: 0.9223, policy_loss: 0.8551, value_loss: 0.3849
2024-07-14 07:58:16,017 [INFO    ] __main__: train step 24580: loss: 0.9223, policy_loss: 0.8551, value_loss: 0.3849
2024-07-14 07:58:16,319 [INFO    ] __main__: train step 24581: loss: 0.9222, policy_loss: 0.8551, value_loss: 0.3849
2024-07-14 07:58:16,605 [INFO    ] __main__: train step 24582: loss: 0.9222, policy_loss: 0.8551, value_loss: 0.3849
2024-07-14 07:58:16,914 [INFO    ] __main__: train step 24583: loss: 0.9222, policy_loss: 0.8551, value_loss: 0.3848
2024-07-14 07:58:17,222 [INFO    ] __main__: train step 24584: loss: 0.9222, policy_loss: 0.8550, value_loss: 0.3848
2024-07-14 07:58:17,534 [INFO    ] __main__: train step 24585: loss: 0.9222, policy_loss: 0.8550, value_loss: 0.3848
2024-07-14 07:58:17,857 [INFO    ] __main__: train step 24586: loss: 0.9222, policy_loss: 0.8550, value_loss: 0.3848
2024-07-14 07:58:18,167 [INFO    ] __main__: train step 24587: loss: 0.9222, policy_loss: 0.8550, value_loss: 0.3848
2024-07-14 07:58:18,469 [INFO    ] __main__: train step 24588: loss: 0.9222, policy_loss: 0.8550, value_loss: 0.3848
2024-07-14 07:58:18,788 [INFO    ] __main__: train step 24589: loss: 0.9222, policy_loss: 0.8550, value_loss: 0.3848
2024-07-14 07:58:19,099 [INFO    ] __main__: train step 24590: loss: 0.9222, policy_loss: 0.8550, value_loss: 0.3848
2024-07-14 07:58:19,411 [INFO    ] __main__: train step 24591: loss: 0.9222, policy_loss: 0.8550, value_loss: 0.3847
2024-07-14 07:58:19,687 [INFO    ] __main__: train step 24592: loss: 0.9222, policy_loss: 0.8550, value_loss: 0.3847
2024-07-14 07:58:19,979 [INFO    ] __main__: train step 24593: loss: 0.9222, policy_loss: 0.8550, value_loss: 0.3847
2024-07-14 07:58:20,280 [INFO    ] __main__: train step 24594: loss: 0.9222, policy_loss: 0.8550, value_loss: 0.3847
2024-07-14 07:58:20,583 [INFO    ] __main__: train step 24595: loss: 0.9222, policy_loss: 0.8550, value_loss: 0.3847
2024-07-14 07:58:22,210 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:58:22,638 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:58:22,706 [INFO    ] __main__: train step 24596: loss: 0.9221, policy_loss: 0.8549, value_loss: 0.3847
2024-07-14 07:58:22,987 [INFO    ] __main__: train step 24597: loss: 0.9221, policy_loss: 0.8549, value_loss: 0.3847
2024-07-14 07:58:23,268 [INFO    ] __main__: train step 24598: loss: 0.9221, policy_loss: 0.8549, value_loss: 0.3847
2024-07-14 07:58:23,548 [INFO    ] __main__: train step 24599: loss: 0.9221, policy_loss: 0.8549, value_loss: 0.3847
2024-07-14 07:58:23,842 [INFO    ] __main__: train step 24600: loss: 0.9221, policy_loss: 0.8549, value_loss: 0.3846
2024-07-14 07:58:24,144 [INFO    ] __main__: train step 24601: loss: 0.9221, policy_loss: 0.8549, value_loss: 0.3846
2024-07-14 07:58:24,405 [INFO    ] __main__: train step 24602: loss: 0.9221, policy_loss: 0.8549, value_loss: 0.3846
2024-07-14 07:58:24,669 [INFO    ] __main__: train step 24603: loss: 0.9221, policy_loss: 0.8549, value_loss: 0.3846
2024-07-14 07:58:24,970 [INFO    ] __main__: train step 24604: loss: 0.9221, policy_loss: 0.8549, value_loss: 0.3846
2024-07-14 07:58:29,594 [INFO    ] __main__: train step 24605: loss: 0.9221, policy_loss: 0.8549, value_loss: 0.3846
2024-07-14 07:58:29,893 [INFO    ] __main__: train step 24606: loss: 0.9221, policy_loss: 0.8549, value_loss: 0.3846
2024-07-14 07:58:30,198 [INFO    ] __main__: train step 24607: loss: 0.9221, policy_loss: 0.8549, value_loss: 0.3846
2024-07-14 07:58:30,504 [INFO    ] __main__: train step 24608: loss: 0.9221, policy_loss: 0.8548, value_loss: 0.3846
2024-07-14 07:58:30,790 [INFO    ] __main__: train step 24609: loss: 0.9221, policy_loss: 0.8548, value_loss: 0.3845
2024-07-14 07:58:31,086 [INFO    ] __main__: train step 24610: loss: 0.9221, policy_loss: 0.8548, value_loss: 0.3845
2024-07-14 07:58:31,395 [INFO    ] __main__: train step 24611: loss: 0.9220, policy_loss: 0.8548, value_loss: 0.3845
2024-07-14 07:58:31,695 [INFO    ] __main__: train step 24612: loss: 0.9220, policy_loss: 0.8548, value_loss: 0.3845
2024-07-14 07:58:33,323 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:58:33,745 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:58:33,821 [INFO    ] __main__: train step 24613: loss: 0.9220, policy_loss: 0.8548, value_loss: 0.3845
2024-07-14 07:58:34,116 [INFO    ] __main__: train step 24614: loss: 0.9220, policy_loss: 0.8548, value_loss: 0.3845
2024-07-14 07:58:34,416 [INFO    ] __main__: train step 24615: loss: 0.9220, policy_loss: 0.8548, value_loss: 0.3845
2024-07-14 07:58:34,711 [INFO    ] __main__: train step 24616: loss: 0.9220, policy_loss: 0.8548, value_loss: 0.3845
2024-07-14 07:58:35,017 [INFO    ] __main__: train step 24617: loss: 0.9220, policy_loss: 0.8548, value_loss: 0.3845
2024-07-14 07:58:35,302 [INFO    ] __main__: train step 24618: loss: 0.9220, policy_loss: 0.8548, value_loss: 0.3844
2024-07-14 07:58:35,596 [INFO    ] __main__: train step 24619: loss: 0.9220, policy_loss: 0.8548, value_loss: 0.3844
2024-07-14 07:58:35,887 [INFO    ] __main__: train step 24620: loss: 0.9220, policy_loss: 0.8547, value_loss: 0.3844
2024-07-14 07:58:36,179 [INFO    ] __main__: train step 24621: loss: 0.9220, policy_loss: 0.8547, value_loss: 0.3844
2024-07-14 07:58:36,473 [INFO    ] __main__: train step 24622: loss: 0.9220, policy_loss: 0.8547, value_loss: 0.3844
2024-07-14 07:58:36,775 [INFO    ] __main__: train step 24623: loss: 0.9220, policy_loss: 0.8547, value_loss: 0.3844
2024-07-14 07:58:37,067 [INFO    ] __main__: train step 24624: loss: 0.9220, policy_loss: 0.8547, value_loss: 0.3844
2024-07-14 07:58:37,355 [INFO    ] __main__: train step 24625: loss: 0.9220, policy_loss: 0.8547, value_loss: 0.3844
2024-07-14 07:58:37,652 [INFO    ] __main__: train step 24626: loss: 0.9219, policy_loss: 0.8547, value_loss: 0.3844
2024-07-14 07:58:37,948 [INFO    ] __main__: train step 24627: loss: 0.9219, policy_loss: 0.8547, value_loss: 0.3843
2024-07-14 07:58:38,256 [INFO    ] __main__: train step 24628: loss: 0.9219, policy_loss: 0.8547, value_loss: 0.3843
2024-07-14 07:58:38,535 [INFO    ] __main__: train step 24629: loss: 0.9219, policy_loss: 0.8547, value_loss: 0.3843
2024-07-14 07:58:40,148 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:58:40,569 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:58:40,637 [INFO    ] __main__: train step 24630: loss: 0.9219, policy_loss: 0.8547, value_loss: 0.3843
2024-07-14 07:58:40,947 [INFO    ] __main__: train step 24631: loss: 0.9219, policy_loss: 0.8547, value_loss: 0.3843
2024-07-14 07:58:41,262 [INFO    ] __main__: train step 24632: loss: 0.9219, policy_loss: 0.8546, value_loss: 0.3843
2024-07-14 07:58:41,563 [INFO    ] __main__: train step 24633: loss: 0.9219, policy_loss: 0.8546, value_loss: 0.3843
2024-07-14 07:58:41,851 [INFO    ] __main__: train step 24634: loss: 0.9219, policy_loss: 0.8546, value_loss: 0.3843
2024-07-14 07:58:42,154 [INFO    ] __main__: train step 24635: loss: 0.9219, policy_loss: 0.8546, value_loss: 0.3843
2024-07-14 07:58:42,465 [INFO    ] __main__: train step 24636: loss: 0.9219, policy_loss: 0.8546, value_loss: 0.3842
2024-07-14 07:58:42,770 [INFO    ] __main__: train step 24637: loss: 0.9219, policy_loss: 0.8546, value_loss: 0.3842
2024-07-14 07:58:43,078 [INFO    ] __main__: train step 24638: loss: 0.9219, policy_loss: 0.8546, value_loss: 0.3842
2024-07-14 07:58:43,363 [INFO    ] __main__: train step 24639: loss: 0.9219, policy_loss: 0.8546, value_loss: 0.3842
2024-07-14 07:58:43,651 [INFO    ] __main__: train step 24640: loss: 0.9218, policy_loss: 0.8546, value_loss: 0.3842
2024-07-14 07:58:43,958 [INFO    ] __main__: train step 24641: loss: 0.9218, policy_loss: 0.8546, value_loss: 0.3842
2024-07-14 07:58:44,274 [INFO    ] __main__: train step 24642: loss: 0.9218, policy_loss: 0.8546, value_loss: 0.3842
2024-07-14 07:58:44,599 [INFO    ] __main__: train step 24643: loss: 0.9218, policy_loss: 0.8546, value_loss: 0.3842
2024-07-14 07:58:44,902 [INFO    ] __main__: train step 24644: loss: 0.9218, policy_loss: 0.8545, value_loss: 0.3842
2024-07-14 07:58:45,177 [INFO    ] __main__: train step 24645: loss: 0.9218, policy_loss: 0.8545, value_loss: 0.3841
2024-07-14 07:58:45,476 [INFO    ] __main__: train step 24646: loss: 0.9218, policy_loss: 0.8545, value_loss: 0.3841
2024-07-14 07:58:47,107 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:58:47,533 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:58:47,598 [INFO    ] __main__: train step 24647: loss: 0.9218, policy_loss: 0.8545, value_loss: 0.3841
2024-07-14 07:58:47,869 [INFO    ] __main__: train step 24648: loss: 0.9218, policy_loss: 0.8545, value_loss: 0.3841
2024-07-14 07:58:48,157 [INFO    ] __main__: train step 24649: loss: 0.9218, policy_loss: 0.8545, value_loss: 0.3841
2024-07-14 07:58:48,464 [INFO    ] __main__: train step 24650: loss: 0.9218, policy_loss: 0.8545, value_loss: 0.3841
2024-07-14 07:58:48,728 [INFO    ] __main__: train step 24651: loss: 0.9218, policy_loss: 0.8545, value_loss: 0.3841
2024-07-14 07:58:49,005 [INFO    ] __main__: train step 24652: loss: 0.9218, policy_loss: 0.8545, value_loss: 0.3841
2024-07-14 07:58:49,299 [INFO    ] __main__: train step 24653: loss: 0.9218, policy_loss: 0.8545, value_loss: 0.3841
2024-07-14 07:58:49,575 [INFO    ] __main__: train step 24654: loss: 0.9218, policy_loss: 0.8545, value_loss: 0.3840
2024-07-14 07:58:49,851 [INFO    ] __main__: train step 24655: loss: 0.9217, policy_loss: 0.8544, value_loss: 0.3840
2024-07-14 07:58:50,138 [INFO    ] __main__: train step 24656: loss: 0.9217, policy_loss: 0.8544, value_loss: 0.3840
2024-07-14 07:58:50,442 [INFO    ] __main__: train step 24657: loss: 0.9217, policy_loss: 0.8544, value_loss: 0.3840
2024-07-14 07:58:50,751 [INFO    ] __main__: train step 24658: loss: 0.9217, policy_loss: 0.8544, value_loss: 0.3840
2024-07-14 07:58:51,050 [INFO    ] __main__: train step 24659: loss: 0.9217, policy_loss: 0.8544, value_loss: 0.3840
2024-07-14 07:58:51,331 [INFO    ] __main__: train step 24660: loss: 0.9217, policy_loss: 0.8544, value_loss: 0.3840
2024-07-14 07:58:51,623 [INFO    ] __main__: train step 24661: loss: 0.9217, policy_loss: 0.8544, value_loss: 0.3840
2024-07-14 07:58:51,930 [INFO    ] __main__: train step 24662: loss: 0.9217, policy_loss: 0.8544, value_loss: 0.3839
2024-07-14 07:58:52,226 [INFO    ] __main__: train step 24663: loss: 0.9217, policy_loss: 0.8544, value_loss: 0.3839
2024-07-14 07:58:53,867 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:58:54,293 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:58:54,357 [INFO    ] __main__: train step 24664: loss: 0.9217, policy_loss: 0.8544, value_loss: 0.3839
2024-07-14 07:58:54,653 [INFO    ] __main__: train step 24665: loss: 0.9217, policy_loss: 0.8544, value_loss: 0.3839
2024-07-14 07:58:54,944 [INFO    ] __main__: train step 24666: loss: 0.9217, policy_loss: 0.8544, value_loss: 0.3839
2024-07-14 07:58:55,233 [INFO    ] __main__: train step 24667: loss: 0.9217, policy_loss: 0.8543, value_loss: 0.3839
2024-07-14 07:58:55,545 [INFO    ] __main__: train step 24668: loss: 0.9217, policy_loss: 0.8543, value_loss: 0.3839
2024-07-14 07:58:55,840 [INFO    ] __main__: train step 24669: loss: 0.9216, policy_loss: 0.8543, value_loss: 0.3839
2024-07-14 07:58:56,141 [INFO    ] __main__: train step 24670: loss: 0.9216, policy_loss: 0.8543, value_loss: 0.3839
2024-07-14 07:58:56,443 [INFO    ] __main__: train step 24671: loss: 0.9216, policy_loss: 0.8543, value_loss: 0.3838
2024-07-14 07:58:56,741 [INFO    ] __main__: train step 24672: loss: 0.9216, policy_loss: 0.8543, value_loss: 0.3838
2024-07-14 07:58:57,056 [INFO    ] __main__: train step 24673: loss: 0.9216, policy_loss: 0.8543, value_loss: 0.3838
2024-07-14 07:58:57,348 [INFO    ] __main__: train step 24674: loss: 0.9216, policy_loss: 0.8543, value_loss: 0.3838
2024-07-14 07:58:57,641 [INFO    ] __main__: train step 24675: loss: 0.9216, policy_loss: 0.8543, value_loss: 0.3838
2024-07-14 07:58:57,933 [INFO    ] __main__: train step 24676: loss: 0.9216, policy_loss: 0.8543, value_loss: 0.3838
2024-07-14 07:58:58,238 [INFO    ] __main__: train step 24677: loss: 0.9216, policy_loss: 0.8543, value_loss: 0.3838
2024-07-14 07:58:58,540 [INFO    ] __main__: train step 24678: loss: 0.9216, policy_loss: 0.8543, value_loss: 0.3838
2024-07-14 07:58:58,856 [INFO    ] __main__: train step 24679: loss: 0.9216, policy_loss: 0.8542, value_loss: 0.3838
2024-07-14 07:58:59,146 [INFO    ] __main__: train step 24680: loss: 0.9216, policy_loss: 0.8542, value_loss: 0.3837
2024-07-14 07:59:00,745 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:59:01,178 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:59:01,243 [INFO    ] __main__: train step 24681: loss: 0.9216, policy_loss: 0.8542, value_loss: 0.3837
2024-07-14 07:59:01,536 [INFO    ] __main__: train step 24682: loss: 0.9216, policy_loss: 0.8542, value_loss: 0.3837
2024-07-14 07:59:01,843 [INFO    ] __main__: train step 24683: loss: 0.9215, policy_loss: 0.8542, value_loss: 0.3837
2024-07-14 07:59:02,113 [INFO    ] __main__: train step 24684: loss: 0.9215, policy_loss: 0.8542, value_loss: 0.3837
2024-07-14 07:59:02,398 [INFO    ] __main__: train step 24685: loss: 0.9215, policy_loss: 0.8542, value_loss: 0.3837
2024-07-14 07:59:02,660 [INFO    ] __main__: train step 24686: loss: 0.9215, policy_loss: 0.8542, value_loss: 0.3837
2024-07-14 07:59:02,961 [INFO    ] __main__: train step 24687: loss: 0.9215, policy_loss: 0.8542, value_loss: 0.3837
2024-07-14 07:59:03,264 [INFO    ] __main__: train step 24688: loss: 0.9215, policy_loss: 0.8542, value_loss: 0.3837
2024-07-14 07:59:03,574 [INFO    ] __main__: train step 24689: loss: 0.9215, policy_loss: 0.8542, value_loss: 0.3836
2024-07-14 07:59:03,855 [INFO    ] __main__: train step 24690: loss: 0.9215, policy_loss: 0.8542, value_loss: 0.3836
2024-07-14 07:59:04,151 [INFO    ] __main__: train step 24691: loss: 0.9215, policy_loss: 0.8541, value_loss: 0.3836
2024-07-14 07:59:04,470 [INFO    ] __main__: train step 24692: loss: 0.9215, policy_loss: 0.8541, value_loss: 0.3836
2024-07-14 07:59:04,772 [INFO    ] __main__: train step 24693: loss: 0.9215, policy_loss: 0.8541, value_loss: 0.3836
2024-07-14 07:59:05,083 [INFO    ] __main__: train step 24694: loss: 0.9215, policy_loss: 0.8541, value_loss: 0.3836
2024-07-14 07:59:05,370 [INFO    ] __main__: train step 24695: loss: 0.9215, policy_loss: 0.8541, value_loss: 0.3836
2024-07-14 07:59:05,670 [INFO    ] __main__: train step 24696: loss: 0.9215, policy_loss: 0.8541, value_loss: 0.3836
2024-07-14 07:59:05,998 [INFO    ] __main__: train step 24697: loss: 0.9214, policy_loss: 0.8541, value_loss: 0.3835
2024-07-14 07:59:07,619 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:59:08,040 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:59:08,105 [INFO    ] __main__: train step 24698: loss: 0.9214, policy_loss: 0.8541, value_loss: 0.3835
2024-07-14 07:59:08,383 [INFO    ] __main__: train step 24699: loss: 0.9214, policy_loss: 0.8541, value_loss: 0.3835
2024-07-14 07:59:08,682 [INFO    ] __main__: train step 24700: loss: 0.9214, policy_loss: 0.8541, value_loss: 0.3835
2024-07-14 07:59:08,979 [INFO    ] __main__: train step 24701: loss: 0.9214, policy_loss: 0.8541, value_loss: 0.3835
2024-07-14 07:59:09,287 [INFO    ] __main__: train step 24702: loss: 0.9214, policy_loss: 0.8541, value_loss: 0.3835
2024-07-14 07:59:09,600 [INFO    ] __main__: train step 24703: loss: 0.9214, policy_loss: 0.8540, value_loss: 0.3835
2024-07-14 07:59:09,909 [INFO    ] __main__: train step 24704: loss: 0.9214, policy_loss: 0.8540, value_loss: 0.3835
2024-07-14 07:59:10,172 [INFO    ] __main__: train step 24705: loss: 0.9214, policy_loss: 0.8540, value_loss: 0.3835
2024-07-14 07:59:10,456 [INFO    ] __main__: train step 24706: loss: 0.9214, policy_loss: 0.8540, value_loss: 0.3834
2024-07-14 07:59:10,756 [INFO    ] __main__: train step 24707: loss: 0.9214, policy_loss: 0.8540, value_loss: 0.3834
2024-07-14 07:59:11,053 [INFO    ] __main__: train step 24708: loss: 0.9214, policy_loss: 0.8540, value_loss: 0.3834
2024-07-14 07:59:11,377 [INFO    ] __main__: train step 24709: loss: 0.9214, policy_loss: 0.8540, value_loss: 0.3834
2024-07-14 07:59:11,667 [INFO    ] __main__: train step 24710: loss: 0.9214, policy_loss: 0.8540, value_loss: 0.3834
2024-07-14 07:59:11,963 [INFO    ] __main__: train step 24711: loss: 0.9213, policy_loss: 0.8540, value_loss: 0.3834
2024-07-14 07:59:12,273 [INFO    ] __main__: train step 24712: loss: 0.9213, policy_loss: 0.8540, value_loss: 0.3834
2024-07-14 07:59:12,587 [INFO    ] __main__: train step 24713: loss: 0.9213, policy_loss: 0.8540, value_loss: 0.3834
2024-07-14 07:59:12,900 [INFO    ] __main__: train step 24714: loss: 0.9213, policy_loss: 0.8540, value_loss: 0.3834
2024-07-14 07:59:14,510 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:59:14,941 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:59:15,005 [INFO    ] __main__: train step 24715: loss: 0.9213, policy_loss: 0.8539, value_loss: 0.3833
2024-07-14 07:59:15,309 [INFO    ] __main__: train step 24716: loss: 0.9213, policy_loss: 0.8539, value_loss: 0.3833
2024-07-14 07:59:15,596 [INFO    ] __main__: train step 24717: loss: 0.9213, policy_loss: 0.8539, value_loss: 0.3833
2024-07-14 07:59:15,909 [INFO    ] __main__: train step 24718: loss: 0.9213, policy_loss: 0.8539, value_loss: 0.3833
2024-07-14 07:59:16,216 [INFO    ] __main__: train step 24719: loss: 0.9213, policy_loss: 0.8539, value_loss: 0.3833
2024-07-14 07:59:16,475 [INFO    ] __main__: train step 24720: loss: 0.9213, policy_loss: 0.8539, value_loss: 0.3833
2024-07-14 07:59:16,758 [INFO    ] __main__: train step 24721: loss: 0.9213, policy_loss: 0.8539, value_loss: 0.3833
2024-07-14 07:59:17,045 [INFO    ] __main__: train step 24722: loss: 0.9213, policy_loss: 0.8539, value_loss: 0.3833
2024-07-14 07:59:17,347 [INFO    ] __main__: train step 24723: loss: 0.9213, policy_loss: 0.8539, value_loss: 0.3832
2024-07-14 07:59:17,648 [INFO    ] __main__: train step 24724: loss: 0.9213, policy_loss: 0.8539, value_loss: 0.3832
2024-07-14 07:59:17,941 [INFO    ] __main__: train step 24725: loss: 0.9212, policy_loss: 0.8539, value_loss: 0.3832
2024-07-14 07:59:18,222 [INFO    ] __main__: train step 24726: loss: 0.9212, policy_loss: 0.8538, value_loss: 0.3832
2024-07-14 07:59:18,526 [INFO    ] __main__: train step 24727: loss: 0.9212, policy_loss: 0.8538, value_loss: 0.3832
2024-07-14 07:59:18,826 [INFO    ] __main__: train step 24728: loss: 0.9212, policy_loss: 0.8538, value_loss: 0.3832
2024-07-14 07:59:19,145 [INFO    ] __main__: train step 24729: loss: 0.9212, policy_loss: 0.8538, value_loss: 0.3832
2024-07-14 07:59:19,420 [INFO    ] __main__: train step 24730: loss: 0.9212, policy_loss: 0.8538, value_loss: 0.3832
2024-07-14 07:59:19,696 [INFO    ] __main__: train step 24731: loss: 0.9212, policy_loss: 0.8538, value_loss: 0.3832
2024-07-14 07:59:25,588 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:59:26,021 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:59:26,092 [INFO    ] __main__: train step 24732: loss: 0.9212, policy_loss: 0.8538, value_loss: 0.3831
2024-07-14 07:59:26,422 [INFO    ] __main__: train step 24733: loss: 0.9212, policy_loss: 0.8538, value_loss: 0.3831
2024-07-14 07:59:26,709 [INFO    ] __main__: train step 24734: loss: 0.9212, policy_loss: 0.8538, value_loss: 0.3831
2024-07-14 07:59:27,017 [INFO    ] __main__: train step 24735: loss: 0.9212, policy_loss: 0.8538, value_loss: 0.3831
2024-07-14 07:59:27,321 [INFO    ] __main__: train step 24736: loss: 0.9212, policy_loss: 0.8538, value_loss: 0.3831
2024-07-14 07:59:27,625 [INFO    ] __main__: train step 24737: loss: 0.9212, policy_loss: 0.8538, value_loss: 0.3831
2024-07-14 07:59:27,941 [INFO    ] __main__: train step 24738: loss: 0.9212, policy_loss: 0.8537, value_loss: 0.3831
2024-07-14 07:59:28,252 [INFO    ] __main__: train step 24739: loss: 0.9211, policy_loss: 0.8537, value_loss: 0.3831
2024-07-14 07:59:28,568 [INFO    ] __main__: train step 24740: loss: 0.9211, policy_loss: 0.8537, value_loss: 0.3831
2024-07-14 07:59:28,874 [INFO    ] __main__: train step 24741: loss: 0.9211, policy_loss: 0.8537, value_loss: 0.3830
2024-07-14 07:59:29,155 [INFO    ] __main__: train step 24742: loss: 0.9211, policy_loss: 0.8537, value_loss: 0.3830
2024-07-14 07:59:29,427 [INFO    ] __main__: train step 24743: loss: 0.9211, policy_loss: 0.8537, value_loss: 0.3830
2024-07-14 07:59:29,728 [INFO    ] __main__: train step 24744: loss: 0.9211, policy_loss: 0.8537, value_loss: 0.3830
2024-07-14 07:59:30,027 [INFO    ] __main__: train step 24745: loss: 0.9211, policy_loss: 0.8537, value_loss: 0.3830
2024-07-14 07:59:30,330 [INFO    ] __main__: train step 24746: loss: 0.9211, policy_loss: 0.8537, value_loss: 0.3830
2024-07-14 07:59:30,601 [INFO    ] __main__: train step 24747: loss: 0.9211, policy_loss: 0.8537, value_loss: 0.3830
2024-07-14 07:59:30,895 [INFO    ] __main__: train step 24748: loss: 0.9211, policy_loss: 0.8537, value_loss: 0.3830
2024-07-14 07:59:32,499 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:59:32,939 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:59:33,009 [INFO    ] __main__: train step 24749: loss: 0.9211, policy_loss: 0.8537, value_loss: 0.3830
2024-07-14 07:59:33,315 [INFO    ] __main__: train step 24750: loss: 0.9211, policy_loss: 0.8536, value_loss: 0.3829
2024-07-14 07:59:33,630 [INFO    ] __main__: train step 24751: loss: 0.9211, policy_loss: 0.8536, value_loss: 0.3829
2024-07-14 07:59:33,932 [INFO    ] __main__: train step 24752: loss: 0.9211, policy_loss: 0.8536, value_loss: 0.3829
2024-07-14 07:59:34,214 [INFO    ] __main__: train step 24753: loss: 0.9210, policy_loss: 0.8536, value_loss: 0.3829
2024-07-14 07:59:34,491 [INFO    ] __main__: train step 24754: loss: 0.9210, policy_loss: 0.8536, value_loss: 0.3829
2024-07-14 07:59:34,772 [INFO    ] __main__: train step 24755: loss: 0.9210, policy_loss: 0.8536, value_loss: 0.3829
2024-07-14 07:59:35,070 [INFO    ] __main__: train step 24756: loss: 0.9210, policy_loss: 0.8536, value_loss: 0.3829
2024-07-14 07:59:35,373 [INFO    ] __main__: train step 24757: loss: 0.9210, policy_loss: 0.8536, value_loss: 0.3829
2024-07-14 07:59:35,678 [INFO    ] __main__: train step 24758: loss: 0.9210, policy_loss: 0.8536, value_loss: 0.3828
2024-07-14 07:59:35,992 [INFO    ] __main__: train step 24759: loss: 0.9210, policy_loss: 0.8536, value_loss: 0.3828
2024-07-14 07:59:36,315 [INFO    ] __main__: train step 24760: loss: 0.9210, policy_loss: 0.8536, value_loss: 0.3828
2024-07-14 07:59:36,624 [INFO    ] __main__: train step 24761: loss: 0.9210, policy_loss: 0.8536, value_loss: 0.3828
2024-07-14 07:59:36,941 [INFO    ] __main__: train step 24762: loss: 0.9210, policy_loss: 0.8535, value_loss: 0.3828
2024-07-14 07:59:37,235 [INFO    ] __main__: train step 24763: loss: 0.9210, policy_loss: 0.8535, value_loss: 0.3828
2024-07-14 07:59:37,534 [INFO    ] __main__: train step 24764: loss: 0.9210, policy_loss: 0.8535, value_loss: 0.3828
2024-07-14 07:59:37,843 [INFO    ] __main__: train step 24765: loss: 0.9210, policy_loss: 0.8535, value_loss: 0.3828
2024-07-14 07:59:39,478 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:59:39,905 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:59:39,975 [INFO    ] __main__: train step 24766: loss: 0.9210, policy_loss: 0.8535, value_loss: 0.3828
2024-07-14 07:59:40,252 [INFO    ] __main__: train step 24767: loss: 0.9209, policy_loss: 0.8535, value_loss: 0.3827
2024-07-14 07:59:40,542 [INFO    ] __main__: train step 24768: loss: 0.9209, policy_loss: 0.8535, value_loss: 0.3827
2024-07-14 07:59:40,853 [INFO    ] __main__: train step 24769: loss: 0.9209, policy_loss: 0.8535, value_loss: 0.3827
2024-07-14 07:59:41,151 [INFO    ] __main__: train step 24770: loss: 0.9209, policy_loss: 0.8535, value_loss: 0.3827
2024-07-14 07:59:41,477 [INFO    ] __main__: train step 24771: loss: 0.9209, policy_loss: 0.8535, value_loss: 0.3827
2024-07-14 07:59:41,776 [INFO    ] __main__: train step 24772: loss: 0.9209, policy_loss: 0.8535, value_loss: 0.3827
2024-07-14 07:59:42,074 [INFO    ] __main__: train step 24773: loss: 0.9209, policy_loss: 0.8534, value_loss: 0.3827
2024-07-14 07:59:42,373 [INFO    ] __main__: train step 24774: loss: 0.9209, policy_loss: 0.8534, value_loss: 0.3827
2024-07-14 07:59:42,667 [INFO    ] __main__: train step 24775: loss: 0.9209, policy_loss: 0.8534, value_loss: 0.3827
2024-07-14 07:59:42,976 [INFO    ] __main__: train step 24776: loss: 0.9209, policy_loss: 0.8534, value_loss: 0.3826
2024-07-14 07:59:43,288 [INFO    ] __main__: train step 24777: loss: 0.9209, policy_loss: 0.8534, value_loss: 0.3826
2024-07-14 07:59:43,547 [INFO    ] __main__: train step 24778: loss: 0.9209, policy_loss: 0.8534, value_loss: 0.3826
2024-07-14 07:59:43,817 [INFO    ] __main__: train step 24779: loss: 0.9209, policy_loss: 0.8534, value_loss: 0.3826
2024-07-14 07:59:44,105 [INFO    ] __main__: train step 24780: loss: 0.9209, policy_loss: 0.8534, value_loss: 0.3826
2024-07-14 07:59:44,410 [INFO    ] __main__: train step 24781: loss: 0.9208, policy_loss: 0.8534, value_loss: 0.3826
2024-07-14 07:59:44,704 [INFO    ] __main__: train step 24782: loss: 0.9208, policy_loss: 0.8534, value_loss: 0.3826
2024-07-14 07:59:46,315 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:59:46,756 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:59:46,821 [INFO    ] __main__: train step 24783: loss: 0.9208, policy_loss: 0.8534, value_loss: 0.3826
2024-07-14 07:59:47,102 [INFO    ] __main__: train step 24784: loss: 0.9208, policy_loss: 0.8534, value_loss: 0.3826
2024-07-14 07:59:47,387 [INFO    ] __main__: train step 24785: loss: 0.9208, policy_loss: 0.8533, value_loss: 0.3825
2024-07-14 07:59:47,655 [INFO    ] __main__: train step 24786: loss: 0.9208, policy_loss: 0.8533, value_loss: 0.3825
2024-07-14 07:59:47,979 [INFO    ] __main__: train step 24787: loss: 0.9208, policy_loss: 0.8533, value_loss: 0.3825
2024-07-14 07:59:48,262 [INFO    ] __main__: train step 24788: loss: 0.9208, policy_loss: 0.8533, value_loss: 0.3825
2024-07-14 07:59:48,531 [INFO    ] __main__: train step 24789: loss: 0.9208, policy_loss: 0.8533, value_loss: 0.3825
2024-07-14 07:59:48,809 [INFO    ] __main__: train step 24790: loss: 0.9208, policy_loss: 0.8533, value_loss: 0.3825
2024-07-14 07:59:49,090 [INFO    ] __main__: train step 24791: loss: 0.9208, policy_loss: 0.8533, value_loss: 0.3825
2024-07-14 07:59:49,401 [INFO    ] __main__: train step 24792: loss: 0.9208, policy_loss: 0.8533, value_loss: 0.3825
2024-07-14 07:59:49,704 [INFO    ] __main__: train step 24793: loss: 0.9208, policy_loss: 0.8533, value_loss: 0.3825
2024-07-14 07:59:49,998 [INFO    ] __main__: train step 24794: loss: 0.9208, policy_loss: 0.8533, value_loss: 0.3824
2024-07-14 07:59:50,315 [INFO    ] __main__: train step 24795: loss: 0.9207, policy_loss: 0.8533, value_loss: 0.3824
2024-07-14 07:59:50,618 [INFO    ] __main__: train step 24796: loss: 0.9207, policy_loss: 0.8533, value_loss: 0.3824
2024-07-14 07:59:50,926 [INFO    ] __main__: train step 24797: loss: 0.9207, policy_loss: 0.8532, value_loss: 0.3824
2024-07-14 07:59:51,221 [INFO    ] __main__: train step 24798: loss: 0.9207, policy_loss: 0.8532, value_loss: 0.3824
2024-07-14 07:59:51,489 [INFO    ] __main__: train step 24799: loss: 0.9207, policy_loss: 0.8532, value_loss: 0.3824
2024-07-14 07:59:53,107 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 07:59:53,543 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 07:59:53,613 [INFO    ] __main__: train step 24800: loss: 0.9207, policy_loss: 0.8532, value_loss: 0.3824
2024-07-14 07:59:53,923 [INFO    ] __main__: train step 24801: loss: 0.9207, policy_loss: 0.8532, value_loss: 0.3824
2024-07-14 07:59:54,226 [INFO    ] __main__: train step 24802: loss: 0.9207, policy_loss: 0.8532, value_loss: 0.3823
2024-07-14 07:59:54,528 [INFO    ] __main__: train step 24803: loss: 0.9207, policy_loss: 0.8532, value_loss: 0.3823
2024-07-14 07:59:54,828 [INFO    ] __main__: train step 24804: loss: 0.9207, policy_loss: 0.8532, value_loss: 0.3823
2024-07-14 07:59:55,138 [INFO    ] __main__: train step 24805: loss: 0.9207, policy_loss: 0.8532, value_loss: 0.3823
2024-07-14 07:59:55,458 [INFO    ] __main__: train step 24806: loss: 0.9207, policy_loss: 0.8532, value_loss: 0.3823
2024-07-14 07:59:55,760 [INFO    ] __main__: train step 24807: loss: 0.9207, policy_loss: 0.8532, value_loss: 0.3823
2024-07-14 07:59:56,038 [INFO    ] __main__: train step 24808: loss: 0.9206, policy_loss: 0.8531, value_loss: 0.3823
2024-07-14 07:59:56,329 [INFO    ] __main__: train step 24809: loss: 0.9206, policy_loss: 0.8531, value_loss: 0.3823
2024-07-14 07:59:56,627 [INFO    ] __main__: train step 24810: loss: 0.9206, policy_loss: 0.8531, value_loss: 0.3823
2024-07-14 07:59:56,933 [INFO    ] __main__: train step 24811: loss: 0.9206, policy_loss: 0.8531, value_loss: 0.3822
2024-07-14 07:59:57,228 [INFO    ] __main__: train step 24812: loss: 0.9206, policy_loss: 0.8531, value_loss: 0.3822
2024-07-14 07:59:57,517 [INFO    ] __main__: train step 24813: loss: 0.9206, policy_loss: 0.8531, value_loss: 0.3822
2024-07-14 07:59:57,828 [INFO    ] __main__: train step 24814: loss: 0.9206, policy_loss: 0.8531, value_loss: 0.3822
2024-07-14 07:59:58,136 [INFO    ] __main__: train step 24815: loss: 0.9206, policy_loss: 0.8531, value_loss: 0.3822
2024-07-14 07:59:58,439 [INFO    ] __main__: train step 24816: loss: 0.9206, policy_loss: 0.8531, value_loss: 0.3822
2024-07-14 08:00:00,079 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 08:00:00,500 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 08:00:00,569 [INFO    ] __main__: train step 24817: loss: 0.9206, policy_loss: 0.8531, value_loss: 0.3822
2024-07-14 08:00:00,833 [INFO    ] __main__: train step 24818: loss: 0.9206, policy_loss: 0.8531, value_loss: 0.3822
2024-07-14 08:00:01,132 [INFO    ] __main__: train step 24819: loss: 0.9206, policy_loss: 0.8531, value_loss: 0.3822
2024-07-14 08:00:01,436 [INFO    ] __main__: train step 24820: loss: 0.9206, policy_loss: 0.8530, value_loss: 0.3821
2024-07-14 08:00:01,737 [INFO    ] __main__: train step 24821: loss: 0.9205, policy_loss: 0.8530, value_loss: 0.3821
2024-07-14 08:00:02,037 [INFO    ] __main__: train step 24822: loss: 0.9205, policy_loss: 0.8530, value_loss: 0.3821
2024-07-14 08:00:02,351 [INFO    ] __main__: train step 24823: loss: 0.9205, policy_loss: 0.8530, value_loss: 0.3821
2024-07-14 08:00:02,642 [INFO    ] __main__: train step 24824: loss: 0.9205, policy_loss: 0.8530, value_loss: 0.3821
2024-07-14 08:00:02,942 [INFO    ] __main__: train step 24825: loss: 0.9205, policy_loss: 0.8530, value_loss: 0.3821
2024-07-14 08:00:03,254 [INFO    ] __main__: train step 24826: loss: 0.9205, policy_loss: 0.8530, value_loss: 0.3821
2024-07-14 08:00:03,570 [INFO    ] __main__: train step 24827: loss: 0.9205, policy_loss: 0.8530, value_loss: 0.3821
2024-07-14 08:00:03,871 [INFO    ] __main__: train step 24828: loss: 0.9205, policy_loss: 0.8530, value_loss: 0.3820
2024-07-14 08:00:04,165 [INFO    ] __main__: train step 24829: loss: 0.9205, policy_loss: 0.8530, value_loss: 0.3820
2024-07-14 08:00:04,476 [INFO    ] __main__: train step 24830: loss: 0.9205, policy_loss: 0.8530, value_loss: 0.3820
2024-07-14 08:00:04,786 [INFO    ] __main__: train step 24831: loss: 0.9205, policy_loss: 0.8529, value_loss: 0.3820
2024-07-14 08:00:05,114 [INFO    ] __main__: train step 24832: loss: 0.9205, policy_loss: 0.8529, value_loss: 0.3820
2024-07-14 08:00:05,393 [INFO    ] __main__: train step 24833: loss: 0.9205, policy_loss: 0.8529, value_loss: 0.3820
2024-07-14 08:00:06,961 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 08:00:07,378 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 08:00:07,447 [INFO    ] __main__: train step 24834: loss: 0.9204, policy_loss: 0.8529, value_loss: 0.3820
2024-07-14 08:00:07,751 [INFO    ] __main__: train step 24835: loss: 0.9204, policy_loss: 0.8529, value_loss: 0.3820
2024-07-14 08:00:08,046 [INFO    ] __main__: train step 24836: loss: 0.9204, policy_loss: 0.8529, value_loss: 0.3820
2024-07-14 08:00:08,357 [INFO    ] __main__: train step 24837: loss: 0.9204, policy_loss: 0.8529, value_loss: 0.3819
2024-07-14 08:00:08,639 [INFO    ] __main__: train step 24838: loss: 0.9204, policy_loss: 0.8529, value_loss: 0.3819
2024-07-14 08:00:08,913 [INFO    ] __main__: train step 24839: loss: 0.9204, policy_loss: 0.8529, value_loss: 0.3819
2024-07-14 08:00:09,209 [INFO    ] __main__: train step 24840: loss: 0.9204, policy_loss: 0.8529, value_loss: 0.3819
2024-07-14 08:00:09,518 [INFO    ] __main__: train step 24841: loss: 0.9204, policy_loss: 0.8529, value_loss: 0.3819
2024-07-14 08:00:09,842 [INFO    ] __main__: train step 24842: loss: 0.9204, policy_loss: 0.8529, value_loss: 0.3819
2024-07-14 08:00:10,110 [INFO    ] __main__: train step 24843: loss: 0.9204, policy_loss: 0.8528, value_loss: 0.3819
2024-07-14 08:00:10,385 [INFO    ] __main__: train step 24844: loss: 0.9204, policy_loss: 0.8528, value_loss: 0.3819
2024-07-14 08:00:10,647 [INFO    ] __main__: train step 24845: loss: 0.9204, policy_loss: 0.8528, value_loss: 0.3819
2024-07-14 08:00:10,968 [INFO    ] __main__: train step 24846: loss: 0.9204, policy_loss: 0.8528, value_loss: 0.3818
2024-07-14 08:00:11,272 [INFO    ] __main__: train step 24847: loss: 0.9204, policy_loss: 0.8528, value_loss: 0.3818
2024-07-14 08:00:11,582 [INFO    ] __main__: train step 24848: loss: 0.9203, policy_loss: 0.8528, value_loss: 0.3818
2024-07-14 08:00:11,857 [INFO    ] __main__: train step 24849: loss: 0.9203, policy_loss: 0.8528, value_loss: 0.3818
2024-07-14 08:00:12,147 [INFO    ] __main__: train step 24850: loss: 0.9203, policy_loss: 0.8528, value_loss: 0.3818
2024-07-14 08:00:13,776 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 08:00:14,187 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 08:00:14,255 [INFO    ] __main__: train step 24851: loss: 0.9203, policy_loss: 0.8528, value_loss: 0.3818
2024-07-14 08:00:14,539 [INFO    ] __main__: train step 24852: loss: 0.9203, policy_loss: 0.8528, value_loss: 0.3818
2024-07-14 08:00:14,841 [INFO    ] __main__: train step 24853: loss: 0.9203, policy_loss: 0.8528, value_loss: 0.3818
2024-07-14 08:00:15,148 [INFO    ] __main__: train step 24854: loss: 0.9203, policy_loss: 0.8527, value_loss: 0.3818
2024-07-14 08:00:15,453 [INFO    ] __main__: train step 24855: loss: 0.9203, policy_loss: 0.8527, value_loss: 0.3817
2024-07-14 08:00:15,749 [INFO    ] __main__: train step 24856: loss: 0.9203, policy_loss: 0.8527, value_loss: 0.3817
2024-07-14 08:00:16,057 [INFO    ] __main__: train step 24857: loss: 0.9203, policy_loss: 0.8527, value_loss: 0.3817
2024-07-14 08:00:16,373 [INFO    ] __main__: train step 24858: loss: 0.9203, policy_loss: 0.8527, value_loss: 0.3817
2024-07-14 08:00:21,006 [INFO    ] __main__: train step 24859: loss: 0.9203, policy_loss: 0.8527, value_loss: 0.3817
2024-07-14 08:00:21,300 [INFO    ] __main__: train step 24860: loss: 0.9203, policy_loss: 0.8527, value_loss: 0.3817
2024-07-14 08:00:21,579 [INFO    ] __main__: train step 24861: loss: 0.9203, policy_loss: 0.8527, value_loss: 0.3817
2024-07-14 08:00:21,864 [INFO    ] __main__: train step 24862: loss: 0.9202, policy_loss: 0.8527, value_loss: 0.3817
2024-07-14 08:00:22,140 [INFO    ] __main__: train step 24863: loss: 0.9202, policy_loss: 0.8527, value_loss: 0.3816
2024-07-14 08:00:22,438 [INFO    ] __main__: train step 24864: loss: 0.9202, policy_loss: 0.8527, value_loss: 0.3816
2024-07-14 08:00:22,758 [INFO    ] __main__: train step 24865: loss: 0.9202, policy_loss: 0.8527, value_loss: 0.3816
2024-07-14 08:00:23,057 [INFO    ] __main__: train step 24866: loss: 0.9202, policy_loss: 0.8526, value_loss: 0.3816
2024-07-14 08:00:23,364 [INFO    ] __main__: train step 24867: loss: 0.9202, policy_loss: 0.8526, value_loss: 0.3816
2024-07-14 08:00:24,985 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 08:00:25,417 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 08:00:25,484 [INFO    ] __main__: train step 24868: loss: 0.9202, policy_loss: 0.8526, value_loss: 0.3816
2024-07-14 08:00:25,775 [INFO    ] __main__: train step 24869: loss: 0.9202, policy_loss: 0.8526, value_loss: 0.3816
2024-07-14 08:00:26,087 [INFO    ] __main__: train step 24870: loss: 0.9202, policy_loss: 0.8526, value_loss: 0.3816
2024-07-14 08:00:26,391 [INFO    ] __main__: train step 24871: loss: 0.9202, policy_loss: 0.8526, value_loss: 0.3816
2024-07-14 08:00:26,685 [INFO    ] __main__: train step 24872: loss: 0.9202, policy_loss: 0.8526, value_loss: 0.3815
2024-07-14 08:00:26,991 [INFO    ] __main__: train step 24873: loss: 0.9202, policy_loss: 0.8526, value_loss: 0.3815
2024-07-14 08:00:27,291 [INFO    ] __main__: train step 24874: loss: 0.9202, policy_loss: 0.8526, value_loss: 0.3815
2024-07-14 08:00:27,600 [INFO    ] __main__: train step 24875: loss: 0.9201, policy_loss: 0.8526, value_loss: 0.3815
2024-07-14 08:00:27,888 [INFO    ] __main__: train step 24876: loss: 0.9201, policy_loss: 0.8526, value_loss: 0.3815
2024-07-14 08:00:28,164 [INFO    ] __main__: train step 24877: loss: 0.9201, policy_loss: 0.8526, value_loss: 0.3815
2024-07-14 08:00:28,461 [INFO    ] __main__: train step 24878: loss: 0.9201, policy_loss: 0.8525, value_loss: 0.3815
2024-07-14 08:00:28,782 [INFO    ] __main__: train step 24879: loss: 0.9201, policy_loss: 0.8525, value_loss: 0.3815
2024-07-14 08:00:29,109 [INFO    ] __main__: train step 24880: loss: 0.9201, policy_loss: 0.8525, value_loss: 0.3815
2024-07-14 08:00:29,411 [INFO    ] __main__: train step 24881: loss: 0.9201, policy_loss: 0.8525, value_loss: 0.3814
2024-07-14 08:00:29,706 [INFO    ] __main__: train step 24882: loss: 0.9201, policy_loss: 0.8525, value_loss: 0.3814
2024-07-14 08:00:30,015 [INFO    ] __main__: train step 24883: loss: 0.9201, policy_loss: 0.8525, value_loss: 0.3814
2024-07-14 08:00:30,327 [INFO    ] __main__: train step 24884: loss: 0.9201, policy_loss: 0.8525, value_loss: 0.3814
2024-07-14 08:00:31,961 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 08:00:32,398 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 08:00:32,472 [INFO    ] __main__: train step 24885: loss: 0.9201, policy_loss: 0.8525, value_loss: 0.3814
2024-07-14 08:00:32,780 [INFO    ] __main__: train step 24886: loss: 0.9201, policy_loss: 0.8525, value_loss: 0.3814
2024-07-14 08:00:33,080 [INFO    ] __main__: train step 24887: loss: 0.9201, policy_loss: 0.8525, value_loss: 0.3814
2024-07-14 08:00:33,381 [INFO    ] __main__: train step 24888: loss: 0.9200, policy_loss: 0.8525, value_loss: 0.3814
2024-07-14 08:00:33,672 [INFO    ] __main__: train step 24889: loss: 0.9200, policy_loss: 0.8524, value_loss: 0.3813
2024-07-14 08:00:33,950 [INFO    ] __main__: train step 24890: loss: 0.9200, policy_loss: 0.8524, value_loss: 0.3813
2024-07-14 08:00:34,256 [INFO    ] __main__: train step 24891: loss: 0.9200, policy_loss: 0.8524, value_loss: 0.3813
2024-07-14 08:00:34,563 [INFO    ] __main__: train step 24892: loss: 0.9200, policy_loss: 0.8524, value_loss: 0.3813
2024-07-14 08:00:34,868 [INFO    ] __main__: train step 24893: loss: 0.9200, policy_loss: 0.8524, value_loss: 0.3813
2024-07-14 08:00:35,168 [INFO    ] __main__: train step 24894: loss: 0.9200, policy_loss: 0.8524, value_loss: 0.3813
2024-07-14 08:00:35,465 [INFO    ] __main__: train step 24895: loss: 0.9200, policy_loss: 0.8524, value_loss: 0.3813
2024-07-14 08:00:35,742 [INFO    ] __main__: train step 24896: loss: 0.9200, policy_loss: 0.8524, value_loss: 0.3813
2024-07-14 08:00:36,036 [INFO    ] __main__: train step 24897: loss: 0.9200, policy_loss: 0.8524, value_loss: 0.3813
2024-07-14 08:00:36,355 [INFO    ] __main__: train step 24898: loss: 0.9200, policy_loss: 0.8524, value_loss: 0.3812
2024-07-14 08:00:36,646 [INFO    ] __main__: train step 24899: loss: 0.9200, policy_loss: 0.8524, value_loss: 0.3812
2024-07-14 08:00:36,939 [INFO    ] __main__: train step 24900: loss: 0.9200, policy_loss: 0.8524, value_loss: 0.3812
2024-07-14 08:00:37,240 [INFO    ] __main__: train step 24901: loss: 0.9199, policy_loss: 0.8523, value_loss: 0.3812
2024-07-14 08:00:38,868 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 08:00:39,290 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 08:00:39,358 [INFO    ] __main__: train step 24902: loss: 0.9199, policy_loss: 0.8523, value_loss: 0.3812
2024-07-14 08:00:39,662 [INFO    ] __main__: train step 24903: loss: 0.9199, policy_loss: 0.8523, value_loss: 0.3812
2024-07-14 08:00:39,958 [INFO    ] __main__: train step 24904: loss: 0.9199, policy_loss: 0.8523, value_loss: 0.3812
2024-07-14 08:00:40,259 [INFO    ] __main__: train step 24905: loss: 0.9199, policy_loss: 0.8523, value_loss: 0.3812
2024-07-14 08:00:40,555 [INFO    ] __main__: train step 24906: loss: 0.9199, policy_loss: 0.8523, value_loss: 0.3811
2024-07-14 08:00:40,826 [INFO    ] __main__: train step 24907: loss: 0.9199, policy_loss: 0.8523, value_loss: 0.3811
2024-07-14 08:00:41,131 [INFO    ] __main__: train step 24908: loss: 0.9199, policy_loss: 0.8523, value_loss: 0.3811
2024-07-14 08:00:41,439 [INFO    ] __main__: train step 24909: loss: 0.9199, policy_loss: 0.8523, value_loss: 0.3811
2024-07-14 08:00:41,762 [INFO    ] __main__: train step 24910: loss: 0.9199, policy_loss: 0.8523, value_loss: 0.3811
2024-07-14 08:00:42,062 [INFO    ] __main__: train step 24911: loss: 0.9199, policy_loss: 0.8523, value_loss: 0.3811
2024-07-14 08:00:42,361 [INFO    ] __main__: train step 24912: loss: 0.9199, policy_loss: 0.8522, value_loss: 0.3811
2024-07-14 08:00:42,664 [INFO    ] __main__: train step 24913: loss: 0.9199, policy_loss: 0.8522, value_loss: 0.3811
2024-07-14 08:00:42,973 [INFO    ] __main__: train step 24914: loss: 0.9198, policy_loss: 0.8522, value_loss: 0.3811
2024-07-14 08:00:43,268 [INFO    ] __main__: train step 24915: loss: 0.9198, policy_loss: 0.8522, value_loss: 0.3810
2024-07-14 08:00:43,551 [INFO    ] __main__: train step 24916: loss: 0.9198, policy_loss: 0.8522, value_loss: 0.3810
2024-07-14 08:00:43,818 [INFO    ] __main__: train step 24917: loss: 0.9198, policy_loss: 0.8522, value_loss: 0.3810
2024-07-14 08:00:44,127 [INFO    ] __main__: train step 24918: loss: 0.9198, policy_loss: 0.8522, value_loss: 0.3810
2024-07-14 08:00:45,767 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 08:00:46,200 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 08:00:46,267 [INFO    ] __main__: train step 24919: loss: 0.9198, policy_loss: 0.8522, value_loss: 0.3810
2024-07-14 08:00:46,577 [INFO    ] __main__: train step 24920: loss: 0.9198, policy_loss: 0.8522, value_loss: 0.3810
2024-07-14 08:00:46,862 [INFO    ] __main__: train step 24921: loss: 0.9198, policy_loss: 0.8522, value_loss: 0.3810
2024-07-14 08:00:47,150 [INFO    ] __main__: train step 24922: loss: 0.9198, policy_loss: 0.8522, value_loss: 0.3810
2024-07-14 08:00:47,450 [INFO    ] __main__: train step 24923: loss: 0.9198, policy_loss: 0.8522, value_loss: 0.3810
2024-07-14 08:00:47,756 [INFO    ] __main__: train step 24924: loss: 0.9198, policy_loss: 0.8521, value_loss: 0.3809
2024-07-14 08:00:48,084 [INFO    ] __main__: train step 24925: loss: 0.9198, policy_loss: 0.8521, value_loss: 0.3809
2024-07-14 08:00:48,378 [INFO    ] __main__: train step 24926: loss: 0.9198, policy_loss: 0.8521, value_loss: 0.3809
2024-07-14 08:00:48,659 [INFO    ] __main__: train step 24927: loss: 0.9197, policy_loss: 0.8521, value_loss: 0.3809
2024-07-14 08:00:48,960 [INFO    ] __main__: train step 24928: loss: 0.9197, policy_loss: 0.8521, value_loss: 0.3809
2024-07-14 08:00:49,260 [INFO    ] __main__: train step 24929: loss: 0.9197, policy_loss: 0.8521, value_loss: 0.3809
2024-07-14 08:00:49,564 [INFO    ] __main__: train step 24930: loss: 0.9197, policy_loss: 0.8521, value_loss: 0.3809
2024-07-14 08:00:49,858 [INFO    ] __main__: train step 24931: loss: 0.9197, policy_loss: 0.8521, value_loss: 0.3809
2024-07-14 08:00:50,145 [INFO    ] __main__: train step 24932: loss: 0.9197, policy_loss: 0.8521, value_loss: 0.3808
2024-07-14 08:00:50,422 [INFO    ] __main__: train step 24933: loss: 0.9197, policy_loss: 0.8521, value_loss: 0.3808
2024-07-14 08:00:50,695 [INFO    ] __main__: train step 24934: loss: 0.9197, policy_loss: 0.8521, value_loss: 0.3808
2024-07-14 08:00:50,983 [INFO    ] __main__: train step 24935: loss: 0.9197, policy_loss: 0.8520, value_loss: 0.3808
2024-07-14 08:00:52,619 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 08:00:53,045 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 08:00:53,108 [INFO    ] __main__: train step 24936: loss: 0.9197, policy_loss: 0.8520, value_loss: 0.3808
2024-07-14 08:00:53,381 [INFO    ] __main__: train step 24937: loss: 0.9197, policy_loss: 0.8520, value_loss: 0.3808
2024-07-14 08:00:53,665 [INFO    ] __main__: train step 24938: loss: 0.9197, policy_loss: 0.8520, value_loss: 0.3808
2024-07-14 08:00:53,960 [INFO    ] __main__: train step 24939: loss: 0.9197, policy_loss: 0.8520, value_loss: 0.3808
2024-07-14 08:00:54,259 [INFO    ] __main__: train step 24940: loss: 0.9197, policy_loss: 0.8520, value_loss: 0.3808
2024-07-14 08:00:54,539 [INFO    ] __main__: train step 24941: loss: 0.9196, policy_loss: 0.8520, value_loss: 0.3807
2024-07-14 08:00:54,804 [INFO    ] __main__: train step 24942: loss: 0.9196, policy_loss: 0.8520, value_loss: 0.3807
2024-07-14 08:00:55,128 [INFO    ] __main__: train step 24943: loss: 0.9196, policy_loss: 0.8520, value_loss: 0.3807
2024-07-14 08:00:55,443 [INFO    ] __main__: train step 24944: loss: 0.9196, policy_loss: 0.8520, value_loss: 0.3807
2024-07-14 08:00:55,745 [INFO    ] __main__: train step 24945: loss: 0.9196, policy_loss: 0.8520, value_loss: 0.3807
2024-07-14 08:00:56,054 [INFO    ] __main__: train step 24946: loss: 0.9196, policy_loss: 0.8520, value_loss: 0.3807
2024-07-14 08:00:56,360 [INFO    ] __main__: train step 24947: loss: 0.9196, policy_loss: 0.8519, value_loss: 0.3807
2024-07-14 08:00:56,646 [INFO    ] __main__: train step 24948: loss: 0.9196, policy_loss: 0.8519, value_loss: 0.3807
2024-07-14 08:00:56,946 [INFO    ] __main__: train step 24949: loss: 0.9196, policy_loss: 0.8519, value_loss: 0.3807
2024-07-14 08:00:57,239 [INFO    ] __main__: train step 24950: loss: 0.9196, policy_loss: 0.8519, value_loss: 0.3806
2024-07-14 08:00:57,531 [INFO    ] __main__: train step 24951: loss: 0.9196, policy_loss: 0.8519, value_loss: 0.3806
2024-07-14 08:00:57,796 [INFO    ] __main__: train step 24952: loss: 0.9196, policy_loss: 0.8519, value_loss: 0.3806
2024-07-14 08:00:59,358 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 08:00:59,731 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 08:00:59,797 [INFO    ] __main__: train step 24953: loss: 0.9196, policy_loss: 0.8519, value_loss: 0.3806
2024-07-14 08:01:00,100 [INFO    ] __main__: train step 24954: loss: 0.9195, policy_loss: 0.8519, value_loss: 0.3806
2024-07-14 08:01:00,401 [INFO    ] __main__: train step 24955: loss: 0.9195, policy_loss: 0.8519, value_loss: 0.3806
2024-07-14 08:01:00,698 [INFO    ] __main__: train step 24956: loss: 0.9195, policy_loss: 0.8519, value_loss: 0.3806
2024-07-14 08:01:00,987 [INFO    ] __main__: train step 24957: loss: 0.9195, policy_loss: 0.8519, value_loss: 0.3806
2024-07-14 08:01:01,292 [INFO    ] __main__: train step 24958: loss: 0.9195, policy_loss: 0.8519, value_loss: 0.3805
2024-07-14 08:01:01,591 [INFO    ] __main__: train step 24959: loss: 0.9195, policy_loss: 0.8518, value_loss: 0.3805
2024-07-14 08:01:01,893 [INFO    ] __main__: train step 24960: loss: 0.9195, policy_loss: 0.8518, value_loss: 0.3805
2024-07-14 08:01:02,193 [INFO    ] __main__: train step 24961: loss: 0.9195, policy_loss: 0.8518, value_loss: 0.3805
2024-07-14 08:01:02,505 [INFO    ] __main__: train step 24962: loss: 0.9195, policy_loss: 0.8518, value_loss: 0.3805
2024-07-14 08:01:02,784 [INFO    ] __main__: train step 24963: loss: 0.9195, policy_loss: 0.8518, value_loss: 0.3805
2024-07-14 08:01:03,085 [INFO    ] __main__: train step 24964: loss: 0.9195, policy_loss: 0.8518, value_loss: 0.3805
2024-07-14 08:01:03,401 [INFO    ] __main__: train step 24965: loss: 0.9195, policy_loss: 0.8518, value_loss: 0.3805
2024-07-14 08:01:03,704 [INFO    ] __main__: train step 24966: loss: 0.9195, policy_loss: 0.8518, value_loss: 0.3805
2024-07-14 08:01:04,013 [INFO    ] __main__: train step 24967: loss: 0.9194, policy_loss: 0.8518, value_loss: 0.3804
2024-07-14 08:01:04,317 [INFO    ] __main__: train step 24968: loss: 0.9194, policy_loss: 0.8518, value_loss: 0.3804
2024-07-14 08:01:04,605 [INFO    ] __main__: train step 24969: loss: 0.9194, policy_loss: 0.8518, value_loss: 0.3804
2024-07-14 08:01:06,229 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 08:01:06,674 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 08:01:06,739 [INFO    ] __main__: train step 24970: loss: 0.9194, policy_loss: 0.8518, value_loss: 0.3804
2024-07-14 08:01:07,040 [INFO    ] __main__: train step 24971: loss: 0.9194, policy_loss: 0.8517, value_loss: 0.3804
2024-07-14 08:01:07,361 [INFO    ] __main__: train step 24972: loss: 0.9194, policy_loss: 0.8517, value_loss: 0.3804
2024-07-14 08:01:07,660 [INFO    ] __main__: train step 24973: loss: 0.9194, policy_loss: 0.8517, value_loss: 0.3804
2024-07-14 08:01:07,963 [INFO    ] __main__: train step 24974: loss: 0.9194, policy_loss: 0.8517, value_loss: 0.3804
2024-07-14 08:01:08,274 [INFO    ] __main__: train step 24975: loss: 0.9194, policy_loss: 0.8517, value_loss: 0.3804
2024-07-14 08:01:08,571 [INFO    ] __main__: train step 24976: loss: 0.9194, policy_loss: 0.8517, value_loss: 0.3803
2024-07-14 08:01:08,894 [INFO    ] __main__: train step 24977: loss: 0.9194, policy_loss: 0.8517, value_loss: 0.3803
2024-07-14 08:01:09,190 [INFO    ] __main__: train step 24978: loss: 0.9194, policy_loss: 0.8517, value_loss: 0.3803
2024-07-14 08:01:09,485 [INFO    ] __main__: train step 24979: loss: 0.9194, policy_loss: 0.8517, value_loss: 0.3803
2024-07-14 08:01:09,783 [INFO    ] __main__: train step 24980: loss: 0.9193, policy_loss: 0.8517, value_loss: 0.3803
2024-07-14 08:01:10,099 [INFO    ] __main__: train step 24981: loss: 0.9193, policy_loss: 0.8517, value_loss: 0.3803
2024-07-14 08:01:10,400 [INFO    ] __main__: train step 24982: loss: 0.9193, policy_loss: 0.8516, value_loss: 0.3803
2024-07-14 08:01:10,707 [INFO    ] __main__: train step 24983: loss: 0.9193, policy_loss: 0.8516, value_loss: 0.3803
2024-07-14 08:01:11,008 [INFO    ] __main__: train step 24984: loss: 0.9193, policy_loss: 0.8516, value_loss: 0.3802
2024-07-14 08:01:11,314 [INFO    ] __main__: train step 24985: loss: 0.9193, policy_loss: 0.8516, value_loss: 0.3802
2024-07-14 08:01:11,623 [INFO    ] __main__: train step 24986: loss: 0.9193, policy_loss: 0.8516, value_loss: 0.3802
2024-07-14 08:01:17,689 [INFO    ] __main__: replay_buffer size = 62500
2024-07-14 08:01:18,129 [INFO    ] __main__: saved replay_buffer to storage
2024-07-14 08:01:18,200 [INFO    ] __main__: train step 24987: loss: 0.9193, policy_loss: 0.8516, value_loss: 0.3802
2024-07-14 08:01:18,502 [INFO    ] __main__: train step 24988: loss: 0.9193, policy_loss: 0.8516, value_loss: 0.3802
2024-07-14 08:01:18,811 [INFO    ] __main__: train step 24989: loss: 0.9193, policy_loss: 0.8516, value_loss: 0.3802
2024-07-14 08:01:19,141 [INFO    ] __main__: train step 24990: loss: 0.9193, policy_loss: 0.8516, value_loss: 0.3802
2024-07-14 08:01:19,460 [INFO    ] __main__: train step 24991: loss: 0.9193, policy_loss: 0.8516, value_loss: 0.3802
2024-07-14 08:01:19,772 [INFO    ] __main__: train step 24992: loss: 0.9192, policy_loss: 0.8516, value_loss: 0.3802
2024-07-14 08:01:20,046 [INFO    ] __main__: train step 24993: loss: 0.9192, policy_loss: 0.8515, value_loss: 0.3801
2024-07-14 08:01:20,352 [INFO    ] __main__: train step 24994: loss: 0.9192, policy_loss: 0.8515, value_loss: 0.3801
2024-07-14 08:01:20,661 [INFO    ] __main__: train step 24995: loss: 0.9192, policy_loss: 0.8515, value_loss: 0.3801
2024-07-14 08:01:20,964 [INFO    ] __main__: train step 24996: loss: 0.9192, policy_loss: 0.8515, value_loss: 0.3801
2024-07-14 08:01:21,274 [INFO    ] __main__: train step 24997: loss: 0.9192, policy_loss: 0.8515, value_loss: 0.3801
2024-07-14 08:01:21,551 [INFO    ] __main__: train step 24998: loss: 0.9192, policy_loss: 0.8515, value_loss: 0.3801
2024-07-14 08:01:21,871 [INFO    ] __main__: train step 24999: loss: 0.9192, policy_loss: 0.8515, value_loss: 0.3801
2024-07-14 08:01:22,176 [INFO    ] __main__: train step 25000: loss: 0.9192, policy_loss: 0.8515, value_loss: 0.3801
2024-07-14 08:01:22,341 [INFO    ] __main__: restored step 24000 for evaluation
2024-07-14 08:01:27,595 [INFO    ] __main__: test network ELO difference from baseline network: +20 (+8/-8) ELO from 32000 self-played games
2024-07-14 08:01:27,597 [INFO    ] __main__: game outcomes: W: 16661, D: 144, L: 15195
2024-07-14 08:01:27,601 [INFO    ] __main__: validation_elo_delta: 20, validation_elo: 3002
2024-07-14 08:01:28,075 [INFO    ] __main__: running self-play game for SVG generation
2024-07-14 08:05:55,898 [INFO    ] __main__: saved self-play game in animations/run2_armageddon/25000.svg
2024-07-14 08:05:56,176 [INFO    ] __main__: train step 25001: loss: 0.9192, policy_loss: 0.8515, value_loss: 0.3801
2024-07-14 08:05:56,475 [INFO    ] __main__: train step 25002: loss: 0.9192, policy_loss: 0.8515, value_loss: 0.3800
2024-07-14 08:05:56,762 [INFO    ] __main__: train step 25003: loss: 0.9192, policy_loss: 0.8515, value_loss: 0.3800
2024-07-14 08:05:56,968 [INFO    ] __main__: training has completed!
2024-07-14 08:08:44,345 [INFO    ] __main__: jax.local_devices(): [cuda(id=0)]
2024-07-14 08:08:44,345 [INFO    ] __main__: selecting devices: [cuda(id=0)]
2024-07-14 08:08:44,345 [INFO    ] __main__: JAX found 1 devices
2024-07-14 08:08:53,091 [INFO    ] __main__: restored step 25006 of run1_baseline as baseline
2024-07-14 08:08:53,428 [INFO    ] __main__: restored step 25003 of run2_armageddon as test
2024-07-14 08:09:13,559 [INFO    ] __main__: test network ELO difference from baseline network: +88 (+8/-8) ELO from 32000 self-played games
2024-07-14 08:09:13,607 [INFO    ] __main__: game outcomes: W: 18860, D: 1035, L: 12105
2024-07-14 08:09:13,716 [INFO    ] __main__: bayeselo raw output:

version 0057, Copyright (C) 1997-2010 Remi Coulom.
compiled Jun 27 2024 08:37:00.
This program comes with ABSOLUTELY NO WARRANTY.
This is free software, and you are welcome to redistribute it
under the terms and conditions of the GNU General Public License.
See http://www.gnu.org/copyleft/gpl.html for details.
ResultSet>off
00:00:00,00
Rank Name              Elo    +    - games score oppo. draws 
   1 run2_armageddon    44    4    4 32000   61%   -44    3% 
   2 run1_baseline     -44    4    4 32000   39%    44    3% 

