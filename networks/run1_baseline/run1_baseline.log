2024-07-11 15:37:13,560 [INFO    ] __main__: jax.local_devices(): [CpuDevice(id=0)]
2024-07-11 15:37:13,560 [INFO    ] __main__: selecting devices: [CpuDevice(id=0)]
2024-07-11 15:37:13,560 [INFO    ] __main__: JAX found 1 devices
2024-07-11 15:37:14,991 [DEBUG   ] __main__: 

                                                                AlphaZeroNet Summary                                                                
┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓
┃ path                         ┃ module         ┃ inputs              ┃ outputs           ┃ flops ┃ batch_stats       ┃ params                     ┃
┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩
│                              │ AlphaZeroNet   │ - float32[1,6,7,2]  │ - float32[1,7]    │ 0     │                   │                            │
│                              │                │ - train: False      │ - float32[1]      │       │                   │                            │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ConvBlock_0                 │ _ConvBlock     │ - float32[1,6,7,2]  │ float32[1,6,7,64] │ 0     │                   │                            │
│                              │                │ - False             │                   │       │                   │                            │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ConvBlock_0/Conv_0          │ Conv           │ float32[1,6,7,2]    │ float32[1,6,7,64] │ 0     │                   │ bias: float32[64]          │
│                              │                │                     │                   │       │                   │ kernel: float32[3,3,2,64]  │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 1,216 (4.9 KB)             │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ConvBlock_0/BatchNorm_0     │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ mean: float32[64] │ bias: float32[64]          │
│                              │                │                     │                   │       │ var: float32[64]  │ scale: float32[64]         │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │ 128 (512 B)       │ 128 (512 B)                │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_0             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                   │                            │
│                              │                │ - False             │                   │       │                   │                            │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_0/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │                   │ bias: float32[64]          │
│                              │                │                     │                   │       │                   │ kernel: float32[3,3,64,64] │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 36,928 (147.7 KB)          │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_0/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ mean: float32[64] │ bias: float32[64]          │
│                              │                │                     │                   │       │ var: float32[64]  │ scale: float32[64]         │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │ 128 (512 B)       │ 128 (512 B)                │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_0/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │                   │ bias: float32[64]          │
│                              │                │                     │                   │       │                   │ kernel: float32[3,3,64,64] │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 36,928 (147.7 KB)          │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_0/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ mean: float32[64] │ bias: float32[64]          │
│                              │                │                     │                   │       │ var: float32[64]  │ scale: float32[64]         │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │ 128 (512 B)       │ 128 (512 B)                │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_1             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                   │                            │
│                              │                │ - False             │                   │       │                   │                            │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_1/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │                   │ bias: float32[64]          │
│                              │                │                     │                   │       │                   │ kernel: float32[3,3,64,64] │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 36,928 (147.7 KB)          │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_1/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ mean: float32[64] │ bias: float32[64]          │
│                              │                │                     │                   │       │ var: float32[64]  │ scale: float32[64]         │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │ 128 (512 B)       │ 128 (512 B)                │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_1/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │                   │ bias: float32[64]          │
│                              │                │                     │                   │       │                   │ kernel: float32[3,3,64,64] │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 36,928 (147.7 KB)          │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_1/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ mean: float32[64] │ bias: float32[64]          │
│                              │                │                     │                   │       │ var: float32[64]  │ scale: float32[64]         │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │ 128 (512 B)       │ 128 (512 B)                │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_2             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                   │                            │
│                              │                │ - False             │                   │       │                   │                            │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_2/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │                   │ bias: float32[64]          │
│                              │                │                     │                   │       │                   │ kernel: float32[3,3,64,64] │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 36,928 (147.7 KB)          │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_2/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ mean: float32[64] │ bias: float32[64]          │
│                              │                │                     │                   │       │ var: float32[64]  │ scale: float32[64]         │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │ 128 (512 B)       │ 128 (512 B)                │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_2/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │                   │ bias: float32[64]          │
│                              │                │                     │                   │       │                   │ kernel: float32[3,3,64,64] │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 36,928 (147.7 KB)          │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_2/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ mean: float32[64] │ bias: float32[64]          │
│                              │                │                     │                   │       │ var: float32[64]  │ scale: float32[64]         │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │ 128 (512 B)       │ 128 (512 B)                │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_3             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                   │                            │
│                              │                │ - False             │                   │       │                   │                            │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_3/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │                   │ bias: float32[64]          │
│                              │                │                     │                   │       │                   │ kernel: float32[3,3,64,64] │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 36,928 (147.7 KB)          │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_3/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ mean: float32[64] │ bias: float32[64]          │
│                              │                │                     │                   │       │ var: float32[64]  │ scale: float32[64]         │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │ 128 (512 B)       │ 128 (512 B)                │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_3/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │                   │ bias: float32[64]          │
│                              │                │                     │                   │       │                   │ kernel: float32[3,3,64,64] │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 36,928 (147.7 KB)          │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_3/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ mean: float32[64] │ bias: float32[64]          │
│                              │                │                     │                   │       │ var: float32[64]  │ scale: float32[64]         │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │ 128 (512 B)       │ 128 (512 B)                │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_4             │ _ResidualBlock │ - float32[1,6,7,64] │ float32[1,6,7,64] │ 0     │                   │                            │
│                              │                │ - False             │                   │       │                   │                            │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_4/Conv_0      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │                   │ bias: float32[64]          │
│                              │                │                     │                   │       │                   │ kernel: float32[3,3,64,64] │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 36,928 (147.7 KB)          │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_4/BatchNorm_0 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ mean: float32[64] │ bias: float32[64]          │
│                              │                │                     │                   │       │ var: float32[64]  │ scale: float32[64]         │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │ 128 (512 B)       │ 128 (512 B)                │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_4/Conv_1      │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │                   │ bias: float32[64]          │
│                              │                │                     │                   │       │                   │ kernel: float32[3,3,64,64] │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 36,928 (147.7 KB)          │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ResidualBlock_4/BatchNorm_1 │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ mean: float32[64] │ bias: float32[64]          │
│                              │                │                     │                   │       │ var: float32[64]  │ scale: float32[64]         │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │ 128 (512 B)       │ 128 (512 B)                │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _PolicyHead_0                │ _PolicyHead    │ - float32[1,6,7,64] │ float32[1,7]      │ 0     │                   │                            │
│                              │                │ - False             │                   │       │                   │                            │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _PolicyHead_0/Conv_0         │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │                   │ bias: float32[64]          │
│                              │                │                     │                   │       │                   │ kernel: float32[1,1,64,64] │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 4,160 (16.6 KB)            │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _PolicyHead_0/BatchNorm_0    │ BatchNorm      │ float32[1,6,7,64]   │ float32[1,6,7,64] │ 0     │ mean: float32[64] │ bias: float32[64]          │
│                              │                │                     │                   │       │ var: float32[64]  │ scale: float32[64]         │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │ 128 (512 B)       │ 128 (512 B)                │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _PolicyHead_0/Dense_0        │ Dense          │ float32[1,2688]     │ float32[1,7]      │ 0     │                   │ bias: float32[7]           │
│                              │                │                     │                   │       │                   │ kernel: float32[2688,7]    │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 18,823 (75.3 KB)           │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ValueHead_0                 │ _ValueHead     │ - float32[1,6,7,64] │ float32[1]        │ 0     │                   │                            │
│                              │                │ - False             │                   │       │                   │                            │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ValueHead_0/Conv_0          │ Conv           │ float32[1,6,7,64]   │ float32[1,6,7,1]  │ 0     │                   │ bias: float32[1]           │
│                              │                │                     │                   │       │                   │ kernel: float32[1,1,64,1]  │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 65 (260 B)                 │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ValueHead_0/BatchNorm_0     │ BatchNorm      │ float32[1,6,7,1]    │ float32[1,6,7,1]  │ 0     │ mean: float32[1]  │ bias: float32[1]           │
│                              │                │                     │                   │       │ var: float32[1]   │ scale: float32[1]          │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │ 2 (8 B)           │ 2 (8 B)                    │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ValueHead_0/Dense_0         │ Dense          │ float32[1,42]       │ float32[1,64]     │ 0     │                   │ bias: float32[64]          │
│                              │                │                     │                   │       │                   │ kernel: float32[42,64]     │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 2,752 (11.0 KB)            │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ValueHead_0/BatchNorm_1     │ BatchNorm      │ float32[1,64]       │ float32[1,64]     │ 0     │ mean: float32[64] │ bias: float32[64]          │
│                              │                │                     │                   │       │ var: float32[64]  │ scale: float32[64]         │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │ 128 (512 B)       │ 128 (512 B)                │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│ _ValueHead_0/Dense_1         │ Dense          │ float32[1,64]       │ float32[1,1]      │ 0     │                   │ bias: float32[1]           │
│                              │                │                     │                   │       │                   │ kernel: float32[64,1]      │
│                              │                │                     │                   │       │                   │                            │
│                              │                │                     │                   │       │                   │ 65 (260 B)                 │
├──────────────────────────────┼────────────────┼─────────────────────┼───────────────────┼───────┼───────────────────┼────────────────────────────┤
│                              │                │                     │                   │ Total │ 1,666 (6.7 KB)    │ 398,027 (1.6 MB)           │
└──────────────────────────────┴────────────────┴─────────────────────┴───────────────────┴───────┴───────────────────┴────────────────────────────┘
                                                                                                                                                    
                                                         Total Parameters: 399,693 (1.6 MB)                                                         


2024-07-11 15:37:17,753 [INFO    ] __main__: jax.local_devices(): [cuda(id=0)]
2024-07-11 15:37:17,753 [INFO    ] __main__: selecting devices: [cuda(id=0)]
2024-07-11 15:37:17,753 [INFO    ] __main__: JAX found 1 devices
2024-07-11 15:37:23,090 [WARNING ] __main__: no checkpoint found in '/root/connect_four/checkpoints/run1_baseline'
2024-07-11 15:37:28,603 [INFO    ] __main__: replay_buffer size = 512
2024-07-11 15:37:28,605 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:37:29,911 [INFO    ] __main__: replay_buffer size = 1024
2024-07-11 15:37:29,918 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:37:31,222 [INFO    ] __main__: replay_buffer size = 1536
2024-07-11 15:37:31,240 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:37:32,576 [INFO    ] __main__: replay_buffer size = 2048
2024-07-11 15:37:32,599 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:37:33,884 [INFO    ] __main__: replay_buffer size = 2560
2024-07-11 15:37:33,910 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:37:35,249 [INFO    ] __main__: replay_buffer size = 3072
2024-07-11 15:37:35,278 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:37:36,576 [INFO    ] __main__: replay_buffer size = 3584
2024-07-11 15:37:36,610 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:37:37,954 [INFO    ] __main__: replay_buffer size = 4096
2024-07-11 15:37:37,991 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:37:44,537 [INFO    ] __main__: train step 0: loss: 0.3127, policy_loss: 2.1493, value_loss: 1.2968
2024-07-11 15:37:44,720 [INFO    ] __main__: train step 1: loss: 0.3009, policy_loss: 2.1332, value_loss: 1.2894
2024-07-11 15:37:44,927 [INFO    ] __main__: train step 2: loss: 0.3045, policy_loss: 2.1238, value_loss: 1.2927
2024-07-11 15:37:45,284 [INFO    ] __main__: train step 3: loss: 0.2948, policy_loss: 2.1178, value_loss: 1.2871
2024-07-11 15:37:45,481 [INFO    ] __main__: train step 4: loss: 0.2925, policy_loss: 2.1095, value_loss: 1.2879
2024-07-11 15:37:45,690 [INFO    ] __main__: train step 5: loss: 0.2897, policy_loss: 2.1018, value_loss: 1.2859
2024-07-11 15:37:45,922 [INFO    ] __main__: train step 6: loss: 0.2855, policy_loss: 2.0951, value_loss: 1.2792
2024-07-11 15:37:46,175 [INFO    ] __main__: train step 7: loss: 0.2808, policy_loss: 2.0913, value_loss: 1.2706
2024-07-11 15:37:46,403 [INFO    ] __main__: train step 8: loss: 0.2765, policy_loss: 2.0895, value_loss: 1.2658
2024-07-11 15:37:46,625 [INFO    ] __main__: train step 9: loss: 0.2753, policy_loss: 2.0889, value_loss: 1.2576
2024-07-11 15:37:46,856 [INFO    ] __main__: train step 10: loss: 0.2716, policy_loss: 2.0875, value_loss: 1.2503
2024-07-11 15:37:47,094 [INFO    ] __main__: train step 11: loss: 0.2684, policy_loss: 2.0858, value_loss: 1.2463
2024-07-11 15:37:47,299 [INFO    ] __main__: train step 12: loss: 0.2654, policy_loss: 2.0825, value_loss: 1.2448
2024-07-11 15:37:47,505 [INFO    ] __main__: train step 13: loss: 0.2623, policy_loss: 2.0781, value_loss: 1.2432
2024-07-11 15:37:47,717 [INFO    ] __main__: train step 14: loss: 0.2600, policy_loss: 2.0755, value_loss: 1.2417
2024-07-11 15:37:47,917 [INFO    ] __main__: train step 15: loss: 0.2576, policy_loss: 2.0736, value_loss: 1.2395
2024-07-11 15:37:48,287 [INFO    ] __main__: train step 16: loss: 0.2560, policy_loss: 2.0717, value_loss: 1.2367
2024-07-11 15:37:49,781 [INFO    ] __main__: replay_buffer size = 4608
2024-07-11 15:37:49,807 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:37:51,387 [INFO    ] __main__: train step 17: loss: 0.2534, policy_loss: 2.0708, value_loss: 1.2359
2024-07-11 15:37:51,556 [INFO    ] __main__: train step 18: loss: 0.2516, policy_loss: 2.0700, value_loss: 1.2339
2024-07-11 15:37:51,756 [INFO    ] __main__: train step 19: loss: 0.2504, policy_loss: 2.0682, value_loss: 1.2342
2024-07-11 15:37:51,965 [INFO    ] __main__: train step 20: loss: 0.2493, policy_loss: 2.0667, value_loss: 1.2339
2024-07-11 15:37:52,171 [INFO    ] __main__: train step 21: loss: 0.2478, policy_loss: 2.0650, value_loss: 1.2341
2024-07-11 15:37:52,408 [INFO    ] __main__: train step 22: loss: 0.2464, policy_loss: 2.0636, value_loss: 1.2350
2024-07-11 15:37:52,609 [INFO    ] __main__: train step 23: loss: 0.2448, policy_loss: 2.0618, value_loss: 1.2349
2024-07-11 15:37:52,968 [INFO    ] __main__: train step 24: loss: 0.2441, policy_loss: 2.0600, value_loss: 1.2354
2024-07-11 15:37:53,193 [INFO    ] __main__: train step 25: loss: 0.2425, policy_loss: 2.0583, value_loss: 1.2361
2024-07-11 15:37:53,411 [INFO    ] __main__: train step 26: loss: 0.2416, policy_loss: 2.0569, value_loss: 1.2365
2024-07-11 15:37:53,637 [INFO    ] __main__: train step 27: loss: 0.2408, policy_loss: 2.0557, value_loss: 1.2356
2024-07-11 15:37:53,975 [INFO    ] __main__: train step 28: loss: 0.2401, policy_loss: 2.0546, value_loss: 1.2347
2024-07-11 15:37:54,211 [INFO    ] __main__: train step 29: loss: 0.2393, policy_loss: 2.0535, value_loss: 1.2335
2024-07-11 15:37:54,416 [INFO    ] __main__: train step 30: loss: 0.2386, policy_loss: 2.0524, value_loss: 1.2330
2024-07-11 15:37:54,649 [INFO    ] __main__: train step 31: loss: 0.2377, policy_loss: 2.0512, value_loss: 1.2314
2024-07-11 15:37:54,848 [INFO    ] __main__: train step 32: loss: 0.2369, policy_loss: 2.0500, value_loss: 1.2305
2024-07-11 15:37:55,087 [INFO    ] __main__: train step 33: loss: 0.2363, policy_loss: 2.0490, value_loss: 1.2302
2024-07-11 15:37:56,543 [INFO    ] __main__: replay_buffer size = 5120
2024-07-11 15:37:56,572 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:37:58,107 [INFO    ] __main__: train step 34: loss: 0.2359, policy_loss: 2.0481, value_loss: 1.2279
2024-07-11 15:37:58,290 [INFO    ] __main__: train step 35: loss: 0.2351, policy_loss: 2.0471, value_loss: 1.2259
2024-07-11 15:37:58,516 [INFO    ] __main__: train step 36: loss: 0.2345, policy_loss: 2.0461, value_loss: 1.2242
2024-07-11 15:37:58,727 [INFO    ] __main__: train step 37: loss: 0.2340, policy_loss: 2.0451, value_loss: 1.2226
2024-07-11 15:37:58,960 [INFO    ] __main__: train step 38: loss: 0.2338, policy_loss: 2.0442, value_loss: 1.2209
2024-07-11 15:37:59,164 [INFO    ] __main__: train step 39: loss: 0.2335, policy_loss: 2.0432, value_loss: 1.2187
2024-07-11 15:37:59,500 [INFO    ] __main__: train step 40: loss: 0.2333, policy_loss: 2.0423, value_loss: 1.2173
2024-07-11 15:37:59,704 [INFO    ] __main__: train step 41: loss: 0.2330, policy_loss: 2.0413, value_loss: 1.2150
2024-07-11 15:37:59,900 [INFO    ] __main__: train step 42: loss: 0.2326, policy_loss: 2.0404, value_loss: 1.2126
2024-07-11 15:38:00,100 [INFO    ] __main__: train step 43: loss: 0.2319, policy_loss: 2.0394, value_loss: 1.2099
2024-07-11 15:38:00,311 [INFO    ] __main__: train step 44: loss: 0.2316, policy_loss: 2.0384, value_loss: 1.2076
2024-07-11 15:38:00,520 [INFO    ] __main__: train step 45: loss: 0.2314, policy_loss: 2.0376, value_loss: 1.2061
2024-07-11 15:38:00,720 [INFO    ] __main__: train step 46: loss: 0.2310, policy_loss: 2.0368, value_loss: 1.2034
2024-07-11 15:38:00,919 [INFO    ] __main__: train step 47: loss: 0.2306, policy_loss: 2.0360, value_loss: 1.2010
2024-07-11 15:38:01,144 [INFO    ] __main__: train step 48: loss: 0.2304, policy_loss: 2.0352, value_loss: 1.1987
2024-07-11 15:38:01,336 [INFO    ] __main__: train step 49: loss: 0.2299, policy_loss: 2.0345, value_loss: 1.1965
2024-07-11 15:38:01,540 [INFO    ] __main__: train step 50: loss: 0.2293, policy_loss: 2.0338, value_loss: 1.1947
2024-07-11 15:38:02,979 [INFO    ] __main__: replay_buffer size = 5632
2024-07-11 15:38:03,012 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:38:04,578 [INFO    ] __main__: train step 51: loss: 0.2289, policy_loss: 2.0329, value_loss: 1.1930
2024-07-11 15:38:04,749 [INFO    ] __main__: train step 52: loss: 0.2286, policy_loss: 2.0320, value_loss: 1.1911
2024-07-11 15:38:05,109 [INFO    ] __main__: train step 53: loss: 0.2283, policy_loss: 2.0313, value_loss: 1.1888
2024-07-11 15:38:05,301 [INFO    ] __main__: train step 54: loss: 0.2280, policy_loss: 2.0307, value_loss: 1.1868
2024-07-11 15:38:05,502 [INFO    ] __main__: train step 55: loss: 0.2276, policy_loss: 2.0301, value_loss: 1.1851
2024-07-11 15:38:05,704 [INFO    ] __main__: train step 56: loss: 0.2273, policy_loss: 2.0295, value_loss: 1.1836
2024-07-11 15:38:05,904 [INFO    ] __main__: train step 57: loss: 0.2271, policy_loss: 2.0288, value_loss: 1.1815
2024-07-11 15:38:06,111 [INFO    ] __main__: train step 58: loss: 0.2266, policy_loss: 2.0281, value_loss: 1.1800
2024-07-11 15:38:06,347 [INFO    ] __main__: train step 59: loss: 0.2264, policy_loss: 2.0274, value_loss: 1.1780
2024-07-11 15:38:06,581 [INFO    ] __main__: train step 60: loss: 0.2263, policy_loss: 2.0267, value_loss: 1.1761
2024-07-11 15:38:06,779 [INFO    ] __main__: train step 61: loss: 0.2260, policy_loss: 2.0258, value_loss: 1.1745
2024-07-11 15:38:06,978 [INFO    ] __main__: train step 62: loss: 0.2259, policy_loss: 2.0251, value_loss: 1.1727
2024-07-11 15:38:07,211 [INFO    ] __main__: train step 63: loss: 0.2258, policy_loss: 2.0243, value_loss: 1.1711
2024-07-11 15:38:07,413 [INFO    ] __main__: train step 64: loss: 0.2254, policy_loss: 2.0235, value_loss: 1.1693
2024-07-11 15:38:07,763 [INFO    ] __main__: train step 65: loss: 0.2253, policy_loss: 2.0229, value_loss: 1.1675
2024-07-11 15:38:07,994 [INFO    ] __main__: train step 66: loss: 0.2252, policy_loss: 2.0222, value_loss: 1.1661
2024-07-11 15:38:08,193 [INFO    ] __main__: train step 67: loss: 0.2249, policy_loss: 2.0215, value_loss: 1.1640
2024-07-11 15:38:09,641 [INFO    ] __main__: replay_buffer size = 6144
2024-07-11 15:38:09,679 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:38:10,864 [INFO    ] __main__: train step 68: loss: 0.2249, policy_loss: 2.0209, value_loss: 1.1625
2024-07-11 15:38:11,029 [INFO    ] __main__: train step 69: loss: 0.2249, policy_loss: 2.0203, value_loss: 1.1610
2024-07-11 15:38:11,247 [INFO    ] __main__: train step 70: loss: 0.2248, policy_loss: 2.0196, value_loss: 1.1593
2024-07-11 15:38:11,456 [INFO    ] __main__: train step 71: loss: 0.2246, policy_loss: 2.0190, value_loss: 1.1581
2024-07-11 15:38:11,656 [INFO    ] __main__: train step 72: loss: 0.2245, policy_loss: 2.0184, value_loss: 1.1567
2024-07-11 15:38:11,867 [INFO    ] __main__: train step 73: loss: 0.2243, policy_loss: 2.0179, value_loss: 1.1554
2024-07-11 15:38:12,067 [INFO    ] __main__: train step 74: loss: 0.2242, policy_loss: 2.0173, value_loss: 1.1538
2024-07-11 15:38:12,277 [INFO    ] __main__: train step 75: loss: 0.2240, policy_loss: 2.0168, value_loss: 1.1527
2024-07-11 15:38:12,475 [INFO    ] __main__: train step 76: loss: 0.2239, policy_loss: 2.0163, value_loss: 1.1511
2024-07-11 15:38:12,682 [INFO    ] __main__: train step 77: loss: 0.2237, policy_loss: 2.0158, value_loss: 1.1497
2024-07-11 15:38:13,013 [INFO    ] __main__: train step 78: loss: 0.2236, policy_loss: 2.0151, value_loss: 1.1483
2024-07-11 15:38:13,228 [INFO    ] __main__: train step 79: loss: 0.2234, policy_loss: 2.0146, value_loss: 1.1472
2024-07-11 15:38:13,437 [INFO    ] __main__: train step 80: loss: 0.2233, policy_loss: 2.0140, value_loss: 1.1458
2024-07-11 15:38:13,640 [INFO    ] __main__: train step 81: loss: 0.2232, policy_loss: 2.0135, value_loss: 1.1445
2024-07-11 15:38:13,867 [INFO    ] __main__: train step 82: loss: 0.2231, policy_loss: 2.0130, value_loss: 1.1433
2024-07-11 15:38:14,089 [INFO    ] __main__: train step 83: loss: 0.2229, policy_loss: 2.0125, value_loss: 1.1421
2024-07-11 15:38:14,294 [INFO    ] __main__: train step 84: loss: 0.2227, policy_loss: 2.0121, value_loss: 1.1407
2024-07-11 15:38:15,864 [INFO    ] __main__: replay_buffer size = 6656
2024-07-11 15:38:15,907 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:38:17,458 [INFO    ] __main__: train step 85: loss: 0.2227, policy_loss: 2.0116, value_loss: 1.1393
2024-07-11 15:38:17,625 [INFO    ] __main__: train step 86: loss: 0.2227, policy_loss: 2.0112, value_loss: 1.1380
2024-07-11 15:38:17,839 [INFO    ] __main__: train step 87: loss: 0.2225, policy_loss: 2.0108, value_loss: 1.1369
2024-07-11 15:38:18,079 [INFO    ] __main__: train step 88: loss: 0.2225, policy_loss: 2.0104, value_loss: 1.1358
2024-07-11 15:38:18,273 [INFO    ] __main__: train step 89: loss: 0.2224, policy_loss: 2.0099, value_loss: 1.1344
2024-07-11 15:38:18,469 [INFO    ] __main__: train step 90: loss: 0.2223, policy_loss: 2.0095, value_loss: 1.1336
2024-07-11 15:38:18,801 [INFO    ] __main__: train step 91: loss: 0.2224, policy_loss: 2.0091, value_loss: 1.1323
2024-07-11 15:38:19,007 [INFO    ] __main__: train step 92: loss: 0.2224, policy_loss: 2.0087, value_loss: 1.1313
2024-07-11 15:38:19,210 [INFO    ] __main__: train step 93: loss: 0.2222, policy_loss: 2.0083, value_loss: 1.1303
2024-07-11 15:38:19,409 [INFO    ] __main__: train step 94: loss: 0.2222, policy_loss: 2.0080, value_loss: 1.1293
2024-07-11 15:38:19,604 [INFO    ] __main__: train step 95: loss: 0.2221, policy_loss: 2.0075, value_loss: 1.1285
2024-07-11 15:38:19,824 [INFO    ] __main__: train step 96: loss: 0.2223, policy_loss: 2.0072, value_loss: 1.1276
2024-07-11 15:38:20,017 [INFO    ] __main__: train step 97: loss: 0.2221, policy_loss: 2.0068, value_loss: 1.1268
2024-07-11 15:38:20,232 [INFO    ] __main__: train step 98: loss: 0.2222, policy_loss: 2.0064, value_loss: 1.1258
2024-07-11 15:38:20,455 [INFO    ] __main__: train step 99: loss: 0.2222, policy_loss: 2.0061, value_loss: 1.1249
2024-07-11 15:38:20,660 [INFO    ] __main__: train step 100: loss: 0.2221, policy_loss: 2.0057, value_loss: 1.1238
2024-07-11 15:38:20,866 [INFO    ] __main__: train step 101: loss: 0.2222, policy_loss: 2.0053, value_loss: 1.1227
2024-07-11 15:38:22,315 [INFO    ] __main__: replay_buffer size = 7168
2024-07-11 15:38:22,359 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:38:23,889 [INFO    ] __main__: train step 102: loss: 0.2221, policy_loss: 2.0049, value_loss: 1.1219
2024-07-11 15:38:24,201 [INFO    ] __main__: train step 103: loss: 0.2220, policy_loss: 2.0045, value_loss: 1.1210
2024-07-11 15:38:24,405 [INFO    ] __main__: train step 104: loss: 0.2221, policy_loss: 2.0041, value_loss: 1.1201
2024-07-11 15:38:24,611 [INFO    ] __main__: train step 105: loss: 0.2221, policy_loss: 2.0036, value_loss: 1.1193
2024-07-11 15:38:24,817 [INFO    ] __main__: train step 106: loss: 0.2221, policy_loss: 2.0032, value_loss: 1.1187
2024-07-11 15:38:25,021 [INFO    ] __main__: train step 107: loss: 0.2221, policy_loss: 2.0029, value_loss: 1.1179
2024-07-11 15:38:25,223 [INFO    ] __main__: train step 108: loss: 0.2220, policy_loss: 2.0025, value_loss: 1.1170
2024-07-11 15:38:25,422 [INFO    ] __main__: train step 109: loss: 0.2221, policy_loss: 2.0022, value_loss: 1.1162
2024-07-11 15:38:25,639 [INFO    ] __main__: train step 110: loss: 0.2220, policy_loss: 2.0018, value_loss: 1.1152
2024-07-11 15:38:25,834 [INFO    ] __main__: train step 111: loss: 0.2219, policy_loss: 2.0015, value_loss: 1.1144
2024-07-11 15:38:26,044 [INFO    ] __main__: train step 112: loss: 0.2218, policy_loss: 2.0011, value_loss: 1.1139
2024-07-11 15:38:26,260 [INFO    ] __main__: train step 113: loss: 0.2219, policy_loss: 2.0007, value_loss: 1.1130
2024-07-11 15:38:26,477 [INFO    ] __main__: train step 114: loss: 0.2220, policy_loss: 2.0004, value_loss: 1.1125
2024-07-11 15:38:26,663 [INFO    ] __main__: train step 115: loss: 0.2220, policy_loss: 2.0000, value_loss: 1.1116
2024-07-11 15:38:26,867 [INFO    ] __main__: train step 116: loss: 0.2220, policy_loss: 1.9997, value_loss: 1.1109
2024-07-11 15:38:27,225 [INFO    ] __main__: train step 117: loss: 0.2220, policy_loss: 1.9993, value_loss: 1.1101
2024-07-11 15:38:27,414 [INFO    ] __main__: train step 118: loss: 0.2220, policy_loss: 1.9990, value_loss: 1.1094
2024-07-11 15:38:28,911 [INFO    ] __main__: replay_buffer size = 7680
2024-07-11 15:38:28,958 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:38:30,469 [INFO    ] __main__: train step 119: loss: 0.2220, policy_loss: 1.9986, value_loss: 1.1088
2024-07-11 15:38:30,633 [INFO    ] __main__: train step 120: loss: 0.2220, policy_loss: 1.9983, value_loss: 1.1082
2024-07-11 15:38:30,844 [INFO    ] __main__: train step 121: loss: 0.2221, policy_loss: 1.9980, value_loss: 1.1076
2024-07-11 15:38:31,042 [INFO    ] __main__: train step 122: loss: 0.2220, policy_loss: 1.9977, value_loss: 1.1071
2024-07-11 15:38:31,239 [INFO    ] __main__: train step 123: loss: 0.2221, policy_loss: 1.9973, value_loss: 1.1065
2024-07-11 15:38:31,455 [INFO    ] __main__: train step 124: loss: 0.2221, policy_loss: 1.9969, value_loss: 1.1058
2024-07-11 15:38:31,651 [INFO    ] __main__: train step 125: loss: 0.2222, policy_loss: 1.9966, value_loss: 1.1053
2024-07-11 15:38:31,870 [INFO    ] __main__: train step 126: loss: 0.2223, policy_loss: 1.9963, value_loss: 1.1046
2024-07-11 15:38:32,098 [INFO    ] __main__: train step 127: loss: 0.2222, policy_loss: 1.9960, value_loss: 1.1042
2024-07-11 15:38:32,313 [INFO    ] __main__: train step 128: loss: 0.2223, policy_loss: 1.9956, value_loss: 1.1036
2024-07-11 15:38:32,653 [INFO    ] __main__: train step 129: loss: 0.2223, policy_loss: 1.9953, value_loss: 1.1032
2024-07-11 15:38:32,853 [INFO    ] __main__: train step 130: loss: 0.2223, policy_loss: 1.9950, value_loss: 1.1027
2024-07-11 15:38:33,061 [INFO    ] __main__: train step 131: loss: 0.2223, policy_loss: 1.9946, value_loss: 1.1019
2024-07-11 15:38:33,261 [INFO    ] __main__: train step 132: loss: 0.2222, policy_loss: 1.9943, value_loss: 1.1012
2024-07-11 15:38:33,467 [INFO    ] __main__: train step 133: loss: 0.2222, policy_loss: 1.9940, value_loss: 1.1007
2024-07-11 15:38:33,669 [INFO    ] __main__: train step 134: loss: 0.2221, policy_loss: 1.9937, value_loss: 1.1003
2024-07-11 15:38:33,865 [INFO    ] __main__: train step 135: loss: 0.2222, policy_loss: 1.9934, value_loss: 1.0996
2024-07-11 15:38:35,352 [INFO    ] __main__: replay_buffer size = 8192
2024-07-11 15:38:35,396 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:38:36,547 [INFO    ] __main__: train step 136: loss: 0.2223, policy_loss: 1.9932, value_loss: 1.0992
2024-07-11 15:38:36,729 [INFO    ] __main__: train step 137: loss: 0.2223, policy_loss: 1.9929, value_loss: 1.0987
2024-07-11 15:38:36,929 [INFO    ] __main__: train step 138: loss: 0.2224, policy_loss: 1.9926, value_loss: 1.0981
2024-07-11 15:38:37,133 [INFO    ] __main__: train step 139: loss: 0.2225, policy_loss: 1.9924, value_loss: 1.0974
2024-07-11 15:38:37,346 [INFO    ] __main__: train step 140: loss: 0.2225, policy_loss: 1.9921, value_loss: 1.0970
2024-07-11 15:38:37,542 [INFO    ] __main__: train step 141: loss: 0.2226, policy_loss: 1.9919, value_loss: 1.0966
2024-07-11 15:38:37,911 [INFO    ] __main__: train step 142: loss: 0.2226, policy_loss: 1.9916, value_loss: 1.0962
2024-07-11 15:38:38,144 [INFO    ] __main__: train step 143: loss: 0.2227, policy_loss: 1.9913, value_loss: 1.0956
2024-07-11 15:38:38,354 [INFO    ] __main__: train step 144: loss: 0.2226, policy_loss: 1.9911, value_loss: 1.0951
2024-07-11 15:38:38,550 [INFO    ] __main__: train step 145: loss: 0.2227, policy_loss: 1.9908, value_loss: 1.0947
2024-07-11 15:38:38,759 [INFO    ] __main__: train step 146: loss: 0.2228, policy_loss: 1.9905, value_loss: 1.0941
2024-07-11 15:38:38,952 [INFO    ] __main__: train step 147: loss: 0.2228, policy_loss: 1.9903, value_loss: 1.0937
2024-07-11 15:38:39,151 [INFO    ] __main__: train step 148: loss: 0.2228, policy_loss: 1.9900, value_loss: 1.0933
2024-07-11 15:38:39,361 [INFO    ] __main__: train step 149: loss: 0.2228, policy_loss: 1.9898, value_loss: 1.0928
2024-07-11 15:38:39,561 [INFO    ] __main__: train step 150: loss: 0.2227, policy_loss: 1.9895, value_loss: 1.0924
2024-07-11 15:38:39,754 [INFO    ] __main__: train step 151: loss: 0.2229, policy_loss: 1.9893, value_loss: 1.0917
2024-07-11 15:38:39,956 [INFO    ] __main__: train step 152: loss: 0.2230, policy_loss: 1.9890, value_loss: 1.0911
2024-07-11 15:38:41,470 [INFO    ] __main__: replay_buffer size = 8704
2024-07-11 15:38:41,528 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:38:43,127 [INFO    ] __main__: train step 153: loss: 0.2230, policy_loss: 1.9887, value_loss: 1.0907
2024-07-11 15:38:43,303 [INFO    ] __main__: train step 154: loss: 0.2231, policy_loss: 1.9885, value_loss: 1.0904
2024-07-11 15:38:43,652 [INFO    ] __main__: train step 155: loss: 0.2232, policy_loss: 1.9882, value_loss: 1.0899
2024-07-11 15:38:43,867 [INFO    ] __main__: train step 156: loss: 0.2232, policy_loss: 1.9880, value_loss: 1.0895
2024-07-11 15:38:44,117 [INFO    ] __main__: train step 157: loss: 0.2233, policy_loss: 1.9877, value_loss: 1.0891
2024-07-11 15:38:44,336 [INFO    ] __main__: train step 158: loss: 0.2234, policy_loss: 1.9874, value_loss: 1.0886
2024-07-11 15:38:44,535 [INFO    ] __main__: train step 159: loss: 0.2235, policy_loss: 1.9872, value_loss: 1.0881
2024-07-11 15:38:44,728 [INFO    ] __main__: train step 160: loss: 0.2235, policy_loss: 1.9869, value_loss: 1.0877
2024-07-11 15:38:44,931 [INFO    ] __main__: train step 161: loss: 0.2234, policy_loss: 1.9867, value_loss: 1.0872
2024-07-11 15:38:45,128 [INFO    ] __main__: train step 162: loss: 0.2235, policy_loss: 1.9864, value_loss: 1.0866
2024-07-11 15:38:45,340 [INFO    ] __main__: train step 163: loss: 0.2235, policy_loss: 1.9862, value_loss: 1.0861
2024-07-11 15:38:45,542 [INFO    ] __main__: train step 164: loss: 0.2236, policy_loss: 1.9860, value_loss: 1.0857
2024-07-11 15:38:45,751 [INFO    ] __main__: train step 165: loss: 0.2236, policy_loss: 1.9857, value_loss: 1.0853
2024-07-11 15:38:45,988 [INFO    ] __main__: train step 166: loss: 0.2237, policy_loss: 1.9855, value_loss: 1.0849
2024-07-11 15:38:46,326 [INFO    ] __main__: train step 167: loss: 0.2237, policy_loss: 1.9853, value_loss: 1.0846
2024-07-11 15:38:46,528 [INFO    ] __main__: train step 168: loss: 0.2237, policy_loss: 1.9851, value_loss: 1.0842
2024-07-11 15:38:46,744 [INFO    ] __main__: train step 169: loss: 0.2237, policy_loss: 1.9848, value_loss: 1.0839
2024-07-11 15:38:48,221 [INFO    ] __main__: replay_buffer size = 9216
2024-07-11 15:38:48,297 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:38:49,944 [INFO    ] __main__: train step 170: loss: 0.2238, policy_loss: 1.9846, value_loss: 1.0835
2024-07-11 15:38:50,114 [INFO    ] __main__: train step 171: loss: 0.2239, policy_loss: 1.9844, value_loss: 1.0831
2024-07-11 15:38:50,344 [INFO    ] __main__: train step 172: loss: 0.2239, policy_loss: 1.9841, value_loss: 1.0829
2024-07-11 15:38:50,558 [INFO    ] __main__: train step 173: loss: 0.2239, policy_loss: 1.9839, value_loss: 1.0825
2024-07-11 15:38:50,764 [INFO    ] __main__: train step 174: loss: 0.2239, policy_loss: 1.9837, value_loss: 1.0820
2024-07-11 15:38:50,960 [INFO    ] __main__: train step 175: loss: 0.2238, policy_loss: 1.9835, value_loss: 1.0818
2024-07-11 15:38:51,166 [INFO    ] __main__: train step 176: loss: 0.2239, policy_loss: 1.9832, value_loss: 1.0815
2024-07-11 15:38:51,375 [INFO    ] __main__: train step 177: loss: 0.2239, policy_loss: 1.9830, value_loss: 1.0810
2024-07-11 15:38:51,587 [INFO    ] __main__: train step 178: loss: 0.2241, policy_loss: 1.9828, value_loss: 1.0806
2024-07-11 15:38:51,797 [INFO    ] __main__: train step 179: loss: 0.2241, policy_loss: 1.9825, value_loss: 1.0804
2024-07-11 15:38:52,154 [INFO    ] __main__: train step 180: loss: 0.2243, policy_loss: 1.9823, value_loss: 1.0801
2024-07-11 15:38:52,372 [INFO    ] __main__: train step 181: loss: 0.2242, policy_loss: 1.9820, value_loss: 1.0797
2024-07-11 15:38:52,579 [INFO    ] __main__: train step 182: loss: 0.2243, policy_loss: 1.9818, value_loss: 1.0792
2024-07-11 15:38:52,790 [INFO    ] __main__: train step 183: loss: 0.2244, policy_loss: 1.9816, value_loss: 1.0788
2024-07-11 15:38:53,020 [INFO    ] __main__: train step 184: loss: 0.2245, policy_loss: 1.9814, value_loss: 1.0784
2024-07-11 15:38:53,241 [INFO    ] __main__: train step 185: loss: 0.2247, policy_loss: 1.9811, value_loss: 1.0779
2024-07-11 15:38:53,432 [INFO    ] __main__: train step 186: loss: 0.2247, policy_loss: 1.9809, value_loss: 1.0775
2024-07-11 15:38:54,860 [INFO    ] __main__: replay_buffer size = 9728
2024-07-11 15:38:54,942 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:38:56,599 [INFO    ] __main__: train step 187: loss: 0.2249, policy_loss: 1.9807, value_loss: 1.0772
2024-07-11 15:38:56,775 [INFO    ] __main__: train step 188: loss: 0.2249, policy_loss: 1.9805, value_loss: 1.0769
2024-07-11 15:38:56,975 [INFO    ] __main__: train step 189: loss: 0.2250, policy_loss: 1.9803, value_loss: 1.0764
2024-07-11 15:38:57,175 [INFO    ] __main__: train step 190: loss: 0.2251, policy_loss: 1.9800, value_loss: 1.0760
2024-07-11 15:38:57,376 [INFO    ] __main__: train step 191: loss: 0.2252, policy_loss: 1.9798, value_loss: 1.0758
2024-07-11 15:38:57,579 [INFO    ] __main__: train step 192: loss: 0.2253, policy_loss: 1.9796, value_loss: 1.0755
2024-07-11 15:38:57,931 [INFO    ] __main__: train step 193: loss: 0.2253, policy_loss: 1.9794, value_loss: 1.0752
2024-07-11 15:38:58,161 [INFO    ] __main__: train step 194: loss: 0.2254, policy_loss: 1.9792, value_loss: 1.0748
2024-07-11 15:38:58,353 [INFO    ] __main__: train step 195: loss: 0.2254, policy_loss: 1.9790, value_loss: 1.0746
2024-07-11 15:38:58,553 [INFO    ] __main__: train step 196: loss: 0.2255, policy_loss: 1.9787, value_loss: 1.0741
2024-07-11 15:38:58,753 [INFO    ] __main__: train step 197: loss: 0.2256, policy_loss: 1.9785, value_loss: 1.0737
2024-07-11 15:38:58,951 [INFO    ] __main__: train step 198: loss: 0.2256, policy_loss: 1.9783, value_loss: 1.0733
2024-07-11 15:38:59,158 [INFO    ] __main__: train step 199: loss: 0.2256, policy_loss: 1.9782, value_loss: 1.0729
2024-07-11 15:38:59,347 [INFO    ] __main__: train step 200: loss: 0.2258, policy_loss: 1.9780, value_loss: 1.0725
2024-07-11 15:38:59,551 [INFO    ] __main__: train step 201: loss: 0.2259, policy_loss: 1.9778, value_loss: 1.0720
2024-07-11 15:38:59,744 [INFO    ] __main__: train step 202: loss: 0.2259, policy_loss: 1.9776, value_loss: 1.0718
2024-07-11 15:38:59,938 [INFO    ] __main__: train step 203: loss: 0.2260, policy_loss: 1.9773, value_loss: 1.0716
2024-07-11 15:39:01,346 [INFO    ] __main__: replay_buffer size = 10240
2024-07-11 15:39:01,404 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:39:02,612 [INFO    ] __main__: train step 204: loss: 0.2260, policy_loss: 1.9771, value_loss: 1.0712
2024-07-11 15:39:02,785 [INFO    ] __main__: train step 205: loss: 0.2261, policy_loss: 1.9769, value_loss: 1.0709
2024-07-11 15:39:03,124 [INFO    ] __main__: train step 206: loss: 0.2261, policy_loss: 1.9767, value_loss: 1.0705
2024-07-11 15:39:03,342 [INFO    ] __main__: train step 207: loss: 0.2262, policy_loss: 1.9764, value_loss: 1.0702
2024-07-11 15:39:03,538 [INFO    ] __main__: train step 208: loss: 0.2262, policy_loss: 1.9762, value_loss: 1.0698
2024-07-11 15:39:03,734 [INFO    ] __main__: train step 209: loss: 0.2263, policy_loss: 1.9760, value_loss: 1.0695
2024-07-11 15:39:03,924 [INFO    ] __main__: train step 210: loss: 0.2264, policy_loss: 1.9758, value_loss: 1.0691
2024-07-11 15:39:04,124 [INFO    ] __main__: train step 211: loss: 0.2265, policy_loss: 1.9756, value_loss: 1.0687
2024-07-11 15:39:04,329 [INFO    ] __main__: train step 212: loss: 0.2266, policy_loss: 1.9754, value_loss: 1.0685
2024-07-11 15:39:04,530 [INFO    ] __main__: train step 213: loss: 0.2266, policy_loss: 1.9752, value_loss: 1.0681
2024-07-11 15:39:04,743 [INFO    ] __main__: train step 214: loss: 0.2267, policy_loss: 1.9750, value_loss: 1.0678
2024-07-11 15:39:04,955 [INFO    ] __main__: train step 215: loss: 0.2269, policy_loss: 1.9748, value_loss: 1.0674
2024-07-11 15:39:05,178 [INFO    ] __main__: train step 216: loss: 0.2269, policy_loss: 1.9746, value_loss: 1.0671
2024-07-11 15:39:05,383 [INFO    ] __main__: train step 217: loss: 0.2270, policy_loss: 1.9744, value_loss: 1.0668
2024-07-11 15:39:05,599 [INFO    ] __main__: train step 218: loss: 0.2271, policy_loss: 1.9742, value_loss: 1.0666
2024-07-11 15:39:05,786 [INFO    ] __main__: train step 219: loss: 0.2271, policy_loss: 1.9740, value_loss: 1.0663
2024-07-11 15:39:06,147 [INFO    ] __main__: train step 220: loss: 0.2272, policy_loss: 1.9738, value_loss: 1.0659
2024-07-11 15:39:07,559 [INFO    ] __main__: replay_buffer size = 10752
2024-07-11 15:39:07,614 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:39:09,209 [INFO    ] __main__: train step 221: loss: 0.2273, policy_loss: 1.9736, value_loss: 1.0656
2024-07-11 15:39:09,379 [INFO    ] __main__: train step 222: loss: 0.2274, policy_loss: 1.9734, value_loss: 1.0652
2024-07-11 15:39:09,592 [INFO    ] __main__: train step 223: loss: 0.2275, policy_loss: 1.9732, value_loss: 1.0649
2024-07-11 15:39:09,784 [INFO    ] __main__: train step 224: loss: 0.2276, policy_loss: 1.9730, value_loss: 1.0646
2024-07-11 15:39:09,979 [INFO    ] __main__: train step 225: loss: 0.2277, policy_loss: 1.9728, value_loss: 1.0644
2024-07-11 15:39:10,173 [INFO    ] __main__: train step 226: loss: 0.2278, policy_loss: 1.9726, value_loss: 1.0641
2024-07-11 15:39:10,375 [INFO    ] __main__: train step 227: loss: 0.2278, policy_loss: 1.9724, value_loss: 1.0638
2024-07-11 15:39:10,560 [INFO    ] __main__: train step 228: loss: 0.2279, policy_loss: 1.9723, value_loss: 1.0635
2024-07-11 15:39:10,767 [INFO    ] __main__: train step 229: loss: 0.2280, policy_loss: 1.9721, value_loss: 1.0633
2024-07-11 15:39:10,993 [INFO    ] __main__: train step 230: loss: 0.2281, policy_loss: 1.9719, value_loss: 1.0631
2024-07-11 15:39:11,201 [INFO    ] __main__: train step 231: loss: 0.2282, policy_loss: 1.9717, value_loss: 1.0628
2024-07-11 15:39:11,555 [INFO    ] __main__: train step 232: loss: 0.2283, policy_loss: 1.9715, value_loss: 1.0625
2024-07-11 15:39:11,746 [INFO    ] __main__: train step 233: loss: 0.2284, policy_loss: 1.9713, value_loss: 1.0624
2024-07-11 15:39:11,952 [INFO    ] __main__: train step 234: loss: 0.2284, policy_loss: 1.9711, value_loss: 1.0621
2024-07-11 15:39:12,146 [INFO    ] __main__: train step 235: loss: 0.2285, policy_loss: 1.9709, value_loss: 1.0617
2024-07-11 15:39:12,350 [INFO    ] __main__: train step 236: loss: 0.2286, policy_loss: 1.9707, value_loss: 1.0614
2024-07-11 15:39:12,563 [INFO    ] __main__: train step 237: loss: 0.2287, policy_loss: 1.9705, value_loss: 1.0612
2024-07-11 15:39:14,016 [INFO    ] __main__: replay_buffer size = 11264
2024-07-11 15:39:14,076 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:39:15,699 [INFO    ] __main__: train step 238: loss: 0.2288, policy_loss: 1.9704, value_loss: 1.0608
2024-07-11 15:39:15,870 [INFO    ] __main__: train step 239: loss: 0.2289, policy_loss: 1.9702, value_loss: 1.0605
2024-07-11 15:39:16,074 [INFO    ] __main__: train step 240: loss: 0.2289, policy_loss: 1.9700, value_loss: 1.0602
2024-07-11 15:39:16,283 [INFO    ] __main__: train step 241: loss: 0.2290, policy_loss: 1.9698, value_loss: 1.0600
2024-07-11 15:39:16,488 [INFO    ] __main__: train step 242: loss: 0.2291, policy_loss: 1.9696, value_loss: 1.0596
2024-07-11 15:39:16,695 [INFO    ] __main__: train step 243: loss: 0.2292, policy_loss: 1.9694, value_loss: 1.0593
2024-07-11 15:39:16,904 [INFO    ] __main__: train step 244: loss: 0.2293, policy_loss: 1.9693, value_loss: 1.0590
2024-07-11 15:39:17,260 [INFO    ] __main__: train step 245: loss: 0.2293, policy_loss: 1.9691, value_loss: 1.0587
2024-07-11 15:39:17,459 [INFO    ] __main__: train step 246: loss: 0.2294, policy_loss: 1.9689, value_loss: 1.0585
2024-07-11 15:39:17,658 [INFO    ] __main__: train step 247: loss: 0.2295, policy_loss: 1.9687, value_loss: 1.0581
2024-07-11 15:39:17,864 [INFO    ] __main__: train step 248: loss: 0.2295, policy_loss: 1.9685, value_loss: 1.0580
2024-07-11 15:39:18,071 [INFO    ] __main__: train step 249: loss: 0.2296, policy_loss: 1.9683, value_loss: 1.0577
2024-07-11 15:39:18,262 [INFO    ] __main__: train step 250: loss: 0.2297, policy_loss: 1.9681, value_loss: 1.0575
2024-07-11 15:39:18,452 [INFO    ] __main__: train step 251: loss: 0.2298, policy_loss: 1.9680, value_loss: 1.0573
2024-07-11 15:39:18,649 [INFO    ] __main__: train step 252: loss: 0.2298, policy_loss: 1.9678, value_loss: 1.0570
2024-07-11 15:39:18,847 [INFO    ] __main__: train step 253: loss: 0.2300, policy_loss: 1.9676, value_loss: 1.0567
2024-07-11 15:39:19,041 [INFO    ] __main__: train step 254: loss: 0.2301, policy_loss: 1.9674, value_loss: 1.0566
2024-07-11 15:39:20,479 [INFO    ] __main__: replay_buffer size = 11776
2024-07-11 15:39:20,543 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:39:22,169 [INFO    ] __main__: train step 255: loss: 0.2302, policy_loss: 1.9672, value_loss: 1.0564
2024-07-11 15:39:22,337 [INFO    ] __main__: train step 256: loss: 0.2303, policy_loss: 1.9670, value_loss: 1.0561
2024-07-11 15:39:22,555 [INFO    ] __main__: train step 257: loss: 0.2304, policy_loss: 1.9668, value_loss: 1.0560
2024-07-11 15:39:22,911 [INFO    ] __main__: train step 258: loss: 0.2305, policy_loss: 1.9667, value_loss: 1.0558
2024-07-11 15:39:23,115 [INFO    ] __main__: train step 259: loss: 0.2305, policy_loss: 1.9665, value_loss: 1.0557
2024-07-11 15:39:23,318 [INFO    ] __main__: train step 260: loss: 0.2306, policy_loss: 1.9663, value_loss: 1.0555
2024-07-11 15:39:23,515 [INFO    ] __main__: train step 261: loss: 0.2306, policy_loss: 1.9661, value_loss: 1.0553
2024-07-11 15:39:23,720 [INFO    ] __main__: train step 262: loss: 0.2307, policy_loss: 1.9660, value_loss: 1.0550
2024-07-11 15:39:23,924 [INFO    ] __main__: train step 263: loss: 0.2308, policy_loss: 1.9658, value_loss: 1.0547
2024-07-11 15:39:24,130 [INFO    ] __main__: train step 264: loss: 0.2309, policy_loss: 1.9656, value_loss: 1.0545
2024-07-11 15:39:24,335 [INFO    ] __main__: train step 265: loss: 0.2309, policy_loss: 1.9654, value_loss: 1.0542
2024-07-11 15:39:24,542 [INFO    ] __main__: train step 266: loss: 0.2310, policy_loss: 1.9652, value_loss: 1.0539
2024-07-11 15:39:24,747 [INFO    ] __main__: train step 267: loss: 0.2311, policy_loss: 1.9650, value_loss: 1.0537
2024-07-11 15:39:24,946 [INFO    ] __main__: train step 268: loss: 0.2312, policy_loss: 1.9648, value_loss: 1.0535
2024-07-11 15:39:25,154 [INFO    ] __main__: train step 269: loss: 0.2313, policy_loss: 1.9647, value_loss: 1.0533
2024-07-11 15:39:25,367 [INFO    ] __main__: train step 270: loss: 0.2314, policy_loss: 1.9645, value_loss: 1.0531
2024-07-11 15:39:25,703 [INFO    ] __main__: train step 271: loss: 0.2315, policy_loss: 1.9643, value_loss: 1.0528
2024-07-11 15:39:27,129 [INFO    ] __main__: replay_buffer size = 12288
2024-07-11 15:39:27,200 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:39:28,395 [INFO    ] __main__: train step 272: loss: 0.2316, policy_loss: 1.9642, value_loss: 1.0526
2024-07-11 15:39:28,558 [INFO    ] __main__: train step 273: loss: 0.2318, policy_loss: 1.9640, value_loss: 1.0522
2024-07-11 15:39:28,770 [INFO    ] __main__: train step 274: loss: 0.2318, policy_loss: 1.9638, value_loss: 1.0519
2024-07-11 15:39:28,970 [INFO    ] __main__: train step 275: loss: 0.2319, policy_loss: 1.9636, value_loss: 1.0516
2024-07-11 15:39:29,207 [INFO    ] __main__: train step 276: loss: 0.2321, policy_loss: 1.9634, value_loss: 1.0515
2024-07-11 15:39:29,401 [INFO    ] __main__: train step 277: loss: 0.2322, policy_loss: 1.9633, value_loss: 1.0513
2024-07-11 15:39:29,602 [INFO    ] __main__: train step 278: loss: 0.2323, policy_loss: 1.9631, value_loss: 1.0510
2024-07-11 15:39:29,800 [INFO    ] __main__: train step 279: loss: 0.2324, policy_loss: 1.9629, value_loss: 1.0508
2024-07-11 15:39:30,009 [INFO    ] __main__: train step 280: loss: 0.2325, policy_loss: 1.9627, value_loss: 1.0505
2024-07-11 15:39:30,211 [INFO    ] __main__: train step 281: loss: 0.2326, policy_loss: 1.9625, value_loss: 1.0502
2024-07-11 15:39:30,400 [INFO    ] __main__: train step 282: loss: 0.2327, policy_loss: 1.9624, value_loss: 1.0499
2024-07-11 15:39:30,597 [INFO    ] __main__: train step 283: loss: 0.2328, policy_loss: 1.9622, value_loss: 1.0497
2024-07-11 15:39:30,937 [INFO    ] __main__: train step 284: loss: 0.2329, policy_loss: 1.9621, value_loss: 1.0493
2024-07-11 15:39:31,175 [INFO    ] __main__: train step 285: loss: 0.2330, policy_loss: 1.9619, value_loss: 1.0492
2024-07-11 15:39:31,402 [INFO    ] __main__: train step 286: loss: 0.2331, policy_loss: 1.9617, value_loss: 1.0489
2024-07-11 15:39:31,640 [INFO    ] __main__: train step 287: loss: 0.2331, policy_loss: 1.9616, value_loss: 1.0488
2024-07-11 15:39:31,864 [INFO    ] __main__: train step 288: loss: 0.2332, policy_loss: 1.9614, value_loss: 1.0487
2024-07-11 15:39:33,292 [INFO    ] __main__: replay_buffer size = 12800
2024-07-11 15:39:33,365 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:39:34,926 [INFO    ] __main__: train step 289: loss: 0.2333, policy_loss: 1.9612, value_loss: 1.0484
2024-07-11 15:39:35,109 [INFO    ] __main__: train step 290: loss: 0.2334, policy_loss: 1.9611, value_loss: 1.0482
2024-07-11 15:39:35,318 [INFO    ] __main__: train step 291: loss: 0.2335, policy_loss: 1.9609, value_loss: 1.0480
2024-07-11 15:39:35,521 [INFO    ] __main__: train step 292: loss: 0.2336, policy_loss: 1.9607, value_loss: 1.0479
2024-07-11 15:39:35,717 [INFO    ] __main__: train step 293: loss: 0.2336, policy_loss: 1.9606, value_loss: 1.0477
2024-07-11 15:39:35,918 [INFO    ] __main__: train step 294: loss: 0.2337, policy_loss: 1.9604, value_loss: 1.0475
2024-07-11 15:39:36,120 [INFO    ] __main__: train step 295: loss: 0.2338, policy_loss: 1.9603, value_loss: 1.0473
2024-07-11 15:39:36,326 [INFO    ] __main__: train step 296: loss: 0.2340, policy_loss: 1.9601, value_loss: 1.0470
2024-07-11 15:39:36,665 [INFO    ] __main__: train step 297: loss: 0.2340, policy_loss: 1.9599, value_loss: 1.0468
2024-07-11 15:39:36,871 [INFO    ] __main__: train step 298: loss: 0.2341, policy_loss: 1.9598, value_loss: 1.0465
2024-07-11 15:39:37,060 [INFO    ] __main__: train step 299: loss: 0.2342, policy_loss: 1.9596, value_loss: 1.0463
2024-07-11 15:39:37,258 [INFO    ] __main__: train step 300: loss: 0.2343, policy_loss: 1.9595, value_loss: 1.0462
2024-07-11 15:39:37,468 [INFO    ] __main__: train step 301: loss: 0.2344, policy_loss: 1.9593, value_loss: 1.0460
2024-07-11 15:39:37,670 [INFO    ] __main__: train step 302: loss: 0.2345, policy_loss: 1.9592, value_loss: 1.0457
2024-07-11 15:39:37,867 [INFO    ] __main__: train step 303: loss: 0.2346, policy_loss: 1.9590, value_loss: 1.0455
2024-07-11 15:39:38,063 [INFO    ] __main__: train step 304: loss: 0.2347, policy_loss: 1.9589, value_loss: 1.0454
2024-07-11 15:39:38,288 [INFO    ] __main__: train step 305: loss: 0.2348, policy_loss: 1.9587, value_loss: 1.0451
2024-07-11 15:39:39,730 [INFO    ] __main__: replay_buffer size = 13312
2024-07-11 15:39:39,824 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:39:41,436 [INFO    ] __main__: train step 306: loss: 0.2349, policy_loss: 1.9585, value_loss: 1.0449
2024-07-11 15:39:41,614 [INFO    ] __main__: train step 307: loss: 0.2349, policy_loss: 1.9584, value_loss: 1.0447
2024-07-11 15:39:41,833 [INFO    ] __main__: train step 308: loss: 0.2350, policy_loss: 1.9582, value_loss: 1.0445
2024-07-11 15:39:42,027 [INFO    ] __main__: train step 309: loss: 0.2351, policy_loss: 1.9580, value_loss: 1.0443
2024-07-11 15:39:42,372 [INFO    ] __main__: train step 310: loss: 0.2352, policy_loss: 1.9579, value_loss: 1.0440
2024-07-11 15:39:42,566 [INFO    ] __main__: train step 311: loss: 0.2353, policy_loss: 1.9577, value_loss: 1.0438
2024-07-11 15:39:42,762 [INFO    ] __main__: train step 312: loss: 0.2354, policy_loss: 1.9576, value_loss: 1.0436
2024-07-11 15:39:42,963 [INFO    ] __main__: train step 313: loss: 0.2355, policy_loss: 1.9574, value_loss: 1.0435
2024-07-11 15:39:43,159 [INFO    ] __main__: train step 314: loss: 0.2355, policy_loss: 1.9573, value_loss: 1.0432
2024-07-11 15:39:43,359 [INFO    ] __main__: train step 315: loss: 0.2357, policy_loss: 1.9571, value_loss: 1.0430
2024-07-11 15:39:43,555 [INFO    ] __main__: train step 316: loss: 0.2358, policy_loss: 1.9570, value_loss: 1.0428
2024-07-11 15:39:43,754 [INFO    ] __main__: train step 317: loss: 0.2359, policy_loss: 1.9568, value_loss: 1.0426
2024-07-11 15:39:43,955 [INFO    ] __main__: train step 318: loss: 0.2359, policy_loss: 1.9567, value_loss: 1.0424
2024-07-11 15:39:44,153 [INFO    ] __main__: train step 319: loss: 0.2361, policy_loss: 1.9565, value_loss: 1.0422
2024-07-11 15:39:44,347 [INFO    ] __main__: train step 320: loss: 0.2361, policy_loss: 1.9564, value_loss: 1.0420
2024-07-11 15:39:44,564 [INFO    ] __main__: train step 321: loss: 0.2362, policy_loss: 1.9562, value_loss: 1.0418
2024-07-11 15:39:44,763 [INFO    ] __main__: train step 322: loss: 0.2363, policy_loss: 1.9561, value_loss: 1.0415
2024-07-11 15:39:46,382 [INFO    ] __main__: replay_buffer size = 13824
2024-07-11 15:39:46,486 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:39:48,072 [INFO    ] __main__: train step 323: loss: 0.2364, policy_loss: 1.9559, value_loss: 1.0413
2024-07-11 15:39:48,239 [INFO    ] __main__: train step 324: loss: 0.2365, policy_loss: 1.9558, value_loss: 1.0411
2024-07-11 15:39:48,470 [INFO    ] __main__: train step 325: loss: 0.2366, policy_loss: 1.9556, value_loss: 1.0409
2024-07-11 15:39:48,676 [INFO    ] __main__: train step 326: loss: 0.2367, policy_loss: 1.9555, value_loss: 1.0408
2024-07-11 15:39:48,882 [INFO    ] __main__: train step 327: loss: 0.2367, policy_loss: 1.9553, value_loss: 1.0406
2024-07-11 15:39:49,087 [INFO    ] __main__: train step 328: loss: 0.2368, policy_loss: 1.9552, value_loss: 1.0406
2024-07-11 15:39:49,293 [INFO    ] __main__: train step 329: loss: 0.2369, policy_loss: 1.9550, value_loss: 1.0403
2024-07-11 15:39:49,497 [INFO    ] __main__: train step 330: loss: 0.2370, policy_loss: 1.9549, value_loss: 1.0401
2024-07-11 15:39:49,704 [INFO    ] __main__: train step 331: loss: 0.2371, policy_loss: 1.9547, value_loss: 1.0399
2024-07-11 15:39:49,907 [INFO    ] __main__: train step 332: loss: 0.2372, policy_loss: 1.9545, value_loss: 1.0397
2024-07-11 15:39:50,137 [INFO    ] __main__: train step 333: loss: 0.2373, policy_loss: 1.9544, value_loss: 1.0395
2024-07-11 15:39:50,328 [INFO    ] __main__: train step 334: loss: 0.2374, policy_loss: 1.9543, value_loss: 1.0393
2024-07-11 15:39:50,551 [INFO    ] __main__: train step 335: loss: 0.2375, policy_loss: 1.9541, value_loss: 1.0392
2024-07-11 15:39:50,909 [INFO    ] __main__: train step 336: loss: 0.2376, policy_loss: 1.9540, value_loss: 1.0391
2024-07-11 15:39:51,124 [INFO    ] __main__: train step 337: loss: 0.2377, policy_loss: 1.9538, value_loss: 1.0390
2024-07-11 15:39:51,341 [INFO    ] __main__: train step 338: loss: 0.2378, policy_loss: 1.9537, value_loss: 1.0389
2024-07-11 15:39:51,550 [INFO    ] __main__: train step 339: loss: 0.2379, policy_loss: 1.9536, value_loss: 1.0387
2024-07-11 15:39:52,975 [INFO    ] __main__: replay_buffer size = 14336
2024-07-11 15:39:53,076 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:39:54,271 [INFO    ] __main__: train step 340: loss: 0.2380, policy_loss: 1.9534, value_loss: 1.0385
2024-07-11 15:39:54,438 [INFO    ] __main__: train step 341: loss: 0.2381, policy_loss: 1.9533, value_loss: 1.0384
2024-07-11 15:39:54,640 [INFO    ] __main__: train step 342: loss: 0.2382, policy_loss: 1.9531, value_loss: 1.0382
2024-07-11 15:39:54,899 [INFO    ] __main__: train step 343: loss: 0.2383, policy_loss: 1.9530, value_loss: 1.0380
2024-07-11 15:39:55,104 [INFO    ] __main__: train step 344: loss: 0.2383, policy_loss: 1.9528, value_loss: 1.0378
2024-07-11 15:39:55,304 [INFO    ] __main__: train step 345: loss: 0.2384, policy_loss: 1.9527, value_loss: 1.0378
2024-07-11 15:39:55,496 [INFO    ] __main__: train step 346: loss: 0.2385, policy_loss: 1.9526, value_loss: 1.0377
2024-07-11 15:39:55,709 [INFO    ] __main__: train step 347: loss: 0.2386, policy_loss: 1.9524, value_loss: 1.0376
2024-07-11 15:39:55,920 [INFO    ] __main__: train step 348: loss: 0.2388, policy_loss: 1.9523, value_loss: 1.0374
2024-07-11 15:39:56,108 [INFO    ] __main__: train step 349: loss: 0.2388, policy_loss: 1.9521, value_loss: 1.0373
2024-07-11 15:39:56,468 [INFO    ] __main__: train step 350: loss: 0.2389, policy_loss: 1.9520, value_loss: 1.0372
2024-07-11 15:39:56,679 [INFO    ] __main__: train step 351: loss: 0.2390, policy_loss: 1.9519, value_loss: 1.0370
2024-07-11 15:39:56,866 [INFO    ] __main__: train step 352: loss: 0.2391, policy_loss: 1.9517, value_loss: 1.0368
2024-07-11 15:39:57,066 [INFO    ] __main__: train step 353: loss: 0.2392, policy_loss: 1.9516, value_loss: 1.0366
2024-07-11 15:39:57,258 [INFO    ] __main__: train step 354: loss: 0.2393, policy_loss: 1.9515, value_loss: 1.0364
2024-07-11 15:39:57,461 [INFO    ] __main__: train step 355: loss: 0.2394, policy_loss: 1.9513, value_loss: 1.0362
2024-07-11 15:39:57,670 [INFO    ] __main__: train step 356: loss: 0.2394, policy_loss: 1.9512, value_loss: 1.0361
2024-07-11 15:39:59,113 [INFO    ] __main__: replay_buffer size = 14848
2024-07-11 15:39:59,226 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:40:00,820 [INFO    ] __main__: train step 357: loss: 0.2395, policy_loss: 1.9510, value_loss: 1.0359
2024-07-11 15:40:00,982 [INFO    ] __main__: train step 358: loss: 0.2397, policy_loss: 1.9509, value_loss: 1.0357
2024-07-11 15:40:01,227 [INFO    ] __main__: train step 359: loss: 0.2398, policy_loss: 1.9508, value_loss: 1.0357
2024-07-11 15:40:01,468 [INFO    ] __main__: train step 360: loss: 0.2399, policy_loss: 1.9506, value_loss: 1.0355
2024-07-11 15:40:01,674 [INFO    ] __main__: train step 361: loss: 0.2400, policy_loss: 1.9505, value_loss: 1.0353
2024-07-11 15:40:02,118 [INFO    ] __main__: train step 362: loss: 0.2401, policy_loss: 1.9504, value_loss: 1.0351
2024-07-11 15:40:02,344 [INFO    ] __main__: train step 363: loss: 0.2402, policy_loss: 1.9502, value_loss: 1.0350
2024-07-11 15:40:02,562 [INFO    ] __main__: train step 364: loss: 0.2404, policy_loss: 1.9501, value_loss: 1.0348
2024-07-11 15:40:02,796 [INFO    ] __main__: train step 365: loss: 0.2405, policy_loss: 1.9499, value_loss: 1.0347
2024-07-11 15:40:03,105 [INFO    ] __main__: train step 366: loss: 0.2406, policy_loss: 1.9498, value_loss: 1.0345
2024-07-11 15:40:03,308 [INFO    ] __main__: train step 367: loss: 0.2407, policy_loss: 1.9496, value_loss: 1.0343
2024-07-11 15:40:03,502 [INFO    ] __main__: train step 368: loss: 0.2408, policy_loss: 1.9495, value_loss: 1.0342
2024-07-11 15:40:03,714 [INFO    ] __main__: train step 369: loss: 0.2409, policy_loss: 1.9494, value_loss: 1.0339
2024-07-11 15:40:03,910 [INFO    ] __main__: train step 370: loss: 0.2410, policy_loss: 1.9493, value_loss: 1.0337
2024-07-11 15:40:04,105 [INFO    ] __main__: train step 371: loss: 0.2411, policy_loss: 1.9491, value_loss: 1.0335
2024-07-11 15:40:04,309 [INFO    ] __main__: train step 372: loss: 0.2412, policy_loss: 1.9490, value_loss: 1.0333
2024-07-11 15:40:04,548 [INFO    ] __main__: train step 373: loss: 0.2413, policy_loss: 1.9489, value_loss: 1.0331
2024-07-11 15:40:05,989 [INFO    ] __main__: replay_buffer size = 15360
2024-07-11 15:40:06,098 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:40:07,702 [INFO    ] __main__: train step 374: loss: 0.2414, policy_loss: 1.9487, value_loss: 1.0329
2024-07-11 15:40:07,880 [INFO    ] __main__: train step 375: loss: 0.2416, policy_loss: 1.9486, value_loss: 1.0328
2024-07-11 15:40:08,259 [INFO    ] __main__: train step 376: loss: 0.2417, policy_loss: 1.9484, value_loss: 1.0325
2024-07-11 15:40:08,474 [INFO    ] __main__: train step 377: loss: 0.2418, policy_loss: 1.9483, value_loss: 1.0324
2024-07-11 15:40:08,711 [INFO    ] __main__: train step 378: loss: 0.2419, policy_loss: 1.9482, value_loss: 1.0322
2024-07-11 15:40:08,912 [INFO    ] __main__: train step 379: loss: 0.2420, policy_loss: 1.9481, value_loss: 1.0321
2024-07-11 15:40:09,118 [INFO    ] __main__: train step 380: loss: 0.2420, policy_loss: 1.9479, value_loss: 1.0318
2024-07-11 15:40:09,309 [INFO    ] __main__: train step 381: loss: 0.2422, policy_loss: 1.9478, value_loss: 1.0316
2024-07-11 15:40:09,516 [INFO    ] __main__: train step 382: loss: 0.2423, policy_loss: 1.9477, value_loss: 1.0316
2024-07-11 15:40:09,708 [INFO    ] __main__: train step 383: loss: 0.2424, policy_loss: 1.9475, value_loss: 1.0315
2024-07-11 15:40:09,912 [INFO    ] __main__: train step 384: loss: 0.2425, policy_loss: 1.9474, value_loss: 1.0313
2024-07-11 15:40:10,112 [INFO    ] __main__: train step 385: loss: 0.2426, policy_loss: 1.9473, value_loss: 1.0310
2024-07-11 15:40:10,312 [INFO    ] __main__: train step 386: loss: 0.2427, policy_loss: 1.9471, value_loss: 1.0309
2024-07-11 15:40:10,512 [INFO    ] __main__: train step 387: loss: 0.2427, policy_loss: 1.9470, value_loss: 1.0308
2024-07-11 15:40:10,726 [INFO    ] __main__: train step 388: loss: 0.2428, policy_loss: 1.9469, value_loss: 1.0307
2024-07-11 15:40:11,091 [INFO    ] __main__: train step 389: loss: 0.2430, policy_loss: 1.9468, value_loss: 1.0306
2024-07-11 15:40:11,272 [INFO    ] __main__: train step 390: loss: 0.2431, policy_loss: 1.9466, value_loss: 1.0305
2024-07-11 15:40:12,755 [INFO    ] __main__: replay_buffer size = 15872
2024-07-11 15:40:12,869 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:40:14,463 [INFO    ] __main__: train step 391: loss: 0.2432, policy_loss: 1.9465, value_loss: 1.0304
2024-07-11 15:40:14,628 [INFO    ] __main__: train step 392: loss: 0.2433, policy_loss: 1.9464, value_loss: 1.0302
2024-07-11 15:40:14,850 [INFO    ] __main__: train step 393: loss: 0.2434, policy_loss: 1.9462, value_loss: 1.0301
2024-07-11 15:40:15,044 [INFO    ] __main__: train step 394: loss: 0.2435, policy_loss: 1.9461, value_loss: 1.0300
2024-07-11 15:40:15,249 [INFO    ] __main__: train step 395: loss: 0.2436, policy_loss: 1.9460, value_loss: 1.0299
2024-07-11 15:40:15,457 [INFO    ] __main__: train step 396: loss: 0.2437, policy_loss: 1.9459, value_loss: 1.0297
2024-07-11 15:40:15,660 [INFO    ] __main__: train step 397: loss: 0.2438, policy_loss: 1.9457, value_loss: 1.0296
2024-07-11 15:40:15,852 [INFO    ] __main__: train step 398: loss: 0.2439, policy_loss: 1.9456, value_loss: 1.0294
2024-07-11 15:40:16,055 [INFO    ] __main__: train step 399: loss: 0.2440, policy_loss: 1.9455, value_loss: 1.0293
2024-07-11 15:40:16,254 [INFO    ] __main__: train step 400: loss: 0.2441, policy_loss: 1.9454, value_loss: 1.0292
2024-07-11 15:40:16,462 [INFO    ] __main__: train step 401: loss: 0.2442, policy_loss: 1.9453, value_loss: 1.0289
2024-07-11 15:40:16,800 [INFO    ] __main__: train step 402: loss: 0.2444, policy_loss: 1.9451, value_loss: 1.0287
2024-07-11 15:40:17,011 [INFO    ] __main__: train step 403: loss: 0.2444, policy_loss: 1.9450, value_loss: 1.0286
2024-07-11 15:40:17,212 [INFO    ] __main__: train step 404: loss: 0.2445, policy_loss: 1.9449, value_loss: 1.0284
2024-07-11 15:40:17,413 [INFO    ] __main__: train step 405: loss: 0.2446, policy_loss: 1.9448, value_loss: 1.0283
2024-07-11 15:40:17,627 [INFO    ] __main__: train step 406: loss: 0.2447, policy_loss: 1.9446, value_loss: 1.0281
2024-07-11 15:40:17,825 [INFO    ] __main__: train step 407: loss: 0.2448, policy_loss: 1.9445, value_loss: 1.0280
2024-07-11 15:40:19,256 [INFO    ] __main__: replay_buffer size = 16384
2024-07-11 15:40:19,346 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:40:20,492 [INFO    ] __main__: train step 408: loss: 0.2449, policy_loss: 1.9444, value_loss: 1.0278
2024-07-11 15:40:20,665 [INFO    ] __main__: train step 409: loss: 0.2450, policy_loss: 1.9443, value_loss: 1.0277
2024-07-11 15:40:20,864 [INFO    ] __main__: train step 410: loss: 0.2451, policy_loss: 1.9441, value_loss: 1.0276
2024-07-11 15:40:21,067 [INFO    ] __main__: train step 411: loss: 0.2453, policy_loss: 1.9440, value_loss: 1.0275
2024-07-11 15:40:21,268 [INFO    ] __main__: train step 412: loss: 0.2454, policy_loss: 1.9439, value_loss: 1.0273
2024-07-11 15:40:21,473 [INFO    ] __main__: train step 413: loss: 0.2455, policy_loss: 1.9438, value_loss: 1.0272
2024-07-11 15:40:21,676 [INFO    ] __main__: train step 414: loss: 0.2456, policy_loss: 1.9437, value_loss: 1.0271
2024-07-11 15:40:21,878 [INFO    ] __main__: train step 415: loss: 0.2457, policy_loss: 1.9435, value_loss: 1.0270
2024-07-11 15:40:22,229 [INFO    ] __main__: train step 416: loss: 0.2458, policy_loss: 1.9434, value_loss: 1.0268
2024-07-11 15:40:22,455 [INFO    ] __main__: train step 417: loss: 0.2459, policy_loss: 1.9433, value_loss: 1.0267
2024-07-11 15:40:22,650 [INFO    ] __main__: train step 418: loss: 0.2460, policy_loss: 1.9432, value_loss: 1.0266
2024-07-11 15:40:22,854 [INFO    ] __main__: train step 419: loss: 0.2462, policy_loss: 1.9430, value_loss: 1.0264
2024-07-11 15:40:23,063 [INFO    ] __main__: train step 420: loss: 0.2463, policy_loss: 1.9429, value_loss: 1.0262
2024-07-11 15:40:23,264 [INFO    ] __main__: train step 421: loss: 0.2464, policy_loss: 1.9428, value_loss: 1.0261
2024-07-11 15:40:23,468 [INFO    ] __main__: train step 422: loss: 0.2466, policy_loss: 1.9427, value_loss: 1.0260
2024-07-11 15:40:23,676 [INFO    ] __main__: train step 423: loss: 0.2467, policy_loss: 1.9426, value_loss: 1.0259
2024-07-11 15:40:23,915 [INFO    ] __main__: train step 424: loss: 0.2469, policy_loss: 1.9425, value_loss: 1.0258
2024-07-11 15:40:25,333 [INFO    ] __main__: replay_buffer size = 16896
2024-07-11 15:40:25,453 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:40:27,074 [INFO    ] __main__: train step 425: loss: 0.2469, policy_loss: 1.9424, value_loss: 1.0257
2024-07-11 15:40:27,240 [INFO    ] __main__: train step 426: loss: 0.2471, policy_loss: 1.9423, value_loss: 1.0256
2024-07-11 15:40:27,468 [INFO    ] __main__: train step 427: loss: 0.2472, policy_loss: 1.9421, value_loss: 1.0255
2024-07-11 15:40:27,673 [INFO    ] __main__: train step 428: loss: 0.2473, policy_loss: 1.9420, value_loss: 1.0254
2024-07-11 15:40:28,033 [INFO    ] __main__: train step 429: loss: 0.2474, policy_loss: 1.9419, value_loss: 1.0254
2024-07-11 15:40:28,234 [INFO    ] __main__: train step 430: loss: 0.2475, policy_loss: 1.9418, value_loss: 1.0253
2024-07-11 15:40:28,432 [INFO    ] __main__: train step 431: loss: 0.2477, policy_loss: 1.9417, value_loss: 1.0252
2024-07-11 15:40:28,642 [INFO    ] __main__: train step 432: loss: 0.2478, policy_loss: 1.9415, value_loss: 1.0251
2024-07-11 15:40:28,856 [INFO    ] __main__: train step 433: loss: 0.2479, policy_loss: 1.9414, value_loss: 1.0250
2024-07-11 15:40:29,079 [INFO    ] __main__: train step 434: loss: 0.2481, policy_loss: 1.9413, value_loss: 1.0248
2024-07-11 15:40:29,284 [INFO    ] __main__: train step 435: loss: 0.2482, policy_loss: 1.9412, value_loss: 1.0246
2024-07-11 15:40:29,481 [INFO    ] __main__: train step 436: loss: 0.2483, policy_loss: 1.9411, value_loss: 1.0244
2024-07-11 15:40:29,680 [INFO    ] __main__: train step 437: loss: 0.2484, policy_loss: 1.9409, value_loss: 1.0243
2024-07-11 15:40:29,878 [INFO    ] __main__: train step 438: loss: 0.2485, policy_loss: 1.9408, value_loss: 1.0241
2024-07-11 15:40:30,074 [INFO    ] __main__: train step 439: loss: 0.2486, policy_loss: 1.9407, value_loss: 1.0240
2024-07-11 15:40:30,278 [INFO    ] __main__: train step 440: loss: 0.2487, policy_loss: 1.9406, value_loss: 1.0240
2024-07-11 15:40:30,462 [INFO    ] __main__: train step 441: loss: 0.2488, policy_loss: 1.9405, value_loss: 1.0239
2024-07-11 15:40:31,891 [INFO    ] __main__: replay_buffer size = 17408
2024-07-11 15:40:32,012 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:40:33,804 [INFO    ] __main__: train step 442: loss: 0.2489, policy_loss: 1.9404, value_loss: 1.0237
2024-07-11 15:40:33,982 [INFO    ] __main__: train step 443: loss: 0.2490, policy_loss: 1.9402, value_loss: 1.0236
2024-07-11 15:40:34,186 [INFO    ] __main__: train step 444: loss: 0.2492, policy_loss: 1.9401, value_loss: 1.0235
2024-07-11 15:40:34,388 [INFO    ] __main__: train step 445: loss: 0.2493, policy_loss: 1.9400, value_loss: 1.0234
2024-07-11 15:40:34,597 [INFO    ] __main__: train step 446: loss: 0.2494, policy_loss: 1.9399, value_loss: 1.0233
2024-07-11 15:40:34,811 [INFO    ] __main__: train step 447: loss: 0.2494, policy_loss: 1.9398, value_loss: 1.0232
2024-07-11 15:40:35,003 [INFO    ] __main__: train step 448: loss: 0.2496, policy_loss: 1.9397, value_loss: 1.0231
2024-07-11 15:40:35,212 [INFO    ] __main__: train step 449: loss: 0.2496, policy_loss: 1.9396, value_loss: 1.0230
2024-07-11 15:40:35,417 [INFO    ] __main__: train step 450: loss: 0.2497, policy_loss: 1.9394, value_loss: 1.0228
2024-07-11 15:40:35,627 [INFO    ] __main__: train step 451: loss: 0.2499, policy_loss: 1.9393, value_loss: 1.0228
2024-07-11 15:40:35,825 [INFO    ] __main__: train step 452: loss: 0.2499, policy_loss: 1.9392, value_loss: 1.0226
2024-07-11 15:40:36,031 [INFO    ] __main__: train step 453: loss: 0.2500, policy_loss: 1.9391, value_loss: 1.0225
2024-07-11 15:40:36,235 [INFO    ] __main__: train step 454: loss: 0.2502, policy_loss: 1.9390, value_loss: 1.0224
2024-07-11 15:40:36,432 [INFO    ] __main__: train step 455: loss: 0.2503, policy_loss: 1.9389, value_loss: 1.0222
2024-07-11 15:40:36,793 [INFO    ] __main__: train step 456: loss: 0.2504, policy_loss: 1.9388, value_loss: 1.0221
2024-07-11 15:40:36,988 [INFO    ] __main__: train step 457: loss: 0.2505, policy_loss: 1.9387, value_loss: 1.0219
2024-07-11 15:40:37,193 [INFO    ] __main__: train step 458: loss: 0.2507, policy_loss: 1.9386, value_loss: 1.0218
2024-07-11 15:40:38,647 [INFO    ] __main__: replay_buffer size = 17920
2024-07-11 15:40:38,770 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:40:40,431 [INFO    ] __main__: train step 459: loss: 0.2508, policy_loss: 1.9385, value_loss: 1.0217
2024-07-11 15:40:40,603 [INFO    ] __main__: train step 460: loss: 0.2509, policy_loss: 1.9384, value_loss: 1.0215
2024-07-11 15:40:40,832 [INFO    ] __main__: train step 461: loss: 0.2510, policy_loss: 1.9383, value_loss: 1.0215
2024-07-11 15:40:41,033 [INFO    ] __main__: train step 462: loss: 0.2511, policy_loss: 1.9381, value_loss: 1.0213
2024-07-11 15:40:41,230 [INFO    ] __main__: train step 463: loss: 0.2512, policy_loss: 1.9380, value_loss: 1.0212
2024-07-11 15:40:41,426 [INFO    ] __main__: train step 464: loss: 0.2513, policy_loss: 1.9379, value_loss: 1.0211
2024-07-11 15:40:41,639 [INFO    ] __main__: train step 465: loss: 0.2514, policy_loss: 1.9378, value_loss: 1.0209
2024-07-11 15:40:41,844 [INFO    ] __main__: train step 466: loss: 0.2515, policy_loss: 1.9377, value_loss: 1.0209
2024-07-11 15:40:42,040 [INFO    ] __main__: train step 467: loss: 0.2516, policy_loss: 1.9376, value_loss: 1.0208
2024-07-11 15:40:42,255 [INFO    ] __main__: train step 468: loss: 0.2517, policy_loss: 1.9375, value_loss: 1.0207
2024-07-11 15:40:42,603 [INFO    ] __main__: train step 469: loss: 0.2518, policy_loss: 1.9374, value_loss: 1.0207
2024-07-11 15:40:42,811 [INFO    ] __main__: train step 470: loss: 0.2519, policy_loss: 1.9373, value_loss: 1.0206
2024-07-11 15:40:43,016 [INFO    ] __main__: train step 471: loss: 0.2520, policy_loss: 1.9372, value_loss: 1.0205
2024-07-11 15:40:43,218 [INFO    ] __main__: train step 472: loss: 0.2521, policy_loss: 1.9371, value_loss: 1.0204
2024-07-11 15:40:43,423 [INFO    ] __main__: train step 473: loss: 0.2522, policy_loss: 1.9370, value_loss: 1.0203
2024-07-11 15:40:43,623 [INFO    ] __main__: train step 474: loss: 0.2523, policy_loss: 1.9369, value_loss: 1.0202
2024-07-11 15:40:43,837 [INFO    ] __main__: train step 475: loss: 0.2524, policy_loss: 1.9367, value_loss: 1.0201
2024-07-11 15:40:45,310 [INFO    ] __main__: replay_buffer size = 18432
2024-07-11 15:40:45,408 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:40:46,595 [INFO    ] __main__: train step 476: loss: 0.2525, policy_loss: 1.9367, value_loss: 1.0200
2024-07-11 15:40:46,781 [INFO    ] __main__: train step 477: loss: 0.2526, policy_loss: 1.9366, value_loss: 1.0199
2024-07-11 15:40:46,983 [INFO    ] __main__: train step 478: loss: 0.2527, policy_loss: 1.9364, value_loss: 1.0197
2024-07-11 15:40:47,187 [INFO    ] __main__: train step 479: loss: 0.2529, policy_loss: 1.9363, value_loss: 1.0196
2024-07-11 15:40:47,381 [INFO    ] __main__: train step 480: loss: 0.2530, policy_loss: 1.9362, value_loss: 1.0196
2024-07-11 15:40:47,580 [INFO    ] __main__: train step 481: loss: 0.2531, policy_loss: 1.9361, value_loss: 1.0194
2024-07-11 15:40:47,787 [INFO    ] __main__: train step 482: loss: 0.2533, policy_loss: 1.9360, value_loss: 1.0193
2024-07-11 15:40:48,183 [INFO    ] __main__: train step 483: loss: 0.2533, policy_loss: 1.9359, value_loss: 1.0192
2024-07-11 15:40:48,377 [INFO    ] __main__: train step 484: loss: 0.2535, policy_loss: 1.9358, value_loss: 1.0191
2024-07-11 15:40:48,579 [INFO    ] __main__: train step 485: loss: 0.2536, policy_loss: 1.9357, value_loss: 1.0190
2024-07-11 15:40:48,789 [INFO    ] __main__: train step 486: loss: 0.2537, policy_loss: 1.9356, value_loss: 1.0189
2024-07-11 15:40:48,999 [INFO    ] __main__: train step 487: loss: 0.2538, policy_loss: 1.9355, value_loss: 1.0188
2024-07-11 15:40:49,199 [INFO    ] __main__: train step 488: loss: 0.2539, policy_loss: 1.9354, value_loss: 1.0186
2024-07-11 15:40:49,397 [INFO    ] __main__: train step 489: loss: 0.2540, policy_loss: 1.9353, value_loss: 1.0185
2024-07-11 15:40:49,600 [INFO    ] __main__: train step 490: loss: 0.2541, policy_loss: 1.9352, value_loss: 1.0185
2024-07-11 15:40:49,824 [INFO    ] __main__: train step 491: loss: 0.2542, policy_loss: 1.9351, value_loss: 1.0184
2024-07-11 15:40:50,021 [INFO    ] __main__: train step 492: loss: 0.2543, policy_loss: 1.9351, value_loss: 1.0183
2024-07-11 15:40:51,465 [INFO    ] __main__: replay_buffer size = 18944
2024-07-11 15:40:51,597 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:40:53,270 [INFO    ] __main__: train step 493: loss: 0.2544, policy_loss: 1.9350, value_loss: 1.0183
2024-07-11 15:40:53,443 [INFO    ] __main__: train step 494: loss: 0.2546, policy_loss: 1.9349, value_loss: 1.0181
2024-07-11 15:40:53,660 [INFO    ] __main__: train step 495: loss: 0.2547, policy_loss: 1.9348, value_loss: 1.0180
2024-07-11 15:40:54,008 [INFO    ] __main__: train step 496: loss: 0.2548, policy_loss: 1.9347, value_loss: 1.0180
2024-07-11 15:40:54,224 [INFO    ] __main__: train step 497: loss: 0.2549, policy_loss: 1.9346, value_loss: 1.0179
2024-07-11 15:40:54,424 [INFO    ] __main__: train step 498: loss: 0.2550, policy_loss: 1.9345, value_loss: 1.0178
2024-07-11 15:40:54,625 [INFO    ] __main__: train step 499: loss: 0.2551, policy_loss: 1.9344, value_loss: 1.0177
2024-07-11 15:40:54,834 [INFO    ] __main__: train step 500: loss: 0.2553, policy_loss: 1.9343, value_loss: 1.0176
2024-07-11 15:40:55,029 [INFO    ] __main__: train step 501: loss: 0.2554, policy_loss: 1.9342, value_loss: 1.0175
2024-07-11 15:40:55,240 [INFO    ] __main__: train step 502: loss: 0.2556, policy_loss: 1.9341, value_loss: 1.0174
2024-07-11 15:40:55,479 [INFO    ] __main__: train step 503: loss: 0.2557, policy_loss: 1.9340, value_loss: 1.0173
2024-07-11 15:40:55,718 [INFO    ] __main__: train step 504: loss: 0.2558, policy_loss: 1.9339, value_loss: 1.0172
2024-07-11 15:40:55,924 [INFO    ] __main__: train step 505: loss: 0.2559, policy_loss: 1.9338, value_loss: 1.0171
2024-07-11 15:40:56,146 [INFO    ] __main__: train step 506: loss: 0.2561, policy_loss: 1.9337, value_loss: 1.0170
2024-07-11 15:40:56,350 [INFO    ] __main__: train step 507: loss: 0.2562, policy_loss: 1.9336, value_loss: 1.0169
2024-07-11 15:40:56,552 [INFO    ] __main__: train step 508: loss: 0.2563, policy_loss: 1.9335, value_loss: 1.0169
2024-07-11 15:40:56,747 [INFO    ] __main__: train step 509: loss: 0.2564, policy_loss: 1.9334, value_loss: 1.0168
2024-07-11 15:40:58,213 [INFO    ] __main__: replay_buffer size = 19456
2024-07-11 15:40:58,333 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:41:00,146 [INFO    ] __main__: train step 510: loss: 0.2566, policy_loss: 1.9333, value_loss: 1.0166
2024-07-11 15:41:00,321 [INFO    ] __main__: train step 511: loss: 0.2567, policy_loss: 1.9332, value_loss: 1.0165
2024-07-11 15:41:00,514 [INFO    ] __main__: train step 512: loss: 0.2568, policy_loss: 1.9330, value_loss: 1.0164
2024-07-11 15:41:00,722 [INFO    ] __main__: train step 513: loss: 0.2569, policy_loss: 1.9329, value_loss: 1.0163
2024-07-11 15:41:00,907 [INFO    ] __main__: train step 514: loss: 0.2571, policy_loss: 1.9328, value_loss: 1.0163
2024-07-11 15:41:01,109 [INFO    ] __main__: train step 515: loss: 0.2572, policy_loss: 1.9327, value_loss: 1.0162
2024-07-11 15:41:01,311 [INFO    ] __main__: train step 516: loss: 0.2573, policy_loss: 1.9326, value_loss: 1.0161
2024-07-11 15:41:01,521 [INFO    ] __main__: train step 517: loss: 0.2574, policy_loss: 1.9325, value_loss: 1.0160
2024-07-11 15:41:01,728 [INFO    ] __main__: train step 518: loss: 0.2576, policy_loss: 1.9324, value_loss: 1.0159
2024-07-11 15:41:01,958 [INFO    ] __main__: train step 519: loss: 0.2577, policy_loss: 1.9323, value_loss: 1.0159
2024-07-11 15:41:02,161 [INFO    ] __main__: train step 520: loss: 0.2578, policy_loss: 1.9322, value_loss: 1.0158
2024-07-11 15:41:02,360 [INFO    ] __main__: train step 521: loss: 0.2579, policy_loss: 1.9321, value_loss: 1.0157
2024-07-11 15:41:02,556 [INFO    ] __main__: train step 522: loss: 0.2580, policy_loss: 1.9321, value_loss: 1.0156
2024-07-11 15:41:02,752 [INFO    ] __main__: train step 523: loss: 0.2582, policy_loss: 1.9320, value_loss: 1.0155
2024-07-11 15:41:03,112 [INFO    ] __main__: train step 524: loss: 0.2583, policy_loss: 1.9319, value_loss: 1.0154
2024-07-11 15:41:03,303 [INFO    ] __main__: train step 525: loss: 0.2584, policy_loss: 1.9318, value_loss: 1.0154
2024-07-11 15:41:03,500 [INFO    ] __main__: train step 526: loss: 0.2586, policy_loss: 1.9317, value_loss: 1.0153
2024-07-11 15:41:05,017 [INFO    ] __main__: replay_buffer size = 19968
2024-07-11 15:41:05,113 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:41:06,759 [INFO    ] __main__: train step 527: loss: 0.2587, policy_loss: 1.9316, value_loss: 1.0152
2024-07-11 15:41:06,934 [INFO    ] __main__: train step 528: loss: 0.2588, policy_loss: 1.9315, value_loss: 1.0151
2024-07-11 15:41:07,153 [INFO    ] __main__: train step 529: loss: 0.2590, policy_loss: 1.9314, value_loss: 1.0150
2024-07-11 15:41:07,358 [INFO    ] __main__: train step 530: loss: 0.2591, policy_loss: 1.9313, value_loss: 1.0149
2024-07-11 15:41:07,565 [INFO    ] __main__: train step 531: loss: 0.2592, policy_loss: 1.9312, value_loss: 1.0147
2024-07-11 15:41:07,784 [INFO    ] __main__: train step 532: loss: 0.2594, policy_loss: 1.9311, value_loss: 1.0146
2024-07-11 15:41:08,022 [INFO    ] __main__: train step 533: loss: 0.2595, policy_loss: 1.9310, value_loss: 1.0145
2024-07-11 15:41:08,224 [INFO    ] __main__: train step 534: loss: 0.2596, policy_loss: 1.9309, value_loss: 1.0144
2024-07-11 15:41:08,471 [INFO    ] __main__: train step 535: loss: 0.2597, policy_loss: 1.9308, value_loss: 1.0143
2024-07-11 15:41:08,702 [INFO    ] __main__: train step 536: loss: 0.2599, policy_loss: 1.9307, value_loss: 1.0142
2024-07-11 15:41:09,056 [INFO    ] __main__: train step 537: loss: 0.2600, policy_loss: 1.9306, value_loss: 1.0141
2024-07-11 15:41:09,269 [INFO    ] __main__: train step 538: loss: 0.2601, policy_loss: 1.9305, value_loss: 1.0141
2024-07-11 15:41:09,470 [INFO    ] __main__: train step 539: loss: 0.2602, policy_loss: 1.9304, value_loss: 1.0140
2024-07-11 15:41:09,666 [INFO    ] __main__: train step 540: loss: 0.2604, policy_loss: 1.9303, value_loss: 1.0140
2024-07-11 15:41:09,878 [INFO    ] __main__: train step 541: loss: 0.2605, policy_loss: 1.9302, value_loss: 1.0139
2024-07-11 15:41:10,078 [INFO    ] __main__: train step 542: loss: 0.2606, policy_loss: 1.9301, value_loss: 1.0139
2024-07-11 15:41:10,314 [INFO    ] __main__: train step 543: loss: 0.2608, policy_loss: 1.9300, value_loss: 1.0138
2024-07-11 15:41:11,803 [INFO    ] __main__: replay_buffer size = 20480
2024-07-11 15:41:11,937 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:41:13,107 [INFO    ] __main__: train step 544: loss: 0.2609, policy_loss: 1.9300, value_loss: 1.0138
2024-07-11 15:41:13,278 [INFO    ] __main__: train step 545: loss: 0.2610, policy_loss: 1.9299, value_loss: 1.0138
2024-07-11 15:41:13,483 [INFO    ] __main__: train step 546: loss: 0.2611, policy_loss: 1.9298, value_loss: 1.0137
2024-07-11 15:41:13,692 [INFO    ] __main__: train step 547: loss: 0.2613, policy_loss: 1.9297, value_loss: 1.0136
2024-07-11 15:41:13,890 [INFO    ] __main__: train step 548: loss: 0.2614, policy_loss: 1.9296, value_loss: 1.0136
2024-07-11 15:41:14,093 [INFO    ] __main__: train step 549: loss: 0.2615, policy_loss: 1.9295, value_loss: 1.0135
2024-07-11 15:41:14,308 [INFO    ] __main__: train step 550: loss: 0.2616, policy_loss: 1.9294, value_loss: 1.0135
2024-07-11 15:41:14,687 [INFO    ] __main__: train step 551: loss: 0.2618, policy_loss: 1.9293, value_loss: 1.0134
2024-07-11 15:41:14,891 [INFO    ] __main__: train step 552: loss: 0.2619, policy_loss: 1.9292, value_loss: 1.0133
2024-07-11 15:41:15,110 [INFO    ] __main__: train step 553: loss: 0.2620, policy_loss: 1.9291, value_loss: 1.0132
2024-07-11 15:41:15,291 [INFO    ] __main__: train step 554: loss: 0.2621, policy_loss: 1.9290, value_loss: 1.0132
2024-07-11 15:41:15,498 [INFO    ] __main__: train step 555: loss: 0.2623, policy_loss: 1.9290, value_loss: 1.0132
2024-07-11 15:41:15,700 [INFO    ] __main__: train step 556: loss: 0.2624, policy_loss: 1.9289, value_loss: 1.0131
2024-07-11 15:41:15,919 [INFO    ] __main__: train step 557: loss: 0.2625, policy_loss: 1.9288, value_loss: 1.0131
2024-07-11 15:41:16,121 [INFO    ] __main__: train step 558: loss: 0.2627, policy_loss: 1.9287, value_loss: 1.0130
2024-07-11 15:41:16,313 [INFO    ] __main__: train step 559: loss: 0.2628, policy_loss: 1.9286, value_loss: 1.0130
2024-07-11 15:41:16,510 [INFO    ] __main__: train step 560: loss: 0.2630, policy_loss: 1.9285, value_loss: 1.0129
2024-07-11 15:41:18,005 [INFO    ] __main__: replay_buffer size = 20992
2024-07-11 15:41:18,111 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:41:19,771 [INFO    ] __main__: train step 561: loss: 0.2631, policy_loss: 1.9284, value_loss: 1.0128
2024-07-11 15:41:19,937 [INFO    ] __main__: train step 562: loss: 0.2632, policy_loss: 1.9283, value_loss: 1.0127
2024-07-11 15:41:20,155 [INFO    ] __main__: train step 563: loss: 0.2633, policy_loss: 1.9282, value_loss: 1.0128
2024-07-11 15:41:20,525 [INFO    ] __main__: train step 564: loss: 0.2635, policy_loss: 1.9281, value_loss: 1.0127
2024-07-11 15:41:20,730 [INFO    ] __main__: train step 565: loss: 0.2636, policy_loss: 1.9280, value_loss: 1.0127
2024-07-11 15:41:20,948 [INFO    ] __main__: train step 566: loss: 0.2637, policy_loss: 1.9279, value_loss: 1.0126
2024-07-11 15:41:21,172 [INFO    ] __main__: train step 567: loss: 0.2639, policy_loss: 1.9278, value_loss: 1.0126
2024-07-11 15:41:21,368 [INFO    ] __main__: train step 568: loss: 0.2640, policy_loss: 1.9277, value_loss: 1.0126
2024-07-11 15:41:21,565 [INFO    ] __main__: train step 569: loss: 0.2641, policy_loss: 1.9277, value_loss: 1.0126
2024-07-11 15:41:21,766 [INFO    ] __main__: train step 570: loss: 0.2643, policy_loss: 1.9276, value_loss: 1.0126
2024-07-11 15:41:21,965 [INFO    ] __main__: train step 571: loss: 0.2644, policy_loss: 1.9275, value_loss: 1.0126
2024-07-11 15:41:22,163 [INFO    ] __main__: train step 572: loss: 0.2645, policy_loss: 1.9274, value_loss: 1.0126
2024-07-11 15:41:22,370 [INFO    ] __main__: train step 573: loss: 0.2646, policy_loss: 1.9273, value_loss: 1.0126
2024-07-11 15:41:22,580 [INFO    ] __main__: train step 574: loss: 0.2648, policy_loss: 1.9272, value_loss: 1.0125
2024-07-11 15:41:22,780 [INFO    ] __main__: train step 575: loss: 0.2649, policy_loss: 1.9271, value_loss: 1.0124
2024-07-11 15:41:22,982 [INFO    ] __main__: train step 576: loss: 0.2651, policy_loss: 1.9270, value_loss: 1.0124
2024-07-11 15:41:23,185 [INFO    ] __main__: train step 577: loss: 0.2652, policy_loss: 1.9269, value_loss: 1.0123
2024-07-11 15:41:24,862 [INFO    ] __main__: replay_buffer size = 21504
2024-07-11 15:41:24,999 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:41:26,655 [INFO    ] __main__: train step 578: loss: 0.2653, policy_loss: 1.9268, value_loss: 1.0122
2024-07-11 15:41:26,823 [INFO    ] __main__: train step 579: loss: 0.2654, policy_loss: 1.9268, value_loss: 1.0122
2024-07-11 15:41:27,042 [INFO    ] __main__: train step 580: loss: 0.2656, policy_loss: 1.9267, value_loss: 1.0121
2024-07-11 15:41:27,251 [INFO    ] __main__: train step 581: loss: 0.2657, policy_loss: 1.9266, value_loss: 1.0121
2024-07-11 15:41:27,481 [INFO    ] __main__: train step 582: loss: 0.2658, policy_loss: 1.9265, value_loss: 1.0121
2024-07-11 15:41:27,678 [INFO    ] __main__: train step 583: loss: 0.2659, policy_loss: 1.9264, value_loss: 1.0121
2024-07-11 15:41:27,889 [INFO    ] __main__: train step 584: loss: 0.2660, policy_loss: 1.9263, value_loss: 1.0120
2024-07-11 15:41:28,095 [INFO    ] __main__: train step 585: loss: 0.2661, policy_loss: 1.9262, value_loss: 1.0120
2024-07-11 15:41:28,308 [INFO    ] __main__: train step 586: loss: 0.2663, policy_loss: 1.9261, value_loss: 1.0119
2024-07-11 15:41:28,519 [INFO    ] __main__: train step 587: loss: 0.2664, policy_loss: 1.9260, value_loss: 1.0119
2024-07-11 15:41:28,713 [INFO    ] __main__: train step 588: loss: 0.2665, policy_loss: 1.9260, value_loss: 1.0118
2024-07-11 15:41:28,924 [INFO    ] __main__: train step 589: loss: 0.2667, policy_loss: 1.9259, value_loss: 1.0117
2024-07-11 15:41:29,137 [INFO    ] __main__: train step 590: loss: 0.2668, policy_loss: 1.9258, value_loss: 1.0117
2024-07-11 15:41:29,351 [INFO    ] __main__: train step 591: loss: 0.2669, policy_loss: 1.9257, value_loss: 1.0116
2024-07-11 15:41:29,730 [INFO    ] __main__: train step 592: loss: 0.2670, policy_loss: 1.9256, value_loss: 1.0116
2024-07-11 15:41:29,899 [INFO    ] __main__: train step 593: loss: 0.2672, policy_loss: 1.9255, value_loss: 1.0116
2024-07-11 15:41:30,116 [INFO    ] __main__: train step 594: loss: 0.2673, policy_loss: 1.9254, value_loss: 1.0115
2024-07-11 15:41:31,549 [INFO    ] __main__: replay_buffer size = 22016
2024-07-11 15:41:31,666 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:41:33,368 [INFO    ] __main__: train step 595: loss: 0.2674, policy_loss: 1.9253, value_loss: 1.0114
2024-07-11 15:41:33,535 [INFO    ] __main__: train step 596: loss: 0.2675, policy_loss: 1.9252, value_loss: 1.0114
2024-07-11 15:41:33,741 [INFO    ] __main__: train step 597: loss: 0.2677, policy_loss: 1.9252, value_loss: 1.0113
2024-07-11 15:41:33,927 [INFO    ] __main__: train step 598: loss: 0.2678, policy_loss: 1.9251, value_loss: 1.0112
2024-07-11 15:41:34,118 [INFO    ] __main__: train step 599: loss: 0.2680, policy_loss: 1.9250, value_loss: 1.0112
2024-07-11 15:41:34,388 [INFO    ] __main__: train step 600: loss: 0.2681, policy_loss: 1.9249, value_loss: 1.0111
2024-07-11 15:41:34,608 [INFO    ] __main__: train step 601: loss: 0.2682, policy_loss: 1.9249, value_loss: 1.0110
2024-07-11 15:41:34,803 [INFO    ] __main__: train step 602: loss: 0.2683, policy_loss: 1.9248, value_loss: 1.0110
2024-07-11 15:41:35,034 [INFO    ] __main__: train step 603: loss: 0.2685, policy_loss: 1.9247, value_loss: 1.0110
2024-07-11 15:41:35,236 [INFO    ] __main__: train step 604: loss: 0.2686, policy_loss: 1.9246, value_loss: 1.0110
2024-07-11 15:41:35,446 [INFO    ] __main__: train step 605: loss: 0.2687, policy_loss: 1.9245, value_loss: 1.0109
2024-07-11 15:41:35,634 [INFO    ] __main__: train step 606: loss: 0.2689, policy_loss: 1.9244, value_loss: 1.0109
2024-07-11 15:41:36,001 [INFO    ] __main__: train step 607: loss: 0.2690, policy_loss: 1.9244, value_loss: 1.0108
2024-07-11 15:41:36,221 [INFO    ] __main__: train step 608: loss: 0.2691, policy_loss: 1.9243, value_loss: 1.0107
2024-07-11 15:41:36,422 [INFO    ] __main__: train step 609: loss: 0.2692, policy_loss: 1.9242, value_loss: 1.0106
2024-07-11 15:41:36,622 [INFO    ] __main__: train step 610: loss: 0.2693, policy_loss: 1.9241, value_loss: 1.0106
2024-07-11 15:41:36,832 [INFO    ] __main__: train step 611: loss: 0.2695, policy_loss: 1.9240, value_loss: 1.0105
2024-07-11 15:41:38,302 [INFO    ] __main__: replay_buffer size = 22528
2024-07-11 15:41:38,440 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:41:39,651 [INFO    ] __main__: train step 612: loss: 0.2696, policy_loss: 1.9239, value_loss: 1.0105
2024-07-11 15:41:39,826 [INFO    ] __main__: train step 613: loss: 0.2697, policy_loss: 1.9239, value_loss: 1.0105
2024-07-11 15:41:40,041 [INFO    ] __main__: train step 614: loss: 0.2699, policy_loss: 1.9238, value_loss: 1.0105
2024-07-11 15:41:40,240 [INFO    ] __main__: train step 615: loss: 0.2700, policy_loss: 1.9237, value_loss: 1.0105
2024-07-11 15:41:40,483 [INFO    ] __main__: train step 616: loss: 0.2701, policy_loss: 1.9236, value_loss: 1.0104
2024-07-11 15:41:40,720 [INFO    ] __main__: train step 617: loss: 0.2703, policy_loss: 1.9235, value_loss: 1.0103
2024-07-11 15:41:40,916 [INFO    ] __main__: train step 618: loss: 0.2704, policy_loss: 1.9234, value_loss: 1.0104
2024-07-11 15:41:41,117 [INFO    ] __main__: train step 619: loss: 0.2705, policy_loss: 1.9233, value_loss: 1.0103
2024-07-11 15:41:41,322 [INFO    ] __main__: train step 620: loss: 0.2707, policy_loss: 1.9233, value_loss: 1.0103
2024-07-11 15:41:41,686 [INFO    ] __main__: train step 621: loss: 0.2708, policy_loss: 1.9232, value_loss: 1.0103
2024-07-11 15:41:41,898 [INFO    ] __main__: train step 622: loss: 0.2709, policy_loss: 1.9231, value_loss: 1.0102
2024-07-11 15:41:42,088 [INFO    ] __main__: train step 623: loss: 0.2711, policy_loss: 1.9230, value_loss: 1.0102
2024-07-11 15:41:42,292 [INFO    ] __main__: train step 624: loss: 0.2712, policy_loss: 1.9229, value_loss: 1.0101
2024-07-11 15:41:42,500 [INFO    ] __main__: train step 625: loss: 0.2713, policy_loss: 1.9228, value_loss: 1.0100
2024-07-11 15:41:42,699 [INFO    ] __main__: train step 626: loss: 0.2715, policy_loss: 1.9227, value_loss: 1.0100
2024-07-11 15:41:42,887 [INFO    ] __main__: train step 627: loss: 0.2716, policy_loss: 1.9226, value_loss: 1.0100
2024-07-11 15:41:43,097 [INFO    ] __main__: train step 628: loss: 0.2717, policy_loss: 1.9226, value_loss: 1.0100
2024-07-11 15:41:44,559 [INFO    ] __main__: replay_buffer size = 23040
2024-07-11 15:41:44,699 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:41:46,338 [INFO    ] __main__: train step 629: loss: 0.2718, policy_loss: 1.9225, value_loss: 1.0099
2024-07-11 15:41:46,515 [INFO    ] __main__: train step 630: loss: 0.2720, policy_loss: 1.9224, value_loss: 1.0099
2024-07-11 15:41:46,749 [INFO    ] __main__: train step 631: loss: 0.2721, policy_loss: 1.9223, value_loss: 1.0099
2024-07-11 15:41:46,982 [INFO    ] __main__: train step 632: loss: 0.2723, policy_loss: 1.9222, value_loss: 1.0099
2024-07-11 15:41:47,186 [INFO    ] __main__: train step 633: loss: 0.2725, policy_loss: 1.9221, value_loss: 1.0098
2024-07-11 15:41:47,386 [INFO    ] __main__: train step 634: loss: 0.2726, policy_loss: 1.9220, value_loss: 1.0098
2024-07-11 15:41:47,771 [INFO    ] __main__: train step 635: loss: 0.2727, policy_loss: 1.9219, value_loss: 1.0098
2024-07-11 15:41:47,977 [INFO    ] __main__: train step 636: loss: 0.2728, policy_loss: 1.9218, value_loss: 1.0098
2024-07-11 15:41:48,186 [INFO    ] __main__: train step 637: loss: 0.2730, policy_loss: 1.9218, value_loss: 1.0097
2024-07-11 15:41:48,384 [INFO    ] __main__: train step 638: loss: 0.2731, policy_loss: 1.9217, value_loss: 1.0097
2024-07-11 15:41:48,580 [INFO    ] __main__: train step 639: loss: 0.2732, policy_loss: 1.9216, value_loss: 1.0097
2024-07-11 15:41:48,785 [INFO    ] __main__: train step 640: loss: 0.2733, policy_loss: 1.9215, value_loss: 1.0097
2024-07-11 15:41:48,989 [INFO    ] __main__: train step 641: loss: 0.2735, policy_loss: 1.9214, value_loss: 1.0096
2024-07-11 15:41:49,181 [INFO    ] __main__: train step 642: loss: 0.2736, policy_loss: 1.9213, value_loss: 1.0096
2024-07-11 15:41:49,395 [INFO    ] __main__: train step 643: loss: 0.2738, policy_loss: 1.9212, value_loss: 1.0095
2024-07-11 15:41:49,619 [INFO    ] __main__: train step 644: loss: 0.2739, policy_loss: 1.9211, value_loss: 1.0095
2024-07-11 15:41:49,827 [INFO    ] __main__: train step 645: loss: 0.2740, policy_loss: 1.9210, value_loss: 1.0094
2024-07-11 15:41:51,358 [INFO    ] __main__: replay_buffer size = 23552
2024-07-11 15:41:51,462 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:41:53,119 [INFO    ] __main__: train step 646: loss: 0.2742, policy_loss: 1.9210, value_loss: 1.0094
2024-07-11 15:41:53,296 [INFO    ] __main__: train step 647: loss: 0.2743, policy_loss: 1.9209, value_loss: 1.0094
2024-07-11 15:41:53,502 [INFO    ] __main__: train step 648: loss: 0.2744, policy_loss: 1.9208, value_loss: 1.0094
2024-07-11 15:41:53,873 [INFO    ] __main__: train step 649: loss: 0.2746, policy_loss: 1.9207, value_loss: 1.0093
2024-07-11 15:41:54,089 [INFO    ] __main__: train step 650: loss: 0.2747, policy_loss: 1.9206, value_loss: 1.0093
2024-07-11 15:41:54,288 [INFO    ] __main__: train step 651: loss: 0.2749, policy_loss: 1.9205, value_loss: 1.0092
2024-07-11 15:41:54,489 [INFO    ] __main__: train step 652: loss: 0.2750, policy_loss: 1.9204, value_loss: 1.0093
2024-07-11 15:41:54,686 [INFO    ] __main__: train step 653: loss: 0.2751, policy_loss: 1.9203, value_loss: 1.0092
2024-07-11 15:41:54,892 [INFO    ] __main__: train step 654: loss: 0.2752, policy_loss: 1.9202, value_loss: 1.0091
2024-07-11 15:41:55,089 [INFO    ] __main__: train step 655: loss: 0.2754, policy_loss: 1.9201, value_loss: 1.0091
2024-07-11 15:41:55,284 [INFO    ] __main__: train step 656: loss: 0.2755, policy_loss: 1.9201, value_loss: 1.0091
2024-07-11 15:41:55,498 [INFO    ] __main__: train step 657: loss: 0.2757, policy_loss: 1.9200, value_loss: 1.0091
2024-07-11 15:41:55,697 [INFO    ] __main__: train step 658: loss: 0.2758, policy_loss: 1.9199, value_loss: 1.0090
2024-07-11 15:41:55,889 [INFO    ] __main__: train step 659: loss: 0.2760, policy_loss: 1.9198, value_loss: 1.0090
2024-07-11 15:41:56,099 [INFO    ] __main__: train step 660: loss: 0.2761, policy_loss: 1.9197, value_loss: 1.0090
2024-07-11 15:41:56,300 [INFO    ] __main__: train step 661: loss: 0.2763, policy_loss: 1.9196, value_loss: 1.0089
2024-07-11 15:41:56,504 [INFO    ] __main__: train step 662: loss: 0.2764, policy_loss: 1.9196, value_loss: 1.0088
2024-07-11 15:41:57,984 [INFO    ] __main__: replay_buffer size = 24064
2024-07-11 15:41:58,129 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:41:59,783 [INFO    ] __main__: train step 663: loss: 0.2766, policy_loss: 1.9195, value_loss: 1.0088
2024-07-11 15:42:00,125 [INFO    ] __main__: train step 664: loss: 0.2767, policy_loss: 1.9194, value_loss: 1.0088
2024-07-11 15:42:00,348 [INFO    ] __main__: train step 665: loss: 0.2769, policy_loss: 1.9193, value_loss: 1.0087
2024-07-11 15:42:00,554 [INFO    ] __main__: train step 666: loss: 0.2770, policy_loss: 1.9193, value_loss: 1.0087
2024-07-11 15:42:00,762 [INFO    ] __main__: train step 667: loss: 0.2771, policy_loss: 1.9192, value_loss: 1.0086
2024-07-11 15:42:00,979 [INFO    ] __main__: train step 668: loss: 0.2773, policy_loss: 1.9191, value_loss: 1.0086
2024-07-11 15:42:01,193 [INFO    ] __main__: train step 669: loss: 0.2774, policy_loss: 1.9190, value_loss: 1.0085
2024-07-11 15:42:01,436 [INFO    ] __main__: train step 670: loss: 0.2775, policy_loss: 1.9189, value_loss: 1.0084
2024-07-11 15:42:01,638 [INFO    ] __main__: train step 671: loss: 0.2777, policy_loss: 1.9189, value_loss: 1.0084
2024-07-11 15:42:01,839 [INFO    ] __main__: train step 672: loss: 0.2778, policy_loss: 1.9188, value_loss: 1.0083
2024-07-11 15:42:02,051 [INFO    ] __main__: train step 673: loss: 0.2780, policy_loss: 1.9187, value_loss: 1.0083
2024-07-11 15:42:02,260 [INFO    ] __main__: train step 674: loss: 0.2781, policy_loss: 1.9186, value_loss: 1.0083
2024-07-11 15:42:02,463 [INFO    ] __main__: train step 675: loss: 0.2782, policy_loss: 1.9185, value_loss: 1.0082
2024-07-11 15:42:02,663 [INFO    ] __main__: train step 676: loss: 0.2784, policy_loss: 1.9184, value_loss: 1.0082
2024-07-11 15:42:02,867 [INFO    ] __main__: train step 677: loss: 0.2785, policy_loss: 1.9183, value_loss: 1.0081
2024-07-11 15:42:03,070 [INFO    ] __main__: train step 678: loss: 0.2786, policy_loss: 1.9183, value_loss: 1.0081
2024-07-11 15:42:03,439 [INFO    ] __main__: train step 679: loss: 0.2788, policy_loss: 1.9182, value_loss: 1.0081
2024-07-11 15:42:05,000 [INFO    ] __main__: replay_buffer size = 24576
2024-07-11 15:42:05,161 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:42:06,363 [INFO    ] __main__: train step 680: loss: 0.2789, policy_loss: 1.9181, value_loss: 1.0080
2024-07-11 15:42:06,531 [INFO    ] __main__: train step 681: loss: 0.2791, policy_loss: 1.9180, value_loss: 1.0080
2024-07-11 15:42:06,754 [INFO    ] __main__: train step 682: loss: 0.2792, policy_loss: 1.9180, value_loss: 1.0079
2024-07-11 15:42:06,954 [INFO    ] __main__: train step 683: loss: 0.2793, policy_loss: 1.9179, value_loss: 1.0078
2024-07-11 15:42:07,147 [INFO    ] __main__: train step 684: loss: 0.2795, policy_loss: 1.9178, value_loss: 1.0078
2024-07-11 15:42:07,356 [INFO    ] __main__: train step 685: loss: 0.2796, policy_loss: 1.9177, value_loss: 1.0078
2024-07-11 15:42:07,562 [INFO    ] __main__: train step 686: loss: 0.2798, policy_loss: 1.9177, value_loss: 1.0077
2024-07-11 15:42:07,766 [INFO    ] __main__: train step 687: loss: 0.2799, policy_loss: 1.9176, value_loss: 1.0077
2024-07-11 15:42:07,966 [INFO    ] __main__: train step 688: loss: 0.2801, policy_loss: 1.9175, value_loss: 1.0077
2024-07-11 15:42:08,165 [INFO    ] __main__: train step 689: loss: 0.2802, policy_loss: 1.9175, value_loss: 1.0076
2024-07-11 15:42:08,361 [INFO    ] __main__: train step 690: loss: 0.2804, policy_loss: 1.9174, value_loss: 1.0076
2024-07-11 15:42:08,565 [INFO    ] __main__: train step 691: loss: 0.2805, policy_loss: 1.9173, value_loss: 1.0076
2024-07-11 15:42:08,760 [INFO    ] __main__: train step 692: loss: 0.2807, policy_loss: 1.9172, value_loss: 1.0076
2024-07-11 15:42:08,962 [INFO    ] __main__: train step 693: loss: 0.2808, policy_loss: 1.9172, value_loss: 1.0076
2024-07-11 15:42:09,335 [INFO    ] __main__: train step 694: loss: 0.2810, policy_loss: 1.9171, value_loss: 1.0076
2024-07-11 15:42:09,547 [INFO    ] __main__: train step 695: loss: 0.2811, policy_loss: 1.9170, value_loss: 1.0075
2024-07-11 15:42:09,751 [INFO    ] __main__: train step 696: loss: 0.2813, policy_loss: 1.9169, value_loss: 1.0075
2024-07-11 15:42:11,239 [INFO    ] __main__: replay_buffer size = 25088
2024-07-11 15:42:11,391 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:42:12,984 [INFO    ] __main__: train step 697: loss: 0.2814, policy_loss: 1.9169, value_loss: 1.0075
2024-07-11 15:42:13,163 [INFO    ] __main__: train step 698: loss: 0.2816, policy_loss: 1.9168, value_loss: 1.0074
2024-07-11 15:42:13,383 [INFO    ] __main__: train step 699: loss: 0.2817, policy_loss: 1.9167, value_loss: 1.0074
2024-07-11 15:42:13,585 [INFO    ] __main__: train step 700: loss: 0.2818, policy_loss: 1.9166, value_loss: 1.0073
2024-07-11 15:42:13,801 [INFO    ] __main__: train step 701: loss: 0.2820, policy_loss: 1.9166, value_loss: 1.0073
2024-07-11 15:42:13,998 [INFO    ] __main__: train step 702: loss: 0.2821, policy_loss: 1.9165, value_loss: 1.0073
2024-07-11 15:42:14,208 [INFO    ] __main__: train step 703: loss: 0.2823, policy_loss: 1.9164, value_loss: 1.0073
2024-07-11 15:42:14,407 [INFO    ] __main__: train step 704: loss: 0.2824, policy_loss: 1.9163, value_loss: 1.0073
2024-07-11 15:42:14,615 [INFO    ] __main__: train step 705: loss: 0.2825, policy_loss: 1.9163, value_loss: 1.0072
2024-07-11 15:42:14,813 [INFO    ] __main__: train step 706: loss: 0.2827, policy_loss: 1.9162, value_loss: 1.0072
2024-07-11 15:42:15,022 [INFO    ] __main__: train step 707: loss: 0.2828, policy_loss: 1.9161, value_loss: 1.0072
2024-07-11 15:42:15,224 [INFO    ] __main__: train step 708: loss: 0.2830, policy_loss: 1.9160, value_loss: 1.0071
2024-07-11 15:42:15,601 [INFO    ] __main__: train step 709: loss: 0.2831, policy_loss: 1.9160, value_loss: 1.0071
2024-07-11 15:42:15,804 [INFO    ] __main__: train step 710: loss: 0.2833, policy_loss: 1.9159, value_loss: 1.0071
2024-07-11 15:42:16,007 [INFO    ] __main__: train step 711: loss: 0.2834, policy_loss: 1.9158, value_loss: 1.0070
2024-07-11 15:42:16,217 [INFO    ] __main__: train step 712: loss: 0.2836, policy_loss: 1.9157, value_loss: 1.0070
2024-07-11 15:42:16,419 [INFO    ] __main__: train step 713: loss: 0.2837, policy_loss: 1.9157, value_loss: 1.0070
2024-07-11 15:42:17,964 [INFO    ] __main__: replay_buffer size = 25600
2024-07-11 15:42:18,106 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:42:19,731 [INFO    ] __main__: train step 714: loss: 0.2839, policy_loss: 1.9156, value_loss: 1.0070
2024-07-11 15:42:19,900 [INFO    ] __main__: train step 715: loss: 0.2840, policy_loss: 1.9155, value_loss: 1.0070
2024-07-11 15:42:20,107 [INFO    ] __main__: train step 716: loss: 0.2842, policy_loss: 1.9154, value_loss: 1.0070
2024-07-11 15:42:20,314 [INFO    ] __main__: train step 717: loss: 0.2843, policy_loss: 1.9154, value_loss: 1.0070
2024-07-11 15:42:20,522 [INFO    ] __main__: train step 718: loss: 0.2845, policy_loss: 1.9153, value_loss: 1.0070
2024-07-11 15:42:20,718 [INFO    ] __main__: train step 719: loss: 0.2847, policy_loss: 1.9152, value_loss: 1.0069
2024-07-11 15:42:20,924 [INFO    ] __main__: train step 720: loss: 0.2848, policy_loss: 1.9151, value_loss: 1.0069
2024-07-11 15:42:21,117 [INFO    ] __main__: train step 721: loss: 0.2850, policy_loss: 1.9151, value_loss: 1.0069
2024-07-11 15:42:21,316 [INFO    ] __main__: train step 722: loss: 0.2852, policy_loss: 1.9150, value_loss: 1.0068
2024-07-11 15:42:21,514 [INFO    ] __main__: train step 723: loss: 0.2853, policy_loss: 1.9149, value_loss: 1.0068
2024-07-11 15:42:21,887 [INFO    ] __main__: train step 724: loss: 0.2855, policy_loss: 1.9148, value_loss: 1.0068
2024-07-11 15:42:22,121 [INFO    ] __main__: train step 725: loss: 0.2856, policy_loss: 1.9147, value_loss: 1.0067
2024-07-11 15:42:22,323 [INFO    ] __main__: train step 726: loss: 0.2857, policy_loss: 1.9147, value_loss: 1.0067
2024-07-11 15:42:22,531 [INFO    ] __main__: train step 727: loss: 0.2859, policy_loss: 1.9146, value_loss: 1.0067
2024-07-11 15:42:22,774 [INFO    ] __main__: train step 728: loss: 0.2860, policy_loss: 1.9145, value_loss: 1.0066
2024-07-11 15:42:22,986 [INFO    ] __main__: train step 729: loss: 0.2862, policy_loss: 1.9144, value_loss: 1.0066
2024-07-11 15:42:23,181 [INFO    ] __main__: train step 730: loss: 0.2863, policy_loss: 1.9143, value_loss: 1.0066
2024-07-11 15:42:24,713 [INFO    ] __main__: replay_buffer size = 26112
2024-07-11 15:42:24,867 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:42:26,535 [INFO    ] __main__: train step 731: loss: 0.2865, policy_loss: 1.9143, value_loss: 1.0065
2024-07-11 15:42:26,705 [INFO    ] __main__: train step 732: loss: 0.2867, policy_loss: 1.9142, value_loss: 1.0065
2024-07-11 15:42:26,914 [INFO    ] __main__: train step 733: loss: 0.2868, policy_loss: 1.9141, value_loss: 1.0065
2024-07-11 15:42:27,129 [INFO    ] __main__: train step 734: loss: 0.2869, policy_loss: 1.9141, value_loss: 1.0065
2024-07-11 15:42:27,321 [INFO    ] __main__: train step 735: loss: 0.2871, policy_loss: 1.9140, value_loss: 1.0065
2024-07-11 15:42:27,518 [INFO    ] __main__: train step 736: loss: 0.2872, policy_loss: 1.9139, value_loss: 1.0065
2024-07-11 15:42:27,723 [INFO    ] __main__: train step 737: loss: 0.2874, policy_loss: 1.9138, value_loss: 1.0065
2024-07-11 15:42:27,922 [INFO    ] __main__: train step 738: loss: 0.2875, policy_loss: 1.9138, value_loss: 1.0064
2024-07-11 15:42:28,295 [INFO    ] __main__: train step 739: loss: 0.2876, policy_loss: 1.9137, value_loss: 1.0064
2024-07-11 15:42:28,520 [INFO    ] __main__: train step 740: loss: 0.2878, policy_loss: 1.9136, value_loss: 1.0064
2024-07-11 15:42:28,750 [INFO    ] __main__: train step 741: loss: 0.2879, policy_loss: 1.9135, value_loss: 1.0063
2024-07-11 15:42:28,949 [INFO    ] __main__: train step 742: loss: 0.2881, policy_loss: 1.9135, value_loss: 1.0063
2024-07-11 15:42:29,167 [INFO    ] __main__: train step 743: loss: 0.2882, policy_loss: 1.9134, value_loss: 1.0063
2024-07-11 15:42:29,359 [INFO    ] __main__: train step 744: loss: 0.2884, policy_loss: 1.9133, value_loss: 1.0063
2024-07-11 15:42:29,572 [INFO    ] __main__: train step 745: loss: 0.2885, policy_loss: 1.9132, value_loss: 1.0063
2024-07-11 15:42:29,768 [INFO    ] __main__: train step 746: loss: 0.2887, policy_loss: 1.9131, value_loss: 1.0063
2024-07-11 15:42:29,960 [INFO    ] __main__: train step 747: loss: 0.2888, policy_loss: 1.9131, value_loss: 1.0062
2024-07-11 15:42:31,502 [INFO    ] __main__: replay_buffer size = 26624
2024-07-11 15:42:31,615 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:42:32,793 [INFO    ] __main__: train step 748: loss: 0.2890, policy_loss: 1.9130, value_loss: 1.0061
2024-07-11 15:42:32,959 [INFO    ] __main__: train step 749: loss: 0.2892, policy_loss: 1.9129, value_loss: 1.0061
2024-07-11 15:42:33,177 [INFO    ] __main__: train step 750: loss: 0.2893, policy_loss: 1.9128, value_loss: 1.0061
2024-07-11 15:42:33,401 [INFO    ] __main__: train step 751: loss: 0.2895, policy_loss: 1.9127, value_loss: 1.0061
2024-07-11 15:42:33,767 [INFO    ] __main__: train step 752: loss: 0.2896, policy_loss: 1.9126, value_loss: 1.0060
2024-07-11 15:42:33,965 [INFO    ] __main__: train step 753: loss: 0.2897, policy_loss: 1.9125, value_loss: 1.0060
2024-07-11 15:42:34,155 [INFO    ] __main__: train step 754: loss: 0.2899, policy_loss: 1.9124, value_loss: 1.0060
2024-07-11 15:42:34,370 [INFO    ] __main__: train step 755: loss: 0.2900, policy_loss: 1.9124, value_loss: 1.0060
2024-07-11 15:42:34,561 [INFO    ] __main__: train step 756: loss: 0.2902, policy_loss: 1.9123, value_loss: 1.0059
2024-07-11 15:42:34,770 [INFO    ] __main__: train step 757: loss: 0.2903, policy_loss: 1.9122, value_loss: 1.0060
2024-07-11 15:42:34,966 [INFO    ] __main__: train step 758: loss: 0.2904, policy_loss: 1.9121, value_loss: 1.0060
2024-07-11 15:42:35,180 [INFO    ] __main__: train step 759: loss: 0.2906, policy_loss: 1.9120, value_loss: 1.0059
2024-07-11 15:42:35,414 [INFO    ] __main__: train step 760: loss: 0.2907, policy_loss: 1.9119, value_loss: 1.0059
2024-07-11 15:42:35,613 [INFO    ] __main__: train step 761: loss: 0.2909, policy_loss: 1.9119, value_loss: 1.0059
2024-07-11 15:42:35,812 [INFO    ] __main__: train step 762: loss: 0.2911, policy_loss: 1.9118, value_loss: 1.0059
2024-07-11 15:42:36,016 [INFO    ] __main__: train step 763: loss: 0.2912, policy_loss: 1.9117, value_loss: 1.0059
2024-07-11 15:42:36,228 [INFO    ] __main__: train step 764: loss: 0.2914, policy_loss: 1.9116, value_loss: 1.0059
2024-07-11 15:42:37,766 [INFO    ] __main__: replay_buffer size = 27136
2024-07-11 15:42:37,918 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:42:39,577 [INFO    ] __main__: train step 765: loss: 0.2915, policy_loss: 1.9115, value_loss: 1.0059
2024-07-11 15:42:39,747 [INFO    ] __main__: train step 766: loss: 0.2917, policy_loss: 1.9115, value_loss: 1.0059
2024-07-11 15:42:40,145 [INFO    ] __main__: train step 767: loss: 0.2918, policy_loss: 1.9114, value_loss: 1.0059
2024-07-11 15:42:40,370 [INFO    ] __main__: train step 768: loss: 0.2920, policy_loss: 1.9113, value_loss: 1.0059
2024-07-11 15:42:40,573 [INFO    ] __main__: train step 769: loss: 0.2921, policy_loss: 1.9113, value_loss: 1.0059
2024-07-11 15:42:40,775 [INFO    ] __main__: train step 770: loss: 0.2923, policy_loss: 1.9112, value_loss: 1.0059
2024-07-11 15:42:41,011 [INFO    ] __main__: train step 771: loss: 0.2924, policy_loss: 1.9111, value_loss: 1.0059
2024-07-11 15:42:41,224 [INFO    ] __main__: train step 772: loss: 0.2926, policy_loss: 1.9111, value_loss: 1.0059
2024-07-11 15:42:41,425 [INFO    ] __main__: train step 773: loss: 0.2927, policy_loss: 1.9110, value_loss: 1.0060
2024-07-11 15:42:41,623 [INFO    ] __main__: train step 774: loss: 0.2928, policy_loss: 1.9109, value_loss: 1.0060
2024-07-11 15:42:41,825 [INFO    ] __main__: train step 775: loss: 0.2930, policy_loss: 1.9108, value_loss: 1.0060
2024-07-11 15:42:42,017 [INFO    ] __main__: train step 776: loss: 0.2931, policy_loss: 1.9108, value_loss: 1.0060
2024-07-11 15:42:42,215 [INFO    ] __main__: train step 777: loss: 0.2933, policy_loss: 1.9107, value_loss: 1.0059
2024-07-11 15:42:42,411 [INFO    ] __main__: train step 778: loss: 0.2934, policy_loss: 1.9106, value_loss: 1.0059
2024-07-11 15:42:42,618 [INFO    ] __main__: train step 779: loss: 0.2936, policy_loss: 1.9105, value_loss: 1.0059
2024-07-11 15:42:42,818 [INFO    ] __main__: train step 780: loss: 0.2937, policy_loss: 1.9105, value_loss: 1.0059
2024-07-11 15:42:43,017 [INFO    ] __main__: train step 781: loss: 0.2938, policy_loss: 1.9104, value_loss: 1.0058
2024-07-11 15:42:44,721 [INFO    ] __main__: replay_buffer size = 27648
2024-07-11 15:42:44,891 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:42:46,524 [INFO    ] __main__: train step 782: loss: 0.2940, policy_loss: 1.9103, value_loss: 1.0058
2024-07-11 15:42:46,698 [INFO    ] __main__: train step 783: loss: 0.2941, policy_loss: 1.9102, value_loss: 1.0057
2024-07-11 15:42:46,911 [INFO    ] __main__: train step 784: loss: 0.2943, policy_loss: 1.9102, value_loss: 1.0057
2024-07-11 15:42:47,120 [INFO    ] __main__: train step 785: loss: 0.2944, policy_loss: 1.9101, value_loss: 1.0057
2024-07-11 15:42:47,351 [INFO    ] __main__: train step 786: loss: 0.2946, policy_loss: 1.9100, value_loss: 1.0057
2024-07-11 15:42:47,548 [INFO    ] __main__: train step 787: loss: 0.2947, policy_loss: 1.9099, value_loss: 1.0057
2024-07-11 15:42:47,755 [INFO    ] __main__: train step 788: loss: 0.2949, policy_loss: 1.9098, value_loss: 1.0057
2024-07-11 15:42:47,958 [INFO    ] __main__: train step 789: loss: 0.2950, policy_loss: 1.9098, value_loss: 1.0057
2024-07-11 15:42:48,167 [INFO    ] __main__: train step 790: loss: 0.2952, policy_loss: 1.9097, value_loss: 1.0057
2024-07-11 15:42:48,354 [INFO    ] __main__: train step 791: loss: 0.2953, policy_loss: 1.9096, value_loss: 1.0057
2024-07-11 15:42:48,561 [INFO    ] __main__: train step 792: loss: 0.2955, policy_loss: 1.9096, value_loss: 1.0056
2024-07-11 15:42:48,791 [INFO    ] __main__: train step 793: loss: 0.2956, policy_loss: 1.9095, value_loss: 1.0056
2024-07-11 15:42:48,990 [INFO    ] __main__: train step 794: loss: 0.2958, policy_loss: 1.9094, value_loss: 1.0056
2024-07-11 15:42:49,198 [INFO    ] __main__: train step 795: loss: 0.2959, policy_loss: 1.9093, value_loss: 1.0056
2024-07-11 15:42:49,600 [INFO    ] __main__: train step 796: loss: 0.2961, policy_loss: 1.9093, value_loss: 1.0055
2024-07-11 15:42:49,814 [INFO    ] __main__: train step 797: loss: 0.2963, policy_loss: 1.9092, value_loss: 1.0055
2024-07-11 15:42:50,010 [INFO    ] __main__: train step 798: loss: 0.2964, policy_loss: 1.9091, value_loss: 1.0055
2024-07-11 15:42:51,561 [INFO    ] __main__: replay_buffer size = 28160
2024-07-11 15:42:51,741 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:42:53,442 [INFO    ] __main__: train step 799: loss: 0.2965, policy_loss: 1.9091, value_loss: 1.0055
2024-07-11 15:42:53,614 [INFO    ] __main__: train step 800: loss: 0.2967, policy_loss: 1.9090, value_loss: 1.0054
2024-07-11 15:42:53,839 [INFO    ] __main__: train step 801: loss: 0.2968, policy_loss: 1.9089, value_loss: 1.0054
2024-07-11 15:42:54,047 [INFO    ] __main__: train step 802: loss: 0.2970, policy_loss: 1.9088, value_loss: 1.0054
2024-07-11 15:42:54,235 [INFO    ] __main__: train step 803: loss: 0.2971, policy_loss: 1.9088, value_loss: 1.0054
2024-07-11 15:42:54,438 [INFO    ] __main__: train step 804: loss: 0.2972, policy_loss: 1.9087, value_loss: 1.0054
2024-07-11 15:42:54,650 [INFO    ] __main__: train step 805: loss: 0.2974, policy_loss: 1.9086, value_loss: 1.0053
2024-07-11 15:42:54,848 [INFO    ] __main__: train step 806: loss: 0.2975, policy_loss: 1.9085, value_loss: 1.0053
2024-07-11 15:42:55,039 [INFO    ] __main__: train step 807: loss: 0.2977, policy_loss: 1.9085, value_loss: 1.0053
2024-07-11 15:42:55,249 [INFO    ] __main__: train step 808: loss: 0.2978, policy_loss: 1.9084, value_loss: 1.0053
2024-07-11 15:42:55,453 [INFO    ] __main__: train step 809: loss: 0.2979, policy_loss: 1.9083, value_loss: 1.0053
2024-07-11 15:42:55,871 [INFO    ] __main__: train step 810: loss: 0.2981, policy_loss: 1.9082, value_loss: 1.0053
2024-07-11 15:42:56,095 [INFO    ] __main__: train step 811: loss: 0.2982, policy_loss: 1.9082, value_loss: 1.0052
2024-07-11 15:42:56,315 [INFO    ] __main__: train step 812: loss: 0.2983, policy_loss: 1.9081, value_loss: 1.0052
2024-07-11 15:42:56,535 [INFO    ] __main__: train step 813: loss: 0.2985, policy_loss: 1.9080, value_loss: 1.0052
2024-07-11 15:42:56,748 [INFO    ] __main__: train step 814: loss: 0.2986, policy_loss: 1.9079, value_loss: 1.0052
2024-07-11 15:42:56,953 [INFO    ] __main__: train step 815: loss: 0.2988, policy_loss: 1.9079, value_loss: 1.0052
2024-07-11 15:42:58,505 [INFO    ] __main__: replay_buffer size = 28672
2024-07-11 15:42:58,717 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:42:59,901 [INFO    ] __main__: train step 816: loss: 0.2989, policy_loss: 1.9078, value_loss: 1.0052
2024-07-11 15:43:00,071 [INFO    ] __main__: train step 817: loss: 0.2991, policy_loss: 1.9077, value_loss: 1.0052
2024-07-11 15:43:00,302 [INFO    ] __main__: train step 818: loss: 0.2992, policy_loss: 1.9077, value_loss: 1.0051
2024-07-11 15:43:00,526 [INFO    ] __main__: train step 819: loss: 0.2994, policy_loss: 1.9076, value_loss: 1.0051
2024-07-11 15:43:00,738 [INFO    ] __main__: train step 820: loss: 0.2995, policy_loss: 1.9075, value_loss: 1.0051
2024-07-11 15:43:00,932 [INFO    ] __main__: train step 821: loss: 0.2996, policy_loss: 1.9075, value_loss: 1.0051
2024-07-11 15:43:01,133 [INFO    ] __main__: train step 822: loss: 0.2998, policy_loss: 1.9074, value_loss: 1.0051
2024-07-11 15:43:01,332 [INFO    ] __main__: train step 823: loss: 0.2999, policy_loss: 1.9073, value_loss: 1.0051
2024-07-11 15:43:01,544 [INFO    ] __main__: train step 824: loss: 0.3001, policy_loss: 1.9073, value_loss: 1.0050
2024-07-11 15:43:01,932 [INFO    ] __main__: train step 825: loss: 0.3002, policy_loss: 1.9072, value_loss: 1.0050
2024-07-11 15:43:02,155 [INFO    ] __main__: train step 826: loss: 0.3004, policy_loss: 1.9071, value_loss: 1.0050
2024-07-11 15:43:02,358 [INFO    ] __main__: train step 827: loss: 0.3005, policy_loss: 1.9071, value_loss: 1.0050
2024-07-11 15:43:02,569 [INFO    ] __main__: train step 828: loss: 0.3007, policy_loss: 1.9070, value_loss: 1.0050
2024-07-11 15:43:02,775 [INFO    ] __main__: train step 829: loss: 0.3008, policy_loss: 1.9069, value_loss: 1.0049
2024-07-11 15:43:02,978 [INFO    ] __main__: train step 830: loss: 0.3010, policy_loss: 1.9068, value_loss: 1.0050
2024-07-11 15:43:03,196 [INFO    ] __main__: train step 831: loss: 0.3012, policy_loss: 1.9068, value_loss: 1.0050
2024-07-11 15:43:03,397 [INFO    ] __main__: train step 832: loss: 0.3013, policy_loss: 1.9067, value_loss: 1.0049
2024-07-11 15:43:04,915 [INFO    ] __main__: replay_buffer size = 29184
2024-07-11 15:43:05,109 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:43:06,756 [INFO    ] __main__: train step 833: loss: 0.3015, policy_loss: 1.9066, value_loss: 1.0049
2024-07-11 15:43:06,924 [INFO    ] __main__: train step 834: loss: 0.3017, policy_loss: 1.9065, value_loss: 1.0049
2024-07-11 15:43:07,140 [INFO    ] __main__: train step 835: loss: 0.3018, policy_loss: 1.9065, value_loss: 1.0049
2024-07-11 15:43:07,357 [INFO    ] __main__: train step 836: loss: 0.3020, policy_loss: 1.9064, value_loss: 1.0049
2024-07-11 15:43:07,549 [INFO    ] __main__: train step 837: loss: 0.3021, policy_loss: 1.9063, value_loss: 1.0049
2024-07-11 15:43:07,766 [INFO    ] __main__: train step 838: loss: 0.3023, policy_loss: 1.9063, value_loss: 1.0049
2024-07-11 15:43:07,962 [INFO    ] __main__: train step 839: loss: 0.3024, policy_loss: 1.9062, value_loss: 1.0049
2024-07-11 15:43:08,362 [INFO    ] __main__: train step 840: loss: 0.3026, policy_loss: 1.9061, value_loss: 1.0049
2024-07-11 15:43:08,593 [INFO    ] __main__: train step 841: loss: 0.3027, policy_loss: 1.9060, value_loss: 1.0050
2024-07-11 15:43:08,817 [INFO    ] __main__: train step 842: loss: 0.3029, policy_loss: 1.9060, value_loss: 1.0049
2024-07-11 15:43:09,024 [INFO    ] __main__: train step 843: loss: 0.3030, policy_loss: 1.9059, value_loss: 1.0049
2024-07-11 15:43:09,222 [INFO    ] __main__: train step 844: loss: 0.3032, policy_loss: 1.9058, value_loss: 1.0049
2024-07-11 15:43:09,414 [INFO    ] __main__: train step 845: loss: 0.3033, policy_loss: 1.9057, value_loss: 1.0049
2024-07-11 15:43:09,616 [INFO    ] __main__: train step 846: loss: 0.3035, policy_loss: 1.9057, value_loss: 1.0049
2024-07-11 15:43:09,815 [INFO    ] __main__: train step 847: loss: 0.3036, policy_loss: 1.9056, value_loss: 1.0049
2024-07-11 15:43:10,029 [INFO    ] __main__: train step 848: loss: 0.3038, policy_loss: 1.9055, value_loss: 1.0049
2024-07-11 15:43:10,226 [INFO    ] __main__: train step 849: loss: 0.3039, policy_loss: 1.9054, value_loss: 1.0049
2024-07-11 15:43:11,745 [INFO    ] __main__: replay_buffer size = 29696
2024-07-11 15:43:11,953 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:43:13,590 [INFO    ] __main__: train step 850: loss: 0.3041, policy_loss: 1.9054, value_loss: 1.0049
2024-07-11 15:43:13,777 [INFO    ] __main__: train step 851: loss: 0.3042, policy_loss: 1.9053, value_loss: 1.0049
2024-07-11 15:43:13,969 [INFO    ] __main__: train step 852: loss: 0.3044, policy_loss: 1.9052, value_loss: 1.0049
2024-07-11 15:43:14,189 [INFO    ] __main__: train step 853: loss: 0.3045, policy_loss: 1.9052, value_loss: 1.0049
2024-07-11 15:43:14,407 [INFO    ] __main__: train step 854: loss: 0.3047, policy_loss: 1.9051, value_loss: 1.0049
2024-07-11 15:43:14,783 [INFO    ] __main__: train step 855: loss: 0.3048, policy_loss: 1.9050, value_loss: 1.0049
2024-07-11 15:43:15,001 [INFO    ] __main__: train step 856: loss: 0.3050, policy_loss: 1.9049, value_loss: 1.0049
2024-07-11 15:43:15,196 [INFO    ] __main__: train step 857: loss: 0.3051, policy_loss: 1.9049, value_loss: 1.0049
2024-07-11 15:43:15,387 [INFO    ] __main__: train step 858: loss: 0.3053, policy_loss: 1.9048, value_loss: 1.0049
2024-07-11 15:43:15,590 [INFO    ] __main__: train step 859: loss: 0.3055, policy_loss: 1.9048, value_loss: 1.0049
2024-07-11 15:43:15,785 [INFO    ] __main__: train step 860: loss: 0.3056, policy_loss: 1.9047, value_loss: 1.0049
2024-07-11 15:43:15,987 [INFO    ] __main__: train step 861: loss: 0.3058, policy_loss: 1.9046, value_loss: 1.0049
2024-07-11 15:43:16,189 [INFO    ] __main__: train step 862: loss: 0.3059, policy_loss: 1.9045, value_loss: 1.0049
2024-07-11 15:43:16,394 [INFO    ] __main__: train step 863: loss: 0.3061, policy_loss: 1.9045, value_loss: 1.0049
2024-07-11 15:43:16,583 [INFO    ] __main__: train step 864: loss: 0.3062, policy_loss: 1.9044, value_loss: 1.0049
2024-07-11 15:43:16,794 [INFO    ] __main__: train step 865: loss: 0.3064, policy_loss: 1.9043, value_loss: 1.0049
2024-07-11 15:43:16,996 [INFO    ] __main__: train step 866: loss: 0.3065, policy_loss: 1.9042, value_loss: 1.0049
2024-07-11 15:43:18,526 [INFO    ] __main__: replay_buffer size = 30208
2024-07-11 15:43:18,740 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:43:20,414 [INFO    ] __main__: train step 867: loss: 0.3067, policy_loss: 1.9042, value_loss: 1.0049
2024-07-11 15:43:20,597 [INFO    ] __main__: train step 868: loss: 0.3069, policy_loss: 1.9041, value_loss: 1.0049
2024-07-11 15:43:20,802 [INFO    ] __main__: train step 869: loss: 0.3070, policy_loss: 1.9040, value_loss: 1.0049
2024-07-11 15:43:21,013 [INFO    ] __main__: train step 870: loss: 0.3072, policy_loss: 1.9039, value_loss: 1.0048
2024-07-11 15:43:21,424 [INFO    ] __main__: train step 871: loss: 0.3074, policy_loss: 1.9039, value_loss: 1.0048
2024-07-11 15:43:21,631 [INFO    ] __main__: train step 872: loss: 0.3075, policy_loss: 1.9038, value_loss: 1.0049
2024-07-11 15:43:21,836 [INFO    ] __main__: train step 873: loss: 0.3077, policy_loss: 1.9037, value_loss: 1.0049
2024-07-11 15:43:22,037 [INFO    ] __main__: train step 874: loss: 0.3079, policy_loss: 1.9037, value_loss: 1.0049
2024-07-11 15:43:22,242 [INFO    ] __main__: train step 875: loss: 0.3080, policy_loss: 1.9036, value_loss: 1.0049
2024-07-11 15:43:22,439 [INFO    ] __main__: train step 876: loss: 0.3081, policy_loss: 1.9035, value_loss: 1.0049
2024-07-11 15:43:22,651 [INFO    ] __main__: train step 877: loss: 0.3083, policy_loss: 1.9034, value_loss: 1.0049
2024-07-11 15:43:22,851 [INFO    ] __main__: train step 878: loss: 0.3084, policy_loss: 1.9034, value_loss: 1.0049
2024-07-11 15:43:23,058 [INFO    ] __main__: train step 879: loss: 0.3086, policy_loss: 1.9033, value_loss: 1.0049
2024-07-11 15:43:23,262 [INFO    ] __main__: train step 880: loss: 0.3088, policy_loss: 1.9032, value_loss: 1.0049
2024-07-11 15:43:23,454 [INFO    ] __main__: train step 881: loss: 0.3089, policy_loss: 1.9031, value_loss: 1.0049
2024-07-11 15:43:23,647 [INFO    ] __main__: train step 882: loss: 0.3090, policy_loss: 1.9031, value_loss: 1.0049
2024-07-11 15:43:23,864 [INFO    ] __main__: train step 883: loss: 0.3092, policy_loss: 1.9030, value_loss: 1.0049
2024-07-11 15:43:25,396 [INFO    ] __main__: replay_buffer size = 30720
2024-07-11 15:43:25,622 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:43:26,831 [INFO    ] __main__: train step 884: loss: 0.3094, policy_loss: 1.9029, value_loss: 1.0049
2024-07-11 15:43:27,002 [INFO    ] __main__: train step 885: loss: 0.3095, policy_loss: 1.9028, value_loss: 1.0049
2024-07-11 15:43:27,398 [INFO    ] __main__: train step 886: loss: 0.3097, policy_loss: 1.9028, value_loss: 1.0049
2024-07-11 15:43:27,599 [INFO    ] __main__: train step 887: loss: 0.3098, policy_loss: 1.9027, value_loss: 1.0049
2024-07-11 15:43:27,803 [INFO    ] __main__: train step 888: loss: 0.3100, policy_loss: 1.9026, value_loss: 1.0049
2024-07-11 15:43:27,995 [INFO    ] __main__: train step 889: loss: 0.3102, policy_loss: 1.9025, value_loss: 1.0048
2024-07-11 15:43:28,204 [INFO    ] __main__: train step 890: loss: 0.3103, policy_loss: 1.9025, value_loss: 1.0049
2024-07-11 15:43:28,410 [INFO    ] __main__: train step 891: loss: 0.3105, policy_loss: 1.9024, value_loss: 1.0048
2024-07-11 15:43:28,612 [INFO    ] __main__: train step 892: loss: 0.3107, policy_loss: 1.9023, value_loss: 1.0048
2024-07-11 15:43:28,812 [INFO    ] __main__: train step 893: loss: 0.3108, policy_loss: 1.9022, value_loss: 1.0048
2024-07-11 15:43:29,024 [INFO    ] __main__: train step 894: loss: 0.3110, policy_loss: 1.9022, value_loss: 1.0048
2024-07-11 15:43:29,226 [INFO    ] __main__: train step 895: loss: 0.3111, policy_loss: 1.9021, value_loss: 1.0047
2024-07-11 15:43:29,423 [INFO    ] __main__: train step 896: loss: 0.3113, policy_loss: 1.9020, value_loss: 1.0047
2024-07-11 15:43:29,626 [INFO    ] __main__: train step 897: loss: 0.3114, policy_loss: 1.9019, value_loss: 1.0047
2024-07-11 15:43:29,833 [INFO    ] __main__: train step 898: loss: 0.3116, policy_loss: 1.9018, value_loss: 1.0047
2024-07-11 15:43:30,035 [INFO    ] __main__: train step 899: loss: 0.3117, policy_loss: 1.9018, value_loss: 1.0047
2024-07-11 15:43:30,239 [INFO    ] __main__: train step 900: loss: 0.3119, policy_loss: 1.9017, value_loss: 1.0047
2024-07-11 15:43:31,768 [INFO    ] __main__: replay_buffer size = 31232
2024-07-11 15:43:31,992 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:43:33,633 [INFO    ] __main__: train step 901: loss: 0.3121, policy_loss: 1.9016, value_loss: 1.0046
2024-07-11 15:43:33,980 [INFO    ] __main__: train step 902: loss: 0.3122, policy_loss: 1.9016, value_loss: 1.0046
2024-07-11 15:43:34,178 [INFO    ] __main__: train step 903: loss: 0.3124, policy_loss: 1.9015, value_loss: 1.0046
2024-07-11 15:43:34,384 [INFO    ] __main__: train step 904: loss: 0.3125, policy_loss: 1.9014, value_loss: 1.0046
2024-07-11 15:43:34,599 [INFO    ] __main__: train step 905: loss: 0.3126, policy_loss: 1.9013, value_loss: 1.0046
2024-07-11 15:43:34,813 [INFO    ] __main__: train step 906: loss: 0.3128, policy_loss: 1.9013, value_loss: 1.0045
2024-07-11 15:43:35,005 [INFO    ] __main__: train step 907: loss: 0.3130, policy_loss: 1.9012, value_loss: 1.0045
2024-07-11 15:43:35,225 [INFO    ] __main__: train step 908: loss: 0.3131, policy_loss: 1.9011, value_loss: 1.0045
2024-07-11 15:43:35,429 [INFO    ] __main__: train step 909: loss: 0.3133, policy_loss: 1.9010, value_loss: 1.0045
2024-07-11 15:43:35,638 [INFO    ] __main__: train step 910: loss: 0.3134, policy_loss: 1.9010, value_loss: 1.0044
2024-07-11 15:43:35,849 [INFO    ] __main__: train step 911: loss: 0.3136, policy_loss: 1.9009, value_loss: 1.0044
2024-07-11 15:43:36,063 [INFO    ] __main__: train step 912: loss: 0.3138, policy_loss: 1.9008, value_loss: 1.0044
2024-07-11 15:43:36,259 [INFO    ] __main__: train step 913: loss: 0.3139, policy_loss: 1.9007, value_loss: 1.0043
2024-07-11 15:43:36,466 [INFO    ] __main__: train step 914: loss: 0.3140, policy_loss: 1.9007, value_loss: 1.0043
2024-07-11 15:43:36,667 [INFO    ] __main__: train step 915: loss: 0.3142, policy_loss: 1.9006, value_loss: 1.0043
2024-07-11 15:43:36,868 [INFO    ] __main__: train step 916: loss: 0.3143, policy_loss: 1.9005, value_loss: 1.0043
2024-07-11 15:43:37,081 [INFO    ] __main__: train step 917: loss: 0.3145, policy_loss: 1.9004, value_loss: 1.0043
2024-07-11 15:43:38,760 [INFO    ] __main__: replay_buffer size = 31744
2024-07-11 15:43:38,984 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:43:40,643 [INFO    ] __main__: train step 918: loss: 0.3147, policy_loss: 1.9003, value_loss: 1.0043
2024-07-11 15:43:40,825 [INFO    ] __main__: train step 919: loss: 0.3148, policy_loss: 1.9003, value_loss: 1.0043
2024-07-11 15:43:41,029 [INFO    ] __main__: train step 920: loss: 0.3150, policy_loss: 1.9002, value_loss: 1.0042
2024-07-11 15:43:41,225 [INFO    ] __main__: train step 921: loss: 0.3152, policy_loss: 1.9001, value_loss: 1.0042
2024-07-11 15:43:41,426 [INFO    ] __main__: train step 922: loss: 0.3153, policy_loss: 1.9000, value_loss: 1.0042
2024-07-11 15:43:41,627 [INFO    ] __main__: train step 923: loss: 0.3154, policy_loss: 1.8999, value_loss: 1.0042
2024-07-11 15:43:41,834 [INFO    ] __main__: train step 924: loss: 0.3156, policy_loss: 1.8998, value_loss: 1.0042
2024-07-11 15:43:42,019 [INFO    ] __main__: train step 925: loss: 0.3157, policy_loss: 1.8998, value_loss: 1.0042
2024-07-11 15:43:42,221 [INFO    ] __main__: train step 926: loss: 0.3159, policy_loss: 1.8997, value_loss: 1.0042
2024-07-11 15:43:42,422 [INFO    ] __main__: train step 927: loss: 0.3161, policy_loss: 1.8996, value_loss: 1.0042
2024-07-11 15:43:42,616 [INFO    ] __main__: train step 928: loss: 0.3162, policy_loss: 1.8995, value_loss: 1.0042
2024-07-11 15:43:42,823 [INFO    ] __main__: train step 929: loss: 0.3163, policy_loss: 1.8994, value_loss: 1.0042
2024-07-11 15:43:43,027 [INFO    ] __main__: train step 930: loss: 0.3165, policy_loss: 1.8993, value_loss: 1.0042
2024-07-11 15:43:43,224 [INFO    ] __main__: train step 931: loss: 0.3166, policy_loss: 1.8993, value_loss: 1.0042
2024-07-11 15:43:43,437 [INFO    ] __main__: train step 932: loss: 0.3168, policy_loss: 1.8992, value_loss: 1.0042
2024-07-11 15:43:43,876 [INFO    ] __main__: train step 933: loss: 0.3170, policy_loss: 1.8991, value_loss: 1.0042
2024-07-11 15:43:44,103 [INFO    ] __main__: train step 934: loss: 0.3171, policy_loss: 1.8990, value_loss: 1.0042
2024-07-11 15:43:45,678 [INFO    ] __main__: replay_buffer size = 32256
2024-07-11 15:43:45,893 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:43:47,569 [INFO    ] __main__: train step 935: loss: 0.3172, policy_loss: 1.8990, value_loss: 1.0042
2024-07-11 15:43:47,737 [INFO    ] __main__: train step 936: loss: 0.3174, policy_loss: 1.8989, value_loss: 1.0043
2024-07-11 15:43:47,952 [INFO    ] __main__: train step 937: loss: 0.3176, policy_loss: 1.8988, value_loss: 1.0043
2024-07-11 15:43:48,162 [INFO    ] __main__: train step 938: loss: 0.3177, policy_loss: 1.8987, value_loss: 1.0043
2024-07-11 15:43:48,392 [INFO    ] __main__: train step 939: loss: 0.3179, policy_loss: 1.8986, value_loss: 1.0043
2024-07-11 15:43:48,584 [INFO    ] __main__: train step 940: loss: 0.3180, policy_loss: 1.8986, value_loss: 1.0042
2024-07-11 15:43:48,784 [INFO    ] __main__: train step 941: loss: 0.3182, policy_loss: 1.8985, value_loss: 1.0043
2024-07-11 15:43:48,980 [INFO    ] __main__: train step 942: loss: 0.3183, policy_loss: 1.8984, value_loss: 1.0043
2024-07-11 15:43:49,194 [INFO    ] __main__: train step 943: loss: 0.3185, policy_loss: 1.8983, value_loss: 1.0043
2024-07-11 15:43:49,410 [INFO    ] __main__: train step 944: loss: 0.3187, policy_loss: 1.8982, value_loss: 1.0043
2024-07-11 15:43:49,626 [INFO    ] __main__: train step 945: loss: 0.3188, policy_loss: 1.8982, value_loss: 1.0043
2024-07-11 15:43:49,824 [INFO    ] __main__: train step 946: loss: 0.3190, policy_loss: 1.8981, value_loss: 1.0043
2024-07-11 15:43:50,024 [INFO    ] __main__: train step 947: loss: 0.3191, policy_loss: 1.8980, value_loss: 1.0043
2024-07-11 15:43:50,432 [INFO    ] __main__: train step 948: loss: 0.3193, policy_loss: 1.8979, value_loss: 1.0043
2024-07-11 15:43:50,664 [INFO    ] __main__: train step 949: loss: 0.3195, policy_loss: 1.8978, value_loss: 1.0043
2024-07-11 15:43:50,867 [INFO    ] __main__: train step 950: loss: 0.3196, policy_loss: 1.8978, value_loss: 1.0043
2024-07-11 15:43:51,064 [INFO    ] __main__: train step 951: loss: 0.3198, policy_loss: 1.8977, value_loss: 1.0043
2024-07-11 15:43:52,596 [INFO    ] __main__: replay_buffer size = 32768
2024-07-11 15:43:52,844 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:43:54,008 [INFO    ] __main__: train step 952: loss: 0.3200, policy_loss: 1.8976, value_loss: 1.0043
2024-07-11 15:43:54,179 [INFO    ] __main__: train step 953: loss: 0.3201, policy_loss: 1.8975, value_loss: 1.0043
2024-07-11 15:43:54,378 [INFO    ] __main__: train step 954: loss: 0.3202, policy_loss: 1.8975, value_loss: 1.0043
2024-07-11 15:43:54,582 [INFO    ] __main__: train step 955: loss: 0.3204, policy_loss: 1.8974, value_loss: 1.0043
2024-07-11 15:43:54,775 [INFO    ] __main__: train step 956: loss: 0.3206, policy_loss: 1.8973, value_loss: 1.0043
2024-07-11 15:43:54,969 [INFO    ] __main__: train step 957: loss: 0.3207, policy_loss: 1.8973, value_loss: 1.0043
2024-07-11 15:43:55,166 [INFO    ] __main__: train step 958: loss: 0.3209, policy_loss: 1.8972, value_loss: 1.0043
2024-07-11 15:43:55,360 [INFO    ] __main__: train step 959: loss: 0.3210, policy_loss: 1.8971, value_loss: 1.0042
2024-07-11 15:43:55,567 [INFO    ] __main__: train step 960: loss: 0.3212, policy_loss: 1.8971, value_loss: 1.0042
2024-07-11 15:43:55,772 [INFO    ] __main__: train step 961: loss: 0.3213, policy_loss: 1.8970, value_loss: 1.0043
2024-07-11 15:43:55,965 [INFO    ] __main__: train step 962: loss: 0.3215, policy_loss: 1.8969, value_loss: 1.0042
2024-07-11 15:43:56,171 [INFO    ] __main__: train step 963: loss: 0.3217, policy_loss: 1.8969, value_loss: 1.0042
2024-07-11 15:43:56,539 [INFO    ] __main__: train step 964: loss: 0.3218, policy_loss: 1.8968, value_loss: 1.0042
2024-07-11 15:43:56,750 [INFO    ] __main__: train step 965: loss: 0.3220, policy_loss: 1.8967, value_loss: 1.0042
2024-07-11 15:43:56,948 [INFO    ] __main__: train step 966: loss: 0.3221, policy_loss: 1.8967, value_loss: 1.0043
2024-07-11 15:43:57,157 [INFO    ] __main__: train step 967: loss: 0.3223, policy_loss: 1.8966, value_loss: 1.0043
2024-07-11 15:43:57,373 [INFO    ] __main__: train step 968: loss: 0.3224, policy_loss: 1.8965, value_loss: 1.0042
2024-07-11 15:43:58,949 [INFO    ] __main__: replay_buffer size = 33280
2024-07-11 15:43:59,180 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:44:00,956 [INFO    ] __main__: train step 969: loss: 0.3226, policy_loss: 1.8964, value_loss: 1.0042
2024-07-11 15:44:01,137 [INFO    ] __main__: train step 970: loss: 0.3227, policy_loss: 1.8963, value_loss: 1.0042
2024-07-11 15:44:01,357 [INFO    ] __main__: train step 971: loss: 0.3229, policy_loss: 1.8963, value_loss: 1.0042
2024-07-11 15:44:01,558 [INFO    ] __main__: train step 972: loss: 0.3230, policy_loss: 1.8962, value_loss: 1.0042
2024-07-11 15:44:01,761 [INFO    ] __main__: train step 973: loss: 0.3232, policy_loss: 1.8961, value_loss: 1.0042
2024-07-11 15:44:01,949 [INFO    ] __main__: train step 974: loss: 0.3234, policy_loss: 1.8960, value_loss: 1.0041
2024-07-11 15:44:02,166 [INFO    ] __main__: train step 975: loss: 0.3236, policy_loss: 1.8960, value_loss: 1.0041
2024-07-11 15:44:02,393 [INFO    ] __main__: train step 976: loss: 0.3237, policy_loss: 1.8959, value_loss: 1.0041
2024-07-11 15:44:02,592 [INFO    ] __main__: train step 977: loss: 0.3239, policy_loss: 1.8958, value_loss: 1.0041
2024-07-11 15:44:02,833 [INFO    ] __main__: train step 978: loss: 0.3240, policy_loss: 1.8957, value_loss: 1.0041
2024-07-11 15:44:03,250 [INFO    ] __main__: train step 979: loss: 0.3242, policy_loss: 1.8957, value_loss: 1.0041
2024-07-11 15:44:03,472 [INFO    ] __main__: train step 980: loss: 0.3244, policy_loss: 1.8956, value_loss: 1.0041
2024-07-11 15:44:03,660 [INFO    ] __main__: train step 981: loss: 0.3245, policy_loss: 1.8955, value_loss: 1.0040
2024-07-11 15:44:03,853 [INFO    ] __main__: train step 982: loss: 0.3247, policy_loss: 1.8954, value_loss: 1.0040
2024-07-11 15:44:04,048 [INFO    ] __main__: train step 983: loss: 0.3248, policy_loss: 1.8954, value_loss: 1.0040
2024-07-11 15:44:04,246 [INFO    ] __main__: train step 984: loss: 0.3250, policy_loss: 1.8953, value_loss: 1.0040
2024-07-11 15:44:04,437 [INFO    ] __main__: train step 985: loss: 0.3252, policy_loss: 1.8952, value_loss: 1.0040
2024-07-11 15:44:05,997 [INFO    ] __main__: replay_buffer size = 33792
2024-07-11 15:44:06,237 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:44:08,029 [INFO    ] __main__: train step 986: loss: 0.3253, policy_loss: 1.8952, value_loss: 1.0040
2024-07-11 15:44:08,199 [INFO    ] __main__: train step 987: loss: 0.3255, policy_loss: 1.8951, value_loss: 1.0040
2024-07-11 15:44:08,407 [INFO    ] __main__: train step 988: loss: 0.3256, policy_loss: 1.8950, value_loss: 1.0039
2024-07-11 15:44:08,605 [INFO    ] __main__: train step 989: loss: 0.3257, policy_loss: 1.8949, value_loss: 1.0039
2024-07-11 15:44:08,805 [INFO    ] __main__: train step 990: loss: 0.3259, policy_loss: 1.8948, value_loss: 1.0039
2024-07-11 15:44:09,005 [INFO    ] __main__: train step 991: loss: 0.3260, policy_loss: 1.8948, value_loss: 1.0039
2024-07-11 15:44:09,215 [INFO    ] __main__: train step 992: loss: 0.3262, policy_loss: 1.8947, value_loss: 1.0039
2024-07-11 15:44:09,455 [INFO    ] __main__: train step 993: loss: 0.3263, policy_loss: 1.8946, value_loss: 1.0039
2024-07-11 15:44:09,837 [INFO    ] __main__: train step 994: loss: 0.3265, policy_loss: 1.8946, value_loss: 1.0039
2024-07-11 15:44:10,031 [INFO    ] __main__: train step 995: loss: 0.3267, policy_loss: 1.8945, value_loss: 1.0039
2024-07-11 15:44:10,234 [INFO    ] __main__: train step 996: loss: 0.3268, policy_loss: 1.8944, value_loss: 1.0039
2024-07-11 15:44:10,488 [INFO    ] __main__: train step 997: loss: 0.3270, policy_loss: 1.8943, value_loss: 1.0039
2024-07-11 15:44:10,712 [INFO    ] __main__: train step 998: loss: 0.3271, policy_loss: 1.8943, value_loss: 1.0039
2024-07-11 15:44:10,918 [INFO    ] __main__: train step 999: loss: 0.3273, policy_loss: 1.8942, value_loss: 1.0039
2024-07-11 15:44:11,116 [INFO    ] __main__: train step 1000: loss: 0.3274, policy_loss: 1.8941, value_loss: 1.0039
2024-07-11 15:44:11,268 [INFO    ] __main__: restored step 0 for evaluation
2024-07-11 15:44:28,275 [INFO    ] __main__: later network ELO difference from earlier network: +400 (+10/-10) ELO from 32000 self-played games
2024-07-11 15:44:28,275 [INFO    ] __main__: game outcomes: W: 28202, D: 0, L: 3798
2024-07-11 15:44:28,277 [INFO    ] __main__: validation_elo_delta: 400, validation_elo: 400
2024-07-11 15:44:29,621 [INFO    ] __main__: train step 1001: loss: 0.3276, policy_loss: 1.8940, value_loss: 1.0039
2024-07-11 15:44:29,824 [INFO    ] __main__: train step 1002: loss: 0.3277, policy_loss: 1.8940, value_loss: 1.0039
2024-07-11 15:44:31,601 [INFO    ] __main__: replay_buffer size = 34304
2024-07-11 15:44:31,835 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:44:33,641 [INFO    ] __main__: train step 1003: loss: 0.3279, policy_loss: 1.8939, value_loss: 1.0039
2024-07-11 15:44:33,810 [INFO    ] __main__: train step 1004: loss: 0.3280, policy_loss: 1.8938, value_loss: 1.0038
2024-07-11 15:44:34,033 [INFO    ] __main__: train step 1005: loss: 0.3282, policy_loss: 1.8937, value_loss: 1.0038
2024-07-11 15:44:34,232 [INFO    ] __main__: train step 1006: loss: 0.3284, policy_loss: 1.8937, value_loss: 1.0038
2024-07-11 15:44:34,470 [INFO    ] __main__: train step 1007: loss: 0.3285, policy_loss: 1.8936, value_loss: 1.0038
2024-07-11 15:44:34,684 [INFO    ] __main__: train step 1008: loss: 0.3287, policy_loss: 1.8935, value_loss: 1.0038
2024-07-11 15:44:34,919 [INFO    ] __main__: train step 1009: loss: 0.3288, policy_loss: 1.8935, value_loss: 1.0038
2024-07-11 15:44:35,118 [INFO    ] __main__: train step 1010: loss: 0.3290, policy_loss: 1.8934, value_loss: 1.0038
2024-07-11 15:44:35,335 [INFO    ] __main__: train step 1011: loss: 0.3291, policy_loss: 1.8933, value_loss: 1.0038
2024-07-11 15:44:35,542 [INFO    ] __main__: train step 1012: loss: 0.3293, policy_loss: 1.8932, value_loss: 1.0038
2024-07-11 15:44:35,747 [INFO    ] __main__: train step 1013: loss: 0.3295, policy_loss: 1.8932, value_loss: 1.0038
2024-07-11 15:44:35,949 [INFO    ] __main__: train step 1014: loss: 0.3296, policy_loss: 1.8931, value_loss: 1.0039
2024-07-11 15:44:36,162 [INFO    ] __main__: train step 1015: loss: 0.3298, policy_loss: 1.8930, value_loss: 1.0039
2024-07-11 15:44:36,374 [INFO    ] __main__: train step 1016: loss: 0.3300, policy_loss: 1.8930, value_loss: 1.0038
2024-07-11 15:44:36,574 [INFO    ] __main__: train step 1017: loss: 0.3301, policy_loss: 1.8929, value_loss: 1.0038
2024-07-11 15:44:36,776 [INFO    ] __main__: train step 1018: loss: 0.3303, policy_loss: 1.8928, value_loss: 1.0038
2024-07-11 15:44:36,969 [INFO    ] __main__: train step 1019: loss: 0.3305, policy_loss: 1.8927, value_loss: 1.0039
2024-07-11 15:44:38,542 [INFO    ] __main__: replay_buffer size = 34816
2024-07-11 15:44:38,820 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:44:40,118 [INFO    ] __main__: train step 1020: loss: 0.3306, policy_loss: 1.8927, value_loss: 1.0039
2024-07-11 15:44:40,291 [INFO    ] __main__: train step 1021: loss: 0.3308, policy_loss: 1.8926, value_loss: 1.0038
2024-07-11 15:44:40,500 [INFO    ] __main__: train step 1022: loss: 0.3309, policy_loss: 1.8925, value_loss: 1.0038
2024-07-11 15:44:40,925 [INFO    ] __main__: train step 1023: loss: 0.3311, policy_loss: 1.8925, value_loss: 1.0038
2024-07-11 15:44:41,133 [INFO    ] __main__: train step 1024: loss: 0.3312, policy_loss: 1.8924, value_loss: 1.0039
2024-07-11 15:44:41,336 [INFO    ] __main__: train step 1025: loss: 0.3314, policy_loss: 1.8924, value_loss: 1.0038
2024-07-11 15:44:41,527 [INFO    ] __main__: train step 1026: loss: 0.3316, policy_loss: 1.8923, value_loss: 1.0038
2024-07-11 15:44:41,724 [INFO    ] __main__: train step 1027: loss: 0.3317, policy_loss: 1.8923, value_loss: 1.0038
2024-07-11 15:44:41,923 [INFO    ] __main__: train step 1028: loss: 0.3319, policy_loss: 1.8922, value_loss: 1.0038
2024-07-11 15:44:42,115 [INFO    ] __main__: train step 1029: loss: 0.3320, policy_loss: 1.8921, value_loss: 1.0038
2024-07-11 15:44:42,316 [INFO    ] __main__: train step 1030: loss: 0.3322, policy_loss: 1.8921, value_loss: 1.0038
2024-07-11 15:44:42,515 [INFO    ] __main__: train step 1031: loss: 0.3323, policy_loss: 1.8920, value_loss: 1.0038
2024-07-11 15:44:42,711 [INFO    ] __main__: train step 1032: loss: 0.3325, policy_loss: 1.8919, value_loss: 1.0038
2024-07-11 15:44:42,902 [INFO    ] __main__: train step 1033: loss: 0.3327, policy_loss: 1.8919, value_loss: 1.0038
2024-07-11 15:44:43,107 [INFO    ] __main__: train step 1034: loss: 0.3328, policy_loss: 1.8918, value_loss: 1.0038
2024-07-11 15:44:43,299 [INFO    ] __main__: train step 1035: loss: 0.3330, policy_loss: 1.8917, value_loss: 1.0038
2024-07-11 15:44:43,511 [INFO    ] __main__: train step 1036: loss: 0.3332, policy_loss: 1.8917, value_loss: 1.0038
2024-07-11 15:44:45,106 [INFO    ] __main__: replay_buffer size = 35328
2024-07-11 15:44:45,364 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:44:47,165 [INFO    ] __main__: train step 1037: loss: 0.3333, policy_loss: 1.8916, value_loss: 1.0038
2024-07-11 15:44:47,342 [INFO    ] __main__: train step 1038: loss: 0.3335, policy_loss: 1.8915, value_loss: 1.0038
2024-07-11 15:44:47,549 [INFO    ] __main__: train step 1039: loss: 0.3336, policy_loss: 1.8914, value_loss: 1.0038
2024-07-11 15:44:47,753 [INFO    ] __main__: train step 1040: loss: 0.3338, policy_loss: 1.8914, value_loss: 1.0038
2024-07-11 15:44:48,184 [INFO    ] __main__: train step 1041: loss: 0.3340, policy_loss: 1.8913, value_loss: 1.0038
2024-07-11 15:44:48,393 [INFO    ] __main__: train step 1042: loss: 0.3341, policy_loss: 1.8912, value_loss: 1.0037
2024-07-11 15:44:48,591 [INFO    ] __main__: train step 1043: loss: 0.3343, policy_loss: 1.8911, value_loss: 1.0038
2024-07-11 15:44:48,786 [INFO    ] __main__: train step 1044: loss: 0.3345, policy_loss: 1.8911, value_loss: 1.0038
2024-07-11 15:44:48,988 [INFO    ] __main__: train step 1045: loss: 0.3346, policy_loss: 1.8910, value_loss: 1.0037
2024-07-11 15:44:49,194 [INFO    ] __main__: train step 1046: loss: 0.3348, policy_loss: 1.8909, value_loss: 1.0037
2024-07-11 15:44:49,401 [INFO    ] __main__: train step 1047: loss: 0.3349, policy_loss: 1.8909, value_loss: 1.0038
2024-07-11 15:44:49,607 [INFO    ] __main__: train step 1048: loss: 0.3351, policy_loss: 1.8908, value_loss: 1.0038
2024-07-11 15:44:49,816 [INFO    ] __main__: train step 1049: loss: 0.3353, policy_loss: 1.8907, value_loss: 1.0037
2024-07-11 15:44:50,018 [INFO    ] __main__: train step 1050: loss: 0.3354, policy_loss: 1.8906, value_loss: 1.0038
2024-07-11 15:44:50,219 [INFO    ] __main__: train step 1051: loss: 0.3356, policy_loss: 1.8906, value_loss: 1.0038
2024-07-11 15:44:50,413 [INFO    ] __main__: train step 1052: loss: 0.3358, policy_loss: 1.8905, value_loss: 1.0038
2024-07-11 15:44:50,613 [INFO    ] __main__: train step 1053: loss: 0.3359, policy_loss: 1.8904, value_loss: 1.0038
2024-07-11 15:44:52,169 [INFO    ] __main__: replay_buffer size = 35840
2024-07-11 15:44:52,421 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:44:54,205 [INFO    ] __main__: train step 1054: loss: 0.3361, policy_loss: 1.8904, value_loss: 1.0038
2024-07-11 15:44:54,371 [INFO    ] __main__: train step 1055: loss: 0.3363, policy_loss: 1.8903, value_loss: 1.0038
2024-07-11 15:44:54,585 [INFO    ] __main__: train step 1056: loss: 0.3364, policy_loss: 1.8902, value_loss: 1.0038
2024-07-11 15:44:54,782 [INFO    ] __main__: train step 1057: loss: 0.3366, policy_loss: 1.8901, value_loss: 1.0037
2024-07-11 15:44:54,987 [INFO    ] __main__: train step 1058: loss: 0.3368, policy_loss: 1.8901, value_loss: 1.0037
2024-07-11 15:44:55,195 [INFO    ] __main__: train step 1059: loss: 0.3370, policy_loss: 1.8900, value_loss: 1.0037
2024-07-11 15:44:55,421 [INFO    ] __main__: train step 1060: loss: 0.3371, policy_loss: 1.8899, value_loss: 1.0037
2024-07-11 15:44:55,823 [INFO    ] __main__: train step 1061: loss: 0.3373, policy_loss: 1.8898, value_loss: 1.0038
2024-07-11 15:44:56,252 [INFO    ] __main__: train step 1062: loss: 0.3374, policy_loss: 1.8898, value_loss: 1.0037
2024-07-11 15:44:56,480 [INFO    ] __main__: train step 1063: loss: 0.3376, policy_loss: 1.8897, value_loss: 1.0037
2024-07-11 15:44:56,676 [INFO    ] __main__: train step 1064: loss: 0.3378, policy_loss: 1.8896, value_loss: 1.0037
2024-07-11 15:44:56,874 [INFO    ] __main__: train step 1065: loss: 0.3379, policy_loss: 1.8895, value_loss: 1.0037
2024-07-11 15:44:57,080 [INFO    ] __main__: train step 1066: loss: 0.3381, policy_loss: 1.8895, value_loss: 1.0037
2024-07-11 15:44:57,292 [INFO    ] __main__: train step 1067: loss: 0.3382, policy_loss: 1.8894, value_loss: 1.0037
2024-07-11 15:44:57,503 [INFO    ] __main__: train step 1068: loss: 0.3384, policy_loss: 1.8893, value_loss: 1.0037
2024-07-11 15:44:57,688 [INFO    ] __main__: train step 1069: loss: 0.3385, policy_loss: 1.8893, value_loss: 1.0037
2024-07-11 15:44:57,895 [INFO    ] __main__: train step 1070: loss: 0.3387, policy_loss: 1.8892, value_loss: 1.0037
2024-07-11 15:44:59,436 [INFO    ] __main__: replay_buffer size = 36352
2024-07-11 15:44:59,705 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:45:01,512 [INFO    ] __main__: train step 1071: loss: 0.3388, policy_loss: 1.8891, value_loss: 1.0036
2024-07-11 15:45:01,685 [INFO    ] __main__: train step 1072: loss: 0.3390, policy_loss: 1.8891, value_loss: 1.0036
2024-07-11 15:45:01,898 [INFO    ] __main__: train step 1073: loss: 0.3391, policy_loss: 1.8890, value_loss: 1.0036
2024-07-11 15:45:02,099 [INFO    ] __main__: train step 1074: loss: 0.3393, policy_loss: 1.8889, value_loss: 1.0036
2024-07-11 15:45:02,307 [INFO    ] __main__: train step 1075: loss: 0.3394, policy_loss: 1.8889, value_loss: 1.0036
2024-07-11 15:45:02,519 [INFO    ] __main__: train step 1076: loss: 0.3396, policy_loss: 1.8888, value_loss: 1.0036
2024-07-11 15:45:02,735 [INFO    ] __main__: train step 1077: loss: 0.3397, policy_loss: 1.8888, value_loss: 1.0036
2024-07-11 15:45:02,964 [INFO    ] __main__: train step 1078: loss: 0.3399, policy_loss: 1.8887, value_loss: 1.0036
2024-07-11 15:45:03,162 [INFO    ] __main__: train step 1079: loss: 0.3400, policy_loss: 1.8886, value_loss: 1.0036
2024-07-11 15:45:03,365 [INFO    ] __main__: train step 1080: loss: 0.3402, policy_loss: 1.8886, value_loss: 1.0036
2024-07-11 15:45:03,566 [INFO    ] __main__: train step 1081: loss: 0.3404, policy_loss: 1.8885, value_loss: 1.0036
2024-07-11 15:45:03,995 [INFO    ] __main__: train step 1082: loss: 0.3405, policy_loss: 1.8884, value_loss: 1.0036
2024-07-11 15:45:04,206 [INFO    ] __main__: train step 1083: loss: 0.3407, policy_loss: 1.8884, value_loss: 1.0036
2024-07-11 15:45:04,408 [INFO    ] __main__: train step 1084: loss: 0.3409, policy_loss: 1.8883, value_loss: 1.0036
2024-07-11 15:45:04,622 [INFO    ] __main__: train step 1085: loss: 0.3410, policy_loss: 1.8883, value_loss: 1.0036
2024-07-11 15:45:04,872 [INFO    ] __main__: train step 1086: loss: 0.3412, policy_loss: 1.8882, value_loss: 1.0036
2024-07-11 15:45:05,114 [INFO    ] __main__: train step 1087: loss: 0.3414, policy_loss: 1.8881, value_loss: 1.0037
2024-07-11 15:45:06,669 [INFO    ] __main__: replay_buffer size = 36864
2024-07-11 15:45:06,891 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:45:08,183 [INFO    ] __main__: train step 1088: loss: 0.3415, policy_loss: 1.8881, value_loss: 1.0037
2024-07-11 15:45:08,373 [INFO    ] __main__: train step 1089: loss: 0.3417, policy_loss: 1.8880, value_loss: 1.0037
2024-07-11 15:45:08,579 [INFO    ] __main__: train step 1090: loss: 0.3418, policy_loss: 1.8879, value_loss: 1.0037
2024-07-11 15:45:08,779 [INFO    ] __main__: train step 1091: loss: 0.3420, policy_loss: 1.8879, value_loss: 1.0037
2024-07-11 15:45:08,985 [INFO    ] __main__: train step 1092: loss: 0.3422, policy_loss: 1.8878, value_loss: 1.0037
2024-07-11 15:45:09,203 [INFO    ] __main__: train step 1093: loss: 0.3423, policy_loss: 1.8877, value_loss: 1.0037
2024-07-11 15:45:09,391 [INFO    ] __main__: train step 1094: loss: 0.3425, policy_loss: 1.8876, value_loss: 1.0037
2024-07-11 15:45:09,599 [INFO    ] __main__: train step 1095: loss: 0.3426, policy_loss: 1.8876, value_loss: 1.0037
2024-07-11 15:45:09,803 [INFO    ] __main__: train step 1096: loss: 0.3428, policy_loss: 1.8875, value_loss: 1.0037
2024-07-11 15:45:10,004 [INFO    ] __main__: train step 1097: loss: 0.3430, policy_loss: 1.8874, value_loss: 1.0037
2024-07-11 15:45:10,221 [INFO    ] __main__: train step 1098: loss: 0.3431, policy_loss: 1.8874, value_loss: 1.0037
2024-07-11 15:45:10,417 [INFO    ] __main__: train step 1099: loss: 0.3433, policy_loss: 1.8873, value_loss: 1.0037
2024-07-11 15:45:10,625 [INFO    ] __main__: train step 1100: loss: 0.3435, policy_loss: 1.8872, value_loss: 1.0037
2024-07-11 15:45:10,850 [INFO    ] __main__: train step 1101: loss: 0.3436, policy_loss: 1.8872, value_loss: 1.0037
2024-07-11 15:45:11,311 [INFO    ] __main__: train step 1102: loss: 0.3438, policy_loss: 1.8871, value_loss: 1.0037
2024-07-11 15:45:11,544 [INFO    ] __main__: train step 1103: loss: 0.3440, policy_loss: 1.8870, value_loss: 1.0037
2024-07-11 15:45:11,740 [INFO    ] __main__: train step 1104: loss: 0.3441, policy_loss: 1.8870, value_loss: 1.0036
2024-07-11 15:45:13,305 [INFO    ] __main__: replay_buffer size = 37376
2024-07-11 15:45:13,578 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:45:15,377 [INFO    ] __main__: train step 1105: loss: 0.3443, policy_loss: 1.8869, value_loss: 1.0036
2024-07-11 15:45:15,539 [INFO    ] __main__: train step 1106: loss: 0.3444, policy_loss: 1.8868, value_loss: 1.0036
2024-07-11 15:45:15,748 [INFO    ] __main__: train step 1107: loss: 0.3446, policy_loss: 1.8868, value_loss: 1.0036
2024-07-11 15:45:15,950 [INFO    ] __main__: train step 1108: loss: 0.3448, policy_loss: 1.8867, value_loss: 1.0036
2024-07-11 15:45:16,148 [INFO    ] __main__: train step 1109: loss: 0.3449, policy_loss: 1.8866, value_loss: 1.0036
2024-07-11 15:45:16,344 [INFO    ] __main__: train step 1110: loss: 0.3451, policy_loss: 1.8866, value_loss: 1.0036
2024-07-11 15:45:16,556 [INFO    ] __main__: train step 1111: loss: 0.3453, policy_loss: 1.8865, value_loss: 1.0036
2024-07-11 15:45:16,784 [INFO    ] __main__: train step 1112: loss: 0.3454, policy_loss: 1.8864, value_loss: 1.0036
2024-07-11 15:45:16,981 [INFO    ] __main__: train step 1113: loss: 0.3456, policy_loss: 1.8863, value_loss: 1.0036
2024-07-11 15:45:17,199 [INFO    ] __main__: train step 1114: loss: 0.3457, policy_loss: 1.8862, value_loss: 1.0036
2024-07-11 15:45:17,401 [INFO    ] __main__: train step 1115: loss: 0.3459, policy_loss: 1.8862, value_loss: 1.0036
2024-07-11 15:45:17,600 [INFO    ] __main__: train step 1116: loss: 0.3461, policy_loss: 1.8861, value_loss: 1.0036
2024-07-11 15:45:17,791 [INFO    ] __main__: train step 1117: loss: 0.3462, policy_loss: 1.8860, value_loss: 1.0036
2024-07-11 15:45:17,984 [INFO    ] __main__: train step 1118: loss: 0.3464, policy_loss: 1.8860, value_loss: 1.0036
2024-07-11 15:45:18,195 [INFO    ] __main__: train step 1119: loss: 0.3466, policy_loss: 1.8859, value_loss: 1.0036
2024-07-11 15:45:18,409 [INFO    ] __main__: train step 1120: loss: 0.3467, policy_loss: 1.8858, value_loss: 1.0036
2024-07-11 15:45:18,598 [INFO    ] __main__: train step 1121: loss: 0.3469, policy_loss: 1.8857, value_loss: 1.0036
2024-07-11 15:45:20,374 [INFO    ] __main__: replay_buffer size = 37888
2024-07-11 15:45:20,642 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:45:22,446 [INFO    ] __main__: train step 1122: loss: 0.3471, policy_loss: 1.8857, value_loss: 1.0036
2024-07-11 15:45:22,623 [INFO    ] __main__: train step 1123: loss: 0.3472, policy_loss: 1.8856, value_loss: 1.0035
2024-07-11 15:45:22,832 [INFO    ] __main__: train step 1124: loss: 0.3474, policy_loss: 1.8855, value_loss: 1.0035
2024-07-11 15:45:23,036 [INFO    ] __main__: train step 1125: loss: 0.3476, policy_loss: 1.8855, value_loss: 1.0035
2024-07-11 15:45:23,238 [INFO    ] __main__: train step 1126: loss: 0.3477, policy_loss: 1.8854, value_loss: 1.0035
2024-07-11 15:45:23,449 [INFO    ] __main__: train step 1127: loss: 0.3479, policy_loss: 1.8853, value_loss: 1.0035
2024-07-11 15:45:23,642 [INFO    ] __main__: train step 1128: loss: 0.3480, policy_loss: 1.8853, value_loss: 1.0035
2024-07-11 15:45:23,849 [INFO    ] __main__: train step 1129: loss: 0.3482, policy_loss: 1.8852, value_loss: 1.0035
2024-07-11 15:45:24,038 [INFO    ] __main__: train step 1130: loss: 0.3484, policy_loss: 1.8851, value_loss: 1.0035
2024-07-11 15:45:24,240 [INFO    ] __main__: train step 1131: loss: 0.3485, policy_loss: 1.8851, value_loss: 1.0035
2024-07-11 15:45:24,441 [INFO    ] __main__: train step 1132: loss: 0.3487, policy_loss: 1.8850, value_loss: 1.0035
2024-07-11 15:45:24,635 [INFO    ] __main__: train step 1133: loss: 0.3488, policy_loss: 1.8849, value_loss: 1.0035
2024-07-11 15:45:24,830 [INFO    ] __main__: train step 1134: loss: 0.3490, policy_loss: 1.8849, value_loss: 1.0035
2024-07-11 15:45:25,032 [INFO    ] __main__: train step 1135: loss: 0.3491, policy_loss: 1.8848, value_loss: 1.0034
2024-07-11 15:45:25,230 [INFO    ] __main__: train step 1136: loss: 0.3493, policy_loss: 1.8847, value_loss: 1.0035
2024-07-11 15:45:25,437 [INFO    ] __main__: train step 1137: loss: 0.3495, policy_loss: 1.8847, value_loss: 1.0034
2024-07-11 15:45:25,657 [INFO    ] __main__: train step 1138: loss: 0.3496, policy_loss: 1.8846, value_loss: 1.0034
2024-07-11 15:45:27,218 [INFO    ] __main__: replay_buffer size = 38400
2024-07-11 15:45:27,452 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:45:29,304 [INFO    ] __main__: train step 1139: loss: 0.3498, policy_loss: 1.8845, value_loss: 1.0035
2024-07-11 15:45:29,708 [INFO    ] __main__: train step 1140: loss: 0.3500, policy_loss: 1.8845, value_loss: 1.0034
2024-07-11 15:45:29,922 [INFO    ] __main__: train step 1141: loss: 0.3501, policy_loss: 1.8844, value_loss: 1.0034
2024-07-11 15:45:30,150 [INFO    ] __main__: train step 1142: loss: 0.3503, policy_loss: 1.8843, value_loss: 1.0034
2024-07-11 15:45:30,372 [INFO    ] __main__: train step 1143: loss: 0.3504, policy_loss: 1.8843, value_loss: 1.0034
2024-07-11 15:45:30,563 [INFO    ] __main__: train step 1144: loss: 0.3506, policy_loss: 1.8842, value_loss: 1.0035
2024-07-11 15:45:30,762 [INFO    ] __main__: train step 1145: loss: 0.3508, policy_loss: 1.8841, value_loss: 1.0035
2024-07-11 15:45:30,972 [INFO    ] __main__: train step 1146: loss: 0.3510, policy_loss: 1.8841, value_loss: 1.0035
2024-07-11 15:45:31,168 [INFO    ] __main__: train step 1147: loss: 0.3511, policy_loss: 1.8840, value_loss: 1.0035
2024-07-11 15:45:31,368 [INFO    ] __main__: train step 1148: loss: 0.3513, policy_loss: 1.8839, value_loss: 1.0035
2024-07-11 15:45:31,572 [INFO    ] __main__: train step 1149: loss: 0.3515, policy_loss: 1.8839, value_loss: 1.0035
2024-07-11 15:45:31,799 [INFO    ] __main__: train step 1150: loss: 0.3516, policy_loss: 1.8838, value_loss: 1.0035
2024-07-11 15:45:31,995 [INFO    ] __main__: train step 1151: loss: 0.3518, policy_loss: 1.8838, value_loss: 1.0034
2024-07-11 15:45:32,206 [INFO    ] __main__: train step 1152: loss: 0.3519, policy_loss: 1.8837, value_loss: 1.0035
2024-07-11 15:45:32,391 [INFO    ] __main__: train step 1153: loss: 0.3521, policy_loss: 1.8836, value_loss: 1.0035
2024-07-11 15:45:32,592 [INFO    ] __main__: train step 1154: loss: 0.3522, policy_loss: 1.8836, value_loss: 1.0034
2024-07-11 15:45:32,791 [INFO    ] __main__: train step 1155: loss: 0.3524, policy_loss: 1.8835, value_loss: 1.0034
2024-07-11 15:45:34,339 [INFO    ] __main__: replay_buffer size = 38912
2024-07-11 15:45:34,589 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:45:35,871 [INFO    ] __main__: train step 1156: loss: 0.3525, policy_loss: 1.8834, value_loss: 1.0034
2024-07-11 15:45:36,042 [INFO    ] __main__: train step 1157: loss: 0.3527, policy_loss: 1.8834, value_loss: 1.0034
2024-07-11 15:45:36,278 [INFO    ] __main__: train step 1158: loss: 0.3528, policy_loss: 1.8833, value_loss: 1.0034
2024-07-11 15:45:36,477 [INFO    ] __main__: train step 1159: loss: 0.3530, policy_loss: 1.8832, value_loss: 1.0033
2024-07-11 15:45:36,695 [INFO    ] __main__: train step 1160: loss: 0.3532, policy_loss: 1.8832, value_loss: 1.0033
2024-07-11 15:45:37,157 [INFO    ] __main__: train step 1161: loss: 0.3533, policy_loss: 1.8831, value_loss: 1.0033
2024-07-11 15:45:37,392 [INFO    ] __main__: train step 1162: loss: 0.3535, policy_loss: 1.8831, value_loss: 1.0033
2024-07-11 15:45:37,587 [INFO    ] __main__: train step 1163: loss: 0.3537, policy_loss: 1.8830, value_loss: 1.0033
2024-07-11 15:45:37,796 [INFO    ] __main__: train step 1164: loss: 0.3538, policy_loss: 1.8829, value_loss: 1.0033
2024-07-11 15:45:38,005 [INFO    ] __main__: train step 1165: loss: 0.3540, policy_loss: 1.8829, value_loss: 1.0033
2024-07-11 15:45:38,209 [INFO    ] __main__: train step 1166: loss: 0.3541, policy_loss: 1.8828, value_loss: 1.0033
2024-07-11 15:45:38,426 [INFO    ] __main__: train step 1167: loss: 0.3543, policy_loss: 1.8827, value_loss: 1.0033
2024-07-11 15:45:38,652 [INFO    ] __main__: train step 1168: loss: 0.3545, policy_loss: 1.8827, value_loss: 1.0033
2024-07-11 15:45:38,858 [INFO    ] __main__: train step 1169: loss: 0.3546, policy_loss: 1.8826, value_loss: 1.0033
2024-07-11 15:45:39,091 [INFO    ] __main__: train step 1170: loss: 0.3548, policy_loss: 1.8825, value_loss: 1.0033
2024-07-11 15:45:39,289 [INFO    ] __main__: train step 1171: loss: 0.3549, policy_loss: 1.8825, value_loss: 1.0033
2024-07-11 15:45:39,486 [INFO    ] __main__: train step 1172: loss: 0.3551, policy_loss: 1.8824, value_loss: 1.0033
2024-07-11 15:45:41,052 [INFO    ] __main__: replay_buffer size = 39424
2024-07-11 15:45:41,313 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:45:43,087 [INFO    ] __main__: train step 1173: loss: 0.3553, policy_loss: 1.8823, value_loss: 1.0033
2024-07-11 15:45:43,263 [INFO    ] __main__: train step 1174: loss: 0.3555, policy_loss: 1.8822, value_loss: 1.0033
2024-07-11 15:45:43,482 [INFO    ] __main__: train step 1175: loss: 0.3556, policy_loss: 1.8822, value_loss: 1.0033
2024-07-11 15:45:43,691 [INFO    ] __main__: train step 1176: loss: 0.3558, policy_loss: 1.8821, value_loss: 1.0033
2024-07-11 15:45:43,889 [INFO    ] __main__: train step 1177: loss: 0.3559, policy_loss: 1.8821, value_loss: 1.0033
2024-07-11 15:45:44,093 [INFO    ] __main__: train step 1178: loss: 0.3561, policy_loss: 1.8820, value_loss: 1.0033
2024-07-11 15:45:44,320 [INFO    ] __main__: train step 1179: loss: 0.3563, policy_loss: 1.8819, value_loss: 1.0033
2024-07-11 15:45:44,529 [INFO    ] __main__: train step 1180: loss: 0.3565, policy_loss: 1.8819, value_loss: 1.0034
2024-07-11 15:45:44,965 [INFO    ] __main__: train step 1181: loss: 0.3566, policy_loss: 1.8818, value_loss: 1.0034
2024-07-11 15:45:45,184 [INFO    ] __main__: train step 1182: loss: 0.3568, policy_loss: 1.8817, value_loss: 1.0033
2024-07-11 15:45:45,401 [INFO    ] __main__: train step 1183: loss: 0.3569, policy_loss: 1.8816, value_loss: 1.0033
2024-07-11 15:45:45,592 [INFO    ] __main__: train step 1184: loss: 0.3571, policy_loss: 1.8816, value_loss: 1.0034
2024-07-11 15:45:45,809 [INFO    ] __main__: train step 1185: loss: 0.3573, policy_loss: 1.8815, value_loss: 1.0034
2024-07-11 15:45:46,019 [INFO    ] __main__: train step 1186: loss: 0.3574, policy_loss: 1.8814, value_loss: 1.0034
2024-07-11 15:45:46,227 [INFO    ] __main__: train step 1187: loss: 0.3576, policy_loss: 1.8814, value_loss: 1.0034
2024-07-11 15:45:46,440 [INFO    ] __main__: train step 1188: loss: 0.3578, policy_loss: 1.8813, value_loss: 1.0034
2024-07-11 15:45:46,636 [INFO    ] __main__: train step 1189: loss: 0.3579, policy_loss: 1.8812, value_loss: 1.0034
2024-07-11 15:45:48,202 [INFO    ] __main__: replay_buffer size = 39936
2024-07-11 15:45:48,558 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:45:50,334 [INFO    ] __main__: train step 1190: loss: 0.3581, policy_loss: 1.8812, value_loss: 1.0034
2024-07-11 15:45:50,503 [INFO    ] __main__: train step 1191: loss: 0.3582, policy_loss: 1.8811, value_loss: 1.0034
2024-07-11 15:45:50,722 [INFO    ] __main__: train step 1192: loss: 0.3584, policy_loss: 1.8810, value_loss: 1.0033
2024-07-11 15:45:50,918 [INFO    ] __main__: train step 1193: loss: 0.3586, policy_loss: 1.8809, value_loss: 1.0033
2024-07-11 15:45:51,115 [INFO    ] __main__: train step 1194: loss: 0.3587, policy_loss: 1.8809, value_loss: 1.0033
2024-07-11 15:45:51,316 [INFO    ] __main__: train step 1195: loss: 0.3589, policy_loss: 1.8808, value_loss: 1.0033
2024-07-11 15:45:51,518 [INFO    ] __main__: train step 1196: loss: 0.3591, policy_loss: 1.8807, value_loss: 1.0033
2024-07-11 15:45:51,717 [INFO    ] __main__: train step 1197: loss: 0.3592, policy_loss: 1.8807, value_loss: 1.0033
2024-07-11 15:45:51,923 [INFO    ] __main__: train step 1198: loss: 0.3594, policy_loss: 1.8806, value_loss: 1.0033
2024-07-11 15:45:52,117 [INFO    ] __main__: train step 1199: loss: 0.3595, policy_loss: 1.8805, value_loss: 1.0033
2024-07-11 15:45:52,322 [INFO    ] __main__: train step 1200: loss: 0.3597, policy_loss: 1.8805, value_loss: 1.0033
2024-07-11 15:45:52,771 [INFO    ] __main__: train step 1201: loss: 0.3599, policy_loss: 1.8804, value_loss: 1.0033
2024-07-11 15:45:52,975 [INFO    ] __main__: train step 1202: loss: 0.3600, policy_loss: 1.8803, value_loss: 1.0033
2024-07-11 15:45:53,182 [INFO    ] __main__: train step 1203: loss: 0.3602, policy_loss: 1.8803, value_loss: 1.0033
2024-07-11 15:45:53,397 [INFO    ] __main__: train step 1204: loss: 0.3604, policy_loss: 1.8802, value_loss: 1.0033
2024-07-11 15:45:53,596 [INFO    ] __main__: train step 1205: loss: 0.3605, policy_loss: 1.8801, value_loss: 1.0033
2024-07-11 15:45:53,791 [INFO    ] __main__: train step 1206: loss: 0.3607, policy_loss: 1.8801, value_loss: 1.0032
2024-07-11 15:45:55,326 [INFO    ] __main__: replay_buffer size = 40448
2024-07-11 15:45:55,588 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:45:57,384 [INFO    ] __main__: train step 1207: loss: 0.3609, policy_loss: 1.8800, value_loss: 1.0033
2024-07-11 15:45:57,548 [INFO    ] __main__: train step 1208: loss: 0.3610, policy_loss: 1.8800, value_loss: 1.0032
2024-07-11 15:45:57,771 [INFO    ] __main__: train step 1209: loss: 0.3612, policy_loss: 1.8799, value_loss: 1.0033
2024-07-11 15:45:57,968 [INFO    ] __main__: train step 1210: loss: 0.3613, policy_loss: 1.8798, value_loss: 1.0033
2024-07-11 15:45:58,164 [INFO    ] __main__: train step 1211: loss: 0.3615, policy_loss: 1.8798, value_loss: 1.0033
2024-07-11 15:45:58,376 [INFO    ] __main__: train step 1212: loss: 0.3616, policy_loss: 1.8797, value_loss: 1.0033
2024-07-11 15:45:58,593 [INFO    ] __main__: train step 1213: loss: 0.3618, policy_loss: 1.8796, value_loss: 1.0033
2024-07-11 15:45:58,789 [INFO    ] __main__: train step 1214: loss: 0.3620, policy_loss: 1.8796, value_loss: 1.0033
2024-07-11 15:45:58,991 [INFO    ] __main__: train step 1215: loss: 0.3621, policy_loss: 1.8795, value_loss: 1.0033
2024-07-11 15:45:59,202 [INFO    ] __main__: train step 1216: loss: 0.3623, policy_loss: 1.8795, value_loss: 1.0032
2024-07-11 15:45:59,400 [INFO    ] __main__: train step 1217: loss: 0.3624, policy_loss: 1.8794, value_loss: 1.0032
2024-07-11 15:45:59,604 [INFO    ] __main__: train step 1218: loss: 0.3626, policy_loss: 1.8793, value_loss: 1.0032
2024-07-11 15:45:59,797 [INFO    ] __main__: train step 1219: loss: 0.3628, policy_loss: 1.8793, value_loss: 1.0032
2024-07-11 15:45:59,997 [INFO    ] __main__: train step 1220: loss: 0.3629, policy_loss: 1.8792, value_loss: 1.0032
2024-07-11 15:46:00,201 [INFO    ] __main__: train step 1221: loss: 0.3631, policy_loss: 1.8792, value_loss: 1.0032
2024-07-11 15:46:00,641 [INFO    ] __main__: train step 1222: loss: 0.3633, policy_loss: 1.8791, value_loss: 1.0032
2024-07-11 15:46:00,870 [INFO    ] __main__: train step 1223: loss: 0.3634, policy_loss: 1.8791, value_loss: 1.0032
2024-07-11 15:46:02,445 [INFO    ] __main__: replay_buffer size = 40960
2024-07-11 15:46:02,673 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:46:03,946 [INFO    ] __main__: train step 1224: loss: 0.3636, policy_loss: 1.8790, value_loss: 1.0032
2024-07-11 15:46:04,111 [INFO    ] __main__: train step 1225: loss: 0.3637, policy_loss: 1.8789, value_loss: 1.0032
2024-07-11 15:46:04,326 [INFO    ] __main__: train step 1226: loss: 0.3639, policy_loss: 1.8788, value_loss: 1.0031
2024-07-11 15:46:04,535 [INFO    ] __main__: train step 1227: loss: 0.3641, policy_loss: 1.8788, value_loss: 1.0031
2024-07-11 15:46:04,744 [INFO    ] __main__: train step 1228: loss: 0.3642, policy_loss: 1.8787, value_loss: 1.0031
2024-07-11 15:46:04,967 [INFO    ] __main__: train step 1229: loss: 0.3644, policy_loss: 1.8786, value_loss: 1.0031
2024-07-11 15:46:05,208 [INFO    ] __main__: train step 1230: loss: 0.3646, policy_loss: 1.8786, value_loss: 1.0031
2024-07-11 15:46:05,457 [INFO    ] __main__: train step 1231: loss: 0.3648, policy_loss: 1.8785, value_loss: 1.0031
2024-07-11 15:46:05,678 [INFO    ] __main__: train step 1232: loss: 0.3649, policy_loss: 1.8784, value_loss: 1.0031
2024-07-11 15:46:05,887 [INFO    ] __main__: train step 1233: loss: 0.3651, policy_loss: 1.8784, value_loss: 1.0031
2024-07-11 15:46:06,088 [INFO    ] __main__: train step 1234: loss: 0.3652, policy_loss: 1.8783, value_loss: 1.0031
2024-07-11 15:46:06,328 [INFO    ] __main__: train step 1235: loss: 0.3654, policy_loss: 1.8782, value_loss: 1.0030
2024-07-11 15:46:06,527 [INFO    ] __main__: train step 1236: loss: 0.3656, policy_loss: 1.8781, value_loss: 1.0030
2024-07-11 15:46:06,727 [INFO    ] __main__: train step 1237: loss: 0.3658, policy_loss: 1.8781, value_loss: 1.0030
2024-07-11 15:46:06,928 [INFO    ] __main__: train step 1238: loss: 0.3659, policy_loss: 1.8780, value_loss: 1.0030
2024-07-11 15:46:07,123 [INFO    ] __main__: train step 1239: loss: 0.3661, policy_loss: 1.8779, value_loss: 1.0030
2024-07-11 15:46:07,334 [INFO    ] __main__: train step 1240: loss: 0.3662, policy_loss: 1.8779, value_loss: 1.0030
2024-07-11 15:46:08,897 [INFO    ] __main__: replay_buffer size = 41472
2024-07-11 15:46:09,143 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:46:11,188 [INFO    ] __main__: train step 1241: loss: 0.3664, policy_loss: 1.8778, value_loss: 1.0030
2024-07-11 15:46:11,356 [INFO    ] __main__: train step 1242: loss: 0.3666, policy_loss: 1.8777, value_loss: 1.0029
2024-07-11 15:46:11,565 [INFO    ] __main__: train step 1243: loss: 0.3667, policy_loss: 1.8777, value_loss: 1.0029
2024-07-11 15:46:11,765 [INFO    ] __main__: train step 1244: loss: 0.3669, policy_loss: 1.8776, value_loss: 1.0029
2024-07-11 15:46:11,963 [INFO    ] __main__: train step 1245: loss: 0.3670, policy_loss: 1.8775, value_loss: 1.0029
2024-07-11 15:46:12,166 [INFO    ] __main__: train step 1246: loss: 0.3672, policy_loss: 1.8775, value_loss: 1.0029
2024-07-11 15:46:12,364 [INFO    ] __main__: train step 1247: loss: 0.3674, policy_loss: 1.8774, value_loss: 1.0029
2024-07-11 15:46:12,562 [INFO    ] __main__: train step 1248: loss: 0.3675, policy_loss: 1.8773, value_loss: 1.0029
2024-07-11 15:46:12,772 [INFO    ] __main__: train step 1249: loss: 0.3677, policy_loss: 1.8772, value_loss: 1.0029
2024-07-11 15:46:12,979 [INFO    ] __main__: train step 1250: loss: 0.3679, policy_loss: 1.8772, value_loss: 1.0029
2024-07-11 15:46:13,170 [INFO    ] __main__: train step 1251: loss: 0.3680, policy_loss: 1.8771, value_loss: 1.0029
2024-07-11 15:46:13,374 [INFO    ] __main__: train step 1252: loss: 0.3682, policy_loss: 1.8770, value_loss: 1.0029
2024-07-11 15:46:13,586 [INFO    ] __main__: train step 1253: loss: 0.3683, policy_loss: 1.8770, value_loss: 1.0029
2024-07-11 15:46:13,787 [INFO    ] __main__: train step 1254: loss: 0.3685, policy_loss: 1.8769, value_loss: 1.0029
2024-07-11 15:46:13,992 [INFO    ] __main__: train step 1255: loss: 0.3687, policy_loss: 1.8768, value_loss: 1.0028
2024-07-11 15:46:14,197 [INFO    ] __main__: train step 1256: loss: 0.3688, policy_loss: 1.8768, value_loss: 1.0028
2024-07-11 15:46:14,396 [INFO    ] __main__: train step 1257: loss: 0.3690, policy_loss: 1.8767, value_loss: 1.0028
2024-07-11 15:46:15,941 [INFO    ] __main__: replay_buffer size = 41984
2024-07-11 15:46:16,214 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:46:18,020 [INFO    ] __main__: train step 1258: loss: 0.3692, policy_loss: 1.8766, value_loss: 1.0028
2024-07-11 15:46:18,190 [INFO    ] __main__: train step 1259: loss: 0.3693, policy_loss: 1.8766, value_loss: 1.0028
2024-07-11 15:46:18,411 [INFO    ] __main__: train step 1260: loss: 0.3695, policy_loss: 1.8765, value_loss: 1.0028
2024-07-11 15:46:18,616 [INFO    ] __main__: train step 1261: loss: 0.3697, policy_loss: 1.8764, value_loss: 1.0028
2024-07-11 15:46:19,060 [INFO    ] __main__: train step 1262: loss: 0.3698, policy_loss: 1.8763, value_loss: 1.0028
2024-07-11 15:46:19,262 [INFO    ] __main__: train step 1263: loss: 0.3700, policy_loss: 1.8763, value_loss: 1.0028
2024-07-11 15:46:19,478 [INFO    ] __main__: train step 1264: loss: 0.3702, policy_loss: 1.8762, value_loss: 1.0028
2024-07-11 15:46:19,724 [INFO    ] __main__: train step 1265: loss: 0.3703, policy_loss: 1.8761, value_loss: 1.0027
2024-07-11 15:46:19,919 [INFO    ] __main__: train step 1266: loss: 0.3705, policy_loss: 1.8760, value_loss: 1.0027
2024-07-11 15:46:20,117 [INFO    ] __main__: train step 1267: loss: 0.3707, policy_loss: 1.8760, value_loss: 1.0027
2024-07-11 15:46:20,328 [INFO    ] __main__: train step 1268: loss: 0.3708, policy_loss: 1.8759, value_loss: 1.0027
2024-07-11 15:46:20,536 [INFO    ] __main__: train step 1269: loss: 0.3710, policy_loss: 1.8758, value_loss: 1.0027
2024-07-11 15:46:20,744 [INFO    ] __main__: train step 1270: loss: 0.3711, policy_loss: 1.8758, value_loss: 1.0027
2024-07-11 15:46:20,953 [INFO    ] __main__: train step 1271: loss: 0.3713, policy_loss: 1.8757, value_loss: 1.0027
2024-07-11 15:46:21,147 [INFO    ] __main__: train step 1272: loss: 0.3715, policy_loss: 1.8756, value_loss: 1.0027
2024-07-11 15:46:21,343 [INFO    ] __main__: train step 1273: loss: 0.3717, policy_loss: 1.8756, value_loss: 1.0027
2024-07-11 15:46:21,551 [INFO    ] __main__: train step 1274: loss: 0.3718, policy_loss: 1.8755, value_loss: 1.0027
2024-07-11 15:46:23,113 [INFO    ] __main__: replay_buffer size = 42496
2024-07-11 15:46:23,386 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:46:25,135 [INFO    ] __main__: train step 1275: loss: 0.3720, policy_loss: 1.8754, value_loss: 1.0027
2024-07-11 15:46:25,305 [INFO    ] __main__: train step 1276: loss: 0.3722, policy_loss: 1.8754, value_loss: 1.0027
2024-07-11 15:46:25,515 [INFO    ] __main__: train step 1277: loss: 0.3724, policy_loss: 1.8753, value_loss: 1.0027
2024-07-11 15:46:25,709 [INFO    ] __main__: train step 1278: loss: 0.3725, policy_loss: 1.8752, value_loss: 1.0027
2024-07-11 15:46:25,909 [INFO    ] __main__: train step 1279: loss: 0.3727, policy_loss: 1.8752, value_loss: 1.0026
2024-07-11 15:46:26,117 [INFO    ] __main__: train step 1280: loss: 0.3728, policy_loss: 1.8751, value_loss: 1.0026
2024-07-11 15:46:26,317 [INFO    ] __main__: train step 1281: loss: 0.3730, policy_loss: 1.8750, value_loss: 1.0026
2024-07-11 15:46:26,523 [INFO    ] __main__: train step 1282: loss: 0.3732, policy_loss: 1.8750, value_loss: 1.0026
2024-07-11 15:46:26,955 [INFO    ] __main__: train step 1283: loss: 0.3733, policy_loss: 1.8749, value_loss: 1.0026
2024-07-11 15:46:27,184 [INFO    ] __main__: train step 1284: loss: 0.3735, policy_loss: 1.8748, value_loss: 1.0026
2024-07-11 15:46:27,375 [INFO    ] __main__: train step 1285: loss: 0.3737, policy_loss: 1.8748, value_loss: 1.0026
2024-07-11 15:46:27,573 [INFO    ] __main__: train step 1286: loss: 0.3738, policy_loss: 1.8747, value_loss: 1.0026
2024-07-11 15:46:27,767 [INFO    ] __main__: train step 1287: loss: 0.3740, policy_loss: 1.8746, value_loss: 1.0026
2024-07-11 15:46:27,969 [INFO    ] __main__: train step 1288: loss: 0.3741, policy_loss: 1.8746, value_loss: 1.0026
2024-07-11 15:46:28,171 [INFO    ] __main__: train step 1289: loss: 0.3743, policy_loss: 1.8745, value_loss: 1.0026
2024-07-11 15:46:28,371 [INFO    ] __main__: train step 1290: loss: 0.3745, policy_loss: 1.8744, value_loss: 1.0025
2024-07-11 15:46:28,575 [INFO    ] __main__: train step 1291: loss: 0.3746, policy_loss: 1.8744, value_loss: 1.0025
2024-07-11 15:46:30,130 [INFO    ] __main__: replay_buffer size = 43008
2024-07-11 15:46:30,406 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:46:31,672 [INFO    ] __main__: train step 1292: loss: 0.3748, policy_loss: 1.8743, value_loss: 1.0025
2024-07-11 15:46:31,841 [INFO    ] __main__: train step 1293: loss: 0.3750, policy_loss: 1.8742, value_loss: 1.0025
2024-07-11 15:46:32,047 [INFO    ] __main__: train step 1294: loss: 0.3752, policy_loss: 1.8742, value_loss: 1.0025
2024-07-11 15:46:32,257 [INFO    ] __main__: train step 1295: loss: 0.3753, policy_loss: 1.8741, value_loss: 1.0025
2024-07-11 15:46:32,476 [INFO    ] __main__: train step 1296: loss: 0.3755, policy_loss: 1.8740, value_loss: 1.0025
2024-07-11 15:46:32,675 [INFO    ] __main__: train step 1297: loss: 0.3757, policy_loss: 1.8740, value_loss: 1.0025
2024-07-11 15:46:32,862 [INFO    ] __main__: train step 1298: loss: 0.3758, policy_loss: 1.8739, value_loss: 1.0024
2024-07-11 15:46:33,064 [INFO    ] __main__: train step 1299: loss: 0.3760, policy_loss: 1.8738, value_loss: 1.0024
2024-07-11 15:46:33,256 [INFO    ] __main__: train step 1300: loss: 0.3762, policy_loss: 1.8738, value_loss: 1.0024
2024-07-11 15:46:33,463 [INFO    ] __main__: train step 1301: loss: 0.3763, policy_loss: 1.8737, value_loss: 1.0024
2024-07-11 15:46:33,651 [INFO    ] __main__: train step 1302: loss: 0.3765, policy_loss: 1.8736, value_loss: 1.0024
2024-07-11 15:46:34,087 [INFO    ] __main__: train step 1303: loss: 0.3767, policy_loss: 1.8736, value_loss: 1.0023
2024-07-11 15:46:34,321 [INFO    ] __main__: train step 1304: loss: 0.3769, policy_loss: 1.8735, value_loss: 1.0023
2024-07-11 15:46:34,513 [INFO    ] __main__: train step 1305: loss: 0.3770, policy_loss: 1.8735, value_loss: 1.0023
2024-07-11 15:46:34,720 [INFO    ] __main__: train step 1306: loss: 0.3772, policy_loss: 1.8734, value_loss: 1.0023
2024-07-11 15:46:34,928 [INFO    ] __main__: train step 1307: loss: 0.3773, policy_loss: 1.8733, value_loss: 1.0022
2024-07-11 15:46:35,131 [INFO    ] __main__: train step 1308: loss: 0.3775, policy_loss: 1.8733, value_loss: 1.0022
2024-07-11 15:46:36,702 [INFO    ] __main__: replay_buffer size = 43520
2024-07-11 15:46:36,964 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:46:38,792 [INFO    ] __main__: train step 1309: loss: 0.3776, policy_loss: 1.8732, value_loss: 1.0022
2024-07-11 15:46:38,957 [INFO    ] __main__: train step 1310: loss: 0.3778, policy_loss: 1.8731, value_loss: 1.0022
2024-07-11 15:46:39,169 [INFO    ] __main__: train step 1311: loss: 0.3780, policy_loss: 1.8730, value_loss: 1.0022
2024-07-11 15:46:39,379 [INFO    ] __main__: train step 1312: loss: 0.3781, policy_loss: 1.8730, value_loss: 1.0022
2024-07-11 15:46:39,613 [INFO    ] __main__: train step 1313: loss: 0.3783, policy_loss: 1.8729, value_loss: 1.0021
2024-07-11 15:46:39,810 [INFO    ] __main__: train step 1314: loss: 0.3785, policy_loss: 1.8728, value_loss: 1.0021
2024-07-11 15:46:40,029 [INFO    ] __main__: train step 1315: loss: 0.3786, policy_loss: 1.8728, value_loss: 1.0021
2024-07-11 15:46:40,227 [INFO    ] __main__: train step 1316: loss: 0.3788, policy_loss: 1.8727, value_loss: 1.0021
2024-07-11 15:46:40,446 [INFO    ] __main__: train step 1317: loss: 0.3789, policy_loss: 1.8726, value_loss: 1.0021
2024-07-11 15:46:40,673 [INFO    ] __main__: train step 1318: loss: 0.3791, policy_loss: 1.8725, value_loss: 1.0021
2024-07-11 15:46:40,867 [INFO    ] __main__: train step 1319: loss: 0.3793, policy_loss: 1.8725, value_loss: 1.0020
2024-07-11 15:46:41,067 [INFO    ] __main__: train step 1320: loss: 0.3794, policy_loss: 1.8724, value_loss: 1.0020
2024-07-11 15:46:41,282 [INFO    ] __main__: train step 1321: loss: 0.3796, policy_loss: 1.8723, value_loss: 1.0020
2024-07-11 15:46:41,471 [INFO    ] __main__: train step 1322: loss: 0.3797, policy_loss: 1.8723, value_loss: 1.0020
2024-07-11 15:46:41,672 [INFO    ] __main__: train step 1323: loss: 0.3799, policy_loss: 1.8722, value_loss: 1.0020
2024-07-11 15:46:42,112 [INFO    ] __main__: train step 1324: loss: 0.3801, policy_loss: 1.8721, value_loss: 1.0020
2024-07-11 15:46:42,325 [INFO    ] __main__: train step 1325: loss: 0.3802, policy_loss: 1.8721, value_loss: 1.0020
2024-07-11 15:46:43,877 [INFO    ] __main__: replay_buffer size = 44032
2024-07-11 15:46:44,167 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:46:45,918 [INFO    ] __main__: train step 1326: loss: 0.3804, policy_loss: 1.8720, value_loss: 1.0020
2024-07-11 15:46:46,083 [INFO    ] __main__: train step 1327: loss: 0.3806, policy_loss: 1.8719, value_loss: 1.0019
2024-07-11 15:46:46,300 [INFO    ] __main__: train step 1328: loss: 0.3808, policy_loss: 1.8719, value_loss: 1.0019
2024-07-11 15:46:46,521 [INFO    ] __main__: train step 1329: loss: 0.3809, policy_loss: 1.8718, value_loss: 1.0019
2024-07-11 15:46:46,740 [INFO    ] __main__: train step 1330: loss: 0.3811, policy_loss: 1.8717, value_loss: 1.0019
2024-07-11 15:46:46,957 [INFO    ] __main__: train step 1331: loss: 0.3812, policy_loss: 1.8717, value_loss: 1.0018
2024-07-11 15:46:47,169 [INFO    ] __main__: train step 1332: loss: 0.3814, policy_loss: 1.8716, value_loss: 1.0018
2024-07-11 15:46:47,385 [INFO    ] __main__: train step 1333: loss: 0.3815, policy_loss: 1.8715, value_loss: 1.0018
2024-07-11 15:46:47,615 [INFO    ] __main__: train step 1334: loss: 0.3817, policy_loss: 1.8715, value_loss: 1.0018
2024-07-11 15:46:47,812 [INFO    ] __main__: train step 1335: loss: 0.3818, policy_loss: 1.8714, value_loss: 1.0018
2024-07-11 15:46:48,002 [INFO    ] __main__: train step 1336: loss: 0.3820, policy_loss: 1.8713, value_loss: 1.0018
2024-07-11 15:46:48,203 [INFO    ] __main__: train step 1337: loss: 0.3822, policy_loss: 1.8713, value_loss: 1.0018
2024-07-11 15:46:48,394 [INFO    ] __main__: train step 1338: loss: 0.3824, policy_loss: 1.8712, value_loss: 1.0018
2024-07-11 15:46:48,592 [INFO    ] __main__: train step 1339: loss: 0.3825, policy_loss: 1.8711, value_loss: 1.0017
2024-07-11 15:46:48,790 [INFO    ] __main__: train step 1340: loss: 0.3827, policy_loss: 1.8711, value_loss: 1.0017
2024-07-11 15:46:48,990 [INFO    ] __main__: train step 1341: loss: 0.3829, policy_loss: 1.8710, value_loss: 1.0017
2024-07-11 15:46:49,183 [INFO    ] __main__: train step 1342: loss: 0.3830, policy_loss: 1.8710, value_loss: 1.0017
2024-07-11 15:46:50,732 [INFO    ] __main__: replay_buffer size = 44544
2024-07-11 15:46:50,969 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:46:52,791 [INFO    ] __main__: train step 1343: loss: 0.3832, policy_loss: 1.8709, value_loss: 1.0017
2024-07-11 15:46:52,966 [INFO    ] __main__: train step 1344: loss: 0.3834, policy_loss: 1.8708, value_loss: 1.0016
2024-07-11 15:46:53,450 [INFO    ] __main__: train step 1345: loss: 0.3835, policy_loss: 1.8708, value_loss: 1.0016
2024-07-11 15:46:53,666 [INFO    ] __main__: train step 1346: loss: 0.3837, policy_loss: 1.8707, value_loss: 1.0016
2024-07-11 15:46:53,880 [INFO    ] __main__: train step 1347: loss: 0.3839, policy_loss: 1.8706, value_loss: 1.0015
2024-07-11 15:46:54,069 [INFO    ] __main__: train step 1348: loss: 0.3840, policy_loss: 1.8706, value_loss: 1.0015
2024-07-11 15:46:54,278 [INFO    ] __main__: train step 1349: loss: 0.3842, policy_loss: 1.8705, value_loss: 1.0015
2024-07-11 15:46:54,473 [INFO    ] __main__: train step 1350: loss: 0.3844, policy_loss: 1.8704, value_loss: 1.0015
2024-07-11 15:46:54,694 [INFO    ] __main__: train step 1351: loss: 0.3845, policy_loss: 1.8704, value_loss: 1.0015
2024-07-11 15:46:54,902 [INFO    ] __main__: train step 1352: loss: 0.3847, policy_loss: 1.8703, value_loss: 1.0015
2024-07-11 15:46:55,113 [INFO    ] __main__: train step 1353: loss: 0.3848, policy_loss: 1.8702, value_loss: 1.0015
2024-07-11 15:46:55,312 [INFO    ] __main__: train step 1354: loss: 0.3850, policy_loss: 1.8702, value_loss: 1.0015
2024-07-11 15:46:55,510 [INFO    ] __main__: train step 1355: loss: 0.3851, policy_loss: 1.8701, value_loss: 1.0015
2024-07-11 15:46:55,730 [INFO    ] __main__: train step 1356: loss: 0.3853, policy_loss: 1.8700, value_loss: 1.0015
2024-07-11 15:46:55,952 [INFO    ] __main__: train step 1357: loss: 0.3854, policy_loss: 1.8700, value_loss: 1.0014
2024-07-11 15:46:56,171 [INFO    ] __main__: train step 1358: loss: 0.3856, policy_loss: 1.8699, value_loss: 1.0014
2024-07-11 15:46:56,378 [INFO    ] __main__: train step 1359: loss: 0.3857, policy_loss: 1.8698, value_loss: 1.0014
2024-07-11 15:46:57,939 [INFO    ] __main__: replay_buffer size = 45056
2024-07-11 15:46:58,244 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:46:59,541 [INFO    ] __main__: train step 1360: loss: 0.3859, policy_loss: 1.8697, value_loss: 1.0014
2024-07-11 15:46:59,713 [INFO    ] __main__: train step 1361: loss: 0.3860, policy_loss: 1.8696, value_loss: 1.0014
2024-07-11 15:46:59,923 [INFO    ] __main__: train step 1362: loss: 0.3862, policy_loss: 1.8696, value_loss: 1.0014
2024-07-11 15:47:00,127 [INFO    ] __main__: train step 1363: loss: 0.3863, policy_loss: 1.8695, value_loss: 1.0013
2024-07-11 15:47:00,336 [INFO    ] __main__: train step 1364: loss: 0.3865, policy_loss: 1.8694, value_loss: 1.0013
2024-07-11 15:47:00,533 [INFO    ] __main__: train step 1365: loss: 0.3867, policy_loss: 1.8693, value_loss: 1.0013
2024-07-11 15:47:00,972 [INFO    ] __main__: train step 1366: loss: 0.3869, policy_loss: 1.8693, value_loss: 1.0012
2024-07-11 15:47:01,176 [INFO    ] __main__: train step 1367: loss: 0.3871, policy_loss: 1.8692, value_loss: 1.0012
2024-07-11 15:47:01,382 [INFO    ] __main__: train step 1368: loss: 0.3872, policy_loss: 1.8691, value_loss: 1.0012
2024-07-11 15:47:01,589 [INFO    ] __main__: train step 1369: loss: 0.3874, policy_loss: 1.8690, value_loss: 1.0012
2024-07-11 15:47:01,798 [INFO    ] __main__: train step 1370: loss: 0.3875, policy_loss: 1.8690, value_loss: 1.0012
2024-07-11 15:47:01,995 [INFO    ] __main__: train step 1371: loss: 0.3877, policy_loss: 1.8689, value_loss: 1.0012
2024-07-11 15:47:02,204 [INFO    ] __main__: train step 1372: loss: 0.3879, policy_loss: 1.8688, value_loss: 1.0012
2024-07-11 15:47:02,419 [INFO    ] __main__: train step 1373: loss: 0.3880, policy_loss: 1.8687, value_loss: 1.0012
2024-07-11 15:47:02,641 [INFO    ] __main__: train step 1374: loss: 0.3882, policy_loss: 1.8687, value_loss: 1.0011
2024-07-11 15:47:02,840 [INFO    ] __main__: train step 1375: loss: 0.3884, policy_loss: 1.8686, value_loss: 1.0012
2024-07-11 15:47:03,053 [INFO    ] __main__: train step 1376: loss: 0.3886, policy_loss: 1.8685, value_loss: 1.0011
2024-07-11 15:47:04,626 [INFO    ] __main__: replay_buffer size = 45568
2024-07-11 15:47:04,903 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:47:06,656 [INFO    ] __main__: train step 1377: loss: 0.3887, policy_loss: 1.8685, value_loss: 1.0011
2024-07-11 15:47:06,830 [INFO    ] __main__: train step 1378: loss: 0.3889, policy_loss: 1.8684, value_loss: 1.0011
2024-07-11 15:47:07,049 [INFO    ] __main__: train step 1379: loss: 0.3891, policy_loss: 1.8683, value_loss: 1.0010
2024-07-11 15:47:07,274 [INFO    ] __main__: train step 1380: loss: 0.3892, policy_loss: 1.8682, value_loss: 1.0010
2024-07-11 15:47:07,488 [INFO    ] __main__: train step 1381: loss: 0.3894, policy_loss: 1.8682, value_loss: 1.0010
2024-07-11 15:47:07,708 [INFO    ] __main__: train step 1382: loss: 0.3895, policy_loss: 1.8681, value_loss: 1.0010
2024-07-11 15:47:07,917 [INFO    ] __main__: train step 1383: loss: 0.3897, policy_loss: 1.8680, value_loss: 1.0010
2024-07-11 15:47:08,138 [INFO    ] __main__: train step 1384: loss: 0.3898, policy_loss: 1.8679, value_loss: 1.0010
2024-07-11 15:47:08,338 [INFO    ] __main__: train step 1385: loss: 0.3900, policy_loss: 1.8679, value_loss: 1.0010
2024-07-11 15:47:08,821 [INFO    ] __main__: train step 1386: loss: 0.3901, policy_loss: 1.8678, value_loss: 1.0010
2024-07-11 15:47:09,035 [INFO    ] __main__: train step 1387: loss: 0.3903, policy_loss: 1.8677, value_loss: 1.0010
2024-07-11 15:47:09,241 [INFO    ] __main__: train step 1388: loss: 0.3905, policy_loss: 1.8677, value_loss: 1.0010
2024-07-11 15:47:09,449 [INFO    ] __main__: train step 1389: loss: 0.3906, policy_loss: 1.8676, value_loss: 1.0009
2024-07-11 15:47:09,647 [INFO    ] __main__: train step 1390: loss: 0.3908, policy_loss: 1.8675, value_loss: 1.0009
2024-07-11 15:47:09,890 [INFO    ] __main__: train step 1391: loss: 0.3910, policy_loss: 1.8674, value_loss: 1.0009
2024-07-11 15:47:10,102 [INFO    ] __main__: train step 1392: loss: 0.3912, policy_loss: 1.8674, value_loss: 1.0009
2024-07-11 15:47:10,316 [INFO    ] __main__: train step 1393: loss: 0.3913, policy_loss: 1.8673, value_loss: 1.0009
2024-07-11 15:47:11,853 [INFO    ] __main__: replay_buffer size = 46080
2024-07-11 15:47:12,139 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:47:13,920 [INFO    ] __main__: train step 1394: loss: 0.3915, policy_loss: 1.8672, value_loss: 1.0009
2024-07-11 15:47:14,098 [INFO    ] __main__: train step 1395: loss: 0.3917, policy_loss: 1.8672, value_loss: 1.0009
2024-07-11 15:47:14,309 [INFO    ] __main__: train step 1396: loss: 0.3918, policy_loss: 1.8671, value_loss: 1.0009
2024-07-11 15:47:14,537 [INFO    ] __main__: train step 1397: loss: 0.3920, policy_loss: 1.8670, value_loss: 1.0009
2024-07-11 15:47:14,736 [INFO    ] __main__: train step 1398: loss: 0.3921, policy_loss: 1.8669, value_loss: 1.0009
2024-07-11 15:47:14,949 [INFO    ] __main__: train step 1399: loss: 0.3923, policy_loss: 1.8669, value_loss: 1.0009
2024-07-11 15:47:15,150 [INFO    ] __main__: train step 1400: loss: 0.3925, policy_loss: 1.8668, value_loss: 1.0009
2024-07-11 15:47:15,358 [INFO    ] __main__: train step 1401: loss: 0.3926, policy_loss: 1.8667, value_loss: 1.0009
2024-07-11 15:47:15,560 [INFO    ] __main__: train step 1402: loss: 0.3928, policy_loss: 1.8666, value_loss: 1.0009
2024-07-11 15:47:15,757 [INFO    ] __main__: train step 1403: loss: 0.3929, policy_loss: 1.8666, value_loss: 1.0008
2024-07-11 15:47:15,960 [INFO    ] __main__: train step 1404: loss: 0.3931, policy_loss: 1.8665, value_loss: 1.0008
2024-07-11 15:47:16,158 [INFO    ] __main__: train step 1405: loss: 0.3933, policy_loss: 1.8664, value_loss: 1.0008
2024-07-11 15:47:16,381 [INFO    ] __main__: train step 1406: loss: 0.3934, policy_loss: 1.8663, value_loss: 1.0008
2024-07-11 15:47:16,829 [INFO    ] __main__: train step 1407: loss: 0.3936, policy_loss: 1.8663, value_loss: 1.0008
2024-07-11 15:47:17,026 [INFO    ] __main__: train step 1408: loss: 0.3938, policy_loss: 1.8662, value_loss: 1.0008
2024-07-11 15:47:17,236 [INFO    ] __main__: train step 1409: loss: 0.3939, policy_loss: 1.8661, value_loss: 1.0008
2024-07-11 15:47:17,421 [INFO    ] __main__: train step 1410: loss: 0.3941, policy_loss: 1.8660, value_loss: 1.0008
2024-07-11 15:47:18,995 [INFO    ] __main__: replay_buffer size = 46592
2024-07-11 15:47:19,291 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:47:21,122 [INFO    ] __main__: train step 1411: loss: 0.3943, policy_loss: 1.8660, value_loss: 1.0008
2024-07-11 15:47:21,292 [INFO    ] __main__: train step 1412: loss: 0.3945, policy_loss: 1.8659, value_loss: 1.0007
2024-07-11 15:47:21,504 [INFO    ] __main__: train step 1413: loss: 0.3946, policy_loss: 1.8658, value_loss: 1.0007
2024-07-11 15:47:21,697 [INFO    ] __main__: train step 1414: loss: 0.3948, policy_loss: 1.8657, value_loss: 1.0007
2024-07-11 15:47:21,898 [INFO    ] __main__: train step 1415: loss: 0.3950, policy_loss: 1.8657, value_loss: 1.0007
2024-07-11 15:47:22,087 [INFO    ] __main__: train step 1416: loss: 0.3951, policy_loss: 1.8656, value_loss: 1.0007
2024-07-11 15:47:22,291 [INFO    ] __main__: train step 1417: loss: 0.3953, policy_loss: 1.8655, value_loss: 1.0007
2024-07-11 15:47:22,503 [INFO    ] __main__: train step 1418: loss: 0.3955, policy_loss: 1.8654, value_loss: 1.0007
2024-07-11 15:47:22,714 [INFO    ] __main__: train step 1419: loss: 0.3957, policy_loss: 1.8654, value_loss: 1.0007
2024-07-11 15:47:22,920 [INFO    ] __main__: train step 1420: loss: 0.3958, policy_loss: 1.8653, value_loss: 1.0007
2024-07-11 15:47:23,125 [INFO    ] __main__: train step 1421: loss: 0.3960, policy_loss: 1.8652, value_loss: 1.0007
2024-07-11 15:47:23,328 [INFO    ] __main__: train step 1422: loss: 0.3962, policy_loss: 1.8652, value_loss: 1.0006
2024-07-11 15:47:23,534 [INFO    ] __main__: train step 1423: loss: 0.3963, policy_loss: 1.8651, value_loss: 1.0006
2024-07-11 15:47:23,758 [INFO    ] __main__: train step 1424: loss: 0.3965, policy_loss: 1.8650, value_loss: 1.0006
2024-07-11 15:47:23,965 [INFO    ] __main__: train step 1425: loss: 0.3966, policy_loss: 1.8650, value_loss: 1.0006
2024-07-11 15:47:24,163 [INFO    ] __main__: train step 1426: loss: 0.3968, policy_loss: 1.8649, value_loss: 1.0006
2024-07-11 15:47:24,364 [INFO    ] __main__: train step 1427: loss: 0.3970, policy_loss: 1.8648, value_loss: 1.0006
2024-07-11 15:47:25,923 [INFO    ] __main__: replay_buffer size = 47104
2024-07-11 15:47:26,233 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:47:27,738 [INFO    ] __main__: train step 1428: loss: 0.3971, policy_loss: 1.8648, value_loss: 1.0006
2024-07-11 15:47:27,904 [INFO    ] __main__: train step 1429: loss: 0.3973, policy_loss: 1.8647, value_loss: 1.0006
2024-07-11 15:47:28,114 [INFO    ] __main__: train step 1430: loss: 0.3975, policy_loss: 1.8646, value_loss: 1.0006
2024-07-11 15:47:28,323 [INFO    ] __main__: train step 1431: loss: 0.3977, policy_loss: 1.8645, value_loss: 1.0006
2024-07-11 15:47:28,527 [INFO    ] __main__: train step 1432: loss: 0.3978, policy_loss: 1.8645, value_loss: 1.0006
2024-07-11 15:47:28,741 [INFO    ] __main__: train step 1433: loss: 0.3980, policy_loss: 1.8644, value_loss: 1.0006
2024-07-11 15:47:28,981 [INFO    ] __main__: train step 1434: loss: 0.3981, policy_loss: 1.8643, value_loss: 1.0006
2024-07-11 15:47:29,193 [INFO    ] __main__: train step 1435: loss: 0.3983, policy_loss: 1.8643, value_loss: 1.0005
2024-07-11 15:47:29,392 [INFO    ] __main__: train step 1436: loss: 0.3984, policy_loss: 1.8642, value_loss: 1.0005
2024-07-11 15:47:29,587 [INFO    ] __main__: train step 1437: loss: 0.3986, policy_loss: 1.8641, value_loss: 1.0005
2024-07-11 15:47:29,788 [INFO    ] __main__: train step 1438: loss: 0.3987, policy_loss: 1.8640, value_loss: 1.0005
2024-07-11 15:47:30,016 [INFO    ] __main__: train step 1439: loss: 0.3989, policy_loss: 1.8640, value_loss: 1.0005
2024-07-11 15:47:30,229 [INFO    ] __main__: train step 1440: loss: 0.3990, policy_loss: 1.8639, value_loss: 1.0005
2024-07-11 15:47:30,424 [INFO    ] __main__: train step 1441: loss: 0.3992, policy_loss: 1.8638, value_loss: 1.0005
2024-07-11 15:47:30,632 [INFO    ] __main__: train step 1442: loss: 0.3994, policy_loss: 1.8637, value_loss: 1.0005
2024-07-11 15:47:30,861 [INFO    ] __main__: train step 1443: loss: 0.3995, policy_loss: 1.8637, value_loss: 1.0005
2024-07-11 15:47:31,064 [INFO    ] __main__: train step 1444: loss: 0.3997, policy_loss: 1.8636, value_loss: 1.0005
2024-07-11 15:47:32,634 [INFO    ] __main__: replay_buffer size = 47616
2024-07-11 15:47:32,903 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:47:34,658 [INFO    ] __main__: train step 1445: loss: 0.3999, policy_loss: 1.8635, value_loss: 1.0005
2024-07-11 15:47:34,836 [INFO    ] __main__: train step 1446: loss: 0.4000, policy_loss: 1.8634, value_loss: 1.0004
2024-07-11 15:47:35,052 [INFO    ] __main__: train step 1447: loss: 0.4002, policy_loss: 1.8634, value_loss: 1.0004
2024-07-11 15:47:35,255 [INFO    ] __main__: train step 1448: loss: 0.4004, policy_loss: 1.8633, value_loss: 1.0004
2024-07-11 15:47:35,763 [INFO    ] __main__: train step 1449: loss: 0.4005, policy_loss: 1.8632, value_loss: 1.0004
2024-07-11 15:47:35,971 [INFO    ] __main__: train step 1450: loss: 0.4007, policy_loss: 1.8632, value_loss: 1.0004
2024-07-11 15:47:36,170 [INFO    ] __main__: train step 1451: loss: 0.4009, policy_loss: 1.8631, value_loss: 1.0004
2024-07-11 15:47:36,389 [INFO    ] __main__: train step 1452: loss: 0.4010, policy_loss: 1.8630, value_loss: 1.0003
2024-07-11 15:47:36,566 [INFO    ] __main__: train step 1453: loss: 0.4012, policy_loss: 1.8629, value_loss: 1.0003
2024-07-11 15:47:36,804 [INFO    ] __main__: train step 1454: loss: 0.4014, policy_loss: 1.8629, value_loss: 1.0003
2024-07-11 15:47:37,035 [INFO    ] __main__: train step 1455: loss: 0.4015, policy_loss: 1.8628, value_loss: 1.0003
2024-07-11 15:47:37,271 [INFO    ] __main__: train step 1456: loss: 0.4017, policy_loss: 1.8627, value_loss: 1.0003
2024-07-11 15:47:37,485 [INFO    ] __main__: train step 1457: loss: 0.4018, policy_loss: 1.8627, value_loss: 1.0003
2024-07-11 15:47:37,692 [INFO    ] __main__: train step 1458: loss: 0.4020, policy_loss: 1.8626, value_loss: 1.0003
2024-07-11 15:47:37,932 [INFO    ] __main__: train step 1459: loss: 0.4022, policy_loss: 1.8625, value_loss: 1.0003
2024-07-11 15:47:38,158 [INFO    ] __main__: train step 1460: loss: 0.4023, policy_loss: 1.8624, value_loss: 1.0002
2024-07-11 15:47:38,356 [INFO    ] __main__: train step 1461: loss: 0.4025, policy_loss: 1.8624, value_loss: 1.0002
2024-07-11 15:47:39,919 [INFO    ] __main__: replay_buffer size = 48128
2024-07-11 15:47:40,199 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:47:41,985 [INFO    ] __main__: train step 1462: loss: 0.4027, policy_loss: 1.8623, value_loss: 1.0002
2024-07-11 15:47:42,156 [INFO    ] __main__: train step 1463: loss: 0.4028, policy_loss: 1.8622, value_loss: 1.0002
2024-07-11 15:47:42,366 [INFO    ] __main__: train step 1464: loss: 0.4030, policy_loss: 1.8622, value_loss: 1.0002
2024-07-11 15:47:42,561 [INFO    ] __main__: train step 1465: loss: 0.4032, policy_loss: 1.8621, value_loss: 1.0002
2024-07-11 15:47:42,751 [INFO    ] __main__: train step 1466: loss: 0.4033, policy_loss: 1.8620, value_loss: 1.0002
2024-07-11 15:47:42,939 [INFO    ] __main__: train step 1467: loss: 0.4035, policy_loss: 1.8620, value_loss: 1.0002
2024-07-11 15:47:43,147 [INFO    ] __main__: train step 1468: loss: 0.4037, policy_loss: 1.8619, value_loss: 1.0001
2024-07-11 15:47:43,600 [INFO    ] __main__: train step 1469: loss: 0.4038, policy_loss: 1.8618, value_loss: 1.0001
2024-07-11 15:47:43,820 [INFO    ] __main__: train step 1470: loss: 0.4040, policy_loss: 1.8618, value_loss: 1.0001
2024-07-11 15:47:44,026 [INFO    ] __main__: train step 1471: loss: 0.4042, policy_loss: 1.8617, value_loss: 1.0001
2024-07-11 15:47:44,226 [INFO    ] __main__: train step 1472: loss: 0.4043, policy_loss: 1.8617, value_loss: 1.0001
2024-07-11 15:47:44,437 [INFO    ] __main__: train step 1473: loss: 0.4045, policy_loss: 1.8616, value_loss: 1.0000
2024-07-11 15:47:44,674 [INFO    ] __main__: train step 1474: loss: 0.4047, policy_loss: 1.8615, value_loss: 1.0000
2024-07-11 15:47:44,900 [INFO    ] __main__: train step 1475: loss: 0.4049, policy_loss: 1.8615, value_loss: 1.0000
2024-07-11 15:47:45,095 [INFO    ] __main__: train step 1476: loss: 0.4050, policy_loss: 1.8614, value_loss: 1.0000
2024-07-11 15:47:45,309 [INFO    ] __main__: train step 1477: loss: 0.4052, policy_loss: 1.8613, value_loss: 0.9999
2024-07-11 15:47:45,532 [INFO    ] __main__: train step 1478: loss: 0.4053, policy_loss: 1.8613, value_loss: 0.9999
2024-07-11 15:47:47,138 [INFO    ] __main__: replay_buffer size = 48640
2024-07-11 15:47:47,472 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:47:49,219 [INFO    ] __main__: train step 1479: loss: 0.4055, policy_loss: 1.8612, value_loss: 0.9999
2024-07-11 15:47:49,384 [INFO    ] __main__: train step 1480: loss: 0.4056, policy_loss: 1.8611, value_loss: 0.9999
2024-07-11 15:47:49,612 [INFO    ] __main__: train step 1481: loss: 0.4058, policy_loss: 1.8610, value_loss: 0.9999
2024-07-11 15:47:49,813 [INFO    ] __main__: train step 1482: loss: 0.4060, policy_loss: 1.8610, value_loss: 0.9998
2024-07-11 15:47:50,020 [INFO    ] __main__: train step 1483: loss: 0.4061, policy_loss: 1.8609, value_loss: 0.9998
2024-07-11 15:47:50,224 [INFO    ] __main__: train step 1484: loss: 0.4063, policy_loss: 1.8608, value_loss: 0.9998
2024-07-11 15:47:50,477 [INFO    ] __main__: train step 1485: loss: 0.4065, policy_loss: 1.8608, value_loss: 0.9997
2024-07-11 15:47:50,700 [INFO    ] __main__: train step 1486: loss: 0.4066, policy_loss: 1.8607, value_loss: 0.9997
2024-07-11 15:47:50,894 [INFO    ] __main__: train step 1487: loss: 0.4068, policy_loss: 1.8606, value_loss: 0.9997
2024-07-11 15:47:51,106 [INFO    ] __main__: train step 1488: loss: 0.4070, policy_loss: 1.8606, value_loss: 0.9997
2024-07-11 15:47:51,294 [INFO    ] __main__: train step 1489: loss: 0.4071, policy_loss: 1.8605, value_loss: 0.9997
2024-07-11 15:47:51,486 [INFO    ] __main__: train step 1490: loss: 0.4073, policy_loss: 1.8604, value_loss: 0.9997
2024-07-11 15:47:51,938 [INFO    ] __main__: train step 1491: loss: 0.4074, policy_loss: 1.8603, value_loss: 0.9997
2024-07-11 15:47:52,138 [INFO    ] __main__: train step 1492: loss: 0.4076, policy_loss: 1.8603, value_loss: 0.9997
2024-07-11 15:47:52,337 [INFO    ] __main__: train step 1493: loss: 0.4078, policy_loss: 1.8602, value_loss: 0.9997
2024-07-11 15:47:52,537 [INFO    ] __main__: train step 1494: loss: 0.4079, policy_loss: 1.8601, value_loss: 0.9996
2024-07-11 15:47:52,751 [INFO    ] __main__: train step 1495: loss: 0.4081, policy_loss: 1.8600, value_loss: 0.9996
2024-07-11 15:47:54,309 [INFO    ] __main__: replay_buffer size = 49152
2024-07-11 15:47:54,638 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:47:55,897 [INFO    ] __main__: train step 1496: loss: 0.4083, policy_loss: 1.8600, value_loss: 0.9996
2024-07-11 15:47:56,061 [INFO    ] __main__: train step 1497: loss: 0.4084, policy_loss: 1.8599, value_loss: 0.9996
2024-07-11 15:47:56,298 [INFO    ] __main__: train step 1498: loss: 0.4086, policy_loss: 1.8598, value_loss: 0.9995
2024-07-11 15:47:56,504 [INFO    ] __main__: train step 1499: loss: 0.4088, policy_loss: 1.8597, value_loss: 0.9995
2024-07-11 15:47:56,718 [INFO    ] __main__: train step 1500: loss: 0.4089, policy_loss: 1.8597, value_loss: 0.9995
2024-07-11 15:47:56,936 [INFO    ] __main__: train step 1501: loss: 0.4091, policy_loss: 1.8596, value_loss: 0.9995
2024-07-11 15:47:57,133 [INFO    ] __main__: train step 1502: loss: 0.4093, policy_loss: 1.8595, value_loss: 0.9995
2024-07-11 15:47:57,345 [INFO    ] __main__: train step 1503: loss: 0.4094, policy_loss: 1.8594, value_loss: 0.9995
2024-07-11 15:47:57,549 [INFO    ] __main__: train step 1504: loss: 0.4096, policy_loss: 1.8594, value_loss: 0.9994
2024-07-11 15:47:57,748 [INFO    ] __main__: train step 1505: loss: 0.4098, policy_loss: 1.8593, value_loss: 0.9994
2024-07-11 15:47:57,949 [INFO    ] __main__: train step 1506: loss: 0.4099, policy_loss: 1.8592, value_loss: 0.9994
2024-07-11 15:47:58,155 [INFO    ] __main__: train step 1507: loss: 0.4101, policy_loss: 1.8592, value_loss: 0.9994
2024-07-11 15:47:58,363 [INFO    ] __main__: train step 1508: loss: 0.4103, policy_loss: 1.8591, value_loss: 0.9994
2024-07-11 15:47:58,566 [INFO    ] __main__: train step 1509: loss: 0.4104, policy_loss: 1.8590, value_loss: 0.9993
2024-07-11 15:47:58,789 [INFO    ] __main__: train step 1510: loss: 0.4106, policy_loss: 1.8590, value_loss: 0.9993
2024-07-11 15:47:59,004 [INFO    ] __main__: train step 1511: loss: 0.4108, policy_loss: 1.8589, value_loss: 0.9993
2024-07-11 15:47:59,189 [INFO    ] __main__: train step 1512: loss: 0.4109, policy_loss: 1.8588, value_loss: 0.9993
2024-07-11 15:48:00,986 [INFO    ] __main__: replay_buffer size = 49664
2024-07-11 15:48:01,331 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:48:03,128 [INFO    ] __main__: train step 1513: loss: 0.4111, policy_loss: 1.8588, value_loss: 0.9993
2024-07-11 15:48:03,296 [INFO    ] __main__: train step 1514: loss: 0.4113, policy_loss: 1.8587, value_loss: 0.9993
2024-07-11 15:48:03,511 [INFO    ] __main__: train step 1515: loss: 0.4114, policy_loss: 1.8586, value_loss: 0.9993
2024-07-11 15:48:03,708 [INFO    ] __main__: train step 1516: loss: 0.4116, policy_loss: 1.8585, value_loss: 0.9992
2024-07-11 15:48:03,904 [INFO    ] __main__: train step 1517: loss: 0.4117, policy_loss: 1.8585, value_loss: 0.9992
2024-07-11 15:48:04,099 [INFO    ] __main__: train step 1518: loss: 0.4119, policy_loss: 1.8584, value_loss: 0.9992
2024-07-11 15:48:04,300 [INFO    ] __main__: train step 1519: loss: 0.4120, policy_loss: 1.8583, value_loss: 0.9992
2024-07-11 15:48:04,502 [INFO    ] __main__: train step 1520: loss: 0.4122, policy_loss: 1.8582, value_loss: 0.9991
2024-07-11 15:48:04,706 [INFO    ] __main__: train step 1521: loss: 0.4124, policy_loss: 1.8582, value_loss: 0.9991
2024-07-11 15:48:04,945 [INFO    ] __main__: train step 1522: loss: 0.4125, policy_loss: 1.8581, value_loss: 0.9991
2024-07-11 15:48:05,171 [INFO    ] __main__: train step 1523: loss: 0.4127, policy_loss: 1.8580, value_loss: 0.9991
2024-07-11 15:48:05,380 [INFO    ] __main__: train step 1524: loss: 0.4129, policy_loss: 1.8580, value_loss: 0.9991
2024-07-11 15:48:05,583 [INFO    ] __main__: train step 1525: loss: 0.4130, policy_loss: 1.8579, value_loss: 0.9991
2024-07-11 15:48:05,785 [INFO    ] __main__: train step 1526: loss: 0.4132, policy_loss: 1.8578, value_loss: 0.9991
2024-07-11 15:48:05,992 [INFO    ] __main__: train step 1527: loss: 0.4134, policy_loss: 1.8578, value_loss: 0.9990
2024-07-11 15:48:06,189 [INFO    ] __main__: train step 1528: loss: 0.4135, policy_loss: 1.8577, value_loss: 0.9990
2024-07-11 15:48:06,392 [INFO    ] __main__: train step 1529: loss: 0.4137, policy_loss: 1.8576, value_loss: 0.9990
2024-07-11 15:48:07,952 [INFO    ] __main__: replay_buffer size = 50176
2024-07-11 15:48:08,293 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:48:10,104 [INFO    ] __main__: train step 1530: loss: 0.4139, policy_loss: 1.8576, value_loss: 0.9990
2024-07-11 15:48:10,277 [INFO    ] __main__: train step 1531: loss: 0.4140, policy_loss: 1.8575, value_loss: 0.9990
2024-07-11 15:48:10,496 [INFO    ] __main__: train step 1532: loss: 0.4142, policy_loss: 1.8574, value_loss: 0.9990
2024-07-11 15:48:10,699 [INFO    ] __main__: train step 1533: loss: 0.4144, policy_loss: 1.8574, value_loss: 0.9990
2024-07-11 15:48:11,166 [INFO    ] __main__: train step 1534: loss: 0.4145, policy_loss: 1.8573, value_loss: 0.9989
2024-07-11 15:48:11,374 [INFO    ] __main__: train step 1535: loss: 0.4147, policy_loss: 1.8572, value_loss: 0.9989
2024-07-11 15:48:11,562 [INFO    ] __main__: train step 1536: loss: 0.4148, policy_loss: 1.8571, value_loss: 0.9989
2024-07-11 15:48:11,766 [INFO    ] __main__: train step 1537: loss: 0.4150, policy_loss: 1.8571, value_loss: 0.9989
2024-07-11 15:48:11,974 [INFO    ] __main__: train step 1538: loss: 0.4152, policy_loss: 1.8570, value_loss: 0.9989
2024-07-11 15:48:12,167 [INFO    ] __main__: train step 1539: loss: 0.4154, policy_loss: 1.8570, value_loss: 0.9989
2024-07-11 15:48:12,361 [INFO    ] __main__: train step 1540: loss: 0.4155, policy_loss: 1.8569, value_loss: 0.9988
2024-07-11 15:48:12,563 [INFO    ] __main__: train step 1541: loss: 0.4157, policy_loss: 1.8568, value_loss: 0.9988
2024-07-11 15:48:12,759 [INFO    ] __main__: train step 1542: loss: 0.4159, policy_loss: 1.8567, value_loss: 0.9988
2024-07-11 15:48:12,967 [INFO    ] __main__: train step 1543: loss: 0.4160, policy_loss: 1.8567, value_loss: 0.9988
2024-07-11 15:48:13,172 [INFO    ] __main__: train step 1544: loss: 0.4162, policy_loss: 1.8566, value_loss: 0.9988
2024-07-11 15:48:13,374 [INFO    ] __main__: train step 1545: loss: 0.4164, policy_loss: 1.8565, value_loss: 0.9987
2024-07-11 15:48:13,580 [INFO    ] __main__: train step 1546: loss: 0.4165, policy_loss: 1.8564, value_loss: 0.9987
2024-07-11 15:48:15,129 [INFO    ] __main__: replay_buffer size = 50688
2024-07-11 15:48:15,417 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:48:17,189 [INFO    ] __main__: train step 1547: loss: 0.4167, policy_loss: 1.8564, value_loss: 0.9987
2024-07-11 15:48:17,367 [INFO    ] __main__: train step 1548: loss: 0.4168, policy_loss: 1.8563, value_loss: 0.9987
2024-07-11 15:48:17,581 [INFO    ] __main__: train step 1549: loss: 0.4170, policy_loss: 1.8562, value_loss: 0.9986
2024-07-11 15:48:17,796 [INFO    ] __main__: train step 1550: loss: 0.4172, policy_loss: 1.8562, value_loss: 0.9986
2024-07-11 15:48:17,984 [INFO    ] __main__: train step 1551: loss: 0.4173, policy_loss: 1.8561, value_loss: 0.9986
2024-07-11 15:48:18,175 [INFO    ] __main__: train step 1552: loss: 0.4175, policy_loss: 1.8560, value_loss: 0.9986
2024-07-11 15:48:18,380 [INFO    ] __main__: train step 1553: loss: 0.4177, policy_loss: 1.8560, value_loss: 0.9986
2024-07-11 15:48:18,584 [INFO    ] __main__: train step 1554: loss: 0.4178, policy_loss: 1.8559, value_loss: 0.9986
2024-07-11 15:48:19,042 [INFO    ] __main__: train step 1555: loss: 0.4180, policy_loss: 1.8558, value_loss: 0.9985
2024-07-11 15:48:19,250 [INFO    ] __main__: train step 1556: loss: 0.4182, policy_loss: 1.8558, value_loss: 0.9985
2024-07-11 15:48:19,449 [INFO    ] __main__: train step 1557: loss: 0.4183, policy_loss: 1.8557, value_loss: 0.9985
2024-07-11 15:48:19,658 [INFO    ] __main__: train step 1558: loss: 0.4185, policy_loss: 1.8556, value_loss: 0.9985
2024-07-11 15:48:19,851 [INFO    ] __main__: train step 1559: loss: 0.4187, policy_loss: 1.8555, value_loss: 0.9985
2024-07-11 15:48:20,054 [INFO    ] __main__: train step 1560: loss: 0.4188, policy_loss: 1.8555, value_loss: 0.9984
2024-07-11 15:48:20,261 [INFO    ] __main__: train step 1561: loss: 0.4190, policy_loss: 1.8554, value_loss: 0.9984
2024-07-11 15:48:20,478 [INFO    ] __main__: train step 1562: loss: 0.4192, policy_loss: 1.8553, value_loss: 0.9984
2024-07-11 15:48:20,686 [INFO    ] __main__: train step 1563: loss: 0.4193, policy_loss: 1.8552, value_loss: 0.9984
2024-07-11 15:48:22,280 [INFO    ] __main__: replay_buffer size = 51200
2024-07-11 15:48:22,603 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:48:23,862 [INFO    ] __main__: train step 1564: loss: 0.4195, policy_loss: 1.8552, value_loss: 0.9984
2024-07-11 15:48:24,022 [INFO    ] __main__: train step 1565: loss: 0.4196, policy_loss: 1.8551, value_loss: 0.9984
2024-07-11 15:48:24,252 [INFO    ] __main__: train step 1566: loss: 0.4198, policy_loss: 1.8550, value_loss: 0.9984
2024-07-11 15:48:24,463 [INFO    ] __main__: train step 1567: loss: 0.4200, policy_loss: 1.8550, value_loss: 0.9984
2024-07-11 15:48:24,668 [INFO    ] __main__: train step 1568: loss: 0.4201, policy_loss: 1.8549, value_loss: 0.9984
2024-07-11 15:48:24,868 [INFO    ] __main__: train step 1569: loss: 0.4203, policy_loss: 1.8548, value_loss: 0.9984
2024-07-11 15:48:25,077 [INFO    ] __main__: train step 1570: loss: 0.4205, policy_loss: 1.8547, value_loss: 0.9983
2024-07-11 15:48:25,279 [INFO    ] __main__: train step 1571: loss: 0.4207, policy_loss: 1.8547, value_loss: 0.9983
2024-07-11 15:48:25,493 [INFO    ] __main__: train step 1572: loss: 0.4208, policy_loss: 1.8546, value_loss: 0.9983
2024-07-11 15:48:25,702 [INFO    ] __main__: train step 1573: loss: 0.4210, policy_loss: 1.8546, value_loss: 0.9983
2024-07-11 15:48:25,924 [INFO    ] __main__: train step 1574: loss: 0.4212, policy_loss: 1.8545, value_loss: 0.9983
2024-07-11 15:48:26,107 [INFO    ] __main__: train step 1575: loss: 0.4213, policy_loss: 1.8544, value_loss: 0.9983
2024-07-11 15:48:26,584 [INFO    ] __main__: train step 1576: loss: 0.4215, policy_loss: 1.8543, value_loss: 0.9983
2024-07-11 15:48:26,781 [INFO    ] __main__: train step 1577: loss: 0.4217, policy_loss: 1.8543, value_loss: 0.9982
2024-07-11 15:48:26,983 [INFO    ] __main__: train step 1578: loss: 0.4218, policy_loss: 1.8542, value_loss: 0.9982
2024-07-11 15:48:27,201 [INFO    ] __main__: train step 1579: loss: 0.4220, policy_loss: 1.8541, value_loss: 0.9982
2024-07-11 15:48:27,394 [INFO    ] __main__: train step 1580: loss: 0.4222, policy_loss: 1.8541, value_loss: 0.9982
2024-07-11 15:48:28,972 [INFO    ] __main__: replay_buffer size = 51712
2024-07-11 15:48:29,328 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:48:31,071 [INFO    ] __main__: train step 1581: loss: 0.4223, policy_loss: 1.8540, value_loss: 0.9981
2024-07-11 15:48:31,239 [INFO    ] __main__: train step 1582: loss: 0.4225, policy_loss: 1.8539, value_loss: 0.9981
2024-07-11 15:48:31,468 [INFO    ] __main__: train step 1583: loss: 0.4226, policy_loss: 1.8538, value_loss: 0.9981
2024-07-11 15:48:31,657 [INFO    ] __main__: train step 1584: loss: 0.4228, policy_loss: 1.8538, value_loss: 0.9981
2024-07-11 15:48:31,863 [INFO    ] __main__: train step 1585: loss: 0.4230, policy_loss: 1.8537, value_loss: 0.9980
2024-07-11 15:48:32,055 [INFO    ] __main__: train step 1586: loss: 0.4231, policy_loss: 1.8536, value_loss: 0.9980
2024-07-11 15:48:32,261 [INFO    ] __main__: train step 1587: loss: 0.4233, policy_loss: 1.8536, value_loss: 0.9980
2024-07-11 15:48:32,459 [INFO    ] __main__: train step 1588: loss: 0.4234, policy_loss: 1.8535, value_loss: 0.9980
2024-07-11 15:48:32,655 [INFO    ] __main__: train step 1589: loss: 0.4236, policy_loss: 1.8534, value_loss: 0.9980
2024-07-11 15:48:32,861 [INFO    ] __main__: train step 1590: loss: 0.4238, policy_loss: 1.8533, value_loss: 0.9980
2024-07-11 15:48:33,052 [INFO    ] __main__: train step 1591: loss: 0.4240, policy_loss: 1.8533, value_loss: 0.9979
2024-07-11 15:48:33,249 [INFO    ] __main__: train step 1592: loss: 0.4241, policy_loss: 1.8532, value_loss: 0.9979
2024-07-11 15:48:33,443 [INFO    ] __main__: train step 1593: loss: 0.4243, policy_loss: 1.8531, value_loss: 0.9979
2024-07-11 15:48:33,651 [INFO    ] __main__: train step 1594: loss: 0.4245, policy_loss: 1.8531, value_loss: 0.9979
2024-07-11 15:48:33,844 [INFO    ] __main__: train step 1595: loss: 0.4246, policy_loss: 1.8530, value_loss: 0.9979
2024-07-11 15:48:34,046 [INFO    ] __main__: train step 1596: loss: 0.4248, policy_loss: 1.8529, value_loss: 0.9978
2024-07-11 15:48:34,495 [INFO    ] __main__: train step 1597: loss: 0.4249, policy_loss: 1.8529, value_loss: 0.9978
2024-07-11 15:48:36,062 [INFO    ] __main__: replay_buffer size = 52224
2024-07-11 15:48:36,375 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:48:38,141 [INFO    ] __main__: train step 1598: loss: 0.4251, policy_loss: 1.8528, value_loss: 0.9978
2024-07-11 15:48:38,323 [INFO    ] __main__: train step 1599: loss: 0.4253, policy_loss: 1.8527, value_loss: 0.9978
2024-07-11 15:48:38,526 [INFO    ] __main__: train step 1600: loss: 0.4254, policy_loss: 1.8527, value_loss: 0.9977
2024-07-11 15:48:38,710 [INFO    ] __main__: train step 1601: loss: 0.4256, policy_loss: 1.8526, value_loss: 0.9977
2024-07-11 15:48:38,912 [INFO    ] __main__: train step 1602: loss: 0.4257, policy_loss: 1.8525, value_loss: 0.9977
2024-07-11 15:48:39,107 [INFO    ] __main__: train step 1603: loss: 0.4259, policy_loss: 1.8525, value_loss: 0.9977
2024-07-11 15:48:39,307 [INFO    ] __main__: train step 1604: loss: 0.4261, policy_loss: 1.8524, value_loss: 0.9977
2024-07-11 15:48:39,498 [INFO    ] __main__: train step 1605: loss: 0.4262, policy_loss: 1.8523, value_loss: 0.9977
2024-07-11 15:48:39,697 [INFO    ] __main__: train step 1606: loss: 0.4264, policy_loss: 1.8523, value_loss: 0.9977
2024-07-11 15:48:39,892 [INFO    ] __main__: train step 1607: loss: 0.4266, policy_loss: 1.8522, value_loss: 0.9977
2024-07-11 15:48:40,115 [INFO    ] __main__: train step 1608: loss: 0.4267, policy_loss: 1.8521, value_loss: 0.9977
2024-07-11 15:48:40,307 [INFO    ] __main__: train step 1609: loss: 0.4269, policy_loss: 1.8521, value_loss: 0.9976
2024-07-11 15:48:40,506 [INFO    ] __main__: train step 1610: loss: 0.4271, policy_loss: 1.8520, value_loss: 0.9976
2024-07-11 15:48:40,703 [INFO    ] __main__: train step 1611: loss: 0.4272, policy_loss: 1.8519, value_loss: 0.9976
2024-07-11 15:48:40,919 [INFO    ] __main__: train step 1612: loss: 0.4274, policy_loss: 1.8519, value_loss: 0.9975
2024-07-11 15:48:41,112 [INFO    ] __main__: train step 1613: loss: 0.4276, policy_loss: 1.8518, value_loss: 0.9975
2024-07-11 15:48:41,324 [INFO    ] __main__: train step 1614: loss: 0.4277, policy_loss: 1.8517, value_loss: 0.9975
2024-07-11 15:48:42,876 [INFO    ] __main__: replay_buffer size = 52736
2024-07-11 15:48:43,223 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:48:45,017 [INFO    ] __main__: train step 1615: loss: 0.4279, policy_loss: 1.8517, value_loss: 0.9975
2024-07-11 15:48:45,182 [INFO    ] __main__: train step 1616: loss: 0.4280, policy_loss: 1.8516, value_loss: 0.9975
2024-07-11 15:48:45,402 [INFO    ] __main__: train step 1617: loss: 0.4282, policy_loss: 1.8515, value_loss: 0.9975
2024-07-11 15:48:45,602 [INFO    ] __main__: train step 1618: loss: 0.4284, policy_loss: 1.8515, value_loss: 0.9974
2024-07-11 15:48:46,059 [INFO    ] __main__: train step 1619: loss: 0.4285, policy_loss: 1.8514, value_loss: 0.9974
2024-07-11 15:48:46,291 [INFO    ] __main__: train step 1620: loss: 0.4287, policy_loss: 1.8513, value_loss: 0.9974
2024-07-11 15:48:46,502 [INFO    ] __main__: train step 1621: loss: 0.4289, policy_loss: 1.8513, value_loss: 0.9974
2024-07-11 15:48:46,716 [INFO    ] __main__: train step 1622: loss: 0.4290, policy_loss: 1.8512, value_loss: 0.9974
2024-07-11 15:48:46,925 [INFO    ] __main__: train step 1623: loss: 0.4292, policy_loss: 1.8511, value_loss: 0.9974
2024-07-11 15:48:47,118 [INFO    ] __main__: train step 1624: loss: 0.4293, policy_loss: 1.8510, value_loss: 0.9973
2024-07-11 15:48:47,336 [INFO    ] __main__: train step 1625: loss: 0.4295, policy_loss: 1.8509, value_loss: 0.9973
2024-07-11 15:48:47,567 [INFO    ] __main__: train step 1626: loss: 0.4297, policy_loss: 1.8509, value_loss: 0.9973
2024-07-11 15:48:47,793 [INFO    ] __main__: train step 1627: loss: 0.4299, policy_loss: 1.8508, value_loss: 0.9973
2024-07-11 15:48:47,988 [INFO    ] __main__: train step 1628: loss: 0.4300, policy_loss: 1.8507, value_loss: 0.9972
2024-07-11 15:48:48,187 [INFO    ] __main__: train step 1629: loss: 0.4302, policy_loss: 1.8507, value_loss: 0.9972
2024-07-11 15:48:48,393 [INFO    ] __main__: train step 1630: loss: 0.4304, policy_loss: 1.8506, value_loss: 0.9972
2024-07-11 15:48:48,589 [INFO    ] __main__: train step 1631: loss: 0.4305, policy_loss: 1.8505, value_loss: 0.9972
2024-07-11 15:48:50,153 [INFO    ] __main__: replay_buffer size = 53248
2024-07-11 15:48:50,489 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:48:51,765 [INFO    ] __main__: train step 1632: loss: 0.4307, policy_loss: 1.8504, value_loss: 0.9972
2024-07-11 15:48:51,944 [INFO    ] __main__: train step 1633: loss: 0.4308, policy_loss: 1.8504, value_loss: 0.9972
2024-07-11 15:48:52,144 [INFO    ] __main__: train step 1634: loss: 0.4310, policy_loss: 1.8503, value_loss: 0.9971
2024-07-11 15:48:52,355 [INFO    ] __main__: train step 1635: loss: 0.4312, policy_loss: 1.8502, value_loss: 0.9971
2024-07-11 15:48:52,576 [INFO    ] __main__: train step 1636: loss: 0.4314, policy_loss: 1.8501, value_loss: 0.9971
2024-07-11 15:48:52,796 [INFO    ] __main__: train step 1637: loss: 0.4315, policy_loss: 1.8501, value_loss: 0.9970
2024-07-11 15:48:52,996 [INFO    ] __main__: train step 1638: loss: 0.4317, policy_loss: 1.8500, value_loss: 0.9970
2024-07-11 15:48:53,203 [INFO    ] __main__: train step 1639: loss: 0.4318, policy_loss: 1.8499, value_loss: 0.9970
2024-07-11 15:48:53,683 [INFO    ] __main__: train step 1640: loss: 0.4320, policy_loss: 1.8498, value_loss: 0.9970
2024-07-11 15:48:53,860 [INFO    ] __main__: train step 1641: loss: 0.4322, policy_loss: 1.8498, value_loss: 0.9969
2024-07-11 15:48:54,071 [INFO    ] __main__: train step 1642: loss: 0.4323, policy_loss: 1.8497, value_loss: 0.9969
2024-07-11 15:48:54,275 [INFO    ] __main__: train step 1643: loss: 0.4325, policy_loss: 1.8496, value_loss: 0.9969
2024-07-11 15:48:54,472 [INFO    ] __main__: train step 1644: loss: 0.4327, policy_loss: 1.8495, value_loss: 0.9969
2024-07-11 15:48:54,678 [INFO    ] __main__: train step 1645: loss: 0.4328, policy_loss: 1.8495, value_loss: 0.9968
2024-07-11 15:48:54,877 [INFO    ] __main__: train step 1646: loss: 0.4330, policy_loss: 1.8494, value_loss: 0.9968
2024-07-11 15:48:55,079 [INFO    ] __main__: train step 1647: loss: 0.4332, policy_loss: 1.8493, value_loss: 0.9968
2024-07-11 15:48:55,290 [INFO    ] __main__: train step 1648: loss: 0.4333, policy_loss: 1.8492, value_loss: 0.9968
2024-07-11 15:48:56,850 [INFO    ] __main__: replay_buffer size = 53760
2024-07-11 15:48:57,130 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:48:58,919 [INFO    ] __main__: train step 1649: loss: 0.4335, policy_loss: 1.8492, value_loss: 0.9967
2024-07-11 15:48:59,084 [INFO    ] __main__: train step 1650: loss: 0.4337, policy_loss: 1.8491, value_loss: 0.9967
2024-07-11 15:48:59,311 [INFO    ] __main__: train step 1651: loss: 0.4338, policy_loss: 1.8490, value_loss: 0.9967
2024-07-11 15:48:59,536 [INFO    ] __main__: train step 1652: loss: 0.4340, policy_loss: 1.8489, value_loss: 0.9967
2024-07-11 15:48:59,730 [INFO    ] __main__: train step 1653: loss: 0.4341, policy_loss: 1.8489, value_loss: 0.9966
2024-07-11 15:48:59,948 [INFO    ] __main__: train step 1654: loss: 0.4343, policy_loss: 1.8488, value_loss: 0.9966
2024-07-11 15:49:00,140 [INFO    ] __main__: train step 1655: loss: 0.4345, policy_loss: 1.8487, value_loss: 0.9966
2024-07-11 15:49:00,358 [INFO    ] __main__: train step 1656: loss: 0.4346, policy_loss: 1.8486, value_loss: 0.9966
2024-07-11 15:49:00,549 [INFO    ] __main__: train step 1657: loss: 0.4348, policy_loss: 1.8486, value_loss: 0.9966
2024-07-11 15:49:00,746 [INFO    ] __main__: train step 1658: loss: 0.4350, policy_loss: 1.8485, value_loss: 0.9965
2024-07-11 15:49:00,956 [INFO    ] __main__: train step 1659: loss: 0.4351, policy_loss: 1.8484, value_loss: 0.9965
2024-07-11 15:49:01,144 [INFO    ] __main__: train step 1660: loss: 0.4353, policy_loss: 1.8484, value_loss: 0.9965
2024-07-11 15:49:01,352 [INFO    ] __main__: train step 1661: loss: 0.4355, policy_loss: 1.8483, value_loss: 0.9965
2024-07-11 15:49:01,842 [INFO    ] __main__: train step 1662: loss: 0.4356, policy_loss: 1.8482, value_loss: 0.9964
2024-07-11 15:49:02,067 [INFO    ] __main__: train step 1663: loss: 0.4358, policy_loss: 1.8481, value_loss: 0.9964
2024-07-11 15:49:02,280 [INFO    ] __main__: train step 1664: loss: 0.4359, policy_loss: 1.8481, value_loss: 0.9963
2024-07-11 15:49:02,489 [INFO    ] __main__: train step 1665: loss: 0.4361, policy_loss: 1.8480, value_loss: 0.9963
2024-07-11 15:49:04,072 [INFO    ] __main__: replay_buffer size = 54272
2024-07-11 15:49:04,410 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:49:06,204 [INFO    ] __main__: train step 1666: loss: 0.4363, policy_loss: 1.8479, value_loss: 0.9963
2024-07-11 15:49:06,373 [INFO    ] __main__: train step 1667: loss: 0.4364, policy_loss: 1.8479, value_loss: 0.9963
2024-07-11 15:49:06,589 [INFO    ] __main__: train step 1668: loss: 0.4366, policy_loss: 1.8478, value_loss: 0.9963
2024-07-11 15:49:06,802 [INFO    ] __main__: train step 1669: loss: 0.4367, policy_loss: 1.8477, value_loss: 0.9962
2024-07-11 15:49:06,989 [INFO    ] __main__: train step 1670: loss: 0.4369, policy_loss: 1.8477, value_loss: 0.9962
2024-07-11 15:49:07,193 [INFO    ] __main__: train step 1671: loss: 0.4371, policy_loss: 1.8476, value_loss: 0.9962
2024-07-11 15:49:07,390 [INFO    ] __main__: train step 1672: loss: 0.4372, policy_loss: 1.8475, value_loss: 0.9962
2024-07-11 15:49:07,605 [INFO    ] __main__: train step 1673: loss: 0.4374, policy_loss: 1.8474, value_loss: 0.9962
2024-07-11 15:49:07,801 [INFO    ] __main__: train step 1674: loss: 0.4376, policy_loss: 1.8474, value_loss: 0.9961
2024-07-11 15:49:07,998 [INFO    ] __main__: train step 1675: loss: 0.4377, policy_loss: 1.8473, value_loss: 0.9961
2024-07-11 15:49:08,204 [INFO    ] __main__: train step 1676: loss: 0.4379, policy_loss: 1.8472, value_loss: 0.9961
2024-07-11 15:49:08,420 [INFO    ] __main__: train step 1677: loss: 0.4381, policy_loss: 1.8471, value_loss: 0.9961
2024-07-11 15:49:08,656 [INFO    ] __main__: train step 1678: loss: 0.4382, policy_loss: 1.8471, value_loss: 0.9960
2024-07-11 15:49:08,851 [INFO    ] __main__: train step 1679: loss: 0.4384, policy_loss: 1.8470, value_loss: 0.9960
2024-07-11 15:49:09,051 [INFO    ] __main__: train step 1680: loss: 0.4386, policy_loss: 1.8469, value_loss: 0.9960
2024-07-11 15:49:09,253 [INFO    ] __main__: train step 1681: loss: 0.4387, policy_loss: 1.8468, value_loss: 0.9960
2024-07-11 15:49:09,440 [INFO    ] __main__: train step 1682: loss: 0.4389, policy_loss: 1.8468, value_loss: 0.9959
2024-07-11 15:49:11,000 [INFO    ] __main__: replay_buffer size = 54784
2024-07-11 15:49:11,295 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:49:13,085 [INFO    ] __main__: train step 1683: loss: 0.4391, policy_loss: 1.8467, value_loss: 0.9959
2024-07-11 15:49:13,520 [INFO    ] __main__: train step 1684: loss: 0.4392, policy_loss: 1.8466, value_loss: 0.9959
2024-07-11 15:49:13,735 [INFO    ] __main__: train step 1685: loss: 0.4394, policy_loss: 1.8466, value_loss: 0.9959
2024-07-11 15:49:13,937 [INFO    ] __main__: train step 1686: loss: 0.4396, policy_loss: 1.8465, value_loss: 0.9958
2024-07-11 15:49:14,142 [INFO    ] __main__: train step 1687: loss: 0.4397, policy_loss: 1.8464, value_loss: 0.9958
2024-07-11 15:49:14,365 [INFO    ] __main__: train step 1688: loss: 0.4399, policy_loss: 1.8464, value_loss: 0.9958
2024-07-11 15:49:14,554 [INFO    ] __main__: train step 1689: loss: 0.4401, policy_loss: 1.8463, value_loss: 0.9958
2024-07-11 15:49:14,761 [INFO    ] __main__: train step 1690: loss: 0.4402, policy_loss: 1.8462, value_loss: 0.9958
2024-07-11 15:49:14,959 [INFO    ] __main__: train step 1691: loss: 0.4404, policy_loss: 1.8461, value_loss: 0.9957
2024-07-11 15:49:15,156 [INFO    ] __main__: train step 1692: loss: 0.4406, policy_loss: 1.8461, value_loss: 0.9957
2024-07-11 15:49:15,366 [INFO    ] __main__: train step 1693: loss: 0.4407, policy_loss: 1.8460, value_loss: 0.9957
2024-07-11 15:49:15,572 [INFO    ] __main__: train step 1694: loss: 0.4409, policy_loss: 1.8459, value_loss: 0.9957
2024-07-11 15:49:15,768 [INFO    ] __main__: train step 1695: loss: 0.4410, policy_loss: 1.8458, value_loss: 0.9957
2024-07-11 15:49:15,959 [INFO    ] __main__: train step 1696: loss: 0.4412, policy_loss: 1.8457, value_loss: 0.9956
2024-07-11 15:49:16,161 [INFO    ] __main__: train step 1697: loss: 0.4414, policy_loss: 1.8457, value_loss: 0.9956
2024-07-11 15:49:16,361 [INFO    ] __main__: train step 1698: loss: 0.4416, policy_loss: 1.8456, value_loss: 0.9956
2024-07-11 15:49:16,598 [INFO    ] __main__: train step 1699: loss: 0.4417, policy_loss: 1.8455, value_loss: 0.9956
2024-07-11 15:49:18,148 [INFO    ] __main__: replay_buffer size = 55296
2024-07-11 15:49:18,529 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:49:19,803 [INFO    ] __main__: train step 1700: loss: 0.4419, policy_loss: 1.8454, value_loss: 0.9956
2024-07-11 15:49:19,979 [INFO    ] __main__: train step 1701: loss: 0.4421, policy_loss: 1.8453, value_loss: 0.9956
2024-07-11 15:49:20,183 [INFO    ] __main__: train step 1702: loss: 0.4422, policy_loss: 1.8452, value_loss: 0.9955
2024-07-11 15:49:20,396 [INFO    ] __main__: train step 1703: loss: 0.4424, policy_loss: 1.8452, value_loss: 0.9955
2024-07-11 15:49:20,589 [INFO    ] __main__: train step 1704: loss: 0.4426, policy_loss: 1.8451, value_loss: 0.9955
2024-07-11 15:49:20,785 [INFO    ] __main__: train step 1705: loss: 0.4427, policy_loss: 1.8450, value_loss: 0.9955
2024-07-11 15:49:20,989 [INFO    ] __main__: train step 1706: loss: 0.4429, policy_loss: 1.8449, value_loss: 0.9955
2024-07-11 15:49:21,462 [INFO    ] __main__: train step 1707: loss: 0.4431, policy_loss: 1.8448, value_loss: 0.9954
2024-07-11 15:49:21,657 [INFO    ] __main__: train step 1708: loss: 0.4432, policy_loss: 1.8448, value_loss: 0.9954
2024-07-11 15:49:21,853 [INFO    ] __main__: train step 1709: loss: 0.4434, policy_loss: 1.8447, value_loss: 0.9954
2024-07-11 15:49:22,059 [INFO    ] __main__: train step 1710: loss: 0.4436, policy_loss: 1.8446, value_loss: 0.9954
2024-07-11 15:49:22,279 [INFO    ] __main__: train step 1711: loss: 0.4437, policy_loss: 1.8445, value_loss: 0.9954
2024-07-11 15:49:22,512 [INFO    ] __main__: train step 1712: loss: 0.4439, policy_loss: 1.8445, value_loss: 0.9954
2024-07-11 15:49:22,706 [INFO    ] __main__: train step 1713: loss: 0.4441, policy_loss: 1.8444, value_loss: 0.9953
2024-07-11 15:49:22,910 [INFO    ] __main__: train step 1714: loss: 0.4442, policy_loss: 1.8443, value_loss: 0.9953
2024-07-11 15:49:23,115 [INFO    ] __main__: train step 1715: loss: 0.4444, policy_loss: 1.8443, value_loss: 0.9953
2024-07-11 15:49:23,337 [INFO    ] __main__: train step 1716: loss: 0.4446, policy_loss: 1.8442, value_loss: 0.9952
2024-07-11 15:49:24,884 [INFO    ] __main__: replay_buffer size = 55808
2024-07-11 15:49:25,281 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:49:27,111 [INFO    ] __main__: train step 1717: loss: 0.4447, policy_loss: 1.8441, value_loss: 0.9952
2024-07-11 15:49:27,300 [INFO    ] __main__: train step 1718: loss: 0.4449, policy_loss: 1.8441, value_loss: 0.9952
2024-07-11 15:49:27,488 [INFO    ] __main__: train step 1719: loss: 0.4450, policy_loss: 1.8440, value_loss: 0.9952
2024-07-11 15:49:27,689 [INFO    ] __main__: train step 1720: loss: 0.4452, policy_loss: 1.8439, value_loss: 0.9952
2024-07-11 15:49:27,890 [INFO    ] __main__: train step 1721: loss: 0.4453, policy_loss: 1.8439, value_loss: 0.9952
2024-07-11 15:49:28,093 [INFO    ] __main__: train step 1722: loss: 0.4455, policy_loss: 1.8438, value_loss: 0.9952
2024-07-11 15:49:28,295 [INFO    ] __main__: train step 1723: loss: 0.4457, policy_loss: 1.8437, value_loss: 0.9951
2024-07-11 15:49:28,500 [INFO    ] __main__: train step 1724: loss: 0.4458, policy_loss: 1.8437, value_loss: 0.9951
2024-07-11 15:49:28,707 [INFO    ] __main__: train step 1725: loss: 0.4460, policy_loss: 1.8436, value_loss: 0.9951
2024-07-11 15:49:28,890 [INFO    ] __main__: train step 1726: loss: 0.4462, policy_loss: 1.8435, value_loss: 0.9951
2024-07-11 15:49:29,096 [INFO    ] __main__: train step 1727: loss: 0.4463, policy_loss: 1.8435, value_loss: 0.9951
2024-07-11 15:49:29,306 [INFO    ] __main__: train step 1728: loss: 0.4465, policy_loss: 1.8434, value_loss: 0.9951
2024-07-11 15:49:29,808 [INFO    ] __main__: train step 1729: loss: 0.4467, policy_loss: 1.8433, value_loss: 0.9951
2024-07-11 15:49:29,999 [INFO    ] __main__: train step 1730: loss: 0.4468, policy_loss: 1.8433, value_loss: 0.9950
2024-07-11 15:49:30,202 [INFO    ] __main__: train step 1731: loss: 0.4470, policy_loss: 1.8432, value_loss: 0.9950
2024-07-11 15:49:30,403 [INFO    ] __main__: train step 1732: loss: 0.4472, policy_loss: 1.8431, value_loss: 0.9950
2024-07-11 15:49:30,603 [INFO    ] __main__: train step 1733: loss: 0.4473, policy_loss: 1.8430, value_loss: 0.9950
2024-07-11 15:49:32,161 [INFO    ] __main__: replay_buffer size = 56320
2024-07-11 15:49:32,553 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:49:34,339 [INFO    ] __main__: train step 1734: loss: 0.4475, policy_loss: 1.8430, value_loss: 0.9950
2024-07-11 15:49:34,520 [INFO    ] __main__: train step 1735: loss: 0.4476, policy_loss: 1.8429, value_loss: 0.9950
2024-07-11 15:49:34,716 [INFO    ] __main__: train step 1736: loss: 0.4478, policy_loss: 1.8428, value_loss: 0.9949
2024-07-11 15:49:34,932 [INFO    ] __main__: train step 1737: loss: 0.4480, policy_loss: 1.8427, value_loss: 0.9949
2024-07-11 15:49:35,130 [INFO    ] __main__: train step 1738: loss: 0.4481, policy_loss: 1.8427, value_loss: 0.9949
2024-07-11 15:49:35,342 [INFO    ] __main__: train step 1739: loss: 0.4483, policy_loss: 1.8426, value_loss: 0.9949
2024-07-11 15:49:35,534 [INFO    ] __main__: train step 1740: loss: 0.4485, policy_loss: 1.8425, value_loss: 0.9949
2024-07-11 15:49:35,727 [INFO    ] __main__: train step 1741: loss: 0.4486, policy_loss: 1.8425, value_loss: 0.9948
2024-07-11 15:49:35,931 [INFO    ] __main__: train step 1742: loss: 0.4488, policy_loss: 1.8424, value_loss: 0.9948
2024-07-11 15:49:36,121 [INFO    ] __main__: train step 1743: loss: 0.4490, policy_loss: 1.8423, value_loss: 0.9948
2024-07-11 15:49:36,319 [INFO    ] __main__: train step 1744: loss: 0.4491, policy_loss: 1.8422, value_loss: 0.9948
2024-07-11 15:49:36,527 [INFO    ] __main__: train step 1745: loss: 0.4493, policy_loss: 1.8422, value_loss: 0.9947
2024-07-11 15:49:36,730 [INFO    ] __main__: train step 1746: loss: 0.4495, policy_loss: 1.8421, value_loss: 0.9947
2024-07-11 15:49:36,939 [INFO    ] __main__: train step 1747: loss: 0.4496, policy_loss: 1.8420, value_loss: 0.9947
2024-07-11 15:49:37,132 [INFO    ] __main__: train step 1748: loss: 0.4498, policy_loss: 1.8419, value_loss: 0.9947
2024-07-11 15:49:37,326 [INFO    ] __main__: train step 1749: loss: 0.4500, policy_loss: 1.8418, value_loss: 0.9947
2024-07-11 15:49:37,523 [INFO    ] __main__: train step 1750: loss: 0.4501, policy_loss: 1.8418, value_loss: 0.9947
2024-07-11 15:49:39,355 [INFO    ] __main__: replay_buffer size = 56832
2024-07-11 15:49:39,741 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:49:41,541 [INFO    ] __main__: train step 1751: loss: 0.4503, policy_loss: 1.8417, value_loss: 0.9947
2024-07-11 15:49:41,702 [INFO    ] __main__: train step 1752: loss: 0.4504, policy_loss: 1.8416, value_loss: 0.9947
2024-07-11 15:49:41,904 [INFO    ] __main__: train step 1753: loss: 0.4506, policy_loss: 1.8416, value_loss: 0.9946
2024-07-11 15:49:42,099 [INFO    ] __main__: train step 1754: loss: 0.4508, policy_loss: 1.8415, value_loss: 0.9946
2024-07-11 15:49:42,305 [INFO    ] __main__: train step 1755: loss: 0.4510, policy_loss: 1.8414, value_loss: 0.9946
2024-07-11 15:49:42,522 [INFO    ] __main__: train step 1756: loss: 0.4511, policy_loss: 1.8413, value_loss: 0.9946
2024-07-11 15:49:42,718 [INFO    ] __main__: train step 1757: loss: 0.4513, policy_loss: 1.8413, value_loss: 0.9946
2024-07-11 15:49:42,918 [INFO    ] __main__: train step 1758: loss: 0.4514, policy_loss: 1.8412, value_loss: 0.9946
2024-07-11 15:49:43,115 [INFO    ] __main__: train step 1759: loss: 0.4516, policy_loss: 1.8412, value_loss: 0.9945
2024-07-11 15:49:43,318 [INFO    ] __main__: train step 1760: loss: 0.4518, policy_loss: 1.8411, value_loss: 0.9945
2024-07-11 15:49:43,519 [INFO    ] __main__: train step 1761: loss: 0.4519, policy_loss: 1.8410, value_loss: 0.9945
2024-07-11 15:49:43,718 [INFO    ] __main__: train step 1762: loss: 0.4521, policy_loss: 1.8409, value_loss: 0.9945
2024-07-11 15:49:43,922 [INFO    ] __main__: train step 1763: loss: 0.4523, policy_loss: 1.8409, value_loss: 0.9944
2024-07-11 15:49:44,155 [INFO    ] __main__: train step 1764: loss: 0.4524, policy_loss: 1.8408, value_loss: 0.9944
2024-07-11 15:49:44,368 [INFO    ] __main__: train step 1765: loss: 0.4526, policy_loss: 1.8407, value_loss: 0.9944
2024-07-11 15:49:44,564 [INFO    ] __main__: train step 1766: loss: 0.4527, policy_loss: 1.8407, value_loss: 0.9944
2024-07-11 15:49:44,765 [INFO    ] __main__: train step 1767: loss: 0.4529, policy_loss: 1.8406, value_loss: 0.9944
2024-07-11 15:49:46,323 [INFO    ] __main__: replay_buffer size = 57344
2024-07-11 15:49:46,725 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:49:48,010 [INFO    ] __main__: train step 1768: loss: 0.4531, policy_loss: 1.8406, value_loss: 0.9943
2024-07-11 15:49:48,186 [INFO    ] __main__: train step 1769: loss: 0.4532, policy_loss: 1.8405, value_loss: 0.9943
2024-07-11 15:49:48,394 [INFO    ] __main__: train step 1770: loss: 0.4534, policy_loss: 1.8405, value_loss: 0.9943
2024-07-11 15:49:48,616 [INFO    ] __main__: train step 1771: loss: 0.4536, policy_loss: 1.8404, value_loss: 0.9943
2024-07-11 15:49:48,812 [INFO    ] __main__: train step 1772: loss: 0.4537, policy_loss: 1.8403, value_loss: 0.9943
2024-07-11 15:49:49,275 [INFO    ] __main__: train step 1773: loss: 0.4539, policy_loss: 1.8403, value_loss: 0.9943
2024-07-11 15:49:49,503 [INFO    ] __main__: train step 1774: loss: 0.4540, policy_loss: 1.8402, value_loss: 0.9943
2024-07-11 15:49:49,708 [INFO    ] __main__: train step 1775: loss: 0.4542, policy_loss: 1.8401, value_loss: 0.9943
2024-07-11 15:49:49,915 [INFO    ] __main__: train step 1776: loss: 0.4543, policy_loss: 1.8401, value_loss: 0.9942
2024-07-11 15:49:50,113 [INFO    ] __main__: train step 1777: loss: 0.4545, policy_loss: 1.8400, value_loss: 0.9942
2024-07-11 15:49:50,343 [INFO    ] __main__: train step 1778: loss: 0.4547, policy_loss: 1.8399, value_loss: 0.9942
2024-07-11 15:49:50,573 [INFO    ] __main__: train step 1779: loss: 0.4548, policy_loss: 1.8399, value_loss: 0.9942
2024-07-11 15:49:50,770 [INFO    ] __main__: train step 1780: loss: 0.4550, policy_loss: 1.8398, value_loss: 0.9942
2024-07-11 15:49:50,975 [INFO    ] __main__: train step 1781: loss: 0.4552, policy_loss: 1.8397, value_loss: 0.9941
2024-07-11 15:49:51,189 [INFO    ] __main__: train step 1782: loss: 0.4553, policy_loss: 1.8397, value_loss: 0.9941
2024-07-11 15:49:51,381 [INFO    ] __main__: train step 1783: loss: 0.4555, policy_loss: 1.8396, value_loss: 0.9941
2024-07-11 15:49:51,590 [INFO    ] __main__: train step 1784: loss: 0.4557, policy_loss: 1.8395, value_loss: 0.9941
2024-07-11 15:49:53,176 [INFO    ] __main__: replay_buffer size = 57856
2024-07-11 15:49:53,601 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:49:55,418 [INFO    ] __main__: train step 1785: loss: 0.4559, policy_loss: 1.8395, value_loss: 0.9940
2024-07-11 15:49:55,594 [INFO    ] __main__: train step 1786: loss: 0.4560, policy_loss: 1.8394, value_loss: 0.9940
2024-07-11 15:49:55,810 [INFO    ] __main__: train step 1787: loss: 0.4562, policy_loss: 1.8393, value_loss: 0.9940
2024-07-11 15:49:56,013 [INFO    ] __main__: train step 1788: loss: 0.4563, policy_loss: 1.8393, value_loss: 0.9940
2024-07-11 15:49:56,212 [INFO    ] __main__: train step 1789: loss: 0.4565, policy_loss: 1.8392, value_loss: 0.9939
2024-07-11 15:49:56,419 [INFO    ] __main__: train step 1790: loss: 0.4567, policy_loss: 1.8391, value_loss: 0.9939
2024-07-11 15:49:56,638 [INFO    ] __main__: train step 1791: loss: 0.4568, policy_loss: 1.8391, value_loss: 0.9939
2024-07-11 15:49:56,827 [INFO    ] __main__: train step 1792: loss: 0.4570, policy_loss: 1.8390, value_loss: 0.9938
2024-07-11 15:49:57,031 [INFO    ] __main__: train step 1793: loss: 0.4572, policy_loss: 1.8389, value_loss: 0.9938
2024-07-11 15:49:57,243 [INFO    ] __main__: train step 1794: loss: 0.4573, policy_loss: 1.8389, value_loss: 0.9938
2024-07-11 15:49:57,739 [INFO    ] __main__: train step 1795: loss: 0.4575, policy_loss: 1.8388, value_loss: 0.9938
2024-07-11 15:49:57,965 [INFO    ] __main__: train step 1796: loss: 0.4577, policy_loss: 1.8388, value_loss: 0.9938
2024-07-11 15:49:58,163 [INFO    ] __main__: train step 1797: loss: 0.4579, policy_loss: 1.8387, value_loss: 0.9937
2024-07-11 15:49:58,366 [INFO    ] __main__: train step 1798: loss: 0.4580, policy_loss: 1.8387, value_loss: 0.9937
2024-07-11 15:49:58,580 [INFO    ] __main__: train step 1799: loss: 0.4582, policy_loss: 1.8386, value_loss: 0.9937
2024-07-11 15:49:58,776 [INFO    ] __main__: train step 1800: loss: 0.4584, policy_loss: 1.8385, value_loss: 0.9937
2024-07-11 15:49:58,985 [INFO    ] __main__: train step 1801: loss: 0.4585, policy_loss: 1.8385, value_loss: 0.9936
2024-07-11 15:50:00,566 [INFO    ] __main__: replay_buffer size = 58368
2024-07-11 15:50:00,964 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:50:02,753 [INFO    ] __main__: train step 1802: loss: 0.4587, policy_loss: 1.8384, value_loss: 0.9936
2024-07-11 15:50:02,926 [INFO    ] __main__: train step 1803: loss: 0.4589, policy_loss: 1.8384, value_loss: 0.9936
2024-07-11 15:50:03,121 [INFO    ] __main__: train step 1804: loss: 0.4590, policy_loss: 1.8383, value_loss: 0.9936
2024-07-11 15:50:03,330 [INFO    ] __main__: train step 1805: loss: 0.4592, policy_loss: 1.8382, value_loss: 0.9935
2024-07-11 15:50:03,536 [INFO    ] __main__: train step 1806: loss: 0.4594, policy_loss: 1.8382, value_loss: 0.9935
2024-07-11 15:50:03,716 [INFO    ] __main__: train step 1807: loss: 0.4596, policy_loss: 1.8381, value_loss: 0.9935
2024-07-11 15:50:03,912 [INFO    ] __main__: train step 1808: loss: 0.4597, policy_loss: 1.8380, value_loss: 0.9935
2024-07-11 15:50:04,121 [INFO    ] __main__: train step 1809: loss: 0.4599, policy_loss: 1.8379, value_loss: 0.9934
2024-07-11 15:50:04,320 [INFO    ] __main__: train step 1810: loss: 0.4601, policy_loss: 1.8379, value_loss: 0.9934
2024-07-11 15:50:04,528 [INFO    ] __main__: train step 1811: loss: 0.4603, policy_loss: 1.8378, value_loss: 0.9934
2024-07-11 15:50:04,746 [INFO    ] __main__: train step 1812: loss: 0.4604, policy_loss: 1.8377, value_loss: 0.9934
2024-07-11 15:50:04,972 [INFO    ] __main__: train step 1813: loss: 0.4606, policy_loss: 1.8377, value_loss: 0.9934
2024-07-11 15:50:05,176 [INFO    ] __main__: train step 1814: loss: 0.4608, policy_loss: 1.8376, value_loss: 0.9933
2024-07-11 15:50:05,430 [INFO    ] __main__: train step 1815: loss: 0.4609, policy_loss: 1.8375, value_loss: 0.9933
2024-07-11 15:50:05,656 [INFO    ] __main__: train step 1816: loss: 0.4611, policy_loss: 1.8375, value_loss: 0.9933
2024-07-11 15:50:05,849 [INFO    ] __main__: train step 1817: loss: 0.4613, policy_loss: 1.8374, value_loss: 0.9933
2024-07-11 15:50:06,326 [INFO    ] __main__: train step 1818: loss: 0.4614, policy_loss: 1.8373, value_loss: 0.9933
2024-07-11 15:50:07,887 [INFO    ] __main__: replay_buffer size = 58880
2024-07-11 15:50:08,275 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:50:10,060 [INFO    ] __main__: train step 1819: loss: 0.4616, policy_loss: 1.8373, value_loss: 0.9933
2024-07-11 15:50:10,238 [INFO    ] __main__: train step 1820: loss: 0.4617, policy_loss: 1.8372, value_loss: 0.9932
2024-07-11 15:50:10,435 [INFO    ] __main__: train step 1821: loss: 0.4619, policy_loss: 1.8371, value_loss: 0.9932
2024-07-11 15:50:10,650 [INFO    ] __main__: train step 1822: loss: 0.4621, policy_loss: 1.8371, value_loss: 0.9932
2024-07-11 15:50:10,855 [INFO    ] __main__: train step 1823: loss: 0.4622, policy_loss: 1.8370, value_loss: 0.9932
2024-07-11 15:50:11,076 [INFO    ] __main__: train step 1824: loss: 0.4624, policy_loss: 1.8369, value_loss: 0.9932
2024-07-11 15:50:11,287 [INFO    ] __main__: train step 1825: loss: 0.4625, policy_loss: 1.8369, value_loss: 0.9932
2024-07-11 15:50:11,519 [INFO    ] __main__: train step 1826: loss: 0.4627, policy_loss: 1.8368, value_loss: 0.9931
2024-07-11 15:50:11,720 [INFO    ] __main__: train step 1827: loss: 0.4629, policy_loss: 1.8368, value_loss: 0.9931
2024-07-11 15:50:11,926 [INFO    ] __main__: train step 1828: loss: 0.4630, policy_loss: 1.8367, value_loss: 0.9931
2024-07-11 15:50:12,136 [INFO    ] __main__: train step 1829: loss: 0.4632, policy_loss: 1.8366, value_loss: 0.9931
2024-07-11 15:50:12,339 [INFO    ] __main__: train step 1830: loss: 0.4633, policy_loss: 1.8366, value_loss: 0.9930
2024-07-11 15:50:12,545 [INFO    ] __main__: train step 1831: loss: 0.4635, policy_loss: 1.8365, value_loss: 0.9930
2024-07-11 15:50:12,745 [INFO    ] __main__: train step 1832: loss: 0.4637, policy_loss: 1.8364, value_loss: 0.9930
2024-07-11 15:50:12,943 [INFO    ] __main__: train step 1833: loss: 0.4638, policy_loss: 1.8364, value_loss: 0.9930
2024-07-11 15:50:13,145 [INFO    ] __main__: train step 1834: loss: 0.4640, policy_loss: 1.8363, value_loss: 0.9930
2024-07-11 15:50:13,348 [INFO    ] __main__: train step 1835: loss: 0.4642, policy_loss: 1.8362, value_loss: 0.9930
2024-07-11 15:50:14,908 [INFO    ] __main__: replay_buffer size = 59392
2024-07-11 15:50:15,298 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:50:16,575 [INFO    ] __main__: train step 1836: loss: 0.4643, policy_loss: 1.8362, value_loss: 0.9929
2024-07-11 15:50:16,750 [INFO    ] __main__: train step 1837: loss: 0.4645, policy_loss: 1.8361, value_loss: 0.9929
2024-07-11 15:50:16,958 [INFO    ] __main__: train step 1838: loss: 0.4646, policy_loss: 1.8360, value_loss: 0.9929
2024-07-11 15:50:17,156 [INFO    ] __main__: train step 1839: loss: 0.4648, policy_loss: 1.8360, value_loss: 0.9929
2024-07-11 15:50:17,642 [INFO    ] __main__: train step 1840: loss: 0.4650, policy_loss: 1.8359, value_loss: 0.9928
2024-07-11 15:50:17,876 [INFO    ] __main__: train step 1841: loss: 0.4651, policy_loss: 1.8359, value_loss: 0.9928
2024-07-11 15:50:18,079 [INFO    ] __main__: train step 1842: loss: 0.4653, policy_loss: 1.8358, value_loss: 0.9928
2024-07-11 15:50:18,291 [INFO    ] __main__: train step 1843: loss: 0.4654, policy_loss: 1.8357, value_loss: 0.9927
2024-07-11 15:50:18,488 [INFO    ] __main__: train step 1844: loss: 0.4656, policy_loss: 1.8357, value_loss: 0.9927
2024-07-11 15:50:18,692 [INFO    ] __main__: train step 1845: loss: 0.4658, policy_loss: 1.8356, value_loss: 0.9927
2024-07-11 15:50:18,882 [INFO    ] __main__: train step 1846: loss: 0.4660, policy_loss: 1.8356, value_loss: 0.9927
2024-07-11 15:50:19,089 [INFO    ] __main__: train step 1847: loss: 0.4661, policy_loss: 1.8355, value_loss: 0.9926
2024-07-11 15:50:19,289 [INFO    ] __main__: train step 1848: loss: 0.4663, policy_loss: 1.8354, value_loss: 0.9926
2024-07-11 15:50:19,493 [INFO    ] __main__: train step 1849: loss: 0.4665, policy_loss: 1.8354, value_loss: 0.9926
2024-07-11 15:50:19,701 [INFO    ] __main__: train step 1850: loss: 0.4667, policy_loss: 1.8353, value_loss: 0.9926
2024-07-11 15:50:19,907 [INFO    ] __main__: train step 1851: loss: 0.4668, policy_loss: 1.8352, value_loss: 0.9925
2024-07-11 15:50:20,122 [INFO    ] __main__: train step 1852: loss: 0.4670, policy_loss: 1.8352, value_loss: 0.9925
2024-07-11 15:50:21,681 [INFO    ] __main__: replay_buffer size = 59904
2024-07-11 15:50:22,066 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:50:23,874 [INFO    ] __main__: train step 1853: loss: 0.4672, policy_loss: 1.8351, value_loss: 0.9925
2024-07-11 15:50:24,050 [INFO    ] __main__: train step 1854: loss: 0.4673, policy_loss: 1.8350, value_loss: 0.9925
2024-07-11 15:50:24,248 [INFO    ] __main__: train step 1855: loss: 0.4675, policy_loss: 1.8350, value_loss: 0.9924
2024-07-11 15:50:24,437 [INFO    ] __main__: train step 1856: loss: 0.4677, policy_loss: 1.8349, value_loss: 0.9924
2024-07-11 15:50:24,645 [INFO    ] __main__: train step 1857: loss: 0.4678, policy_loss: 1.8348, value_loss: 0.9924
2024-07-11 15:50:24,843 [INFO    ] __main__: train step 1858: loss: 0.4680, policy_loss: 1.8347, value_loss: 0.9924
2024-07-11 15:50:25,035 [INFO    ] __main__: train step 1859: loss: 0.4682, policy_loss: 1.8347, value_loss: 0.9923
2024-07-11 15:50:25,234 [INFO    ] __main__: train step 1860: loss: 0.4683, policy_loss: 1.8346, value_loss: 0.9923
2024-07-11 15:50:25,423 [INFO    ] __main__: train step 1861: loss: 0.4685, policy_loss: 1.8346, value_loss: 0.9923
2024-07-11 15:50:25,632 [INFO    ] __main__: train step 1862: loss: 0.4686, policy_loss: 1.8345, value_loss: 0.9922
2024-07-11 15:50:26,122 [INFO    ] __main__: train step 1863: loss: 0.4688, policy_loss: 1.8344, value_loss: 0.9922
2024-07-11 15:50:26,356 [INFO    ] __main__: train step 1864: loss: 0.4690, policy_loss: 1.8344, value_loss: 0.9922
2024-07-11 15:50:26,554 [INFO    ] __main__: train step 1865: loss: 0.4691, policy_loss: 1.8343, value_loss: 0.9921
2024-07-11 15:50:26,743 [INFO    ] __main__: train step 1866: loss: 0.4693, policy_loss: 1.8343, value_loss: 0.9921
2024-07-11 15:50:26,952 [INFO    ] __main__: train step 1867: loss: 0.4694, policy_loss: 1.8342, value_loss: 0.9921
2024-07-11 15:50:27,148 [INFO    ] __main__: train step 1868: loss: 0.4696, policy_loss: 1.8341, value_loss: 0.9921
2024-07-11 15:50:27,338 [INFO    ] __main__: train step 1869: loss: 0.4698, policy_loss: 1.8341, value_loss: 0.9921
2024-07-11 15:50:28,894 [INFO    ] __main__: replay_buffer size = 60416
2024-07-11 15:50:29,228 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:50:30,991 [INFO    ] __main__: train step 1870: loss: 0.4700, policy_loss: 1.8340, value_loss: 0.9920
2024-07-11 15:50:31,161 [INFO    ] __main__: train step 1871: loss: 0.4701, policy_loss: 1.8339, value_loss: 0.9920
2024-07-11 15:50:31,376 [INFO    ] __main__: train step 1872: loss: 0.4703, policy_loss: 1.8338, value_loss: 0.9920
2024-07-11 15:50:31,586 [INFO    ] __main__: train step 1873: loss: 0.4705, policy_loss: 1.8338, value_loss: 0.9920
2024-07-11 15:50:31,817 [INFO    ] __main__: train step 1874: loss: 0.4706, policy_loss: 1.8337, value_loss: 0.9919
2024-07-11 15:50:32,020 [INFO    ] __main__: train step 1875: loss: 0.4708, policy_loss: 1.8336, value_loss: 0.9919
2024-07-11 15:50:32,221 [INFO    ] __main__: train step 1876: loss: 0.4709, policy_loss: 1.8335, value_loss: 0.9919
2024-07-11 15:50:32,425 [INFO    ] __main__: train step 1877: loss: 0.4711, policy_loss: 1.8335, value_loss: 0.9919
2024-07-11 15:50:32,640 [INFO    ] __main__: train step 1878: loss: 0.4713, policy_loss: 1.8334, value_loss: 0.9918
2024-07-11 15:50:32,851 [INFO    ] __main__: train step 1879: loss: 0.4715, policy_loss: 1.8333, value_loss: 0.9918
2024-07-11 15:50:33,049 [INFO    ] __main__: train step 1880: loss: 0.4716, policy_loss: 1.8332, value_loss: 0.9918
2024-07-11 15:50:33,246 [INFO    ] __main__: train step 1881: loss: 0.4718, policy_loss: 1.8332, value_loss: 0.9918
2024-07-11 15:50:33,444 [INFO    ] __main__: train step 1882: loss: 0.4719, policy_loss: 1.8331, value_loss: 0.9918
2024-07-11 15:50:33,639 [INFO    ] __main__: train step 1883: loss: 0.4721, policy_loss: 1.8330, value_loss: 0.9918
2024-07-11 15:50:33,841 [INFO    ] __main__: train step 1884: loss: 0.4723, policy_loss: 1.8330, value_loss: 0.9917
2024-07-11 15:50:34,039 [INFO    ] __main__: train step 1885: loss: 0.4724, policy_loss: 1.8329, value_loss: 0.9917
2024-07-11 15:50:34,512 [INFO    ] __main__: train step 1886: loss: 0.4726, policy_loss: 1.8328, value_loss: 0.9917
2024-07-11 15:50:36,084 [INFO    ] __main__: replay_buffer size = 60928
2024-07-11 15:50:36,486 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:50:38,297 [INFO    ] __main__: train step 1887: loss: 0.4728, policy_loss: 1.8328, value_loss: 0.9916
2024-07-11 15:50:38,470 [INFO    ] __main__: train step 1888: loss: 0.4729, policy_loss: 1.8327, value_loss: 0.9916
2024-07-11 15:50:38,701 [INFO    ] __main__: train step 1889: loss: 0.4731, policy_loss: 1.8326, value_loss: 0.9916
2024-07-11 15:50:38,898 [INFO    ] __main__: train step 1890: loss: 0.4732, policy_loss: 1.8326, value_loss: 0.9916
2024-07-11 15:50:39,096 [INFO    ] __main__: train step 1891: loss: 0.4734, policy_loss: 1.8325, value_loss: 0.9915
2024-07-11 15:50:39,299 [INFO    ] __main__: train step 1892: loss: 0.4736, policy_loss: 1.8324, value_loss: 0.9915
2024-07-11 15:50:39,492 [INFO    ] __main__: train step 1893: loss: 0.4738, policy_loss: 1.8324, value_loss: 0.9915
2024-07-11 15:50:39,688 [INFO    ] __main__: train step 1894: loss: 0.4739, policy_loss: 1.8323, value_loss: 0.9915
2024-07-11 15:50:39,892 [INFO    ] __main__: train step 1895: loss: 0.4741, policy_loss: 1.8322, value_loss: 0.9914
2024-07-11 15:50:40,104 [INFO    ] __main__: train step 1896: loss: 0.4743, policy_loss: 1.8322, value_loss: 0.9914
2024-07-11 15:50:40,319 [INFO    ] __main__: train step 1897: loss: 0.4744, policy_loss: 1.8321, value_loss: 0.9914
2024-07-11 15:50:40,528 [INFO    ] __main__: train step 1898: loss: 0.4746, policy_loss: 1.8320, value_loss: 0.9914
2024-07-11 15:50:40,748 [INFO    ] __main__: train step 1899: loss: 0.4748, policy_loss: 1.8320, value_loss: 0.9913
2024-07-11 15:50:40,961 [INFO    ] __main__: train step 1900: loss: 0.4749, policy_loss: 1.8319, value_loss: 0.9913
2024-07-11 15:50:41,181 [INFO    ] __main__: train step 1901: loss: 0.4751, policy_loss: 1.8318, value_loss: 0.9913
2024-07-11 15:50:41,398 [INFO    ] __main__: train step 1902: loss: 0.4753, policy_loss: 1.8318, value_loss: 0.9913
2024-07-11 15:50:41,636 [INFO    ] __main__: train step 1903: loss: 0.4755, policy_loss: 1.8317, value_loss: 0.9913
2024-07-11 15:50:43,199 [INFO    ] __main__: replay_buffer size = 61440
2024-07-11 15:50:43,542 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:50:44,817 [INFO    ] __main__: train step 1904: loss: 0.4756, policy_loss: 1.8316, value_loss: 0.9913
2024-07-11 15:50:44,993 [INFO    ] __main__: train step 1905: loss: 0.4758, policy_loss: 1.8315, value_loss: 0.9912
2024-07-11 15:50:45,204 [INFO    ] __main__: train step 1906: loss: 0.4759, policy_loss: 1.8315, value_loss: 0.9912
2024-07-11 15:50:45,408 [INFO    ] __main__: train step 1907: loss: 0.4761, policy_loss: 1.8314, value_loss: 0.9912
2024-07-11 15:50:45,881 [INFO    ] __main__: train step 1908: loss: 0.4763, policy_loss: 1.8314, value_loss: 0.9912
2024-07-11 15:50:46,092 [INFO    ] __main__: train step 1909: loss: 0.4764, policy_loss: 1.8313, value_loss: 0.9911
2024-07-11 15:50:46,305 [INFO    ] __main__: train step 1910: loss: 0.4766, policy_loss: 1.8312, value_loss: 0.9911
2024-07-11 15:50:46,558 [INFO    ] __main__: train step 1911: loss: 0.4768, policy_loss: 1.8312, value_loss: 0.9911
2024-07-11 15:50:46,764 [INFO    ] __main__: train step 1912: loss: 0.4769, policy_loss: 1.8311, value_loss: 0.9911
2024-07-11 15:50:46,954 [INFO    ] __main__: train step 1913: loss: 0.4771, policy_loss: 1.8310, value_loss: 0.9910
2024-07-11 15:50:47,166 [INFO    ] __main__: train step 1914: loss: 0.4773, policy_loss: 1.8310, value_loss: 0.9910
2024-07-11 15:50:47,398 [INFO    ] __main__: train step 1915: loss: 0.4774, policy_loss: 1.8309, value_loss: 0.9910
2024-07-11 15:50:47,591 [INFO    ] __main__: train step 1916: loss: 0.4776, policy_loss: 1.8308, value_loss: 0.9910
2024-07-11 15:50:47,791 [INFO    ] __main__: train step 1917: loss: 0.4777, policy_loss: 1.8308, value_loss: 0.9910
2024-07-11 15:50:47,998 [INFO    ] __main__: train step 1918: loss: 0.4779, policy_loss: 1.8307, value_loss: 0.9909
2024-07-11 15:50:48,208 [INFO    ] __main__: train step 1919: loss: 0.4781, policy_loss: 1.8306, value_loss: 0.9909
2024-07-11 15:50:48,423 [INFO    ] __main__: train step 1920: loss: 0.4783, policy_loss: 1.8305, value_loss: 0.9909
2024-07-11 15:50:49,999 [INFO    ] __main__: replay_buffer size = 61952
2024-07-11 15:50:50,507 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:50:52,266 [INFO    ] __main__: train step 1921: loss: 0.4784, policy_loss: 1.8305, value_loss: 0.9909
2024-07-11 15:50:52,443 [INFO    ] __main__: train step 1922: loss: 0.4786, policy_loss: 1.8304, value_loss: 0.9909
2024-07-11 15:50:52,660 [INFO    ] __main__: train step 1923: loss: 0.4787, policy_loss: 1.8303, value_loss: 0.9909
2024-07-11 15:50:52,857 [INFO    ] __main__: train step 1924: loss: 0.4789, policy_loss: 1.8303, value_loss: 0.9908
2024-07-11 15:50:53,059 [INFO    ] __main__: train step 1925: loss: 0.4791, policy_loss: 1.8302, value_loss: 0.9908
2024-07-11 15:50:53,279 [INFO    ] __main__: train step 1926: loss: 0.4792, policy_loss: 1.8301, value_loss: 0.9908
2024-07-11 15:50:53,467 [INFO    ] __main__: train step 1927: loss: 0.4794, policy_loss: 1.8301, value_loss: 0.9908
2024-07-11 15:50:53,668 [INFO    ] __main__: train step 1928: loss: 0.4796, policy_loss: 1.8300, value_loss: 0.9908
2024-07-11 15:50:53,877 [INFO    ] __main__: train step 1929: loss: 0.4797, policy_loss: 1.8299, value_loss: 0.9907
2024-07-11 15:50:54,080 [INFO    ] __main__: train step 1930: loss: 0.4799, policy_loss: 1.8298, value_loss: 0.9907
2024-07-11 15:50:54,291 [INFO    ] __main__: train step 1931: loss: 0.4801, policy_loss: 1.8298, value_loss: 0.9907
2024-07-11 15:50:54,790 [INFO    ] __main__: train step 1932: loss: 0.4802, policy_loss: 1.8297, value_loss: 0.9907
2024-07-11 15:50:55,017 [INFO    ] __main__: train step 1933: loss: 0.4804, policy_loss: 1.8296, value_loss: 0.9907
2024-07-11 15:50:55,222 [INFO    ] __main__: train step 1934: loss: 0.4805, policy_loss: 1.8296, value_loss: 0.9906
2024-07-11 15:50:55,418 [INFO    ] __main__: train step 1935: loss: 0.4807, policy_loss: 1.8295, value_loss: 0.9906
2024-07-11 15:50:55,637 [INFO    ] __main__: train step 1936: loss: 0.4809, policy_loss: 1.8294, value_loss: 0.9906
2024-07-11 15:50:55,829 [INFO    ] __main__: train step 1937: loss: 0.4810, policy_loss: 1.8293, value_loss: 0.9906
2024-07-11 15:50:57,406 [INFO    ] __main__: replay_buffer size = 62464
2024-07-11 15:50:57,802 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:50:59,607 [INFO    ] __main__: train step 1938: loss: 0.4812, policy_loss: 1.8293, value_loss: 0.9905
2024-07-11 15:50:59,776 [INFO    ] __main__: train step 1939: loss: 0.4813, policy_loss: 1.8292, value_loss: 0.9905
2024-07-11 15:51:00,008 [INFO    ] __main__: train step 1940: loss: 0.4815, policy_loss: 1.8291, value_loss: 0.9905
2024-07-11 15:51:00,232 [INFO    ] __main__: train step 1941: loss: 0.4817, policy_loss: 1.8291, value_loss: 0.9905
2024-07-11 15:51:00,431 [INFO    ] __main__: train step 1942: loss: 0.4818, policy_loss: 1.8290, value_loss: 0.9904
2024-07-11 15:51:00,627 [INFO    ] __main__: train step 1943: loss: 0.4820, policy_loss: 1.8289, value_loss: 0.9904
2024-07-11 15:51:00,830 [INFO    ] __main__: train step 1944: loss: 0.4821, policy_loss: 1.8288, value_loss: 0.9904
2024-07-11 15:51:01,028 [INFO    ] __main__: train step 1945: loss: 0.4823, policy_loss: 1.8288, value_loss: 0.9904
2024-07-11 15:51:01,238 [INFO    ] __main__: train step 1946: loss: 0.4825, policy_loss: 1.8287, value_loss: 0.9903
2024-07-11 15:51:01,464 [INFO    ] __main__: train step 1947: loss: 0.4827, policy_loss: 1.8286, value_loss: 0.9903
2024-07-11 15:51:01,684 [INFO    ] __main__: train step 1948: loss: 0.4828, policy_loss: 1.8285, value_loss: 0.9903
2024-07-11 15:51:01,889 [INFO    ] __main__: train step 1949: loss: 0.4830, policy_loss: 1.8285, value_loss: 0.9902
2024-07-11 15:51:02,080 [INFO    ] __main__: train step 1950: loss: 0.4832, policy_loss: 1.8284, value_loss: 0.9902
2024-07-11 15:51:02,283 [INFO    ] __main__: train step 1951: loss: 0.4833, policy_loss: 1.8283, value_loss: 0.9902
2024-07-11 15:51:02,474 [INFO    ] __main__: train step 1952: loss: 0.4835, policy_loss: 1.8283, value_loss: 0.9902
2024-07-11 15:51:02,683 [INFO    ] __main__: train step 1953: loss: 0.4837, policy_loss: 1.8282, value_loss: 0.9901
2024-07-11 15:51:02,893 [INFO    ] __main__: train step 1954: loss: 0.4838, policy_loss: 1.8281, value_loss: 0.9901
2024-07-11 15:51:04,585 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:51:04,914 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:51:06,993 [INFO    ] __main__: train step 1955: loss: 0.4840, policy_loss: 1.8280, value_loss: 0.9900
2024-07-11 15:51:07,161 [INFO    ] __main__: train step 1956: loss: 0.4841, policy_loss: 1.8279, value_loss: 0.9900
2024-07-11 15:51:07,390 [INFO    ] __main__: train step 1957: loss: 0.4843, policy_loss: 1.8279, value_loss: 0.9900
2024-07-11 15:51:07,588 [INFO    ] __main__: train step 1958: loss: 0.4845, policy_loss: 1.8278, value_loss: 0.9900
2024-07-11 15:51:07,786 [INFO    ] __main__: train step 1959: loss: 0.4846, policy_loss: 1.8277, value_loss: 0.9899
2024-07-11 15:51:07,988 [INFO    ] __main__: train step 1960: loss: 0.4848, policy_loss: 1.8276, value_loss: 0.9899
2024-07-11 15:51:08,185 [INFO    ] __main__: train step 1961: loss: 0.4850, policy_loss: 1.8275, value_loss: 0.9899
2024-07-11 15:51:08,405 [INFO    ] __main__: train step 1962: loss: 0.4851, policy_loss: 1.8275, value_loss: 0.9898
2024-07-11 15:51:08,630 [INFO    ] __main__: train step 1963: loss: 0.4853, policy_loss: 1.8274, value_loss: 0.9898
2024-07-11 15:51:08,857 [INFO    ] __main__: train step 1964: loss: 0.4855, policy_loss: 1.8273, value_loss: 0.9898
2024-07-11 15:51:09,050 [INFO    ] __main__: train step 1965: loss: 0.4857, policy_loss: 1.8272, value_loss: 0.9897
2024-07-11 15:51:09,257 [INFO    ] __main__: train step 1966: loss: 0.4858, policy_loss: 1.8272, value_loss: 0.9897
2024-07-11 15:51:09,452 [INFO    ] __main__: train step 1967: loss: 0.4860, policy_loss: 1.8271, value_loss: 0.9897
2024-07-11 15:51:09,656 [INFO    ] __main__: train step 1968: loss: 0.4861, policy_loss: 1.8270, value_loss: 0.9897
2024-07-11 15:51:09,846 [INFO    ] __main__: train step 1969: loss: 0.4863, policy_loss: 1.8269, value_loss: 0.9896
2024-07-11 15:51:10,036 [INFO    ] __main__: train step 1970: loss: 0.4865, policy_loss: 1.8269, value_loss: 0.9896
2024-07-11 15:51:10,242 [INFO    ] __main__: train step 1971: loss: 0.4866, policy_loss: 1.8268, value_loss: 0.9896
2024-07-11 15:51:11,936 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:51:12,332 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:51:12,389 [INFO    ] __main__: train step 1972: loss: 0.4868, policy_loss: 1.8267, value_loss: 0.9896
2024-07-11 15:51:12,563 [INFO    ] __main__: train step 1973: loss: 0.4869, policy_loss: 1.8266, value_loss: 0.9895
2024-07-11 15:51:12,766 [INFO    ] __main__: train step 1974: loss: 0.4871, policy_loss: 1.8266, value_loss: 0.9895
2024-07-11 15:51:12,980 [INFO    ] __main__: train step 1975: loss: 0.4873, policy_loss: 1.8265, value_loss: 0.9895
2024-07-11 15:51:13,184 [INFO    ] __main__: train step 1976: loss: 0.4874, policy_loss: 1.8264, value_loss: 0.9895
2024-07-11 15:51:13,383 [INFO    ] __main__: train step 1977: loss: 0.4876, policy_loss: 1.8263, value_loss: 0.9894
2024-07-11 15:51:13,590 [INFO    ] __main__: train step 1978: loss: 0.4877, policy_loss: 1.8262, value_loss: 0.9894
2024-07-11 15:51:14,069 [INFO    ] __main__: train step 1979: loss: 0.4879, policy_loss: 1.8261, value_loss: 0.9894
2024-07-11 15:51:14,278 [INFO    ] __main__: train step 1980: loss: 0.4881, policy_loss: 1.8261, value_loss: 0.9894
2024-07-11 15:51:14,490 [INFO    ] __main__: train step 1981: loss: 0.4882, policy_loss: 1.8260, value_loss: 0.9893
2024-07-11 15:51:14,690 [INFO    ] __main__: train step 1982: loss: 0.4884, policy_loss: 1.8259, value_loss: 0.9893
2024-07-11 15:51:14,891 [INFO    ] __main__: train step 1983: loss: 0.4885, policy_loss: 1.8258, value_loss: 0.9893
2024-07-11 15:51:15,097 [INFO    ] __main__: train step 1984: loss: 0.4887, policy_loss: 1.8258, value_loss: 0.9893
2024-07-11 15:51:15,294 [INFO    ] __main__: train step 1985: loss: 0.4889, policy_loss: 1.8257, value_loss: 0.9892
2024-07-11 15:51:15,490 [INFO    ] __main__: train step 1986: loss: 0.4890, policy_loss: 1.8256, value_loss: 0.9892
2024-07-11 15:51:15,683 [INFO    ] __main__: train step 1987: loss: 0.4892, policy_loss: 1.8255, value_loss: 0.9892
2024-07-11 15:51:15,890 [INFO    ] __main__: train step 1988: loss: 0.4894, policy_loss: 1.8255, value_loss: 0.9892
2024-07-11 15:51:17,326 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:51:17,702 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:51:17,760 [INFO    ] __main__: train step 1989: loss: 0.4895, policy_loss: 1.8254, value_loss: 0.9892
2024-07-11 15:51:17,929 [INFO    ] __main__: train step 1990: loss: 0.4897, policy_loss: 1.8253, value_loss: 0.9891
2024-07-11 15:51:18,132 [INFO    ] __main__: train step 1991: loss: 0.4899, policy_loss: 1.8252, value_loss: 0.9891
2024-07-11 15:51:18,359 [INFO    ] __main__: train step 1992: loss: 0.4900, policy_loss: 1.8251, value_loss: 0.9891
2024-07-11 15:51:18,589 [INFO    ] __main__: train step 1993: loss: 0.4902, policy_loss: 1.8251, value_loss: 0.9891
2024-07-11 15:51:18,783 [INFO    ] __main__: train step 1994: loss: 0.4904, policy_loss: 1.8250, value_loss: 0.9890
2024-07-11 15:51:18,979 [INFO    ] __main__: train step 1995: loss: 0.4905, policy_loss: 1.8249, value_loss: 0.9890
2024-07-11 15:51:19,174 [INFO    ] __main__: train step 1996: loss: 0.4907, policy_loss: 1.8248, value_loss: 0.9890
2024-07-11 15:51:19,384 [INFO    ] __main__: train step 1997: loss: 0.4909, policy_loss: 1.8247, value_loss: 0.9890
2024-07-11 15:51:19,581 [INFO    ] __main__: train step 1998: loss: 0.4910, policy_loss: 1.8246, value_loss: 0.9889
2024-07-11 15:51:19,789 [INFO    ] __main__: train step 1999: loss: 0.4912, policy_loss: 1.8246, value_loss: 0.9889
2024-07-11 15:51:20,019 [INFO    ] __main__: train step 2000: loss: 0.4914, policy_loss: 1.8245, value_loss: 0.9889
2024-07-11 15:51:20,128 [INFO    ] __main__: restored step 1000 for evaluation
2024-07-11 15:51:27,686 [INFO    ] __main__: later network ELO difference from earlier network: +168 (+8/-8) ELO from 32000 self-played games
2024-07-11 15:51:27,686 [INFO    ] __main__: game outcomes: W: 21974, D: 11, L: 10015
2024-07-11 15:51:27,688 [INFO    ] __main__: validation_elo_delta: 168, validation_elo: 568
2024-07-11 15:51:28,178 [INFO    ] __main__: train step 2001: loss: 0.4915, policy_loss: 1.8244, value_loss: 0.9889
2024-07-11 15:51:28,383 [INFO    ] __main__: train step 2002: loss: 0.4917, policy_loss: 1.8243, value_loss: 0.9889
2024-07-11 15:51:28,873 [INFO    ] __main__: train step 2003: loss: 0.4919, policy_loss: 1.8243, value_loss: 0.9889
2024-07-11 15:51:29,094 [INFO    ] __main__: train step 2004: loss: 0.4920, policy_loss: 1.8242, value_loss: 0.9888
2024-07-11 15:51:29,290 [INFO    ] __main__: train step 2005: loss: 0.4922, policy_loss: 1.8241, value_loss: 0.9888
2024-07-11 15:51:30,748 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:51:31,122 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:51:31,182 [INFO    ] __main__: train step 2006: loss: 0.4924, policy_loss: 1.8240, value_loss: 0.9888
2024-07-11 15:51:31,360 [INFO    ] __main__: train step 2007: loss: 0.4925, policy_loss: 1.8239, value_loss: 0.9888
2024-07-11 15:51:31,568 [INFO    ] __main__: train step 2008: loss: 0.4927, policy_loss: 1.8239, value_loss: 0.9887
2024-07-11 15:51:31,771 [INFO    ] __main__: train step 2009: loss: 0.4928, policy_loss: 1.8238, value_loss: 0.9887
2024-07-11 15:51:31,976 [INFO    ] __main__: train step 2010: loss: 0.4930, policy_loss: 1.8237, value_loss: 0.9887
2024-07-11 15:51:32,166 [INFO    ] __main__: train step 2011: loss: 0.4932, policy_loss: 1.8236, value_loss: 0.9886
2024-07-11 15:51:32,379 [INFO    ] __main__: train step 2012: loss: 0.4933, policy_loss: 1.8235, value_loss: 0.9886
2024-07-11 15:51:32,611 [INFO    ] __main__: train step 2013: loss: 0.4935, policy_loss: 1.8235, value_loss: 0.9886
2024-07-11 15:51:32,810 [INFO    ] __main__: train step 2014: loss: 0.4937, policy_loss: 1.8234, value_loss: 0.9886
2024-07-11 15:51:33,007 [INFO    ] __main__: train step 2015: loss: 0.4938, policy_loss: 1.8233, value_loss: 0.9886
2024-07-11 15:51:33,215 [INFO    ] __main__: train step 2016: loss: 0.4940, policy_loss: 1.8232, value_loss: 0.9885
2024-07-11 15:51:33,411 [INFO    ] __main__: train step 2017: loss: 0.4941, policy_loss: 1.8232, value_loss: 0.9885
2024-07-11 15:51:33,605 [INFO    ] __main__: train step 2018: loss: 0.4943, policy_loss: 1.8231, value_loss: 0.9885
2024-07-11 15:51:33,807 [INFO    ] __main__: train step 2019: loss: 0.4945, policy_loss: 1.8230, value_loss: 0.9885
2024-07-11 15:51:34,005 [INFO    ] __main__: train step 2020: loss: 0.4946, policy_loss: 1.8229, value_loss: 0.9885
2024-07-11 15:51:34,205 [INFO    ] __main__: train step 2021: loss: 0.4948, policy_loss: 1.8228, value_loss: 0.9884
2024-07-11 15:51:34,401 [INFO    ] __main__: train step 2022: loss: 0.4950, policy_loss: 1.8228, value_loss: 0.9884
2024-07-11 15:51:35,861 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:51:36,263 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:51:36,319 [INFO    ] __main__: train step 2023: loss: 0.4951, policy_loss: 1.8227, value_loss: 0.9884
2024-07-11 15:51:36,482 [INFO    ] __main__: train step 2024: loss: 0.4953, policy_loss: 1.8226, value_loss: 0.9883
2024-07-11 15:51:36,955 [INFO    ] __main__: train step 2025: loss: 0.4955, policy_loss: 1.8225, value_loss: 0.9883
2024-07-11 15:51:37,156 [INFO    ] __main__: train step 2026: loss: 0.4956, policy_loss: 1.8224, value_loss: 0.9883
2024-07-11 15:51:37,359 [INFO    ] __main__: train step 2027: loss: 0.4958, policy_loss: 1.8223, value_loss: 0.9883
2024-07-11 15:51:37,564 [INFO    ] __main__: train step 2028: loss: 0.4960, policy_loss: 1.8223, value_loss: 0.9882
2024-07-11 15:51:37,774 [INFO    ] __main__: train step 2029: loss: 0.4961, policy_loss: 1.8222, value_loss: 0.9882
2024-07-11 15:51:37,967 [INFO    ] __main__: train step 2030: loss: 0.4963, policy_loss: 1.8221, value_loss: 0.9882
2024-07-11 15:51:38,163 [INFO    ] __main__: train step 2031: loss: 0.4965, policy_loss: 1.8220, value_loss: 0.9882
2024-07-11 15:51:38,384 [INFO    ] __main__: train step 2032: loss: 0.4966, policy_loss: 1.8219, value_loss: 0.9882
2024-07-11 15:51:38,605 [INFO    ] __main__: train step 2033: loss: 0.4968, policy_loss: 1.8219, value_loss: 0.9881
2024-07-11 15:51:38,802 [INFO    ] __main__: train step 2034: loss: 0.4970, policy_loss: 1.8218, value_loss: 0.9881
2024-07-11 15:51:39,004 [INFO    ] __main__: train step 2035: loss: 0.4971, policy_loss: 1.8217, value_loss: 0.9881
2024-07-11 15:51:39,211 [INFO    ] __main__: train step 2036: loss: 0.4973, policy_loss: 1.8216, value_loss: 0.9881
2024-07-11 15:51:39,405 [INFO    ] __main__: train step 2037: loss: 0.4975, policy_loss: 1.8215, value_loss: 0.9880
2024-07-11 15:51:39,599 [INFO    ] __main__: train step 2038: loss: 0.4976, policy_loss: 1.8215, value_loss: 0.9880
2024-07-11 15:51:39,803 [INFO    ] __main__: train step 2039: loss: 0.4978, policy_loss: 1.8214, value_loss: 0.9880
2024-07-11 15:51:41,248 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:51:41,684 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:51:41,740 [INFO    ] __main__: train step 2040: loss: 0.4979, policy_loss: 1.8213, value_loss: 0.9880
2024-07-11 15:51:41,907 [INFO    ] __main__: train step 2041: loss: 0.4981, policy_loss: 1.8212, value_loss: 0.9879
2024-07-11 15:51:42,114 [INFO    ] __main__: train step 2042: loss: 0.4983, policy_loss: 1.8212, value_loss: 0.9879
2024-07-11 15:51:42,325 [INFO    ] __main__: train step 2043: loss: 0.4985, policy_loss: 1.8211, value_loss: 0.9879
2024-07-11 15:51:42,522 [INFO    ] __main__: train step 2044: loss: 0.4986, policy_loss: 1.8210, value_loss: 0.9879
2024-07-11 15:51:42,745 [INFO    ] __main__: train step 2045: loss: 0.4988, policy_loss: 1.8209, value_loss: 0.9879
2024-07-11 15:51:42,977 [INFO    ] __main__: train step 2046: loss: 0.4989, policy_loss: 1.8209, value_loss: 0.9878
2024-07-11 15:51:43,170 [INFO    ] __main__: train step 2047: loss: 0.4991, policy_loss: 1.8208, value_loss: 0.9878
2024-07-11 15:51:43,666 [INFO    ] __main__: train step 2048: loss: 0.4993, policy_loss: 1.8207, value_loss: 0.9878
2024-07-11 15:51:43,894 [INFO    ] __main__: train step 2049: loss: 0.4994, policy_loss: 1.8206, value_loss: 0.9878
2024-07-11 15:51:44,084 [INFO    ] __main__: train step 2050: loss: 0.4996, policy_loss: 1.8205, value_loss: 0.9877
2024-07-11 15:51:44,288 [INFO    ] __main__: train step 2051: loss: 0.4998, policy_loss: 1.8204, value_loss: 0.9877
2024-07-11 15:51:44,496 [INFO    ] __main__: train step 2052: loss: 0.4999, policy_loss: 1.8203, value_loss: 0.9877
2024-07-11 15:51:44,697 [INFO    ] __main__: train step 2053: loss: 0.5001, policy_loss: 1.8203, value_loss: 0.9877
2024-07-11 15:51:44,894 [INFO    ] __main__: train step 2054: loss: 0.5003, policy_loss: 1.8202, value_loss: 0.9876
2024-07-11 15:51:45,110 [INFO    ] __main__: train step 2055: loss: 0.5004, policy_loss: 1.8201, value_loss: 0.9876
2024-07-11 15:51:45,309 [INFO    ] __main__: train step 2056: loss: 0.5006, policy_loss: 1.8200, value_loss: 0.9876
2024-07-11 15:51:46,749 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:51:47,192 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:51:47,256 [INFO    ] __main__: train step 2057: loss: 0.5008, policy_loss: 1.8199, value_loss: 0.9875
2024-07-11 15:51:47,464 [INFO    ] __main__: train step 2058: loss: 0.5009, policy_loss: 1.8198, value_loss: 0.9875
2024-07-11 15:51:47,686 [INFO    ] __main__: train step 2059: loss: 0.5011, policy_loss: 1.8197, value_loss: 0.9875
2024-07-11 15:51:47,881 [INFO    ] __main__: train step 2060: loss: 0.5012, policy_loss: 1.8196, value_loss: 0.9875
2024-07-11 15:51:48,081 [INFO    ] __main__: train step 2061: loss: 0.5014, policy_loss: 1.8196, value_loss: 0.9874
2024-07-11 15:51:48,287 [INFO    ] __main__: train step 2062: loss: 0.5016, policy_loss: 1.8195, value_loss: 0.9874
2024-07-11 15:51:48,497 [INFO    ] __main__: train step 2063: loss: 0.5017, policy_loss: 1.8194, value_loss: 0.9874
2024-07-11 15:51:48,692 [INFO    ] __main__: train step 2064: loss: 0.5019, policy_loss: 1.8193, value_loss: 0.9874
2024-07-11 15:51:48,887 [INFO    ] __main__: train step 2065: loss: 0.5021, policy_loss: 1.8192, value_loss: 0.9873
2024-07-11 15:51:49,087 [INFO    ] __main__: train step 2066: loss: 0.5023, policy_loss: 1.8191, value_loss: 0.9873
2024-07-11 15:51:49,290 [INFO    ] __main__: train step 2067: loss: 0.5024, policy_loss: 1.8190, value_loss: 0.9873
2024-07-11 15:51:49,487 [INFO    ] __main__: train step 2068: loss: 0.5026, policy_loss: 1.8189, value_loss: 0.9873
2024-07-11 15:51:49,707 [INFO    ] __main__: train step 2069: loss: 0.5027, policy_loss: 1.8188, value_loss: 0.9872
2024-07-11 15:51:49,921 [INFO    ] __main__: train step 2070: loss: 0.5029, policy_loss: 1.8187, value_loss: 0.9872
2024-07-11 15:51:50,447 [INFO    ] __main__: train step 2071: loss: 0.5031, policy_loss: 1.8187, value_loss: 0.9872
2024-07-11 15:51:50,660 [INFO    ] __main__: train step 2072: loss: 0.5032, policy_loss: 1.8186, value_loss: 0.9872
2024-07-11 15:51:50,859 [INFO    ] __main__: train step 2073: loss: 0.5034, policy_loss: 1.8185, value_loss: 0.9871
2024-07-11 15:51:52,292 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:51:52,720 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:51:52,781 [INFO    ] __main__: train step 2074: loss: 0.5036, policy_loss: 1.8184, value_loss: 0.9871
2024-07-11 15:51:52,958 [INFO    ] __main__: train step 2075: loss: 0.5037, policy_loss: 1.8183, value_loss: 0.9871
2024-07-11 15:51:53,187 [INFO    ] __main__: train step 2076: loss: 0.5039, policy_loss: 1.8182, value_loss: 0.9870
2024-07-11 15:51:53,415 [INFO    ] __main__: train step 2077: loss: 0.5040, policy_loss: 1.8181, value_loss: 0.9870
2024-07-11 15:51:53,614 [INFO    ] __main__: train step 2078: loss: 0.5042, policy_loss: 1.8180, value_loss: 0.9870
2024-07-11 15:51:53,816 [INFO    ] __main__: train step 2079: loss: 0.5044, policy_loss: 1.8179, value_loss: 0.9870
2024-07-11 15:51:54,019 [INFO    ] __main__: train step 2080: loss: 0.5045, policy_loss: 1.8178, value_loss: 0.9870
2024-07-11 15:51:54,226 [INFO    ] __main__: train step 2081: loss: 0.5047, policy_loss: 1.8177, value_loss: 0.9869
2024-07-11 15:51:54,425 [INFO    ] __main__: train step 2082: loss: 0.5048, policy_loss: 1.8176, value_loss: 0.9869
2024-07-11 15:51:54,629 [INFO    ] __main__: train step 2083: loss: 0.5050, policy_loss: 1.8175, value_loss: 0.9869
2024-07-11 15:51:54,828 [INFO    ] __main__: train step 2084: loss: 0.5052, policy_loss: 1.8174, value_loss: 0.9869
2024-07-11 15:51:55,037 [INFO    ] __main__: train step 2085: loss: 0.5053, policy_loss: 1.8174, value_loss: 0.9868
2024-07-11 15:51:55,272 [INFO    ] __main__: train step 2086: loss: 0.5055, policy_loss: 1.8173, value_loss: 0.9868
2024-07-11 15:51:55,460 [INFO    ] __main__: train step 2087: loss: 0.5056, policy_loss: 1.8172, value_loss: 0.9868
2024-07-11 15:51:55,663 [INFO    ] __main__: train step 2088: loss: 0.5058, policy_loss: 1.8171, value_loss: 0.9867
2024-07-11 15:51:55,883 [INFO    ] __main__: train step 2089: loss: 0.5059, policy_loss: 1.8170, value_loss: 0.9867
2024-07-11 15:51:56,074 [INFO    ] __main__: train step 2090: loss: 0.5061, policy_loss: 1.8169, value_loss: 0.9867
2024-07-11 15:51:57,533 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:51:57,932 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:51:57,991 [INFO    ] __main__: train step 2091: loss: 0.5063, policy_loss: 1.8168, value_loss: 0.9867
2024-07-11 15:51:58,154 [INFO    ] __main__: train step 2092: loss: 0.5064, policy_loss: 1.8167, value_loss: 0.9866
2024-07-11 15:51:58,373 [INFO    ] __main__: train step 2093: loss: 0.5066, policy_loss: 1.8167, value_loss: 0.9866
2024-07-11 15:51:58,585 [INFO    ] __main__: train step 2094: loss: 0.5068, policy_loss: 1.8166, value_loss: 0.9866
2024-07-11 15:51:59,084 [INFO    ] __main__: train step 2095: loss: 0.5069, policy_loss: 1.8165, value_loss: 0.9866
2024-07-11 15:51:59,321 [INFO    ] __main__: train step 2096: loss: 0.5071, policy_loss: 1.8164, value_loss: 0.9865
2024-07-11 15:51:59,525 [INFO    ] __main__: train step 2097: loss: 0.5072, policy_loss: 1.8163, value_loss: 0.9865
2024-07-11 15:51:59,731 [INFO    ] __main__: train step 2098: loss: 0.5074, policy_loss: 1.8162, value_loss: 0.9865
2024-07-11 15:51:59,941 [INFO    ] __main__: train step 2099: loss: 0.5076, policy_loss: 1.8161, value_loss: 0.9865
2024-07-11 15:52:00,153 [INFO    ] __main__: train step 2100: loss: 0.5077, policy_loss: 1.8160, value_loss: 0.9864
2024-07-11 15:52:00,368 [INFO    ] __main__: train step 2101: loss: 0.5079, policy_loss: 1.8159, value_loss: 0.9864
2024-07-11 15:52:00,573 [INFO    ] __main__: train step 2102: loss: 0.5081, policy_loss: 1.8159, value_loss: 0.9864
2024-07-11 15:52:00,783 [INFO    ] __main__: train step 2103: loss: 0.5082, policy_loss: 1.8158, value_loss: 0.9864
2024-07-11 15:52:00,983 [INFO    ] __main__: train step 2104: loss: 0.5084, policy_loss: 1.8157, value_loss: 0.9863
2024-07-11 15:52:01,192 [INFO    ] __main__: train step 2105: loss: 0.5085, policy_loss: 1.8156, value_loss: 0.9863
2024-07-11 15:52:01,396 [INFO    ] __main__: train step 2106: loss: 0.5087, policy_loss: 1.8155, value_loss: 0.9863
2024-07-11 15:52:01,596 [INFO    ] __main__: train step 2107: loss: 0.5089, policy_loss: 1.8154, value_loss: 0.9862
2024-07-11 15:52:03,041 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:52:03,447 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:52:03,506 [INFO    ] __main__: train step 2108: loss: 0.5090, policy_loss: 1.8153, value_loss: 0.9862
2024-07-11 15:52:03,670 [INFO    ] __main__: train step 2109: loss: 0.5092, policy_loss: 1.8153, value_loss: 0.9862
2024-07-11 15:52:03,865 [INFO    ] __main__: train step 2110: loss: 0.5094, policy_loss: 1.8152, value_loss: 0.9862
2024-07-11 15:52:04,066 [INFO    ] __main__: train step 2111: loss: 0.5095, policy_loss: 1.8151, value_loss: 0.9862
2024-07-11 15:52:04,252 [INFO    ] __main__: train step 2112: loss: 0.5097, policy_loss: 1.8150, value_loss: 0.9861
2024-07-11 15:52:04,457 [INFO    ] __main__: train step 2113: loss: 0.5098, policy_loss: 1.8149, value_loss: 0.9861
2024-07-11 15:52:04,645 [INFO    ] __main__: train step 2114: loss: 0.5100, policy_loss: 1.8148, value_loss: 0.9861
2024-07-11 15:52:04,858 [INFO    ] __main__: train step 2115: loss: 0.5102, policy_loss: 1.8147, value_loss: 0.9861
2024-07-11 15:52:05,053 [INFO    ] __main__: train step 2116: loss: 0.5103, policy_loss: 1.8146, value_loss: 0.9860
2024-07-11 15:52:05,248 [INFO    ] __main__: train step 2117: loss: 0.5105, policy_loss: 1.8145, value_loss: 0.9860
2024-07-11 15:52:05,724 [INFO    ] __main__: train step 2118: loss: 0.5107, policy_loss: 1.8144, value_loss: 0.9860
2024-07-11 15:52:05,926 [INFO    ] __main__: train step 2119: loss: 0.5108, policy_loss: 1.8143, value_loss: 0.9860
2024-07-11 15:52:06,122 [INFO    ] __main__: train step 2120: loss: 0.5110, policy_loss: 1.8143, value_loss: 0.9859
2024-07-11 15:52:06,330 [INFO    ] __main__: train step 2121: loss: 0.5111, policy_loss: 1.8142, value_loss: 0.9859
2024-07-11 15:52:06,523 [INFO    ] __main__: train step 2122: loss: 0.5113, policy_loss: 1.8141, value_loss: 0.9859
2024-07-11 15:52:06,723 [INFO    ] __main__: train step 2123: loss: 0.5115, policy_loss: 1.8140, value_loss: 0.9858
2024-07-11 15:52:06,923 [INFO    ] __main__: train step 2124: loss: 0.5116, policy_loss: 1.8139, value_loss: 0.9858
2024-07-11 15:52:08,350 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:52:08,763 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:52:08,827 [INFO    ] __main__: train step 2125: loss: 0.5118, policy_loss: 1.8138, value_loss: 0.9858
2024-07-11 15:52:08,995 [INFO    ] __main__: train step 2126: loss: 0.5119, policy_loss: 1.8137, value_loss: 0.9857
2024-07-11 15:52:09,202 [INFO    ] __main__: train step 2127: loss: 0.5121, policy_loss: 1.8136, value_loss: 0.9857
2024-07-11 15:52:09,407 [INFO    ] __main__: train step 2128: loss: 0.5123, policy_loss: 1.8135, value_loss: 0.9857
2024-07-11 15:52:09,604 [INFO    ] __main__: train step 2129: loss: 0.5124, policy_loss: 1.8134, value_loss: 0.9857
2024-07-11 15:52:09,799 [INFO    ] __main__: train step 2130: loss: 0.5126, policy_loss: 1.8133, value_loss: 0.9856
2024-07-11 15:52:09,989 [INFO    ] __main__: train step 2131: loss: 0.5128, policy_loss: 1.8133, value_loss: 0.9856
2024-07-11 15:52:10,192 [INFO    ] __main__: train step 2132: loss: 0.5129, policy_loss: 1.8132, value_loss: 0.9856
2024-07-11 15:52:10,393 [INFO    ] __main__: train step 2133: loss: 0.5131, policy_loss: 1.8131, value_loss: 0.9856
2024-07-11 15:52:10,615 [INFO    ] __main__: train step 2134: loss: 0.5132, policy_loss: 1.8130, value_loss: 0.9856
2024-07-11 15:52:10,849 [INFO    ] __main__: train step 2135: loss: 0.5134, policy_loss: 1.8129, value_loss: 0.9855
2024-07-11 15:52:11,080 [INFO    ] __main__: train step 2136: loss: 0.5136, policy_loss: 1.8128, value_loss: 0.9855
2024-07-11 15:52:11,290 [INFO    ] __main__: train step 2137: loss: 0.5138, policy_loss: 1.8127, value_loss: 0.9855
2024-07-11 15:52:11,494 [INFO    ] __main__: train step 2138: loss: 0.5139, policy_loss: 1.8126, value_loss: 0.9855
2024-07-11 15:52:11,686 [INFO    ] __main__: train step 2139: loss: 0.5141, policy_loss: 1.8125, value_loss: 0.9855
2024-07-11 15:52:11,890 [INFO    ] __main__: train step 2140: loss: 0.5142, policy_loss: 1.8124, value_loss: 0.9854
2024-07-11 15:52:12,369 [INFO    ] __main__: train step 2141: loss: 0.5144, policy_loss: 1.8123, value_loss: 0.9854
2024-07-11 15:52:13,822 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:52:14,231 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:52:14,292 [INFO    ] __main__: train step 2142: loss: 0.5146, policy_loss: 1.8122, value_loss: 0.9854
2024-07-11 15:52:14,478 [INFO    ] __main__: train step 2143: loss: 0.5147, policy_loss: 1.8121, value_loss: 0.9853
2024-07-11 15:52:14,716 [INFO    ] __main__: train step 2144: loss: 0.5149, policy_loss: 1.8120, value_loss: 0.9853
2024-07-11 15:52:14,917 [INFO    ] __main__: train step 2145: loss: 0.5151, policy_loss: 1.8119, value_loss: 0.9853
2024-07-11 15:52:15,146 [INFO    ] __main__: train step 2146: loss: 0.5152, policy_loss: 1.8118, value_loss: 0.9852
2024-07-11 15:52:15,353 [INFO    ] __main__: train step 2147: loss: 0.5154, policy_loss: 1.8117, value_loss: 0.9852
2024-07-11 15:52:15,549 [INFO    ] __main__: train step 2148: loss: 0.5155, policy_loss: 1.8116, value_loss: 0.9852
2024-07-11 15:52:15,748 [INFO    ] __main__: train step 2149: loss: 0.5157, policy_loss: 1.8115, value_loss: 0.9851
2024-07-11 15:52:15,956 [INFO    ] __main__: train step 2150: loss: 0.5159, policy_loss: 1.8114, value_loss: 0.9851
2024-07-11 15:52:16,157 [INFO    ] __main__: train step 2151: loss: 0.5160, policy_loss: 1.8113, value_loss: 0.9851
2024-07-11 15:52:16,359 [INFO    ] __main__: train step 2152: loss: 0.5162, policy_loss: 1.8112, value_loss: 0.9851
2024-07-11 15:52:16,569 [INFO    ] __main__: train step 2153: loss: 0.5164, policy_loss: 1.8111, value_loss: 0.9850
2024-07-11 15:52:16,783 [INFO    ] __main__: train step 2154: loss: 0.5165, policy_loss: 1.8110, value_loss: 0.9850
2024-07-11 15:52:16,982 [INFO    ] __main__: train step 2155: loss: 0.5167, policy_loss: 1.8109, value_loss: 0.9849
2024-07-11 15:52:17,181 [INFO    ] __main__: train step 2156: loss: 0.5168, policy_loss: 1.8108, value_loss: 0.9849
2024-07-11 15:52:17,396 [INFO    ] __main__: train step 2157: loss: 0.5170, policy_loss: 1.8107, value_loss: 0.9849
2024-07-11 15:52:17,621 [INFO    ] __main__: train step 2158: loss: 0.5172, policy_loss: 1.8106, value_loss: 0.9849
2024-07-11 15:52:19,044 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:52:19,482 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:52:19,545 [INFO    ] __main__: train step 2159: loss: 0.5173, policy_loss: 1.8105, value_loss: 0.9848
2024-07-11 15:52:19,710 [INFO    ] __main__: train step 2160: loss: 0.5175, policy_loss: 1.8104, value_loss: 0.9848
2024-07-11 15:52:19,929 [INFO    ] __main__: train step 2161: loss: 0.5176, policy_loss: 1.8103, value_loss: 0.9848
2024-07-11 15:52:20,134 [INFO    ] __main__: train step 2162: loss: 0.5178, policy_loss: 1.8102, value_loss: 0.9848
2024-07-11 15:52:20,634 [INFO    ] __main__: train step 2163: loss: 0.5180, policy_loss: 1.8101, value_loss: 0.9847
2024-07-11 15:52:20,854 [INFO    ] __main__: train step 2164: loss: 0.5181, policy_loss: 1.8100, value_loss: 0.9847
2024-07-11 15:52:21,057 [INFO    ] __main__: train step 2165: loss: 0.5183, policy_loss: 1.8099, value_loss: 0.9847
2024-07-11 15:52:21,278 [INFO    ] __main__: train step 2166: loss: 0.5184, policy_loss: 1.8098, value_loss: 0.9847
2024-07-11 15:52:21,482 [INFO    ] __main__: train step 2167: loss: 0.5186, policy_loss: 1.8097, value_loss: 0.9846
2024-07-11 15:52:21,685 [INFO    ] __main__: train step 2168: loss: 0.5187, policy_loss: 1.8096, value_loss: 0.9846
2024-07-11 15:52:21,896 [INFO    ] __main__: train step 2169: loss: 0.5189, policy_loss: 1.8095, value_loss: 0.9846
2024-07-11 15:52:22,083 [INFO    ] __main__: train step 2170: loss: 0.5191, policy_loss: 1.8094, value_loss: 0.9846
2024-07-11 15:52:22,297 [INFO    ] __main__: train step 2171: loss: 0.5192, policy_loss: 1.8093, value_loss: 0.9845
2024-07-11 15:52:22,495 [INFO    ] __main__: train step 2172: loss: 0.5194, policy_loss: 1.8092, value_loss: 0.9845
2024-07-11 15:52:22,733 [INFO    ] __main__: train step 2173: loss: 0.5196, policy_loss: 1.8091, value_loss: 0.9845
2024-07-11 15:52:22,942 [INFO    ] __main__: train step 2174: loss: 0.5197, policy_loss: 1.8090, value_loss: 0.9845
2024-07-11 15:52:23,158 [INFO    ] __main__: train step 2175: loss: 0.5199, policy_loss: 1.8089, value_loss: 0.9845
2024-07-11 15:52:24,616 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:52:25,023 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:52:25,081 [INFO    ] __main__: train step 2176: loss: 0.5201, policy_loss: 1.8088, value_loss: 0.9844
2024-07-11 15:52:25,265 [INFO    ] __main__: train step 2177: loss: 0.5202, policy_loss: 1.8087, value_loss: 0.9844
2024-07-11 15:52:25,464 [INFO    ] __main__: train step 2178: loss: 0.5204, policy_loss: 1.8086, value_loss: 0.9844
2024-07-11 15:52:25,666 [INFO    ] __main__: train step 2179: loss: 0.5206, policy_loss: 1.8085, value_loss: 0.9844
2024-07-11 15:52:25,876 [INFO    ] __main__: train step 2180: loss: 0.5207, policy_loss: 1.8084, value_loss: 0.9843
2024-07-11 15:52:26,081 [INFO    ] __main__: train step 2181: loss: 0.5209, policy_loss: 1.8083, value_loss: 0.9843
2024-07-11 15:52:26,288 [INFO    ] __main__: train step 2182: loss: 0.5211, policy_loss: 1.8082, value_loss: 0.9843
2024-07-11 15:52:26,495 [INFO    ] __main__: train step 2183: loss: 0.5212, policy_loss: 1.8081, value_loss: 0.9842
2024-07-11 15:52:26,702 [INFO    ] __main__: train step 2184: loss: 0.5214, policy_loss: 1.8080, value_loss: 0.9842
2024-07-11 15:52:26,902 [INFO    ] __main__: train step 2185: loss: 0.5215, policy_loss: 1.8079, value_loss: 0.9842
2024-07-11 15:52:27,101 [INFO    ] __main__: train step 2186: loss: 0.5217, policy_loss: 1.8078, value_loss: 0.9842
2024-07-11 15:52:27,591 [INFO    ] __main__: train step 2187: loss: 0.5219, policy_loss: 1.8077, value_loss: 0.9841
2024-07-11 15:52:27,783 [INFO    ] __main__: train step 2188: loss: 0.5220, policy_loss: 1.8076, value_loss: 0.9841
2024-07-11 15:52:27,992 [INFO    ] __main__: train step 2189: loss: 0.5222, policy_loss: 1.8075, value_loss: 0.9841
2024-07-11 15:52:28,189 [INFO    ] __main__: train step 2190: loss: 0.5224, policy_loss: 1.8074, value_loss: 0.9841
2024-07-11 15:52:28,390 [INFO    ] __main__: train step 2191: loss: 0.5225, policy_loss: 1.8072, value_loss: 0.9840
2024-07-11 15:52:28,592 [INFO    ] __main__: train step 2192: loss: 0.5227, policy_loss: 1.8071, value_loss: 0.9840
2024-07-11 15:52:30,033 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:52:30,443 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:52:30,497 [INFO    ] __main__: train step 2193: loss: 0.5229, policy_loss: 1.8071, value_loss: 0.9840
2024-07-11 15:52:30,668 [INFO    ] __main__: train step 2194: loss: 0.5230, policy_loss: 1.8070, value_loss: 0.9840
2024-07-11 15:52:30,864 [INFO    ] __main__: train step 2195: loss: 0.5232, policy_loss: 1.8068, value_loss: 0.9839
2024-07-11 15:52:31,063 [INFO    ] __main__: train step 2196: loss: 0.5234, policy_loss: 1.8067, value_loss: 0.9839
2024-07-11 15:52:31,272 [INFO    ] __main__: train step 2197: loss: 0.5235, policy_loss: 1.8066, value_loss: 0.9839
2024-07-11 15:52:31,463 [INFO    ] __main__: train step 2198: loss: 0.5237, policy_loss: 1.8065, value_loss: 0.9839
2024-07-11 15:52:31,665 [INFO    ] __main__: train step 2199: loss: 0.5238, policy_loss: 1.8064, value_loss: 0.9838
2024-07-11 15:52:31,869 [INFO    ] __main__: train step 2200: loss: 0.5240, policy_loss: 1.8063, value_loss: 0.9838
2024-07-11 15:52:32,069 [INFO    ] __main__: train step 2201: loss: 0.5242, policy_loss: 1.8062, value_loss: 0.9838
2024-07-11 15:52:32,298 [INFO    ] __main__: train step 2202: loss: 0.5243, policy_loss: 1.8061, value_loss: 0.9838
2024-07-11 15:52:32,502 [INFO    ] __main__: train step 2203: loss: 0.5245, policy_loss: 1.8060, value_loss: 0.9838
2024-07-11 15:52:32,694 [INFO    ] __main__: train step 2204: loss: 0.5247, policy_loss: 1.8059, value_loss: 0.9837
2024-07-11 15:52:32,893 [INFO    ] __main__: train step 2205: loss: 0.5248, policy_loss: 1.8058, value_loss: 0.9837
2024-07-11 15:52:33,101 [INFO    ] __main__: train step 2206: loss: 0.5250, policy_loss: 1.8057, value_loss: 0.9837
2024-07-11 15:52:33,312 [INFO    ] __main__: train step 2207: loss: 0.5251, policy_loss: 1.8056, value_loss: 0.9837
2024-07-11 15:52:33,500 [INFO    ] __main__: train step 2208: loss: 0.5253, policy_loss: 1.8055, value_loss: 0.9836
2024-07-11 15:52:33,697 [INFO    ] __main__: train step 2209: loss: 0.5255, policy_loss: 1.8054, value_loss: 0.9836
2024-07-11 15:52:35,426 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:52:35,857 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:52:35,919 [INFO    ] __main__: train step 2210: loss: 0.5256, policy_loss: 1.8053, value_loss: 0.9836
2024-07-11 15:52:36,085 [INFO    ] __main__: train step 2211: loss: 0.5258, policy_loss: 1.8052, value_loss: 0.9836
2024-07-11 15:52:36,281 [INFO    ] __main__: train step 2212: loss: 0.5260, policy_loss: 1.8050, value_loss: 0.9835
2024-07-11 15:52:36,486 [INFO    ] __main__: train step 2213: loss: 0.5261, policy_loss: 1.8049, value_loss: 0.9835
2024-07-11 15:52:36,685 [INFO    ] __main__: train step 2214: loss: 0.5263, policy_loss: 1.8048, value_loss: 0.9835
2024-07-11 15:52:36,893 [INFO    ] __main__: train step 2215: loss: 0.5265, policy_loss: 1.8047, value_loss: 0.9835
2024-07-11 15:52:37,082 [INFO    ] __main__: train step 2216: loss: 0.5266, policy_loss: 1.8046, value_loss: 0.9835
2024-07-11 15:52:37,291 [INFO    ] __main__: train step 2217: loss: 0.5268, policy_loss: 1.8045, value_loss: 0.9835
2024-07-11 15:52:37,497 [INFO    ] __main__: train step 2218: loss: 0.5270, policy_loss: 1.8044, value_loss: 0.9834
2024-07-11 15:52:37,695 [INFO    ] __main__: train step 2219: loss: 0.5271, policy_loss: 1.8043, value_loss: 0.9834
2024-07-11 15:52:37,910 [INFO    ] __main__: train step 2220: loss: 0.5273, policy_loss: 1.8041, value_loss: 0.9834
2024-07-11 15:52:38,115 [INFO    ] __main__: train step 2221: loss: 0.5274, policy_loss: 1.8040, value_loss: 0.9834
2024-07-11 15:52:38,320 [INFO    ] __main__: train step 2222: loss: 0.5276, policy_loss: 1.8039, value_loss: 0.9834
2024-07-11 15:52:38,519 [INFO    ] __main__: train step 2223: loss: 0.5277, policy_loss: 1.8038, value_loss: 0.9833
2024-07-11 15:52:38,728 [INFO    ] __main__: train step 2224: loss: 0.5279, policy_loss: 1.8037, value_loss: 0.9833
2024-07-11 15:52:38,936 [INFO    ] __main__: train step 2225: loss: 0.5281, policy_loss: 1.8036, value_loss: 0.9833
2024-07-11 15:52:39,139 [INFO    ] __main__: train step 2226: loss: 0.5282, policy_loss: 1.8035, value_loss: 0.9833
2024-07-11 15:52:40,605 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:52:41,013 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:52:41,066 [INFO    ] __main__: train step 2227: loss: 0.5284, policy_loss: 1.8034, value_loss: 0.9832
2024-07-11 15:52:41,240 [INFO    ] __main__: train step 2228: loss: 0.5285, policy_loss: 1.8033, value_loss: 0.9832
2024-07-11 15:52:41,451 [INFO    ] __main__: train step 2229: loss: 0.5287, policy_loss: 1.8031, value_loss: 0.9832
2024-07-11 15:52:41,670 [INFO    ] __main__: train step 2230: loss: 0.5289, policy_loss: 1.8030, value_loss: 0.9832
2024-07-11 15:52:41,882 [INFO    ] __main__: train step 2231: loss: 0.5290, policy_loss: 1.8029, value_loss: 0.9832
2024-07-11 15:52:42,109 [INFO    ] __main__: train step 2232: loss: 0.5292, policy_loss: 1.8028, value_loss: 0.9831
2024-07-11 15:52:42,601 [INFO    ] __main__: train step 2233: loss: 0.5293, policy_loss: 1.8027, value_loss: 0.9831
2024-07-11 15:52:42,772 [INFO    ] __main__: train step 2234: loss: 0.5295, policy_loss: 1.8026, value_loss: 0.9831
2024-07-11 15:52:42,967 [INFO    ] __main__: train step 2235: loss: 0.5297, policy_loss: 1.8025, value_loss: 0.9831
2024-07-11 15:52:43,168 [INFO    ] __main__: train step 2236: loss: 0.5298, policy_loss: 1.8024, value_loss: 0.9831
2024-07-11 15:52:43,372 [INFO    ] __main__: train step 2237: loss: 0.5300, policy_loss: 1.8023, value_loss: 0.9830
2024-07-11 15:52:43,581 [INFO    ] __main__: train step 2238: loss: 0.5301, policy_loss: 1.8021, value_loss: 0.9830
2024-07-11 15:52:43,789 [INFO    ] __main__: train step 2239: loss: 0.5303, policy_loss: 1.8020, value_loss: 0.9830
2024-07-11 15:52:43,983 [INFO    ] __main__: train step 2240: loss: 0.5304, policy_loss: 1.8019, value_loss: 0.9830
2024-07-11 15:52:44,190 [INFO    ] __main__: train step 2241: loss: 0.5306, policy_loss: 1.8018, value_loss: 0.9829
2024-07-11 15:52:44,399 [INFO    ] __main__: train step 2242: loss: 0.5307, policy_loss: 1.8017, value_loss: 0.9829
2024-07-11 15:52:44,586 [INFO    ] __main__: train step 2243: loss: 0.5309, policy_loss: 1.8016, value_loss: 0.9829
2024-07-11 15:52:46,022 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:52:46,459 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:52:46,524 [INFO    ] __main__: train step 2244: loss: 0.5310, policy_loss: 1.8015, value_loss: 0.9829
2024-07-11 15:52:46,698 [INFO    ] __main__: train step 2245: loss: 0.5312, policy_loss: 1.8014, value_loss: 0.9828
2024-07-11 15:52:46,937 [INFO    ] __main__: train step 2246: loss: 0.5313, policy_loss: 1.8012, value_loss: 0.9828
2024-07-11 15:52:47,140 [INFO    ] __main__: train step 2247: loss: 0.5315, policy_loss: 1.8011, value_loss: 0.9828
2024-07-11 15:52:47,356 [INFO    ] __main__: train step 2248: loss: 0.5317, policy_loss: 1.8010, value_loss: 0.9827
2024-07-11 15:52:47,572 [INFO    ] __main__: train step 2249: loss: 0.5318, policy_loss: 1.8009, value_loss: 0.9827
2024-07-11 15:52:47,764 [INFO    ] __main__: train step 2250: loss: 0.5320, policy_loss: 1.8008, value_loss: 0.9827
2024-07-11 15:52:47,954 [INFO    ] __main__: train step 2251: loss: 0.5321, policy_loss: 1.8007, value_loss: 0.9827
2024-07-11 15:52:48,167 [INFO    ] __main__: train step 2252: loss: 0.5323, policy_loss: 1.8006, value_loss: 0.9826
2024-07-11 15:52:48,359 [INFO    ] __main__: train step 2253: loss: 0.5325, policy_loss: 1.8005, value_loss: 0.9826
2024-07-11 15:52:48,569 [INFO    ] __main__: train step 2254: loss: 0.5326, policy_loss: 1.8004, value_loss: 0.9826
2024-07-11 15:52:48,792 [INFO    ] __main__: train step 2255: loss: 0.5328, policy_loss: 1.8003, value_loss: 0.9825
2024-07-11 15:52:48,996 [INFO    ] __main__: train step 2256: loss: 0.5329, policy_loss: 1.8001, value_loss: 0.9825
2024-07-11 15:52:49,194 [INFO    ] __main__: train step 2257: loss: 0.5331, policy_loss: 1.8000, value_loss: 0.9825
2024-07-11 15:52:49,698 [INFO    ] __main__: train step 2258: loss: 0.5333, policy_loss: 1.7999, value_loss: 0.9825
2024-07-11 15:52:49,920 [INFO    ] __main__: train step 2259: loss: 0.5334, policy_loss: 1.7998, value_loss: 0.9824
2024-07-11 15:52:50,148 [INFO    ] __main__: train step 2260: loss: 0.5336, policy_loss: 1.7997, value_loss: 0.9824
2024-07-11 15:52:51,608 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:52:51,983 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:52:52,038 [INFO    ] __main__: train step 2261: loss: 0.5337, policy_loss: 1.7996, value_loss: 0.9824
2024-07-11 15:52:52,212 [INFO    ] __main__: train step 2262: loss: 0.5339, policy_loss: 1.7995, value_loss: 0.9823
2024-07-11 15:52:52,409 [INFO    ] __main__: train step 2263: loss: 0.5341, policy_loss: 1.7993, value_loss: 0.9823
2024-07-11 15:52:52,616 [INFO    ] __main__: train step 2264: loss: 0.5343, policy_loss: 1.7992, value_loss: 0.9823
2024-07-11 15:52:52,815 [INFO    ] __main__: train step 2265: loss: 0.5344, policy_loss: 1.7991, value_loss: 0.9823
2024-07-11 15:52:53,017 [INFO    ] __main__: train step 2266: loss: 0.5346, policy_loss: 1.7990, value_loss: 0.9822
2024-07-11 15:52:53,217 [INFO    ] __main__: train step 2267: loss: 0.5347, policy_loss: 1.7989, value_loss: 0.9822
2024-07-11 15:52:53,435 [INFO    ] __main__: train step 2268: loss: 0.5349, policy_loss: 1.7988, value_loss: 0.9822
2024-07-11 15:52:53,663 [INFO    ] __main__: train step 2269: loss: 0.5351, policy_loss: 1.7987, value_loss: 0.9822
2024-07-11 15:52:53,856 [INFO    ] __main__: train step 2270: loss: 0.5352, policy_loss: 1.7986, value_loss: 0.9821
2024-07-11 15:52:54,052 [INFO    ] __main__: train step 2271: loss: 0.5354, policy_loss: 1.7984, value_loss: 0.9821
2024-07-11 15:52:54,252 [INFO    ] __main__: train step 2272: loss: 0.5355, policy_loss: 1.7983, value_loss: 0.9821
2024-07-11 15:52:54,458 [INFO    ] __main__: train step 2273: loss: 0.5357, policy_loss: 1.7982, value_loss: 0.9821
2024-07-11 15:52:54,653 [INFO    ] __main__: train step 2274: loss: 0.5358, policy_loss: 1.7981, value_loss: 0.9820
2024-07-11 15:52:54,844 [INFO    ] __main__: train step 2275: loss: 0.5360, policy_loss: 1.7980, value_loss: 0.9820
2024-07-11 15:52:55,040 [INFO    ] __main__: train step 2276: loss: 0.5362, policy_loss: 1.7978, value_loss: 0.9820
2024-07-11 15:52:55,237 [INFO    ] __main__: train step 2277: loss: 0.5363, policy_loss: 1.7977, value_loss: 0.9820
2024-07-11 15:52:56,674 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:52:57,078 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:52:57,134 [INFO    ] __main__: train step 2278: loss: 0.5365, policy_loss: 1.7976, value_loss: 0.9819
2024-07-11 15:52:57,308 [INFO    ] __main__: train step 2279: loss: 0.5366, policy_loss: 1.7975, value_loss: 0.9819
2024-07-11 15:52:57,507 [INFO    ] __main__: train step 2280: loss: 0.5368, policy_loss: 1.7973, value_loss: 0.9819
2024-07-11 15:52:57,991 [INFO    ] __main__: train step 2281: loss: 0.5370, policy_loss: 1.7972, value_loss: 0.9819
2024-07-11 15:52:58,198 [INFO    ] __main__: train step 2282: loss: 0.5371, policy_loss: 1.7971, value_loss: 0.9818
2024-07-11 15:52:58,402 [INFO    ] __main__: train step 2283: loss: 0.5373, policy_loss: 1.7970, value_loss: 0.9818
2024-07-11 15:52:58,613 [INFO    ] __main__: train step 2284: loss: 0.5375, policy_loss: 1.7969, value_loss: 0.9818
2024-07-11 15:52:58,819 [INFO    ] __main__: train step 2285: loss: 0.5376, policy_loss: 1.7968, value_loss: 0.9818
2024-07-11 15:52:59,028 [INFO    ] __main__: train step 2286: loss: 0.5378, policy_loss: 1.7966, value_loss: 0.9817
2024-07-11 15:52:59,229 [INFO    ] __main__: train step 2287: loss: 0.5379, policy_loss: 1.7965, value_loss: 0.9817
2024-07-11 15:52:59,431 [INFO    ] __main__: train step 2288: loss: 0.5381, policy_loss: 1.7964, value_loss: 0.9817
2024-07-11 15:52:59,630 [INFO    ] __main__: train step 2289: loss: 0.5383, policy_loss: 1.7963, value_loss: 0.9816
2024-07-11 15:52:59,838 [INFO    ] __main__: train step 2290: loss: 0.5384, policy_loss: 1.7962, value_loss: 0.9816
2024-07-11 15:53:00,032 [INFO    ] __main__: train step 2291: loss: 0.5386, policy_loss: 1.7961, value_loss: 0.9816
2024-07-11 15:53:00,219 [INFO    ] __main__: train step 2292: loss: 0.5387, policy_loss: 1.7960, value_loss: 0.9816
2024-07-11 15:53:00,432 [INFO    ] __main__: train step 2293: loss: 0.5389, policy_loss: 1.7958, value_loss: 0.9815
2024-07-11 15:53:00,643 [INFO    ] __main__: train step 2294: loss: 0.5391, policy_loss: 1.7957, value_loss: 0.9815
2024-07-11 15:53:02,090 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:53:02,526 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:53:02,584 [INFO    ] __main__: train step 2295: loss: 0.5392, policy_loss: 1.7956, value_loss: 0.9815
2024-07-11 15:53:02,750 [INFO    ] __main__: train step 2296: loss: 0.5394, policy_loss: 1.7955, value_loss: 0.9814
2024-07-11 15:53:02,956 [INFO    ] __main__: train step 2297: loss: 0.5396, policy_loss: 1.7953, value_loss: 0.9814
2024-07-11 15:53:03,166 [INFO    ] __main__: train step 2298: loss: 0.5397, policy_loss: 1.7952, value_loss: 0.9814
2024-07-11 15:53:03,366 [INFO    ] __main__: train step 2299: loss: 0.5399, policy_loss: 1.7951, value_loss: 0.9813
2024-07-11 15:53:03,564 [INFO    ] __main__: train step 2300: loss: 0.5400, policy_loss: 1.7950, value_loss: 0.9813
2024-07-11 15:53:03,780 [INFO    ] __main__: train step 2301: loss: 0.5402, policy_loss: 1.7949, value_loss: 0.9813
2024-07-11 15:53:03,974 [INFO    ] __main__: train step 2302: loss: 0.5404, policy_loss: 1.7947, value_loss: 0.9813
2024-07-11 15:53:04,456 [INFO    ] __main__: train step 2303: loss: 0.5405, policy_loss: 1.7946, value_loss: 0.9812
2024-07-11 15:53:04,645 [INFO    ] __main__: train step 2304: loss: 0.5407, policy_loss: 1.7945, value_loss: 0.9812
2024-07-11 15:53:04,866 [INFO    ] __main__: train step 2305: loss: 0.5408, policy_loss: 1.7944, value_loss: 0.9812
2024-07-11 15:53:05,097 [INFO    ] __main__: train step 2306: loss: 0.5410, policy_loss: 1.7942, value_loss: 0.9811
2024-07-11 15:53:05,322 [INFO    ] __main__: train step 2307: loss: 0.5412, policy_loss: 1.7941, value_loss: 0.9811
2024-07-11 15:53:05,551 [INFO    ] __main__: train step 2308: loss: 0.5413, policy_loss: 1.7940, value_loss: 0.9811
2024-07-11 15:53:05,763 [INFO    ] __main__: train step 2309: loss: 0.5415, policy_loss: 1.7939, value_loss: 0.9810
2024-07-11 15:53:05,959 [INFO    ] __main__: train step 2310: loss: 0.5416, policy_loss: 1.7937, value_loss: 0.9810
2024-07-11 15:53:06,169 [INFO    ] __main__: train step 2311: loss: 0.5418, policy_loss: 1.7936, value_loss: 0.9810
2024-07-11 15:53:07,614 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:53:08,013 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:53:08,068 [INFO    ] __main__: train step 2312: loss: 0.5419, policy_loss: 1.7935, value_loss: 0.9809
2024-07-11 15:53:08,234 [INFO    ] __main__: train step 2313: loss: 0.5421, policy_loss: 1.7934, value_loss: 0.9809
2024-07-11 15:53:08,449 [INFO    ] __main__: train step 2314: loss: 0.5423, policy_loss: 1.7933, value_loss: 0.9809
2024-07-11 15:53:08,673 [INFO    ] __main__: train step 2315: loss: 0.5424, policy_loss: 1.7931, value_loss: 0.9809
2024-07-11 15:53:08,882 [INFO    ] __main__: train step 2316: loss: 0.5426, policy_loss: 1.7930, value_loss: 0.9808
2024-07-11 15:53:09,084 [INFO    ] __main__: train step 2317: loss: 0.5428, policy_loss: 1.7929, value_loss: 0.9808
2024-07-11 15:53:09,290 [INFO    ] __main__: train step 2318: loss: 0.5429, policy_loss: 1.7928, value_loss: 0.9808
2024-07-11 15:53:09,489 [INFO    ] __main__: train step 2319: loss: 0.5431, policy_loss: 1.7926, value_loss: 0.9808
2024-07-11 15:53:09,679 [INFO    ] __main__: train step 2320: loss: 0.5432, policy_loss: 1.7925, value_loss: 0.9807
2024-07-11 15:53:09,883 [INFO    ] __main__: train step 2321: loss: 0.5434, policy_loss: 1.7924, value_loss: 0.9807
2024-07-11 15:53:10,079 [INFO    ] __main__: train step 2322: loss: 0.5436, policy_loss: 1.7923, value_loss: 0.9807
2024-07-11 15:53:10,284 [INFO    ] __main__: train step 2323: loss: 0.5437, policy_loss: 1.7921, value_loss: 0.9807
2024-07-11 15:53:10,480 [INFO    ] __main__: train step 2324: loss: 0.5439, policy_loss: 1.7920, value_loss: 0.9806
2024-07-11 15:53:10,680 [INFO    ] __main__: train step 2325: loss: 0.5440, policy_loss: 1.7919, value_loss: 0.9806
2024-07-11 15:53:11,171 [INFO    ] __main__: train step 2326: loss: 0.5442, policy_loss: 1.7918, value_loss: 0.9806
2024-07-11 15:53:11,405 [INFO    ] __main__: train step 2327: loss: 0.5443, policy_loss: 1.7916, value_loss: 0.9805
2024-07-11 15:53:11,602 [INFO    ] __main__: train step 2328: loss: 0.5445, policy_loss: 1.7915, value_loss: 0.9805
2024-07-11 15:53:13,046 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:53:13,441 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:53:13,497 [INFO    ] __main__: train step 2329: loss: 0.5447, policy_loss: 1.7914, value_loss: 0.9805
2024-07-11 15:53:13,666 [INFO    ] __main__: train step 2330: loss: 0.5448, policy_loss: 1.7912, value_loss: 0.9805
2024-07-11 15:53:13,889 [INFO    ] __main__: train step 2331: loss: 0.5450, policy_loss: 1.7911, value_loss: 0.9804
2024-07-11 15:53:14,120 [INFO    ] __main__: train step 2332: loss: 0.5451, policy_loss: 1.7910, value_loss: 0.9804
2024-07-11 15:53:14,331 [INFO    ] __main__: train step 2333: loss: 0.5453, policy_loss: 1.7909, value_loss: 0.9804
2024-07-11 15:53:14,570 [INFO    ] __main__: train step 2334: loss: 0.5454, policy_loss: 1.7907, value_loss: 0.9804
2024-07-11 15:53:14,757 [INFO    ] __main__: train step 2335: loss: 0.5456, policy_loss: 1.7906, value_loss: 0.9803
2024-07-11 15:53:14,959 [INFO    ] __main__: train step 2336: loss: 0.5457, policy_loss: 1.7905, value_loss: 0.9803
2024-07-11 15:53:15,169 [INFO    ] __main__: train step 2337: loss: 0.5459, policy_loss: 1.7904, value_loss: 0.9803
2024-07-11 15:53:15,380 [INFO    ] __main__: train step 2338: loss: 0.5461, policy_loss: 1.7903, value_loss: 0.9802
2024-07-11 15:53:15,576 [INFO    ] __main__: train step 2339: loss: 0.5462, policy_loss: 1.7901, value_loss: 0.9802
2024-07-11 15:53:15,769 [INFO    ] __main__: train step 2340: loss: 0.5464, policy_loss: 1.7900, value_loss: 0.9802
2024-07-11 15:53:15,974 [INFO    ] __main__: train step 2341: loss: 0.5465, policy_loss: 1.7899, value_loss: 0.9801
2024-07-11 15:53:16,189 [INFO    ] __main__: train step 2342: loss: 0.5467, policy_loss: 1.7898, value_loss: 0.9801
2024-07-11 15:53:16,411 [INFO    ] __main__: train step 2343: loss: 0.5468, policy_loss: 1.7896, value_loss: 0.9801
2024-07-11 15:53:16,629 [INFO    ] __main__: train step 2344: loss: 0.5470, policy_loss: 1.7895, value_loss: 0.9801
2024-07-11 15:53:16,842 [INFO    ] __main__: train step 2345: loss: 0.5471, policy_loss: 1.7894, value_loss: 0.9800
2024-07-11 15:53:18,288 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:53:18,682 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:53:18,738 [INFO    ] __main__: train step 2346: loss: 0.5473, policy_loss: 1.7893, value_loss: 0.9800
2024-07-11 15:53:18,898 [INFO    ] __main__: train step 2347: loss: 0.5475, policy_loss: 1.7892, value_loss: 0.9800
2024-07-11 15:53:19,107 [INFO    ] __main__: train step 2348: loss: 0.5476, policy_loss: 1.7890, value_loss: 0.9799
2024-07-11 15:53:19,595 [INFO    ] __main__: train step 2349: loss: 0.5478, policy_loss: 1.7889, value_loss: 0.9799
2024-07-11 15:53:19,837 [INFO    ] __main__: train step 2350: loss: 0.5479, policy_loss: 1.7888, value_loss: 0.9799
2024-07-11 15:53:20,046 [INFO    ] __main__: train step 2351: loss: 0.5481, policy_loss: 1.7887, value_loss: 0.9799
2024-07-11 15:53:20,292 [INFO    ] __main__: train step 2352: loss: 0.5482, policy_loss: 1.7885, value_loss: 0.9799
2024-07-11 15:53:20,485 [INFO    ] __main__: train step 2353: loss: 0.5484, policy_loss: 1.7884, value_loss: 0.9798
2024-07-11 15:53:20,691 [INFO    ] __main__: train step 2354: loss: 0.5485, policy_loss: 1.7883, value_loss: 0.9798
2024-07-11 15:53:20,898 [INFO    ] __main__: train step 2355: loss: 0.5487, policy_loss: 1.7882, value_loss: 0.9798
2024-07-11 15:53:21,109 [INFO    ] __main__: train step 2356: loss: 0.5488, policy_loss: 1.7880, value_loss: 0.9798
2024-07-11 15:53:21,310 [INFO    ] __main__: train step 2357: loss: 0.5490, policy_loss: 1.7879, value_loss: 0.9797
2024-07-11 15:53:21,511 [INFO    ] __main__: train step 2358: loss: 0.5492, policy_loss: 1.7878, value_loss: 0.9797
2024-07-11 15:53:21,706 [INFO    ] __main__: train step 2359: loss: 0.5493, policy_loss: 1.7877, value_loss: 0.9797
2024-07-11 15:53:21,915 [INFO    ] __main__: train step 2360: loss: 0.5495, policy_loss: 1.7875, value_loss: 0.9797
2024-07-11 15:53:22,126 [INFO    ] __main__: train step 2361: loss: 0.5497, policy_loss: 1.7874, value_loss: 0.9796
2024-07-11 15:53:22,330 [INFO    ] __main__: train step 2362: loss: 0.5498, policy_loss: 1.7873, value_loss: 0.9796
2024-07-11 15:53:23,798 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:53:24,189 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:53:24,249 [INFO    ] __main__: train step 2363: loss: 0.5500, policy_loss: 1.7872, value_loss: 0.9796
2024-07-11 15:53:24,420 [INFO    ] __main__: train step 2364: loss: 0.5501, policy_loss: 1.7870, value_loss: 0.9796
2024-07-11 15:53:24,624 [INFO    ] __main__: train step 2365: loss: 0.5503, policy_loss: 1.7869, value_loss: 0.9796
2024-07-11 15:53:24,822 [INFO    ] __main__: train step 2366: loss: 0.5504, policy_loss: 1.7868, value_loss: 0.9795
2024-07-11 15:53:25,024 [INFO    ] __main__: train step 2367: loss: 0.5506, policy_loss: 1.7866, value_loss: 0.9795
2024-07-11 15:53:25,223 [INFO    ] __main__: train step 2368: loss: 0.5508, policy_loss: 1.7865, value_loss: 0.9795
2024-07-11 15:53:25,426 [INFO    ] __main__: train step 2369: loss: 0.5509, policy_loss: 1.7864, value_loss: 0.9795
2024-07-11 15:53:25,639 [INFO    ] __main__: train step 2370: loss: 0.5511, policy_loss: 1.7863, value_loss: 0.9794
2024-07-11 15:53:25,875 [INFO    ] __main__: train step 2371: loss: 0.5512, policy_loss: 1.7862, value_loss: 0.9794
2024-07-11 15:53:26,076 [INFO    ] __main__: train step 2372: loss: 0.5514, policy_loss: 1.7860, value_loss: 0.9794
2024-07-11 15:53:26,556 [INFO    ] __main__: train step 2373: loss: 0.5516, policy_loss: 1.7859, value_loss: 0.9794
2024-07-11 15:53:26,767 [INFO    ] __main__: train step 2374: loss: 0.5517, policy_loss: 1.7858, value_loss: 0.9794
2024-07-11 15:53:26,990 [INFO    ] __main__: train step 2375: loss: 0.5519, policy_loss: 1.7857, value_loss: 0.9794
2024-07-11 15:53:27,190 [INFO    ] __main__: train step 2376: loss: 0.5520, policy_loss: 1.7855, value_loss: 0.9793
2024-07-11 15:53:27,390 [INFO    ] __main__: train step 2377: loss: 0.5522, policy_loss: 1.7854, value_loss: 0.9793
2024-07-11 15:53:27,626 [INFO    ] __main__: train step 2378: loss: 0.5524, policy_loss: 1.7853, value_loss: 0.9793
2024-07-11 15:53:27,812 [INFO    ] __main__: train step 2379: loss: 0.5525, policy_loss: 1.7851, value_loss: 0.9793
2024-07-11 15:53:29,264 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:53:29,694 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:53:29,757 [INFO    ] __main__: train step 2380: loss: 0.5527, policy_loss: 1.7850, value_loss: 0.9793
2024-07-11 15:53:29,927 [INFO    ] __main__: train step 2381: loss: 0.5528, policy_loss: 1.7849, value_loss: 0.9792
2024-07-11 15:53:30,119 [INFO    ] __main__: train step 2382: loss: 0.5530, policy_loss: 1.7847, value_loss: 0.9792
2024-07-11 15:53:30,320 [INFO    ] __main__: train step 2383: loss: 0.5531, policy_loss: 1.7846, value_loss: 0.9792
2024-07-11 15:53:30,505 [INFO    ] __main__: train step 2384: loss: 0.5533, policy_loss: 1.7845, value_loss: 0.9792
2024-07-11 15:53:30,695 [INFO    ] __main__: train step 2385: loss: 0.5534, policy_loss: 1.7843, value_loss: 0.9791
2024-07-11 15:53:30,898 [INFO    ] __main__: train step 2386: loss: 0.5536, policy_loss: 1.7842, value_loss: 0.9791
2024-07-11 15:53:31,102 [INFO    ] __main__: train step 2387: loss: 0.5537, policy_loss: 1.7841, value_loss: 0.9791
2024-07-11 15:53:31,300 [INFO    ] __main__: train step 2388: loss: 0.5539, policy_loss: 1.7840, value_loss: 0.9790
2024-07-11 15:53:31,517 [INFO    ] __main__: train step 2389: loss: 0.5541, policy_loss: 1.7838, value_loss: 0.9790
2024-07-11 15:53:31,758 [INFO    ] __main__: train step 2390: loss: 0.5542, policy_loss: 1.7837, value_loss: 0.9790
2024-07-11 15:53:31,990 [INFO    ] __main__: train step 2391: loss: 0.5544, policy_loss: 1.7836, value_loss: 0.9790
2024-07-11 15:53:32,192 [INFO    ] __main__: train step 2392: loss: 0.5545, policy_loss: 1.7834, value_loss: 0.9789
2024-07-11 15:53:32,405 [INFO    ] __main__: train step 2393: loss: 0.5547, policy_loss: 1.7833, value_loss: 0.9789
2024-07-11 15:53:32,633 [INFO    ] __main__: train step 2394: loss: 0.5548, policy_loss: 1.7832, value_loss: 0.9789
2024-07-11 15:53:32,833 [INFO    ] __main__: train step 2395: loss: 0.5550, policy_loss: 1.7831, value_loss: 0.9789
2024-07-11 15:53:33,318 [INFO    ] __main__: train step 2396: loss: 0.5552, policy_loss: 1.7830, value_loss: 0.9788
2024-07-11 15:53:34,788 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:53:35,219 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:53:35,282 [INFO    ] __main__: train step 2397: loss: 0.5553, policy_loss: 1.7828, value_loss: 0.9788
2024-07-11 15:53:35,452 [INFO    ] __main__: train step 2398: loss: 0.5555, policy_loss: 1.7827, value_loss: 0.9788
2024-07-11 15:53:35,660 [INFO    ] __main__: train step 2399: loss: 0.5557, policy_loss: 1.7826, value_loss: 0.9788
2024-07-11 15:53:35,856 [INFO    ] __main__: train step 2400: loss: 0.5558, policy_loss: 1.7824, value_loss: 0.9787
2024-07-11 15:53:36,053 [INFO    ] __main__: train step 2401: loss: 0.5560, policy_loss: 1.7823, value_loss: 0.9787
2024-07-11 15:53:36,247 [INFO    ] __main__: train step 2402: loss: 0.5561, policy_loss: 1.7822, value_loss: 0.9787
2024-07-11 15:53:36,462 [INFO    ] __main__: train step 2403: loss: 0.5563, policy_loss: 1.7820, value_loss: 0.9786
2024-07-11 15:53:36,658 [INFO    ] __main__: train step 2404: loss: 0.5565, policy_loss: 1.7819, value_loss: 0.9786
2024-07-11 15:53:36,853 [INFO    ] __main__: train step 2405: loss: 0.5566, policy_loss: 1.7818, value_loss: 0.9786
2024-07-11 15:53:37,049 [INFO    ] __main__: train step 2406: loss: 0.5568, policy_loss: 1.7816, value_loss: 0.9786
2024-07-11 15:53:37,253 [INFO    ] __main__: train step 2407: loss: 0.5569, policy_loss: 1.7815, value_loss: 0.9785
2024-07-11 15:53:37,459 [INFO    ] __main__: train step 2408: loss: 0.5571, policy_loss: 1.7814, value_loss: 0.9785
2024-07-11 15:53:37,659 [INFO    ] __main__: train step 2409: loss: 0.5572, policy_loss: 1.7813, value_loss: 0.9785
2024-07-11 15:53:37,868 [INFO    ] __main__: train step 2410: loss: 0.5574, policy_loss: 1.7812, value_loss: 0.9784
2024-07-11 15:53:38,071 [INFO    ] __main__: train step 2411: loss: 0.5576, policy_loss: 1.7810, value_loss: 0.9784
2024-07-11 15:53:38,271 [INFO    ] __main__: train step 2412: loss: 0.5577, policy_loss: 1.7809, value_loss: 0.9784
2024-07-11 15:53:38,467 [INFO    ] __main__: train step 2413: loss: 0.5578, policy_loss: 1.7808, value_loss: 0.9783
2024-07-11 15:53:39,907 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:53:40,341 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:53:40,404 [INFO    ] __main__: train step 2414: loss: 0.5580, policy_loss: 1.7807, value_loss: 0.9783
2024-07-11 15:53:40,586 [INFO    ] __main__: train step 2415: loss: 0.5582, policy_loss: 1.7805, value_loss: 0.9783
2024-07-11 15:53:40,784 [INFO    ] __main__: train step 2416: loss: 0.5583, policy_loss: 1.7804, value_loss: 0.9783
2024-07-11 15:53:40,997 [INFO    ] __main__: train step 2417: loss: 0.5585, policy_loss: 1.7802, value_loss: 0.9782
2024-07-11 15:53:41,212 [INFO    ] __main__: train step 2418: loss: 0.5586, policy_loss: 1.7801, value_loss: 0.9782
2024-07-11 15:53:41,693 [INFO    ] __main__: train step 2419: loss: 0.5588, policy_loss: 1.7800, value_loss: 0.9782
2024-07-11 15:53:41,887 [INFO    ] __main__: train step 2420: loss: 0.5589, policy_loss: 1.7798, value_loss: 0.9782
2024-07-11 15:53:42,077 [INFO    ] __main__: train step 2421: loss: 0.5591, policy_loss: 1.7797, value_loss: 0.9781
2024-07-11 15:53:42,266 [INFO    ] __main__: train step 2422: loss: 0.5592, policy_loss: 1.7796, value_loss: 0.9781
2024-07-11 15:53:42,454 [INFO    ] __main__: train step 2423: loss: 0.5594, policy_loss: 1.7794, value_loss: 0.9781
2024-07-11 15:53:42,644 [INFO    ] __main__: train step 2424: loss: 0.5595, policy_loss: 1.7793, value_loss: 0.9780
2024-07-11 15:53:42,933 [INFO    ] __main__: train step 2425: loss: 0.5597, policy_loss: 1.7792, value_loss: 0.9780
2024-07-11 15:53:43,119 [INFO    ] __main__: train step 2426: loss: 0.5598, policy_loss: 1.7790, value_loss: 0.9780
2024-07-11 15:53:43,316 [INFO    ] __main__: train step 2427: loss: 0.5600, policy_loss: 1.7789, value_loss: 0.9780
2024-07-11 15:53:43,518 [INFO    ] __main__: train step 2428: loss: 0.5602, policy_loss: 1.7788, value_loss: 0.9779
2024-07-11 15:53:43,721 [INFO    ] __main__: train step 2429: loss: 0.5603, policy_loss: 1.7786, value_loss: 0.9779
2024-07-11 15:53:43,949 [INFO    ] __main__: train step 2430: loss: 0.5605, policy_loss: 1.7785, value_loss: 0.9779
2024-07-11 15:53:45,400 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:53:45,780 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:53:45,836 [INFO    ] __main__: train step 2431: loss: 0.5606, policy_loss: 1.7784, value_loss: 0.9779
2024-07-11 15:53:46,012 [INFO    ] __main__: train step 2432: loss: 0.5608, policy_loss: 1.7782, value_loss: 0.9778
2024-07-11 15:53:46,216 [INFO    ] __main__: train step 2433: loss: 0.5609, policy_loss: 1.7781, value_loss: 0.9778
2024-07-11 15:53:46,424 [INFO    ] __main__: train step 2434: loss: 0.5611, policy_loss: 1.7780, value_loss: 0.9778
2024-07-11 15:53:46,637 [INFO    ] __main__: train step 2435: loss: 0.5612, policy_loss: 1.7778, value_loss: 0.9777
2024-07-11 15:53:46,841 [INFO    ] __main__: train step 2436: loss: 0.5614, policy_loss: 1.7777, value_loss: 0.9777
2024-07-11 15:53:47,051 [INFO    ] __main__: train step 2437: loss: 0.5615, policy_loss: 1.7776, value_loss: 0.9777
2024-07-11 15:53:47,261 [INFO    ] __main__: train step 2438: loss: 0.5617, policy_loss: 1.7775, value_loss: 0.9777
2024-07-11 15:53:47,507 [INFO    ] __main__: train step 2439: loss: 0.5618, policy_loss: 1.7773, value_loss: 0.9776
2024-07-11 15:53:47,739 [INFO    ] __main__: train step 2440: loss: 0.5620, policy_loss: 1.7772, value_loss: 0.9776
2024-07-11 15:53:47,928 [INFO    ] __main__: train step 2441: loss: 0.5622, policy_loss: 1.7770, value_loss: 0.9776
2024-07-11 15:53:48,136 [INFO    ] __main__: train step 2442: loss: 0.5623, policy_loss: 1.7769, value_loss: 0.9776
2024-07-11 15:53:48,648 [INFO    ] __main__: train step 2443: loss: 0.5625, policy_loss: 1.7768, value_loss: 0.9775
2024-07-11 15:53:48,844 [INFO    ] __main__: train step 2444: loss: 0.5626, policy_loss: 1.7767, value_loss: 0.9775
2024-07-11 15:53:49,044 [INFO    ] __main__: train step 2445: loss: 0.5628, policy_loss: 1.7765, value_loss: 0.9775
2024-07-11 15:53:49,234 [INFO    ] __main__: train step 2446: loss: 0.5629, policy_loss: 1.7764, value_loss: 0.9774
2024-07-11 15:53:49,442 [INFO    ] __main__: train step 2447: loss: 0.5631, policy_loss: 1.7762, value_loss: 0.9774
2024-07-11 15:53:50,882 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:53:51,275 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:53:51,329 [INFO    ] __main__: train step 2448: loss: 0.5632, policy_loss: 1.7761, value_loss: 0.9774
2024-07-11 15:53:51,502 [INFO    ] __main__: train step 2449: loss: 0.5634, policy_loss: 1.7760, value_loss: 0.9774
2024-07-11 15:53:51,700 [INFO    ] __main__: train step 2450: loss: 0.5635, policy_loss: 1.7758, value_loss: 0.9773
2024-07-11 15:53:51,926 [INFO    ] __main__: train step 2451: loss: 0.5637, policy_loss: 1.7757, value_loss: 0.9773
2024-07-11 15:53:52,127 [INFO    ] __main__: train step 2452: loss: 0.5638, policy_loss: 1.7756, value_loss: 0.9773
2024-07-11 15:53:52,335 [INFO    ] __main__: train step 2453: loss: 0.5640, policy_loss: 1.7755, value_loss: 0.9772
2024-07-11 15:53:52,550 [INFO    ] __main__: train step 2454: loss: 0.5642, policy_loss: 1.7753, value_loss: 0.9772
2024-07-11 15:53:52,796 [INFO    ] __main__: train step 2455: loss: 0.5643, policy_loss: 1.7752, value_loss: 0.9772
2024-07-11 15:53:53,030 [INFO    ] __main__: train step 2456: loss: 0.5645, policy_loss: 1.7751, value_loss: 0.9772
2024-07-11 15:53:53,237 [INFO    ] __main__: train step 2457: loss: 0.5646, policy_loss: 1.7749, value_loss: 0.9771
2024-07-11 15:53:53,444 [INFO    ] __main__: train step 2458: loss: 0.5648, policy_loss: 1.7748, value_loss: 0.9771
2024-07-11 15:53:53,643 [INFO    ] __main__: train step 2459: loss: 0.5649, policy_loss: 1.7747, value_loss: 0.9771
2024-07-11 15:53:53,844 [INFO    ] __main__: train step 2460: loss: 0.5651, policy_loss: 1.7745, value_loss: 0.9770
2024-07-11 15:53:54,048 [INFO    ] __main__: train step 2461: loss: 0.5652, policy_loss: 1.7744, value_loss: 0.9770
2024-07-11 15:53:54,249 [INFO    ] __main__: train step 2462: loss: 0.5654, policy_loss: 1.7743, value_loss: 0.9770
2024-07-11 15:53:54,451 [INFO    ] __main__: train step 2463: loss: 0.5656, policy_loss: 1.7742, value_loss: 0.9770
2024-07-11 15:53:54,643 [INFO    ] __main__: train step 2464: loss: 0.5657, policy_loss: 1.7740, value_loss: 0.9769
2024-07-11 15:53:56,078 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:53:56,486 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:53:56,539 [INFO    ] __main__: train step 2465: loss: 0.5659, policy_loss: 1.7739, value_loss: 0.9769
2024-07-11 15:53:56,992 [INFO    ] __main__: train step 2466: loss: 0.5660, policy_loss: 1.7738, value_loss: 0.9769
2024-07-11 15:53:57,200 [INFO    ] __main__: train step 2467: loss: 0.5662, policy_loss: 1.7737, value_loss: 0.9768
2024-07-11 15:53:57,406 [INFO    ] __main__: train step 2468: loss: 0.5663, policy_loss: 1.7735, value_loss: 0.9768
2024-07-11 15:53:57,612 [INFO    ] __main__: train step 2469: loss: 0.5665, policy_loss: 1.7734, value_loss: 0.9768
2024-07-11 15:53:57,803 [INFO    ] __main__: train step 2470: loss: 0.5667, policy_loss: 1.7733, value_loss: 0.9767
2024-07-11 15:53:58,010 [INFO    ] __main__: train step 2471: loss: 0.5668, policy_loss: 1.7731, value_loss: 0.9767
2024-07-11 15:53:58,222 [INFO    ] __main__: train step 2472: loss: 0.5670, policy_loss: 1.7730, value_loss: 0.9767
2024-07-11 15:53:58,424 [INFO    ] __main__: train step 2473: loss: 0.5671, policy_loss: 1.7729, value_loss: 0.9767
2024-07-11 15:53:58,626 [INFO    ] __main__: train step 2474: loss: 0.5673, policy_loss: 1.7727, value_loss: 0.9766
2024-07-11 15:53:58,860 [INFO    ] __main__: train step 2475: loss: 0.5674, policy_loss: 1.7726, value_loss: 0.9766
2024-07-11 15:53:59,074 [INFO    ] __main__: train step 2476: loss: 0.5676, policy_loss: 1.7725, value_loss: 0.9766
2024-07-11 15:53:59,277 [INFO    ] __main__: train step 2477: loss: 0.5678, policy_loss: 1.7723, value_loss: 0.9766
2024-07-11 15:53:59,487 [INFO    ] __main__: train step 2478: loss: 0.5679, policy_loss: 1.7722, value_loss: 0.9765
2024-07-11 15:53:59,720 [INFO    ] __main__: train step 2479: loss: 0.5681, policy_loss: 1.7721, value_loss: 0.9765
2024-07-11 15:53:59,925 [INFO    ] __main__: train step 2480: loss: 0.5682, policy_loss: 1.7719, value_loss: 0.9765
2024-07-11 15:54:00,121 [INFO    ] __main__: train step 2481: loss: 0.5684, policy_loss: 1.7718, value_loss: 0.9765
2024-07-11 15:54:01,570 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:54:01,995 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:54:02,053 [INFO    ] __main__: train step 2482: loss: 0.5685, policy_loss: 1.7717, value_loss: 0.9764
2024-07-11 15:54:02,220 [INFO    ] __main__: train step 2483: loss: 0.5687, policy_loss: 1.7715, value_loss: 0.9764
2024-07-11 15:54:02,438 [INFO    ] __main__: train step 2484: loss: 0.5688, policy_loss: 1.7714, value_loss: 0.9764
2024-07-11 15:54:02,630 [INFO    ] __main__: train step 2485: loss: 0.5690, policy_loss: 1.7713, value_loss: 0.9763
2024-07-11 15:54:02,837 [INFO    ] __main__: train step 2486: loss: 0.5692, policy_loss: 1.7711, value_loss: 0.9763
2024-07-11 15:54:03,034 [INFO    ] __main__: train step 2487: loss: 0.5693, policy_loss: 1.7710, value_loss: 0.9763
2024-07-11 15:54:03,230 [INFO    ] __main__: train step 2488: loss: 0.5695, policy_loss: 1.7709, value_loss: 0.9763
2024-07-11 15:54:03,722 [INFO    ] __main__: train step 2489: loss: 0.5696, policy_loss: 1.7708, value_loss: 0.9763
2024-07-11 15:54:03,946 [INFO    ] __main__: train step 2490: loss: 0.5698, policy_loss: 1.7706, value_loss: 0.9762
2024-07-11 15:54:04,154 [INFO    ] __main__: train step 2491: loss: 0.5699, policy_loss: 1.7705, value_loss: 0.9762
2024-07-11 15:54:04,352 [INFO    ] __main__: train step 2492: loss: 0.5701, policy_loss: 1.7704, value_loss: 0.9762
2024-07-11 15:54:04,565 [INFO    ] __main__: train step 2493: loss: 0.5702, policy_loss: 1.7702, value_loss: 0.9761
2024-07-11 15:54:04,760 [INFO    ] __main__: train step 2494: loss: 0.5704, policy_loss: 1.7701, value_loss: 0.9761
2024-07-11 15:54:04,982 [INFO    ] __main__: train step 2495: loss: 0.5705, policy_loss: 1.7700, value_loss: 0.9761
2024-07-11 15:54:05,173 [INFO    ] __main__: train step 2496: loss: 0.5707, policy_loss: 1.7698, value_loss: 0.9760
2024-07-11 15:54:05,372 [INFO    ] __main__: train step 2497: loss: 0.5708, policy_loss: 1.7697, value_loss: 0.9760
2024-07-11 15:54:05,571 [INFO    ] __main__: train step 2498: loss: 0.5710, policy_loss: 1.7696, value_loss: 0.9760
2024-07-11 15:54:07,013 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:54:07,414 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:54:07,473 [INFO    ] __main__: train step 2499: loss: 0.5712, policy_loss: 1.7695, value_loss: 0.9759
2024-07-11 15:54:07,655 [INFO    ] __main__: train step 2500: loss: 0.5713, policy_loss: 1.7694, value_loss: 0.9759
2024-07-11 15:54:07,852 [INFO    ] __main__: train step 2501: loss: 0.5714, policy_loss: 1.7692, value_loss: 0.9759
2024-07-11 15:54:08,054 [INFO    ] __main__: train step 2502: loss: 0.5716, policy_loss: 1.7691, value_loss: 0.9758
2024-07-11 15:54:08,268 [INFO    ] __main__: train step 2503: loss: 0.5718, policy_loss: 1.7690, value_loss: 0.9758
2024-07-11 15:54:08,471 [INFO    ] __main__: train step 2504: loss: 0.5719, policy_loss: 1.7688, value_loss: 0.9758
2024-07-11 15:54:08,699 [INFO    ] __main__: train step 2505: loss: 0.5721, policy_loss: 1.7687, value_loss: 0.9757
2024-07-11 15:54:08,901 [INFO    ] __main__: train step 2506: loss: 0.5722, policy_loss: 1.7686, value_loss: 0.9757
2024-07-11 15:54:09,095 [INFO    ] __main__: train step 2507: loss: 0.5724, policy_loss: 1.7684, value_loss: 0.9757
2024-07-11 15:54:09,299 [INFO    ] __main__: train step 2508: loss: 0.5726, policy_loss: 1.7683, value_loss: 0.9757
2024-07-11 15:54:09,494 [INFO    ] __main__: train step 2509: loss: 0.5727, policy_loss: 1.7682, value_loss: 0.9756
2024-07-11 15:54:09,695 [INFO    ] __main__: train step 2510: loss: 0.5729, policy_loss: 1.7681, value_loss: 0.9756
2024-07-11 15:54:09,893 [INFO    ] __main__: train step 2511: loss: 0.5730, policy_loss: 1.7679, value_loss: 0.9756
2024-07-11 15:54:10,098 [INFO    ] __main__: train step 2512: loss: 0.5732, policy_loss: 1.7678, value_loss: 0.9756
2024-07-11 15:54:10,581 [INFO    ] __main__: train step 2513: loss: 0.5733, policy_loss: 1.7677, value_loss: 0.9755
2024-07-11 15:54:10,805 [INFO    ] __main__: train step 2514: loss: 0.5735, policy_loss: 1.7675, value_loss: 0.9755
2024-07-11 15:54:11,017 [INFO    ] __main__: train step 2515: loss: 0.5736, policy_loss: 1.7674, value_loss: 0.9755
2024-07-11 15:54:12,484 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:54:12,867 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:54:12,923 [INFO    ] __main__: train step 2516: loss: 0.5738, policy_loss: 1.7673, value_loss: 0.9755
2024-07-11 15:54:13,099 [INFO    ] __main__: train step 2517: loss: 0.5739, policy_loss: 1.7671, value_loss: 0.9754
2024-07-11 15:54:13,303 [INFO    ] __main__: train step 2518: loss: 0.5741, policy_loss: 1.7670, value_loss: 0.9754
2024-07-11 15:54:13,513 [INFO    ] __main__: train step 2519: loss: 0.5742, policy_loss: 1.7668, value_loss: 0.9754
2024-07-11 15:54:13,743 [INFO    ] __main__: train step 2520: loss: 0.5744, policy_loss: 1.7667, value_loss: 0.9754
2024-07-11 15:54:13,962 [INFO    ] __main__: train step 2521: loss: 0.5745, policy_loss: 1.7666, value_loss: 0.9753
2024-07-11 15:54:14,185 [INFO    ] __main__: train step 2522: loss: 0.5747, policy_loss: 1.7664, value_loss: 0.9753
2024-07-11 15:54:14,431 [INFO    ] __main__: train step 2523: loss: 0.5748, policy_loss: 1.7663, value_loss: 0.9753
2024-07-11 15:54:14,655 [INFO    ] __main__: train step 2524: loss: 0.5750, policy_loss: 1.7662, value_loss: 0.9752
2024-07-11 15:54:14,849 [INFO    ] __main__: train step 2525: loss: 0.5752, policy_loss: 1.7660, value_loss: 0.9752
2024-07-11 15:54:15,045 [INFO    ] __main__: train step 2526: loss: 0.5753, policy_loss: 1.7659, value_loss: 0.9752
2024-07-11 15:54:15,244 [INFO    ] __main__: train step 2527: loss: 0.5755, policy_loss: 1.7658, value_loss: 0.9751
2024-07-11 15:54:15,440 [INFO    ] __main__: train step 2528: loss: 0.5756, policy_loss: 1.7656, value_loss: 0.9751
2024-07-11 15:54:15,643 [INFO    ] __main__: train step 2529: loss: 0.5757, policy_loss: 1.7655, value_loss: 0.9751
2024-07-11 15:54:15,832 [INFO    ] __main__: train step 2530: loss: 0.5759, policy_loss: 1.7654, value_loss: 0.9751
2024-07-11 15:54:16,049 [INFO    ] __main__: train step 2531: loss: 0.5761, policy_loss: 1.7653, value_loss: 0.9750
2024-07-11 15:54:16,236 [INFO    ] __main__: train step 2532: loss: 0.5762, policy_loss: 1.7651, value_loss: 0.9750
2024-07-11 15:54:17,686 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:54:18,064 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:54:18,118 [INFO    ] __main__: train step 2533: loss: 0.5764, policy_loss: 1.7650, value_loss: 0.9750
2024-07-11 15:54:18,286 [INFO    ] __main__: train step 2534: loss: 0.5765, policy_loss: 1.7649, value_loss: 0.9750
2024-07-11 15:54:18,490 [INFO    ] __main__: train step 2535: loss: 0.5767, policy_loss: 1.7647, value_loss: 0.9749
2024-07-11 15:54:18,697 [INFO    ] __main__: train step 2536: loss: 0.5768, policy_loss: 1.7646, value_loss: 0.9749
2024-07-11 15:54:19,178 [INFO    ] __main__: train step 2537: loss: 0.5770, policy_loss: 1.7645, value_loss: 0.9749
2024-07-11 15:54:19,394 [INFO    ] __main__: train step 2538: loss: 0.5771, policy_loss: 1.7644, value_loss: 0.9749
2024-07-11 15:54:19,610 [INFO    ] __main__: train step 2539: loss: 0.5773, policy_loss: 1.7642, value_loss: 0.9748
2024-07-11 15:54:19,843 [INFO    ] __main__: train step 2540: loss: 0.5774, policy_loss: 1.7641, value_loss: 0.9748
2024-07-11 15:54:20,054 [INFO    ] __main__: train step 2541: loss: 0.5776, policy_loss: 1.7640, value_loss: 0.9748
2024-07-11 15:54:20,258 [INFO    ] __main__: train step 2542: loss: 0.5777, policy_loss: 1.7638, value_loss: 0.9747
2024-07-11 15:54:20,479 [INFO    ] __main__: train step 2543: loss: 0.5779, policy_loss: 1.7637, value_loss: 0.9747
2024-07-11 15:54:20,682 [INFO    ] __main__: train step 2544: loss: 0.5780, policy_loss: 1.7636, value_loss: 0.9747
2024-07-11 15:54:20,881 [INFO    ] __main__: train step 2545: loss: 0.5782, policy_loss: 1.7635, value_loss: 0.9747
2024-07-11 15:54:21,097 [INFO    ] __main__: train step 2546: loss: 0.5783, policy_loss: 1.7633, value_loss: 0.9746
2024-07-11 15:54:21,298 [INFO    ] __main__: train step 2547: loss: 0.5785, policy_loss: 1.7632, value_loss: 0.9746
2024-07-11 15:54:21,499 [INFO    ] __main__: train step 2548: loss: 0.5786, policy_loss: 1.7631, value_loss: 0.9746
2024-07-11 15:54:21,709 [INFO    ] __main__: train step 2549: loss: 0.5788, policy_loss: 1.7629, value_loss: 0.9746
2024-07-11 15:54:23,166 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:54:23,593 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:54:23,648 [INFO    ] __main__: train step 2550: loss: 0.5789, policy_loss: 1.7628, value_loss: 0.9745
2024-07-11 15:54:23,822 [INFO    ] __main__: train step 2551: loss: 0.5791, policy_loss: 1.7627, value_loss: 0.9745
2024-07-11 15:54:24,025 [INFO    ] __main__: train step 2552: loss: 0.5792, policy_loss: 1.7625, value_loss: 0.9745
2024-07-11 15:54:24,212 [INFO    ] __main__: train step 2553: loss: 0.5794, policy_loss: 1.7624, value_loss: 0.9745
2024-07-11 15:54:24,415 [INFO    ] __main__: train step 2554: loss: 0.5796, policy_loss: 1.7623, value_loss: 0.9745
2024-07-11 15:54:24,614 [INFO    ] __main__: train step 2555: loss: 0.5797, policy_loss: 1.7622, value_loss: 0.9744
2024-07-11 15:54:24,818 [INFO    ] __main__: train step 2556: loss: 0.5798, policy_loss: 1.7620, value_loss: 0.9744
2024-07-11 15:54:25,027 [INFO    ] __main__: train step 2557: loss: 0.5800, policy_loss: 1.7619, value_loss: 0.9744
2024-07-11 15:54:25,228 [INFO    ] __main__: train step 2558: loss: 0.5802, policy_loss: 1.7618, value_loss: 0.9744
2024-07-11 15:54:25,421 [INFO    ] __main__: train step 2559: loss: 0.5803, policy_loss: 1.7616, value_loss: 0.9743
2024-07-11 15:54:25,918 [INFO    ] __main__: train step 2560: loss: 0.5805, policy_loss: 1.7615, value_loss: 0.9743
2024-07-11 15:54:26,135 [INFO    ] __main__: train step 2561: loss: 0.5806, policy_loss: 1.7614, value_loss: 0.9742
2024-07-11 15:54:26,353 [INFO    ] __main__: train step 2562: loss: 0.5808, policy_loss: 1.7613, value_loss: 0.9742
2024-07-11 15:54:26,581 [INFO    ] __main__: train step 2563: loss: 0.5809, policy_loss: 1.7611, value_loss: 0.9742
2024-07-11 15:54:26,773 [INFO    ] __main__: train step 2564: loss: 0.5811, policy_loss: 1.7610, value_loss: 0.9741
2024-07-11 15:54:27,009 [INFO    ] __main__: train step 2565: loss: 0.5812, policy_loss: 1.7609, value_loss: 0.9741
2024-07-11 15:54:27,223 [INFO    ] __main__: train step 2566: loss: 0.5814, policy_loss: 1.7607, value_loss: 0.9741
2024-07-11 15:54:28,658 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:54:29,021 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:54:29,082 [INFO    ] __main__: train step 2567: loss: 0.5816, policy_loss: 1.7606, value_loss: 0.9740
2024-07-11 15:54:29,254 [INFO    ] __main__: train step 2568: loss: 0.5817, policy_loss: 1.7605, value_loss: 0.9740
2024-07-11 15:54:29,463 [INFO    ] __main__: train step 2569: loss: 0.5819, policy_loss: 1.7604, value_loss: 0.9740
2024-07-11 15:54:29,663 [INFO    ] __main__: train step 2570: loss: 0.5820, policy_loss: 1.7602, value_loss: 0.9739
2024-07-11 15:54:29,865 [INFO    ] __main__: train step 2571: loss: 0.5822, policy_loss: 1.7601, value_loss: 0.9739
2024-07-11 15:54:30,078 [INFO    ] __main__: train step 2572: loss: 0.5823, policy_loss: 1.7600, value_loss: 0.9739
2024-07-11 15:54:30,280 [INFO    ] __main__: train step 2573: loss: 0.5825, policy_loss: 1.7598, value_loss: 0.9738
2024-07-11 15:54:30,479 [INFO    ] __main__: train step 2574: loss: 0.5826, policy_loss: 1.7597, value_loss: 0.9738
2024-07-11 15:54:30,680 [INFO    ] __main__: train step 2575: loss: 0.5827, policy_loss: 1.7596, value_loss: 0.9738
2024-07-11 15:54:30,880 [INFO    ] __main__: train step 2576: loss: 0.5829, policy_loss: 1.7594, value_loss: 0.9737
2024-07-11 15:54:31,081 [INFO    ] __main__: train step 2577: loss: 0.5830, policy_loss: 1.7593, value_loss: 0.9737
2024-07-11 15:54:31,279 [INFO    ] __main__: train step 2578: loss: 0.5832, policy_loss: 1.7592, value_loss: 0.9737
2024-07-11 15:54:31,488 [INFO    ] __main__: train step 2579: loss: 0.5834, policy_loss: 1.7590, value_loss: 0.9737
2024-07-11 15:54:31,687 [INFO    ] __main__: train step 2580: loss: 0.5835, policy_loss: 1.7589, value_loss: 0.9736
2024-07-11 15:54:31,888 [INFO    ] __main__: train step 2581: loss: 0.5837, policy_loss: 1.7588, value_loss: 0.9736
2024-07-11 15:54:32,080 [INFO    ] __main__: train step 2582: loss: 0.5838, policy_loss: 1.7586, value_loss: 0.9736
2024-07-11 15:54:32,288 [INFO    ] __main__: train step 2583: loss: 0.5840, policy_loss: 1.7585, value_loss: 0.9736
2024-07-11 15:54:33,999 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:54:34,413 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:54:34,473 [INFO    ] __main__: train step 2584: loss: 0.5841, policy_loss: 1.7584, value_loss: 0.9735
2024-07-11 15:54:34,654 [INFO    ] __main__: train step 2585: loss: 0.5843, policy_loss: 1.7582, value_loss: 0.9735
2024-07-11 15:54:34,862 [INFO    ] __main__: train step 2586: loss: 0.5844, policy_loss: 1.7581, value_loss: 0.9735
2024-07-11 15:54:35,063 [INFO    ] __main__: train step 2587: loss: 0.5846, policy_loss: 1.7580, value_loss: 0.9734
2024-07-11 15:54:35,254 [INFO    ] __main__: train step 2588: loss: 0.5847, policy_loss: 1.7578, value_loss: 0.9734
2024-07-11 15:54:35,473 [INFO    ] __main__: train step 2589: loss: 0.5849, policy_loss: 1.7577, value_loss: 0.9734
2024-07-11 15:54:35,718 [INFO    ] __main__: train step 2590: loss: 0.5850, policy_loss: 1.7576, value_loss: 0.9733
2024-07-11 15:54:35,962 [INFO    ] __main__: train step 2591: loss: 0.5852, policy_loss: 1.7574, value_loss: 0.9733
2024-07-11 15:54:36,189 [INFO    ] __main__: train step 2592: loss: 0.5853, policy_loss: 1.7573, value_loss: 0.9733
2024-07-11 15:54:36,391 [INFO    ] __main__: train step 2593: loss: 0.5855, policy_loss: 1.7572, value_loss: 0.9733
2024-07-11 15:54:36,585 [INFO    ] __main__: train step 2594: loss: 0.5856, policy_loss: 1.7570, value_loss: 0.9732
2024-07-11 15:54:36,796 [INFO    ] __main__: train step 2595: loss: 0.5858, policy_loss: 1.7569, value_loss: 0.9732
2024-07-11 15:54:36,986 [INFO    ] __main__: train step 2596: loss: 0.5859, policy_loss: 1.7568, value_loss: 0.9732
2024-07-11 15:54:37,195 [INFO    ] __main__: train step 2597: loss: 0.5861, policy_loss: 1.7567, value_loss: 0.9731
2024-07-11 15:54:37,400 [INFO    ] __main__: train step 2598: loss: 0.5862, policy_loss: 1.7565, value_loss: 0.9731
2024-07-11 15:54:37,620 [INFO    ] __main__: train step 2599: loss: 0.5864, policy_loss: 1.7564, value_loss: 0.9731
2024-07-11 15:54:37,840 [INFO    ] __main__: train step 2600: loss: 0.5865, policy_loss: 1.7563, value_loss: 0.9731
2024-07-11 15:54:39,279 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:54:39,639 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:54:39,696 [INFO    ] __main__: train step 2601: loss: 0.5867, policy_loss: 1.7562, value_loss: 0.9730
2024-07-11 15:54:39,881 [INFO    ] __main__: train step 2602: loss: 0.5868, policy_loss: 1.7560, value_loss: 0.9730
2024-07-11 15:54:40,087 [INFO    ] __main__: train step 2603: loss: 0.5870, policy_loss: 1.7559, value_loss: 0.9730
2024-07-11 15:54:40,311 [INFO    ] __main__: train step 2604: loss: 0.5871, policy_loss: 1.7558, value_loss: 0.9729
2024-07-11 15:54:40,525 [INFO    ] __main__: train step 2605: loss: 0.5873, policy_loss: 1.7556, value_loss: 0.9729
2024-07-11 15:54:40,766 [INFO    ] __main__: train step 2606: loss: 0.5875, policy_loss: 1.7555, value_loss: 0.9729
2024-07-11 15:54:41,257 [INFO    ] __main__: train step 2607: loss: 0.5876, policy_loss: 1.7554, value_loss: 0.9729
2024-07-11 15:54:41,485 [INFO    ] __main__: train step 2608: loss: 0.5878, policy_loss: 1.7553, value_loss: 0.9728
2024-07-11 15:54:41,684 [INFO    ] __main__: train step 2609: loss: 0.5879, policy_loss: 1.7551, value_loss: 0.9728
2024-07-11 15:54:41,889 [INFO    ] __main__: train step 2610: loss: 0.5881, policy_loss: 1.7550, value_loss: 0.9728
2024-07-11 15:54:42,102 [INFO    ] __main__: train step 2611: loss: 0.5882, policy_loss: 1.7548, value_loss: 0.9728
2024-07-11 15:54:42,334 [INFO    ] __main__: train step 2612: loss: 0.5884, policy_loss: 1.7547, value_loss: 0.9727
2024-07-11 15:54:42,541 [INFO    ] __main__: train step 2613: loss: 0.5885, policy_loss: 1.7546, value_loss: 0.9727
2024-07-11 15:54:42,743 [INFO    ] __main__: train step 2614: loss: 0.5887, policy_loss: 1.7545, value_loss: 0.9727
2024-07-11 15:54:42,950 [INFO    ] __main__: train step 2615: loss: 0.5888, policy_loss: 1.7543, value_loss: 0.9726
2024-07-11 15:54:43,158 [INFO    ] __main__: train step 2616: loss: 0.5890, policy_loss: 1.7542, value_loss: 0.9726
2024-07-11 15:54:43,358 [INFO    ] __main__: train step 2617: loss: 0.5891, policy_loss: 1.7541, value_loss: 0.9726
2024-07-11 15:54:44,809 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:54:45,202 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:54:45,271 [INFO    ] __main__: train step 2618: loss: 0.5893, policy_loss: 1.7539, value_loss: 0.9726
2024-07-11 15:54:45,451 [INFO    ] __main__: train step 2619: loss: 0.5894, policy_loss: 1.7538, value_loss: 0.9725
2024-07-11 15:54:45,667 [INFO    ] __main__: train step 2620: loss: 0.5896, policy_loss: 1.7537, value_loss: 0.9725
2024-07-11 15:54:45,872 [INFO    ] __main__: train step 2621: loss: 0.5897, policy_loss: 1.7535, value_loss: 0.9725
2024-07-11 15:54:46,063 [INFO    ] __main__: train step 2622: loss: 0.5899, policy_loss: 1.7534, value_loss: 0.9724
2024-07-11 15:54:46,275 [INFO    ] __main__: train step 2623: loss: 0.5900, policy_loss: 1.7533, value_loss: 0.9724
2024-07-11 15:54:46,518 [INFO    ] __main__: train step 2624: loss: 0.5902, policy_loss: 1.7532, value_loss: 0.9724
2024-07-11 15:54:46,738 [INFO    ] __main__: train step 2625: loss: 0.5903, policy_loss: 1.7530, value_loss: 0.9724
2024-07-11 15:54:46,946 [INFO    ] __main__: train step 2626: loss: 0.5905, policy_loss: 1.7529, value_loss: 0.9723
2024-07-11 15:54:47,136 [INFO    ] __main__: train step 2627: loss: 0.5906, policy_loss: 1.7528, value_loss: 0.9723
2024-07-11 15:54:47,349 [INFO    ] __main__: train step 2628: loss: 0.5908, policy_loss: 1.7526, value_loss: 0.9723
2024-07-11 15:54:47,540 [INFO    ] __main__: train step 2629: loss: 0.5909, policy_loss: 1.7525, value_loss: 0.9723
2024-07-11 15:54:47,745 [INFO    ] __main__: train step 2630: loss: 0.5911, policy_loss: 1.7524, value_loss: 0.9722
2024-07-11 15:54:48,225 [INFO    ] __main__: train step 2631: loss: 0.5912, policy_loss: 1.7522, value_loss: 0.9722
2024-07-11 15:54:48,436 [INFO    ] __main__: train step 2632: loss: 0.5914, policy_loss: 1.7521, value_loss: 0.9722
2024-07-11 15:54:48,633 [INFO    ] __main__: train step 2633: loss: 0.5915, policy_loss: 1.7520, value_loss: 0.9721
2024-07-11 15:54:48,859 [INFO    ] __main__: train step 2634: loss: 0.5917, policy_loss: 1.7518, value_loss: 0.9721
2024-07-11 15:54:50,287 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:54:50,660 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:54:50,719 [INFO    ] __main__: train step 2635: loss: 0.5918, policy_loss: 1.7517, value_loss: 0.9721
2024-07-11 15:54:50,883 [INFO    ] __main__: train step 2636: loss: 0.5920, policy_loss: 1.7516, value_loss: 0.9720
2024-07-11 15:54:51,098 [INFO    ] __main__: train step 2637: loss: 0.5921, policy_loss: 1.7514, value_loss: 0.9720
2024-07-11 15:54:51,291 [INFO    ] __main__: train step 2638: loss: 0.5923, policy_loss: 1.7513, value_loss: 0.9720
2024-07-11 15:54:51,492 [INFO    ] __main__: train step 2639: loss: 0.5924, policy_loss: 1.7512, value_loss: 0.9720
2024-07-11 15:54:51,692 [INFO    ] __main__: train step 2640: loss: 0.5926, policy_loss: 1.7510, value_loss: 0.9719
2024-07-11 15:54:51,904 [INFO    ] __main__: train step 2641: loss: 0.5927, policy_loss: 1.7509, value_loss: 0.9719
2024-07-11 15:54:52,104 [INFO    ] __main__: train step 2642: loss: 0.5929, policy_loss: 1.7508, value_loss: 0.9719
2024-07-11 15:54:52,314 [INFO    ] __main__: train step 2643: loss: 0.5930, policy_loss: 1.7506, value_loss: 0.9718
2024-07-11 15:54:52,513 [INFO    ] __main__: train step 2644: loss: 0.5931, policy_loss: 1.7505, value_loss: 0.9718
2024-07-11 15:54:52,714 [INFO    ] __main__: train step 2645: loss: 0.5933, policy_loss: 1.7504, value_loss: 0.9718
2024-07-11 15:54:52,915 [INFO    ] __main__: train step 2646: loss: 0.5934, policy_loss: 1.7502, value_loss: 0.9717
2024-07-11 15:54:53,120 [INFO    ] __main__: train step 2647: loss: 0.5936, policy_loss: 1.7501, value_loss: 0.9717
2024-07-11 15:54:53,331 [INFO    ] __main__: train step 2648: loss: 0.5937, policy_loss: 1.7500, value_loss: 0.9717
2024-07-11 15:54:53,518 [INFO    ] __main__: train step 2649: loss: 0.5939, policy_loss: 1.7498, value_loss: 0.9716
2024-07-11 15:54:53,715 [INFO    ] __main__: train step 2650: loss: 0.5940, policy_loss: 1.7497, value_loss: 0.9716
2024-07-11 15:54:53,909 [INFO    ] __main__: train step 2651: loss: 0.5942, policy_loss: 1.7496, value_loss: 0.9716
2024-07-11 15:54:55,355 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:54:55,757 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:54:55,819 [INFO    ] __main__: train step 2652: loss: 0.5943, policy_loss: 1.7494, value_loss: 0.9716
2024-07-11 15:54:55,984 [INFO    ] __main__: train step 2653: loss: 0.5945, policy_loss: 1.7493, value_loss: 0.9715
2024-07-11 15:54:56,473 [INFO    ] __main__: train step 2654: loss: 0.5946, policy_loss: 1.7491, value_loss: 0.9715
2024-07-11 15:54:56,641 [INFO    ] __main__: train step 2655: loss: 0.5948, policy_loss: 1.7490, value_loss: 0.9715
2024-07-11 15:54:56,840 [INFO    ] __main__: train step 2656: loss: 0.5949, policy_loss: 1.7489, value_loss: 0.9715
2024-07-11 15:54:57,036 [INFO    ] __main__: train step 2657: loss: 0.5951, policy_loss: 1.7488, value_loss: 0.9714
2024-07-11 15:54:57,233 [INFO    ] __main__: train step 2658: loss: 0.5952, policy_loss: 1.7486, value_loss: 0.9714
2024-07-11 15:54:57,439 [INFO    ] __main__: train step 2659: loss: 0.5954, policy_loss: 1.7485, value_loss: 0.9714
2024-07-11 15:54:57,653 [INFO    ] __main__: train step 2660: loss: 0.5955, policy_loss: 1.7484, value_loss: 0.9713
2024-07-11 15:54:57,872 [INFO    ] __main__: train step 2661: loss: 0.5957, policy_loss: 1.7482, value_loss: 0.9713
2024-07-11 15:54:58,069 [INFO    ] __main__: train step 2662: loss: 0.5958, policy_loss: 1.7481, value_loss: 0.9713
2024-07-11 15:54:58,282 [INFO    ] __main__: train step 2663: loss: 0.5960, policy_loss: 1.7480, value_loss: 0.9712
2024-07-11 15:54:58,476 [INFO    ] __main__: train step 2664: loss: 0.5961, policy_loss: 1.7478, value_loss: 0.9712
2024-07-11 15:54:58,668 [INFO    ] __main__: train step 2665: loss: 0.5963, policy_loss: 1.7477, value_loss: 0.9712
2024-07-11 15:54:58,872 [INFO    ] __main__: train step 2666: loss: 0.5964, policy_loss: 1.7476, value_loss: 0.9711
2024-07-11 15:54:59,063 [INFO    ] __main__: train step 2667: loss: 0.5966, policy_loss: 1.7474, value_loss: 0.9711
2024-07-11 15:54:59,260 [INFO    ] __main__: train step 2668: loss: 0.5967, policy_loss: 1.7473, value_loss: 0.9711
2024-07-11 15:55:00,682 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:55:01,091 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:55:01,156 [INFO    ] __main__: train step 2669: loss: 0.5969, policy_loss: 1.7472, value_loss: 0.9710
2024-07-11 15:55:01,343 [INFO    ] __main__: train step 2670: loss: 0.5970, policy_loss: 1.7470, value_loss: 0.9710
2024-07-11 15:55:01,587 [INFO    ] __main__: train step 2671: loss: 0.5972, policy_loss: 1.7469, value_loss: 0.9710
2024-07-11 15:55:01,804 [INFO    ] __main__: train step 2672: loss: 0.5973, policy_loss: 1.7468, value_loss: 0.9710
2024-07-11 15:55:02,020 [INFO    ] __main__: train step 2673: loss: 0.5975, policy_loss: 1.7466, value_loss: 0.9709
2024-07-11 15:55:02,219 [INFO    ] __main__: train step 2674: loss: 0.5976, policy_loss: 1.7465, value_loss: 0.9709
2024-07-11 15:55:02,443 [INFO    ] __main__: train step 2675: loss: 0.5978, policy_loss: 1.7464, value_loss: 0.9709
2024-07-11 15:55:02,692 [INFO    ] __main__: train step 2676: loss: 0.5979, policy_loss: 1.7462, value_loss: 0.9708
2024-07-11 15:55:02,887 [INFO    ] __main__: train step 2677: loss: 0.5981, policy_loss: 1.7461, value_loss: 0.9708
2024-07-11 15:55:03,093 [INFO    ] __main__: train step 2678: loss: 0.5982, policy_loss: 1.7460, value_loss: 0.9708
2024-07-11 15:55:03,581 [INFO    ] __main__: train step 2679: loss: 0.5984, policy_loss: 1.7458, value_loss: 0.9707
2024-07-11 15:55:03,773 [INFO    ] __main__: train step 2680: loss: 0.5985, policy_loss: 1.7457, value_loss: 0.9707
2024-07-11 15:55:03,968 [INFO    ] __main__: train step 2681: loss: 0.5987, policy_loss: 1.7456, value_loss: 0.9707
2024-07-11 15:55:04,173 [INFO    ] __main__: train step 2682: loss: 0.5988, policy_loss: 1.7455, value_loss: 0.9707
2024-07-11 15:55:04,384 [INFO    ] __main__: train step 2683: loss: 0.5990, policy_loss: 1.7453, value_loss: 0.9706
2024-07-11 15:55:04,599 [INFO    ] __main__: train step 2684: loss: 0.5991, policy_loss: 1.7452, value_loss: 0.9706
2024-07-11 15:55:04,833 [INFO    ] __main__: train step 2685: loss: 0.5993, policy_loss: 1.7451, value_loss: 0.9706
2024-07-11 15:55:06,277 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:55:06,637 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:55:06,693 [INFO    ] __main__: train step 2686: loss: 0.5994, policy_loss: 1.7449, value_loss: 0.9705
2024-07-11 15:55:06,871 [INFO    ] __main__: train step 2687: loss: 0.5995, policy_loss: 1.7448, value_loss: 0.9705
2024-07-11 15:55:07,064 [INFO    ] __main__: train step 2688: loss: 0.5997, policy_loss: 1.7447, value_loss: 0.9705
2024-07-11 15:55:07,281 [INFO    ] __main__: train step 2689: loss: 0.5999, policy_loss: 1.7445, value_loss: 0.9704
2024-07-11 15:55:07,477 [INFO    ] __main__: train step 2690: loss: 0.6000, policy_loss: 1.7444, value_loss: 0.9704
2024-07-11 15:55:07,690 [INFO    ] __main__: train step 2691: loss: 0.6002, policy_loss: 1.7443, value_loss: 0.9704
2024-07-11 15:55:07,921 [INFO    ] __main__: train step 2692: loss: 0.6003, policy_loss: 1.7441, value_loss: 0.9703
2024-07-11 15:55:08,153 [INFO    ] __main__: train step 2693: loss: 0.6005, policy_loss: 1.7440, value_loss: 0.9703
2024-07-11 15:55:08,355 [INFO    ] __main__: train step 2694: loss: 0.6006, policy_loss: 1.7439, value_loss: 0.9703
2024-07-11 15:55:08,559 [INFO    ] __main__: train step 2695: loss: 0.6007, policy_loss: 1.7437, value_loss: 0.9702
2024-07-11 15:55:08,762 [INFO    ] __main__: train step 2696: loss: 0.6009, policy_loss: 1.7436, value_loss: 0.9702
2024-07-11 15:55:08,960 [INFO    ] __main__: train step 2697: loss: 0.6010, policy_loss: 1.7435, value_loss: 0.9702
2024-07-11 15:55:09,162 [INFO    ] __main__: train step 2698: loss: 0.6012, policy_loss: 1.7433, value_loss: 0.9702
2024-07-11 15:55:09,398 [INFO    ] __main__: train step 2699: loss: 0.6013, policy_loss: 1.7432, value_loss: 0.9701
2024-07-11 15:55:09,590 [INFO    ] __main__: train step 2700: loss: 0.6015, policy_loss: 1.7431, value_loss: 0.9701
2024-07-11 15:55:10,077 [INFO    ] __main__: train step 2701: loss: 0.6016, policy_loss: 1.7429, value_loss: 0.9701
2024-07-11 15:55:10,294 [INFO    ] __main__: train step 2702: loss: 0.6018, policy_loss: 1.7428, value_loss: 0.9700
2024-07-11 15:55:11,747 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:55:12,132 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:55:12,185 [INFO    ] __main__: train step 2703: loss: 0.6019, policy_loss: 1.7427, value_loss: 0.9700
2024-07-11 15:55:12,369 [INFO    ] __main__: train step 2704: loss: 0.6020, policy_loss: 1.7425, value_loss: 0.9700
2024-07-11 15:55:12,595 [INFO    ] __main__: train step 2705: loss: 0.6022, policy_loss: 1.7424, value_loss: 0.9699
2024-07-11 15:55:12,794 [INFO    ] __main__: train step 2706: loss: 0.6023, policy_loss: 1.7423, value_loss: 0.9699
2024-07-11 15:55:13,013 [INFO    ] __main__: train step 2707: loss: 0.6025, policy_loss: 1.7421, value_loss: 0.9699
2024-07-11 15:55:13,220 [INFO    ] __main__: train step 2708: loss: 0.6026, policy_loss: 1.7420, value_loss: 0.9698
2024-07-11 15:55:13,423 [INFO    ] __main__: train step 2709: loss: 0.6028, policy_loss: 1.7419, value_loss: 0.9698
2024-07-11 15:55:13,636 [INFO    ] __main__: train step 2710: loss: 0.6029, policy_loss: 1.7417, value_loss: 0.9698
2024-07-11 15:55:13,884 [INFO    ] __main__: train step 2711: loss: 0.6031, policy_loss: 1.7416, value_loss: 0.9698
2024-07-11 15:55:14,094 [INFO    ] __main__: train step 2712: loss: 0.6032, policy_loss: 1.7414, value_loss: 0.9697
2024-07-11 15:55:14,305 [INFO    ] __main__: train step 2713: loss: 0.6034, policy_loss: 1.7413, value_loss: 0.9697
2024-07-11 15:55:14,533 [INFO    ] __main__: train step 2714: loss: 0.6035, policy_loss: 1.7412, value_loss: 0.9697
2024-07-11 15:55:14,736 [INFO    ] __main__: train step 2715: loss: 0.6037, policy_loss: 1.7410, value_loss: 0.9697
2024-07-11 15:55:14,934 [INFO    ] __main__: train step 2716: loss: 0.6038, policy_loss: 1.7409, value_loss: 0.9696
2024-07-11 15:55:15,145 [INFO    ] __main__: train step 2717: loss: 0.6039, policy_loss: 1.7408, value_loss: 0.9696
2024-07-11 15:55:15,370 [INFO    ] __main__: train step 2718: loss: 0.6041, policy_loss: 1.7407, value_loss: 0.9696
2024-07-11 15:55:15,572 [INFO    ] __main__: train step 2719: loss: 0.6043, policy_loss: 1.7405, value_loss: 0.9695
2024-07-11 15:55:17,025 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:55:17,445 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:55:17,504 [INFO    ] __main__: train step 2720: loss: 0.6044, policy_loss: 1.7404, value_loss: 0.9695
2024-07-11 15:55:17,670 [INFO    ] __main__: train step 2721: loss: 0.6046, policy_loss: 1.7403, value_loss: 0.9695
2024-07-11 15:55:17,873 [INFO    ] __main__: train step 2722: loss: 0.6047, policy_loss: 1.7401, value_loss: 0.9694
2024-07-11 15:55:18,085 [INFO    ] __main__: train step 2723: loss: 0.6049, policy_loss: 1.7400, value_loss: 0.9694
2024-07-11 15:55:18,274 [INFO    ] __main__: train step 2724: loss: 0.6050, policy_loss: 1.7399, value_loss: 0.9694
2024-07-11 15:55:18,757 [INFO    ] __main__: train step 2725: loss: 0.6052, policy_loss: 1.7397, value_loss: 0.9693
2024-07-11 15:55:18,975 [INFO    ] __main__: train step 2726: loss: 0.6053, policy_loss: 1.7396, value_loss: 0.9693
2024-07-11 15:55:19,170 [INFO    ] __main__: train step 2727: loss: 0.6055, policy_loss: 1.7395, value_loss: 0.9693
2024-07-11 15:55:19,380 [INFO    ] __main__: train step 2728: loss: 0.6056, policy_loss: 1.7393, value_loss: 0.9692
2024-07-11 15:55:19,580 [INFO    ] __main__: train step 2729: loss: 0.6058, policy_loss: 1.7392, value_loss: 0.9692
2024-07-11 15:55:19,795 [INFO    ] __main__: train step 2730: loss: 0.6059, policy_loss: 1.7391, value_loss: 0.9692
2024-07-11 15:55:20,029 [INFO    ] __main__: train step 2731: loss: 0.6060, policy_loss: 1.7389, value_loss: 0.9691
2024-07-11 15:55:20,244 [INFO    ] __main__: train step 2732: loss: 0.6062, policy_loss: 1.7388, value_loss: 0.9691
2024-07-11 15:55:20,468 [INFO    ] __main__: train step 2733: loss: 0.6063, policy_loss: 1.7387, value_loss: 0.9691
2024-07-11 15:55:20,670 [INFO    ] __main__: train step 2734: loss: 0.6065, policy_loss: 1.7386, value_loss: 0.9691
2024-07-11 15:55:20,862 [INFO    ] __main__: train step 2735: loss: 0.6066, policy_loss: 1.7384, value_loss: 0.9690
2024-07-11 15:55:21,073 [INFO    ] __main__: train step 2736: loss: 0.6068, policy_loss: 1.7383, value_loss: 0.9690
2024-07-11 15:55:22,525 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:55:22,925 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:55:22,979 [INFO    ] __main__: train step 2737: loss: 0.6069, policy_loss: 1.7382, value_loss: 0.9690
2024-07-11 15:55:23,148 [INFO    ] __main__: train step 2738: loss: 0.6071, policy_loss: 1.7380, value_loss: 0.9689
2024-07-11 15:55:23,364 [INFO    ] __main__: train step 2739: loss: 0.6072, policy_loss: 1.7379, value_loss: 0.9689
2024-07-11 15:55:23,591 [INFO    ] __main__: train step 2740: loss: 0.6074, policy_loss: 1.7377, value_loss: 0.9689
2024-07-11 15:55:23,807 [INFO    ] __main__: train step 2741: loss: 0.6075, policy_loss: 1.7376, value_loss: 0.9688
2024-07-11 15:55:24,001 [INFO    ] __main__: train step 2742: loss: 0.6077, policy_loss: 1.7375, value_loss: 0.9688
2024-07-11 15:55:24,204 [INFO    ] __main__: train step 2743: loss: 0.6078, policy_loss: 1.7373, value_loss: 0.9688
2024-07-11 15:55:24,400 [INFO    ] __main__: train step 2744: loss: 0.6079, policy_loss: 1.7372, value_loss: 0.9687
2024-07-11 15:55:24,599 [INFO    ] __main__: train step 2745: loss: 0.6081, policy_loss: 1.7371, value_loss: 0.9687
2024-07-11 15:55:24,805 [INFO    ] __main__: train step 2746: loss: 0.6082, policy_loss: 1.7370, value_loss: 0.9687
2024-07-11 15:55:25,010 [INFO    ] __main__: train step 2747: loss: 0.6084, policy_loss: 1.7368, value_loss: 0.9686
2024-07-11 15:55:25,209 [INFO    ] __main__: train step 2748: loss: 0.6085, policy_loss: 1.7367, value_loss: 0.9686
2024-07-11 15:55:25,749 [INFO    ] __main__: train step 2749: loss: 0.6087, policy_loss: 1.7366, value_loss: 0.9686
2024-07-11 15:55:25,948 [INFO    ] __main__: train step 2750: loss: 0.6088, policy_loss: 1.7364, value_loss: 0.9686
2024-07-11 15:55:26,149 [INFO    ] __main__: train step 2751: loss: 0.6090, policy_loss: 1.7363, value_loss: 0.9685
2024-07-11 15:55:26,364 [INFO    ] __main__: train step 2752: loss: 0.6091, policy_loss: 1.7362, value_loss: 0.9685
2024-07-11 15:55:26,588 [INFO    ] __main__: train step 2753: loss: 0.6093, policy_loss: 1.7360, value_loss: 0.9684
2024-07-11 15:55:28,026 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:55:28,415 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:55:28,477 [INFO    ] __main__: train step 2754: loss: 0.6094, policy_loss: 1.7359, value_loss: 0.9684
2024-07-11 15:55:28,658 [INFO    ] __main__: train step 2755: loss: 0.6096, policy_loss: 1.7358, value_loss: 0.9684
2024-07-11 15:55:28,879 [INFO    ] __main__: train step 2756: loss: 0.6097, policy_loss: 1.7356, value_loss: 0.9683
2024-07-11 15:55:29,102 [INFO    ] __main__: train step 2757: loss: 0.6099, policy_loss: 1.7355, value_loss: 0.9683
2024-07-11 15:55:29,303 [INFO    ] __main__: train step 2758: loss: 0.6100, policy_loss: 1.7354, value_loss: 0.9683
2024-07-11 15:55:29,526 [INFO    ] __main__: train step 2759: loss: 0.6102, policy_loss: 1.7352, value_loss: 0.9682
2024-07-11 15:55:29,729 [INFO    ] __main__: train step 2760: loss: 0.6103, policy_loss: 1.7351, value_loss: 0.9682
2024-07-11 15:55:29,927 [INFO    ] __main__: train step 2761: loss: 0.6104, policy_loss: 1.7350, value_loss: 0.9682
2024-07-11 15:55:30,137 [INFO    ] __main__: train step 2762: loss: 0.6106, policy_loss: 1.7348, value_loss: 0.9681
2024-07-11 15:55:30,332 [INFO    ] __main__: train step 2763: loss: 0.6107, policy_loss: 1.7347, value_loss: 0.9681
2024-07-11 15:55:30,531 [INFO    ] __main__: train step 2764: loss: 0.6109, policy_loss: 1.7346, value_loss: 0.9681
2024-07-11 15:55:30,749 [INFO    ] __main__: train step 2765: loss: 0.6110, policy_loss: 1.7344, value_loss: 0.9680
2024-07-11 15:55:30,978 [INFO    ] __main__: train step 2766: loss: 0.6111, policy_loss: 1.7343, value_loss: 0.9680
2024-07-11 15:55:31,187 [INFO    ] __main__: train step 2767: loss: 0.6113, policy_loss: 1.7342, value_loss: 0.9680
2024-07-11 15:55:31,417 [INFO    ] __main__: train step 2768: loss: 0.6114, policy_loss: 1.7340, value_loss: 0.9679
2024-07-11 15:55:31,641 [INFO    ] __main__: train step 2769: loss: 0.6116, policy_loss: 1.7339, value_loss: 0.9679
2024-07-11 15:55:31,846 [INFO    ] __main__: train step 2770: loss: 0.6117, policy_loss: 1.7338, value_loss: 0.9679
2024-07-11 15:55:33,278 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:55:33,629 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:55:33,687 [INFO    ] __main__: train step 2771: loss: 0.6119, policy_loss: 1.7337, value_loss: 0.9679
2024-07-11 15:55:33,860 [INFO    ] __main__: train step 2772: loss: 0.6120, policy_loss: 1.7335, value_loss: 0.9678
2024-07-11 15:55:34,060 [INFO    ] __main__: train step 2773: loss: 0.6121, policy_loss: 1.7334, value_loss: 0.9678
2024-07-11 15:55:34,530 [INFO    ] __main__: train step 2774: loss: 0.6123, policy_loss: 1.7333, value_loss: 0.9678
2024-07-11 15:55:34,755 [INFO    ] __main__: train step 2775: loss: 0.6124, policy_loss: 1.7331, value_loss: 0.9677
2024-07-11 15:55:34,978 [INFO    ] __main__: train step 2776: loss: 0.6126, policy_loss: 1.7330, value_loss: 0.9677
2024-07-11 15:55:35,181 [INFO    ] __main__: train step 2777: loss: 0.6127, policy_loss: 1.7329, value_loss: 0.9677
2024-07-11 15:55:35,391 [INFO    ] __main__: train step 2778: loss: 0.6129, policy_loss: 1.7327, value_loss: 0.9676
2024-07-11 15:55:35,588 [INFO    ] __main__: train step 2779: loss: 0.6130, policy_loss: 1.7326, value_loss: 0.9676
2024-07-11 15:55:35,805 [INFO    ] __main__: train step 2780: loss: 0.6132, policy_loss: 1.7324, value_loss: 0.9676
2024-07-11 15:55:36,024 [INFO    ] __main__: train step 2781: loss: 0.6133, policy_loss: 1.7323, value_loss: 0.9675
2024-07-11 15:55:36,225 [INFO    ] __main__: train step 2782: loss: 0.6135, policy_loss: 1.7322, value_loss: 0.9675
2024-07-11 15:55:36,427 [INFO    ] __main__: train step 2783: loss: 0.6136, policy_loss: 1.7320, value_loss: 0.9675
2024-07-11 15:55:36,624 [INFO    ] __main__: train step 2784: loss: 0.6137, policy_loss: 1.7319, value_loss: 0.9674
2024-07-11 15:55:36,824 [INFO    ] __main__: train step 2785: loss: 0.6139, policy_loss: 1.7318, value_loss: 0.9674
2024-07-11 15:55:37,032 [INFO    ] __main__: train step 2786: loss: 0.6140, policy_loss: 1.7316, value_loss: 0.9674
2024-07-11 15:55:37,233 [INFO    ] __main__: train step 2787: loss: 0.6142, policy_loss: 1.7315, value_loss: 0.9674
2024-07-11 15:55:38,680 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:55:39,045 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:55:39,101 [INFO    ] __main__: train step 2788: loss: 0.6143, policy_loss: 1.7314, value_loss: 0.9673
2024-07-11 15:55:39,269 [INFO    ] __main__: train step 2789: loss: 0.6145, policy_loss: 1.7313, value_loss: 0.9673
2024-07-11 15:55:39,483 [INFO    ] __main__: train step 2790: loss: 0.6146, policy_loss: 1.7311, value_loss: 0.9673
2024-07-11 15:55:39,692 [INFO    ] __main__: train step 2791: loss: 0.6148, policy_loss: 1.7310, value_loss: 0.9672
2024-07-11 15:55:39,899 [INFO    ] __main__: train step 2792: loss: 0.6149, policy_loss: 1.7309, value_loss: 0.9672
2024-07-11 15:55:40,097 [INFO    ] __main__: train step 2793: loss: 0.6151, policy_loss: 1.7307, value_loss: 0.9671
2024-07-11 15:55:40,309 [INFO    ] __main__: train step 2794: loss: 0.6152, policy_loss: 1.7306, value_loss: 0.9671
2024-07-11 15:55:40,507 [INFO    ] __main__: train step 2795: loss: 0.6154, policy_loss: 1.7305, value_loss: 0.9671
2024-07-11 15:55:40,730 [INFO    ] __main__: train step 2796: loss: 0.6155, policy_loss: 1.7303, value_loss: 0.9670
2024-07-11 15:55:41,221 [INFO    ] __main__: train step 2797: loss: 0.6156, policy_loss: 1.7302, value_loss: 0.9670
2024-07-11 15:55:41,459 [INFO    ] __main__: train step 2798: loss: 0.6158, policy_loss: 1.7301, value_loss: 0.9670
2024-07-11 15:55:41,698 [INFO    ] __main__: train step 2799: loss: 0.6159, policy_loss: 1.7300, value_loss: 0.9669
2024-07-11 15:55:41,900 [INFO    ] __main__: train step 2800: loss: 0.6161, policy_loss: 1.7298, value_loss: 0.9669
2024-07-11 15:55:42,108 [INFO    ] __main__: train step 2801: loss: 0.6162, policy_loss: 1.7297, value_loss: 0.9669
2024-07-11 15:55:42,320 [INFO    ] __main__: train step 2802: loss: 0.6164, policy_loss: 1.7296, value_loss: 0.9668
2024-07-11 15:55:42,519 [INFO    ] __main__: train step 2803: loss: 0.6165, policy_loss: 1.7294, value_loss: 0.9668
2024-07-11 15:55:42,731 [INFO    ] __main__: train step 2804: loss: 0.6166, policy_loss: 1.7293, value_loss: 0.9668
2024-07-11 15:55:44,174 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:55:44,552 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:55:44,609 [INFO    ] __main__: train step 2805: loss: 0.6168, policy_loss: 1.7292, value_loss: 0.9668
2024-07-11 15:55:44,780 [INFO    ] __main__: train step 2806: loss: 0.6169, policy_loss: 1.7290, value_loss: 0.9667
2024-07-11 15:55:44,970 [INFO    ] __main__: train step 2807: loss: 0.6171, policy_loss: 1.7289, value_loss: 0.9667
2024-07-11 15:55:45,173 [INFO    ] __main__: train step 2808: loss: 0.6172, policy_loss: 1.7288, value_loss: 0.9666
2024-07-11 15:55:45,369 [INFO    ] __main__: train step 2809: loss: 0.6174, policy_loss: 1.7286, value_loss: 0.9666
2024-07-11 15:55:45,562 [INFO    ] __main__: train step 2810: loss: 0.6175, policy_loss: 1.7285, value_loss: 0.9666
2024-07-11 15:55:45,761 [INFO    ] __main__: train step 2811: loss: 0.6176, policy_loss: 1.7284, value_loss: 0.9665
2024-07-11 15:55:45,957 [INFO    ] __main__: train step 2812: loss: 0.6178, policy_loss: 1.7282, value_loss: 0.9665
2024-07-11 15:55:46,155 [INFO    ] __main__: train step 2813: loss: 0.6179, policy_loss: 1.7281, value_loss: 0.9665
2024-07-11 15:55:46,356 [INFO    ] __main__: train step 2814: loss: 0.6181, policy_loss: 1.7280, value_loss: 0.9664
2024-07-11 15:55:46,564 [INFO    ] __main__: train step 2815: loss: 0.6182, policy_loss: 1.7279, value_loss: 0.9664
2024-07-11 15:55:46,756 [INFO    ] __main__: train step 2816: loss: 0.6184, policy_loss: 1.7277, value_loss: 0.9664
2024-07-11 15:55:46,966 [INFO    ] __main__: train step 2817: loss: 0.6185, policy_loss: 1.7276, value_loss: 0.9663
2024-07-11 15:55:47,163 [INFO    ] __main__: train step 2818: loss: 0.6187, policy_loss: 1.7275, value_loss: 0.9663
2024-07-11 15:55:47,385 [INFO    ] __main__: train step 2819: loss: 0.6188, policy_loss: 1.7273, value_loss: 0.9663
2024-07-11 15:55:47,571 [INFO    ] __main__: train step 2820: loss: 0.6190, policy_loss: 1.7272, value_loss: 0.9663
2024-07-11 15:55:48,049 [INFO    ] __main__: train step 2821: loss: 0.6191, policy_loss: 1.7271, value_loss: 0.9662
2024-07-11 15:55:49,514 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:55:49,909 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:55:49,971 [INFO    ] __main__: train step 2822: loss: 0.6193, policy_loss: 1.7269, value_loss: 0.9662
2024-07-11 15:55:50,155 [INFO    ] __main__: train step 2823: loss: 0.6194, policy_loss: 1.7268, value_loss: 0.9662
2024-07-11 15:55:50,396 [INFO    ] __main__: train step 2824: loss: 0.6196, policy_loss: 1.7267, value_loss: 0.9661
2024-07-11 15:55:50,614 [INFO    ] __main__: train step 2825: loss: 0.6197, policy_loss: 1.7265, value_loss: 0.9661
2024-07-11 15:55:50,804 [INFO    ] __main__: train step 2826: loss: 0.6198, policy_loss: 1.7264, value_loss: 0.9661
2024-07-11 15:55:50,998 [INFO    ] __main__: train step 2827: loss: 0.6200, policy_loss: 1.7263, value_loss: 0.9660
2024-07-11 15:55:51,201 [INFO    ] __main__: train step 2828: loss: 0.6201, policy_loss: 1.7261, value_loss: 0.9660
2024-07-11 15:55:51,402 [INFO    ] __main__: train step 2829: loss: 0.6203, policy_loss: 1.7260, value_loss: 0.9660
2024-07-11 15:55:51,596 [INFO    ] __main__: train step 2830: loss: 0.6204, policy_loss: 1.7259, value_loss: 0.9659
2024-07-11 15:55:51,788 [INFO    ] __main__: train step 2831: loss: 0.6206, policy_loss: 1.7257, value_loss: 0.9659
2024-07-11 15:55:51,991 [INFO    ] __main__: train step 2832: loss: 0.6207, policy_loss: 1.7256, value_loss: 0.9659
2024-07-11 15:55:52,184 [INFO    ] __main__: train step 2833: loss: 0.6209, policy_loss: 1.7255, value_loss: 0.9658
2024-07-11 15:55:52,395 [INFO    ] __main__: train step 2834: loss: 0.6210, policy_loss: 1.7253, value_loss: 0.9658
2024-07-11 15:55:52,602 [INFO    ] __main__: train step 2835: loss: 0.6211, policy_loss: 1.7252, value_loss: 0.9658
2024-07-11 15:55:52,805 [INFO    ] __main__: train step 2836: loss: 0.6213, policy_loss: 1.7251, value_loss: 0.9657
2024-07-11 15:55:53,021 [INFO    ] __main__: train step 2837: loss: 0.6214, policy_loss: 1.7250, value_loss: 0.9657
2024-07-11 15:55:53,221 [INFO    ] __main__: train step 2838: loss: 0.6216, policy_loss: 1.7248, value_loss: 0.9657
2024-07-11 15:55:54,682 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:55:55,048 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:55:55,104 [INFO    ] __main__: train step 2839: loss: 0.6217, policy_loss: 1.7247, value_loss: 0.9656
2024-07-11 15:55:55,278 [INFO    ] __main__: train step 2840: loss: 0.6219, policy_loss: 1.7246, value_loss: 0.9656
2024-07-11 15:55:55,487 [INFO    ] __main__: train step 2841: loss: 0.6220, policy_loss: 1.7244, value_loss: 0.9656
2024-07-11 15:55:55,695 [INFO    ] __main__: train step 2842: loss: 0.6221, policy_loss: 1.7243, value_loss: 0.9655
2024-07-11 15:55:55,904 [INFO    ] __main__: train step 2843: loss: 0.6223, policy_loss: 1.7242, value_loss: 0.9655
2024-07-11 15:55:56,383 [INFO    ] __main__: train step 2844: loss: 0.6224, policy_loss: 1.7240, value_loss: 0.9655
2024-07-11 15:55:56,587 [INFO    ] __main__: train step 2845: loss: 0.6226, policy_loss: 1.7239, value_loss: 0.9654
2024-07-11 15:55:56,797 [INFO    ] __main__: train step 2846: loss: 0.6227, policy_loss: 1.7238, value_loss: 0.9654
2024-07-11 15:55:57,004 [INFO    ] __main__: train step 2847: loss: 0.6229, policy_loss: 1.7236, value_loss: 0.9653
2024-07-11 15:55:57,203 [INFO    ] __main__: train step 2848: loss: 0.6230, policy_loss: 1.7235, value_loss: 0.9653
2024-07-11 15:55:57,399 [INFO    ] __main__: train step 2849: loss: 0.6232, policy_loss: 1.7234, value_loss: 0.9653
2024-07-11 15:55:57,605 [INFO    ] __main__: train step 2850: loss: 0.6233, policy_loss: 1.7233, value_loss: 0.9653
2024-07-11 15:55:57,803 [INFO    ] __main__: train step 2851: loss: 0.6235, policy_loss: 1.7231, value_loss: 0.9652
2024-07-11 15:55:58,021 [INFO    ] __main__: train step 2852: loss: 0.6236, policy_loss: 1.7230, value_loss: 0.9652
2024-07-11 15:55:58,268 [INFO    ] __main__: train step 2853: loss: 0.6237, policy_loss: 1.7228, value_loss: 0.9652
2024-07-11 15:55:58,511 [INFO    ] __main__: train step 2854: loss: 0.6239, policy_loss: 1.7227, value_loss: 0.9651
2024-07-11 15:55:58,716 [INFO    ] __main__: train step 2855: loss: 0.6240, policy_loss: 1.7226, value_loss: 0.9651
2024-07-11 15:56:00,174 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:56:00,568 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:56:00,623 [INFO    ] __main__: train step 2856: loss: 0.6241, policy_loss: 1.7224, value_loss: 0.9651
2024-07-11 15:56:00,799 [INFO    ] __main__: train step 2857: loss: 0.6243, policy_loss: 1.7223, value_loss: 0.9650
2024-07-11 15:56:00,997 [INFO    ] __main__: train step 2858: loss: 0.6244, policy_loss: 1.7222, value_loss: 0.9650
2024-07-11 15:56:01,211 [INFO    ] __main__: train step 2859: loss: 0.6246, policy_loss: 1.7220, value_loss: 0.9650
2024-07-11 15:56:01,417 [INFO    ] __main__: train step 2860: loss: 0.6247, policy_loss: 1.7219, value_loss: 0.9650
2024-07-11 15:56:01,634 [INFO    ] __main__: train step 2861: loss: 0.6248, policy_loss: 1.7218, value_loss: 0.9649
2024-07-11 15:56:01,847 [INFO    ] __main__: train step 2862: loss: 0.6250, policy_loss: 1.7216, value_loss: 0.9649
2024-07-11 15:56:02,064 [INFO    ] __main__: train step 2863: loss: 0.6251, policy_loss: 1.7215, value_loss: 0.9649
2024-07-11 15:56:02,258 [INFO    ] __main__: train step 2864: loss: 0.6253, policy_loss: 1.7214, value_loss: 0.9648
2024-07-11 15:56:02,472 [INFO    ] __main__: train step 2865: loss: 0.6254, policy_loss: 1.7212, value_loss: 0.9648
2024-07-11 15:56:02,948 [INFO    ] __main__: train step 2866: loss: 0.6255, policy_loss: 1.7211, value_loss: 0.9648
2024-07-11 15:56:03,116 [INFO    ] __main__: train step 2867: loss: 0.6257, policy_loss: 1.7210, value_loss: 0.9648
2024-07-11 15:56:03,323 [INFO    ] __main__: train step 2868: loss: 0.6258, policy_loss: 1.7208, value_loss: 0.9647
2024-07-11 15:56:03,524 [INFO    ] __main__: train step 2869: loss: 0.6260, policy_loss: 1.7207, value_loss: 0.9647
2024-07-11 15:56:03,730 [INFO    ] __main__: train step 2870: loss: 0.6261, policy_loss: 1.7206, value_loss: 0.9646
2024-07-11 15:56:03,934 [INFO    ] __main__: train step 2871: loss: 0.6263, policy_loss: 1.7205, value_loss: 0.9646
2024-07-11 15:56:04,126 [INFO    ] __main__: train step 2872: loss: 0.6264, policy_loss: 1.7203, value_loss: 0.9646
2024-07-11 15:56:05,577 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:56:05,971 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:56:06,035 [INFO    ] __main__: train step 2873: loss: 0.6265, policy_loss: 1.7202, value_loss: 0.9645
2024-07-11 15:56:06,212 [INFO    ] __main__: train step 2874: loss: 0.6267, policy_loss: 1.7201, value_loss: 0.9645
2024-07-11 15:56:06,401 [INFO    ] __main__: train step 2875: loss: 0.6268, policy_loss: 1.7199, value_loss: 0.9645
2024-07-11 15:56:06,596 [INFO    ] __main__: train step 2876: loss: 0.6270, policy_loss: 1.7198, value_loss: 0.9645
2024-07-11 15:56:06,793 [INFO    ] __main__: train step 2877: loss: 0.6271, policy_loss: 1.7197, value_loss: 0.9644
2024-07-11 15:56:06,995 [INFO    ] __main__: train step 2878: loss: 0.6273, policy_loss: 1.7196, value_loss: 0.9644
2024-07-11 15:56:07,192 [INFO    ] __main__: train step 2879: loss: 0.6274, policy_loss: 1.7194, value_loss: 0.9643
2024-07-11 15:56:07,387 [INFO    ] __main__: train step 2880: loss: 0.6275, policy_loss: 1.7193, value_loss: 0.9643
2024-07-11 15:56:07,585 [INFO    ] __main__: train step 2881: loss: 0.6277, policy_loss: 1.7192, value_loss: 0.9643
2024-07-11 15:56:07,787 [INFO    ] __main__: train step 2882: loss: 0.6278, policy_loss: 1.7190, value_loss: 0.9643
2024-07-11 15:56:07,995 [INFO    ] __main__: train step 2883: loss: 0.6280, policy_loss: 1.7189, value_loss: 0.9642
2024-07-11 15:56:08,221 [INFO    ] __main__: train step 2884: loss: 0.6281, policy_loss: 1.7188, value_loss: 0.9642
2024-07-11 15:56:08,440 [INFO    ] __main__: train step 2885: loss: 0.6283, policy_loss: 1.7186, value_loss: 0.9642
2024-07-11 15:56:08,669 [INFO    ] __main__: train step 2886: loss: 0.6284, policy_loss: 1.7185, value_loss: 0.9641
2024-07-11 15:56:08,871 [INFO    ] __main__: train step 2887: loss: 0.6286, policy_loss: 1.7184, value_loss: 0.9641
2024-07-11 15:56:09,064 [INFO    ] __main__: train step 2888: loss: 0.6287, policy_loss: 1.7182, value_loss: 0.9641
2024-07-11 15:56:09,547 [INFO    ] __main__: train step 2889: loss: 0.6288, policy_loss: 1.7181, value_loss: 0.9640
2024-07-11 15:56:11,011 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:56:11,430 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:56:11,492 [INFO    ] __main__: train step 2890: loss: 0.6290, policy_loss: 1.7180, value_loss: 0.9640
2024-07-11 15:56:11,669 [INFO    ] __main__: train step 2891: loss: 0.6291, policy_loss: 1.7179, value_loss: 0.9640
2024-07-11 15:56:11,865 [INFO    ] __main__: train step 2892: loss: 0.6293, policy_loss: 1.7177, value_loss: 0.9639
2024-07-11 15:56:12,054 [INFO    ] __main__: train step 2893: loss: 0.6294, policy_loss: 1.7176, value_loss: 0.9639
2024-07-11 15:56:12,255 [INFO    ] __main__: train step 2894: loss: 0.6296, policy_loss: 1.7175, value_loss: 0.9639
2024-07-11 15:56:12,447 [INFO    ] __main__: train step 2895: loss: 0.6297, policy_loss: 1.7173, value_loss: 0.9638
2024-07-11 15:56:12,642 [INFO    ] __main__: train step 2896: loss: 0.6298, policy_loss: 1.7172, value_loss: 0.9638
2024-07-11 15:56:12,853 [INFO    ] __main__: train step 2897: loss: 0.6300, policy_loss: 1.7171, value_loss: 0.9638
2024-07-11 15:56:13,050 [INFO    ] __main__: train step 2898: loss: 0.6301, policy_loss: 1.7169, value_loss: 0.9637
2024-07-11 15:56:13,252 [INFO    ] __main__: train step 2899: loss: 0.6303, policy_loss: 1.7168, value_loss: 0.9637
2024-07-11 15:56:13,485 [INFO    ] __main__: train step 2900: loss: 0.6304, policy_loss: 1.7167, value_loss: 0.9637
2024-07-11 15:56:13,680 [INFO    ] __main__: train step 2901: loss: 0.6306, policy_loss: 1.7166, value_loss: 0.9636
2024-07-11 15:56:13,876 [INFO    ] __main__: train step 2902: loss: 0.6307, policy_loss: 1.7164, value_loss: 0.9636
2024-07-11 15:56:14,079 [INFO    ] __main__: train step 2903: loss: 0.6309, policy_loss: 1.7163, value_loss: 0.9636
2024-07-11 15:56:14,274 [INFO    ] __main__: train step 2904: loss: 0.6310, policy_loss: 1.7162, value_loss: 0.9635
2024-07-11 15:56:14,480 [INFO    ] __main__: train step 2905: loss: 0.6311, policy_loss: 1.7160, value_loss: 0.9635
2024-07-11 15:56:14,682 [INFO    ] __main__: train step 2906: loss: 0.6313, policy_loss: 1.7159, value_loss: 0.9634
2024-07-11 15:56:16,113 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:56:16,554 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:56:16,619 [INFO    ] __main__: train step 2907: loss: 0.6314, policy_loss: 1.7158, value_loss: 0.9634
2024-07-11 15:56:16,787 [INFO    ] __main__: train step 2908: loss: 0.6316, policy_loss: 1.7156, value_loss: 0.9634
2024-07-11 15:56:16,992 [INFO    ] __main__: train step 2909: loss: 0.6317, policy_loss: 1.7155, value_loss: 0.9633
2024-07-11 15:56:17,189 [INFO    ] __main__: train step 2910: loss: 0.6319, policy_loss: 1.7154, value_loss: 0.9633
2024-07-11 15:56:17,411 [INFO    ] __main__: train step 2911: loss: 0.6320, policy_loss: 1.7153, value_loss: 0.9633
2024-07-11 15:56:17,602 [INFO    ] __main__: train step 2912: loss: 0.6321, policy_loss: 1.7151, value_loss: 0.9632
2024-07-11 15:56:18,076 [INFO    ] __main__: train step 2913: loss: 0.6323, policy_loss: 1.7150, value_loss: 0.9632
2024-07-11 15:56:18,287 [INFO    ] __main__: train step 2914: loss: 0.6324, policy_loss: 1.7149, value_loss: 0.9631
2024-07-11 15:56:18,488 [INFO    ] __main__: train step 2915: loss: 0.6326, policy_loss: 1.7148, value_loss: 0.9631
2024-07-11 15:56:18,703 [INFO    ] __main__: train step 2916: loss: 0.6327, policy_loss: 1.7146, value_loss: 0.9631
2024-07-11 15:56:18,924 [INFO    ] __main__: train step 2917: loss: 0.6329, policy_loss: 1.7145, value_loss: 0.9630
2024-07-11 15:56:19,122 [INFO    ] __main__: train step 2918: loss: 0.6330, policy_loss: 1.7144, value_loss: 0.9630
2024-07-11 15:56:19,349 [INFO    ] __main__: train step 2919: loss: 0.6331, policy_loss: 1.7142, value_loss: 0.9630
2024-07-11 15:56:19,567 [INFO    ] __main__: train step 2920: loss: 0.6333, policy_loss: 1.7141, value_loss: 0.9629
2024-07-11 15:56:19,804 [INFO    ] __main__: train step 2921: loss: 0.6334, policy_loss: 1.7140, value_loss: 0.9629
2024-07-11 15:56:20,017 [INFO    ] __main__: train step 2922: loss: 0.6335, policy_loss: 1.7138, value_loss: 0.9629
2024-07-11 15:56:20,215 [INFO    ] __main__: train step 2923: loss: 0.6337, policy_loss: 1.7137, value_loss: 0.9628
2024-07-11 15:56:21,673 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:56:22,085 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:56:22,139 [INFO    ] __main__: train step 2924: loss: 0.6338, policy_loss: 1.7136, value_loss: 0.9628
2024-07-11 15:56:22,329 [INFO    ] __main__: train step 2925: loss: 0.6340, policy_loss: 1.7135, value_loss: 0.9628
2024-07-11 15:56:22,557 [INFO    ] __main__: train step 2926: loss: 0.6341, policy_loss: 1.7133, value_loss: 0.9628
2024-07-11 15:56:22,757 [INFO    ] __main__: train step 2927: loss: 0.6343, policy_loss: 1.7132, value_loss: 0.9627
2024-07-11 15:56:22,978 [INFO    ] __main__: train step 2928: loss: 0.6344, policy_loss: 1.7131, value_loss: 0.9627
2024-07-11 15:56:23,211 [INFO    ] __main__: train step 2929: loss: 0.6345, policy_loss: 1.7129, value_loss: 0.9627
2024-07-11 15:56:23,430 [INFO    ] __main__: train step 2930: loss: 0.6347, policy_loss: 1.7128, value_loss: 0.9626
2024-07-11 15:56:23,625 [INFO    ] __main__: train step 2931: loss: 0.6348, policy_loss: 1.7127, value_loss: 0.9626
2024-07-11 15:56:23,821 [INFO    ] __main__: train step 2932: loss: 0.6350, policy_loss: 1.7125, value_loss: 0.9626
2024-07-11 15:56:24,029 [INFO    ] __main__: train step 2933: loss: 0.6351, policy_loss: 1.7124, value_loss: 0.9625
2024-07-11 15:56:24,227 [INFO    ] __main__: train step 2934: loss: 0.6352, policy_loss: 1.7123, value_loss: 0.9625
2024-07-11 15:56:24,459 [INFO    ] __main__: train step 2935: loss: 0.6354, policy_loss: 1.7121, value_loss: 0.9625
2024-07-11 15:56:24,655 [INFO    ] __main__: train step 2936: loss: 0.6355, policy_loss: 1.7120, value_loss: 0.9624
2024-07-11 15:56:25,124 [INFO    ] __main__: train step 2937: loss: 0.6357, policy_loss: 1.7119, value_loss: 0.9624
2024-07-11 15:56:25,333 [INFO    ] __main__: train step 2938: loss: 0.6358, policy_loss: 1.7118, value_loss: 0.9624
2024-07-11 15:56:25,529 [INFO    ] __main__: train step 2939: loss: 0.6359, policy_loss: 1.7116, value_loss: 0.9624
2024-07-11 15:56:25,737 [INFO    ] __main__: train step 2940: loss: 0.6361, policy_loss: 1.7115, value_loss: 0.9623
2024-07-11 15:56:27,191 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:56:27,645 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:56:27,705 [INFO    ] __main__: train step 2941: loss: 0.6362, policy_loss: 1.7114, value_loss: 0.9623
2024-07-11 15:56:27,873 [INFO    ] __main__: train step 2942: loss: 0.6364, policy_loss: 1.7112, value_loss: 0.9623
2024-07-11 15:56:28,084 [INFO    ] __main__: train step 2943: loss: 0.6365, policy_loss: 1.7111, value_loss: 0.9622
2024-07-11 15:56:28,284 [INFO    ] __main__: train step 2944: loss: 0.6367, policy_loss: 1.7110, value_loss: 0.9622
2024-07-11 15:56:28,475 [INFO    ] __main__: train step 2945: loss: 0.6368, policy_loss: 1.7108, value_loss: 0.9622
2024-07-11 15:56:28,687 [INFO    ] __main__: train step 2946: loss: 0.6369, policy_loss: 1.7107, value_loss: 0.9622
2024-07-11 15:56:28,898 [INFO    ] __main__: train step 2947: loss: 0.6371, policy_loss: 1.7106, value_loss: 0.9621
2024-07-11 15:56:29,112 [INFO    ] __main__: train step 2948: loss: 0.6372, policy_loss: 1.7104, value_loss: 0.9621
2024-07-11 15:56:29,328 [INFO    ] __main__: train step 2949: loss: 0.6373, policy_loss: 1.7103, value_loss: 0.9620
2024-07-11 15:56:29,573 [INFO    ] __main__: train step 2950: loss: 0.6375, policy_loss: 1.7102, value_loss: 0.9620
2024-07-11 15:56:29,807 [INFO    ] __main__: train step 2951: loss: 0.6376, policy_loss: 1.7101, value_loss: 0.9620
2024-07-11 15:56:30,008 [INFO    ] __main__: train step 2952: loss: 0.6378, policy_loss: 1.7099, value_loss: 0.9619
2024-07-11 15:56:30,212 [INFO    ] __main__: train step 2953: loss: 0.6379, policy_loss: 1.7098, value_loss: 0.9619
2024-07-11 15:56:30,427 [INFO    ] __main__: train step 2954: loss: 0.6381, policy_loss: 1.7097, value_loss: 0.9619
2024-07-11 15:56:30,659 [INFO    ] __main__: train step 2955: loss: 0.6382, policy_loss: 1.7095, value_loss: 0.9618
2024-07-11 15:56:30,862 [INFO    ] __main__: train step 2956: loss: 0.6383, policy_loss: 1.7094, value_loss: 0.9618
2024-07-11 15:56:31,067 [INFO    ] __main__: train step 2957: loss: 0.6385, policy_loss: 1.7093, value_loss: 0.9618
2024-07-11 15:56:32,556 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:56:32,996 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:56:33,062 [INFO    ] __main__: train step 2958: loss: 0.6386, policy_loss: 1.7091, value_loss: 0.9617
2024-07-11 15:56:33,231 [INFO    ] __main__: train step 2959: loss: 0.6388, policy_loss: 1.7090, value_loss: 0.9617
2024-07-11 15:56:33,711 [INFO    ] __main__: train step 2960: loss: 0.6389, policy_loss: 1.7089, value_loss: 0.9617
2024-07-11 15:56:33,910 [INFO    ] __main__: train step 2961: loss: 0.6390, policy_loss: 1.7087, value_loss: 0.9616
2024-07-11 15:56:34,115 [INFO    ] __main__: train step 2962: loss: 0.6392, policy_loss: 1.7086, value_loss: 0.9616
2024-07-11 15:56:34,315 [INFO    ] __main__: train step 2963: loss: 0.6393, policy_loss: 1.7085, value_loss: 0.9616
2024-07-11 15:56:34,535 [INFO    ] __main__: train step 2964: loss: 0.6395, policy_loss: 1.7084, value_loss: 0.9615
2024-07-11 15:56:34,729 [INFO    ] __main__: train step 2965: loss: 0.6396, policy_loss: 1.7082, value_loss: 0.9615
2024-07-11 15:56:34,960 [INFO    ] __main__: train step 2966: loss: 0.6397, policy_loss: 1.7081, value_loss: 0.9615
2024-07-11 15:56:35,156 [INFO    ] __main__: train step 2967: loss: 0.6399, policy_loss: 1.7080, value_loss: 0.9614
2024-07-11 15:56:35,367 [INFO    ] __main__: train step 2968: loss: 0.6400, policy_loss: 1.7078, value_loss: 0.9614
2024-07-11 15:56:35,562 [INFO    ] __main__: train step 2969: loss: 0.6402, policy_loss: 1.7077, value_loss: 0.9614
2024-07-11 15:56:35,765 [INFO    ] __main__: train step 2970: loss: 0.6403, policy_loss: 1.7076, value_loss: 0.9613
2024-07-11 15:56:35,964 [INFO    ] __main__: train step 2971: loss: 0.6404, policy_loss: 1.7075, value_loss: 0.9613
2024-07-11 15:56:36,165 [INFO    ] __main__: train step 2972: loss: 0.6406, policy_loss: 1.7073, value_loss: 0.9613
2024-07-11 15:56:36,374 [INFO    ] __main__: train step 2973: loss: 0.6407, policy_loss: 1.7072, value_loss: 0.9612
2024-07-11 15:56:36,582 [INFO    ] __main__: train step 2974: loss: 0.6409, policy_loss: 1.7071, value_loss: 0.9612
2024-07-11 15:56:38,026 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:56:38,471 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:56:38,532 [INFO    ] __main__: train step 2975: loss: 0.6410, policy_loss: 1.7069, value_loss: 0.9611
2024-07-11 15:56:38,697 [INFO    ] __main__: train step 2976: loss: 0.6411, policy_loss: 1.7068, value_loss: 0.9611
2024-07-11 15:56:38,906 [INFO    ] __main__: train step 2977: loss: 0.6413, policy_loss: 1.7067, value_loss: 0.9611
2024-07-11 15:56:39,107 [INFO    ] __main__: train step 2978: loss: 0.6414, policy_loss: 1.7065, value_loss: 0.9610
2024-07-11 15:56:39,308 [INFO    ] __main__: train step 2979: loss: 0.6415, policy_loss: 1.7064, value_loss: 0.9610
2024-07-11 15:56:39,517 [INFO    ] __main__: train step 2980: loss: 0.6417, policy_loss: 1.7063, value_loss: 0.9610
2024-07-11 15:56:39,730 [INFO    ] __main__: train step 2981: loss: 0.6418, policy_loss: 1.7062, value_loss: 0.9609
2024-07-11 15:56:39,935 [INFO    ] __main__: train step 2982: loss: 0.6420, policy_loss: 1.7060, value_loss: 0.9609
2024-07-11 15:56:40,143 [INFO    ] __main__: train step 2983: loss: 0.6421, policy_loss: 1.7059, value_loss: 0.9609
2024-07-11 15:56:40,648 [INFO    ] __main__: train step 2984: loss: 0.6423, policy_loss: 1.7058, value_loss: 0.9608
2024-07-11 15:56:40,851 [INFO    ] __main__: train step 2985: loss: 0.6424, policy_loss: 1.7056, value_loss: 0.9608
2024-07-11 15:56:41,057 [INFO    ] __main__: train step 2986: loss: 0.6425, policy_loss: 1.7055, value_loss: 0.9608
2024-07-11 15:56:41,270 [INFO    ] __main__: train step 2987: loss: 0.6427, policy_loss: 1.7054, value_loss: 0.9607
2024-07-11 15:56:41,470 [INFO    ] __main__: train step 2988: loss: 0.6428, policy_loss: 1.7053, value_loss: 0.9607
2024-07-11 15:56:41,668 [INFO    ] __main__: train step 2989: loss: 0.6430, policy_loss: 1.7051, value_loss: 0.9607
2024-07-11 15:56:41,874 [INFO    ] __main__: train step 2990: loss: 0.6431, policy_loss: 1.7050, value_loss: 0.9606
2024-07-11 15:56:42,081 [INFO    ] __main__: train step 2991: loss: 0.6433, policy_loss: 1.7049, value_loss: 0.9606
2024-07-11 15:56:43,540 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:56:43,984 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:56:44,044 [INFO    ] __main__: train step 2992: loss: 0.6434, policy_loss: 1.7048, value_loss: 0.9606
2024-07-11 15:56:44,209 [INFO    ] __main__: train step 2993: loss: 0.6436, policy_loss: 1.7046, value_loss: 0.9605
2024-07-11 15:56:44,441 [INFO    ] __main__: train step 2994: loss: 0.6437, policy_loss: 1.7045, value_loss: 0.9605
2024-07-11 15:56:44,677 [INFO    ] __main__: train step 2995: loss: 0.6438, policy_loss: 1.7044, value_loss: 0.9604
2024-07-11 15:56:44,868 [INFO    ] __main__: train step 2996: loss: 0.6440, policy_loss: 1.7043, value_loss: 0.9604
2024-07-11 15:56:45,068 [INFO    ] __main__: train step 2997: loss: 0.6441, policy_loss: 1.7041, value_loss: 0.9604
2024-07-11 15:56:45,281 [INFO    ] __main__: train step 2998: loss: 0.6443, policy_loss: 1.7040, value_loss: 0.9604
2024-07-11 15:56:45,477 [INFO    ] __main__: train step 2999: loss: 0.6444, policy_loss: 1.7039, value_loss: 0.9603
2024-07-11 15:56:45,668 [INFO    ] __main__: train step 3000: loss: 0.6445, policy_loss: 1.7037, value_loss: 0.9603
2024-07-11 15:56:45,795 [INFO    ] __main__: restored step 2000 for evaluation
2024-07-11 15:56:53,581 [INFO    ] __main__: later network ELO difference from earlier network: +186 (+8/-8) ELO from 32000 self-played games
2024-07-11 15:56:53,581 [INFO    ] __main__: game outcomes: W: 22509, D: 141, L: 9350
2024-07-11 15:56:53,583 [INFO    ] __main__: validation_elo_delta: 186, validation_elo: 754
2024-07-11 15:56:54,070 [INFO    ] __main__: train step 3001: loss: 0.6447, policy_loss: 1.7036, value_loss: 0.9602
2024-07-11 15:56:54,273 [INFO    ] __main__: train step 3002: loss: 0.6448, policy_loss: 1.7035, value_loss: 0.9602
2024-07-11 15:56:54,466 [INFO    ] __main__: train step 3003: loss: 0.6450, policy_loss: 1.7034, value_loss: 0.9602
2024-07-11 15:56:54,659 [INFO    ] __main__: train step 3004: loss: 0.6451, policy_loss: 1.7032, value_loss: 0.9602
2024-07-11 15:56:54,855 [INFO    ] __main__: train step 3005: loss: 0.6452, policy_loss: 1.7031, value_loss: 0.9601
2024-07-11 15:56:55,324 [INFO    ] __main__: train step 3006: loss: 0.6454, policy_loss: 1.7030, value_loss: 0.9601
2024-07-11 15:56:55,530 [INFO    ] __main__: train step 3007: loss: 0.6455, policy_loss: 1.7029, value_loss: 0.9601
2024-07-11 15:56:55,723 [INFO    ] __main__: train step 3008: loss: 0.6457, policy_loss: 1.7027, value_loss: 0.9600
2024-07-11 15:56:57,161 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:56:57,616 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:56:57,688 [INFO    ] __main__: train step 3009: loss: 0.6458, policy_loss: 1.7026, value_loss: 0.9600
2024-07-11 15:56:57,860 [INFO    ] __main__: train step 3010: loss: 0.6459, policy_loss: 1.7025, value_loss: 0.9600
2024-07-11 15:56:58,047 [INFO    ] __main__: train step 3011: loss: 0.6461, policy_loss: 1.7024, value_loss: 0.9599
2024-07-11 15:56:58,242 [INFO    ] __main__: train step 3012: loss: 0.6462, policy_loss: 1.7022, value_loss: 0.9599
2024-07-11 15:56:58,444 [INFO    ] __main__: train step 3013: loss: 0.6464, policy_loss: 1.7021, value_loss: 0.9599
2024-07-11 15:56:58,651 [INFO    ] __main__: train step 3014: loss: 0.6465, policy_loss: 1.7020, value_loss: 0.9598
2024-07-11 15:56:58,862 [INFO    ] __main__: train step 3015: loss: 0.6466, policy_loss: 1.7019, value_loss: 0.9598
2024-07-11 15:56:59,061 [INFO    ] __main__: train step 3016: loss: 0.6468, policy_loss: 1.7017, value_loss: 0.9598
2024-07-11 15:56:59,265 [INFO    ] __main__: train step 3017: loss: 0.6469, policy_loss: 1.7016, value_loss: 0.9597
2024-07-11 15:56:59,466 [INFO    ] __main__: train step 3018: loss: 0.6470, policy_loss: 1.7015, value_loss: 0.9597
2024-07-11 15:56:59,673 [INFO    ] __main__: train step 3019: loss: 0.6472, policy_loss: 1.7014, value_loss: 0.9597
2024-07-11 15:56:59,861 [INFO    ] __main__: train step 3020: loss: 0.6473, policy_loss: 1.7012, value_loss: 0.9596
2024-07-11 15:57:00,078 [INFO    ] __main__: train step 3021: loss: 0.6474, policy_loss: 1.7011, value_loss: 0.9596
2024-07-11 15:57:00,264 [INFO    ] __main__: train step 3022: loss: 0.6476, policy_loss: 1.7010, value_loss: 0.9596
2024-07-11 15:57:00,462 [INFO    ] __main__: train step 3023: loss: 0.6477, policy_loss: 1.7008, value_loss: 0.9595
2024-07-11 15:57:00,671 [INFO    ] __main__: train step 3024: loss: 0.6479, policy_loss: 1.7007, value_loss: 0.9595
2024-07-11 15:57:00,873 [INFO    ] __main__: train step 3025: loss: 0.6480, policy_loss: 1.7006, value_loss: 0.9595
2024-07-11 15:57:02,326 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:57:02,760 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:57:02,822 [INFO    ] __main__: train step 3026: loss: 0.6481, policy_loss: 1.7005, value_loss: 0.9594
2024-07-11 15:57:02,978 [INFO    ] __main__: train step 3027: loss: 0.6483, policy_loss: 1.7003, value_loss: 0.9594
2024-07-11 15:57:03,184 [INFO    ] __main__: train step 3028: loss: 0.6484, policy_loss: 1.7002, value_loss: 0.9594
2024-07-11 15:57:03,385 [INFO    ] __main__: train step 3029: loss: 0.6485, policy_loss: 1.7001, value_loss: 0.9593
2024-07-11 15:57:03,859 [INFO    ] __main__: train step 3030: loss: 0.6487, policy_loss: 1.7000, value_loss: 0.9593
2024-07-11 15:57:04,053 [INFO    ] __main__: train step 3031: loss: 0.6488, policy_loss: 1.6998, value_loss: 0.9592
2024-07-11 15:57:04,259 [INFO    ] __main__: train step 3032: loss: 0.6489, policy_loss: 1.6997, value_loss: 0.9592
2024-07-11 15:57:04,454 [INFO    ] __main__: train step 3033: loss: 0.6491, policy_loss: 1.6996, value_loss: 0.9592
2024-07-11 15:57:04,659 [INFO    ] __main__: train step 3034: loss: 0.6492, policy_loss: 1.6994, value_loss: 0.9591
2024-07-11 15:57:04,851 [INFO    ] __main__: train step 3035: loss: 0.6494, policy_loss: 1.6993, value_loss: 0.9591
2024-07-11 15:57:05,066 [INFO    ] __main__: train step 3036: loss: 0.6495, policy_loss: 1.6992, value_loss: 0.9591
2024-07-11 15:57:05,273 [INFO    ] __main__: train step 3037: loss: 0.6496, policy_loss: 1.6991, value_loss: 0.9590
2024-07-11 15:57:05,502 [INFO    ] __main__: train step 3038: loss: 0.6498, policy_loss: 1.6989, value_loss: 0.9590
2024-07-11 15:57:05,701 [INFO    ] __main__: train step 3039: loss: 0.6499, policy_loss: 1.6988, value_loss: 0.9590
2024-07-11 15:57:05,899 [INFO    ] __main__: train step 3040: loss: 0.6500, policy_loss: 1.6987, value_loss: 0.9589
2024-07-11 15:57:06,106 [INFO    ] __main__: train step 3041: loss: 0.6502, policy_loss: 1.6986, value_loss: 0.9589
2024-07-11 15:57:06,302 [INFO    ] __main__: train step 3042: loss: 0.6503, policy_loss: 1.6984, value_loss: 0.9589
2024-07-11 15:57:07,746 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:57:08,181 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:57:08,239 [INFO    ] __main__: train step 3043: loss: 0.6505, policy_loss: 1.6983, value_loss: 0.9588
2024-07-11 15:57:08,416 [INFO    ] __main__: train step 3044: loss: 0.6506, policy_loss: 1.6982, value_loss: 0.9588
2024-07-11 15:57:08,654 [INFO    ] __main__: train step 3045: loss: 0.6507, policy_loss: 1.6980, value_loss: 0.9588
2024-07-11 15:57:08,851 [INFO    ] __main__: train step 3046: loss: 0.6509, policy_loss: 1.6979, value_loss: 0.9587
2024-07-11 15:57:09,084 [INFO    ] __main__: train step 3047: loss: 0.6510, policy_loss: 1.6978, value_loss: 0.9587
2024-07-11 15:57:09,284 [INFO    ] __main__: train step 3048: loss: 0.6511, policy_loss: 1.6977, value_loss: 0.9587
2024-07-11 15:57:09,486 [INFO    ] __main__: train step 3049: loss: 0.6513, policy_loss: 1.6975, value_loss: 0.9586
2024-07-11 15:57:09,714 [INFO    ] __main__: train step 3050: loss: 0.6514, policy_loss: 1.6974, value_loss: 0.9586
2024-07-11 15:57:09,943 [INFO    ] __main__: train step 3051: loss: 0.6516, policy_loss: 1.6973, value_loss: 0.9586
2024-07-11 15:57:10,159 [INFO    ] __main__: train step 3052: loss: 0.6517, policy_loss: 1.6971, value_loss: 0.9585
2024-07-11 15:57:10,668 [INFO    ] __main__: train step 3053: loss: 0.6518, policy_loss: 1.6970, value_loss: 0.9585
2024-07-11 15:57:10,927 [INFO    ] __main__: train step 3054: loss: 0.6520, policy_loss: 1.6969, value_loss: 0.9585
2024-07-11 15:57:11,152 [INFO    ] __main__: train step 3055: loss: 0.6521, policy_loss: 1.6968, value_loss: 0.9584
2024-07-11 15:57:11,427 [INFO    ] __main__: train step 3056: loss: 0.6522, policy_loss: 1.6966, value_loss: 0.9584
2024-07-11 15:57:11,636 [INFO    ] __main__: train step 3057: loss: 0.6524, policy_loss: 1.6965, value_loss: 0.9584
2024-07-11 15:57:11,826 [INFO    ] __main__: train step 3058: loss: 0.6525, policy_loss: 1.6964, value_loss: 0.9583
2024-07-11 15:57:12,025 [INFO    ] __main__: train step 3059: loss: 0.6526, policy_loss: 1.6963, value_loss: 0.9583
2024-07-11 15:57:13,491 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:57:13,934 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:57:13,989 [INFO    ] __main__: train step 3060: loss: 0.6528, policy_loss: 1.6961, value_loss: 0.9583
2024-07-11 15:57:14,155 [INFO    ] __main__: train step 3061: loss: 0.6529, policy_loss: 1.6960, value_loss: 0.9582
2024-07-11 15:57:14,371 [INFO    ] __main__: train step 3062: loss: 0.6531, policy_loss: 1.6959, value_loss: 0.9582
2024-07-11 15:57:14,568 [INFO    ] __main__: train step 3063: loss: 0.6532, policy_loss: 1.6958, value_loss: 0.9582
2024-07-11 15:57:14,778 [INFO    ] __main__: train step 3064: loss: 0.6533, policy_loss: 1.6956, value_loss: 0.9581
2024-07-11 15:57:14,971 [INFO    ] __main__: train step 3065: loss: 0.6535, policy_loss: 1.6955, value_loss: 0.9581
2024-07-11 15:57:15,165 [INFO    ] __main__: train step 3066: loss: 0.6536, policy_loss: 1.6954, value_loss: 0.9580
2024-07-11 15:57:15,367 [INFO    ] __main__: train step 3067: loss: 0.6537, policy_loss: 1.6953, value_loss: 0.9580
2024-07-11 15:57:15,573 [INFO    ] __main__: train step 3068: loss: 0.6539, policy_loss: 1.6951, value_loss: 0.9580
2024-07-11 15:57:15,779 [INFO    ] __main__: train step 3069: loss: 0.6540, policy_loss: 1.6950, value_loss: 0.9579
2024-07-11 15:57:15,975 [INFO    ] __main__: train step 3070: loss: 0.6542, policy_loss: 1.6949, value_loss: 0.9579
2024-07-11 15:57:16,181 [INFO    ] __main__: train step 3071: loss: 0.6543, policy_loss: 1.6948, value_loss: 0.9579
2024-07-11 15:57:16,383 [INFO    ] __main__: train step 3072: loss: 0.6544, policy_loss: 1.6946, value_loss: 0.9578
2024-07-11 15:57:16,605 [INFO    ] __main__: train step 3073: loss: 0.6545, policy_loss: 1.6945, value_loss: 0.9578
2024-07-11 15:57:16,832 [INFO    ] __main__: train step 3074: loss: 0.6547, policy_loss: 1.6944, value_loss: 0.9578
2024-07-11 15:57:17,023 [INFO    ] __main__: train step 3075: loss: 0.6548, policy_loss: 1.6942, value_loss: 0.9577
2024-07-11 15:57:17,224 [INFO    ] __main__: train step 3076: loss: 0.6550, policy_loss: 1.6941, value_loss: 0.9577
2024-07-11 15:57:18,955 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:57:19,401 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:57:19,467 [INFO    ] __main__: train step 3077: loss: 0.6551, policy_loss: 1.6940, value_loss: 0.9577
2024-07-11 15:57:19,639 [INFO    ] __main__: train step 3078: loss: 0.6552, policy_loss: 1.6939, value_loss: 0.9576
2024-07-11 15:57:19,842 [INFO    ] __main__: train step 3079: loss: 0.6554, policy_loss: 1.6937, value_loss: 0.9576
2024-07-11 15:57:20,037 [INFO    ] __main__: train step 3080: loss: 0.6555, policy_loss: 1.6936, value_loss: 0.9576
2024-07-11 15:57:20,240 [INFO    ] __main__: train step 3081: loss: 0.6557, policy_loss: 1.6935, value_loss: 0.9575
2024-07-11 15:57:20,453 [INFO    ] __main__: train step 3082: loss: 0.6558, policy_loss: 1.6934, value_loss: 0.9575
2024-07-11 15:57:20,660 [INFO    ] __main__: train step 3083: loss: 0.6559, policy_loss: 1.6932, value_loss: 0.9574
2024-07-11 15:57:20,857 [INFO    ] __main__: train step 3084: loss: 0.6561, policy_loss: 1.6931, value_loss: 0.9574
2024-07-11 15:57:21,057 [INFO    ] __main__: train step 3085: loss: 0.6562, policy_loss: 1.6930, value_loss: 0.9574
2024-07-11 15:57:21,257 [INFO    ] __main__: train step 3086: loss: 0.6564, policy_loss: 1.6929, value_loss: 0.9573
2024-07-11 15:57:21,462 [INFO    ] __main__: train step 3087: loss: 0.6565, policy_loss: 1.6927, value_loss: 0.9573
2024-07-11 15:57:21,657 [INFO    ] __main__: train step 3088: loss: 0.6566, policy_loss: 1.6926, value_loss: 0.9573
2024-07-11 15:57:21,855 [INFO    ] __main__: train step 3089: loss: 0.6568, policy_loss: 1.6925, value_loss: 0.9572
2024-07-11 15:57:22,054 [INFO    ] __main__: train step 3090: loss: 0.6569, policy_loss: 1.6924, value_loss: 0.9572
2024-07-11 15:57:22,272 [INFO    ] __main__: train step 3091: loss: 0.6571, policy_loss: 1.6922, value_loss: 0.9572
2024-07-11 15:57:22,496 [INFO    ] __main__: train step 3092: loss: 0.6572, policy_loss: 1.6921, value_loss: 0.9571
2024-07-11 15:57:22,693 [INFO    ] __main__: train step 3093: loss: 0.6573, policy_loss: 1.6920, value_loss: 0.9571
2024-07-11 15:57:24,137 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:57:24,569 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:57:24,623 [INFO    ] __main__: train step 3094: loss: 0.6575, policy_loss: 1.6919, value_loss: 0.9571
2024-07-11 15:57:24,792 [INFO    ] __main__: train step 3095: loss: 0.6576, policy_loss: 1.6917, value_loss: 0.9570
2024-07-11 15:57:25,007 [INFO    ] __main__: train step 3096: loss: 0.6577, policy_loss: 1.6916, value_loss: 0.9570
2024-07-11 15:57:25,226 [INFO    ] __main__: train step 3097: loss: 0.6579, policy_loss: 1.6915, value_loss: 0.9570
2024-07-11 15:57:25,418 [INFO    ] __main__: train step 3098: loss: 0.6580, policy_loss: 1.6913, value_loss: 0.9569
2024-07-11 15:57:25,909 [INFO    ] __main__: train step 3099: loss: 0.6581, policy_loss: 1.6912, value_loss: 0.9569
2024-07-11 15:57:26,115 [INFO    ] __main__: train step 3100: loss: 0.6583, policy_loss: 1.6911, value_loss: 0.9569
2024-07-11 15:57:26,326 [INFO    ] __main__: train step 3101: loss: 0.6584, policy_loss: 1.6910, value_loss: 0.9568
2024-07-11 15:57:26,559 [INFO    ] __main__: train step 3102: loss: 0.6586, policy_loss: 1.6908, value_loss: 0.9568
2024-07-11 15:57:26,768 [INFO    ] __main__: train step 3103: loss: 0.6587, policy_loss: 1.6907, value_loss: 0.9568
2024-07-11 15:57:26,964 [INFO    ] __main__: train step 3104: loss: 0.6588, policy_loss: 1.6906, value_loss: 0.9567
2024-07-11 15:57:27,166 [INFO    ] __main__: train step 3105: loss: 0.6590, policy_loss: 1.6905, value_loss: 0.9567
2024-07-11 15:57:27,390 [INFO    ] __main__: train step 3106: loss: 0.6591, policy_loss: 1.6903, value_loss: 0.9567
2024-07-11 15:57:27,582 [INFO    ] __main__: train step 3107: loss: 0.6592, policy_loss: 1.6902, value_loss: 0.9566
2024-07-11 15:57:27,798 [INFO    ] __main__: train step 3108: loss: 0.6594, policy_loss: 1.6901, value_loss: 0.9566
2024-07-11 15:57:27,999 [INFO    ] __main__: train step 3109: loss: 0.6595, policy_loss: 1.6900, value_loss: 0.9566
2024-07-11 15:57:28,204 [INFO    ] __main__: train step 3110: loss: 0.6596, policy_loss: 1.6898, value_loss: 0.9565
2024-07-11 15:57:29,638 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:57:30,082 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:57:30,146 [INFO    ] __main__: train step 3111: loss: 0.6598, policy_loss: 1.6897, value_loss: 0.9565
2024-07-11 15:57:30,313 [INFO    ] __main__: train step 3112: loss: 0.6599, policy_loss: 1.6896, value_loss: 0.9565
2024-07-11 15:57:30,517 [INFO    ] __main__: train step 3113: loss: 0.6601, policy_loss: 1.6895, value_loss: 0.9564
2024-07-11 15:57:30,719 [INFO    ] __main__: train step 3114: loss: 0.6602, policy_loss: 1.6893, value_loss: 0.9564
2024-07-11 15:57:30,946 [INFO    ] __main__: train step 3115: loss: 0.6603, policy_loss: 1.6892, value_loss: 0.9564
2024-07-11 15:57:31,141 [INFO    ] __main__: train step 3116: loss: 0.6605, policy_loss: 1.6891, value_loss: 0.9563
2024-07-11 15:57:31,343 [INFO    ] __main__: train step 3117: loss: 0.6606, policy_loss: 1.6890, value_loss: 0.9563
2024-07-11 15:57:31,545 [INFO    ] __main__: train step 3118: loss: 0.6608, policy_loss: 1.6888, value_loss: 0.9563
2024-07-11 15:57:31,760 [INFO    ] __main__: train step 3119: loss: 0.6609, policy_loss: 1.6887, value_loss: 0.9562
2024-07-11 15:57:31,998 [INFO    ] __main__: train step 3120: loss: 0.6610, policy_loss: 1.6886, value_loss: 0.9562
2024-07-11 15:57:32,192 [INFO    ] __main__: train step 3121: loss: 0.6612, policy_loss: 1.6885, value_loss: 0.9562
2024-07-11 15:57:32,677 [INFO    ] __main__: train step 3122: loss: 0.6613, policy_loss: 1.6884, value_loss: 0.9561
2024-07-11 15:57:32,907 [INFO    ] __main__: train step 3123: loss: 0.6614, policy_loss: 1.6882, value_loss: 0.9561
2024-07-11 15:57:33,139 [INFO    ] __main__: train step 3124: loss: 0.6616, policy_loss: 1.6881, value_loss: 0.9560
2024-07-11 15:57:33,345 [INFO    ] __main__: train step 3125: loss: 0.6617, policy_loss: 1.6880, value_loss: 0.9560
2024-07-11 15:57:33,533 [INFO    ] __main__: train step 3126: loss: 0.6619, policy_loss: 1.6879, value_loss: 0.9560
2024-07-11 15:57:33,743 [INFO    ] __main__: train step 3127: loss: 0.6620, policy_loss: 1.6877, value_loss: 0.9560
2024-07-11 15:57:35,190 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:57:35,659 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:57:35,722 [INFO    ] __main__: train step 3128: loss: 0.6621, policy_loss: 1.6876, value_loss: 0.9559
2024-07-11 15:57:35,913 [INFO    ] __main__: train step 3129: loss: 0.6623, policy_loss: 1.6875, value_loss: 0.9559
2024-07-11 15:57:36,111 [INFO    ] __main__: train step 3130: loss: 0.6624, policy_loss: 1.6874, value_loss: 0.9559
2024-07-11 15:57:36,330 [INFO    ] __main__: train step 3131: loss: 0.6626, policy_loss: 1.6873, value_loss: 0.9558
2024-07-11 15:57:36,572 [INFO    ] __main__: train step 3132: loss: 0.6627, policy_loss: 1.6871, value_loss: 0.9558
2024-07-11 15:57:36,774 [INFO    ] __main__: train step 3133: loss: 0.6628, policy_loss: 1.6870, value_loss: 0.9558
2024-07-11 15:57:36,965 [INFO    ] __main__: train step 3134: loss: 0.6630, policy_loss: 1.6869, value_loss: 0.9557
2024-07-11 15:57:37,230 [INFO    ] __main__: train step 3135: loss: 0.6631, policy_loss: 1.6868, value_loss: 0.9557
2024-07-11 15:57:37,437 [INFO    ] __main__: train step 3136: loss: 0.6632, policy_loss: 1.6866, value_loss: 0.9557
2024-07-11 15:57:37,644 [INFO    ] __main__: train step 3137: loss: 0.6634, policy_loss: 1.6865, value_loss: 0.9556
2024-07-11 15:57:37,865 [INFO    ] __main__: train step 3138: loss: 0.6635, policy_loss: 1.6864, value_loss: 0.9556
2024-07-11 15:57:38,102 [INFO    ] __main__: train step 3139: loss: 0.6636, policy_loss: 1.6863, value_loss: 0.9556
2024-07-11 15:57:38,309 [INFO    ] __main__: train step 3140: loss: 0.6638, policy_loss: 1.6861, value_loss: 0.9555
2024-07-11 15:57:38,531 [INFO    ] __main__: train step 3141: loss: 0.6639, policy_loss: 1.6860, value_loss: 0.9555
2024-07-11 15:57:38,734 [INFO    ] __main__: train step 3142: loss: 0.6641, policy_loss: 1.6859, value_loss: 0.9555
2024-07-11 15:57:38,931 [INFO    ] __main__: train step 3143: loss: 0.6642, policy_loss: 1.6858, value_loss: 0.9554
2024-07-11 15:57:39,125 [INFO    ] __main__: train step 3144: loss: 0.6643, policy_loss: 1.6856, value_loss: 0.9554
2024-07-11 15:57:40,840 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:57:41,286 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:57:41,349 [INFO    ] __main__: train step 3145: loss: 0.6645, policy_loss: 1.6855, value_loss: 0.9554
2024-07-11 15:57:41,528 [INFO    ] __main__: train step 3146: loss: 0.6646, policy_loss: 1.6854, value_loss: 0.9553
2024-07-11 15:57:41,738 [INFO    ] __main__: train step 3147: loss: 0.6647, policy_loss: 1.6853, value_loss: 0.9553
2024-07-11 15:57:41,926 [INFO    ] __main__: train step 3148: loss: 0.6649, policy_loss: 1.6852, value_loss: 0.9553
2024-07-11 15:57:42,123 [INFO    ] __main__: train step 3149: loss: 0.6650, policy_loss: 1.6850, value_loss: 0.9553
2024-07-11 15:57:42,335 [INFO    ] __main__: train step 3150: loss: 0.6651, policy_loss: 1.6849, value_loss: 0.9552
2024-07-11 15:57:42,528 [INFO    ] __main__: train step 3151: loss: 0.6653, policy_loss: 1.6848, value_loss: 0.9552
2024-07-11 15:57:42,740 [INFO    ] __main__: train step 3152: loss: 0.6654, policy_loss: 1.6847, value_loss: 0.9552
2024-07-11 15:57:42,934 [INFO    ] __main__: train step 3153: loss: 0.6655, policy_loss: 1.6845, value_loss: 0.9551
2024-07-11 15:57:43,131 [INFO    ] __main__: train step 3154: loss: 0.6657, policy_loss: 1.6844, value_loss: 0.9551
2024-07-11 15:57:43,331 [INFO    ] __main__: train step 3155: loss: 0.6658, policy_loss: 1.6843, value_loss: 0.9551
2024-07-11 15:57:43,555 [INFO    ] __main__: train step 3156: loss: 0.6659, policy_loss: 1.6842, value_loss: 0.9550
2024-07-11 15:57:43,787 [INFO    ] __main__: train step 3157: loss: 0.6661, policy_loss: 1.6840, value_loss: 0.9550
2024-07-11 15:57:43,990 [INFO    ] __main__: train step 3158: loss: 0.6662, policy_loss: 1.6839, value_loss: 0.9550
2024-07-11 15:57:44,188 [INFO    ] __main__: train step 3159: loss: 0.6663, policy_loss: 1.6838, value_loss: 0.9550
2024-07-11 15:57:44,399 [INFO    ] __main__: train step 3160: loss: 0.6665, policy_loss: 1.6837, value_loss: 0.9549
2024-07-11 15:57:44,599 [INFO    ] __main__: train step 3161: loss: 0.6666, policy_loss: 1.6835, value_loss: 0.9549
2024-07-11 15:57:46,033 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:57:46,478 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:57:46,535 [INFO    ] __main__: train step 3162: loss: 0.6667, policy_loss: 1.6834, value_loss: 0.9549
2024-07-11 15:57:46,709 [INFO    ] __main__: train step 3163: loss: 0.6669, policy_loss: 1.6833, value_loss: 0.9548
2024-07-11 15:57:46,921 [INFO    ] __main__: train step 3164: loss: 0.6670, policy_loss: 1.6831, value_loss: 0.9548
2024-07-11 15:57:47,127 [INFO    ] __main__: train step 3165: loss: 0.6671, policy_loss: 1.6830, value_loss: 0.9548
2024-07-11 15:57:47,346 [INFO    ] __main__: train step 3166: loss: 0.6673, policy_loss: 1.6829, value_loss: 0.9547
2024-07-11 15:57:47,554 [INFO    ] __main__: train step 3167: loss: 0.6674, policy_loss: 1.6828, value_loss: 0.9547
2024-07-11 15:57:47,759 [INFO    ] __main__: train step 3168: loss: 0.6675, policy_loss: 1.6826, value_loss: 0.9547
2024-07-11 15:57:47,969 [INFO    ] __main__: train step 3169: loss: 0.6677, policy_loss: 1.6825, value_loss: 0.9546
2024-07-11 15:57:48,423 [INFO    ] __main__: train step 3170: loss: 0.6678, policy_loss: 1.6824, value_loss: 0.9546
2024-07-11 15:57:48,674 [INFO    ] __main__: train step 3171: loss: 0.6679, policy_loss: 1.6823, value_loss: 0.9546
2024-07-11 15:57:48,914 [INFO    ] __main__: train step 3172: loss: 0.6681, policy_loss: 1.6821, value_loss: 0.9545
2024-07-11 15:57:49,133 [INFO    ] __main__: train step 3173: loss: 0.6682, policy_loss: 1.6820, value_loss: 0.9545
2024-07-11 15:57:49,380 [INFO    ] __main__: train step 3174: loss: 0.6683, policy_loss: 1.6819, value_loss: 0.9545
2024-07-11 15:57:49,582 [INFO    ] __main__: train step 3175: loss: 0.6685, policy_loss: 1.6818, value_loss: 0.9544
2024-07-11 15:57:49,806 [INFO    ] __main__: train step 3176: loss: 0.6686, policy_loss: 1.6817, value_loss: 0.9544
2024-07-11 15:57:50,030 [INFO    ] __main__: train step 3177: loss: 0.6687, policy_loss: 1.6815, value_loss: 0.9544
2024-07-11 15:57:50,271 [INFO    ] __main__: train step 3178: loss: 0.6689, policy_loss: 1.6814, value_loss: 0.9543
2024-07-11 15:57:51,764 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:57:52,231 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:57:52,290 [INFO    ] __main__: train step 3179: loss: 0.6690, policy_loss: 1.6813, value_loss: 0.9543
2024-07-11 15:57:52,462 [INFO    ] __main__: train step 3180: loss: 0.6691, policy_loss: 1.6812, value_loss: 0.9543
2024-07-11 15:57:52,671 [INFO    ] __main__: train step 3181: loss: 0.6693, policy_loss: 1.6810, value_loss: 0.9542
2024-07-11 15:57:52,866 [INFO    ] __main__: train step 3182: loss: 0.6694, policy_loss: 1.6809, value_loss: 0.9542
2024-07-11 15:57:53,071 [INFO    ] __main__: train step 3183: loss: 0.6695, policy_loss: 1.6808, value_loss: 0.9542
2024-07-11 15:57:53,274 [INFO    ] __main__: train step 3184: loss: 0.6697, policy_loss: 1.6807, value_loss: 0.9541
2024-07-11 15:57:53,479 [INFO    ] __main__: train step 3185: loss: 0.6698, policy_loss: 1.6805, value_loss: 0.9541
2024-07-11 15:57:53,678 [INFO    ] __main__: train step 3186: loss: 0.6699, policy_loss: 1.6804, value_loss: 0.9541
2024-07-11 15:57:53,898 [INFO    ] __main__: train step 3187: loss: 0.6701, policy_loss: 1.6803, value_loss: 0.9540
2024-07-11 15:57:54,106 [INFO    ] __main__: train step 3188: loss: 0.6702, policy_loss: 1.6802, value_loss: 0.9540
2024-07-11 15:57:54,305 [INFO    ] __main__: train step 3189: loss: 0.6703, policy_loss: 1.6800, value_loss: 0.9540
2024-07-11 15:57:54,503 [INFO    ] __main__: train step 3190: loss: 0.6705, policy_loss: 1.6799, value_loss: 0.9539
2024-07-11 15:57:54,703 [INFO    ] __main__: train step 3191: loss: 0.6706, policy_loss: 1.6798, value_loss: 0.9539
2024-07-11 15:57:54,909 [INFO    ] __main__: train step 3192: loss: 0.6707, policy_loss: 1.6797, value_loss: 0.9539
2024-07-11 15:57:55,389 [INFO    ] __main__: train step 3193: loss: 0.6709, policy_loss: 1.6795, value_loss: 0.9538
2024-07-11 15:57:55,606 [INFO    ] __main__: train step 3194: loss: 0.6710, policy_loss: 1.6794, value_loss: 0.9538
2024-07-11 15:57:55,797 [INFO    ] __main__: train step 3195: loss: 0.6711, policy_loss: 1.6793, value_loss: 0.9538
2024-07-11 15:57:57,224 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:57:57,647 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:57:57,702 [INFO    ] __main__: train step 3196: loss: 0.6713, policy_loss: 1.6792, value_loss: 0.9537
2024-07-11 15:57:57,882 [INFO    ] __main__: train step 3197: loss: 0.6714, policy_loss: 1.6791, value_loss: 0.9537
2024-07-11 15:57:58,089 [INFO    ] __main__: train step 3198: loss: 0.6715, policy_loss: 1.6789, value_loss: 0.9537
2024-07-11 15:57:58,290 [INFO    ] __main__: train step 3199: loss: 0.6717, policy_loss: 1.6788, value_loss: 0.9536
2024-07-11 15:57:58,493 [INFO    ] __main__: train step 3200: loss: 0.6718, policy_loss: 1.6787, value_loss: 0.9536
2024-07-11 15:57:58,712 [INFO    ] __main__: train step 3201: loss: 0.6720, policy_loss: 1.6786, value_loss: 0.9536
2024-07-11 15:57:58,929 [INFO    ] __main__: train step 3202: loss: 0.6721, policy_loss: 1.6785, value_loss: 0.9536
2024-07-11 15:57:59,140 [INFO    ] __main__: train step 3203: loss: 0.6722, policy_loss: 1.6783, value_loss: 0.9535
2024-07-11 15:57:59,343 [INFO    ] __main__: train step 3204: loss: 0.6724, policy_loss: 1.6782, value_loss: 0.9535
2024-07-11 15:57:59,554 [INFO    ] __main__: train step 3205: loss: 0.6725, policy_loss: 1.6781, value_loss: 0.9535
2024-07-11 15:57:59,781 [INFO    ] __main__: train step 3206: loss: 0.6726, policy_loss: 1.6780, value_loss: 0.9534
2024-07-11 15:57:59,976 [INFO    ] __main__: train step 3207: loss: 0.6728, policy_loss: 1.6779, value_loss: 0.9534
2024-07-11 15:58:00,173 [INFO    ] __main__: train step 3208: loss: 0.6729, policy_loss: 1.6777, value_loss: 0.9534
2024-07-11 15:58:00,381 [INFO    ] __main__: train step 3209: loss: 0.6730, policy_loss: 1.6776, value_loss: 0.9533
2024-07-11 15:58:00,592 [INFO    ] __main__: train step 3210: loss: 0.6732, policy_loss: 1.6775, value_loss: 0.9533
2024-07-11 15:58:00,795 [INFO    ] __main__: train step 3211: loss: 0.6733, policy_loss: 1.6774, value_loss: 0.9533
2024-07-11 15:58:00,988 [INFO    ] __main__: train step 3212: loss: 0.6735, policy_loss: 1.6773, value_loss: 0.9532
2024-07-11 15:58:02,425 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:58:02,856 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:58:02,912 [INFO    ] __main__: train step 3213: loss: 0.6736, policy_loss: 1.6771, value_loss: 0.9532
2024-07-11 15:58:03,085 [INFO    ] __main__: train step 3214: loss: 0.6737, policy_loss: 1.6770, value_loss: 0.9532
2024-07-11 15:58:03,288 [INFO    ] __main__: train step 3215: loss: 0.6739, policy_loss: 1.6769, value_loss: 0.9531
2024-07-11 15:58:03,782 [INFO    ] __main__: train step 3216: loss: 0.6740, policy_loss: 1.6768, value_loss: 0.9531
2024-07-11 15:58:03,987 [INFO    ] __main__: train step 3217: loss: 0.6741, policy_loss: 1.6766, value_loss: 0.9531
2024-07-11 15:58:04,198 [INFO    ] __main__: train step 3218: loss: 0.6743, policy_loss: 1.6765, value_loss: 0.9530
2024-07-11 15:58:04,399 [INFO    ] __main__: train step 3219: loss: 0.6744, policy_loss: 1.6764, value_loss: 0.9530
2024-07-11 15:58:04,609 [INFO    ] __main__: train step 3220: loss: 0.6745, policy_loss: 1.6763, value_loss: 0.9530
2024-07-11 15:58:04,816 [INFO    ] __main__: train step 3221: loss: 0.6747, policy_loss: 1.6761, value_loss: 0.9529
2024-07-11 15:58:05,027 [INFO    ] __main__: train step 3222: loss: 0.6748, policy_loss: 1.6760, value_loss: 0.9529
2024-07-11 15:58:05,235 [INFO    ] __main__: train step 3223: loss: 0.6749, policy_loss: 1.6759, value_loss: 0.9528
2024-07-11 15:58:05,450 [INFO    ] __main__: train step 3224: loss: 0.6751, policy_loss: 1.6758, value_loss: 0.9528
2024-07-11 15:58:05,681 [INFO    ] __main__: train step 3225: loss: 0.6752, policy_loss: 1.6757, value_loss: 0.9528
2024-07-11 15:58:05,884 [INFO    ] __main__: train step 3226: loss: 0.6753, policy_loss: 1.6755, value_loss: 0.9527
2024-07-11 15:58:06,079 [INFO    ] __main__: train step 3227: loss: 0.6754, policy_loss: 1.6754, value_loss: 0.9527
2024-07-11 15:58:06,280 [INFO    ] __main__: train step 3228: loss: 0.6756, policy_loss: 1.6753, value_loss: 0.9527
2024-07-11 15:58:06,485 [INFO    ] __main__: train step 3229: loss: 0.6757, policy_loss: 1.6752, value_loss: 0.9526
2024-07-11 15:58:07,927 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:58:08,367 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:58:08,425 [INFO    ] __main__: train step 3230: loss: 0.6758, policy_loss: 1.6750, value_loss: 0.9526
2024-07-11 15:58:08,592 [INFO    ] __main__: train step 3231: loss: 0.6760, policy_loss: 1.6749, value_loss: 0.9526
2024-07-11 15:58:08,801 [INFO    ] __main__: train step 3232: loss: 0.6761, policy_loss: 1.6748, value_loss: 0.9525
2024-07-11 15:58:09,017 [INFO    ] __main__: train step 3233: loss: 0.6762, policy_loss: 1.6747, value_loss: 0.9525
2024-07-11 15:58:09,213 [INFO    ] __main__: train step 3234: loss: 0.6764, policy_loss: 1.6745, value_loss: 0.9525
2024-07-11 15:58:09,413 [INFO    ] __main__: train step 3235: loss: 0.6765, policy_loss: 1.6744, value_loss: 0.9524
2024-07-11 15:58:09,626 [INFO    ] __main__: train step 3236: loss: 0.6766, policy_loss: 1.6743, value_loss: 0.9524
2024-07-11 15:58:09,820 [INFO    ] __main__: train step 3237: loss: 0.6768, policy_loss: 1.6742, value_loss: 0.9524
2024-07-11 15:58:10,025 [INFO    ] __main__: train step 3238: loss: 0.6769, policy_loss: 1.6740, value_loss: 0.9523
2024-07-11 15:58:10,513 [INFO    ] __main__: train step 3239: loss: 0.6770, policy_loss: 1.6739, value_loss: 0.9523
2024-07-11 15:58:10,746 [INFO    ] __main__: train step 3240: loss: 0.6771, policy_loss: 1.6738, value_loss: 0.9522
2024-07-11 15:58:10,945 [INFO    ] __main__: train step 3241: loss: 0.6773, policy_loss: 1.6737, value_loss: 0.9522
2024-07-11 15:58:11,145 [INFO    ] __main__: train step 3242: loss: 0.6774, policy_loss: 1.6736, value_loss: 0.9522
2024-07-11 15:58:11,355 [INFO    ] __main__: train step 3243: loss: 0.6776, policy_loss: 1.6734, value_loss: 0.9521
2024-07-11 15:58:11,562 [INFO    ] __main__: train step 3244: loss: 0.6777, policy_loss: 1.6733, value_loss: 0.9521
2024-07-11 15:58:11,764 [INFO    ] __main__: train step 3245: loss: 0.6778, policy_loss: 1.6732, value_loss: 0.9521
2024-07-11 15:58:11,957 [INFO    ] __main__: train step 3246: loss: 0.6780, policy_loss: 1.6731, value_loss: 0.9520
2024-07-11 15:58:13,393 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:58:13,848 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:58:13,904 [INFO    ] __main__: train step 3247: loss: 0.6781, policy_loss: 1.6729, value_loss: 0.9520
2024-07-11 15:58:14,070 [INFO    ] __main__: train step 3248: loss: 0.6782, policy_loss: 1.6728, value_loss: 0.9520
2024-07-11 15:58:14,273 [INFO    ] __main__: train step 3249: loss: 0.6784, policy_loss: 1.6727, value_loss: 0.9519
2024-07-11 15:58:14,477 [INFO    ] __main__: train step 3250: loss: 0.6785, policy_loss: 1.6726, value_loss: 0.9519
2024-07-11 15:58:14,670 [INFO    ] __main__: train step 3251: loss: 0.6786, policy_loss: 1.6725, value_loss: 0.9519
2024-07-11 15:58:14,857 [INFO    ] __main__: train step 3252: loss: 0.6788, policy_loss: 1.6723, value_loss: 0.9518
2024-07-11 15:58:15,061 [INFO    ] __main__: train step 3253: loss: 0.6789, policy_loss: 1.6722, value_loss: 0.9518
2024-07-11 15:58:15,256 [INFO    ] __main__: train step 3254: loss: 0.6790, policy_loss: 1.6721, value_loss: 0.9518
2024-07-11 15:58:15,459 [INFO    ] __main__: train step 3255: loss: 0.6792, policy_loss: 1.6720, value_loss: 0.9517
2024-07-11 15:58:15,660 [INFO    ] __main__: train step 3256: loss: 0.6793, policy_loss: 1.6719, value_loss: 0.9517
2024-07-11 15:58:15,864 [INFO    ] __main__: train step 3257: loss: 0.6794, policy_loss: 1.6717, value_loss: 0.9517
2024-07-11 15:58:16,061 [INFO    ] __main__: train step 3258: loss: 0.6796, policy_loss: 1.6716, value_loss: 0.9516
2024-07-11 15:58:16,264 [INFO    ] __main__: train step 3259: loss: 0.6797, policy_loss: 1.6715, value_loss: 0.9516
2024-07-11 15:58:16,460 [INFO    ] __main__: train step 3260: loss: 0.6798, policy_loss: 1.6714, value_loss: 0.9516
2024-07-11 15:58:16,669 [INFO    ] __main__: train step 3261: loss: 0.6800, policy_loss: 1.6712, value_loss: 0.9515
2024-07-11 15:58:16,886 [INFO    ] __main__: train step 3262: loss: 0.6801, policy_loss: 1.6711, value_loss: 0.9515
2024-07-11 15:58:17,355 [INFO    ] __main__: train step 3263: loss: 0.6802, policy_loss: 1.6710, value_loss: 0.9515
2024-07-11 15:58:18,799 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:58:19,212 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:58:19,266 [INFO    ] __main__: train step 3264: loss: 0.6804, policy_loss: 1.6709, value_loss: 0.9514
2024-07-11 15:58:19,448 [INFO    ] __main__: train step 3265: loss: 0.6805, policy_loss: 1.6708, value_loss: 0.9514
2024-07-11 15:58:19,683 [INFO    ] __main__: train step 3266: loss: 0.6806, policy_loss: 1.6706, value_loss: 0.9514
2024-07-11 15:58:19,894 [INFO    ] __main__: train step 3267: loss: 0.6808, policy_loss: 1.6705, value_loss: 0.9513
2024-07-11 15:58:20,129 [INFO    ] __main__: train step 3268: loss: 0.6809, policy_loss: 1.6704, value_loss: 0.9513
2024-07-11 15:58:20,331 [INFO    ] __main__: train step 3269: loss: 0.6810, policy_loss: 1.6703, value_loss: 0.9513
2024-07-11 15:58:20,541 [INFO    ] __main__: train step 3270: loss: 0.6812, policy_loss: 1.6701, value_loss: 0.9512
2024-07-11 15:58:20,740 [INFO    ] __main__: train step 3271: loss: 0.6813, policy_loss: 1.6700, value_loss: 0.9512
2024-07-11 15:58:20,938 [INFO    ] __main__: train step 3272: loss: 0.6814, policy_loss: 1.6699, value_loss: 0.9512
2024-07-11 15:58:21,137 [INFO    ] __main__: train step 3273: loss: 0.6816, policy_loss: 1.6698, value_loss: 0.9511
2024-07-11 15:58:21,346 [INFO    ] __main__: train step 3274: loss: 0.6817, policy_loss: 1.6697, value_loss: 0.9511
2024-07-11 15:58:21,549 [INFO    ] __main__: train step 3275: loss: 0.6818, policy_loss: 1.6695, value_loss: 0.9511
2024-07-11 15:58:21,742 [INFO    ] __main__: train step 3276: loss: 0.6820, policy_loss: 1.6694, value_loss: 0.9510
2024-07-11 15:58:21,952 [INFO    ] __main__: train step 3277: loss: 0.6821, policy_loss: 1.6693, value_loss: 0.9510
2024-07-11 15:58:22,143 [INFO    ] __main__: train step 3278: loss: 0.6822, policy_loss: 1.6692, value_loss: 0.9510
2024-07-11 15:58:22,349 [INFO    ] __main__: train step 3279: loss: 0.6823, policy_loss: 1.6690, value_loss: 0.9509
2024-07-11 15:58:22,581 [INFO    ] __main__: train step 3280: loss: 0.6825, policy_loss: 1.6689, value_loss: 0.9509
2024-07-11 15:58:24,018 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:58:24,407 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:58:24,460 [INFO    ] __main__: train step 3281: loss: 0.6826, policy_loss: 1.6688, value_loss: 0.9509
2024-07-11 15:58:24,639 [INFO    ] __main__: train step 3282: loss: 0.6827, policy_loss: 1.6687, value_loss: 0.9508
2024-07-11 15:58:24,839 [INFO    ] __main__: train step 3283: loss: 0.6829, policy_loss: 1.6685, value_loss: 0.9508
2024-07-11 15:58:25,040 [INFO    ] __main__: train step 3284: loss: 0.6830, policy_loss: 1.6684, value_loss: 0.9508
2024-07-11 15:58:25,530 [INFO    ] __main__: train step 3285: loss: 0.6831, policy_loss: 1.6683, value_loss: 0.9507
2024-07-11 15:58:25,738 [INFO    ] __main__: train step 3286: loss: 0.6833, policy_loss: 1.6682, value_loss: 0.9507
2024-07-11 15:58:25,976 [INFO    ] __main__: train step 3287: loss: 0.6834, policy_loss: 1.6681, value_loss: 0.9507
2024-07-11 15:58:26,174 [INFO    ] __main__: train step 3288: loss: 0.6835, policy_loss: 1.6679, value_loss: 0.9506
2024-07-11 15:58:26,397 [INFO    ] __main__: train step 3289: loss: 0.6837, policy_loss: 1.6678, value_loss: 0.9506
2024-07-11 15:58:26,617 [INFO    ] __main__: train step 3290: loss: 0.6838, policy_loss: 1.6677, value_loss: 0.9506
2024-07-11 15:58:26,823 [INFO    ] __main__: train step 3291: loss: 0.6839, policy_loss: 1.6676, value_loss: 0.9505
2024-07-11 15:58:27,018 [INFO    ] __main__: train step 3292: loss: 0.6840, policy_loss: 1.6674, value_loss: 0.9505
2024-07-11 15:58:27,229 [INFO    ] __main__: train step 3293: loss: 0.6842, policy_loss: 1.6673, value_loss: 0.9504
2024-07-11 15:58:27,440 [INFO    ] __main__: train step 3294: loss: 0.6843, policy_loss: 1.6672, value_loss: 0.9504
2024-07-11 15:58:27,642 [INFO    ] __main__: train step 3295: loss: 0.6844, policy_loss: 1.6671, value_loss: 0.9504
2024-07-11 15:58:27,854 [INFO    ] __main__: train step 3296: loss: 0.6846, policy_loss: 1.6670, value_loss: 0.9503
2024-07-11 15:58:28,062 [INFO    ] __main__: train step 3297: loss: 0.6847, policy_loss: 1.6668, value_loss: 0.9503
2024-07-11 15:58:29,504 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:58:29,936 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:58:29,991 [INFO    ] __main__: train step 3298: loss: 0.6849, policy_loss: 1.6667, value_loss: 0.9503
2024-07-11 15:58:30,163 [INFO    ] __main__: train step 3299: loss: 0.6850, policy_loss: 1.6666, value_loss: 0.9502
2024-07-11 15:58:30,384 [INFO    ] __main__: train step 3300: loss: 0.6851, policy_loss: 1.6665, value_loss: 0.9502
2024-07-11 15:58:30,613 [INFO    ] __main__: train step 3301: loss: 0.6852, policy_loss: 1.6663, value_loss: 0.9502
2024-07-11 15:58:30,819 [INFO    ] __main__: train step 3302: loss: 0.6854, policy_loss: 1.6662, value_loss: 0.9501
2024-07-11 15:58:31,028 [INFO    ] __main__: train step 3303: loss: 0.6855, policy_loss: 1.6661, value_loss: 0.9501
2024-07-11 15:58:31,246 [INFO    ] __main__: train step 3304: loss: 0.6856, policy_loss: 1.6660, value_loss: 0.9501
2024-07-11 15:58:31,434 [INFO    ] __main__: train step 3305: loss: 0.6858, policy_loss: 1.6658, value_loss: 0.9500
2024-07-11 15:58:31,655 [INFO    ] __main__: train step 3306: loss: 0.6859, policy_loss: 1.6657, value_loss: 0.9500
2024-07-11 15:58:31,878 [INFO    ] __main__: train step 3307: loss: 0.6860, policy_loss: 1.6656, value_loss: 0.9500
2024-07-11 15:58:32,382 [INFO    ] __main__: train step 3308: loss: 0.6861, policy_loss: 1.6655, value_loss: 0.9499
2024-07-11 15:58:32,671 [INFO    ] __main__: train step 3309: loss: 0.6863, policy_loss: 1.6654, value_loss: 0.9499
2024-07-11 15:58:32,885 [INFO    ] __main__: train step 3310: loss: 0.6864, policy_loss: 1.6652, value_loss: 0.9499
2024-07-11 15:58:33,074 [INFO    ] __main__: train step 3311: loss: 0.6865, policy_loss: 1.6651, value_loss: 0.9498
2024-07-11 15:58:33,273 [INFO    ] __main__: train step 3312: loss: 0.6867, policy_loss: 1.6650, value_loss: 0.9498
2024-07-11 15:58:33,467 [INFO    ] __main__: train step 3313: loss: 0.6868, policy_loss: 1.6649, value_loss: 0.9498
2024-07-11 15:58:33,663 [INFO    ] __main__: train step 3314: loss: 0.6869, policy_loss: 1.6647, value_loss: 0.9497
2024-07-11 15:58:35,103 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:58:35,521 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:58:35,576 [INFO    ] __main__: train step 3315: loss: 0.6870, policy_loss: 1.6646, value_loss: 0.9497
2024-07-11 15:58:35,743 [INFO    ] __main__: train step 3316: loss: 0.6871, policy_loss: 1.6645, value_loss: 0.9497
2024-07-11 15:58:35,959 [INFO    ] __main__: train step 3317: loss: 0.6873, policy_loss: 1.6644, value_loss: 0.9496
2024-07-11 15:58:36,193 [INFO    ] __main__: train step 3318: loss: 0.6874, policy_loss: 1.6642, value_loss: 0.9496
2024-07-11 15:58:36,389 [INFO    ] __main__: train step 3319: loss: 0.6875, policy_loss: 1.6641, value_loss: 0.9495
2024-07-11 15:58:36,593 [INFO    ] __main__: train step 3320: loss: 0.6877, policy_loss: 1.6640, value_loss: 0.9495
2024-07-11 15:58:36,802 [INFO    ] __main__: train step 3321: loss: 0.6878, policy_loss: 1.6639, value_loss: 0.9495
2024-07-11 15:58:37,000 [INFO    ] __main__: train step 3322: loss: 0.6879, policy_loss: 1.6637, value_loss: 0.9494
2024-07-11 15:58:37,212 [INFO    ] __main__: train step 3323: loss: 0.6881, policy_loss: 1.6636, value_loss: 0.9494
2024-07-11 15:58:37,412 [INFO    ] __main__: train step 3324: loss: 0.6882, policy_loss: 1.6635, value_loss: 0.9494
2024-07-11 15:58:37,603 [INFO    ] __main__: train step 3325: loss: 0.6883, policy_loss: 1.6634, value_loss: 0.9493
2024-07-11 15:58:37,820 [INFO    ] __main__: train step 3326: loss: 0.6884, policy_loss: 1.6632, value_loss: 0.9493
2024-07-11 15:58:38,070 [INFO    ] __main__: train step 3327: loss: 0.6886, policy_loss: 1.6631, value_loss: 0.9493
2024-07-11 15:58:38,286 [INFO    ] __main__: train step 3328: loss: 0.6887, policy_loss: 1.6630, value_loss: 0.9492
2024-07-11 15:58:38,487 [INFO    ] __main__: train step 3329: loss: 0.6888, policy_loss: 1.6629, value_loss: 0.9492
2024-07-11 15:58:38,690 [INFO    ] __main__: train step 3330: loss: 0.6889, policy_loss: 1.6628, value_loss: 0.9492
2024-07-11 15:58:39,164 [INFO    ] __main__: train step 3331: loss: 0.6891, policy_loss: 1.6626, value_loss: 0.9491
2024-07-11 15:58:40,605 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:58:41,058 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:58:41,120 [INFO    ] __main__: train step 3332: loss: 0.6892, policy_loss: 1.6625, value_loss: 0.9491
2024-07-11 15:58:41,296 [INFO    ] __main__: train step 3333: loss: 0.6893, policy_loss: 1.6624, value_loss: 0.9490
2024-07-11 15:58:41,526 [INFO    ] __main__: train step 3334: loss: 0.6895, policy_loss: 1.6623, value_loss: 0.9490
2024-07-11 15:58:41,731 [INFO    ] __main__: train step 3335: loss: 0.6896, policy_loss: 1.6621, value_loss: 0.9490
2024-07-11 15:58:41,933 [INFO    ] __main__: train step 3336: loss: 0.6897, policy_loss: 1.6620, value_loss: 0.9490
2024-07-11 15:58:42,129 [INFO    ] __main__: train step 3337: loss: 0.6899, policy_loss: 1.6619, value_loss: 0.9489
2024-07-11 15:58:42,342 [INFO    ] __main__: train step 3338: loss: 0.6900, policy_loss: 1.6618, value_loss: 0.9489
2024-07-11 15:58:42,545 [INFO    ] __main__: train step 3339: loss: 0.6901, policy_loss: 1.6617, value_loss: 0.9488
2024-07-11 15:58:42,755 [INFO    ] __main__: train step 3340: loss: 0.6903, policy_loss: 1.6615, value_loss: 0.9488
2024-07-11 15:58:42,957 [INFO    ] __main__: train step 3341: loss: 0.6904, policy_loss: 1.6614, value_loss: 0.9488
2024-07-11 15:58:43,188 [INFO    ] __main__: train step 3342: loss: 0.6905, policy_loss: 1.6613, value_loss: 0.9487
2024-07-11 15:58:43,414 [INFO    ] __main__: train step 3343: loss: 0.6906, policy_loss: 1.6612, value_loss: 0.9487
2024-07-11 15:58:43,626 [INFO    ] __main__: train step 3344: loss: 0.6908, policy_loss: 1.6610, value_loss: 0.9487
2024-07-11 15:58:43,846 [INFO    ] __main__: train step 3345: loss: 0.6909, policy_loss: 1.6609, value_loss: 0.9486
2024-07-11 15:58:44,073 [INFO    ] __main__: train step 3346: loss: 0.6910, policy_loss: 1.6608, value_loss: 0.9486
2024-07-11 15:58:44,290 [INFO    ] __main__: train step 3347: loss: 0.6912, policy_loss: 1.6607, value_loss: 0.9486
2024-07-11 15:58:44,513 [INFO    ] __main__: train step 3348: loss: 0.6913, policy_loss: 1.6605, value_loss: 0.9485
2024-07-11 15:58:45,961 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:58:46,383 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:58:46,437 [INFO    ] __main__: train step 3349: loss: 0.6914, policy_loss: 1.6604, value_loss: 0.9485
2024-07-11 15:58:46,610 [INFO    ] __main__: train step 3350: loss: 0.6915, policy_loss: 1.6603, value_loss: 0.9485
2024-07-11 15:58:46,809 [INFO    ] __main__: train step 3351: loss: 0.6917, policy_loss: 1.6602, value_loss: 0.9484
2024-07-11 15:58:47,013 [INFO    ] __main__: train step 3352: loss: 0.6918, policy_loss: 1.6600, value_loss: 0.9484
2024-07-11 15:58:47,205 [INFO    ] __main__: train step 3353: loss: 0.6919, policy_loss: 1.6599, value_loss: 0.9484
2024-07-11 15:58:47,682 [INFO    ] __main__: train step 3354: loss: 0.6921, policy_loss: 1.6598, value_loss: 0.9483
2024-07-11 15:58:47,896 [INFO    ] __main__: train step 3355: loss: 0.6922, policy_loss: 1.6597, value_loss: 0.9483
2024-07-11 15:58:48,096 [INFO    ] __main__: train step 3356: loss: 0.6923, policy_loss: 1.6596, value_loss: 0.9482
2024-07-11 15:58:48,302 [INFO    ] __main__: train step 3357: loss: 0.6925, policy_loss: 1.6594, value_loss: 0.9482
2024-07-11 15:58:48,519 [INFO    ] __main__: train step 3358: loss: 0.6926, policy_loss: 1.6593, value_loss: 0.9482
2024-07-11 15:58:48,708 [INFO    ] __main__: train step 3359: loss: 0.6927, policy_loss: 1.6592, value_loss: 0.9482
2024-07-11 15:58:48,923 [INFO    ] __main__: train step 3360: loss: 0.6928, policy_loss: 1.6591, value_loss: 0.9481
2024-07-11 15:58:49,144 [INFO    ] __main__: train step 3361: loss: 0.6930, policy_loss: 1.6589, value_loss: 0.9481
2024-07-11 15:58:49,366 [INFO    ] __main__: train step 3362: loss: 0.6931, policy_loss: 1.6588, value_loss: 0.9481
2024-07-11 15:58:49,598 [INFO    ] __main__: train step 3363: loss: 0.6932, policy_loss: 1.6587, value_loss: 0.9480
2024-07-11 15:58:49,830 [INFO    ] __main__: train step 3364: loss: 0.6933, policy_loss: 1.6586, value_loss: 0.9480
2024-07-11 15:58:50,044 [INFO    ] __main__: train step 3365: loss: 0.6935, policy_loss: 1.6584, value_loss: 0.9480
2024-07-11 15:58:51,498 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:58:51,903 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:58:51,958 [INFO    ] __main__: train step 3366: loss: 0.6936, policy_loss: 1.6583, value_loss: 0.9479
2024-07-11 15:58:52,131 [INFO    ] __main__: train step 3367: loss: 0.6937, policy_loss: 1.6582, value_loss: 0.9479
2024-07-11 15:58:52,340 [INFO    ] __main__: train step 3368: loss: 0.6938, policy_loss: 1.6581, value_loss: 0.9479
2024-07-11 15:58:52,566 [INFO    ] __main__: train step 3369: loss: 0.6940, policy_loss: 1.6579, value_loss: 0.9478
2024-07-11 15:58:52,766 [INFO    ] __main__: train step 3370: loss: 0.6941, policy_loss: 1.6578, value_loss: 0.9478
2024-07-11 15:58:52,980 [INFO    ] __main__: train step 3371: loss: 0.6942, policy_loss: 1.6577, value_loss: 0.9478
2024-07-11 15:58:53,171 [INFO    ] __main__: train step 3372: loss: 0.6943, policy_loss: 1.6576, value_loss: 0.9477
2024-07-11 15:58:53,404 [INFO    ] __main__: train step 3373: loss: 0.6945, policy_loss: 1.6575, value_loss: 0.9477
2024-07-11 15:58:53,632 [INFO    ] __main__: train step 3374: loss: 0.6946, policy_loss: 1.6573, value_loss: 0.9477
2024-07-11 15:58:53,866 [INFO    ] __main__: train step 3375: loss: 0.6947, policy_loss: 1.6572, value_loss: 0.9476
2024-07-11 15:58:54,101 [INFO    ] __main__: train step 3376: loss: 0.6949, policy_loss: 1.6571, value_loss: 0.9476
2024-07-11 15:58:54,332 [INFO    ] __main__: train step 3377: loss: 0.6950, policy_loss: 1.6570, value_loss: 0.9476
2024-07-11 15:58:54,815 [INFO    ] __main__: train step 3378: loss: 0.6951, policy_loss: 1.6568, value_loss: 0.9475
2024-07-11 15:58:55,030 [INFO    ] __main__: train step 3379: loss: 0.6953, policy_loss: 1.6567, value_loss: 0.9475
2024-07-11 15:58:55,223 [INFO    ] __main__: train step 3380: loss: 0.6954, policy_loss: 1.6566, value_loss: 0.9475
2024-07-11 15:58:55,423 [INFO    ] __main__: train step 3381: loss: 0.6955, policy_loss: 1.6565, value_loss: 0.9474
2024-07-11 15:58:55,626 [INFO    ] __main__: train step 3382: loss: 0.6957, policy_loss: 1.6564, value_loss: 0.9474
2024-07-11 15:58:57,078 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:58:57,510 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:58:57,569 [INFO    ] __main__: train step 3383: loss: 0.6958, policy_loss: 1.6563, value_loss: 0.9474
2024-07-11 15:58:57,736 [INFO    ] __main__: train step 3384: loss: 0.6959, policy_loss: 1.6561, value_loss: 0.9473
2024-07-11 15:58:57,937 [INFO    ] __main__: train step 3385: loss: 0.6961, policy_loss: 1.6560, value_loss: 0.9473
2024-07-11 15:58:58,139 [INFO    ] __main__: train step 3386: loss: 0.6962, policy_loss: 1.6559, value_loss: 0.9473
2024-07-11 15:58:58,329 [INFO    ] __main__: train step 3387: loss: 0.6963, policy_loss: 1.6558, value_loss: 0.9472
2024-07-11 15:58:58,528 [INFO    ] __main__: train step 3388: loss: 0.6964, policy_loss: 1.6556, value_loss: 0.9472
2024-07-11 15:58:58,730 [INFO    ] __main__: train step 3389: loss: 0.6966, policy_loss: 1.6555, value_loss: 0.9472
2024-07-11 15:58:58,937 [INFO    ] __main__: train step 3390: loss: 0.6967, policy_loss: 1.6554, value_loss: 0.9471
2024-07-11 15:58:59,142 [INFO    ] __main__: train step 3391: loss: 0.6968, policy_loss: 1.6553, value_loss: 0.9471
2024-07-11 15:58:59,350 [INFO    ] __main__: train step 3392: loss: 0.6969, policy_loss: 1.6552, value_loss: 0.9470
2024-07-11 15:58:59,579 [INFO    ] __main__: train step 3393: loss: 0.6971, policy_loss: 1.6550, value_loss: 0.9470
2024-07-11 15:58:59,776 [INFO    ] __main__: train step 3394: loss: 0.6972, policy_loss: 1.6549, value_loss: 0.9470
2024-07-11 15:58:59,974 [INFO    ] __main__: train step 3395: loss: 0.6973, policy_loss: 1.6548, value_loss: 0.9469
2024-07-11 15:59:00,168 [INFO    ] __main__: train step 3396: loss: 0.6974, policy_loss: 1.6547, value_loss: 0.9469
2024-07-11 15:59:00,361 [INFO    ] __main__: train step 3397: loss: 0.6976, policy_loss: 1.6545, value_loss: 0.9469
2024-07-11 15:59:00,561 [INFO    ] __main__: train step 3398: loss: 0.6977, policy_loss: 1.6544, value_loss: 0.9468
2024-07-11 15:59:00,789 [INFO    ] __main__: train step 3399: loss: 0.6978, policy_loss: 1.6543, value_loss: 0.9468
2024-07-11 15:59:02,214 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:59:02,641 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:59:02,695 [INFO    ] __main__: train step 3400: loss: 0.6980, policy_loss: 1.6542, value_loss: 0.9468
2024-07-11 15:59:03,137 [INFO    ] __main__: train step 3401: loss: 0.6981, policy_loss: 1.6541, value_loss: 0.9467
2024-07-11 15:59:03,339 [INFO    ] __main__: train step 3402: loss: 0.6982, policy_loss: 1.6539, value_loss: 0.9467
2024-07-11 15:59:03,552 [INFO    ] __main__: train step 3403: loss: 0.6984, policy_loss: 1.6538, value_loss: 0.9467
2024-07-11 15:59:03,744 [INFO    ] __main__: train step 3404: loss: 0.6985, policy_loss: 1.6537, value_loss: 0.9466
2024-07-11 15:59:03,949 [INFO    ] __main__: train step 3405: loss: 0.6986, policy_loss: 1.6536, value_loss: 0.9466
2024-07-11 15:59:04,157 [INFO    ] __main__: train step 3406: loss: 0.6987, policy_loss: 1.6535, value_loss: 0.9465
2024-07-11 15:59:04,358 [INFO    ] __main__: train step 3407: loss: 0.6989, policy_loss: 1.6533, value_loss: 0.9465
2024-07-11 15:59:04,555 [INFO    ] __main__: train step 3408: loss: 0.6990, policy_loss: 1.6532, value_loss: 0.9465
2024-07-11 15:59:04,768 [INFO    ] __main__: train step 3409: loss: 0.6991, policy_loss: 1.6531, value_loss: 0.9465
2024-07-11 15:59:04,960 [INFO    ] __main__: train step 3410: loss: 0.6993, policy_loss: 1.6530, value_loss: 0.9464
2024-07-11 15:59:05,162 [INFO    ] __main__: train step 3411: loss: 0.6994, policy_loss: 1.6529, value_loss: 0.9464
2024-07-11 15:59:05,374 [INFO    ] __main__: train step 3412: loss: 0.6995, policy_loss: 1.6527, value_loss: 0.9463
2024-07-11 15:59:05,589 [INFO    ] __main__: train step 3413: loss: 0.6997, policy_loss: 1.6526, value_loss: 0.9463
2024-07-11 15:59:05,785 [INFO    ] __main__: train step 3414: loss: 0.6998, policy_loss: 1.6525, value_loss: 0.9463
2024-07-11 15:59:05,979 [INFO    ] __main__: train step 3415: loss: 0.6999, policy_loss: 1.6524, value_loss: 0.9462
2024-07-11 15:59:06,177 [INFO    ] __main__: train step 3416: loss: 0.7001, policy_loss: 1.6523, value_loss: 0.9462
2024-07-11 15:59:07,622 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:59:08,054 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:59:08,115 [INFO    ] __main__: train step 3417: loss: 0.7002, policy_loss: 1.6521, value_loss: 0.9462
2024-07-11 15:59:08,290 [INFO    ] __main__: train step 3418: loss: 0.7003, policy_loss: 1.6520, value_loss: 0.9461
2024-07-11 15:59:08,499 [INFO    ] __main__: train step 3419: loss: 0.7005, policy_loss: 1.6519, value_loss: 0.9461
2024-07-11 15:59:08,694 [INFO    ] __main__: train step 3420: loss: 0.7006, policy_loss: 1.6518, value_loss: 0.9461
2024-07-11 15:59:08,898 [INFO    ] __main__: train step 3421: loss: 0.7007, policy_loss: 1.6517, value_loss: 0.9460
2024-07-11 15:59:09,132 [INFO    ] __main__: train step 3422: loss: 0.7008, policy_loss: 1.6516, value_loss: 0.9460
2024-07-11 15:59:09,338 [INFO    ] __main__: train step 3423: loss: 0.7010, policy_loss: 1.6514, value_loss: 0.9460
2024-07-11 15:59:09,549 [INFO    ] __main__: train step 3424: loss: 0.7011, policy_loss: 1.6513, value_loss: 0.9459
2024-07-11 15:59:10,057 [INFO    ] __main__: train step 3425: loss: 0.7012, policy_loss: 1.6512, value_loss: 0.9459
2024-07-11 15:59:10,266 [INFO    ] __main__: train step 3426: loss: 0.7014, policy_loss: 1.6511, value_loss: 0.9459
2024-07-11 15:59:10,473 [INFO    ] __main__: train step 3427: loss: 0.7015, policy_loss: 1.6510, value_loss: 0.9458
2024-07-11 15:59:10,688 [INFO    ] __main__: train step 3428: loss: 0.7016, policy_loss: 1.6508, value_loss: 0.9458
2024-07-11 15:59:10,912 [INFO    ] __main__: train step 3429: loss: 0.7017, policy_loss: 1.6507, value_loss: 0.9458
2024-07-11 15:59:11,145 [INFO    ] __main__: train step 3430: loss: 0.7019, policy_loss: 1.6506, value_loss: 0.9457
2024-07-11 15:59:11,352 [INFO    ] __main__: train step 3431: loss: 0.7020, policy_loss: 1.6505, value_loss: 0.9457
2024-07-11 15:59:11,554 [INFO    ] __main__: train step 3432: loss: 0.7021, policy_loss: 1.6503, value_loss: 0.9456
2024-07-11 15:59:11,758 [INFO    ] __main__: train step 3433: loss: 0.7023, policy_loss: 1.6502, value_loss: 0.9456
2024-07-11 15:59:13,205 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:59:13,693 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:59:13,752 [INFO    ] __main__: train step 3434: loss: 0.7024, policy_loss: 1.6501, value_loss: 0.9456
2024-07-11 15:59:13,928 [INFO    ] __main__: train step 3435: loss: 0.7025, policy_loss: 1.6500, value_loss: 0.9455
2024-07-11 15:59:14,121 [INFO    ] __main__: train step 3436: loss: 0.7026, policy_loss: 1.6499, value_loss: 0.9455
2024-07-11 15:59:14,322 [INFO    ] __main__: train step 3437: loss: 0.7028, policy_loss: 1.6498, value_loss: 0.9455
2024-07-11 15:59:14,522 [INFO    ] __main__: train step 3438: loss: 0.7029, policy_loss: 1.6496, value_loss: 0.9454
2024-07-11 15:59:14,738 [INFO    ] __main__: train step 3439: loss: 0.7030, policy_loss: 1.6495, value_loss: 0.9454
2024-07-11 15:59:14,969 [INFO    ] __main__: train step 3440: loss: 0.7031, policy_loss: 1.6494, value_loss: 0.9454
2024-07-11 15:59:15,173 [INFO    ] __main__: train step 3441: loss: 0.7033, policy_loss: 1.6493, value_loss: 0.9453
2024-07-11 15:59:15,372 [INFO    ] __main__: train step 3442: loss: 0.7034, policy_loss: 1.6492, value_loss: 0.9453
2024-07-11 15:59:15,575 [INFO    ] __main__: train step 3443: loss: 0.7035, policy_loss: 1.6490, value_loss: 0.9453
2024-07-11 15:59:15,770 [INFO    ] __main__: train step 3444: loss: 0.7037, policy_loss: 1.6489, value_loss: 0.9452
2024-07-11 15:59:15,971 [INFO    ] __main__: train step 3445: loss: 0.7038, policy_loss: 1.6488, value_loss: 0.9452
2024-07-11 15:59:16,173 [INFO    ] __main__: train step 3446: loss: 0.7039, policy_loss: 1.6487, value_loss: 0.9452
2024-07-11 15:59:16,367 [INFO    ] __main__: train step 3447: loss: 0.7041, policy_loss: 1.6486, value_loss: 0.9451
2024-07-11 15:59:16,867 [INFO    ] __main__: train step 3448: loss: 0.7042, policy_loss: 1.6485, value_loss: 0.9451
2024-07-11 15:59:17,071 [INFO    ] __main__: train step 3449: loss: 0.7043, policy_loss: 1.6483, value_loss: 0.9451
2024-07-11 15:59:17,305 [INFO    ] __main__: train step 3450: loss: 0.7044, policy_loss: 1.6482, value_loss: 0.9450
2024-07-11 15:59:18,749 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:59:19,171 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:59:19,230 [INFO    ] __main__: train step 3451: loss: 0.7046, policy_loss: 1.6481, value_loss: 0.9450
2024-07-11 15:59:19,399 [INFO    ] __main__: train step 3452: loss: 0.7047, policy_loss: 1.6480, value_loss: 0.9450
2024-07-11 15:59:19,618 [INFO    ] __main__: train step 3453: loss: 0.7048, policy_loss: 1.6479, value_loss: 0.9449
2024-07-11 15:59:19,855 [INFO    ] __main__: train step 3454: loss: 0.7050, policy_loss: 1.6477, value_loss: 0.9449
2024-07-11 15:59:20,068 [INFO    ] __main__: train step 3455: loss: 0.7051, policy_loss: 1.6476, value_loss: 0.9449
2024-07-11 15:59:20,298 [INFO    ] __main__: train step 3456: loss: 0.7052, policy_loss: 1.6475, value_loss: 0.9449
2024-07-11 15:59:20,502 [INFO    ] __main__: train step 3457: loss: 0.7053, policy_loss: 1.6474, value_loss: 0.9448
2024-07-11 15:59:20,700 [INFO    ] __main__: train step 3458: loss: 0.7055, policy_loss: 1.6473, value_loss: 0.9448
2024-07-11 15:59:20,896 [INFO    ] __main__: train step 3459: loss: 0.7056, policy_loss: 1.6471, value_loss: 0.9447
2024-07-11 15:59:21,099 [INFO    ] __main__: train step 3460: loss: 0.7057, policy_loss: 1.6470, value_loss: 0.9447
2024-07-11 15:59:21,321 [INFO    ] __main__: train step 3461: loss: 0.7059, policy_loss: 1.6469, value_loss: 0.9447
2024-07-11 15:59:21,518 [INFO    ] __main__: train step 3462: loss: 0.7060, policy_loss: 1.6468, value_loss: 0.9446
2024-07-11 15:59:21,720 [INFO    ] __main__: train step 3463: loss: 0.7061, policy_loss: 1.6467, value_loss: 0.9446
2024-07-11 15:59:21,925 [INFO    ] __main__: train step 3464: loss: 0.7063, policy_loss: 1.6466, value_loss: 0.9446
2024-07-11 15:59:22,116 [INFO    ] __main__: train step 3465: loss: 0.7064, policy_loss: 1.6464, value_loss: 0.9445
2024-07-11 15:59:22,313 [INFO    ] __main__: train step 3466: loss: 0.7065, policy_loss: 1.6463, value_loss: 0.9445
2024-07-11 15:59:22,529 [INFO    ] __main__: train step 3467: loss: 0.7066, policy_loss: 1.6462, value_loss: 0.9445
2024-07-11 15:59:23,977 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:59:24,379 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:59:24,434 [INFO    ] __main__: train step 3468: loss: 0.7068, policy_loss: 1.6461, value_loss: 0.9444
2024-07-11 15:59:24,600 [INFO    ] __main__: train step 3469: loss: 0.7069, policy_loss: 1.6460, value_loss: 0.9444
2024-07-11 15:59:24,814 [INFO    ] __main__: train step 3470: loss: 0.7070, policy_loss: 1.6458, value_loss: 0.9444
2024-07-11 15:59:25,291 [INFO    ] __main__: train step 3471: loss: 0.7072, policy_loss: 1.6457, value_loss: 0.9444
2024-07-11 15:59:25,488 [INFO    ] __main__: train step 3472: loss: 0.7073, policy_loss: 1.6456, value_loss: 0.9443
2024-07-11 15:59:25,696 [INFO    ] __main__: train step 3473: loss: 0.7074, policy_loss: 1.6455, value_loss: 0.9443
2024-07-11 15:59:25,941 [INFO    ] __main__: train step 3474: loss: 0.7075, policy_loss: 1.6454, value_loss: 0.9443
2024-07-11 15:59:26,175 [INFO    ] __main__: train step 3475: loss: 0.7077, policy_loss: 1.6452, value_loss: 0.9442
2024-07-11 15:59:26,386 [INFO    ] __main__: train step 3476: loss: 0.7078, policy_loss: 1.6451, value_loss: 0.9442
2024-07-11 15:59:26,584 [INFO    ] __main__: train step 3477: loss: 0.7079, policy_loss: 1.6450, value_loss: 0.9442
2024-07-11 15:59:26,780 [INFO    ] __main__: train step 3478: loss: 0.7081, policy_loss: 1.6449, value_loss: 0.9441
2024-07-11 15:59:26,992 [INFO    ] __main__: train step 3479: loss: 0.7082, policy_loss: 1.6448, value_loss: 0.9441
2024-07-11 15:59:27,189 [INFO    ] __main__: train step 3480: loss: 0.7083, policy_loss: 1.6447, value_loss: 0.9441
2024-07-11 15:59:27,398 [INFO    ] __main__: train step 3481: loss: 0.7084, policy_loss: 1.6445, value_loss: 0.9440
2024-07-11 15:59:27,627 [INFO    ] __main__: train step 3482: loss: 0.7086, policy_loss: 1.6444, value_loss: 0.9440
2024-07-11 15:59:27,830 [INFO    ] __main__: train step 3483: loss: 0.7087, policy_loss: 1.6443, value_loss: 0.9439
2024-07-11 15:59:28,030 [INFO    ] __main__: train step 3484: loss: 0.7088, policy_loss: 1.6442, value_loss: 0.9439
2024-07-11 15:59:29,476 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:59:29,912 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:59:29,974 [INFO    ] __main__: train step 3485: loss: 0.7090, policy_loss: 1.6441, value_loss: 0.9439
2024-07-11 15:59:30,142 [INFO    ] __main__: train step 3486: loss: 0.7091, policy_loss: 1.6439, value_loss: 0.9439
2024-07-11 15:59:30,348 [INFO    ] __main__: train step 3487: loss: 0.7092, policy_loss: 1.6438, value_loss: 0.9438
2024-07-11 15:59:30,556 [INFO    ] __main__: train step 3488: loss: 0.7094, policy_loss: 1.6437, value_loss: 0.9438
2024-07-11 15:59:30,760 [INFO    ] __main__: train step 3489: loss: 0.7095, policy_loss: 1.6436, value_loss: 0.9437
2024-07-11 15:59:30,957 [INFO    ] __main__: train step 3490: loss: 0.7096, policy_loss: 1.6435, value_loss: 0.9437
2024-07-11 15:59:31,163 [INFO    ] __main__: train step 3491: loss: 0.7097, policy_loss: 1.6434, value_loss: 0.9437
2024-07-11 15:59:31,370 [INFO    ] __main__: train step 3492: loss: 0.7099, policy_loss: 1.6432, value_loss: 0.9436
2024-07-11 15:59:31,578 [INFO    ] __main__: train step 3493: loss: 0.7100, policy_loss: 1.6431, value_loss: 0.9436
2024-07-11 15:59:32,099 [INFO    ] __main__: train step 3494: loss: 0.7101, policy_loss: 1.6430, value_loss: 0.9436
2024-07-11 15:59:32,315 [INFO    ] __main__: train step 3495: loss: 0.7102, policy_loss: 1.6429, value_loss: 0.9435
2024-07-11 15:59:32,516 [INFO    ] __main__: train step 3496: loss: 0.7104, policy_loss: 1.6427, value_loss: 0.9435
2024-07-11 15:59:32,724 [INFO    ] __main__: train step 3497: loss: 0.7105, policy_loss: 1.6426, value_loss: 0.9435
2024-07-11 15:59:32,928 [INFO    ] __main__: train step 3498: loss: 0.7106, policy_loss: 1.6425, value_loss: 0.9434
2024-07-11 15:59:33,127 [INFO    ] __main__: train step 3499: loss: 0.7108, policy_loss: 1.6424, value_loss: 0.9434
2024-07-11 15:59:33,333 [INFO    ] __main__: train step 3500: loss: 0.7109, policy_loss: 1.6423, value_loss: 0.9433
2024-07-11 15:59:33,539 [INFO    ] __main__: train step 3501: loss: 0.7110, policy_loss: 1.6422, value_loss: 0.9433
2024-07-11 15:59:34,981 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:59:35,402 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:59:35,464 [INFO    ] __main__: train step 3502: loss: 0.7111, policy_loss: 1.6421, value_loss: 0.9433
2024-07-11 15:59:35,631 [INFO    ] __main__: train step 3503: loss: 0.7113, policy_loss: 1.6419, value_loss: 0.9432
2024-07-11 15:59:35,829 [INFO    ] __main__: train step 3504: loss: 0.7114, policy_loss: 1.6418, value_loss: 0.9432
2024-07-11 15:59:36,043 [INFO    ] __main__: train step 3505: loss: 0.7115, policy_loss: 1.6417, value_loss: 0.9432
2024-07-11 15:59:36,235 [INFO    ] __main__: train step 3506: loss: 0.7116, policy_loss: 1.6416, value_loss: 0.9431
2024-07-11 15:59:36,442 [INFO    ] __main__: train step 3507: loss: 0.7118, policy_loss: 1.6415, value_loss: 0.9431
2024-07-11 15:59:36,650 [INFO    ] __main__: train step 3508: loss: 0.7119, policy_loss: 1.6413, value_loss: 0.9431
2024-07-11 15:59:36,864 [INFO    ] __main__: train step 3509: loss: 0.7120, policy_loss: 1.6412, value_loss: 0.9430
2024-07-11 15:59:37,061 [INFO    ] __main__: train step 3510: loss: 0.7121, policy_loss: 1.6411, value_loss: 0.9430
2024-07-11 15:59:37,264 [INFO    ] __main__: train step 3511: loss: 0.7123, policy_loss: 1.6410, value_loss: 0.9430
2024-07-11 15:59:37,467 [INFO    ] __main__: train step 3512: loss: 0.7124, policy_loss: 1.6409, value_loss: 0.9429
2024-07-11 15:59:37,667 [INFO    ] __main__: train step 3513: loss: 0.7125, policy_loss: 1.6407, value_loss: 0.9429
2024-07-11 15:59:37,888 [INFO    ] __main__: train step 3514: loss: 0.7127, policy_loss: 1.6406, value_loss: 0.9429
2024-07-11 15:59:38,113 [INFO    ] __main__: train step 3515: loss: 0.7128, policy_loss: 1.6405, value_loss: 0.9428
2024-07-11 15:59:38,372 [INFO    ] __main__: train step 3516: loss: 0.7129, policy_loss: 1.6404, value_loss: 0.9428
2024-07-11 15:59:38,864 [INFO    ] __main__: train step 3517: loss: 0.7130, policy_loss: 1.6403, value_loss: 0.9427
2024-07-11 15:59:39,072 [INFO    ] __main__: train step 3518: loss: 0.7132, policy_loss: 1.6402, value_loss: 0.9427
2024-07-11 15:59:40,508 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:59:40,924 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:59:40,984 [INFO    ] __main__: train step 3519: loss: 0.7133, policy_loss: 1.6400, value_loss: 0.9427
2024-07-11 15:59:41,154 [INFO    ] __main__: train step 3520: loss: 0.7134, policy_loss: 1.6399, value_loss: 0.9426
2024-07-11 15:59:41,369 [INFO    ] __main__: train step 3521: loss: 0.7135, policy_loss: 1.6398, value_loss: 0.9426
2024-07-11 15:59:41,603 [INFO    ] __main__: train step 3522: loss: 0.7137, policy_loss: 1.6397, value_loss: 0.9426
2024-07-11 15:59:41,814 [INFO    ] __main__: train step 3523: loss: 0.7138, policy_loss: 1.6396, value_loss: 0.9425
2024-07-11 15:59:42,010 [INFO    ] __main__: train step 3524: loss: 0.7139, policy_loss: 1.6394, value_loss: 0.9425
2024-07-11 15:59:42,213 [INFO    ] __main__: train step 3525: loss: 0.7140, policy_loss: 1.6393, value_loss: 0.9425
2024-07-11 15:59:42,403 [INFO    ] __main__: train step 3526: loss: 0.7142, policy_loss: 1.6392, value_loss: 0.9424
2024-07-11 15:59:42,607 [INFO    ] __main__: train step 3527: loss: 0.7143, policy_loss: 1.6391, value_loss: 0.9424
2024-07-11 15:59:42,817 [INFO    ] __main__: train step 3528: loss: 0.7144, policy_loss: 1.6390, value_loss: 0.9424
2024-07-11 15:59:43,017 [INFO    ] __main__: train step 3529: loss: 0.7146, policy_loss: 1.6388, value_loss: 0.9423
2024-07-11 15:59:43,223 [INFO    ] __main__: train step 3530: loss: 0.7147, policy_loss: 1.6387, value_loss: 0.9423
2024-07-11 15:59:43,425 [INFO    ] __main__: train step 3531: loss: 0.7148, policy_loss: 1.6386, value_loss: 0.9423
2024-07-11 15:59:43,626 [INFO    ] __main__: train step 3532: loss: 0.7149, policy_loss: 1.6385, value_loss: 0.9422
2024-07-11 15:59:43,840 [INFO    ] __main__: train step 3533: loss: 0.7151, policy_loss: 1.6384, value_loss: 0.9422
2024-07-11 15:59:44,037 [INFO    ] __main__: train step 3534: loss: 0.7152, policy_loss: 1.6383, value_loss: 0.9422
2024-07-11 15:59:44,241 [INFO    ] __main__: train step 3535: loss: 0.7153, policy_loss: 1.6381, value_loss: 0.9421
2024-07-11 15:59:45,693 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:59:46,093 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:59:46,151 [INFO    ] __main__: train step 3536: loss: 0.7155, policy_loss: 1.6380, value_loss: 0.9421
2024-07-11 15:59:46,332 [INFO    ] __main__: train step 3537: loss: 0.7156, policy_loss: 1.6379, value_loss: 0.9421
2024-07-11 15:59:46,570 [INFO    ] __main__: train step 3538: loss: 0.7157, policy_loss: 1.6378, value_loss: 0.9420
2024-07-11 15:59:46,805 [INFO    ] __main__: train step 3539: loss: 0.7158, policy_loss: 1.6377, value_loss: 0.9420
2024-07-11 15:59:47,275 [INFO    ] __main__: train step 3540: loss: 0.7160, policy_loss: 1.6376, value_loss: 0.9420
2024-07-11 15:59:47,518 [INFO    ] __main__: train step 3541: loss: 0.7161, policy_loss: 1.6374, value_loss: 0.9419
2024-07-11 15:59:47,757 [INFO    ] __main__: train step 3542: loss: 0.7162, policy_loss: 1.6373, value_loss: 0.9419
2024-07-11 15:59:47,958 [INFO    ] __main__: train step 3543: loss: 0.7163, policy_loss: 1.6372, value_loss: 0.9419
2024-07-11 15:59:48,156 [INFO    ] __main__: train step 3544: loss: 0.7165, policy_loss: 1.6371, value_loss: 0.9418
2024-07-11 15:59:48,356 [INFO    ] __main__: train step 3545: loss: 0.7166, policy_loss: 1.6370, value_loss: 0.9418
2024-07-11 15:59:48,542 [INFO    ] __main__: train step 3546: loss: 0.7167, policy_loss: 1.6369, value_loss: 0.9418
2024-07-11 15:59:48,739 [INFO    ] __main__: train step 3547: loss: 0.7168, policy_loss: 1.6367, value_loss: 0.9417
2024-07-11 15:59:48,946 [INFO    ] __main__: train step 3548: loss: 0.7170, policy_loss: 1.6366, value_loss: 0.9417
2024-07-11 15:59:49,152 [INFO    ] __main__: train step 3549: loss: 0.7171, policy_loss: 1.6365, value_loss: 0.9417
2024-07-11 15:59:49,356 [INFO    ] __main__: train step 3550: loss: 0.7172, policy_loss: 1.6364, value_loss: 0.9416
2024-07-11 15:59:49,554 [INFO    ] __main__: train step 3551: loss: 0.7173, policy_loss: 1.6363, value_loss: 0.9416
2024-07-11 15:59:49,764 [INFO    ] __main__: train step 3552: loss: 0.7175, policy_loss: 1.6361, value_loss: 0.9416
2024-07-11 15:59:51,203 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:59:51,603 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:59:51,658 [INFO    ] __main__: train step 3553: loss: 0.7176, policy_loss: 1.6360, value_loss: 0.9415
2024-07-11 15:59:51,856 [INFO    ] __main__: train step 3554: loss: 0.7177, policy_loss: 1.6359, value_loss: 0.9415
2024-07-11 15:59:52,065 [INFO    ] __main__: train step 3555: loss: 0.7179, policy_loss: 1.6358, value_loss: 0.9415
2024-07-11 15:59:52,281 [INFO    ] __main__: train step 3556: loss: 0.7180, policy_loss: 1.6357, value_loss: 0.9414
2024-07-11 15:59:52,513 [INFO    ] __main__: train step 3557: loss: 0.7181, policy_loss: 1.6356, value_loss: 0.9414
2024-07-11 15:59:52,715 [INFO    ] __main__: train step 3558: loss: 0.7182, policy_loss: 1.6354, value_loss: 0.9414
2024-07-11 15:59:52,917 [INFO    ] __main__: train step 3559: loss: 0.7184, policy_loss: 1.6353, value_loss: 0.9413
2024-07-11 15:59:53,122 [INFO    ] __main__: train step 3560: loss: 0.7185, policy_loss: 1.6352, value_loss: 0.9413
2024-07-11 15:59:53,326 [INFO    ] __main__: train step 3561: loss: 0.7186, policy_loss: 1.6351, value_loss: 0.9413
2024-07-11 15:59:53,823 [INFO    ] __main__: train step 3562: loss: 0.7187, policy_loss: 1.6350, value_loss: 0.9412
2024-07-11 15:59:54,027 [INFO    ] __main__: train step 3563: loss: 0.7189, policy_loss: 1.6348, value_loss: 0.9412
2024-07-11 15:59:54,230 [INFO    ] __main__: train step 3564: loss: 0.7190, policy_loss: 1.6347, value_loss: 0.9412
2024-07-11 15:59:54,444 [INFO    ] __main__: train step 3565: loss: 0.7191, policy_loss: 1.6346, value_loss: 0.9411
2024-07-11 15:59:54,636 [INFO    ] __main__: train step 3566: loss: 0.7192, policy_loss: 1.6345, value_loss: 0.9411
2024-07-11 15:59:54,844 [INFO    ] __main__: train step 3567: loss: 0.7194, policy_loss: 1.6344, value_loss: 0.9411
2024-07-11 15:59:55,038 [INFO    ] __main__: train step 3568: loss: 0.7195, policy_loss: 1.6342, value_loss: 0.9410
2024-07-11 15:59:55,242 [INFO    ] __main__: train step 3569: loss: 0.7196, policy_loss: 1.6341, value_loss: 0.9410
2024-07-11 15:59:56,701 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 15:59:57,111 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 15:59:57,165 [INFO    ] __main__: train step 3570: loss: 0.7197, policy_loss: 1.6340, value_loss: 0.9409
2024-07-11 15:59:57,334 [INFO    ] __main__: train step 3571: loss: 0.7199, policy_loss: 1.6339, value_loss: 0.9409
2024-07-11 15:59:57,527 [INFO    ] __main__: train step 3572: loss: 0.7200, policy_loss: 1.6338, value_loss: 0.9409
2024-07-11 15:59:57,732 [INFO    ] __main__: train step 3573: loss: 0.7201, policy_loss: 1.6337, value_loss: 0.9408
2024-07-11 15:59:57,942 [INFO    ] __main__: train step 3574: loss: 0.7202, policy_loss: 1.6335, value_loss: 0.9408
2024-07-11 15:59:58,136 [INFO    ] __main__: train step 3575: loss: 0.7204, policy_loss: 1.6334, value_loss: 0.9408
2024-07-11 15:59:58,339 [INFO    ] __main__: train step 3576: loss: 0.7205, policy_loss: 1.6333, value_loss: 0.9408
2024-07-11 15:59:58,587 [INFO    ] __main__: train step 3577: loss: 0.7206, policy_loss: 1.6332, value_loss: 0.9407
2024-07-11 15:59:58,813 [INFO    ] __main__: train step 3578: loss: 0.7208, policy_loss: 1.6331, value_loss: 0.9407
2024-07-11 15:59:59,018 [INFO    ] __main__: train step 3579: loss: 0.7209, policy_loss: 1.6330, value_loss: 0.9407
2024-07-11 15:59:59,224 [INFO    ] __main__: train step 3580: loss: 0.7210, policy_loss: 1.6328, value_loss: 0.9406
2024-07-11 15:59:59,428 [INFO    ] __main__: train step 3581: loss: 0.7211, policy_loss: 1.6327, value_loss: 0.9406
2024-07-11 15:59:59,666 [INFO    ] __main__: train step 3582: loss: 0.7213, policy_loss: 1.6326, value_loss: 0.9406
2024-07-11 15:59:59,901 [INFO    ] __main__: train step 3583: loss: 0.7214, policy_loss: 1.6325, value_loss: 0.9405
2024-07-11 16:00:00,093 [INFO    ] __main__: train step 3584: loss: 0.7215, policy_loss: 1.6324, value_loss: 0.9405
2024-07-11 16:00:00,289 [INFO    ] __main__: train step 3585: loss: 0.7216, policy_loss: 1.6323, value_loss: 0.9404
2024-07-11 16:00:00,759 [INFO    ] __main__: train step 3586: loss: 0.7218, policy_loss: 1.6321, value_loss: 0.9404
2024-07-11 16:00:02,203 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:00:02,621 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:00:02,678 [INFO    ] __main__: train step 3587: loss: 0.7219, policy_loss: 1.6320, value_loss: 0.9404
2024-07-11 16:00:02,858 [INFO    ] __main__: train step 3588: loss: 0.7220, policy_loss: 1.6319, value_loss: 0.9403
2024-07-11 16:00:03,062 [INFO    ] __main__: train step 3589: loss: 0.7221, policy_loss: 1.6318, value_loss: 0.9403
2024-07-11 16:00:03,285 [INFO    ] __main__: train step 3590: loss: 0.7223, policy_loss: 1.6317, value_loss: 0.9403
2024-07-11 16:00:03,489 [INFO    ] __main__: train step 3591: loss: 0.7224, policy_loss: 1.6315, value_loss: 0.9402
2024-07-11 16:00:03,702 [INFO    ] __main__: train step 3592: loss: 0.7225, policy_loss: 1.6314, value_loss: 0.9402
2024-07-11 16:00:03,895 [INFO    ] __main__: train step 3593: loss: 0.7226, policy_loss: 1.6313, value_loss: 0.9402
2024-07-11 16:00:04,098 [INFO    ] __main__: train step 3594: loss: 0.7228, policy_loss: 1.6312, value_loss: 0.9401
2024-07-11 16:00:04,303 [INFO    ] __main__: train step 3595: loss: 0.7229, policy_loss: 1.6311, value_loss: 0.9401
2024-07-11 16:00:04,498 [INFO    ] __main__: train step 3596: loss: 0.7230, policy_loss: 1.6309, value_loss: 0.9401
2024-07-11 16:00:04,742 [INFO    ] __main__: train step 3597: loss: 0.7231, policy_loss: 1.6308, value_loss: 0.9400
2024-07-11 16:00:04,956 [INFO    ] __main__: train step 3598: loss: 0.7233, policy_loss: 1.6307, value_loss: 0.9400
2024-07-11 16:00:05,166 [INFO    ] __main__: train step 3599: loss: 0.7234, policy_loss: 1.6306, value_loss: 0.9400
2024-07-11 16:00:05,376 [INFO    ] __main__: train step 3600: loss: 0.7235, policy_loss: 1.6305, value_loss: 0.9399
2024-07-11 16:00:05,574 [INFO    ] __main__: train step 3601: loss: 0.7236, policy_loss: 1.6303, value_loss: 0.9399
2024-07-11 16:00:05,779 [INFO    ] __main__: train step 3602: loss: 0.7237, policy_loss: 1.6302, value_loss: 0.9399
2024-07-11 16:00:05,978 [INFO    ] __main__: train step 3603: loss: 0.7239, policy_loss: 1.6301, value_loss: 0.9398
2024-07-11 16:00:07,414 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:00:07,775 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:00:07,830 [INFO    ] __main__: train step 3604: loss: 0.7240, policy_loss: 1.6300, value_loss: 0.9398
2024-07-11 16:00:08,011 [INFO    ] __main__: train step 3605: loss: 0.7241, policy_loss: 1.6299, value_loss: 0.9398
2024-07-11 16:00:08,212 [INFO    ] __main__: train step 3606: loss: 0.7242, policy_loss: 1.6298, value_loss: 0.9397
2024-07-11 16:00:08,425 [INFO    ] __main__: train step 3607: loss: 0.7244, policy_loss: 1.6296, value_loss: 0.9397
2024-07-11 16:00:08,665 [INFO    ] __main__: train step 3608: loss: 0.7245, policy_loss: 1.6295, value_loss: 0.9397
2024-07-11 16:00:09,160 [INFO    ] __main__: train step 3609: loss: 0.7246, policy_loss: 1.6294, value_loss: 0.9396
2024-07-11 16:00:09,371 [INFO    ] __main__: train step 3610: loss: 0.7248, policy_loss: 1.6293, value_loss: 0.9396
2024-07-11 16:00:09,569 [INFO    ] __main__: train step 3611: loss: 0.7249, policy_loss: 1.6292, value_loss: 0.9396
2024-07-11 16:00:09,783 [INFO    ] __main__: train step 3612: loss: 0.7250, policy_loss: 1.6291, value_loss: 0.9395
2024-07-11 16:00:09,987 [INFO    ] __main__: train step 3613: loss: 0.7251, policy_loss: 1.6289, value_loss: 0.9395
2024-07-11 16:00:10,194 [INFO    ] __main__: train step 3614: loss: 0.7253, policy_loss: 1.6288, value_loss: 0.9395
2024-07-11 16:00:10,391 [INFO    ] __main__: train step 3615: loss: 0.7254, policy_loss: 1.6287, value_loss: 0.9394
2024-07-11 16:00:10,611 [INFO    ] __main__: train step 3616: loss: 0.7255, policy_loss: 1.6286, value_loss: 0.9394
2024-07-11 16:00:10,848 [INFO    ] __main__: train step 3617: loss: 0.7256, policy_loss: 1.6285, value_loss: 0.9394
2024-07-11 16:00:11,072 [INFO    ] __main__: train step 3618: loss: 0.7258, policy_loss: 1.6284, value_loss: 0.9393
2024-07-11 16:00:11,310 [INFO    ] __main__: train step 3619: loss: 0.7259, policy_loss: 1.6283, value_loss: 0.9393
2024-07-11 16:00:11,508 [INFO    ] __main__: train step 3620: loss: 0.7260, policy_loss: 1.6281, value_loss: 0.9393
2024-07-11 16:00:12,942 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:00:13,361 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:00:13,424 [INFO    ] __main__: train step 3621: loss: 0.7261, policy_loss: 1.6280, value_loss: 0.9392
2024-07-11 16:00:13,606 [INFO    ] __main__: train step 3622: loss: 0.7263, policy_loss: 1.6279, value_loss: 0.9392
2024-07-11 16:00:13,846 [INFO    ] __main__: train step 3623: loss: 0.7264, policy_loss: 1.6278, value_loss: 0.9391
2024-07-11 16:00:14,043 [INFO    ] __main__: train step 3624: loss: 0.7265, policy_loss: 1.6277, value_loss: 0.9391
2024-07-11 16:00:14,241 [INFO    ] __main__: train step 3625: loss: 0.7266, policy_loss: 1.6276, value_loss: 0.9391
2024-07-11 16:00:14,445 [INFO    ] __main__: train step 3626: loss: 0.7267, policy_loss: 1.6274, value_loss: 0.9390
2024-07-11 16:00:14,678 [INFO    ] __main__: train step 3627: loss: 0.7269, policy_loss: 1.6273, value_loss: 0.9390
2024-07-11 16:00:14,908 [INFO    ] __main__: train step 3628: loss: 0.7270, policy_loss: 1.6272, value_loss: 0.9390
2024-07-11 16:00:15,113 [INFO    ] __main__: train step 3629: loss: 0.7271, policy_loss: 1.6271, value_loss: 0.9389
2024-07-11 16:00:15,346 [INFO    ] __main__: train step 3630: loss: 0.7272, policy_loss: 1.6270, value_loss: 0.9389
2024-07-11 16:00:15,554 [INFO    ] __main__: train step 3631: loss: 0.7274, policy_loss: 1.6269, value_loss: 0.9389
2024-07-11 16:00:16,059 [INFO    ] __main__: train step 3632: loss: 0.7275, policy_loss: 1.6267, value_loss: 0.9388
2024-07-11 16:00:16,269 [INFO    ] __main__: train step 3633: loss: 0.7276, policy_loss: 1.6266, value_loss: 0.9388
2024-07-11 16:00:16,471 [INFO    ] __main__: train step 3634: loss: 0.7277, policy_loss: 1.6265, value_loss: 0.9388
2024-07-11 16:00:16,685 [INFO    ] __main__: train step 3635: loss: 0.7279, policy_loss: 1.6264, value_loss: 0.9387
2024-07-11 16:00:16,910 [INFO    ] __main__: train step 3636: loss: 0.7280, policy_loss: 1.6263, value_loss: 0.9387
2024-07-11 16:00:17,118 [INFO    ] __main__: train step 3637: loss: 0.7281, policy_loss: 1.6262, value_loss: 0.9387
2024-07-11 16:00:18,571 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:00:18,981 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:00:19,044 [INFO    ] __main__: train step 3638: loss: 0.7282, policy_loss: 1.6260, value_loss: 0.9386
2024-07-11 16:00:19,213 [INFO    ] __main__: train step 3639: loss: 0.7284, policy_loss: 1.6259, value_loss: 0.9386
2024-07-11 16:00:19,418 [INFO    ] __main__: train step 3640: loss: 0.7285, policy_loss: 1.6258, value_loss: 0.9386
2024-07-11 16:00:19,619 [INFO    ] __main__: train step 3641: loss: 0.7286, policy_loss: 1.6257, value_loss: 0.9385
2024-07-11 16:00:19,821 [INFO    ] __main__: train step 3642: loss: 0.7287, policy_loss: 1.6256, value_loss: 0.9385
2024-07-11 16:00:20,042 [INFO    ] __main__: train step 3643: loss: 0.7289, policy_loss: 1.6255, value_loss: 0.9385
2024-07-11 16:00:20,258 [INFO    ] __main__: train step 3644: loss: 0.7290, policy_loss: 1.6253, value_loss: 0.9384
2024-07-11 16:00:20,464 [INFO    ] __main__: train step 3645: loss: 0.7291, policy_loss: 1.6252, value_loss: 0.9384
2024-07-11 16:00:20,678 [INFO    ] __main__: train step 3646: loss: 0.7292, policy_loss: 1.6251, value_loss: 0.9383
2024-07-11 16:00:20,915 [INFO    ] __main__: train step 3647: loss: 0.7293, policy_loss: 1.6250, value_loss: 0.9383
2024-07-11 16:00:21,119 [INFO    ] __main__: train step 3648: loss: 0.7295, policy_loss: 1.6249, value_loss: 0.9383
2024-07-11 16:00:21,319 [INFO    ] __main__: train step 3649: loss: 0.7296, policy_loss: 1.6248, value_loss: 0.9382
2024-07-11 16:00:21,522 [INFO    ] __main__: train step 3650: loss: 0.7297, policy_loss: 1.6246, value_loss: 0.9382
2024-07-11 16:00:21,728 [INFO    ] __main__: train step 3651: loss: 0.7299, policy_loss: 1.6245, value_loss: 0.9382
2024-07-11 16:00:21,930 [INFO    ] __main__: train step 3652: loss: 0.7300, policy_loss: 1.6244, value_loss: 0.9381
2024-07-11 16:00:22,123 [INFO    ] __main__: train step 3653: loss: 0.7301, policy_loss: 1.6243, value_loss: 0.9381
2024-07-11 16:00:22,329 [INFO    ] __main__: train step 3654: loss: 0.7302, policy_loss: 1.6242, value_loss: 0.9381
2024-07-11 16:00:23,764 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:00:24,126 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:00:24,184 [INFO    ] __main__: train step 3655: loss: 0.7304, policy_loss: 1.6241, value_loss: 0.9380
2024-07-11 16:00:24,633 [INFO    ] __main__: train step 3656: loss: 0.7305, policy_loss: 1.6239, value_loss: 0.9380
2024-07-11 16:00:24,844 [INFO    ] __main__: train step 3657: loss: 0.7306, policy_loss: 1.6238, value_loss: 0.9379
2024-07-11 16:00:25,045 [INFO    ] __main__: train step 3658: loss: 0.7307, policy_loss: 1.6237, value_loss: 0.9379
2024-07-11 16:00:25,246 [INFO    ] __main__: train step 3659: loss: 0.7309, policy_loss: 1.6236, value_loss: 0.9379
2024-07-11 16:00:25,455 [INFO    ] __main__: train step 3660: loss: 0.7310, policy_loss: 1.6235, value_loss: 0.9378
2024-07-11 16:00:25,667 [INFO    ] __main__: train step 3661: loss: 0.7311, policy_loss: 1.6234, value_loss: 0.9378
2024-07-11 16:00:25,860 [INFO    ] __main__: train step 3662: loss: 0.7312, policy_loss: 1.6232, value_loss: 0.9378
2024-07-11 16:00:26,066 [INFO    ] __main__: train step 3663: loss: 0.7314, policy_loss: 1.6231, value_loss: 0.9377
2024-07-11 16:00:26,264 [INFO    ] __main__: train step 3664: loss: 0.7315, policy_loss: 1.6230, value_loss: 0.9377
2024-07-11 16:00:26,471 [INFO    ] __main__: train step 3665: loss: 0.7316, policy_loss: 1.6229, value_loss: 0.9377
2024-07-11 16:00:26,677 [INFO    ] __main__: train step 3666: loss: 0.7317, policy_loss: 1.6228, value_loss: 0.9376
2024-07-11 16:00:26,881 [INFO    ] __main__: train step 3667: loss: 0.7318, policy_loss: 1.6227, value_loss: 0.9376
2024-07-11 16:00:27,084 [INFO    ] __main__: train step 3668: loss: 0.7320, policy_loss: 1.6225, value_loss: 0.9376
2024-07-11 16:00:27,286 [INFO    ] __main__: train step 3669: loss: 0.7321, policy_loss: 1.6224, value_loss: 0.9375
2024-07-11 16:00:27,494 [INFO    ] __main__: train step 3670: loss: 0.7322, policy_loss: 1.6223, value_loss: 0.9375
2024-07-11 16:00:27,689 [INFO    ] __main__: train step 3671: loss: 0.7323, policy_loss: 1.6222, value_loss: 0.9375
2024-07-11 16:00:29,132 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:00:29,525 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:00:29,580 [INFO    ] __main__: train step 3672: loss: 0.7324, policy_loss: 1.6221, value_loss: 0.9374
2024-07-11 16:00:29,752 [INFO    ] __main__: train step 3673: loss: 0.7326, policy_loss: 1.6219, value_loss: 0.9374
2024-07-11 16:00:29,950 [INFO    ] __main__: train step 3674: loss: 0.7327, policy_loss: 1.6218, value_loss: 0.9374
2024-07-11 16:00:30,169 [INFO    ] __main__: train step 3675: loss: 0.7328, policy_loss: 1.6217, value_loss: 0.9373
2024-07-11 16:00:30,381 [INFO    ] __main__: train step 3676: loss: 0.7329, policy_loss: 1.6216, value_loss: 0.9373
2024-07-11 16:00:30,582 [INFO    ] __main__: train step 3677: loss: 0.7330, policy_loss: 1.6215, value_loss: 0.9373
2024-07-11 16:00:30,786 [INFO    ] __main__: train step 3678: loss: 0.7332, policy_loss: 1.6214, value_loss: 0.9372
2024-07-11 16:00:31,271 [INFO    ] __main__: train step 3679: loss: 0.7333, policy_loss: 1.6212, value_loss: 0.9372
2024-07-11 16:00:31,489 [INFO    ] __main__: train step 3680: loss: 0.7334, policy_loss: 1.6211, value_loss: 0.9372
2024-07-11 16:00:31,722 [INFO    ] __main__: train step 3681: loss: 0.7335, policy_loss: 1.6210, value_loss: 0.9371
2024-07-11 16:00:31,964 [INFO    ] __main__: train step 3682: loss: 0.7336, policy_loss: 1.6209, value_loss: 0.9371
2024-07-11 16:00:32,171 [INFO    ] __main__: train step 3683: loss: 0.7338, policy_loss: 1.6208, value_loss: 0.9370
2024-07-11 16:00:32,395 [INFO    ] __main__: train step 3684: loss: 0.7339, policy_loss: 1.6206, value_loss: 0.9370
2024-07-11 16:00:32,641 [INFO    ] __main__: train step 3685: loss: 0.7340, policy_loss: 1.6205, value_loss: 0.9370
2024-07-11 16:00:32,870 [INFO    ] __main__: train step 3686: loss: 0.7342, policy_loss: 1.6204, value_loss: 0.9369
2024-07-11 16:00:33,074 [INFO    ] __main__: train step 3687: loss: 0.7343, policy_loss: 1.6203, value_loss: 0.9369
2024-07-11 16:00:33,273 [INFO    ] __main__: train step 3688: loss: 0.7344, policy_loss: 1.6202, value_loss: 0.9369
2024-07-11 16:00:34,716 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:00:35,193 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:00:35,252 [INFO    ] __main__: train step 3689: loss: 0.7345, policy_loss: 1.6201, value_loss: 0.9368
2024-07-11 16:00:35,432 [INFO    ] __main__: train step 3690: loss: 0.7347, policy_loss: 1.6199, value_loss: 0.9368
2024-07-11 16:00:35,621 [INFO    ] __main__: train step 3691: loss: 0.7348, policy_loss: 1.6198, value_loss: 0.9368
2024-07-11 16:00:35,814 [INFO    ] __main__: train step 3692: loss: 0.7349, policy_loss: 1.6197, value_loss: 0.9367
2024-07-11 16:00:36,026 [INFO    ] __main__: train step 3693: loss: 0.7350, policy_loss: 1.6196, value_loss: 0.9367
2024-07-11 16:00:36,213 [INFO    ] __main__: train step 3694: loss: 0.7351, policy_loss: 1.6195, value_loss: 0.9366
2024-07-11 16:00:36,419 [INFO    ] __main__: train step 3695: loss: 0.7353, policy_loss: 1.6194, value_loss: 0.9366
2024-07-11 16:00:36,620 [INFO    ] __main__: train step 3696: loss: 0.7354, policy_loss: 1.6193, value_loss: 0.9366
2024-07-11 16:00:36,819 [INFO    ] __main__: train step 3697: loss: 0.7355, policy_loss: 1.6191, value_loss: 0.9365
2024-07-11 16:00:37,027 [INFO    ] __main__: train step 3698: loss: 0.7356, policy_loss: 1.6190, value_loss: 0.9365
2024-07-11 16:00:37,227 [INFO    ] __main__: train step 3699: loss: 0.7358, policy_loss: 1.6189, value_loss: 0.9365
2024-07-11 16:00:37,430 [INFO    ] __main__: train step 3700: loss: 0.7359, policy_loss: 1.6188, value_loss: 0.9364
2024-07-11 16:00:37,660 [INFO    ] __main__: train step 3701: loss: 0.7360, policy_loss: 1.6187, value_loss: 0.9364
2024-07-11 16:00:37,906 [INFO    ] __main__: train step 3702: loss: 0.7361, policy_loss: 1.6186, value_loss: 0.9364
2024-07-11 16:00:38,432 [INFO    ] __main__: train step 3703: loss: 0.7362, policy_loss: 1.6184, value_loss: 0.9363
2024-07-11 16:00:38,625 [INFO    ] __main__: train step 3704: loss: 0.7364, policy_loss: 1.6183, value_loss: 0.9363
2024-07-11 16:00:38,832 [INFO    ] __main__: train step 3705: loss: 0.7365, policy_loss: 1.6182, value_loss: 0.9363
2024-07-11 16:00:40,275 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:00:40,696 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:00:40,762 [INFO    ] __main__: train step 3706: loss: 0.7366, policy_loss: 1.6181, value_loss: 0.9362
2024-07-11 16:00:40,946 [INFO    ] __main__: train step 3707: loss: 0.7367, policy_loss: 1.6180, value_loss: 0.9362
2024-07-11 16:00:41,141 [INFO    ] __main__: train step 3708: loss: 0.7368, policy_loss: 1.6178, value_loss: 0.9362
2024-07-11 16:00:41,355 [INFO    ] __main__: train step 3709: loss: 0.7370, policy_loss: 1.6177, value_loss: 0.9361
2024-07-11 16:00:41,596 [INFO    ] __main__: train step 3710: loss: 0.7371, policy_loss: 1.6176, value_loss: 0.9361
2024-07-11 16:00:41,790 [INFO    ] __main__: train step 3711: loss: 0.7372, policy_loss: 1.6175, value_loss: 0.9361
2024-07-11 16:00:41,991 [INFO    ] __main__: train step 3712: loss: 0.7373, policy_loss: 1.6174, value_loss: 0.9360
2024-07-11 16:00:42,197 [INFO    ] __main__: train step 3713: loss: 0.7374, policy_loss: 1.6173, value_loss: 0.9360
2024-07-11 16:00:42,406 [INFO    ] __main__: train step 3714: loss: 0.7376, policy_loss: 1.6171, value_loss: 0.9360
2024-07-11 16:00:42,600 [INFO    ] __main__: train step 3715: loss: 0.7377, policy_loss: 1.6170, value_loss: 0.9359
2024-07-11 16:00:42,805 [INFO    ] __main__: train step 3716: loss: 0.7378, policy_loss: 1.6169, value_loss: 0.9359
2024-07-11 16:00:43,013 [INFO    ] __main__: train step 3717: loss: 0.7379, policy_loss: 1.6168, value_loss: 0.9358
2024-07-11 16:00:43,205 [INFO    ] __main__: train step 3718: loss: 0.7380, policy_loss: 1.6167, value_loss: 0.9358
2024-07-11 16:00:43,414 [INFO    ] __main__: train step 3719: loss: 0.7382, policy_loss: 1.6166, value_loss: 0.9358
2024-07-11 16:00:43,627 [INFO    ] __main__: train step 3720: loss: 0.7383, policy_loss: 1.6164, value_loss: 0.9357
2024-07-11 16:00:43,864 [INFO    ] __main__: train step 3721: loss: 0.7384, policy_loss: 1.6163, value_loss: 0.9357
2024-07-11 16:00:44,076 [INFO    ] __main__: train step 3722: loss: 0.7385, policy_loss: 1.6162, value_loss: 0.9357
2024-07-11 16:00:45,507 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:00:45,895 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:00:45,950 [INFO    ] __main__: train step 3723: loss: 0.7386, policy_loss: 1.6161, value_loss: 0.9356
2024-07-11 16:00:46,125 [INFO    ] __main__: train step 3724: loss: 0.7388, policy_loss: 1.6160, value_loss: 0.9356
2024-07-11 16:00:46,322 [INFO    ] __main__: train step 3725: loss: 0.7389, policy_loss: 1.6158, value_loss: 0.9356
2024-07-11 16:00:46,799 [INFO    ] __main__: train step 3726: loss: 0.7390, policy_loss: 1.6157, value_loss: 0.9355
2024-07-11 16:00:47,015 [INFO    ] __main__: train step 3727: loss: 0.7391, policy_loss: 1.6156, value_loss: 0.9355
2024-07-11 16:00:47,216 [INFO    ] __main__: train step 3728: loss: 0.7393, policy_loss: 1.6155, value_loss: 0.9354
2024-07-11 16:00:47,424 [INFO    ] __main__: train step 3729: loss: 0.7394, policy_loss: 1.6154, value_loss: 0.9354
2024-07-11 16:00:47,623 [INFO    ] __main__: train step 3730: loss: 0.7395, policy_loss: 1.6153, value_loss: 0.9354
2024-07-11 16:00:47,839 [INFO    ] __main__: train step 3731: loss: 0.7396, policy_loss: 1.6151, value_loss: 0.9353
2024-07-11 16:00:48,050 [INFO    ] __main__: train step 3732: loss: 0.7397, policy_loss: 1.6150, value_loss: 0.9353
2024-07-11 16:00:48,249 [INFO    ] __main__: train step 3733: loss: 0.7399, policy_loss: 1.6149, value_loss: 0.9353
2024-07-11 16:00:48,454 [INFO    ] __main__: train step 3734: loss: 0.7400, policy_loss: 1.6148, value_loss: 0.9352
2024-07-11 16:00:48,653 [INFO    ] __main__: train step 3735: loss: 0.7401, policy_loss: 1.6147, value_loss: 0.9352
2024-07-11 16:00:48,854 [INFO    ] __main__: train step 3736: loss: 0.7402, policy_loss: 1.6146, value_loss: 0.9352
2024-07-11 16:00:49,056 [INFO    ] __main__: train step 3737: loss: 0.7403, policy_loss: 1.6144, value_loss: 0.9351
2024-07-11 16:00:49,258 [INFO    ] __main__: train step 3738: loss: 0.7405, policy_loss: 1.6143, value_loss: 0.9351
2024-07-11 16:00:49,458 [INFO    ] __main__: train step 3739: loss: 0.7406, policy_loss: 1.6142, value_loss: 0.9351
2024-07-11 16:00:50,896 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:00:51,315 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:00:51,380 [INFO    ] __main__: train step 3740: loss: 0.7407, policy_loss: 1.6141, value_loss: 0.9350
2024-07-11 16:00:51,547 [INFO    ] __main__: train step 3741: loss: 0.7408, policy_loss: 1.6140, value_loss: 0.9350
2024-07-11 16:00:51,751 [INFO    ] __main__: train step 3742: loss: 0.7409, policy_loss: 1.6139, value_loss: 0.9349
2024-07-11 16:00:51,961 [INFO    ] __main__: train step 3743: loss: 0.7410, policy_loss: 1.6137, value_loss: 0.9349
2024-07-11 16:00:52,160 [INFO    ] __main__: train step 3744: loss: 0.7412, policy_loss: 1.6136, value_loss: 0.9349
2024-07-11 16:00:52,352 [INFO    ] __main__: train step 3745: loss: 0.7413, policy_loss: 1.6135, value_loss: 0.9348
2024-07-11 16:00:52,560 [INFO    ] __main__: train step 3746: loss: 0.7414, policy_loss: 1.6134, value_loss: 0.9348
2024-07-11 16:00:52,759 [INFO    ] __main__: train step 3747: loss: 0.7415, policy_loss: 1.6133, value_loss: 0.9348
2024-07-11 16:00:52,963 [INFO    ] __main__: train step 3748: loss: 0.7417, policy_loss: 1.6132, value_loss: 0.9347
2024-07-11 16:00:53,466 [INFO    ] __main__: train step 3749: loss: 0.7418, policy_loss: 1.6130, value_loss: 0.9347
2024-07-11 16:00:53,680 [INFO    ] __main__: train step 3750: loss: 0.7419, policy_loss: 1.6129, value_loss: 0.9347
2024-07-11 16:00:53,873 [INFO    ] __main__: train step 3751: loss: 0.7420, policy_loss: 1.6128, value_loss: 0.9346
2024-07-11 16:00:54,087 [INFO    ] __main__: train step 3752: loss: 0.7422, policy_loss: 1.6127, value_loss: 0.9346
2024-07-11 16:00:54,285 [INFO    ] __main__: train step 3753: loss: 0.7423, policy_loss: 1.6126, value_loss: 0.9346
2024-07-11 16:00:54,483 [INFO    ] __main__: train step 3754: loss: 0.7424, policy_loss: 1.6125, value_loss: 0.9345
2024-07-11 16:00:54,672 [INFO    ] __main__: train step 3755: loss: 0.7425, policy_loss: 1.6123, value_loss: 0.9345
2024-07-11 16:00:54,881 [INFO    ] __main__: train step 3756: loss: 0.7426, policy_loss: 1.6122, value_loss: 0.9345
2024-07-11 16:00:56,327 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:00:56,744 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:00:56,805 [INFO    ] __main__: train step 3757: loss: 0.7427, policy_loss: 1.6121, value_loss: 0.9344
2024-07-11 16:00:56,970 [INFO    ] __main__: train step 3758: loss: 0.7429, policy_loss: 1.6120, value_loss: 0.9344
2024-07-11 16:00:57,167 [INFO    ] __main__: train step 3759: loss: 0.7430, policy_loss: 1.6119, value_loss: 0.9344
2024-07-11 16:00:57,376 [INFO    ] __main__: train step 3760: loss: 0.7431, policy_loss: 1.6118, value_loss: 0.9343
2024-07-11 16:00:57,572 [INFO    ] __main__: train step 3761: loss: 0.7432, policy_loss: 1.6116, value_loss: 0.9343
2024-07-11 16:00:57,770 [INFO    ] __main__: train step 3762: loss: 0.7433, policy_loss: 1.6115, value_loss: 0.9343
2024-07-11 16:00:57,972 [INFO    ] __main__: train step 3763: loss: 0.7435, policy_loss: 1.6114, value_loss: 0.9342
2024-07-11 16:00:58,165 [INFO    ] __main__: train step 3764: loss: 0.7436, policy_loss: 1.6113, value_loss: 0.9342
2024-07-11 16:00:58,374 [INFO    ] __main__: train step 3765: loss: 0.7437, policy_loss: 1.6112, value_loss: 0.9342
2024-07-11 16:00:58,578 [INFO    ] __main__: train step 3766: loss: 0.7438, policy_loss: 1.6110, value_loss: 0.9341
2024-07-11 16:00:58,815 [INFO    ] __main__: train step 3767: loss: 0.7439, policy_loss: 1.6109, value_loss: 0.9341
2024-07-11 16:00:59,035 [INFO    ] __main__: train step 3768: loss: 0.7441, policy_loss: 1.6108, value_loss: 0.9341
2024-07-11 16:00:59,238 [INFO    ] __main__: train step 3769: loss: 0.7442, policy_loss: 1.6107, value_loss: 0.9340
2024-07-11 16:00:59,452 [INFO    ] __main__: train step 3770: loss: 0.7443, policy_loss: 1.6106, value_loss: 0.9340
2024-07-11 16:00:59,651 [INFO    ] __main__: train step 3771: loss: 0.7444, policy_loss: 1.6105, value_loss: 0.9339
2024-07-11 16:00:59,844 [INFO    ] __main__: train step 3772: loss: 0.7445, policy_loss: 1.6103, value_loss: 0.9339
2024-07-11 16:01:00,323 [INFO    ] __main__: train step 3773: loss: 0.7447, policy_loss: 1.6102, value_loss: 0.9339
2024-07-11 16:01:01,756 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:01:02,144 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:01:02,199 [INFO    ] __main__: train step 3774: loss: 0.7448, policy_loss: 1.6101, value_loss: 0.9338
2024-07-11 16:01:02,379 [INFO    ] __main__: train step 3775: loss: 0.7449, policy_loss: 1.6100, value_loss: 0.9338
2024-07-11 16:01:02,576 [INFO    ] __main__: train step 3776: loss: 0.7450, policy_loss: 1.6099, value_loss: 0.9338
2024-07-11 16:01:02,770 [INFO    ] __main__: train step 3777: loss: 0.7451, policy_loss: 1.6098, value_loss: 0.9337
2024-07-11 16:01:02,971 [INFO    ] __main__: train step 3778: loss: 0.7453, policy_loss: 1.6096, value_loss: 0.9337
2024-07-11 16:01:03,172 [INFO    ] __main__: train step 3779: loss: 0.7454, policy_loss: 1.6095, value_loss: 0.9337
2024-07-11 16:01:03,376 [INFO    ] __main__: train step 3780: loss: 0.7455, policy_loss: 1.6094, value_loss: 0.9336
2024-07-11 16:01:03,573 [INFO    ] __main__: train step 3781: loss: 0.7456, policy_loss: 1.6093, value_loss: 0.9336
2024-07-11 16:01:03,773 [INFO    ] __main__: train step 3782: loss: 0.7457, policy_loss: 1.6092, value_loss: 0.9336
2024-07-11 16:01:03,969 [INFO    ] __main__: train step 3783: loss: 0.7459, policy_loss: 1.6090, value_loss: 0.9335
2024-07-11 16:01:04,167 [INFO    ] __main__: train step 3784: loss: 0.7460, policy_loss: 1.6089, value_loss: 0.9335
2024-07-11 16:01:04,366 [INFO    ] __main__: train step 3785: loss: 0.7461, policy_loss: 1.6088, value_loss: 0.9335
2024-07-11 16:01:04,573 [INFO    ] __main__: train step 3786: loss: 0.7462, policy_loss: 1.6087, value_loss: 0.9334
2024-07-11 16:01:04,778 [INFO    ] __main__: train step 3787: loss: 0.7463, policy_loss: 1.6086, value_loss: 0.9334
2024-07-11 16:01:04,987 [INFO    ] __main__: train step 3788: loss: 0.7464, policy_loss: 1.6085, value_loss: 0.9333
2024-07-11 16:01:05,181 [INFO    ] __main__: train step 3789: loss: 0.7466, policy_loss: 1.6083, value_loss: 0.9333
2024-07-11 16:01:05,382 [INFO    ] __main__: train step 3790: loss: 0.7467, policy_loss: 1.6082, value_loss: 0.9333
2024-07-11 16:01:06,837 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:01:07,202 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:01:07,260 [INFO    ] __main__: train step 3791: loss: 0.7468, policy_loss: 1.6081, value_loss: 0.9332
2024-07-11 16:01:07,431 [INFO    ] __main__: train step 3792: loss: 0.7469, policy_loss: 1.6080, value_loss: 0.9332
2024-07-11 16:01:07,645 [INFO    ] __main__: train step 3793: loss: 0.7470, policy_loss: 1.6079, value_loss: 0.9332
2024-07-11 16:01:07,849 [INFO    ] __main__: train step 3794: loss: 0.7472, policy_loss: 1.6077, value_loss: 0.9331
2024-07-11 16:01:08,044 [INFO    ] __main__: train step 3795: loss: 0.7473, policy_loss: 1.6076, value_loss: 0.9331
2024-07-11 16:01:08,526 [INFO    ] __main__: train step 3796: loss: 0.7474, policy_loss: 1.6075, value_loss: 0.9331
2024-07-11 16:01:08,744 [INFO    ] __main__: train step 3797: loss: 0.7475, policy_loss: 1.6074, value_loss: 0.9330
2024-07-11 16:01:08,945 [INFO    ] __main__: train step 3798: loss: 0.7476, policy_loss: 1.6073, value_loss: 0.9330
2024-07-11 16:01:09,149 [INFO    ] __main__: train step 3799: loss: 0.7477, policy_loss: 1.6072, value_loss: 0.9330
2024-07-11 16:01:09,367 [INFO    ] __main__: train step 3800: loss: 0.7479, policy_loss: 1.6070, value_loss: 0.9329
2024-07-11 16:01:09,565 [INFO    ] __main__: train step 3801: loss: 0.7480, policy_loss: 1.6069, value_loss: 0.9329
2024-07-11 16:01:09,771 [INFO    ] __main__: train step 3802: loss: 0.7481, policy_loss: 1.6068, value_loss: 0.9329
2024-07-11 16:01:10,010 [INFO    ] __main__: train step 3803: loss: 0.7482, policy_loss: 1.6067, value_loss: 0.9328
2024-07-11 16:01:10,206 [INFO    ] __main__: train step 3804: loss: 0.7483, policy_loss: 1.6066, value_loss: 0.9328
2024-07-11 16:01:10,416 [INFO    ] __main__: train step 3805: loss: 0.7485, policy_loss: 1.6065, value_loss: 0.9327
2024-07-11 16:01:10,665 [INFO    ] __main__: train step 3806: loss: 0.7486, policy_loss: 1.6063, value_loss: 0.9327
2024-07-11 16:01:10,867 [INFO    ] __main__: train step 3807: loss: 0.7487, policy_loss: 1.6062, value_loss: 0.9327
2024-07-11 16:01:12,323 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:01:12,726 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:01:12,783 [INFO    ] __main__: train step 3808: loss: 0.7488, policy_loss: 1.6061, value_loss: 0.9326
2024-07-11 16:01:12,953 [INFO    ] __main__: train step 3809: loss: 0.7489, policy_loss: 1.6060, value_loss: 0.9326
2024-07-11 16:01:13,159 [INFO    ] __main__: train step 3810: loss: 0.7491, policy_loss: 1.6059, value_loss: 0.9326
2024-07-11 16:01:13,369 [INFO    ] __main__: train step 3811: loss: 0.7492, policy_loss: 1.6058, value_loss: 0.9325
2024-07-11 16:01:13,559 [INFO    ] __main__: train step 3812: loss: 0.7493, policy_loss: 1.6056, value_loss: 0.9325
2024-07-11 16:01:13,755 [INFO    ] __main__: train step 3813: loss: 0.7494, policy_loss: 1.6055, value_loss: 0.9325
2024-07-11 16:01:13,971 [INFO    ] __main__: train step 3814: loss: 0.7495, policy_loss: 1.6054, value_loss: 0.9324
2024-07-11 16:01:14,166 [INFO    ] __main__: train step 3815: loss: 0.7497, policy_loss: 1.6053, value_loss: 0.9324
2024-07-11 16:01:14,383 [INFO    ] __main__: train step 3816: loss: 0.7498, policy_loss: 1.6052, value_loss: 0.9324
2024-07-11 16:01:14,580 [INFO    ] __main__: train step 3817: loss: 0.7499, policy_loss: 1.6051, value_loss: 0.9323
2024-07-11 16:01:14,783 [INFO    ] __main__: train step 3818: loss: 0.7500, policy_loss: 1.6049, value_loss: 0.9323
2024-07-11 16:01:15,252 [INFO    ] __main__: train step 3819: loss: 0.7501, policy_loss: 1.6048, value_loss: 0.9323
2024-07-11 16:01:15,484 [INFO    ] __main__: train step 3820: loss: 0.7503, policy_loss: 1.6047, value_loss: 0.9322
2024-07-11 16:01:15,692 [INFO    ] __main__: train step 3821: loss: 0.7504, policy_loss: 1.6046, value_loss: 0.9322
2024-07-11 16:01:15,901 [INFO    ] __main__: train step 3822: loss: 0.7505, policy_loss: 1.6045, value_loss: 0.9322
2024-07-11 16:01:16,095 [INFO    ] __main__: train step 3823: loss: 0.7506, policy_loss: 1.6044, value_loss: 0.9321
2024-07-11 16:01:16,296 [INFO    ] __main__: train step 3824: loss: 0.7507, policy_loss: 1.6043, value_loss: 0.9321
2024-07-11 16:01:17,727 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:01:18,123 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:01:18,177 [INFO    ] __main__: train step 3825: loss: 0.7509, policy_loss: 1.6041, value_loss: 0.9321
2024-07-11 16:01:18,356 [INFO    ] __main__: train step 3826: loss: 0.7510, policy_loss: 1.6040, value_loss: 0.9320
2024-07-11 16:01:18,553 [INFO    ] __main__: train step 3827: loss: 0.7511, policy_loss: 1.6039, value_loss: 0.9320
2024-07-11 16:01:18,749 [INFO    ] __main__: train step 3828: loss: 0.7512, policy_loss: 1.6038, value_loss: 0.9320
2024-07-11 16:01:18,945 [INFO    ] __main__: train step 3829: loss: 0.7513, policy_loss: 1.6037, value_loss: 0.9319
2024-07-11 16:01:19,143 [INFO    ] __main__: train step 3830: loss: 0.7515, policy_loss: 1.6036, value_loss: 0.9319
2024-07-11 16:01:19,341 [INFO    ] __main__: train step 3831: loss: 0.7516, policy_loss: 1.6034, value_loss: 0.9318
2024-07-11 16:01:19,538 [INFO    ] __main__: train step 3832: loss: 0.7517, policy_loss: 1.6033, value_loss: 0.9318
2024-07-11 16:01:19,734 [INFO    ] __main__: train step 3833: loss: 0.7518, policy_loss: 1.6032, value_loss: 0.9318
2024-07-11 16:01:19,955 [INFO    ] __main__: train step 3834: loss: 0.7519, policy_loss: 1.6031, value_loss: 0.9317
2024-07-11 16:01:20,183 [INFO    ] __main__: train step 3835: loss: 0.7521, policy_loss: 1.6030, value_loss: 0.9317
2024-07-11 16:01:20,409 [INFO    ] __main__: train step 3836: loss: 0.7522, policy_loss: 1.6029, value_loss: 0.9317
2024-07-11 16:01:20,622 [INFO    ] __main__: train step 3837: loss: 0.7523, policy_loss: 1.6028, value_loss: 0.9316
2024-07-11 16:01:20,825 [INFO    ] __main__: train step 3838: loss: 0.7524, policy_loss: 1.6026, value_loss: 0.9316
2024-07-11 16:01:21,024 [INFO    ] __main__: train step 3839: loss: 0.7525, policy_loss: 1.6025, value_loss: 0.9316
2024-07-11 16:01:21,216 [INFO    ] __main__: train step 3840: loss: 0.7527, policy_loss: 1.6024, value_loss: 0.9315
2024-07-11 16:01:21,416 [INFO    ] __main__: train step 3841: loss: 0.7528, policy_loss: 1.6023, value_loss: 0.9315
2024-07-11 16:01:23,128 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:01:23,526 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:01:23,592 [INFO    ] __main__: train step 3842: loss: 0.7529, policy_loss: 1.6022, value_loss: 0.9315
2024-07-11 16:01:23,761 [INFO    ] __main__: train step 3843: loss: 0.7530, policy_loss: 1.6021, value_loss: 0.9314
2024-07-11 16:01:23,961 [INFO    ] __main__: train step 3844: loss: 0.7531, policy_loss: 1.6019, value_loss: 0.9314
2024-07-11 16:01:24,178 [INFO    ] __main__: train step 3845: loss: 0.7533, policy_loss: 1.6018, value_loss: 0.9314
2024-07-11 16:01:24,374 [INFO    ] __main__: train step 3846: loss: 0.7534, policy_loss: 1.6017, value_loss: 0.9313
2024-07-11 16:01:24,577 [INFO    ] __main__: train step 3847: loss: 0.7535, policy_loss: 1.6016, value_loss: 0.9313
2024-07-11 16:01:24,782 [INFO    ] __main__: train step 3848: loss: 0.7536, policy_loss: 1.6015, value_loss: 0.9313
2024-07-11 16:01:24,985 [INFO    ] __main__: train step 3849: loss: 0.7537, policy_loss: 1.6014, value_loss: 0.9312
2024-07-11 16:01:25,194 [INFO    ] __main__: train step 3850: loss: 0.7538, policy_loss: 1.6012, value_loss: 0.9312
2024-07-11 16:01:25,399 [INFO    ] __main__: train step 3851: loss: 0.7540, policy_loss: 1.6011, value_loss: 0.9312
2024-07-11 16:01:25,604 [INFO    ] __main__: train step 3852: loss: 0.7541, policy_loss: 1.6010, value_loss: 0.9311
2024-07-11 16:01:25,810 [INFO    ] __main__: train step 3853: loss: 0.7542, policy_loss: 1.6009, value_loss: 0.9311
2024-07-11 16:01:26,009 [INFO    ] __main__: train step 3854: loss: 0.7543, policy_loss: 1.6008, value_loss: 0.9311
2024-07-11 16:01:26,198 [INFO    ] __main__: train step 3855: loss: 0.7544, policy_loss: 1.6007, value_loss: 0.9310
2024-07-11 16:01:26,416 [INFO    ] __main__: train step 3856: loss: 0.7545, policy_loss: 1.6005, value_loss: 0.9310
2024-07-11 16:01:26,644 [INFO    ] __main__: train step 3857: loss: 0.7547, policy_loss: 1.6004, value_loss: 0.9310
2024-07-11 16:01:26,847 [INFO    ] __main__: train step 3858: loss: 0.7548, policy_loss: 1.6003, value_loss: 0.9309
2024-07-11 16:01:28,288 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:01:28,687 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:01:28,747 [INFO    ] __main__: train step 3859: loss: 0.7549, policy_loss: 1.6002, value_loss: 0.9309
2024-07-11 16:01:28,928 [INFO    ] __main__: train step 3860: loss: 0.7550, policy_loss: 1.6001, value_loss: 0.9308
2024-07-11 16:01:29,154 [INFO    ] __main__: train step 3861: loss: 0.7551, policy_loss: 1.6000, value_loss: 0.9308
2024-07-11 16:01:29,357 [INFO    ] __main__: train step 3862: loss: 0.7553, policy_loss: 1.5999, value_loss: 0.9308
2024-07-11 16:01:29,574 [INFO    ] __main__: train step 3863: loss: 0.7554, policy_loss: 1.5998, value_loss: 0.9307
2024-07-11 16:01:29,781 [INFO    ] __main__: train step 3864: loss: 0.7555, policy_loss: 1.5996, value_loss: 0.9307
2024-07-11 16:01:29,990 [INFO    ] __main__: train step 3865: loss: 0.7556, policy_loss: 1.5995, value_loss: 0.9307
2024-07-11 16:01:30,486 [INFO    ] __main__: train step 3866: loss: 0.7558, policy_loss: 1.5994, value_loss: 0.9306
2024-07-11 16:01:30,694 [INFO    ] __main__: train step 3867: loss: 0.7559, policy_loss: 1.5993, value_loss: 0.9306
2024-07-11 16:01:30,902 [INFO    ] __main__: train step 3868: loss: 0.7560, policy_loss: 1.5992, value_loss: 0.9306
2024-07-11 16:01:31,106 [INFO    ] __main__: train step 3869: loss: 0.7561, policy_loss: 1.5991, value_loss: 0.9305
2024-07-11 16:01:31,300 [INFO    ] __main__: train step 3870: loss: 0.7562, policy_loss: 1.5989, value_loss: 0.9305
2024-07-11 16:01:31,512 [INFO    ] __main__: train step 3871: loss: 0.7563, policy_loss: 1.5988, value_loss: 0.9305
2024-07-11 16:01:31,715 [INFO    ] __main__: train step 3872: loss: 0.7565, policy_loss: 1.5987, value_loss: 0.9304
2024-07-11 16:01:31,930 [INFO    ] __main__: train step 3873: loss: 0.7566, policy_loss: 1.5986, value_loss: 0.9304
2024-07-11 16:01:32,123 [INFO    ] __main__: train step 3874: loss: 0.7567, policy_loss: 1.5985, value_loss: 0.9303
2024-07-11 16:01:32,333 [INFO    ] __main__: train step 3875: loss: 0.7568, policy_loss: 1.5984, value_loss: 0.9303
2024-07-11 16:01:33,765 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:01:34,018 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:01:34,071 [INFO    ] __main__: train step 3876: loss: 0.7569, policy_loss: 1.5983, value_loss: 0.9303
2024-07-11 16:01:34,241 [INFO    ] __main__: train step 3877: loss: 0.7571, policy_loss: 1.5981, value_loss: 0.9302
2024-07-11 16:01:34,454 [INFO    ] __main__: train step 3878: loss: 0.7572, policy_loss: 1.5980, value_loss: 0.9302
2024-07-11 16:01:34,670 [INFO    ] __main__: train step 3879: loss: 0.7573, policy_loss: 1.5979, value_loss: 0.9302
2024-07-11 16:01:34,889 [INFO    ] __main__: train step 3880: loss: 0.7574, policy_loss: 1.5978, value_loss: 0.9301
2024-07-11 16:01:35,087 [INFO    ] __main__: train step 3881: loss: 0.7575, policy_loss: 1.5977, value_loss: 0.9301
2024-07-11 16:01:35,300 [INFO    ] __main__: train step 3882: loss: 0.7577, policy_loss: 1.5976, value_loss: 0.9301
2024-07-11 16:01:35,516 [INFO    ] __main__: train step 3883: loss: 0.7578, policy_loss: 1.5975, value_loss: 0.9300
2024-07-11 16:01:35,759 [INFO    ] __main__: train step 3884: loss: 0.7579, policy_loss: 1.5973, value_loss: 0.9300
2024-07-11 16:01:35,966 [INFO    ] __main__: train step 3885: loss: 0.7580, policy_loss: 1.5972, value_loss: 0.9300
2024-07-11 16:01:36,169 [INFO    ] __main__: train step 3886: loss: 0.7581, policy_loss: 1.5971, value_loss: 0.9299
2024-07-11 16:01:36,374 [INFO    ] __main__: train step 3887: loss: 0.7583, policy_loss: 1.5970, value_loss: 0.9299
2024-07-11 16:01:36,586 [INFO    ] __main__: train step 3888: loss: 0.7584, policy_loss: 1.5969, value_loss: 0.9298
2024-07-11 16:01:36,784 [INFO    ] __main__: train step 3889: loss: 0.7585, policy_loss: 1.5968, value_loss: 0.9298
2024-07-11 16:01:37,269 [INFO    ] __main__: train step 3890: loss: 0.7586, policy_loss: 1.5966, value_loss: 0.9298
2024-07-11 16:01:37,491 [INFO    ] __main__: train step 3891: loss: 0.7587, policy_loss: 1.5965, value_loss: 0.9297
2024-07-11 16:01:37,698 [INFO    ] __main__: train step 3892: loss: 0.7588, policy_loss: 1.5964, value_loss: 0.9297
2024-07-11 16:01:39,153 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:01:39,525 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:01:39,579 [INFO    ] __main__: train step 3893: loss: 0.7590, policy_loss: 1.5963, value_loss: 0.9297
2024-07-11 16:01:39,747 [INFO    ] __main__: train step 3894: loss: 0.7591, policy_loss: 1.5962, value_loss: 0.9296
2024-07-11 16:01:39,946 [INFO    ] __main__: train step 3895: loss: 0.7592, policy_loss: 1.5961, value_loss: 0.9296
2024-07-11 16:01:40,178 [INFO    ] __main__: train step 3896: loss: 0.7593, policy_loss: 1.5959, value_loss: 0.9295
2024-07-11 16:01:40,413 [INFO    ] __main__: train step 3897: loss: 0.7594, policy_loss: 1.5958, value_loss: 0.9295
2024-07-11 16:01:40,637 [INFO    ] __main__: train step 3898: loss: 0.7595, policy_loss: 1.5957, value_loss: 0.9295
2024-07-11 16:01:40,858 [INFO    ] __main__: train step 3899: loss: 0.7597, policy_loss: 1.5956, value_loss: 0.9294
2024-07-11 16:01:41,077 [INFO    ] __main__: train step 3900: loss: 0.7598, policy_loss: 1.5955, value_loss: 0.9294
2024-07-11 16:01:41,313 [INFO    ] __main__: train step 3901: loss: 0.7599, policy_loss: 1.5954, value_loss: 0.9294
2024-07-11 16:01:41,535 [INFO    ] __main__: train step 3902: loss: 0.7600, policy_loss: 1.5953, value_loss: 0.9293
2024-07-11 16:01:41,731 [INFO    ] __main__: train step 3903: loss: 0.7601, policy_loss: 1.5951, value_loss: 0.9293
2024-07-11 16:01:41,927 [INFO    ] __main__: train step 3904: loss: 0.7603, policy_loss: 1.5950, value_loss: 0.9293
2024-07-11 16:01:42,128 [INFO    ] __main__: train step 3905: loss: 0.7604, policy_loss: 1.5949, value_loss: 0.9292
2024-07-11 16:01:42,343 [INFO    ] __main__: train step 3906: loss: 0.7605, policy_loss: 1.5948, value_loss: 0.9292
2024-07-11 16:01:42,564 [INFO    ] __main__: train step 3907: loss: 0.7606, policy_loss: 1.5947, value_loss: 0.9292
2024-07-11 16:01:42,765 [INFO    ] __main__: train step 3908: loss: 0.7607, policy_loss: 1.5946, value_loss: 0.9291
2024-07-11 16:01:42,962 [INFO    ] __main__: train step 3909: loss: 0.7609, policy_loss: 1.5945, value_loss: 0.9291
2024-07-11 16:01:44,412 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:01:44,762 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:01:44,819 [INFO    ] __main__: train step 3910: loss: 0.7610, policy_loss: 1.5943, value_loss: 0.9290
2024-07-11 16:01:44,985 [INFO    ] __main__: train step 3911: loss: 0.7611, policy_loss: 1.5942, value_loss: 0.9290
2024-07-11 16:01:45,182 [INFO    ] __main__: train step 3912: loss: 0.7612, policy_loss: 1.5941, value_loss: 0.9290
2024-07-11 16:01:45,380 [INFO    ] __main__: train step 3913: loss: 0.7613, policy_loss: 1.5940, value_loss: 0.9289
2024-07-11 16:01:45,852 [INFO    ] __main__: train step 3914: loss: 0.7614, policy_loss: 1.5939, value_loss: 0.9289
2024-07-11 16:01:46,057 [INFO    ] __main__: train step 3915: loss: 0.7616, policy_loss: 1.5938, value_loss: 0.9289
2024-07-11 16:01:46,259 [INFO    ] __main__: train step 3916: loss: 0.7617, policy_loss: 1.5937, value_loss: 0.9288
2024-07-11 16:01:46,466 [INFO    ] __main__: train step 3917: loss: 0.7618, policy_loss: 1.5935, value_loss: 0.9288
2024-07-11 16:01:46,692 [INFO    ] __main__: train step 3918: loss: 0.7619, policy_loss: 1.5934, value_loss: 0.9288
2024-07-11 16:01:46,884 [INFO    ] __main__: train step 3919: loss: 0.7620, policy_loss: 1.5933, value_loss: 0.9287
2024-07-11 16:01:47,090 [INFO    ] __main__: train step 3920: loss: 0.7621, policy_loss: 1.5932, value_loss: 0.9287
2024-07-11 16:01:47,318 [INFO    ] __main__: train step 3921: loss: 0.7622, policy_loss: 1.5931, value_loss: 0.9287
2024-07-11 16:01:47,530 [INFO    ] __main__: train step 3922: loss: 0.7624, policy_loss: 1.5929, value_loss: 0.9286
2024-07-11 16:01:47,733 [INFO    ] __main__: train step 3923: loss: 0.7625, policy_loss: 1.5928, value_loss: 0.9286
2024-07-11 16:01:47,967 [INFO    ] __main__: train step 3924: loss: 0.7626, policy_loss: 1.5927, value_loss: 0.9285
2024-07-11 16:01:48,173 [INFO    ] __main__: train step 3925: loss: 0.7627, policy_loss: 1.5926, value_loss: 0.9285
2024-07-11 16:01:48,383 [INFO    ] __main__: train step 3926: loss: 0.7628, policy_loss: 1.5925, value_loss: 0.9285
2024-07-11 16:01:49,821 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:01:50,179 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:01:50,237 [INFO    ] __main__: train step 3927: loss: 0.7630, policy_loss: 1.5924, value_loss: 0.9284
2024-07-11 16:01:50,440 [INFO    ] __main__: train step 3928: loss: 0.7631, policy_loss: 1.5923, value_loss: 0.9284
2024-07-11 16:01:50,681 [INFO    ] __main__: train step 3929: loss: 0.7632, policy_loss: 1.5921, value_loss: 0.9284
2024-07-11 16:01:50,898 [INFO    ] __main__: train step 3930: loss: 0.7633, policy_loss: 1.5920, value_loss: 0.9283
2024-07-11 16:01:51,099 [INFO    ] __main__: train step 3931: loss: 0.7634, policy_loss: 1.5919, value_loss: 0.9283
2024-07-11 16:01:51,297 [INFO    ] __main__: train step 3932: loss: 0.7635, policy_loss: 1.5918, value_loss: 0.9283
2024-07-11 16:01:51,499 [INFO    ] __main__: train step 3933: loss: 0.7637, policy_loss: 1.5917, value_loss: 0.9282
2024-07-11 16:01:51,701 [INFO    ] __main__: train step 3934: loss: 0.7638, policy_loss: 1.5916, value_loss: 0.9282
2024-07-11 16:01:51,899 [INFO    ] __main__: train step 3935: loss: 0.7639, policy_loss: 1.5914, value_loss: 0.9282
2024-07-11 16:01:52,095 [INFO    ] __main__: train step 3936: loss: 0.7640, policy_loss: 1.5913, value_loss: 0.9281
2024-07-11 16:01:52,571 [INFO    ] __main__: train step 3937: loss: 0.7641, policy_loss: 1.5912, value_loss: 0.9281
2024-07-11 16:01:52,784 [INFO    ] __main__: train step 3938: loss: 0.7643, policy_loss: 1.5911, value_loss: 0.9281
2024-07-11 16:01:52,983 [INFO    ] __main__: train step 3939: loss: 0.7644, policy_loss: 1.5910, value_loss: 0.9280
2024-07-11 16:01:53,236 [INFO    ] __main__: train step 3940: loss: 0.7645, policy_loss: 1.5909, value_loss: 0.9280
2024-07-11 16:01:53,481 [INFO    ] __main__: train step 3941: loss: 0.7646, policy_loss: 1.5908, value_loss: 0.9280
2024-07-11 16:01:53,713 [INFO    ] __main__: train step 3942: loss: 0.7647, policy_loss: 1.5906, value_loss: 0.9279
2024-07-11 16:01:53,915 [INFO    ] __main__: train step 3943: loss: 0.7648, policy_loss: 1.5905, value_loss: 0.9279
2024-07-11 16:01:55,344 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:01:55,796 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:01:55,853 [INFO    ] __main__: train step 3944: loss: 0.7650, policy_loss: 1.5904, value_loss: 0.9278
2024-07-11 16:01:56,031 [INFO    ] __main__: train step 3945: loss: 0.7651, policy_loss: 1.5903, value_loss: 0.9278
2024-07-11 16:01:56,227 [INFO    ] __main__: train step 3946: loss: 0.7652, policy_loss: 1.5902, value_loss: 0.9278
2024-07-11 16:01:56,466 [INFO    ] __main__: train step 3947: loss: 0.7653, policy_loss: 1.5901, value_loss: 0.9277
2024-07-11 16:01:56,693 [INFO    ] __main__: train step 3948: loss: 0.7654, policy_loss: 1.5899, value_loss: 0.9277
2024-07-11 16:01:56,899 [INFO    ] __main__: train step 3949: loss: 0.7656, policy_loss: 1.5898, value_loss: 0.9277
2024-07-11 16:01:57,099 [INFO    ] __main__: train step 3950: loss: 0.7657, policy_loss: 1.5897, value_loss: 0.9276
2024-07-11 16:01:57,345 [INFO    ] __main__: train step 3951: loss: 0.7658, policy_loss: 1.5896, value_loss: 0.9276
2024-07-11 16:01:57,566 [INFO    ] __main__: train step 3952: loss: 0.7659, policy_loss: 1.5895, value_loss: 0.9276
2024-07-11 16:01:57,773 [INFO    ] __main__: train step 3953: loss: 0.7660, policy_loss: 1.5894, value_loss: 0.9275
2024-07-11 16:01:57,978 [INFO    ] __main__: train step 3954: loss: 0.7661, policy_loss: 1.5893, value_loss: 0.9275
2024-07-11 16:01:58,196 [INFO    ] __main__: train step 3955: loss: 0.7663, policy_loss: 1.5891, value_loss: 0.9275
2024-07-11 16:01:58,427 [INFO    ] __main__: train step 3956: loss: 0.7664, policy_loss: 1.5890, value_loss: 0.9274
2024-07-11 16:01:58,644 [INFO    ] __main__: train step 3957: loss: 0.7665, policy_loss: 1.5889, value_loss: 0.9274
2024-07-11 16:01:58,887 [INFO    ] __main__: train step 3958: loss: 0.7666, policy_loss: 1.5888, value_loss: 0.9274
2024-07-11 16:01:59,121 [INFO    ] __main__: train step 3959: loss: 0.7667, policy_loss: 1.5887, value_loss: 0.9273
2024-07-11 16:01:59,329 [INFO    ] __main__: train step 3960: loss: 0.7669, policy_loss: 1.5886, value_loss: 0.9273
2024-07-11 16:02:01,066 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:02:01,460 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:02:01,521 [INFO    ] __main__: train step 3961: loss: 0.7670, policy_loss: 1.5885, value_loss: 0.9272
2024-07-11 16:02:01,704 [INFO    ] __main__: train step 3962: loss: 0.7671, policy_loss: 1.5883, value_loss: 0.9272
2024-07-11 16:02:01,910 [INFO    ] __main__: train step 3963: loss: 0.7672, policy_loss: 1.5882, value_loss: 0.9272
2024-07-11 16:02:02,142 [INFO    ] __main__: train step 3964: loss: 0.7673, policy_loss: 1.5881, value_loss: 0.9271
2024-07-11 16:02:02,338 [INFO    ] __main__: train step 3965: loss: 0.7674, policy_loss: 1.5880, value_loss: 0.9271
2024-07-11 16:02:02,544 [INFO    ] __main__: train step 3966: loss: 0.7676, policy_loss: 1.5879, value_loss: 0.9271
2024-07-11 16:02:02,752 [INFO    ] __main__: train step 3967: loss: 0.7677, policy_loss: 1.5878, value_loss: 0.9270
2024-07-11 16:02:02,954 [INFO    ] __main__: train step 3968: loss: 0.7678, policy_loss: 1.5876, value_loss: 0.9270
2024-07-11 16:02:03,156 [INFO    ] __main__: train step 3969: loss: 0.7679, policy_loss: 1.5875, value_loss: 0.9270
2024-07-11 16:02:03,357 [INFO    ] __main__: train step 3970: loss: 0.7681, policy_loss: 1.5874, value_loss: 0.9269
2024-07-11 16:02:03,564 [INFO    ] __main__: train step 3971: loss: 0.7682, policy_loss: 1.5873, value_loss: 0.9269
2024-07-11 16:02:03,760 [INFO    ] __main__: train step 3972: loss: 0.7683, policy_loss: 1.5872, value_loss: 0.9269
2024-07-11 16:02:03,965 [INFO    ] __main__: train step 3973: loss: 0.7684, policy_loss: 1.5871, value_loss: 0.9268
2024-07-11 16:02:04,155 [INFO    ] __main__: train step 3974: loss: 0.7685, policy_loss: 1.5870, value_loss: 0.9268
2024-07-11 16:02:04,360 [INFO    ] __main__: train step 3975: loss: 0.7687, policy_loss: 1.5868, value_loss: 0.9268
2024-07-11 16:02:04,569 [INFO    ] __main__: train step 3976: loss: 0.7688, policy_loss: 1.5867, value_loss: 0.9267
2024-07-11 16:02:04,810 [INFO    ] __main__: train step 3977: loss: 0.7689, policy_loss: 1.5866, value_loss: 0.9267
2024-07-11 16:02:06,250 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:02:06,618 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:02:06,674 [INFO    ] __main__: train step 3978: loss: 0.7690, policy_loss: 1.5865, value_loss: 0.9267
2024-07-11 16:02:06,839 [INFO    ] __main__: train step 3979: loss: 0.7691, policy_loss: 1.5864, value_loss: 0.9266
2024-07-11 16:02:07,051 [INFO    ] __main__: train step 3980: loss: 0.7692, policy_loss: 1.5863, value_loss: 0.9266
2024-07-11 16:02:07,250 [INFO    ] __main__: train step 3981: loss: 0.7694, policy_loss: 1.5862, value_loss: 0.9266
2024-07-11 16:02:07,442 [INFO    ] __main__: train step 3982: loss: 0.7695, policy_loss: 1.5860, value_loss: 0.9265
2024-07-11 16:02:07,947 [INFO    ] __main__: train step 3983: loss: 0.7696, policy_loss: 1.5859, value_loss: 0.9265
2024-07-11 16:02:08,153 [INFO    ] __main__: train step 3984: loss: 0.7697, policy_loss: 1.5858, value_loss: 0.9264
2024-07-11 16:02:08,367 [INFO    ] __main__: train step 3985: loss: 0.7698, policy_loss: 1.5857, value_loss: 0.9264
2024-07-11 16:02:08,578 [INFO    ] __main__: train step 3986: loss: 0.7699, policy_loss: 1.5856, value_loss: 0.9264
2024-07-11 16:02:08,783 [INFO    ] __main__: train step 3987: loss: 0.7701, policy_loss: 1.5855, value_loss: 0.9263
2024-07-11 16:02:08,973 [INFO    ] __main__: train step 3988: loss: 0.7702, policy_loss: 1.5854, value_loss: 0.9263
2024-07-11 16:02:09,170 [INFO    ] __main__: train step 3989: loss: 0.7703, policy_loss: 1.5852, value_loss: 0.9263
2024-07-11 16:02:09,382 [INFO    ] __main__: train step 3990: loss: 0.7704, policy_loss: 1.5851, value_loss: 0.9262
2024-07-11 16:02:09,589 [INFO    ] __main__: train step 3991: loss: 0.7705, policy_loss: 1.5850, value_loss: 0.9262
2024-07-11 16:02:09,803 [INFO    ] __main__: train step 3992: loss: 0.7706, policy_loss: 1.5849, value_loss: 0.9262
2024-07-11 16:02:10,000 [INFO    ] __main__: train step 3993: loss: 0.7707, policy_loss: 1.5848, value_loss: 0.9261
2024-07-11 16:02:10,203 [INFO    ] __main__: train step 3994: loss: 0.7708, policy_loss: 1.5847, value_loss: 0.9261
2024-07-11 16:02:11,638 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:02:12,061 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:02:12,115 [INFO    ] __main__: train step 3995: loss: 0.7710, policy_loss: 1.5845, value_loss: 0.9261
2024-07-11 16:02:12,291 [INFO    ] __main__: train step 3996: loss: 0.7711, policy_loss: 1.5844, value_loss: 0.9260
2024-07-11 16:02:12,495 [INFO    ] __main__: train step 3997: loss: 0.7712, policy_loss: 1.5843, value_loss: 0.9260
2024-07-11 16:02:12,703 [INFO    ] __main__: train step 3998: loss: 0.7713, policy_loss: 1.5842, value_loss: 0.9260
2024-07-11 16:02:12,918 [INFO    ] __main__: train step 3999: loss: 0.7714, policy_loss: 1.5841, value_loss: 0.9259
2024-07-11 16:02:13,121 [INFO    ] __main__: train step 4000: loss: 0.7715, policy_loss: 1.5840, value_loss: 0.9259
2024-07-11 16:02:13,239 [INFO    ] __main__: restored step 3000 for evaluation
2024-07-11 16:02:20,830 [INFO    ] __main__: later network ELO difference from earlier network: +238 (+8/-8) ELO from 32000 self-played games
2024-07-11 16:02:20,830 [INFO    ] __main__: game outcomes: W: 24072, D: 335, L: 7593
2024-07-11 16:02:20,831 [INFO    ] __main__: validation_elo_delta: 238, validation_elo: 992
2024-07-11 16:02:21,326 [INFO    ] __main__: train step 4001: loss: 0.7717, policy_loss: 1.5839, value_loss: 0.9258
2024-07-11 16:02:21,549 [INFO    ] __main__: train step 4002: loss: 0.7718, policy_loss: 1.5837, value_loss: 0.9258
2024-07-11 16:02:21,781 [INFO    ] __main__: train step 4003: loss: 0.7719, policy_loss: 1.5836, value_loss: 0.9258
2024-07-11 16:02:22,260 [INFO    ] __main__: train step 4004: loss: 0.7720, policy_loss: 1.5835, value_loss: 0.9257
2024-07-11 16:02:22,462 [INFO    ] __main__: train step 4005: loss: 0.7721, policy_loss: 1.5834, value_loss: 0.9257
2024-07-11 16:02:22,704 [INFO    ] __main__: train step 4006: loss: 0.7723, policy_loss: 1.5833, value_loss: 0.9257
2024-07-11 16:02:22,908 [INFO    ] __main__: train step 4007: loss: 0.7724, policy_loss: 1.5832, value_loss: 0.9256
2024-07-11 16:02:23,114 [INFO    ] __main__: train step 4008: loss: 0.7725, policy_loss: 1.5831, value_loss: 0.9256
2024-07-11 16:02:23,330 [INFO    ] __main__: train step 4009: loss: 0.7726, policy_loss: 1.5830, value_loss: 0.9256
2024-07-11 16:02:23,534 [INFO    ] __main__: train step 4010: loss: 0.7727, policy_loss: 1.5828, value_loss: 0.9255
2024-07-11 16:02:23,743 [INFO    ] __main__: train step 4011: loss: 0.7729, policy_loss: 1.5827, value_loss: 0.9255
2024-07-11 16:02:25,186 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:02:25,579 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:02:25,640 [INFO    ] __main__: train step 4012: loss: 0.7730, policy_loss: 1.5826, value_loss: 0.9255
2024-07-11 16:02:25,819 [INFO    ] __main__: train step 4013: loss: 0.7731, policy_loss: 1.5825, value_loss: 0.9254
2024-07-11 16:02:26,038 [INFO    ] __main__: train step 4014: loss: 0.7732, policy_loss: 1.5824, value_loss: 0.9254
2024-07-11 16:02:26,267 [INFO    ] __main__: train step 4015: loss: 0.7733, policy_loss: 1.5823, value_loss: 0.9254
2024-07-11 16:02:26,476 [INFO    ] __main__: train step 4016: loss: 0.7734, policy_loss: 1.5822, value_loss: 0.9253
2024-07-11 16:02:26,676 [INFO    ] __main__: train step 4017: loss: 0.7735, policy_loss: 1.5820, value_loss: 0.9253
2024-07-11 16:02:26,875 [INFO    ] __main__: train step 4018: loss: 0.7736, policy_loss: 1.5819, value_loss: 0.9253
2024-07-11 16:02:27,078 [INFO    ] __main__: train step 4019: loss: 0.7738, policy_loss: 1.5818, value_loss: 0.9252
2024-07-11 16:02:27,275 [INFO    ] __main__: train step 4020: loss: 0.7739, policy_loss: 1.5817, value_loss: 0.9252
2024-07-11 16:02:27,467 [INFO    ] __main__: train step 4021: loss: 0.7740, policy_loss: 1.5816, value_loss: 0.9251
2024-07-11 16:02:27,675 [INFO    ] __main__: train step 4022: loss: 0.7741, policy_loss: 1.5815, value_loss: 0.9251
2024-07-11 16:02:27,869 [INFO    ] __main__: train step 4023: loss: 0.7742, policy_loss: 1.5814, value_loss: 0.9251
2024-07-11 16:02:28,069 [INFO    ] __main__: train step 4024: loss: 0.7743, policy_loss: 1.5812, value_loss: 0.9250
2024-07-11 16:02:28,267 [INFO    ] __main__: train step 4025: loss: 0.7745, policy_loss: 1.5811, value_loss: 0.9250
2024-07-11 16:02:28,467 [INFO    ] __main__: train step 4026: loss: 0.7746, policy_loss: 1.5810, value_loss: 0.9250
2024-07-11 16:02:28,664 [INFO    ] __main__: train step 4027: loss: 0.7747, policy_loss: 1.5809, value_loss: 0.9249
2024-07-11 16:02:29,159 [INFO    ] __main__: train step 4028: loss: 0.7748, policy_loss: 1.5808, value_loss: 0.9249
2024-07-11 16:02:30,606 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:02:30,980 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:02:31,035 [INFO    ] __main__: train step 4029: loss: 0.7749, policy_loss: 1.5807, value_loss: 0.9249
2024-07-11 16:02:31,202 [INFO    ] __main__: train step 4030: loss: 0.7750, policy_loss: 1.5806, value_loss: 0.9248
2024-07-11 16:02:31,411 [INFO    ] __main__: train step 4031: loss: 0.7752, policy_loss: 1.5804, value_loss: 0.9248
2024-07-11 16:02:31,612 [INFO    ] __main__: train step 4032: loss: 0.7753, policy_loss: 1.5803, value_loss: 0.9247
2024-07-11 16:02:31,831 [INFO    ] __main__: train step 4033: loss: 0.7754, policy_loss: 1.5802, value_loss: 0.9247
2024-07-11 16:02:32,050 [INFO    ] __main__: train step 4034: loss: 0.7755, policy_loss: 1.5801, value_loss: 0.9247
2024-07-11 16:02:32,251 [INFO    ] __main__: train step 4035: loss: 0.7756, policy_loss: 1.5800, value_loss: 0.9246
2024-07-11 16:02:32,467 [INFO    ] __main__: train step 4036: loss: 0.7757, policy_loss: 1.5799, value_loss: 0.9246
2024-07-11 16:02:32,675 [INFO    ] __main__: train step 4037: loss: 0.7758, policy_loss: 1.5798, value_loss: 0.9246
2024-07-11 16:02:32,907 [INFO    ] __main__: train step 4038: loss: 0.7759, policy_loss: 1.5796, value_loss: 0.9245
2024-07-11 16:02:33,114 [INFO    ] __main__: train step 4039: loss: 0.7761, policy_loss: 1.5795, value_loss: 0.9245
2024-07-11 16:02:33,309 [INFO    ] __main__: train step 4040: loss: 0.7762, policy_loss: 1.5794, value_loss: 0.9245
2024-07-11 16:02:33,501 [INFO    ] __main__: train step 4041: loss: 0.7763, policy_loss: 1.5793, value_loss: 0.9244
2024-07-11 16:02:33,700 [INFO    ] __main__: train step 4042: loss: 0.7764, policy_loss: 1.5792, value_loss: 0.9244
2024-07-11 16:02:33,909 [INFO    ] __main__: train step 4043: loss: 0.7765, policy_loss: 1.5791, value_loss: 0.9244
2024-07-11 16:02:34,124 [INFO    ] __main__: train step 4044: loss: 0.7766, policy_loss: 1.5790, value_loss: 0.9243
2024-07-11 16:02:34,317 [INFO    ] __main__: train step 4045: loss: 0.7768, policy_loss: 1.5789, value_loss: 0.9243
2024-07-11 16:02:35,757 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:02:36,141 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:02:36,195 [INFO    ] __main__: train step 4046: loss: 0.7769, policy_loss: 1.5787, value_loss: 0.9242
2024-07-11 16:02:36,373 [INFO    ] __main__: train step 4047: loss: 0.7770, policy_loss: 1.5786, value_loss: 0.9242
2024-07-11 16:02:36,571 [INFO    ] __main__: train step 4048: loss: 0.7771, policy_loss: 1.5785, value_loss: 0.9242
2024-07-11 16:02:36,782 [INFO    ] __main__: train step 4049: loss: 0.7772, policy_loss: 1.5784, value_loss: 0.9241
2024-07-11 16:02:37,261 [INFO    ] __main__: train step 4050: loss: 0.7773, policy_loss: 1.5783, value_loss: 0.9241
2024-07-11 16:02:37,473 [INFO    ] __main__: train step 4051: loss: 0.7774, policy_loss: 1.5782, value_loss: 0.9241
2024-07-11 16:02:37,710 [INFO    ] __main__: train step 4052: loss: 0.7776, policy_loss: 1.5781, value_loss: 0.9240
2024-07-11 16:02:37,940 [INFO    ] __main__: train step 4053: loss: 0.7777, policy_loss: 1.5780, value_loss: 0.9240
2024-07-11 16:02:38,167 [INFO    ] __main__: train step 4054: loss: 0.7778, policy_loss: 1.5778, value_loss: 0.9240
2024-07-11 16:02:38,416 [INFO    ] __main__: train step 4055: loss: 0.7779, policy_loss: 1.5777, value_loss: 0.9239
2024-07-11 16:02:38,644 [INFO    ] __main__: train step 4056: loss: 0.7780, policy_loss: 1.5776, value_loss: 0.9239
2024-07-11 16:02:38,842 [INFO    ] __main__: train step 4057: loss: 0.7781, policy_loss: 1.5775, value_loss: 0.9239
2024-07-11 16:02:39,039 [INFO    ] __main__: train step 4058: loss: 0.7783, policy_loss: 1.5774, value_loss: 0.9238
2024-07-11 16:02:39,234 [INFO    ] __main__: train step 4059: loss: 0.7784, policy_loss: 1.5773, value_loss: 0.9238
2024-07-11 16:02:39,440 [INFO    ] __main__: train step 4060: loss: 0.7785, policy_loss: 1.5771, value_loss: 0.9238
2024-07-11 16:02:39,642 [INFO    ] __main__: train step 4061: loss: 0.7786, policy_loss: 1.5770, value_loss: 0.9237
2024-07-11 16:02:39,841 [INFO    ] __main__: train step 4062: loss: 0.7787, policy_loss: 1.5769, value_loss: 0.9237
2024-07-11 16:02:41,296 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:02:41,731 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:02:41,792 [INFO    ] __main__: train step 4063: loss: 0.7788, policy_loss: 1.5768, value_loss: 0.9237
2024-07-11 16:02:41,961 [INFO    ] __main__: train step 4064: loss: 0.7789, policy_loss: 1.5767, value_loss: 0.9236
2024-07-11 16:02:42,164 [INFO    ] __main__: train step 4065: loss: 0.7791, policy_loss: 1.5766, value_loss: 0.9236
2024-07-11 16:02:42,384 [INFO    ] __main__: train step 4066: loss: 0.7792, policy_loss: 1.5765, value_loss: 0.9236
2024-07-11 16:02:42,576 [INFO    ] __main__: train step 4067: loss: 0.7793, policy_loss: 1.5763, value_loss: 0.9235
2024-07-11 16:02:42,773 [INFO    ] __main__: train step 4068: loss: 0.7794, policy_loss: 1.5762, value_loss: 0.9235
2024-07-11 16:02:42,977 [INFO    ] __main__: train step 4069: loss: 0.7795, policy_loss: 1.5761, value_loss: 0.9234
2024-07-11 16:02:43,191 [INFO    ] __main__: train step 4070: loss: 0.7796, policy_loss: 1.5760, value_loss: 0.9234
2024-07-11 16:02:43,399 [INFO    ] __main__: train step 4071: loss: 0.7797, policy_loss: 1.5759, value_loss: 0.9234
2024-07-11 16:02:43,598 [INFO    ] __main__: train step 4072: loss: 0.7799, policy_loss: 1.5758, value_loss: 0.9233
2024-07-11 16:02:44,088 [INFO    ] __main__: train step 4073: loss: 0.7800, policy_loss: 1.5757, value_loss: 0.9233
2024-07-11 16:02:44,297 [INFO    ] __main__: train step 4074: loss: 0.7801, policy_loss: 1.5755, value_loss: 0.9233
2024-07-11 16:02:44,504 [INFO    ] __main__: train step 4075: loss: 0.7802, policy_loss: 1.5754, value_loss: 0.9232
2024-07-11 16:02:44,716 [INFO    ] __main__: train step 4076: loss: 0.7803, policy_loss: 1.5753, value_loss: 0.9232
2024-07-11 16:02:44,920 [INFO    ] __main__: train step 4077: loss: 0.7804, policy_loss: 1.5752, value_loss: 0.9232
2024-07-11 16:02:45,117 [INFO    ] __main__: train step 4078: loss: 0.7805, policy_loss: 1.5751, value_loss: 0.9231
2024-07-11 16:02:45,323 [INFO    ] __main__: train step 4079: loss: 0.7807, policy_loss: 1.5750, value_loss: 0.9231
2024-07-11 16:02:46,752 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:02:47,149 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:02:47,203 [INFO    ] __main__: train step 4080: loss: 0.7808, policy_loss: 1.5749, value_loss: 0.9230
2024-07-11 16:02:47,385 [INFO    ] __main__: train step 4081: loss: 0.7809, policy_loss: 1.5747, value_loss: 0.9230
2024-07-11 16:02:47,583 [INFO    ] __main__: train step 4082: loss: 0.7810, policy_loss: 1.5746, value_loss: 0.9230
2024-07-11 16:02:47,787 [INFO    ] __main__: train step 4083: loss: 0.7811, policy_loss: 1.5745, value_loss: 0.9229
2024-07-11 16:02:47,981 [INFO    ] __main__: train step 4084: loss: 0.7812, policy_loss: 1.5744, value_loss: 0.9229
2024-07-11 16:02:48,188 [INFO    ] __main__: train step 4085: loss: 0.7813, policy_loss: 1.5743, value_loss: 0.9229
2024-07-11 16:02:48,387 [INFO    ] __main__: train step 4086: loss: 0.7815, policy_loss: 1.5742, value_loss: 0.9228
2024-07-11 16:02:48,584 [INFO    ] __main__: train step 4087: loss: 0.7816, policy_loss: 1.5741, value_loss: 0.9228
2024-07-11 16:02:48,786 [INFO    ] __main__: train step 4088: loss: 0.7817, policy_loss: 1.5739, value_loss: 0.9228
2024-07-11 16:02:49,001 [INFO    ] __main__: train step 4089: loss: 0.7818, policy_loss: 1.5738, value_loss: 0.9227
2024-07-11 16:02:49,201 [INFO    ] __main__: train step 4090: loss: 0.7819, policy_loss: 1.5737, value_loss: 0.9227
2024-07-11 16:02:49,406 [INFO    ] __main__: train step 4091: loss: 0.7820, policy_loss: 1.5736, value_loss: 0.9227
2024-07-11 16:02:49,617 [INFO    ] __main__: train step 4092: loss: 0.7821, policy_loss: 1.5735, value_loss: 0.9226
2024-07-11 16:02:49,808 [INFO    ] __main__: train step 4093: loss: 0.7822, policy_loss: 1.5734, value_loss: 0.9226
2024-07-11 16:02:50,013 [INFO    ] __main__: train step 4094: loss: 0.7824, policy_loss: 1.5733, value_loss: 0.9226
2024-07-11 16:02:50,214 [INFO    ] __main__: train step 4095: loss: 0.7825, policy_loss: 1.5732, value_loss: 0.9225
2024-07-11 16:02:50,416 [INFO    ] __main__: train step 4096: loss: 0.7826, policy_loss: 1.5730, value_loss: 0.9225
2024-07-11 16:02:52,125 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:02:52,538 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:02:52,596 [INFO    ] __main__: train step 4097: loss: 0.7827, policy_loss: 1.5729, value_loss: 0.9224
2024-07-11 16:02:52,774 [INFO    ] __main__: train step 4098: loss: 0.7828, policy_loss: 1.5728, value_loss: 0.9224
2024-07-11 16:02:52,978 [INFO    ] __main__: train step 4099: loss: 0.7829, policy_loss: 1.5727, value_loss: 0.9224
2024-07-11 16:02:53,187 [INFO    ] __main__: train step 4100: loss: 0.7830, policy_loss: 1.5726, value_loss: 0.9223
2024-07-11 16:02:53,378 [INFO    ] __main__: train step 4101: loss: 0.7831, policy_loss: 1.5725, value_loss: 0.9223
2024-07-11 16:02:53,583 [INFO    ] __main__: train step 4102: loss: 0.7833, policy_loss: 1.5724, value_loss: 0.9223
2024-07-11 16:02:53,780 [INFO    ] __main__: train step 4103: loss: 0.7834, policy_loss: 1.5722, value_loss: 0.9222
2024-07-11 16:02:53,980 [INFO    ] __main__: train step 4104: loss: 0.7835, policy_loss: 1.5721, value_loss: 0.9222
2024-07-11 16:02:54,182 [INFO    ] __main__: train step 4105: loss: 0.7836, policy_loss: 1.5720, value_loss: 0.9222
2024-07-11 16:02:54,393 [INFO    ] __main__: train step 4106: loss: 0.7837, policy_loss: 1.5719, value_loss: 0.9221
2024-07-11 16:02:54,620 [INFO    ] __main__: train step 4107: loss: 0.7838, policy_loss: 1.5718, value_loss: 0.9221
2024-07-11 16:02:54,812 [INFO    ] __main__: train step 4108: loss: 0.7839, policy_loss: 1.5717, value_loss: 0.9220
2024-07-11 16:02:55,011 [INFO    ] __main__: train step 4109: loss: 0.7840, policy_loss: 1.5715, value_loss: 0.9220
2024-07-11 16:02:55,221 [INFO    ] __main__: train step 4110: loss: 0.7841, policy_loss: 1.5714, value_loss: 0.9220
2024-07-11 16:02:55,421 [INFO    ] __main__: train step 4111: loss: 0.7843, policy_loss: 1.5713, value_loss: 0.9219
2024-07-11 16:02:55,623 [INFO    ] __main__: train step 4112: loss: 0.7844, policy_loss: 1.5712, value_loss: 0.9219
2024-07-11 16:02:55,860 [INFO    ] __main__: train step 4113: loss: 0.7845, policy_loss: 1.5711, value_loss: 0.9219
2024-07-11 16:02:57,296 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:02:57,689 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:02:57,748 [INFO    ] __main__: train step 4114: loss: 0.7846, policy_loss: 1.5710, value_loss: 0.9218
2024-07-11 16:02:57,932 [INFO    ] __main__: train step 4115: loss: 0.7847, policy_loss: 1.5709, value_loss: 0.9218
2024-07-11 16:02:58,160 [INFO    ] __main__: train step 4116: loss: 0.7848, policy_loss: 1.5708, value_loss: 0.9217
2024-07-11 16:02:58,357 [INFO    ] __main__: train step 4117: loss: 0.7849, policy_loss: 1.5706, value_loss: 0.9217
2024-07-11 16:02:58,561 [INFO    ] __main__: train step 4118: loss: 0.7850, policy_loss: 1.5705, value_loss: 0.9217
2024-07-11 16:02:58,773 [INFO    ] __main__: train step 4119: loss: 0.7852, policy_loss: 1.5704, value_loss: 0.9216
2024-07-11 16:02:58,974 [INFO    ] __main__: train step 4120: loss: 0.7853, policy_loss: 1.5703, value_loss: 0.9216
2024-07-11 16:02:59,446 [INFO    ] __main__: train step 4121: loss: 0.7854, policy_loss: 1.5702, value_loss: 0.9216
2024-07-11 16:02:59,644 [INFO    ] __main__: train step 4122: loss: 0.7855, policy_loss: 1.5701, value_loss: 0.9215
2024-07-11 16:02:59,843 [INFO    ] __main__: train step 4123: loss: 0.7856, policy_loss: 1.5700, value_loss: 0.9215
2024-07-11 16:03:00,045 [INFO    ] __main__: train step 4124: loss: 0.7857, policy_loss: 1.5698, value_loss: 0.9215
2024-07-11 16:03:00,243 [INFO    ] __main__: train step 4125: loss: 0.7858, policy_loss: 1.5697, value_loss: 0.9214
2024-07-11 16:03:00,435 [INFO    ] __main__: train step 4126: loss: 0.7859, policy_loss: 1.5696, value_loss: 0.9214
2024-07-11 16:03:00,641 [INFO    ] __main__: train step 4127: loss: 0.7861, policy_loss: 1.5695, value_loss: 0.9213
2024-07-11 16:03:00,849 [INFO    ] __main__: train step 4128: loss: 0.7862, policy_loss: 1.5694, value_loss: 0.9213
2024-07-11 16:03:01,054 [INFO    ] __main__: train step 4129: loss: 0.7863, policy_loss: 1.5693, value_loss: 0.9213
2024-07-11 16:03:01,269 [INFO    ] __main__: train step 4130: loss: 0.7864, policy_loss: 1.5692, value_loss: 0.9212
2024-07-11 16:03:02,722 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:03:03,106 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:03:03,162 [INFO    ] __main__: train step 4131: loss: 0.7865, policy_loss: 1.5690, value_loss: 0.9212
2024-07-11 16:03:03,335 [INFO    ] __main__: train step 4132: loss: 0.7866, policy_loss: 1.5689, value_loss: 0.9212
2024-07-11 16:03:03,544 [INFO    ] __main__: train step 4133: loss: 0.7867, policy_loss: 1.5688, value_loss: 0.9211
2024-07-11 16:03:03,744 [INFO    ] __main__: train step 4134: loss: 0.7868, policy_loss: 1.5687, value_loss: 0.9211
2024-07-11 16:03:03,937 [INFO    ] __main__: train step 4135: loss: 0.7870, policy_loss: 1.5686, value_loss: 0.9210
2024-07-11 16:03:04,143 [INFO    ] __main__: train step 4136: loss: 0.7871, policy_loss: 1.5685, value_loss: 0.9210
2024-07-11 16:03:04,335 [INFO    ] __main__: train step 4137: loss: 0.7872, policy_loss: 1.5684, value_loss: 0.9210
2024-07-11 16:03:04,533 [INFO    ] __main__: train step 4138: loss: 0.7873, policy_loss: 1.5682, value_loss: 0.9209
2024-07-11 16:03:04,742 [INFO    ] __main__: train step 4139: loss: 0.7874, policy_loss: 1.5681, value_loss: 0.9209
2024-07-11 16:03:04,944 [INFO    ] __main__: train step 4140: loss: 0.7875, policy_loss: 1.5680, value_loss: 0.9209
2024-07-11 16:03:05,181 [INFO    ] __main__: train step 4141: loss: 0.7876, policy_loss: 1.5679, value_loss: 0.9208
2024-07-11 16:03:05,405 [INFO    ] __main__: train step 4142: loss: 0.7878, policy_loss: 1.5678, value_loss: 0.9208
2024-07-11 16:03:05,628 [INFO    ] __main__: train step 4143: loss: 0.7879, policy_loss: 1.5677, value_loss: 0.9208
2024-07-11 16:03:05,851 [INFO    ] __main__: train step 4144: loss: 0.7880, policy_loss: 1.5676, value_loss: 0.9207
2024-07-11 16:03:06,333 [INFO    ] __main__: train step 4145: loss: 0.7881, policy_loss: 1.5675, value_loss: 0.9207
2024-07-11 16:03:06,533 [INFO    ] __main__: train step 4146: loss: 0.7882, policy_loss: 1.5674, value_loss: 0.9207
2024-07-11 16:03:06,734 [INFO    ] __main__: train step 4147: loss: 0.7883, policy_loss: 1.5672, value_loss: 0.9206
2024-07-11 16:03:08,178 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:03:08,601 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:03:08,661 [INFO    ] __main__: train step 4148: loss: 0.7884, policy_loss: 1.5671, value_loss: 0.9206
2024-07-11 16:03:08,833 [INFO    ] __main__: train step 4149: loss: 0.7885, policy_loss: 1.5670, value_loss: 0.9206
2024-07-11 16:03:09,038 [INFO    ] __main__: train step 4150: loss: 0.7887, policy_loss: 1.5669, value_loss: 0.9205
2024-07-11 16:03:09,270 [INFO    ] __main__: train step 4151: loss: 0.7888, policy_loss: 1.5668, value_loss: 0.9205
2024-07-11 16:03:09,482 [INFO    ] __main__: train step 4152: loss: 0.7889, policy_loss: 1.5667, value_loss: 0.9204
2024-07-11 16:03:09,709 [INFO    ] __main__: train step 4153: loss: 0.7890, policy_loss: 1.5666, value_loss: 0.9204
2024-07-11 16:03:09,937 [INFO    ] __main__: train step 4154: loss: 0.7891, policy_loss: 1.5665, value_loss: 0.9204
2024-07-11 16:03:10,142 [INFO    ] __main__: train step 4155: loss: 0.7892, policy_loss: 1.5663, value_loss: 0.9203
2024-07-11 16:03:10,330 [INFO    ] __main__: train step 4156: loss: 0.7893, policy_loss: 1.5662, value_loss: 0.9203
2024-07-11 16:03:10,533 [INFO    ] __main__: train step 4157: loss: 0.7895, policy_loss: 1.5661, value_loss: 0.9203
2024-07-11 16:03:10,739 [INFO    ] __main__: train step 4158: loss: 0.7896, policy_loss: 1.5660, value_loss: 0.9202
2024-07-11 16:03:10,940 [INFO    ] __main__: train step 4159: loss: 0.7897, policy_loss: 1.5659, value_loss: 0.9202
2024-07-11 16:03:11,139 [INFO    ] __main__: train step 4160: loss: 0.7898, policy_loss: 1.5658, value_loss: 0.9201
2024-07-11 16:03:11,347 [INFO    ] __main__: train step 4161: loss: 0.7899, policy_loss: 1.5657, value_loss: 0.9201
2024-07-11 16:03:11,549 [INFO    ] __main__: train step 4162: loss: 0.7900, policy_loss: 1.5656, value_loss: 0.9201
2024-07-11 16:03:11,748 [INFO    ] __main__: train step 4163: loss: 0.7901, policy_loss: 1.5654, value_loss: 0.9201
2024-07-11 16:03:11,949 [INFO    ] __main__: train step 4164: loss: 0.7902, policy_loss: 1.5653, value_loss: 0.9200
2024-07-11 16:03:13,396 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:03:13,805 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:03:13,868 [INFO    ] __main__: train step 4165: loss: 0.7904, policy_loss: 1.5652, value_loss: 0.9200
2024-07-11 16:03:14,043 [INFO    ] __main__: train step 4166: loss: 0.7905, policy_loss: 1.5651, value_loss: 0.9199
2024-07-11 16:03:14,271 [INFO    ] __main__: train step 4167: loss: 0.7906, policy_loss: 1.5650, value_loss: 0.9199
2024-07-11 16:03:14,760 [INFO    ] __main__: train step 4168: loss: 0.7907, policy_loss: 1.5649, value_loss: 0.9199
2024-07-11 16:03:14,954 [INFO    ] __main__: train step 4169: loss: 0.7908, policy_loss: 1.5648, value_loss: 0.9198
2024-07-11 16:03:15,176 [INFO    ] __main__: train step 4170: loss: 0.7909, policy_loss: 1.5647, value_loss: 0.9198
2024-07-11 16:03:15,366 [INFO    ] __main__: train step 4171: loss: 0.7910, policy_loss: 1.5646, value_loss: 0.9198
2024-07-11 16:03:15,561 [INFO    ] __main__: train step 4172: loss: 0.7911, policy_loss: 1.5644, value_loss: 0.9197
2024-07-11 16:03:15,754 [INFO    ] __main__: train step 4173: loss: 0.7913, policy_loss: 1.5643, value_loss: 0.9197
2024-07-11 16:03:15,988 [INFO    ] __main__: train step 4174: loss: 0.7914, policy_loss: 1.5642, value_loss: 0.9197
2024-07-11 16:03:16,189 [INFO    ] __main__: train step 4175: loss: 0.7915, policy_loss: 1.5641, value_loss: 0.9196
2024-07-11 16:03:16,391 [INFO    ] __main__: train step 4176: loss: 0.7916, policy_loss: 1.5640, value_loss: 0.9196
2024-07-11 16:03:16,619 [INFO    ] __main__: train step 4177: loss: 0.7917, policy_loss: 1.5639, value_loss: 0.9196
2024-07-11 16:03:16,840 [INFO    ] __main__: train step 4178: loss: 0.7918, policy_loss: 1.5638, value_loss: 0.9195
2024-07-11 16:03:17,072 [INFO    ] __main__: train step 4179: loss: 0.7919, policy_loss: 1.5637, value_loss: 0.9195
2024-07-11 16:03:17,268 [INFO    ] __main__: train step 4180: loss: 0.7920, policy_loss: 1.5636, value_loss: 0.9195
2024-07-11 16:03:17,493 [INFO    ] __main__: train step 4181: loss: 0.7922, policy_loss: 1.5634, value_loss: 0.9194
2024-07-11 16:03:18,967 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:03:19,354 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:03:19,408 [INFO    ] __main__: train step 4182: loss: 0.7923, policy_loss: 1.5633, value_loss: 0.9194
2024-07-11 16:03:19,588 [INFO    ] __main__: train step 4183: loss: 0.7924, policy_loss: 1.5632, value_loss: 0.9193
2024-07-11 16:03:19,786 [INFO    ] __main__: train step 4184: loss: 0.7925, policy_loss: 1.5631, value_loss: 0.9193
2024-07-11 16:03:19,993 [INFO    ] __main__: train step 4185: loss: 0.7926, policy_loss: 1.5630, value_loss: 0.9193
2024-07-11 16:03:20,200 [INFO    ] __main__: train step 4186: loss: 0.7927, policy_loss: 1.5629, value_loss: 0.9193
2024-07-11 16:03:20,416 [INFO    ] __main__: train step 4187: loss: 0.7928, policy_loss: 1.5628, value_loss: 0.9192
2024-07-11 16:03:20,649 [INFO    ] __main__: train step 4188: loss: 0.7930, policy_loss: 1.5627, value_loss: 0.9192
2024-07-11 16:03:20,870 [INFO    ] __main__: train step 4189: loss: 0.7931, policy_loss: 1.5626, value_loss: 0.9192
2024-07-11 16:03:21,066 [INFO    ] __main__: train step 4190: loss: 0.7932, policy_loss: 1.5624, value_loss: 0.9191
2024-07-11 16:03:21,552 [INFO    ] __main__: train step 4191: loss: 0.7933, policy_loss: 1.5623, value_loss: 0.9191
2024-07-11 16:03:21,758 [INFO    ] __main__: train step 4192: loss: 0.7934, policy_loss: 1.5622, value_loss: 0.9191
2024-07-11 16:03:21,968 [INFO    ] __main__: train step 4193: loss: 0.7935, policy_loss: 1.5621, value_loss: 0.9190
2024-07-11 16:03:22,168 [INFO    ] __main__: train step 4194: loss: 0.7936, policy_loss: 1.5620, value_loss: 0.9190
2024-07-11 16:03:22,385 [INFO    ] __main__: train step 4195: loss: 0.7938, policy_loss: 1.5619, value_loss: 0.9190
2024-07-11 16:03:22,586 [INFO    ] __main__: train step 4196: loss: 0.7939, policy_loss: 1.5618, value_loss: 0.9189
2024-07-11 16:03:22,789 [INFO    ] __main__: train step 4197: loss: 0.7940, policy_loss: 1.5617, value_loss: 0.9189
2024-07-11 16:03:23,001 [INFO    ] __main__: train step 4198: loss: 0.7941, policy_loss: 1.5616, value_loss: 0.9189
2024-07-11 16:03:24,466 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:03:24,872 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:03:24,930 [INFO    ] __main__: train step 4199: loss: 0.7942, policy_loss: 1.5614, value_loss: 0.9188
2024-07-11 16:03:25,110 [INFO    ] __main__: train step 4200: loss: 0.7943, policy_loss: 1.5613, value_loss: 0.9188
2024-07-11 16:03:25,322 [INFO    ] __main__: train step 4201: loss: 0.7944, policy_loss: 1.5612, value_loss: 0.9187
2024-07-11 16:03:25,522 [INFO    ] __main__: train step 4202: loss: 0.7945, policy_loss: 1.5611, value_loss: 0.9187
2024-07-11 16:03:25,731 [INFO    ] __main__: train step 4203: loss: 0.7947, policy_loss: 1.5610, value_loss: 0.9187
2024-07-11 16:03:25,967 [INFO    ] __main__: train step 4204: loss: 0.7948, policy_loss: 1.5609, value_loss: 0.9186
2024-07-11 16:03:26,182 [INFO    ] __main__: train step 4205: loss: 0.7949, policy_loss: 1.5608, value_loss: 0.9186
2024-07-11 16:03:26,389 [INFO    ] __main__: train step 4206: loss: 0.7950, policy_loss: 1.5607, value_loss: 0.9186
2024-07-11 16:03:26,591 [INFO    ] __main__: train step 4207: loss: 0.7951, policy_loss: 1.5605, value_loss: 0.9185
2024-07-11 16:03:26,820 [INFO    ] __main__: train step 4208: loss: 0.7952, policy_loss: 1.5604, value_loss: 0.9185
2024-07-11 16:03:27,023 [INFO    ] __main__: train step 4209: loss: 0.7953, policy_loss: 1.5603, value_loss: 0.9185
2024-07-11 16:03:27,217 [INFO    ] __main__: train step 4210: loss: 0.7955, policy_loss: 1.5602, value_loss: 0.9184
2024-07-11 16:03:27,423 [INFO    ] __main__: train step 4211: loss: 0.7956, policy_loss: 1.5601, value_loss: 0.9184
2024-07-11 16:03:27,652 [INFO    ] __main__: train step 4212: loss: 0.7957, policy_loss: 1.5600, value_loss: 0.9183
2024-07-11 16:03:27,848 [INFO    ] __main__: train step 4213: loss: 0.7958, policy_loss: 1.5599, value_loss: 0.9183
2024-07-11 16:03:28,367 [INFO    ] __main__: train step 4214: loss: 0.7959, policy_loss: 1.5598, value_loss: 0.9183
2024-07-11 16:03:28,592 [INFO    ] __main__: train step 4215: loss: 0.7960, policy_loss: 1.5596, value_loss: 0.9182
2024-07-11 16:03:30,070 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:03:30,472 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:03:30,533 [INFO    ] __main__: train step 4216: loss: 0.7961, policy_loss: 1.5595, value_loss: 0.9182
2024-07-11 16:03:30,701 [INFO    ] __main__: train step 4217: loss: 0.7963, policy_loss: 1.5594, value_loss: 0.9182
2024-07-11 16:03:30,903 [INFO    ] __main__: train step 4218: loss: 0.7964, policy_loss: 1.5593, value_loss: 0.9181
2024-07-11 16:03:31,108 [INFO    ] __main__: train step 4219: loss: 0.7965, policy_loss: 1.5592, value_loss: 0.9181
2024-07-11 16:03:31,310 [INFO    ] __main__: train step 4220: loss: 0.7966, policy_loss: 1.5591, value_loss: 0.9181
2024-07-11 16:03:31,510 [INFO    ] __main__: train step 4221: loss: 0.7967, policy_loss: 1.5590, value_loss: 0.9180
2024-07-11 16:03:31,733 [INFO    ] __main__: train step 4222: loss: 0.7968, policy_loss: 1.5589, value_loss: 0.9180
2024-07-11 16:03:31,956 [INFO    ] __main__: train step 4223: loss: 0.7969, policy_loss: 1.5587, value_loss: 0.9180
2024-07-11 16:03:32,176 [INFO    ] __main__: train step 4224: loss: 0.7970, policy_loss: 1.5586, value_loss: 0.9179
2024-07-11 16:03:32,426 [INFO    ] __main__: train step 4225: loss: 0.7971, policy_loss: 1.5585, value_loss: 0.9179
2024-07-11 16:03:32,630 [INFO    ] __main__: train step 4226: loss: 0.7972, policy_loss: 1.5584, value_loss: 0.9179
2024-07-11 16:03:32,841 [INFO    ] __main__: train step 4227: loss: 0.7974, policy_loss: 1.5583, value_loss: 0.9178
2024-07-11 16:03:33,042 [INFO    ] __main__: train step 4228: loss: 0.7975, policy_loss: 1.5582, value_loss: 0.9178
2024-07-11 16:03:33,245 [INFO    ] __main__: train step 4229: loss: 0.7976, policy_loss: 1.5581, value_loss: 0.9177
2024-07-11 16:03:33,451 [INFO    ] __main__: train step 4230: loss: 0.7977, policy_loss: 1.5580, value_loss: 0.9177
2024-07-11 16:03:33,656 [INFO    ] __main__: train step 4231: loss: 0.7978, policy_loss: 1.5579, value_loss: 0.9177
2024-07-11 16:03:33,894 [INFO    ] __main__: train step 4232: loss: 0.7979, policy_loss: 1.5577, value_loss: 0.9176
2024-07-11 16:03:35,319 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:03:35,692 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:03:35,748 [INFO    ] __main__: train step 4233: loss: 0.7980, policy_loss: 1.5576, value_loss: 0.9176
2024-07-11 16:03:35,923 [INFO    ] __main__: train step 4234: loss: 0.7981, policy_loss: 1.5575, value_loss: 0.9176
2024-07-11 16:03:36,119 [INFO    ] __main__: train step 4235: loss: 0.7982, policy_loss: 1.5574, value_loss: 0.9175
2024-07-11 16:03:36,325 [INFO    ] __main__: train step 4236: loss: 0.7984, policy_loss: 1.5573, value_loss: 0.9175
2024-07-11 16:03:36,526 [INFO    ] __main__: train step 4237: loss: 0.7985, policy_loss: 1.5572, value_loss: 0.9175
2024-07-11 16:03:37,021 [INFO    ] __main__: train step 4238: loss: 0.7986, policy_loss: 1.5571, value_loss: 0.9174
2024-07-11 16:03:37,268 [INFO    ] __main__: train step 4239: loss: 0.7987, policy_loss: 1.5570, value_loss: 0.9174
2024-07-11 16:03:37,461 [INFO    ] __main__: train step 4240: loss: 0.7988, policy_loss: 1.5569, value_loss: 0.9174
2024-07-11 16:03:37,692 [INFO    ] __main__: train step 4241: loss: 0.7989, policy_loss: 1.5567, value_loss: 0.9173
2024-07-11 16:03:37,915 [INFO    ] __main__: train step 4242: loss: 0.7990, policy_loss: 1.5566, value_loss: 0.9173
2024-07-11 16:03:38,121 [INFO    ] __main__: train step 4243: loss: 0.7991, policy_loss: 1.5565, value_loss: 0.9172
2024-07-11 16:03:38,330 [INFO    ] __main__: train step 4244: loss: 0.7992, policy_loss: 1.5564, value_loss: 0.9172
2024-07-11 16:03:38,535 [INFO    ] __main__: train step 4245: loss: 0.7994, policy_loss: 1.5563, value_loss: 0.9172
2024-07-11 16:03:38,765 [INFO    ] __main__: train step 4246: loss: 0.7995, policy_loss: 1.5562, value_loss: 0.9171
2024-07-11 16:03:38,966 [INFO    ] __main__: train step 4247: loss: 0.7996, policy_loss: 1.5561, value_loss: 0.9171
2024-07-11 16:03:39,171 [INFO    ] __main__: train step 4248: loss: 0.7997, policy_loss: 1.5560, value_loss: 0.9171
2024-07-11 16:03:39,374 [INFO    ] __main__: train step 4249: loss: 0.7998, policy_loss: 1.5559, value_loss: 0.9170
2024-07-11 16:03:40,861 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:03:41,270 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:03:41,329 [INFO    ] __main__: train step 4250: loss: 0.7999, policy_loss: 1.5557, value_loss: 0.9170
2024-07-11 16:03:41,508 [INFO    ] __main__: train step 4251: loss: 0.8000, policy_loss: 1.5556, value_loss: 0.9170
2024-07-11 16:03:41,715 [INFO    ] __main__: train step 4252: loss: 0.8001, policy_loss: 1.5555, value_loss: 0.9169
2024-07-11 16:03:41,912 [INFO    ] __main__: train step 4253: loss: 0.8002, policy_loss: 1.5554, value_loss: 0.9169
2024-07-11 16:03:42,114 [INFO    ] __main__: train step 4254: loss: 0.8003, policy_loss: 1.5553, value_loss: 0.9168
2024-07-11 16:03:42,319 [INFO    ] __main__: train step 4255: loss: 0.8004, policy_loss: 1.5552, value_loss: 0.9168
2024-07-11 16:03:42,522 [INFO    ] __main__: train step 4256: loss: 0.8005, policy_loss: 1.5551, value_loss: 0.9168
2024-07-11 16:03:42,735 [INFO    ] __main__: train step 4257: loss: 0.8007, policy_loss: 1.5550, value_loss: 0.9167
2024-07-11 16:03:42,932 [INFO    ] __main__: train step 4258: loss: 0.8008, policy_loss: 1.5548, value_loss: 0.9167
2024-07-11 16:03:43,148 [INFO    ] __main__: train step 4259: loss: 0.8009, policy_loss: 1.5547, value_loss: 0.9167
2024-07-11 16:03:43,358 [INFO    ] __main__: train step 4260: loss: 0.8010, policy_loss: 1.5546, value_loss: 0.9166
2024-07-11 16:03:43,857 [INFO    ] __main__: train step 4261: loss: 0.8011, policy_loss: 1.5545, value_loss: 0.9166
2024-07-11 16:03:44,079 [INFO    ] __main__: train step 4262: loss: 0.8012, policy_loss: 1.5544, value_loss: 0.9166
2024-07-11 16:03:44,280 [INFO    ] __main__: train step 4263: loss: 0.8013, policy_loss: 1.5543, value_loss: 0.9165
2024-07-11 16:03:44,499 [INFO    ] __main__: train step 4264: loss: 0.8014, policy_loss: 1.5542, value_loss: 0.9165
2024-07-11 16:03:44,697 [INFO    ] __main__: train step 4265: loss: 0.8016, policy_loss: 1.5541, value_loss: 0.9165
2024-07-11 16:03:44,897 [INFO    ] __main__: train step 4266: loss: 0.8017, policy_loss: 1.5540, value_loss: 0.9164
2024-07-11 16:03:46,324 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:03:46,717 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:03:46,772 [INFO    ] __main__: train step 4267: loss: 0.8018, policy_loss: 1.5539, value_loss: 0.9164
2024-07-11 16:03:46,948 [INFO    ] __main__: train step 4268: loss: 0.8019, policy_loss: 1.5538, value_loss: 0.9163
2024-07-11 16:03:47,158 [INFO    ] __main__: train step 4269: loss: 0.8020, policy_loss: 1.5536, value_loss: 0.9163
2024-07-11 16:03:47,359 [INFO    ] __main__: train step 4270: loss: 0.8021, policy_loss: 1.5535, value_loss: 0.9163
2024-07-11 16:03:47,575 [INFO    ] __main__: train step 4271: loss: 0.8022, policy_loss: 1.5534, value_loss: 0.9162
2024-07-11 16:03:47,766 [INFO    ] __main__: train step 4272: loss: 0.8023, policy_loss: 1.5533, value_loss: 0.9162
2024-07-11 16:03:47,981 [INFO    ] __main__: train step 4273: loss: 0.8024, policy_loss: 1.5532, value_loss: 0.9162
2024-07-11 16:03:48,197 [INFO    ] __main__: train step 4274: loss: 0.8026, policy_loss: 1.5531, value_loss: 0.9161
2024-07-11 16:03:48,395 [INFO    ] __main__: train step 4275: loss: 0.8027, policy_loss: 1.5530, value_loss: 0.9161
2024-07-11 16:03:48,592 [INFO    ] __main__: train step 4276: loss: 0.8028, policy_loss: 1.5529, value_loss: 0.9160
2024-07-11 16:03:48,797 [INFO    ] __main__: train step 4277: loss: 0.8029, policy_loss: 1.5528, value_loss: 0.9160
2024-07-11 16:03:49,014 [INFO    ] __main__: train step 4278: loss: 0.8030, policy_loss: 1.5526, value_loss: 0.9160
2024-07-11 16:03:49,211 [INFO    ] __main__: train step 4279: loss: 0.8031, policy_loss: 1.5525, value_loss: 0.9159
2024-07-11 16:03:49,405 [INFO    ] __main__: train step 4280: loss: 0.8032, policy_loss: 1.5524, value_loss: 0.9159
2024-07-11 16:03:49,620 [INFO    ] __main__: train step 4281: loss: 0.8033, policy_loss: 1.5523, value_loss: 0.9159
2024-07-11 16:03:49,843 [INFO    ] __main__: train step 4282: loss: 0.8034, policy_loss: 1.5522, value_loss: 0.9158
2024-07-11 16:03:50,042 [INFO    ] __main__: train step 4283: loss: 0.8035, policy_loss: 1.5521, value_loss: 0.9158
2024-07-11 16:03:51,479 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:03:51,842 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:03:51,898 [INFO    ] __main__: train step 4284: loss: 0.8037, policy_loss: 1.5520, value_loss: 0.9157
2024-07-11 16:03:52,351 [INFO    ] __main__: train step 4285: loss: 0.8038, policy_loss: 1.5519, value_loss: 0.9157
2024-07-11 16:03:52,546 [INFO    ] __main__: train step 4286: loss: 0.8039, policy_loss: 1.5518, value_loss: 0.9157
2024-07-11 16:03:52,760 [INFO    ] __main__: train step 4287: loss: 0.8040, policy_loss: 1.5516, value_loss: 0.9156
2024-07-11 16:03:52,962 [INFO    ] __main__: train step 4288: loss: 0.8041, policy_loss: 1.5515, value_loss: 0.9156
2024-07-11 16:03:53,165 [INFO    ] __main__: train step 4289: loss: 0.8042, policy_loss: 1.5514, value_loss: 0.9156
2024-07-11 16:03:53,402 [INFO    ] __main__: train step 4290: loss: 0.8043, policy_loss: 1.5513, value_loss: 0.9155
2024-07-11 16:03:53,596 [INFO    ] __main__: train step 4291: loss: 0.8044, policy_loss: 1.5512, value_loss: 0.9155
2024-07-11 16:03:53,801 [INFO    ] __main__: train step 4292: loss: 0.8045, policy_loss: 1.5511, value_loss: 0.9155
2024-07-11 16:03:54,009 [INFO    ] __main__: train step 4293: loss: 0.8047, policy_loss: 1.5510, value_loss: 0.9154
2024-07-11 16:03:54,202 [INFO    ] __main__: train step 4294: loss: 0.8048, policy_loss: 1.5509, value_loss: 0.9154
2024-07-11 16:03:54,424 [INFO    ] __main__: train step 4295: loss: 0.8049, policy_loss: 1.5508, value_loss: 0.9154
2024-07-11 16:03:54,619 [INFO    ] __main__: train step 4296: loss: 0.8050, policy_loss: 1.5507, value_loss: 0.9153
2024-07-11 16:03:54,807 [INFO    ] __main__: train step 4297: loss: 0.8051, policy_loss: 1.5506, value_loss: 0.9153
2024-07-11 16:03:55,020 [INFO    ] __main__: train step 4298: loss: 0.8052, policy_loss: 1.5505, value_loss: 0.9152
2024-07-11 16:03:55,242 [INFO    ] __main__: train step 4299: loss: 0.8053, policy_loss: 1.5503, value_loss: 0.9152
2024-07-11 16:03:55,448 [INFO    ] __main__: train step 4300: loss: 0.8054, policy_loss: 1.5502, value_loss: 0.9152
2024-07-11 16:03:56,924 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:03:57,287 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:03:57,348 [INFO    ] __main__: train step 4301: loss: 0.8056, policy_loss: 1.5501, value_loss: 0.9151
2024-07-11 16:03:57,515 [INFO    ] __main__: train step 4302: loss: 0.8057, policy_loss: 1.5500, value_loss: 0.9151
2024-07-11 16:03:57,718 [INFO    ] __main__: train step 4303: loss: 0.8058, policy_loss: 1.5499, value_loss: 0.9151
2024-07-11 16:03:57,916 [INFO    ] __main__: train step 4304: loss: 0.8059, policy_loss: 1.5498, value_loss: 0.9150
2024-07-11 16:03:58,116 [INFO    ] __main__: train step 4305: loss: 0.8060, policy_loss: 1.5497, value_loss: 0.9150
2024-07-11 16:03:58,321 [INFO    ] __main__: train step 4306: loss: 0.8061, policy_loss: 1.5496, value_loss: 0.9150
2024-07-11 16:03:58,522 [INFO    ] __main__: train step 4307: loss: 0.8062, policy_loss: 1.5494, value_loss: 0.9149
2024-07-11 16:03:59,025 [INFO    ] __main__: train step 4308: loss: 0.8063, policy_loss: 1.5493, value_loss: 0.9149
2024-07-11 16:03:59,217 [INFO    ] __main__: train step 4309: loss: 0.8064, policy_loss: 1.5492, value_loss: 0.9149
2024-07-11 16:03:59,414 [INFO    ] __main__: train step 4310: loss: 0.8065, policy_loss: 1.5491, value_loss: 0.9148
2024-07-11 16:03:59,635 [INFO    ] __main__: train step 4311: loss: 0.8067, policy_loss: 1.5490, value_loss: 0.9148
2024-07-11 16:03:59,846 [INFO    ] __main__: train step 4312: loss: 0.8068, policy_loss: 1.5489, value_loss: 0.9147
2024-07-11 16:04:00,040 [INFO    ] __main__: train step 4313: loss: 0.8069, policy_loss: 1.5488, value_loss: 0.9147
2024-07-11 16:04:00,241 [INFO    ] __main__: train step 4314: loss: 0.8070, policy_loss: 1.5487, value_loss: 0.9147
2024-07-11 16:04:00,440 [INFO    ] __main__: train step 4315: loss: 0.8071, policy_loss: 1.5486, value_loss: 0.9146
2024-07-11 16:04:00,652 [INFO    ] __main__: train step 4316: loss: 0.8072, policy_loss: 1.5485, value_loss: 0.9146
2024-07-11 16:04:00,844 [INFO    ] __main__: train step 4317: loss: 0.8073, policy_loss: 1.5483, value_loss: 0.9146
2024-07-11 16:04:02,282 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:04:02,609 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:04:02,664 [INFO    ] __main__: train step 4318: loss: 0.8074, policy_loss: 1.5482, value_loss: 0.9145
2024-07-11 16:04:02,853 [INFO    ] __main__: train step 4319: loss: 0.8075, policy_loss: 1.5481, value_loss: 0.9145
2024-07-11 16:04:03,101 [INFO    ] __main__: train step 4320: loss: 0.8076, policy_loss: 1.5480, value_loss: 0.9145
2024-07-11 16:04:03,302 [INFO    ] __main__: train step 4321: loss: 0.8077, policy_loss: 1.5479, value_loss: 0.9144
2024-07-11 16:04:03,505 [INFO    ] __main__: train step 4322: loss: 0.8078, policy_loss: 1.5478, value_loss: 0.9144
2024-07-11 16:04:03,714 [INFO    ] __main__: train step 4323: loss: 0.8080, policy_loss: 1.5477, value_loss: 0.9143
2024-07-11 16:04:03,914 [INFO    ] __main__: train step 4324: loss: 0.8081, policy_loss: 1.5476, value_loss: 0.9143
2024-07-11 16:04:04,113 [INFO    ] __main__: train step 4325: loss: 0.8082, policy_loss: 1.5475, value_loss: 0.9143
2024-07-11 16:04:04,302 [INFO    ] __main__: train step 4326: loss: 0.8083, policy_loss: 1.5474, value_loss: 0.9142
2024-07-11 16:04:04,490 [INFO    ] __main__: train step 4327: loss: 0.8084, policy_loss: 1.5472, value_loss: 0.9142
2024-07-11 16:04:04,687 [INFO    ] __main__: train step 4328: loss: 0.8085, policy_loss: 1.5471, value_loss: 0.9142
2024-07-11 16:04:04,898 [INFO    ] __main__: train step 4329: loss: 0.8086, policy_loss: 1.5470, value_loss: 0.9141
2024-07-11 16:04:05,123 [INFO    ] __main__: train step 4330: loss: 0.8087, policy_loss: 1.5469, value_loss: 0.9141
2024-07-11 16:04:05,613 [INFO    ] __main__: train step 4331: loss: 0.8088, policy_loss: 1.5468, value_loss: 0.9140
2024-07-11 16:04:05,788 [INFO    ] __main__: train step 4332: loss: 0.8090, policy_loss: 1.5467, value_loss: 0.9140
2024-07-11 16:04:05,976 [INFO    ] __main__: train step 4333: loss: 0.8091, policy_loss: 1.5466, value_loss: 0.9140
2024-07-11 16:04:06,171 [INFO    ] __main__: train step 4334: loss: 0.8092, policy_loss: 1.5465, value_loss: 0.9139
2024-07-11 16:04:07,602 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:04:07,995 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:04:08,050 [INFO    ] __main__: train step 4335: loss: 0.8093, policy_loss: 1.5464, value_loss: 0.9139
2024-07-11 16:04:08,222 [INFO    ] __main__: train step 4336: loss: 0.8094, policy_loss: 1.5463, value_loss: 0.9139
2024-07-11 16:04:08,429 [INFO    ] __main__: train step 4337: loss: 0.8095, policy_loss: 1.5461, value_loss: 0.9138
2024-07-11 16:04:08,641 [INFO    ] __main__: train step 4338: loss: 0.8096, policy_loss: 1.5460, value_loss: 0.9138
2024-07-11 16:04:08,849 [INFO    ] __main__: train step 4339: loss: 0.8097, policy_loss: 1.5459, value_loss: 0.9138
2024-07-11 16:04:09,052 [INFO    ] __main__: train step 4340: loss: 0.8098, policy_loss: 1.5458, value_loss: 0.9137
2024-07-11 16:04:09,252 [INFO    ] __main__: train step 4341: loss: 0.8099, policy_loss: 1.5457, value_loss: 0.9137
2024-07-11 16:04:09,465 [INFO    ] __main__: train step 4342: loss: 0.8101, policy_loss: 1.5456, value_loss: 0.9137
2024-07-11 16:04:09,659 [INFO    ] __main__: train step 4343: loss: 0.8102, policy_loss: 1.5455, value_loss: 0.9136
2024-07-11 16:04:09,863 [INFO    ] __main__: train step 4344: loss: 0.8103, policy_loss: 1.5454, value_loss: 0.9136
2024-07-11 16:04:10,060 [INFO    ] __main__: train step 4345: loss: 0.8104, policy_loss: 1.5453, value_loss: 0.9135
2024-07-11 16:04:10,269 [INFO    ] __main__: train step 4346: loss: 0.8105, policy_loss: 1.5452, value_loss: 0.9135
2024-07-11 16:04:10,467 [INFO    ] __main__: train step 4347: loss: 0.8106, policy_loss: 1.5450, value_loss: 0.9135
2024-07-11 16:04:10,699 [INFO    ] __main__: train step 4348: loss: 0.8107, policy_loss: 1.5449, value_loss: 0.9134
2024-07-11 16:04:10,930 [INFO    ] __main__: train step 4349: loss: 0.8108, policy_loss: 1.5448, value_loss: 0.9134
2024-07-11 16:04:11,126 [INFO    ] __main__: train step 4350: loss: 0.8109, policy_loss: 1.5447, value_loss: 0.9134
2024-07-11 16:04:11,326 [INFO    ] __main__: train step 4351: loss: 0.8110, policy_loss: 1.5446, value_loss: 0.9133
2024-07-11 16:04:12,786 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:04:13,188 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:04:13,247 [INFO    ] __main__: train step 4352: loss: 0.8111, policy_loss: 1.5445, value_loss: 0.9133
2024-07-11 16:04:13,422 [INFO    ] __main__: train step 4353: loss: 0.8112, policy_loss: 1.5444, value_loss: 0.9132
2024-07-11 16:04:13,639 [INFO    ] __main__: train step 4354: loss: 0.8114, policy_loss: 1.5443, value_loss: 0.9132
2024-07-11 16:04:13,843 [INFO    ] __main__: train step 4355: loss: 0.8115, policy_loss: 1.5442, value_loss: 0.9132
2024-07-11 16:04:14,341 [INFO    ] __main__: train step 4356: loss: 0.8116, policy_loss: 1.5441, value_loss: 0.9131
2024-07-11 16:04:14,547 [INFO    ] __main__: train step 4357: loss: 0.8117, policy_loss: 1.5439, value_loss: 0.9131
2024-07-11 16:04:14,747 [INFO    ] __main__: train step 4358: loss: 0.8118, policy_loss: 1.5438, value_loss: 0.9131
2024-07-11 16:04:14,956 [INFO    ] __main__: train step 4359: loss: 0.8119, policy_loss: 1.5437, value_loss: 0.9130
2024-07-11 16:04:15,161 [INFO    ] __main__: train step 4360: loss: 0.8120, policy_loss: 1.5436, value_loss: 0.9130
2024-07-11 16:04:15,356 [INFO    ] __main__: train step 4361: loss: 0.8121, policy_loss: 1.5435, value_loss: 0.9129
2024-07-11 16:04:15,551 [INFO    ] __main__: train step 4362: loss: 0.8122, policy_loss: 1.5434, value_loss: 0.9129
2024-07-11 16:04:15,759 [INFO    ] __main__: train step 4363: loss: 0.8123, policy_loss: 1.5433, value_loss: 0.9129
2024-07-11 16:04:15,960 [INFO    ] __main__: train step 4364: loss: 0.8124, policy_loss: 1.5432, value_loss: 0.9128
2024-07-11 16:04:16,152 [INFO    ] __main__: train step 4365: loss: 0.8125, policy_loss: 1.5431, value_loss: 0.9128
2024-07-11 16:04:16,355 [INFO    ] __main__: train step 4366: loss: 0.8127, policy_loss: 1.5430, value_loss: 0.9128
2024-07-11 16:04:16,556 [INFO    ] __main__: train step 4367: loss: 0.8128, policy_loss: 1.5428, value_loss: 0.9127
2024-07-11 16:04:16,771 [INFO    ] __main__: train step 4368: loss: 0.8129, policy_loss: 1.5427, value_loss: 0.9127
2024-07-11 16:04:18,239 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:04:18,645 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:04:18,709 [INFO    ] __main__: train step 4369: loss: 0.8130, policy_loss: 1.5426, value_loss: 0.9127
2024-07-11 16:04:18,884 [INFO    ] __main__: train step 4370: loss: 0.8131, policy_loss: 1.5425, value_loss: 0.9126
2024-07-11 16:04:19,089 [INFO    ] __main__: train step 4371: loss: 0.8132, policy_loss: 1.5424, value_loss: 0.9126
2024-07-11 16:04:19,278 [INFO    ] __main__: train step 4372: loss: 0.8133, policy_loss: 1.5423, value_loss: 0.9125
2024-07-11 16:04:19,478 [INFO    ] __main__: train step 4373: loss: 0.8134, policy_loss: 1.5422, value_loss: 0.9125
2024-07-11 16:04:19,692 [INFO    ] __main__: train step 4374: loss: 0.8135, policy_loss: 1.5421, value_loss: 0.9125
2024-07-11 16:04:19,901 [INFO    ] __main__: train step 4375: loss: 0.8136, policy_loss: 1.5420, value_loss: 0.9124
2024-07-11 16:04:20,130 [INFO    ] __main__: train step 4376: loss: 0.8137, policy_loss: 1.5418, value_loss: 0.9124
2024-07-11 16:04:20,357 [INFO    ] __main__: train step 4377: loss: 0.8138, policy_loss: 1.5417, value_loss: 0.9124
2024-07-11 16:04:20,557 [INFO    ] __main__: train step 4378: loss: 0.8139, policy_loss: 1.5416, value_loss: 0.9123
2024-07-11 16:04:21,027 [INFO    ] __main__: train step 4379: loss: 0.8140, policy_loss: 1.5415, value_loss: 0.9123
2024-07-11 16:04:21,231 [INFO    ] __main__: train step 4380: loss: 0.8141, policy_loss: 1.5414, value_loss: 0.9122
2024-07-11 16:04:21,429 [INFO    ] __main__: train step 4381: loss: 0.8143, policy_loss: 1.5413, value_loss: 0.9122
2024-07-11 16:04:21,620 [INFO    ] __main__: train step 4382: loss: 0.8144, policy_loss: 1.5412, value_loss: 0.9122
2024-07-11 16:04:21,826 [INFO    ] __main__: train step 4383: loss: 0.8145, policy_loss: 1.5411, value_loss: 0.9121
2024-07-11 16:04:22,024 [INFO    ] __main__: train step 4384: loss: 0.8146, policy_loss: 1.5410, value_loss: 0.9121
2024-07-11 16:04:22,224 [INFO    ] __main__: train step 4385: loss: 0.8147, policy_loss: 1.5409, value_loss: 0.9120
2024-07-11 16:04:23,663 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:04:24,060 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:04:24,116 [INFO    ] __main__: train step 4386: loss: 0.8148, policy_loss: 1.5408, value_loss: 0.9120
2024-07-11 16:04:24,288 [INFO    ] __main__: train step 4387: loss: 0.8149, policy_loss: 1.5406, value_loss: 0.9120
2024-07-11 16:04:24,496 [INFO    ] __main__: train step 4388: loss: 0.8150, policy_loss: 1.5405, value_loss: 0.9119
2024-07-11 16:04:24,735 [INFO    ] __main__: train step 4389: loss: 0.8151, policy_loss: 1.5404, value_loss: 0.9119
2024-07-11 16:04:24,929 [INFO    ] __main__: train step 4390: loss: 0.8152, policy_loss: 1.5403, value_loss: 0.9119
2024-07-11 16:04:25,127 [INFO    ] __main__: train step 4391: loss: 0.8153, policy_loss: 1.5402, value_loss: 0.9118
2024-07-11 16:04:25,322 [INFO    ] __main__: train step 4392: loss: 0.8154, policy_loss: 1.5401, value_loss: 0.9118
2024-07-11 16:04:25,542 [INFO    ] __main__: train step 4393: loss: 0.8155, policy_loss: 1.5400, value_loss: 0.9117
2024-07-11 16:04:25,775 [INFO    ] __main__: train step 4394: loss: 0.8157, policy_loss: 1.5399, value_loss: 0.9117
2024-07-11 16:04:26,013 [INFO    ] __main__: train step 4395: loss: 0.8158, policy_loss: 1.5398, value_loss: 0.9117
2024-07-11 16:04:26,207 [INFO    ] __main__: train step 4396: loss: 0.8159, policy_loss: 1.5397, value_loss: 0.9116
2024-07-11 16:04:26,419 [INFO    ] __main__: train step 4397: loss: 0.8160, policy_loss: 1.5396, value_loss: 0.9116
2024-07-11 16:04:26,618 [INFO    ] __main__: train step 4398: loss: 0.8161, policy_loss: 1.5394, value_loss: 0.9116
2024-07-11 16:04:26,853 [INFO    ] __main__: train step 4399: loss: 0.8162, policy_loss: 1.5393, value_loss: 0.9115
2024-07-11 16:04:27,041 [INFO    ] __main__: train step 4400: loss: 0.8163, policy_loss: 1.5392, value_loss: 0.9115
2024-07-11 16:04:27,235 [INFO    ] __main__: train step 4401: loss: 0.8164, policy_loss: 1.5391, value_loss: 0.9115
2024-07-11 16:04:27,711 [INFO    ] __main__: train step 4402: loss: 0.8165, policy_loss: 1.5390, value_loss: 0.9114
2024-07-11 16:04:29,158 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:04:29,545 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:04:29,599 [INFO    ] __main__: train step 4403: loss: 0.8166, policy_loss: 1.5389, value_loss: 0.9114
2024-07-11 16:04:29,767 [INFO    ] __main__: train step 4404: loss: 0.8167, policy_loss: 1.5388, value_loss: 0.9113
2024-07-11 16:04:29,972 [INFO    ] __main__: train step 4405: loss: 0.8169, policy_loss: 1.5387, value_loss: 0.9113
2024-07-11 16:04:30,186 [INFO    ] __main__: train step 4406: loss: 0.8170, policy_loss: 1.5386, value_loss: 0.9113
2024-07-11 16:04:30,383 [INFO    ] __main__: train step 4407: loss: 0.8171, policy_loss: 1.5385, value_loss: 0.9112
2024-07-11 16:04:30,569 [INFO    ] __main__: train step 4408: loss: 0.8172, policy_loss: 1.5384, value_loss: 0.9112
2024-07-11 16:04:30,768 [INFO    ] __main__: train step 4409: loss: 0.8173, policy_loss: 1.5383, value_loss: 0.9112
2024-07-11 16:04:30,975 [INFO    ] __main__: train step 4410: loss: 0.8174, policy_loss: 1.5381, value_loss: 0.9111
2024-07-11 16:04:31,182 [INFO    ] __main__: train step 4411: loss: 0.8175, policy_loss: 1.5380, value_loss: 0.9111
2024-07-11 16:04:31,386 [INFO    ] __main__: train step 4412: loss: 0.8176, policy_loss: 1.5379, value_loss: 0.9111
2024-07-11 16:04:31,592 [INFO    ] __main__: train step 4413: loss: 0.8177, policy_loss: 1.5378, value_loss: 0.9110
2024-07-11 16:04:31,824 [INFO    ] __main__: train step 4414: loss: 0.8178, policy_loss: 1.5377, value_loss: 0.9110
2024-07-11 16:04:32,030 [INFO    ] __main__: train step 4415: loss: 0.8179, policy_loss: 1.5376, value_loss: 0.9110
2024-07-11 16:04:32,226 [INFO    ] __main__: train step 4416: loss: 0.8180, policy_loss: 1.5375, value_loss: 0.9109
2024-07-11 16:04:32,430 [INFO    ] __main__: train step 4417: loss: 0.8181, policy_loss: 1.5374, value_loss: 0.9109
2024-07-11 16:04:32,614 [INFO    ] __main__: train step 4418: loss: 0.8182, policy_loss: 1.5373, value_loss: 0.9108
2024-07-11 16:04:32,825 [INFO    ] __main__: train step 4419: loss: 0.8183, policy_loss: 1.5372, value_loss: 0.9108
2024-07-11 16:04:34,282 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:04:34,654 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:04:34,711 [INFO    ] __main__: train step 4420: loss: 0.8185, policy_loss: 1.5370, value_loss: 0.9108
2024-07-11 16:04:34,884 [INFO    ] __main__: train step 4421: loss: 0.8186, policy_loss: 1.5369, value_loss: 0.9107
2024-07-11 16:04:35,087 [INFO    ] __main__: train step 4422: loss: 0.8187, policy_loss: 1.5368, value_loss: 0.9107
2024-07-11 16:04:35,315 [INFO    ] __main__: train step 4423: loss: 0.8188, policy_loss: 1.5367, value_loss: 0.9107
2024-07-11 16:04:35,505 [INFO    ] __main__: train step 4424: loss: 0.8189, policy_loss: 1.5366, value_loss: 0.9106
2024-07-11 16:04:35,979 [INFO    ] __main__: train step 4425: loss: 0.8190, policy_loss: 1.5365, value_loss: 0.9106
2024-07-11 16:04:36,179 [INFO    ] __main__: train step 4426: loss: 0.8191, policy_loss: 1.5364, value_loss: 0.9106
2024-07-11 16:04:36,391 [INFO    ] __main__: train step 4427: loss: 0.8192, policy_loss: 1.5363, value_loss: 0.9105
2024-07-11 16:04:36,586 [INFO    ] __main__: train step 4428: loss: 0.8193, policy_loss: 1.5362, value_loss: 0.9105
2024-07-11 16:04:36,789 [INFO    ] __main__: train step 4429: loss: 0.8194, policy_loss: 1.5361, value_loss: 0.9104
2024-07-11 16:04:36,986 [INFO    ] __main__: train step 4430: loss: 0.8195, policy_loss: 1.5360, value_loss: 0.9104
2024-07-11 16:04:37,189 [INFO    ] __main__: train step 4431: loss: 0.8196, policy_loss: 1.5359, value_loss: 0.9104
2024-07-11 16:04:37,398 [INFO    ] __main__: train step 4432: loss: 0.8197, policy_loss: 1.5358, value_loss: 0.9103
2024-07-11 16:04:37,633 [INFO    ] __main__: train step 4433: loss: 0.8198, policy_loss: 1.5356, value_loss: 0.9103
2024-07-11 16:04:37,838 [INFO    ] __main__: train step 4434: loss: 0.8199, policy_loss: 1.5355, value_loss: 0.9103
2024-07-11 16:04:38,042 [INFO    ] __main__: train step 4435: loss: 0.8200, policy_loss: 1.5354, value_loss: 0.9102
2024-07-11 16:04:38,238 [INFO    ] __main__: train step 4436: loss: 0.8202, policy_loss: 1.5353, value_loss: 0.9102
2024-07-11 16:04:39,672 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:04:40,059 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:04:40,115 [INFO    ] __main__: train step 4437: loss: 0.8203, policy_loss: 1.5352, value_loss: 0.9102
2024-07-11 16:04:40,287 [INFO    ] __main__: train step 4438: loss: 0.8204, policy_loss: 1.5351, value_loss: 0.9101
2024-07-11 16:04:40,491 [INFO    ] __main__: train step 4439: loss: 0.8205, policy_loss: 1.5350, value_loss: 0.9101
2024-07-11 16:04:40,700 [INFO    ] __main__: train step 4440: loss: 0.8206, policy_loss: 1.5349, value_loss: 0.9100
2024-07-11 16:04:40,936 [INFO    ] __main__: train step 4441: loss: 0.8207, policy_loss: 1.5348, value_loss: 0.9100
2024-07-11 16:04:41,166 [INFO    ] __main__: train step 4442: loss: 0.8208, policy_loss: 1.5347, value_loss: 0.9100
2024-07-11 16:04:41,397 [INFO    ] __main__: train step 4443: loss: 0.8209, policy_loss: 1.5345, value_loss: 0.9099
2024-07-11 16:04:41,619 [INFO    ] __main__: train step 4444: loss: 0.8210, policy_loss: 1.5344, value_loss: 0.9099
2024-07-11 16:04:41,826 [INFO    ] __main__: train step 4445: loss: 0.8211, policy_loss: 1.5343, value_loss: 0.9099
2024-07-11 16:04:42,029 [INFO    ] __main__: train step 4446: loss: 0.8212, policy_loss: 1.5342, value_loss: 0.9098
2024-07-11 16:04:42,229 [INFO    ] __main__: train step 4447: loss: 0.8213, policy_loss: 1.5341, value_loss: 0.9098
2024-07-11 16:04:42,437 [INFO    ] __main__: train step 4448: loss: 0.8214, policy_loss: 1.5340, value_loss: 0.9097
2024-07-11 16:04:42,914 [INFO    ] __main__: train step 4449: loss: 0.8215, policy_loss: 1.5339, value_loss: 0.9097
2024-07-11 16:04:43,155 [INFO    ] __main__: train step 4450: loss: 0.8216, policy_loss: 1.5338, value_loss: 0.9097
2024-07-11 16:04:43,365 [INFO    ] __main__: train step 4451: loss: 0.8217, policy_loss: 1.5337, value_loss: 0.9096
2024-07-11 16:04:43,569 [INFO    ] __main__: train step 4452: loss: 0.8218, policy_loss: 1.5336, value_loss: 0.9096
2024-07-11 16:04:43,786 [INFO    ] __main__: train step 4453: loss: 0.8219, policy_loss: 1.5335, value_loss: 0.9096
2024-07-11 16:04:45,227 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:04:45,616 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:04:45,670 [INFO    ] __main__: train step 4454: loss: 0.8220, policy_loss: 1.5333, value_loss: 0.9095
2024-07-11 16:04:45,834 [INFO    ] __main__: train step 4455: loss: 0.8222, policy_loss: 1.5332, value_loss: 0.9095
2024-07-11 16:04:46,051 [INFO    ] __main__: train step 4456: loss: 0.8223, policy_loss: 1.5331, value_loss: 0.9095
2024-07-11 16:04:46,248 [INFO    ] __main__: train step 4457: loss: 0.8224, policy_loss: 1.5330, value_loss: 0.9094
2024-07-11 16:04:46,445 [INFO    ] __main__: train step 4458: loss: 0.8225, policy_loss: 1.5329, value_loss: 0.9094
2024-07-11 16:04:46,647 [INFO    ] __main__: train step 4459: loss: 0.8226, policy_loss: 1.5328, value_loss: 0.9093
2024-07-11 16:04:46,858 [INFO    ] __main__: train step 4460: loss: 0.8227, policy_loss: 1.5327, value_loss: 0.9093
2024-07-11 16:04:47,063 [INFO    ] __main__: train step 4461: loss: 0.8228, policy_loss: 1.5326, value_loss: 0.9093
2024-07-11 16:04:47,260 [INFO    ] __main__: train step 4462: loss: 0.8229, policy_loss: 1.5325, value_loss: 0.9092
2024-07-11 16:04:47,481 [INFO    ] __main__: train step 4463: loss: 0.8230, policy_loss: 1.5324, value_loss: 0.9092
2024-07-11 16:04:47,715 [INFO    ] __main__: train step 4464: loss: 0.8231, policy_loss: 1.5323, value_loss: 0.9092
2024-07-11 16:04:47,949 [INFO    ] __main__: train step 4465: loss: 0.8232, policy_loss: 1.5321, value_loss: 0.9091
2024-07-11 16:04:48,150 [INFO    ] __main__: train step 4466: loss: 0.8233, policy_loss: 1.5320, value_loss: 0.9091
2024-07-11 16:04:48,352 [INFO    ] __main__: train step 4467: loss: 0.8234, policy_loss: 1.5319, value_loss: 0.9090
2024-07-11 16:04:48,564 [INFO    ] __main__: train step 4468: loss: 0.8235, policy_loss: 1.5318, value_loss: 0.9090
2024-07-11 16:04:48,782 [INFO    ] __main__: train step 4469: loss: 0.8236, policy_loss: 1.5317, value_loss: 0.9090
2024-07-11 16:04:48,984 [INFO    ] __main__: train step 4470: loss: 0.8237, policy_loss: 1.5316, value_loss: 0.9089
2024-07-11 16:04:50,430 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:04:50,805 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:04:50,865 [INFO    ] __main__: train step 4471: loss: 0.8238, policy_loss: 1.5315, value_loss: 0.9089
2024-07-11 16:04:51,037 [INFO    ] __main__: train step 4472: loss: 0.8239, policy_loss: 1.5314, value_loss: 0.9089
2024-07-11 16:04:51,507 [INFO    ] __main__: train step 4473: loss: 0.8241, policy_loss: 1.5313, value_loss: 0.9088
2024-07-11 16:04:51,715 [INFO    ] __main__: train step 4474: loss: 0.8242, policy_loss: 1.5312, value_loss: 0.9088
2024-07-11 16:04:51,928 [INFO    ] __main__: train step 4475: loss: 0.8243, policy_loss: 1.5311, value_loss: 0.9088
2024-07-11 16:04:52,165 [INFO    ] __main__: train step 4476: loss: 0.8244, policy_loss: 1.5310, value_loss: 0.9087
2024-07-11 16:04:52,355 [INFO    ] __main__: train step 4477: loss: 0.8245, policy_loss: 1.5308, value_loss: 0.9087
2024-07-11 16:04:52,553 [INFO    ] __main__: train step 4478: loss: 0.8246, policy_loss: 1.5307, value_loss: 0.9086
2024-07-11 16:04:52,757 [INFO    ] __main__: train step 4479: loss: 0.8247, policy_loss: 1.5306, value_loss: 0.9086
2024-07-11 16:04:52,962 [INFO    ] __main__: train step 4480: loss: 0.8248, policy_loss: 1.5305, value_loss: 0.9086
2024-07-11 16:04:53,165 [INFO    ] __main__: train step 4481: loss: 0.8249, policy_loss: 1.5304, value_loss: 0.9085
2024-07-11 16:04:53,375 [INFO    ] __main__: train step 4482: loss: 0.8250, policy_loss: 1.5303, value_loss: 0.9085
2024-07-11 16:04:53,582 [INFO    ] __main__: train step 4483: loss: 0.8251, policy_loss: 1.5302, value_loss: 0.9085
2024-07-11 16:04:53,778 [INFO    ] __main__: train step 4484: loss: 0.8252, policy_loss: 1.5301, value_loss: 0.9084
2024-07-11 16:04:53,962 [INFO    ] __main__: train step 4485: loss: 0.8253, policy_loss: 1.5300, value_loss: 0.9084
2024-07-11 16:04:54,169 [INFO    ] __main__: train step 4486: loss: 0.8254, policy_loss: 1.5299, value_loss: 0.9084
2024-07-11 16:04:54,367 [INFO    ] __main__: train step 4487: loss: 0.8255, policy_loss: 1.5298, value_loss: 0.9083
2024-07-11 16:04:55,812 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:04:56,209 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:04:56,269 [INFO    ] __main__: train step 4488: loss: 0.8256, policy_loss: 1.5297, value_loss: 0.9083
2024-07-11 16:04:56,436 [INFO    ] __main__: train step 4489: loss: 0.8257, policy_loss: 1.5295, value_loss: 0.9082
2024-07-11 16:04:56,643 [INFO    ] __main__: train step 4490: loss: 0.8258, policy_loss: 1.5294, value_loss: 0.9082
2024-07-11 16:04:56,853 [INFO    ] __main__: train step 4491: loss: 0.8259, policy_loss: 1.5293, value_loss: 0.9082
2024-07-11 16:04:57,054 [INFO    ] __main__: train step 4492: loss: 0.8260, policy_loss: 1.5292, value_loss: 0.9081
2024-07-11 16:04:57,246 [INFO    ] __main__: train step 4493: loss: 0.8262, policy_loss: 1.5291, value_loss: 0.9081
2024-07-11 16:04:57,448 [INFO    ] __main__: train step 4494: loss: 0.8263, policy_loss: 1.5290, value_loss: 0.9081
2024-07-11 16:04:57,642 [INFO    ] __main__: train step 4495: loss: 0.8264, policy_loss: 1.5289, value_loss: 0.9080
2024-07-11 16:04:58,122 [INFO    ] __main__: train step 4496: loss: 0.8265, policy_loss: 1.5288, value_loss: 0.9080
2024-07-11 16:04:58,342 [INFO    ] __main__: train step 4497: loss: 0.8266, policy_loss: 1.5287, value_loss: 0.9080
2024-07-11 16:04:58,542 [INFO    ] __main__: train step 4498: loss: 0.8267, policy_loss: 1.5285, value_loss: 0.9079
2024-07-11 16:04:58,754 [INFO    ] __main__: train step 4499: loss: 0.8268, policy_loss: 1.5284, value_loss: 0.9079
2024-07-11 16:04:58,985 [INFO    ] __main__: train step 4500: loss: 0.8269, policy_loss: 1.5283, value_loss: 0.9078
2024-07-11 16:04:59,191 [INFO    ] __main__: train step 4501: loss: 0.8270, policy_loss: 1.5282, value_loss: 0.9078
2024-07-11 16:04:59,398 [INFO    ] __main__: train step 4502: loss: 0.8271, policy_loss: 1.5281, value_loss: 0.9078
2024-07-11 16:04:59,603 [INFO    ] __main__: train step 4503: loss: 0.8272, policy_loss: 1.5280, value_loss: 0.9077
2024-07-11 16:04:59,799 [INFO    ] __main__: train step 4504: loss: 0.8273, policy_loss: 1.5279, value_loss: 0.9077
2024-07-11 16:05:01,251 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:05:01,648 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:05:01,707 [INFO    ] __main__: train step 4505: loss: 0.8274, policy_loss: 1.5278, value_loss: 0.9076
2024-07-11 16:05:01,887 [INFO    ] __main__: train step 4506: loss: 0.8275, policy_loss: 1.5277, value_loss: 0.9076
2024-07-11 16:05:02,100 [INFO    ] __main__: train step 4507: loss: 0.8276, policy_loss: 1.5276, value_loss: 0.9076
2024-07-11 16:05:02,333 [INFO    ] __main__: train step 4508: loss: 0.8277, policy_loss: 1.5275, value_loss: 0.9075
2024-07-11 16:05:02,540 [INFO    ] __main__: train step 4509: loss: 0.8278, policy_loss: 1.5274, value_loss: 0.9075
2024-07-11 16:05:02,754 [INFO    ] __main__: train step 4510: loss: 0.8279, policy_loss: 1.5273, value_loss: 0.9075
2024-07-11 16:05:02,958 [INFO    ] __main__: train step 4511: loss: 0.8280, policy_loss: 1.5271, value_loss: 0.9074
2024-07-11 16:05:03,172 [INFO    ] __main__: train step 4512: loss: 0.8281, policy_loss: 1.5270, value_loss: 0.9074
2024-07-11 16:05:03,370 [INFO    ] __main__: train step 4513: loss: 0.8282, policy_loss: 1.5269, value_loss: 0.9074
2024-07-11 16:05:03,581 [INFO    ] __main__: train step 4514: loss: 0.8283, policy_loss: 1.5268, value_loss: 0.9073
2024-07-11 16:05:03,787 [INFO    ] __main__: train step 4515: loss: 0.8284, policy_loss: 1.5267, value_loss: 0.9073
2024-07-11 16:05:04,001 [INFO    ] __main__: train step 4516: loss: 0.8285, policy_loss: 1.5266, value_loss: 0.9072
2024-07-11 16:05:04,200 [INFO    ] __main__: train step 4517: loss: 0.8286, policy_loss: 1.5265, value_loss: 0.9072
2024-07-11 16:05:04,405 [INFO    ] __main__: train step 4518: loss: 0.8287, policy_loss: 1.5264, value_loss: 0.9072
2024-07-11 16:05:04,606 [INFO    ] __main__: train step 4519: loss: 0.8288, policy_loss: 1.5263, value_loss: 0.9071
2024-07-11 16:05:05,084 [INFO    ] __main__: train step 4520: loss: 0.8290, policy_loss: 1.5262, value_loss: 0.9071
2024-07-11 16:05:05,309 [INFO    ] __main__: train step 4521: loss: 0.8291, policy_loss: 1.5261, value_loss: 0.9071
2024-07-11 16:05:06,767 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:05:07,118 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:05:07,178 [INFO    ] __main__: train step 4522: loss: 0.8292, policy_loss: 1.5260, value_loss: 0.9070
2024-07-11 16:05:07,366 [INFO    ] __main__: train step 4523: loss: 0.8293, policy_loss: 1.5259, value_loss: 0.9070
2024-07-11 16:05:07,590 [INFO    ] __main__: train step 4524: loss: 0.8294, policy_loss: 1.5258, value_loss: 0.9069
2024-07-11 16:05:07,803 [INFO    ] __main__: train step 4525: loss: 0.8295, policy_loss: 1.5256, value_loss: 0.9069
2024-07-11 16:05:08,019 [INFO    ] __main__: train step 4526: loss: 0.8296, policy_loss: 1.5255, value_loss: 0.9069
2024-07-11 16:05:08,219 [INFO    ] __main__: train step 4527: loss: 0.8297, policy_loss: 1.5254, value_loss: 0.9068
2024-07-11 16:05:08,425 [INFO    ] __main__: train step 4528: loss: 0.8298, policy_loss: 1.5253, value_loss: 0.9068
2024-07-11 16:05:08,662 [INFO    ] __main__: train step 4529: loss: 0.8299, policy_loss: 1.5252, value_loss: 0.9067
2024-07-11 16:05:08,855 [INFO    ] __main__: train step 4530: loss: 0.8300, policy_loss: 1.5251, value_loss: 0.9067
2024-07-11 16:05:09,048 [INFO    ] __main__: train step 4531: loss: 0.8301, policy_loss: 1.5250, value_loss: 0.9067
2024-07-11 16:05:09,256 [INFO    ] __main__: train step 4532: loss: 0.8302, policy_loss: 1.5249, value_loss: 0.9066
2024-07-11 16:05:09,462 [INFO    ] __main__: train step 4533: loss: 0.8303, policy_loss: 1.5248, value_loss: 0.9066
2024-07-11 16:05:09,691 [INFO    ] __main__: train step 4534: loss: 0.8304, policy_loss: 1.5247, value_loss: 0.9066
2024-07-11 16:05:09,884 [INFO    ] __main__: train step 4535: loss: 0.8305, policy_loss: 1.5246, value_loss: 0.9065
2024-07-11 16:05:10,085 [INFO    ] __main__: train step 4536: loss: 0.8306, policy_loss: 1.5245, value_loss: 0.9065
2024-07-11 16:05:10,280 [INFO    ] __main__: train step 4537: loss: 0.8307, policy_loss: 1.5244, value_loss: 0.9065
2024-07-11 16:05:10,482 [INFO    ] __main__: train step 4538: loss: 0.8308, policy_loss: 1.5242, value_loss: 0.9064
2024-07-11 16:05:11,938 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:05:12,335 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:05:12,398 [INFO    ] __main__: train step 4539: loss: 0.8309, policy_loss: 1.5241, value_loss: 0.9064
2024-07-11 16:05:12,570 [INFO    ] __main__: train step 4540: loss: 0.8310, policy_loss: 1.5240, value_loss: 0.9063
2024-07-11 16:05:12,767 [INFO    ] __main__: train step 4541: loss: 0.8312, policy_loss: 1.5239, value_loss: 0.9063
2024-07-11 16:05:12,967 [INFO    ] __main__: train step 4542: loss: 0.8313, policy_loss: 1.5238, value_loss: 0.9063
2024-07-11 16:05:13,435 [INFO    ] __main__: train step 4543: loss: 0.8314, policy_loss: 1.5237, value_loss: 0.9062
2024-07-11 16:05:13,643 [INFO    ] __main__: train step 4544: loss: 0.8315, policy_loss: 1.5236, value_loss: 0.9062
2024-07-11 16:05:13,850 [INFO    ] __main__: train step 4545: loss: 0.8316, policy_loss: 1.5235, value_loss: 0.9062
2024-07-11 16:05:14,058 [INFO    ] __main__: train step 4546: loss: 0.8317, policy_loss: 1.5234, value_loss: 0.9061
2024-07-11 16:05:14,257 [INFO    ] __main__: train step 4547: loss: 0.8318, policy_loss: 1.5233, value_loss: 0.9061
2024-07-11 16:05:14,459 [INFO    ] __main__: train step 4548: loss: 0.8319, policy_loss: 1.5232, value_loss: 0.9061
2024-07-11 16:05:14,661 [INFO    ] __main__: train step 4549: loss: 0.8320, policy_loss: 1.5231, value_loss: 0.9060
2024-07-11 16:05:14,855 [INFO    ] __main__: train step 4550: loss: 0.8321, policy_loss: 1.5229, value_loss: 0.9060
2024-07-11 16:05:15,052 [INFO    ] __main__: train step 4551: loss: 0.8322, policy_loss: 1.5228, value_loss: 0.9059
2024-07-11 16:05:15,250 [INFO    ] __main__: train step 4552: loss: 0.8323, policy_loss: 1.5227, value_loss: 0.9059
2024-07-11 16:05:15,462 [INFO    ] __main__: train step 4553: loss: 0.8324, policy_loss: 1.5226, value_loss: 0.9059
2024-07-11 16:05:15,699 [INFO    ] __main__: train step 4554: loss: 0.8325, policy_loss: 1.5225, value_loss: 0.9058
2024-07-11 16:05:15,898 [INFO    ] __main__: train step 4555: loss: 0.8326, policy_loss: 1.5224, value_loss: 0.9058
2024-07-11 16:05:17,340 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:05:17,750 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:05:17,809 [INFO    ] __main__: train step 4556: loss: 0.8327, policy_loss: 1.5223, value_loss: 0.9058
2024-07-11 16:05:17,984 [INFO    ] __main__: train step 4557: loss: 0.8328, policy_loss: 1.5222, value_loss: 0.9057
2024-07-11 16:05:18,184 [INFO    ] __main__: train step 4558: loss: 0.8329, policy_loss: 1.5221, value_loss: 0.9057
2024-07-11 16:05:18,385 [INFO    ] __main__: train step 4559: loss: 0.8330, policy_loss: 1.5220, value_loss: 0.9056
2024-07-11 16:05:18,577 [INFO    ] __main__: train step 4560: loss: 0.8331, policy_loss: 1.5219, value_loss: 0.9056
2024-07-11 16:05:18,772 [INFO    ] __main__: train step 4561: loss: 0.8332, policy_loss: 1.5218, value_loss: 0.9056
2024-07-11 16:05:18,972 [INFO    ] __main__: train step 4562: loss: 0.8333, policy_loss: 1.5217, value_loss: 0.9055
2024-07-11 16:05:19,176 [INFO    ] __main__: train step 4563: loss: 0.8334, policy_loss: 1.5216, value_loss: 0.9055
2024-07-11 16:05:19,379 [INFO    ] __main__: train step 4564: loss: 0.8335, policy_loss: 1.5215, value_loss: 0.9055
2024-07-11 16:05:19,597 [INFO    ] __main__: train step 4565: loss: 0.8336, policy_loss: 1.5213, value_loss: 0.9054
2024-07-11 16:05:20,089 [INFO    ] __main__: train step 4566: loss: 0.8337, policy_loss: 1.5212, value_loss: 0.9054
2024-07-11 16:05:20,308 [INFO    ] __main__: train step 4567: loss: 0.8338, policy_loss: 1.5211, value_loss: 0.9053
2024-07-11 16:05:20,535 [INFO    ] __main__: train step 4568: loss: 0.8340, policy_loss: 1.5210, value_loss: 0.9053
2024-07-11 16:05:20,730 [INFO    ] __main__: train step 4569: loss: 0.8341, policy_loss: 1.5209, value_loss: 0.9053
2024-07-11 16:05:20,939 [INFO    ] __main__: train step 4570: loss: 0.8342, policy_loss: 1.5208, value_loss: 0.9052
2024-07-11 16:05:21,140 [INFO    ] __main__: train step 4571: loss: 0.8343, policy_loss: 1.5207, value_loss: 0.9052
2024-07-11 16:05:21,362 [INFO    ] __main__: train step 4572: loss: 0.8344, policy_loss: 1.5206, value_loss: 0.9052
2024-07-11 16:05:22,813 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:05:23,197 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:05:23,253 [INFO    ] __main__: train step 4573: loss: 0.8345, policy_loss: 1.5205, value_loss: 0.9051
2024-07-11 16:05:23,443 [INFO    ] __main__: train step 4574: loss: 0.8346, policy_loss: 1.5204, value_loss: 0.9051
2024-07-11 16:05:23,650 [INFO    ] __main__: train step 4575: loss: 0.8347, policy_loss: 1.5203, value_loss: 0.9051
2024-07-11 16:05:23,847 [INFO    ] __main__: train step 4576: loss: 0.8348, policy_loss: 1.5202, value_loss: 0.9050
2024-07-11 16:05:24,029 [INFO    ] __main__: train step 4577: loss: 0.8349, policy_loss: 1.5201, value_loss: 0.9050
2024-07-11 16:05:24,216 [INFO    ] __main__: train step 4578: loss: 0.8350, policy_loss: 1.5200, value_loss: 0.9049
2024-07-11 16:05:24,417 [INFO    ] __main__: train step 4579: loss: 0.8351, policy_loss: 1.5199, value_loss: 0.9049
2024-07-11 16:05:24,645 [INFO    ] __main__: train step 4580: loss: 0.8352, policy_loss: 1.5198, value_loss: 0.9049
2024-07-11 16:05:24,837 [INFO    ] __main__: train step 4581: loss: 0.8353, policy_loss: 1.5196, value_loss: 0.9048
2024-07-11 16:05:25,026 [INFO    ] __main__: train step 4582: loss: 0.8354, policy_loss: 1.5195, value_loss: 0.9048
2024-07-11 16:05:25,257 [INFO    ] __main__: train step 4583: loss: 0.8355, policy_loss: 1.5194, value_loss: 0.9048
2024-07-11 16:05:25,466 [INFO    ] __main__: train step 4584: loss: 0.8356, policy_loss: 1.5193, value_loss: 0.9047
2024-07-11 16:05:25,676 [INFO    ] __main__: train step 4585: loss: 0.8357, policy_loss: 1.5192, value_loss: 0.9047
2024-07-11 16:05:25,908 [INFO    ] __main__: train step 4586: loss: 0.8358, policy_loss: 1.5191, value_loss: 0.9047
2024-07-11 16:05:26,111 [INFO    ] __main__: train step 4587: loss: 0.8359, policy_loss: 1.5190, value_loss: 0.9046
2024-07-11 16:05:26,306 [INFO    ] __main__: train step 4588: loss: 0.8360, policy_loss: 1.5189, value_loss: 0.9046
2024-07-11 16:05:26,527 [INFO    ] __main__: train step 4589: loss: 0.8361, policy_loss: 1.5188, value_loss: 0.9045
2024-07-11 16:05:28,259 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:05:28,661 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:05:28,716 [INFO    ] __main__: train step 4590: loss: 0.8362, policy_loss: 1.5187, value_loss: 0.9045
2024-07-11 16:05:28,883 [INFO    ] __main__: train step 4591: loss: 0.8363, policy_loss: 1.5186, value_loss: 0.9045
2024-07-11 16:05:29,089 [INFO    ] __main__: train step 4592: loss: 0.8364, policy_loss: 1.5185, value_loss: 0.9044
2024-07-11 16:05:29,295 [INFO    ] __main__: train step 4593: loss: 0.8365, policy_loss: 1.5184, value_loss: 0.9044
2024-07-11 16:05:29,518 [INFO    ] __main__: train step 4594: loss: 0.8366, policy_loss: 1.5183, value_loss: 0.9044
2024-07-11 16:05:29,746 [INFO    ] __main__: train step 4595: loss: 0.8367, policy_loss: 1.5182, value_loss: 0.9043
2024-07-11 16:05:29,942 [INFO    ] __main__: train step 4596: loss: 0.8368, policy_loss: 1.5180, value_loss: 0.9043
2024-07-11 16:05:30,141 [INFO    ] __main__: train step 4597: loss: 0.8369, policy_loss: 1.5179, value_loss: 0.9043
2024-07-11 16:05:30,335 [INFO    ] __main__: train step 4598: loss: 0.8370, policy_loss: 1.5178, value_loss: 0.9042
2024-07-11 16:05:30,531 [INFO    ] __main__: train step 4599: loss: 0.8371, policy_loss: 1.5177, value_loss: 0.9042
2024-07-11 16:05:30,729 [INFO    ] __main__: train step 4600: loss: 0.8372, policy_loss: 1.5176, value_loss: 0.9041
2024-07-11 16:05:30,933 [INFO    ] __main__: train step 4601: loss: 0.8374, policy_loss: 1.5175, value_loss: 0.9041
2024-07-11 16:05:31,135 [INFO    ] __main__: train step 4602: loss: 0.8375, policy_loss: 1.5174, value_loss: 0.9041
2024-07-11 16:05:31,342 [INFO    ] __main__: train step 4603: loss: 0.8376, policy_loss: 1.5173, value_loss: 0.9040
2024-07-11 16:05:31,574 [INFO    ] __main__: train step 4604: loss: 0.8377, policy_loss: 1.5172, value_loss: 0.9040
2024-07-11 16:05:31,784 [INFO    ] __main__: train step 4605: loss: 0.8378, policy_loss: 1.5171, value_loss: 0.9040
2024-07-11 16:05:31,982 [INFO    ] __main__: train step 4606: loss: 0.8379, policy_loss: 1.5170, value_loss: 0.9039
2024-07-11 16:05:33,415 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:05:33,810 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:05:33,865 [INFO    ] __main__: train step 4607: loss: 0.8380, policy_loss: 1.5169, value_loss: 0.9039
2024-07-11 16:05:34,031 [INFO    ] __main__: train step 4608: loss: 0.8381, policy_loss: 1.5168, value_loss: 0.9039
2024-07-11 16:05:34,263 [INFO    ] __main__: train step 4609: loss: 0.8382, policy_loss: 1.5167, value_loss: 0.9038
2024-07-11 16:05:34,472 [INFO    ] __main__: train step 4610: loss: 0.8383, policy_loss: 1.5166, value_loss: 0.9038
2024-07-11 16:05:34,665 [INFO    ] __main__: train step 4611: loss: 0.8384, policy_loss: 1.5165, value_loss: 0.9037
2024-07-11 16:05:34,883 [INFO    ] __main__: train step 4612: loss: 0.8385, policy_loss: 1.5163, value_loss: 0.9037
2024-07-11 16:05:35,080 [INFO    ] __main__: train step 4613: loss: 0.8386, policy_loss: 1.5162, value_loss: 0.9037
2024-07-11 16:05:35,283 [INFO    ] __main__: train step 4614: loss: 0.8387, policy_loss: 1.5161, value_loss: 0.9036
2024-07-11 16:05:35,739 [INFO    ] __main__: train step 4615: loss: 0.8388, policy_loss: 1.5160, value_loss: 0.9036
2024-07-11 16:05:35,935 [INFO    ] __main__: train step 4616: loss: 0.8389, policy_loss: 1.5159, value_loss: 0.9036
2024-07-11 16:05:36,157 [INFO    ] __main__: train step 4617: loss: 0.8390, policy_loss: 1.5158, value_loss: 0.9035
2024-07-11 16:05:36,366 [INFO    ] __main__: train step 4618: loss: 0.8391, policy_loss: 1.5157, value_loss: 0.9035
2024-07-11 16:05:36,574 [INFO    ] __main__: train step 4619: loss: 0.8392, policy_loss: 1.5156, value_loss: 0.9034
2024-07-11 16:05:36,773 [INFO    ] __main__: train step 4620: loss: 0.8393, policy_loss: 1.5155, value_loss: 0.9034
2024-07-11 16:05:36,969 [INFO    ] __main__: train step 4621: loss: 0.8394, policy_loss: 1.5154, value_loss: 0.9034
2024-07-11 16:05:37,165 [INFO    ] __main__: train step 4622: loss: 0.8395, policy_loss: 1.5153, value_loss: 0.9033
2024-07-11 16:05:37,372 [INFO    ] __main__: train step 4623: loss: 0.8396, policy_loss: 1.5152, value_loss: 0.9033
2024-07-11 16:05:38,803 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:05:39,232 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:05:39,293 [INFO    ] __main__: train step 4624: loss: 0.8397, policy_loss: 1.5151, value_loss: 0.9033
2024-07-11 16:05:39,469 [INFO    ] __main__: train step 4625: loss: 0.8398, policy_loss: 1.5150, value_loss: 0.9032
2024-07-11 16:05:39,661 [INFO    ] __main__: train step 4626: loss: 0.8399, policy_loss: 1.5149, value_loss: 0.9032
2024-07-11 16:05:39,867 [INFO    ] __main__: train step 4627: loss: 0.8400, policy_loss: 1.5148, value_loss: 0.9031
2024-07-11 16:05:40,058 [INFO    ] __main__: train step 4628: loss: 0.8401, policy_loss: 1.5146, value_loss: 0.9031
2024-07-11 16:05:40,259 [INFO    ] __main__: train step 4629: loss: 0.8402, policy_loss: 1.5145, value_loss: 0.9031
2024-07-11 16:05:40,456 [INFO    ] __main__: train step 4630: loss: 0.8403, policy_loss: 1.5144, value_loss: 0.9030
2024-07-11 16:05:40,654 [INFO    ] __main__: train step 4631: loss: 0.8404, policy_loss: 1.5143, value_loss: 0.9030
2024-07-11 16:05:40,868 [INFO    ] __main__: train step 4632: loss: 0.8405, policy_loss: 1.5142, value_loss: 0.9030
2024-07-11 16:05:41,070 [INFO    ] __main__: train step 4633: loss: 0.8406, policy_loss: 1.5141, value_loss: 0.9029
2024-07-11 16:05:41,311 [INFO    ] __main__: train step 4634: loss: 0.8407, policy_loss: 1.5140, value_loss: 0.9029
2024-07-11 16:05:41,519 [INFO    ] __main__: train step 4635: loss: 0.8408, policy_loss: 1.5139, value_loss: 0.9029
2024-07-11 16:05:41,722 [INFO    ] __main__: train step 4636: loss: 0.8409, policy_loss: 1.5138, value_loss: 0.9028
2024-07-11 16:05:41,925 [INFO    ] __main__: train step 4637: loss: 0.8410, policy_loss: 1.5137, value_loss: 0.9028
2024-07-11 16:05:42,399 [INFO    ] __main__: train step 4638: loss: 0.8411, policy_loss: 1.5136, value_loss: 0.9027
2024-07-11 16:05:42,630 [INFO    ] __main__: train step 4639: loss: 0.8412, policy_loss: 1.5135, value_loss: 0.9027
2024-07-11 16:05:42,838 [INFO    ] __main__: train step 4640: loss: 0.8413, policy_loss: 1.5134, value_loss: 0.9027
2024-07-11 16:05:44,277 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:05:44,734 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:05:44,794 [INFO    ] __main__: train step 4641: loss: 0.8414, policy_loss: 1.5133, value_loss: 0.9026
2024-07-11 16:05:44,958 [INFO    ] __main__: train step 4642: loss: 0.8415, policy_loss: 1.5131, value_loss: 0.9026
2024-07-11 16:05:45,164 [INFO    ] __main__: train step 4643: loss: 0.8416, policy_loss: 1.5130, value_loss: 0.9026
2024-07-11 16:05:45,354 [INFO    ] __main__: train step 4644: loss: 0.8417, policy_loss: 1.5129, value_loss: 0.9025
2024-07-11 16:05:45,560 [INFO    ] __main__: train step 4645: loss: 0.8418, policy_loss: 1.5128, value_loss: 0.9025
2024-07-11 16:05:45,765 [INFO    ] __main__: train step 4646: loss: 0.8419, policy_loss: 1.5127, value_loss: 0.9025
2024-07-11 16:05:45,991 [INFO    ] __main__: train step 4647: loss: 0.8420, policy_loss: 1.5126, value_loss: 0.9024
2024-07-11 16:05:46,192 [INFO    ] __main__: train step 4648: loss: 0.8421, policy_loss: 1.5125, value_loss: 0.9024
2024-07-11 16:05:46,392 [INFO    ] __main__: train step 4649: loss: 0.8422, policy_loss: 1.5124, value_loss: 0.9023
2024-07-11 16:05:46,599 [INFO    ] __main__: train step 4650: loss: 0.8423, policy_loss: 1.5123, value_loss: 0.9023
2024-07-11 16:05:46,809 [INFO    ] __main__: train step 4651: loss: 0.8424, policy_loss: 1.5122, value_loss: 0.9023
2024-07-11 16:05:47,048 [INFO    ] __main__: train step 4652: loss: 0.8425, policy_loss: 1.5121, value_loss: 0.9022
2024-07-11 16:05:47,281 [INFO    ] __main__: train step 4653: loss: 0.8426, policy_loss: 1.5120, value_loss: 0.9022
2024-07-11 16:05:47,504 [INFO    ] __main__: train step 4654: loss: 0.8427, policy_loss: 1.5119, value_loss: 0.9022
2024-07-11 16:05:47,733 [INFO    ] __main__: train step 4655: loss: 0.8428, policy_loss: 1.5118, value_loss: 0.9021
2024-07-11 16:05:47,970 [INFO    ] __main__: train step 4656: loss: 0.8429, policy_loss: 1.5117, value_loss: 0.9021
2024-07-11 16:05:48,168 [INFO    ] __main__: train step 4657: loss: 0.8430, policy_loss: 1.5116, value_loss: 0.9020
2024-07-11 16:05:49,606 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:05:50,019 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:05:50,079 [INFO    ] __main__: train step 4658: loss: 0.8431, policy_loss: 1.5115, value_loss: 0.9020
2024-07-11 16:05:50,250 [INFO    ] __main__: train step 4659: loss: 0.8432, policy_loss: 1.5113, value_loss: 0.9020
2024-07-11 16:05:50,466 [INFO    ] __main__: train step 4660: loss: 0.8433, policy_loss: 1.5112, value_loss: 0.9019
2024-07-11 16:05:50,936 [INFO    ] __main__: train step 4661: loss: 0.8434, policy_loss: 1.5111, value_loss: 0.9019
2024-07-11 16:05:51,148 [INFO    ] __main__: train step 4662: loss: 0.8435, policy_loss: 1.5110, value_loss: 0.9018
2024-07-11 16:05:51,339 [INFO    ] __main__: train step 4663: loss: 0.8436, policy_loss: 1.5109, value_loss: 0.9018
2024-07-11 16:05:51,554 [INFO    ] __main__: train step 4664: loss: 0.8437, policy_loss: 1.5108, value_loss: 0.9018
2024-07-11 16:05:51,779 [INFO    ] __main__: train step 4665: loss: 0.8438, policy_loss: 1.5107, value_loss: 0.9017
2024-07-11 16:05:51,970 [INFO    ] __main__: train step 4666: loss: 0.8439, policy_loss: 1.5106, value_loss: 0.9017
2024-07-11 16:05:52,174 [INFO    ] __main__: train step 4667: loss: 0.8440, policy_loss: 1.5105, value_loss: 0.9017
2024-07-11 16:05:52,375 [INFO    ] __main__: train step 4668: loss: 0.8441, policy_loss: 1.5104, value_loss: 0.9016
2024-07-11 16:05:52,576 [INFO    ] __main__: train step 4669: loss: 0.8443, policy_loss: 1.5103, value_loss: 0.9016
2024-07-11 16:05:52,776 [INFO    ] __main__: train step 4670: loss: 0.8444, policy_loss: 1.5102, value_loss: 0.9015
2024-07-11 16:05:52,977 [INFO    ] __main__: train step 4671: loss: 0.8445, policy_loss: 1.5101, value_loss: 0.9015
2024-07-11 16:05:53,176 [INFO    ] __main__: train step 4672: loss: 0.8446, policy_loss: 1.5100, value_loss: 0.9015
2024-07-11 16:05:53,372 [INFO    ] __main__: train step 4673: loss: 0.8447, policy_loss: 1.5099, value_loss: 0.9014
2024-07-11 16:05:53,578 [INFO    ] __main__: train step 4674: loss: 0.8448, policy_loss: 1.5098, value_loss: 0.9014
2024-07-11 16:05:55,010 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:05:55,451 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:05:55,513 [INFO    ] __main__: train step 4675: loss: 0.8449, policy_loss: 1.5097, value_loss: 0.9014
2024-07-11 16:05:55,692 [INFO    ] __main__: train step 4676: loss: 0.8450, policy_loss: 1.5096, value_loss: 0.9013
2024-07-11 16:05:55,890 [INFO    ] __main__: train step 4677: loss: 0.8451, policy_loss: 1.5095, value_loss: 0.9013
2024-07-11 16:05:56,097 [INFO    ] __main__: train step 4678: loss: 0.8452, policy_loss: 1.5094, value_loss: 0.9013
2024-07-11 16:05:56,293 [INFO    ] __main__: train step 4679: loss: 0.8453, policy_loss: 1.5093, value_loss: 0.9012
2024-07-11 16:05:56,513 [INFO    ] __main__: train step 4680: loss: 0.8454, policy_loss: 1.5092, value_loss: 0.9012
2024-07-11 16:05:56,735 [INFO    ] __main__: train step 4681: loss: 0.8455, policy_loss: 1.5090, value_loss: 0.9011
2024-07-11 16:05:56,945 [INFO    ] __main__: train step 4682: loss: 0.8456, policy_loss: 1.5089, value_loss: 0.9011
2024-07-11 16:05:57,146 [INFO    ] __main__: train step 4683: loss: 0.8457, policy_loss: 1.5088, value_loss: 0.9011
2024-07-11 16:05:57,342 [INFO    ] __main__: train step 4684: loss: 0.8458, policy_loss: 1.5087, value_loss: 0.9010
2024-07-11 16:05:57,819 [INFO    ] __main__: train step 4685: loss: 0.8459, policy_loss: 1.5086, value_loss: 0.9010
2024-07-11 16:05:58,018 [INFO    ] __main__: train step 4686: loss: 0.8460, policy_loss: 1.5085, value_loss: 0.9010
2024-07-11 16:05:58,226 [INFO    ] __main__: train step 4687: loss: 0.8461, policy_loss: 1.5084, value_loss: 0.9009
2024-07-11 16:05:58,419 [INFO    ] __main__: train step 4688: loss: 0.8462, policy_loss: 1.5083, value_loss: 0.9009
2024-07-11 16:05:58,619 [INFO    ] __main__: train step 4689: loss: 0.8463, policy_loss: 1.5082, value_loss: 0.9008
2024-07-11 16:05:58,838 [INFO    ] __main__: train step 4690: loss: 0.8464, policy_loss: 1.5081, value_loss: 0.9008
2024-07-11 16:05:59,033 [INFO    ] __main__: train step 4691: loss: 0.8465, policy_loss: 1.5080, value_loss: 0.9008
2024-07-11 16:06:00,469 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:06:00,882 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:06:00,937 [INFO    ] __main__: train step 4692: loss: 0.8466, policy_loss: 1.5079, value_loss: 0.9007
2024-07-11 16:06:01,111 [INFO    ] __main__: train step 4693: loss: 0.8467, policy_loss: 1.5078, value_loss: 0.9007
2024-07-11 16:06:01,312 [INFO    ] __main__: train step 4694: loss: 0.8468, policy_loss: 1.5077, value_loss: 0.9006
2024-07-11 16:06:01,519 [INFO    ] __main__: train step 4695: loss: 0.8469, policy_loss: 1.5076, value_loss: 0.9006
2024-07-11 16:06:01,722 [INFO    ] __main__: train step 4696: loss: 0.8470, policy_loss: 1.5075, value_loss: 0.9006
2024-07-11 16:06:01,926 [INFO    ] __main__: train step 4697: loss: 0.8471, policy_loss: 1.5074, value_loss: 0.9005
2024-07-11 16:06:02,139 [INFO    ] __main__: train step 4698: loss: 0.8472, policy_loss: 1.5073, value_loss: 0.9005
2024-07-11 16:06:02,354 [INFO    ] __main__: train step 4699: loss: 0.8473, policy_loss: 1.5071, value_loss: 0.9005
2024-07-11 16:06:02,549 [INFO    ] __main__: train step 4700: loss: 0.8474, policy_loss: 1.5070, value_loss: 0.9004
2024-07-11 16:06:02,746 [INFO    ] __main__: train step 4701: loss: 0.8475, policy_loss: 1.5069, value_loss: 0.9004
2024-07-11 16:06:02,945 [INFO    ] __main__: train step 4702: loss: 0.8476, policy_loss: 1.5068, value_loss: 0.9003
2024-07-11 16:06:03,153 [INFO    ] __main__: train step 4703: loss: 0.8476, policy_loss: 1.5067, value_loss: 0.9003
2024-07-11 16:06:03,349 [INFO    ] __main__: train step 4704: loss: 0.8478, policy_loss: 1.5066, value_loss: 0.9003
2024-07-11 16:06:03,554 [INFO    ] __main__: train step 4705: loss: 0.8479, policy_loss: 1.5065, value_loss: 0.9002
2024-07-11 16:06:03,756 [INFO    ] __main__: train step 4706: loss: 0.8480, policy_loss: 1.5064, value_loss: 0.9002
2024-07-11 16:06:04,232 [INFO    ] __main__: train step 4707: loss: 0.8481, policy_loss: 1.5063, value_loss: 0.9001
2024-07-11 16:06:04,446 [INFO    ] __main__: train step 4708: loss: 0.8482, policy_loss: 1.5062, value_loss: 0.9001
2024-07-11 16:06:05,912 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:06:06,468 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:06:06,528 [INFO    ] __main__: train step 4709: loss: 0.8483, policy_loss: 1.5061, value_loss: 0.9001
2024-07-11 16:06:06,699 [INFO    ] __main__: train step 4710: loss: 0.8484, policy_loss: 1.5060, value_loss: 0.9000
2024-07-11 16:06:06,893 [INFO    ] __main__: train step 4711: loss: 0.8485, policy_loss: 1.5059, value_loss: 0.9000
2024-07-11 16:06:07,094 [INFO    ] __main__: train step 4712: loss: 0.8486, policy_loss: 1.5058, value_loss: 0.9000
2024-07-11 16:06:07,297 [INFO    ] __main__: train step 4713: loss: 0.8487, policy_loss: 1.5057, value_loss: 0.8999
2024-07-11 16:06:07,493 [INFO    ] __main__: train step 4714: loss: 0.8488, policy_loss: 1.5056, value_loss: 0.8999
2024-07-11 16:06:07,715 [INFO    ] __main__: train step 4715: loss: 0.8489, policy_loss: 1.5055, value_loss: 0.8998
2024-07-11 16:06:07,916 [INFO    ] __main__: train step 4716: loss: 0.8490, policy_loss: 1.5054, value_loss: 0.8998
2024-07-11 16:06:08,126 [INFO    ] __main__: train step 4717: loss: 0.8491, policy_loss: 1.5053, value_loss: 0.8998
2024-07-11 16:06:08,332 [INFO    ] __main__: train step 4718: loss: 0.8492, policy_loss: 1.5052, value_loss: 0.8997
2024-07-11 16:06:08,546 [INFO    ] __main__: train step 4719: loss: 0.8493, policy_loss: 1.5051, value_loss: 0.8997
2024-07-11 16:06:08,735 [INFO    ] __main__: train step 4720: loss: 0.8494, policy_loss: 1.5050, value_loss: 0.8997
2024-07-11 16:06:08,937 [INFO    ] __main__: train step 4721: loss: 0.8494, policy_loss: 1.5048, value_loss: 0.8996
2024-07-11 16:06:09,134 [INFO    ] __main__: train step 4722: loss: 0.8495, policy_loss: 1.5047, value_loss: 0.8996
2024-07-11 16:06:09,350 [INFO    ] __main__: train step 4723: loss: 0.8496, policy_loss: 1.5046, value_loss: 0.8995
2024-07-11 16:06:09,555 [INFO    ] __main__: train step 4724: loss: 0.8497, policy_loss: 1.5045, value_loss: 0.8995
2024-07-11 16:06:09,760 [INFO    ] __main__: train step 4725: loss: 0.8498, policy_loss: 1.5044, value_loss: 0.8995
2024-07-11 16:06:11,191 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:06:11,622 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:06:11,677 [INFO    ] __main__: train step 4726: loss: 0.8499, policy_loss: 1.5043, value_loss: 0.8994
2024-07-11 16:06:11,855 [INFO    ] __main__: train step 4727: loss: 0.8500, policy_loss: 1.5042, value_loss: 0.8994
2024-07-11 16:06:12,061 [INFO    ] __main__: train step 4728: loss: 0.8501, policy_loss: 1.5041, value_loss: 0.8994
2024-07-11 16:06:12,256 [INFO    ] __main__: train step 4729: loss: 0.8502, policy_loss: 1.5040, value_loss: 0.8993
2024-07-11 16:06:12,736 [INFO    ] __main__: train step 4730: loss: 0.8503, policy_loss: 1.5039, value_loss: 0.8993
2024-07-11 16:06:12,964 [INFO    ] __main__: train step 4731: loss: 0.8504, policy_loss: 1.5038, value_loss: 0.8992
2024-07-11 16:06:13,159 [INFO    ] __main__: train step 4732: loss: 0.8505, policy_loss: 1.5037, value_loss: 0.8992
2024-07-11 16:06:13,365 [INFO    ] __main__: train step 4733: loss: 0.8506, policy_loss: 1.5036, value_loss: 0.8992
2024-07-11 16:06:13,565 [INFO    ] __main__: train step 4734: loss: 0.8507, policy_loss: 1.5035, value_loss: 0.8991
2024-07-11 16:06:13,785 [INFO    ] __main__: train step 4735: loss: 0.8508, policy_loss: 1.5034, value_loss: 0.8991
2024-07-11 16:06:14,008 [INFO    ] __main__: train step 4736: loss: 0.8509, policy_loss: 1.5033, value_loss: 0.8990
2024-07-11 16:06:14,205 [INFO    ] __main__: train step 4737: loss: 0.8510, policy_loss: 1.5032, value_loss: 0.8990
2024-07-11 16:06:14,414 [INFO    ] __main__: train step 4738: loss: 0.8511, policy_loss: 1.5030, value_loss: 0.8990
2024-07-11 16:06:14,607 [INFO    ] __main__: train step 4739: loss: 0.8512, policy_loss: 1.5029, value_loss: 0.8989
2024-07-11 16:06:14,801 [INFO    ] __main__: train step 4740: loss: 0.8513, policy_loss: 1.5028, value_loss: 0.8989
2024-07-11 16:06:14,997 [INFO    ] __main__: train step 4741: loss: 0.8514, policy_loss: 1.5027, value_loss: 0.8989
2024-07-11 16:06:15,200 [INFO    ] __main__: train step 4742: loss: 0.8515, policy_loss: 1.5026, value_loss: 0.8988
2024-07-11 16:06:16,642 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:06:17,095 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:06:17,155 [INFO    ] __main__: train step 4743: loss: 0.8516, policy_loss: 1.5025, value_loss: 0.8988
2024-07-11 16:06:17,334 [INFO    ] __main__: train step 4744: loss: 0.8517, policy_loss: 1.5024, value_loss: 0.8988
2024-07-11 16:06:17,556 [INFO    ] __main__: train step 4745: loss: 0.8518, policy_loss: 1.5023, value_loss: 0.8987
2024-07-11 16:06:17,752 [INFO    ] __main__: train step 4746: loss: 0.8519, policy_loss: 1.5022, value_loss: 0.8987
2024-07-11 16:06:17,955 [INFO    ] __main__: train step 4747: loss: 0.8520, policy_loss: 1.5021, value_loss: 0.8986
2024-07-11 16:06:18,154 [INFO    ] __main__: train step 4748: loss: 0.8521, policy_loss: 1.5020, value_loss: 0.8986
2024-07-11 16:06:18,348 [INFO    ] __main__: train step 4749: loss: 0.8522, policy_loss: 1.5019, value_loss: 0.8986
2024-07-11 16:06:18,556 [INFO    ] __main__: train step 4750: loss: 0.8523, policy_loss: 1.5018, value_loss: 0.8985
2024-07-11 16:06:18,764 [INFO    ] __main__: train step 4751: loss: 0.8524, policy_loss: 1.5017, value_loss: 0.8985
2024-07-11 16:06:18,975 [INFO    ] __main__: train step 4752: loss: 0.8525, policy_loss: 1.5016, value_loss: 0.8985
2024-07-11 16:06:19,454 [INFO    ] __main__: train step 4753: loss: 0.8526, policy_loss: 1.5015, value_loss: 0.8984
2024-07-11 16:06:19,653 [INFO    ] __main__: train step 4754: loss: 0.8527, policy_loss: 1.5014, value_loss: 0.8984
2024-07-11 16:06:19,857 [INFO    ] __main__: train step 4755: loss: 0.8528, policy_loss: 1.5013, value_loss: 0.8983
2024-07-11 16:06:20,056 [INFO    ] __main__: train step 4756: loss: 0.8529, policy_loss: 1.5012, value_loss: 0.8983
2024-07-11 16:06:20,256 [INFO    ] __main__: train step 4757: loss: 0.8530, policy_loss: 1.5010, value_loss: 0.8983
2024-07-11 16:06:20,475 [INFO    ] __main__: train step 4758: loss: 0.8531, policy_loss: 1.5009, value_loss: 0.8982
2024-07-11 16:06:20,705 [INFO    ] __main__: train step 4759: loss: 0.8532, policy_loss: 1.5008, value_loss: 0.8982
2024-07-11 16:06:22,140 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:06:22,566 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:06:22,622 [INFO    ] __main__: train step 4760: loss: 0.8533, policy_loss: 1.5007, value_loss: 0.8982
2024-07-11 16:06:22,800 [INFO    ] __main__: train step 4761: loss: 0.8534, policy_loss: 1.5006, value_loss: 0.8981
2024-07-11 16:06:22,997 [INFO    ] __main__: train step 4762: loss: 0.8535, policy_loss: 1.5005, value_loss: 0.8981
2024-07-11 16:06:23,203 [INFO    ] __main__: train step 4763: loss: 0.8536, policy_loss: 1.5004, value_loss: 0.8980
2024-07-11 16:06:23,415 [INFO    ] __main__: train step 4764: loss: 0.8537, policy_loss: 1.5003, value_loss: 0.8980
2024-07-11 16:06:23,620 [INFO    ] __main__: train step 4765: loss: 0.8538, policy_loss: 1.5002, value_loss: 0.8980
2024-07-11 16:06:23,823 [INFO    ] __main__: train step 4766: loss: 0.8539, policy_loss: 1.5001, value_loss: 0.8979
2024-07-11 16:06:24,031 [INFO    ] __main__: train step 4767: loss: 0.8540, policy_loss: 1.5000, value_loss: 0.8979
2024-07-11 16:06:24,237 [INFO    ] __main__: train step 4768: loss: 0.8541, policy_loss: 1.4999, value_loss: 0.8979
2024-07-11 16:06:24,435 [INFO    ] __main__: train step 4769: loss: 0.8542, policy_loss: 1.4998, value_loss: 0.8978
2024-07-11 16:06:24,648 [INFO    ] __main__: train step 4770: loss: 0.8543, policy_loss: 1.4997, value_loss: 0.8978
2024-07-11 16:06:24,852 [INFO    ] __main__: train step 4771: loss: 0.8544, policy_loss: 1.4996, value_loss: 0.8977
2024-07-11 16:06:25,052 [INFO    ] __main__: train step 4772: loss: 0.8545, policy_loss: 1.4995, value_loss: 0.8977
2024-07-11 16:06:25,265 [INFO    ] __main__: train step 4773: loss: 0.8546, policy_loss: 1.4994, value_loss: 0.8977
2024-07-11 16:06:25,463 [INFO    ] __main__: train step 4774: loss: 0.8547, policy_loss: 1.4993, value_loss: 0.8976
2024-07-11 16:06:25,677 [INFO    ] __main__: train step 4775: loss: 0.8548, policy_loss: 1.4992, value_loss: 0.8976
2024-07-11 16:06:26,189 [INFO    ] __main__: train step 4776: loss: 0.8549, policy_loss: 1.4991, value_loss: 0.8976
2024-07-11 16:06:27,624 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:06:28,055 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:06:28,117 [INFO    ] __main__: train step 4777: loss: 0.8550, policy_loss: 1.4989, value_loss: 0.8975
2024-07-11 16:06:28,286 [INFO    ] __main__: train step 4778: loss: 0.8551, policy_loss: 1.4988, value_loss: 0.8975
2024-07-11 16:06:28,485 [INFO    ] __main__: train step 4779: loss: 0.8552, policy_loss: 1.4987, value_loss: 0.8975
2024-07-11 16:06:28,712 [INFO    ] __main__: train step 4780: loss: 0.8553, policy_loss: 1.4986, value_loss: 0.8974
2024-07-11 16:06:28,937 [INFO    ] __main__: train step 4781: loss: 0.8554, policy_loss: 1.4985, value_loss: 0.8974
2024-07-11 16:06:29,141 [INFO    ] __main__: train step 4782: loss: 0.8555, policy_loss: 1.4984, value_loss: 0.8973
2024-07-11 16:06:29,351 [INFO    ] __main__: train step 4783: loss: 0.8556, policy_loss: 1.4983, value_loss: 0.8973
2024-07-11 16:06:29,590 [INFO    ] __main__: train step 4784: loss: 0.8557, policy_loss: 1.4982, value_loss: 0.8973
2024-07-11 16:06:29,789 [INFO    ] __main__: train step 4785: loss: 0.8558, policy_loss: 1.4981, value_loss: 0.8972
2024-07-11 16:06:29,984 [INFO    ] __main__: train step 4786: loss: 0.8558, policy_loss: 1.4980, value_loss: 0.8972
2024-07-11 16:06:30,181 [INFO    ] __main__: train step 4787: loss: 0.8559, policy_loss: 1.4979, value_loss: 0.8971
2024-07-11 16:06:30,379 [INFO    ] __main__: train step 4788: loss: 0.8560, policy_loss: 1.4978, value_loss: 0.8971
2024-07-11 16:06:30,590 [INFO    ] __main__: train step 4789: loss: 0.8561, policy_loss: 1.4977, value_loss: 0.8971
2024-07-11 16:06:30,812 [INFO    ] __main__: train step 4790: loss: 0.8562, policy_loss: 1.4976, value_loss: 0.8970
2024-07-11 16:06:31,014 [INFO    ] __main__: train step 4791: loss: 0.8563, policy_loss: 1.4975, value_loss: 0.8970
2024-07-11 16:06:31,221 [INFO    ] __main__: train step 4792: loss: 0.8564, policy_loss: 1.4974, value_loss: 0.8970
2024-07-11 16:06:31,415 [INFO    ] __main__: train step 4793: loss: 0.8565, policy_loss: 1.4973, value_loss: 0.8969
2024-07-11 16:06:32,856 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:06:33,277 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:06:33,336 [INFO    ] __main__: train step 4794: loss: 0.8566, policy_loss: 1.4972, value_loss: 0.8969
2024-07-11 16:06:33,511 [INFO    ] __main__: train step 4795: loss: 0.8567, policy_loss: 1.4971, value_loss: 0.8968
2024-07-11 16:06:33,705 [INFO    ] __main__: train step 4796: loss: 0.8568, policy_loss: 1.4970, value_loss: 0.8968
2024-07-11 16:06:33,908 [INFO    ] __main__: train step 4797: loss: 0.8569, policy_loss: 1.4969, value_loss: 0.8968
2024-07-11 16:06:34,107 [INFO    ] __main__: train step 4798: loss: 0.8570, policy_loss: 1.4967, value_loss: 0.8967
2024-07-11 16:06:34,304 [INFO    ] __main__: train step 4799: loss: 0.8571, policy_loss: 1.4966, value_loss: 0.8967
2024-07-11 16:06:34,787 [INFO    ] __main__: train step 4800: loss: 0.8572, policy_loss: 1.4965, value_loss: 0.8967
2024-07-11 16:06:34,983 [INFO    ] __main__: train step 4801: loss: 0.8573, policy_loss: 1.4964, value_loss: 0.8966
2024-07-11 16:06:35,190 [INFO    ] __main__: train step 4802: loss: 0.8574, policy_loss: 1.4963, value_loss: 0.8966
2024-07-11 16:06:35,424 [INFO    ] __main__: train step 4803: loss: 0.8575, policy_loss: 1.4962, value_loss: 0.8965
2024-07-11 16:06:35,619 [INFO    ] __main__: train step 4804: loss: 0.8576, policy_loss: 1.4961, value_loss: 0.8965
2024-07-11 16:06:35,824 [INFO    ] __main__: train step 4805: loss: 0.8577, policy_loss: 1.4960, value_loss: 0.8965
2024-07-11 16:06:36,022 [INFO    ] __main__: train step 4806: loss: 0.8578, policy_loss: 1.4959, value_loss: 0.8964
2024-07-11 16:06:36,222 [INFO    ] __main__: train step 4807: loss: 0.8579, policy_loss: 1.4958, value_loss: 0.8964
2024-07-11 16:06:36,426 [INFO    ] __main__: train step 4808: loss: 0.8580, policy_loss: 1.4957, value_loss: 0.8963
2024-07-11 16:06:36,622 [INFO    ] __main__: train step 4809: loss: 0.8581, policy_loss: 1.4956, value_loss: 0.8963
2024-07-11 16:06:36,830 [INFO    ] __main__: train step 4810: loss: 0.8582, policy_loss: 1.4955, value_loss: 0.8963
2024-07-11 16:06:38,266 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:06:38,696 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:06:38,758 [INFO    ] __main__: train step 4811: loss: 0.8583, policy_loss: 1.4954, value_loss: 0.8962
2024-07-11 16:06:38,928 [INFO    ] __main__: train step 4812: loss: 0.8584, policy_loss: 1.4953, value_loss: 0.8962
2024-07-11 16:06:39,135 [INFO    ] __main__: train step 4813: loss: 0.8585, policy_loss: 1.4952, value_loss: 0.8962
2024-07-11 16:06:39,329 [INFO    ] __main__: train step 4814: loss: 0.8585, policy_loss: 1.4951, value_loss: 0.8961
2024-07-11 16:06:39,528 [INFO    ] __main__: train step 4815: loss: 0.8586, policy_loss: 1.4950, value_loss: 0.8961
2024-07-11 16:06:39,727 [INFO    ] __main__: train step 4816: loss: 0.8587, policy_loss: 1.4949, value_loss: 0.8960
2024-07-11 16:06:39,920 [INFO    ] __main__: train step 4817: loss: 0.8588, policy_loss: 1.4948, value_loss: 0.8960
2024-07-11 16:06:40,123 [INFO    ] __main__: train step 4818: loss: 0.8589, policy_loss: 1.4947, value_loss: 0.8960
2024-07-11 16:06:40,324 [INFO    ] __main__: train step 4819: loss: 0.8590, policy_loss: 1.4946, value_loss: 0.8959
2024-07-11 16:06:40,520 [INFO    ] __main__: train step 4820: loss: 0.8591, policy_loss: 1.4944, value_loss: 0.8959
2024-07-11 16:06:40,734 [INFO    ] __main__: train step 4821: loss: 0.8592, policy_loss: 1.4943, value_loss: 0.8958
2024-07-11 16:06:40,924 [INFO    ] __main__: train step 4822: loss: 0.8593, policy_loss: 1.4942, value_loss: 0.8958
2024-07-11 16:06:41,126 [INFO    ] __main__: train step 4823: loss: 0.8594, policy_loss: 1.4941, value_loss: 0.8958
2024-07-11 16:06:41,607 [INFO    ] __main__: train step 4824: loss: 0.8595, policy_loss: 1.4940, value_loss: 0.8957
2024-07-11 16:06:41,824 [INFO    ] __main__: train step 4825: loss: 0.8596, policy_loss: 1.4939, value_loss: 0.8957
2024-07-11 16:06:42,019 [INFO    ] __main__: train step 4826: loss: 0.8597, policy_loss: 1.4938, value_loss: 0.8957
2024-07-11 16:06:42,224 [INFO    ] __main__: train step 4827: loss: 0.8598, policy_loss: 1.4937, value_loss: 0.8956
2024-07-11 16:06:43,666 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:06:44,107 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:06:44,167 [INFO    ] __main__: train step 4828: loss: 0.8599, policy_loss: 1.4936, value_loss: 0.8956
2024-07-11 16:06:44,329 [INFO    ] __main__: train step 4829: loss: 0.8600, policy_loss: 1.4935, value_loss: 0.8955
2024-07-11 16:06:44,544 [INFO    ] __main__: train step 4830: loss: 0.8601, policy_loss: 1.4934, value_loss: 0.8955
2024-07-11 16:06:44,736 [INFO    ] __main__: train step 4831: loss: 0.8602, policy_loss: 1.4933, value_loss: 0.8955
2024-07-11 16:06:44,939 [INFO    ] __main__: train step 4832: loss: 0.8603, policy_loss: 1.4932, value_loss: 0.8954
2024-07-11 16:06:45,146 [INFO    ] __main__: train step 4833: loss: 0.8604, policy_loss: 1.4931, value_loss: 0.8954
2024-07-11 16:06:45,338 [INFO    ] __main__: train step 4834: loss: 0.8605, policy_loss: 1.4930, value_loss: 0.8954
2024-07-11 16:06:45,540 [INFO    ] __main__: train step 4835: loss: 0.8606, policy_loss: 1.4929, value_loss: 0.8953
2024-07-11 16:06:45,745 [INFO    ] __main__: train step 4836: loss: 0.8607, policy_loss: 1.4928, value_loss: 0.8953
2024-07-11 16:06:45,944 [INFO    ] __main__: train step 4837: loss: 0.8608, policy_loss: 1.4927, value_loss: 0.8952
2024-07-11 16:06:46,150 [INFO    ] __main__: train step 4838: loss: 0.8609, policy_loss: 1.4926, value_loss: 0.8952
2024-07-11 16:06:46,344 [INFO    ] __main__: train step 4839: loss: 0.8610, policy_loss: 1.4925, value_loss: 0.8952
2024-07-11 16:06:46,584 [INFO    ] __main__: train step 4840: loss: 0.8611, policy_loss: 1.4924, value_loss: 0.8951
2024-07-11 16:06:46,788 [INFO    ] __main__: train step 4841: loss: 0.8611, policy_loss: 1.4923, value_loss: 0.8951
2024-07-11 16:06:46,982 [INFO    ] __main__: train step 4842: loss: 0.8612, policy_loss: 1.4922, value_loss: 0.8951
2024-07-11 16:06:47,192 [INFO    ] __main__: train step 4843: loss: 0.8613, policy_loss: 1.4921, value_loss: 0.8950
2024-07-11 16:06:47,393 [INFO    ] __main__: train step 4844: loss: 0.8614, policy_loss: 1.4920, value_loss: 0.8950
2024-07-11 16:06:48,829 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:06:49,224 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:06:49,280 [INFO    ] __main__: train step 4845: loss: 0.8615, policy_loss: 1.4918, value_loss: 0.8949
2024-07-11 16:06:49,452 [INFO    ] __main__: train step 4846: loss: 0.8616, policy_loss: 1.4917, value_loss: 0.8949
2024-07-11 16:06:49,953 [INFO    ] __main__: train step 4847: loss: 0.8617, policy_loss: 1.4916, value_loss: 0.8949
2024-07-11 16:06:50,150 [INFO    ] __main__: train step 4848: loss: 0.8618, policy_loss: 1.4915, value_loss: 0.8948
2024-07-11 16:06:50,351 [INFO    ] __main__: train step 4849: loss: 0.8619, policy_loss: 1.4914, value_loss: 0.8948
2024-07-11 16:06:50,548 [INFO    ] __main__: train step 4850: loss: 0.8620, policy_loss: 1.4913, value_loss: 0.8948
2024-07-11 16:06:50,751 [INFO    ] __main__: train step 4851: loss: 0.8621, policy_loss: 1.4912, value_loss: 0.8947
2024-07-11 16:06:50,941 [INFO    ] __main__: train step 4852: loss: 0.8622, policy_loss: 1.4911, value_loss: 0.8947
2024-07-11 16:06:51,145 [INFO    ] __main__: train step 4853: loss: 0.8623, policy_loss: 1.4910, value_loss: 0.8946
2024-07-11 16:06:51,351 [INFO    ] __main__: train step 4854: loss: 0.8624, policy_loss: 1.4909, value_loss: 0.8946
2024-07-11 16:06:51,546 [INFO    ] __main__: train step 4855: loss: 0.8625, policy_loss: 1.4908, value_loss: 0.8946
2024-07-11 16:06:51,748 [INFO    ] __main__: train step 4856: loss: 0.8626, policy_loss: 1.4907, value_loss: 0.8945
2024-07-11 16:06:51,941 [INFO    ] __main__: train step 4857: loss: 0.8627, policy_loss: 1.4906, value_loss: 0.8945
2024-07-11 16:06:52,134 [INFO    ] __main__: train step 4858: loss: 0.8628, policy_loss: 1.4905, value_loss: 0.8945
2024-07-11 16:06:52,338 [INFO    ] __main__: train step 4859: loss: 0.8629, policy_loss: 1.4904, value_loss: 0.8944
2024-07-11 16:06:52,531 [INFO    ] __main__: train step 4860: loss: 0.8630, policy_loss: 1.4903, value_loss: 0.8944
2024-07-11 16:06:52,740 [INFO    ] __main__: train step 4861: loss: 0.8631, policy_loss: 1.4902, value_loss: 0.8943
2024-07-11 16:06:54,175 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:06:54,614 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:06:54,676 [INFO    ] __main__: train step 4862: loss: 0.8632, policy_loss: 1.4901, value_loss: 0.8943
2024-07-11 16:06:54,841 [INFO    ] __main__: train step 4863: loss: 0.8633, policy_loss: 1.4900, value_loss: 0.8943
2024-07-11 16:06:55,042 [INFO    ] __main__: train step 4864: loss: 0.8634, policy_loss: 1.4899, value_loss: 0.8942
2024-07-11 16:06:55,243 [INFO    ] __main__: train step 4865: loss: 0.8634, policy_loss: 1.4898, value_loss: 0.8942
2024-07-11 16:06:55,441 [INFO    ] __main__: train step 4866: loss: 0.8635, policy_loss: 1.4896, value_loss: 0.8942
2024-07-11 16:06:55,640 [INFO    ] __main__: train step 4867: loss: 0.8636, policy_loss: 1.4895, value_loss: 0.8941
2024-07-11 16:06:55,849 [INFO    ] __main__: train step 4868: loss: 0.8637, policy_loss: 1.4894, value_loss: 0.8941
2024-07-11 16:06:56,058 [INFO    ] __main__: train step 4869: loss: 0.8638, policy_loss: 1.4893, value_loss: 0.8940
2024-07-11 16:06:56,553 [INFO    ] __main__: train step 4870: loss: 0.8639, policy_loss: 1.4892, value_loss: 0.8940
2024-07-11 16:06:56,725 [INFO    ] __main__: train step 4871: loss: 0.8640, policy_loss: 1.4891, value_loss: 0.8940
2024-07-11 16:06:56,927 [INFO    ] __main__: train step 4872: loss: 0.8641, policy_loss: 1.4890, value_loss: 0.8939
2024-07-11 16:06:57,136 [INFO    ] __main__: train step 4873: loss: 0.8642, policy_loss: 1.4889, value_loss: 0.8939
2024-07-11 16:06:57,338 [INFO    ] __main__: train step 4874: loss: 0.8643, policy_loss: 1.4888, value_loss: 0.8938
2024-07-11 16:06:57,534 [INFO    ] __main__: train step 4875: loss: 0.8644, policy_loss: 1.4887, value_loss: 0.8938
2024-07-11 16:06:57,740 [INFO    ] __main__: train step 4876: loss: 0.8645, policy_loss: 1.4886, value_loss: 0.8938
2024-07-11 16:06:57,948 [INFO    ] __main__: train step 4877: loss: 0.8646, policy_loss: 1.4885, value_loss: 0.8937
2024-07-11 16:06:58,149 [INFO    ] __main__: train step 4878: loss: 0.8647, policy_loss: 1.4884, value_loss: 0.8937
2024-07-11 16:06:59,584 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:06:59,998 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:07:00,053 [INFO    ] __main__: train step 4879: loss: 0.8648, policy_loss: 1.4883, value_loss: 0.8937
2024-07-11 16:07:00,224 [INFO    ] __main__: train step 4880: loss: 0.8649, policy_loss: 1.4882, value_loss: 0.8936
2024-07-11 16:07:00,421 [INFO    ] __main__: train step 4881: loss: 0.8650, policy_loss: 1.4881, value_loss: 0.8936
2024-07-11 16:07:00,622 [INFO    ] __main__: train step 4882: loss: 0.8651, policy_loss: 1.4880, value_loss: 0.8935
2024-07-11 16:07:00,826 [INFO    ] __main__: train step 4883: loss: 0.8652, policy_loss: 1.4879, value_loss: 0.8935
2024-07-11 16:07:01,029 [INFO    ] __main__: train step 4884: loss: 0.8653, policy_loss: 1.4878, value_loss: 0.8935
2024-07-11 16:07:01,234 [INFO    ] __main__: train step 4885: loss: 0.8654, policy_loss: 1.4877, value_loss: 0.8934
2024-07-11 16:07:01,441 [INFO    ] __main__: train step 4886: loss: 0.8655, policy_loss: 1.4876, value_loss: 0.8934
2024-07-11 16:07:01,649 [INFO    ] __main__: train step 4887: loss: 0.8655, policy_loss: 1.4875, value_loss: 0.8934
2024-07-11 16:07:01,872 [INFO    ] __main__: train step 4888: loss: 0.8656, policy_loss: 1.4874, value_loss: 0.8933
2024-07-11 16:07:02,084 [INFO    ] __main__: train step 4889: loss: 0.8657, policy_loss: 1.4873, value_loss: 0.8933
2024-07-11 16:07:02,286 [INFO    ] __main__: train step 4890: loss: 0.8658, policy_loss: 1.4872, value_loss: 0.8932
2024-07-11 16:07:02,495 [INFO    ] __main__: train step 4891: loss: 0.8659, policy_loss: 1.4871, value_loss: 0.8932
2024-07-11 16:07:02,705 [INFO    ] __main__: train step 4892: loss: 0.8660, policy_loss: 1.4870, value_loss: 0.8932
2024-07-11 16:07:02,913 [INFO    ] __main__: train step 4893: loss: 0.8661, policy_loss: 1.4869, value_loss: 0.8931
2024-07-11 16:07:03,387 [INFO    ] __main__: train step 4894: loss: 0.8662, policy_loss: 1.4867, value_loss: 0.8931
2024-07-11 16:07:03,596 [INFO    ] __main__: train step 4895: loss: 0.8663, policy_loss: 1.4866, value_loss: 0.8930
2024-07-11 16:07:05,033 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:07:05,482 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:07:05,541 [INFO    ] __main__: train step 4896: loss: 0.8664, policy_loss: 1.4865, value_loss: 0.8930
2024-07-11 16:07:05,703 [INFO    ] __main__: train step 4897: loss: 0.8665, policy_loss: 1.4864, value_loss: 0.8930
2024-07-11 16:07:05,913 [INFO    ] __main__: train step 4898: loss: 0.8666, policy_loss: 1.4863, value_loss: 0.8929
2024-07-11 16:07:06,126 [INFO    ] __main__: train step 4899: loss: 0.8667, policy_loss: 1.4862, value_loss: 0.8929
2024-07-11 16:07:06,326 [INFO    ] __main__: train step 4900: loss: 0.8668, policy_loss: 1.4861, value_loss: 0.8929
2024-07-11 16:07:06,550 [INFO    ] __main__: train step 4901: loss: 0.8669, policy_loss: 1.4860, value_loss: 0.8928
2024-07-11 16:07:06,749 [INFO    ] __main__: train step 4902: loss: 0.8670, policy_loss: 1.4859, value_loss: 0.8928
2024-07-11 16:07:06,954 [INFO    ] __main__: train step 4903: loss: 0.8671, policy_loss: 1.4858, value_loss: 0.8928
2024-07-11 16:07:07,163 [INFO    ] __main__: train step 4904: loss: 0.8671, policy_loss: 1.4857, value_loss: 0.8927
2024-07-11 16:07:07,393 [INFO    ] __main__: train step 4905: loss: 0.8672, policy_loss: 1.4856, value_loss: 0.8927
2024-07-11 16:07:07,597 [INFO    ] __main__: train step 4906: loss: 0.8673, policy_loss: 1.4855, value_loss: 0.8926
2024-07-11 16:07:07,799 [INFO    ] __main__: train step 4907: loss: 0.8674, policy_loss: 1.4854, value_loss: 0.8926
2024-07-11 16:07:08,003 [INFO    ] __main__: train step 4908: loss: 0.8675, policy_loss: 1.4853, value_loss: 0.8926
2024-07-11 16:07:08,210 [INFO    ] __main__: train step 4909: loss: 0.8676, policy_loss: 1.4852, value_loss: 0.8925
2024-07-11 16:07:08,403 [INFO    ] __main__: train step 4910: loss: 0.8677, policy_loss: 1.4851, value_loss: 0.8925
2024-07-11 16:07:08,609 [INFO    ] __main__: train step 4911: loss: 0.8678, policy_loss: 1.4850, value_loss: 0.8924
2024-07-11 16:07:08,815 [INFO    ] __main__: train step 4912: loss: 0.8679, policy_loss: 1.4849, value_loss: 0.8924
2024-07-11 16:07:10,251 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:07:10,630 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:07:10,687 [INFO    ] __main__: train step 4913: loss: 0.8680, policy_loss: 1.4848, value_loss: 0.8924
2024-07-11 16:07:10,859 [INFO    ] __main__: train step 4914: loss: 0.8681, policy_loss: 1.4847, value_loss: 0.8923
2024-07-11 16:07:11,068 [INFO    ] __main__: train step 4915: loss: 0.8682, policy_loss: 1.4846, value_loss: 0.8923
2024-07-11 16:07:11,279 [INFO    ] __main__: train step 4916: loss: 0.8683, policy_loss: 1.4845, value_loss: 0.8923
2024-07-11 16:07:11,525 [INFO    ] __main__: train step 4917: loss: 0.8684, policy_loss: 1.4844, value_loss: 0.8922
2024-07-11 16:07:12,048 [INFO    ] __main__: train step 4918: loss: 0.8685, policy_loss: 1.4843, value_loss: 0.8922
2024-07-11 16:07:12,297 [INFO    ] __main__: train step 4919: loss: 0.8686, policy_loss: 1.4842, value_loss: 0.8921
2024-07-11 16:07:12,519 [INFO    ] __main__: train step 4920: loss: 0.8686, policy_loss: 1.4840, value_loss: 0.8921
2024-07-11 16:07:12,713 [INFO    ] __main__: train step 4921: loss: 0.8687, policy_loss: 1.4839, value_loss: 0.8921
2024-07-11 16:07:12,916 [INFO    ] __main__: train step 4922: loss: 0.8688, policy_loss: 1.4838, value_loss: 0.8920
2024-07-11 16:07:13,115 [INFO    ] __main__: train step 4923: loss: 0.8689, policy_loss: 1.4837, value_loss: 0.8920
2024-07-11 16:07:13,314 [INFO    ] __main__: train step 4924: loss: 0.8690, policy_loss: 1.4836, value_loss: 0.8920
2024-07-11 16:07:13,512 [INFO    ] __main__: train step 4925: loss: 0.8691, policy_loss: 1.4835, value_loss: 0.8919
2024-07-11 16:07:13,715 [INFO    ] __main__: train step 4926: loss: 0.8692, policy_loss: 1.4834, value_loss: 0.8919
2024-07-11 16:07:13,935 [INFO    ] __main__: train step 4927: loss: 0.8693, policy_loss: 1.4833, value_loss: 0.8918
2024-07-11 16:07:14,170 [INFO    ] __main__: train step 4928: loss: 0.8694, policy_loss: 1.4832, value_loss: 0.8918
2024-07-11 16:07:14,402 [INFO    ] __main__: train step 4929: loss: 0.8695, policy_loss: 1.4831, value_loss: 0.8918
2024-07-11 16:07:15,851 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:07:16,273 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:07:16,333 [INFO    ] __main__: train step 4930: loss: 0.8696, policy_loss: 1.4830, value_loss: 0.8917
2024-07-11 16:07:16,513 [INFO    ] __main__: train step 4931: loss: 0.8697, policy_loss: 1.4829, value_loss: 0.8917
2024-07-11 16:07:16,759 [INFO    ] __main__: train step 4932: loss: 0.8697, policy_loss: 1.4828, value_loss: 0.8916
2024-07-11 16:07:17,001 [INFO    ] __main__: train step 4933: loss: 0.8698, policy_loss: 1.4827, value_loss: 0.8916
2024-07-11 16:07:17,194 [INFO    ] __main__: train step 4934: loss: 0.8699, policy_loss: 1.4826, value_loss: 0.8916
2024-07-11 16:07:17,398 [INFO    ] __main__: train step 4935: loss: 0.8700, policy_loss: 1.4825, value_loss: 0.8915
2024-07-11 16:07:17,605 [INFO    ] __main__: train step 4936: loss: 0.8701, policy_loss: 1.4824, value_loss: 0.8915
2024-07-11 16:07:17,811 [INFO    ] __main__: train step 4937: loss: 0.8702, policy_loss: 1.4823, value_loss: 0.8914
2024-07-11 16:07:18,010 [INFO    ] __main__: train step 4938: loss: 0.8703, policy_loss: 1.4822, value_loss: 0.8914
2024-07-11 16:07:18,205 [INFO    ] __main__: train step 4939: loss: 0.8704, policy_loss: 1.4821, value_loss: 0.8914
2024-07-11 16:07:18,400 [INFO    ] __main__: train step 4940: loss: 0.8705, policy_loss: 1.4820, value_loss: 0.8913
2024-07-11 16:07:18,884 [INFO    ] __main__: train step 4941: loss: 0.8706, policy_loss: 1.4819, value_loss: 0.8913
2024-07-11 16:07:19,098 [INFO    ] __main__: train step 4942: loss: 0.8707, policy_loss: 1.4818, value_loss: 0.8913
2024-07-11 16:07:19,286 [INFO    ] __main__: train step 4943: loss: 0.8708, policy_loss: 1.4817, value_loss: 0.8912
2024-07-11 16:07:19,502 [INFO    ] __main__: train step 4944: loss: 0.8709, policy_loss: 1.4816, value_loss: 0.8912
2024-07-11 16:07:19,742 [INFO    ] __main__: train step 4945: loss: 0.8710, policy_loss: 1.4815, value_loss: 0.8911
2024-07-11 16:07:19,974 [INFO    ] __main__: train step 4946: loss: 0.8711, policy_loss: 1.4814, value_loss: 0.8911
2024-07-11 16:07:21,414 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:07:21,847 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:07:21,908 [INFO    ] __main__: train step 4947: loss: 0.8711, policy_loss: 1.4813, value_loss: 0.8911
2024-07-11 16:07:22,081 [INFO    ] __main__: train step 4948: loss: 0.8712, policy_loss: 1.4812, value_loss: 0.8910
2024-07-11 16:07:22,283 [INFO    ] __main__: train step 4949: loss: 0.8713, policy_loss: 1.4811, value_loss: 0.8910
2024-07-11 16:07:22,493 [INFO    ] __main__: train step 4950: loss: 0.8714, policy_loss: 1.4810, value_loss: 0.8910
2024-07-11 16:07:22,715 [INFO    ] __main__: train step 4951: loss: 0.8715, policy_loss: 1.4809, value_loss: 0.8909
2024-07-11 16:07:22,955 [INFO    ] __main__: train step 4952: loss: 0.8716, policy_loss: 1.4808, value_loss: 0.8909
2024-07-11 16:07:23,166 [INFO    ] __main__: train step 4953: loss: 0.8717, policy_loss: 1.4807, value_loss: 0.8908
2024-07-11 16:07:23,376 [INFO    ] __main__: train step 4954: loss: 0.8718, policy_loss: 1.4806, value_loss: 0.8908
2024-07-11 16:07:23,588 [INFO    ] __main__: train step 4955: loss: 0.8719, policy_loss: 1.4805, value_loss: 0.8908
2024-07-11 16:07:23,796 [INFO    ] __main__: train step 4956: loss: 0.8720, policy_loss: 1.4803, value_loss: 0.8907
2024-07-11 16:07:23,992 [INFO    ] __main__: train step 4957: loss: 0.8721, policy_loss: 1.4802, value_loss: 0.8907
2024-07-11 16:07:24,203 [INFO    ] __main__: train step 4958: loss: 0.8721, policy_loss: 1.4801, value_loss: 0.8906
2024-07-11 16:07:24,417 [INFO    ] __main__: train step 4959: loss: 0.8722, policy_loss: 1.4800, value_loss: 0.8906
2024-07-11 16:07:24,621 [INFO    ] __main__: train step 4960: loss: 0.8723, policy_loss: 1.4799, value_loss: 0.8906
2024-07-11 16:07:24,837 [INFO    ] __main__: train step 4961: loss: 0.8724, policy_loss: 1.4798, value_loss: 0.8905
2024-07-11 16:07:25,053 [INFO    ] __main__: train step 4962: loss: 0.8725, policy_loss: 1.4797, value_loss: 0.8905
2024-07-11 16:07:25,278 [INFO    ] __main__: train step 4963: loss: 0.8726, policy_loss: 1.4796, value_loss: 0.8904
2024-07-11 16:07:26,746 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:07:27,283 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:07:27,355 [INFO    ] __main__: train step 4964: loss: 0.8727, policy_loss: 1.4795, value_loss: 0.8904
2024-07-11 16:07:27,802 [INFO    ] __main__: train step 4965: loss: 0.8728, policy_loss: 1.4794, value_loss: 0.8904
2024-07-11 16:07:28,032 [INFO    ] __main__: train step 4966: loss: 0.8729, policy_loss: 1.4793, value_loss: 0.8903
2024-07-11 16:07:28,229 [INFO    ] __main__: train step 4967: loss: 0.8730, policy_loss: 1.4792, value_loss: 0.8903
2024-07-11 16:07:28,426 [INFO    ] __main__: train step 4968: loss: 0.8731, policy_loss: 1.4791, value_loss: 0.8903
2024-07-11 16:07:28,623 [INFO    ] __main__: train step 4969: loss: 0.8732, policy_loss: 1.4790, value_loss: 0.8902
2024-07-11 16:07:28,846 [INFO    ] __main__: train step 4970: loss: 0.8733, policy_loss: 1.4789, value_loss: 0.8902
2024-07-11 16:07:29,058 [INFO    ] __main__: train step 4971: loss: 0.8733, policy_loss: 1.4788, value_loss: 0.8901
2024-07-11 16:07:29,252 [INFO    ] __main__: train step 4972: loss: 0.8734, policy_loss: 1.4787, value_loss: 0.8901
2024-07-11 16:07:29,472 [INFO    ] __main__: train step 4973: loss: 0.8735, policy_loss: 1.4786, value_loss: 0.8901
2024-07-11 16:07:29,700 [INFO    ] __main__: train step 4974: loss: 0.8736, policy_loss: 1.4785, value_loss: 0.8900
2024-07-11 16:07:29,902 [INFO    ] __main__: train step 4975: loss: 0.8737, policy_loss: 1.4784, value_loss: 0.8900
2024-07-11 16:07:30,096 [INFO    ] __main__: train step 4976: loss: 0.8738, policy_loss: 1.4783, value_loss: 0.8899
2024-07-11 16:07:30,301 [INFO    ] __main__: train step 4977: loss: 0.8739, policy_loss: 1.4782, value_loss: 0.8899
2024-07-11 16:07:30,499 [INFO    ] __main__: train step 4978: loss: 0.8740, policy_loss: 1.4781, value_loss: 0.8899
2024-07-11 16:07:30,695 [INFO    ] __main__: train step 4979: loss: 0.8741, policy_loss: 1.4780, value_loss: 0.8898
2024-07-11 16:07:30,894 [INFO    ] __main__: train step 4980: loss: 0.8742, policy_loss: 1.4779, value_loss: 0.8898
2024-07-11 16:07:32,354 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:07:32,773 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:07:32,829 [INFO    ] __main__: train step 4981: loss: 0.8743, policy_loss: 1.4778, value_loss: 0.8898
2024-07-11 16:07:33,007 [INFO    ] __main__: train step 4982: loss: 0.8743, policy_loss: 1.4777, value_loss: 0.8897
2024-07-11 16:07:33,247 [INFO    ] __main__: train step 4983: loss: 0.8744, policy_loss: 1.4776, value_loss: 0.8897
2024-07-11 16:07:33,451 [INFO    ] __main__: train step 4984: loss: 0.8745, policy_loss: 1.4775, value_loss: 0.8896
2024-07-11 16:07:33,676 [INFO    ] __main__: train step 4985: loss: 0.8746, policy_loss: 1.4774, value_loss: 0.8896
2024-07-11 16:07:33,880 [INFO    ] __main__: train step 4986: loss: 0.8747, policy_loss: 1.4773, value_loss: 0.8896
2024-07-11 16:07:34,111 [INFO    ] __main__: train step 4987: loss: 0.8748, policy_loss: 1.4772, value_loss: 0.8895
2024-07-11 16:07:34,608 [INFO    ] __main__: train step 4988: loss: 0.8749, policy_loss: 1.4771, value_loss: 0.8895
2024-07-11 16:07:34,804 [INFO    ] __main__: train step 4989: loss: 0.8750, policy_loss: 1.4770, value_loss: 0.8895
2024-07-11 16:07:35,025 [INFO    ] __main__: train step 4990: loss: 0.8751, policy_loss: 1.4769, value_loss: 0.8894
2024-07-11 16:07:35,220 [INFO    ] __main__: train step 4991: loss: 0.8752, policy_loss: 1.4768, value_loss: 0.8894
2024-07-11 16:07:35,434 [INFO    ] __main__: train step 4992: loss: 0.8753, policy_loss: 1.4767, value_loss: 0.8893
2024-07-11 16:07:35,623 [INFO    ] __main__: train step 4993: loss: 0.8754, policy_loss: 1.4766, value_loss: 0.8893
2024-07-11 16:07:35,817 [INFO    ] __main__: train step 4994: loss: 0.8755, policy_loss: 1.4765, value_loss: 0.8893
2024-07-11 16:07:36,035 [INFO    ] __main__: train step 4995: loss: 0.8756, policy_loss: 1.4764, value_loss: 0.8892
2024-07-11 16:07:36,256 [INFO    ] __main__: train step 4996: loss: 0.8756, policy_loss: 1.4763, value_loss: 0.8892
2024-07-11 16:07:36,495 [INFO    ] __main__: train step 4997: loss: 0.8757, policy_loss: 1.4761, value_loss: 0.8892
2024-07-11 16:07:37,986 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:07:38,364 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:07:38,418 [INFO    ] __main__: train step 4998: loss: 0.8758, policy_loss: 1.4760, value_loss: 0.8891
2024-07-11 16:07:38,602 [INFO    ] __main__: train step 4999: loss: 0.8759, policy_loss: 1.4759, value_loss: 0.8891
2024-07-11 16:07:38,823 [INFO    ] __main__: train step 5000: loss: 0.8760, policy_loss: 1.4758, value_loss: 0.8890
2024-07-11 16:07:38,948 [INFO    ] __main__: restored step 4000 for evaluation
2024-07-11 16:07:46,318 [INFO    ] __main__: later network ELO difference from earlier network: +180 (+8/-8) ELO from 32000 self-played games
2024-07-11 16:07:46,318 [INFO    ] __main__: game outcomes: W: 22030, D: 1020, L: 8950
2024-07-11 16:07:46,320 [INFO    ] __main__: validation_elo_delta: 180, validation_elo: 1172
2024-07-11 16:07:46,634 [INFO    ] __main__: running self-play game for SVG generation
2024-07-11 16:10:30,556 [INFO    ] __main__: saved self-play game in animations/run1_baseline/05000.svg
2024-07-11 16:10:30,723 [INFO    ] __main__: train step 5001: loss: 0.8761, policy_loss: 1.4757, value_loss: 0.8890
2024-07-11 16:10:30,937 [INFO    ] __main__: train step 5002: loss: 0.8762, policy_loss: 1.4756, value_loss: 0.8890
2024-07-11 16:10:31,146 [INFO    ] __main__: train step 5003: loss: 0.8763, policy_loss: 1.4755, value_loss: 0.8889
2024-07-11 16:10:31,352 [INFO    ] __main__: train step 5004: loss: 0.8764, policy_loss: 1.4754, value_loss: 0.8889
2024-07-11 16:10:31,561 [INFO    ] __main__: train step 5005: loss: 0.8765, policy_loss: 1.4753, value_loss: 0.8888
2024-07-11 16:10:31,760 [INFO    ] __main__: train step 5006: loss: 0.8766, policy_loss: 1.4752, value_loss: 0.8888
2024-07-11 16:10:31,962 [INFO    ] __main__: train step 5007: loss: 0.8766, policy_loss: 1.4751, value_loss: 0.8888
2024-07-11 16:10:32,206 [INFO    ] __main__: train step 5008: loss: 0.8767, policy_loss: 1.4750, value_loss: 0.8887
2024-07-11 16:10:32,433 [INFO    ] __main__: train step 5009: loss: 0.8768, policy_loss: 1.4749, value_loss: 0.8887
2024-07-11 16:10:32,641 [INFO    ] __main__: train step 5010: loss: 0.8769, policy_loss: 1.4748, value_loss: 0.8887
2024-07-11 16:10:32,857 [INFO    ] __main__: train step 5011: loss: 0.8770, policy_loss: 1.4747, value_loss: 0.8886
2024-07-11 16:10:33,067 [INFO    ] __main__: train step 5012: loss: 0.8771, policy_loss: 1.4746, value_loss: 0.8886
2024-07-11 16:10:33,269 [INFO    ] __main__: train step 5013: loss: 0.8772, policy_loss: 1.4745, value_loss: 0.8885
2024-07-11 16:10:33,463 [INFO    ] __main__: train step 5014: loss: 0.8773, policy_loss: 1.4744, value_loss: 0.8885
2024-07-11 16:10:34,903 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:10:35,357 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:10:35,416 [INFO    ] __main__: train step 5015: loss: 0.8774, policy_loss: 1.4743, value_loss: 0.8885
2024-07-11 16:10:35,591 [INFO    ] __main__: train step 5016: loss: 0.8775, policy_loss: 1.4742, value_loss: 0.8884
2024-07-11 16:10:35,801 [INFO    ] __main__: train step 5017: loss: 0.8776, policy_loss: 1.4741, value_loss: 0.8884
2024-07-11 16:10:36,008 [INFO    ] __main__: train step 5018: loss: 0.8777, policy_loss: 1.4740, value_loss: 0.8884
2024-07-11 16:10:36,211 [INFO    ] __main__: train step 5019: loss: 0.8778, policy_loss: 1.4739, value_loss: 0.8883
2024-07-11 16:10:36,406 [INFO    ] __main__: train step 5020: loss: 0.8779, policy_loss: 1.4738, value_loss: 0.8883
2024-07-11 16:10:36,602 [INFO    ] __main__: train step 5021: loss: 0.8780, policy_loss: 1.4737, value_loss: 0.8882
2024-07-11 16:10:37,629 [INFO    ] __main__: train step 5022: loss: 0.8780, policy_loss: 1.4736, value_loss: 0.8882
2024-07-11 16:10:37,844 [INFO    ] __main__: train step 5023: loss: 0.8781, policy_loss: 1.4735, value_loss: 0.8882
2024-07-11 16:10:38,046 [INFO    ] __main__: train step 5024: loss: 0.8782, policy_loss: 1.4734, value_loss: 0.8881
2024-07-11 16:10:38,256 [INFO    ] __main__: train step 5025: loss: 0.8783, policy_loss: 1.4733, value_loss: 0.8881
2024-07-11 16:10:38,493 [INFO    ] __main__: train step 5026: loss: 0.8784, policy_loss: 1.4732, value_loss: 0.8880
2024-07-11 16:10:38,732 [INFO    ] __main__: train step 5027: loss: 0.8785, policy_loss: 1.4731, value_loss: 0.8880
2024-07-11 16:10:38,926 [INFO    ] __main__: train step 5028: loss: 0.8786, policy_loss: 1.4730, value_loss: 0.8880
2024-07-11 16:10:39,126 [INFO    ] __main__: train step 5029: loss: 0.8787, policy_loss: 1.4729, value_loss: 0.8879
2024-07-11 16:10:39,326 [INFO    ] __main__: train step 5030: loss: 0.8788, policy_loss: 1.4728, value_loss: 0.8879
2024-07-11 16:10:39,518 [INFO    ] __main__: train step 5031: loss: 0.8789, policy_loss: 1.4727, value_loss: 0.8878
2024-07-11 16:10:40,949 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:10:41,332 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:10:41,387 [INFO    ] __main__: train step 5032: loss: 0.8790, policy_loss: 1.4726, value_loss: 0.8878
2024-07-11 16:10:41,569 [INFO    ] __main__: train step 5033: loss: 0.8790, policy_loss: 1.4725, value_loss: 0.8878
2024-07-11 16:10:41,799 [INFO    ] __main__: train step 5034: loss: 0.8791, policy_loss: 1.4724, value_loss: 0.8877
2024-07-11 16:10:41,998 [INFO    ] __main__: train step 5035: loss: 0.8792, policy_loss: 1.4723, value_loss: 0.8877
2024-07-11 16:10:42,199 [INFO    ] __main__: train step 5036: loss: 0.8793, policy_loss: 1.4722, value_loss: 0.8877
2024-07-11 16:10:42,400 [INFO    ] __main__: train step 5037: loss: 0.8794, policy_loss: 1.4721, value_loss: 0.8876
2024-07-11 16:10:42,598 [INFO    ] __main__: train step 5038: loss: 0.8795, policy_loss: 1.4720, value_loss: 0.8876
2024-07-11 16:10:42,802 [INFO    ] __main__: train step 5039: loss: 0.8796, policy_loss: 1.4719, value_loss: 0.8876
2024-07-11 16:10:43,003 [INFO    ] __main__: train step 5040: loss: 0.8797, policy_loss: 1.4718, value_loss: 0.8875
2024-07-11 16:10:43,220 [INFO    ] __main__: train step 5041: loss: 0.8798, policy_loss: 1.4717, value_loss: 0.8875
2024-07-11 16:10:43,404 [INFO    ] __main__: train step 5042: loss: 0.8799, policy_loss: 1.4716, value_loss: 0.8874
2024-07-11 16:10:43,604 [INFO    ] __main__: train step 5043: loss: 0.8800, policy_loss: 1.4715, value_loss: 0.8874
2024-07-11 16:10:43,822 [INFO    ] __main__: train step 5044: loss: 0.8801, policy_loss: 1.4714, value_loss: 0.8874
2024-07-11 16:10:44,045 [INFO    ] __main__: train step 5045: loss: 0.8802, policy_loss: 1.4713, value_loss: 0.8873
2024-07-11 16:10:44,273 [INFO    ] __main__: train step 5046: loss: 0.8802, policy_loss: 1.4712, value_loss: 0.8873
2024-07-11 16:10:44,485 [INFO    ] __main__: train step 5047: loss: 0.8803, policy_loss: 1.4711, value_loss: 0.8873
2024-07-11 16:10:44,713 [INFO    ] __main__: train step 5048: loss: 0.8804, policy_loss: 1.4710, value_loss: 0.8872
2024-07-11 16:10:46,132 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:10:46,550 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:10:46,604 [INFO    ] __main__: train step 5049: loss: 0.8805, policy_loss: 1.4709, value_loss: 0.8872
2024-07-11 16:10:46,785 [INFO    ] __main__: train step 5050: loss: 0.8806, policy_loss: 1.4708, value_loss: 0.8871
2024-07-11 16:10:46,995 [INFO    ] __main__: train step 5051: loss: 0.8807, policy_loss: 1.4707, value_loss: 0.8871
2024-07-11 16:10:47,235 [INFO    ] __main__: train step 5052: loss: 0.8808, policy_loss: 1.4706, value_loss: 0.8871
2024-07-11 16:10:47,462 [INFO    ] __main__: train step 5053: loss: 0.8809, policy_loss: 1.4705, value_loss: 0.8870
2024-07-11 16:10:47,673 [INFO    ] __main__: train step 5054: loss: 0.8810, policy_loss: 1.4704, value_loss: 0.8870
2024-07-11 16:10:47,869 [INFO    ] __main__: train step 5055: loss: 0.8811, policy_loss: 1.4703, value_loss: 0.8870
2024-07-11 16:10:48,074 [INFO    ] __main__: train step 5056: loss: 0.8812, policy_loss: 1.4702, value_loss: 0.8869
2024-07-11 16:10:48,308 [INFO    ] __main__: train step 5057: loss: 0.8813, policy_loss: 1.4701, value_loss: 0.8869
2024-07-11 16:10:48,497 [INFO    ] __main__: train step 5058: loss: 0.8813, policy_loss: 1.4700, value_loss: 0.8868
2024-07-11 16:10:48,710 [INFO    ] __main__: train step 5059: loss: 0.8814, policy_loss: 1.4699, value_loss: 0.8868
2024-07-11 16:10:48,910 [INFO    ] __main__: train step 5060: loss: 0.8815, policy_loss: 1.4698, value_loss: 0.8868
2024-07-11 16:10:49,119 [INFO    ] __main__: train step 5061: loss: 0.8816, policy_loss: 1.4697, value_loss: 0.8867
2024-07-11 16:10:49,311 [INFO    ] __main__: train step 5062: loss: 0.8817, policy_loss: 1.4696, value_loss: 0.8867
2024-07-11 16:10:49,513 [INFO    ] __main__: train step 5063: loss: 0.8818, policy_loss: 1.4694, value_loss: 0.8866
2024-07-11 16:10:49,707 [INFO    ] __main__: train step 5064: loss: 0.8819, policy_loss: 1.4693, value_loss: 0.8866
2024-07-11 16:10:49,919 [INFO    ] __main__: train step 5065: loss: 0.8820, policy_loss: 1.4692, value_loss: 0.8866
2024-07-11 16:10:51,351 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:10:51,760 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:10:51,814 [INFO    ] __main__: train step 5066: loss: 0.8821, policy_loss: 1.4691, value_loss: 0.8865
2024-07-11 16:10:51,984 [INFO    ] __main__: train step 5067: loss: 0.8821, policy_loss: 1.4690, value_loss: 0.8865
2024-07-11 16:10:52,181 [INFO    ] __main__: train step 5068: loss: 0.8822, policy_loss: 1.4689, value_loss: 0.8865
2024-07-11 16:10:52,391 [INFO    ] __main__: train step 5069: loss: 0.8823, policy_loss: 1.4688, value_loss: 0.8864
2024-07-11 16:10:52,631 [INFO    ] __main__: train step 5070: loss: 0.8824, policy_loss: 1.4687, value_loss: 0.8864
2024-07-11 16:10:52,842 [INFO    ] __main__: train step 5071: loss: 0.8825, policy_loss: 1.4686, value_loss: 0.8863
2024-07-11 16:10:53,049 [INFO    ] __main__: train step 5072: loss: 0.8826, policy_loss: 1.4685, value_loss: 0.8863
2024-07-11 16:10:53,270 [INFO    ] __main__: train step 5073: loss: 0.8827, policy_loss: 1.4684, value_loss: 0.8863
2024-07-11 16:10:53,510 [INFO    ] __main__: train step 5074: loss: 0.8828, policy_loss: 1.4683, value_loss: 0.8862
2024-07-11 16:10:53,697 [INFO    ] __main__: train step 5075: loss: 0.8829, policy_loss: 1.4682, value_loss: 0.8862
2024-07-11 16:10:53,910 [INFO    ] __main__: train step 5076: loss: 0.8830, policy_loss: 1.4681, value_loss: 0.8861
2024-07-11 16:10:54,118 [INFO    ] __main__: train step 5077: loss: 0.8831, policy_loss: 1.4680, value_loss: 0.8861
2024-07-11 16:10:54,331 [INFO    ] __main__: train step 5078: loss: 0.8831, policy_loss: 1.4679, value_loss: 0.8861
2024-07-11 16:10:54,534 [INFO    ] __main__: train step 5079: loss: 0.8832, policy_loss: 1.4679, value_loss: 0.8860
2024-07-11 16:10:54,747 [INFO    ] __main__: train step 5080: loss: 0.8833, policy_loss: 1.4678, value_loss: 0.8860
2024-07-11 16:10:54,946 [INFO    ] __main__: train step 5081: loss: 0.8834, policy_loss: 1.4677, value_loss: 0.8860
2024-07-11 16:10:55,151 [INFO    ] __main__: train step 5082: loss: 0.8835, policy_loss: 1.4676, value_loss: 0.8859
2024-07-11 16:10:56,599 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:10:57,071 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:10:57,136 [INFO    ] __main__: train step 5083: loss: 0.8836, policy_loss: 1.4675, value_loss: 0.8859
2024-07-11 16:10:57,323 [INFO    ] __main__: train step 5084: loss: 0.8837, policy_loss: 1.4674, value_loss: 0.8858
2024-07-11 16:10:57,516 [INFO    ] __main__: train step 5085: loss: 0.8838, policy_loss: 1.4672, value_loss: 0.8858
2024-07-11 16:10:57,707 [INFO    ] __main__: train step 5086: loss: 0.8839, policy_loss: 1.4671, value_loss: 0.8858
2024-07-11 16:10:57,921 [INFO    ] __main__: train step 5087: loss: 0.8840, policy_loss: 1.4670, value_loss: 0.8857
2024-07-11 16:10:58,117 [INFO    ] __main__: train step 5088: loss: 0.8840, policy_loss: 1.4669, value_loss: 0.8857
2024-07-11 16:10:58,310 [INFO    ] __main__: train step 5089: loss: 0.8841, policy_loss: 1.4668, value_loss: 0.8856
2024-07-11 16:10:58,520 [INFO    ] __main__: train step 5090: loss: 0.8842, policy_loss: 1.4668, value_loss: 0.8856
2024-07-11 16:10:58,733 [INFO    ] __main__: train step 5091: loss: 0.8843, policy_loss: 1.4666, value_loss: 0.8856
2024-07-11 16:10:58,980 [INFO    ] __main__: train step 5092: loss: 0.8844, policy_loss: 1.4665, value_loss: 0.8855
2024-07-11 16:10:59,207 [INFO    ] __main__: train step 5093: loss: 0.8845, policy_loss: 1.4664, value_loss: 0.8855
2024-07-11 16:11:00,259 [INFO    ] __main__: train step 5094: loss: 0.8846, policy_loss: 1.4663, value_loss: 0.8855
2024-07-11 16:11:00,482 [INFO    ] __main__: train step 5095: loss: 0.8847, policy_loss: 1.4662, value_loss: 0.8854
2024-07-11 16:11:00,713 [INFO    ] __main__: train step 5096: loss: 0.8848, policy_loss: 1.4661, value_loss: 0.8854
2024-07-11 16:11:00,920 [INFO    ] __main__: train step 5097: loss: 0.8848, policy_loss: 1.4660, value_loss: 0.8853
2024-07-11 16:11:01,165 [INFO    ] __main__: train step 5098: loss: 0.8849, policy_loss: 1.4659, value_loss: 0.8853
2024-07-11 16:11:01,394 [INFO    ] __main__: train step 5099: loss: 0.8850, policy_loss: 1.4658, value_loss: 0.8853
2024-07-11 16:11:02,826 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:11:03,259 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:11:03,321 [INFO    ] __main__: train step 5100: loss: 0.8851, policy_loss: 1.4657, value_loss: 0.8852
2024-07-11 16:11:03,491 [INFO    ] __main__: train step 5101: loss: 0.8852, policy_loss: 1.4656, value_loss: 0.8852
2024-07-11 16:11:03,692 [INFO    ] __main__: train step 5102: loss: 0.8853, policy_loss: 1.4655, value_loss: 0.8852
2024-07-11 16:11:03,893 [INFO    ] __main__: train step 5103: loss: 0.8854, policy_loss: 1.4654, value_loss: 0.8851
2024-07-11 16:11:04,105 [INFO    ] __main__: train step 5104: loss: 0.8855, policy_loss: 1.4653, value_loss: 0.8851
2024-07-11 16:11:04,307 [INFO    ] __main__: train step 5105: loss: 0.8855, policy_loss: 1.4652, value_loss: 0.8850
2024-07-11 16:11:04,514 [INFO    ] __main__: train step 5106: loss: 0.8856, policy_loss: 1.4651, value_loss: 0.8850
2024-07-11 16:11:04,723 [INFO    ] __main__: train step 5107: loss: 0.8857, policy_loss: 1.4650, value_loss: 0.8850
2024-07-11 16:11:04,957 [INFO    ] __main__: train step 5108: loss: 0.8858, policy_loss: 1.4649, value_loss: 0.8849
2024-07-11 16:11:05,193 [INFO    ] __main__: train step 5109: loss: 0.8859, policy_loss: 1.4648, value_loss: 0.8849
2024-07-11 16:11:05,399 [INFO    ] __main__: train step 5110: loss: 0.8860, policy_loss: 1.4647, value_loss: 0.8849
2024-07-11 16:11:05,605 [INFO    ] __main__: train step 5111: loss: 0.8861, policy_loss: 1.4646, value_loss: 0.8848
2024-07-11 16:11:05,800 [INFO    ] __main__: train step 5112: loss: 0.8862, policy_loss: 1.4645, value_loss: 0.8848
2024-07-11 16:11:06,011 [INFO    ] __main__: train step 5113: loss: 0.8863, policy_loss: 1.4644, value_loss: 0.8847
2024-07-11 16:11:06,199 [INFO    ] __main__: train step 5114: loss: 0.8864, policy_loss: 1.4643, value_loss: 0.8847
2024-07-11 16:11:06,405 [INFO    ] __main__: train step 5115: loss: 0.8865, policy_loss: 1.4642, value_loss: 0.8847
2024-07-11 16:11:06,624 [INFO    ] __main__: train step 5116: loss: 0.8865, policy_loss: 1.4641, value_loss: 0.8846
2024-07-11 16:11:08,064 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:11:08,483 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:11:08,537 [INFO    ] __main__: train step 5117: loss: 0.8866, policy_loss: 1.4640, value_loss: 0.8846
2024-07-11 16:11:08,712 [INFO    ] __main__: train step 5118: loss: 0.8867, policy_loss: 1.4639, value_loss: 0.8845
2024-07-11 16:11:08,918 [INFO    ] __main__: train step 5119: loss: 0.8868, policy_loss: 1.4638, value_loss: 0.8845
2024-07-11 16:11:09,124 [INFO    ] __main__: train step 5120: loss: 0.8869, policy_loss: 1.4637, value_loss: 0.8845
2024-07-11 16:11:09,315 [INFO    ] __main__: train step 5121: loss: 0.8870, policy_loss: 1.4636, value_loss: 0.8844
2024-07-11 16:11:09,509 [INFO    ] __main__: train step 5122: loss: 0.8871, policy_loss: 1.4635, value_loss: 0.8844
2024-07-11 16:11:09,698 [INFO    ] __main__: train step 5123: loss: 0.8872, policy_loss: 1.4634, value_loss: 0.8843
2024-07-11 16:11:09,901 [INFO    ] __main__: train step 5124: loss: 0.8873, policy_loss: 1.4633, value_loss: 0.8843
2024-07-11 16:11:10,114 [INFO    ] __main__: train step 5125: loss: 0.8873, policy_loss: 1.4632, value_loss: 0.8843
2024-07-11 16:11:10,316 [INFO    ] __main__: train step 5126: loss: 0.8874, policy_loss: 1.4631, value_loss: 0.8842
2024-07-11 16:11:10,538 [INFO    ] __main__: train step 5127: loss: 0.8875, policy_loss: 1.4630, value_loss: 0.8842
2024-07-11 16:11:10,741 [INFO    ] __main__: train step 5128: loss: 0.8876, policy_loss: 1.4629, value_loss: 0.8841
2024-07-11 16:11:10,949 [INFO    ] __main__: train step 5129: loss: 0.8877, policy_loss: 1.4628, value_loss: 0.8841
2024-07-11 16:11:11,148 [INFO    ] __main__: train step 5130: loss: 0.8878, policy_loss: 1.4627, value_loss: 0.8841
2024-07-11 16:11:11,356 [INFO    ] __main__: train step 5131: loss: 0.8879, policy_loss: 1.4626, value_loss: 0.8840
2024-07-11 16:11:11,612 [INFO    ] __main__: train step 5132: loss: 0.8880, policy_loss: 1.4625, value_loss: 0.8840
2024-07-11 16:11:11,841 [INFO    ] __main__: train step 5133: loss: 0.8880, policy_loss: 1.4624, value_loss: 0.8840
2024-07-11 16:11:13,280 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:11:13,725 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:11:13,787 [INFO    ] __main__: train step 5134: loss: 0.8881, policy_loss: 1.4623, value_loss: 0.8839
2024-07-11 16:11:13,957 [INFO    ] __main__: train step 5135: loss: 0.8882, policy_loss: 1.4622, value_loss: 0.8839
2024-07-11 16:11:14,163 [INFO    ] __main__: train step 5136: loss: 0.8883, policy_loss: 1.4621, value_loss: 0.8838
2024-07-11 16:11:14,367 [INFO    ] __main__: train step 5137: loss: 0.8884, policy_loss: 1.4620, value_loss: 0.8838
2024-07-11 16:11:14,574 [INFO    ] __main__: train step 5138: loss: 0.8885, policy_loss: 1.4619, value_loss: 0.8838
2024-07-11 16:11:14,786 [INFO    ] __main__: train step 5139: loss: 0.8886, policy_loss: 1.4618, value_loss: 0.8837
2024-07-11 16:11:14,973 [INFO    ] __main__: train step 5140: loss: 0.8887, policy_loss: 1.4617, value_loss: 0.8837
2024-07-11 16:11:15,179 [INFO    ] __main__: train step 5141: loss: 0.8887, policy_loss: 1.4616, value_loss: 0.8836
2024-07-11 16:11:15,378 [INFO    ] __main__: train step 5142: loss: 0.8888, policy_loss: 1.4615, value_loss: 0.8836
2024-07-11 16:11:15,580 [INFO    ] __main__: train step 5143: loss: 0.8889, policy_loss: 1.4614, value_loss: 0.8836
2024-07-11 16:11:15,782 [INFO    ] __main__: train step 5144: loss: 0.8890, policy_loss: 1.4613, value_loss: 0.8835
2024-07-11 16:11:15,983 [INFO    ] __main__: train step 5145: loss: 0.8891, policy_loss: 1.4612, value_loss: 0.8835
2024-07-11 16:11:16,181 [INFO    ] __main__: train step 5146: loss: 0.8892, policy_loss: 1.4611, value_loss: 0.8834
2024-07-11 16:11:16,395 [INFO    ] __main__: train step 5147: loss: 0.8893, policy_loss: 1.4610, value_loss: 0.8834
2024-07-11 16:11:16,594 [INFO    ] __main__: train step 5148: loss: 0.8894, policy_loss: 1.4609, value_loss: 0.8834
2024-07-11 16:11:16,810 [INFO    ] __main__: train step 5149: loss: 0.8895, policy_loss: 1.4608, value_loss: 0.8833
2024-07-11 16:11:17,045 [INFO    ] __main__: train step 5150: loss: 0.8895, policy_loss: 1.4607, value_loss: 0.8833
2024-07-11 16:11:18,473 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:11:18,913 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:11:18,973 [INFO    ] __main__: train step 5151: loss: 0.8896, policy_loss: 1.4606, value_loss: 0.8833
2024-07-11 16:11:19,139 [INFO    ] __main__: train step 5152: loss: 0.8897, policy_loss: 1.4605, value_loss: 0.8832
2024-07-11 16:11:19,337 [INFO    ] __main__: train step 5153: loss: 0.8898, policy_loss: 1.4604, value_loss: 0.8832
2024-07-11 16:11:19,537 [INFO    ] __main__: train step 5154: loss: 0.8899, policy_loss: 1.4603, value_loss: 0.8831
2024-07-11 16:11:19,741 [INFO    ] __main__: train step 5155: loss: 0.8900, policy_loss: 1.4602, value_loss: 0.8831
2024-07-11 16:11:19,976 [INFO    ] __main__: train step 5156: loss: 0.8901, policy_loss: 1.4601, value_loss: 0.8831
2024-07-11 16:11:20,180 [INFO    ] __main__: train step 5157: loss: 0.8901, policy_loss: 1.4600, value_loss: 0.8830
2024-07-11 16:11:20,371 [INFO    ] __main__: train step 5158: loss: 0.8902, policy_loss: 1.4599, value_loss: 0.8830
2024-07-11 16:11:20,569 [INFO    ] __main__: train step 5159: loss: 0.8903, policy_loss: 1.4598, value_loss: 0.8829
2024-07-11 16:11:20,774 [INFO    ] __main__: train step 5160: loss: 0.8904, policy_loss: 1.4597, value_loss: 0.8829
2024-07-11 16:11:20,978 [INFO    ] __main__: train step 5161: loss: 0.8905, policy_loss: 1.4596, value_loss: 0.8829
2024-07-11 16:11:21,173 [INFO    ] __main__: train step 5162: loss: 0.8906, policy_loss: 1.4595, value_loss: 0.8828
2024-07-11 16:11:21,365 [INFO    ] __main__: train step 5163: loss: 0.8907, policy_loss: 1.4594, value_loss: 0.8828
2024-07-11 16:11:21,561 [INFO    ] __main__: train step 5164: loss: 0.8908, policy_loss: 1.4593, value_loss: 0.8827
2024-07-11 16:11:21,761 [INFO    ] __main__: train step 5165: loss: 0.8908, policy_loss: 1.4592, value_loss: 0.8827
2024-07-11 16:11:21,963 [INFO    ] __main__: train step 5166: loss: 0.8909, policy_loss: 1.4591, value_loss: 0.8827
2024-07-11 16:11:22,160 [INFO    ] __main__: train step 5167: loss: 0.8910, policy_loss: 1.4590, value_loss: 0.8826
2024-07-11 16:11:24,427 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:11:24,862 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:11:24,920 [INFO    ] __main__: train step 5168: loss: 0.8911, policy_loss: 1.4589, value_loss: 0.8826
2024-07-11 16:11:25,094 [INFO    ] __main__: train step 5169: loss: 0.8912, policy_loss: 1.4588, value_loss: 0.8826
2024-07-11 16:11:25,294 [INFO    ] __main__: train step 5170: loss: 0.8913, policy_loss: 1.4587, value_loss: 0.8825
2024-07-11 16:11:25,518 [INFO    ] __main__: train step 5171: loss: 0.8913, policy_loss: 1.4586, value_loss: 0.8825
2024-07-11 16:11:25,743 [INFO    ] __main__: train step 5172: loss: 0.8914, policy_loss: 1.4585, value_loss: 0.8824
2024-07-11 16:11:25,944 [INFO    ] __main__: train step 5173: loss: 0.8915, policy_loss: 1.4584, value_loss: 0.8824
2024-07-11 16:11:26,152 [INFO    ] __main__: train step 5174: loss: 0.8916, policy_loss: 1.4583, value_loss: 0.8824
2024-07-11 16:11:26,404 [INFO    ] __main__: train step 5175: loss: 0.8917, policy_loss: 1.4582, value_loss: 0.8823
2024-07-11 16:11:26,602 [INFO    ] __main__: train step 5176: loss: 0.8918, policy_loss: 1.4581, value_loss: 0.8823
2024-07-11 16:11:26,799 [INFO    ] __main__: train step 5177: loss: 0.8919, policy_loss: 1.4580, value_loss: 0.8822
2024-07-11 16:11:27,001 [INFO    ] __main__: train step 5178: loss: 0.8920, policy_loss: 1.4579, value_loss: 0.8822
2024-07-11 16:11:27,196 [INFO    ] __main__: train step 5179: loss: 0.8920, policy_loss: 1.4578, value_loss: 0.8822
2024-07-11 16:11:27,396 [INFO    ] __main__: train step 5180: loss: 0.8921, policy_loss: 1.4577, value_loss: 0.8821
2024-07-11 16:11:27,590 [INFO    ] __main__: train step 5181: loss: 0.8922, policy_loss: 1.4576, value_loss: 0.8821
2024-07-11 16:11:27,790 [INFO    ] __main__: train step 5182: loss: 0.8923, policy_loss: 1.4575, value_loss: 0.8820
2024-07-11 16:11:27,987 [INFO    ] __main__: train step 5183: loss: 0.8924, policy_loss: 1.4574, value_loss: 0.8820
2024-07-11 16:11:28,188 [INFO    ] __main__: train step 5184: loss: 0.8925, policy_loss: 1.4573, value_loss: 0.8820
2024-07-11 16:11:29,654 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:11:30,052 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:11:30,105 [INFO    ] __main__: train step 5185: loss: 0.8926, policy_loss: 1.4572, value_loss: 0.8819
2024-07-11 16:11:30,277 [INFO    ] __main__: train step 5186: loss: 0.8926, policy_loss: 1.4571, value_loss: 0.8819
2024-07-11 16:11:30,481 [INFO    ] __main__: train step 5187: loss: 0.8927, policy_loss: 1.4570, value_loss: 0.8818
2024-07-11 16:11:30,677 [INFO    ] __main__: train step 5188: loss: 0.8928, policy_loss: 1.4569, value_loss: 0.8818
2024-07-11 16:11:30,869 [INFO    ] __main__: train step 5189: loss: 0.8929, policy_loss: 1.4568, value_loss: 0.8818
2024-07-11 16:11:31,071 [INFO    ] __main__: train step 5190: loss: 0.8930, policy_loss: 1.4567, value_loss: 0.8817
2024-07-11 16:11:31,273 [INFO    ] __main__: train step 5191: loss: 0.8931, policy_loss: 1.4566, value_loss: 0.8817
2024-07-11 16:11:31,482 [INFO    ] __main__: train step 5192: loss: 0.8932, policy_loss: 1.4565, value_loss: 0.8817
2024-07-11 16:11:31,735 [INFO    ] __main__: train step 5193: loss: 0.8933, policy_loss: 1.4564, value_loss: 0.8816
2024-07-11 16:11:31,970 [INFO    ] __main__: train step 5194: loss: 0.8933, policy_loss: 1.4563, value_loss: 0.8816
2024-07-11 16:11:32,184 [INFO    ] __main__: train step 5195: loss: 0.8934, policy_loss: 1.4562, value_loss: 0.8815
2024-07-11 16:11:32,395 [INFO    ] __main__: train step 5196: loss: 0.8935, policy_loss: 1.4561, value_loss: 0.8815
2024-07-11 16:11:32,610 [INFO    ] __main__: train step 5197: loss: 0.8936, policy_loss: 1.4560, value_loss: 0.8815
2024-07-11 16:11:32,814 [INFO    ] __main__: train step 5198: loss: 0.8937, policy_loss: 1.4559, value_loss: 0.8814
2024-07-11 16:11:33,030 [INFO    ] __main__: train step 5199: loss: 0.8938, policy_loss: 1.4558, value_loss: 0.8814
2024-07-11 16:11:33,225 [INFO    ] __main__: train step 5200: loss: 0.8939, policy_loss: 1.4557, value_loss: 0.8813
2024-07-11 16:11:33,422 [INFO    ] __main__: train step 5201: loss: 0.8940, policy_loss: 1.4556, value_loss: 0.8813
2024-07-11 16:11:34,868 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:11:35,270 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:11:35,324 [INFO    ] __main__: train step 5202: loss: 0.8940, policy_loss: 1.4555, value_loss: 0.8813
2024-07-11 16:11:35,503 [INFO    ] __main__: train step 5203: loss: 0.8941, policy_loss: 1.4554, value_loss: 0.8812
2024-07-11 16:11:35,697 [INFO    ] __main__: train step 5204: loss: 0.8942, policy_loss: 1.4554, value_loss: 0.8812
2024-07-11 16:11:35,898 [INFO    ] __main__: train step 5205: loss: 0.8943, policy_loss: 1.4553, value_loss: 0.8812
2024-07-11 16:11:36,092 [INFO    ] __main__: train step 5206: loss: 0.8944, policy_loss: 1.4552, value_loss: 0.8811
2024-07-11 16:11:36,300 [INFO    ] __main__: train step 5207: loss: 0.8945, policy_loss: 1.4551, value_loss: 0.8811
2024-07-11 16:11:36,508 [INFO    ] __main__: train step 5208: loss: 0.8946, policy_loss: 1.4550, value_loss: 0.8810
2024-07-11 16:11:36,707 [INFO    ] __main__: train step 5209: loss: 0.8947, policy_loss: 1.4549, value_loss: 0.8810
2024-07-11 16:11:36,905 [INFO    ] __main__: train step 5210: loss: 0.8947, policy_loss: 1.4548, value_loss: 0.8810
2024-07-11 16:11:37,111 [INFO    ] __main__: train step 5211: loss: 0.8948, policy_loss: 1.4547, value_loss: 0.8809
2024-07-11 16:11:37,310 [INFO    ] __main__: train step 5212: loss: 0.8949, policy_loss: 1.4546, value_loss: 0.8809
2024-07-11 16:11:37,510 [INFO    ] __main__: train step 5213: loss: 0.8950, policy_loss: 1.4545, value_loss: 0.8809
2024-07-11 16:11:37,733 [INFO    ] __main__: train step 5214: loss: 0.8951, policy_loss: 1.4544, value_loss: 0.8808
2024-07-11 16:11:37,961 [INFO    ] __main__: train step 5215: loss: 0.8952, policy_loss: 1.4543, value_loss: 0.8808
2024-07-11 16:11:38,153 [INFO    ] __main__: train step 5216: loss: 0.8953, policy_loss: 1.4542, value_loss: 0.8807
2024-07-11 16:11:38,350 [INFO    ] __main__: train step 5217: loss: 0.8954, policy_loss: 1.4541, value_loss: 0.8807
2024-07-11 16:11:38,548 [INFO    ] __main__: train step 5218: loss: 0.8954, policy_loss: 1.4540, value_loss: 0.8807
2024-07-11 16:11:40,000 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:11:40,437 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:11:40,490 [INFO    ] __main__: train step 5219: loss: 0.8955, policy_loss: 1.4539, value_loss: 0.8806
2024-07-11 16:11:40,656 [INFO    ] __main__: train step 5220: loss: 0.8956, policy_loss: 1.4538, value_loss: 0.8806
2024-07-11 16:11:40,860 [INFO    ] __main__: train step 5221: loss: 0.8957, policy_loss: 1.4537, value_loss: 0.8805
2024-07-11 16:11:41,057 [INFO    ] __main__: train step 5222: loss: 0.8958, policy_loss: 1.4536, value_loss: 0.8805
2024-07-11 16:11:41,261 [INFO    ] __main__: train step 5223: loss: 0.8959, policy_loss: 1.4535, value_loss: 0.8805
2024-07-11 16:11:41,479 [INFO    ] __main__: train step 5224: loss: 0.8960, policy_loss: 1.4534, value_loss: 0.8804
2024-07-11 16:11:41,674 [INFO    ] __main__: train step 5225: loss: 0.8961, policy_loss: 1.4533, value_loss: 0.8804
2024-07-11 16:11:41,875 [INFO    ] __main__: train step 5226: loss: 0.8961, policy_loss: 1.4532, value_loss: 0.8803
2024-07-11 16:11:42,079 [INFO    ] __main__: train step 5227: loss: 0.8962, policy_loss: 1.4531, value_loss: 0.8803
2024-07-11 16:11:42,285 [INFO    ] __main__: train step 5228: loss: 0.8963, policy_loss: 1.4530, value_loss: 0.8803
2024-07-11 16:11:42,486 [INFO    ] __main__: train step 5229: loss: 0.8964, policy_loss: 1.4529, value_loss: 0.8802
2024-07-11 16:11:42,696 [INFO    ] __main__: train step 5230: loss: 0.8965, policy_loss: 1.4528, value_loss: 0.8802
2024-07-11 16:11:42,905 [INFO    ] __main__: train step 5231: loss: 0.8966, policy_loss: 1.4527, value_loss: 0.8801
2024-07-11 16:11:43,100 [INFO    ] __main__: train step 5232: loss: 0.8967, policy_loss: 1.4526, value_loss: 0.8801
2024-07-11 16:11:43,295 [INFO    ] __main__: train step 5233: loss: 0.8967, policy_loss: 1.4525, value_loss: 0.8801
2024-07-11 16:11:43,497 [INFO    ] __main__: train step 5234: loss: 0.8968, policy_loss: 1.4524, value_loss: 0.8800
2024-07-11 16:11:43,701 [INFO    ] __main__: train step 5235: loss: 0.8969, policy_loss: 1.4523, value_loss: 0.8800
2024-07-11 16:11:45,127 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:11:45,538 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:11:45,592 [INFO    ] __main__: train step 5236: loss: 0.8970, policy_loss: 1.4522, value_loss: 0.8799
2024-07-11 16:11:45,756 [INFO    ] __main__: train step 5237: loss: 0.8971, policy_loss: 1.4521, value_loss: 0.8799
2024-07-11 16:11:45,955 [INFO    ] __main__: train step 5238: loss: 0.8972, policy_loss: 1.4520, value_loss: 0.8799
2024-07-11 16:11:46,164 [INFO    ] __main__: train step 5239: loss: 0.8973, policy_loss: 1.4519, value_loss: 0.8798
2024-07-11 16:11:46,370 [INFO    ] __main__: train step 5240: loss: 0.8973, policy_loss: 1.4518, value_loss: 0.8798
2024-07-11 16:11:46,570 [INFO    ] __main__: train step 5241: loss: 0.8974, policy_loss: 1.4517, value_loss: 0.8797
2024-07-11 16:11:47,653 [INFO    ] __main__: train step 5242: loss: 0.8975, policy_loss: 1.4516, value_loss: 0.8797
2024-07-11 16:11:47,867 [INFO    ] __main__: train step 5243: loss: 0.8976, policy_loss: 1.4515, value_loss: 0.8797
2024-07-11 16:11:48,072 [INFO    ] __main__: train step 5244: loss: 0.8977, policy_loss: 1.4514, value_loss: 0.8796
2024-07-11 16:11:48,270 [INFO    ] __main__: train step 5245: loss: 0.8978, policy_loss: 1.4513, value_loss: 0.8796
2024-07-11 16:11:48,477 [INFO    ] __main__: train step 5246: loss: 0.8978, policy_loss: 1.4512, value_loss: 0.8795
2024-07-11 16:11:48,689 [INFO    ] __main__: train step 5247: loss: 0.8979, policy_loss: 1.4511, value_loss: 0.8795
2024-07-11 16:11:48,883 [INFO    ] __main__: train step 5248: loss: 0.8980, policy_loss: 1.4510, value_loss: 0.8795
2024-07-11 16:11:49,090 [INFO    ] __main__: train step 5249: loss: 0.8981, policy_loss: 1.4509, value_loss: 0.8794
2024-07-11 16:11:49,297 [INFO    ] __main__: train step 5250: loss: 0.8982, policy_loss: 1.4508, value_loss: 0.8794
2024-07-11 16:11:49,506 [INFO    ] __main__: train step 5251: loss: 0.8983, policy_loss: 1.4507, value_loss: 0.8793
2024-07-11 16:11:49,715 [INFO    ] __main__: train step 5252: loss: 0.8983, policy_loss: 1.4506, value_loss: 0.8793
2024-07-11 16:11:51,159 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:11:51,586 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:11:51,642 [INFO    ] __main__: train step 5253: loss: 0.8984, policy_loss: 1.4505, value_loss: 0.8793
2024-07-11 16:11:51,805 [INFO    ] __main__: train step 5254: loss: 0.8985, policy_loss: 1.4504, value_loss: 0.8792
2024-07-11 16:11:52,011 [INFO    ] __main__: train step 5255: loss: 0.8986, policy_loss: 1.4503, value_loss: 0.8792
2024-07-11 16:11:52,209 [INFO    ] __main__: train step 5256: loss: 0.8987, policy_loss: 1.4502, value_loss: 0.8791
2024-07-11 16:11:52,410 [INFO    ] __main__: train step 5257: loss: 0.8988, policy_loss: 1.4501, value_loss: 0.8791
2024-07-11 16:11:52,606 [INFO    ] __main__: train step 5258: loss: 0.8989, policy_loss: 1.4500, value_loss: 0.8791
2024-07-11 16:11:52,812 [INFO    ] __main__: train step 5259: loss: 0.8989, policy_loss: 1.4499, value_loss: 0.8790
2024-07-11 16:11:53,029 [INFO    ] __main__: train step 5260: loss: 0.8990, policy_loss: 1.4498, value_loss: 0.8790
2024-07-11 16:11:53,237 [INFO    ] __main__: train step 5261: loss: 0.8991, policy_loss: 1.4497, value_loss: 0.8789
2024-07-11 16:11:53,449 [INFO    ] __main__: train step 5262: loss: 0.8992, policy_loss: 1.4496, value_loss: 0.8789
2024-07-11 16:11:53,647 [INFO    ] __main__: train step 5263: loss: 0.8993, policy_loss: 1.4496, value_loss: 0.8789
2024-07-11 16:11:53,859 [INFO    ] __main__: train step 5264: loss: 0.8994, policy_loss: 1.4495, value_loss: 0.8788
2024-07-11 16:11:54,056 [INFO    ] __main__: train step 5265: loss: 0.8995, policy_loss: 1.4494, value_loss: 0.8788
2024-07-11 16:11:54,264 [INFO    ] __main__: train step 5266: loss: 0.8995, policy_loss: 1.4493, value_loss: 0.8787
2024-07-11 16:11:54,456 [INFO    ] __main__: train step 5267: loss: 0.8996, policy_loss: 1.4492, value_loss: 0.8787
2024-07-11 16:11:54,664 [INFO    ] __main__: train step 5268: loss: 0.8997, policy_loss: 1.4491, value_loss: 0.8787
2024-07-11 16:11:54,870 [INFO    ] __main__: train step 5269: loss: 0.8998, policy_loss: 1.4490, value_loss: 0.8786
2024-07-11 16:11:56,315 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:11:56,743 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:11:56,798 [INFO    ] __main__: train step 5270: loss: 0.8999, policy_loss: 1.4489, value_loss: 0.8786
2024-07-11 16:11:56,965 [INFO    ] __main__: train step 5271: loss: 0.9000, policy_loss: 1.4488, value_loss: 0.8785
2024-07-11 16:11:57,168 [INFO    ] __main__: train step 5272: loss: 0.9000, policy_loss: 1.4487, value_loss: 0.8785
2024-07-11 16:11:57,368 [INFO    ] __main__: train step 5273: loss: 0.9001, policy_loss: 1.4486, value_loss: 0.8785
2024-07-11 16:11:57,561 [INFO    ] __main__: train step 5274: loss: 0.9002, policy_loss: 1.4485, value_loss: 0.8784
2024-07-11 16:11:57,776 [INFO    ] __main__: train step 5275: loss: 0.9003, policy_loss: 1.4484, value_loss: 0.8784
2024-07-11 16:11:58,006 [INFO    ] __main__: train step 5276: loss: 0.9004, policy_loss: 1.4483, value_loss: 0.8783
2024-07-11 16:11:58,197 [INFO    ] __main__: train step 5277: loss: 0.9005, policy_loss: 1.4482, value_loss: 0.8783
2024-07-11 16:11:58,405 [INFO    ] __main__: train step 5278: loss: 0.9005, policy_loss: 1.4481, value_loss: 0.8783
2024-07-11 16:11:58,600 [INFO    ] __main__: train step 5279: loss: 0.9006, policy_loss: 1.4480, value_loss: 0.8782
2024-07-11 16:11:58,804 [INFO    ] __main__: train step 5280: loss: 0.9007, policy_loss: 1.4479, value_loss: 0.8782
2024-07-11 16:11:59,011 [INFO    ] __main__: train step 5281: loss: 0.9008, policy_loss: 1.4478, value_loss: 0.8781
2024-07-11 16:11:59,245 [INFO    ] __main__: train step 5282: loss: 0.9009, policy_loss: 1.4477, value_loss: 0.8781
2024-07-11 16:11:59,437 [INFO    ] __main__: train step 5283: loss: 0.9010, policy_loss: 1.4476, value_loss: 0.8781
2024-07-11 16:11:59,631 [INFO    ] __main__: train step 5284: loss: 0.9011, policy_loss: 1.4475, value_loss: 0.8780
2024-07-11 16:11:59,839 [INFO    ] __main__: train step 5285: loss: 0.9011, policy_loss: 1.4474, value_loss: 0.8780
2024-07-11 16:12:00,042 [INFO    ] __main__: train step 5286: loss: 0.9012, policy_loss: 1.4473, value_loss: 0.8780
2024-07-11 16:12:01,473 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:12:01,870 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:12:01,927 [INFO    ] __main__: train step 5287: loss: 0.9013, policy_loss: 1.4472, value_loss: 0.8779
2024-07-11 16:12:02,106 [INFO    ] __main__: train step 5288: loss: 0.9014, policy_loss: 1.4471, value_loss: 0.8779
2024-07-11 16:12:02,300 [INFO    ] __main__: train step 5289: loss: 0.9015, policy_loss: 1.4470, value_loss: 0.8778
2024-07-11 16:12:02,511 [INFO    ] __main__: train step 5290: loss: 0.9016, policy_loss: 1.4469, value_loss: 0.8778
2024-07-11 16:12:02,704 [INFO    ] __main__: train step 5291: loss: 0.9016, policy_loss: 1.4468, value_loss: 0.8778
2024-07-11 16:12:02,906 [INFO    ] __main__: train step 5292: loss: 0.9017, policy_loss: 1.4467, value_loss: 0.8777
2024-07-11 16:12:03,100 [INFO    ] __main__: train step 5293: loss: 0.9018, policy_loss: 1.4466, value_loss: 0.8777
2024-07-11 16:12:03,305 [INFO    ] __main__: train step 5294: loss: 0.9019, policy_loss: 1.4465, value_loss: 0.8776
2024-07-11 16:12:03,495 [INFO    ] __main__: train step 5295: loss: 0.9020, policy_loss: 1.4464, value_loss: 0.8776
2024-07-11 16:12:03,687 [INFO    ] __main__: train step 5296: loss: 0.9021, policy_loss: 1.4463, value_loss: 0.8776
2024-07-11 16:12:03,884 [INFO    ] __main__: train step 5297: loss: 0.9021, policy_loss: 1.4462, value_loss: 0.8775
2024-07-11 16:12:04,079 [INFO    ] __main__: train step 5298: loss: 0.9022, policy_loss: 1.4461, value_loss: 0.8775
2024-07-11 16:12:04,278 [INFO    ] __main__: train step 5299: loss: 0.9023, policy_loss: 1.4460, value_loss: 0.8774
2024-07-11 16:12:04,473 [INFO    ] __main__: train step 5300: loss: 0.9024, policy_loss: 1.4459, value_loss: 0.8774
2024-07-11 16:12:04,675 [INFO    ] __main__: train step 5301: loss: 0.9025, policy_loss: 1.4458, value_loss: 0.8774
2024-07-11 16:12:04,877 [INFO    ] __main__: train step 5302: loss: 0.9026, policy_loss: 1.4457, value_loss: 0.8773
2024-07-11 16:12:05,079 [INFO    ] __main__: train step 5303: loss: 0.9026, policy_loss: 1.4456, value_loss: 0.8773
2024-07-11 16:12:06,525 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:12:06,916 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:12:06,971 [INFO    ] __main__: train step 5304: loss: 0.9027, policy_loss: 1.4455, value_loss: 0.8772
2024-07-11 16:12:07,144 [INFO    ] __main__: train step 5305: loss: 0.9028, policy_loss: 1.4454, value_loss: 0.8772
2024-07-11 16:12:07,350 [INFO    ] __main__: train step 5306: loss: 0.9029, policy_loss: 1.4453, value_loss: 0.8772
2024-07-11 16:12:07,546 [INFO    ] __main__: train step 5307: loss: 0.9030, policy_loss: 1.4452, value_loss: 0.8771
2024-07-11 16:12:07,757 [INFO    ] __main__: train step 5308: loss: 0.9031, policy_loss: 1.4451, value_loss: 0.8771
2024-07-11 16:12:07,953 [INFO    ] __main__: train step 5309: loss: 0.9031, policy_loss: 1.4450, value_loss: 0.8770
2024-07-11 16:12:08,154 [INFO    ] __main__: train step 5310: loss: 0.9032, policy_loss: 1.4449, value_loss: 0.8770
2024-07-11 16:12:08,352 [INFO    ] __main__: train step 5311: loss: 0.9033, policy_loss: 1.4448, value_loss: 0.8770
2024-07-11 16:12:08,572 [INFO    ] __main__: train step 5312: loss: 0.9034, policy_loss: 1.4447, value_loss: 0.8769
2024-07-11 16:12:08,803 [INFO    ] __main__: train step 5313: loss: 0.9035, policy_loss: 1.4447, value_loss: 0.8769
2024-07-11 16:12:08,987 [INFO    ] __main__: train step 5314: loss: 0.9036, policy_loss: 1.4446, value_loss: 0.8768
2024-07-11 16:12:10,016 [INFO    ] __main__: train step 5315: loss: 0.9036, policy_loss: 1.4445, value_loss: 0.8768
2024-07-11 16:12:10,228 [INFO    ] __main__: train step 5316: loss: 0.9037, policy_loss: 1.4444, value_loss: 0.8768
2024-07-11 16:12:10,423 [INFO    ] __main__: train step 5317: loss: 0.9038, policy_loss: 1.4443, value_loss: 0.8767
2024-07-11 16:12:10,620 [INFO    ] __main__: train step 5318: loss: 0.9039, policy_loss: 1.4442, value_loss: 0.8767
2024-07-11 16:12:10,825 [INFO    ] __main__: train step 5319: loss: 0.9040, policy_loss: 1.4441, value_loss: 0.8766
2024-07-11 16:12:11,042 [INFO    ] __main__: train step 5320: loss: 0.9041, policy_loss: 1.4440, value_loss: 0.8766
2024-07-11 16:12:12,473 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:12:12,871 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:12:12,927 [INFO    ] __main__: train step 5321: loss: 0.9042, policy_loss: 1.4439, value_loss: 0.8766
2024-07-11 16:12:13,106 [INFO    ] __main__: train step 5322: loss: 0.9043, policy_loss: 1.4438, value_loss: 0.8765
2024-07-11 16:12:13,337 [INFO    ] __main__: train step 5323: loss: 0.9043, policy_loss: 1.4437, value_loss: 0.8765
2024-07-11 16:12:13,539 [INFO    ] __main__: train step 5324: loss: 0.9044, policy_loss: 1.4436, value_loss: 0.8764
2024-07-11 16:12:13,750 [INFO    ] __main__: train step 5325: loss: 0.9045, policy_loss: 1.4435, value_loss: 0.8764
2024-07-11 16:12:13,946 [INFO    ] __main__: train step 5326: loss: 0.9046, policy_loss: 1.4434, value_loss: 0.8764
2024-07-11 16:12:14,161 [INFO    ] __main__: train step 5327: loss: 0.9047, policy_loss: 1.4433, value_loss: 0.8763
2024-07-11 16:12:14,360 [INFO    ] __main__: train step 5328: loss: 0.9047, policy_loss: 1.4432, value_loss: 0.8763
2024-07-11 16:12:14,579 [INFO    ] __main__: train step 5329: loss: 0.9048, policy_loss: 1.4431, value_loss: 0.8762
2024-07-11 16:12:14,784 [INFO    ] __main__: train step 5330: loss: 0.9049, policy_loss: 1.4430, value_loss: 0.8762
2024-07-11 16:12:14,991 [INFO    ] __main__: train step 5331: loss: 0.9050, policy_loss: 1.4429, value_loss: 0.8762
2024-07-11 16:12:15,199 [INFO    ] __main__: train step 5332: loss: 0.9051, policy_loss: 1.4428, value_loss: 0.8761
2024-07-11 16:12:15,414 [INFO    ] __main__: train step 5333: loss: 0.9052, policy_loss: 1.4427, value_loss: 0.8761
2024-07-11 16:12:15,606 [INFO    ] __main__: train step 5334: loss: 0.9052, policy_loss: 1.4426, value_loss: 0.8760
2024-07-11 16:12:15,827 [INFO    ] __main__: train step 5335: loss: 0.9053, policy_loss: 1.4425, value_loss: 0.8760
2024-07-11 16:12:16,029 [INFO    ] __main__: train step 5336: loss: 0.9054, policy_loss: 1.4424, value_loss: 0.8760
2024-07-11 16:12:16,242 [INFO    ] __main__: train step 5337: loss: 0.9055, policy_loss: 1.4423, value_loss: 0.8759
2024-07-11 16:12:17,702 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:12:18,111 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:12:18,169 [INFO    ] __main__: train step 5338: loss: 0.9056, policy_loss: 1.4422, value_loss: 0.8759
2024-07-11 16:12:18,337 [INFO    ] __main__: train step 5339: loss: 0.9057, policy_loss: 1.4422, value_loss: 0.8759
2024-07-11 16:12:18,538 [INFO    ] __main__: train step 5340: loss: 0.9058, policy_loss: 1.4421, value_loss: 0.8758
2024-07-11 16:12:18,747 [INFO    ] __main__: train step 5341: loss: 0.9058, policy_loss: 1.4420, value_loss: 0.8758
2024-07-11 16:12:18,949 [INFO    ] __main__: train step 5342: loss: 0.9059, policy_loss: 1.4419, value_loss: 0.8757
2024-07-11 16:12:19,141 [INFO    ] __main__: train step 5343: loss: 0.9060, policy_loss: 1.4418, value_loss: 0.8757
2024-07-11 16:12:19,343 [INFO    ] __main__: train step 5344: loss: 0.9061, policy_loss: 1.4417, value_loss: 0.8756
2024-07-11 16:12:19,538 [INFO    ] __main__: train step 5345: loss: 0.9062, policy_loss: 1.4416, value_loss: 0.8756
2024-07-11 16:12:19,757 [INFO    ] __main__: train step 5346: loss: 0.9063, policy_loss: 1.4415, value_loss: 0.8756
2024-07-11 16:12:19,986 [INFO    ] __main__: train step 5347: loss: 0.9064, policy_loss: 1.4414, value_loss: 0.8755
2024-07-11 16:12:20,191 [INFO    ] __main__: train step 5348: loss: 0.9064, policy_loss: 1.4413, value_loss: 0.8755
2024-07-11 16:12:20,385 [INFO    ] __main__: train step 5349: loss: 0.9065, policy_loss: 1.4412, value_loss: 0.8754
2024-07-11 16:12:20,592 [INFO    ] __main__: train step 5350: loss: 0.9066, policy_loss: 1.4411, value_loss: 0.8754
2024-07-11 16:12:20,799 [INFO    ] __main__: train step 5351: loss: 0.9067, policy_loss: 1.4410, value_loss: 0.8754
2024-07-11 16:12:21,000 [INFO    ] __main__: train step 5352: loss: 0.9068, policy_loss: 1.4409, value_loss: 0.8753
2024-07-11 16:12:21,205 [INFO    ] __main__: train step 5353: loss: 0.9068, policy_loss: 1.4408, value_loss: 0.8753
2024-07-11 16:12:21,413 [INFO    ] __main__: train step 5354: loss: 0.9069, policy_loss: 1.4407, value_loss: 0.8752
2024-07-11 16:12:22,850 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:12:23,278 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:12:23,336 [INFO    ] __main__: train step 5355: loss: 0.9070, policy_loss: 1.4406, value_loss: 0.8752
2024-07-11 16:12:23,509 [INFO    ] __main__: train step 5356: loss: 0.9071, policy_loss: 1.4405, value_loss: 0.8752
2024-07-11 16:12:23,723 [INFO    ] __main__: train step 5357: loss: 0.9072, policy_loss: 1.4404, value_loss: 0.8751
2024-07-11 16:12:23,940 [INFO    ] __main__: train step 5358: loss: 0.9073, policy_loss: 1.4403, value_loss: 0.8751
2024-07-11 16:12:24,143 [INFO    ] __main__: train step 5359: loss: 0.9073, policy_loss: 1.4402, value_loss: 0.8750
2024-07-11 16:12:24,352 [INFO    ] __main__: train step 5360: loss: 0.9074, policy_loss: 1.4401, value_loss: 0.8750
2024-07-11 16:12:24,560 [INFO    ] __main__: train step 5361: loss: 0.9075, policy_loss: 1.4400, value_loss: 0.8750
2024-07-11 16:12:24,762 [INFO    ] __main__: train step 5362: loss: 0.9076, policy_loss: 1.4399, value_loss: 0.8749
2024-07-11 16:12:24,958 [INFO    ] __main__: train step 5363: loss: 0.9077, policy_loss: 1.4399, value_loss: 0.8749
2024-07-11 16:12:25,173 [INFO    ] __main__: train step 5364: loss: 0.9078, policy_loss: 1.4398, value_loss: 0.8748
2024-07-11 16:12:25,371 [INFO    ] __main__: train step 5365: loss: 0.9078, policy_loss: 1.4397, value_loss: 0.8748
2024-07-11 16:12:25,566 [INFO    ] __main__: train step 5366: loss: 0.9079, policy_loss: 1.4396, value_loss: 0.8748
2024-07-11 16:12:25,792 [INFO    ] __main__: train step 5367: loss: 0.9080, policy_loss: 1.4395, value_loss: 0.8747
2024-07-11 16:12:25,998 [INFO    ] __main__: train step 5368: loss: 0.9081, policy_loss: 1.4394, value_loss: 0.8747
2024-07-11 16:12:26,206 [INFO    ] __main__: train step 5369: loss: 0.9082, policy_loss: 1.4393, value_loss: 0.8746
2024-07-11 16:12:26,399 [INFO    ] __main__: train step 5370: loss: 0.9082, policy_loss: 1.4392, value_loss: 0.8746
2024-07-11 16:12:26,598 [INFO    ] __main__: train step 5371: loss: 0.9083, policy_loss: 1.4391, value_loss: 0.8746
2024-07-11 16:12:28,048 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:12:28,434 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:12:28,499 [INFO    ] __main__: train step 5372: loss: 0.9084, policy_loss: 1.4390, value_loss: 0.8745
2024-07-11 16:12:28,677 [INFO    ] __main__: train step 5373: loss: 0.9085, policy_loss: 1.4389, value_loss: 0.8745
2024-07-11 16:12:28,884 [INFO    ] __main__: train step 5374: loss: 0.9086, policy_loss: 1.4388, value_loss: 0.8744
2024-07-11 16:12:29,123 [INFO    ] __main__: train step 5375: loss: 0.9087, policy_loss: 1.4387, value_loss: 0.8744
2024-07-11 16:12:29,359 [INFO    ] __main__: train step 5376: loss: 0.9087, policy_loss: 1.4386, value_loss: 0.8744
2024-07-11 16:12:29,577 [INFO    ] __main__: train step 5377: loss: 0.9088, policy_loss: 1.4385, value_loss: 0.8743
2024-07-11 16:12:29,774 [INFO    ] __main__: train step 5378: loss: 0.9089, policy_loss: 1.4384, value_loss: 0.8743
2024-07-11 16:12:29,976 [INFO    ] __main__: train step 5379: loss: 0.9090, policy_loss: 1.4383, value_loss: 0.8742
2024-07-11 16:12:30,192 [INFO    ] __main__: train step 5380: loss: 0.9091, policy_loss: 1.4382, value_loss: 0.8742
2024-07-11 16:12:30,399 [INFO    ] __main__: train step 5381: loss: 0.9091, policy_loss: 1.4381, value_loss: 0.8742
2024-07-11 16:12:30,604 [INFO    ] __main__: train step 5382: loss: 0.9092, policy_loss: 1.4380, value_loss: 0.8741
2024-07-11 16:12:30,801 [INFO    ] __main__: train step 5383: loss: 0.9093, policy_loss: 1.4379, value_loss: 0.8741
2024-07-11 16:12:30,999 [INFO    ] __main__: train step 5384: loss: 0.9094, policy_loss: 1.4378, value_loss: 0.8740
2024-07-11 16:12:31,202 [INFO    ] __main__: train step 5385: loss: 0.9095, policy_loss: 1.4377, value_loss: 0.8740
2024-07-11 16:12:31,397 [INFO    ] __main__: train step 5386: loss: 0.9096, policy_loss: 1.4376, value_loss: 0.8739
2024-07-11 16:12:31,599 [INFO    ] __main__: train step 5387: loss: 0.9096, policy_loss: 1.4375, value_loss: 0.8739
2024-07-11 16:12:31,818 [INFO    ] __main__: train step 5388: loss: 0.9097, policy_loss: 1.4375, value_loss: 0.8739
2024-07-11 16:12:34,180 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:12:34,576 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:12:34,631 [INFO    ] __main__: train step 5389: loss: 0.9098, policy_loss: 1.4374, value_loss: 0.8738
2024-07-11 16:12:34,808 [INFO    ] __main__: train step 5390: loss: 0.9099, policy_loss: 1.4373, value_loss: 0.8738
2024-07-11 16:12:35,027 [INFO    ] __main__: train step 5391: loss: 0.9100, policy_loss: 1.4372, value_loss: 0.8737
2024-07-11 16:12:35,267 [INFO    ] __main__: train step 5392: loss: 0.9101, policy_loss: 1.4371, value_loss: 0.8737
2024-07-11 16:12:35,515 [INFO    ] __main__: train step 5393: loss: 0.9101, policy_loss: 1.4370, value_loss: 0.8737
2024-07-11 16:12:35,749 [INFO    ] __main__: train step 5394: loss: 0.9102, policy_loss: 1.4369, value_loss: 0.8736
2024-07-11 16:12:35,949 [INFO    ] __main__: train step 5395: loss: 0.9103, policy_loss: 1.4368, value_loss: 0.8736
2024-07-11 16:12:36,150 [INFO    ] __main__: train step 5396: loss: 0.9104, policy_loss: 1.4367, value_loss: 0.8735
2024-07-11 16:12:36,359 [INFO    ] __main__: train step 5397: loss: 0.9105, policy_loss: 1.4366, value_loss: 0.8735
2024-07-11 16:12:36,561 [INFO    ] __main__: train step 5398: loss: 0.9106, policy_loss: 1.4365, value_loss: 0.8735
2024-07-11 16:12:36,759 [INFO    ] __main__: train step 5399: loss: 0.9106, policy_loss: 1.4364, value_loss: 0.8734
2024-07-11 16:12:36,957 [INFO    ] __main__: train step 5400: loss: 0.9107, policy_loss: 1.4363, value_loss: 0.8734
2024-07-11 16:12:37,152 [INFO    ] __main__: train step 5401: loss: 0.9108, policy_loss: 1.4362, value_loss: 0.8733
2024-07-11 16:12:37,357 [INFO    ] __main__: train step 5402: loss: 0.9109, policy_loss: 1.4362, value_loss: 0.8733
2024-07-11 16:12:37,551 [INFO    ] __main__: train step 5403: loss: 0.9110, policy_loss: 1.4361, value_loss: 0.8733
2024-07-11 16:12:37,773 [INFO    ] __main__: train step 5404: loss: 0.9111, policy_loss: 1.4360, value_loss: 0.8732
2024-07-11 16:12:38,011 [INFO    ] __main__: train step 5405: loss: 0.9111, policy_loss: 1.4359, value_loss: 0.8732
2024-07-11 16:12:39,486 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:12:39,874 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:12:39,929 [INFO    ] __main__: train step 5406: loss: 0.9112, policy_loss: 1.4358, value_loss: 0.8731
2024-07-11 16:12:40,111 [INFO    ] __main__: train step 5407: loss: 0.9113, policy_loss: 1.4357, value_loss: 0.8731
2024-07-11 16:12:40,315 [INFO    ] __main__: train step 5408: loss: 0.9114, policy_loss: 1.4356, value_loss: 0.8731
2024-07-11 16:12:40,509 [INFO    ] __main__: train step 5409: loss: 0.9115, policy_loss: 1.4355, value_loss: 0.8730
2024-07-11 16:12:40,721 [INFO    ] __main__: train step 5410: loss: 0.9115, policy_loss: 1.4354, value_loss: 0.8730
2024-07-11 16:12:40,952 [INFO    ] __main__: train step 5411: loss: 0.9116, policy_loss: 1.4353, value_loss: 0.8729
2024-07-11 16:12:41,151 [INFO    ] __main__: train step 5412: loss: 0.9117, policy_loss: 1.4352, value_loss: 0.8729
2024-07-11 16:12:41,366 [INFO    ] __main__: train step 5413: loss: 0.9118, policy_loss: 1.4351, value_loss: 0.8729
2024-07-11 16:12:41,600 [INFO    ] __main__: train step 5414: loss: 0.9119, policy_loss: 1.4350, value_loss: 0.8728
2024-07-11 16:12:41,785 [INFO    ] __main__: train step 5415: loss: 0.9120, policy_loss: 1.4349, value_loss: 0.8728
2024-07-11 16:12:41,984 [INFO    ] __main__: train step 5416: loss: 0.9120, policy_loss: 1.4348, value_loss: 0.8727
2024-07-11 16:12:42,189 [INFO    ] __main__: train step 5417: loss: 0.9121, policy_loss: 1.4347, value_loss: 0.8727
2024-07-11 16:12:42,382 [INFO    ] __main__: train step 5418: loss: 0.9122, policy_loss: 1.4346, value_loss: 0.8726
2024-07-11 16:12:42,576 [INFO    ] __main__: train step 5419: loss: 0.9123, policy_loss: 1.4346, value_loss: 0.8726
2024-07-11 16:12:42,771 [INFO    ] __main__: train step 5420: loss: 0.9124, policy_loss: 1.4345, value_loss: 0.8726
2024-07-11 16:12:42,973 [INFO    ] __main__: train step 5421: loss: 0.9125, policy_loss: 1.4344, value_loss: 0.8725
2024-07-11 16:12:43,173 [INFO    ] __main__: train step 5422: loss: 0.9125, policy_loss: 1.4343, value_loss: 0.8725
2024-07-11 16:12:44,620 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:12:45,010 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:12:45,065 [INFO    ] __main__: train step 5423: loss: 0.9126, policy_loss: 1.4342, value_loss: 0.8724
2024-07-11 16:12:45,244 [INFO    ] __main__: train step 5424: loss: 0.9127, policy_loss: 1.4341, value_loss: 0.8724
2024-07-11 16:12:45,463 [INFO    ] __main__: train step 5425: loss: 0.9128, policy_loss: 1.4340, value_loss: 0.8724
2024-07-11 16:12:45,670 [INFO    ] __main__: train step 5426: loss: 0.9129, policy_loss: 1.4339, value_loss: 0.8723
2024-07-11 16:12:45,875 [INFO    ] __main__: train step 5427: loss: 0.9129, policy_loss: 1.4338, value_loss: 0.8723
2024-07-11 16:12:46,075 [INFO    ] __main__: train step 5428: loss: 0.9130, policy_loss: 1.4337, value_loss: 0.8722
2024-07-11 16:12:46,277 [INFO    ] __main__: train step 5429: loss: 0.9131, policy_loss: 1.4336, value_loss: 0.8722
2024-07-11 16:12:46,499 [INFO    ] __main__: train step 5430: loss: 0.9132, policy_loss: 1.4335, value_loss: 0.8722
2024-07-11 16:12:46,714 [INFO    ] __main__: train step 5431: loss: 0.9133, policy_loss: 1.4334, value_loss: 0.8721
2024-07-11 16:12:46,950 [INFO    ] __main__: train step 5432: loss: 0.9133, policy_loss: 1.4333, value_loss: 0.8721
2024-07-11 16:12:47,161 [INFO    ] __main__: train step 5433: loss: 0.9134, policy_loss: 1.4332, value_loss: 0.8720
2024-07-11 16:12:47,386 [INFO    ] __main__: train step 5434: loss: 0.9135, policy_loss: 1.4331, value_loss: 0.8720
2024-07-11 16:12:47,579 [INFO    ] __main__: train step 5435: loss: 0.9136, policy_loss: 1.4330, value_loss: 0.8720
2024-07-11 16:12:47,782 [INFO    ] __main__: train step 5436: loss: 0.9137, policy_loss: 1.4329, value_loss: 0.8719
2024-07-11 16:12:47,979 [INFO    ] __main__: train step 5437: loss: 0.9138, policy_loss: 1.4329, value_loss: 0.8719
2024-07-11 16:12:48,190 [INFO    ] __main__: train step 5438: loss: 0.9138, policy_loss: 1.4328, value_loss: 0.8718
2024-07-11 16:12:48,396 [INFO    ] __main__: train step 5439: loss: 0.9139, policy_loss: 1.4327, value_loss: 0.8718
2024-07-11 16:12:49,844 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:12:50,279 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:12:50,341 [INFO    ] __main__: train step 5440: loss: 0.9140, policy_loss: 1.4326, value_loss: 0.8718
2024-07-11 16:12:50,518 [INFO    ] __main__: train step 5441: loss: 0.9141, policy_loss: 1.4325, value_loss: 0.8717
2024-07-11 16:12:50,713 [INFO    ] __main__: train step 5442: loss: 0.9142, policy_loss: 1.4324, value_loss: 0.8717
2024-07-11 16:12:50,925 [INFO    ] __main__: train step 5443: loss: 0.9142, policy_loss: 1.4323, value_loss: 0.8716
2024-07-11 16:12:51,154 [INFO    ] __main__: train step 5444: loss: 0.9143, policy_loss: 1.4322, value_loss: 0.8716
2024-07-11 16:12:51,362 [INFO    ] __main__: train step 5445: loss: 0.9144, policy_loss: 1.4321, value_loss: 0.8716
2024-07-11 16:12:51,560 [INFO    ] __main__: train step 5446: loss: 0.9145, policy_loss: 1.4320, value_loss: 0.8715
2024-07-11 16:12:51,762 [INFO    ] __main__: train step 5447: loss: 0.9146, policy_loss: 1.4319, value_loss: 0.8715
2024-07-11 16:12:51,959 [INFO    ] __main__: train step 5448: loss: 0.9147, policy_loss: 1.4318, value_loss: 0.8715
2024-07-11 16:12:52,158 [INFO    ] __main__: train step 5449: loss: 0.9147, policy_loss: 1.4317, value_loss: 0.8714
2024-07-11 16:12:52,354 [INFO    ] __main__: train step 5450: loss: 0.9148, policy_loss: 1.4316, value_loss: 0.8714
2024-07-11 16:12:52,566 [INFO    ] __main__: train step 5451: loss: 0.9149, policy_loss: 1.4315, value_loss: 0.8713
2024-07-11 16:12:52,791 [INFO    ] __main__: train step 5452: loss: 0.9150, policy_loss: 1.4314, value_loss: 0.8713
2024-07-11 16:12:52,985 [INFO    ] __main__: train step 5453: loss: 0.9151, policy_loss: 1.4313, value_loss: 0.8712
2024-07-11 16:12:53,185 [INFO    ] __main__: train step 5454: loss: 0.9151, policy_loss: 1.4313, value_loss: 0.8712
2024-07-11 16:12:53,393 [INFO    ] __main__: train step 5455: loss: 0.9152, policy_loss: 1.4312, value_loss: 0.8712
2024-07-11 16:12:53,591 [INFO    ] __main__: train step 5456: loss: 0.9153, policy_loss: 1.4311, value_loss: 0.8711
2024-07-11 16:12:55,038 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:12:55,427 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:12:55,481 [INFO    ] __main__: train step 5457: loss: 0.9154, policy_loss: 1.4310, value_loss: 0.8711
2024-07-11 16:12:55,673 [INFO    ] __main__: train step 5458: loss: 0.9155, policy_loss: 1.4309, value_loss: 0.8711
2024-07-11 16:12:55,907 [INFO    ] __main__: train step 5459: loss: 0.9156, policy_loss: 1.4308, value_loss: 0.8710
2024-07-11 16:12:56,125 [INFO    ] __main__: train step 5460: loss: 0.9156, policy_loss: 1.4307, value_loss: 0.8710
2024-07-11 16:12:56,354 [INFO    ] __main__: train step 5461: loss: 0.9157, policy_loss: 1.4306, value_loss: 0.8709
2024-07-11 16:12:56,590 [INFO    ] __main__: train step 5462: loss: 0.9158, policy_loss: 1.4305, value_loss: 0.8709
2024-07-11 16:12:57,685 [INFO    ] __main__: train step 5463: loss: 0.9159, policy_loss: 1.4304, value_loss: 0.8709
2024-07-11 16:12:57,883 [INFO    ] __main__: train step 5464: loss: 0.9160, policy_loss: 1.4303, value_loss: 0.8708
2024-07-11 16:12:58,084 [INFO    ] __main__: train step 5465: loss: 0.9161, policy_loss: 1.4302, value_loss: 0.8708
2024-07-11 16:12:58,297 [INFO    ] __main__: train step 5466: loss: 0.9161, policy_loss: 1.4301, value_loss: 0.8707
2024-07-11 16:12:58,525 [INFO    ] __main__: train step 5467: loss: 0.9162, policy_loss: 1.4300, value_loss: 0.8707
2024-07-11 16:12:58,723 [INFO    ] __main__: train step 5468: loss: 0.9163, policy_loss: 1.4299, value_loss: 0.8707
2024-07-11 16:12:58,922 [INFO    ] __main__: train step 5469: loss: 0.9164, policy_loss: 1.4298, value_loss: 0.8706
2024-07-11 16:12:59,129 [INFO    ] __main__: train step 5470: loss: 0.9164, policy_loss: 1.4298, value_loss: 0.8706
2024-07-11 16:12:59,342 [INFO    ] __main__: train step 5471: loss: 0.9165, policy_loss: 1.4297, value_loss: 0.8705
2024-07-11 16:12:59,558 [INFO    ] __main__: train step 5472: loss: 0.9166, policy_loss: 1.4296, value_loss: 0.8705
2024-07-11 16:12:59,748 [INFO    ] __main__: train step 5473: loss: 0.9167, policy_loss: 1.4295, value_loss: 0.8705
2024-07-11 16:13:01,214 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:13:01,580 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:13:01,637 [INFO    ] __main__: train step 5474: loss: 0.9168, policy_loss: 1.4294, value_loss: 0.8704
2024-07-11 16:13:01,825 [INFO    ] __main__: train step 5475: loss: 0.9168, policy_loss: 1.4293, value_loss: 0.8704
2024-07-11 16:13:02,036 [INFO    ] __main__: train step 5476: loss: 0.9169, policy_loss: 1.4292, value_loss: 0.8703
2024-07-11 16:13:02,277 [INFO    ] __main__: train step 5477: loss: 0.9170, policy_loss: 1.4291, value_loss: 0.8703
2024-07-11 16:13:02,511 [INFO    ] __main__: train step 5478: loss: 0.9171, policy_loss: 1.4290, value_loss: 0.8703
2024-07-11 16:13:02,710 [INFO    ] __main__: train step 5479: loss: 0.9172, policy_loss: 1.4289, value_loss: 0.8702
2024-07-11 16:13:02,916 [INFO    ] __main__: train step 5480: loss: 0.9173, policy_loss: 1.4288, value_loss: 0.8702
2024-07-11 16:13:03,118 [INFO    ] __main__: train step 5481: loss: 0.9173, policy_loss: 1.4287, value_loss: 0.8701
2024-07-11 16:13:03,325 [INFO    ] __main__: train step 5482: loss: 0.9174, policy_loss: 1.4286, value_loss: 0.8701
2024-07-11 16:13:03,533 [INFO    ] __main__: train step 5483: loss: 0.9175, policy_loss: 1.4285, value_loss: 0.8701
2024-07-11 16:13:03,731 [INFO    ] __main__: train step 5484: loss: 0.9176, policy_loss: 1.4284, value_loss: 0.8700
2024-07-11 16:13:03,970 [INFO    ] __main__: train step 5485: loss: 0.9177, policy_loss: 1.4284, value_loss: 0.8700
2024-07-11 16:13:04,173 [INFO    ] __main__: train step 5486: loss: 0.9177, policy_loss: 1.4283, value_loss: 0.8699
2024-07-11 16:13:04,380 [INFO    ] __main__: train step 5487: loss: 0.9178, policy_loss: 1.4282, value_loss: 0.8699
2024-07-11 16:13:04,590 [INFO    ] __main__: train step 5488: loss: 0.9179, policy_loss: 1.4281, value_loss: 0.8699
2024-07-11 16:13:04,794 [INFO    ] __main__: train step 5489: loss: 0.9180, policy_loss: 1.4280, value_loss: 0.8698
2024-07-11 16:13:05,019 [INFO    ] __main__: train step 5490: loss: 0.9181, policy_loss: 1.4279, value_loss: 0.8698
2024-07-11 16:13:06,486 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:13:06,880 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:13:06,936 [INFO    ] __main__: train step 5491: loss: 0.9182, policy_loss: 1.4278, value_loss: 0.8697
2024-07-11 16:13:07,106 [INFO    ] __main__: train step 5492: loss: 0.9182, policy_loss: 1.4277, value_loss: 0.8697
2024-07-11 16:13:07,308 [INFO    ] __main__: train step 5493: loss: 0.9183, policy_loss: 1.4276, value_loss: 0.8697
2024-07-11 16:13:07,507 [INFO    ] __main__: train step 5494: loss: 0.9184, policy_loss: 1.4275, value_loss: 0.8696
2024-07-11 16:13:07,720 [INFO    ] __main__: train step 5495: loss: 0.9185, policy_loss: 1.4274, value_loss: 0.8696
2024-07-11 16:13:07,912 [INFO    ] __main__: train step 5496: loss: 0.9185, policy_loss: 1.4273, value_loss: 0.8695
2024-07-11 16:13:08,126 [INFO    ] __main__: train step 5497: loss: 0.9186, policy_loss: 1.4272, value_loss: 0.8695
2024-07-11 16:13:08,329 [INFO    ] __main__: train step 5498: loss: 0.9187, policy_loss: 1.4271, value_loss: 0.8695
2024-07-11 16:13:08,540 [INFO    ] __main__: train step 5499: loss: 0.9188, policy_loss: 1.4270, value_loss: 0.8694
2024-07-11 16:13:08,741 [INFO    ] __main__: train step 5500: loss: 0.9189, policy_loss: 1.4270, value_loss: 0.8694
2024-07-11 16:13:08,951 [INFO    ] __main__: train step 5501: loss: 0.9189, policy_loss: 1.4269, value_loss: 0.8693
2024-07-11 16:13:09,153 [INFO    ] __main__: train step 5502: loss: 0.9190, policy_loss: 1.4268, value_loss: 0.8693
2024-07-11 16:13:09,348 [INFO    ] __main__: train step 5503: loss: 0.9191, policy_loss: 1.4267, value_loss: 0.8693
2024-07-11 16:13:09,548 [INFO    ] __main__: train step 5504: loss: 0.9192, policy_loss: 1.4266, value_loss: 0.8692
2024-07-11 16:13:09,761 [INFO    ] __main__: train step 5505: loss: 0.9193, policy_loss: 1.4265, value_loss: 0.8692
2024-07-11 16:13:09,955 [INFO    ] __main__: train step 5506: loss: 0.9194, policy_loss: 1.4264, value_loss: 0.8691
2024-07-11 16:13:10,165 [INFO    ] __main__: train step 5507: loss: 0.9194, policy_loss: 1.4263, value_loss: 0.8691
2024-07-11 16:13:11,617 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:13:12,009 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:13:12,064 [INFO    ] __main__: train step 5508: loss: 0.9195, policy_loss: 1.4262, value_loss: 0.8691
2024-07-11 16:13:12,230 [INFO    ] __main__: train step 5509: loss: 0.9196, policy_loss: 1.4261, value_loss: 0.8690
2024-07-11 16:13:12,445 [INFO    ] __main__: train step 5510: loss: 0.9197, policy_loss: 1.4260, value_loss: 0.8690
2024-07-11 16:13:12,648 [INFO    ] __main__: train step 5511: loss: 0.9198, policy_loss: 1.4259, value_loss: 0.8689
2024-07-11 16:13:12,850 [INFO    ] __main__: train step 5512: loss: 0.9198, policy_loss: 1.4258, value_loss: 0.8689
2024-07-11 16:13:13,051 [INFO    ] __main__: train step 5513: loss: 0.9199, policy_loss: 1.4258, value_loss: 0.8689
2024-07-11 16:13:13,260 [INFO    ] __main__: train step 5514: loss: 0.9200, policy_loss: 1.4257, value_loss: 0.8688
2024-07-11 16:13:13,460 [INFO    ] __main__: train step 5515: loss: 0.9201, policy_loss: 1.4256, value_loss: 0.8688
2024-07-11 16:13:13,665 [INFO    ] __main__: train step 5516: loss: 0.9202, policy_loss: 1.4255, value_loss: 0.8687
2024-07-11 16:13:13,877 [INFO    ] __main__: train step 5517: loss: 0.9202, policy_loss: 1.4254, value_loss: 0.8687
2024-07-11 16:13:14,083 [INFO    ] __main__: train step 5518: loss: 0.9203, policy_loss: 1.4253, value_loss: 0.8687
2024-07-11 16:13:14,299 [INFO    ] __main__: train step 5519: loss: 0.9204, policy_loss: 1.4252, value_loss: 0.8686
2024-07-11 16:13:14,518 [INFO    ] __main__: train step 5520: loss: 0.9205, policy_loss: 1.4251, value_loss: 0.8686
2024-07-11 16:13:14,713 [INFO    ] __main__: train step 5521: loss: 0.9205, policy_loss: 1.4250, value_loss: 0.8685
2024-07-11 16:13:14,925 [INFO    ] __main__: train step 5522: loss: 0.9206, policy_loss: 1.4249, value_loss: 0.8685
2024-07-11 16:13:15,116 [INFO    ] __main__: train step 5523: loss: 0.9207, policy_loss: 1.4248, value_loss: 0.8685
2024-07-11 16:13:15,326 [INFO    ] __main__: train step 5524: loss: 0.9208, policy_loss: 1.4247, value_loss: 0.8684
2024-07-11 16:13:16,760 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:13:17,168 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:13:17,224 [INFO    ] __main__: train step 5525: loss: 0.9209, policy_loss: 1.4246, value_loss: 0.8684
2024-07-11 16:13:17,396 [INFO    ] __main__: train step 5526: loss: 0.9209, policy_loss: 1.4246, value_loss: 0.8683
2024-07-11 16:13:17,597 [INFO    ] __main__: train step 5527: loss: 0.9210, policy_loss: 1.4245, value_loss: 0.8683
2024-07-11 16:13:17,790 [INFO    ] __main__: train step 5528: loss: 0.9211, policy_loss: 1.4244, value_loss: 0.8683
2024-07-11 16:13:17,992 [INFO    ] __main__: train step 5529: loss: 0.9212, policy_loss: 1.4243, value_loss: 0.8682
2024-07-11 16:13:18,195 [INFO    ] __main__: train step 5530: loss: 0.9213, policy_loss: 1.4242, value_loss: 0.8682
2024-07-11 16:13:18,395 [INFO    ] __main__: train step 5531: loss: 0.9213, policy_loss: 1.4241, value_loss: 0.8681
2024-07-11 16:13:18,593 [INFO    ] __main__: train step 5532: loss: 0.9214, policy_loss: 1.4240, value_loss: 0.8681
2024-07-11 16:13:18,789 [INFO    ] __main__: train step 5533: loss: 0.9215, policy_loss: 1.4239, value_loss: 0.8681
2024-07-11 16:13:18,992 [INFO    ] __main__: train step 5534: loss: 0.9216, policy_loss: 1.4238, value_loss: 0.8680
2024-07-11 16:13:19,191 [INFO    ] __main__: train step 5535: loss: 0.9217, policy_loss: 1.4237, value_loss: 0.8680
2024-07-11 16:13:19,394 [INFO    ] __main__: train step 5536: loss: 0.9217, policy_loss: 1.4236, value_loss: 0.8679
2024-07-11 16:13:20,443 [INFO    ] __main__: train step 5537: loss: 0.9218, policy_loss: 1.4235, value_loss: 0.8679
2024-07-11 16:13:20,651 [INFO    ] __main__: train step 5538: loss: 0.9219, policy_loss: 1.4234, value_loss: 0.8679
2024-07-11 16:13:20,855 [INFO    ] __main__: train step 5539: loss: 0.9220, policy_loss: 1.4234, value_loss: 0.8678
2024-07-11 16:13:21,055 [INFO    ] __main__: train step 5540: loss: 0.9221, policy_loss: 1.4233, value_loss: 0.8678
2024-07-11 16:13:21,259 [INFO    ] __main__: train step 5541: loss: 0.9222, policy_loss: 1.4232, value_loss: 0.8678
2024-07-11 16:13:22,679 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:13:23,101 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:13:23,162 [INFO    ] __main__: train step 5542: loss: 0.9222, policy_loss: 1.4231, value_loss: 0.8677
2024-07-11 16:13:23,340 [INFO    ] __main__: train step 5543: loss: 0.9223, policy_loss: 1.4230, value_loss: 0.8677
2024-07-11 16:13:23,553 [INFO    ] __main__: train step 5544: loss: 0.9224, policy_loss: 1.4229, value_loss: 0.8676
2024-07-11 16:13:23,743 [INFO    ] __main__: train step 5545: loss: 0.9225, policy_loss: 1.4228, value_loss: 0.8676
2024-07-11 16:13:23,953 [INFO    ] __main__: train step 5546: loss: 0.9225, policy_loss: 1.4227, value_loss: 0.8676
2024-07-11 16:13:24,154 [INFO    ] __main__: train step 5547: loss: 0.9226, policy_loss: 1.4226, value_loss: 0.8675
2024-07-11 16:13:24,363 [INFO    ] __main__: train step 5548: loss: 0.9227, policy_loss: 1.4225, value_loss: 0.8675
2024-07-11 16:13:24,557 [INFO    ] __main__: train step 5549: loss: 0.9228, policy_loss: 1.4224, value_loss: 0.8674
2024-07-11 16:13:24,766 [INFO    ] __main__: train step 5550: loss: 0.9229, policy_loss: 1.4223, value_loss: 0.8674
2024-07-11 16:13:24,963 [INFO    ] __main__: train step 5551: loss: 0.9229, policy_loss: 1.4223, value_loss: 0.8673
2024-07-11 16:13:25,164 [INFO    ] __main__: train step 5552: loss: 0.9230, policy_loss: 1.4222, value_loss: 0.8673
2024-07-11 16:13:25,364 [INFO    ] __main__: train step 5553: loss: 0.9231, policy_loss: 1.4221, value_loss: 0.8673
2024-07-11 16:13:25,598 [INFO    ] __main__: train step 5554: loss: 0.9232, policy_loss: 1.4220, value_loss: 0.8672
2024-07-11 16:13:25,830 [INFO    ] __main__: train step 5555: loss: 0.9233, policy_loss: 1.4219, value_loss: 0.8672
2024-07-11 16:13:26,045 [INFO    ] __main__: train step 5556: loss: 0.9233, policy_loss: 1.4218, value_loss: 0.8671
2024-07-11 16:13:26,239 [INFO    ] __main__: train step 5557: loss: 0.9234, policy_loss: 1.4217, value_loss: 0.8671
2024-07-11 16:13:26,447 [INFO    ] __main__: train step 5558: loss: 0.9235, policy_loss: 1.4216, value_loss: 0.8671
2024-07-11 16:13:27,877 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:13:28,244 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:13:28,300 [INFO    ] __main__: train step 5559: loss: 0.9236, policy_loss: 1.4215, value_loss: 0.8670
2024-07-11 16:13:28,471 [INFO    ] __main__: train step 5560: loss: 0.9237, policy_loss: 1.4214, value_loss: 0.8670
2024-07-11 16:13:28,683 [INFO    ] __main__: train step 5561: loss: 0.9237, policy_loss: 1.4213, value_loss: 0.8670
2024-07-11 16:13:28,879 [INFO    ] __main__: train step 5562: loss: 0.9238, policy_loss: 1.4212, value_loss: 0.8669
2024-07-11 16:13:29,073 [INFO    ] __main__: train step 5563: loss: 0.9239, policy_loss: 1.4212, value_loss: 0.8669
2024-07-11 16:13:29,271 [INFO    ] __main__: train step 5564: loss: 0.9240, policy_loss: 1.4211, value_loss: 0.8668
2024-07-11 16:13:29,483 [INFO    ] __main__: train step 5565: loss: 0.9241, policy_loss: 1.4210, value_loss: 0.8668
2024-07-11 16:13:29,679 [INFO    ] __main__: train step 5566: loss: 0.9241, policy_loss: 1.4209, value_loss: 0.8667
2024-07-11 16:13:29,871 [INFO    ] __main__: train step 5567: loss: 0.9242, policy_loss: 1.4208, value_loss: 0.8667
2024-07-11 16:13:30,081 [INFO    ] __main__: train step 5568: loss: 0.9243, policy_loss: 1.4207, value_loss: 0.8667
2024-07-11 16:13:30,311 [INFO    ] __main__: train step 5569: loss: 0.9244, policy_loss: 1.4206, value_loss: 0.8666
2024-07-11 16:13:30,513 [INFO    ] __main__: train step 5570: loss: 0.9245, policy_loss: 1.4205, value_loss: 0.8666
2024-07-11 16:13:30,714 [INFO    ] __main__: train step 5571: loss: 0.9245, policy_loss: 1.4204, value_loss: 0.8665
2024-07-11 16:13:30,908 [INFO    ] __main__: train step 5572: loss: 0.9246, policy_loss: 1.4203, value_loss: 0.8665
2024-07-11 16:13:31,112 [INFO    ] __main__: train step 5573: loss: 0.9247, policy_loss: 1.4202, value_loss: 0.8665
2024-07-11 16:13:31,307 [INFO    ] __main__: train step 5574: loss: 0.9248, policy_loss: 1.4202, value_loss: 0.8664
2024-07-11 16:13:31,509 [INFO    ] __main__: train step 5575: loss: 0.9249, policy_loss: 1.4201, value_loss: 0.8664
2024-07-11 16:13:32,938 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:13:33,308 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:13:33,361 [INFO    ] __main__: train step 5576: loss: 0.9249, policy_loss: 1.4200, value_loss: 0.8663
2024-07-11 16:13:33,538 [INFO    ] __main__: train step 5577: loss: 0.9250, policy_loss: 1.4199, value_loss: 0.8663
2024-07-11 16:13:33,750 [INFO    ] __main__: train step 5578: loss: 0.9251, policy_loss: 1.4198, value_loss: 0.8663
2024-07-11 16:13:33,950 [INFO    ] __main__: train step 5579: loss: 0.9252, policy_loss: 1.4197, value_loss: 0.8662
2024-07-11 16:13:34,151 [INFO    ] __main__: train step 5580: loss: 0.9253, policy_loss: 1.4196, value_loss: 0.8662
2024-07-11 16:13:34,366 [INFO    ] __main__: train step 5581: loss: 0.9253, policy_loss: 1.4195, value_loss: 0.8661
2024-07-11 16:13:34,573 [INFO    ] __main__: train step 5582: loss: 0.9254, policy_loss: 1.4194, value_loss: 0.8661
2024-07-11 16:13:34,786 [INFO    ] __main__: train step 5583: loss: 0.9255, policy_loss: 1.4193, value_loss: 0.8661
2024-07-11 16:13:34,998 [INFO    ] __main__: train step 5584: loss: 0.9256, policy_loss: 1.4193, value_loss: 0.8660
2024-07-11 16:13:35,213 [INFO    ] __main__: train step 5585: loss: 0.9257, policy_loss: 1.4192, value_loss: 0.8660
2024-07-11 16:13:35,416 [INFO    ] __main__: train step 5586: loss: 0.9257, policy_loss: 1.4191, value_loss: 0.8659
2024-07-11 16:13:35,624 [INFO    ] __main__: train step 5587: loss: 0.9258, policy_loss: 1.4190, value_loss: 0.8659
2024-07-11 16:13:35,861 [INFO    ] __main__: train step 5588: loss: 0.9259, policy_loss: 1.4189, value_loss: 0.8659
2024-07-11 16:13:36,072 [INFO    ] __main__: train step 5589: loss: 0.9260, policy_loss: 1.4188, value_loss: 0.8658
2024-07-11 16:13:36,281 [INFO    ] __main__: train step 5590: loss: 0.9260, policy_loss: 1.4187, value_loss: 0.8658
2024-07-11 16:13:36,481 [INFO    ] __main__: train step 5591: loss: 0.9261, policy_loss: 1.4186, value_loss: 0.8658
2024-07-11 16:13:36,699 [INFO    ] __main__: train step 5592: loss: 0.9262, policy_loss: 1.4185, value_loss: 0.8657
2024-07-11 16:13:38,119 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:13:38,518 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:13:38,576 [INFO    ] __main__: train step 5593: loss: 0.9263, policy_loss: 1.4184, value_loss: 0.8657
2024-07-11 16:13:38,748 [INFO    ] __main__: train step 5594: loss: 0.9264, policy_loss: 1.4183, value_loss: 0.8656
2024-07-11 16:13:38,949 [INFO    ] __main__: train step 5595: loss: 0.9264, policy_loss: 1.4182, value_loss: 0.8656
2024-07-11 16:13:39,150 [INFO    ] __main__: train step 5596: loss: 0.9265, policy_loss: 1.4182, value_loss: 0.8656
2024-07-11 16:13:39,360 [INFO    ] __main__: train step 5597: loss: 0.9266, policy_loss: 1.4181, value_loss: 0.8655
2024-07-11 16:13:39,561 [INFO    ] __main__: train step 5598: loss: 0.9267, policy_loss: 1.4180, value_loss: 0.8655
2024-07-11 16:13:39,772 [INFO    ] __main__: train step 5599: loss: 0.9267, policy_loss: 1.4179, value_loss: 0.8654
2024-07-11 16:13:39,969 [INFO    ] __main__: train step 5600: loss: 0.9268, policy_loss: 1.4178, value_loss: 0.8654
2024-07-11 16:13:40,164 [INFO    ] __main__: train step 5601: loss: 0.9269, policy_loss: 1.4177, value_loss: 0.8654
2024-07-11 16:13:40,373 [INFO    ] __main__: train step 5602: loss: 0.9270, policy_loss: 1.4176, value_loss: 0.8653
2024-07-11 16:13:40,575 [INFO    ] __main__: train step 5603: loss: 0.9271, policy_loss: 1.4175, value_loss: 0.8653
2024-07-11 16:13:40,794 [INFO    ] __main__: train step 5604: loss: 0.9271, policy_loss: 1.4174, value_loss: 0.8652
2024-07-11 16:13:41,027 [INFO    ] __main__: train step 5605: loss: 0.9272, policy_loss: 1.4173, value_loss: 0.8652
2024-07-11 16:13:41,232 [INFO    ] __main__: train step 5606: loss: 0.9273, policy_loss: 1.4172, value_loss: 0.8652
2024-07-11 16:13:41,431 [INFO    ] __main__: train step 5607: loss: 0.9274, policy_loss: 1.4171, value_loss: 0.8651
2024-07-11 16:13:41,638 [INFO    ] __main__: train step 5608: loss: 0.9275, policy_loss: 1.4171, value_loss: 0.8651
2024-07-11 16:13:41,843 [INFO    ] __main__: train step 5609: loss: 0.9275, policy_loss: 1.4170, value_loss: 0.8650
2024-07-11 16:13:44,089 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:13:44,454 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:13:44,513 [INFO    ] __main__: train step 5610: loss: 0.9276, policy_loss: 1.4169, value_loss: 0.8650
2024-07-11 16:13:44,698 [INFO    ] __main__: train step 5611: loss: 0.9277, policy_loss: 1.4168, value_loss: 0.8650
2024-07-11 16:13:44,925 [INFO    ] __main__: train step 5612: loss: 0.9278, policy_loss: 1.4167, value_loss: 0.8649
2024-07-11 16:13:45,135 [INFO    ] __main__: train step 5613: loss: 0.9278, policy_loss: 1.4166, value_loss: 0.8649
2024-07-11 16:13:45,352 [INFO    ] __main__: train step 5614: loss: 0.9279, policy_loss: 1.4165, value_loss: 0.8648
2024-07-11 16:13:45,585 [INFO    ] __main__: train step 5615: loss: 0.9280, policy_loss: 1.4164, value_loss: 0.8648
2024-07-11 16:13:45,785 [INFO    ] __main__: train step 5616: loss: 0.9281, policy_loss: 1.4163, value_loss: 0.8647
2024-07-11 16:13:45,986 [INFO    ] __main__: train step 5617: loss: 0.9281, policy_loss: 1.4162, value_loss: 0.8647
2024-07-11 16:13:46,179 [INFO    ] __main__: train step 5618: loss: 0.9282, policy_loss: 1.4161, value_loss: 0.8647
2024-07-11 16:13:46,382 [INFO    ] __main__: train step 5619: loss: 0.9283, policy_loss: 1.4160, value_loss: 0.8646
2024-07-11 16:13:46,587 [INFO    ] __main__: train step 5620: loss: 0.9284, policy_loss: 1.4160, value_loss: 0.8646
2024-07-11 16:13:46,783 [INFO    ] __main__: train step 5621: loss: 0.9285, policy_loss: 1.4159, value_loss: 0.8646
2024-07-11 16:13:47,008 [INFO    ] __main__: train step 5622: loss: 0.9285, policy_loss: 1.4158, value_loss: 0.8645
2024-07-11 16:13:47,243 [INFO    ] __main__: train step 5623: loss: 0.9286, policy_loss: 1.4157, value_loss: 0.8645
2024-07-11 16:13:47,446 [INFO    ] __main__: train step 5624: loss: 0.9287, policy_loss: 1.4156, value_loss: 0.8644
2024-07-11 16:13:47,647 [INFO    ] __main__: train step 5625: loss: 0.9288, policy_loss: 1.4155, value_loss: 0.8644
2024-07-11 16:13:47,863 [INFO    ] __main__: train step 5626: loss: 0.9288, policy_loss: 1.4154, value_loss: 0.8644
2024-07-11 16:13:49,292 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:13:49,667 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:13:49,723 [INFO    ] __main__: train step 5627: loss: 0.9289, policy_loss: 1.4153, value_loss: 0.8643
2024-07-11 16:13:49,909 [INFO    ] __main__: train step 5628: loss: 0.9290, policy_loss: 1.4152, value_loss: 0.8643
2024-07-11 16:13:50,143 [INFO    ] __main__: train step 5629: loss: 0.9291, policy_loss: 1.4151, value_loss: 0.8642
2024-07-11 16:13:50,347 [INFO    ] __main__: train step 5630: loss: 0.9292, policy_loss: 1.4150, value_loss: 0.8642
2024-07-11 16:13:50,561 [INFO    ] __main__: train step 5631: loss: 0.9292, policy_loss: 1.4150, value_loss: 0.8642
2024-07-11 16:13:50,785 [INFO    ] __main__: train step 5632: loss: 0.9293, policy_loss: 1.4149, value_loss: 0.8641
2024-07-11 16:13:51,016 [INFO    ] __main__: train step 5633: loss: 0.9294, policy_loss: 1.4148, value_loss: 0.8641
2024-07-11 16:13:51,216 [INFO    ] __main__: train step 5634: loss: 0.9295, policy_loss: 1.4147, value_loss: 0.8640
2024-07-11 16:13:51,415 [INFO    ] __main__: train step 5635: loss: 0.9295, policy_loss: 1.4146, value_loss: 0.8640
2024-07-11 16:13:51,611 [INFO    ] __main__: train step 5636: loss: 0.9296, policy_loss: 1.4145, value_loss: 0.8640
2024-07-11 16:13:51,817 [INFO    ] __main__: train step 5637: loss: 0.9297, policy_loss: 1.4144, value_loss: 0.8639
2024-07-11 16:13:52,017 [INFO    ] __main__: train step 5638: loss: 0.9298, policy_loss: 1.4143, value_loss: 0.8639
2024-07-11 16:13:52,204 [INFO    ] __main__: train step 5639: loss: 0.9298, policy_loss: 1.4142, value_loss: 0.8638
2024-07-11 16:13:52,401 [INFO    ] __main__: train step 5640: loss: 0.9299, policy_loss: 1.4141, value_loss: 0.8638
2024-07-11 16:13:52,606 [INFO    ] __main__: train step 5641: loss: 0.9300, policy_loss: 1.4140, value_loss: 0.8638
2024-07-11 16:13:52,815 [INFO    ] __main__: train step 5642: loss: 0.9301, policy_loss: 1.4139, value_loss: 0.8637
2024-07-11 16:13:53,020 [INFO    ] __main__: train step 5643: loss: 0.9302, policy_loss: 1.4139, value_loss: 0.8637
2024-07-11 16:13:54,465 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:13:54,859 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:13:54,917 [INFO    ] __main__: train step 5644: loss: 0.9302, policy_loss: 1.4138, value_loss: 0.8636
2024-07-11 16:13:55,091 [INFO    ] __main__: train step 5645: loss: 0.9303, policy_loss: 1.4137, value_loss: 0.8636
2024-07-11 16:13:55,293 [INFO    ] __main__: train step 5646: loss: 0.9304, policy_loss: 1.4136, value_loss: 0.8636
2024-07-11 16:13:55,506 [INFO    ] __main__: train step 5647: loss: 0.9305, policy_loss: 1.4135, value_loss: 0.8635
2024-07-11 16:13:55,714 [INFO    ] __main__: train step 5648: loss: 0.9305, policy_loss: 1.4134, value_loss: 0.8635
2024-07-11 16:13:55,952 [INFO    ] __main__: train step 5649: loss: 0.9306, policy_loss: 1.4133, value_loss: 0.8634
2024-07-11 16:13:56,146 [INFO    ] __main__: train step 5650: loss: 0.9307, policy_loss: 1.4132, value_loss: 0.8634
2024-07-11 16:13:56,345 [INFO    ] __main__: train step 5651: loss: 0.9308, policy_loss: 1.4131, value_loss: 0.8634
2024-07-11 16:13:56,556 [INFO    ] __main__: train step 5652: loss: 0.9308, policy_loss: 1.4130, value_loss: 0.8633
2024-07-11 16:13:56,783 [INFO    ] __main__: train step 5653: loss: 0.9309, policy_loss: 1.4129, value_loss: 0.8633
2024-07-11 16:13:56,983 [INFO    ] __main__: train step 5654: loss: 0.9310, policy_loss: 1.4128, value_loss: 0.8632
2024-07-11 16:13:57,192 [INFO    ] __main__: train step 5655: loss: 0.9311, policy_loss: 1.4128, value_loss: 0.8632
2024-07-11 16:13:57,420 [INFO    ] __main__: train step 5656: loss: 0.9311, policy_loss: 1.4127, value_loss: 0.8632
2024-07-11 16:13:57,635 [INFO    ] __main__: train step 5657: loss: 0.9312, policy_loss: 1.4126, value_loss: 0.8631
2024-07-11 16:13:57,834 [INFO    ] __main__: train step 5658: loss: 0.9313, policy_loss: 1.4125, value_loss: 0.8631
2024-07-11 16:13:58,030 [INFO    ] __main__: train step 5659: loss: 0.9314, policy_loss: 1.4124, value_loss: 0.8630
2024-07-11 16:13:58,237 [INFO    ] __main__: train step 5660: loss: 0.9314, policy_loss: 1.4123, value_loss: 0.8630
2024-07-11 16:13:59,671 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:14:00,054 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:14:00,108 [INFO    ] __main__: train step 5661: loss: 0.9315, policy_loss: 1.4122, value_loss: 0.8630
2024-07-11 16:14:00,274 [INFO    ] __main__: train step 5662: loss: 0.9316, policy_loss: 1.4121, value_loss: 0.8629
2024-07-11 16:14:00,487 [INFO    ] __main__: train step 5663: loss: 0.9317, policy_loss: 1.4120, value_loss: 0.8629
2024-07-11 16:14:00,674 [INFO    ] __main__: train step 5664: loss: 0.9318, policy_loss: 1.4119, value_loss: 0.8628
2024-07-11 16:14:00,880 [INFO    ] __main__: train step 5665: loss: 0.9318, policy_loss: 1.4118, value_loss: 0.8628
2024-07-11 16:14:01,081 [INFO    ] __main__: train step 5666: loss: 0.9319, policy_loss: 1.4117, value_loss: 0.8628
2024-07-11 16:14:01,282 [INFO    ] __main__: train step 5667: loss: 0.9320, policy_loss: 1.4117, value_loss: 0.8627
2024-07-11 16:14:01,480 [INFO    ] __main__: train step 5668: loss: 0.9321, policy_loss: 1.4116, value_loss: 0.8627
2024-07-11 16:14:01,683 [INFO    ] __main__: train step 5669: loss: 0.9321, policy_loss: 1.4115, value_loss: 0.8627
2024-07-11 16:14:01,882 [INFO    ] __main__: train step 5670: loss: 0.9322, policy_loss: 1.4114, value_loss: 0.8626
2024-07-11 16:14:02,094 [INFO    ] __main__: train step 5671: loss: 0.9323, policy_loss: 1.4113, value_loss: 0.8626
2024-07-11 16:14:02,303 [INFO    ] __main__: train step 5672: loss: 0.9324, policy_loss: 1.4112, value_loss: 0.8625
2024-07-11 16:14:02,529 [INFO    ] __main__: train step 5673: loss: 0.9325, policy_loss: 1.4111, value_loss: 0.8625
2024-07-11 16:14:02,765 [INFO    ] __main__: train step 5674: loss: 0.9325, policy_loss: 1.4110, value_loss: 0.8625
2024-07-11 16:14:02,964 [INFO    ] __main__: train step 5675: loss: 0.9326, policy_loss: 1.4109, value_loss: 0.8624
2024-07-11 16:14:03,163 [INFO    ] __main__: train step 5676: loss: 0.9327, policy_loss: 1.4109, value_loss: 0.8624
2024-07-11 16:14:03,367 [INFO    ] __main__: train step 5677: loss: 0.9328, policy_loss: 1.4108, value_loss: 0.8623
2024-07-11 16:14:04,805 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:14:05,186 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:14:05,244 [INFO    ] __main__: train step 5678: loss: 0.9328, policy_loss: 1.4107, value_loss: 0.8623
2024-07-11 16:14:05,419 [INFO    ] __main__: train step 5679: loss: 0.9329, policy_loss: 1.4106, value_loss: 0.8623
2024-07-11 16:14:05,624 [INFO    ] __main__: train step 5680: loss: 0.9330, policy_loss: 1.4105, value_loss: 0.8622
2024-07-11 16:14:05,828 [INFO    ] __main__: train step 5681: loss: 0.9331, policy_loss: 1.4104, value_loss: 0.8622
2024-07-11 16:14:06,023 [INFO    ] __main__: train step 5682: loss: 0.9331, policy_loss: 1.4103, value_loss: 0.8621
2024-07-11 16:14:06,230 [INFO    ] __main__: train step 5683: loss: 0.9332, policy_loss: 1.4102, value_loss: 0.8621
2024-07-11 16:14:07,273 [INFO    ] __main__: train step 5684: loss: 0.9333, policy_loss: 1.4101, value_loss: 0.8621
2024-07-11 16:14:07,489 [INFO    ] __main__: train step 5685: loss: 0.9334, policy_loss: 1.4100, value_loss: 0.8620
2024-07-11 16:14:07,682 [INFO    ] __main__: train step 5686: loss: 0.9334, policy_loss: 1.4100, value_loss: 0.8620
2024-07-11 16:14:07,892 [INFO    ] __main__: train step 5687: loss: 0.9335, policy_loss: 1.4099, value_loss: 0.8619
2024-07-11 16:14:08,096 [INFO    ] __main__: train step 5688: loss: 0.9336, policy_loss: 1.4098, value_loss: 0.8619
2024-07-11 16:14:08,299 [INFO    ] __main__: train step 5689: loss: 0.9337, policy_loss: 1.4097, value_loss: 0.8619
2024-07-11 16:14:08,508 [INFO    ] __main__: train step 5690: loss: 0.9337, policy_loss: 1.4096, value_loss: 0.8618
2024-07-11 16:14:08,696 [INFO    ] __main__: train step 5691: loss: 0.9338, policy_loss: 1.4095, value_loss: 0.8618
2024-07-11 16:14:08,900 [INFO    ] __main__: train step 5692: loss: 0.9339, policy_loss: 1.4094, value_loss: 0.8617
2024-07-11 16:14:09,133 [INFO    ] __main__: train step 5693: loss: 0.9340, policy_loss: 1.4093, value_loss: 0.8617
2024-07-11 16:14:09,335 [INFO    ] __main__: train step 5694: loss: 0.9341, policy_loss: 1.4092, value_loss: 0.8617
2024-07-11 16:14:10,788 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:14:11,203 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:14:11,264 [INFO    ] __main__: train step 5695: loss: 0.9341, policy_loss: 1.4091, value_loss: 0.8616
2024-07-11 16:14:11,434 [INFO    ] __main__: train step 5696: loss: 0.9342, policy_loss: 1.4091, value_loss: 0.8616
2024-07-11 16:14:11,650 [INFO    ] __main__: train step 5697: loss: 0.9343, policy_loss: 1.4090, value_loss: 0.8616
2024-07-11 16:14:11,850 [INFO    ] __main__: train step 5698: loss: 0.9344, policy_loss: 1.4089, value_loss: 0.8615
2024-07-11 16:14:12,092 [INFO    ] __main__: train step 5699: loss: 0.9345, policy_loss: 1.4088, value_loss: 0.8615
2024-07-11 16:14:12,299 [INFO    ] __main__: train step 5700: loss: 0.9345, policy_loss: 1.4087, value_loss: 0.8614
2024-07-11 16:14:12,542 [INFO    ] __main__: train step 5701: loss: 0.9346, policy_loss: 1.4086, value_loss: 0.8614
2024-07-11 16:14:12,748 [INFO    ] __main__: train step 5702: loss: 0.9347, policy_loss: 1.4085, value_loss: 0.8614
2024-07-11 16:14:12,953 [INFO    ] __main__: train step 5703: loss: 0.9348, policy_loss: 1.4084, value_loss: 0.8613
2024-07-11 16:14:13,174 [INFO    ] __main__: train step 5704: loss: 0.9348, policy_loss: 1.4083, value_loss: 0.8613
2024-07-11 16:14:13,370 [INFO    ] __main__: train step 5705: loss: 0.9349, policy_loss: 1.4082, value_loss: 0.8612
2024-07-11 16:14:13,567 [INFO    ] __main__: train step 5706: loss: 0.9350, policy_loss: 1.4082, value_loss: 0.8612
2024-07-11 16:14:13,787 [INFO    ] __main__: train step 5707: loss: 0.9351, policy_loss: 1.4081, value_loss: 0.8612
2024-07-11 16:14:14,020 [INFO    ] __main__: train step 5708: loss: 0.9351, policy_loss: 1.4080, value_loss: 0.8611
2024-07-11 16:14:14,224 [INFO    ] __main__: train step 5709: loss: 0.9352, policy_loss: 1.4079, value_loss: 0.8611
2024-07-11 16:14:14,438 [INFO    ] __main__: train step 5710: loss: 0.9353, policy_loss: 1.4078, value_loss: 0.8610
2024-07-11 16:14:14,635 [INFO    ] __main__: train step 5711: loss: 0.9354, policy_loss: 1.4077, value_loss: 0.8610
2024-07-11 16:14:16,068 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:14:16,490 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:14:16,545 [INFO    ] __main__: train step 5712: loss: 0.9354, policy_loss: 1.4076, value_loss: 0.8610
2024-07-11 16:14:16,741 [INFO    ] __main__: train step 5713: loss: 0.9355, policy_loss: 1.4075, value_loss: 0.8609
2024-07-11 16:14:16,972 [INFO    ] __main__: train step 5714: loss: 0.9356, policy_loss: 1.4074, value_loss: 0.8609
2024-07-11 16:14:17,170 [INFO    ] __main__: train step 5715: loss: 0.9357, policy_loss: 1.4073, value_loss: 0.8609
2024-07-11 16:14:17,369 [INFO    ] __main__: train step 5716: loss: 0.9357, policy_loss: 1.4073, value_loss: 0.8608
2024-07-11 16:14:17,584 [INFO    ] __main__: train step 5717: loss: 0.9358, policy_loss: 1.4072, value_loss: 0.8608
2024-07-11 16:14:17,792 [INFO    ] __main__: train step 5718: loss: 0.9359, policy_loss: 1.4071, value_loss: 0.8607
2024-07-11 16:14:18,000 [INFO    ] __main__: train step 5719: loss: 0.9360, policy_loss: 1.4070, value_loss: 0.8607
2024-07-11 16:14:18,203 [INFO    ] __main__: train step 5720: loss: 0.9360, policy_loss: 1.4069, value_loss: 0.8607
2024-07-11 16:14:18,405 [INFO    ] __main__: train step 5721: loss: 0.9361, policy_loss: 1.4068, value_loss: 0.8606
2024-07-11 16:14:18,615 [INFO    ] __main__: train step 5722: loss: 0.9362, policy_loss: 1.4067, value_loss: 0.8606
2024-07-11 16:14:18,813 [INFO    ] __main__: train step 5723: loss: 0.9363, policy_loss: 1.4066, value_loss: 0.8605
2024-07-11 16:14:19,025 [INFO    ] __main__: train step 5724: loss: 0.9364, policy_loss: 1.4065, value_loss: 0.8605
2024-07-11 16:14:19,224 [INFO    ] __main__: train step 5725: loss: 0.9364, policy_loss: 1.4065, value_loss: 0.8605
2024-07-11 16:14:19,425 [INFO    ] __main__: train step 5726: loss: 0.9365, policy_loss: 1.4064, value_loss: 0.8604
2024-07-11 16:14:19,620 [INFO    ] __main__: train step 5727: loss: 0.9366, policy_loss: 1.4063, value_loss: 0.8604
2024-07-11 16:14:19,833 [INFO    ] __main__: train step 5728: loss: 0.9367, policy_loss: 1.4062, value_loss: 0.8603
2024-07-11 16:14:21,303 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:14:21,676 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:14:21,731 [INFO    ] __main__: train step 5729: loss: 0.9367, policy_loss: 1.4061, value_loss: 0.8603
2024-07-11 16:14:21,898 [INFO    ] __main__: train step 5730: loss: 0.9368, policy_loss: 1.4060, value_loss: 0.8603
2024-07-11 16:14:22,132 [INFO    ] __main__: train step 5731: loss: 0.9369, policy_loss: 1.4059, value_loss: 0.8602
2024-07-11 16:14:22,361 [INFO    ] __main__: train step 5732: loss: 0.9370, policy_loss: 1.4058, value_loss: 0.8602
2024-07-11 16:14:22,555 [INFO    ] __main__: train step 5733: loss: 0.9370, policy_loss: 1.4057, value_loss: 0.8601
2024-07-11 16:14:22,757 [INFO    ] __main__: train step 5734: loss: 0.9371, policy_loss: 1.4056, value_loss: 0.8601
2024-07-11 16:14:22,969 [INFO    ] __main__: train step 5735: loss: 0.9372, policy_loss: 1.4056, value_loss: 0.8601
2024-07-11 16:14:23,183 [INFO    ] __main__: train step 5736: loss: 0.9373, policy_loss: 1.4055, value_loss: 0.8600
2024-07-11 16:14:23,397 [INFO    ] __main__: train step 5737: loss: 0.9373, policy_loss: 1.4054, value_loss: 0.8600
2024-07-11 16:14:23,630 [INFO    ] __main__: train step 5738: loss: 0.9374, policy_loss: 1.4053, value_loss: 0.8599
2024-07-11 16:14:23,861 [INFO    ] __main__: train step 5739: loss: 0.9375, policy_loss: 1.4052, value_loss: 0.8599
2024-07-11 16:14:24,069 [INFO    ] __main__: train step 5740: loss: 0.9376, policy_loss: 1.4051, value_loss: 0.8599
2024-07-11 16:14:24,293 [INFO    ] __main__: train step 5741: loss: 0.9377, policy_loss: 1.4050, value_loss: 0.8598
2024-07-11 16:14:24,487 [INFO    ] __main__: train step 5742: loss: 0.9377, policy_loss: 1.4049, value_loss: 0.8598
2024-07-11 16:14:24,682 [INFO    ] __main__: train step 5743: loss: 0.9378, policy_loss: 1.4049, value_loss: 0.8598
2024-07-11 16:14:24,873 [INFO    ] __main__: train step 5744: loss: 0.9379, policy_loss: 1.4048, value_loss: 0.8597
2024-07-11 16:14:25,077 [INFO    ] __main__: train step 5745: loss: 0.9380, policy_loss: 1.4047, value_loss: 0.8597
2024-07-11 16:14:26,518 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:14:26,888 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:14:26,947 [INFO    ] __main__: train step 5746: loss: 0.9380, policy_loss: 1.4046, value_loss: 0.8596
2024-07-11 16:14:27,119 [INFO    ] __main__: train step 5747: loss: 0.9381, policy_loss: 1.4045, value_loss: 0.8596
2024-07-11 16:14:27,324 [INFO    ] __main__: train step 5748: loss: 0.9382, policy_loss: 1.4044, value_loss: 0.8596
2024-07-11 16:14:27,540 [INFO    ] __main__: train step 5749: loss: 0.9383, policy_loss: 1.4043, value_loss: 0.8595
2024-07-11 16:14:27,737 [INFO    ] __main__: train step 5750: loss: 0.9383, policy_loss: 1.4042, value_loss: 0.8595
2024-07-11 16:14:27,948 [INFO    ] __main__: train step 5751: loss: 0.9384, policy_loss: 1.4041, value_loss: 0.8594
2024-07-11 16:14:28,144 [INFO    ] __main__: train step 5752: loss: 0.9385, policy_loss: 1.4040, value_loss: 0.8594
2024-07-11 16:14:28,351 [INFO    ] __main__: train step 5753: loss: 0.9386, policy_loss: 1.4040, value_loss: 0.8594
2024-07-11 16:14:28,558 [INFO    ] __main__: train step 5754: loss: 0.9386, policy_loss: 1.4039, value_loss: 0.8593
2024-07-11 16:14:28,764 [INFO    ] __main__: train step 5755: loss: 0.9387, policy_loss: 1.4038, value_loss: 0.8593
2024-07-11 16:14:28,968 [INFO    ] __main__: train step 5756: loss: 0.9388, policy_loss: 1.4037, value_loss: 0.8593
2024-07-11 16:14:29,169 [INFO    ] __main__: train step 5757: loss: 0.9389, policy_loss: 1.4036, value_loss: 0.8592
2024-07-11 16:14:30,233 [INFO    ] __main__: train step 5758: loss: 0.9390, policy_loss: 1.4035, value_loss: 0.8592
2024-07-11 16:14:30,431 [INFO    ] __main__: train step 5759: loss: 0.9390, policy_loss: 1.4034, value_loss: 0.8592
2024-07-11 16:14:30,633 [INFO    ] __main__: train step 5760: loss: 0.9391, policy_loss: 1.4033, value_loss: 0.8591
2024-07-11 16:14:30,839 [INFO    ] __main__: train step 5761: loss: 0.9392, policy_loss: 1.4033, value_loss: 0.8591
2024-07-11 16:14:31,041 [INFO    ] __main__: train step 5762: loss: 0.9393, policy_loss: 1.4032, value_loss: 0.8590
2024-07-11 16:14:32,487 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:14:32,890 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:14:32,952 [INFO    ] __main__: train step 5763: loss: 0.9393, policy_loss: 1.4031, value_loss: 0.8590
2024-07-11 16:14:33,113 [INFO    ] __main__: train step 5764: loss: 0.9394, policy_loss: 1.4030, value_loss: 0.8590
2024-07-11 16:14:33,337 [INFO    ] __main__: train step 5765: loss: 0.9395, policy_loss: 1.4029, value_loss: 0.8589
2024-07-11 16:14:33,533 [INFO    ] __main__: train step 5766: loss: 0.9396, policy_loss: 1.4028, value_loss: 0.8589
2024-07-11 16:14:33,736 [INFO    ] __main__: train step 5767: loss: 0.9396, policy_loss: 1.4027, value_loss: 0.8589
2024-07-11 16:14:33,944 [INFO    ] __main__: train step 5768: loss: 0.9397, policy_loss: 1.4026, value_loss: 0.8588
2024-07-11 16:14:34,162 [INFO    ] __main__: train step 5769: loss: 0.9398, policy_loss: 1.4026, value_loss: 0.8588
2024-07-11 16:14:34,351 [INFO    ] __main__: train step 5770: loss: 0.9399, policy_loss: 1.4025, value_loss: 0.8587
2024-07-11 16:14:34,569 [INFO    ] __main__: train step 5771: loss: 0.9400, policy_loss: 1.4024, value_loss: 0.8587
2024-07-11 16:14:34,771 [INFO    ] __main__: train step 5772: loss: 0.9400, policy_loss: 1.4023, value_loss: 0.8587
2024-07-11 16:14:34,978 [INFO    ] __main__: train step 5773: loss: 0.9401, policy_loss: 1.4022, value_loss: 0.8586
2024-07-11 16:14:35,189 [INFO    ] __main__: train step 5774: loss: 0.9402, policy_loss: 1.4021, value_loss: 0.8586
2024-07-11 16:14:35,394 [INFO    ] __main__: train step 5775: loss: 0.9403, policy_loss: 1.4020, value_loss: 0.8585
2024-07-11 16:14:35,611 [INFO    ] __main__: train step 5776: loss: 0.9403, policy_loss: 1.4019, value_loss: 0.8585
2024-07-11 16:14:35,804 [INFO    ] __main__: train step 5777: loss: 0.9404, policy_loss: 1.4019, value_loss: 0.8584
2024-07-11 16:14:36,006 [INFO    ] __main__: train step 5778: loss: 0.9405, policy_loss: 1.4018, value_loss: 0.8584
2024-07-11 16:14:36,207 [INFO    ] __main__: train step 5779: loss: 0.9406, policy_loss: 1.4017, value_loss: 0.8584
2024-07-11 16:14:37,656 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:14:38,022 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:14:38,081 [INFO    ] __main__: train step 5780: loss: 0.9406, policy_loss: 1.4016, value_loss: 0.8583
2024-07-11 16:14:38,251 [INFO    ] __main__: train step 5781: loss: 0.9407, policy_loss: 1.4015, value_loss: 0.8583
2024-07-11 16:14:38,451 [INFO    ] __main__: train step 5782: loss: 0.9408, policy_loss: 1.4014, value_loss: 0.8583
2024-07-11 16:14:38,675 [INFO    ] __main__: train step 5783: loss: 0.9409, policy_loss: 1.4013, value_loss: 0.8582
2024-07-11 16:14:38,871 [INFO    ] __main__: train step 5784: loss: 0.9409, policy_loss: 1.4012, value_loss: 0.8582
2024-07-11 16:14:39,072 [INFO    ] __main__: train step 5785: loss: 0.9410, policy_loss: 1.4012, value_loss: 0.8581
2024-07-11 16:14:39,279 [INFO    ] __main__: train step 5786: loss: 0.9411, policy_loss: 1.4011, value_loss: 0.8581
2024-07-11 16:14:39,468 [INFO    ] __main__: train step 5787: loss: 0.9412, policy_loss: 1.4010, value_loss: 0.8581
2024-07-11 16:14:39,671 [INFO    ] __main__: train step 5788: loss: 0.9412, policy_loss: 1.4009, value_loss: 0.8580
2024-07-11 16:14:39,869 [INFO    ] __main__: train step 5789: loss: 0.9413, policy_loss: 1.4008, value_loss: 0.8580
2024-07-11 16:14:40,061 [INFO    ] __main__: train step 5790: loss: 0.9414, policy_loss: 1.4007, value_loss: 0.8580
2024-07-11 16:14:40,270 [INFO    ] __main__: train step 5791: loss: 0.9415, policy_loss: 1.4006, value_loss: 0.8579
2024-07-11 16:14:40,463 [INFO    ] __main__: train step 5792: loss: 0.9416, policy_loss: 1.4005, value_loss: 0.8579
2024-07-11 16:14:40,665 [INFO    ] __main__: train step 5793: loss: 0.9416, policy_loss: 1.4005, value_loss: 0.8578
2024-07-11 16:14:40,886 [INFO    ] __main__: train step 5794: loss: 0.9417, policy_loss: 1.4004, value_loss: 0.8578
2024-07-11 16:14:41,116 [INFO    ] __main__: train step 5795: loss: 0.9418, policy_loss: 1.4003, value_loss: 0.8578
2024-07-11 16:14:41,314 [INFO    ] __main__: train step 5796: loss: 0.9419, policy_loss: 1.4002, value_loss: 0.8577
2024-07-11 16:14:42,767 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:14:43,113 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:14:43,168 [INFO    ] __main__: train step 5797: loss: 0.9419, policy_loss: 1.4001, value_loss: 0.8577
2024-07-11 16:14:43,358 [INFO    ] __main__: train step 5798: loss: 0.9420, policy_loss: 1.4000, value_loss: 0.8576
2024-07-11 16:14:43,555 [INFO    ] __main__: train step 5799: loss: 0.9421, policy_loss: 1.3999, value_loss: 0.8576
2024-07-11 16:14:43,761 [INFO    ] __main__: train step 5800: loss: 0.9422, policy_loss: 1.3999, value_loss: 0.8576
2024-07-11 16:14:43,972 [INFO    ] __main__: train step 5801: loss: 0.9422, policy_loss: 1.3998, value_loss: 0.8575
2024-07-11 16:14:44,217 [INFO    ] __main__: train step 5802: loss: 0.9423, policy_loss: 1.3997, value_loss: 0.8575
2024-07-11 16:14:44,413 [INFO    ] __main__: train step 5803: loss: 0.9424, policy_loss: 1.3996, value_loss: 0.8574
2024-07-11 16:14:44,656 [INFO    ] __main__: train step 5804: loss: 0.9425, policy_loss: 1.3995, value_loss: 0.8574
2024-07-11 16:14:44,859 [INFO    ] __main__: train step 5805: loss: 0.9425, policy_loss: 1.3994, value_loss: 0.8574
2024-07-11 16:14:45,053 [INFO    ] __main__: train step 5806: loss: 0.9426, policy_loss: 1.3993, value_loss: 0.8573
2024-07-11 16:14:45,249 [INFO    ] __main__: train step 5807: loss: 0.9427, policy_loss: 1.3992, value_loss: 0.8573
2024-07-11 16:14:45,453 [INFO    ] __main__: train step 5808: loss: 0.9428, policy_loss: 1.3992, value_loss: 0.8573
2024-07-11 16:14:45,647 [INFO    ] __main__: train step 5809: loss: 0.9428, policy_loss: 1.3991, value_loss: 0.8572
2024-07-11 16:14:45,854 [INFO    ] __main__: train step 5810: loss: 0.9429, policy_loss: 1.3990, value_loss: 0.8572
2024-07-11 16:14:46,044 [INFO    ] __main__: train step 5811: loss: 0.9430, policy_loss: 1.3989, value_loss: 0.8571
2024-07-11 16:14:46,246 [INFO    ] __main__: train step 5812: loss: 0.9431, policy_loss: 1.3988, value_loss: 0.8571
2024-07-11 16:14:46,440 [INFO    ] __main__: train step 5813: loss: 0.9432, policy_loss: 1.3987, value_loss: 0.8571
2024-07-11 16:14:47,862 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:14:48,221 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:14:48,276 [INFO    ] __main__: train step 5814: loss: 0.9432, policy_loss: 1.3986, value_loss: 0.8570
2024-07-11 16:14:48,441 [INFO    ] __main__: train step 5815: loss: 0.9433, policy_loss: 1.3985, value_loss: 0.8570
2024-07-11 16:14:48,644 [INFO    ] __main__: train step 5816: loss: 0.9434, policy_loss: 1.3985, value_loss: 0.8570
2024-07-11 16:14:48,841 [INFO    ] __main__: train step 5817: loss: 0.9435, policy_loss: 1.3984, value_loss: 0.8569
2024-07-11 16:14:49,041 [INFO    ] __main__: train step 5818: loss: 0.9435, policy_loss: 1.3983, value_loss: 0.8569
2024-07-11 16:14:49,245 [INFO    ] __main__: train step 5819: loss: 0.9436, policy_loss: 1.3982, value_loss: 0.8568
2024-07-11 16:14:49,438 [INFO    ] __main__: train step 5820: loss: 0.9437, policy_loss: 1.3981, value_loss: 0.8568
2024-07-11 16:14:49,639 [INFO    ] __main__: train step 5821: loss: 0.9438, policy_loss: 1.3980, value_loss: 0.8568
2024-07-11 16:14:49,857 [INFO    ] __main__: train step 5822: loss: 0.9438, policy_loss: 1.3979, value_loss: 0.8567
2024-07-11 16:14:50,080 [INFO    ] __main__: train step 5823: loss: 0.9439, policy_loss: 1.3979, value_loss: 0.8567
2024-07-11 16:14:50,313 [INFO    ] __main__: train step 5824: loss: 0.9440, policy_loss: 1.3978, value_loss: 0.8566
2024-07-11 16:14:50,517 [INFO    ] __main__: train step 5825: loss: 0.9441, policy_loss: 1.3977, value_loss: 0.8566
2024-07-11 16:14:50,718 [INFO    ] __main__: train step 5826: loss: 0.9441, policy_loss: 1.3976, value_loss: 0.8566
2024-07-11 16:14:50,917 [INFO    ] __main__: train step 5827: loss: 0.9442, policy_loss: 1.3975, value_loss: 0.8565
2024-07-11 16:14:51,121 [INFO    ] __main__: train step 5828: loss: 0.9443, policy_loss: 1.3974, value_loss: 0.8565
2024-07-11 16:14:51,319 [INFO    ] __main__: train step 5829: loss: 0.9444, policy_loss: 1.3973, value_loss: 0.8565
2024-07-11 16:14:51,520 [INFO    ] __main__: train step 5830: loss: 0.9444, policy_loss: 1.3972, value_loss: 0.8564
2024-07-11 16:14:53,795 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:14:54,170 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:14:54,224 [INFO    ] __main__: train step 5831: loss: 0.9445, policy_loss: 1.3971, value_loss: 0.8564
2024-07-11 16:14:54,389 [INFO    ] __main__: train step 5832: loss: 0.9446, policy_loss: 1.3971, value_loss: 0.8563
2024-07-11 16:14:54,592 [INFO    ] __main__: train step 5833: loss: 0.9447, policy_loss: 1.3970, value_loss: 0.8563
2024-07-11 16:14:54,802 [INFO    ] __main__: train step 5834: loss: 0.9447, policy_loss: 1.3969, value_loss: 0.8563
2024-07-11 16:14:55,009 [INFO    ] __main__: train step 5835: loss: 0.9448, policy_loss: 1.3968, value_loss: 0.8562
2024-07-11 16:14:55,215 [INFO    ] __main__: train step 5836: loss: 0.9449, policy_loss: 1.3967, value_loss: 0.8562
2024-07-11 16:14:55,419 [INFO    ] __main__: train step 5837: loss: 0.9450, policy_loss: 1.3966, value_loss: 0.8562
2024-07-11 16:14:55,629 [INFO    ] __main__: train step 5838: loss: 0.9450, policy_loss: 1.3965, value_loss: 0.8561
2024-07-11 16:14:55,845 [INFO    ] __main__: train step 5839: loss: 0.9451, policy_loss: 1.3965, value_loss: 0.8561
2024-07-11 16:14:56,045 [INFO    ] __main__: train step 5840: loss: 0.9452, policy_loss: 1.3964, value_loss: 0.8560
2024-07-11 16:14:56,234 [INFO    ] __main__: train step 5841: loss: 0.9453, policy_loss: 1.3963, value_loss: 0.8560
2024-07-11 16:14:56,454 [INFO    ] __main__: train step 5842: loss: 0.9453, policy_loss: 1.3962, value_loss: 0.8560
2024-07-11 16:14:56,658 [INFO    ] __main__: train step 5843: loss: 0.9454, policy_loss: 1.3961, value_loss: 0.8559
2024-07-11 16:14:56,891 [INFO    ] __main__: train step 5844: loss: 0.9455, policy_loss: 1.3960, value_loss: 0.8559
2024-07-11 16:14:57,101 [INFO    ] __main__: train step 5845: loss: 0.9456, policy_loss: 1.3959, value_loss: 0.8558
2024-07-11 16:14:57,317 [INFO    ] __main__: train step 5846: loss: 0.9456, policy_loss: 1.3959, value_loss: 0.8558
2024-07-11 16:14:57,503 [INFO    ] __main__: train step 5847: loss: 0.9457, policy_loss: 1.3958, value_loss: 0.8558
2024-07-11 16:14:58,950 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:14:59,369 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:14:59,434 [INFO    ] __main__: train step 5848: loss: 0.9458, policy_loss: 1.3957, value_loss: 0.8557
2024-07-11 16:14:59,615 [INFO    ] __main__: train step 5849: loss: 0.9459, policy_loss: 1.3956, value_loss: 0.8557
2024-07-11 16:14:59,839 [INFO    ] __main__: train step 5850: loss: 0.9459, policy_loss: 1.3955, value_loss: 0.8557
2024-07-11 16:15:00,056 [INFO    ] __main__: train step 5851: loss: 0.9460, policy_loss: 1.3954, value_loss: 0.8556
2024-07-11 16:15:00,246 [INFO    ] __main__: train step 5852: loss: 0.9461, policy_loss: 1.3953, value_loss: 0.8556
2024-07-11 16:15:00,455 [INFO    ] __main__: train step 5853: loss: 0.9462, policy_loss: 1.3953, value_loss: 0.8555
2024-07-11 16:15:00,664 [INFO    ] __main__: train step 5854: loss: 0.9462, policy_loss: 1.3952, value_loss: 0.8555
2024-07-11 16:15:00,864 [INFO    ] __main__: train step 5855: loss: 0.9463, policy_loss: 1.3951, value_loss: 0.8555
2024-07-11 16:15:01,077 [INFO    ] __main__: train step 5856: loss: 0.9464, policy_loss: 1.3950, value_loss: 0.8554
2024-07-11 16:15:01,273 [INFO    ] __main__: train step 5857: loss: 0.9465, policy_loss: 1.3949, value_loss: 0.8554
2024-07-11 16:15:01,472 [INFO    ] __main__: train step 5858: loss: 0.9465, policy_loss: 1.3948, value_loss: 0.8553
2024-07-11 16:15:01,683 [INFO    ] __main__: train step 5859: loss: 0.9466, policy_loss: 1.3947, value_loss: 0.8553
2024-07-11 16:15:01,877 [INFO    ] __main__: train step 5860: loss: 0.9467, policy_loss: 1.3946, value_loss: 0.8553
2024-07-11 16:15:02,084 [INFO    ] __main__: train step 5861: loss: 0.9468, policy_loss: 1.3946, value_loss: 0.8552
2024-07-11 16:15:02,280 [INFO    ] __main__: train step 5862: loss: 0.9468, policy_loss: 1.3945, value_loss: 0.8552
2024-07-11 16:15:02,508 [INFO    ] __main__: train step 5863: loss: 0.9469, policy_loss: 1.3944, value_loss: 0.8552
2024-07-11 16:15:02,695 [INFO    ] __main__: train step 5864: loss: 0.9470, policy_loss: 1.3943, value_loss: 0.8551
2024-07-11 16:15:04,149 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:15:04,505 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:15:04,560 [INFO    ] __main__: train step 5865: loss: 0.9471, policy_loss: 1.3942, value_loss: 0.8551
2024-07-11 16:15:04,731 [INFO    ] __main__: train step 5866: loss: 0.9471, policy_loss: 1.3941, value_loss: 0.8550
2024-07-11 16:15:04,935 [INFO    ] __main__: train step 5867: loss: 0.9472, policy_loss: 1.3940, value_loss: 0.8550
2024-07-11 16:15:05,146 [INFO    ] __main__: train step 5868: loss: 0.9473, policy_loss: 1.3940, value_loss: 0.8550
2024-07-11 16:15:05,345 [INFO    ] __main__: train step 5869: loss: 0.9474, policy_loss: 1.3939, value_loss: 0.8549
2024-07-11 16:15:05,555 [INFO    ] __main__: train step 5870: loss: 0.9474, policy_loss: 1.3938, value_loss: 0.8549
2024-07-11 16:15:05,751 [INFO    ] __main__: train step 5871: loss: 0.9475, policy_loss: 1.3937, value_loss: 0.8548
2024-07-11 16:15:05,958 [INFO    ] __main__: train step 5872: loss: 0.9476, policy_loss: 1.3936, value_loss: 0.8548
2024-07-11 16:15:06,159 [INFO    ] __main__: train step 5873: loss: 0.9477, policy_loss: 1.3935, value_loss: 0.8548
2024-07-11 16:15:06,368 [INFO    ] __main__: train step 5874: loss: 0.9477, policy_loss: 1.3934, value_loss: 0.8547
2024-07-11 16:15:06,562 [INFO    ] __main__: train step 5875: loss: 0.9478, policy_loss: 1.3934, value_loss: 0.8547
2024-07-11 16:15:06,749 [INFO    ] __main__: train step 5876: loss: 0.9479, policy_loss: 1.3933, value_loss: 0.8546
2024-07-11 16:15:06,956 [INFO    ] __main__: train step 5877: loss: 0.9480, policy_loss: 1.3932, value_loss: 0.8546
2024-07-11 16:15:07,154 [INFO    ] __main__: train step 5878: loss: 0.9480, policy_loss: 1.3931, value_loss: 0.8546
2024-07-11 16:15:07,357 [INFO    ] __main__: train step 5879: loss: 0.9481, policy_loss: 1.3930, value_loss: 0.8545
2024-07-11 16:15:07,556 [INFO    ] __main__: train step 5880: loss: 0.9482, policy_loss: 1.3929, value_loss: 0.8545
2024-07-11 16:15:07,777 [INFO    ] __main__: train step 5881: loss: 0.9483, policy_loss: 1.3929, value_loss: 0.8545
2024-07-11 16:15:09,235 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:15:09,611 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:15:09,676 [INFO    ] __main__: train step 5882: loss: 0.9483, policy_loss: 1.3928, value_loss: 0.8544
2024-07-11 16:15:09,841 [INFO    ] __main__: train step 5883: loss: 0.9484, policy_loss: 1.3927, value_loss: 0.8544
2024-07-11 16:15:10,046 [INFO    ] __main__: train step 5884: loss: 0.9485, policy_loss: 1.3926, value_loss: 0.8543
2024-07-11 16:15:10,244 [INFO    ] __main__: train step 5885: loss: 0.9486, policy_loss: 1.3925, value_loss: 0.8543
2024-07-11 16:15:10,441 [INFO    ] __main__: train step 5886: loss: 0.9486, policy_loss: 1.3924, value_loss: 0.8543
2024-07-11 16:15:10,638 [INFO    ] __main__: train step 5887: loss: 0.9487, policy_loss: 1.3923, value_loss: 0.8542
2024-07-11 16:15:10,847 [INFO    ] __main__: train step 5888: loss: 0.9488, policy_loss: 1.3923, value_loss: 0.8542
2024-07-11 16:15:11,051 [INFO    ] __main__: train step 5889: loss: 0.9489, policy_loss: 1.3922, value_loss: 0.8542
2024-07-11 16:15:11,258 [INFO    ] __main__: train step 5890: loss: 0.9489, policy_loss: 1.3921, value_loss: 0.8541
2024-07-11 16:15:11,460 [INFO    ] __main__: train step 5891: loss: 0.9490, policy_loss: 1.3920, value_loss: 0.8541
2024-07-11 16:15:11,663 [INFO    ] __main__: train step 5892: loss: 0.9491, policy_loss: 1.3919, value_loss: 0.8540
2024-07-11 16:15:11,873 [INFO    ] __main__: train step 5893: loss: 0.9492, policy_loss: 1.3918, value_loss: 0.8540
2024-07-11 16:15:12,075 [INFO    ] __main__: train step 5894: loss: 0.9492, policy_loss: 1.3917, value_loss: 0.8540
2024-07-11 16:15:12,305 [INFO    ] __main__: train step 5895: loss: 0.9493, policy_loss: 1.3917, value_loss: 0.8539
2024-07-11 16:15:12,501 [INFO    ] __main__: train step 5896: loss: 0.9494, policy_loss: 1.3916, value_loss: 0.8539
2024-07-11 16:15:12,708 [INFO    ] __main__: train step 5897: loss: 0.9494, policy_loss: 1.3915, value_loss: 0.8538
2024-07-11 16:15:12,904 [INFO    ] __main__: train step 5898: loss: 0.9495, policy_loss: 1.3914, value_loss: 0.8538
2024-07-11 16:15:14,359 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:15:14,623 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:15:14,677 [INFO    ] __main__: train step 5899: loss: 0.9496, policy_loss: 1.3913, value_loss: 0.8538
2024-07-11 16:15:14,851 [INFO    ] __main__: train step 5900: loss: 0.9497, policy_loss: 1.3912, value_loss: 0.8537
2024-07-11 16:15:15,051 [INFO    ] __main__: train step 5901: loss: 0.9497, policy_loss: 1.3912, value_loss: 0.8537
2024-07-11 16:15:15,262 [INFO    ] __main__: train step 5902: loss: 0.9498, policy_loss: 1.3911, value_loss: 0.8536
2024-07-11 16:15:15,475 [INFO    ] __main__: train step 5903: loss: 0.9499, policy_loss: 1.3910, value_loss: 0.8536
2024-07-11 16:15:16,512 [INFO    ] __main__: train step 5904: loss: 0.9500, policy_loss: 1.3909, value_loss: 0.8536
2024-07-11 16:15:16,734 [INFO    ] __main__: train step 5905: loss: 0.9500, policy_loss: 1.3908, value_loss: 0.8535
2024-07-11 16:15:16,946 [INFO    ] __main__: train step 5906: loss: 0.9501, policy_loss: 1.3907, value_loss: 0.8535
2024-07-11 16:15:17,140 [INFO    ] __main__: train step 5907: loss: 0.9502, policy_loss: 1.3906, value_loss: 0.8535
2024-07-11 16:15:17,345 [INFO    ] __main__: train step 5908: loss: 0.9503, policy_loss: 1.3906, value_loss: 0.8534
2024-07-11 16:15:17,576 [INFO    ] __main__: train step 5909: loss: 0.9503, policy_loss: 1.3905, value_loss: 0.8534
2024-07-11 16:15:17,805 [INFO    ] __main__: train step 5910: loss: 0.9504, policy_loss: 1.3904, value_loss: 0.8533
2024-07-11 16:15:18,026 [INFO    ] __main__: train step 5911: loss: 0.9505, policy_loss: 1.3903, value_loss: 0.8533
2024-07-11 16:15:18,255 [INFO    ] __main__: train step 5912: loss: 0.9506, policy_loss: 1.3902, value_loss: 0.8533
2024-07-11 16:15:18,467 [INFO    ] __main__: train step 5913: loss: 0.9506, policy_loss: 1.3901, value_loss: 0.8532
2024-07-11 16:15:18,656 [INFO    ] __main__: train step 5914: loss: 0.9507, policy_loss: 1.3900, value_loss: 0.8532
2024-07-11 16:15:18,863 [INFO    ] __main__: train step 5915: loss: 0.9508, policy_loss: 1.3900, value_loss: 0.8532
2024-07-11 16:15:20,302 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:15:20,710 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:15:20,769 [INFO    ] __main__: train step 5916: loss: 0.9509, policy_loss: 1.3899, value_loss: 0.8531
2024-07-11 16:15:20,943 [INFO    ] __main__: train step 5917: loss: 0.9509, policy_loss: 1.3898, value_loss: 0.8531
2024-07-11 16:15:21,147 [INFO    ] __main__: train step 5918: loss: 0.9510, policy_loss: 1.3897, value_loss: 0.8530
2024-07-11 16:15:21,360 [INFO    ] __main__: train step 5919: loss: 0.9511, policy_loss: 1.3896, value_loss: 0.8530
2024-07-11 16:15:21,563 [INFO    ] __main__: train step 5920: loss: 0.9512, policy_loss: 1.3895, value_loss: 0.8530
2024-07-11 16:15:21,757 [INFO    ] __main__: train step 5921: loss: 0.9512, policy_loss: 1.3894, value_loss: 0.8529
2024-07-11 16:15:21,956 [INFO    ] __main__: train step 5922: loss: 0.9513, policy_loss: 1.3894, value_loss: 0.8529
2024-07-11 16:15:22,161 [INFO    ] __main__: train step 5923: loss: 0.9514, policy_loss: 1.3893, value_loss: 0.8528
2024-07-11 16:15:22,365 [INFO    ] __main__: train step 5924: loss: 0.9514, policy_loss: 1.3892, value_loss: 0.8528
2024-07-11 16:15:22,558 [INFO    ] __main__: train step 5925: loss: 0.9515, policy_loss: 1.3891, value_loss: 0.8528
2024-07-11 16:15:22,771 [INFO    ] __main__: train step 5926: loss: 0.9516, policy_loss: 1.3890, value_loss: 0.8527
2024-07-11 16:15:23,013 [INFO    ] __main__: train step 5927: loss: 0.9517, policy_loss: 1.3889, value_loss: 0.8527
2024-07-11 16:15:23,262 [INFO    ] __main__: train step 5928: loss: 0.9517, policy_loss: 1.3888, value_loss: 0.8527
2024-07-11 16:15:23,489 [INFO    ] __main__: train step 5929: loss: 0.9518, policy_loss: 1.3888, value_loss: 0.8526
2024-07-11 16:15:23,696 [INFO    ] __main__: train step 5930: loss: 0.9519, policy_loss: 1.3887, value_loss: 0.8526
2024-07-11 16:15:23,901 [INFO    ] __main__: train step 5931: loss: 0.9520, policy_loss: 1.3886, value_loss: 0.8525
2024-07-11 16:15:24,100 [INFO    ] __main__: train step 5932: loss: 0.9520, policy_loss: 1.3885, value_loss: 0.8525
2024-07-11 16:15:25,550 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:15:25,955 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:15:26,023 [INFO    ] __main__: train step 5933: loss: 0.9521, policy_loss: 1.3884, value_loss: 0.8525
2024-07-11 16:15:26,212 [INFO    ] __main__: train step 5934: loss: 0.9522, policy_loss: 1.3883, value_loss: 0.8524
2024-07-11 16:15:26,418 [INFO    ] __main__: train step 5935: loss: 0.9522, policy_loss: 1.3882, value_loss: 0.8524
2024-07-11 16:15:26,617 [INFO    ] __main__: train step 5936: loss: 0.9523, policy_loss: 1.3882, value_loss: 0.8524
2024-07-11 16:15:26,817 [INFO    ] __main__: train step 5937: loss: 0.9524, policy_loss: 1.3881, value_loss: 0.8523
2024-07-11 16:15:27,008 [INFO    ] __main__: train step 5938: loss: 0.9525, policy_loss: 1.3880, value_loss: 0.8523
2024-07-11 16:15:27,208 [INFO    ] __main__: train step 5939: loss: 0.9525, policy_loss: 1.3879, value_loss: 0.8522
2024-07-11 16:15:27,436 [INFO    ] __main__: train step 5940: loss: 0.9526, policy_loss: 1.3878, value_loss: 0.8522
2024-07-11 16:15:27,632 [INFO    ] __main__: train step 5941: loss: 0.9527, policy_loss: 1.3877, value_loss: 0.8522
2024-07-11 16:15:27,830 [INFO    ] __main__: train step 5942: loss: 0.9528, policy_loss: 1.3877, value_loss: 0.8521
2024-07-11 16:15:28,039 [INFO    ] __main__: train step 5943: loss: 0.9528, policy_loss: 1.3876, value_loss: 0.8521
2024-07-11 16:15:28,248 [INFO    ] __main__: train step 5944: loss: 0.9529, policy_loss: 1.3875, value_loss: 0.8520
2024-07-11 16:15:28,453 [INFO    ] __main__: train step 5945: loss: 0.9530, policy_loss: 1.3874, value_loss: 0.8520
2024-07-11 16:15:28,653 [INFO    ] __main__: train step 5946: loss: 0.9530, policy_loss: 1.3873, value_loss: 0.8520
2024-07-11 16:15:28,857 [INFO    ] __main__: train step 5947: loss: 0.9531, policy_loss: 1.3872, value_loss: 0.8519
2024-07-11 16:15:29,048 [INFO    ] __main__: train step 5948: loss: 0.9532, policy_loss: 1.3871, value_loss: 0.8519
2024-07-11 16:15:29,264 [INFO    ] __main__: train step 5949: loss: 0.9533, policy_loss: 1.3871, value_loss: 0.8519
2024-07-11 16:15:30,701 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:15:31,059 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:15:31,118 [INFO    ] __main__: train step 5950: loss: 0.9533, policy_loss: 1.3870, value_loss: 0.8518
2024-07-11 16:15:31,292 [INFO    ] __main__: train step 5951: loss: 0.9534, policy_loss: 1.3869, value_loss: 0.8518
2024-07-11 16:15:31,491 [INFO    ] __main__: train step 5952: loss: 0.9535, policy_loss: 1.3868, value_loss: 0.8517
2024-07-11 16:15:31,699 [INFO    ] __main__: train step 5953: loss: 0.9536, policy_loss: 1.3867, value_loss: 0.8517
2024-07-11 16:15:31,918 [INFO    ] __main__: train step 5954: loss: 0.9536, policy_loss: 1.3866, value_loss: 0.8517
2024-07-11 16:15:32,156 [INFO    ] __main__: train step 5955: loss: 0.9537, policy_loss: 1.3866, value_loss: 0.8516
2024-07-11 16:15:32,352 [INFO    ] __main__: train step 5956: loss: 0.9538, policy_loss: 1.3865, value_loss: 0.8516
2024-07-11 16:15:32,570 [INFO    ] __main__: train step 5957: loss: 0.9538, policy_loss: 1.3864, value_loss: 0.8515
2024-07-11 16:15:32,762 [INFO    ] __main__: train step 5958: loss: 0.9539, policy_loss: 1.3863, value_loss: 0.8515
2024-07-11 16:15:32,968 [INFO    ] __main__: train step 5959: loss: 0.9540, policy_loss: 1.3862, value_loss: 0.8515
2024-07-11 16:15:33,166 [INFO    ] __main__: train step 5960: loss: 0.9541, policy_loss: 1.3861, value_loss: 0.8514
2024-07-11 16:15:33,362 [INFO    ] __main__: train step 5961: loss: 0.9541, policy_loss: 1.3860, value_loss: 0.8514
2024-07-11 16:15:33,585 [INFO    ] __main__: train step 5962: loss: 0.9542, policy_loss: 1.3860, value_loss: 0.8514
2024-07-11 16:15:33,810 [INFO    ] __main__: train step 5963: loss: 0.9543, policy_loss: 1.3859, value_loss: 0.8513
2024-07-11 16:15:34,029 [INFO    ] __main__: train step 5964: loss: 0.9544, policy_loss: 1.3858, value_loss: 0.8513
2024-07-11 16:15:34,257 [INFO    ] __main__: train step 5965: loss: 0.9544, policy_loss: 1.3857, value_loss: 0.8512
2024-07-11 16:15:34,460 [INFO    ] __main__: train step 5966: loss: 0.9545, policy_loss: 1.3856, value_loss: 0.8512
2024-07-11 16:15:35,894 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:15:36,245 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:15:36,301 [INFO    ] __main__: train step 5967: loss: 0.9546, policy_loss: 1.3855, value_loss: 0.8512
2024-07-11 16:15:36,473 [INFO    ] __main__: train step 5968: loss: 0.9546, policy_loss: 1.3855, value_loss: 0.8511
2024-07-11 16:15:36,683 [INFO    ] __main__: train step 5969: loss: 0.9547, policy_loss: 1.3854, value_loss: 0.8511
2024-07-11 16:15:36,897 [INFO    ] __main__: train step 5970: loss: 0.9548, policy_loss: 1.3853, value_loss: 0.8510
2024-07-11 16:15:37,110 [INFO    ] __main__: train step 5971: loss: 0.9549, policy_loss: 1.3852, value_loss: 0.8510
2024-07-11 16:15:37,316 [INFO    ] __main__: train step 5972: loss: 0.9549, policy_loss: 1.3851, value_loss: 0.8510
2024-07-11 16:15:37,523 [INFO    ] __main__: train step 5973: loss: 0.9550, policy_loss: 1.3850, value_loss: 0.8509
2024-07-11 16:15:37,742 [INFO    ] __main__: train step 5974: loss: 0.9551, policy_loss: 1.3849, value_loss: 0.8509
2024-07-11 16:15:37,946 [INFO    ] __main__: train step 5975: loss: 0.9551, policy_loss: 1.3849, value_loss: 0.8509
2024-07-11 16:15:38,169 [INFO    ] __main__: train step 5976: loss: 0.9552, policy_loss: 1.3848, value_loss: 0.8508
2024-07-11 16:15:38,371 [INFO    ] __main__: train step 5977: loss: 0.9553, policy_loss: 1.3847, value_loss: 0.8508
2024-07-11 16:15:39,461 [INFO    ] __main__: train step 5978: loss: 0.9554, policy_loss: 1.3846, value_loss: 0.8507
2024-07-11 16:15:39,660 [INFO    ] __main__: train step 5979: loss: 0.9554, policy_loss: 1.3845, value_loss: 0.8507
2024-07-11 16:15:39,873 [INFO    ] __main__: train step 5980: loss: 0.9555, policy_loss: 1.3844, value_loss: 0.8507
2024-07-11 16:15:40,074 [INFO    ] __main__: train step 5981: loss: 0.9556, policy_loss: 1.3844, value_loss: 0.8506
2024-07-11 16:15:40,287 [INFO    ] __main__: train step 5982: loss: 0.9556, policy_loss: 1.3843, value_loss: 0.8506
2024-07-11 16:15:40,493 [INFO    ] __main__: train step 5983: loss: 0.9557, policy_loss: 1.3842, value_loss: 0.8505
2024-07-11 16:15:41,949 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:15:42,412 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:15:42,466 [INFO    ] __main__: train step 5984: loss: 0.9558, policy_loss: 1.3841, value_loss: 0.8505
2024-07-11 16:15:42,639 [INFO    ] __main__: train step 5985: loss: 0.9559, policy_loss: 1.3840, value_loss: 0.8505
2024-07-11 16:15:42,841 [INFO    ] __main__: train step 5986: loss: 0.9559, policy_loss: 1.3839, value_loss: 0.8504
2024-07-11 16:15:43,033 [INFO    ] __main__: train step 5987: loss: 0.9560, policy_loss: 1.3838, value_loss: 0.8504
2024-07-11 16:15:43,240 [INFO    ] __main__: train step 5988: loss: 0.9561, policy_loss: 1.3838, value_loss: 0.8504
2024-07-11 16:15:43,431 [INFO    ] __main__: train step 5989: loss: 0.9561, policy_loss: 1.3837, value_loss: 0.8503
2024-07-11 16:15:43,627 [INFO    ] __main__: train step 5990: loss: 0.9562, policy_loss: 1.3836, value_loss: 0.8503
2024-07-11 16:15:43,835 [INFO    ] __main__: train step 5991: loss: 0.9563, policy_loss: 1.3835, value_loss: 0.8502
2024-07-11 16:15:44,053 [INFO    ] __main__: train step 5992: loss: 0.9564, policy_loss: 1.3834, value_loss: 0.8502
2024-07-11 16:15:44,247 [INFO    ] __main__: train step 5993: loss: 0.9564, policy_loss: 1.3833, value_loss: 0.8502
2024-07-11 16:15:44,463 [INFO    ] __main__: train step 5994: loss: 0.9565, policy_loss: 1.3832, value_loss: 0.8501
2024-07-11 16:15:44,679 [INFO    ] __main__: train step 5995: loss: 0.9566, policy_loss: 1.3832, value_loss: 0.8501
2024-07-11 16:15:44,879 [INFO    ] __main__: train step 5996: loss: 0.9566, policy_loss: 1.3831, value_loss: 0.8501
2024-07-11 16:15:45,081 [INFO    ] __main__: train step 5997: loss: 0.9567, policy_loss: 1.3830, value_loss: 0.8500
2024-07-11 16:15:45,287 [INFO    ] __main__: train step 5998: loss: 0.9568, policy_loss: 1.3829, value_loss: 0.8500
2024-07-11 16:15:45,491 [INFO    ] __main__: train step 5999: loss: 0.9569, policy_loss: 1.3828, value_loss: 0.8499
2024-07-11 16:15:45,701 [INFO    ] __main__: train step 6000: loss: 0.9569, policy_loss: 1.3827, value_loss: 0.8499
2024-07-11 16:15:45,827 [INFO    ] __main__: restored step 5000 for evaluation
2024-07-11 16:15:53,449 [INFO    ] __main__: later network ELO difference from earlier network: +196 (+8/-8) ELO from 32000 self-played games
2024-07-11 16:15:53,449 [INFO    ] __main__: game outcomes: W: 22642, D: 908, L: 8450
2024-07-11 16:15:53,451 [INFO    ] __main__: validation_elo_delta: 196, validation_elo: 1368
2024-07-11 16:15:55,199 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:15:55,630 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:15:55,692 [INFO    ] __main__: train step 6001: loss: 0.9570, policy_loss: 1.3827, value_loss: 0.8499
2024-07-11 16:15:55,878 [INFO    ] __main__: train step 6002: loss: 0.9571, policy_loss: 1.3826, value_loss: 0.8498
2024-07-11 16:15:56,123 [INFO    ] __main__: train step 6003: loss: 0.9571, policy_loss: 1.3825, value_loss: 0.8498
2024-07-11 16:15:56,367 [INFO    ] __main__: train step 6004: loss: 0.9572, policy_loss: 1.3824, value_loss: 0.8497
2024-07-11 16:15:56,596 [INFO    ] __main__: train step 6005: loss: 0.9573, policy_loss: 1.3823, value_loss: 0.8497
2024-07-11 16:15:56,830 [INFO    ] __main__: train step 6006: loss: 0.9574, policy_loss: 1.3822, value_loss: 0.8497
2024-07-11 16:15:57,044 [INFO    ] __main__: train step 6007: loss: 0.9574, policy_loss: 1.3822, value_loss: 0.8496
2024-07-11 16:15:57,240 [INFO    ] __main__: train step 6008: loss: 0.9575, policy_loss: 1.3821, value_loss: 0.8496
2024-07-11 16:15:57,450 [INFO    ] __main__: train step 6009: loss: 0.9576, policy_loss: 1.3820, value_loss: 0.8496
2024-07-11 16:15:57,653 [INFO    ] __main__: train step 6010: loss: 0.9577, policy_loss: 1.3819, value_loss: 0.8495
2024-07-11 16:15:57,854 [INFO    ] __main__: train step 6011: loss: 0.9577, policy_loss: 1.3818, value_loss: 0.8495
2024-07-11 16:15:58,051 [INFO    ] __main__: train step 6012: loss: 0.9578, policy_loss: 1.3817, value_loss: 0.8494
2024-07-11 16:15:58,258 [INFO    ] __main__: train step 6013: loss: 0.9579, policy_loss: 1.3817, value_loss: 0.8494
2024-07-11 16:15:58,461 [INFO    ] __main__: train step 6014: loss: 0.9579, policy_loss: 1.3816, value_loss: 0.8494
2024-07-11 16:15:58,657 [INFO    ] __main__: train step 6015: loss: 0.9580, policy_loss: 1.3815, value_loss: 0.8493
2024-07-11 16:15:58,865 [INFO    ] __main__: train step 6016: loss: 0.9581, policy_loss: 1.3814, value_loss: 0.8493
2024-07-11 16:15:59,067 [INFO    ] __main__: train step 6017: loss: 0.9582, policy_loss: 1.3813, value_loss: 0.8492
2024-07-11 16:16:00,494 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:16:00,882 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:16:00,938 [INFO    ] __main__: train step 6018: loss: 0.9582, policy_loss: 1.3812, value_loss: 0.8492
2024-07-11 16:16:01,100 [INFO    ] __main__: train step 6019: loss: 0.9583, policy_loss: 1.3811, value_loss: 0.8492
2024-07-11 16:16:01,305 [INFO    ] __main__: train step 6020: loss: 0.9584, policy_loss: 1.3811, value_loss: 0.8491
2024-07-11 16:16:01,505 [INFO    ] __main__: train step 6021: loss: 0.9584, policy_loss: 1.3810, value_loss: 0.8491
2024-07-11 16:16:01,713 [INFO    ] __main__: train step 6022: loss: 0.9585, policy_loss: 1.3809, value_loss: 0.8491
2024-07-11 16:16:01,915 [INFO    ] __main__: train step 6023: loss: 0.9586, policy_loss: 1.3808, value_loss: 0.8490
2024-07-11 16:16:02,126 [INFO    ] __main__: train step 6024: loss: 0.9587, policy_loss: 1.3807, value_loss: 0.8490
2024-07-11 16:16:02,330 [INFO    ] __main__: train step 6025: loss: 0.9587, policy_loss: 1.3806, value_loss: 0.8489
2024-07-11 16:16:02,548 [INFO    ] __main__: train step 6026: loss: 0.9588, policy_loss: 1.3806, value_loss: 0.8489
2024-07-11 16:16:02,766 [INFO    ] __main__: train step 6027: loss: 0.9589, policy_loss: 1.3805, value_loss: 0.8489
2024-07-11 16:16:02,962 [INFO    ] __main__: train step 6028: loss: 0.9589, policy_loss: 1.3804, value_loss: 0.8488
2024-07-11 16:16:03,170 [INFO    ] __main__: train step 6029: loss: 0.9590, policy_loss: 1.3803, value_loss: 0.8488
2024-07-11 16:16:03,372 [INFO    ] __main__: train step 6030: loss: 0.9591, policy_loss: 1.3802, value_loss: 0.8488
2024-07-11 16:16:03,582 [INFO    ] __main__: train step 6031: loss: 0.9592, policy_loss: 1.3801, value_loss: 0.8487
2024-07-11 16:16:03,777 [INFO    ] __main__: train step 6032: loss: 0.9592, policy_loss: 1.3801, value_loss: 0.8487
2024-07-11 16:16:03,981 [INFO    ] __main__: train step 6033: loss: 0.9593, policy_loss: 1.3800, value_loss: 0.8486
2024-07-11 16:16:04,176 [INFO    ] __main__: train step 6034: loss: 0.9594, policy_loss: 1.3799, value_loss: 0.8486
2024-07-11 16:16:05,619 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:16:06,069 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:16:06,131 [INFO    ] __main__: train step 6035: loss: 0.9594, policy_loss: 1.3798, value_loss: 0.8486
2024-07-11 16:16:06,303 [INFO    ] __main__: train step 6036: loss: 0.9595, policy_loss: 1.3797, value_loss: 0.8485
2024-07-11 16:16:06,508 [INFO    ] __main__: train step 6037: loss: 0.9596, policy_loss: 1.3796, value_loss: 0.8485
2024-07-11 16:16:06,704 [INFO    ] __main__: train step 6038: loss: 0.9597, policy_loss: 1.3796, value_loss: 0.8485
2024-07-11 16:16:06,905 [INFO    ] __main__: train step 6039: loss: 0.9597, policy_loss: 1.3795, value_loss: 0.8484
2024-07-11 16:16:07,112 [INFO    ] __main__: train step 6040: loss: 0.9598, policy_loss: 1.3794, value_loss: 0.8484
2024-07-11 16:16:07,309 [INFO    ] __main__: train step 6041: loss: 0.9599, policy_loss: 1.3793, value_loss: 0.8483
2024-07-11 16:16:07,512 [INFO    ] __main__: train step 6042: loss: 0.9599, policy_loss: 1.3792, value_loss: 0.8483
2024-07-11 16:16:07,715 [INFO    ] __main__: train step 6043: loss: 0.9600, policy_loss: 1.3791, value_loss: 0.8483
2024-07-11 16:16:07,907 [INFO    ] __main__: train step 6044: loss: 0.9601, policy_loss: 1.3791, value_loss: 0.8482
2024-07-11 16:16:08,126 [INFO    ] __main__: train step 6045: loss: 0.9602, policy_loss: 1.3790, value_loss: 0.8482
2024-07-11 16:16:08,337 [INFO    ] __main__: train step 6046: loss: 0.9602, policy_loss: 1.3789, value_loss: 0.8482
2024-07-11 16:16:08,541 [INFO    ] __main__: train step 6047: loss: 0.9603, policy_loss: 1.3788, value_loss: 0.8481
2024-07-11 16:16:08,738 [INFO    ] __main__: train step 6048: loss: 0.9604, policy_loss: 1.3787, value_loss: 0.8481
2024-07-11 16:16:08,955 [INFO    ] __main__: train step 6049: loss: 0.9604, policy_loss: 1.3786, value_loss: 0.8480
2024-07-11 16:16:10,024 [INFO    ] __main__: train step 6050: loss: 0.9605, policy_loss: 1.3786, value_loss: 0.8480
2024-07-11 16:16:10,230 [INFO    ] __main__: train step 6051: loss: 0.9606, policy_loss: 1.3785, value_loss: 0.8480
2024-07-11 16:16:11,695 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:16:12,105 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:16:12,164 [INFO    ] __main__: train step 6052: loss: 0.9606, policy_loss: 1.3784, value_loss: 0.8479
2024-07-11 16:16:12,339 [INFO    ] __main__: train step 6053: loss: 0.9607, policy_loss: 1.3783, value_loss: 0.8479
2024-07-11 16:16:12,531 [INFO    ] __main__: train step 6054: loss: 0.9608, policy_loss: 1.3782, value_loss: 0.8478
2024-07-11 16:16:12,733 [INFO    ] __main__: train step 6055: loss: 0.9609, policy_loss: 1.3781, value_loss: 0.8478
2024-07-11 16:16:12,933 [INFO    ] __main__: train step 6056: loss: 0.9609, policy_loss: 1.3781, value_loss: 0.8478
2024-07-11 16:16:13,146 [INFO    ] __main__: train step 6057: loss: 0.9610, policy_loss: 1.3780, value_loss: 0.8477
2024-07-11 16:16:13,336 [INFO    ] __main__: train step 6058: loss: 0.9611, policy_loss: 1.3779, value_loss: 0.8477
2024-07-11 16:16:13,560 [INFO    ] __main__: train step 6059: loss: 0.9611, policy_loss: 1.3778, value_loss: 0.8477
2024-07-11 16:16:13,784 [INFO    ] __main__: train step 6060: loss: 0.9612, policy_loss: 1.3777, value_loss: 0.8476
2024-07-11 16:16:13,987 [INFO    ] __main__: train step 6061: loss: 0.9613, policy_loss: 1.3776, value_loss: 0.8476
2024-07-11 16:16:14,218 [INFO    ] __main__: train step 6062: loss: 0.9613, policy_loss: 1.3776, value_loss: 0.8475
2024-07-11 16:16:14,414 [INFO    ] __main__: train step 6063: loss: 0.9614, policy_loss: 1.3775, value_loss: 0.8475
2024-07-11 16:16:14,632 [INFO    ] __main__: train step 6064: loss: 0.9615, policy_loss: 1.3774, value_loss: 0.8475
2024-07-11 16:16:14,829 [INFO    ] __main__: train step 6065: loss: 0.9616, policy_loss: 1.3773, value_loss: 0.8474
2024-07-11 16:16:15,028 [INFO    ] __main__: train step 6066: loss: 0.9616, policy_loss: 1.3772, value_loss: 0.8474
2024-07-11 16:16:15,225 [INFO    ] __main__: train step 6067: loss: 0.9617, policy_loss: 1.3771, value_loss: 0.8473
2024-07-11 16:16:15,439 [INFO    ] __main__: train step 6068: loss: 0.9618, policy_loss: 1.3771, value_loss: 0.8473
2024-07-11 16:16:16,874 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:16:17,309 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:16:17,369 [INFO    ] __main__: train step 6069: loss: 0.9618, policy_loss: 1.3770, value_loss: 0.8473
2024-07-11 16:16:17,543 [INFO    ] __main__: train step 6070: loss: 0.9619, policy_loss: 1.3769, value_loss: 0.8472
2024-07-11 16:16:17,739 [INFO    ] __main__: train step 6071: loss: 0.9620, policy_loss: 1.3768, value_loss: 0.8472
2024-07-11 16:16:17,944 [INFO    ] __main__: train step 6072: loss: 0.9621, policy_loss: 1.3767, value_loss: 0.8472
2024-07-11 16:16:18,139 [INFO    ] __main__: train step 6073: loss: 0.9621, policy_loss: 1.3766, value_loss: 0.8471
2024-07-11 16:16:18,349 [INFO    ] __main__: train step 6074: loss: 0.9622, policy_loss: 1.3766, value_loss: 0.8471
2024-07-11 16:16:18,546 [INFO    ] __main__: train step 6075: loss: 0.9623, policy_loss: 1.3765, value_loss: 0.8470
2024-07-11 16:16:18,748 [INFO    ] __main__: train step 6076: loss: 0.9623, policy_loss: 1.3764, value_loss: 0.8470
2024-07-11 16:16:18,948 [INFO    ] __main__: train step 6077: loss: 0.9624, policy_loss: 1.3763, value_loss: 0.8470
2024-07-11 16:16:19,175 [INFO    ] __main__: train step 6078: loss: 0.9625, policy_loss: 1.3762, value_loss: 0.8469
2024-07-11 16:16:19,389 [INFO    ] __main__: train step 6079: loss: 0.9625, policy_loss: 1.3761, value_loss: 0.8469
2024-07-11 16:16:19,588 [INFO    ] __main__: train step 6080: loss: 0.9626, policy_loss: 1.3761, value_loss: 0.8469
2024-07-11 16:16:19,798 [INFO    ] __main__: train step 6081: loss: 0.9627, policy_loss: 1.3760, value_loss: 0.8468
2024-07-11 16:16:20,023 [INFO    ] __main__: train step 6082: loss: 0.9628, policy_loss: 1.3759, value_loss: 0.8468
2024-07-11 16:16:20,229 [INFO    ] __main__: train step 6083: loss: 0.9628, policy_loss: 1.3758, value_loss: 0.8467
2024-07-11 16:16:20,451 [INFO    ] __main__: train step 6084: loss: 0.9629, policy_loss: 1.3757, value_loss: 0.8467
2024-07-11 16:16:20,665 [INFO    ] __main__: train step 6085: loss: 0.9630, policy_loss: 1.3756, value_loss: 0.8467
2024-07-11 16:16:22,121 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:16:22,538 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:16:22,599 [INFO    ] __main__: train step 6086: loss: 0.9630, policy_loss: 1.3756, value_loss: 0.8466
2024-07-11 16:16:22,763 [INFO    ] __main__: train step 6087: loss: 0.9631, policy_loss: 1.3755, value_loss: 0.8466
2024-07-11 16:16:22,959 [INFO    ] __main__: train step 6088: loss: 0.9632, policy_loss: 1.3754, value_loss: 0.8466
2024-07-11 16:16:23,170 [INFO    ] __main__: train step 6089: loss: 0.9632, policy_loss: 1.3753, value_loss: 0.8465
2024-07-11 16:16:23,371 [INFO    ] __main__: train step 6090: loss: 0.9633, policy_loss: 1.3752, value_loss: 0.8465
2024-07-11 16:16:23,574 [INFO    ] __main__: train step 6091: loss: 0.9634, policy_loss: 1.3751, value_loss: 0.8464
2024-07-11 16:16:23,777 [INFO    ] __main__: train step 6092: loss: 0.9635, policy_loss: 1.3751, value_loss: 0.8464
2024-07-11 16:16:23,990 [INFO    ] __main__: train step 6093: loss: 0.9635, policy_loss: 1.3750, value_loss: 0.8464
2024-07-11 16:16:24,204 [INFO    ] __main__: train step 6094: loss: 0.9636, policy_loss: 1.3749, value_loss: 0.8463
2024-07-11 16:16:24,410 [INFO    ] __main__: train step 6095: loss: 0.9637, policy_loss: 1.3748, value_loss: 0.8463
2024-07-11 16:16:24,599 [INFO    ] __main__: train step 6096: loss: 0.9637, policy_loss: 1.3747, value_loss: 0.8462
2024-07-11 16:16:24,808 [INFO    ] __main__: train step 6097: loss: 0.9638, policy_loss: 1.3746, value_loss: 0.8462
2024-07-11 16:16:25,003 [INFO    ] __main__: train step 6098: loss: 0.9639, policy_loss: 1.3746, value_loss: 0.8462
2024-07-11 16:16:25,208 [INFO    ] __main__: train step 6099: loss: 0.9639, policy_loss: 1.3745, value_loss: 0.8461
2024-07-11 16:16:25,412 [INFO    ] __main__: train step 6100: loss: 0.9640, policy_loss: 1.3744, value_loss: 0.8461
2024-07-11 16:16:25,595 [INFO    ] __main__: train step 6101: loss: 0.9641, policy_loss: 1.3743, value_loss: 0.8461
2024-07-11 16:16:25,813 [INFO    ] __main__: train step 6102: loss: 0.9642, policy_loss: 1.3742, value_loss: 0.8460
2024-07-11 16:16:27,255 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:16:27,681 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:16:27,735 [INFO    ] __main__: train step 6103: loss: 0.9642, policy_loss: 1.3741, value_loss: 0.8460
2024-07-11 16:16:27,920 [INFO    ] __main__: train step 6104: loss: 0.9643, policy_loss: 1.3741, value_loss: 0.8460
2024-07-11 16:16:28,109 [INFO    ] __main__: train step 6105: loss: 0.9644, policy_loss: 1.3740, value_loss: 0.8459
2024-07-11 16:16:28,302 [INFO    ] __main__: train step 6106: loss: 0.9644, policy_loss: 1.3739, value_loss: 0.8459
2024-07-11 16:16:28,497 [INFO    ] __main__: train step 6107: loss: 0.9645, policy_loss: 1.3738, value_loss: 0.8458
2024-07-11 16:16:28,699 [INFO    ] __main__: train step 6108: loss: 0.9646, policy_loss: 1.3737, value_loss: 0.8458
2024-07-11 16:16:28,899 [INFO    ] __main__: train step 6109: loss: 0.9646, policy_loss: 1.3736, value_loss: 0.8458
2024-07-11 16:16:29,115 [INFO    ] __main__: train step 6110: loss: 0.9647, policy_loss: 1.3736, value_loss: 0.8457
2024-07-11 16:16:29,360 [INFO    ] __main__: train step 6111: loss: 0.9648, policy_loss: 1.3735, value_loss: 0.8457
2024-07-11 16:16:29,569 [INFO    ] __main__: train step 6112: loss: 0.9648, policy_loss: 1.3734, value_loss: 0.8457
2024-07-11 16:16:29,761 [INFO    ] __main__: train step 6113: loss: 0.9649, policy_loss: 1.3733, value_loss: 0.8456
2024-07-11 16:16:29,978 [INFO    ] __main__: train step 6114: loss: 0.9650, policy_loss: 1.3732, value_loss: 0.8456
2024-07-11 16:16:30,174 [INFO    ] __main__: train step 6115: loss: 0.9651, policy_loss: 1.3731, value_loss: 0.8455
2024-07-11 16:16:30,379 [INFO    ] __main__: train step 6116: loss: 0.9651, policy_loss: 1.3731, value_loss: 0.8455
2024-07-11 16:16:30,581 [INFO    ] __main__: train step 6117: loss: 0.9652, policy_loss: 1.3730, value_loss: 0.8455
2024-07-11 16:16:30,772 [INFO    ] __main__: train step 6118: loss: 0.9653, policy_loss: 1.3729, value_loss: 0.8454
2024-07-11 16:16:30,976 [INFO    ] __main__: train step 6119: loss: 0.9653, policy_loss: 1.3728, value_loss: 0.8454
2024-07-11 16:16:32,412 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:16:32,797 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:16:32,856 [INFO    ] __main__: train step 6120: loss: 0.9654, policy_loss: 1.3727, value_loss: 0.8454
2024-07-11 16:16:33,028 [INFO    ] __main__: train step 6121: loss: 0.9655, policy_loss: 1.3726, value_loss: 0.8453
2024-07-11 16:16:34,047 [INFO    ] __main__: train step 6122: loss: 0.9655, policy_loss: 1.3726, value_loss: 0.8453
2024-07-11 16:16:34,254 [INFO    ] __main__: train step 6123: loss: 0.9656, policy_loss: 1.3725, value_loss: 0.8452
2024-07-11 16:16:34,452 [INFO    ] __main__: train step 6124: loss: 0.9657, policy_loss: 1.3724, value_loss: 0.8452
2024-07-11 16:16:34,647 [INFO    ] __main__: train step 6125: loss: 0.9657, policy_loss: 1.3723, value_loss: 0.8452
2024-07-11 16:16:34,871 [INFO    ] __main__: train step 6126: loss: 0.9658, policy_loss: 1.3722, value_loss: 0.8451
2024-07-11 16:16:35,073 [INFO    ] __main__: train step 6127: loss: 0.9659, policy_loss: 1.3721, value_loss: 0.8451
2024-07-11 16:16:35,291 [INFO    ] __main__: train step 6128: loss: 0.9660, policy_loss: 1.3721, value_loss: 0.8451
2024-07-11 16:16:35,529 [INFO    ] __main__: train step 6129: loss: 0.9660, policy_loss: 1.3720, value_loss: 0.8450
2024-07-11 16:16:35,722 [INFO    ] __main__: train step 6130: loss: 0.9661, policy_loss: 1.3719, value_loss: 0.8450
2024-07-11 16:16:35,922 [INFO    ] __main__: train step 6131: loss: 0.9662, policy_loss: 1.3718, value_loss: 0.8449
2024-07-11 16:16:36,123 [INFO    ] __main__: train step 6132: loss: 0.9662, policy_loss: 1.3717, value_loss: 0.8449
2024-07-11 16:16:36,324 [INFO    ] __main__: train step 6133: loss: 0.9663, policy_loss: 1.3717, value_loss: 0.8449
2024-07-11 16:16:36,531 [INFO    ] __main__: train step 6134: loss: 0.9664, policy_loss: 1.3716, value_loss: 0.8448
2024-07-11 16:16:36,741 [INFO    ] __main__: train step 6135: loss: 0.9664, policy_loss: 1.3715, value_loss: 0.8448
2024-07-11 16:16:36,945 [INFO    ] __main__: train step 6136: loss: 0.9665, policy_loss: 1.3714, value_loss: 0.8448
2024-07-11 16:16:38,386 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:16:38,803 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:16:38,864 [INFO    ] __main__: train step 6137: loss: 0.9666, policy_loss: 1.3713, value_loss: 0.8447
2024-07-11 16:16:39,043 [INFO    ] __main__: train step 6138: loss: 0.9666, policy_loss: 1.3712, value_loss: 0.8447
2024-07-11 16:16:39,242 [INFO    ] __main__: train step 6139: loss: 0.9667, policy_loss: 1.3712, value_loss: 0.8446
2024-07-11 16:16:39,433 [INFO    ] __main__: train step 6140: loss: 0.9668, policy_loss: 1.3711, value_loss: 0.8446
2024-07-11 16:16:39,647 [INFO    ] __main__: train step 6141: loss: 0.9668, policy_loss: 1.3710, value_loss: 0.8446
2024-07-11 16:16:39,869 [INFO    ] __main__: train step 6142: loss: 0.9669, policy_loss: 1.3709, value_loss: 0.8445
2024-07-11 16:16:40,070 [INFO    ] __main__: train step 6143: loss: 0.9670, policy_loss: 1.3708, value_loss: 0.8445
2024-07-11 16:16:40,277 [INFO    ] __main__: train step 6144: loss: 0.9670, policy_loss: 1.3707, value_loss: 0.8444
2024-07-11 16:16:40,479 [INFO    ] __main__: train step 6145: loss: 0.9671, policy_loss: 1.3706, value_loss: 0.8444
2024-07-11 16:16:40,684 [INFO    ] __main__: train step 6146: loss: 0.9672, policy_loss: 1.3706, value_loss: 0.8444
2024-07-11 16:16:40,895 [INFO    ] __main__: train step 6147: loss: 0.9672, policy_loss: 1.3705, value_loss: 0.8443
2024-07-11 16:16:41,103 [INFO    ] __main__: train step 6148: loss: 0.9673, policy_loss: 1.3704, value_loss: 0.8443
2024-07-11 16:16:41,314 [INFO    ] __main__: train step 6149: loss: 0.9674, policy_loss: 1.3703, value_loss: 0.8443
2024-07-11 16:16:41,508 [INFO    ] __main__: train step 6150: loss: 0.9674, policy_loss: 1.3702, value_loss: 0.8442
2024-07-11 16:16:41,728 [INFO    ] __main__: train step 6151: loss: 0.9675, policy_loss: 1.3702, value_loss: 0.8442
2024-07-11 16:16:41,931 [INFO    ] __main__: train step 6152: loss: 0.9676, policy_loss: 1.3701, value_loss: 0.8441
2024-07-11 16:16:42,135 [INFO    ] __main__: train step 6153: loss: 0.9676, policy_loss: 1.3700, value_loss: 0.8441
2024-07-11 16:16:43,580 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:16:44,012 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:16:44,079 [INFO    ] __main__: train step 6154: loss: 0.9677, policy_loss: 1.3699, value_loss: 0.8441
2024-07-11 16:16:44,264 [INFO    ] __main__: train step 6155: loss: 0.9678, policy_loss: 1.3698, value_loss: 0.8440
2024-07-11 16:16:44,500 [INFO    ] __main__: train step 6156: loss: 0.9678, policy_loss: 1.3697, value_loss: 0.8440
2024-07-11 16:16:44,736 [INFO    ] __main__: train step 6157: loss: 0.9679, policy_loss: 1.3697, value_loss: 0.8440
2024-07-11 16:16:44,947 [INFO    ] __main__: train step 6158: loss: 0.9680, policy_loss: 1.3696, value_loss: 0.8439
2024-07-11 16:16:45,143 [INFO    ] __main__: train step 6159: loss: 0.9680, policy_loss: 1.3695, value_loss: 0.8439
2024-07-11 16:16:45,357 [INFO    ] __main__: train step 6160: loss: 0.9681, policy_loss: 1.3694, value_loss: 0.8438
2024-07-11 16:16:45,551 [INFO    ] __main__: train step 6161: loss: 0.9682, policy_loss: 1.3693, value_loss: 0.8438
2024-07-11 16:16:45,759 [INFO    ] __main__: train step 6162: loss: 0.9683, policy_loss: 1.3692, value_loss: 0.8438
2024-07-11 16:16:45,960 [INFO    ] __main__: train step 6163: loss: 0.9683, policy_loss: 1.3692, value_loss: 0.8437
2024-07-11 16:16:46,167 [INFO    ] __main__: train step 6164: loss: 0.9684, policy_loss: 1.3691, value_loss: 0.8437
2024-07-11 16:16:46,383 [INFO    ] __main__: train step 6165: loss: 0.9685, policy_loss: 1.3690, value_loss: 0.8437
2024-07-11 16:16:46,578 [INFO    ] __main__: train step 6166: loss: 0.9685, policy_loss: 1.3689, value_loss: 0.8436
2024-07-11 16:16:46,795 [INFO    ] __main__: train step 6167: loss: 0.9686, policy_loss: 1.3688, value_loss: 0.8436
2024-07-11 16:16:47,038 [INFO    ] __main__: train step 6168: loss: 0.9687, policy_loss: 1.3688, value_loss: 0.8436
2024-07-11 16:16:47,247 [INFO    ] __main__: train step 6169: loss: 0.9687, policy_loss: 1.3687, value_loss: 0.8435
2024-07-11 16:16:47,460 [INFO    ] __main__: train step 6170: loss: 0.9688, policy_loss: 1.3686, value_loss: 0.8435
2024-07-11 16:16:48,888 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:16:49,271 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:16:49,326 [INFO    ] __main__: train step 6171: loss: 0.9689, policy_loss: 1.3685, value_loss: 0.8434
2024-07-11 16:16:49,494 [INFO    ] __main__: train step 6172: loss: 0.9689, policy_loss: 1.3684, value_loss: 0.8434
2024-07-11 16:16:49,706 [INFO    ] __main__: train step 6173: loss: 0.9690, policy_loss: 1.3683, value_loss: 0.8434
2024-07-11 16:16:49,922 [INFO    ] __main__: train step 6174: loss: 0.9691, policy_loss: 1.3683, value_loss: 0.8433
2024-07-11 16:16:50,120 [INFO    ] __main__: train step 6175: loss: 0.9691, policy_loss: 1.3682, value_loss: 0.8433
2024-07-11 16:16:50,323 [INFO    ] __main__: train step 6176: loss: 0.9692, policy_loss: 1.3681, value_loss: 0.8433
2024-07-11 16:16:50,527 [INFO    ] __main__: train step 6177: loss: 0.9693, policy_loss: 1.3680, value_loss: 0.8432
2024-07-11 16:16:50,735 [INFO    ] __main__: train step 6178: loss: 0.9693, policy_loss: 1.3679, value_loss: 0.8432
2024-07-11 16:16:50,945 [INFO    ] __main__: train step 6179: loss: 0.9694, policy_loss: 1.3678, value_loss: 0.8431
2024-07-11 16:16:51,140 [INFO    ] __main__: train step 6180: loss: 0.9695, policy_loss: 1.3678, value_loss: 0.8431
2024-07-11 16:16:51,332 [INFO    ] __main__: train step 6181: loss: 0.9695, policy_loss: 1.3677, value_loss: 0.8431
2024-07-11 16:16:51,543 [INFO    ] __main__: train step 6182: loss: 0.9696, policy_loss: 1.3676, value_loss: 0.8430
2024-07-11 16:16:51,732 [INFO    ] __main__: train step 6183: loss: 0.9697, policy_loss: 1.3675, value_loss: 0.8430
2024-07-11 16:16:51,945 [INFO    ] __main__: train step 6184: loss: 0.9697, policy_loss: 1.3674, value_loss: 0.8430
2024-07-11 16:16:52,139 [INFO    ] __main__: train step 6185: loss: 0.9698, policy_loss: 1.3674, value_loss: 0.8429
2024-07-11 16:16:52,346 [INFO    ] __main__: train step 6186: loss: 0.9699, policy_loss: 1.3673, value_loss: 0.8429
2024-07-11 16:16:52,548 [INFO    ] __main__: train step 6187: loss: 0.9699, policy_loss: 1.3672, value_loss: 0.8428
2024-07-11 16:16:54,001 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:16:54,377 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:16:54,433 [INFO    ] __main__: train step 6188: loss: 0.9700, policy_loss: 1.3671, value_loss: 0.8428
2024-07-11 16:16:54,609 [INFO    ] __main__: train step 6189: loss: 0.9701, policy_loss: 1.3670, value_loss: 0.8428
2024-07-11 16:16:54,807 [INFO    ] __main__: train step 6190: loss: 0.9701, policy_loss: 1.3669, value_loss: 0.8427
2024-07-11 16:16:55,012 [INFO    ] __main__: train step 6191: loss: 0.9702, policy_loss: 1.3669, value_loss: 0.8427
2024-07-11 16:16:55,207 [INFO    ] __main__: train step 6192: loss: 0.9703, policy_loss: 1.3668, value_loss: 0.8426
2024-07-11 16:16:55,399 [INFO    ] __main__: train step 6193: loss: 0.9703, policy_loss: 1.3667, value_loss: 0.8426
2024-07-11 16:16:55,595 [INFO    ] __main__: train step 6194: loss: 0.9704, policy_loss: 1.3666, value_loss: 0.8426
2024-07-11 16:16:55,812 [INFO    ] __main__: train step 6195: loss: 0.9705, policy_loss: 1.3665, value_loss: 0.8425
2024-07-11 16:16:56,039 [INFO    ] __main__: train step 6196: loss: 0.9705, policy_loss: 1.3664, value_loss: 0.8425
2024-07-11 16:16:57,112 [INFO    ] __main__: train step 6197: loss: 0.9706, policy_loss: 1.3664, value_loss: 0.8425
2024-07-11 16:16:57,322 [INFO    ] __main__: train step 6198: loss: 0.9707, policy_loss: 1.3663, value_loss: 0.8424
2024-07-11 16:16:57,557 [INFO    ] __main__: train step 6199: loss: 0.9707, policy_loss: 1.3662, value_loss: 0.8424
2024-07-11 16:16:57,748 [INFO    ] __main__: train step 6200: loss: 0.9708, policy_loss: 1.3661, value_loss: 0.8424
2024-07-11 16:16:57,959 [INFO    ] __main__: train step 6201: loss: 0.9709, policy_loss: 1.3660, value_loss: 0.8423
2024-07-11 16:16:58,197 [INFO    ] __main__: train step 6202: loss: 0.9709, policy_loss: 1.3659, value_loss: 0.8423
2024-07-11 16:16:58,398 [INFO    ] __main__: train step 6203: loss: 0.9710, policy_loss: 1.3659, value_loss: 0.8422
2024-07-11 16:16:58,610 [INFO    ] __main__: train step 6204: loss: 0.9711, policy_loss: 1.3658, value_loss: 0.8422
2024-07-11 16:17:00,055 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:17:00,430 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:17:00,485 [INFO    ] __main__: train step 6205: loss: 0.9711, policy_loss: 1.3657, value_loss: 0.8422
2024-07-11 16:17:00,659 [INFO    ] __main__: train step 6206: loss: 0.9712, policy_loss: 1.3656, value_loss: 0.8421
2024-07-11 16:17:00,848 [INFO    ] __main__: train step 6207: loss: 0.9713, policy_loss: 1.3655, value_loss: 0.8421
2024-07-11 16:17:01,044 [INFO    ] __main__: train step 6208: loss: 0.9713, policy_loss: 1.3655, value_loss: 0.8421
2024-07-11 16:17:01,239 [INFO    ] __main__: train step 6209: loss: 0.9714, policy_loss: 1.3654, value_loss: 0.8420
2024-07-11 16:17:01,438 [INFO    ] __main__: train step 6210: loss: 0.9715, policy_loss: 1.3653, value_loss: 0.8420
2024-07-11 16:17:01,660 [INFO    ] __main__: train step 6211: loss: 0.9715, policy_loss: 1.3652, value_loss: 0.8419
2024-07-11 16:17:01,892 [INFO    ] __main__: train step 6212: loss: 0.9716, policy_loss: 1.3651, value_loss: 0.8419
2024-07-11 16:17:02,129 [INFO    ] __main__: train step 6213: loss: 0.9717, policy_loss: 1.3650, value_loss: 0.8419
2024-07-11 16:17:02,348 [INFO    ] __main__: train step 6214: loss: 0.9717, policy_loss: 1.3650, value_loss: 0.8418
2024-07-11 16:17:02,595 [INFO    ] __main__: train step 6215: loss: 0.9718, policy_loss: 1.3649, value_loss: 0.8418
2024-07-11 16:17:02,818 [INFO    ] __main__: train step 6216: loss: 0.9719, policy_loss: 1.3648, value_loss: 0.8418
2024-07-11 16:17:03,007 [INFO    ] __main__: train step 6217: loss: 0.9719, policy_loss: 1.3647, value_loss: 0.8417
2024-07-11 16:17:03,217 [INFO    ] __main__: train step 6218: loss: 0.9720, policy_loss: 1.3646, value_loss: 0.8417
2024-07-11 16:17:03,421 [INFO    ] __main__: train step 6219: loss: 0.9721, policy_loss: 1.3645, value_loss: 0.8416
2024-07-11 16:17:03,629 [INFO    ] __main__: train step 6220: loss: 0.9721, policy_loss: 1.3645, value_loss: 0.8416
2024-07-11 16:17:03,819 [INFO    ] __main__: train step 6221: loss: 0.9722, policy_loss: 1.3644, value_loss: 0.8416
2024-07-11 16:17:05,236 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:17:05,618 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:17:05,673 [INFO    ] __main__: train step 6222: loss: 0.9723, policy_loss: 1.3643, value_loss: 0.8415
2024-07-11 16:17:05,840 [INFO    ] __main__: train step 6223: loss: 0.9723, policy_loss: 1.3642, value_loss: 0.8415
2024-07-11 16:17:06,053 [INFO    ] __main__: train step 6224: loss: 0.9724, policy_loss: 1.3641, value_loss: 0.8415
2024-07-11 16:17:06,276 [INFO    ] __main__: train step 6225: loss: 0.9725, policy_loss: 1.3641, value_loss: 0.8414
2024-07-11 16:17:06,469 [INFO    ] __main__: train step 6226: loss: 0.9725, policy_loss: 1.3640, value_loss: 0.8414
2024-07-11 16:17:06,680 [INFO    ] __main__: train step 6227: loss: 0.9726, policy_loss: 1.3639, value_loss: 0.8414
2024-07-11 16:17:06,875 [INFO    ] __main__: train step 6228: loss: 0.9727, policy_loss: 1.3638, value_loss: 0.8413
2024-07-11 16:17:07,081 [INFO    ] __main__: train step 6229: loss: 0.9727, policy_loss: 1.3637, value_loss: 0.8413
2024-07-11 16:17:07,286 [INFO    ] __main__: train step 6230: loss: 0.9728, policy_loss: 1.3637, value_loss: 0.8412
2024-07-11 16:17:07,487 [INFO    ] __main__: train step 6231: loss: 0.9729, policy_loss: 1.3636, value_loss: 0.8412
2024-07-11 16:17:07,701 [INFO    ] __main__: train step 6232: loss: 0.9729, policy_loss: 1.3635, value_loss: 0.8412
2024-07-11 16:17:07,921 [INFO    ] __main__: train step 6233: loss: 0.9730, policy_loss: 1.3634, value_loss: 0.8411
2024-07-11 16:17:08,252 [INFO    ] __main__: train step 6234: loss: 0.9731, policy_loss: 1.3633, value_loss: 0.8411
2024-07-11 16:17:08,578 [INFO    ] __main__: train step 6235: loss: 0.9731, policy_loss: 1.3632, value_loss: 0.8411
2024-07-11 16:17:08,940 [INFO    ] __main__: train step 6236: loss: 0.9732, policy_loss: 1.3632, value_loss: 0.8410
2024-07-11 16:17:09,170 [INFO    ] __main__: train step 6237: loss: 0.9733, policy_loss: 1.3631, value_loss: 0.8410
2024-07-11 16:17:09,374 [INFO    ] __main__: train step 6238: loss: 0.9733, policy_loss: 1.3630, value_loss: 0.8409
2024-07-11 16:17:11,363 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:17:11,716 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:17:11,772 [INFO    ] __main__: train step 6239: loss: 0.9734, policy_loss: 1.3629, value_loss: 0.8409
2024-07-11 16:17:11,953 [INFO    ] __main__: train step 6240: loss: 0.9735, policy_loss: 1.3628, value_loss: 0.8409
2024-07-11 16:17:12,163 [INFO    ] __main__: train step 6241: loss: 0.9735, policy_loss: 1.3627, value_loss: 0.8408
2024-07-11 16:17:12,357 [INFO    ] __main__: train step 6242: loss: 0.9736, policy_loss: 1.3627, value_loss: 0.8408
2024-07-11 16:17:12,561 [INFO    ] __main__: train step 6243: loss: 0.9737, policy_loss: 1.3626, value_loss: 0.8408
2024-07-11 16:17:12,765 [INFO    ] __main__: train step 6244: loss: 0.9737, policy_loss: 1.3625, value_loss: 0.8407
2024-07-11 16:17:12,996 [INFO    ] __main__: train step 6245: loss: 0.9738, policy_loss: 1.3624, value_loss: 0.8407
2024-07-11 16:17:13,232 [INFO    ] __main__: train step 6246: loss: 0.9739, policy_loss: 1.3623, value_loss: 0.8407
2024-07-11 16:17:13,445 [INFO    ] __main__: train step 6247: loss: 0.9739, policy_loss: 1.3623, value_loss: 0.8406
2024-07-11 16:17:13,654 [INFO    ] __main__: train step 6248: loss: 0.9740, policy_loss: 1.3622, value_loss: 0.8406
2024-07-11 16:17:13,888 [INFO    ] __main__: train step 6249: loss: 0.9741, policy_loss: 1.3621, value_loss: 0.8405
2024-07-11 16:17:14,088 [INFO    ] __main__: train step 6250: loss: 0.9741, policy_loss: 1.3620, value_loss: 0.8405
2024-07-11 16:17:14,295 [INFO    ] __main__: train step 6251: loss: 0.9742, policy_loss: 1.3619, value_loss: 0.8405
2024-07-11 16:17:14,521 [INFO    ] __main__: train step 6252: loss: 0.9743, policy_loss: 1.3618, value_loss: 0.8404
2024-07-11 16:17:14,745 [INFO    ] __main__: train step 6253: loss: 0.9743, policy_loss: 1.3618, value_loss: 0.8404
2024-07-11 16:17:14,964 [INFO    ] __main__: train step 6254: loss: 0.9744, policy_loss: 1.3617, value_loss: 0.8404
2024-07-11 16:17:15,167 [INFO    ] __main__: train step 6255: loss: 0.9745, policy_loss: 1.3616, value_loss: 0.8403
2024-07-11 16:17:16,613 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:17:17,010 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:17:17,066 [INFO    ] __main__: train step 6256: loss: 0.9745, policy_loss: 1.3615, value_loss: 0.8403
2024-07-11 16:17:17,254 [INFO    ] __main__: train step 6257: loss: 0.9746, policy_loss: 1.3614, value_loss: 0.8403
2024-07-11 16:17:17,444 [INFO    ] __main__: train step 6258: loss: 0.9747, policy_loss: 1.3614, value_loss: 0.8402
2024-07-11 16:17:17,650 [INFO    ] __main__: train step 6259: loss: 0.9747, policy_loss: 1.3613, value_loss: 0.8402
2024-07-11 16:17:17,858 [INFO    ] __main__: train step 6260: loss: 0.9748, policy_loss: 1.3612, value_loss: 0.8402
2024-07-11 16:17:18,073 [INFO    ] __main__: train step 6261: loss: 0.9749, policy_loss: 1.3611, value_loss: 0.8401
2024-07-11 16:17:18,297 [INFO    ] __main__: train step 6262: loss: 0.9749, policy_loss: 1.3610, value_loss: 0.8401
2024-07-11 16:17:18,502 [INFO    ] __main__: train step 6263: loss: 0.9750, policy_loss: 1.3609, value_loss: 0.8400
2024-07-11 16:17:18,706 [INFO    ] __main__: train step 6264: loss: 0.9751, policy_loss: 1.3609, value_loss: 0.8400
2024-07-11 16:17:18,938 [INFO    ] __main__: train step 6265: loss: 0.9751, policy_loss: 1.3608, value_loss: 0.8400
2024-07-11 16:17:19,151 [INFO    ] __main__: train step 6266: loss: 0.9752, policy_loss: 1.3607, value_loss: 0.8399
2024-07-11 16:17:19,344 [INFO    ] __main__: train step 6267: loss: 0.9753, policy_loss: 1.3606, value_loss: 0.8399
2024-07-11 16:17:19,550 [INFO    ] __main__: train step 6268: loss: 0.9753, policy_loss: 1.3605, value_loss: 0.8399
2024-07-11 16:17:19,759 [INFO    ] __main__: train step 6269: loss: 0.9754, policy_loss: 1.3605, value_loss: 0.8398
2024-07-11 16:17:20,837 [INFO    ] __main__: train step 6270: loss: 0.9755, policy_loss: 1.3604, value_loss: 0.8398
2024-07-11 16:17:21,069 [INFO    ] __main__: train step 6271: loss: 0.9755, policy_loss: 1.3603, value_loss: 0.8398
2024-07-11 16:17:21,281 [INFO    ] __main__: train step 6272: loss: 0.9756, policy_loss: 1.3602, value_loss: 0.8397
2024-07-11 16:17:22,730 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:17:23,151 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:17:23,209 [INFO    ] __main__: train step 6273: loss: 0.9756, policy_loss: 1.3601, value_loss: 0.8397
2024-07-11 16:17:23,384 [INFO    ] __main__: train step 6274: loss: 0.9757, policy_loss: 1.3600, value_loss: 0.8396
2024-07-11 16:17:23,591 [INFO    ] __main__: train step 6275: loss: 0.9758, policy_loss: 1.3600, value_loss: 0.8396
2024-07-11 16:17:23,811 [INFO    ] __main__: train step 6276: loss: 0.9758, policy_loss: 1.3599, value_loss: 0.8396
2024-07-11 16:17:23,997 [INFO    ] __main__: train step 6277: loss: 0.9759, policy_loss: 1.3598, value_loss: 0.8395
2024-07-11 16:17:24,199 [INFO    ] __main__: train step 6278: loss: 0.9760, policy_loss: 1.3597, value_loss: 0.8395
2024-07-11 16:17:24,400 [INFO    ] __main__: train step 6279: loss: 0.9760, policy_loss: 1.3596, value_loss: 0.8395
2024-07-11 16:17:24,606 [INFO    ] __main__: train step 6280: loss: 0.9761, policy_loss: 1.3596, value_loss: 0.8394
2024-07-11 16:17:24,800 [INFO    ] __main__: train step 6281: loss: 0.9762, policy_loss: 1.3595, value_loss: 0.8394
2024-07-11 16:17:25,001 [INFO    ] __main__: train step 6282: loss: 0.9762, policy_loss: 1.3594, value_loss: 0.8393
2024-07-11 16:17:25,206 [INFO    ] __main__: train step 6283: loss: 0.9763, policy_loss: 1.3593, value_loss: 0.8393
2024-07-11 16:17:25,414 [INFO    ] __main__: train step 6284: loss: 0.9764, policy_loss: 1.3592, value_loss: 0.8393
2024-07-11 16:17:25,609 [INFO    ] __main__: train step 6285: loss: 0.9764, policy_loss: 1.3592, value_loss: 0.8392
2024-07-11 16:17:25,810 [INFO    ] __main__: train step 6286: loss: 0.9765, policy_loss: 1.3591, value_loss: 0.8392
2024-07-11 16:17:26,017 [INFO    ] __main__: train step 6287: loss: 0.9766, policy_loss: 1.3590, value_loss: 0.8392
2024-07-11 16:17:26,223 [INFO    ] __main__: train step 6288: loss: 0.9766, policy_loss: 1.3589, value_loss: 0.8391
2024-07-11 16:17:26,433 [INFO    ] __main__: train step 6289: loss: 0.9767, policy_loss: 1.3588, value_loss: 0.8391
2024-07-11 16:17:27,852 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:17:28,198 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:17:28,254 [INFO    ] __main__: train step 6290: loss: 0.9767, policy_loss: 1.3587, value_loss: 0.8390
2024-07-11 16:17:28,428 [INFO    ] __main__: train step 6291: loss: 0.9768, policy_loss: 1.3587, value_loss: 0.8390
2024-07-11 16:17:28,621 [INFO    ] __main__: train step 6292: loss: 0.9769, policy_loss: 1.3586, value_loss: 0.8390
2024-07-11 16:17:28,822 [INFO    ] __main__: train step 6293: loss: 0.9769, policy_loss: 1.3585, value_loss: 0.8389
2024-07-11 16:17:29,025 [INFO    ] __main__: train step 6294: loss: 0.9770, policy_loss: 1.3584, value_loss: 0.8389
2024-07-11 16:17:29,226 [INFO    ] __main__: train step 6295: loss: 0.9771, policy_loss: 1.3583, value_loss: 0.8389
2024-07-11 16:17:29,435 [INFO    ] __main__: train step 6296: loss: 0.9771, policy_loss: 1.3583, value_loss: 0.8388
2024-07-11 16:17:29,628 [INFO    ] __main__: train step 6297: loss: 0.9772, policy_loss: 1.3582, value_loss: 0.8388
2024-07-11 16:17:29,822 [INFO    ] __main__: train step 6298: loss: 0.9773, policy_loss: 1.3581, value_loss: 0.8388
2024-07-11 16:17:30,026 [INFO    ] __main__: train step 6299: loss: 0.9773, policy_loss: 1.3580, value_loss: 0.8387
2024-07-11 16:17:30,219 [INFO    ] __main__: train step 6300: loss: 0.9774, policy_loss: 1.3579, value_loss: 0.8387
2024-07-11 16:17:30,421 [INFO    ] __main__: train step 6301: loss: 0.9775, policy_loss: 1.3578, value_loss: 0.8386
2024-07-11 16:17:30,621 [INFO    ] __main__: train step 6302: loss: 0.9775, policy_loss: 1.3578, value_loss: 0.8386
2024-07-11 16:17:30,820 [INFO    ] __main__: train step 6303: loss: 0.9776, policy_loss: 1.3577, value_loss: 0.8386
2024-07-11 16:17:31,021 [INFO    ] __main__: train step 6304: loss: 0.9776, policy_loss: 1.3576, value_loss: 0.8385
2024-07-11 16:17:31,229 [INFO    ] __main__: train step 6305: loss: 0.9777, policy_loss: 1.3575, value_loss: 0.8385
2024-07-11 16:17:31,434 [INFO    ] __main__: train step 6306: loss: 0.9778, policy_loss: 1.3574, value_loss: 0.8385
2024-07-11 16:17:32,864 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:17:33,250 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:17:33,305 [INFO    ] __main__: train step 6307: loss: 0.9778, policy_loss: 1.3574, value_loss: 0.8384
2024-07-11 16:17:33,469 [INFO    ] __main__: train step 6308: loss: 0.9779, policy_loss: 1.3573, value_loss: 0.8384
2024-07-11 16:17:33,671 [INFO    ] __main__: train step 6309: loss: 0.9780, policy_loss: 1.3572, value_loss: 0.8384
2024-07-11 16:17:33,876 [INFO    ] __main__: train step 6310: loss: 0.9780, policy_loss: 1.3571, value_loss: 0.8383
2024-07-11 16:17:34,072 [INFO    ] __main__: train step 6311: loss: 0.9781, policy_loss: 1.3570, value_loss: 0.8383
2024-07-11 16:17:34,286 [INFO    ] __main__: train step 6312: loss: 0.9782, policy_loss: 1.3570, value_loss: 0.8382
2024-07-11 16:17:34,479 [INFO    ] __main__: train step 6313: loss: 0.9782, policy_loss: 1.3569, value_loss: 0.8382
2024-07-11 16:17:34,676 [INFO    ] __main__: train step 6314: loss: 0.9783, policy_loss: 1.3568, value_loss: 0.8382
2024-07-11 16:17:34,891 [INFO    ] __main__: train step 6315: loss: 0.9784, policy_loss: 1.3567, value_loss: 0.8381
2024-07-11 16:17:35,093 [INFO    ] __main__: train step 6316: loss: 0.9784, policy_loss: 1.3566, value_loss: 0.8381
2024-07-11 16:17:35,301 [INFO    ] __main__: train step 6317: loss: 0.9785, policy_loss: 1.3565, value_loss: 0.8381
2024-07-11 16:17:35,500 [INFO    ] __main__: train step 6318: loss: 0.9786, policy_loss: 1.3565, value_loss: 0.8380
2024-07-11 16:17:35,702 [INFO    ] __main__: train step 6319: loss: 0.9786, policy_loss: 1.3564, value_loss: 0.8380
2024-07-11 16:17:35,901 [INFO    ] __main__: train step 6320: loss: 0.9787, policy_loss: 1.3563, value_loss: 0.8380
2024-07-11 16:17:36,102 [INFO    ] __main__: train step 6321: loss: 0.9787, policy_loss: 1.3562, value_loss: 0.8379
2024-07-11 16:17:36,330 [INFO    ] __main__: train step 6322: loss: 0.9788, policy_loss: 1.3561, value_loss: 0.8379
2024-07-11 16:17:36,528 [INFO    ] __main__: train step 6323: loss: 0.9789, policy_loss: 1.3561, value_loss: 0.8378
2024-07-11 16:17:37,983 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:17:38,403 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:17:38,465 [INFO    ] __main__: train step 6324: loss: 0.9789, policy_loss: 1.3560, value_loss: 0.8378
2024-07-11 16:17:38,652 [INFO    ] __main__: train step 6325: loss: 0.9790, policy_loss: 1.3559, value_loss: 0.8378
2024-07-11 16:17:38,850 [INFO    ] __main__: train step 6326: loss: 0.9791, policy_loss: 1.3558, value_loss: 0.8377
2024-07-11 16:17:39,053 [INFO    ] __main__: train step 6327: loss: 0.9791, policy_loss: 1.3557, value_loss: 0.8377
2024-07-11 16:17:39,258 [INFO    ] __main__: train step 6328: loss: 0.9792, policy_loss: 1.3556, value_loss: 0.8377
2024-07-11 16:17:39,475 [INFO    ] __main__: train step 6329: loss: 0.9792, policy_loss: 1.3556, value_loss: 0.8376
2024-07-11 16:17:39,682 [INFO    ] __main__: train step 6330: loss: 0.9793, policy_loss: 1.3555, value_loss: 0.8376
2024-07-11 16:17:39,927 [INFO    ] __main__: train step 6331: loss: 0.9794, policy_loss: 1.3554, value_loss: 0.8376
2024-07-11 16:17:40,129 [INFO    ] __main__: train step 6332: loss: 0.9794, policy_loss: 1.3553, value_loss: 0.8375
2024-07-11 16:17:40,334 [INFO    ] __main__: train step 6333: loss: 0.9795, policy_loss: 1.3552, value_loss: 0.8375
2024-07-11 16:17:40,550 [INFO    ] __main__: train step 6334: loss: 0.9796, policy_loss: 1.3552, value_loss: 0.8374
2024-07-11 16:17:40,763 [INFO    ] __main__: train step 6335: loss: 0.9796, policy_loss: 1.3551, value_loss: 0.8374
2024-07-11 16:17:41,004 [INFO    ] __main__: train step 6336: loss: 0.9797, policy_loss: 1.3550, value_loss: 0.8374
2024-07-11 16:17:41,192 [INFO    ] __main__: train step 6337: loss: 0.9798, policy_loss: 1.3549, value_loss: 0.8373
2024-07-11 16:17:41,393 [INFO    ] __main__: train step 6338: loss: 0.9798, policy_loss: 1.3548, value_loss: 0.8373
2024-07-11 16:17:41,627 [INFO    ] __main__: train step 6339: loss: 0.9799, policy_loss: 1.3548, value_loss: 0.8373
2024-07-11 16:17:41,848 [INFO    ] __main__: train step 6340: loss: 0.9799, policy_loss: 1.3547, value_loss: 0.8372
2024-07-11 16:17:43,300 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:17:43,649 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:17:43,709 [INFO    ] __main__: train step 6341: loss: 0.9800, policy_loss: 1.3546, value_loss: 0.8372
2024-07-11 16:17:43,881 [INFO    ] __main__: train step 6342: loss: 0.9801, policy_loss: 1.3545, value_loss: 0.8372
2024-07-11 16:17:44,098 [INFO    ] __main__: train step 6343: loss: 0.9801, policy_loss: 1.3544, value_loss: 0.8371
2024-07-11 16:17:45,141 [INFO    ] __main__: train step 6344: loss: 0.9802, policy_loss: 1.3543, value_loss: 0.8371
2024-07-11 16:17:45,362 [INFO    ] __main__: train step 6345: loss: 0.9803, policy_loss: 1.3543, value_loss: 0.8371
2024-07-11 16:17:45,594 [INFO    ] __main__: train step 6346: loss: 0.9803, policy_loss: 1.3542, value_loss: 0.8370
2024-07-11 16:17:45,792 [INFO    ] __main__: train step 6347: loss: 0.9804, policy_loss: 1.3541, value_loss: 0.8370
2024-07-11 16:17:45,996 [INFO    ] __main__: train step 6348: loss: 0.9805, policy_loss: 1.3540, value_loss: 0.8369
2024-07-11 16:17:46,207 [INFO    ] __main__: train step 6349: loss: 0.9805, policy_loss: 1.3539, value_loss: 0.8369
2024-07-11 16:17:46,436 [INFO    ] __main__: train step 6350: loss: 0.9806, policy_loss: 1.3539, value_loss: 0.8369
2024-07-11 16:17:46,630 [INFO    ] __main__: train step 6351: loss: 0.9807, policy_loss: 1.3538, value_loss: 0.8368
2024-07-11 16:17:46,835 [INFO    ] __main__: train step 6352: loss: 0.9807, policy_loss: 1.3537, value_loss: 0.8368
2024-07-11 16:17:47,041 [INFO    ] __main__: train step 6353: loss: 0.9808, policy_loss: 1.3536, value_loss: 0.8368
2024-07-11 16:17:47,292 [INFO    ] __main__: train step 6354: loss: 0.9808, policy_loss: 1.3535, value_loss: 0.8367
2024-07-11 16:17:47,527 [INFO    ] __main__: train step 6355: loss: 0.9809, policy_loss: 1.3535, value_loss: 0.8367
2024-07-11 16:17:47,748 [INFO    ] __main__: train step 6356: loss: 0.9810, policy_loss: 1.3534, value_loss: 0.8367
2024-07-11 16:17:47,954 [INFO    ] __main__: train step 6357: loss: 0.9810, policy_loss: 1.3533, value_loss: 0.8366
2024-07-11 16:17:49,399 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:17:49,779 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:17:49,836 [INFO    ] __main__: train step 6358: loss: 0.9811, policy_loss: 1.3532, value_loss: 0.8366
2024-07-11 16:17:50,010 [INFO    ] __main__: train step 6359: loss: 0.9812, policy_loss: 1.3531, value_loss: 0.8366
2024-07-11 16:17:50,211 [INFO    ] __main__: train step 6360: loss: 0.9812, policy_loss: 1.3531, value_loss: 0.8365
2024-07-11 16:17:50,411 [INFO    ] __main__: train step 6361: loss: 0.9813, policy_loss: 1.3530, value_loss: 0.8365
2024-07-11 16:17:50,608 [INFO    ] __main__: train step 6362: loss: 0.9814, policy_loss: 1.3529, value_loss: 0.8365
2024-07-11 16:17:50,799 [INFO    ] __main__: train step 6363: loss: 0.9814, policy_loss: 1.3528, value_loss: 0.8364
2024-07-11 16:17:51,005 [INFO    ] __main__: train step 6364: loss: 0.9815, policy_loss: 1.3527, value_loss: 0.8364
2024-07-11 16:17:51,217 [INFO    ] __main__: train step 6365: loss: 0.9815, policy_loss: 1.3526, value_loss: 0.8363
2024-07-11 16:17:51,424 [INFO    ] __main__: train step 6366: loss: 0.9816, policy_loss: 1.3526, value_loss: 0.8363
2024-07-11 16:17:51,659 [INFO    ] __main__: train step 6367: loss: 0.9817, policy_loss: 1.3525, value_loss: 0.8363
2024-07-11 16:17:51,889 [INFO    ] __main__: train step 6368: loss: 0.9817, policy_loss: 1.3524, value_loss: 0.8362
2024-07-11 16:17:52,088 [INFO    ] __main__: train step 6369: loss: 0.9818, policy_loss: 1.3523, value_loss: 0.8362
2024-07-11 16:17:52,283 [INFO    ] __main__: train step 6370: loss: 0.9819, policy_loss: 1.3522, value_loss: 0.8362
2024-07-11 16:17:52,483 [INFO    ] __main__: train step 6371: loss: 0.9819, policy_loss: 1.3522, value_loss: 0.8361
2024-07-11 16:17:52,696 [INFO    ] __main__: train step 6372: loss: 0.9820, policy_loss: 1.3521, value_loss: 0.8361
2024-07-11 16:17:52,923 [INFO    ] __main__: train step 6373: loss: 0.9821, policy_loss: 1.3520, value_loss: 0.8361
2024-07-11 16:17:53,143 [INFO    ] __main__: train step 6374: loss: 0.9821, policy_loss: 1.3519, value_loss: 0.8360
2024-07-11 16:17:54,637 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:17:55,023 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:17:55,082 [INFO    ] __main__: train step 6375: loss: 0.9822, policy_loss: 1.3518, value_loss: 0.8360
2024-07-11 16:17:55,249 [INFO    ] __main__: train step 6376: loss: 0.9822, policy_loss: 1.3517, value_loss: 0.8360
2024-07-11 16:17:55,456 [INFO    ] __main__: train step 6377: loss: 0.9823, policy_loss: 1.3517, value_loss: 0.8359
2024-07-11 16:17:55,659 [INFO    ] __main__: train step 6378: loss: 0.9824, policy_loss: 1.3516, value_loss: 0.8359
2024-07-11 16:17:55,866 [INFO    ] __main__: train step 6379: loss: 0.9824, policy_loss: 1.3515, value_loss: 0.8359
2024-07-11 16:17:56,101 [INFO    ] __main__: train step 6380: loss: 0.9825, policy_loss: 1.3514, value_loss: 0.8358
2024-07-11 16:17:56,297 [INFO    ] __main__: train step 6381: loss: 0.9825, policy_loss: 1.3513, value_loss: 0.8358
2024-07-11 16:17:56,503 [INFO    ] __main__: train step 6382: loss: 0.9826, policy_loss: 1.3513, value_loss: 0.8357
2024-07-11 16:17:56,717 [INFO    ] __main__: train step 6383: loss: 0.9827, policy_loss: 1.3512, value_loss: 0.8357
2024-07-11 16:17:56,948 [INFO    ] __main__: train step 6384: loss: 0.9827, policy_loss: 1.3511, value_loss: 0.8357
2024-07-11 16:17:57,155 [INFO    ] __main__: train step 6385: loss: 0.9828, policy_loss: 1.3510, value_loss: 0.8356
2024-07-11 16:17:57,359 [INFO    ] __main__: train step 6386: loss: 0.9829, policy_loss: 1.3509, value_loss: 0.8356
2024-07-11 16:17:57,563 [INFO    ] __main__: train step 6387: loss: 0.9829, policy_loss: 1.3509, value_loss: 0.8356
2024-07-11 16:17:57,763 [INFO    ] __main__: train step 6388: loss: 0.9830, policy_loss: 1.3508, value_loss: 0.8355
2024-07-11 16:17:57,983 [INFO    ] __main__: train step 6389: loss: 0.9830, policy_loss: 1.3507, value_loss: 0.8355
2024-07-11 16:17:58,188 [INFO    ] __main__: train step 6390: loss: 0.9831, policy_loss: 1.3506, value_loss: 0.8354
2024-07-11 16:17:58,390 [INFO    ] __main__: train step 6391: loss: 0.9832, policy_loss: 1.3505, value_loss: 0.8354
2024-07-11 16:17:59,823 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:18:00,210 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:18:00,268 [INFO    ] __main__: train step 6392: loss: 0.9832, policy_loss: 1.3504, value_loss: 0.8354
2024-07-11 16:18:00,435 [INFO    ] __main__: train step 6393: loss: 0.9833, policy_loss: 1.3504, value_loss: 0.8353
2024-07-11 16:18:00,638 [INFO    ] __main__: train step 6394: loss: 0.9833, policy_loss: 1.3503, value_loss: 0.8353
2024-07-11 16:18:00,822 [INFO    ] __main__: train step 6395: loss: 0.9834, policy_loss: 1.3502, value_loss: 0.8353
2024-07-11 16:18:01,012 [INFO    ] __main__: train step 6396: loss: 0.9835, policy_loss: 1.3501, value_loss: 0.8352
2024-07-11 16:18:01,207 [INFO    ] __main__: train step 6397: loss: 0.9835, policy_loss: 1.3500, value_loss: 0.8352
2024-07-11 16:18:01,433 [INFO    ] __main__: train step 6398: loss: 0.9836, policy_loss: 1.3500, value_loss: 0.8352
2024-07-11 16:18:01,634 [INFO    ] __main__: train step 6399: loss: 0.9837, policy_loss: 1.3499, value_loss: 0.8351
2024-07-11 16:18:01,891 [INFO    ] __main__: train step 6400: loss: 0.9837, policy_loss: 1.3498, value_loss: 0.8351
2024-07-11 16:18:02,110 [INFO    ] __main__: train step 6401: loss: 0.9838, policy_loss: 1.3497, value_loss: 0.8351
2024-07-11 16:18:02,312 [INFO    ] __main__: train step 6402: loss: 0.9838, policy_loss: 1.3496, value_loss: 0.8350
2024-07-11 16:18:02,534 [INFO    ] __main__: train step 6403: loss: 0.9839, policy_loss: 1.3495, value_loss: 0.8350
2024-07-11 16:18:02,746 [INFO    ] __main__: train step 6404: loss: 0.9840, policy_loss: 1.3495, value_loss: 0.8349
2024-07-11 16:18:02,975 [INFO    ] __main__: train step 6405: loss: 0.9840, policy_loss: 1.3494, value_loss: 0.8349
2024-07-11 16:18:03,173 [INFO    ] __main__: train step 6406: loss: 0.9841, policy_loss: 1.3493, value_loss: 0.8349
2024-07-11 16:18:03,379 [INFO    ] __main__: train step 6407: loss: 0.9841, policy_loss: 1.3492, value_loss: 0.8348
2024-07-11 16:18:03,575 [INFO    ] __main__: train step 6408: loss: 0.9842, policy_loss: 1.3491, value_loss: 0.8348
2024-07-11 16:18:05,012 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:18:05,432 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:18:05,493 [INFO    ] __main__: train step 6409: loss: 0.9843, policy_loss: 1.3491, value_loss: 0.8348
2024-07-11 16:18:05,660 [INFO    ] __main__: train step 6410: loss: 0.9843, policy_loss: 1.3490, value_loss: 0.8347
2024-07-11 16:18:05,864 [INFO    ] __main__: train step 6411: loss: 0.9844, policy_loss: 1.3489, value_loss: 0.8347
2024-07-11 16:18:06,061 [INFO    ] __main__: train step 6412: loss: 0.9845, policy_loss: 1.3488, value_loss: 0.8347
2024-07-11 16:18:06,265 [INFO    ] __main__: train step 6413: loss: 0.9845, policy_loss: 1.3487, value_loss: 0.8346
2024-07-11 16:18:06,463 [INFO    ] __main__: train step 6414: loss: 0.9846, policy_loss: 1.3487, value_loss: 0.8346
2024-07-11 16:18:06,656 [INFO    ] __main__: train step 6415: loss: 0.9846, policy_loss: 1.3486, value_loss: 0.8346
2024-07-11 16:18:06,863 [INFO    ] __main__: train step 6416: loss: 0.9847, policy_loss: 1.3485, value_loss: 0.8345
2024-07-11 16:18:07,906 [INFO    ] __main__: train step 6417: loss: 0.9848, policy_loss: 1.3484, value_loss: 0.8345
2024-07-11 16:18:08,132 [INFO    ] __main__: train step 6418: loss: 0.9848, policy_loss: 1.3483, value_loss: 0.8345
2024-07-11 16:18:08,333 [INFO    ] __main__: train step 6419: loss: 0.9849, policy_loss: 1.3483, value_loss: 0.8344
2024-07-11 16:18:08,545 [INFO    ] __main__: train step 6420: loss: 0.9850, policy_loss: 1.3482, value_loss: 0.8344
2024-07-11 16:18:08,737 [INFO    ] __main__: train step 6421: loss: 0.9850, policy_loss: 1.3481, value_loss: 0.8344
2024-07-11 16:18:08,936 [INFO    ] __main__: train step 6422: loss: 0.9851, policy_loss: 1.3480, value_loss: 0.8343
2024-07-11 16:18:09,143 [INFO    ] __main__: train step 6423: loss: 0.9851, policy_loss: 1.3479, value_loss: 0.8343
2024-07-11 16:18:09,339 [INFO    ] __main__: train step 6424: loss: 0.9852, policy_loss: 1.3478, value_loss: 0.8342
2024-07-11 16:18:09,537 [INFO    ] __main__: train step 6425: loss: 0.9853, policy_loss: 1.3478, value_loss: 0.8342
2024-07-11 16:18:10,979 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:18:11,372 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:18:11,426 [INFO    ] __main__: train step 6426: loss: 0.9853, policy_loss: 1.3477, value_loss: 0.8342
2024-07-11 16:18:11,600 [INFO    ] __main__: train step 6427: loss: 0.9854, policy_loss: 1.3476, value_loss: 0.8341
2024-07-11 16:18:11,808 [INFO    ] __main__: train step 6428: loss: 0.9854, policy_loss: 1.3475, value_loss: 0.8341
2024-07-11 16:18:12,002 [INFO    ] __main__: train step 6429: loss: 0.9855, policy_loss: 1.3474, value_loss: 0.8341
2024-07-11 16:18:12,222 [INFO    ] __main__: train step 6430: loss: 0.9856, policy_loss: 1.3474, value_loss: 0.8340
2024-07-11 16:18:12,421 [INFO    ] __main__: train step 6431: loss: 0.9856, policy_loss: 1.3473, value_loss: 0.8340
2024-07-11 16:18:12,625 [INFO    ] __main__: train step 6432: loss: 0.9857, policy_loss: 1.3472, value_loss: 0.8340
2024-07-11 16:18:12,829 [INFO    ] __main__: train step 6433: loss: 0.9857, policy_loss: 1.3471, value_loss: 0.8339
2024-07-11 16:18:13,033 [INFO    ] __main__: train step 6434: loss: 0.9858, policy_loss: 1.3470, value_loss: 0.8339
2024-07-11 16:18:13,237 [INFO    ] __main__: train step 6435: loss: 0.9859, policy_loss: 1.3470, value_loss: 0.8339
2024-07-11 16:18:13,432 [INFO    ] __main__: train step 6436: loss: 0.9859, policy_loss: 1.3469, value_loss: 0.8338
2024-07-11 16:18:13,630 [INFO    ] __main__: train step 6437: loss: 0.9860, policy_loss: 1.3468, value_loss: 0.8338
2024-07-11 16:18:13,829 [INFO    ] __main__: train step 6438: loss: 0.9861, policy_loss: 1.3467, value_loss: 0.8338
2024-07-11 16:18:14,048 [INFO    ] __main__: train step 6439: loss: 0.9861, policy_loss: 1.3466, value_loss: 0.8337
2024-07-11 16:18:14,276 [INFO    ] __main__: train step 6440: loss: 0.9862, policy_loss: 1.3465, value_loss: 0.8337
2024-07-11 16:18:14,509 [INFO    ] __main__: train step 6441: loss: 0.9862, policy_loss: 1.3465, value_loss: 0.8336
2024-07-11 16:18:14,717 [INFO    ] __main__: train step 6442: loss: 0.9863, policy_loss: 1.3464, value_loss: 0.8336
2024-07-11 16:18:16,147 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:18:16,574 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:18:16,638 [INFO    ] __main__: train step 6443: loss: 0.9864, policy_loss: 1.3463, value_loss: 0.8336
2024-07-11 16:18:16,827 [INFO    ] __main__: train step 6444: loss: 0.9864, policy_loss: 1.3462, value_loss: 0.8335
2024-07-11 16:18:17,026 [INFO    ] __main__: train step 6445: loss: 0.9865, policy_loss: 1.3461, value_loss: 0.8335
2024-07-11 16:18:17,229 [INFO    ] __main__: train step 6446: loss: 0.9865, policy_loss: 1.3461, value_loss: 0.8335
2024-07-11 16:18:17,433 [INFO    ] __main__: train step 6447: loss: 0.9866, policy_loss: 1.3460, value_loss: 0.8334
2024-07-11 16:18:17,650 [INFO    ] __main__: train step 6448: loss: 0.9867, policy_loss: 1.3459, value_loss: 0.8334
2024-07-11 16:18:17,852 [INFO    ] __main__: train step 6449: loss: 0.9867, policy_loss: 1.3458, value_loss: 0.8334
2024-07-11 16:18:18,058 [INFO    ] __main__: train step 6450: loss: 0.9868, policy_loss: 1.3457, value_loss: 0.8333
2024-07-11 16:18:18,258 [INFO    ] __main__: train step 6451: loss: 0.9868, policy_loss: 1.3457, value_loss: 0.8333
2024-07-11 16:18:18,483 [INFO    ] __main__: train step 6452: loss: 0.9869, policy_loss: 1.3456, value_loss: 0.8333
2024-07-11 16:18:18,712 [INFO    ] __main__: train step 6453: loss: 0.9870, policy_loss: 1.3455, value_loss: 0.8332
2024-07-11 16:18:18,935 [INFO    ] __main__: train step 6454: loss: 0.9870, policy_loss: 1.3454, value_loss: 0.8332
2024-07-11 16:18:19,163 [INFO    ] __main__: train step 6455: loss: 0.9871, policy_loss: 1.3453, value_loss: 0.8332
2024-07-11 16:18:19,368 [INFO    ] __main__: train step 6456: loss: 0.9871, policy_loss: 1.3452, value_loss: 0.8331
2024-07-11 16:18:19,577 [INFO    ] __main__: train step 6457: loss: 0.9872, policy_loss: 1.3452, value_loss: 0.8331
2024-07-11 16:18:19,793 [INFO    ] __main__: train step 6458: loss: 0.9873, policy_loss: 1.3451, value_loss: 0.8331
2024-07-11 16:18:20,025 [INFO    ] __main__: train step 6459: loss: 0.9873, policy_loss: 1.3450, value_loss: 0.8330
2024-07-11 16:18:21,481 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:18:21,871 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:18:21,933 [INFO    ] __main__: train step 6460: loss: 0.9874, policy_loss: 1.3449, value_loss: 0.8330
2024-07-11 16:18:22,097 [INFO    ] __main__: train step 6461: loss: 0.9874, policy_loss: 1.3448, value_loss: 0.8330
2024-07-11 16:18:22,293 [INFO    ] __main__: train step 6462: loss: 0.9875, policy_loss: 1.3448, value_loss: 0.8329
2024-07-11 16:18:22,496 [INFO    ] __main__: train step 6463: loss: 0.9876, policy_loss: 1.3447, value_loss: 0.8329
2024-07-11 16:18:22,697 [INFO    ] __main__: train step 6464: loss: 0.9876, policy_loss: 1.3446, value_loss: 0.8329
2024-07-11 16:18:22,904 [INFO    ] __main__: train step 6465: loss: 0.9877, policy_loss: 1.3445, value_loss: 0.8328
2024-07-11 16:18:23,119 [INFO    ] __main__: train step 6466: loss: 0.9878, policy_loss: 1.3444, value_loss: 0.8328
2024-07-11 16:18:23,315 [INFO    ] __main__: train step 6467: loss: 0.9878, policy_loss: 1.3444, value_loss: 0.8328
2024-07-11 16:18:23,532 [INFO    ] __main__: train step 6468: loss: 0.9879, policy_loss: 1.3443, value_loss: 0.8327
2024-07-11 16:18:23,746 [INFO    ] __main__: train step 6469: loss: 0.9879, policy_loss: 1.3442, value_loss: 0.8327
2024-07-11 16:18:23,950 [INFO    ] __main__: train step 6470: loss: 0.9880, policy_loss: 1.3441, value_loss: 0.8327
2024-07-11 16:18:24,149 [INFO    ] __main__: train step 6471: loss: 0.9881, policy_loss: 1.3440, value_loss: 0.8326
2024-07-11 16:18:24,344 [INFO    ] __main__: train step 6472: loss: 0.9881, policy_loss: 1.3440, value_loss: 0.8326
2024-07-11 16:18:24,572 [INFO    ] __main__: train step 6473: loss: 0.9882, policy_loss: 1.3439, value_loss: 0.8326
2024-07-11 16:18:24,771 [INFO    ] __main__: train step 6474: loss: 0.9882, policy_loss: 1.3438, value_loss: 0.8325
2024-07-11 16:18:24,976 [INFO    ] __main__: train step 6475: loss: 0.9883, policy_loss: 1.3437, value_loss: 0.8325
2024-07-11 16:18:25,165 [INFO    ] __main__: train step 6476: loss: 0.9884, policy_loss: 1.3436, value_loss: 0.8324
2024-07-11 16:18:26,605 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:18:27,014 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:18:27,074 [INFO    ] __main__: train step 6477: loss: 0.9884, policy_loss: 1.3436, value_loss: 0.8324
2024-07-11 16:18:27,246 [INFO    ] __main__: train step 6478: loss: 0.9885, policy_loss: 1.3435, value_loss: 0.8324
2024-07-11 16:18:27,472 [INFO    ] __main__: train step 6479: loss: 0.9886, policy_loss: 1.3434, value_loss: 0.8323
2024-07-11 16:18:27,663 [INFO    ] __main__: train step 6480: loss: 0.9886, policy_loss: 1.3433, value_loss: 0.8323
2024-07-11 16:18:27,862 [INFO    ] __main__: train step 6481: loss: 0.9887, policy_loss: 1.3432, value_loss: 0.8323
2024-07-11 16:18:28,064 [INFO    ] __main__: train step 6482: loss: 0.9887, policy_loss: 1.3432, value_loss: 0.8322
2024-07-11 16:18:28,270 [INFO    ] __main__: train step 6483: loss: 0.9888, policy_loss: 1.3431, value_loss: 0.8322
2024-07-11 16:18:28,469 [INFO    ] __main__: train step 6484: loss: 0.9889, policy_loss: 1.3430, value_loss: 0.8322
2024-07-11 16:18:28,672 [INFO    ] __main__: train step 6485: loss: 0.9889, policy_loss: 1.3429, value_loss: 0.8321
2024-07-11 16:18:28,891 [INFO    ] __main__: train step 6486: loss: 0.9890, policy_loss: 1.3428, value_loss: 0.8321
2024-07-11 16:18:29,095 [INFO    ] __main__: train step 6487: loss: 0.9890, policy_loss: 1.3427, value_loss: 0.8321
2024-07-11 16:18:29,295 [INFO    ] __main__: train step 6488: loss: 0.9891, policy_loss: 1.3427, value_loss: 0.8320
2024-07-11 16:18:29,495 [INFO    ] __main__: train step 6489: loss: 0.9891, policy_loss: 1.3426, value_loss: 0.8320
2024-07-11 16:18:30,542 [INFO    ] __main__: train step 6490: loss: 0.9892, policy_loss: 1.3425, value_loss: 0.8320
2024-07-11 16:18:30,743 [INFO    ] __main__: train step 6491: loss: 0.9893, policy_loss: 1.3424, value_loss: 0.8319
2024-07-11 16:18:30,936 [INFO    ] __main__: train step 6492: loss: 0.9893, policy_loss: 1.3423, value_loss: 0.8319
2024-07-11 16:18:31,133 [INFO    ] __main__: train step 6493: loss: 0.9894, policy_loss: 1.3423, value_loss: 0.8319
2024-07-11 16:18:32,566 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:18:32,955 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:18:33,008 [INFO    ] __main__: train step 6494: loss: 0.9894, policy_loss: 1.3422, value_loss: 0.8318
2024-07-11 16:18:33,168 [INFO    ] __main__: train step 6495: loss: 0.9895, policy_loss: 1.3421, value_loss: 0.8318
2024-07-11 16:18:33,378 [INFO    ] __main__: train step 6496: loss: 0.9896, policy_loss: 1.3420, value_loss: 0.8318
2024-07-11 16:18:33,584 [INFO    ] __main__: train step 6497: loss: 0.9896, policy_loss: 1.3419, value_loss: 0.8317
2024-07-11 16:18:33,781 [INFO    ] __main__: train step 6498: loss: 0.9897, policy_loss: 1.3419, value_loss: 0.8317
2024-07-11 16:18:33,983 [INFO    ] __main__: train step 6499: loss: 0.9897, policy_loss: 1.3418, value_loss: 0.8317
2024-07-11 16:18:34,183 [INFO    ] __main__: train step 6500: loss: 0.9898, policy_loss: 1.3417, value_loss: 0.8316
2024-07-11 16:18:34,399 [INFO    ] __main__: train step 6501: loss: 0.9899, policy_loss: 1.3416, value_loss: 0.8316
2024-07-11 16:18:34,588 [INFO    ] __main__: train step 6502: loss: 0.9899, policy_loss: 1.3415, value_loss: 0.8316
2024-07-11 16:18:34,793 [INFO    ] __main__: train step 6503: loss: 0.9900, policy_loss: 1.3415, value_loss: 0.8315
2024-07-11 16:18:34,986 [INFO    ] __main__: train step 6504: loss: 0.9900, policy_loss: 1.3414, value_loss: 0.8315
2024-07-11 16:18:35,192 [INFO    ] __main__: train step 6505: loss: 0.9901, policy_loss: 1.3413, value_loss: 0.8314
2024-07-11 16:18:35,389 [INFO    ] __main__: train step 6506: loss: 0.9902, policy_loss: 1.3412, value_loss: 0.8314
2024-07-11 16:18:35,608 [INFO    ] __main__: train step 6507: loss: 0.9902, policy_loss: 1.3411, value_loss: 0.8314
2024-07-11 16:18:35,847 [INFO    ] __main__: train step 6508: loss: 0.9903, policy_loss: 1.3411, value_loss: 0.8313
2024-07-11 16:18:36,042 [INFO    ] __main__: train step 6509: loss: 0.9903, policy_loss: 1.3410, value_loss: 0.8313
2024-07-11 16:18:36,242 [INFO    ] __main__: train step 6510: loss: 0.9904, policy_loss: 1.3409, value_loss: 0.8313
2024-07-11 16:18:37,692 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:18:38,084 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:18:38,143 [INFO    ] __main__: train step 6511: loss: 0.9905, policy_loss: 1.3408, value_loss: 0.8312
2024-07-11 16:18:38,316 [INFO    ] __main__: train step 6512: loss: 0.9905, policy_loss: 1.3407, value_loss: 0.8312
2024-07-11 16:18:38,526 [INFO    ] __main__: train step 6513: loss: 0.9906, policy_loss: 1.3407, value_loss: 0.8312
2024-07-11 16:18:38,723 [INFO    ] __main__: train step 6514: loss: 0.9906, policy_loss: 1.3406, value_loss: 0.8311
2024-07-11 16:18:38,924 [INFO    ] __main__: train step 6515: loss: 0.9907, policy_loss: 1.3405, value_loss: 0.8311
2024-07-11 16:18:39,129 [INFO    ] __main__: train step 6516: loss: 0.9908, policy_loss: 1.3404, value_loss: 0.8311
2024-07-11 16:18:39,334 [INFO    ] __main__: train step 6517: loss: 0.9908, policy_loss: 1.3403, value_loss: 0.8310
2024-07-11 16:18:39,579 [INFO    ] __main__: train step 6518: loss: 0.9909, policy_loss: 1.3403, value_loss: 0.8310
2024-07-11 16:18:39,788 [INFO    ] __main__: train step 6519: loss: 0.9909, policy_loss: 1.3402, value_loss: 0.8310
2024-07-11 16:18:40,001 [INFO    ] __main__: train step 6520: loss: 0.9910, policy_loss: 1.3401, value_loss: 0.8309
2024-07-11 16:18:40,209 [INFO    ] __main__: train step 6521: loss: 0.9910, policy_loss: 1.3400, value_loss: 0.8309
2024-07-11 16:18:40,415 [INFO    ] __main__: train step 6522: loss: 0.9911, policy_loss: 1.3399, value_loss: 0.8309
2024-07-11 16:18:40,620 [INFO    ] __main__: train step 6523: loss: 0.9912, policy_loss: 1.3398, value_loss: 0.8308
2024-07-11 16:18:40,839 [INFO    ] __main__: train step 6524: loss: 0.9912, policy_loss: 1.3398, value_loss: 0.8308
2024-07-11 16:18:41,064 [INFO    ] __main__: train step 6525: loss: 0.9913, policy_loss: 1.3397, value_loss: 0.8308
2024-07-11 16:18:41,270 [INFO    ] __main__: train step 6526: loss: 0.9913, policy_loss: 1.3396, value_loss: 0.8307
2024-07-11 16:18:41,522 [INFO    ] __main__: train step 6527: loss: 0.9914, policy_loss: 1.3395, value_loss: 0.8307
2024-07-11 16:18:42,953 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:18:43,324 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:18:43,379 [INFO    ] __main__: train step 6528: loss: 0.9915, policy_loss: 1.3394, value_loss: 0.8307
2024-07-11 16:18:43,557 [INFO    ] __main__: train step 6529: loss: 0.9915, policy_loss: 1.3394, value_loss: 0.8306
2024-07-11 16:18:43,757 [INFO    ] __main__: train step 6530: loss: 0.9916, policy_loss: 1.3393, value_loss: 0.8306
2024-07-11 16:18:43,968 [INFO    ] __main__: train step 6531: loss: 0.9916, policy_loss: 1.3392, value_loss: 0.8306
2024-07-11 16:18:44,175 [INFO    ] __main__: train step 6532: loss: 0.9917, policy_loss: 1.3391, value_loss: 0.8305
2024-07-11 16:18:44,367 [INFO    ] __main__: train step 6533: loss: 0.9918, policy_loss: 1.3390, value_loss: 0.8305
2024-07-11 16:18:44,579 [INFO    ] __main__: train step 6534: loss: 0.9918, policy_loss: 1.3390, value_loss: 0.8305
2024-07-11 16:18:44,782 [INFO    ] __main__: train step 6535: loss: 0.9919, policy_loss: 1.3389, value_loss: 0.8304
2024-07-11 16:18:44,980 [INFO    ] __main__: train step 6536: loss: 0.9919, policy_loss: 1.3388, value_loss: 0.8304
2024-07-11 16:18:45,180 [INFO    ] __main__: train step 6537: loss: 0.9920, policy_loss: 1.3387, value_loss: 0.8304
2024-07-11 16:18:45,394 [INFO    ] __main__: train step 6538: loss: 0.9921, policy_loss: 1.3386, value_loss: 0.8303
2024-07-11 16:18:45,600 [INFO    ] __main__: train step 6539: loss: 0.9921, policy_loss: 1.3386, value_loss: 0.8303
2024-07-11 16:18:45,799 [INFO    ] __main__: train step 6540: loss: 0.9922, policy_loss: 1.3385, value_loss: 0.8303
2024-07-11 16:18:45,999 [INFO    ] __main__: train step 6541: loss: 0.9922, policy_loss: 1.3384, value_loss: 0.8302
2024-07-11 16:18:46,217 [INFO    ] __main__: train step 6542: loss: 0.9923, policy_loss: 1.3383, value_loss: 0.8302
2024-07-11 16:18:46,451 [INFO    ] __main__: train step 6543: loss: 0.9924, policy_loss: 1.3382, value_loss: 0.8302
2024-07-11 16:18:46,685 [INFO    ] __main__: train step 6544: loss: 0.9924, policy_loss: 1.3382, value_loss: 0.8301
2024-07-11 16:18:48,109 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:18:48,501 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:18:48,555 [INFO    ] __main__: train step 6545: loss: 0.9925, policy_loss: 1.3381, value_loss: 0.8301
2024-07-11 16:18:48,719 [INFO    ] __main__: train step 6546: loss: 0.9925, policy_loss: 1.3380, value_loss: 0.8301
2024-07-11 16:18:48,928 [INFO    ] __main__: train step 6547: loss: 0.9926, policy_loss: 1.3379, value_loss: 0.8300
2024-07-11 16:18:49,131 [INFO    ] __main__: train step 6548: loss: 0.9926, policy_loss: 1.3378, value_loss: 0.8300
2024-07-11 16:18:49,329 [INFO    ] __main__: train step 6549: loss: 0.9927, policy_loss: 1.3378, value_loss: 0.8300
2024-07-11 16:18:49,533 [INFO    ] __main__: train step 6550: loss: 0.9928, policy_loss: 1.3377, value_loss: 0.8299
2024-07-11 16:18:49,736 [INFO    ] __main__: train step 6551: loss: 0.9928, policy_loss: 1.3376, value_loss: 0.8299
2024-07-11 16:18:49,946 [INFO    ] __main__: train step 6552: loss: 0.9929, policy_loss: 1.3375, value_loss: 0.8299
2024-07-11 16:18:50,151 [INFO    ] __main__: train step 6553: loss: 0.9929, policy_loss: 1.3374, value_loss: 0.8298
2024-07-11 16:18:50,356 [INFO    ] __main__: train step 6554: loss: 0.9930, policy_loss: 1.3373, value_loss: 0.8298
2024-07-11 16:18:50,557 [INFO    ] __main__: train step 6555: loss: 0.9931, policy_loss: 1.3373, value_loss: 0.8298
2024-07-11 16:18:50,759 [INFO    ] __main__: train step 6556: loss: 0.9931, policy_loss: 1.3372, value_loss: 0.8297
2024-07-11 16:18:50,974 [INFO    ] __main__: train step 6557: loss: 0.9932, policy_loss: 1.3371, value_loss: 0.8297
2024-07-11 16:18:51,171 [INFO    ] __main__: train step 6558: loss: 0.9932, policy_loss: 1.3370, value_loss: 0.8297
2024-07-11 16:18:51,371 [INFO    ] __main__: train step 6559: loss: 0.9933, policy_loss: 1.3369, value_loss: 0.8296
2024-07-11 16:18:51,606 [INFO    ] __main__: train step 6560: loss: 0.9933, policy_loss: 1.3369, value_loss: 0.8296
2024-07-11 16:18:51,803 [INFO    ] __main__: train step 6561: loss: 0.9934, policy_loss: 1.3368, value_loss: 0.8296
2024-07-11 16:18:53,235 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:18:53,607 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:18:53,661 [INFO    ] __main__: train step 6562: loss: 0.9935, policy_loss: 1.3367, value_loss: 0.8295
2024-07-11 16:18:54,673 [INFO    ] __main__: train step 6563: loss: 0.9935, policy_loss: 1.3366, value_loss: 0.8295
2024-07-11 16:18:54,887 [INFO    ] __main__: train step 6564: loss: 0.9936, policy_loss: 1.3365, value_loss: 0.8295
2024-07-11 16:18:55,098 [INFO    ] __main__: train step 6565: loss: 0.9936, policy_loss: 1.3365, value_loss: 0.8294
2024-07-11 16:18:55,304 [INFO    ] __main__: train step 6566: loss: 0.9937, policy_loss: 1.3364, value_loss: 0.8294
2024-07-11 16:18:55,508 [INFO    ] __main__: train step 6567: loss: 0.9937, policy_loss: 1.3363, value_loss: 0.8293
2024-07-11 16:18:55,734 [INFO    ] __main__: train step 6568: loss: 0.9938, policy_loss: 1.3362, value_loss: 0.8293
2024-07-11 16:18:55,949 [INFO    ] __main__: train step 6569: loss: 0.9938, policy_loss: 1.3361, value_loss: 0.8293
2024-07-11 16:18:56,166 [INFO    ] __main__: train step 6570: loss: 0.9939, policy_loss: 1.3361, value_loss: 0.8292
2024-07-11 16:18:56,371 [INFO    ] __main__: train step 6571: loss: 0.9940, policy_loss: 1.3360, value_loss: 0.8292
2024-07-11 16:18:56,603 [INFO    ] __main__: train step 6572: loss: 0.9940, policy_loss: 1.3359, value_loss: 0.8292
2024-07-11 16:18:56,818 [INFO    ] __main__: train step 6573: loss: 0.9941, policy_loss: 1.3358, value_loss: 0.8292
2024-07-11 16:18:57,060 [INFO    ] __main__: train step 6574: loss: 0.9941, policy_loss: 1.3357, value_loss: 0.8291
2024-07-11 16:18:57,291 [INFO    ] __main__: train step 6575: loss: 0.9942, policy_loss: 1.3357, value_loss: 0.8291
2024-07-11 16:18:57,498 [INFO    ] __main__: train step 6576: loss: 0.9943, policy_loss: 1.3356, value_loss: 0.8291
2024-07-11 16:18:57,708 [INFO    ] __main__: train step 6577: loss: 0.9943, policy_loss: 1.3355, value_loss: 0.8290
2024-07-11 16:18:57,944 [INFO    ] __main__: train step 6578: loss: 0.9944, policy_loss: 1.3354, value_loss: 0.8290
2024-07-11 16:18:59,422 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:18:59,787 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:18:59,845 [INFO    ] __main__: train step 6579: loss: 0.9944, policy_loss: 1.3353, value_loss: 0.8290
2024-07-11 16:19:00,026 [INFO    ] __main__: train step 6580: loss: 0.9945, policy_loss: 1.3353, value_loss: 0.8289
2024-07-11 16:19:00,231 [INFO    ] __main__: train step 6581: loss: 0.9946, policy_loss: 1.3352, value_loss: 0.8289
2024-07-11 16:19:00,443 [INFO    ] __main__: train step 6582: loss: 0.9946, policy_loss: 1.3351, value_loss: 0.8288
2024-07-11 16:19:00,656 [INFO    ] __main__: train step 6583: loss: 0.9947, policy_loss: 1.3350, value_loss: 0.8288
2024-07-11 16:19:00,862 [INFO    ] __main__: train step 6584: loss: 0.9947, policy_loss: 1.3349, value_loss: 0.8288
2024-07-11 16:19:01,070 [INFO    ] __main__: train step 6585: loss: 0.9948, policy_loss: 1.3349, value_loss: 0.8287
2024-07-11 16:19:01,268 [INFO    ] __main__: train step 6586: loss: 0.9948, policy_loss: 1.3348, value_loss: 0.8287
2024-07-11 16:19:01,479 [INFO    ] __main__: train step 6587: loss: 0.9949, policy_loss: 1.3347, value_loss: 0.8287
2024-07-11 16:19:01,682 [INFO    ] __main__: train step 6588: loss: 0.9950, policy_loss: 1.3346, value_loss: 0.8286
2024-07-11 16:19:01,905 [INFO    ] __main__: train step 6589: loss: 0.9950, policy_loss: 1.3345, value_loss: 0.8286
2024-07-11 16:19:02,129 [INFO    ] __main__: train step 6590: loss: 0.9951, policy_loss: 1.3345, value_loss: 0.8286
2024-07-11 16:19:02,336 [INFO    ] __main__: train step 6591: loss: 0.9951, policy_loss: 1.3344, value_loss: 0.8285
2024-07-11 16:19:02,552 [INFO    ] __main__: train step 6592: loss: 0.9952, policy_loss: 1.3343, value_loss: 0.8285
2024-07-11 16:19:02,777 [INFO    ] __main__: train step 6593: loss: 0.9952, policy_loss: 1.3342, value_loss: 0.8285
2024-07-11 16:19:02,976 [INFO    ] __main__: train step 6594: loss: 0.9953, policy_loss: 1.3341, value_loss: 0.8284
2024-07-11 16:19:03,177 [INFO    ] __main__: train step 6595: loss: 0.9954, policy_loss: 1.3341, value_loss: 0.8284
2024-07-11 16:19:04,610 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:19:04,995 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:19:05,051 [INFO    ] __main__: train step 6596: loss: 0.9954, policy_loss: 1.3340, value_loss: 0.8284
2024-07-11 16:19:05,234 [INFO    ] __main__: train step 6597: loss: 0.9955, policy_loss: 1.3339, value_loss: 0.8283
2024-07-11 16:19:05,436 [INFO    ] __main__: train step 6598: loss: 0.9955, policy_loss: 1.3338, value_loss: 0.8283
2024-07-11 16:19:05,664 [INFO    ] __main__: train step 6599: loss: 0.9956, policy_loss: 1.3337, value_loss: 0.8283
2024-07-11 16:19:05,886 [INFO    ] __main__: train step 6600: loss: 0.9957, policy_loss: 1.3337, value_loss: 0.8282
2024-07-11 16:19:06,088 [INFO    ] __main__: train step 6601: loss: 0.9957, policy_loss: 1.3336, value_loss: 0.8282
2024-07-11 16:19:06,297 [INFO    ] __main__: train step 6602: loss: 0.9958, policy_loss: 1.3335, value_loss: 0.8282
2024-07-11 16:19:06,491 [INFO    ] __main__: train step 6603: loss: 0.9958, policy_loss: 1.3334, value_loss: 0.8281
2024-07-11 16:19:06,722 [INFO    ] __main__: train step 6604: loss: 0.9959, policy_loss: 1.3334, value_loss: 0.8281
2024-07-11 16:19:06,930 [INFO    ] __main__: train step 6605: loss: 0.9959, policy_loss: 1.3333, value_loss: 0.8281
2024-07-11 16:19:07,125 [INFO    ] __main__: train step 6606: loss: 0.9960, policy_loss: 1.3332, value_loss: 0.8280
2024-07-11 16:19:07,321 [INFO    ] __main__: train step 6607: loss: 0.9960, policy_loss: 1.3331, value_loss: 0.8280
2024-07-11 16:19:07,513 [INFO    ] __main__: train step 6608: loss: 0.9961, policy_loss: 1.3330, value_loss: 0.8280
2024-07-11 16:19:07,715 [INFO    ] __main__: train step 6609: loss: 0.9962, policy_loss: 1.3329, value_loss: 0.8279
2024-07-11 16:19:07,922 [INFO    ] __main__: train step 6610: loss: 0.9962, policy_loss: 1.3329, value_loss: 0.8279
2024-07-11 16:19:08,146 [INFO    ] __main__: train step 6611: loss: 0.9963, policy_loss: 1.3328, value_loss: 0.8279
2024-07-11 16:19:08,379 [INFO    ] __main__: train step 6612: loss: 0.9963, policy_loss: 1.3327, value_loss: 0.8278
2024-07-11 16:19:09,827 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:19:10,255 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:19:10,315 [INFO    ] __main__: train step 6613: loss: 0.9964, policy_loss: 1.3326, value_loss: 0.8278
2024-07-11 16:19:10,485 [INFO    ] __main__: train step 6614: loss: 0.9964, policy_loss: 1.3325, value_loss: 0.8278
2024-07-11 16:19:10,688 [INFO    ] __main__: train step 6615: loss: 0.9965, policy_loss: 1.3325, value_loss: 0.8277
2024-07-11 16:19:10,921 [INFO    ] __main__: train step 6616: loss: 0.9966, policy_loss: 1.3324, value_loss: 0.8277
2024-07-11 16:19:11,156 [INFO    ] __main__: train step 6617: loss: 0.9966, policy_loss: 1.3323, value_loss: 0.8277
2024-07-11 16:19:11,397 [INFO    ] __main__: train step 6618: loss: 0.9967, policy_loss: 1.3322, value_loss: 0.8277
2024-07-11 16:19:11,613 [INFO    ] __main__: train step 6619: loss: 0.9967, policy_loss: 1.3321, value_loss: 0.8276
2024-07-11 16:19:11,803 [INFO    ] __main__: train step 6620: loss: 0.9968, policy_loss: 1.3321, value_loss: 0.8276
2024-07-11 16:19:12,010 [INFO    ] __main__: train step 6621: loss: 0.9968, policy_loss: 1.3320, value_loss: 0.8276
2024-07-11 16:19:12,210 [INFO    ] __main__: train step 6622: loss: 0.9969, policy_loss: 1.3319, value_loss: 0.8275
2024-07-11 16:19:12,415 [INFO    ] __main__: train step 6623: loss: 0.9970, policy_loss: 1.3318, value_loss: 0.8275
2024-07-11 16:19:12,615 [INFO    ] __main__: train step 6624: loss: 0.9970, policy_loss: 1.3317, value_loss: 0.8275
2024-07-11 16:19:12,809 [INFO    ] __main__: train step 6625: loss: 0.9971, policy_loss: 1.3317, value_loss: 0.8274
2024-07-11 16:19:13,017 [INFO    ] __main__: train step 6626: loss: 0.9971, policy_loss: 1.3316, value_loss: 0.8274
2024-07-11 16:19:13,219 [INFO    ] __main__: train step 6627: loss: 0.9972, policy_loss: 1.3315, value_loss: 0.8274
2024-07-11 16:19:13,425 [INFO    ] __main__: train step 6628: loss: 0.9972, policy_loss: 1.3314, value_loss: 0.8273
2024-07-11 16:19:13,623 [INFO    ] __main__: train step 6629: loss: 0.9973, policy_loss: 1.3313, value_loss: 0.8273
2024-07-11 16:19:15,072 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:19:15,424 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:19:15,484 [INFO    ] __main__: train step 6630: loss: 0.9974, policy_loss: 1.3313, value_loss: 0.8273
2024-07-11 16:19:15,661 [INFO    ] __main__: train step 6631: loss: 0.9974, policy_loss: 1.3312, value_loss: 0.8272
2024-07-11 16:19:15,856 [INFO    ] __main__: train step 6632: loss: 0.9975, policy_loss: 1.3311, value_loss: 0.8272
2024-07-11 16:19:16,059 [INFO    ] __main__: train step 6633: loss: 0.9975, policy_loss: 1.3310, value_loss: 0.8272
2024-07-11 16:19:16,260 [INFO    ] __main__: train step 6634: loss: 0.9976, policy_loss: 1.3309, value_loss: 0.8271
2024-07-11 16:19:16,480 [INFO    ] __main__: train step 6635: loss: 0.9976, policy_loss: 1.3309, value_loss: 0.8271
2024-07-11 16:19:16,677 [INFO    ] __main__: train step 6636: loss: 0.9977, policy_loss: 1.3308, value_loss: 0.8271
2024-07-11 16:19:16,885 [INFO    ] __main__: train step 6637: loss: 0.9978, policy_loss: 1.3307, value_loss: 0.8270
2024-07-11 16:19:17,935 [INFO    ] __main__: train step 6638: loss: 0.9978, policy_loss: 1.3306, value_loss: 0.8270
2024-07-11 16:19:18,148 [INFO    ] __main__: train step 6639: loss: 0.9979, policy_loss: 1.3305, value_loss: 0.8270
2024-07-11 16:19:18,349 [INFO    ] __main__: train step 6640: loss: 0.9979, policy_loss: 1.3305, value_loss: 0.8269
2024-07-11 16:19:18,563 [INFO    ] __main__: train step 6641: loss: 0.9980, policy_loss: 1.3304, value_loss: 0.8269
2024-07-11 16:19:18,755 [INFO    ] __main__: train step 6642: loss: 0.9980, policy_loss: 1.3303, value_loss: 0.8269
2024-07-11 16:19:18,964 [INFO    ] __main__: train step 6643: loss: 0.9981, policy_loss: 1.3302, value_loss: 0.8268
2024-07-11 16:19:19,160 [INFO    ] __main__: train step 6644: loss: 0.9981, policy_loss: 1.3301, value_loss: 0.8268
2024-07-11 16:19:19,357 [INFO    ] __main__: train step 6645: loss: 0.9982, policy_loss: 1.3301, value_loss: 0.8268
2024-07-11 16:19:19,553 [INFO    ] __main__: train step 6646: loss: 0.9983, policy_loss: 1.3300, value_loss: 0.8267
2024-07-11 16:19:21,000 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:19:21,458 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:19:21,521 [INFO    ] __main__: train step 6647: loss: 0.9983, policy_loss: 1.3299, value_loss: 0.8267
2024-07-11 16:19:21,695 [INFO    ] __main__: train step 6648: loss: 0.9984, policy_loss: 1.3298, value_loss: 0.8267
2024-07-11 16:19:21,911 [INFO    ] __main__: train step 6649: loss: 0.9984, policy_loss: 1.3297, value_loss: 0.8266
2024-07-11 16:19:22,104 [INFO    ] __main__: train step 6650: loss: 0.9985, policy_loss: 1.3297, value_loss: 0.8266
2024-07-11 16:19:22,295 [INFO    ] __main__: train step 6651: loss: 0.9985, policy_loss: 1.3296, value_loss: 0.8266
2024-07-11 16:19:22,522 [INFO    ] __main__: train step 6652: loss: 0.9986, policy_loss: 1.3295, value_loss: 0.8265
2024-07-11 16:19:22,722 [INFO    ] __main__: train step 6653: loss: 0.9986, policy_loss: 1.3294, value_loss: 0.8265
2024-07-11 16:19:22,938 [INFO    ] __main__: train step 6654: loss: 0.9987, policy_loss: 1.3293, value_loss: 0.8265
2024-07-11 16:19:23,169 [INFO    ] __main__: train step 6655: loss: 0.9988, policy_loss: 1.3293, value_loss: 0.8264
2024-07-11 16:19:23,382 [INFO    ] __main__: train step 6656: loss: 0.9988, policy_loss: 1.3292, value_loss: 0.8264
2024-07-11 16:19:23,587 [INFO    ] __main__: train step 6657: loss: 0.9989, policy_loss: 1.3291, value_loss: 0.8264
2024-07-11 16:19:23,783 [INFO    ] __main__: train step 6658: loss: 0.9989, policy_loss: 1.3290, value_loss: 0.8263
2024-07-11 16:19:23,986 [INFO    ] __main__: train step 6659: loss: 0.9990, policy_loss: 1.3290, value_loss: 0.8263
2024-07-11 16:19:24,178 [INFO    ] __main__: train step 6660: loss: 0.9990, policy_loss: 1.3289, value_loss: 0.8263
2024-07-11 16:19:24,384 [INFO    ] __main__: train step 6661: loss: 0.9991, policy_loss: 1.3288, value_loss: 0.8262
2024-07-11 16:19:24,582 [INFO    ] __main__: train step 6662: loss: 0.9992, policy_loss: 1.3287, value_loss: 0.8262
2024-07-11 16:19:24,777 [INFO    ] __main__: train step 6663: loss: 0.9992, policy_loss: 1.3286, value_loss: 0.8262
2024-07-11 16:19:26,208 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:19:26,664 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:19:26,729 [INFO    ] __main__: train step 6664: loss: 0.9993, policy_loss: 1.3286, value_loss: 0.8261
2024-07-11 16:19:26,896 [INFO    ] __main__: train step 6665: loss: 0.9993, policy_loss: 1.3285, value_loss: 0.8261
2024-07-11 16:19:27,098 [INFO    ] __main__: train step 6666: loss: 0.9994, policy_loss: 1.3284, value_loss: 0.8261
2024-07-11 16:19:27,290 [INFO    ] __main__: train step 6667: loss: 0.9994, policy_loss: 1.3283, value_loss: 0.8260
2024-07-11 16:19:27,494 [INFO    ] __main__: train step 6668: loss: 0.9995, policy_loss: 1.3282, value_loss: 0.8260
2024-07-11 16:19:27,695 [INFO    ] __main__: train step 6669: loss: 0.9995, policy_loss: 1.3282, value_loss: 0.8260
2024-07-11 16:19:27,902 [INFO    ] __main__: train step 6670: loss: 0.9996, policy_loss: 1.3281, value_loss: 0.8259
2024-07-11 16:19:28,102 [INFO    ] __main__: train step 6671: loss: 0.9996, policy_loss: 1.3280, value_loss: 0.8259
2024-07-11 16:19:28,302 [INFO    ] __main__: train step 6672: loss: 0.9997, policy_loss: 1.3279, value_loss: 0.8259
2024-07-11 16:19:28,503 [INFO    ] __main__: train step 6673: loss: 0.9998, policy_loss: 1.3278, value_loss: 0.8258
2024-07-11 16:19:28,705 [INFO    ] __main__: train step 6674: loss: 0.9998, policy_loss: 1.3278, value_loss: 0.8258
2024-07-11 16:19:28,917 [INFO    ] __main__: train step 6675: loss: 0.9999, policy_loss: 1.3277, value_loss: 0.8258
2024-07-11 16:19:29,157 [INFO    ] __main__: train step 6676: loss: 0.9999, policy_loss: 1.3276, value_loss: 0.8257
2024-07-11 16:19:29,387 [INFO    ] __main__: train step 6677: loss: 1.0000, policy_loss: 1.3275, value_loss: 0.8257
2024-07-11 16:19:29,602 [INFO    ] __main__: train step 6678: loss: 1.0000, policy_loss: 1.3274, value_loss: 0.8257
2024-07-11 16:19:29,827 [INFO    ] __main__: train step 6679: loss: 1.0001, policy_loss: 1.3274, value_loss: 0.8256
2024-07-11 16:19:30,029 [INFO    ] __main__: train step 6680: loss: 1.0002, policy_loss: 1.3273, value_loss: 0.8256
2024-07-11 16:19:31,473 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:19:31,888 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:19:31,943 [INFO    ] __main__: train step 6681: loss: 1.0002, policy_loss: 1.3272, value_loss: 0.8256
2024-07-11 16:19:32,121 [INFO    ] __main__: train step 6682: loss: 1.0003, policy_loss: 1.3271, value_loss: 0.8256
2024-07-11 16:19:32,330 [INFO    ] __main__: train step 6683: loss: 1.0003, policy_loss: 1.3270, value_loss: 0.8255
2024-07-11 16:19:32,525 [INFO    ] __main__: train step 6684: loss: 1.0004, policy_loss: 1.3270, value_loss: 0.8255
2024-07-11 16:19:32,746 [INFO    ] __main__: train step 6685: loss: 1.0004, policy_loss: 1.3269, value_loss: 0.8255
2024-07-11 16:19:32,978 [INFO    ] __main__: train step 6686: loss: 1.0005, policy_loss: 1.3268, value_loss: 0.8254
2024-07-11 16:19:33,172 [INFO    ] __main__: train step 6687: loss: 1.0005, policy_loss: 1.3267, value_loss: 0.8254
2024-07-11 16:19:33,373 [INFO    ] __main__: train step 6688: loss: 1.0006, policy_loss: 1.3266, value_loss: 0.8254
2024-07-11 16:19:33,570 [INFO    ] __main__: train step 6689: loss: 1.0007, policy_loss: 1.3266, value_loss: 0.8253
2024-07-11 16:19:33,763 [INFO    ] __main__: train step 6690: loss: 1.0007, policy_loss: 1.3265, value_loss: 0.8253
2024-07-11 16:19:33,968 [INFO    ] __main__: train step 6691: loss: 1.0008, policy_loss: 1.3264, value_loss: 0.8253
2024-07-11 16:19:34,172 [INFO    ] __main__: train step 6692: loss: 1.0008, policy_loss: 1.3263, value_loss: 0.8252
2024-07-11 16:19:34,382 [INFO    ] __main__: train step 6693: loss: 1.0009, policy_loss: 1.3263, value_loss: 0.8252
2024-07-11 16:19:34,598 [INFO    ] __main__: train step 6694: loss: 1.0009, policy_loss: 1.3262, value_loss: 0.8252
2024-07-11 16:19:34,839 [INFO    ] __main__: train step 6695: loss: 1.0010, policy_loss: 1.3261, value_loss: 0.8251
2024-07-11 16:19:35,080 [INFO    ] __main__: train step 6696: loss: 1.0010, policy_loss: 1.3260, value_loss: 0.8251
2024-07-11 16:19:35,287 [INFO    ] __main__: train step 6697: loss: 1.0011, policy_loss: 1.3259, value_loss: 0.8251
2024-07-11 16:19:36,732 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:19:37,181 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:19:37,241 [INFO    ] __main__: train step 6698: loss: 1.0011, policy_loss: 1.3259, value_loss: 0.8250
2024-07-11 16:19:37,419 [INFO    ] __main__: train step 6699: loss: 1.0012, policy_loss: 1.3258, value_loss: 0.8250
2024-07-11 16:19:37,649 [INFO    ] __main__: train step 6700: loss: 1.0012, policy_loss: 1.3257, value_loss: 0.8250
2024-07-11 16:19:37,861 [INFO    ] __main__: train step 6701: loss: 1.0013, policy_loss: 1.3256, value_loss: 0.8249
2024-07-11 16:19:38,066 [INFO    ] __main__: train step 6702: loss: 1.0014, policy_loss: 1.3255, value_loss: 0.8249
2024-07-11 16:19:38,305 [INFO    ] __main__: train step 6703: loss: 1.0014, policy_loss: 1.3255, value_loss: 0.8249
2024-07-11 16:19:38,518 [INFO    ] __main__: train step 6704: loss: 1.0015, policy_loss: 1.3254, value_loss: 0.8248
2024-07-11 16:19:38,755 [INFO    ] __main__: train step 6705: loss: 1.0015, policy_loss: 1.3253, value_loss: 0.8248
2024-07-11 16:19:38,957 [INFO    ] __main__: train step 6706: loss: 1.0016, policy_loss: 1.3252, value_loss: 0.8248
2024-07-11 16:19:39,167 [INFO    ] __main__: train step 6707: loss: 1.0016, policy_loss: 1.3251, value_loss: 0.8247
2024-07-11 16:19:39,374 [INFO    ] __main__: train step 6708: loss: 1.0017, policy_loss: 1.3251, value_loss: 0.8247
2024-07-11 16:19:39,588 [INFO    ] __main__: train step 6709: loss: 1.0018, policy_loss: 1.3250, value_loss: 0.8247
2024-07-11 16:19:39,780 [INFO    ] __main__: train step 6710: loss: 1.0018, policy_loss: 1.3249, value_loss: 0.8246
2024-07-11 16:19:40,804 [INFO    ] __main__: train step 6711: loss: 1.0019, policy_loss: 1.3248, value_loss: 0.8246
2024-07-11 16:19:41,032 [INFO    ] __main__: train step 6712: loss: 1.0019, policy_loss: 1.3248, value_loss: 0.8246
2024-07-11 16:19:41,235 [INFO    ] __main__: train step 6713: loss: 1.0020, policy_loss: 1.3247, value_loss: 0.8245
2024-07-11 16:19:41,452 [INFO    ] __main__: train step 6714: loss: 1.0020, policy_loss: 1.3246, value_loss: 0.8245
2024-07-11 16:19:42,906 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:19:43,337 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:19:43,392 [INFO    ] __main__: train step 6715: loss: 1.0021, policy_loss: 1.3245, value_loss: 0.8245
2024-07-11 16:19:43,567 [INFO    ] __main__: train step 6716: loss: 1.0021, policy_loss: 1.3244, value_loss: 0.8244
2024-07-11 16:19:43,766 [INFO    ] __main__: train step 6717: loss: 1.0022, policy_loss: 1.3244, value_loss: 0.8244
2024-07-11 16:19:43,977 [INFO    ] __main__: train step 6718: loss: 1.0022, policy_loss: 1.3243, value_loss: 0.8244
2024-07-11 16:19:44,183 [INFO    ] __main__: train step 6719: loss: 1.0023, policy_loss: 1.3242, value_loss: 0.8243
2024-07-11 16:19:44,414 [INFO    ] __main__: train step 6720: loss: 1.0024, policy_loss: 1.3241, value_loss: 0.8243
2024-07-11 16:19:44,619 [INFO    ] __main__: train step 6721: loss: 1.0024, policy_loss: 1.3241, value_loss: 0.8243
2024-07-11 16:19:44,851 [INFO    ] __main__: train step 6722: loss: 1.0025, policy_loss: 1.3240, value_loss: 0.8242
2024-07-11 16:19:45,054 [INFO    ] __main__: train step 6723: loss: 1.0025, policy_loss: 1.3239, value_loss: 0.8242
2024-07-11 16:19:45,243 [INFO    ] __main__: train step 6724: loss: 1.0026, policy_loss: 1.3238, value_loss: 0.8242
2024-07-11 16:19:45,444 [INFO    ] __main__: train step 6725: loss: 1.0026, policy_loss: 1.3237, value_loss: 0.8241
2024-07-11 16:19:45,652 [INFO    ] __main__: train step 6726: loss: 1.0027, policy_loss: 1.3237, value_loss: 0.8241
2024-07-11 16:19:45,847 [INFO    ] __main__: train step 6727: loss: 1.0027, policy_loss: 1.3236, value_loss: 0.8241
2024-07-11 16:19:46,044 [INFO    ] __main__: train step 6728: loss: 1.0028, policy_loss: 1.3235, value_loss: 0.8240
2024-07-11 16:19:46,240 [INFO    ] __main__: train step 6729: loss: 1.0028, policy_loss: 1.3234, value_loss: 0.8240
2024-07-11 16:19:46,440 [INFO    ] __main__: train step 6730: loss: 1.0029, policy_loss: 1.3233, value_loss: 0.8240
2024-07-11 16:19:46,636 [INFO    ] __main__: train step 6731: loss: 1.0029, policy_loss: 1.3233, value_loss: 0.8239
2024-07-11 16:19:48,094 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:19:48,543 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:19:48,603 [INFO    ] __main__: train step 6732: loss: 1.0030, policy_loss: 1.3232, value_loss: 0.8239
2024-07-11 16:19:48,768 [INFO    ] __main__: train step 6733: loss: 1.0031, policy_loss: 1.3231, value_loss: 0.8239
2024-07-11 16:19:48,965 [INFO    ] __main__: train step 6734: loss: 1.0031, policy_loss: 1.3230, value_loss: 0.8238
2024-07-11 16:19:49,164 [INFO    ] __main__: train step 6735: loss: 1.0032, policy_loss: 1.3230, value_loss: 0.8238
2024-07-11 16:19:49,365 [INFO    ] __main__: train step 6736: loss: 1.0032, policy_loss: 1.3229, value_loss: 0.8238
2024-07-11 16:19:49,558 [INFO    ] __main__: train step 6737: loss: 1.0033, policy_loss: 1.3228, value_loss: 0.8237
2024-07-11 16:19:49,763 [INFO    ] __main__: train step 6738: loss: 1.0033, policy_loss: 1.3227, value_loss: 0.8237
2024-07-11 16:19:49,970 [INFO    ] __main__: train step 6739: loss: 1.0034, policy_loss: 1.3226, value_loss: 0.8237
2024-07-11 16:19:50,165 [INFO    ] __main__: train step 6740: loss: 1.0034, policy_loss: 1.3226, value_loss: 0.8237
2024-07-11 16:19:50,356 [INFO    ] __main__: train step 6741: loss: 1.0035, policy_loss: 1.3225, value_loss: 0.8236
2024-07-11 16:19:50,566 [INFO    ] __main__: train step 6742: loss: 1.0035, policy_loss: 1.3224, value_loss: 0.8236
2024-07-11 16:19:50,770 [INFO    ] __main__: train step 6743: loss: 1.0036, policy_loss: 1.3223, value_loss: 0.8236
2024-07-11 16:19:50,991 [INFO    ] __main__: train step 6744: loss: 1.0037, policy_loss: 1.3223, value_loss: 0.8235
2024-07-11 16:19:51,197 [INFO    ] __main__: train step 6745: loss: 1.0037, policy_loss: 1.3222, value_loss: 0.8235
2024-07-11 16:19:51,426 [INFO    ] __main__: train step 6746: loss: 1.0038, policy_loss: 1.3221, value_loss: 0.8235
2024-07-11 16:19:51,638 [INFO    ] __main__: train step 6747: loss: 1.0038, policy_loss: 1.3220, value_loss: 0.8234
2024-07-11 16:19:51,849 [INFO    ] __main__: train step 6748: loss: 1.0039, policy_loss: 1.3219, value_loss: 0.8234
2024-07-11 16:19:53,332 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:19:53,798 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:19:53,859 [INFO    ] __main__: train step 6749: loss: 1.0039, policy_loss: 1.3219, value_loss: 0.8234
2024-07-11 16:19:54,032 [INFO    ] __main__: train step 6750: loss: 1.0040, policy_loss: 1.3218, value_loss: 0.8233
2024-07-11 16:19:54,229 [INFO    ] __main__: train step 6751: loss: 1.0040, policy_loss: 1.3217, value_loss: 0.8233
2024-07-11 16:19:54,434 [INFO    ] __main__: train step 6752: loss: 1.0041, policy_loss: 1.3216, value_loss: 0.8233
2024-07-11 16:19:54,633 [INFO    ] __main__: train step 6753: loss: 1.0041, policy_loss: 1.3215, value_loss: 0.8232
2024-07-11 16:19:54,834 [INFO    ] __main__: train step 6754: loss: 1.0042, policy_loss: 1.3215, value_loss: 0.8232
2024-07-11 16:19:55,035 [INFO    ] __main__: train step 6755: loss: 1.0043, policy_loss: 1.3214, value_loss: 0.8232
2024-07-11 16:19:55,228 [INFO    ] __main__: train step 6756: loss: 1.0043, policy_loss: 1.3213, value_loss: 0.8231
2024-07-11 16:19:55,432 [INFO    ] __main__: train step 6757: loss: 1.0044, policy_loss: 1.3212, value_loss: 0.8231
2024-07-11 16:19:55,636 [INFO    ] __main__: train step 6758: loss: 1.0044, policy_loss: 1.3212, value_loss: 0.8231
2024-07-11 16:19:55,835 [INFO    ] __main__: train step 6759: loss: 1.0045, policy_loss: 1.3211, value_loss: 0.8230
2024-07-11 16:19:56,029 [INFO    ] __main__: train step 6760: loss: 1.0045, policy_loss: 1.3210, value_loss: 0.8230
2024-07-11 16:19:56,240 [INFO    ] __main__: train step 6761: loss: 1.0046, policy_loss: 1.3209, value_loss: 0.8230
2024-07-11 16:19:56,436 [INFO    ] __main__: train step 6762: loss: 1.0046, policy_loss: 1.3208, value_loss: 0.8229
2024-07-11 16:19:56,646 [INFO    ] __main__: train step 6763: loss: 1.0047, policy_loss: 1.3208, value_loss: 0.8229
2024-07-11 16:19:56,881 [INFO    ] __main__: train step 6764: loss: 1.0047, policy_loss: 1.3207, value_loss: 0.8229
2024-07-11 16:19:57,090 [INFO    ] __main__: train step 6765: loss: 1.0048, policy_loss: 1.3206, value_loss: 0.8228
2024-07-11 16:19:58,513 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:19:58,971 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:19:59,026 [INFO    ] __main__: train step 6766: loss: 1.0048, policy_loss: 1.3205, value_loss: 0.8228
2024-07-11 16:19:59,202 [INFO    ] __main__: train step 6767: loss: 1.0049, policy_loss: 1.3205, value_loss: 0.8228
2024-07-11 16:19:59,413 [INFO    ] __main__: train step 6768: loss: 1.0050, policy_loss: 1.3204, value_loss: 0.8228
2024-07-11 16:19:59,623 [INFO    ] __main__: train step 6769: loss: 1.0050, policy_loss: 1.3203, value_loss: 0.8227
2024-07-11 16:19:59,832 [INFO    ] __main__: train step 6770: loss: 1.0051, policy_loss: 1.3202, value_loss: 0.8227
2024-07-11 16:20:00,040 [INFO    ] __main__: train step 6771: loss: 1.0051, policy_loss: 1.3201, value_loss: 0.8227
2024-07-11 16:20:00,257 [INFO    ] __main__: train step 6772: loss: 1.0052, policy_loss: 1.3201, value_loss: 0.8226
2024-07-11 16:20:00,473 [INFO    ] __main__: train step 6773: loss: 1.0052, policy_loss: 1.3200, value_loss: 0.8226
2024-07-11 16:20:00,677 [INFO    ] __main__: train step 6774: loss: 1.0053, policy_loss: 1.3199, value_loss: 0.8226
2024-07-11 16:20:00,877 [INFO    ] __main__: train step 6775: loss: 1.0053, policy_loss: 1.3198, value_loss: 0.8225
2024-07-11 16:20:01,091 [INFO    ] __main__: train step 6776: loss: 1.0054, policy_loss: 1.3197, value_loss: 0.8225
2024-07-11 16:20:01,300 [INFO    ] __main__: train step 6777: loss: 1.0054, policy_loss: 1.3197, value_loss: 0.8225
2024-07-11 16:20:01,505 [INFO    ] __main__: train step 6778: loss: 1.0055, policy_loss: 1.3196, value_loss: 0.8224
2024-07-11 16:20:01,716 [INFO    ] __main__: train step 6779: loss: 1.0055, policy_loss: 1.3195, value_loss: 0.8224
2024-07-11 16:20:01,938 [INFO    ] __main__: train step 6780: loss: 1.0056, policy_loss: 1.3194, value_loss: 0.8224
2024-07-11 16:20:02,165 [INFO    ] __main__: train step 6781: loss: 1.0056, policy_loss: 1.3194, value_loss: 0.8223
2024-07-11 16:20:02,368 [INFO    ] __main__: train step 6782: loss: 1.0057, policy_loss: 1.3193, value_loss: 0.8223
2024-07-11 16:20:04,661 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:20:05,123 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:20:05,181 [INFO    ] __main__: train step 6783: loss: 1.0057, policy_loss: 1.3192, value_loss: 0.8223
2024-07-11 16:20:05,357 [INFO    ] __main__: train step 6784: loss: 1.0058, policy_loss: 1.3191, value_loss: 0.8222
2024-07-11 16:20:05,554 [INFO    ] __main__: train step 6785: loss: 1.0058, policy_loss: 1.3190, value_loss: 0.8222
2024-07-11 16:20:05,751 [INFO    ] __main__: train step 6786: loss: 1.0059, policy_loss: 1.3190, value_loss: 0.8222
2024-07-11 16:20:05,958 [INFO    ] __main__: train step 6787: loss: 1.0060, policy_loss: 1.3189, value_loss: 0.8221
2024-07-11 16:20:06,153 [INFO    ] __main__: train step 6788: loss: 1.0060, policy_loss: 1.3188, value_loss: 0.8221
2024-07-11 16:20:06,355 [INFO    ] __main__: train step 6789: loss: 1.0061, policy_loss: 1.3187, value_loss: 0.8221
2024-07-11 16:20:06,557 [INFO    ] __main__: train step 6790: loss: 1.0061, policy_loss: 1.3186, value_loss: 0.8220
2024-07-11 16:20:06,752 [INFO    ] __main__: train step 6791: loss: 1.0062, policy_loss: 1.3186, value_loss: 0.8220
2024-07-11 16:20:06,953 [INFO    ] __main__: train step 6792: loss: 1.0062, policy_loss: 1.3185, value_loss: 0.8220
2024-07-11 16:20:07,159 [INFO    ] __main__: train step 6793: loss: 1.0063, policy_loss: 1.3184, value_loss: 0.8219
2024-07-11 16:20:07,362 [INFO    ] __main__: train step 6794: loss: 1.0063, policy_loss: 1.3183, value_loss: 0.8219
2024-07-11 16:20:07,569 [INFO    ] __main__: train step 6795: loss: 1.0064, policy_loss: 1.3183, value_loss: 0.8219
2024-07-11 16:20:07,777 [INFO    ] __main__: train step 6796: loss: 1.0064, policy_loss: 1.3182, value_loss: 0.8218
2024-07-11 16:20:07,975 [INFO    ] __main__: train step 6797: loss: 1.0065, policy_loss: 1.3181, value_loss: 0.8218
2024-07-11 16:20:08,174 [INFO    ] __main__: train step 6798: loss: 1.0065, policy_loss: 1.3180, value_loss: 0.8218
2024-07-11 16:20:08,378 [INFO    ] __main__: train step 6799: loss: 1.0066, policy_loss: 1.3179, value_loss: 0.8217
2024-07-11 16:20:09,813 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:20:10,234 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:20:10,290 [INFO    ] __main__: train step 6800: loss: 1.0066, policy_loss: 1.3179, value_loss: 0.8217
2024-07-11 16:20:10,459 [INFO    ] __main__: train step 6801: loss: 1.0067, policy_loss: 1.3178, value_loss: 0.8217
2024-07-11 16:20:10,656 [INFO    ] __main__: train step 6802: loss: 1.0067, policy_loss: 1.3177, value_loss: 0.8216
2024-07-11 16:20:10,882 [INFO    ] __main__: train step 6803: loss: 1.0068, policy_loss: 1.3176, value_loss: 0.8216
2024-07-11 16:20:11,102 [INFO    ] __main__: train step 6804: loss: 1.0068, policy_loss: 1.3176, value_loss: 0.8216
2024-07-11 16:20:11,305 [INFO    ] __main__: train step 6805: loss: 1.0069, policy_loss: 1.3175, value_loss: 0.8215
2024-07-11 16:20:11,505 [INFO    ] __main__: train step 6806: loss: 1.0069, policy_loss: 1.3174, value_loss: 0.8215
2024-07-11 16:20:11,711 [INFO    ] __main__: train step 6807: loss: 1.0070, policy_loss: 1.3173, value_loss: 0.8215
2024-07-11 16:20:11,918 [INFO    ] __main__: train step 6808: loss: 1.0070, policy_loss: 1.3172, value_loss: 0.8214
2024-07-11 16:20:12,117 [INFO    ] __main__: train step 6809: loss: 1.0071, policy_loss: 1.3172, value_loss: 0.8214
2024-07-11 16:20:12,314 [INFO    ] __main__: train step 6810: loss: 1.0071, policy_loss: 1.3171, value_loss: 0.8214
2024-07-11 16:20:12,520 [INFO    ] __main__: train step 6811: loss: 1.0072, policy_loss: 1.3170, value_loss: 0.8213
2024-07-11 16:20:12,715 [INFO    ] __main__: train step 6812: loss: 1.0072, policy_loss: 1.3169, value_loss: 0.8213
2024-07-11 16:20:12,910 [INFO    ] __main__: train step 6813: loss: 1.0073, policy_loss: 1.3168, value_loss: 0.8213
2024-07-11 16:20:13,108 [INFO    ] __main__: train step 6814: loss: 1.0073, policy_loss: 1.3168, value_loss: 0.8212
2024-07-11 16:20:13,316 [INFO    ] __main__: train step 6815: loss: 1.0074, policy_loss: 1.3167, value_loss: 0.8212
2024-07-11 16:20:13,510 [INFO    ] __main__: train step 6816: loss: 1.0074, policy_loss: 1.3166, value_loss: 0.8212
2024-07-11 16:20:14,957 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:20:15,390 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:20:15,445 [INFO    ] __main__: train step 6817: loss: 1.0075, policy_loss: 1.3165, value_loss: 0.8211
2024-07-11 16:20:15,614 [INFO    ] __main__: train step 6818: loss: 1.0076, policy_loss: 1.3165, value_loss: 0.8211
2024-07-11 16:20:15,816 [INFO    ] __main__: train step 6819: loss: 1.0076, policy_loss: 1.3164, value_loss: 0.8211
2024-07-11 16:20:16,028 [INFO    ] __main__: train step 6820: loss: 1.0077, policy_loss: 1.3163, value_loss: 0.8211
2024-07-11 16:20:16,232 [INFO    ] __main__: train step 6821: loss: 1.0077, policy_loss: 1.3162, value_loss: 0.8210
2024-07-11 16:20:16,423 [INFO    ] __main__: train step 6822: loss: 1.0078, policy_loss: 1.3162, value_loss: 0.8210
2024-07-11 16:20:16,615 [INFO    ] __main__: train step 6823: loss: 1.0078, policy_loss: 1.3161, value_loss: 0.8210
2024-07-11 16:20:16,831 [INFO    ] __main__: train step 6824: loss: 1.0079, policy_loss: 1.3160, value_loss: 0.8209
2024-07-11 16:20:17,073 [INFO    ] __main__: train step 6825: loss: 1.0079, policy_loss: 1.3159, value_loss: 0.8209
2024-07-11 16:20:17,312 [INFO    ] __main__: train step 6826: loss: 1.0080, policy_loss: 1.3158, value_loss: 0.8209
2024-07-11 16:20:17,526 [INFO    ] __main__: train step 6827: loss: 1.0080, policy_loss: 1.3158, value_loss: 0.8208
2024-07-11 16:20:17,757 [INFO    ] __main__: train step 6828: loss: 1.0081, policy_loss: 1.3157, value_loss: 0.8208
2024-07-11 16:20:17,968 [INFO    ] __main__: train step 6829: loss: 1.0081, policy_loss: 1.3156, value_loss: 0.8208
2024-07-11 16:20:18,169 [INFO    ] __main__: train step 6830: loss: 1.0082, policy_loss: 1.3155, value_loss: 0.8207
2024-07-11 16:20:18,374 [INFO    ] __main__: train step 6831: loss: 1.0082, policy_loss: 1.3155, value_loss: 0.8207
2024-07-11 16:20:18,573 [INFO    ] __main__: train step 6832: loss: 1.0083, policy_loss: 1.3154, value_loss: 0.8207
2024-07-11 16:20:18,768 [INFO    ] __main__: train step 6833: loss: 1.0083, policy_loss: 1.3153, value_loss: 0.8206
2024-07-11 16:20:20,204 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:20:20,628 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:20:20,683 [INFO    ] __main__: train step 6834: loss: 1.0084, policy_loss: 1.3152, value_loss: 0.8206
2024-07-11 16:20:20,857 [INFO    ] __main__: train step 6835: loss: 1.0084, policy_loss: 1.3151, value_loss: 0.8206
2024-07-11 16:20:21,054 [INFO    ] __main__: train step 6836: loss: 1.0085, policy_loss: 1.3151, value_loss: 0.8205
2024-07-11 16:20:21,264 [INFO    ] __main__: train step 6837: loss: 1.0085, policy_loss: 1.3150, value_loss: 0.8205
2024-07-11 16:20:21,470 [INFO    ] __main__: train step 6838: loss: 1.0086, policy_loss: 1.3149, value_loss: 0.8205
2024-07-11 16:20:21,684 [INFO    ] __main__: train step 6839: loss: 1.0086, policy_loss: 1.3148, value_loss: 0.8204
2024-07-11 16:20:21,897 [INFO    ] __main__: train step 6840: loss: 1.0087, policy_loss: 1.3148, value_loss: 0.8204
2024-07-11 16:20:22,106 [INFO    ] __main__: train step 6841: loss: 1.0087, policy_loss: 1.3147, value_loss: 0.8204
2024-07-11 16:20:22,316 [INFO    ] __main__: train step 6842: loss: 1.0088, policy_loss: 1.3146, value_loss: 0.8203
2024-07-11 16:20:22,527 [INFO    ] __main__: train step 6843: loss: 1.0088, policy_loss: 1.3145, value_loss: 0.8203
2024-07-11 16:20:22,734 [INFO    ] __main__: train step 6844: loss: 1.0089, policy_loss: 1.3144, value_loss: 0.8203
2024-07-11 16:20:22,948 [INFO    ] __main__: train step 6845: loss: 1.0089, policy_loss: 1.3144, value_loss: 0.8202
2024-07-11 16:20:23,181 [INFO    ] __main__: train step 6846: loss: 1.0090, policy_loss: 1.3143, value_loss: 0.8202
2024-07-11 16:20:23,394 [INFO    ] __main__: train step 6847: loss: 1.0091, policy_loss: 1.3142, value_loss: 0.8202
2024-07-11 16:20:23,628 [INFO    ] __main__: train step 6848: loss: 1.0091, policy_loss: 1.3141, value_loss: 0.8201
2024-07-11 16:20:23,831 [INFO    ] __main__: train step 6849: loss: 1.0091, policy_loss: 1.3141, value_loss: 0.8201
2024-07-11 16:20:24,019 [INFO    ] __main__: train step 6850: loss: 1.0092, policy_loss: 1.3140, value_loss: 0.8201
2024-07-11 16:20:25,451 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:20:25,848 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:20:25,907 [INFO    ] __main__: train step 6851: loss: 1.0092, policy_loss: 1.3139, value_loss: 0.8200
2024-07-11 16:20:26,093 [INFO    ] __main__: train step 6852: loss: 1.0093, policy_loss: 1.3138, value_loss: 0.8200
2024-07-11 16:20:26,319 [INFO    ] __main__: train step 6853: loss: 1.0093, policy_loss: 1.3138, value_loss: 0.8200
2024-07-11 16:20:26,515 [INFO    ] __main__: train step 6854: loss: 1.0094, policy_loss: 1.3137, value_loss: 0.8200
2024-07-11 16:20:26,713 [INFO    ] __main__: train step 6855: loss: 1.0095, policy_loss: 1.3136, value_loss: 0.8199
2024-07-11 16:20:27,759 [INFO    ] __main__: train step 6856: loss: 1.0095, policy_loss: 1.3135, value_loss: 0.8199
2024-07-11 16:20:27,973 [INFO    ] __main__: train step 6857: loss: 1.0096, policy_loss: 1.3134, value_loss: 0.8199
2024-07-11 16:20:28,169 [INFO    ] __main__: train step 6858: loss: 1.0096, policy_loss: 1.3134, value_loss: 0.8198
2024-07-11 16:20:28,372 [INFO    ] __main__: train step 6859: loss: 1.0097, policy_loss: 1.3133, value_loss: 0.8198
2024-07-11 16:20:28,573 [INFO    ] __main__: train step 6860: loss: 1.0097, policy_loss: 1.3132, value_loss: 0.8198
2024-07-11 16:20:28,768 [INFO    ] __main__: train step 6861: loss: 1.0098, policy_loss: 1.3131, value_loss: 0.8197
2024-07-11 16:20:28,969 [INFO    ] __main__: train step 6862: loss: 1.0098, policy_loss: 1.3131, value_loss: 0.8197
2024-07-11 16:20:29,179 [INFO    ] __main__: train step 6863: loss: 1.0099, policy_loss: 1.3130, value_loss: 0.8197
2024-07-11 16:20:29,379 [INFO    ] __main__: train step 6864: loss: 1.0099, policy_loss: 1.3129, value_loss: 0.8196
2024-07-11 16:20:29,579 [INFO    ] __main__: train step 6865: loss: 1.0100, policy_loss: 1.3128, value_loss: 0.8196
2024-07-11 16:20:29,808 [INFO    ] __main__: train step 6866: loss: 1.0100, policy_loss: 1.3128, value_loss: 0.8196
2024-07-11 16:20:29,999 [INFO    ] __main__: train step 6867: loss: 1.0101, policy_loss: 1.3127, value_loss: 0.8195
2024-07-11 16:20:31,452 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:20:31,847 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:20:31,906 [INFO    ] __main__: train step 6868: loss: 1.0101, policy_loss: 1.3126, value_loss: 0.8195
2024-07-11 16:20:32,080 [INFO    ] __main__: train step 6869: loss: 1.0102, policy_loss: 1.3125, value_loss: 0.8195
2024-07-11 16:20:32,286 [INFO    ] __main__: train step 6870: loss: 1.0102, policy_loss: 1.3124, value_loss: 0.8194
2024-07-11 16:20:32,486 [INFO    ] __main__: train step 6871: loss: 1.0103, policy_loss: 1.3124, value_loss: 0.8194
2024-07-11 16:20:32,707 [INFO    ] __main__: train step 6872: loss: 1.0103, policy_loss: 1.3123, value_loss: 0.8194
2024-07-11 16:20:32,940 [INFO    ] __main__: train step 6873: loss: 1.0104, policy_loss: 1.3122, value_loss: 0.8194
2024-07-11 16:20:33,138 [INFO    ] __main__: train step 6874: loss: 1.0104, policy_loss: 1.3121, value_loss: 0.8193
2024-07-11 16:20:33,345 [INFO    ] __main__: train step 6875: loss: 1.0105, policy_loss: 1.3121, value_loss: 0.8193
2024-07-11 16:20:33,536 [INFO    ] __main__: train step 6876: loss: 1.0105, policy_loss: 1.3120, value_loss: 0.8193
2024-07-11 16:20:33,731 [INFO    ] __main__: train step 6877: loss: 1.0106, policy_loss: 1.3119, value_loss: 0.8192
2024-07-11 16:20:33,936 [INFO    ] __main__: train step 6878: loss: 1.0106, policy_loss: 1.3118, value_loss: 0.8192
2024-07-11 16:20:34,132 [INFO    ] __main__: train step 6879: loss: 1.0107, policy_loss: 1.3117, value_loss: 0.8192
2024-07-11 16:20:34,332 [INFO    ] __main__: train step 6880: loss: 1.0107, policy_loss: 1.3117, value_loss: 0.8191
2024-07-11 16:20:34,524 [INFO    ] __main__: train step 6881: loss: 1.0108, policy_loss: 1.3116, value_loss: 0.8191
2024-07-11 16:20:34,732 [INFO    ] __main__: train step 6882: loss: 1.0108, policy_loss: 1.3115, value_loss: 0.8191
2024-07-11 16:20:34,953 [INFO    ] __main__: train step 6883: loss: 1.0109, policy_loss: 1.3114, value_loss: 0.8190
2024-07-11 16:20:35,179 [INFO    ] __main__: train step 6884: loss: 1.0109, policy_loss: 1.3114, value_loss: 0.8190
2024-07-11 16:20:36,610 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:20:37,008 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:20:37,062 [INFO    ] __main__: train step 6885: loss: 1.0110, policy_loss: 1.3113, value_loss: 0.8190
2024-07-11 16:20:37,232 [INFO    ] __main__: train step 6886: loss: 1.0110, policy_loss: 1.3112, value_loss: 0.8189
2024-07-11 16:20:37,436 [INFO    ] __main__: train step 6887: loss: 1.0111, policy_loss: 1.3111, value_loss: 0.8189
2024-07-11 16:20:37,635 [INFO    ] __main__: train step 6888: loss: 1.0111, policy_loss: 1.3110, value_loss: 0.8189
2024-07-11 16:20:37,839 [INFO    ] __main__: train step 6889: loss: 1.0112, policy_loss: 1.3110, value_loss: 0.8189
2024-07-11 16:20:38,042 [INFO    ] __main__: train step 6890: loss: 1.0112, policy_loss: 1.3109, value_loss: 0.8188
2024-07-11 16:20:38,253 [INFO    ] __main__: train step 6891: loss: 1.0113, policy_loss: 1.3108, value_loss: 0.8188
2024-07-11 16:20:38,456 [INFO    ] __main__: train step 6892: loss: 1.0113, policy_loss: 1.3107, value_loss: 0.8188
2024-07-11 16:20:38,653 [INFO    ] __main__: train step 6893: loss: 1.0114, policy_loss: 1.3107, value_loss: 0.8187
2024-07-11 16:20:38,850 [INFO    ] __main__: train step 6894: loss: 1.0114, policy_loss: 1.3106, value_loss: 0.8187
2024-07-11 16:20:39,056 [INFO    ] __main__: train step 6895: loss: 1.0115, policy_loss: 1.3105, value_loss: 0.8187
2024-07-11 16:20:39,286 [INFO    ] __main__: train step 6896: loss: 1.0115, policy_loss: 1.3104, value_loss: 0.8186
2024-07-11 16:20:39,492 [INFO    ] __main__: train step 6897: loss: 1.0116, policy_loss: 1.3103, value_loss: 0.8186
2024-07-11 16:20:39,687 [INFO    ] __main__: train step 6898: loss: 1.0116, policy_loss: 1.3103, value_loss: 0.8186
2024-07-11 16:20:39,896 [INFO    ] __main__: train step 6899: loss: 1.0117, policy_loss: 1.3102, value_loss: 0.8185
2024-07-11 16:20:40,103 [INFO    ] __main__: train step 6900: loss: 1.0117, policy_loss: 1.3101, value_loss: 0.8185
2024-07-11 16:20:40,308 [INFO    ] __main__: train step 6901: loss: 1.0118, policy_loss: 1.3100, value_loss: 0.8185
2024-07-11 16:20:41,756 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:20:42,168 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:20:42,223 [INFO    ] __main__: train step 6902: loss: 1.0118, policy_loss: 1.3100, value_loss: 0.8185
2024-07-11 16:20:42,405 [INFO    ] __main__: train step 6903: loss: 1.0119, policy_loss: 1.3099, value_loss: 0.8184
2024-07-11 16:20:42,609 [INFO    ] __main__: train step 6904: loss: 1.0119, policy_loss: 1.3098, value_loss: 0.8184
2024-07-11 16:20:42,805 [INFO    ] __main__: train step 6905: loss: 1.0120, policy_loss: 1.3097, value_loss: 0.8184
2024-07-11 16:20:43,005 [INFO    ] __main__: train step 6906: loss: 1.0120, policy_loss: 1.3096, value_loss: 0.8183
2024-07-11 16:20:43,206 [INFO    ] __main__: train step 6907: loss: 1.0121, policy_loss: 1.3096, value_loss: 0.8183
2024-07-11 16:20:43,406 [INFO    ] __main__: train step 6908: loss: 1.0121, policy_loss: 1.3095, value_loss: 0.8183
2024-07-11 16:20:43,616 [INFO    ] __main__: train step 6909: loss: 1.0122, policy_loss: 1.3094, value_loss: 0.8182
2024-07-11 16:20:43,831 [INFO    ] __main__: train step 6910: loss: 1.0122, policy_loss: 1.3093, value_loss: 0.8182
2024-07-11 16:20:44,064 [INFO    ] __main__: train step 6911: loss: 1.0123, policy_loss: 1.3093, value_loss: 0.8182
2024-07-11 16:20:44,261 [INFO    ] __main__: train step 6912: loss: 1.0123, policy_loss: 1.3092, value_loss: 0.8181
2024-07-11 16:20:44,468 [INFO    ] __main__: train step 6913: loss: 1.0124, policy_loss: 1.3091, value_loss: 0.8181
2024-07-11 16:20:44,677 [INFO    ] __main__: train step 6914: loss: 1.0124, policy_loss: 1.3090, value_loss: 0.8181
2024-07-11 16:20:44,877 [INFO    ] __main__: train step 6915: loss: 1.0125, policy_loss: 1.3089, value_loss: 0.8180
2024-07-11 16:20:45,077 [INFO    ] __main__: train step 6916: loss: 1.0125, policy_loss: 1.3089, value_loss: 0.8180
2024-07-11 16:20:45,275 [INFO    ] __main__: train step 6917: loss: 1.0126, policy_loss: 1.3088, value_loss: 0.8180
2024-07-11 16:20:45,476 [INFO    ] __main__: train step 6918: loss: 1.0126, policy_loss: 1.3087, value_loss: 0.8179
2024-07-11 16:20:46,902 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:20:47,305 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:20:47,363 [INFO    ] __main__: train step 6919: loss: 1.0127, policy_loss: 1.3086, value_loss: 0.8179
2024-07-11 16:20:47,534 [INFO    ] __main__: train step 6920: loss: 1.0127, policy_loss: 1.3086, value_loss: 0.8179
2024-07-11 16:20:47,739 [INFO    ] __main__: train step 6921: loss: 1.0128, policy_loss: 1.3085, value_loss: 0.8179
2024-07-11 16:20:47,939 [INFO    ] __main__: train step 6922: loss: 1.0128, policy_loss: 1.3084, value_loss: 0.8178
2024-07-11 16:20:48,165 [INFO    ] __main__: train step 6923: loss: 1.0129, policy_loss: 1.3083, value_loss: 0.8178
2024-07-11 16:20:48,357 [INFO    ] __main__: train step 6924: loss: 1.0129, policy_loss: 1.3082, value_loss: 0.8178
2024-07-11 16:20:48,560 [INFO    ] __main__: train step 6925: loss: 1.0130, policy_loss: 1.3082, value_loss: 0.8177
2024-07-11 16:20:48,762 [INFO    ] __main__: train step 6926: loss: 1.0130, policy_loss: 1.3081, value_loss: 0.8177
2024-07-11 16:20:48,968 [INFO    ] __main__: train step 6927: loss: 1.0131, policy_loss: 1.3080, value_loss: 0.8177
2024-07-11 16:20:49,169 [INFO    ] __main__: train step 6928: loss: 1.0131, policy_loss: 1.3079, value_loss: 0.8176
2024-07-11 16:20:49,367 [INFO    ] __main__: train step 6929: loss: 1.0132, policy_loss: 1.3079, value_loss: 0.8176
2024-07-11 16:20:50,425 [INFO    ] __main__: train step 6930: loss: 1.0132, policy_loss: 1.3078, value_loss: 0.8176
2024-07-11 16:20:50,639 [INFO    ] __main__: train step 6931: loss: 1.0133, policy_loss: 1.3077, value_loss: 0.8176
2024-07-11 16:20:50,839 [INFO    ] __main__: train step 6932: loss: 1.0133, policy_loss: 1.3076, value_loss: 0.8175
2024-07-11 16:20:51,039 [INFO    ] __main__: train step 6933: loss: 1.0134, policy_loss: 1.3075, value_loss: 0.8175
2024-07-11 16:20:51,233 [INFO    ] __main__: train step 6934: loss: 1.0134, policy_loss: 1.3075, value_loss: 0.8175
2024-07-11 16:20:51,431 [INFO    ] __main__: train step 6935: loss: 1.0135, policy_loss: 1.3074, value_loss: 0.8174
2024-07-11 16:20:52,867 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:20:53,289 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:20:53,349 [INFO    ] __main__: train step 6936: loss: 1.0135, policy_loss: 1.3073, value_loss: 0.8174
2024-07-11 16:20:53,521 [INFO    ] __main__: train step 6937: loss: 1.0136, policy_loss: 1.3072, value_loss: 0.8174
2024-07-11 16:20:53,741 [INFO    ] __main__: train step 6938: loss: 1.0136, policy_loss: 1.3072, value_loss: 0.8173
2024-07-11 16:20:53,941 [INFO    ] __main__: train step 6939: loss: 1.0137, policy_loss: 1.3071, value_loss: 0.8173
2024-07-11 16:20:54,162 [INFO    ] __main__: train step 6940: loss: 1.0137, policy_loss: 1.3070, value_loss: 0.8173
2024-07-11 16:20:54,392 [INFO    ] __main__: train step 6941: loss: 1.0137, policy_loss: 1.3069, value_loss: 0.8172
2024-07-11 16:20:54,598 [INFO    ] __main__: train step 6942: loss: 1.0138, policy_loss: 1.3069, value_loss: 0.8172
2024-07-11 16:20:54,809 [INFO    ] __main__: train step 6943: loss: 1.0138, policy_loss: 1.3068, value_loss: 0.8172
2024-07-11 16:20:55,019 [INFO    ] __main__: train step 6944: loss: 1.0139, policy_loss: 1.3067, value_loss: 0.8171
2024-07-11 16:20:55,227 [INFO    ] __main__: train step 6945: loss: 1.0139, policy_loss: 1.3066, value_loss: 0.8171
2024-07-11 16:20:55,435 [INFO    ] __main__: train step 6946: loss: 1.0140, policy_loss: 1.3065, value_loss: 0.8171
2024-07-11 16:20:55,632 [INFO    ] __main__: train step 6947: loss: 1.0140, policy_loss: 1.3065, value_loss: 0.8170
2024-07-11 16:20:55,851 [INFO    ] __main__: train step 6948: loss: 1.0141, policy_loss: 1.3064, value_loss: 0.8170
2024-07-11 16:20:56,046 [INFO    ] __main__: train step 6949: loss: 1.0141, policy_loss: 1.3063, value_loss: 0.8170
2024-07-11 16:20:56,262 [INFO    ] __main__: train step 6950: loss: 1.0142, policy_loss: 1.3062, value_loss: 0.8170
2024-07-11 16:20:56,452 [INFO    ] __main__: train step 6951: loss: 1.0142, policy_loss: 1.3062, value_loss: 0.8169
2024-07-11 16:20:56,665 [INFO    ] __main__: train step 6952: loss: 1.0143, policy_loss: 1.3061, value_loss: 0.8169
2024-07-11 16:20:58,115 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:20:58,529 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:20:58,588 [INFO    ] __main__: train step 6953: loss: 1.0143, policy_loss: 1.3060, value_loss: 0.8169
2024-07-11 16:20:58,760 [INFO    ] __main__: train step 6954: loss: 1.0144, policy_loss: 1.3059, value_loss: 0.8168
2024-07-11 16:20:58,975 [INFO    ] __main__: train step 6955: loss: 1.0144, policy_loss: 1.3058, value_loss: 0.8168
2024-07-11 16:20:59,175 [INFO    ] __main__: train step 6956: loss: 1.0145, policy_loss: 1.3058, value_loss: 0.8168
2024-07-11 16:20:59,397 [INFO    ] __main__: train step 6957: loss: 1.0145, policy_loss: 1.3057, value_loss: 0.8167
2024-07-11 16:20:59,595 [INFO    ] __main__: train step 6958: loss: 1.0146, policy_loss: 1.3056, value_loss: 0.8167
2024-07-11 16:20:59,814 [INFO    ] __main__: train step 6959: loss: 1.0146, policy_loss: 1.3055, value_loss: 0.8167
2024-07-11 16:21:00,015 [INFO    ] __main__: train step 6960: loss: 1.0147, policy_loss: 1.3055, value_loss: 0.8166
2024-07-11 16:21:00,215 [INFO    ] __main__: train step 6961: loss: 1.0147, policy_loss: 1.3054, value_loss: 0.8166
2024-07-11 16:21:00,425 [INFO    ] __main__: train step 6962: loss: 1.0148, policy_loss: 1.3053, value_loss: 0.8166
2024-07-11 16:21:00,631 [INFO    ] __main__: train step 6963: loss: 1.0148, policy_loss: 1.3052, value_loss: 0.8165
2024-07-11 16:21:00,828 [INFO    ] __main__: train step 6964: loss: 1.0149, policy_loss: 1.3052, value_loss: 0.8165
2024-07-11 16:21:01,040 [INFO    ] __main__: train step 6965: loss: 1.0149, policy_loss: 1.3051, value_loss: 0.8165
2024-07-11 16:21:01,249 [INFO    ] __main__: train step 6966: loss: 1.0150, policy_loss: 1.3050, value_loss: 0.8165
2024-07-11 16:21:01,457 [INFO    ] __main__: train step 6967: loss: 1.0150, policy_loss: 1.3049, value_loss: 0.8164
2024-07-11 16:21:01,651 [INFO    ] __main__: train step 6968: loss: 1.0150, policy_loss: 1.3048, value_loss: 0.8164
2024-07-11 16:21:01,879 [INFO    ] __main__: train step 6969: loss: 1.0151, policy_loss: 1.3048, value_loss: 0.8164
2024-07-11 16:21:03,349 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:21:03,742 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:21:03,799 [INFO    ] __main__: train step 6970: loss: 1.0151, policy_loss: 1.3047, value_loss: 0.8163
2024-07-11 16:21:03,967 [INFO    ] __main__: train step 6971: loss: 1.0152, policy_loss: 1.3046, value_loss: 0.8163
2024-07-11 16:21:04,171 [INFO    ] __main__: train step 6972: loss: 1.0152, policy_loss: 1.3045, value_loss: 0.8163
2024-07-11 16:21:04,379 [INFO    ] __main__: train step 6973: loss: 1.0153, policy_loss: 1.3045, value_loss: 0.8162
2024-07-11 16:21:04,579 [INFO    ] __main__: train step 6974: loss: 1.0153, policy_loss: 1.3044, value_loss: 0.8162
2024-07-11 16:21:04,798 [INFO    ] __main__: train step 6975: loss: 1.0154, policy_loss: 1.3043, value_loss: 0.8162
2024-07-11 16:21:04,995 [INFO    ] __main__: train step 6976: loss: 1.0154, policy_loss: 1.3042, value_loss: 0.8161
2024-07-11 16:21:05,206 [INFO    ] __main__: train step 6977: loss: 1.0155, policy_loss: 1.3041, value_loss: 0.8161
2024-07-11 16:21:05,426 [INFO    ] __main__: train step 6978: loss: 1.0155, policy_loss: 1.3041, value_loss: 0.8161
2024-07-11 16:21:05,632 [INFO    ] __main__: train step 6979: loss: 1.0156, policy_loss: 1.3040, value_loss: 0.8160
2024-07-11 16:21:05,831 [INFO    ] __main__: train step 6980: loss: 1.0156, policy_loss: 1.3039, value_loss: 0.8160
2024-07-11 16:21:06,036 [INFO    ] __main__: train step 6981: loss: 1.0157, policy_loss: 1.3038, value_loss: 0.8160
2024-07-11 16:21:06,238 [INFO    ] __main__: train step 6982: loss: 1.0157, policy_loss: 1.3038, value_loss: 0.8159
2024-07-11 16:21:06,455 [INFO    ] __main__: train step 6983: loss: 1.0157, policy_loss: 1.3037, value_loss: 0.8159
2024-07-11 16:21:06,649 [INFO    ] __main__: train step 6984: loss: 1.0158, policy_loss: 1.3036, value_loss: 0.8159
2024-07-11 16:21:06,846 [INFO    ] __main__: train step 6985: loss: 1.0158, policy_loss: 1.3035, value_loss: 0.8159
2024-07-11 16:21:07,052 [INFO    ] __main__: train step 6986: loss: 1.0159, policy_loss: 1.3035, value_loss: 0.8158
2024-07-11 16:21:08,498 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:21:08,921 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:21:08,978 [INFO    ] __main__: train step 6987: loss: 1.0159, policy_loss: 1.3034, value_loss: 0.8158
2024-07-11 16:21:09,146 [INFO    ] __main__: train step 6988: loss: 1.0160, policy_loss: 1.3033, value_loss: 0.8158
2024-07-11 16:21:09,346 [INFO    ] __main__: train step 6989: loss: 1.0160, policy_loss: 1.3032, value_loss: 0.8157
2024-07-11 16:21:09,546 [INFO    ] __main__: train step 6990: loss: 1.0161, policy_loss: 1.3031, value_loss: 0.8157
2024-07-11 16:21:09,749 [INFO    ] __main__: train step 6991: loss: 1.0161, policy_loss: 1.3031, value_loss: 0.8157
2024-07-11 16:21:09,954 [INFO    ] __main__: train step 6992: loss: 1.0162, policy_loss: 1.3030, value_loss: 0.8156
2024-07-11 16:21:10,151 [INFO    ] __main__: train step 6993: loss: 1.0162, policy_loss: 1.3029, value_loss: 0.8156
2024-07-11 16:21:10,363 [INFO    ] __main__: train step 6994: loss: 1.0163, policy_loss: 1.3028, value_loss: 0.8156
2024-07-11 16:21:10,593 [INFO    ] __main__: train step 6995: loss: 1.0163, policy_loss: 1.3028, value_loss: 0.8155
2024-07-11 16:21:10,803 [INFO    ] __main__: train step 6996: loss: 1.0164, policy_loss: 1.3027, value_loss: 0.8155
2024-07-11 16:21:11,005 [INFO    ] __main__: train step 6997: loss: 1.0164, policy_loss: 1.3026, value_loss: 0.8155
2024-07-11 16:21:11,218 [INFO    ] __main__: train step 6998: loss: 1.0164, policy_loss: 1.3025, value_loss: 0.8154
2024-07-11 16:21:11,422 [INFO    ] __main__: train step 6999: loss: 1.0165, policy_loss: 1.3024, value_loss: 0.8154
2024-07-11 16:21:11,670 [INFO    ] __main__: train step 7000: loss: 1.0165, policy_loss: 1.3024, value_loss: 0.8154
2024-07-11 16:21:11,793 [INFO    ] __main__: restored step 6000 for evaluation
2024-07-11 16:21:19,327 [INFO    ] __main__: later network ELO difference from earlier network: +186 (+8/-8) ELO from 32000 self-played games
2024-07-11 16:21:19,327 [INFO    ] __main__: game outcomes: W: 22216, D: 1115, L: 8669
2024-07-11 16:21:19,329 [INFO    ] __main__: validation_elo_delta: 186, validation_elo: 1554
2024-07-11 16:21:19,831 [INFO    ] __main__: train step 7001: loss: 1.0166, policy_loss: 1.3023, value_loss: 0.8154
2024-07-11 16:21:20,038 [INFO    ] __main__: train step 7002: loss: 1.0166, policy_loss: 1.3022, value_loss: 0.8153
2024-07-11 16:21:21,104 [INFO    ] __main__: train step 7003: loss: 1.0167, policy_loss: 1.3021, value_loss: 0.8153
2024-07-11 16:21:22,542 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:21:22,968 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:21:23,029 [INFO    ] __main__: train step 7004: loss: 1.0167, policy_loss: 1.3021, value_loss: 0.8153
2024-07-11 16:21:23,217 [INFO    ] __main__: train step 7005: loss: 1.0168, policy_loss: 1.3020, value_loss: 0.8152
2024-07-11 16:21:23,446 [INFO    ] __main__: train step 7006: loss: 1.0168, policy_loss: 1.3019, value_loss: 0.8152
2024-07-11 16:21:23,655 [INFO    ] __main__: train step 7007: loss: 1.0169, policy_loss: 1.3018, value_loss: 0.8152
2024-07-11 16:21:23,846 [INFO    ] __main__: train step 7008: loss: 1.0169, policy_loss: 1.3018, value_loss: 0.8151
2024-07-11 16:21:24,050 [INFO    ] __main__: train step 7009: loss: 1.0170, policy_loss: 1.3017, value_loss: 0.8151
2024-07-11 16:21:24,249 [INFO    ] __main__: train step 7010: loss: 1.0170, policy_loss: 1.3016, value_loss: 0.8151
2024-07-11 16:21:24,482 [INFO    ] __main__: train step 7011: loss: 1.0170, policy_loss: 1.3015, value_loss: 0.8150
2024-07-11 16:21:24,701 [INFO    ] __main__: train step 7012: loss: 1.0171, policy_loss: 1.3014, value_loss: 0.8150
2024-07-11 16:21:24,925 [INFO    ] __main__: train step 7013: loss: 1.0171, policy_loss: 1.3014, value_loss: 0.8150
2024-07-11 16:21:25,125 [INFO    ] __main__: train step 7014: loss: 1.0172, policy_loss: 1.3013, value_loss: 0.8149
2024-07-11 16:21:25,318 [INFO    ] __main__: train step 7015: loss: 1.0172, policy_loss: 1.3012, value_loss: 0.8149
2024-07-11 16:21:25,515 [INFO    ] __main__: train step 7016: loss: 1.0173, policy_loss: 1.3011, value_loss: 0.8149
2024-07-11 16:21:25,726 [INFO    ] __main__: train step 7017: loss: 1.0173, policy_loss: 1.3011, value_loss: 0.8149
2024-07-11 16:21:25,941 [INFO    ] __main__: train step 7018: loss: 1.0174, policy_loss: 1.3010, value_loss: 0.8148
2024-07-11 16:21:26,171 [INFO    ] __main__: train step 7019: loss: 1.0174, policy_loss: 1.3009, value_loss: 0.8148
2024-07-11 16:21:26,364 [INFO    ] __main__: train step 7020: loss: 1.0175, policy_loss: 1.3008, value_loss: 0.8148
2024-07-11 16:21:27,823 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:21:28,207 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:21:28,266 [INFO    ] __main__: train step 7021: loss: 1.0175, policy_loss: 1.3007, value_loss: 0.8147
2024-07-11 16:21:28,435 [INFO    ] __main__: train step 7022: loss: 1.0176, policy_loss: 1.3007, value_loss: 0.8147
2024-07-11 16:21:28,646 [INFO    ] __main__: train step 7023: loss: 1.0176, policy_loss: 1.3006, value_loss: 0.8147
2024-07-11 16:21:28,855 [INFO    ] __main__: train step 7024: loss: 1.0176, policy_loss: 1.3005, value_loss: 0.8146
2024-07-11 16:21:29,054 [INFO    ] __main__: train step 7025: loss: 1.0177, policy_loss: 1.3004, value_loss: 0.8146
2024-07-11 16:21:29,267 [INFO    ] __main__: train step 7026: loss: 1.0177, policy_loss: 1.3004, value_loss: 0.8146
2024-07-11 16:21:29,467 [INFO    ] __main__: train step 7027: loss: 1.0178, policy_loss: 1.3003, value_loss: 0.8146
2024-07-11 16:21:29,677 [INFO    ] __main__: train step 7028: loss: 1.0178, policy_loss: 1.3002, value_loss: 0.8145
2024-07-11 16:21:29,887 [INFO    ] __main__: train step 7029: loss: 1.0179, policy_loss: 1.3001, value_loss: 0.8145
2024-07-11 16:21:30,103 [INFO    ] __main__: train step 7030: loss: 1.0179, policy_loss: 1.3000, value_loss: 0.8145
2024-07-11 16:21:30,308 [INFO    ] __main__: train step 7031: loss: 1.0180, policy_loss: 1.3000, value_loss: 0.8144
2024-07-11 16:21:30,510 [INFO    ] __main__: train step 7032: loss: 1.0180, policy_loss: 1.2999, value_loss: 0.8144
2024-07-11 16:21:30,716 [INFO    ] __main__: train step 7033: loss: 1.0181, policy_loss: 1.2998, value_loss: 0.8144
2024-07-11 16:21:30,922 [INFO    ] __main__: train step 7034: loss: 1.0181, policy_loss: 1.2997, value_loss: 0.8143
2024-07-11 16:21:31,128 [INFO    ] __main__: train step 7035: loss: 1.0181, policy_loss: 1.2997, value_loss: 0.8143
2024-07-11 16:21:31,331 [INFO    ] __main__: train step 7036: loss: 1.0182, policy_loss: 1.2996, value_loss: 0.8143
2024-07-11 16:21:31,545 [INFO    ] __main__: train step 7037: loss: 1.0182, policy_loss: 1.2995, value_loss: 0.8142
2024-07-11 16:21:32,975 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:21:33,401 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:21:33,457 [INFO    ] __main__: train step 7038: loss: 1.0183, policy_loss: 1.2994, value_loss: 0.8142
2024-07-11 16:21:33,628 [INFO    ] __main__: train step 7039: loss: 1.0183, policy_loss: 1.2994, value_loss: 0.8142
2024-07-11 16:21:33,843 [INFO    ] __main__: train step 7040: loss: 1.0184, policy_loss: 1.2993, value_loss: 0.8141
2024-07-11 16:21:34,043 [INFO    ] __main__: train step 7041: loss: 1.0184, policy_loss: 1.2992, value_loss: 0.8141
2024-07-11 16:21:34,242 [INFO    ] __main__: train step 7042: loss: 1.0185, policy_loss: 1.2991, value_loss: 0.8141
2024-07-11 16:21:34,455 [INFO    ] __main__: train step 7043: loss: 1.0185, policy_loss: 1.2990, value_loss: 0.8141
2024-07-11 16:21:34,673 [INFO    ] __main__: train step 7044: loss: 1.0185, policy_loss: 1.2990, value_loss: 0.8140
2024-07-11 16:21:34,903 [INFO    ] __main__: train step 7045: loss: 1.0186, policy_loss: 1.2989, value_loss: 0.8140
2024-07-11 16:21:35,136 [INFO    ] __main__: train step 7046: loss: 1.0186, policy_loss: 1.2988, value_loss: 0.8140
2024-07-11 16:21:35,327 [INFO    ] __main__: train step 7047: loss: 1.0187, policy_loss: 1.2987, value_loss: 0.8139
2024-07-11 16:21:35,540 [INFO    ] __main__: train step 7048: loss: 1.0187, policy_loss: 1.2987, value_loss: 0.8139
2024-07-11 16:21:35,758 [INFO    ] __main__: train step 7049: loss: 1.0188, policy_loss: 1.2986, value_loss: 0.8139
2024-07-11 16:21:35,993 [INFO    ] __main__: train step 7050: loss: 1.0188, policy_loss: 1.2985, value_loss: 0.8138
2024-07-11 16:21:36,203 [INFO    ] __main__: train step 7051: loss: 1.0189, policy_loss: 1.2984, value_loss: 0.8138
2024-07-11 16:21:36,397 [INFO    ] __main__: train step 7052: loss: 1.0189, policy_loss: 1.2984, value_loss: 0.8138
2024-07-11 16:21:36,604 [INFO    ] __main__: train step 7053: loss: 1.0190, policy_loss: 1.2983, value_loss: 0.8137
2024-07-11 16:21:36,807 [INFO    ] __main__: train step 7054: loss: 1.0190, policy_loss: 1.2982, value_loss: 0.8137
2024-07-11 16:21:38,234 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:21:38,635 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:21:38,693 [INFO    ] __main__: train step 7055: loss: 1.0190, policy_loss: 1.2981, value_loss: 0.8137
2024-07-11 16:21:38,872 [INFO    ] __main__: train step 7056: loss: 1.0191, policy_loss: 1.2980, value_loss: 0.8136
2024-07-11 16:21:39,106 [INFO    ] __main__: train step 7057: loss: 1.0191, policy_loss: 1.2980, value_loss: 0.8136
2024-07-11 16:21:39,322 [INFO    ] __main__: train step 7058: loss: 1.0192, policy_loss: 1.2979, value_loss: 0.8136
2024-07-11 16:21:39,540 [INFO    ] __main__: train step 7059: loss: 1.0192, policy_loss: 1.2978, value_loss: 0.8136
2024-07-11 16:21:39,748 [INFO    ] __main__: train step 7060: loss: 1.0193, policy_loss: 1.2977, value_loss: 0.8135
2024-07-11 16:21:39,943 [INFO    ] __main__: train step 7061: loss: 1.0193, policy_loss: 1.2977, value_loss: 0.8135
2024-07-11 16:21:40,139 [INFO    ] __main__: train step 7062: loss: 1.0193, policy_loss: 1.2976, value_loss: 0.8135
2024-07-11 16:21:40,345 [INFO    ] __main__: train step 7063: loss: 1.0194, policy_loss: 1.2975, value_loss: 0.8134
2024-07-11 16:21:40,546 [INFO    ] __main__: train step 7064: loss: 1.0194, policy_loss: 1.2974, value_loss: 0.8134
2024-07-11 16:21:40,747 [INFO    ] __main__: train step 7065: loss: 1.0195, policy_loss: 1.2973, value_loss: 0.8134
2024-07-11 16:21:40,966 [INFO    ] __main__: train step 7066: loss: 1.0195, policy_loss: 1.2973, value_loss: 0.8133
2024-07-11 16:21:41,169 [INFO    ] __main__: train step 7067: loss: 1.0196, policy_loss: 1.2972, value_loss: 0.8133
2024-07-11 16:21:41,378 [INFO    ] __main__: train step 7068: loss: 1.0196, policy_loss: 1.2971, value_loss: 0.8133
2024-07-11 16:21:41,623 [INFO    ] __main__: train step 7069: loss: 1.0197, policy_loss: 1.2970, value_loss: 0.8133
2024-07-11 16:21:41,862 [INFO    ] __main__: train step 7070: loss: 1.0197, policy_loss: 1.2970, value_loss: 0.8132
2024-07-11 16:21:42,053 [INFO    ] __main__: train step 7071: loss: 1.0198, policy_loss: 1.2969, value_loss: 0.8132
2024-07-11 16:21:43,508 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:21:43,778 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:21:43,833 [INFO    ] __main__: train step 7072: loss: 1.0198, policy_loss: 1.2968, value_loss: 0.8132
2024-07-11 16:21:44,012 [INFO    ] __main__: train step 7073: loss: 1.0198, policy_loss: 1.2967, value_loss: 0.8131
2024-07-11 16:21:44,205 [INFO    ] __main__: train step 7074: loss: 1.0199, policy_loss: 1.2966, value_loss: 0.8131
2024-07-11 16:21:44,411 [INFO    ] __main__: train step 7075: loss: 1.0199, policy_loss: 1.2966, value_loss: 0.8131
2024-07-11 16:21:44,610 [INFO    ] __main__: train step 7076: loss: 1.0200, policy_loss: 1.2965, value_loss: 0.8130
2024-07-11 16:21:45,654 [INFO    ] __main__: train step 7077: loss: 1.0200, policy_loss: 1.2964, value_loss: 0.8130
2024-07-11 16:21:45,876 [INFO    ] __main__: train step 7078: loss: 1.0201, policy_loss: 1.2963, value_loss: 0.8130
2024-07-11 16:21:46,076 [INFO    ] __main__: train step 7079: loss: 1.0201, policy_loss: 1.2963, value_loss: 0.8129
2024-07-11 16:21:46,319 [INFO    ] __main__: train step 7080: loss: 1.0201, policy_loss: 1.2962, value_loss: 0.8129
2024-07-11 16:21:46,521 [INFO    ] __main__: train step 7081: loss: 1.0202, policy_loss: 1.2961, value_loss: 0.8129
2024-07-11 16:21:46,724 [INFO    ] __main__: train step 7082: loss: 1.0202, policy_loss: 1.2960, value_loss: 0.8129
2024-07-11 16:21:46,963 [INFO    ] __main__: train step 7083: loss: 1.0203, policy_loss: 1.2959, value_loss: 0.8128
2024-07-11 16:21:47,209 [INFO    ] __main__: train step 7084: loss: 1.0203, policy_loss: 1.2959, value_loss: 0.8128
2024-07-11 16:21:47,442 [INFO    ] __main__: train step 7085: loss: 1.0204, policy_loss: 1.2958, value_loss: 0.8128
2024-07-11 16:21:47,659 [INFO    ] __main__: train step 7086: loss: 1.0204, policy_loss: 1.2957, value_loss: 0.8127
2024-07-11 16:21:47,897 [INFO    ] __main__: train step 7087: loss: 1.0204, policy_loss: 1.2956, value_loss: 0.8127
2024-07-11 16:21:48,100 [INFO    ] __main__: train step 7088: loss: 1.0205, policy_loss: 1.2956, value_loss: 0.8127
2024-07-11 16:21:49,529 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:21:49,913 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:21:49,973 [INFO    ] __main__: train step 7089: loss: 1.0205, policy_loss: 1.2955, value_loss: 0.8126
2024-07-11 16:21:50,157 [INFO    ] __main__: train step 7090: loss: 1.0206, policy_loss: 1.2954, value_loss: 0.8126
2024-07-11 16:21:50,359 [INFO    ] __main__: train step 7091: loss: 1.0206, policy_loss: 1.2953, value_loss: 0.8126
2024-07-11 16:21:50,624 [INFO    ] __main__: train step 7092: loss: 1.0207, policy_loss: 1.2952, value_loss: 0.8125
2024-07-11 16:21:50,851 [INFO    ] __main__: train step 7093: loss: 1.0207, policy_loss: 1.2952, value_loss: 0.8125
2024-07-11 16:21:51,059 [INFO    ] __main__: train step 7094: loss: 1.0207, policy_loss: 1.2951, value_loss: 0.8125
2024-07-11 16:21:51,267 [INFO    ] __main__: train step 7095: loss: 1.0208, policy_loss: 1.2950, value_loss: 0.8125
2024-07-11 16:21:51,474 [INFO    ] __main__: train step 7096: loss: 1.0208, policy_loss: 1.2949, value_loss: 0.8124
2024-07-11 16:21:51,685 [INFO    ] __main__: train step 7097: loss: 1.0209, policy_loss: 1.2949, value_loss: 0.8124
2024-07-11 16:21:51,886 [INFO    ] __main__: train step 7098: loss: 1.0209, policy_loss: 1.2948, value_loss: 0.8124
2024-07-11 16:21:52,095 [INFO    ] __main__: train step 7099: loss: 1.0210, policy_loss: 1.2947, value_loss: 0.8123
2024-07-11 16:21:52,311 [INFO    ] __main__: train step 7100: loss: 1.0210, policy_loss: 1.2946, value_loss: 0.8123
2024-07-11 16:21:52,521 [INFO    ] __main__: train step 7101: loss: 1.0211, policy_loss: 1.2946, value_loss: 0.8123
2024-07-11 16:21:52,734 [INFO    ] __main__: train step 7102: loss: 1.0211, policy_loss: 1.2945, value_loss: 0.8123
2024-07-11 16:21:52,949 [INFO    ] __main__: train step 7103: loss: 1.0211, policy_loss: 1.2944, value_loss: 0.8122
2024-07-11 16:21:53,172 [INFO    ] __main__: train step 7104: loss: 1.0212, policy_loss: 1.2943, value_loss: 0.8122
2024-07-11 16:21:53,394 [INFO    ] __main__: train step 7105: loss: 1.0212, policy_loss: 1.2943, value_loss: 0.8122
2024-07-11 16:21:54,836 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:21:55,208 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:21:55,266 [INFO    ] __main__: train step 7106: loss: 1.0213, policy_loss: 1.2942, value_loss: 0.8121
2024-07-11 16:21:55,445 [INFO    ] __main__: train step 7107: loss: 1.0213, policy_loss: 1.2941, value_loss: 0.8121
2024-07-11 16:21:55,657 [INFO    ] __main__: train step 7108: loss: 1.0214, policy_loss: 1.2940, value_loss: 0.8121
2024-07-11 16:21:55,892 [INFO    ] __main__: train step 7109: loss: 1.0214, policy_loss: 1.2939, value_loss: 0.8120
2024-07-11 16:21:56,111 [INFO    ] __main__: train step 7110: loss: 1.0215, policy_loss: 1.2939, value_loss: 0.8120
2024-07-11 16:21:56,336 [INFO    ] __main__: train step 7111: loss: 1.0215, policy_loss: 1.2938, value_loss: 0.8120
2024-07-11 16:21:56,558 [INFO    ] __main__: train step 7112: loss: 1.0215, policy_loss: 1.2937, value_loss: 0.8120
2024-07-11 16:21:56,759 [INFO    ] __main__: train step 7113: loss: 1.0216, policy_loss: 1.2936, value_loss: 0.8119
2024-07-11 16:21:56,976 [INFO    ] __main__: train step 7114: loss: 1.0216, policy_loss: 1.2936, value_loss: 0.8119
2024-07-11 16:21:57,201 [INFO    ] __main__: train step 7115: loss: 1.0217, policy_loss: 1.2935, value_loss: 0.8119
2024-07-11 16:21:57,404 [INFO    ] __main__: train step 7116: loss: 1.0217, policy_loss: 1.2934, value_loss: 0.8118
2024-07-11 16:21:57,604 [INFO    ] __main__: train step 7117: loss: 1.0218, policy_loss: 1.2933, value_loss: 0.8118
2024-07-11 16:21:57,816 [INFO    ] __main__: train step 7118: loss: 1.0218, policy_loss: 1.2933, value_loss: 0.8118
2024-07-11 16:21:58,006 [INFO    ] __main__: train step 7119: loss: 1.0218, policy_loss: 1.2932, value_loss: 0.8117
2024-07-11 16:21:58,207 [INFO    ] __main__: train step 7120: loss: 1.0219, policy_loss: 1.2931, value_loss: 0.8117
2024-07-11 16:21:58,415 [INFO    ] __main__: train step 7121: loss: 1.0219, policy_loss: 1.2930, value_loss: 0.8117
2024-07-11 16:21:58,615 [INFO    ] __main__: train step 7122: loss: 1.0220, policy_loss: 1.2930, value_loss: 0.8116
2024-07-11 16:22:00,072 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:22:00,442 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:22:00,497 [INFO    ] __main__: train step 7123: loss: 1.0220, policy_loss: 1.2929, value_loss: 0.8116
2024-07-11 16:22:00,671 [INFO    ] __main__: train step 7124: loss: 1.0221, policy_loss: 1.2928, value_loss: 0.8116
2024-07-11 16:22:00,873 [INFO    ] __main__: train step 7125: loss: 1.0221, policy_loss: 1.2927, value_loss: 0.8116
2024-07-11 16:22:01,097 [INFO    ] __main__: train step 7126: loss: 1.0221, policy_loss: 1.2926, value_loss: 0.8115
2024-07-11 16:22:01,291 [INFO    ] __main__: train step 7127: loss: 1.0222, policy_loss: 1.2926, value_loss: 0.8115
2024-07-11 16:22:01,491 [INFO    ] __main__: train step 7128: loss: 1.0222, policy_loss: 1.2925, value_loss: 0.8115
2024-07-11 16:22:01,702 [INFO    ] __main__: train step 7129: loss: 1.0223, policy_loss: 1.2924, value_loss: 0.8114
2024-07-11 16:22:01,899 [INFO    ] __main__: train step 7130: loss: 1.0223, policy_loss: 1.2923, value_loss: 0.8114
2024-07-11 16:22:02,107 [INFO    ] __main__: train step 7131: loss: 1.0224, policy_loss: 1.2923, value_loss: 0.8114
2024-07-11 16:22:02,345 [INFO    ] __main__: train step 7132: loss: 1.0224, policy_loss: 1.2922, value_loss: 0.8113
2024-07-11 16:22:02,556 [INFO    ] __main__: train step 7133: loss: 1.0224, policy_loss: 1.2921, value_loss: 0.8113
2024-07-11 16:22:02,750 [INFO    ] __main__: train step 7134: loss: 1.0225, policy_loss: 1.2920, value_loss: 0.8113
2024-07-11 16:22:02,942 [INFO    ] __main__: train step 7135: loss: 1.0225, policy_loss: 1.2919, value_loss: 0.8113
2024-07-11 16:22:03,141 [INFO    ] __main__: train step 7136: loss: 1.0226, policy_loss: 1.2919, value_loss: 0.8112
2024-07-11 16:22:03,347 [INFO    ] __main__: train step 7137: loss: 1.0226, policy_loss: 1.2918, value_loss: 0.8112
2024-07-11 16:22:03,560 [INFO    ] __main__: train step 7138: loss: 1.0227, policy_loss: 1.2917, value_loss: 0.8112
2024-07-11 16:22:03,759 [INFO    ] __main__: train step 7139: loss: 1.0227, policy_loss: 1.2916, value_loss: 0.8111
2024-07-11 16:22:05,203 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:22:05,622 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:22:05,682 [INFO    ] __main__: train step 7140: loss: 1.0227, policy_loss: 1.2916, value_loss: 0.8111
2024-07-11 16:22:05,855 [INFO    ] __main__: train step 7141: loss: 1.0228, policy_loss: 1.2915, value_loss: 0.8111
2024-07-11 16:22:06,073 [INFO    ] __main__: train step 7142: loss: 1.0228, policy_loss: 1.2914, value_loss: 0.8111
2024-07-11 16:22:06,278 [INFO    ] __main__: train step 7143: loss: 1.0229, policy_loss: 1.2913, value_loss: 0.8110
2024-07-11 16:22:06,480 [INFO    ] __main__: train step 7144: loss: 1.0229, policy_loss: 1.2912, value_loss: 0.8110
2024-07-11 16:22:06,680 [INFO    ] __main__: train step 7145: loss: 1.0230, policy_loss: 1.2912, value_loss: 0.8110
2024-07-11 16:22:06,882 [INFO    ] __main__: train step 7146: loss: 1.0230, policy_loss: 1.2911, value_loss: 0.8109
2024-07-11 16:22:07,088 [INFO    ] __main__: train step 7147: loss: 1.0230, policy_loss: 1.2910, value_loss: 0.8109
2024-07-11 16:22:07,293 [INFO    ] __main__: train step 7148: loss: 1.0231, policy_loss: 1.2909, value_loss: 0.8109
2024-07-11 16:22:07,502 [INFO    ] __main__: train step 7149: loss: 1.0231, policy_loss: 1.2909, value_loss: 0.8108
2024-07-11 16:22:07,694 [INFO    ] __main__: train step 7150: loss: 1.0232, policy_loss: 1.2908, value_loss: 0.8108
2024-07-11 16:22:07,902 [INFO    ] __main__: train step 7151: loss: 1.0232, policy_loss: 1.2907, value_loss: 0.8108
2024-07-11 16:22:08,990 [INFO    ] __main__: train step 7152: loss: 1.0233, policy_loss: 1.2906, value_loss: 0.8108
2024-07-11 16:22:09,209 [INFO    ] __main__: train step 7153: loss: 1.0233, policy_loss: 1.2906, value_loss: 0.8107
2024-07-11 16:22:09,414 [INFO    ] __main__: train step 7154: loss: 1.0233, policy_loss: 1.2905, value_loss: 0.8107
2024-07-11 16:22:09,617 [INFO    ] __main__: train step 7155: loss: 1.0234, policy_loss: 1.2904, value_loss: 0.8107
2024-07-11 16:22:09,822 [INFO    ] __main__: train step 7156: loss: 1.0234, policy_loss: 1.2903, value_loss: 0.8106
2024-07-11 16:22:11,251 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:22:11,658 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:22:11,716 [INFO    ] __main__: train step 7157: loss: 1.0235, policy_loss: 1.2903, value_loss: 0.8106
2024-07-11 16:22:11,890 [INFO    ] __main__: train step 7158: loss: 1.0235, policy_loss: 1.2902, value_loss: 0.8106
2024-07-11 16:22:12,097 [INFO    ] __main__: train step 7159: loss: 1.0235, policy_loss: 1.2901, value_loss: 0.8105
2024-07-11 16:22:12,313 [INFO    ] __main__: train step 7160: loss: 1.0236, policy_loss: 1.2900, value_loss: 0.8105
2024-07-11 16:22:12,519 [INFO    ] __main__: train step 7161: loss: 1.0236, policy_loss: 1.2899, value_loss: 0.8105
2024-07-11 16:22:12,719 [INFO    ] __main__: train step 7162: loss: 1.0237, policy_loss: 1.2899, value_loss: 0.8105
2024-07-11 16:22:12,932 [INFO    ] __main__: train step 7163: loss: 1.0237, policy_loss: 1.2898, value_loss: 0.8104
2024-07-11 16:22:13,145 [INFO    ] __main__: train step 7164: loss: 1.0238, policy_loss: 1.2897, value_loss: 0.8104
2024-07-11 16:22:13,347 [INFO    ] __main__: train step 7165: loss: 1.0238, policy_loss: 1.2896, value_loss: 0.8104
2024-07-11 16:22:13,551 [INFO    ] __main__: train step 7166: loss: 1.0238, policy_loss: 1.2896, value_loss: 0.8103
2024-07-11 16:22:13,766 [INFO    ] __main__: train step 7167: loss: 1.0239, policy_loss: 1.2895, value_loss: 0.8103
2024-07-11 16:22:13,976 [INFO    ] __main__: train step 7168: loss: 1.0239, policy_loss: 1.2894, value_loss: 0.8103
2024-07-11 16:22:14,193 [INFO    ] __main__: train step 7169: loss: 1.0240, policy_loss: 1.2893, value_loss: 0.8102
2024-07-11 16:22:14,419 [INFO    ] __main__: train step 7170: loss: 1.0240, policy_loss: 1.2893, value_loss: 0.8102
2024-07-11 16:22:14,641 [INFO    ] __main__: train step 7171: loss: 1.0240, policy_loss: 1.2892, value_loss: 0.8102
2024-07-11 16:22:14,875 [INFO    ] __main__: train step 7172: loss: 1.0241, policy_loss: 1.2891, value_loss: 0.8102
2024-07-11 16:22:15,079 [INFO    ] __main__: train step 7173: loss: 1.0241, policy_loss: 1.2890, value_loss: 0.8101
2024-07-11 16:22:16,520 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:22:16,911 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:22:16,965 [INFO    ] __main__: train step 7174: loss: 1.0242, policy_loss: 1.2889, value_loss: 0.8101
2024-07-11 16:22:17,145 [INFO    ] __main__: train step 7175: loss: 1.0242, policy_loss: 1.2889, value_loss: 0.8101
2024-07-11 16:22:17,359 [INFO    ] __main__: train step 7176: loss: 1.0243, policy_loss: 1.2888, value_loss: 0.8100
2024-07-11 16:22:17,568 [INFO    ] __main__: train step 7177: loss: 1.0243, policy_loss: 1.2887, value_loss: 0.8100
2024-07-11 16:22:17,794 [INFO    ] __main__: train step 7178: loss: 1.0243, policy_loss: 1.2886, value_loss: 0.8100
2024-07-11 16:22:17,999 [INFO    ] __main__: train step 7179: loss: 1.0244, policy_loss: 1.2886, value_loss: 0.8099
2024-07-11 16:22:18,191 [INFO    ] __main__: train step 7180: loss: 1.0244, policy_loss: 1.2885, value_loss: 0.8099
2024-07-11 16:22:18,396 [INFO    ] __main__: train step 7181: loss: 1.0245, policy_loss: 1.2884, value_loss: 0.8099
2024-07-11 16:22:18,605 [INFO    ] __main__: train step 7182: loss: 1.0245, policy_loss: 1.2883, value_loss: 0.8098
2024-07-11 16:22:18,804 [INFO    ] __main__: train step 7183: loss: 1.0245, policy_loss: 1.2882, value_loss: 0.8098
2024-07-11 16:22:19,039 [INFO    ] __main__: train step 7184: loss: 1.0246, policy_loss: 1.2882, value_loss: 0.8098
2024-07-11 16:22:19,231 [INFO    ] __main__: train step 7185: loss: 1.0246, policy_loss: 1.2881, value_loss: 0.8098
2024-07-11 16:22:19,432 [INFO    ] __main__: train step 7186: loss: 1.0247, policy_loss: 1.2880, value_loss: 0.8097
2024-07-11 16:22:19,639 [INFO    ] __main__: train step 7187: loss: 1.0247, policy_loss: 1.2879, value_loss: 0.8097
2024-07-11 16:22:19,884 [INFO    ] __main__: train step 7188: loss: 1.0247, policy_loss: 1.2879, value_loss: 0.8097
2024-07-11 16:22:20,139 [INFO    ] __main__: train step 7189: loss: 1.0248, policy_loss: 1.2878, value_loss: 0.8096
2024-07-11 16:22:20,359 [INFO    ] __main__: train step 7190: loss: 1.0248, policy_loss: 1.2877, value_loss: 0.8096
2024-07-11 16:22:21,826 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:22:22,205 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:22:22,266 [INFO    ] __main__: train step 7191: loss: 1.0249, policy_loss: 1.2876, value_loss: 0.8096
2024-07-11 16:22:22,440 [INFO    ] __main__: train step 7192: loss: 1.0249, policy_loss: 1.2875, value_loss: 0.8096
2024-07-11 16:22:22,638 [INFO    ] __main__: train step 7193: loss: 1.0249, policy_loss: 1.2875, value_loss: 0.8095
2024-07-11 16:22:22,858 [INFO    ] __main__: train step 7194: loss: 1.0250, policy_loss: 1.2874, value_loss: 0.8095
2024-07-11 16:22:23,093 [INFO    ] __main__: train step 7195: loss: 1.0250, policy_loss: 1.2873, value_loss: 0.8095
2024-07-11 16:22:23,320 [INFO    ] __main__: train step 7196: loss: 1.0251, policy_loss: 1.2872, value_loss: 0.8094
2024-07-11 16:22:23,523 [INFO    ] __main__: train step 7197: loss: 1.0251, policy_loss: 1.2872, value_loss: 0.8094
2024-07-11 16:22:23,740 [INFO    ] __main__: train step 7198: loss: 1.0251, policy_loss: 1.2871, value_loss: 0.8094
2024-07-11 16:22:23,934 [INFO    ] __main__: train step 7199: loss: 1.0252, policy_loss: 1.2870, value_loss: 0.8093
2024-07-11 16:22:24,129 [INFO    ] __main__: train step 7200: loss: 1.0252, policy_loss: 1.2869, value_loss: 0.8093
2024-07-11 16:22:24,325 [INFO    ] __main__: train step 7201: loss: 1.0253, policy_loss: 1.2869, value_loss: 0.8093
2024-07-11 16:22:24,523 [INFO    ] __main__: train step 7202: loss: 1.0253, policy_loss: 1.2868, value_loss: 0.8093
2024-07-11 16:22:24,718 [INFO    ] __main__: train step 7203: loss: 1.0253, policy_loss: 1.2867, value_loss: 0.8092
2024-07-11 16:22:24,915 [INFO    ] __main__: train step 7204: loss: 1.0254, policy_loss: 1.2866, value_loss: 0.8092
2024-07-11 16:22:25,118 [INFO    ] __main__: train step 7205: loss: 1.0254, policy_loss: 1.2865, value_loss: 0.8092
2024-07-11 16:22:25,321 [INFO    ] __main__: train step 7206: loss: 1.0255, policy_loss: 1.2865, value_loss: 0.8091
2024-07-11 16:22:25,522 [INFO    ] __main__: train step 7207: loss: 1.0255, policy_loss: 1.2864, value_loss: 0.8091
2024-07-11 16:22:26,967 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:22:27,387 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:22:27,452 [INFO    ] __main__: train step 7208: loss: 1.0256, policy_loss: 1.2863, value_loss: 0.8091
2024-07-11 16:22:27,618 [INFO    ] __main__: train step 7209: loss: 1.0256, policy_loss: 1.2862, value_loss: 0.8090
2024-07-11 16:22:27,818 [INFO    ] __main__: train step 7210: loss: 1.0256, policy_loss: 1.2862, value_loss: 0.8090
2024-07-11 16:22:28,023 [INFO    ] __main__: train step 7211: loss: 1.0257, policy_loss: 1.2861, value_loss: 0.8090
2024-07-11 16:22:28,237 [INFO    ] __main__: train step 7212: loss: 1.0257, policy_loss: 1.2860, value_loss: 0.8090
2024-07-11 16:22:28,451 [INFO    ] __main__: train step 7213: loss: 1.0257, policy_loss: 1.2859, value_loss: 0.8089
2024-07-11 16:22:28,649 [INFO    ] __main__: train step 7214: loss: 1.0258, policy_loss: 1.2859, value_loss: 0.8089
2024-07-11 16:22:28,865 [INFO    ] __main__: train step 7215: loss: 1.0258, policy_loss: 1.2858, value_loss: 0.8089
2024-07-11 16:22:29,083 [INFO    ] __main__: train step 7216: loss: 1.0259, policy_loss: 1.2857, value_loss: 0.8088
2024-07-11 16:22:29,290 [INFO    ] __main__: train step 7217: loss: 1.0259, policy_loss: 1.2856, value_loss: 0.8088
2024-07-11 16:22:29,491 [INFO    ] __main__: train step 7218: loss: 1.0260, policy_loss: 1.2856, value_loss: 0.8088
2024-07-11 16:22:29,717 [INFO    ] __main__: train step 7219: loss: 1.0260, policy_loss: 1.2855, value_loss: 0.8088
2024-07-11 16:22:29,951 [INFO    ] __main__: train step 7220: loss: 1.0260, policy_loss: 1.2854, value_loss: 0.8087
2024-07-11 16:22:30,148 [INFO    ] __main__: train step 7221: loss: 1.0261, policy_loss: 1.2853, value_loss: 0.8087
2024-07-11 16:22:30,347 [INFO    ] __main__: train step 7222: loss: 1.0261, policy_loss: 1.2853, value_loss: 0.8087
2024-07-11 16:22:30,564 [INFO    ] __main__: train step 7223: loss: 1.0262, policy_loss: 1.2852, value_loss: 0.8086
2024-07-11 16:22:30,761 [INFO    ] __main__: train step 7224: loss: 1.0262, policy_loss: 1.2851, value_loss: 0.8086
2024-07-11 16:22:33,056 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:22:33,473 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:22:33,529 [INFO    ] __main__: train step 7225: loss: 1.0262, policy_loss: 1.2850, value_loss: 0.8086
2024-07-11 16:22:33,696 [INFO    ] __main__: train step 7226: loss: 1.0263, policy_loss: 1.2849, value_loss: 0.8085
2024-07-11 16:22:33,909 [INFO    ] __main__: train step 7227: loss: 1.0263, policy_loss: 1.2849, value_loss: 0.8085
2024-07-11 16:22:34,134 [INFO    ] __main__: train step 7228: loss: 1.0264, policy_loss: 1.2848, value_loss: 0.8085
2024-07-11 16:22:34,363 [INFO    ] __main__: train step 7229: loss: 1.0264, policy_loss: 1.2847, value_loss: 0.8085
2024-07-11 16:22:34,561 [INFO    ] __main__: train step 7230: loss: 1.0264, policy_loss: 1.2846, value_loss: 0.8084
2024-07-11 16:22:34,770 [INFO    ] __main__: train step 7231: loss: 1.0265, policy_loss: 1.2846, value_loss: 0.8084
2024-07-11 16:22:34,983 [INFO    ] __main__: train step 7232: loss: 1.0265, policy_loss: 1.2845, value_loss: 0.8084
2024-07-11 16:22:35,189 [INFO    ] __main__: train step 7233: loss: 1.0266, policy_loss: 1.2844, value_loss: 0.8083
2024-07-11 16:22:35,389 [INFO    ] __main__: train step 7234: loss: 1.0266, policy_loss: 1.2843, value_loss: 0.8083
2024-07-11 16:22:35,599 [INFO    ] __main__: train step 7235: loss: 1.0266, policy_loss: 1.2842, value_loss: 0.8083
2024-07-11 16:22:35,831 [INFO    ] __main__: train step 7236: loss: 1.0267, policy_loss: 1.2842, value_loss: 0.8083
2024-07-11 16:22:36,032 [INFO    ] __main__: train step 7237: loss: 1.0267, policy_loss: 1.2841, value_loss: 0.8082
2024-07-11 16:22:36,240 [INFO    ] __main__: train step 7238: loss: 1.0268, policy_loss: 1.2840, value_loss: 0.8082
2024-07-11 16:22:36,448 [INFO    ] __main__: train step 7239: loss: 1.0268, policy_loss: 1.2839, value_loss: 0.8082
2024-07-11 16:22:36,651 [INFO    ] __main__: train step 7240: loss: 1.0268, policy_loss: 1.2839, value_loss: 0.8081
2024-07-11 16:22:36,876 [INFO    ] __main__: train step 7241: loss: 1.0269, policy_loss: 1.2838, value_loss: 0.8081
2024-07-11 16:22:38,310 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:22:38,749 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:22:38,809 [INFO    ] __main__: train step 7242: loss: 1.0269, policy_loss: 1.2837, value_loss: 0.8081
2024-07-11 16:22:38,977 [INFO    ] __main__: train step 7243: loss: 1.0270, policy_loss: 1.2836, value_loss: 0.8081
2024-07-11 16:22:39,171 [INFO    ] __main__: train step 7244: loss: 1.0270, policy_loss: 1.2836, value_loss: 0.8080
2024-07-11 16:22:39,382 [INFO    ] __main__: train step 7245: loss: 1.0270, policy_loss: 1.2835, value_loss: 0.8080
2024-07-11 16:22:39,609 [INFO    ] __main__: train step 7246: loss: 1.0271, policy_loss: 1.2834, value_loss: 0.8080
2024-07-11 16:22:39,814 [INFO    ] __main__: train step 7247: loss: 1.0271, policy_loss: 1.2833, value_loss: 0.8079
2024-07-11 16:22:40,008 [INFO    ] __main__: train step 7248: loss: 1.0272, policy_loss: 1.2833, value_loss: 0.8079
2024-07-11 16:22:40,219 [INFO    ] __main__: train step 7249: loss: 1.0272, policy_loss: 1.2832, value_loss: 0.8079
2024-07-11 16:22:40,430 [INFO    ] __main__: train step 7250: loss: 1.0272, policy_loss: 1.2831, value_loss: 0.8078
2024-07-11 16:22:40,655 [INFO    ] __main__: train step 7251: loss: 1.0273, policy_loss: 1.2830, value_loss: 0.8078
2024-07-11 16:22:40,859 [INFO    ] __main__: train step 7252: loss: 1.0273, policy_loss: 1.2830, value_loss: 0.8078
2024-07-11 16:22:41,088 [INFO    ] __main__: train step 7253: loss: 1.0274, policy_loss: 1.2829, value_loss: 0.8078
2024-07-11 16:22:41,301 [INFO    ] __main__: train step 7254: loss: 1.0274, policy_loss: 1.2828, value_loss: 0.8077
2024-07-11 16:22:41,499 [INFO    ] __main__: train step 7255: loss: 1.0274, policy_loss: 1.2827, value_loss: 0.8077
2024-07-11 16:22:41,715 [INFO    ] __main__: train step 7256: loss: 1.0275, policy_loss: 1.2826, value_loss: 0.8077
2024-07-11 16:22:41,926 [INFO    ] __main__: train step 7257: loss: 1.0275, policy_loss: 1.2826, value_loss: 0.8076
2024-07-11 16:22:42,152 [INFO    ] __main__: train step 7258: loss: 1.0276, policy_loss: 1.2825, value_loss: 0.8076
2024-07-11 16:22:43,599 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:22:43,999 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:22:44,055 [INFO    ] __main__: train step 7259: loss: 1.0276, policy_loss: 1.2824, value_loss: 0.8076
2024-07-11 16:22:44,228 [INFO    ] __main__: train step 7260: loss: 1.0276, policy_loss: 1.2823, value_loss: 0.8076
2024-07-11 16:22:44,429 [INFO    ] __main__: train step 7261: loss: 1.0277, policy_loss: 1.2823, value_loss: 0.8075
2024-07-11 16:22:44,645 [INFO    ] __main__: train step 7262: loss: 1.0277, policy_loss: 1.2822, value_loss: 0.8075
2024-07-11 16:22:44,867 [INFO    ] __main__: train step 7263: loss: 1.0278, policy_loss: 1.2821, value_loss: 0.8075
2024-07-11 16:22:45,068 [INFO    ] __main__: train step 7264: loss: 1.0278, policy_loss: 1.2820, value_loss: 0.8074
2024-07-11 16:22:45,280 [INFO    ] __main__: train step 7265: loss: 1.0278, policy_loss: 1.2820, value_loss: 0.8074
2024-07-11 16:22:45,484 [INFO    ] __main__: train step 7266: loss: 1.0279, policy_loss: 1.2819, value_loss: 0.8074
2024-07-11 16:22:45,683 [INFO    ] __main__: train step 7267: loss: 1.0279, policy_loss: 1.2818, value_loss: 0.8073
2024-07-11 16:22:45,886 [INFO    ] __main__: train step 7268: loss: 1.0279, policy_loss: 1.2817, value_loss: 0.8073
2024-07-11 16:22:46,089 [INFO    ] __main__: train step 7269: loss: 1.0280, policy_loss: 1.2817, value_loss: 0.8073
2024-07-11 16:22:46,294 [INFO    ] __main__: train step 7270: loss: 1.0280, policy_loss: 1.2816, value_loss: 0.8073
2024-07-11 16:22:46,505 [INFO    ] __main__: train step 7271: loss: 1.0281, policy_loss: 1.2815, value_loss: 0.8072
2024-07-11 16:22:46,699 [INFO    ] __main__: train step 7272: loss: 1.0281, policy_loss: 1.2814, value_loss: 0.8072
2024-07-11 16:22:46,906 [INFO    ] __main__: train step 7273: loss: 1.0281, policy_loss: 1.2813, value_loss: 0.8072
2024-07-11 16:22:47,110 [INFO    ] __main__: train step 7274: loss: 1.0282, policy_loss: 1.2813, value_loss: 0.8071
2024-07-11 16:22:47,309 [INFO    ] __main__: train step 7275: loss: 1.0282, policy_loss: 1.2812, value_loss: 0.8071
2024-07-11 16:22:48,726 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:22:49,154 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:22:49,216 [INFO    ] __main__: train step 7276: loss: 1.0283, policy_loss: 1.2811, value_loss: 0.8071
2024-07-11 16:22:49,390 [INFO    ] __main__: train step 7277: loss: 1.0283, policy_loss: 1.2810, value_loss: 0.8071
2024-07-11 16:22:49,595 [INFO    ] __main__: train step 7278: loss: 1.0283, policy_loss: 1.2810, value_loss: 0.8070
2024-07-11 16:22:49,810 [INFO    ] __main__: train step 7279: loss: 1.0284, policy_loss: 1.2809, value_loss: 0.8070
2024-07-11 16:22:50,015 [INFO    ] __main__: train step 7280: loss: 1.0284, policy_loss: 1.2808, value_loss: 0.8070
2024-07-11 16:22:50,211 [INFO    ] __main__: train step 7281: loss: 1.0285, policy_loss: 1.2807, value_loss: 0.8069
2024-07-11 16:22:50,415 [INFO    ] __main__: train step 7282: loss: 1.0285, policy_loss: 1.2807, value_loss: 0.8069
2024-07-11 16:22:50,637 [INFO    ] __main__: train step 7283: loss: 1.0285, policy_loss: 1.2806, value_loss: 0.8069
2024-07-11 16:22:50,870 [INFO    ] __main__: train step 7284: loss: 1.0286, policy_loss: 1.2805, value_loss: 0.8068
2024-07-11 16:22:51,068 [INFO    ] __main__: train step 7285: loss: 1.0286, policy_loss: 1.2804, value_loss: 0.8068
2024-07-11 16:22:51,272 [INFO    ] __main__: train step 7286: loss: 1.0286, policy_loss: 1.2804, value_loss: 0.8068
2024-07-11 16:22:51,481 [INFO    ] __main__: train step 7287: loss: 1.0287, policy_loss: 1.2803, value_loss: 0.8068
2024-07-11 16:22:51,685 [INFO    ] __main__: train step 7288: loss: 1.0287, policy_loss: 1.2802, value_loss: 0.8067
2024-07-11 16:22:51,898 [INFO    ] __main__: train step 7289: loss: 1.0287, policy_loss: 1.2801, value_loss: 0.8067
2024-07-11 16:22:52,102 [INFO    ] __main__: train step 7290: loss: 1.0288, policy_loss: 1.2801, value_loss: 0.8067
2024-07-11 16:22:52,309 [INFO    ] __main__: train step 7291: loss: 1.0288, policy_loss: 1.2800, value_loss: 0.8066
2024-07-11 16:22:52,512 [INFO    ] __main__: train step 7292: loss: 1.0289, policy_loss: 1.2799, value_loss: 0.8066
2024-07-11 16:22:53,944 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:22:54,397 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:22:54,457 [INFO    ] __main__: train step 7293: loss: 1.0289, policy_loss: 1.2798, value_loss: 0.8066
2024-07-11 16:22:54,624 [INFO    ] __main__: train step 7294: loss: 1.0289, policy_loss: 1.2797, value_loss: 0.8066
2024-07-11 16:22:54,838 [INFO    ] __main__: train step 7295: loss: 1.0290, policy_loss: 1.2797, value_loss: 0.8065
2024-07-11 16:22:55,044 [INFO    ] __main__: train step 7296: loss: 1.0290, policy_loss: 1.2796, value_loss: 0.8065
2024-07-11 16:22:55,243 [INFO    ] __main__: train step 7297: loss: 1.0291, policy_loss: 1.2795, value_loss: 0.8065
2024-07-11 16:22:55,450 [INFO    ] __main__: train step 7298: loss: 1.0291, policy_loss: 1.2794, value_loss: 0.8064
2024-07-11 16:22:56,523 [INFO    ] __main__: train step 7299: loss: 1.0291, policy_loss: 1.2794, value_loss: 0.8064
2024-07-11 16:22:56,768 [INFO    ] __main__: train step 7300: loss: 1.0292, policy_loss: 1.2793, value_loss: 0.8064
2024-07-11 16:22:56,964 [INFO    ] __main__: train step 7301: loss: 1.0292, policy_loss: 1.2792, value_loss: 0.8064
2024-07-11 16:22:57,160 [INFO    ] __main__: train step 7302: loss: 1.0293, policy_loss: 1.2791, value_loss: 0.8063
2024-07-11 16:22:57,364 [INFO    ] __main__: train step 7303: loss: 1.0293, policy_loss: 1.2791, value_loss: 0.8063
2024-07-11 16:22:57,565 [INFO    ] __main__: train step 7304: loss: 1.0293, policy_loss: 1.2790, value_loss: 0.8063
2024-07-11 16:22:57,767 [INFO    ] __main__: train step 7305: loss: 1.0294, policy_loss: 1.2789, value_loss: 0.8062
2024-07-11 16:22:57,965 [INFO    ] __main__: train step 7306: loss: 1.0294, policy_loss: 1.2788, value_loss: 0.8062
2024-07-11 16:22:58,171 [INFO    ] __main__: train step 7307: loss: 1.0295, policy_loss: 1.2788, value_loss: 0.8062
2024-07-11 16:22:58,379 [INFO    ] __main__: train step 7308: loss: 1.0295, policy_loss: 1.2787, value_loss: 0.8062
2024-07-11 16:22:58,580 [INFO    ] __main__: train step 7309: loss: 1.0295, policy_loss: 1.2786, value_loss: 0.8061
2024-07-11 16:23:00,030 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:23:00,464 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:23:00,522 [INFO    ] __main__: train step 7310: loss: 1.0296, policy_loss: 1.2785, value_loss: 0.8061
2024-07-11 16:23:00,701 [INFO    ] __main__: train step 7311: loss: 1.0296, policy_loss: 1.2785, value_loss: 0.8061
2024-07-11 16:23:00,892 [INFO    ] __main__: train step 7312: loss: 1.0296, policy_loss: 1.2784, value_loss: 0.8060
2024-07-11 16:23:01,093 [INFO    ] __main__: train step 7313: loss: 1.0297, policy_loss: 1.2783, value_loss: 0.8060
2024-07-11 16:23:01,302 [INFO    ] __main__: train step 7314: loss: 1.0297, policy_loss: 1.2782, value_loss: 0.8060
2024-07-11 16:23:01,502 [INFO    ] __main__: train step 7315: loss: 1.0297, policy_loss: 1.2781, value_loss: 0.8060
2024-07-11 16:23:01,710 [INFO    ] __main__: train step 7316: loss: 1.0298, policy_loss: 1.2781, value_loss: 0.8059
2024-07-11 16:23:01,905 [INFO    ] __main__: train step 7317: loss: 1.0298, policy_loss: 1.2780, value_loss: 0.8059
2024-07-11 16:23:02,112 [INFO    ] __main__: train step 7318: loss: 1.0299, policy_loss: 1.2779, value_loss: 0.8059
2024-07-11 16:23:02,316 [INFO    ] __main__: train step 7319: loss: 1.0299, policy_loss: 1.2778, value_loss: 0.8058
2024-07-11 16:23:02,552 [INFO    ] __main__: train step 7320: loss: 1.0299, policy_loss: 1.2778, value_loss: 0.8058
2024-07-11 16:23:02,759 [INFO    ] __main__: train step 7321: loss: 1.0300, policy_loss: 1.2777, value_loss: 0.8058
2024-07-11 16:23:02,958 [INFO    ] __main__: train step 7322: loss: 1.0300, policy_loss: 1.2776, value_loss: 0.8058
2024-07-11 16:23:03,154 [INFO    ] __main__: train step 7323: loss: 1.0301, policy_loss: 1.2775, value_loss: 0.8057
2024-07-11 16:23:03,362 [INFO    ] __main__: train step 7324: loss: 1.0301, policy_loss: 1.2775, value_loss: 0.8057
2024-07-11 16:23:03,559 [INFO    ] __main__: train step 7325: loss: 1.0301, policy_loss: 1.2774, value_loss: 0.8057
2024-07-11 16:23:03,759 [INFO    ] __main__: train step 7326: loss: 1.0302, policy_loss: 1.2773, value_loss: 0.8056
2024-07-11 16:23:05,202 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:23:05,635 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:23:05,690 [INFO    ] __main__: train step 7327: loss: 1.0302, policy_loss: 1.2772, value_loss: 0.8056
2024-07-11 16:23:05,878 [INFO    ] __main__: train step 7328: loss: 1.0303, policy_loss: 1.2772, value_loss: 0.8056
2024-07-11 16:23:06,098 [INFO    ] __main__: train step 7329: loss: 1.0303, policy_loss: 1.2771, value_loss: 0.8056
2024-07-11 16:23:06,298 [INFO    ] __main__: train step 7330: loss: 1.0303, policy_loss: 1.2770, value_loss: 0.8055
2024-07-11 16:23:06,498 [INFO    ] __main__: train step 7331: loss: 1.0304, policy_loss: 1.2769, value_loss: 0.8055
2024-07-11 16:23:06,694 [INFO    ] __main__: train step 7332: loss: 1.0304, policy_loss: 1.2769, value_loss: 0.8055
2024-07-11 16:23:06,902 [INFO    ] __main__: train step 7333: loss: 1.0304, policy_loss: 1.2768, value_loss: 0.8054
2024-07-11 16:23:07,097 [INFO    ] __main__: train step 7334: loss: 1.0305, policy_loss: 1.2767, value_loss: 0.8054
2024-07-11 16:23:07,304 [INFO    ] __main__: train step 7335: loss: 1.0305, policy_loss: 1.2766, value_loss: 0.8054
2024-07-11 16:23:07,499 [INFO    ] __main__: train step 7336: loss: 1.0306, policy_loss: 1.2765, value_loss: 0.8054
2024-07-11 16:23:07,708 [INFO    ] __main__: train step 7337: loss: 1.0306, policy_loss: 1.2765, value_loss: 0.8053
2024-07-11 16:23:07,928 [INFO    ] __main__: train step 7338: loss: 1.0306, policy_loss: 1.2764, value_loss: 0.8053
2024-07-11 16:23:08,135 [INFO    ] __main__: train step 7339: loss: 1.0307, policy_loss: 1.2763, value_loss: 0.8053
2024-07-11 16:23:08,373 [INFO    ] __main__: train step 7340: loss: 1.0307, policy_loss: 1.2762, value_loss: 0.8052
2024-07-11 16:23:08,576 [INFO    ] __main__: train step 7341: loss: 1.0307, policy_loss: 1.2762, value_loss: 0.8052
2024-07-11 16:23:08,793 [INFO    ] __main__: train step 7342: loss: 1.0308, policy_loss: 1.2761, value_loss: 0.8052
2024-07-11 16:23:09,004 [INFO    ] __main__: train step 7343: loss: 1.0308, policy_loss: 1.2760, value_loss: 0.8052
2024-07-11 16:23:10,436 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:23:10,881 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:23:10,937 [INFO    ] __main__: train step 7344: loss: 1.0309, policy_loss: 1.2759, value_loss: 0.8051
2024-07-11 16:23:11,109 [INFO    ] __main__: train step 7345: loss: 1.0309, policy_loss: 1.2759, value_loss: 0.8051
2024-07-11 16:23:11,324 [INFO    ] __main__: train step 7346: loss: 1.0309, policy_loss: 1.2758, value_loss: 0.8051
2024-07-11 16:23:11,531 [INFO    ] __main__: train step 7347: loss: 1.0310, policy_loss: 1.2757, value_loss: 0.8051
2024-07-11 16:23:11,735 [INFO    ] __main__: train step 7348: loss: 1.0310, policy_loss: 1.2756, value_loss: 0.8050
2024-07-11 16:23:11,945 [INFO    ] __main__: train step 7349: loss: 1.0311, policy_loss: 1.2756, value_loss: 0.8050
2024-07-11 16:23:12,140 [INFO    ] __main__: train step 7350: loss: 1.0311, policy_loss: 1.2755, value_loss: 0.8050
2024-07-11 16:23:12,362 [INFO    ] __main__: train step 7351: loss: 1.0311, policy_loss: 1.2754, value_loss: 0.8049
2024-07-11 16:23:12,571 [INFO    ] __main__: train step 7352: loss: 1.0312, policy_loss: 1.2753, value_loss: 0.8049
2024-07-11 16:23:12,773 [INFO    ] __main__: train step 7353: loss: 1.0312, policy_loss: 1.2753, value_loss: 0.8049
2024-07-11 16:23:12,973 [INFO    ] __main__: train step 7354: loss: 1.0312, policy_loss: 1.2752, value_loss: 0.8049
2024-07-11 16:23:13,184 [INFO    ] __main__: train step 7355: loss: 1.0313, policy_loss: 1.2751, value_loss: 0.8048
2024-07-11 16:23:13,395 [INFO    ] __main__: train step 7356: loss: 1.0313, policy_loss: 1.2750, value_loss: 0.8048
2024-07-11 16:23:13,629 [INFO    ] __main__: train step 7357: loss: 1.0313, policy_loss: 1.2749, value_loss: 0.8048
2024-07-11 16:23:13,839 [INFO    ] __main__: train step 7358: loss: 1.0314, policy_loss: 1.2749, value_loss: 0.8047
2024-07-11 16:23:14,058 [INFO    ] __main__: train step 7359: loss: 1.0314, policy_loss: 1.2748, value_loss: 0.8047
2024-07-11 16:23:14,259 [INFO    ] __main__: train step 7360: loss: 1.0315, policy_loss: 1.2747, value_loss: 0.8047
2024-07-11 16:23:15,682 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:23:16,087 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:23:16,143 [INFO    ] __main__: train step 7361: loss: 1.0315, policy_loss: 1.2746, value_loss: 0.8047
2024-07-11 16:23:16,317 [INFO    ] __main__: train step 7362: loss: 1.0315, policy_loss: 1.2746, value_loss: 0.8046
2024-07-11 16:23:16,527 [INFO    ] __main__: train step 7363: loss: 1.0316, policy_loss: 1.2745, value_loss: 0.8046
2024-07-11 16:23:16,720 [INFO    ] __main__: train step 7364: loss: 1.0316, policy_loss: 1.2744, value_loss: 0.8046
2024-07-11 16:23:16,929 [INFO    ] __main__: train step 7365: loss: 1.0316, policy_loss: 1.2743, value_loss: 0.8045
2024-07-11 16:23:17,126 [INFO    ] __main__: train step 7366: loss: 1.0317, policy_loss: 1.2743, value_loss: 0.8045
2024-07-11 16:23:17,320 [INFO    ] __main__: train step 7367: loss: 1.0317, policy_loss: 1.2742, value_loss: 0.8045
2024-07-11 16:23:17,525 [INFO    ] __main__: train step 7368: loss: 1.0318, policy_loss: 1.2741, value_loss: 0.8045
2024-07-11 16:23:17,723 [INFO    ] __main__: train step 7369: loss: 1.0318, policy_loss: 1.2740, value_loss: 0.8044
2024-07-11 16:23:17,923 [INFO    ] __main__: train step 7370: loss: 1.0318, policy_loss: 1.2739, value_loss: 0.8044
2024-07-11 16:23:18,116 [INFO    ] __main__: train step 7371: loss: 1.0319, policy_loss: 1.2739, value_loss: 0.8044
2024-07-11 16:23:19,140 [INFO    ] __main__: train step 7372: loss: 1.0319, policy_loss: 1.2738, value_loss: 0.8044
2024-07-11 16:23:19,357 [INFO    ] __main__: train step 7373: loss: 1.0319, policy_loss: 1.2737, value_loss: 0.8043
2024-07-11 16:23:19,553 [INFO    ] __main__: train step 7374: loss: 1.0320, policy_loss: 1.2736, value_loss: 0.8043
2024-07-11 16:23:19,753 [INFO    ] __main__: train step 7375: loss: 1.0320, policy_loss: 1.2736, value_loss: 0.8043
2024-07-11 16:23:19,949 [INFO    ] __main__: train step 7376: loss: 1.0321, policy_loss: 1.2735, value_loss: 0.8043
2024-07-11 16:23:20,147 [INFO    ] __main__: train step 7377: loss: 1.0321, policy_loss: 1.2734, value_loss: 0.8042
2024-07-11 16:23:21,593 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:23:22,003 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:23:22,059 [INFO    ] __main__: train step 7378: loss: 1.0321, policy_loss: 1.2733, value_loss: 0.8042
2024-07-11 16:23:22,227 [INFO    ] __main__: train step 7379: loss: 1.0322, policy_loss: 1.2733, value_loss: 0.8042
2024-07-11 16:23:22,425 [INFO    ] __main__: train step 7380: loss: 1.0322, policy_loss: 1.2732, value_loss: 0.8041
2024-07-11 16:23:22,637 [INFO    ] __main__: train step 7381: loss: 1.0322, policy_loss: 1.2731, value_loss: 0.8041
2024-07-11 16:23:22,876 [INFO    ] __main__: train step 7382: loss: 1.0323, policy_loss: 1.2730, value_loss: 0.8041
2024-07-11 16:23:23,072 [INFO    ] __main__: train step 7383: loss: 1.0323, policy_loss: 1.2730, value_loss: 0.8041
2024-07-11 16:23:23,279 [INFO    ] __main__: train step 7384: loss: 1.0323, policy_loss: 1.2729, value_loss: 0.8040
2024-07-11 16:23:23,490 [INFO    ] __main__: train step 7385: loss: 1.0324, policy_loss: 1.2728, value_loss: 0.8040
2024-07-11 16:23:23,690 [INFO    ] __main__: train step 7386: loss: 1.0324, policy_loss: 1.2727, value_loss: 0.8040
2024-07-11 16:23:23,891 [INFO    ] __main__: train step 7387: loss: 1.0325, policy_loss: 1.2727, value_loss: 0.8040
2024-07-11 16:23:24,101 [INFO    ] __main__: train step 7388: loss: 1.0325, policy_loss: 1.2726, value_loss: 0.8039
2024-07-11 16:23:24,304 [INFO    ] __main__: train step 7389: loss: 1.0325, policy_loss: 1.2725, value_loss: 0.8039
2024-07-11 16:23:24,498 [INFO    ] __main__: train step 7390: loss: 1.0326, policy_loss: 1.2724, value_loss: 0.8039
2024-07-11 16:23:24,707 [INFO    ] __main__: train step 7391: loss: 1.0326, policy_loss: 1.2723, value_loss: 0.8038
2024-07-11 16:23:24,912 [INFO    ] __main__: train step 7392: loss: 1.0326, policy_loss: 1.2723, value_loss: 0.8038
2024-07-11 16:23:25,140 [INFO    ] __main__: train step 7393: loss: 1.0327, policy_loss: 1.2722, value_loss: 0.8038
2024-07-11 16:23:25,343 [INFO    ] __main__: train step 7394: loss: 1.0327, policy_loss: 1.2721, value_loss: 0.8038
2024-07-11 16:23:26,776 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:23:27,180 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:23:27,240 [INFO    ] __main__: train step 7395: loss: 1.0328, policy_loss: 1.2720, value_loss: 0.8037
2024-07-11 16:23:27,424 [INFO    ] __main__: train step 7396: loss: 1.0328, policy_loss: 1.2720, value_loss: 0.8037
2024-07-11 16:23:27,616 [INFO    ] __main__: train step 7397: loss: 1.0328, policy_loss: 1.2719, value_loss: 0.8037
2024-07-11 16:23:27,815 [INFO    ] __main__: train step 7398: loss: 1.0329, policy_loss: 1.2718, value_loss: 0.8037
2024-07-11 16:23:28,016 [INFO    ] __main__: train step 7399: loss: 1.0329, policy_loss: 1.2717, value_loss: 0.8036
2024-07-11 16:23:28,228 [INFO    ] __main__: train step 7400: loss: 1.0329, policy_loss: 1.2717, value_loss: 0.8036
2024-07-11 16:23:28,430 [INFO    ] __main__: train step 7401: loss: 1.0330, policy_loss: 1.2716, value_loss: 0.8036
2024-07-11 16:23:28,628 [INFO    ] __main__: train step 7402: loss: 1.0330, policy_loss: 1.2715, value_loss: 0.8035
2024-07-11 16:23:28,844 [INFO    ] __main__: train step 7403: loss: 1.0330, policy_loss: 1.2714, value_loss: 0.8035
2024-07-11 16:23:29,075 [INFO    ] __main__: train step 7404: loss: 1.0331, policy_loss: 1.2714, value_loss: 0.8035
2024-07-11 16:23:29,275 [INFO    ] __main__: train step 7405: loss: 1.0331, policy_loss: 1.2713, value_loss: 0.8035
2024-07-11 16:23:29,486 [INFO    ] __main__: train step 7406: loss: 1.0332, policy_loss: 1.2712, value_loss: 0.8034
2024-07-11 16:23:29,683 [INFO    ] __main__: train step 7407: loss: 1.0332, policy_loss: 1.2711, value_loss: 0.8034
2024-07-11 16:23:29,886 [INFO    ] __main__: train step 7408: loss: 1.0332, policy_loss: 1.2711, value_loss: 0.8034
2024-07-11 16:23:30,095 [INFO    ] __main__: train step 7409: loss: 1.0333, policy_loss: 1.2710, value_loss: 0.8034
2024-07-11 16:23:30,335 [INFO    ] __main__: train step 7410: loss: 1.0333, policy_loss: 1.2709, value_loss: 0.8033
2024-07-11 16:23:30,527 [INFO    ] __main__: train step 7411: loss: 1.0333, policy_loss: 1.2708, value_loss: 0.8033
2024-07-11 16:23:31,980 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:23:32,398 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:23:32,454 [INFO    ] __main__: train step 7412: loss: 1.0334, policy_loss: 1.2707, value_loss: 0.8033
2024-07-11 16:23:32,634 [INFO    ] __main__: train step 7413: loss: 1.0334, policy_loss: 1.2707, value_loss: 0.8032
2024-07-11 16:23:32,838 [INFO    ] __main__: train step 7414: loss: 1.0334, policy_loss: 1.2706, value_loss: 0.8032
2024-07-11 16:23:33,050 [INFO    ] __main__: train step 7415: loss: 1.0335, policy_loss: 1.2705, value_loss: 0.8032
2024-07-11 16:23:33,251 [INFO    ] __main__: train step 7416: loss: 1.0335, policy_loss: 1.2704, value_loss: 0.8032
2024-07-11 16:23:33,461 [INFO    ] __main__: train step 7417: loss: 1.0335, policy_loss: 1.2704, value_loss: 0.8031
2024-07-11 16:23:33,674 [INFO    ] __main__: train step 7418: loss: 1.0336, policy_loss: 1.2703, value_loss: 0.8031
2024-07-11 16:23:33,878 [INFO    ] __main__: train step 7419: loss: 1.0336, policy_loss: 1.2702, value_loss: 0.8031
2024-07-11 16:23:34,088 [INFO    ] __main__: train step 7420: loss: 1.0336, policy_loss: 1.2701, value_loss: 0.8031
2024-07-11 16:23:34,297 [INFO    ] __main__: train step 7421: loss: 1.0337, policy_loss: 1.2701, value_loss: 0.8030
2024-07-11 16:23:34,494 [INFO    ] __main__: train step 7422: loss: 1.0337, policy_loss: 1.2700, value_loss: 0.8030
2024-07-11 16:23:34,699 [INFO    ] __main__: train step 7423: loss: 1.0338, policy_loss: 1.2699, value_loss: 0.8030
2024-07-11 16:23:34,909 [INFO    ] __main__: train step 7424: loss: 1.0338, policy_loss: 1.2698, value_loss: 0.8030
2024-07-11 16:23:35,111 [INFO    ] __main__: train step 7425: loss: 1.0338, policy_loss: 1.2697, value_loss: 0.8029
2024-07-11 16:23:35,308 [INFO    ] __main__: train step 7426: loss: 1.0339, policy_loss: 1.2697, value_loss: 0.8029
2024-07-11 16:23:35,499 [INFO    ] __main__: train step 7427: loss: 1.0339, policy_loss: 1.2696, value_loss: 0.8029
2024-07-11 16:23:35,730 [INFO    ] __main__: train step 7428: loss: 1.0339, policy_loss: 1.2695, value_loss: 0.8029
2024-07-11 16:23:37,173 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:23:37,703 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:23:37,764 [INFO    ] __main__: train step 7429: loss: 1.0340, policy_loss: 1.2694, value_loss: 0.8028
2024-07-11 16:23:37,954 [INFO    ] __main__: train step 7430: loss: 1.0340, policy_loss: 1.2694, value_loss: 0.8028
2024-07-11 16:23:38,165 [INFO    ] __main__: train step 7431: loss: 1.0340, policy_loss: 1.2693, value_loss: 0.8028
2024-07-11 16:23:38,373 [INFO    ] __main__: train step 7432: loss: 1.0341, policy_loss: 1.2692, value_loss: 0.8027
2024-07-11 16:23:38,572 [INFO    ] __main__: train step 7433: loss: 1.0341, policy_loss: 1.2691, value_loss: 0.8027
2024-07-11 16:23:38,767 [INFO    ] __main__: train step 7434: loss: 1.0342, policy_loss: 1.2691, value_loss: 0.8027
2024-07-11 16:23:38,966 [INFO    ] __main__: train step 7435: loss: 1.0342, policy_loss: 1.2690, value_loss: 0.8027
2024-07-11 16:23:39,177 [INFO    ] __main__: train step 7436: loss: 1.0342, policy_loss: 1.2689, value_loss: 0.8026
2024-07-11 16:23:39,375 [INFO    ] __main__: train step 7437: loss: 1.0343, policy_loss: 1.2688, value_loss: 0.8026
2024-07-11 16:23:39,578 [INFO    ] __main__: train step 7438: loss: 1.0343, policy_loss: 1.2687, value_loss: 0.8026
2024-07-11 16:23:39,789 [INFO    ] __main__: train step 7439: loss: 1.0343, policy_loss: 1.2687, value_loss: 0.8026
2024-07-11 16:23:39,986 [INFO    ] __main__: train step 7440: loss: 1.0344, policy_loss: 1.2686, value_loss: 0.8025
2024-07-11 16:23:40,196 [INFO    ] __main__: train step 7441: loss: 1.0344, policy_loss: 1.2685, value_loss: 0.8025
2024-07-11 16:23:40,401 [INFO    ] __main__: train step 7442: loss: 1.0344, policy_loss: 1.2684, value_loss: 0.8025
2024-07-11 16:23:40,605 [INFO    ] __main__: train step 7443: loss: 1.0345, policy_loss: 1.2684, value_loss: 0.8024
2024-07-11 16:23:40,804 [INFO    ] __main__: train step 7444: loss: 1.0345, policy_loss: 1.2683, value_loss: 0.8024
2024-07-11 16:23:41,015 [INFO    ] __main__: train step 7445: loss: 1.0345, policy_loss: 1.2682, value_loss: 0.8024
2024-07-11 16:23:43,290 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:23:43,735 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:23:43,793 [INFO    ] __main__: train step 7446: loss: 1.0346, policy_loss: 1.2681, value_loss: 0.8024
2024-07-11 16:23:43,975 [INFO    ] __main__: train step 7447: loss: 1.0346, policy_loss: 1.2681, value_loss: 0.8023
2024-07-11 16:23:44,186 [INFO    ] __main__: train step 7448: loss: 1.0346, policy_loss: 1.2680, value_loss: 0.8023
2024-07-11 16:23:44,388 [INFO    ] __main__: train step 7449: loss: 1.0347, policy_loss: 1.2679, value_loss: 0.8023
2024-07-11 16:23:44,587 [INFO    ] __main__: train step 7450: loss: 1.0347, policy_loss: 1.2678, value_loss: 0.8023
2024-07-11 16:23:44,787 [INFO    ] __main__: train step 7451: loss: 1.0347, policy_loss: 1.2677, value_loss: 0.8022
2024-07-11 16:23:44,981 [INFO    ] __main__: train step 7452: loss: 1.0348, policy_loss: 1.2677, value_loss: 0.8022
2024-07-11 16:23:45,187 [INFO    ] __main__: train step 7453: loss: 1.0348, policy_loss: 1.2676, value_loss: 0.8022
2024-07-11 16:23:45,389 [INFO    ] __main__: train step 7454: loss: 1.0348, policy_loss: 1.2675, value_loss: 0.8022
2024-07-11 16:23:45,588 [INFO    ] __main__: train step 7455: loss: 1.0349, policy_loss: 1.2674, value_loss: 0.8021
2024-07-11 16:23:45,796 [INFO    ] __main__: train step 7456: loss: 1.0349, policy_loss: 1.2674, value_loss: 0.8021
2024-07-11 16:23:45,991 [INFO    ] __main__: train step 7457: loss: 1.0349, policy_loss: 1.2673, value_loss: 0.8021
2024-07-11 16:23:46,192 [INFO    ] __main__: train step 7458: loss: 1.0350, policy_loss: 1.2672, value_loss: 0.8020
2024-07-11 16:23:46,415 [INFO    ] __main__: train step 7459: loss: 1.0350, policy_loss: 1.2671, value_loss: 0.8020
2024-07-11 16:23:46,646 [INFO    ] __main__: train step 7460: loss: 1.0350, policy_loss: 1.2671, value_loss: 0.8020
2024-07-11 16:23:46,856 [INFO    ] __main__: train step 7461: loss: 1.0351, policy_loss: 1.2670, value_loss: 0.8020
2024-07-11 16:23:47,063 [INFO    ] __main__: train step 7462: loss: 1.0351, policy_loss: 1.2669, value_loss: 0.8019
2024-07-11 16:23:48,513 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:23:48,951 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:23:49,007 [INFO    ] __main__: train step 7463: loss: 1.0352, policy_loss: 1.2668, value_loss: 0.8019
2024-07-11 16:23:49,187 [INFO    ] __main__: train step 7464: loss: 1.0352, policy_loss: 1.2667, value_loss: 0.8019
2024-07-11 16:23:49,379 [INFO    ] __main__: train step 7465: loss: 1.0352, policy_loss: 1.2667, value_loss: 0.8019
2024-07-11 16:23:49,587 [INFO    ] __main__: train step 7466: loss: 1.0353, policy_loss: 1.2666, value_loss: 0.8018
2024-07-11 16:23:49,796 [INFO    ] __main__: train step 7467: loss: 1.0353, policy_loss: 1.2665, value_loss: 0.8018
2024-07-11 16:23:50,008 [INFO    ] __main__: train step 7468: loss: 1.0353, policy_loss: 1.2664, value_loss: 0.8018
2024-07-11 16:23:50,251 [INFO    ] __main__: train step 7469: loss: 1.0354, policy_loss: 1.2664, value_loss: 0.8018
2024-07-11 16:23:50,456 [INFO    ] __main__: train step 7470: loss: 1.0354, policy_loss: 1.2663, value_loss: 0.8017
2024-07-11 16:23:50,670 [INFO    ] __main__: train step 7471: loss: 1.0354, policy_loss: 1.2662, value_loss: 0.8017
2024-07-11 16:23:50,874 [INFO    ] __main__: train step 7472: loss: 1.0355, policy_loss: 1.2661, value_loss: 0.8017
2024-07-11 16:23:51,074 [INFO    ] __main__: train step 7473: loss: 1.0355, policy_loss: 1.2661, value_loss: 0.8017
2024-07-11 16:23:51,272 [INFO    ] __main__: train step 7474: loss: 1.0355, policy_loss: 1.2660, value_loss: 0.8016
2024-07-11 16:23:51,491 [INFO    ] __main__: train step 7475: loss: 1.0356, policy_loss: 1.2659, value_loss: 0.8016
2024-07-11 16:23:51,688 [INFO    ] __main__: train step 7476: loss: 1.0356, policy_loss: 1.2658, value_loss: 0.8016
2024-07-11 16:23:51,891 [INFO    ] __main__: train step 7477: loss: 1.0357, policy_loss: 1.2658, value_loss: 0.8016
2024-07-11 16:23:52,126 [INFO    ] __main__: train step 7478: loss: 1.0357, policy_loss: 1.2657, value_loss: 0.8015
2024-07-11 16:23:52,323 [INFO    ] __main__: train step 7479: loss: 1.0357, policy_loss: 1.2656, value_loss: 0.8015
2024-07-11 16:23:53,749 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:23:54,163 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:23:54,219 [INFO    ] __main__: train step 7480: loss: 1.0358, policy_loss: 1.2655, value_loss: 0.8015
2024-07-11 16:23:54,396 [INFO    ] __main__: train step 7481: loss: 1.0358, policy_loss: 1.2655, value_loss: 0.8015
2024-07-11 16:23:54,606 [INFO    ] __main__: train step 7482: loss: 1.0358, policy_loss: 1.2654, value_loss: 0.8014
2024-07-11 16:23:54,809 [INFO    ] __main__: train step 7483: loss: 1.0359, policy_loss: 1.2653, value_loss: 0.8014
2024-07-11 16:23:55,013 [INFO    ] __main__: train step 7484: loss: 1.0359, policy_loss: 1.2652, value_loss: 0.8014
2024-07-11 16:23:55,217 [INFO    ] __main__: train step 7485: loss: 1.0359, policy_loss: 1.2652, value_loss: 0.8014
2024-07-11 16:23:55,419 [INFO    ] __main__: train step 7486: loss: 1.0360, policy_loss: 1.2651, value_loss: 0.8013
2024-07-11 16:23:55,631 [INFO    ] __main__: train step 7487: loss: 1.0360, policy_loss: 1.2650, value_loss: 0.8013
2024-07-11 16:23:55,835 [INFO    ] __main__: train step 7488: loss: 1.0360, policy_loss: 1.2649, value_loss: 0.8013
2024-07-11 16:23:56,029 [INFO    ] __main__: train step 7489: loss: 1.0361, policy_loss: 1.2648, value_loss: 0.8013
2024-07-11 16:23:56,255 [INFO    ] __main__: train step 7490: loss: 1.0361, policy_loss: 1.2648, value_loss: 0.8012
2024-07-11 16:23:56,491 [INFO    ] __main__: train step 7491: loss: 1.0361, policy_loss: 1.2647, value_loss: 0.8012
2024-07-11 16:23:56,699 [INFO    ] __main__: train step 7492: loss: 1.0362, policy_loss: 1.2646, value_loss: 0.8012
2024-07-11 16:23:56,934 [INFO    ] __main__: train step 7493: loss: 1.0362, policy_loss: 1.2645, value_loss: 0.8011
2024-07-11 16:23:57,167 [INFO    ] __main__: train step 7494: loss: 1.0362, policy_loss: 1.2645, value_loss: 0.8011
2024-07-11 16:23:57,378 [INFO    ] __main__: train step 7495: loss: 1.0363, policy_loss: 1.2644, value_loss: 0.8011
2024-07-11 16:23:57,569 [INFO    ] __main__: train step 7496: loss: 1.0363, policy_loss: 1.2643, value_loss: 0.8011
2024-07-11 16:23:58,990 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:23:59,428 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:23:59,490 [INFO    ] __main__: train step 7497: loss: 1.0364, policy_loss: 1.2642, value_loss: 0.8011
2024-07-11 16:23:59,670 [INFO    ] __main__: train step 7498: loss: 1.0364, policy_loss: 1.2642, value_loss: 0.8010
2024-07-11 16:23:59,893 [INFO    ] __main__: train step 7499: loss: 1.0364, policy_loss: 1.2641, value_loss: 0.8010
2024-07-11 16:24:00,097 [INFO    ] __main__: train step 7500: loss: 1.0365, policy_loss: 1.2640, value_loss: 0.8010
2024-07-11 16:24:00,308 [INFO    ] __main__: train step 7501: loss: 1.0365, policy_loss: 1.2639, value_loss: 0.8010
2024-07-11 16:24:00,548 [INFO    ] __main__: train step 7502: loss: 1.0365, policy_loss: 1.2638, value_loss: 0.8009
2024-07-11 16:24:00,764 [INFO    ] __main__: train step 7503: loss: 1.0366, policy_loss: 1.2638, value_loss: 0.8009
2024-07-11 16:24:00,973 [INFO    ] __main__: train step 7504: loss: 1.0366, policy_loss: 1.2637, value_loss: 0.8009
2024-07-11 16:24:01,179 [INFO    ] __main__: train step 7505: loss: 1.0366, policy_loss: 1.2636, value_loss: 0.8009
2024-07-11 16:24:01,368 [INFO    ] __main__: train step 7506: loss: 1.0367, policy_loss: 1.2635, value_loss: 0.8008
2024-07-11 16:24:01,572 [INFO    ] __main__: train step 7507: loss: 1.0367, policy_loss: 1.2635, value_loss: 0.8008
2024-07-11 16:24:01,757 [INFO    ] __main__: train step 7508: loss: 1.0367, policy_loss: 1.2634, value_loss: 0.8008
2024-07-11 16:24:01,970 [INFO    ] __main__: train step 7509: loss: 1.0368, policy_loss: 1.2633, value_loss: 0.8008
2024-07-11 16:24:02,214 [INFO    ] __main__: train step 7510: loss: 1.0368, policy_loss: 1.2632, value_loss: 0.8007
2024-07-11 16:24:02,441 [INFO    ] __main__: train step 7511: loss: 1.0368, policy_loss: 1.2632, value_loss: 0.8007
2024-07-11 16:24:02,648 [INFO    ] __main__: train step 7512: loss: 1.0369, policy_loss: 1.2631, value_loss: 0.8007
2024-07-11 16:24:02,872 [INFO    ] __main__: train step 7513: loss: 1.0369, policy_loss: 1.2630, value_loss: 0.8007
2024-07-11 16:24:04,288 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:24:04,695 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:24:04,749 [INFO    ] __main__: train step 7514: loss: 1.0369, policy_loss: 1.2629, value_loss: 0.8006
2024-07-11 16:24:04,934 [INFO    ] __main__: train step 7515: loss: 1.0370, policy_loss: 1.2628, value_loss: 0.8006
2024-07-11 16:24:05,165 [INFO    ] __main__: train step 7516: loss: 1.0370, policy_loss: 1.2628, value_loss: 0.8006
2024-07-11 16:24:05,357 [INFO    ] __main__: train step 7517: loss: 1.0370, policy_loss: 1.2627, value_loss: 0.8006
2024-07-11 16:24:05,564 [INFO    ] __main__: train step 7518: loss: 1.0371, policy_loss: 1.2626, value_loss: 0.8005
2024-07-11 16:24:06,598 [INFO    ] __main__: train step 7519: loss: 1.0371, policy_loss: 1.2625, value_loss: 0.8005
2024-07-11 16:24:06,830 [INFO    ] __main__: train step 7520: loss: 1.0371, policy_loss: 1.2625, value_loss: 0.8005
2024-07-11 16:24:07,027 [INFO    ] __main__: train step 7521: loss: 1.0372, policy_loss: 1.2624, value_loss: 0.8004
2024-07-11 16:24:07,242 [INFO    ] __main__: train step 7522: loss: 1.0372, policy_loss: 1.2623, value_loss: 0.8004
2024-07-11 16:24:07,444 [INFO    ] __main__: train step 7523: loss: 1.0372, policy_loss: 1.2622, value_loss: 0.8004
2024-07-11 16:24:07,650 [INFO    ] __main__: train step 7524: loss: 1.0373, policy_loss: 1.2621, value_loss: 0.8004
2024-07-11 16:24:07,852 [INFO    ] __main__: train step 7525: loss: 1.0373, policy_loss: 1.2621, value_loss: 0.8003
2024-07-11 16:24:08,050 [INFO    ] __main__: train step 7526: loss: 1.0373, policy_loss: 1.2620, value_loss: 0.8003
2024-07-11 16:24:08,250 [INFO    ] __main__: train step 7527: loss: 1.0374, policy_loss: 1.2619, value_loss: 0.8003
2024-07-11 16:24:08,467 [INFO    ] __main__: train step 7528: loss: 1.0374, policy_loss: 1.2618, value_loss: 0.8003
2024-07-11 16:24:08,691 [INFO    ] __main__: train step 7529: loss: 1.0374, policy_loss: 1.2618, value_loss: 0.8002
2024-07-11 16:24:08,888 [INFO    ] __main__: train step 7530: loss: 1.0375, policy_loss: 1.2617, value_loss: 0.8002
2024-07-11 16:24:10,324 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:24:10,746 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:24:10,801 [INFO    ] __main__: train step 7531: loss: 1.0375, policy_loss: 1.2616, value_loss: 0.8002
2024-07-11 16:24:10,973 [INFO    ] __main__: train step 7532: loss: 1.0375, policy_loss: 1.2615, value_loss: 0.8002
2024-07-11 16:24:11,189 [INFO    ] __main__: train step 7533: loss: 1.0376, policy_loss: 1.2615, value_loss: 0.8001
2024-07-11 16:24:11,386 [INFO    ] __main__: train step 7534: loss: 1.0376, policy_loss: 1.2614, value_loss: 0.8001
2024-07-11 16:24:11,586 [INFO    ] __main__: train step 7535: loss: 1.0376, policy_loss: 1.2613, value_loss: 0.8001
2024-07-11 16:24:11,790 [INFO    ] __main__: train step 7536: loss: 1.0377, policy_loss: 1.2612, value_loss: 0.8001
2024-07-11 16:24:11,995 [INFO    ] __main__: train step 7537: loss: 1.0377, policy_loss: 1.2612, value_loss: 0.8000
2024-07-11 16:24:12,196 [INFO    ] __main__: train step 7538: loss: 1.0377, policy_loss: 1.2611, value_loss: 0.8000
2024-07-11 16:24:12,399 [INFO    ] __main__: train step 7539: loss: 1.0378, policy_loss: 1.2610, value_loss: 0.8000
2024-07-11 16:24:12,611 [INFO    ] __main__: train step 7540: loss: 1.0378, policy_loss: 1.2609, value_loss: 0.8000
2024-07-11 16:24:12,857 [INFO    ] __main__: train step 7541: loss: 1.0378, policy_loss: 1.2608, value_loss: 0.7999
2024-07-11 16:24:13,078 [INFO    ] __main__: train step 7542: loss: 1.0379, policy_loss: 1.2608, value_loss: 0.7999
2024-07-11 16:24:13,279 [INFO    ] __main__: train step 7543: loss: 1.0379, policy_loss: 1.2607, value_loss: 0.7999
2024-07-11 16:24:13,477 [INFO    ] __main__: train step 7544: loss: 1.0379, policy_loss: 1.2606, value_loss: 0.7999
2024-07-11 16:24:13,684 [INFO    ] __main__: train step 7545: loss: 1.0380, policy_loss: 1.2605, value_loss: 0.7998
2024-07-11 16:24:13,902 [INFO    ] __main__: train step 7546: loss: 1.0380, policy_loss: 1.2605, value_loss: 0.7998
2024-07-11 16:24:14,098 [INFO    ] __main__: train step 7547: loss: 1.0380, policy_loss: 1.2604, value_loss: 0.7998
2024-07-11 16:24:15,522 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:24:15,943 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:24:15,997 [INFO    ] __main__: train step 7548: loss: 1.0381, policy_loss: 1.2603, value_loss: 0.7998
2024-07-11 16:24:16,173 [INFO    ] __main__: train step 7549: loss: 1.0381, policy_loss: 1.2602, value_loss: 0.7997
2024-07-11 16:24:16,388 [INFO    ] __main__: train step 7550: loss: 1.0381, policy_loss: 1.2602, value_loss: 0.7997
2024-07-11 16:24:16,586 [INFO    ] __main__: train step 7551: loss: 1.0382, policy_loss: 1.2601, value_loss: 0.7997
2024-07-11 16:24:16,793 [INFO    ] __main__: train step 7552: loss: 1.0382, policy_loss: 1.2600, value_loss: 0.7997
2024-07-11 16:24:17,002 [INFO    ] __main__: train step 7553: loss: 1.0382, policy_loss: 1.2599, value_loss: 0.7996
2024-07-11 16:24:17,210 [INFO    ] __main__: train step 7554: loss: 1.0383, policy_loss: 1.2599, value_loss: 0.7996
2024-07-11 16:24:17,410 [INFO    ] __main__: train step 7555: loss: 1.0383, policy_loss: 1.2598, value_loss: 0.7996
2024-07-11 16:24:17,605 [INFO    ] __main__: train step 7556: loss: 1.0383, policy_loss: 1.2597, value_loss: 0.7996
2024-07-11 16:24:17,807 [INFO    ] __main__: train step 7557: loss: 1.0384, policy_loss: 1.2596, value_loss: 0.7995
2024-07-11 16:24:18,014 [INFO    ] __main__: train step 7558: loss: 1.0384, policy_loss: 1.2595, value_loss: 0.7995
2024-07-11 16:24:18,220 [INFO    ] __main__: train step 7559: loss: 1.0384, policy_loss: 1.2595, value_loss: 0.7995
2024-07-11 16:24:18,435 [INFO    ] __main__: train step 7560: loss: 1.0385, policy_loss: 1.2594, value_loss: 0.7995
2024-07-11 16:24:18,669 [INFO    ] __main__: train step 7561: loss: 1.0385, policy_loss: 1.2593, value_loss: 0.7994
2024-07-11 16:24:18,872 [INFO    ] __main__: train step 7562: loss: 1.0385, policy_loss: 1.2592, value_loss: 0.7994
2024-07-11 16:24:19,076 [INFO    ] __main__: train step 7563: loss: 1.0386, policy_loss: 1.2592, value_loss: 0.7994
2024-07-11 16:24:19,286 [INFO    ] __main__: train step 7564: loss: 1.0386, policy_loss: 1.2591, value_loss: 0.7994
2024-07-11 16:24:20,719 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:24:21,145 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:24:21,199 [INFO    ] __main__: train step 7565: loss: 1.0386, policy_loss: 1.2590, value_loss: 0.7993
2024-07-11 16:24:21,370 [INFO    ] __main__: train step 7566: loss: 1.0387, policy_loss: 1.2589, value_loss: 0.7993
2024-07-11 16:24:21,578 [INFO    ] __main__: train step 7567: loss: 1.0387, policy_loss: 1.2589, value_loss: 0.7993
2024-07-11 16:24:21,787 [INFO    ] __main__: train step 7568: loss: 1.0387, policy_loss: 1.2588, value_loss: 0.7993
2024-07-11 16:24:21,984 [INFO    ] __main__: train step 7569: loss: 1.0388, policy_loss: 1.2587, value_loss: 0.7993
2024-07-11 16:24:22,193 [INFO    ] __main__: train step 7570: loss: 1.0388, policy_loss: 1.2586, value_loss: 0.7992
2024-07-11 16:24:22,385 [INFO    ] __main__: train step 7571: loss: 1.0388, policy_loss: 1.2585, value_loss: 0.7992
2024-07-11 16:24:22,595 [INFO    ] __main__: train step 7572: loss: 1.0389, policy_loss: 1.2585, value_loss: 0.7992
2024-07-11 16:24:22,802 [INFO    ] __main__: train step 7573: loss: 1.0389, policy_loss: 1.2584, value_loss: 0.7992
2024-07-11 16:24:23,009 [INFO    ] __main__: train step 7574: loss: 1.0389, policy_loss: 1.2583, value_loss: 0.7991
2024-07-11 16:24:23,219 [INFO    ] __main__: train step 7575: loss: 1.0390, policy_loss: 1.2582, value_loss: 0.7991
2024-07-11 16:24:23,416 [INFO    ] __main__: train step 7576: loss: 1.0390, policy_loss: 1.2582, value_loss: 0.7991
2024-07-11 16:24:23,629 [INFO    ] __main__: train step 7577: loss: 1.0390, policy_loss: 1.2581, value_loss: 0.7991
2024-07-11 16:24:23,819 [INFO    ] __main__: train step 7578: loss: 1.0391, policy_loss: 1.2580, value_loss: 0.7990
2024-07-11 16:24:24,022 [INFO    ] __main__: train step 7579: loss: 1.0391, policy_loss: 1.2579, value_loss: 0.7990
2024-07-11 16:24:24,225 [INFO    ] __main__: train step 7580: loss: 1.0391, policy_loss: 1.2579, value_loss: 0.7990
2024-07-11 16:24:24,431 [INFO    ] __main__: train step 7581: loss: 1.0391, policy_loss: 1.2578, value_loss: 0.7990
2024-07-11 16:24:25,875 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:24:26,302 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:24:26,357 [INFO    ] __main__: train step 7582: loss: 1.0392, policy_loss: 1.2577, value_loss: 0.7989
2024-07-11 16:24:26,531 [INFO    ] __main__: train step 7583: loss: 1.0392, policy_loss: 1.2576, value_loss: 0.7989
2024-07-11 16:24:26,737 [INFO    ] __main__: train step 7584: loss: 1.0392, policy_loss: 1.2575, value_loss: 0.7989
2024-07-11 16:24:26,953 [INFO    ] __main__: train step 7585: loss: 1.0393, policy_loss: 1.2575, value_loss: 0.7989
2024-07-11 16:24:27,152 [INFO    ] __main__: train step 7586: loss: 1.0393, policy_loss: 1.2574, value_loss: 0.7988
2024-07-11 16:24:27,363 [INFO    ] __main__: train step 7587: loss: 1.0393, policy_loss: 1.2573, value_loss: 0.7988
2024-07-11 16:24:27,565 [INFO    ] __main__: train step 7588: loss: 1.0394, policy_loss: 1.2572, value_loss: 0.7988
2024-07-11 16:24:27,772 [INFO    ] __main__: train step 7589: loss: 1.0394, policy_loss: 1.2572, value_loss: 0.7988
2024-07-11 16:24:27,978 [INFO    ] __main__: train step 7590: loss: 1.0394, policy_loss: 1.2571, value_loss: 0.7987
2024-07-11 16:24:28,179 [INFO    ] __main__: train step 7591: loss: 1.0395, policy_loss: 1.2570, value_loss: 0.7987
2024-07-11 16:24:29,232 [INFO    ] __main__: train step 7592: loss: 1.0395, policy_loss: 1.2569, value_loss: 0.7987
2024-07-11 16:24:29,454 [INFO    ] __main__: train step 7593: loss: 1.0395, policy_loss: 1.2569, value_loss: 0.7987
2024-07-11 16:24:29,667 [INFO    ] __main__: train step 7594: loss: 1.0396, policy_loss: 1.2568, value_loss: 0.7986
2024-07-11 16:24:29,869 [INFO    ] __main__: train step 7595: loss: 1.0396, policy_loss: 1.2567, value_loss: 0.7986
2024-07-11 16:24:30,067 [INFO    ] __main__: train step 7596: loss: 1.0396, policy_loss: 1.2566, value_loss: 0.7986
2024-07-11 16:24:30,272 [INFO    ] __main__: train step 7597: loss: 1.0397, policy_loss: 1.2566, value_loss: 0.7986
2024-07-11 16:24:30,475 [INFO    ] __main__: train step 7598: loss: 1.0397, policy_loss: 1.2565, value_loss: 0.7985
2024-07-11 16:24:31,911 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:24:32,335 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:24:32,391 [INFO    ] __main__: train step 7599: loss: 1.0397, policy_loss: 1.2564, value_loss: 0.7985
2024-07-11 16:24:32,580 [INFO    ] __main__: train step 7600: loss: 1.0398, policy_loss: 1.2563, value_loss: 0.7985
2024-07-11 16:24:32,775 [INFO    ] __main__: train step 7601: loss: 1.0398, policy_loss: 1.2563, value_loss: 0.7985
2024-07-11 16:24:32,981 [INFO    ] __main__: train step 7602: loss: 1.0398, policy_loss: 1.2562, value_loss: 0.7984
2024-07-11 16:24:33,184 [INFO    ] __main__: train step 7603: loss: 1.0399, policy_loss: 1.2561, value_loss: 0.7984
2024-07-11 16:24:33,386 [INFO    ] __main__: train step 7604: loss: 1.0399, policy_loss: 1.2560, value_loss: 0.7984
2024-07-11 16:24:33,586 [INFO    ] __main__: train step 7605: loss: 1.0399, policy_loss: 1.2559, value_loss: 0.7984
2024-07-11 16:24:33,794 [INFO    ] __main__: train step 7606: loss: 1.0400, policy_loss: 1.2559, value_loss: 0.7984
2024-07-11 16:24:34,001 [INFO    ] __main__: train step 7607: loss: 1.0400, policy_loss: 1.2558, value_loss: 0.7983
2024-07-11 16:24:34,197 [INFO    ] __main__: train step 7608: loss: 1.0400, policy_loss: 1.2557, value_loss: 0.7983
2024-07-11 16:24:34,406 [INFO    ] __main__: train step 7609: loss: 1.0401, policy_loss: 1.2556, value_loss: 0.7983
2024-07-11 16:24:34,600 [INFO    ] __main__: train step 7610: loss: 1.0401, policy_loss: 1.2556, value_loss: 0.7983
2024-07-11 16:24:34,809 [INFO    ] __main__: train step 7611: loss: 1.0401, policy_loss: 1.2555, value_loss: 0.7982
2024-07-11 16:24:35,022 [INFO    ] __main__: train step 7612: loss: 1.0401, policy_loss: 1.2554, value_loss: 0.7982
2024-07-11 16:24:35,232 [INFO    ] __main__: train step 7613: loss: 1.0402, policy_loss: 1.2553, value_loss: 0.7982
2024-07-11 16:24:35,444 [INFO    ] __main__: train step 7614: loss: 1.0402, policy_loss: 1.2552, value_loss: 0.7982
2024-07-11 16:24:35,698 [INFO    ] __main__: train step 7615: loss: 1.0402, policy_loss: 1.2552, value_loss: 0.7981
2024-07-11 16:24:37,177 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:24:37,614 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:24:37,677 [INFO    ] __main__: train step 7616: loss: 1.0403, policy_loss: 1.2551, value_loss: 0.7981
2024-07-11 16:24:37,869 [INFO    ] __main__: train step 7617: loss: 1.0403, policy_loss: 1.2550, value_loss: 0.7981
2024-07-11 16:24:38,106 [INFO    ] __main__: train step 7618: loss: 1.0403, policy_loss: 1.2549, value_loss: 0.7981
2024-07-11 16:24:38,308 [INFO    ] __main__: train step 7619: loss: 1.0404, policy_loss: 1.2549, value_loss: 0.7980
2024-07-11 16:24:38,509 [INFO    ] __main__: train step 7620: loss: 1.0404, policy_loss: 1.2548, value_loss: 0.7980
2024-07-11 16:24:38,716 [INFO    ] __main__: train step 7621: loss: 1.0404, policy_loss: 1.2547, value_loss: 0.7980
2024-07-11 16:24:38,925 [INFO    ] __main__: train step 7622: loss: 1.0405, policy_loss: 1.2546, value_loss: 0.7980
2024-07-11 16:24:39,137 [INFO    ] __main__: train step 7623: loss: 1.0405, policy_loss: 1.2546, value_loss: 0.7979
2024-07-11 16:24:39,336 [INFO    ] __main__: train step 7624: loss: 1.0405, policy_loss: 1.2545, value_loss: 0.7979
2024-07-11 16:24:39,529 [INFO    ] __main__: train step 7625: loss: 1.0405, policy_loss: 1.2544, value_loss: 0.7979
2024-07-11 16:24:39,736 [INFO    ] __main__: train step 7626: loss: 1.0406, policy_loss: 1.2543, value_loss: 0.7979
2024-07-11 16:24:39,949 [INFO    ] __main__: train step 7627: loss: 1.0406, policy_loss: 1.2543, value_loss: 0.7978
2024-07-11 16:24:40,172 [INFO    ] __main__: train step 7628: loss: 1.0406, policy_loss: 1.2542, value_loss: 0.7978
2024-07-11 16:24:40,359 [INFO    ] __main__: train step 7629: loss: 1.0407, policy_loss: 1.2541, value_loss: 0.7978
2024-07-11 16:24:40,568 [INFO    ] __main__: train step 7630: loss: 1.0407, policy_loss: 1.2540, value_loss: 0.7978
2024-07-11 16:24:40,767 [INFO    ] __main__: train step 7631: loss: 1.0407, policy_loss: 1.2539, value_loss: 0.7977
2024-07-11 16:24:40,970 [INFO    ] __main__: train step 7632: loss: 1.0408, policy_loss: 1.2539, value_loss: 0.7977
2024-07-11 16:24:42,412 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:24:42,819 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:24:42,873 [INFO    ] __main__: train step 7633: loss: 1.0408, policy_loss: 1.2538, value_loss: 0.7977
2024-07-11 16:24:43,044 [INFO    ] __main__: train step 7634: loss: 1.0408, policy_loss: 1.2537, value_loss: 0.7977
2024-07-11 16:24:43,241 [INFO    ] __main__: train step 7635: loss: 1.0409, policy_loss: 1.2536, value_loss: 0.7976
2024-07-11 16:24:43,433 [INFO    ] __main__: train step 7636: loss: 1.0409, policy_loss: 1.2536, value_loss: 0.7976
2024-07-11 16:24:43,637 [INFO    ] __main__: train step 7637: loss: 1.0409, policy_loss: 1.2535, value_loss: 0.7976
2024-07-11 16:24:43,837 [INFO    ] __main__: train step 7638: loss: 1.0409, policy_loss: 1.2534, value_loss: 0.7976
2024-07-11 16:24:44,042 [INFO    ] __main__: train step 7639: loss: 1.0410, policy_loss: 1.2533, value_loss: 0.7975
2024-07-11 16:24:44,248 [INFO    ] __main__: train step 7640: loss: 1.0410, policy_loss: 1.2533, value_loss: 0.7975
2024-07-11 16:24:44,453 [INFO    ] __main__: train step 7641: loss: 1.0410, policy_loss: 1.2532, value_loss: 0.7975
2024-07-11 16:24:44,661 [INFO    ] __main__: train step 7642: loss: 1.0411, policy_loss: 1.2531, value_loss: 0.7975
2024-07-11 16:24:44,883 [INFO    ] __main__: train step 7643: loss: 1.0411, policy_loss: 1.2530, value_loss: 0.7974
2024-07-11 16:24:45,076 [INFO    ] __main__: train step 7644: loss: 1.0411, policy_loss: 1.2530, value_loss: 0.7974
2024-07-11 16:24:45,287 [INFO    ] __main__: train step 7645: loss: 1.0412, policy_loss: 1.2529, value_loss: 0.7974
2024-07-11 16:24:45,491 [INFO    ] __main__: train step 7646: loss: 1.0412, policy_loss: 1.2528, value_loss: 0.7974
2024-07-11 16:24:45,693 [INFO    ] __main__: train step 7647: loss: 1.0412, policy_loss: 1.2527, value_loss: 0.7973
2024-07-11 16:24:45,895 [INFO    ] __main__: train step 7648: loss: 1.0413, policy_loss: 1.2527, value_loss: 0.7973
2024-07-11 16:24:46,089 [INFO    ] __main__: train step 7649: loss: 1.0413, policy_loss: 1.2526, value_loss: 0.7973
2024-07-11 16:24:47,515 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:24:47,924 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:24:47,978 [INFO    ] __main__: train step 7650: loss: 1.0413, policy_loss: 1.2525, value_loss: 0.7973
2024-07-11 16:24:48,156 [INFO    ] __main__: train step 7651: loss: 1.0413, policy_loss: 1.2524, value_loss: 0.7972
2024-07-11 16:24:48,351 [INFO    ] __main__: train step 7652: loss: 1.0414, policy_loss: 1.2524, value_loss: 0.7972
2024-07-11 16:24:48,554 [INFO    ] __main__: train step 7653: loss: 1.0414, policy_loss: 1.2523, value_loss: 0.7972
2024-07-11 16:24:48,758 [INFO    ] __main__: train step 7654: loss: 1.0414, policy_loss: 1.2522, value_loss: 0.7971
2024-07-11 16:24:48,952 [INFO    ] __main__: train step 7655: loss: 1.0415, policy_loss: 1.2521, value_loss: 0.7971
2024-07-11 16:24:49,154 [INFO    ] __main__: train step 7656: loss: 1.0415, policy_loss: 1.2521, value_loss: 0.7971
2024-07-11 16:24:49,354 [INFO    ] __main__: train step 7657: loss: 1.0415, policy_loss: 1.2520, value_loss: 0.7971
2024-07-11 16:24:49,559 [INFO    ] __main__: train step 7658: loss: 1.0416, policy_loss: 1.2519, value_loss: 0.7970
2024-07-11 16:24:49,750 [INFO    ] __main__: train step 7659: loss: 1.0416, policy_loss: 1.2518, value_loss: 0.7970
2024-07-11 16:24:49,950 [INFO    ] __main__: train step 7660: loss: 1.0416, policy_loss: 1.2518, value_loss: 0.7970
2024-07-11 16:24:50,156 [INFO    ] __main__: train step 7661: loss: 1.0416, policy_loss: 1.2517, value_loss: 0.7970
2024-07-11 16:24:50,361 [INFO    ] __main__: train step 7662: loss: 1.0417, policy_loss: 1.2516, value_loss: 0.7970
2024-07-11 16:24:50,563 [INFO    ] __main__: train step 7663: loss: 1.0417, policy_loss: 1.2515, value_loss: 0.7969
2024-07-11 16:24:50,769 [INFO    ] __main__: train step 7664: loss: 1.0417, policy_loss: 1.2514, value_loss: 0.7969
2024-07-11 16:24:50,969 [INFO    ] __main__: train step 7665: loss: 1.0418, policy_loss: 1.2514, value_loss: 0.7969
2024-07-11 16:24:51,995 [INFO    ] __main__: train step 7666: loss: 1.0418, policy_loss: 1.2513, value_loss: 0.7969
2024-07-11 16:24:53,460 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:24:53,912 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:24:53,974 [INFO    ] __main__: train step 7667: loss: 1.0418, policy_loss: 1.2512, value_loss: 0.7968
2024-07-11 16:24:54,141 [INFO    ] __main__: train step 7668: loss: 1.0419, policy_loss: 1.2511, value_loss: 0.7968
2024-07-11 16:24:54,365 [INFO    ] __main__: train step 7669: loss: 1.0419, policy_loss: 1.2511, value_loss: 0.7968
2024-07-11 16:24:54,566 [INFO    ] __main__: train step 7670: loss: 1.0419, policy_loss: 1.2510, value_loss: 0.7967
2024-07-11 16:24:54,761 [INFO    ] __main__: train step 7671: loss: 1.0419, policy_loss: 1.2509, value_loss: 0.7967
2024-07-11 16:24:54,981 [INFO    ] __main__: train step 7672: loss: 1.0420, policy_loss: 1.2508, value_loss: 0.7967
2024-07-11 16:24:55,188 [INFO    ] __main__: train step 7673: loss: 1.0420, policy_loss: 1.2508, value_loss: 0.7967
2024-07-11 16:24:55,397 [INFO    ] __main__: train step 7674: loss: 1.0420, policy_loss: 1.2507, value_loss: 0.7967
2024-07-11 16:24:55,595 [INFO    ] __main__: train step 7675: loss: 1.0421, policy_loss: 1.2506, value_loss: 0.7966
2024-07-11 16:24:55,812 [INFO    ] __main__: train step 7676: loss: 1.0421, policy_loss: 1.2505, value_loss: 0.7966
2024-07-11 16:24:56,030 [INFO    ] __main__: train step 7677: loss: 1.0421, policy_loss: 1.2505, value_loss: 0.7966
2024-07-11 16:24:56,252 [INFO    ] __main__: train step 7678: loss: 1.0421, policy_loss: 1.2504, value_loss: 0.7965
2024-07-11 16:24:56,465 [INFO    ] __main__: train step 7679: loss: 1.0422, policy_loss: 1.2503, value_loss: 0.7965
2024-07-11 16:24:56,674 [INFO    ] __main__: train step 7680: loss: 1.0422, policy_loss: 1.2502, value_loss: 0.7965
2024-07-11 16:24:56,890 [INFO    ] __main__: train step 7681: loss: 1.0422, policy_loss: 1.2502, value_loss: 0.7965
2024-07-11 16:24:57,113 [INFO    ] __main__: train step 7682: loss: 1.0423, policy_loss: 1.2501, value_loss: 0.7964
2024-07-11 16:24:57,303 [INFO    ] __main__: train step 7683: loss: 1.0423, policy_loss: 1.2500, value_loss: 0.7964
2024-07-11 16:24:58,776 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:24:59,171 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:24:59,226 [INFO    ] __main__: train step 7684: loss: 1.0423, policy_loss: 1.2499, value_loss: 0.7964
2024-07-11 16:24:59,410 [INFO    ] __main__: train step 7685: loss: 1.0424, policy_loss: 1.2498, value_loss: 0.7964
2024-07-11 16:24:59,617 [INFO    ] __main__: train step 7686: loss: 1.0424, policy_loss: 1.2498, value_loss: 0.7964
2024-07-11 16:24:59,818 [INFO    ] __main__: train step 7687: loss: 1.0424, policy_loss: 1.2497, value_loss: 0.7963
2024-07-11 16:25:00,024 [INFO    ] __main__: train step 7688: loss: 1.0424, policy_loss: 1.2496, value_loss: 0.7963
2024-07-11 16:25:00,222 [INFO    ] __main__: train step 7689: loss: 1.0425, policy_loss: 1.2495, value_loss: 0.7963
2024-07-11 16:25:00,431 [INFO    ] __main__: train step 7690: loss: 1.0425, policy_loss: 1.2495, value_loss: 0.7963
2024-07-11 16:25:00,630 [INFO    ] __main__: train step 7691: loss: 1.0425, policy_loss: 1.2494, value_loss: 0.7962
2024-07-11 16:25:00,829 [INFO    ] __main__: train step 7692: loss: 1.0426, policy_loss: 1.2493, value_loss: 0.7962
2024-07-11 16:25:01,024 [INFO    ] __main__: train step 7693: loss: 1.0426, policy_loss: 1.2492, value_loss: 0.7962
2024-07-11 16:25:01,230 [INFO    ] __main__: train step 7694: loss: 1.0426, policy_loss: 1.2492, value_loss: 0.7962
2024-07-11 16:25:01,435 [INFO    ] __main__: train step 7695: loss: 1.0427, policy_loss: 1.2491, value_loss: 0.7961
2024-07-11 16:25:01,650 [INFO    ] __main__: train step 7696: loss: 1.0427, policy_loss: 1.2490, value_loss: 0.7961
2024-07-11 16:25:01,848 [INFO    ] __main__: train step 7697: loss: 1.0427, policy_loss: 1.2490, value_loss: 0.7961
2024-07-11 16:25:02,065 [INFO    ] __main__: train step 7698: loss: 1.0427, policy_loss: 1.2489, value_loss: 0.7960
2024-07-11 16:25:02,286 [INFO    ] __main__: train step 7699: loss: 1.0428, policy_loss: 1.2488, value_loss: 0.7960
2024-07-11 16:25:02,475 [INFO    ] __main__: train step 7700: loss: 1.0428, policy_loss: 1.2487, value_loss: 0.7960
2024-07-11 16:25:03,911 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:25:04,360 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:25:04,421 [INFO    ] __main__: train step 7701: loss: 1.0428, policy_loss: 1.2486, value_loss: 0.7960
2024-07-11 16:25:04,598 [INFO    ] __main__: train step 7702: loss: 1.0429, policy_loss: 1.2486, value_loss: 0.7959
2024-07-11 16:25:04,796 [INFO    ] __main__: train step 7703: loss: 1.0429, policy_loss: 1.2485, value_loss: 0.7959
2024-07-11 16:25:04,998 [INFO    ] __main__: train step 7704: loss: 1.0429, policy_loss: 1.2484, value_loss: 0.7959
2024-07-11 16:25:05,198 [INFO    ] __main__: train step 7705: loss: 1.0429, policy_loss: 1.2483, value_loss: 0.7959
2024-07-11 16:25:05,417 [INFO    ] __main__: train step 7706: loss: 1.0430, policy_loss: 1.2483, value_loss: 0.7959
2024-07-11 16:25:05,629 [INFO    ] __main__: train step 7707: loss: 1.0430, policy_loss: 1.2482, value_loss: 0.7958
2024-07-11 16:25:05,848 [INFO    ] __main__: train step 7708: loss: 1.0430, policy_loss: 1.2481, value_loss: 0.7958
2024-07-11 16:25:06,046 [INFO    ] __main__: train step 7709: loss: 1.0431, policy_loss: 1.2480, value_loss: 0.7958
2024-07-11 16:25:06,249 [INFO    ] __main__: train step 7710: loss: 1.0431, policy_loss: 1.2480, value_loss: 0.7958
2024-07-11 16:25:06,447 [INFO    ] __main__: train step 7711: loss: 1.0431, policy_loss: 1.2479, value_loss: 0.7957
2024-07-11 16:25:06,645 [INFO    ] __main__: train step 7712: loss: 1.0432, policy_loss: 1.2478, value_loss: 0.7957
2024-07-11 16:25:06,855 [INFO    ] __main__: train step 7713: loss: 1.0432, policy_loss: 1.2477, value_loss: 0.7957
2024-07-11 16:25:07,057 [INFO    ] __main__: train step 7714: loss: 1.0432, policy_loss: 1.2477, value_loss: 0.7957
2024-07-11 16:25:07,256 [INFO    ] __main__: train step 7715: loss: 1.0432, policy_loss: 1.2476, value_loss: 0.7956
2024-07-11 16:25:07,454 [INFO    ] __main__: train step 7716: loss: 1.0433, policy_loss: 1.2475, value_loss: 0.7956
2024-07-11 16:25:07,666 [INFO    ] __main__: train step 7717: loss: 1.0433, policy_loss: 1.2474, value_loss: 0.7956
2024-07-11 16:25:09,099 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:25:09,534 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:25:09,591 [INFO    ] __main__: train step 7718: loss: 1.0433, policy_loss: 1.2474, value_loss: 0.7956
2024-07-11 16:25:09,759 [INFO    ] __main__: train step 7719: loss: 1.0433, policy_loss: 1.2473, value_loss: 0.7955
2024-07-11 16:25:09,972 [INFO    ] __main__: train step 7720: loss: 1.0434, policy_loss: 1.2472, value_loss: 0.7955
2024-07-11 16:25:10,165 [INFO    ] __main__: train step 7721: loss: 1.0434, policy_loss: 1.2471, value_loss: 0.7955
2024-07-11 16:25:10,364 [INFO    ] __main__: train step 7722: loss: 1.0434, policy_loss: 1.2471, value_loss: 0.7955
2024-07-11 16:25:10,562 [INFO    ] __main__: train step 7723: loss: 1.0435, policy_loss: 1.2470, value_loss: 0.7954
2024-07-11 16:25:10,763 [INFO    ] __main__: train step 7724: loss: 1.0435, policy_loss: 1.2469, value_loss: 0.7954
2024-07-11 16:25:10,966 [INFO    ] __main__: train step 7725: loss: 1.0435, policy_loss: 1.2468, value_loss: 0.7954
2024-07-11 16:25:11,162 [INFO    ] __main__: train step 7726: loss: 1.0435, policy_loss: 1.2467, value_loss: 0.7954
2024-07-11 16:25:11,379 [INFO    ] __main__: train step 7727: loss: 1.0436, policy_loss: 1.2467, value_loss: 0.7953
2024-07-11 16:25:11,582 [INFO    ] __main__: train step 7728: loss: 1.0436, policy_loss: 1.2466, value_loss: 0.7953
2024-07-11 16:25:11,776 [INFO    ] __main__: train step 7729: loss: 1.0436, policy_loss: 1.2465, value_loss: 0.7953
2024-07-11 16:25:11,981 [INFO    ] __main__: train step 7730: loss: 1.0437, policy_loss: 1.2465, value_loss: 0.7953
2024-07-11 16:25:12,219 [INFO    ] __main__: train step 7731: loss: 1.0437, policy_loss: 1.2464, value_loss: 0.7952
2024-07-11 16:25:12,415 [INFO    ] __main__: train step 7732: loss: 1.0437, policy_loss: 1.2463, value_loss: 0.7952
2024-07-11 16:25:12,629 [INFO    ] __main__: train step 7733: loss: 1.0438, policy_loss: 1.2462, value_loss: 0.7952
2024-07-11 16:25:12,846 [INFO    ] __main__: train step 7734: loss: 1.0438, policy_loss: 1.2461, value_loss: 0.7952
2024-07-11 16:25:14,286 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:25:14,746 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:25:14,810 [INFO    ] __main__: train step 7735: loss: 1.0438, policy_loss: 1.2461, value_loss: 0.7951
2024-07-11 16:25:14,985 [INFO    ] __main__: train step 7736: loss: 1.0438, policy_loss: 1.2460, value_loss: 0.7951
2024-07-11 16:25:15,186 [INFO    ] __main__: train step 7737: loss: 1.0439, policy_loss: 1.2459, value_loss: 0.7951
2024-07-11 16:25:15,385 [INFO    ] __main__: train step 7738: loss: 1.0439, policy_loss: 1.2458, value_loss: 0.7951
2024-07-11 16:25:15,583 [INFO    ] __main__: train step 7739: loss: 1.0439, policy_loss: 1.2458, value_loss: 0.7950
2024-07-11 16:25:16,606 [INFO    ] __main__: train step 7740: loss: 1.0439, policy_loss: 1.2457, value_loss: 0.7950
2024-07-11 16:25:16,822 [INFO    ] __main__: train step 7741: loss: 1.0440, policy_loss: 1.2456, value_loss: 0.7950
2024-07-11 16:25:17,022 [INFO    ] __main__: train step 7742: loss: 1.0440, policy_loss: 1.2455, value_loss: 0.7950
2024-07-11 16:25:17,228 [INFO    ] __main__: train step 7743: loss: 1.0440, policy_loss: 1.2455, value_loss: 0.7949
2024-07-11 16:25:17,431 [INFO    ] __main__: train step 7744: loss: 1.0441, policy_loss: 1.2454, value_loss: 0.7949
2024-07-11 16:25:17,641 [INFO    ] __main__: train step 7745: loss: 1.0441, policy_loss: 1.2453, value_loss: 0.7949
2024-07-11 16:25:17,840 [INFO    ] __main__: train step 7746: loss: 1.0441, policy_loss: 1.2452, value_loss: 0.7949
2024-07-11 16:25:18,040 [INFO    ] __main__: train step 7747: loss: 1.0441, policy_loss: 1.2452, value_loss: 0.7948
2024-07-11 16:25:18,236 [INFO    ] __main__: train step 7748: loss: 1.0442, policy_loss: 1.2451, value_loss: 0.7948
2024-07-11 16:25:18,433 [INFO    ] __main__: train step 7749: loss: 1.0442, policy_loss: 1.2450, value_loss: 0.7948
2024-07-11 16:25:18,644 [INFO    ] __main__: train step 7750: loss: 1.0442, policy_loss: 1.2449, value_loss: 0.7948
2024-07-11 16:25:18,847 [INFO    ] __main__: train step 7751: loss: 1.0443, policy_loss: 1.2449, value_loss: 0.7947
2024-07-11 16:25:20,272 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:25:20,720 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:25:20,781 [INFO    ] __main__: train step 7752: loss: 1.0443, policy_loss: 1.2448, value_loss: 0.7947
2024-07-11 16:25:20,951 [INFO    ] __main__: train step 7753: loss: 1.0443, policy_loss: 1.2447, value_loss: 0.7947
2024-07-11 16:25:21,156 [INFO    ] __main__: train step 7754: loss: 1.0443, policy_loss: 1.2446, value_loss: 0.7947
2024-07-11 16:25:21,387 [INFO    ] __main__: train step 7755: loss: 1.0444, policy_loss: 1.2446, value_loss: 0.7946
2024-07-11 16:25:21,584 [INFO    ] __main__: train step 7756: loss: 1.0444, policy_loss: 1.2445, value_loss: 0.7946
2024-07-11 16:25:21,784 [INFO    ] __main__: train step 7757: loss: 1.0444, policy_loss: 1.2444, value_loss: 0.7946
2024-07-11 16:25:21,980 [INFO    ] __main__: train step 7758: loss: 1.0445, policy_loss: 1.2443, value_loss: 0.7946
2024-07-11 16:25:22,185 [INFO    ] __main__: train step 7759: loss: 1.0445, policy_loss: 1.2443, value_loss: 0.7945
2024-07-11 16:25:22,401 [INFO    ] __main__: train step 7760: loss: 1.0445, policy_loss: 1.2442, value_loss: 0.7945
2024-07-11 16:25:22,617 [INFO    ] __main__: train step 7761: loss: 1.0445, policy_loss: 1.2441, value_loss: 0.7945
2024-07-11 16:25:22,819 [INFO    ] __main__: train step 7762: loss: 1.0446, policy_loss: 1.2440, value_loss: 0.7945
2024-07-11 16:25:23,022 [INFO    ] __main__: train step 7763: loss: 1.0446, policy_loss: 1.2440, value_loss: 0.7945
2024-07-11 16:25:23,269 [INFO    ] __main__: train step 7764: loss: 1.0446, policy_loss: 1.2439, value_loss: 0.7944
2024-07-11 16:25:23,492 [INFO    ] __main__: train step 7765: loss: 1.0447, policy_loss: 1.2438, value_loss: 0.7944
2024-07-11 16:25:23,704 [INFO    ] __main__: train step 7766: loss: 1.0447, policy_loss: 1.2437, value_loss: 0.7944
2024-07-11 16:25:23,926 [INFO    ] __main__: train step 7767: loss: 1.0447, policy_loss: 1.2437, value_loss: 0.7944
2024-07-11 16:25:24,128 [INFO    ] __main__: train step 7768: loss: 1.0447, policy_loss: 1.2436, value_loss: 0.7943
2024-07-11 16:25:25,564 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:25:26,002 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:25:26,065 [INFO    ] __main__: train step 7769: loss: 1.0448, policy_loss: 1.2435, value_loss: 0.7943
2024-07-11 16:25:26,242 [INFO    ] __main__: train step 7770: loss: 1.0448, policy_loss: 1.2434, value_loss: 0.7943
2024-07-11 16:25:26,433 [INFO    ] __main__: train step 7771: loss: 1.0448, policy_loss: 1.2434, value_loss: 0.7943
2024-07-11 16:25:26,641 [INFO    ] __main__: train step 7772: loss: 1.0448, policy_loss: 1.2433, value_loss: 0.7942
2024-07-11 16:25:26,842 [INFO    ] __main__: train step 7773: loss: 1.0449, policy_loss: 1.2432, value_loss: 0.7942
2024-07-11 16:25:27,051 [INFO    ] __main__: train step 7774: loss: 1.0449, policy_loss: 1.2431, value_loss: 0.7942
2024-07-11 16:25:27,255 [INFO    ] __main__: train step 7775: loss: 1.0449, policy_loss: 1.2431, value_loss: 0.7942
2024-07-11 16:25:27,462 [INFO    ] __main__: train step 7776: loss: 1.0449, policy_loss: 1.2430, value_loss: 0.7941
2024-07-11 16:25:27,664 [INFO    ] __main__: train step 7777: loss: 1.0450, policy_loss: 1.2429, value_loss: 0.7941
2024-07-11 16:25:27,864 [INFO    ] __main__: train step 7778: loss: 1.0450, policy_loss: 1.2428, value_loss: 0.7941
2024-07-11 16:25:28,063 [INFO    ] __main__: train step 7779: loss: 1.0450, policy_loss: 1.2428, value_loss: 0.7941
2024-07-11 16:25:28,260 [INFO    ] __main__: train step 7780: loss: 1.0451, policy_loss: 1.2427, value_loss: 0.7940
2024-07-11 16:25:28,502 [INFO    ] __main__: train step 7781: loss: 1.0451, policy_loss: 1.2426, value_loss: 0.7940
2024-07-11 16:25:28,696 [INFO    ] __main__: train step 7782: loss: 1.0451, policy_loss: 1.2425, value_loss: 0.7940
2024-07-11 16:25:28,904 [INFO    ] __main__: train step 7783: loss: 1.0451, policy_loss: 1.2424, value_loss: 0.7940
2024-07-11 16:25:29,112 [INFO    ] __main__: train step 7784: loss: 1.0452, policy_loss: 1.2424, value_loss: 0.7939
2024-07-11 16:25:29,329 [INFO    ] __main__: train step 7785: loss: 1.0452, policy_loss: 1.2423, value_loss: 0.7939
2024-07-11 16:25:30,768 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:25:31,170 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:25:31,227 [INFO    ] __main__: train step 7786: loss: 1.0452, policy_loss: 1.2422, value_loss: 0.7939
2024-07-11 16:25:31,402 [INFO    ] __main__: train step 7787: loss: 1.0452, policy_loss: 1.2421, value_loss: 0.7939
2024-07-11 16:25:31,612 [INFO    ] __main__: train step 7788: loss: 1.0453, policy_loss: 1.2421, value_loss: 0.7938
2024-07-11 16:25:31,822 [INFO    ] __main__: train step 7789: loss: 1.0453, policy_loss: 1.2420, value_loss: 0.7938
2024-07-11 16:25:32,028 [INFO    ] __main__: train step 7790: loss: 1.0453, policy_loss: 1.2419, value_loss: 0.7938
2024-07-11 16:25:32,245 [INFO    ] __main__: train step 7791: loss: 1.0454, policy_loss: 1.2418, value_loss: 0.7938
2024-07-11 16:25:32,468 [INFO    ] __main__: train step 7792: loss: 1.0454, policy_loss: 1.2418, value_loss: 0.7937
2024-07-11 16:25:32,677 [INFO    ] __main__: train step 7793: loss: 1.0454, policy_loss: 1.2417, value_loss: 0.7937
2024-07-11 16:25:32,873 [INFO    ] __main__: train step 7794: loss: 1.0454, policy_loss: 1.2416, value_loss: 0.7937
2024-07-11 16:25:33,066 [INFO    ] __main__: train step 7795: loss: 1.0455, policy_loss: 1.2415, value_loss: 0.7937
2024-07-11 16:25:33,269 [INFO    ] __main__: train step 7796: loss: 1.0455, policy_loss: 1.2415, value_loss: 0.7936
2024-07-11 16:25:33,475 [INFO    ] __main__: train step 7797: loss: 1.0455, policy_loss: 1.2414, value_loss: 0.7936
2024-07-11 16:25:33,712 [INFO    ] __main__: train step 7798: loss: 1.0455, policy_loss: 1.2413, value_loss: 0.7936
2024-07-11 16:25:33,918 [INFO    ] __main__: train step 7799: loss: 1.0456, policy_loss: 1.2412, value_loss: 0.7936
2024-07-11 16:25:34,121 [INFO    ] __main__: train step 7800: loss: 1.0456, policy_loss: 1.2412, value_loss: 0.7935
2024-07-11 16:25:34,320 [INFO    ] __main__: train step 7801: loss: 1.0456, policy_loss: 1.2411, value_loss: 0.7935
2024-07-11 16:25:34,531 [INFO    ] __main__: train step 7802: loss: 1.0456, policy_loss: 1.2410, value_loss: 0.7935
2024-07-11 16:25:35,978 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:25:36,395 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:25:36,449 [INFO    ] __main__: train step 7803: loss: 1.0457, policy_loss: 1.2409, value_loss: 0.7935
2024-07-11 16:25:36,622 [INFO    ] __main__: train step 7804: loss: 1.0457, policy_loss: 1.2409, value_loss: 0.7934
2024-07-11 16:25:36,827 [INFO    ] __main__: train step 7805: loss: 1.0457, policy_loss: 1.2408, value_loss: 0.7934
2024-07-11 16:25:37,028 [INFO    ] __main__: train step 7806: loss: 1.0457, policy_loss: 1.2407, value_loss: 0.7934
2024-07-11 16:25:37,232 [INFO    ] __main__: train step 7807: loss: 1.0458, policy_loss: 1.2406, value_loss: 0.7934
2024-07-11 16:25:37,435 [INFO    ] __main__: train step 7808: loss: 1.0458, policy_loss: 1.2406, value_loss: 0.7933
2024-07-11 16:25:37,635 [INFO    ] __main__: train step 7809: loss: 1.0458, policy_loss: 1.2405, value_loss: 0.7933
2024-07-11 16:25:37,836 [INFO    ] __main__: train step 7810: loss: 1.0458, policy_loss: 1.2404, value_loss: 0.7933
2024-07-11 16:25:38,039 [INFO    ] __main__: train step 7811: loss: 1.0459, policy_loss: 1.2403, value_loss: 0.7933
2024-07-11 16:25:38,241 [INFO    ] __main__: train step 7812: loss: 1.0459, policy_loss: 1.2403, value_loss: 0.7932
2024-07-11 16:25:39,314 [INFO    ] __main__: train step 7813: loss: 1.0459, policy_loss: 1.2402, value_loss: 0.7932
2024-07-11 16:25:39,542 [INFO    ] __main__: train step 7814: loss: 1.0459, policy_loss: 1.2401, value_loss: 0.7932
2024-07-11 16:25:39,744 [INFO    ] __main__: train step 7815: loss: 1.0460, policy_loss: 1.2400, value_loss: 0.7932
2024-07-11 16:25:39,969 [INFO    ] __main__: train step 7816: loss: 1.0460, policy_loss: 1.2400, value_loss: 0.7931
2024-07-11 16:25:40,198 [INFO    ] __main__: train step 7817: loss: 1.0460, policy_loss: 1.2399, value_loss: 0.7931
2024-07-11 16:25:40,400 [INFO    ] __main__: train step 7818: loss: 1.0460, policy_loss: 1.2398, value_loss: 0.7931
2024-07-11 16:25:40,604 [INFO    ] __main__: train step 7819: loss: 1.0461, policy_loss: 1.2397, value_loss: 0.7931
2024-07-11 16:25:42,027 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:25:42,444 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:25:42,501 [INFO    ] __main__: train step 7820: loss: 1.0461, policy_loss: 1.2397, value_loss: 0.7930
2024-07-11 16:25:42,674 [INFO    ] __main__: train step 7821: loss: 1.0461, policy_loss: 1.2396, value_loss: 0.7930
2024-07-11 16:25:42,873 [INFO    ] __main__: train step 7822: loss: 1.0461, policy_loss: 1.2395, value_loss: 0.7930
2024-07-11 16:25:43,075 [INFO    ] __main__: train step 7823: loss: 1.0462, policy_loss: 1.2394, value_loss: 0.7930
2024-07-11 16:25:43,278 [INFO    ] __main__: train step 7824: loss: 1.0462, policy_loss: 1.2394, value_loss: 0.7929
2024-07-11 16:25:43,482 [INFO    ] __main__: train step 7825: loss: 1.0462, policy_loss: 1.2393, value_loss: 0.7929
2024-07-11 16:25:43,684 [INFO    ] __main__: train step 7826: loss: 1.0462, policy_loss: 1.2392, value_loss: 0.7929
2024-07-11 16:25:43,893 [INFO    ] __main__: train step 7827: loss: 1.0463, policy_loss: 1.2391, value_loss: 0.7929
2024-07-11 16:25:44,106 [INFO    ] __main__: train step 7828: loss: 1.0463, policy_loss: 1.2390, value_loss: 0.7928
2024-07-11 16:25:44,317 [INFO    ] __main__: train step 7829: loss: 1.0463, policy_loss: 1.2390, value_loss: 0.7928
2024-07-11 16:25:44,548 [INFO    ] __main__: train step 7830: loss: 1.0463, policy_loss: 1.2389, value_loss: 0.7928
2024-07-11 16:25:44,735 [INFO    ] __main__: train step 7831: loss: 1.0464, policy_loss: 1.2388, value_loss: 0.7928
2024-07-11 16:25:44,951 [INFO    ] __main__: train step 7832: loss: 1.0464, policy_loss: 1.2387, value_loss: 0.7927
2024-07-11 16:25:45,149 [INFO    ] __main__: train step 7833: loss: 1.0464, policy_loss: 1.2387, value_loss: 0.7927
2024-07-11 16:25:45,350 [INFO    ] __main__: train step 7834: loss: 1.0464, policy_loss: 1.2386, value_loss: 0.7927
2024-07-11 16:25:45,570 [INFO    ] __main__: train step 7835: loss: 1.0465, policy_loss: 1.2385, value_loss: 0.7927
2024-07-11 16:25:45,757 [INFO    ] __main__: train step 7836: loss: 1.0465, policy_loss: 1.2384, value_loss: 0.7926
2024-07-11 16:25:47,191 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:25:47,606 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:25:47,659 [INFO    ] __main__: train step 7837: loss: 1.0465, policy_loss: 1.2384, value_loss: 0.7926
2024-07-11 16:25:47,822 [INFO    ] __main__: train step 7838: loss: 1.0465, policy_loss: 1.2383, value_loss: 0.7926
2024-07-11 16:25:48,046 [INFO    ] __main__: train step 7839: loss: 1.0466, policy_loss: 1.2382, value_loss: 0.7926
2024-07-11 16:25:48,246 [INFO    ] __main__: train step 7840: loss: 1.0466, policy_loss: 1.2381, value_loss: 0.7925
2024-07-11 16:25:48,445 [INFO    ] __main__: train step 7841: loss: 1.0466, policy_loss: 1.2381, value_loss: 0.7925
2024-07-11 16:25:48,644 [INFO    ] __main__: train step 7842: loss: 1.0466, policy_loss: 1.2380, value_loss: 0.7925
2024-07-11 16:25:48,851 [INFO    ] __main__: train step 7843: loss: 1.0467, policy_loss: 1.2379, value_loss: 0.7925
2024-07-11 16:25:49,048 [INFO    ] __main__: train step 7844: loss: 1.0467, policy_loss: 1.2378, value_loss: 0.7924
2024-07-11 16:25:49,262 [INFO    ] __main__: train step 7845: loss: 1.0467, policy_loss: 1.2378, value_loss: 0.7924
2024-07-11 16:25:49,462 [INFO    ] __main__: train step 7846: loss: 1.0467, policy_loss: 1.2377, value_loss: 0.7924
2024-07-11 16:25:49,669 [INFO    ] __main__: train step 7847: loss: 1.0468, policy_loss: 1.2376, value_loss: 0.7924
2024-07-11 16:25:49,865 [INFO    ] __main__: train step 7848: loss: 1.0468, policy_loss: 1.2375, value_loss: 0.7923
2024-07-11 16:25:50,070 [INFO    ] __main__: train step 7849: loss: 1.0468, policy_loss: 1.2375, value_loss: 0.7923
2024-07-11 16:25:50,280 [INFO    ] __main__: train step 7850: loss: 1.0468, policy_loss: 1.2374, value_loss: 0.7923
2024-07-11 16:25:50,480 [INFO    ] __main__: train step 7851: loss: 1.0469, policy_loss: 1.2373, value_loss: 0.7923
2024-07-11 16:25:50,684 [INFO    ] __main__: train step 7852: loss: 1.0469, policy_loss: 1.2372, value_loss: 0.7922
2024-07-11 16:25:50,892 [INFO    ] __main__: train step 7853: loss: 1.0469, policy_loss: 1.2372, value_loss: 0.7922
2024-07-11 16:25:52,336 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:25:52,771 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:25:52,832 [INFO    ] __main__: train step 7854: loss: 1.0469, policy_loss: 1.2371, value_loss: 0.7922
2024-07-11 16:25:53,003 [INFO    ] __main__: train step 7855: loss: 1.0470, policy_loss: 1.2370, value_loss: 0.7922
2024-07-11 16:25:53,221 [INFO    ] __main__: train step 7856: loss: 1.0470, policy_loss: 1.2369, value_loss: 0.7922
2024-07-11 16:25:53,471 [INFO    ] __main__: train step 7857: loss: 1.0470, policy_loss: 1.2369, value_loss: 0.7921
2024-07-11 16:25:53,707 [INFO    ] __main__: train step 7858: loss: 1.0470, policy_loss: 1.2368, value_loss: 0.7921
2024-07-11 16:25:53,913 [INFO    ] __main__: train step 7859: loss: 1.0471, policy_loss: 1.2367, value_loss: 0.7921
2024-07-11 16:25:54,112 [INFO    ] __main__: train step 7860: loss: 1.0471, policy_loss: 1.2366, value_loss: 0.7920
2024-07-11 16:25:54,316 [INFO    ] __main__: train step 7861: loss: 1.0471, policy_loss: 1.2366, value_loss: 0.7920
2024-07-11 16:25:54,514 [INFO    ] __main__: train step 7862: loss: 1.0471, policy_loss: 1.2365, value_loss: 0.7920
2024-07-11 16:25:54,719 [INFO    ] __main__: train step 7863: loss: 1.0472, policy_loss: 1.2364, value_loss: 0.7920
2024-07-11 16:25:54,916 [INFO    ] __main__: train step 7864: loss: 1.0472, policy_loss: 1.2363, value_loss: 0.7919
2024-07-11 16:25:55,118 [INFO    ] __main__: train step 7865: loss: 1.0472, policy_loss: 1.2363, value_loss: 0.7919
2024-07-11 16:25:55,320 [INFO    ] __main__: train step 7866: loss: 1.0472, policy_loss: 1.2362, value_loss: 0.7919
2024-07-11 16:25:55,533 [INFO    ] __main__: train step 7867: loss: 1.0473, policy_loss: 1.2361, value_loss: 0.7919
2024-07-11 16:25:55,746 [INFO    ] __main__: train step 7868: loss: 1.0473, policy_loss: 1.2360, value_loss: 0.7918
2024-07-11 16:25:55,952 [INFO    ] __main__: train step 7869: loss: 1.0473, policy_loss: 1.2359, value_loss: 0.7918
2024-07-11 16:25:56,186 [INFO    ] __main__: train step 7870: loss: 1.0473, policy_loss: 1.2359, value_loss: 0.7918
2024-07-11 16:25:57,626 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:25:58,038 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:25:58,094 [INFO    ] __main__: train step 7871: loss: 1.0474, policy_loss: 1.2358, value_loss: 0.7918
2024-07-11 16:25:58,265 [INFO    ] __main__: train step 7872: loss: 1.0474, policy_loss: 1.2357, value_loss: 0.7918
2024-07-11 16:25:58,468 [INFO    ] __main__: train step 7873: loss: 1.0474, policy_loss: 1.2356, value_loss: 0.7917
2024-07-11 16:25:58,661 [INFO    ] __main__: train step 7874: loss: 1.0474, policy_loss: 1.2356, value_loss: 0.7917
2024-07-11 16:25:58,870 [INFO    ] __main__: train step 7875: loss: 1.0475, policy_loss: 1.2355, value_loss: 0.7917
2024-07-11 16:25:59,073 [INFO    ] __main__: train step 7876: loss: 1.0475, policy_loss: 1.2354, value_loss: 0.7917
2024-07-11 16:25:59,298 [INFO    ] __main__: train step 7877: loss: 1.0475, policy_loss: 1.2353, value_loss: 0.7916
2024-07-11 16:25:59,516 [INFO    ] __main__: train step 7878: loss: 1.0475, policy_loss: 1.2353, value_loss: 0.7916
2024-07-11 16:25:59,735 [INFO    ] __main__: train step 7879: loss: 1.0475, policy_loss: 1.2352, value_loss: 0.7916
2024-07-11 16:25:59,931 [INFO    ] __main__: train step 7880: loss: 1.0476, policy_loss: 1.2351, value_loss: 0.7916
2024-07-11 16:26:00,130 [INFO    ] __main__: train step 7881: loss: 1.0476, policy_loss: 1.2350, value_loss: 0.7915
2024-07-11 16:26:00,328 [INFO    ] __main__: train step 7882: loss: 1.0476, policy_loss: 1.2350, value_loss: 0.7915
2024-07-11 16:26:00,530 [INFO    ] __main__: train step 7883: loss: 1.0476, policy_loss: 1.2349, value_loss: 0.7915
2024-07-11 16:26:00,738 [INFO    ] __main__: train step 7884: loss: 1.0477, policy_loss: 1.2348, value_loss: 0.7915
2024-07-11 16:26:00,938 [INFO    ] __main__: train step 7885: loss: 1.0477, policy_loss: 1.2347, value_loss: 0.7914
2024-07-11 16:26:01,983 [INFO    ] __main__: train step 7886: loss: 1.0477, policy_loss: 1.2347, value_loss: 0.7914
2024-07-11 16:26:02,209 [INFO    ] __main__: train step 7887: loss: 1.0477, policy_loss: 1.2346, value_loss: 0.7914
2024-07-11 16:26:03,639 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:26:04,012 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:26:04,067 [INFO    ] __main__: train step 7888: loss: 1.0477, policy_loss: 1.2345, value_loss: 0.7914
2024-07-11 16:26:04,246 [INFO    ] __main__: train step 7889: loss: 1.0478, policy_loss: 1.2344, value_loss: 0.7913
2024-07-11 16:26:04,455 [INFO    ] __main__: train step 7890: loss: 1.0478, policy_loss: 1.2344, value_loss: 0.7913
2024-07-11 16:26:04,655 [INFO    ] __main__: train step 7891: loss: 1.0478, policy_loss: 1.2343, value_loss: 0.7913
2024-07-11 16:26:04,878 [INFO    ] __main__: train step 7892: loss: 1.0478, policy_loss: 1.2342, value_loss: 0.7913
2024-07-11 16:26:05,074 [INFO    ] __main__: train step 7893: loss: 1.0479, policy_loss: 1.2341, value_loss: 0.7912
2024-07-11 16:26:05,270 [INFO    ] __main__: train step 7894: loss: 1.0479, policy_loss: 1.2341, value_loss: 0.7912
2024-07-11 16:26:05,474 [INFO    ] __main__: train step 7895: loss: 1.0479, policy_loss: 1.2340, value_loss: 0.7912
2024-07-11 16:26:05,685 [INFO    ] __main__: train step 7896: loss: 1.0479, policy_loss: 1.2339, value_loss: 0.7912
2024-07-11 16:26:05,910 [INFO    ] __main__: train step 7897: loss: 1.0480, policy_loss: 1.2338, value_loss: 0.7911
2024-07-11 16:26:06,130 [INFO    ] __main__: train step 7898: loss: 1.0480, policy_loss: 1.2337, value_loss: 0.7911
2024-07-11 16:26:06,362 [INFO    ] __main__: train step 7899: loss: 1.0480, policy_loss: 1.2337, value_loss: 0.7911
2024-07-11 16:26:06,586 [INFO    ] __main__: train step 7900: loss: 1.0480, policy_loss: 1.2336, value_loss: 0.7911
2024-07-11 16:26:06,788 [INFO    ] __main__: train step 7901: loss: 1.0480, policy_loss: 1.2335, value_loss: 0.7910
2024-07-11 16:26:06,998 [INFO    ] __main__: train step 7902: loss: 1.0481, policy_loss: 1.2334, value_loss: 0.7910
2024-07-11 16:26:07,196 [INFO    ] __main__: train step 7903: loss: 1.0481, policy_loss: 1.2334, value_loss: 0.7910
2024-07-11 16:26:07,399 [INFO    ] __main__: train step 7904: loss: 1.0481, policy_loss: 1.2333, value_loss: 0.7910
2024-07-11 16:26:08,830 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:26:09,218 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:26:09,277 [INFO    ] __main__: train step 7905: loss: 1.0481, policy_loss: 1.2332, value_loss: 0.7909
2024-07-11 16:26:09,453 [INFO    ] __main__: train step 7906: loss: 1.0482, policy_loss: 1.2331, value_loss: 0.7909
2024-07-11 16:26:09,685 [INFO    ] __main__: train step 7907: loss: 1.0482, policy_loss: 1.2331, value_loss: 0.7909
2024-07-11 16:26:09,890 [INFO    ] __main__: train step 7908: loss: 1.0482, policy_loss: 1.2330, value_loss: 0.7909
2024-07-11 16:26:10,097 [INFO    ] __main__: train step 7909: loss: 1.0482, policy_loss: 1.2329, value_loss: 0.7908
2024-07-11 16:26:10,294 [INFO    ] __main__: train step 7910: loss: 1.0482, policy_loss: 1.2328, value_loss: 0.7908
2024-07-11 16:26:10,498 [INFO    ] __main__: train step 7911: loss: 1.0483, policy_loss: 1.2328, value_loss: 0.7908
2024-07-11 16:26:10,700 [INFO    ] __main__: train step 7912: loss: 1.0483, policy_loss: 1.2327, value_loss: 0.7907
2024-07-11 16:26:10,923 [INFO    ] __main__: train step 7913: loss: 1.0483, policy_loss: 1.2326, value_loss: 0.7907
2024-07-11 16:26:11,135 [INFO    ] __main__: train step 7914: loss: 1.0483, policy_loss: 1.2325, value_loss: 0.7907
2024-07-11 16:26:11,375 [INFO    ] __main__: train step 7915: loss: 1.0483, policy_loss: 1.2325, value_loss: 0.7907
2024-07-11 16:26:11,607 [INFO    ] __main__: train step 7916: loss: 1.0484, policy_loss: 1.2324, value_loss: 0.7906
2024-07-11 16:26:11,806 [INFO    ] __main__: train step 7917: loss: 1.0484, policy_loss: 1.2323, value_loss: 0.7906
2024-07-11 16:26:12,017 [INFO    ] __main__: train step 7918: loss: 1.0484, policy_loss: 1.2322, value_loss: 0.7906
2024-07-11 16:26:12,248 [INFO    ] __main__: train step 7919: loss: 1.0484, policy_loss: 1.2322, value_loss: 0.7906
2024-07-11 16:26:12,459 [INFO    ] __main__: train step 7920: loss: 1.0485, policy_loss: 1.2321, value_loss: 0.7905
2024-07-11 16:26:12,660 [INFO    ] __main__: train step 7921: loss: 1.0485, policy_loss: 1.2320, value_loss: 0.7905
2024-07-11 16:26:14,091 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:26:14,511 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:26:14,565 [INFO    ] __main__: train step 7922: loss: 1.0485, policy_loss: 1.2319, value_loss: 0.7905
2024-07-11 16:26:14,737 [INFO    ] __main__: train step 7923: loss: 1.0485, policy_loss: 1.2318, value_loss: 0.7905
2024-07-11 16:26:14,941 [INFO    ] __main__: train step 7924: loss: 1.0485, policy_loss: 1.2318, value_loss: 0.7904
2024-07-11 16:26:15,150 [INFO    ] __main__: train step 7925: loss: 1.0486, policy_loss: 1.2317, value_loss: 0.7904
2024-07-11 16:26:15,351 [INFO    ] __main__: train step 7926: loss: 1.0486, policy_loss: 1.2316, value_loss: 0.7904
2024-07-11 16:26:15,546 [INFO    ] __main__: train step 7927: loss: 1.0486, policy_loss: 1.2315, value_loss: 0.7904
2024-07-11 16:26:15,743 [INFO    ] __main__: train step 7928: loss: 1.0486, policy_loss: 1.2315, value_loss: 0.7903
2024-07-11 16:26:15,924 [INFO    ] __main__: train step 7929: loss: 1.0486, policy_loss: 1.2314, value_loss: 0.7903
2024-07-11 16:26:16,120 [INFO    ] __main__: train step 7930: loss: 1.0487, policy_loss: 1.2313, value_loss: 0.7903
2024-07-11 16:26:16,306 [INFO    ] __main__: train step 7931: loss: 1.0487, policy_loss: 1.2312, value_loss: 0.7903
2024-07-11 16:26:16,508 [INFO    ] __main__: train step 7932: loss: 1.0487, policy_loss: 1.2312, value_loss: 0.7902
2024-07-11 16:26:16,707 [INFO    ] __main__: train step 7933: loss: 1.0487, policy_loss: 1.2311, value_loss: 0.7902
2024-07-11 16:26:16,915 [INFO    ] __main__: train step 7934: loss: 1.0488, policy_loss: 1.2310, value_loss: 0.7902
2024-07-11 16:26:17,103 [INFO    ] __main__: train step 7935: loss: 1.0488, policy_loss: 1.2309, value_loss: 0.7902
2024-07-11 16:26:17,337 [INFO    ] __main__: train step 7936: loss: 1.0488, policy_loss: 1.2308, value_loss: 0.7902
2024-07-11 16:26:17,546 [INFO    ] __main__: train step 7937: loss: 1.0488, policy_loss: 1.2308, value_loss: 0.7901
2024-07-11 16:26:17,751 [INFO    ] __main__: train step 7938: loss: 1.0488, policy_loss: 1.2307, value_loss: 0.7901
2024-07-11 16:26:19,190 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:26:19,606 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:26:19,660 [INFO    ] __main__: train step 7939: loss: 1.0489, policy_loss: 1.2306, value_loss: 0.7901
2024-07-11 16:26:19,836 [INFO    ] __main__: train step 7940: loss: 1.0489, policy_loss: 1.2305, value_loss: 0.7901
2024-07-11 16:26:20,050 [INFO    ] __main__: train step 7941: loss: 1.0489, policy_loss: 1.2305, value_loss: 0.7900
2024-07-11 16:26:20,243 [INFO    ] __main__: train step 7942: loss: 1.0489, policy_loss: 1.2304, value_loss: 0.7900
2024-07-11 16:26:20,447 [INFO    ] __main__: train step 7943: loss: 1.0489, policy_loss: 1.2303, value_loss: 0.7900
2024-07-11 16:26:20,650 [INFO    ] __main__: train step 7944: loss: 1.0490, policy_loss: 1.2302, value_loss: 0.7900
2024-07-11 16:26:20,845 [INFO    ] __main__: train step 7945: loss: 1.0490, policy_loss: 1.2302, value_loss: 0.7899
2024-07-11 16:26:21,062 [INFO    ] __main__: train step 7946: loss: 1.0490, policy_loss: 1.2301, value_loss: 0.7899
2024-07-11 16:26:21,266 [INFO    ] __main__: train step 7947: loss: 1.0490, policy_loss: 1.2300, value_loss: 0.7899
2024-07-11 16:26:21,465 [INFO    ] __main__: train step 7948: loss: 1.0491, policy_loss: 1.2299, value_loss: 0.7899
2024-07-11 16:26:21,667 [INFO    ] __main__: train step 7949: loss: 1.0491, policy_loss: 1.2299, value_loss: 0.7898
2024-07-11 16:26:21,864 [INFO    ] __main__: train step 7950: loss: 1.0491, policy_loss: 1.2298, value_loss: 0.7898
2024-07-11 16:26:22,061 [INFO    ] __main__: train step 7951: loss: 1.0491, policy_loss: 1.2297, value_loss: 0.7898
2024-07-11 16:26:22,269 [INFO    ] __main__: train step 7952: loss: 1.0491, policy_loss: 1.2296, value_loss: 0.7898
2024-07-11 16:26:22,481 [INFO    ] __main__: train step 7953: loss: 1.0492, policy_loss: 1.2296, value_loss: 0.7897
2024-07-11 16:26:22,677 [INFO    ] __main__: train step 7954: loss: 1.0492, policy_loss: 1.2295, value_loss: 0.7897
2024-07-11 16:26:22,915 [INFO    ] __main__: train step 7955: loss: 1.0492, policy_loss: 1.2294, value_loss: 0.7897
2024-07-11 16:26:24,365 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:26:24,800 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:26:24,861 [INFO    ] __main__: train step 7956: loss: 1.0492, policy_loss: 1.2293, value_loss: 0.7897
2024-07-11 16:26:25,027 [INFO    ] __main__: train step 7957: loss: 1.0492, policy_loss: 1.2293, value_loss: 0.7896
2024-07-11 16:26:25,226 [INFO    ] __main__: train step 7958: loss: 1.0493, policy_loss: 1.2292, value_loss: 0.7896
2024-07-11 16:26:26,261 [INFO    ] __main__: train step 7959: loss: 1.0493, policy_loss: 1.2291, value_loss: 0.7896
2024-07-11 16:26:26,470 [INFO    ] __main__: train step 7960: loss: 1.0493, policy_loss: 1.2290, value_loss: 0.7896
2024-07-11 16:26:26,680 [INFO    ] __main__: train step 7961: loss: 1.0493, policy_loss: 1.2290, value_loss: 0.7895
2024-07-11 16:26:26,883 [INFO    ] __main__: train step 7962: loss: 1.0494, policy_loss: 1.2289, value_loss: 0.7895
2024-07-11 16:26:27,081 [INFO    ] __main__: train step 7963: loss: 1.0494, policy_loss: 1.2288, value_loss: 0.7895
2024-07-11 16:26:27,283 [INFO    ] __main__: train step 7964: loss: 1.0494, policy_loss: 1.2287, value_loss: 0.7895
2024-07-11 16:26:27,485 [INFO    ] __main__: train step 7965: loss: 1.0494, policy_loss: 1.2287, value_loss: 0.7894
2024-07-11 16:26:27,681 [INFO    ] __main__: train step 7966: loss: 1.0494, policy_loss: 1.2286, value_loss: 0.7894
2024-07-11 16:26:27,887 [INFO    ] __main__: train step 7967: loss: 1.0495, policy_loss: 1.2285, value_loss: 0.7894
2024-07-11 16:26:28,090 [INFO    ] __main__: train step 7968: loss: 1.0495, policy_loss: 1.2284, value_loss: 0.7894
2024-07-11 16:26:28,289 [INFO    ] __main__: train step 7969: loss: 1.0495, policy_loss: 1.2284, value_loss: 0.7893
2024-07-11 16:26:28,491 [INFO    ] __main__: train step 7970: loss: 1.0495, policy_loss: 1.2283, value_loss: 0.7893
2024-07-11 16:26:28,690 [INFO    ] __main__: train step 7971: loss: 1.0496, policy_loss: 1.2282, value_loss: 0.7893
2024-07-11 16:26:28,897 [INFO    ] __main__: train step 7972: loss: 1.0496, policy_loss: 1.2281, value_loss: 0.7893
2024-07-11 16:26:30,341 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:26:30,693 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:26:30,749 [INFO    ] __main__: train step 7973: loss: 1.0496, policy_loss: 1.2281, value_loss: 0.7892
2024-07-11 16:26:30,926 [INFO    ] __main__: train step 7974: loss: 1.0496, policy_loss: 1.2280, value_loss: 0.7892
2024-07-11 16:26:31,140 [INFO    ] __main__: train step 7975: loss: 1.0496, policy_loss: 1.2279, value_loss: 0.7892
2024-07-11 16:26:31,337 [INFO    ] __main__: train step 7976: loss: 1.0497, policy_loss: 1.2278, value_loss: 0.7892
2024-07-11 16:26:31,545 [INFO    ] __main__: train step 7977: loss: 1.0497, policy_loss: 1.2278, value_loss: 0.7891
2024-07-11 16:26:31,751 [INFO    ] __main__: train step 7978: loss: 1.0497, policy_loss: 1.2277, value_loss: 0.7891
2024-07-11 16:26:31,954 [INFO    ] __main__: train step 7979: loss: 1.0497, policy_loss: 1.2276, value_loss: 0.7891
2024-07-11 16:26:32,163 [INFO    ] __main__: train step 7980: loss: 1.0497, policy_loss: 1.2275, value_loss: 0.7891
2024-07-11 16:26:32,369 [INFO    ] __main__: train step 7981: loss: 1.0498, policy_loss: 1.2275, value_loss: 0.7890
2024-07-11 16:26:32,576 [INFO    ] __main__: train step 7982: loss: 1.0498, policy_loss: 1.2274, value_loss: 0.7890
2024-07-11 16:26:32,771 [INFO    ] __main__: train step 7983: loss: 1.0498, policy_loss: 1.2273, value_loss: 0.7890
2024-07-11 16:26:32,965 [INFO    ] __main__: train step 7984: loss: 1.0498, policy_loss: 1.2272, value_loss: 0.7890
2024-07-11 16:26:33,168 [INFO    ] __main__: train step 7985: loss: 1.0498, policy_loss: 1.2271, value_loss: 0.7889
2024-07-11 16:26:33,371 [INFO    ] __main__: train step 7986: loss: 1.0499, policy_loss: 1.2271, value_loss: 0.7889
2024-07-11 16:26:33,567 [INFO    ] __main__: train step 7987: loss: 1.0499, policy_loss: 1.2270, value_loss: 0.7889
2024-07-11 16:26:33,775 [INFO    ] __main__: train step 7988: loss: 1.0499, policy_loss: 1.2269, value_loss: 0.7889
2024-07-11 16:26:33,984 [INFO    ] __main__: train step 7989: loss: 1.0499, policy_loss: 1.2268, value_loss: 0.7888
2024-07-11 16:26:35,427 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:26:35,862 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:26:35,925 [INFO    ] __main__: train step 7990: loss: 1.0499, policy_loss: 1.2268, value_loss: 0.7888
2024-07-11 16:26:36,083 [INFO    ] __main__: train step 7991: loss: 1.0500, policy_loss: 1.2267, value_loss: 0.7888
2024-07-11 16:26:36,287 [INFO    ] __main__: train step 7992: loss: 1.0500, policy_loss: 1.2266, value_loss: 0.7888
2024-07-11 16:26:36,497 [INFO    ] __main__: train step 7993: loss: 1.0500, policy_loss: 1.2265, value_loss: 0.7887
2024-07-11 16:26:36,688 [INFO    ] __main__: train step 7994: loss: 1.0500, policy_loss: 1.2265, value_loss: 0.7887
2024-07-11 16:26:36,882 [INFO    ] __main__: train step 7995: loss: 1.0500, policy_loss: 1.2264, value_loss: 0.7887
2024-07-11 16:26:37,084 [INFO    ] __main__: train step 7996: loss: 1.0500, policy_loss: 1.2263, value_loss: 0.7887
2024-07-11 16:26:37,281 [INFO    ] __main__: train step 7997: loss: 1.0501, policy_loss: 1.2262, value_loss: 0.7886
2024-07-11 16:26:37,486 [INFO    ] __main__: train step 7998: loss: 1.0501, policy_loss: 1.2262, value_loss: 0.7886
2024-07-11 16:26:37,687 [INFO    ] __main__: train step 7999: loss: 1.0501, policy_loss: 1.2261, value_loss: 0.7886
2024-07-11 16:26:37,893 [INFO    ] __main__: train step 8000: loss: 1.0501, policy_loss: 1.2260, value_loss: 0.7886
2024-07-11 16:26:38,009 [INFO    ] __main__: restored step 7000 for evaluation
2024-07-11 16:26:45,451 [INFO    ] __main__: later network ELO difference from earlier network: +80 (+8/-8) ELO from 32000 self-played games
2024-07-11 16:26:45,451 [INFO    ] __main__: game outcomes: W: 18674, D: 542, L: 12784
2024-07-11 16:26:45,453 [INFO    ] __main__: validation_elo_delta: 80, validation_elo: 1634
2024-07-11 16:26:45,935 [INFO    ] __main__: train step 8001: loss: 1.0501, policy_loss: 1.2259, value_loss: 0.7885
2024-07-11 16:26:46,129 [INFO    ] __main__: train step 8002: loss: 1.0502, policy_loss: 1.2259, value_loss: 0.7885
2024-07-11 16:26:46,324 [INFO    ] __main__: train step 8003: loss: 1.0502, policy_loss: 1.2258, value_loss: 0.7885
2024-07-11 16:26:46,530 [INFO    ] __main__: train step 8004: loss: 1.0502, policy_loss: 1.2257, value_loss: 0.7885
2024-07-11 16:26:46,723 [INFO    ] __main__: train step 8005: loss: 1.0502, policy_loss: 1.2256, value_loss: 0.7884
2024-07-11 16:26:46,957 [INFO    ] __main__: train step 8006: loss: 1.0502, policy_loss: 1.2256, value_loss: 0.7884
2024-07-11 16:26:48,399 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:26:48,787 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:26:48,842 [INFO    ] __main__: train step 8007: loss: 1.0503, policy_loss: 1.2255, value_loss: 0.7884
2024-07-11 16:26:49,017 [INFO    ] __main__: train step 8008: loss: 1.0503, policy_loss: 1.2254, value_loss: 0.7884
2024-07-11 16:26:49,217 [INFO    ] __main__: train step 8009: loss: 1.0503, policy_loss: 1.2253, value_loss: 0.7883
2024-07-11 16:26:49,419 [INFO    ] __main__: train step 8010: loss: 1.0503, policy_loss: 1.2253, value_loss: 0.7883
2024-07-11 16:26:49,624 [INFO    ] __main__: train step 8011: loss: 1.0503, policy_loss: 1.2252, value_loss: 0.7883
2024-07-11 16:26:49,826 [INFO    ] __main__: train step 8012: loss: 1.0504, policy_loss: 1.2251, value_loss: 0.7883
2024-07-11 16:26:50,035 [INFO    ] __main__: train step 8013: loss: 1.0504, policy_loss: 1.2250, value_loss: 0.7882
2024-07-11 16:26:50,234 [INFO    ] __main__: train step 8014: loss: 1.0504, policy_loss: 1.2250, value_loss: 0.7882
2024-07-11 16:26:50,442 [INFO    ] __main__: train step 8015: loss: 1.0504, policy_loss: 1.2249, value_loss: 0.7882
2024-07-11 16:26:50,649 [INFO    ] __main__: train step 8016: loss: 1.0504, policy_loss: 1.2248, value_loss: 0.7882
2024-07-11 16:26:50,843 [INFO    ] __main__: train step 8017: loss: 1.0505, policy_loss: 1.2247, value_loss: 0.7881
2024-07-11 16:26:51,047 [INFO    ] __main__: train step 8018: loss: 1.0505, policy_loss: 1.2246, value_loss: 0.7881
2024-07-11 16:26:51,246 [INFO    ] __main__: train step 8019: loss: 1.0505, policy_loss: 1.2246, value_loss: 0.7881
2024-07-11 16:26:51,458 [INFO    ] __main__: train step 8020: loss: 1.0505, policy_loss: 1.2245, value_loss: 0.7881
2024-07-11 16:26:51,651 [INFO    ] __main__: train step 8021: loss: 1.0505, policy_loss: 1.2244, value_loss: 0.7880
2024-07-11 16:26:51,843 [INFO    ] __main__: train step 8022: loss: 1.0506, policy_loss: 1.2244, value_loss: 0.7880
2024-07-11 16:26:52,038 [INFO    ] __main__: train step 8023: loss: 1.0506, policy_loss: 1.2243, value_loss: 0.7880
2024-07-11 16:26:53,470 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:26:53,890 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:26:53,952 [INFO    ] __main__: train step 8024: loss: 1.0506, policy_loss: 1.2242, value_loss: 0.7880
2024-07-11 16:26:54,120 [INFO    ] __main__: train step 8025: loss: 1.0506, policy_loss: 1.2241, value_loss: 0.7879
2024-07-11 16:26:54,314 [INFO    ] __main__: train step 8026: loss: 1.0506, policy_loss: 1.2241, value_loss: 0.7879
2024-07-11 16:26:54,508 [INFO    ] __main__: train step 8027: loss: 1.0507, policy_loss: 1.2240, value_loss: 0.7879
2024-07-11 16:26:54,723 [INFO    ] __main__: train step 8028: loss: 1.0507, policy_loss: 1.2239, value_loss: 0.7879
2024-07-11 16:26:54,920 [INFO    ] __main__: train step 8029: loss: 1.0507, policy_loss: 1.2238, value_loss: 0.7878
2024-07-11 16:26:55,125 [INFO    ] __main__: train step 8030: loss: 1.0507, policy_loss: 1.2238, value_loss: 0.7878
2024-07-11 16:26:56,164 [INFO    ] __main__: train step 8031: loss: 1.0507, policy_loss: 1.2237, value_loss: 0.7878
2024-07-11 16:26:56,379 [INFO    ] __main__: train step 8032: loss: 1.0507, policy_loss: 1.2236, value_loss: 0.7878
2024-07-11 16:26:56,577 [INFO    ] __main__: train step 8033: loss: 1.0508, policy_loss: 1.2235, value_loss: 0.7877
2024-07-11 16:26:56,774 [INFO    ] __main__: train step 8034: loss: 1.0508, policy_loss: 1.2235, value_loss: 0.7877
2024-07-11 16:26:56,974 [INFO    ] __main__: train step 8035: loss: 1.0508, policy_loss: 1.2234, value_loss: 0.7877
2024-07-11 16:26:57,180 [INFO    ] __main__: train step 8036: loss: 1.0508, policy_loss: 1.2233, value_loss: 0.7876
2024-07-11 16:26:57,388 [INFO    ] __main__: train step 8037: loss: 1.0508, policy_loss: 1.2232, value_loss: 0.7876
2024-07-11 16:26:57,585 [INFO    ] __main__: train step 8038: loss: 1.0509, policy_loss: 1.2232, value_loss: 0.7876
2024-07-11 16:26:57,794 [INFO    ] __main__: train step 8039: loss: 1.0509, policy_loss: 1.2231, value_loss: 0.7876
2024-07-11 16:26:58,002 [INFO    ] __main__: train step 8040: loss: 1.0509, policy_loss: 1.2230, value_loss: 0.7875
2024-07-11 16:26:59,439 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:26:59,829 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:26:59,883 [INFO    ] __main__: train step 8041: loss: 1.0509, policy_loss: 1.2229, value_loss: 0.7875
2024-07-11 16:27:00,054 [INFO    ] __main__: train step 8042: loss: 1.0509, policy_loss: 1.2229, value_loss: 0.7875
2024-07-11 16:27:00,264 [INFO    ] __main__: train step 8043: loss: 1.0509, policy_loss: 1.2228, value_loss: 0.7875
2024-07-11 16:27:00,463 [INFO    ] __main__: train step 8044: loss: 1.0510, policy_loss: 1.2227, value_loss: 0.7874
2024-07-11 16:27:00,676 [INFO    ] __main__: train step 8045: loss: 1.0510, policy_loss: 1.2226, value_loss: 0.7874
2024-07-11 16:27:00,874 [INFO    ] __main__: train step 8046: loss: 1.0510, policy_loss: 1.2226, value_loss: 0.7874
2024-07-11 16:27:01,081 [INFO    ] __main__: train step 8047: loss: 1.0510, policy_loss: 1.2225, value_loss: 0.7874
2024-07-11 16:27:01,289 [INFO    ] __main__: train step 8048: loss: 1.0510, policy_loss: 1.2224, value_loss: 0.7873
2024-07-11 16:27:01,494 [INFO    ] __main__: train step 8049: loss: 1.0511, policy_loss: 1.2223, value_loss: 0.7873
2024-07-11 16:27:01,703 [INFO    ] __main__: train step 8050: loss: 1.0511, policy_loss: 1.2223, value_loss: 0.7873
2024-07-11 16:27:01,916 [INFO    ] __main__: train step 8051: loss: 1.0511, policy_loss: 1.2222, value_loss: 0.7873
2024-07-11 16:27:02,114 [INFO    ] __main__: train step 8052: loss: 1.0511, policy_loss: 1.2221, value_loss: 0.7872
2024-07-11 16:27:02,326 [INFO    ] __main__: train step 8053: loss: 1.0511, policy_loss: 1.2220, value_loss: 0.7872
2024-07-11 16:27:02,541 [INFO    ] __main__: train step 8054: loss: 1.0512, policy_loss: 1.2220, value_loss: 0.7872
2024-07-11 16:27:02,761 [INFO    ] __main__: train step 8055: loss: 1.0512, policy_loss: 1.2219, value_loss: 0.7872
2024-07-11 16:27:02,965 [INFO    ] __main__: train step 8056: loss: 1.0512, policy_loss: 1.2218, value_loss: 0.7871
2024-07-11 16:27:03,181 [INFO    ] __main__: train step 8057: loss: 1.0512, policy_loss: 1.2217, value_loss: 0.7871
2024-07-11 16:27:04,631 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:27:05,058 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:27:05,115 [INFO    ] __main__: train step 8058: loss: 1.0512, policy_loss: 1.2216, value_loss: 0.7871
2024-07-11 16:27:05,282 [INFO    ] __main__: train step 8059: loss: 1.0512, policy_loss: 1.2216, value_loss: 0.7871
2024-07-11 16:27:05,490 [INFO    ] __main__: train step 8060: loss: 1.0513, policy_loss: 1.2215, value_loss: 0.7870
2024-07-11 16:27:05,705 [INFO    ] __main__: train step 8061: loss: 1.0513, policy_loss: 1.2214, value_loss: 0.7870
2024-07-11 16:27:05,950 [INFO    ] __main__: train step 8062: loss: 1.0513, policy_loss: 1.2213, value_loss: 0.7870
2024-07-11 16:27:06,176 [INFO    ] __main__: train step 8063: loss: 1.0513, policy_loss: 1.2213, value_loss: 0.7870
2024-07-11 16:27:06,376 [INFO    ] __main__: train step 8064: loss: 1.0513, policy_loss: 1.2212, value_loss: 0.7869
2024-07-11 16:27:06,583 [INFO    ] __main__: train step 8065: loss: 1.0513, policy_loss: 1.2211, value_loss: 0.7869
2024-07-11 16:27:06,776 [INFO    ] __main__: train step 8066: loss: 1.0514, policy_loss: 1.2210, value_loss: 0.7869
2024-07-11 16:27:06,976 [INFO    ] __main__: train step 8067: loss: 1.0514, policy_loss: 1.2210, value_loss: 0.7869
2024-07-11 16:27:07,181 [INFO    ] __main__: train step 8068: loss: 1.0514, policy_loss: 1.2209, value_loss: 0.7868
2024-07-11 16:27:07,407 [INFO    ] __main__: train step 8069: loss: 1.0514, policy_loss: 1.2208, value_loss: 0.7868
2024-07-11 16:27:07,628 [INFO    ] __main__: train step 8070: loss: 1.0514, policy_loss: 1.2207, value_loss: 0.7868
2024-07-11 16:27:07,871 [INFO    ] __main__: train step 8071: loss: 1.0514, policy_loss: 1.2207, value_loss: 0.7868
2024-07-11 16:27:08,092 [INFO    ] __main__: train step 8072: loss: 1.0515, policy_loss: 1.2206, value_loss: 0.7867
2024-07-11 16:27:08,291 [INFO    ] __main__: train step 8073: loss: 1.0515, policy_loss: 1.2205, value_loss: 0.7867
2024-07-11 16:27:08,488 [INFO    ] __main__: train step 8074: loss: 1.0515, policy_loss: 1.2204, value_loss: 0.7867
2024-07-11 16:27:09,949 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:27:10,339 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:27:10,393 [INFO    ] __main__: train step 8075: loss: 1.0515, policy_loss: 1.2204, value_loss: 0.7867
2024-07-11 16:27:10,565 [INFO    ] __main__: train step 8076: loss: 1.0515, policy_loss: 1.2203, value_loss: 0.7866
2024-07-11 16:27:10,755 [INFO    ] __main__: train step 8077: loss: 1.0516, policy_loss: 1.2202, value_loss: 0.7866
2024-07-11 16:27:10,964 [INFO    ] __main__: train step 8078: loss: 1.0516, policy_loss: 1.2201, value_loss: 0.7866
2024-07-11 16:27:11,171 [INFO    ] __main__: train step 8079: loss: 1.0516, policy_loss: 1.2201, value_loss: 0.7866
2024-07-11 16:27:11,374 [INFO    ] __main__: train step 8080: loss: 1.0516, policy_loss: 1.2200, value_loss: 0.7865
2024-07-11 16:27:11,576 [INFO    ] __main__: train step 8081: loss: 1.0516, policy_loss: 1.2199, value_loss: 0.7865
2024-07-11 16:27:11,788 [INFO    ] __main__: train step 8082: loss: 1.0516, policy_loss: 1.2198, value_loss: 0.7865
2024-07-11 16:27:11,986 [INFO    ] __main__: train step 8083: loss: 1.0517, policy_loss: 1.2198, value_loss: 0.7865
2024-07-11 16:27:12,190 [INFO    ] __main__: train step 8084: loss: 1.0517, policy_loss: 1.2197, value_loss: 0.7864
2024-07-11 16:27:12,400 [INFO    ] __main__: train step 8085: loss: 1.0517, policy_loss: 1.2196, value_loss: 0.7864
2024-07-11 16:27:12,634 [INFO    ] __main__: train step 8086: loss: 1.0517, policy_loss: 1.2195, value_loss: 0.7864
2024-07-11 16:27:12,826 [INFO    ] __main__: train step 8087: loss: 1.0517, policy_loss: 1.2195, value_loss: 0.7864
2024-07-11 16:27:13,037 [INFO    ] __main__: train step 8088: loss: 1.0517, policy_loss: 1.2194, value_loss: 0.7863
2024-07-11 16:27:13,253 [INFO    ] __main__: train step 8089: loss: 1.0518, policy_loss: 1.2193, value_loss: 0.7863
2024-07-11 16:27:13,501 [INFO    ] __main__: train step 8090: loss: 1.0518, policy_loss: 1.2192, value_loss: 0.7863
2024-07-11 16:27:13,685 [INFO    ] __main__: train step 8091: loss: 1.0518, policy_loss: 1.2192, value_loss: 0.7863
2024-07-11 16:27:15,159 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:27:15,568 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:27:15,622 [INFO    ] __main__: train step 8092: loss: 1.0518, policy_loss: 1.2191, value_loss: 0.7862
2024-07-11 16:27:15,797 [INFO    ] __main__: train step 8093: loss: 1.0518, policy_loss: 1.2190, value_loss: 0.7862
2024-07-11 16:27:16,000 [INFO    ] __main__: train step 8094: loss: 1.0518, policy_loss: 1.2189, value_loss: 0.7862
2024-07-11 16:27:16,210 [INFO    ] __main__: train step 8095: loss: 1.0519, policy_loss: 1.2188, value_loss: 0.7862
2024-07-11 16:27:16,424 [INFO    ] __main__: train step 8096: loss: 1.0519, policy_loss: 1.2188, value_loss: 0.7861
2024-07-11 16:27:16,619 [INFO    ] __main__: train step 8097: loss: 1.0519, policy_loss: 1.2187, value_loss: 0.7861
2024-07-11 16:27:16,837 [INFO    ] __main__: train step 8098: loss: 1.0519, policy_loss: 1.2186, value_loss: 0.7861
2024-07-11 16:27:17,051 [INFO    ] __main__: train step 8099: loss: 1.0519, policy_loss: 1.2185, value_loss: 0.7861
2024-07-11 16:27:17,254 [INFO    ] __main__: train step 8100: loss: 1.0519, policy_loss: 1.2185, value_loss: 0.7860
2024-07-11 16:27:17,458 [INFO    ] __main__: train step 8101: loss: 1.0520, policy_loss: 1.2184, value_loss: 0.7860
2024-07-11 16:27:17,660 [INFO    ] __main__: train step 8102: loss: 1.0520, policy_loss: 1.2183, value_loss: 0.7860
2024-07-11 16:27:17,891 [INFO    ] __main__: train step 8103: loss: 1.0520, policy_loss: 1.2182, value_loss: 0.7859
2024-07-11 16:27:18,924 [INFO    ] __main__: train step 8104: loss: 1.0520, policy_loss: 1.2182, value_loss: 0.7859
2024-07-11 16:27:19,128 [INFO    ] __main__: train step 8105: loss: 1.0520, policy_loss: 1.2181, value_loss: 0.7859
2024-07-11 16:27:19,335 [INFO    ] __main__: train step 8106: loss: 1.0520, policy_loss: 1.2180, value_loss: 0.7859
2024-07-11 16:27:19,538 [INFO    ] __main__: train step 8107: loss: 1.0521, policy_loss: 1.2179, value_loss: 0.7858
2024-07-11 16:27:19,739 [INFO    ] __main__: train step 8108: loss: 1.0521, policy_loss: 1.2179, value_loss: 0.7858
2024-07-11 16:27:21,187 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:27:21,613 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:27:21,675 [INFO    ] __main__: train step 8109: loss: 1.0521, policy_loss: 1.2178, value_loss: 0.7858
2024-07-11 16:27:21,844 [INFO    ] __main__: train step 8110: loss: 1.0521, policy_loss: 1.2177, value_loss: 0.7858
2024-07-11 16:27:22,065 [INFO    ] __main__: train step 8111: loss: 1.0521, policy_loss: 1.2176, value_loss: 0.7857
2024-07-11 16:27:22,264 [INFO    ] __main__: train step 8112: loss: 1.0521, policy_loss: 1.2176, value_loss: 0.7857
2024-07-11 16:27:22,468 [INFO    ] __main__: train step 8113: loss: 1.0521, policy_loss: 1.2175, value_loss: 0.7857
2024-07-11 16:27:22,676 [INFO    ] __main__: train step 8114: loss: 1.0522, policy_loss: 1.2174, value_loss: 0.7857
2024-07-11 16:27:22,901 [INFO    ] __main__: train step 8115: loss: 1.0522, policy_loss: 1.2173, value_loss: 0.7856
2024-07-11 16:27:23,146 [INFO    ] __main__: train step 8116: loss: 1.0522, policy_loss: 1.2173, value_loss: 0.7856
2024-07-11 16:27:23,360 [INFO    ] __main__: train step 8117: loss: 1.0522, policy_loss: 1.2172, value_loss: 0.7856
2024-07-11 16:27:23,563 [INFO    ] __main__: train step 8118: loss: 1.0522, policy_loss: 1.2171, value_loss: 0.7856
2024-07-11 16:27:23,767 [INFO    ] __main__: train step 8119: loss: 1.0522, policy_loss: 1.2170, value_loss: 0.7855
2024-07-11 16:27:23,976 [INFO    ] __main__: train step 8120: loss: 1.0523, policy_loss: 1.2170, value_loss: 0.7855
2024-07-11 16:27:24,179 [INFO    ] __main__: train step 8121: loss: 1.0523, policy_loss: 1.2169, value_loss: 0.7855
2024-07-11 16:27:24,391 [INFO    ] __main__: train step 8122: loss: 1.0523, policy_loss: 1.2168, value_loss: 0.7855
2024-07-11 16:27:24,596 [INFO    ] __main__: train step 8123: loss: 1.0523, policy_loss: 1.2167, value_loss: 0.7854
2024-07-11 16:27:24,806 [INFO    ] __main__: train step 8124: loss: 1.0523, policy_loss: 1.2167, value_loss: 0.7854
2024-07-11 16:27:25,013 [INFO    ] __main__: train step 8125: loss: 1.0523, policy_loss: 1.2166, value_loss: 0.7854
2024-07-11 16:27:26,460 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:27:26,845 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:27:26,898 [INFO    ] __main__: train step 8126: loss: 1.0523, policy_loss: 1.2165, value_loss: 0.7854
2024-07-11 16:27:27,079 [INFO    ] __main__: train step 8127: loss: 1.0524, policy_loss: 1.2164, value_loss: 0.7853
2024-07-11 16:27:27,302 [INFO    ] __main__: train step 8128: loss: 1.0524, policy_loss: 1.2164, value_loss: 0.7853
2024-07-11 16:27:27,509 [INFO    ] __main__: train step 8129: loss: 1.0524, policy_loss: 1.2163, value_loss: 0.7853
2024-07-11 16:27:27,705 [INFO    ] __main__: train step 8130: loss: 1.0524, policy_loss: 1.2162, value_loss: 0.7852
2024-07-11 16:27:27,904 [INFO    ] __main__: train step 8131: loss: 1.0524, policy_loss: 1.2161, value_loss: 0.7852
2024-07-11 16:27:28,100 [INFO    ] __main__: train step 8132: loss: 1.0524, policy_loss: 1.2161, value_loss: 0.7852
2024-07-11 16:27:28,306 [INFO    ] __main__: train step 8133: loss: 1.0525, policy_loss: 1.2160, value_loss: 0.7852
2024-07-11 16:27:28,507 [INFO    ] __main__: train step 8134: loss: 1.0525, policy_loss: 1.2159, value_loss: 0.7851
2024-07-11 16:27:28,709 [INFO    ] __main__: train step 8135: loss: 1.0525, policy_loss: 1.2158, value_loss: 0.7851
2024-07-11 16:27:28,923 [INFO    ] __main__: train step 8136: loss: 1.0525, policy_loss: 1.2158, value_loss: 0.7851
2024-07-11 16:27:29,121 [INFO    ] __main__: train step 8137: loss: 1.0525, policy_loss: 1.2157, value_loss: 0.7851
2024-07-11 16:27:29,313 [INFO    ] __main__: train step 8138: loss: 1.0525, policy_loss: 1.2156, value_loss: 0.7850
2024-07-11 16:27:29,503 [INFO    ] __main__: train step 8139: loss: 1.0525, policy_loss: 1.2155, value_loss: 0.7850
2024-07-11 16:27:29,726 [INFO    ] __main__: train step 8140: loss: 1.0526, policy_loss: 1.2155, value_loss: 0.7850
2024-07-11 16:27:29,914 [INFO    ] __main__: train step 8141: loss: 1.0526, policy_loss: 1.2154, value_loss: 0.7850
2024-07-11 16:27:30,113 [INFO    ] __main__: train step 8142: loss: 1.0526, policy_loss: 1.2153, value_loss: 0.7849
2024-07-11 16:27:31,553 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:27:31,936 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:27:31,995 [INFO    ] __main__: train step 8143: loss: 1.0526, policy_loss: 1.2152, value_loss: 0.7849
2024-07-11 16:27:32,176 [INFO    ] __main__: train step 8144: loss: 1.0526, policy_loss: 1.2152, value_loss: 0.7849
2024-07-11 16:27:32,380 [INFO    ] __main__: train step 8145: loss: 1.0526, policy_loss: 1.2151, value_loss: 0.7849
2024-07-11 16:27:32,598 [INFO    ] __main__: train step 8146: loss: 1.0526, policy_loss: 1.2150, value_loss: 0.7848
2024-07-11 16:27:32,798 [INFO    ] __main__: train step 8147: loss: 1.0527, policy_loss: 1.2149, value_loss: 0.7848
2024-07-11 16:27:32,999 [INFO    ] __main__: train step 8148: loss: 1.0527, policy_loss: 1.2149, value_loss: 0.7848
2024-07-11 16:27:33,206 [INFO    ] __main__: train step 8149: loss: 1.0527, policy_loss: 1.2148, value_loss: 0.7847
2024-07-11 16:27:33,413 [INFO    ] __main__: train step 8150: loss: 1.0527, policy_loss: 1.2147, value_loss: 0.7847
2024-07-11 16:27:33,616 [INFO    ] __main__: train step 8151: loss: 1.0527, policy_loss: 1.2146, value_loss: 0.7847
2024-07-11 16:27:33,824 [INFO    ] __main__: train step 8152: loss: 1.0527, policy_loss: 1.2146, value_loss: 0.7847
2024-07-11 16:27:34,034 [INFO    ] __main__: train step 8153: loss: 1.0527, policy_loss: 1.2145, value_loss: 0.7846
2024-07-11 16:27:34,232 [INFO    ] __main__: train step 8154: loss: 1.0528, policy_loss: 1.2144, value_loss: 0.7846
2024-07-11 16:27:34,434 [INFO    ] __main__: train step 8155: loss: 1.0528, policy_loss: 1.2143, value_loss: 0.7846
2024-07-11 16:27:34,638 [INFO    ] __main__: train step 8156: loss: 1.0528, policy_loss: 1.2143, value_loss: 0.7846
2024-07-11 16:27:34,863 [INFO    ] __main__: train step 8157: loss: 1.0528, policy_loss: 1.2142, value_loss: 0.7845
2024-07-11 16:27:35,058 [INFO    ] __main__: train step 8158: loss: 1.0528, policy_loss: 1.2141, value_loss: 0.7845
2024-07-11 16:27:35,274 [INFO    ] __main__: train step 8159: loss: 1.0528, policy_loss: 1.2140, value_loss: 0.7845
2024-07-11 16:27:36,718 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:27:36,971 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:27:37,025 [INFO    ] __main__: train step 8160: loss: 1.0528, policy_loss: 1.2140, value_loss: 0.7844
2024-07-11 16:27:37,193 [INFO    ] __main__: train step 8161: loss: 1.0529, policy_loss: 1.2139, value_loss: 0.7844
2024-07-11 16:27:37,401 [INFO    ] __main__: train step 8162: loss: 1.0529, policy_loss: 1.2138, value_loss: 0.7844
2024-07-11 16:27:37,647 [INFO    ] __main__: train step 8163: loss: 1.0529, policy_loss: 1.2137, value_loss: 0.7844
2024-07-11 16:27:37,849 [INFO    ] __main__: train step 8164: loss: 1.0529, policy_loss: 1.2137, value_loss: 0.7843
2024-07-11 16:27:38,043 [INFO    ] __main__: train step 8165: loss: 1.0529, policy_loss: 1.2136, value_loss: 0.7843
2024-07-11 16:27:38,256 [INFO    ] __main__: train step 8166: loss: 1.0529, policy_loss: 1.2135, value_loss: 0.7843
2024-07-11 16:27:38,454 [INFO    ] __main__: train step 8167: loss: 1.0529, policy_loss: 1.2134, value_loss: 0.7843
2024-07-11 16:27:38,667 [INFO    ] __main__: train step 8168: loss: 1.0529, policy_loss: 1.2134, value_loss: 0.7842
2024-07-11 16:27:38,866 [INFO    ] __main__: train step 8169: loss: 1.0530, policy_loss: 1.2133, value_loss: 0.7842
2024-07-11 16:27:39,071 [INFO    ] __main__: train step 8170: loss: 1.0530, policy_loss: 1.2132, value_loss: 0.7842
2024-07-11 16:27:39,263 [INFO    ] __main__: train step 8171: loss: 1.0530, policy_loss: 1.2131, value_loss: 0.7842
2024-07-11 16:27:39,481 [INFO    ] __main__: train step 8172: loss: 1.0530, policy_loss: 1.2130, value_loss: 0.7841
2024-07-11 16:27:39,732 [INFO    ] __main__: train step 8173: loss: 1.0530, policy_loss: 1.2130, value_loss: 0.7841
2024-07-11 16:27:39,923 [INFO    ] __main__: train step 8174: loss: 1.0530, policy_loss: 1.2129, value_loss: 0.7841
2024-07-11 16:27:40,126 [INFO    ] __main__: train step 8175: loss: 1.0530, policy_loss: 1.2128, value_loss: 0.7840
2024-07-11 16:27:40,332 [INFO    ] __main__: train step 8176: loss: 1.0531, policy_loss: 1.2128, value_loss: 0.7840
2024-07-11 16:27:41,818 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:27:42,166 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:27:42,222 [INFO    ] __main__: train step 8177: loss: 1.0531, policy_loss: 1.2127, value_loss: 0.7840
2024-07-11 16:27:43,243 [INFO    ] __main__: train step 8178: loss: 1.0531, policy_loss: 1.2126, value_loss: 0.7840
2024-07-11 16:27:43,450 [INFO    ] __main__: train step 8179: loss: 1.0531, policy_loss: 1.2125, value_loss: 0.7839
2024-07-11 16:27:43,643 [INFO    ] __main__: train step 8180: loss: 1.0531, policy_loss: 1.2125, value_loss: 0.7839
2024-07-11 16:27:43,865 [INFO    ] __main__: train step 8181: loss: 1.0531, policy_loss: 1.2124, value_loss: 0.7839
2024-07-11 16:27:44,114 [INFO    ] __main__: train step 8182: loss: 1.0531, policy_loss: 1.2123, value_loss: 0.7839
2024-07-11 16:27:44,351 [INFO    ] __main__: train step 8183: loss: 1.0532, policy_loss: 1.2122, value_loss: 0.7838
2024-07-11 16:27:44,551 [INFO    ] __main__: train step 8184: loss: 1.0532, policy_loss: 1.2122, value_loss: 0.7838
2024-07-11 16:27:44,752 [INFO    ] __main__: train step 8185: loss: 1.0532, policy_loss: 1.2121, value_loss: 0.7838
2024-07-11 16:27:44,944 [INFO    ] __main__: train step 8186: loss: 1.0532, policy_loss: 1.2120, value_loss: 0.7838
2024-07-11 16:27:45,141 [INFO    ] __main__: train step 8187: loss: 1.0532, policy_loss: 1.2119, value_loss: 0.7837
2024-07-11 16:27:45,348 [INFO    ] __main__: train step 8188: loss: 1.0532, policy_loss: 1.2118, value_loss: 0.7837
2024-07-11 16:27:45,553 [INFO    ] __main__: train step 8189: loss: 1.0532, policy_loss: 1.2118, value_loss: 0.7837
2024-07-11 16:27:45,755 [INFO    ] __main__: train step 8190: loss: 1.0532, policy_loss: 1.2117, value_loss: 0.7836
2024-07-11 16:27:45,958 [INFO    ] __main__: train step 8191: loss: 1.0533, policy_loss: 1.2116, value_loss: 0.7836
2024-07-11 16:27:46,154 [INFO    ] __main__: train step 8192: loss: 1.0533, policy_loss: 1.2115, value_loss: 0.7836
2024-07-11 16:27:46,364 [INFO    ] __main__: train step 8193: loss: 1.0533, policy_loss: 1.2115, value_loss: 0.7836
2024-07-11 16:27:47,805 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:27:48,188 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:27:48,242 [INFO    ] __main__: train step 8194: loss: 1.0533, policy_loss: 1.2114, value_loss: 0.7835
2024-07-11 16:27:48,419 [INFO    ] __main__: train step 8195: loss: 1.0533, policy_loss: 1.2113, value_loss: 0.7835
2024-07-11 16:27:48,631 [INFO    ] __main__: train step 8196: loss: 1.0533, policy_loss: 1.2112, value_loss: 0.7835
2024-07-11 16:27:48,839 [INFO    ] __main__: train step 8197: loss: 1.0533, policy_loss: 1.2112, value_loss: 0.7835
2024-07-11 16:27:49,051 [INFO    ] __main__: train step 8198: loss: 1.0533, policy_loss: 1.2111, value_loss: 0.7834
2024-07-11 16:27:49,248 [INFO    ] __main__: train step 8199: loss: 1.0533, policy_loss: 1.2110, value_loss: 0.7834
2024-07-11 16:27:49,458 [INFO    ] __main__: train step 8200: loss: 1.0534, policy_loss: 1.2109, value_loss: 0.7834
2024-07-11 16:27:49,653 [INFO    ] __main__: train step 8201: loss: 1.0534, policy_loss: 1.2109, value_loss: 0.7833
2024-07-11 16:27:49,867 [INFO    ] __main__: train step 8202: loss: 1.0534, policy_loss: 1.2108, value_loss: 0.7833
2024-07-11 16:27:50,090 [INFO    ] __main__: train step 8203: loss: 1.0534, policy_loss: 1.2107, value_loss: 0.7833
2024-07-11 16:27:50,327 [INFO    ] __main__: train step 8204: loss: 1.0534, policy_loss: 1.2106, value_loss: 0.7833
2024-07-11 16:27:50,530 [INFO    ] __main__: train step 8205: loss: 1.0534, policy_loss: 1.2106, value_loss: 0.7832
2024-07-11 16:27:50,730 [INFO    ] __main__: train step 8206: loss: 1.0534, policy_loss: 1.2105, value_loss: 0.7832
2024-07-11 16:27:50,936 [INFO    ] __main__: train step 8207: loss: 1.0534, policy_loss: 1.2104, value_loss: 0.7832
2024-07-11 16:27:51,145 [INFO    ] __main__: train step 8208: loss: 1.0535, policy_loss: 1.2103, value_loss: 0.7832
2024-07-11 16:27:51,344 [INFO    ] __main__: train step 8209: loss: 1.0535, policy_loss: 1.2103, value_loss: 0.7831
2024-07-11 16:27:51,549 [INFO    ] __main__: train step 8210: loss: 1.0535, policy_loss: 1.2102, value_loss: 0.7831
2024-07-11 16:27:52,991 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:27:53,405 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:27:53,461 [INFO    ] __main__: train step 8211: loss: 1.0535, policy_loss: 1.2101, value_loss: 0.7831
2024-07-11 16:27:53,655 [INFO    ] __main__: train step 8212: loss: 1.0535, policy_loss: 1.2100, value_loss: 0.7830
2024-07-11 16:27:53,870 [INFO    ] __main__: train step 8213: loss: 1.0535, policy_loss: 1.2100, value_loss: 0.7830
2024-07-11 16:27:54,118 [INFO    ] __main__: train step 8214: loss: 1.0535, policy_loss: 1.2099, value_loss: 0.7830
2024-07-11 16:27:54,314 [INFO    ] __main__: train step 8215: loss: 1.0535, policy_loss: 1.2098, value_loss: 0.7830
2024-07-11 16:27:54,525 [INFO    ] __main__: train step 8216: loss: 1.0535, policy_loss: 1.2097, value_loss: 0.7829
2024-07-11 16:27:54,717 [INFO    ] __main__: train step 8217: loss: 1.0536, policy_loss: 1.2097, value_loss: 0.7829
2024-07-11 16:27:54,920 [INFO    ] __main__: train step 8218: loss: 1.0536, policy_loss: 1.2096, value_loss: 0.7829
2024-07-11 16:27:55,130 [INFO    ] __main__: train step 8219: loss: 1.0536, policy_loss: 1.2095, value_loss: 0.7829
2024-07-11 16:27:55,336 [INFO    ] __main__: train step 8220: loss: 1.0536, policy_loss: 1.2094, value_loss: 0.7828
2024-07-11 16:27:55,572 [INFO    ] __main__: train step 8221: loss: 1.0536, policy_loss: 1.2094, value_loss: 0.7828
2024-07-11 16:27:55,771 [INFO    ] __main__: train step 8222: loss: 1.0536, policy_loss: 1.2093, value_loss: 0.7828
2024-07-11 16:27:55,978 [INFO    ] __main__: train step 8223: loss: 1.0536, policy_loss: 1.2092, value_loss: 0.7827
2024-07-11 16:27:56,176 [INFO    ] __main__: train step 8224: loss: 1.0536, policy_loss: 1.2091, value_loss: 0.7827
2024-07-11 16:27:56,393 [INFO    ] __main__: train step 8225: loss: 1.0536, policy_loss: 1.2091, value_loss: 0.7827
2024-07-11 16:27:56,632 [INFO    ] __main__: train step 8226: loss: 1.0537, policy_loss: 1.2090, value_loss: 0.7827
2024-07-11 16:27:56,831 [INFO    ] __main__: train step 8227: loss: 1.0537, policy_loss: 1.2089, value_loss: 0.7826
2024-07-11 16:27:58,289 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:27:58,649 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:27:58,711 [INFO    ] __main__: train step 8228: loss: 1.0537, policy_loss: 1.2088, value_loss: 0.7826
2024-07-11 16:27:58,888 [INFO    ] __main__: train step 8229: loss: 1.0537, policy_loss: 1.2088, value_loss: 0.7826
2024-07-11 16:27:59,092 [INFO    ] __main__: train step 8230: loss: 1.0537, policy_loss: 1.2087, value_loss: 0.7825
2024-07-11 16:27:59,304 [INFO    ] __main__: train step 8231: loss: 1.0537, policy_loss: 1.2086, value_loss: 0.7825
2024-07-11 16:27:59,499 [INFO    ] __main__: train step 8232: loss: 1.0537, policy_loss: 1.2085, value_loss: 0.7825
2024-07-11 16:27:59,709 [INFO    ] __main__: train step 8233: loss: 1.0537, policy_loss: 1.2085, value_loss: 0.7825
2024-07-11 16:27:59,924 [INFO    ] __main__: train step 8234: loss: 1.0537, policy_loss: 1.2084, value_loss: 0.7824
2024-07-11 16:28:00,162 [INFO    ] __main__: train step 8235: loss: 1.0538, policy_loss: 1.2083, value_loss: 0.7824
2024-07-11 16:28:00,368 [INFO    ] __main__: train step 8236: loss: 1.0538, policy_loss: 1.2082, value_loss: 0.7824
2024-07-11 16:28:00,581 [INFO    ] __main__: train step 8237: loss: 1.0538, policy_loss: 1.2082, value_loss: 0.7823
2024-07-11 16:28:00,817 [INFO    ] __main__: train step 8238: loss: 1.0538, policy_loss: 1.2081, value_loss: 0.7823
2024-07-11 16:28:01,021 [INFO    ] __main__: train step 8239: loss: 1.0538, policy_loss: 1.2080, value_loss: 0.7823
2024-07-11 16:28:01,212 [INFO    ] __main__: train step 8240: loss: 1.0538, policy_loss: 1.2079, value_loss: 0.7823
2024-07-11 16:28:01,419 [INFO    ] __main__: train step 8241: loss: 1.0538, policy_loss: 1.2079, value_loss: 0.7822
2024-07-11 16:28:01,610 [INFO    ] __main__: train step 8242: loss: 1.0538, policy_loss: 1.2078, value_loss: 0.7822
2024-07-11 16:28:01,808 [INFO    ] __main__: train step 8243: loss: 1.0538, policy_loss: 1.2077, value_loss: 0.7822
2024-07-11 16:28:02,023 [INFO    ] __main__: train step 8244: loss: 1.0539, policy_loss: 1.2076, value_loss: 0.7821
2024-07-11 16:28:03,511 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:28:03,861 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:28:03,916 [INFO    ] __main__: train step 8245: loss: 1.0539, policy_loss: 1.2076, value_loss: 0.7821
2024-07-11 16:28:04,098 [INFO    ] __main__: train step 8246: loss: 1.0539, policy_loss: 1.2075, value_loss: 0.7821
2024-07-11 16:28:04,304 [INFO    ] __main__: train step 8247: loss: 1.0539, policy_loss: 1.2074, value_loss: 0.7821
2024-07-11 16:28:04,505 [INFO    ] __main__: train step 8248: loss: 1.0539, policy_loss: 1.2073, value_loss: 0.7820
2024-07-11 16:28:04,713 [INFO    ] __main__: train step 8249: loss: 1.0539, policy_loss: 1.2073, value_loss: 0.7820
2024-07-11 16:28:04,936 [INFO    ] __main__: train step 8250: loss: 1.0539, policy_loss: 1.2072, value_loss: 0.7820
2024-07-11 16:28:05,184 [INFO    ] __main__: train step 8251: loss: 1.0539, policy_loss: 1.2071, value_loss: 0.7820
2024-07-11 16:28:06,247 [INFO    ] __main__: train step 8252: loss: 1.0539, policy_loss: 1.2070, value_loss: 0.7819
2024-07-11 16:28:06,474 [INFO    ] __main__: train step 8253: loss: 1.0539, policy_loss: 1.2070, value_loss: 0.7819
2024-07-11 16:28:06,681 [INFO    ] __main__: train step 8254: loss: 1.0540, policy_loss: 1.2069, value_loss: 0.7819
2024-07-11 16:28:06,919 [INFO    ] __main__: train step 8255: loss: 1.0540, policy_loss: 1.2068, value_loss: 0.7819
2024-07-11 16:28:07,117 [INFO    ] __main__: train step 8256: loss: 1.0540, policy_loss: 1.2067, value_loss: 0.7818
2024-07-11 16:28:07,322 [INFO    ] __main__: train step 8257: loss: 1.0540, policy_loss: 1.2067, value_loss: 0.7818
2024-07-11 16:28:07,541 [INFO    ] __main__: train step 8258: loss: 1.0540, policy_loss: 1.2066, value_loss: 0.7818
2024-07-11 16:28:07,748 [INFO    ] __main__: train step 8259: loss: 1.0540, policy_loss: 1.2065, value_loss: 0.7817
2024-07-11 16:28:07,972 [INFO    ] __main__: train step 8260: loss: 1.0540, policy_loss: 1.2064, value_loss: 0.7817
2024-07-11 16:28:08,168 [INFO    ] __main__: train step 8261: loss: 1.0540, policy_loss: 1.2064, value_loss: 0.7817
2024-07-11 16:28:09,621 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:28:09,983 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:28:10,039 [INFO    ] __main__: train step 8262: loss: 1.0540, policy_loss: 1.2063, value_loss: 0.7817
2024-07-11 16:28:10,215 [INFO    ] __main__: train step 8263: loss: 1.0541, policy_loss: 1.2062, value_loss: 0.7816
2024-07-11 16:28:10,408 [INFO    ] __main__: train step 8264: loss: 1.0541, policy_loss: 1.2061, value_loss: 0.7816
2024-07-11 16:28:10,613 [INFO    ] __main__: train step 8265: loss: 1.0541, policy_loss: 1.2061, value_loss: 0.7816
2024-07-11 16:28:10,821 [INFO    ] __main__: train step 8266: loss: 1.0541, policy_loss: 1.2060, value_loss: 0.7815
2024-07-11 16:28:11,022 [INFO    ] __main__: train step 8267: loss: 1.0541, policy_loss: 1.2059, value_loss: 0.7815
2024-07-11 16:28:11,269 [INFO    ] __main__: train step 8268: loss: 1.0541, policy_loss: 1.2058, value_loss: 0.7815
2024-07-11 16:28:11,497 [INFO    ] __main__: train step 8269: loss: 1.0541, policy_loss: 1.2058, value_loss: 0.7815
2024-07-11 16:28:11,697 [INFO    ] __main__: train step 8270: loss: 1.0541, policy_loss: 1.2057, value_loss: 0.7814
2024-07-11 16:28:11,894 [INFO    ] __main__: train step 8271: loss: 1.0541, policy_loss: 1.2056, value_loss: 0.7814
2024-07-11 16:28:12,103 [INFO    ] __main__: train step 8272: loss: 1.0541, policy_loss: 1.2055, value_loss: 0.7814
2024-07-11 16:28:12,309 [INFO    ] __main__: train step 8273: loss: 1.0541, policy_loss: 1.2055, value_loss: 0.7813
2024-07-11 16:28:12,504 [INFO    ] __main__: train step 8274: loss: 1.0542, policy_loss: 1.2054, value_loss: 0.7813
2024-07-11 16:28:12,699 [INFO    ] __main__: train step 8275: loss: 1.0542, policy_loss: 1.2053, value_loss: 0.7813
2024-07-11 16:28:12,896 [INFO    ] __main__: train step 8276: loss: 1.0542, policy_loss: 1.2052, value_loss: 0.7813
2024-07-11 16:28:13,092 [INFO    ] __main__: train step 8277: loss: 1.0542, policy_loss: 1.2052, value_loss: 0.7812
2024-07-11 16:28:13,298 [INFO    ] __main__: train step 8278: loss: 1.0542, policy_loss: 1.2051, value_loss: 0.7812
2024-07-11 16:28:14,738 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:28:15,089 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:28:15,144 [INFO    ] __main__: train step 8279: loss: 1.0542, policy_loss: 1.2050, value_loss: 0.7812
2024-07-11 16:28:15,329 [INFO    ] __main__: train step 8280: loss: 1.0542, policy_loss: 1.2049, value_loss: 0.7811
2024-07-11 16:28:15,539 [INFO    ] __main__: train step 8281: loss: 1.0542, policy_loss: 1.2049, value_loss: 0.7811
2024-07-11 16:28:15,754 [INFO    ] __main__: train step 8282: loss: 1.0542, policy_loss: 1.2048, value_loss: 0.7811
2024-07-11 16:28:15,960 [INFO    ] __main__: train step 8283: loss: 1.0542, policy_loss: 1.2047, value_loss: 0.7811
2024-07-11 16:28:16,162 [INFO    ] __main__: train step 8284: loss: 1.0542, policy_loss: 1.2046, value_loss: 0.7810
2024-07-11 16:28:16,360 [INFO    ] __main__: train step 8285: loss: 1.0543, policy_loss: 1.2046, value_loss: 0.7810
2024-07-11 16:28:16,555 [INFO    ] __main__: train step 8286: loss: 1.0543, policy_loss: 1.2045, value_loss: 0.7810
2024-07-11 16:28:16,756 [INFO    ] __main__: train step 8287: loss: 1.0543, policy_loss: 1.2044, value_loss: 0.7810
2024-07-11 16:28:16,960 [INFO    ] __main__: train step 8288: loss: 1.0543, policy_loss: 1.2043, value_loss: 0.7809
2024-07-11 16:28:17,180 [INFO    ] __main__: train step 8289: loss: 1.0543, policy_loss: 1.2042, value_loss: 0.7809
2024-07-11 16:28:17,384 [INFO    ] __main__: train step 8290: loss: 1.0543, policy_loss: 1.2042, value_loss: 0.7809
2024-07-11 16:28:17,580 [INFO    ] __main__: train step 8291: loss: 1.0543, policy_loss: 1.2041, value_loss: 0.7808
2024-07-11 16:28:17,772 [INFO    ] __main__: train step 8292: loss: 1.0543, policy_loss: 1.2040, value_loss: 0.7808
2024-07-11 16:28:17,967 [INFO    ] __main__: train step 8293: loss: 1.0543, policy_loss: 1.2039, value_loss: 0.7808
2024-07-11 16:28:18,171 [INFO    ] __main__: train step 8294: loss: 1.0543, policy_loss: 1.2039, value_loss: 0.7808
2024-07-11 16:28:18,380 [INFO    ] __main__: train step 8295: loss: 1.0543, policy_loss: 1.2038, value_loss: 0.7807
2024-07-11 16:28:19,823 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:28:20,195 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:28:20,250 [INFO    ] __main__: train step 8296: loss: 1.0543, policy_loss: 1.2037, value_loss: 0.7807
2024-07-11 16:28:20,433 [INFO    ] __main__: train step 8297: loss: 1.0544, policy_loss: 1.2036, value_loss: 0.7807
2024-07-11 16:28:20,628 [INFO    ] __main__: train step 8298: loss: 1.0544, policy_loss: 1.2036, value_loss: 0.7807
2024-07-11 16:28:20,832 [INFO    ] __main__: train step 8299: loss: 1.0544, policy_loss: 1.2035, value_loss: 0.7806
2024-07-11 16:28:21,028 [INFO    ] __main__: train step 8300: loss: 1.0544, policy_loss: 1.2034, value_loss: 0.7806
2024-07-11 16:28:21,229 [INFO    ] __main__: train step 8301: loss: 1.0544, policy_loss: 1.2033, value_loss: 0.7806
2024-07-11 16:28:21,435 [INFO    ] __main__: train step 8302: loss: 1.0544, policy_loss: 1.2033, value_loss: 0.7805
2024-07-11 16:28:21,665 [INFO    ] __main__: train step 8303: loss: 1.0544, policy_loss: 1.2032, value_loss: 0.7805
2024-07-11 16:28:21,877 [INFO    ] __main__: train step 8304: loss: 1.0544, policy_loss: 1.2031, value_loss: 0.7805
2024-07-11 16:28:22,080 [INFO    ] __main__: train step 8305: loss: 1.0544, policy_loss: 1.2030, value_loss: 0.7805
2024-07-11 16:28:22,281 [INFO    ] __main__: train step 8306: loss: 1.0544, policy_loss: 1.2030, value_loss: 0.7804
2024-07-11 16:28:22,485 [INFO    ] __main__: train step 8307: loss: 1.0544, policy_loss: 1.2029, value_loss: 0.7804
2024-07-11 16:28:22,689 [INFO    ] __main__: train step 8308: loss: 1.0544, policy_loss: 1.2028, value_loss: 0.7804
2024-07-11 16:28:22,903 [INFO    ] __main__: train step 8309: loss: 1.0545, policy_loss: 1.2027, value_loss: 0.7803
2024-07-11 16:28:23,097 [INFO    ] __main__: train step 8310: loss: 1.0545, policy_loss: 1.2027, value_loss: 0.7803
2024-07-11 16:28:23,325 [INFO    ] __main__: train step 8311: loss: 1.0545, policy_loss: 1.2026, value_loss: 0.7803
2024-07-11 16:28:23,551 [INFO    ] __main__: train step 8312: loss: 1.0545, policy_loss: 1.2025, value_loss: 0.7803
2024-07-11 16:28:24,998 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:28:25,399 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:28:25,461 [INFO    ] __main__: train step 8313: loss: 1.0545, policy_loss: 1.2024, value_loss: 0.7802
2024-07-11 16:28:25,637 [INFO    ] __main__: train step 8314: loss: 1.0545, policy_loss: 1.2024, value_loss: 0.7802
2024-07-11 16:28:25,859 [INFO    ] __main__: train step 8315: loss: 1.0545, policy_loss: 1.2023, value_loss: 0.7802
2024-07-11 16:28:26,059 [INFO    ] __main__: train step 8316: loss: 1.0545, policy_loss: 1.2022, value_loss: 0.7801
2024-07-11 16:28:26,268 [INFO    ] __main__: train step 8317: loss: 1.0545, policy_loss: 1.2021, value_loss: 0.7801
2024-07-11 16:28:26,462 [INFO    ] __main__: train step 8318: loss: 1.0545, policy_loss: 1.2021, value_loss: 0.7801
2024-07-11 16:28:26,667 [INFO    ] __main__: train step 8319: loss: 1.0545, policy_loss: 1.2020, value_loss: 0.7801
2024-07-11 16:28:26,874 [INFO    ] __main__: train step 8320: loss: 1.0545, policy_loss: 1.2019, value_loss: 0.7800
2024-07-11 16:28:27,073 [INFO    ] __main__: train step 8321: loss: 1.0546, policy_loss: 1.2018, value_loss: 0.7800
2024-07-11 16:28:27,270 [INFO    ] __main__: train step 8322: loss: 1.0546, policy_loss: 1.2018, value_loss: 0.7800
2024-07-11 16:28:27,480 [INFO    ] __main__: train step 8323: loss: 1.0546, policy_loss: 1.2017, value_loss: 0.7799
2024-07-11 16:28:27,674 [INFO    ] __main__: train step 8324: loss: 1.0546, policy_loss: 1.2016, value_loss: 0.7799
2024-07-11 16:28:28,681 [INFO    ] __main__: train step 8325: loss: 1.0546, policy_loss: 1.2015, value_loss: 0.7799
2024-07-11 16:28:29,006 [INFO    ] __main__: train step 8326: loss: 1.0546, policy_loss: 1.2015, value_loss: 0.7799
2024-07-11 16:28:29,257 [INFO    ] __main__: train step 8327: loss: 1.0546, policy_loss: 1.2014, value_loss: 0.7798
2024-07-11 16:28:29,475 [INFO    ] __main__: train step 8328: loss: 1.0546, policy_loss: 1.2013, value_loss: 0.7798
2024-07-11 16:28:29,720 [INFO    ] __main__: train step 8329: loss: 1.0546, policy_loss: 1.2012, value_loss: 0.7798
2024-07-11 16:28:31,196 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:28:31,555 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:28:31,610 [INFO    ] __main__: train step 8330: loss: 1.0546, policy_loss: 1.2012, value_loss: 0.7797
2024-07-11 16:28:31,787 [INFO    ] __main__: train step 8331: loss: 1.0546, policy_loss: 1.2011, value_loss: 0.7797
2024-07-11 16:28:32,000 [INFO    ] __main__: train step 8332: loss: 1.0546, policy_loss: 1.2010, value_loss: 0.7797
2024-07-11 16:28:32,206 [INFO    ] __main__: train step 8333: loss: 1.0546, policy_loss: 1.2009, value_loss: 0.7796
2024-07-11 16:28:32,438 [INFO    ] __main__: train step 8334: loss: 1.0546, policy_loss: 1.2009, value_loss: 0.7796
2024-07-11 16:28:32,694 [INFO    ] __main__: train step 8335: loss: 1.0547, policy_loss: 1.2008, value_loss: 0.7796
2024-07-11 16:28:32,910 [INFO    ] __main__: train step 8336: loss: 1.0547, policy_loss: 1.2007, value_loss: 0.7796
2024-07-11 16:28:33,123 [INFO    ] __main__: train step 8337: loss: 1.0547, policy_loss: 1.2006, value_loss: 0.7795
2024-07-11 16:28:33,322 [INFO    ] __main__: train step 8338: loss: 1.0547, policy_loss: 1.2006, value_loss: 0.7795
2024-07-11 16:28:33,518 [INFO    ] __main__: train step 8339: loss: 1.0547, policy_loss: 1.2005, value_loss: 0.7795
2024-07-11 16:28:33,721 [INFO    ] __main__: train step 8340: loss: 1.0547, policy_loss: 1.2004, value_loss: 0.7794
2024-07-11 16:28:33,945 [INFO    ] __main__: train step 8341: loss: 1.0547, policy_loss: 1.2003, value_loss: 0.7794
2024-07-11 16:28:34,172 [INFO    ] __main__: train step 8342: loss: 1.0547, policy_loss: 1.2003, value_loss: 0.7794
2024-07-11 16:28:34,371 [INFO    ] __main__: train step 8343: loss: 1.0547, policy_loss: 1.2002, value_loss: 0.7794
2024-07-11 16:28:34,576 [INFO    ] __main__: train step 8344: loss: 1.0547, policy_loss: 1.2001, value_loss: 0.7793
2024-07-11 16:28:34,787 [INFO    ] __main__: train step 8345: loss: 1.0547, policy_loss: 1.2000, value_loss: 0.7793
2024-07-11 16:28:35,016 [INFO    ] __main__: train step 8346: loss: 1.0547, policy_loss: 1.2000, value_loss: 0.7793
2024-07-11 16:28:36,482 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:28:36,797 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:28:36,851 [INFO    ] __main__: train step 8347: loss: 1.0547, policy_loss: 1.1999, value_loss: 0.7792
2024-07-11 16:28:37,039 [INFO    ] __main__: train step 8348: loss: 1.0547, policy_loss: 1.1998, value_loss: 0.7792
2024-07-11 16:28:37,257 [INFO    ] __main__: train step 8349: loss: 1.0547, policy_loss: 1.1997, value_loss: 0.7792
2024-07-11 16:28:37,484 [INFO    ] __main__: train step 8350: loss: 1.0547, policy_loss: 1.1997, value_loss: 0.7791
2024-07-11 16:28:37,683 [INFO    ] __main__: train step 8351: loss: 1.0548, policy_loss: 1.1996, value_loss: 0.7791
2024-07-11 16:28:37,930 [INFO    ] __main__: train step 8352: loss: 1.0548, policy_loss: 1.1995, value_loss: 0.7791
2024-07-11 16:28:38,164 [INFO    ] __main__: train step 8353: loss: 1.0548, policy_loss: 1.1994, value_loss: 0.7791
2024-07-11 16:28:38,383 [INFO    ] __main__: train step 8354: loss: 1.0548, policy_loss: 1.1994, value_loss: 0.7790
2024-07-11 16:28:38,600 [INFO    ] __main__: train step 8355: loss: 1.0548, policy_loss: 1.1993, value_loss: 0.7790
2024-07-11 16:28:38,824 [INFO    ] __main__: train step 8356: loss: 1.0548, policy_loss: 1.1992, value_loss: 0.7790
2024-07-11 16:28:39,032 [INFO    ] __main__: train step 8357: loss: 1.0548, policy_loss: 1.1991, value_loss: 0.7789
2024-07-11 16:28:39,252 [INFO    ] __main__: train step 8358: loss: 1.0548, policy_loss: 1.1991, value_loss: 0.7789
2024-07-11 16:28:39,460 [INFO    ] __main__: train step 8359: loss: 1.0548, policy_loss: 1.1990, value_loss: 0.7789
2024-07-11 16:28:39,655 [INFO    ] __main__: train step 8360: loss: 1.0548, policy_loss: 1.1989, value_loss: 0.7789
2024-07-11 16:28:39,892 [INFO    ] __main__: train step 8361: loss: 1.0548, policy_loss: 1.1988, value_loss: 0.7788
2024-07-11 16:28:40,091 [INFO    ] __main__: train step 8362: loss: 1.0548, policy_loss: 1.1988, value_loss: 0.7788
2024-07-11 16:28:40,301 [INFO    ] __main__: train step 8363: loss: 1.0548, policy_loss: 1.1987, value_loss: 0.7788
2024-07-11 16:28:41,740 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:28:42,089 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:28:42,146 [INFO    ] __main__: train step 8364: loss: 1.0548, policy_loss: 1.1986, value_loss: 0.7787
2024-07-11 16:28:42,313 [INFO    ] __main__: train step 8365: loss: 1.0549, policy_loss: 1.1985, value_loss: 0.7787
2024-07-11 16:28:42,523 [INFO    ] __main__: train step 8366: loss: 1.0549, policy_loss: 1.1985, value_loss: 0.7787
2024-07-11 16:28:42,731 [INFO    ] __main__: train step 8367: loss: 1.0549, policy_loss: 1.1984, value_loss: 0.7787
2024-07-11 16:28:42,924 [INFO    ] __main__: train step 8368: loss: 1.0549, policy_loss: 1.1983, value_loss: 0.7786
2024-07-11 16:28:43,122 [INFO    ] __main__: train step 8369: loss: 1.0549, policy_loss: 1.1982, value_loss: 0.7786
2024-07-11 16:28:43,322 [INFO    ] __main__: train step 8370: loss: 1.0549, policy_loss: 1.1982, value_loss: 0.7786
2024-07-11 16:28:43,531 [INFO    ] __main__: train step 8371: loss: 1.0549, policy_loss: 1.1981, value_loss: 0.7785
2024-07-11 16:28:43,733 [INFO    ] __main__: train step 8372: loss: 1.0549, policy_loss: 1.1980, value_loss: 0.7785
2024-07-11 16:28:43,932 [INFO    ] __main__: train step 8373: loss: 1.0549, policy_loss: 1.1979, value_loss: 0.7785
2024-07-11 16:28:44,135 [INFO    ] __main__: train step 8374: loss: 1.0549, policy_loss: 1.1979, value_loss: 0.7785
2024-07-11 16:28:44,353 [INFO    ] __main__: train step 8375: loss: 1.0549, policy_loss: 1.1978, value_loss: 0.7784
2024-07-11 16:28:44,594 [INFO    ] __main__: train step 8376: loss: 1.0549, policy_loss: 1.1977, value_loss: 0.7784
2024-07-11 16:28:44,802 [INFO    ] __main__: train step 8377: loss: 1.0549, policy_loss: 1.1976, value_loss: 0.7784
2024-07-11 16:28:45,000 [INFO    ] __main__: train step 8378: loss: 1.0549, policy_loss: 1.1976, value_loss: 0.7783
2024-07-11 16:28:45,198 [INFO    ] __main__: train step 8379: loss: 1.0549, policy_loss: 1.1975, value_loss: 0.7783
2024-07-11 16:28:45,412 [INFO    ] __main__: train step 8380: loss: 1.0549, policy_loss: 1.1974, value_loss: 0.7783
2024-07-11 16:28:46,835 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:28:47,202 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:28:47,262 [INFO    ] __main__: train step 8381: loss: 1.0549, policy_loss: 1.1973, value_loss: 0.7782
2024-07-11 16:28:47,438 [INFO    ] __main__: train step 8382: loss: 1.0549, policy_loss: 1.1973, value_loss: 0.7782
2024-07-11 16:28:47,649 [INFO    ] __main__: train step 8383: loss: 1.0550, policy_loss: 1.1972, value_loss: 0.7782
2024-07-11 16:28:47,881 [INFO    ] __main__: train step 8384: loss: 1.0550, policy_loss: 1.1971, value_loss: 0.7782
2024-07-11 16:28:48,095 [INFO    ] __main__: train step 8385: loss: 1.0550, policy_loss: 1.1970, value_loss: 0.7781
2024-07-11 16:28:48,333 [INFO    ] __main__: train step 8386: loss: 1.0550, policy_loss: 1.1970, value_loss: 0.7781
2024-07-11 16:28:48,560 [INFO    ] __main__: train step 8387: loss: 1.0550, policy_loss: 1.1969, value_loss: 0.7781
2024-07-11 16:28:48,764 [INFO    ] __main__: train step 8388: loss: 1.0550, policy_loss: 1.1968, value_loss: 0.7780
2024-07-11 16:28:48,966 [INFO    ] __main__: train step 8389: loss: 1.0550, policy_loss: 1.1968, value_loss: 0.7780
2024-07-11 16:28:49,168 [INFO    ] __main__: train step 8390: loss: 1.0550, policy_loss: 1.1967, value_loss: 0.7780
2024-07-11 16:28:49,380 [INFO    ] __main__: train step 8391: loss: 1.0550, policy_loss: 1.1966, value_loss: 0.7779
2024-07-11 16:28:49,581 [INFO    ] __main__: train step 8392: loss: 1.0550, policy_loss: 1.1965, value_loss: 0.7779
2024-07-11 16:28:49,780 [INFO    ] __main__: train step 8393: loss: 1.0550, policy_loss: 1.1965, value_loss: 0.7779
2024-07-11 16:28:49,998 [INFO    ] __main__: train step 8394: loss: 1.0550, policy_loss: 1.1964, value_loss: 0.7779
2024-07-11 16:28:50,217 [INFO    ] __main__: train step 8395: loss: 1.0550, policy_loss: 1.1963, value_loss: 0.7778
2024-07-11 16:28:50,436 [INFO    ] __main__: train step 8396: loss: 1.0550, policy_loss: 1.1962, value_loss: 0.7778
2024-07-11 16:28:50,652 [INFO    ] __main__: train step 8397: loss: 1.0550, policy_loss: 1.1962, value_loss: 0.7778
2024-07-11 16:28:52,942 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:28:53,315 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:28:53,372 [INFO    ] __main__: train step 8398: loss: 1.0550, policy_loss: 1.1961, value_loss: 0.7777
2024-07-11 16:28:53,550 [INFO    ] __main__: train step 8399: loss: 1.0550, policy_loss: 1.1960, value_loss: 0.7777
2024-07-11 16:28:53,761 [INFO    ] __main__: train step 8400: loss: 1.0550, policy_loss: 1.1959, value_loss: 0.7777
2024-07-11 16:28:53,984 [INFO    ] __main__: train step 8401: loss: 1.0550, policy_loss: 1.1959, value_loss: 0.7776
2024-07-11 16:28:54,182 [INFO    ] __main__: train step 8402: loss: 1.0550, policy_loss: 1.1958, value_loss: 0.7776
2024-07-11 16:28:54,380 [INFO    ] __main__: train step 8403: loss: 1.0551, policy_loss: 1.1957, value_loss: 0.7776
2024-07-11 16:28:54,582 [INFO    ] __main__: train step 8404: loss: 1.0551, policy_loss: 1.1956, value_loss: 0.7776
2024-07-11 16:28:54,781 [INFO    ] __main__: train step 8405: loss: 1.0551, policy_loss: 1.1956, value_loss: 0.7775
2024-07-11 16:28:54,986 [INFO    ] __main__: train step 8406: loss: 1.0551, policy_loss: 1.1955, value_loss: 0.7775
2024-07-11 16:28:55,183 [INFO    ] __main__: train step 8407: loss: 1.0551, policy_loss: 1.1954, value_loss: 0.7775
2024-07-11 16:28:55,392 [INFO    ] __main__: train step 8408: loss: 1.0551, policy_loss: 1.1953, value_loss: 0.7774
2024-07-11 16:28:55,594 [INFO    ] __main__: train step 8409: loss: 1.0551, policy_loss: 1.1953, value_loss: 0.7774
2024-07-11 16:28:55,806 [INFO    ] __main__: train step 8410: loss: 1.0551, policy_loss: 1.1952, value_loss: 0.7774
2024-07-11 16:28:56,031 [INFO    ] __main__: train step 8411: loss: 1.0551, policy_loss: 1.1951, value_loss: 0.7773
2024-07-11 16:28:56,256 [INFO    ] __main__: train step 8412: loss: 1.0551, policy_loss: 1.1950, value_loss: 0.7773
2024-07-11 16:28:56,467 [INFO    ] __main__: train step 8413: loss: 1.0551, policy_loss: 1.1950, value_loss: 0.7773
2024-07-11 16:28:56,686 [INFO    ] __main__: train step 8414: loss: 1.0551, policy_loss: 1.1949, value_loss: 0.7773
2024-07-11 16:28:58,146 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:28:58,525 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:28:58,584 [INFO    ] __main__: train step 8415: loss: 1.0551, policy_loss: 1.1948, value_loss: 0.7772
2024-07-11 16:28:58,761 [INFO    ] __main__: train step 8416: loss: 1.0551, policy_loss: 1.1948, value_loss: 0.7772
2024-07-11 16:28:58,988 [INFO    ] __main__: train step 8417: loss: 1.0551, policy_loss: 1.1947, value_loss: 0.7772
2024-07-11 16:28:59,204 [INFO    ] __main__: train step 8418: loss: 1.0551, policy_loss: 1.1946, value_loss: 0.7771
2024-07-11 16:28:59,405 [INFO    ] __main__: train step 8419: loss: 1.0551, policy_loss: 1.1945, value_loss: 0.7771
2024-07-11 16:28:59,618 [INFO    ] __main__: train step 8420: loss: 1.0551, policy_loss: 1.1945, value_loss: 0.7771
2024-07-11 16:28:59,820 [INFO    ] __main__: train step 8421: loss: 1.0551, policy_loss: 1.1944, value_loss: 0.7770
2024-07-11 16:29:00,026 [INFO    ] __main__: train step 8422: loss: 1.0552, policy_loss: 1.1943, value_loss: 0.7770
2024-07-11 16:29:00,220 [INFO    ] __main__: train step 8423: loss: 1.0552, policy_loss: 1.1942, value_loss: 0.7770
2024-07-11 16:29:00,424 [INFO    ] __main__: train step 8424: loss: 1.0552, policy_loss: 1.1942, value_loss: 0.7770
2024-07-11 16:29:00,620 [INFO    ] __main__: train step 8425: loss: 1.0552, policy_loss: 1.1941, value_loss: 0.7769
2024-07-11 16:29:00,812 [INFO    ] __main__: train step 8426: loss: 1.0552, policy_loss: 1.1940, value_loss: 0.7769
2024-07-11 16:29:01,025 [INFO    ] __main__: train step 8427: loss: 1.0552, policy_loss: 1.1939, value_loss: 0.7769
2024-07-11 16:29:01,218 [INFO    ] __main__: train step 8428: loss: 1.0552, policy_loss: 1.1939, value_loss: 0.7768
2024-07-11 16:29:01,441 [INFO    ] __main__: train step 8429: loss: 1.0552, policy_loss: 1.1938, value_loss: 0.7768
2024-07-11 16:29:01,640 [INFO    ] __main__: train step 8430: loss: 1.0552, policy_loss: 1.1937, value_loss: 0.7768
2024-07-11 16:29:01,874 [INFO    ] __main__: train step 8431: loss: 1.0552, policy_loss: 1.1936, value_loss: 0.7768
2024-07-11 16:29:03,322 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:29:03,657 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:29:03,716 [INFO    ] __main__: train step 8432: loss: 1.0552, policy_loss: 1.1936, value_loss: 0.7767
2024-07-11 16:29:03,890 [INFO    ] __main__: train step 8433: loss: 1.0552, policy_loss: 1.1935, value_loss: 0.7767
2024-07-11 16:29:04,097 [INFO    ] __main__: train step 8434: loss: 1.0552, policy_loss: 1.1934, value_loss: 0.7767
2024-07-11 16:29:04,309 [INFO    ] __main__: train step 8435: loss: 1.0552, policy_loss: 1.1933, value_loss: 0.7766
2024-07-11 16:29:04,512 [INFO    ] __main__: train step 8436: loss: 1.0552, policy_loss: 1.1933, value_loss: 0.7766
2024-07-11 16:29:04,703 [INFO    ] __main__: train step 8437: loss: 1.0552, policy_loss: 1.1932, value_loss: 0.7766
2024-07-11 16:29:04,914 [INFO    ] __main__: train step 8438: loss: 1.0552, policy_loss: 1.1931, value_loss: 0.7765
2024-07-11 16:29:05,130 [INFO    ] __main__: train step 8439: loss: 1.0552, policy_loss: 1.1931, value_loss: 0.7765
2024-07-11 16:29:05,351 [INFO    ] __main__: train step 8440: loss: 1.0553, policy_loss: 1.1930, value_loss: 0.7765
2024-07-11 16:29:05,569 [INFO    ] __main__: train step 8441: loss: 1.0553, policy_loss: 1.1929, value_loss: 0.7765
2024-07-11 16:29:05,792 [INFO    ] __main__: train step 8442: loss: 1.0553, policy_loss: 1.1928, value_loss: 0.7764
2024-07-11 16:29:06,026 [INFO    ] __main__: train step 8443: loss: 1.0553, policy_loss: 1.1928, value_loss: 0.7764
2024-07-11 16:29:06,221 [INFO    ] __main__: train step 8444: loss: 1.0553, policy_loss: 1.1927, value_loss: 0.7764
2024-07-11 16:29:06,429 [INFO    ] __main__: train step 8445: loss: 1.0553, policy_loss: 1.1926, value_loss: 0.7763
2024-07-11 16:29:06,637 [INFO    ] __main__: train step 8446: loss: 1.0553, policy_loss: 1.1925, value_loss: 0.7763
2024-07-11 16:29:06,845 [INFO    ] __main__: train step 8447: loss: 1.0553, policy_loss: 1.1925, value_loss: 0.7763
2024-07-11 16:29:07,046 [INFO    ] __main__: train step 8448: loss: 1.0553, policy_loss: 1.1924, value_loss: 0.7762
2024-07-11 16:29:08,494 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:29:08,886 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:29:08,942 [INFO    ] __main__: train step 8449: loss: 1.0553, policy_loss: 1.1923, value_loss: 0.7762
2024-07-11 16:29:09,115 [INFO    ] __main__: train step 8450: loss: 1.0553, policy_loss: 1.1922, value_loss: 0.7762
2024-07-11 16:29:09,330 [INFO    ] __main__: train step 8451: loss: 1.0553, policy_loss: 1.1922, value_loss: 0.7762
2024-07-11 16:29:09,527 [INFO    ] __main__: train step 8452: loss: 1.0553, policy_loss: 1.1921, value_loss: 0.7761
2024-07-11 16:29:09,726 [INFO    ] __main__: train step 8453: loss: 1.0553, policy_loss: 1.1920, value_loss: 0.7761
2024-07-11 16:29:09,927 [INFO    ] __main__: train step 8454: loss: 1.0553, policy_loss: 1.1920, value_loss: 0.7761
2024-07-11 16:29:10,131 [INFO    ] __main__: train step 8455: loss: 1.0553, policy_loss: 1.1919, value_loss: 0.7760
2024-07-11 16:29:10,333 [INFO    ] __main__: train step 8456: loss: 1.0553, policy_loss: 1.1918, value_loss: 0.7760
2024-07-11 16:29:10,529 [INFO    ] __main__: train step 8457: loss: 1.0553, policy_loss: 1.1917, value_loss: 0.7760
2024-07-11 16:29:10,731 [INFO    ] __main__: train step 8458: loss: 1.0553, policy_loss: 1.1917, value_loss: 0.7760
2024-07-11 16:29:10,943 [INFO    ] __main__: train step 8459: loss: 1.0553, policy_loss: 1.1916, value_loss: 0.7759
2024-07-11 16:29:11,150 [INFO    ] __main__: train step 8460: loss: 1.0553, policy_loss: 1.1915, value_loss: 0.7759
2024-07-11 16:29:11,361 [INFO    ] __main__: train step 8461: loss: 1.0554, policy_loss: 1.1914, value_loss: 0.7759
2024-07-11 16:29:11,553 [INFO    ] __main__: train step 8462: loss: 1.0554, policy_loss: 1.1914, value_loss: 0.7758
2024-07-11 16:29:11,759 [INFO    ] __main__: train step 8463: loss: 1.0554, policy_loss: 1.1913, value_loss: 0.7758
2024-07-11 16:29:11,968 [INFO    ] __main__: train step 8464: loss: 1.0554, policy_loss: 1.1912, value_loss: 0.7758
2024-07-11 16:29:12,162 [INFO    ] __main__: train step 8465: loss: 1.0554, policy_loss: 1.1911, value_loss: 0.7757
2024-07-11 16:29:13,603 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:29:13,965 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:29:14,023 [INFO    ] __main__: train step 8466: loss: 1.0554, policy_loss: 1.1911, value_loss: 0.7757
2024-07-11 16:29:14,206 [INFO    ] __main__: train step 8467: loss: 1.0554, policy_loss: 1.1910, value_loss: 0.7757
2024-07-11 16:29:14,407 [INFO    ] __main__: train step 8468: loss: 1.0554, policy_loss: 1.1909, value_loss: 0.7756
2024-07-11 16:29:14,603 [INFO    ] __main__: train step 8469: loss: 1.0554, policy_loss: 1.1909, value_loss: 0.7756
2024-07-11 16:29:14,821 [INFO    ] __main__: train step 8470: loss: 1.0554, policy_loss: 1.1908, value_loss: 0.7756
2024-07-11 16:29:15,894 [INFO    ] __main__: train step 8471: loss: 1.0554, policy_loss: 1.1907, value_loss: 0.7755
2024-07-11 16:29:16,135 [INFO    ] __main__: train step 8472: loss: 1.0554, policy_loss: 1.1906, value_loss: 0.7755
2024-07-11 16:29:16,343 [INFO    ] __main__: train step 8473: loss: 1.0554, policy_loss: 1.1906, value_loss: 0.7755
2024-07-11 16:29:16,544 [INFO    ] __main__: train step 8474: loss: 1.0554, policy_loss: 1.1905, value_loss: 0.7755
2024-07-11 16:29:16,742 [INFO    ] __main__: train step 8475: loss: 1.0554, policy_loss: 1.1904, value_loss: 0.7754
2024-07-11 16:29:16,960 [INFO    ] __main__: train step 8476: loss: 1.0554, policy_loss: 1.1903, value_loss: 0.7754
2024-07-11 16:29:17,163 [INFO    ] __main__: train step 8477: loss: 1.0554, policy_loss: 1.1903, value_loss: 0.7754
2024-07-11 16:29:17,380 [INFO    ] __main__: train step 8478: loss: 1.0554, policy_loss: 1.1902, value_loss: 0.7753
2024-07-11 16:29:17,569 [INFO    ] __main__: train step 8479: loss: 1.0554, policy_loss: 1.1901, value_loss: 0.7753
2024-07-11 16:29:17,782 [INFO    ] __main__: train step 8480: loss: 1.0554, policy_loss: 1.1900, value_loss: 0.7753
2024-07-11 16:29:17,985 [INFO    ] __main__: train step 8481: loss: 1.0554, policy_loss: 1.1900, value_loss: 0.7752
2024-07-11 16:29:18,191 [INFO    ] __main__: train step 8482: loss: 1.0554, policy_loss: 1.1899, value_loss: 0.7752
2024-07-11 16:29:19,647 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:29:20,064 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:29:20,123 [INFO    ] __main__: train step 8483: loss: 1.0554, policy_loss: 1.1898, value_loss: 0.7752
2024-07-11 16:29:20,307 [INFO    ] __main__: train step 8484: loss: 1.0554, policy_loss: 1.1898, value_loss: 0.7752
2024-07-11 16:29:20,508 [INFO    ] __main__: train step 8485: loss: 1.0554, policy_loss: 1.1897, value_loss: 0.7751
2024-07-11 16:29:20,717 [INFO    ] __main__: train step 8486: loss: 1.0554, policy_loss: 1.1896, value_loss: 0.7751
2024-07-11 16:29:20,924 [INFO    ] __main__: train step 8487: loss: 1.0554, policy_loss: 1.1895, value_loss: 0.7751
2024-07-11 16:29:21,139 [INFO    ] __main__: train step 8488: loss: 1.0554, policy_loss: 1.1895, value_loss: 0.7750
2024-07-11 16:29:21,337 [INFO    ] __main__: train step 8489: loss: 1.0554, policy_loss: 1.1894, value_loss: 0.7750
2024-07-11 16:29:21,544 [INFO    ] __main__: train step 8490: loss: 1.0554, policy_loss: 1.1893, value_loss: 0.7750
2024-07-11 16:29:21,743 [INFO    ] __main__: train step 8491: loss: 1.0554, policy_loss: 1.1892, value_loss: 0.7749
2024-07-11 16:29:21,940 [INFO    ] __main__: train step 8492: loss: 1.0554, policy_loss: 1.1892, value_loss: 0.7749
2024-07-11 16:29:22,139 [INFO    ] __main__: train step 8493: loss: 1.0554, policy_loss: 1.1891, value_loss: 0.7749
2024-07-11 16:29:22,345 [INFO    ] __main__: train step 8494: loss: 1.0555, policy_loss: 1.1890, value_loss: 0.7748
2024-07-11 16:29:22,544 [INFO    ] __main__: train step 8495: loss: 1.0555, policy_loss: 1.1889, value_loss: 0.7748
2024-07-11 16:29:22,755 [INFO    ] __main__: train step 8496: loss: 1.0555, policy_loss: 1.1889, value_loss: 0.7748
2024-07-11 16:29:22,960 [INFO    ] __main__: train step 8497: loss: 1.0555, policy_loss: 1.1888, value_loss: 0.7747
2024-07-11 16:29:23,173 [INFO    ] __main__: train step 8498: loss: 1.0555, policy_loss: 1.1887, value_loss: 0.7747
2024-07-11 16:29:23,415 [INFO    ] __main__: train step 8499: loss: 1.0555, policy_loss: 1.1887, value_loss: 0.7747
2024-07-11 16:29:24,876 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:29:25,270 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:29:25,326 [INFO    ] __main__: train step 8500: loss: 1.0555, policy_loss: 1.1886, value_loss: 0.7747
2024-07-11 16:29:25,498 [INFO    ] __main__: train step 8501: loss: 1.0555, policy_loss: 1.1885, value_loss: 0.7746
2024-07-11 16:29:25,703 [INFO    ] __main__: train step 8502: loss: 1.0555, policy_loss: 1.1884, value_loss: 0.7746
2024-07-11 16:29:25,918 [INFO    ] __main__: train step 8503: loss: 1.0555, policy_loss: 1.1884, value_loss: 0.7746
2024-07-11 16:29:26,131 [INFO    ] __main__: train step 8504: loss: 1.0555, policy_loss: 1.1883, value_loss: 0.7745
2024-07-11 16:29:26,337 [INFO    ] __main__: train step 8505: loss: 1.0555, policy_loss: 1.1882, value_loss: 0.7745
2024-07-11 16:29:26,541 [INFO    ] __main__: train step 8506: loss: 1.0555, policy_loss: 1.1881, value_loss: 0.7745
2024-07-11 16:29:26,754 [INFO    ] __main__: train step 8507: loss: 1.0555, policy_loss: 1.1881, value_loss: 0.7744
2024-07-11 16:29:26,951 [INFO    ] __main__: train step 8508: loss: 1.0555, policy_loss: 1.1880, value_loss: 0.7744
2024-07-11 16:29:27,157 [INFO    ] __main__: train step 8509: loss: 1.0555, policy_loss: 1.1879, value_loss: 0.7744
2024-07-11 16:29:27,364 [INFO    ] __main__: train step 8510: loss: 1.0555, policy_loss: 1.1879, value_loss: 0.7744
2024-07-11 16:29:27,571 [INFO    ] __main__: train step 8511: loss: 1.0555, policy_loss: 1.1878, value_loss: 0.7743
2024-07-11 16:29:27,773 [INFO    ] __main__: train step 8512: loss: 1.0555, policy_loss: 1.1877, value_loss: 0.7743
2024-07-11 16:29:27,982 [INFO    ] __main__: train step 8513: loss: 1.0555, policy_loss: 1.1876, value_loss: 0.7743
2024-07-11 16:29:28,199 [INFO    ] __main__: train step 8514: loss: 1.0555, policy_loss: 1.1876, value_loss: 0.7742
2024-07-11 16:29:28,413 [INFO    ] __main__: train step 8515: loss: 1.0555, policy_loss: 1.1875, value_loss: 0.7742
2024-07-11 16:29:28,612 [INFO    ] __main__: train step 8516: loss: 1.0555, policy_loss: 1.1874, value_loss: 0.7742
2024-07-11 16:29:30,063 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:29:30,443 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:29:30,498 [INFO    ] __main__: train step 8517: loss: 1.0555, policy_loss: 1.1873, value_loss: 0.7741
2024-07-11 16:29:30,689 [INFO    ] __main__: train step 8518: loss: 1.0555, policy_loss: 1.1873, value_loss: 0.7741
2024-07-11 16:29:30,935 [INFO    ] __main__: train step 8519: loss: 1.0555, policy_loss: 1.1872, value_loss: 0.7741
2024-07-11 16:29:31,158 [INFO    ] __main__: train step 8520: loss: 1.0555, policy_loss: 1.1871, value_loss: 0.7740
2024-07-11 16:29:31,361 [INFO    ] __main__: train step 8521: loss: 1.0555, policy_loss: 1.1871, value_loss: 0.7740
2024-07-11 16:29:31,566 [INFO    ] __main__: train step 8522: loss: 1.0555, policy_loss: 1.1870, value_loss: 0.7740
2024-07-11 16:29:31,770 [INFO    ] __main__: train step 8523: loss: 1.0555, policy_loss: 1.1869, value_loss: 0.7739
2024-07-11 16:29:31,988 [INFO    ] __main__: train step 8524: loss: 1.0555, policy_loss: 1.1868, value_loss: 0.7739
2024-07-11 16:29:32,225 [INFO    ] __main__: train step 8525: loss: 1.0555, policy_loss: 1.1868, value_loss: 0.7739
2024-07-11 16:29:32,460 [INFO    ] __main__: train step 8526: loss: 1.0555, policy_loss: 1.1867, value_loss: 0.7738
2024-07-11 16:29:32,658 [INFO    ] __main__: train step 8527: loss: 1.0555, policy_loss: 1.1866, value_loss: 0.7738
2024-07-11 16:29:32,862 [INFO    ] __main__: train step 8528: loss: 1.0555, policy_loss: 1.1865, value_loss: 0.7738
2024-07-11 16:29:33,059 [INFO    ] __main__: train step 8529: loss: 1.0555, policy_loss: 1.1865, value_loss: 0.7737
2024-07-11 16:29:33,263 [INFO    ] __main__: train step 8530: loss: 1.0555, policy_loss: 1.1864, value_loss: 0.7737
2024-07-11 16:29:33,463 [INFO    ] __main__: train step 8531: loss: 1.0555, policy_loss: 1.1863, value_loss: 0.7737
2024-07-11 16:29:33,666 [INFO    ] __main__: train step 8532: loss: 1.0555, policy_loss: 1.1862, value_loss: 0.7736
2024-07-11 16:29:33,865 [INFO    ] __main__: train step 8533: loss: 1.0555, policy_loss: 1.1862, value_loss: 0.7736
2024-07-11 16:29:35,317 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:29:35,720 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:29:35,775 [INFO    ] __main__: train step 8534: loss: 1.0555, policy_loss: 1.1861, value_loss: 0.7736
2024-07-11 16:29:35,960 [INFO    ] __main__: train step 8535: loss: 1.0555, policy_loss: 1.1860, value_loss: 0.7736
2024-07-11 16:29:36,157 [INFO    ] __main__: train step 8536: loss: 1.0555, policy_loss: 1.1859, value_loss: 0.7735
2024-07-11 16:29:36,371 [INFO    ] __main__: train step 8537: loss: 1.0555, policy_loss: 1.1859, value_loss: 0.7735
2024-07-11 16:29:36,594 [INFO    ] __main__: train step 8538: loss: 1.0555, policy_loss: 1.1858, value_loss: 0.7735
2024-07-11 16:29:36,807 [INFO    ] __main__: train step 8539: loss: 1.0555, policy_loss: 1.1857, value_loss: 0.7734
2024-07-11 16:29:37,016 [INFO    ] __main__: train step 8540: loss: 1.0555, policy_loss: 1.1857, value_loss: 0.7734
2024-07-11 16:29:37,261 [INFO    ] __main__: train step 8541: loss: 1.0555, policy_loss: 1.1856, value_loss: 0.7734
2024-07-11 16:29:37,462 [INFO    ] __main__: train step 8542: loss: 1.0555, policy_loss: 1.1855, value_loss: 0.7733
2024-07-11 16:29:37,697 [INFO    ] __main__: train step 8543: loss: 1.0555, policy_loss: 1.1854, value_loss: 0.7733
2024-07-11 16:29:37,892 [INFO    ] __main__: train step 8544: loss: 1.0555, policy_loss: 1.1854, value_loss: 0.7733
2024-07-11 16:29:38,971 [INFO    ] __main__: train step 8545: loss: 1.0555, policy_loss: 1.1853, value_loss: 0.7732
2024-07-11 16:29:39,183 [INFO    ] __main__: train step 8546: loss: 1.0555, policy_loss: 1.1852, value_loss: 0.7732
2024-07-11 16:29:39,412 [INFO    ] __main__: train step 8547: loss: 1.0555, policy_loss: 1.1851, value_loss: 0.7732
2024-07-11 16:29:39,599 [INFO    ] __main__: train step 8548: loss: 1.0555, policy_loss: 1.1851, value_loss: 0.7731
2024-07-11 16:29:39,805 [INFO    ] __main__: train step 8549: loss: 1.0555, policy_loss: 1.1850, value_loss: 0.7731
2024-07-11 16:29:39,998 [INFO    ] __main__: train step 8550: loss: 1.0555, policy_loss: 1.1849, value_loss: 0.7731
2024-07-11 16:29:41,433 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:29:41,872 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:29:41,931 [INFO    ] __main__: train step 8551: loss: 1.0555, policy_loss: 1.1849, value_loss: 0.7730
2024-07-11 16:29:42,115 [INFO    ] __main__: train step 8552: loss: 1.0555, policy_loss: 1.1848, value_loss: 0.7730
2024-07-11 16:29:42,313 [INFO    ] __main__: train step 8553: loss: 1.0555, policy_loss: 1.1847, value_loss: 0.7730
2024-07-11 16:29:42,521 [INFO    ] __main__: train step 8554: loss: 1.0555, policy_loss: 1.1846, value_loss: 0.7729
2024-07-11 16:29:42,728 [INFO    ] __main__: train step 8555: loss: 1.0555, policy_loss: 1.1846, value_loss: 0.7729
2024-07-11 16:29:42,934 [INFO    ] __main__: train step 8556: loss: 1.0555, policy_loss: 1.1845, value_loss: 0.7729
2024-07-11 16:29:43,133 [INFO    ] __main__: train step 8557: loss: 1.0555, policy_loss: 1.1844, value_loss: 0.7729
2024-07-11 16:29:43,341 [INFO    ] __main__: train step 8558: loss: 1.0555, policy_loss: 1.1843, value_loss: 0.7728
2024-07-11 16:29:43,540 [INFO    ] __main__: train step 8559: loss: 1.0555, policy_loss: 1.1843, value_loss: 0.7728
2024-07-11 16:29:43,755 [INFO    ] __main__: train step 8560: loss: 1.0555, policy_loss: 1.1842, value_loss: 0.7728
2024-07-11 16:29:43,947 [INFO    ] __main__: train step 8561: loss: 1.0555, policy_loss: 1.1841, value_loss: 0.7727
2024-07-11 16:29:44,155 [INFO    ] __main__: train step 8562: loss: 1.0555, policy_loss: 1.1840, value_loss: 0.7727
2024-07-11 16:29:44,380 [INFO    ] __main__: train step 8563: loss: 1.0555, policy_loss: 1.1840, value_loss: 0.7727
2024-07-11 16:29:44,571 [INFO    ] __main__: train step 8564: loss: 1.0555, policy_loss: 1.1839, value_loss: 0.7726
2024-07-11 16:29:44,781 [INFO    ] __main__: train step 8565: loss: 1.0555, policy_loss: 1.1838, value_loss: 0.7726
2024-07-11 16:29:44,976 [INFO    ] __main__: train step 8566: loss: 1.0555, policy_loss: 1.1838, value_loss: 0.7726
2024-07-11 16:29:45,177 [INFO    ] __main__: train step 8567: loss: 1.0555, policy_loss: 1.1837, value_loss: 0.7725
2024-07-11 16:29:46,627 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:29:47,023 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:29:47,080 [INFO    ] __main__: train step 8568: loss: 1.0555, policy_loss: 1.1836, value_loss: 0.7725
2024-07-11 16:29:47,264 [INFO    ] __main__: train step 8569: loss: 1.0555, policy_loss: 1.1835, value_loss: 0.7725
2024-07-11 16:29:47,489 [INFO    ] __main__: train step 8570: loss: 1.0555, policy_loss: 1.1835, value_loss: 0.7724
2024-07-11 16:29:47,715 [INFO    ] __main__: train step 8571: loss: 1.0555, policy_loss: 1.1834, value_loss: 0.7724
2024-07-11 16:29:47,906 [INFO    ] __main__: train step 8572: loss: 1.0555, policy_loss: 1.1833, value_loss: 0.7724
2024-07-11 16:29:48,098 [INFO    ] __main__: train step 8573: loss: 1.0555, policy_loss: 1.1832, value_loss: 0.7723
2024-07-11 16:29:48,327 [INFO    ] __main__: train step 8574: loss: 1.0555, policy_loss: 1.1832, value_loss: 0.7723
2024-07-11 16:29:48,530 [INFO    ] __main__: train step 8575: loss: 1.0555, policy_loss: 1.1831, value_loss: 0.7723
2024-07-11 16:29:48,725 [INFO    ] __main__: train step 8576: loss: 1.0555, policy_loss: 1.1830, value_loss: 0.7722
2024-07-11 16:29:48,932 [INFO    ] __main__: train step 8577: loss: 1.0555, policy_loss: 1.1830, value_loss: 0.7722
2024-07-11 16:29:49,127 [INFO    ] __main__: train step 8578: loss: 1.0555, policy_loss: 1.1829, value_loss: 0.7722
2024-07-11 16:29:49,320 [INFO    ] __main__: train step 8579: loss: 1.0555, policy_loss: 1.1828, value_loss: 0.7721
2024-07-11 16:29:49,522 [INFO    ] __main__: train step 8580: loss: 1.0555, policy_loss: 1.1827, value_loss: 0.7721
2024-07-11 16:29:49,728 [INFO    ] __main__: train step 8581: loss: 1.0555, policy_loss: 1.1827, value_loss: 0.7721
2024-07-11 16:29:49,938 [INFO    ] __main__: train step 8582: loss: 1.0555, policy_loss: 1.1826, value_loss: 0.7721
2024-07-11 16:29:50,186 [INFO    ] __main__: train step 8583: loss: 1.0555, policy_loss: 1.1825, value_loss: 0.7720
2024-07-11 16:29:50,418 [INFO    ] __main__: train step 8584: loss: 1.0555, policy_loss: 1.1824, value_loss: 0.7720
2024-07-11 16:29:51,865 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:29:52,292 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:29:52,356 [INFO    ] __main__: train step 8585: loss: 1.0555, policy_loss: 1.1824, value_loss: 0.7720
2024-07-11 16:29:52,526 [INFO    ] __main__: train step 8586: loss: 1.0555, policy_loss: 1.1823, value_loss: 0.7719
2024-07-11 16:29:52,734 [INFO    ] __main__: train step 8587: loss: 1.0555, policy_loss: 1.1822, value_loss: 0.7719
2024-07-11 16:29:52,941 [INFO    ] __main__: train step 8588: loss: 1.0555, policy_loss: 1.1821, value_loss: 0.7719
2024-07-11 16:29:53,152 [INFO    ] __main__: train step 8589: loss: 1.0555, policy_loss: 1.1821, value_loss: 0.7718
2024-07-11 16:29:53,342 [INFO    ] __main__: train step 8590: loss: 1.0555, policy_loss: 1.1820, value_loss: 0.7718
2024-07-11 16:29:53,553 [INFO    ] __main__: train step 8591: loss: 1.0555, policy_loss: 1.1819, value_loss: 0.7718
2024-07-11 16:29:53,767 [INFO    ] __main__: train step 8592: loss: 1.0555, policy_loss: 1.1819, value_loss: 0.7717
2024-07-11 16:29:53,987 [INFO    ] __main__: train step 8593: loss: 1.0555, policy_loss: 1.1818, value_loss: 0.7717
2024-07-11 16:29:54,195 [INFO    ] __main__: train step 8594: loss: 1.0555, policy_loss: 1.1817, value_loss: 0.7717
2024-07-11 16:29:54,398 [INFO    ] __main__: train step 8595: loss: 1.0555, policy_loss: 1.1816, value_loss: 0.7716
2024-07-11 16:29:54,591 [INFO    ] __main__: train step 8596: loss: 1.0555, policy_loss: 1.1816, value_loss: 0.7716
2024-07-11 16:29:54,788 [INFO    ] __main__: train step 8597: loss: 1.0555, policy_loss: 1.1815, value_loss: 0.7716
2024-07-11 16:29:55,001 [INFO    ] __main__: train step 8598: loss: 1.0555, policy_loss: 1.1814, value_loss: 0.7715
2024-07-11 16:29:55,200 [INFO    ] __main__: train step 8599: loss: 1.0555, policy_loss: 1.1814, value_loss: 0.7715
2024-07-11 16:29:55,400 [INFO    ] __main__: train step 8600: loss: 1.0555, policy_loss: 1.1813, value_loss: 0.7715
2024-07-11 16:29:55,592 [INFO    ] __main__: train step 8601: loss: 1.0555, policy_loss: 1.1812, value_loss: 0.7714
2024-07-11 16:29:57,029 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:29:57,425 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:29:57,481 [INFO    ] __main__: train step 8602: loss: 1.0555, policy_loss: 1.1811, value_loss: 0.7714
2024-07-11 16:29:57,656 [INFO    ] __main__: train step 8603: loss: 1.0555, policy_loss: 1.1811, value_loss: 0.7714
2024-07-11 16:29:57,852 [INFO    ] __main__: train step 8604: loss: 1.0555, policy_loss: 1.1810, value_loss: 0.7713
2024-07-11 16:29:58,063 [INFO    ] __main__: train step 8605: loss: 1.0555, policy_loss: 1.1809, value_loss: 0.7713
2024-07-11 16:29:58,270 [INFO    ] __main__: train step 8606: loss: 1.0555, policy_loss: 1.1808, value_loss: 0.7713
2024-07-11 16:29:58,472 [INFO    ] __main__: train step 8607: loss: 1.0555, policy_loss: 1.1808, value_loss: 0.7712
2024-07-11 16:29:58,667 [INFO    ] __main__: train step 8608: loss: 1.0555, policy_loss: 1.1807, value_loss: 0.7712
2024-07-11 16:29:58,870 [INFO    ] __main__: train step 8609: loss: 1.0555, policy_loss: 1.1806, value_loss: 0.7712
2024-07-11 16:29:59,075 [INFO    ] __main__: train step 8610: loss: 1.0555, policy_loss: 1.1805, value_loss: 0.7711
2024-07-11 16:29:59,283 [INFO    ] __main__: train step 8611: loss: 1.0555, policy_loss: 1.1805, value_loss: 0.7711
2024-07-11 16:29:59,487 [INFO    ] __main__: train step 8612: loss: 1.0555, policy_loss: 1.1804, value_loss: 0.7711
2024-07-11 16:29:59,731 [INFO    ] __main__: train step 8613: loss: 1.0555, policy_loss: 1.1803, value_loss: 0.7710
2024-07-11 16:29:59,960 [INFO    ] __main__: train step 8614: loss: 1.0555, policy_loss: 1.1803, value_loss: 0.7710
2024-07-11 16:30:00,160 [INFO    ] __main__: train step 8615: loss: 1.0555, policy_loss: 1.1802, value_loss: 0.7710
2024-07-11 16:30:00,371 [INFO    ] __main__: train step 8616: loss: 1.0555, policy_loss: 1.1801, value_loss: 0.7710
2024-07-11 16:30:00,564 [INFO    ] __main__: train step 8617: loss: 1.0555, policy_loss: 1.1800, value_loss: 0.7709
2024-07-11 16:30:01,615 [INFO    ] __main__: train step 8618: loss: 1.0555, policy_loss: 1.1800, value_loss: 0.7709
2024-07-11 16:30:03,101 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:30:03,475 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:30:03,531 [INFO    ] __main__: train step 8619: loss: 1.0555, policy_loss: 1.1799, value_loss: 0.7709
2024-07-11 16:30:03,704 [INFO    ] __main__: train step 8620: loss: 1.0555, policy_loss: 1.1798, value_loss: 0.7708
2024-07-11 16:30:03,918 [INFO    ] __main__: train step 8621: loss: 1.0555, policy_loss: 1.1797, value_loss: 0.7708
2024-07-11 16:30:04,119 [INFO    ] __main__: train step 8622: loss: 1.0555, policy_loss: 1.1797, value_loss: 0.7708
2024-07-11 16:30:04,318 [INFO    ] __main__: train step 8623: loss: 1.0555, policy_loss: 1.1796, value_loss: 0.7707
2024-07-11 16:30:04,516 [INFO    ] __main__: train step 8624: loss: 1.0555, policy_loss: 1.1795, value_loss: 0.7707
2024-07-11 16:30:04,712 [INFO    ] __main__: train step 8625: loss: 1.0555, policy_loss: 1.1795, value_loss: 0.7707
2024-07-11 16:30:04,926 [INFO    ] __main__: train step 8626: loss: 1.0555, policy_loss: 1.1794, value_loss: 0.7706
2024-07-11 16:30:05,136 [INFO    ] __main__: train step 8627: loss: 1.0555, policy_loss: 1.1793, value_loss: 0.7706
2024-07-11 16:30:05,339 [INFO    ] __main__: train step 8628: loss: 1.0555, policy_loss: 1.1792, value_loss: 0.7706
2024-07-11 16:30:05,542 [INFO    ] __main__: train step 8629: loss: 1.0555, policy_loss: 1.1792, value_loss: 0.7705
2024-07-11 16:30:05,766 [INFO    ] __main__: train step 8630: loss: 1.0555, policy_loss: 1.1791, value_loss: 0.7705
2024-07-11 16:30:06,005 [INFO    ] __main__: train step 8631: loss: 1.0555, policy_loss: 1.1790, value_loss: 0.7705
2024-07-11 16:30:06,209 [INFO    ] __main__: train step 8632: loss: 1.0555, policy_loss: 1.1789, value_loss: 0.7704
2024-07-11 16:30:06,417 [INFO    ] __main__: train step 8633: loss: 1.0555, policy_loss: 1.1789, value_loss: 0.7704
2024-07-11 16:30:06,623 [INFO    ] __main__: train step 8634: loss: 1.0555, policy_loss: 1.1788, value_loss: 0.7704
2024-07-11 16:30:06,828 [INFO    ] __main__: train step 8635: loss: 1.0555, policy_loss: 1.1787, value_loss: 0.7703
2024-07-11 16:30:08,275 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:30:08,684 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:30:08,743 [INFO    ] __main__: train step 8636: loss: 1.0555, policy_loss: 1.1787, value_loss: 0.7703
2024-07-11 16:30:08,906 [INFO    ] __main__: train step 8637: loss: 1.0555, policy_loss: 1.1786, value_loss: 0.7703
2024-07-11 16:30:09,109 [INFO    ] __main__: train step 8638: loss: 1.0555, policy_loss: 1.1785, value_loss: 0.7702
2024-07-11 16:30:09,316 [INFO    ] __main__: train step 8639: loss: 1.0555, policy_loss: 1.1784, value_loss: 0.7702
2024-07-11 16:30:09,515 [INFO    ] __main__: train step 8640: loss: 1.0555, policy_loss: 1.1784, value_loss: 0.7702
2024-07-11 16:30:09,712 [INFO    ] __main__: train step 8641: loss: 1.0555, policy_loss: 1.1783, value_loss: 0.7701
2024-07-11 16:30:09,912 [INFO    ] __main__: train step 8642: loss: 1.0555, policy_loss: 1.1782, value_loss: 0.7701
2024-07-11 16:30:10,114 [INFO    ] __main__: train step 8643: loss: 1.0555, policy_loss: 1.1781, value_loss: 0.7701
2024-07-11 16:30:10,309 [INFO    ] __main__: train step 8644: loss: 1.0555, policy_loss: 1.1781, value_loss: 0.7700
2024-07-11 16:30:10,517 [INFO    ] __main__: train step 8645: loss: 1.0555, policy_loss: 1.1780, value_loss: 0.7700
2024-07-11 16:30:10,707 [INFO    ] __main__: train step 8646: loss: 1.0555, policy_loss: 1.1779, value_loss: 0.7700
2024-07-11 16:30:10,925 [INFO    ] __main__: train step 8647: loss: 1.0555, policy_loss: 1.1779, value_loss: 0.7699
2024-07-11 16:30:11,148 [INFO    ] __main__: train step 8648: loss: 1.0555, policy_loss: 1.1778, value_loss: 0.7699
2024-07-11 16:30:11,358 [INFO    ] __main__: train step 8649: loss: 1.0555, policy_loss: 1.1777, value_loss: 0.7699
2024-07-11 16:30:11,574 [INFO    ] __main__: train step 8650: loss: 1.0555, policy_loss: 1.1776, value_loss: 0.7699
2024-07-11 16:30:11,809 [INFO    ] __main__: train step 8651: loss: 1.0555, policy_loss: 1.1776, value_loss: 0.7698
2024-07-11 16:30:12,038 [INFO    ] __main__: train step 8652: loss: 1.0555, policy_loss: 1.1775, value_loss: 0.7698
2024-07-11 16:30:13,485 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:30:13,867 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:30:13,929 [INFO    ] __main__: train step 8653: loss: 1.0554, policy_loss: 1.1774, value_loss: 0.7698
2024-07-11 16:30:14,112 [INFO    ] __main__: train step 8654: loss: 1.0554, policy_loss: 1.1773, value_loss: 0.7697
2024-07-11 16:30:14,310 [INFO    ] __main__: train step 8655: loss: 1.0554, policy_loss: 1.1773, value_loss: 0.7697
2024-07-11 16:30:14,515 [INFO    ] __main__: train step 8656: loss: 1.0554, policy_loss: 1.1772, value_loss: 0.7697
2024-07-11 16:30:14,735 [INFO    ] __main__: train step 8657: loss: 1.0554, policy_loss: 1.1771, value_loss: 0.7696
2024-07-11 16:30:14,950 [INFO    ] __main__: train step 8658: loss: 1.0554, policy_loss: 1.1771, value_loss: 0.7696
2024-07-11 16:30:15,144 [INFO    ] __main__: train step 8659: loss: 1.0554, policy_loss: 1.1770, value_loss: 0.7696
2024-07-11 16:30:15,346 [INFO    ] __main__: train step 8660: loss: 1.0554, policy_loss: 1.1769, value_loss: 0.7695
2024-07-11 16:30:15,535 [INFO    ] __main__: train step 8661: loss: 1.0554, policy_loss: 1.1768, value_loss: 0.7695
2024-07-11 16:30:15,747 [INFO    ] __main__: train step 8662: loss: 1.0554, policy_loss: 1.1768, value_loss: 0.7695
2024-07-11 16:30:15,940 [INFO    ] __main__: train step 8663: loss: 1.0554, policy_loss: 1.1767, value_loss: 0.7694
2024-07-11 16:30:16,157 [INFO    ] __main__: train step 8664: loss: 1.0554, policy_loss: 1.1766, value_loss: 0.7694
2024-07-11 16:30:16,393 [INFO    ] __main__: train step 8665: loss: 1.0554, policy_loss: 1.1765, value_loss: 0.7694
2024-07-11 16:30:16,591 [INFO    ] __main__: train step 8666: loss: 1.0554, policy_loss: 1.1765, value_loss: 0.7693
2024-07-11 16:30:16,784 [INFO    ] __main__: train step 8667: loss: 1.0554, policy_loss: 1.1764, value_loss: 0.7693
2024-07-11 16:30:17,004 [INFO    ] __main__: train step 8668: loss: 1.0554, policy_loss: 1.1763, value_loss: 0.7693
2024-07-11 16:30:17,202 [INFO    ] __main__: train step 8669: loss: 1.0554, policy_loss: 1.1763, value_loss: 0.7692
2024-07-11 16:30:18,666 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:30:19,062 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:30:19,123 [INFO    ] __main__: train step 8670: loss: 1.0554, policy_loss: 1.1762, value_loss: 0.7692
2024-07-11 16:30:19,291 [INFO    ] __main__: train step 8671: loss: 1.0554, policy_loss: 1.1761, value_loss: 0.7692
2024-07-11 16:30:19,501 [INFO    ] __main__: train step 8672: loss: 1.0554, policy_loss: 1.1760, value_loss: 0.7691
2024-07-11 16:30:19,704 [INFO    ] __main__: train step 8673: loss: 1.0554, policy_loss: 1.1760, value_loss: 0.7691
2024-07-11 16:30:19,932 [INFO    ] __main__: train step 8674: loss: 1.0554, policy_loss: 1.1759, value_loss: 0.7691
2024-07-11 16:30:20,154 [INFO    ] __main__: train step 8675: loss: 1.0554, policy_loss: 1.1758, value_loss: 0.7690
2024-07-11 16:30:20,371 [INFO    ] __main__: train step 8676: loss: 1.0554, policy_loss: 1.1757, value_loss: 0.7690
2024-07-11 16:30:20,577 [INFO    ] __main__: train step 8677: loss: 1.0554, policy_loss: 1.1757, value_loss: 0.7690
2024-07-11 16:30:20,815 [INFO    ] __main__: train step 8678: loss: 1.0554, policy_loss: 1.1756, value_loss: 0.7689
2024-07-11 16:30:21,051 [INFO    ] __main__: train step 8679: loss: 1.0554, policy_loss: 1.1755, value_loss: 0.7689
2024-07-11 16:30:21,286 [INFO    ] __main__: train step 8680: loss: 1.0554, policy_loss: 1.1755, value_loss: 0.7689
2024-07-11 16:30:21,498 [INFO    ] __main__: train step 8681: loss: 1.0554, policy_loss: 1.1754, value_loss: 0.7688
2024-07-11 16:30:21,726 [INFO    ] __main__: train step 8682: loss: 1.0554, policy_loss: 1.1753, value_loss: 0.7688
2024-07-11 16:30:21,926 [INFO    ] __main__: train step 8683: loss: 1.0554, policy_loss: 1.1752, value_loss: 0.7688
2024-07-11 16:30:22,131 [INFO    ] __main__: train step 8684: loss: 1.0553, policy_loss: 1.1752, value_loss: 0.7687
2024-07-11 16:30:22,343 [INFO    ] __main__: train step 8685: loss: 1.0553, policy_loss: 1.1751, value_loss: 0.7687
2024-07-11 16:30:22,575 [INFO    ] __main__: train step 8686: loss: 1.0553, policy_loss: 1.1750, value_loss: 0.7687
2024-07-11 16:30:24,004 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:30:24,387 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:30:24,445 [INFO    ] __main__: train step 8687: loss: 1.0553, policy_loss: 1.1750, value_loss: 0.7686
2024-07-11 16:30:24,614 [INFO    ] __main__: train step 8688: loss: 1.0553, policy_loss: 1.1749, value_loss: 0.7686
2024-07-11 16:30:24,826 [INFO    ] __main__: train step 8689: loss: 1.0553, policy_loss: 1.1748, value_loss: 0.7686
2024-07-11 16:30:25,034 [INFO    ] __main__: train step 8690: loss: 1.0553, policy_loss: 1.1747, value_loss: 0.7685
2024-07-11 16:30:26,081 [INFO    ] __main__: train step 8691: loss: 1.0553, policy_loss: 1.1747, value_loss: 0.7685
2024-07-11 16:30:26,296 [INFO    ] __main__: train step 8692: loss: 1.0553, policy_loss: 1.1746, value_loss: 0.7685
2024-07-11 16:30:26,511 [INFO    ] __main__: train step 8693: loss: 1.0553, policy_loss: 1.1745, value_loss: 0.7684
2024-07-11 16:30:26,732 [INFO    ] __main__: train step 8694: loss: 1.0553, policy_loss: 1.1745, value_loss: 0.7684
2024-07-11 16:30:26,967 [INFO    ] __main__: train step 8695: loss: 1.0553, policy_loss: 1.1744, value_loss: 0.7684
2024-07-11 16:30:27,166 [INFO    ] __main__: train step 8696: loss: 1.0553, policy_loss: 1.1743, value_loss: 0.7683
2024-07-11 16:30:27,386 [INFO    ] __main__: train step 8697: loss: 1.0553, policy_loss: 1.1742, value_loss: 0.7683
2024-07-11 16:30:27,587 [INFO    ] __main__: train step 8698: loss: 1.0553, policy_loss: 1.1742, value_loss: 0.7683
2024-07-11 16:30:27,790 [INFO    ] __main__: train step 8699: loss: 1.0553, policy_loss: 1.1741, value_loss: 0.7682
2024-07-11 16:30:28,002 [INFO    ] __main__: train step 8700: loss: 1.0553, policy_loss: 1.1740, value_loss: 0.7682
2024-07-11 16:30:28,219 [INFO    ] __main__: train step 8701: loss: 1.0553, policy_loss: 1.1740, value_loss: 0.7682
2024-07-11 16:30:28,420 [INFO    ] __main__: train step 8702: loss: 1.0553, policy_loss: 1.1739, value_loss: 0.7681
2024-07-11 16:30:28,661 [INFO    ] __main__: train step 8703: loss: 1.0553, policy_loss: 1.1738, value_loss: 0.7681
2024-07-11 16:30:30,107 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:30:30,553 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:30:30,612 [INFO    ] __main__: train step 8704: loss: 1.0553, policy_loss: 1.1737, value_loss: 0.7681
2024-07-11 16:30:30,790 [INFO    ] __main__: train step 8705: loss: 1.0553, policy_loss: 1.1737, value_loss: 0.7680
2024-07-11 16:30:30,978 [INFO    ] __main__: train step 8706: loss: 1.0553, policy_loss: 1.1736, value_loss: 0.7680
2024-07-11 16:30:31,193 [INFO    ] __main__: train step 8707: loss: 1.0553, policy_loss: 1.1735, value_loss: 0.7680
2024-07-11 16:30:31,402 [INFO    ] __main__: train step 8708: loss: 1.0553, policy_loss: 1.1734, value_loss: 0.7679
2024-07-11 16:30:31,604 [INFO    ] __main__: train step 8709: loss: 1.0553, policy_loss: 1.1734, value_loss: 0.7679
2024-07-11 16:30:31,838 [INFO    ] __main__: train step 8710: loss: 1.0553, policy_loss: 1.1733, value_loss: 0.7679
2024-07-11 16:30:32,054 [INFO    ] __main__: train step 8711: loss: 1.0553, policy_loss: 1.1732, value_loss: 0.7678
2024-07-11 16:30:32,287 [INFO    ] __main__: train step 8712: loss: 1.0553, policy_loss: 1.1732, value_loss: 0.7678
2024-07-11 16:30:32,528 [INFO    ] __main__: train step 8713: loss: 1.0553, policy_loss: 1.1731, value_loss: 0.7678
2024-07-11 16:30:32,768 [INFO    ] __main__: train step 8714: loss: 1.0553, policy_loss: 1.1730, value_loss: 0.7677
2024-07-11 16:30:32,972 [INFO    ] __main__: train step 8715: loss: 1.0552, policy_loss: 1.1729, value_loss: 0.7677
2024-07-11 16:30:33,190 [INFO    ] __main__: train step 8716: loss: 1.0552, policy_loss: 1.1729, value_loss: 0.7677
2024-07-11 16:30:33,404 [INFO    ] __main__: train step 8717: loss: 1.0552, policy_loss: 1.1728, value_loss: 0.7676
2024-07-11 16:30:33,620 [INFO    ] __main__: train step 8718: loss: 1.0552, policy_loss: 1.1727, value_loss: 0.7676
2024-07-11 16:30:33,849 [INFO    ] __main__: train step 8719: loss: 1.0552, policy_loss: 1.1727, value_loss: 0.7676
2024-07-11 16:30:34,050 [INFO    ] __main__: train step 8720: loss: 1.0552, policy_loss: 1.1726, value_loss: 0.7675
2024-07-11 16:30:35,492 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:30:35,863 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:30:35,919 [INFO    ] __main__: train step 8721: loss: 1.0552, policy_loss: 1.1725, value_loss: 0.7675
2024-07-11 16:30:36,095 [INFO    ] __main__: train step 8722: loss: 1.0552, policy_loss: 1.1724, value_loss: 0.7675
2024-07-11 16:30:36,292 [INFO    ] __main__: train step 8723: loss: 1.0552, policy_loss: 1.1724, value_loss: 0.7674
2024-07-11 16:30:36,501 [INFO    ] __main__: train step 8724: loss: 1.0552, policy_loss: 1.1723, value_loss: 0.7674
2024-07-11 16:30:36,704 [INFO    ] __main__: train step 8725: loss: 1.0552, policy_loss: 1.1722, value_loss: 0.7674
2024-07-11 16:30:36,904 [INFO    ] __main__: train step 8726: loss: 1.0552, policy_loss: 1.1722, value_loss: 0.7673
2024-07-11 16:30:37,108 [INFO    ] __main__: train step 8727: loss: 1.0552, policy_loss: 1.1721, value_loss: 0.7673
2024-07-11 16:30:37,304 [INFO    ] __main__: train step 8728: loss: 1.0552, policy_loss: 1.1720, value_loss: 0.7673
2024-07-11 16:30:37,511 [INFO    ] __main__: train step 8729: loss: 1.0552, policy_loss: 1.1719, value_loss: 0.7672
2024-07-11 16:30:37,723 [INFO    ] __main__: train step 8730: loss: 1.0552, policy_loss: 1.1719, value_loss: 0.7672
2024-07-11 16:30:37,968 [INFO    ] __main__: train step 8731: loss: 1.0552, policy_loss: 1.1718, value_loss: 0.7672
2024-07-11 16:30:38,194 [INFO    ] __main__: train step 8732: loss: 1.0552, policy_loss: 1.1717, value_loss: 0.7671
2024-07-11 16:30:38,396 [INFO    ] __main__: train step 8733: loss: 1.0552, policy_loss: 1.1716, value_loss: 0.7671
2024-07-11 16:30:38,602 [INFO    ] __main__: train step 8734: loss: 1.0552, policy_loss: 1.1716, value_loss: 0.7671
2024-07-11 16:30:38,807 [INFO    ] __main__: train step 8735: loss: 1.0552, policy_loss: 1.1715, value_loss: 0.7670
2024-07-11 16:30:39,012 [INFO    ] __main__: train step 8736: loss: 1.0552, policy_loss: 1.1714, value_loss: 0.7670
2024-07-11 16:30:39,215 [INFO    ] __main__: train step 8737: loss: 1.0551, policy_loss: 1.1714, value_loss: 0.7669
2024-07-11 16:30:40,662 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:30:41,044 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:30:41,100 [INFO    ] __main__: train step 8738: loss: 1.0551, policy_loss: 1.1713, value_loss: 0.7669
2024-07-11 16:30:41,277 [INFO    ] __main__: train step 8739: loss: 1.0551, policy_loss: 1.1712, value_loss: 0.7669
2024-07-11 16:30:41,473 [INFO    ] __main__: train step 8740: loss: 1.0551, policy_loss: 1.1711, value_loss: 0.7669
2024-07-11 16:30:41,684 [INFO    ] __main__: train step 8741: loss: 1.0551, policy_loss: 1.1711, value_loss: 0.7668
2024-07-11 16:30:41,917 [INFO    ] __main__: train step 8742: loss: 1.0551, policy_loss: 1.1710, value_loss: 0.7668
2024-07-11 16:30:42,120 [INFO    ] __main__: train step 8743: loss: 1.0551, policy_loss: 1.1709, value_loss: 0.7667
2024-07-11 16:30:42,314 [INFO    ] __main__: train step 8744: loss: 1.0551, policy_loss: 1.1709, value_loss: 0.7667
2024-07-11 16:30:42,522 [INFO    ] __main__: train step 8745: loss: 1.0551, policy_loss: 1.1708, value_loss: 0.7667
2024-07-11 16:30:42,725 [INFO    ] __main__: train step 8746: loss: 1.0551, policy_loss: 1.1707, value_loss: 0.7666
2024-07-11 16:30:42,922 [INFO    ] __main__: train step 8747: loss: 1.0551, policy_loss: 1.1706, value_loss: 0.7666
2024-07-11 16:30:43,124 [INFO    ] __main__: train step 8748: loss: 1.0551, policy_loss: 1.1706, value_loss: 0.7666
2024-07-11 16:30:43,327 [INFO    ] __main__: train step 8749: loss: 1.0551, policy_loss: 1.1705, value_loss: 0.7666
2024-07-11 16:30:43,518 [INFO    ] __main__: train step 8750: loss: 1.0551, policy_loss: 1.1704, value_loss: 0.7665
2024-07-11 16:30:43,740 [INFO    ] __main__: train step 8751: loss: 1.0551, policy_loss: 1.1704, value_loss: 0.7665
2024-07-11 16:30:43,944 [INFO    ] __main__: train step 8752: loss: 1.0551, policy_loss: 1.1703, value_loss: 0.7665
2024-07-11 16:30:44,148 [INFO    ] __main__: train step 8753: loss: 1.0551, policy_loss: 1.1702, value_loss: 0.7664
2024-07-11 16:30:44,345 [INFO    ] __main__: train step 8754: loss: 1.0551, policy_loss: 1.1701, value_loss: 0.7664
2024-07-11 16:30:45,781 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:30:46,163 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:30:46,218 [INFO    ] __main__: train step 8755: loss: 1.0551, policy_loss: 1.1701, value_loss: 0.7664
2024-07-11 16:30:46,386 [INFO    ] __main__: train step 8756: loss: 1.0551, policy_loss: 1.1700, value_loss: 0.7663
2024-07-11 16:30:46,613 [INFO    ] __main__: train step 8757: loss: 1.0551, policy_loss: 1.1699, value_loss: 0.7663
2024-07-11 16:30:46,808 [INFO    ] __main__: train step 8758: loss: 1.0551, policy_loss: 1.1698, value_loss: 0.7663
2024-07-11 16:30:47,023 [INFO    ] __main__: train step 8759: loss: 1.0551, policy_loss: 1.1698, value_loss: 0.7662
2024-07-11 16:30:47,250 [INFO    ] __main__: train step 8760: loss: 1.0550, policy_loss: 1.1697, value_loss: 0.7662
2024-07-11 16:30:47,485 [INFO    ] __main__: train step 8761: loss: 1.0550, policy_loss: 1.1696, value_loss: 0.7662
2024-07-11 16:30:47,702 [INFO    ] __main__: train step 8762: loss: 1.0550, policy_loss: 1.1696, value_loss: 0.7661
2024-07-11 16:30:47,946 [INFO    ] __main__: train step 8763: loss: 1.0550, policy_loss: 1.1695, value_loss: 0.7661
2024-07-11 16:30:48,150 [INFO    ] __main__: train step 8764: loss: 1.0550, policy_loss: 1.1694, value_loss: 0.7661
2024-07-11 16:30:49,186 [INFO    ] __main__: train step 8765: loss: 1.0550, policy_loss: 1.1693, value_loss: 0.7660
2024-07-11 16:30:49,411 [INFO    ] __main__: train step 8766: loss: 1.0550, policy_loss: 1.1693, value_loss: 0.7660
2024-07-11 16:30:49,617 [INFO    ] __main__: train step 8767: loss: 1.0550, policy_loss: 1.1692, value_loss: 0.7660
2024-07-11 16:30:49,822 [INFO    ] __main__: train step 8768: loss: 1.0550, policy_loss: 1.1691, value_loss: 0.7659
2024-07-11 16:30:50,042 [INFO    ] __main__: train step 8769: loss: 1.0550, policy_loss: 1.1691, value_loss: 0.7659
2024-07-11 16:30:50,282 [INFO    ] __main__: train step 8770: loss: 1.0550, policy_loss: 1.1690, value_loss: 0.7659
2024-07-11 16:30:50,518 [INFO    ] __main__: train step 8771: loss: 1.0550, policy_loss: 1.1689, value_loss: 0.7658
2024-07-11 16:30:51,957 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:30:52,319 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:30:52,381 [INFO    ] __main__: train step 8772: loss: 1.0550, policy_loss: 1.1688, value_loss: 0.7658
2024-07-11 16:30:52,557 [INFO    ] __main__: train step 8773: loss: 1.0550, policy_loss: 1.1688, value_loss: 0.7658
2024-07-11 16:30:52,762 [INFO    ] __main__: train step 8774: loss: 1.0550, policy_loss: 1.1687, value_loss: 0.7657
2024-07-11 16:30:52,963 [INFO    ] __main__: train step 8775: loss: 1.0550, policy_loss: 1.1686, value_loss: 0.7657
2024-07-11 16:30:53,190 [INFO    ] __main__: train step 8776: loss: 1.0550, policy_loss: 1.1686, value_loss: 0.7657
2024-07-11 16:30:53,415 [INFO    ] __main__: train step 8777: loss: 1.0550, policy_loss: 1.1685, value_loss: 0.7656
2024-07-11 16:30:53,609 [INFO    ] __main__: train step 8778: loss: 1.0550, policy_loss: 1.1684, value_loss: 0.7656
2024-07-11 16:30:53,826 [INFO    ] __main__: train step 8779: loss: 1.0550, policy_loss: 1.1683, value_loss: 0.7656
2024-07-11 16:30:54,034 [INFO    ] __main__: train step 8780: loss: 1.0550, policy_loss: 1.1683, value_loss: 0.7655
2024-07-11 16:30:54,239 [INFO    ] __main__: train step 8781: loss: 1.0550, policy_loss: 1.1682, value_loss: 0.7655
2024-07-11 16:30:54,428 [INFO    ] __main__: train step 8782: loss: 1.0550, policy_loss: 1.1681, value_loss: 0.7655
2024-07-11 16:30:54,627 [INFO    ] __main__: train step 8783: loss: 1.0550, policy_loss: 1.1681, value_loss: 0.7654
2024-07-11 16:30:54,818 [INFO    ] __main__: train step 8784: loss: 1.0549, policy_loss: 1.1680, value_loss: 0.7654
2024-07-11 16:30:55,019 [INFO    ] __main__: train step 8785: loss: 1.0549, policy_loss: 1.1679, value_loss: 0.7654
2024-07-11 16:30:55,229 [INFO    ] __main__: train step 8786: loss: 1.0549, policy_loss: 1.1678, value_loss: 0.7653
2024-07-11 16:30:55,425 [INFO    ] __main__: train step 8787: loss: 1.0549, policy_loss: 1.1678, value_loss: 0.7653
2024-07-11 16:30:55,628 [INFO    ] __main__: train step 8788: loss: 1.0549, policy_loss: 1.1677, value_loss: 0.7653
2024-07-11 16:30:57,071 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:30:57,414 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:30:57,473 [INFO    ] __main__: train step 8789: loss: 1.0549, policy_loss: 1.1676, value_loss: 0.7652
2024-07-11 16:30:57,650 [INFO    ] __main__: train step 8790: loss: 1.0549, policy_loss: 1.1676, value_loss: 0.7652
2024-07-11 16:30:57,857 [INFO    ] __main__: train step 8791: loss: 1.0549, policy_loss: 1.1675, value_loss: 0.7652
2024-07-11 16:30:58,060 [INFO    ] __main__: train step 8792: loss: 1.0549, policy_loss: 1.1674, value_loss: 0.7651
2024-07-11 16:30:58,267 [INFO    ] __main__: train step 8793: loss: 1.0549, policy_loss: 1.1673, value_loss: 0.7651
2024-07-11 16:30:58,468 [INFO    ] __main__: train step 8794: loss: 1.0549, policy_loss: 1.1673, value_loss: 0.7651
2024-07-11 16:30:58,676 [INFO    ] __main__: train step 8795: loss: 1.0549, policy_loss: 1.1672, value_loss: 0.7650
2024-07-11 16:30:58,873 [INFO    ] __main__: train step 8796: loss: 1.0549, policy_loss: 1.1671, value_loss: 0.7650
2024-07-11 16:30:59,078 [INFO    ] __main__: train step 8797: loss: 1.0549, policy_loss: 1.1671, value_loss: 0.7650
2024-07-11 16:30:59,284 [INFO    ] __main__: train step 8798: loss: 1.0549, policy_loss: 1.1670, value_loss: 0.7649
2024-07-11 16:30:59,503 [INFO    ] __main__: train step 8799: loss: 1.0549, policy_loss: 1.1669, value_loss: 0.7649
2024-07-11 16:30:59,706 [INFO    ] __main__: train step 8800: loss: 1.0549, policy_loss: 1.1668, value_loss: 0.7649
2024-07-11 16:30:59,913 [INFO    ] __main__: train step 8801: loss: 1.0549, policy_loss: 1.1668, value_loss: 0.7648
2024-07-11 16:31:00,118 [INFO    ] __main__: train step 8802: loss: 1.0549, policy_loss: 1.1667, value_loss: 0.7648
2024-07-11 16:31:00,322 [INFO    ] __main__: train step 8803: loss: 1.0549, policy_loss: 1.1666, value_loss: 0.7648
2024-07-11 16:31:00,529 [INFO    ] __main__: train step 8804: loss: 1.0549, policy_loss: 1.1666, value_loss: 0.7647
2024-07-11 16:31:00,732 [INFO    ] __main__: train step 8805: loss: 1.0549, policy_loss: 1.1665, value_loss: 0.7647
2024-07-11 16:31:02,165 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:31:02,519 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:31:02,573 [INFO    ] __main__: train step 8806: loss: 1.0549, policy_loss: 1.1664, value_loss: 0.7647
2024-07-11 16:31:02,757 [INFO    ] __main__: train step 8807: loss: 1.0548, policy_loss: 1.1663, value_loss: 0.7646
2024-07-11 16:31:02,998 [INFO    ] __main__: train step 8808: loss: 1.0548, policy_loss: 1.1663, value_loss: 0.7646
2024-07-11 16:31:03,207 [INFO    ] __main__: train step 8809: loss: 1.0548, policy_loss: 1.1662, value_loss: 0.7646
2024-07-11 16:31:03,411 [INFO    ] __main__: train step 8810: loss: 1.0548, policy_loss: 1.1661, value_loss: 0.7645
2024-07-11 16:31:03,622 [INFO    ] __main__: train step 8811: loss: 1.0548, policy_loss: 1.1661, value_loss: 0.7645
2024-07-11 16:31:03,819 [INFO    ] __main__: train step 8812: loss: 1.0548, policy_loss: 1.1660, value_loss: 0.7645
2024-07-11 16:31:04,026 [INFO    ] __main__: train step 8813: loss: 1.0548, policy_loss: 1.1659, value_loss: 0.7644
2024-07-11 16:31:04,225 [INFO    ] __main__: train step 8814: loss: 1.0548, policy_loss: 1.1658, value_loss: 0.7644
2024-07-11 16:31:04,446 [INFO    ] __main__: train step 8815: loss: 1.0548, policy_loss: 1.1658, value_loss: 0.7644
2024-07-11 16:31:04,667 [INFO    ] __main__: train step 8816: loss: 1.0548, policy_loss: 1.1657, value_loss: 0.7643
2024-07-11 16:31:04,869 [INFO    ] __main__: train step 8817: loss: 1.0548, policy_loss: 1.1656, value_loss: 0.7643
2024-07-11 16:31:05,088 [INFO    ] __main__: train step 8818: loss: 1.0548, policy_loss: 1.1656, value_loss: 0.7643
2024-07-11 16:31:05,337 [INFO    ] __main__: train step 8819: loss: 1.0548, policy_loss: 1.1655, value_loss: 0.7642
2024-07-11 16:31:05,568 [INFO    ] __main__: train step 8820: loss: 1.0548, policy_loss: 1.1654, value_loss: 0.7642
2024-07-11 16:31:05,773 [INFO    ] __main__: train step 8821: loss: 1.0548, policy_loss: 1.1654, value_loss: 0.7642
2024-07-11 16:31:05,981 [INFO    ] __main__: train step 8822: loss: 1.0548, policy_loss: 1.1653, value_loss: 0.7641
2024-07-11 16:31:07,417 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:31:07,805 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:31:07,865 [INFO    ] __main__: train step 8823: loss: 1.0548, policy_loss: 1.1652, value_loss: 0.7641
2024-07-11 16:31:08,061 [INFO    ] __main__: train step 8824: loss: 1.0548, policy_loss: 1.1651, value_loss: 0.7641
2024-07-11 16:31:08,268 [INFO    ] __main__: train step 8825: loss: 1.0548, policy_loss: 1.1651, value_loss: 0.7640
2024-07-11 16:31:08,503 [INFO    ] __main__: train step 8826: loss: 1.0548, policy_loss: 1.1650, value_loss: 0.7640
2024-07-11 16:31:08,704 [INFO    ] __main__: train step 8827: loss: 1.0548, policy_loss: 1.1649, value_loss: 0.7640
2024-07-11 16:31:08,909 [INFO    ] __main__: train step 8828: loss: 1.0548, policy_loss: 1.1649, value_loss: 0.7640
2024-07-11 16:31:09,099 [INFO    ] __main__: train step 8829: loss: 1.0547, policy_loss: 1.1648, value_loss: 0.7639
2024-07-11 16:31:09,302 [INFO    ] __main__: train step 8830: loss: 1.0547, policy_loss: 1.1647, value_loss: 0.7639
2024-07-11 16:31:09,495 [INFO    ] __main__: train step 8831: loss: 1.0547, policy_loss: 1.1646, value_loss: 0.7639
2024-07-11 16:31:09,701 [INFO    ] __main__: train step 8832: loss: 1.0547, policy_loss: 1.1646, value_loss: 0.7638
2024-07-11 16:31:09,893 [INFO    ] __main__: train step 8833: loss: 1.0547, policy_loss: 1.1645, value_loss: 0.7638
2024-07-11 16:31:10,114 [INFO    ] __main__: train step 8834: loss: 1.0547, policy_loss: 1.1644, value_loss: 0.7638
2024-07-11 16:31:10,345 [INFO    ] __main__: train step 8835: loss: 1.0547, policy_loss: 1.1644, value_loss: 0.7637
2024-07-11 16:31:10,543 [INFO    ] __main__: train step 8836: loss: 1.0547, policy_loss: 1.1643, value_loss: 0.7637
2024-07-11 16:31:10,741 [INFO    ] __main__: train step 8837: loss: 1.0547, policy_loss: 1.1642, value_loss: 0.7637
2024-07-11 16:31:10,954 [INFO    ] __main__: train step 8838: loss: 1.0547, policy_loss: 1.1641, value_loss: 0.7636
2024-07-11 16:31:12,016 [INFO    ] __main__: train step 8839: loss: 1.0547, policy_loss: 1.1641, value_loss: 0.7636
2024-07-11 16:31:13,468 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:31:13,854 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:31:13,912 [INFO    ] __main__: train step 8840: loss: 1.0547, policy_loss: 1.1640, value_loss: 0.7636
2024-07-11 16:31:14,090 [INFO    ] __main__: train step 8841: loss: 1.0547, policy_loss: 1.1639, value_loss: 0.7635
2024-07-11 16:31:14,307 [INFO    ] __main__: train step 8842: loss: 1.0547, policy_loss: 1.1639, value_loss: 0.7635
2024-07-11 16:31:14,506 [INFO    ] __main__: train step 8843: loss: 1.0547, policy_loss: 1.1638, value_loss: 0.7635
2024-07-11 16:31:14,710 [INFO    ] __main__: train step 8844: loss: 1.0547, policy_loss: 1.1637, value_loss: 0.7634
2024-07-11 16:31:14,902 [INFO    ] __main__: train step 8845: loss: 1.0547, policy_loss: 1.1636, value_loss: 0.7634
2024-07-11 16:31:15,102 [INFO    ] __main__: train step 8846: loss: 1.0547, policy_loss: 1.1636, value_loss: 0.7634
2024-07-11 16:31:15,313 [INFO    ] __main__: train step 8847: loss: 1.0547, policy_loss: 1.1635, value_loss: 0.7633
2024-07-11 16:31:15,515 [INFO    ] __main__: train step 8848: loss: 1.0546, policy_loss: 1.1634, value_loss: 0.7633
2024-07-11 16:31:15,712 [INFO    ] __main__: train step 8849: loss: 1.0546, policy_loss: 1.1634, value_loss: 0.7633
2024-07-11 16:31:15,908 [INFO    ] __main__: train step 8850: loss: 1.0546, policy_loss: 1.1633, value_loss: 0.7632
2024-07-11 16:31:16,115 [INFO    ] __main__: train step 8851: loss: 1.0546, policy_loss: 1.1632, value_loss: 0.7632
2024-07-11 16:31:16,318 [INFO    ] __main__: train step 8852: loss: 1.0546, policy_loss: 1.1631, value_loss: 0.7632
2024-07-11 16:31:16,550 [INFO    ] __main__: train step 8853: loss: 1.0546, policy_loss: 1.1631, value_loss: 0.7631
2024-07-11 16:31:16,758 [INFO    ] __main__: train step 8854: loss: 1.0546, policy_loss: 1.1630, value_loss: 0.7631
2024-07-11 16:31:16,966 [INFO    ] __main__: train step 8855: loss: 1.0546, policy_loss: 1.1629, value_loss: 0.7631
2024-07-11 16:31:17,208 [INFO    ] __main__: train step 8856: loss: 1.0546, policy_loss: 1.1629, value_loss: 0.7630
2024-07-11 16:31:18,643 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:31:19,045 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:31:19,105 [INFO    ] __main__: train step 8857: loss: 1.0546, policy_loss: 1.1628, value_loss: 0.7630
2024-07-11 16:31:19,274 [INFO    ] __main__: train step 8858: loss: 1.0546, policy_loss: 1.1627, value_loss: 0.7630
2024-07-11 16:31:19,475 [INFO    ] __main__: train step 8859: loss: 1.0546, policy_loss: 1.1626, value_loss: 0.7630
2024-07-11 16:31:19,684 [INFO    ] __main__: train step 8860: loss: 1.0546, policy_loss: 1.1626, value_loss: 0.7629
2024-07-11 16:31:19,890 [INFO    ] __main__: train step 8861: loss: 1.0546, policy_loss: 1.1625, value_loss: 0.7629
2024-07-11 16:31:20,101 [INFO    ] __main__: train step 8862: loss: 1.0546, policy_loss: 1.1624, value_loss: 0.7629
2024-07-11 16:31:20,298 [INFO    ] __main__: train step 8863: loss: 1.0546, policy_loss: 1.1624, value_loss: 0.7628
2024-07-11 16:31:20,503 [INFO    ] __main__: train step 8864: loss: 1.0546, policy_loss: 1.1623, value_loss: 0.7628
2024-07-11 16:31:20,733 [INFO    ] __main__: train step 8865: loss: 1.0546, policy_loss: 1.1622, value_loss: 0.7628
2024-07-11 16:31:20,964 [INFO    ] __main__: train step 8866: loss: 1.0546, policy_loss: 1.1621, value_loss: 0.7627
2024-07-11 16:31:21,172 [INFO    ] __main__: train step 8867: loss: 1.0546, policy_loss: 1.1621, value_loss: 0.7627
2024-07-11 16:31:21,383 [INFO    ] __main__: train step 8868: loss: 1.0545, policy_loss: 1.1620, value_loss: 0.7627
2024-07-11 16:31:21,586 [INFO    ] __main__: train step 8869: loss: 1.0545, policy_loss: 1.1619, value_loss: 0.7626
2024-07-11 16:31:21,785 [INFO    ] __main__: train step 8870: loss: 1.0545, policy_loss: 1.1619, value_loss: 0.7626
2024-07-11 16:31:22,010 [INFO    ] __main__: train step 8871: loss: 1.0545, policy_loss: 1.1618, value_loss: 0.7626
2024-07-11 16:31:22,206 [INFO    ] __main__: train step 8872: loss: 1.0545, policy_loss: 1.1617, value_loss: 0.7625
2024-07-11 16:31:22,407 [INFO    ] __main__: train step 8873: loss: 1.0545, policy_loss: 1.1616, value_loss: 0.7625
2024-07-11 16:31:23,863 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:31:24,260 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:31:24,323 [INFO    ] __main__: train step 8874: loss: 1.0545, policy_loss: 1.1616, value_loss: 0.7625
2024-07-11 16:31:24,498 [INFO    ] __main__: train step 8875: loss: 1.0545, policy_loss: 1.1615, value_loss: 0.7624
2024-07-11 16:31:24,706 [INFO    ] __main__: train step 8876: loss: 1.0545, policy_loss: 1.1614, value_loss: 0.7624
2024-07-11 16:31:24,911 [INFO    ] __main__: train step 8877: loss: 1.0545, policy_loss: 1.1614, value_loss: 0.7624
2024-07-11 16:31:25,130 [INFO    ] __main__: train step 8878: loss: 1.0545, policy_loss: 1.1613, value_loss: 0.7623
2024-07-11 16:31:25,332 [INFO    ] __main__: train step 8879: loss: 1.0545, policy_loss: 1.1612, value_loss: 0.7623
2024-07-11 16:31:25,526 [INFO    ] __main__: train step 8880: loss: 1.0545, policy_loss: 1.1612, value_loss: 0.7623
2024-07-11 16:31:25,732 [INFO    ] __main__: train step 8881: loss: 1.0545, policy_loss: 1.1611, value_loss: 0.7622
2024-07-11 16:31:25,946 [INFO    ] __main__: train step 8882: loss: 1.0545, policy_loss: 1.1610, value_loss: 0.7622
2024-07-11 16:31:26,149 [INFO    ] __main__: train step 8883: loss: 1.0545, policy_loss: 1.1609, value_loss: 0.7622
2024-07-11 16:31:26,366 [INFO    ] __main__: train step 8884: loss: 1.0545, policy_loss: 1.1609, value_loss: 0.7622
2024-07-11 16:31:26,572 [INFO    ] __main__: train step 8885: loss: 1.0545, policy_loss: 1.1608, value_loss: 0.7621
2024-07-11 16:31:26,785 [INFO    ] __main__: train step 8886: loss: 1.0545, policy_loss: 1.1607, value_loss: 0.7621
2024-07-11 16:31:26,991 [INFO    ] __main__: train step 8887: loss: 1.0545, policy_loss: 1.1607, value_loss: 0.7621
2024-07-11 16:31:27,189 [INFO    ] __main__: train step 8888: loss: 1.0545, policy_loss: 1.1606, value_loss: 0.7620
2024-07-11 16:31:27,397 [INFO    ] __main__: train step 8889: loss: 1.0545, policy_loss: 1.1605, value_loss: 0.7620
2024-07-11 16:31:27,604 [INFO    ] __main__: train step 8890: loss: 1.0544, policy_loss: 1.1605, value_loss: 0.7620
2024-07-11 16:31:29,057 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:31:29,417 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:31:29,476 [INFO    ] __main__: train step 8891: loss: 1.0544, policy_loss: 1.1604, value_loss: 0.7619
2024-07-11 16:31:29,649 [INFO    ] __main__: train step 8892: loss: 1.0544, policy_loss: 1.1603, value_loss: 0.7619
2024-07-11 16:31:29,844 [INFO    ] __main__: train step 8893: loss: 1.0544, policy_loss: 1.1602, value_loss: 0.7619
2024-07-11 16:31:30,046 [INFO    ] __main__: train step 8894: loss: 1.0544, policy_loss: 1.1602, value_loss: 0.7618
2024-07-11 16:31:30,241 [INFO    ] __main__: train step 8895: loss: 1.0544, policy_loss: 1.1601, value_loss: 0.7618
2024-07-11 16:31:30,443 [INFO    ] __main__: train step 8896: loss: 1.0544, policy_loss: 1.1600, value_loss: 0.7618
2024-07-11 16:31:30,677 [INFO    ] __main__: train step 8897: loss: 1.0544, policy_loss: 1.1600, value_loss: 0.7617
2024-07-11 16:31:30,875 [INFO    ] __main__: train step 8898: loss: 1.0544, policy_loss: 1.1599, value_loss: 0.7617
2024-07-11 16:31:31,082 [INFO    ] __main__: train step 8899: loss: 1.0544, policy_loss: 1.1598, value_loss: 0.7617
2024-07-11 16:31:31,281 [INFO    ] __main__: train step 8900: loss: 1.0544, policy_loss: 1.1597, value_loss: 0.7616
2024-07-11 16:31:31,476 [INFO    ] __main__: train step 8901: loss: 1.0544, policy_loss: 1.1597, value_loss: 0.7616
2024-07-11 16:31:31,679 [INFO    ] __main__: train step 8902: loss: 1.0544, policy_loss: 1.1596, value_loss: 0.7616
2024-07-11 16:31:31,871 [INFO    ] __main__: train step 8903: loss: 1.0544, policy_loss: 1.1595, value_loss: 0.7615
2024-07-11 16:31:32,085 [INFO    ] __main__: train step 8904: loss: 1.0544, policy_loss: 1.1595, value_loss: 0.7615
2024-07-11 16:31:32,281 [INFO    ] __main__: train step 8905: loss: 1.0544, policy_loss: 1.1594, value_loss: 0.7615
2024-07-11 16:31:32,491 [INFO    ] __main__: train step 8906: loss: 1.0544, policy_loss: 1.1593, value_loss: 0.7614
2024-07-11 16:31:32,690 [INFO    ] __main__: train step 8907: loss: 1.0543, policy_loss: 1.1592, value_loss: 0.7614
2024-07-11 16:31:34,119 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:31:34,503 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:31:34,572 [INFO    ] __main__: train step 8908: loss: 1.0543, policy_loss: 1.1592, value_loss: 0.7614
2024-07-11 16:31:34,745 [INFO    ] __main__: train step 8909: loss: 1.0543, policy_loss: 1.1591, value_loss: 0.7613
2024-07-11 16:31:34,959 [INFO    ] __main__: train step 8910: loss: 1.0543, policy_loss: 1.1590, value_loss: 0.7613
2024-07-11 16:31:35,163 [INFO    ] __main__: train step 8911: loss: 1.0543, policy_loss: 1.1590, value_loss: 0.7613
2024-07-11 16:31:35,365 [INFO    ] __main__: train step 8912: loss: 1.0543, policy_loss: 1.1589, value_loss: 0.7612
2024-07-11 16:31:36,437 [INFO    ] __main__: train step 8913: loss: 1.0543, policy_loss: 1.1588, value_loss: 0.7612
2024-07-11 16:31:36,643 [INFO    ] __main__: train step 8914: loss: 1.0543, policy_loss: 1.1588, value_loss: 0.7612
2024-07-11 16:31:36,845 [INFO    ] __main__: train step 8915: loss: 1.0543, policy_loss: 1.1587, value_loss: 0.7612
2024-07-11 16:31:37,052 [INFO    ] __main__: train step 8916: loss: 1.0543, policy_loss: 1.1586, value_loss: 0.7611
2024-07-11 16:31:37,253 [INFO    ] __main__: train step 8917: loss: 1.0543, policy_loss: 1.1585, value_loss: 0.7611
2024-07-11 16:31:37,458 [INFO    ] __main__: train step 8918: loss: 1.0543, policy_loss: 1.1585, value_loss: 0.7611
2024-07-11 16:31:37,668 [INFO    ] __main__: train step 8919: loss: 1.0543, policy_loss: 1.1584, value_loss: 0.7610
2024-07-11 16:31:37,874 [INFO    ] __main__: train step 8920: loss: 1.0543, policy_loss: 1.1583, value_loss: 0.7610
2024-07-11 16:31:38,087 [INFO    ] __main__: train step 8921: loss: 1.0543, policy_loss: 1.1583, value_loss: 0.7610
2024-07-11 16:31:38,299 [INFO    ] __main__: train step 8922: loss: 1.0543, policy_loss: 1.1582, value_loss: 0.7609
2024-07-11 16:31:38,496 [INFO    ] __main__: train step 8923: loss: 1.0543, policy_loss: 1.1581, value_loss: 0.7609
2024-07-11 16:31:38,698 [INFO    ] __main__: train step 8924: loss: 1.0543, policy_loss: 1.1580, value_loss: 0.7609
2024-07-11 16:31:40,135 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:31:40,474 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:31:40,530 [INFO    ] __main__: train step 8925: loss: 1.0542, policy_loss: 1.1580, value_loss: 0.7608
2024-07-11 16:31:40,715 [INFO    ] __main__: train step 8926: loss: 1.0542, policy_loss: 1.1579, value_loss: 0.7608
2024-07-11 16:31:40,960 [INFO    ] __main__: train step 8927: loss: 1.0542, policy_loss: 1.1578, value_loss: 0.7608
2024-07-11 16:31:41,192 [INFO    ] __main__: train step 8928: loss: 1.0542, policy_loss: 1.1578, value_loss: 0.7607
2024-07-11 16:31:41,408 [INFO    ] __main__: train step 8929: loss: 1.0542, policy_loss: 1.1577, value_loss: 0.7607
2024-07-11 16:31:41,641 [INFO    ] __main__: train step 8930: loss: 1.0542, policy_loss: 1.1576, value_loss: 0.7607
2024-07-11 16:31:41,868 [INFO    ] __main__: train step 8931: loss: 1.0542, policy_loss: 1.1576, value_loss: 0.7606
2024-07-11 16:31:42,065 [INFO    ] __main__: train step 8932: loss: 1.0542, policy_loss: 1.1575, value_loss: 0.7606
2024-07-11 16:31:42,276 [INFO    ] __main__: train step 8933: loss: 1.0542, policy_loss: 1.1574, value_loss: 0.7606
2024-07-11 16:31:42,474 [INFO    ] __main__: train step 8934: loss: 1.0542, policy_loss: 1.1573, value_loss: 0.7605
2024-07-11 16:31:42,677 [INFO    ] __main__: train step 8935: loss: 1.0542, policy_loss: 1.1573, value_loss: 0.7605
2024-07-11 16:31:42,886 [INFO    ] __main__: train step 8936: loss: 1.0542, policy_loss: 1.1572, value_loss: 0.7605
2024-07-11 16:31:43,079 [INFO    ] __main__: train step 8937: loss: 1.0542, policy_loss: 1.1571, value_loss: 0.7604
2024-07-11 16:31:43,278 [INFO    ] __main__: train step 8938: loss: 1.0542, policy_loss: 1.1571, value_loss: 0.7604
2024-07-11 16:31:43,480 [INFO    ] __main__: train step 8939: loss: 1.0541, policy_loss: 1.1570, value_loss: 0.7604
2024-07-11 16:31:43,676 [INFO    ] __main__: train step 8940: loss: 1.0541, policy_loss: 1.1569, value_loss: 0.7603
2024-07-11 16:31:43,891 [INFO    ] __main__: train step 8941: loss: 1.0541, policy_loss: 1.1568, value_loss: 0.7603
2024-07-11 16:31:45,369 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:31:45,718 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:31:45,776 [INFO    ] __main__: train step 8942: loss: 1.0541, policy_loss: 1.1568, value_loss: 0.7603
2024-07-11 16:31:45,940 [INFO    ] __main__: train step 8943: loss: 1.0541, policy_loss: 1.1567, value_loss: 0.7602
2024-07-11 16:31:46,142 [INFO    ] __main__: train step 8944: loss: 1.0541, policy_loss: 1.1566, value_loss: 0.7602
2024-07-11 16:31:46,351 [INFO    ] __main__: train step 8945: loss: 1.0541, policy_loss: 1.1566, value_loss: 0.7602
2024-07-11 16:31:46,554 [INFO    ] __main__: train step 8946: loss: 1.0541, policy_loss: 1.1565, value_loss: 0.7601
2024-07-11 16:31:46,765 [INFO    ] __main__: train step 8947: loss: 1.0541, policy_loss: 1.1564, value_loss: 0.7601
2024-07-11 16:31:46,969 [INFO    ] __main__: train step 8948: loss: 1.0541, policy_loss: 1.1564, value_loss: 0.7601
2024-07-11 16:31:47,189 [INFO    ] __main__: train step 8949: loss: 1.0541, policy_loss: 1.1563, value_loss: 0.7600
2024-07-11 16:31:47,413 [INFO    ] __main__: train step 8950: loss: 1.0541, policy_loss: 1.1562, value_loss: 0.7600
2024-07-11 16:31:47,627 [INFO    ] __main__: train step 8951: loss: 1.0541, policy_loss: 1.1561, value_loss: 0.7600
2024-07-11 16:31:47,831 [INFO    ] __main__: train step 8952: loss: 1.0541, policy_loss: 1.1561, value_loss: 0.7599
2024-07-11 16:31:48,037 [INFO    ] __main__: train step 8953: loss: 1.0541, policy_loss: 1.1560, value_loss: 0.7599
2024-07-11 16:31:48,244 [INFO    ] __main__: train step 8954: loss: 1.0541, policy_loss: 1.1559, value_loss: 0.7599
2024-07-11 16:31:48,459 [INFO    ] __main__: train step 8955: loss: 1.0540, policy_loss: 1.1559, value_loss: 0.7598
2024-07-11 16:31:48,663 [INFO    ] __main__: train step 8956: loss: 1.0540, policy_loss: 1.1558, value_loss: 0.7598
2024-07-11 16:31:48,860 [INFO    ] __main__: train step 8957: loss: 1.0540, policy_loss: 1.1557, value_loss: 0.7598
2024-07-11 16:31:49,079 [INFO    ] __main__: train step 8958: loss: 1.0540, policy_loss: 1.1557, value_loss: 0.7597
2024-07-11 16:31:50,525 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:31:51,049 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:31:51,102 [INFO    ] __main__: train step 8959: loss: 1.0540, policy_loss: 1.1556, value_loss: 0.7597
2024-07-11 16:31:51,278 [INFO    ] __main__: train step 8960: loss: 1.0540, policy_loss: 1.1555, value_loss: 0.7597
2024-07-11 16:31:51,490 [INFO    ] __main__: train step 8961: loss: 1.0540, policy_loss: 1.1554, value_loss: 0.7596
2024-07-11 16:31:51,686 [INFO    ] __main__: train step 8962: loss: 1.0540, policy_loss: 1.1554, value_loss: 0.7596
2024-07-11 16:31:51,888 [INFO    ] __main__: train step 8963: loss: 1.0540, policy_loss: 1.1553, value_loss: 0.7596
2024-07-11 16:31:52,082 [INFO    ] __main__: train step 8964: loss: 1.0540, policy_loss: 1.1552, value_loss: 0.7595
2024-07-11 16:31:52,283 [INFO    ] __main__: train step 8965: loss: 1.0540, policy_loss: 1.1552, value_loss: 0.7595
2024-07-11 16:31:52,498 [INFO    ] __main__: train step 8966: loss: 1.0540, policy_loss: 1.1551, value_loss: 0.7595
2024-07-11 16:31:52,703 [INFO    ] __main__: train step 8967: loss: 1.0540, policy_loss: 1.1550, value_loss: 0.7594
2024-07-11 16:31:52,901 [INFO    ] __main__: train step 8968: loss: 1.0539, policy_loss: 1.1550, value_loss: 0.7594
2024-07-11 16:31:53,117 [INFO    ] __main__: train step 8969: loss: 1.0539, policy_loss: 1.1549, value_loss: 0.7594
2024-07-11 16:31:53,320 [INFO    ] __main__: train step 8970: loss: 1.0539, policy_loss: 1.1548, value_loss: 0.7593
2024-07-11 16:31:53,534 [INFO    ] __main__: train step 8971: loss: 1.0539, policy_loss: 1.1547, value_loss: 0.7593
2024-07-11 16:31:53,745 [INFO    ] __main__: train step 8972: loss: 1.0539, policy_loss: 1.1547, value_loss: 0.7593
2024-07-11 16:31:53,975 [INFO    ] __main__: train step 8973: loss: 1.0539, policy_loss: 1.1546, value_loss: 0.7592
2024-07-11 16:31:54,173 [INFO    ] __main__: train step 8974: loss: 1.0539, policy_loss: 1.1545, value_loss: 0.7592
2024-07-11 16:31:54,378 [INFO    ] __main__: train step 8975: loss: 1.0539, policy_loss: 1.1545, value_loss: 0.7592
2024-07-11 16:31:55,836 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:31:56,262 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:31:56,319 [INFO    ] __main__: train step 8976: loss: 1.0539, policy_loss: 1.1544, value_loss: 0.7591
2024-07-11 16:31:56,493 [INFO    ] __main__: train step 8977: loss: 1.0539, policy_loss: 1.1543, value_loss: 0.7591
2024-07-11 16:31:56,711 [INFO    ] __main__: train step 8978: loss: 1.0539, policy_loss: 1.1543, value_loss: 0.7591
2024-07-11 16:31:56,939 [INFO    ] __main__: train step 8979: loss: 1.0539, policy_loss: 1.1542, value_loss: 0.7590
2024-07-11 16:31:57,142 [INFO    ] __main__: train step 8980: loss: 1.0539, policy_loss: 1.1541, value_loss: 0.7590
2024-07-11 16:31:57,357 [INFO    ] __main__: train step 8981: loss: 1.0539, policy_loss: 1.1540, value_loss: 0.7590
2024-07-11 16:31:57,554 [INFO    ] __main__: train step 8982: loss: 1.0539, policy_loss: 1.1540, value_loss: 0.7589
2024-07-11 16:31:57,756 [INFO    ] __main__: train step 8983: loss: 1.0538, policy_loss: 1.1539, value_loss: 0.7589
2024-07-11 16:31:57,961 [INFO    ] __main__: train step 8984: loss: 1.0538, policy_loss: 1.1538, value_loss: 0.7589
2024-07-11 16:31:58,157 [INFO    ] __main__: train step 8985: loss: 1.0538, policy_loss: 1.1538, value_loss: 0.7589
2024-07-11 16:31:59,246 [INFO    ] __main__: train step 8986: loss: 1.0538, policy_loss: 1.1537, value_loss: 0.7588
2024-07-11 16:31:59,460 [INFO    ] __main__: train step 8987: loss: 1.0538, policy_loss: 1.1536, value_loss: 0.7588
2024-07-11 16:31:59,661 [INFO    ] __main__: train step 8988: loss: 1.0538, policy_loss: 1.1536, value_loss: 0.7587
2024-07-11 16:31:59,866 [INFO    ] __main__: train step 8989: loss: 1.0538, policy_loss: 1.1535, value_loss: 0.7587
2024-07-11 16:32:00,066 [INFO    ] __main__: train step 8990: loss: 1.0538, policy_loss: 1.1534, value_loss: 0.7587
2024-07-11 16:32:00,268 [INFO    ] __main__: train step 8991: loss: 1.0538, policy_loss: 1.1534, value_loss: 0.7586
2024-07-11 16:32:00,481 [INFO    ] __main__: train step 8992: loss: 1.0538, policy_loss: 1.1533, value_loss: 0.7586
2024-07-11 16:32:01,914 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:32:02,465 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:32:02,524 [INFO    ] __main__: train step 8993: loss: 1.0538, policy_loss: 1.1532, value_loss: 0.7586
2024-07-11 16:32:02,724 [INFO    ] __main__: train step 8994: loss: 1.0538, policy_loss: 1.1531, value_loss: 0.7585
2024-07-11 16:32:03,051 [INFO    ] __main__: train step 8995: loss: 1.0537, policy_loss: 1.1531, value_loss: 0.7585
2024-07-11 16:32:03,273 [INFO    ] __main__: train step 8996: loss: 1.0537, policy_loss: 1.1530, value_loss: 0.7585
2024-07-11 16:32:03,487 [INFO    ] __main__: train step 8997: loss: 1.0537, policy_loss: 1.1529, value_loss: 0.7584
2024-07-11 16:32:03,733 [INFO    ] __main__: train step 8998: loss: 1.0537, policy_loss: 1.1529, value_loss: 0.7584
2024-07-11 16:32:04,623 [INFO    ] __main__: train step 8999: loss: 1.0537, policy_loss: 1.1528, value_loss: 0.7584
2024-07-11 16:32:04,945 [INFO    ] __main__: train step 9000: loss: 1.0537, policy_loss: 1.1527, value_loss: 0.7583
2024-07-11 16:32:05,091 [INFO    ] __main__: restored step 8000 for evaluation
2024-07-11 16:32:12,785 [INFO    ] __main__: later network ELO difference from earlier network: +250 (+8/-8) ELO from 32000 self-played games
2024-07-11 16:32:12,786 [INFO    ] __main__: game outcomes: W: 24423, D: 632, L: 6945
2024-07-11 16:32:12,787 [INFO    ] __main__: validation_elo_delta: 250, validation_elo: 1884
2024-07-11 16:32:13,293 [INFO    ] __main__: train step 9001: loss: 1.0537, policy_loss: 1.1526, value_loss: 0.7583
2024-07-11 16:32:13,498 [INFO    ] __main__: train step 9002: loss: 1.0537, policy_loss: 1.1526, value_loss: 0.7583
2024-07-11 16:32:13,699 [INFO    ] __main__: train step 9003: loss: 1.0537, policy_loss: 1.1525, value_loss: 0.7582
2024-07-11 16:32:13,903 [INFO    ] __main__: train step 9004: loss: 1.0537, policy_loss: 1.1524, value_loss: 0.7582
2024-07-11 16:32:14,110 [INFO    ] __main__: train step 9005: loss: 1.0537, policy_loss: 1.1524, value_loss: 0.7582
2024-07-11 16:32:14,343 [INFO    ] __main__: train step 9006: loss: 1.0537, policy_loss: 1.1523, value_loss: 0.7581
2024-07-11 16:32:14,542 [INFO    ] __main__: train step 9007: loss: 1.0536, policy_loss: 1.1522, value_loss: 0.7581
2024-07-11 16:32:14,741 [INFO    ] __main__: train step 9008: loss: 1.0536, policy_loss: 1.1522, value_loss: 0.7581
2024-07-11 16:32:14,935 [INFO    ] __main__: train step 9009: loss: 1.0536, policy_loss: 1.1521, value_loss: 0.7580
2024-07-11 16:32:16,372 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:32:16,779 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:32:16,838 [INFO    ] __main__: train step 9010: loss: 1.0536, policy_loss: 1.1520, value_loss: 0.7580
2024-07-11 16:32:17,025 [INFO    ] __main__: train step 9011: loss: 1.0536, policy_loss: 1.1520, value_loss: 0.7580
2024-07-11 16:32:17,268 [INFO    ] __main__: train step 9012: loss: 1.0536, policy_loss: 1.1519, value_loss: 0.7579
2024-07-11 16:32:17,464 [INFO    ] __main__: train step 9013: loss: 1.0536, policy_loss: 1.1518, value_loss: 0.7579
2024-07-11 16:32:17,664 [INFO    ] __main__: train step 9014: loss: 1.0536, policy_loss: 1.1517, value_loss: 0.7579
2024-07-11 16:32:17,858 [INFO    ] __main__: train step 9015: loss: 1.0536, policy_loss: 1.1517, value_loss: 0.7578
2024-07-11 16:32:18,061 [INFO    ] __main__: train step 9016: loss: 1.0536, policy_loss: 1.1516, value_loss: 0.7578
2024-07-11 16:32:18,261 [INFO    ] __main__: train step 9017: loss: 1.0536, policy_loss: 1.1515, value_loss: 0.7578
2024-07-11 16:32:18,461 [INFO    ] __main__: train step 9018: loss: 1.0536, policy_loss: 1.1515, value_loss: 0.7577
2024-07-11 16:32:18,657 [INFO    ] __main__: train step 9019: loss: 1.0535, policy_loss: 1.1514, value_loss: 0.7577
2024-07-11 16:32:18,850 [INFO    ] __main__: train step 9020: loss: 1.0535, policy_loss: 1.1513, value_loss: 0.7577
2024-07-11 16:32:19,051 [INFO    ] __main__: train step 9021: loss: 1.0535, policy_loss: 1.1513, value_loss: 0.7576
2024-07-11 16:32:19,248 [INFO    ] __main__: train step 9022: loss: 1.0535, policy_loss: 1.1512, value_loss: 0.7576
2024-07-11 16:32:19,455 [INFO    ] __main__: train step 9023: loss: 1.0535, policy_loss: 1.1511, value_loss: 0.7576
2024-07-11 16:32:19,650 [INFO    ] __main__: train step 9024: loss: 1.0535, policy_loss: 1.1510, value_loss: 0.7575
2024-07-11 16:32:19,848 [INFO    ] __main__: train step 9025: loss: 1.0535, policy_loss: 1.1510, value_loss: 0.7575
2024-07-11 16:32:20,080 [INFO    ] __main__: train step 9026: loss: 1.0535, policy_loss: 1.1509, value_loss: 0.7575
2024-07-11 16:32:21,555 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:32:21,935 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:32:21,993 [INFO    ] __main__: train step 9027: loss: 1.0535, policy_loss: 1.1508, value_loss: 0.7574
2024-07-11 16:32:22,171 [INFO    ] __main__: train step 9028: loss: 1.0535, policy_loss: 1.1508, value_loss: 0.7574
2024-07-11 16:32:22,384 [INFO    ] __main__: train step 9029: loss: 1.0535, policy_loss: 1.1507, value_loss: 0.7574
2024-07-11 16:32:22,585 [INFO    ] __main__: train step 9030: loss: 1.0535, policy_loss: 1.1506, value_loss: 0.7573
2024-07-11 16:32:22,800 [INFO    ] __main__: train step 9031: loss: 1.0535, policy_loss: 1.1506, value_loss: 0.7573
2024-07-11 16:32:23,006 [INFO    ] __main__: train step 9032: loss: 1.0534, policy_loss: 1.1505, value_loss: 0.7573
2024-07-11 16:32:23,222 [INFO    ] __main__: train step 9033: loss: 1.0534, policy_loss: 1.1504, value_loss: 0.7572
2024-07-11 16:32:23,435 [INFO    ] __main__: train step 9034: loss: 1.0534, policy_loss: 1.1504, value_loss: 0.7572
2024-07-11 16:32:23,637 [INFO    ] __main__: train step 9035: loss: 1.0534, policy_loss: 1.1503, value_loss: 0.7572
2024-07-11 16:32:23,849 [INFO    ] __main__: train step 9036: loss: 1.0534, policy_loss: 1.1502, value_loss: 0.7571
2024-07-11 16:32:24,051 [INFO    ] __main__: train step 9037: loss: 1.0534, policy_loss: 1.1501, value_loss: 0.7571
2024-07-11 16:32:24,253 [INFO    ] __main__: train step 9038: loss: 1.0534, policy_loss: 1.1501, value_loss: 0.7571
2024-07-11 16:32:24,458 [INFO    ] __main__: train step 9039: loss: 1.0534, policy_loss: 1.1500, value_loss: 0.7570
2024-07-11 16:32:24,667 [INFO    ] __main__: train step 9040: loss: 1.0534, policy_loss: 1.1499, value_loss: 0.7570
2024-07-11 16:32:24,861 [INFO    ] __main__: train step 9041: loss: 1.0534, policy_loss: 1.1499, value_loss: 0.7570
2024-07-11 16:32:25,062 [INFO    ] __main__: train step 9042: loss: 1.0534, policy_loss: 1.1498, value_loss: 0.7569
2024-07-11 16:32:25,256 [INFO    ] __main__: train step 9043: loss: 1.0534, policy_loss: 1.1497, value_loss: 0.7569
2024-07-11 16:32:26,699 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:32:27,086 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:32:27,144 [INFO    ] __main__: train step 9044: loss: 1.0533, policy_loss: 1.1497, value_loss: 0.7569
2024-07-11 16:32:27,324 [INFO    ] __main__: train step 9045: loss: 1.0533, policy_loss: 1.1496, value_loss: 0.7568
2024-07-11 16:32:27,522 [INFO    ] __main__: train step 9046: loss: 1.0533, policy_loss: 1.1495, value_loss: 0.7568
2024-07-11 16:32:27,727 [INFO    ] __main__: train step 9047: loss: 1.0533, policy_loss: 1.1495, value_loss: 0.7568
2024-07-11 16:32:27,938 [INFO    ] __main__: train step 9048: loss: 1.0533, policy_loss: 1.1494, value_loss: 0.7567
2024-07-11 16:32:28,139 [INFO    ] __main__: train step 9049: loss: 1.0533, policy_loss: 1.1493, value_loss: 0.7567
2024-07-11 16:32:28,347 [INFO    ] __main__: train step 9050: loss: 1.0533, policy_loss: 1.1492, value_loss: 0.7567
2024-07-11 16:32:28,559 [INFO    ] __main__: train step 9051: loss: 1.0533, policy_loss: 1.1492, value_loss: 0.7566
2024-07-11 16:32:28,764 [INFO    ] __main__: train step 9052: loss: 1.0533, policy_loss: 1.1491, value_loss: 0.7566
2024-07-11 16:32:28,977 [INFO    ] __main__: train step 9053: loss: 1.0533, policy_loss: 1.1490, value_loss: 0.7566
2024-07-11 16:32:29,191 [INFO    ] __main__: train step 9054: loss: 1.0533, policy_loss: 1.1490, value_loss: 0.7565
2024-07-11 16:32:29,426 [INFO    ] __main__: train step 9055: loss: 1.0533, policy_loss: 1.1489, value_loss: 0.7565
2024-07-11 16:32:29,630 [INFO    ] __main__: train step 9056: loss: 1.0533, policy_loss: 1.1488, value_loss: 0.7565
2024-07-11 16:32:29,854 [INFO    ] __main__: train step 9057: loss: 1.0532, policy_loss: 1.1488, value_loss: 0.7564
2024-07-11 16:32:30,085 [INFO    ] __main__: train step 9058: loss: 1.0532, policy_loss: 1.1487, value_loss: 0.7564
2024-07-11 16:32:30,304 [INFO    ] __main__: train step 9059: loss: 1.0532, policy_loss: 1.1486, value_loss: 0.7564
2024-07-11 16:32:31,331 [INFO    ] __main__: train step 9060: loss: 1.0532, policy_loss: 1.1486, value_loss: 0.7563
2024-07-11 16:32:32,777 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:32:33,194 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:32:33,251 [INFO    ] __main__: train step 9061: loss: 1.0532, policy_loss: 1.1485, value_loss: 0.7563
2024-07-11 16:32:33,422 [INFO    ] __main__: train step 9062: loss: 1.0532, policy_loss: 1.1484, value_loss: 0.7563
2024-07-11 16:32:33,615 [INFO    ] __main__: train step 9063: loss: 1.0532, policy_loss: 1.1484, value_loss: 0.7562
2024-07-11 16:32:33,816 [INFO    ] __main__: train step 9064: loss: 1.0532, policy_loss: 1.1483, value_loss: 0.7562
2024-07-11 16:32:34,015 [INFO    ] __main__: train step 9065: loss: 1.0532, policy_loss: 1.1482, value_loss: 0.7562
2024-07-11 16:32:34,219 [INFO    ] __main__: train step 9066: loss: 1.0532, policy_loss: 1.1481, value_loss: 0.7561
2024-07-11 16:32:34,413 [INFO    ] __main__: train step 9067: loss: 1.0532, policy_loss: 1.1481, value_loss: 0.7561
2024-07-11 16:32:34,608 [INFO    ] __main__: train step 9068: loss: 1.0531, policy_loss: 1.1480, value_loss: 0.7561
2024-07-11 16:32:34,814 [INFO    ] __main__: train step 9069: loss: 1.0531, policy_loss: 1.1479, value_loss: 0.7560
2024-07-11 16:32:35,039 [INFO    ] __main__: train step 9070: loss: 1.0531, policy_loss: 1.1479, value_loss: 0.7560
2024-07-11 16:32:35,231 [INFO    ] __main__: train step 9071: loss: 1.0531, policy_loss: 1.1478, value_loss: 0.7560
2024-07-11 16:32:35,441 [INFO    ] __main__: train step 9072: loss: 1.0531, policy_loss: 1.1477, value_loss: 0.7559
2024-07-11 16:32:35,641 [INFO    ] __main__: train step 9073: loss: 1.0531, policy_loss: 1.1477, value_loss: 0.7559
2024-07-11 16:32:35,849 [INFO    ] __main__: train step 9074: loss: 1.0531, policy_loss: 1.1476, value_loss: 0.7559
2024-07-11 16:32:36,044 [INFO    ] __main__: train step 9075: loss: 1.0531, policy_loss: 1.1475, value_loss: 0.7558
2024-07-11 16:32:36,245 [INFO    ] __main__: train step 9076: loss: 1.0531, policy_loss: 1.1475, value_loss: 0.7558
2024-07-11 16:32:36,447 [INFO    ] __main__: train step 9077: loss: 1.0531, policy_loss: 1.1474, value_loss: 0.7558
2024-07-11 16:32:37,881 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:32:38,293 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:32:38,351 [INFO    ] __main__: train step 9078: loss: 1.0531, policy_loss: 1.1473, value_loss: 0.7557
2024-07-11 16:32:38,523 [INFO    ] __main__: train step 9079: loss: 1.0531, policy_loss: 1.1473, value_loss: 0.7557
2024-07-11 16:32:38,744 [INFO    ] __main__: train step 9080: loss: 1.0530, policy_loss: 1.1472, value_loss: 0.7557
2024-07-11 16:32:38,946 [INFO    ] __main__: train step 9081: loss: 1.0530, policy_loss: 1.1471, value_loss: 0.7556
2024-07-11 16:32:39,152 [INFO    ] __main__: train step 9082: loss: 1.0530, policy_loss: 1.1470, value_loss: 0.7556
2024-07-11 16:32:39,355 [INFO    ] __main__: train step 9083: loss: 1.0530, policy_loss: 1.1470, value_loss: 0.7556
2024-07-11 16:32:39,558 [INFO    ] __main__: train step 9084: loss: 1.0530, policy_loss: 1.1469, value_loss: 0.7555
2024-07-11 16:32:39,772 [INFO    ] __main__: train step 9085: loss: 1.0530, policy_loss: 1.1468, value_loss: 0.7555
2024-07-11 16:32:39,978 [INFO    ] __main__: train step 9086: loss: 1.0530, policy_loss: 1.1468, value_loss: 0.7555
2024-07-11 16:32:40,205 [INFO    ] __main__: train step 9087: loss: 1.0530, policy_loss: 1.1467, value_loss: 0.7554
2024-07-11 16:32:40,405 [INFO    ] __main__: train step 9088: loss: 1.0530, policy_loss: 1.1466, value_loss: 0.7554
2024-07-11 16:32:40,617 [INFO    ] __main__: train step 9089: loss: 1.0530, policy_loss: 1.1466, value_loss: 0.7554
2024-07-11 16:32:40,826 [INFO    ] __main__: train step 9090: loss: 1.0529, policy_loss: 1.1465, value_loss: 0.7553
2024-07-11 16:32:41,054 [INFO    ] __main__: train step 9091: loss: 1.0529, policy_loss: 1.1464, value_loss: 0.7553
2024-07-11 16:32:41,256 [INFO    ] __main__: train step 9092: loss: 1.0529, policy_loss: 1.1464, value_loss: 0.7553
2024-07-11 16:32:41,451 [INFO    ] __main__: train step 9093: loss: 1.0529, policy_loss: 1.1463, value_loss: 0.7552
2024-07-11 16:32:41,657 [INFO    ] __main__: train step 9094: loss: 1.0529, policy_loss: 1.1462, value_loss: 0.7552
2024-07-11 16:32:43,087 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:32:43,499 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:32:43,561 [INFO    ] __main__: train step 9095: loss: 1.0529, policy_loss: 1.1461, value_loss: 0.7552
2024-07-11 16:32:43,734 [INFO    ] __main__: train step 9096: loss: 1.0529, policy_loss: 1.1461, value_loss: 0.7551
2024-07-11 16:32:43,931 [INFO    ] __main__: train step 9097: loss: 1.0529, policy_loss: 1.1460, value_loss: 0.7551
2024-07-11 16:32:44,144 [INFO    ] __main__: train step 9098: loss: 1.0529, policy_loss: 1.1459, value_loss: 0.7551
2024-07-11 16:32:44,345 [INFO    ] __main__: train step 9099: loss: 1.0529, policy_loss: 1.1459, value_loss: 0.7550
2024-07-11 16:32:44,550 [INFO    ] __main__: train step 9100: loss: 1.0529, policy_loss: 1.1458, value_loss: 0.7550
2024-07-11 16:32:44,772 [INFO    ] __main__: train step 9101: loss: 1.0528, policy_loss: 1.1457, value_loss: 0.7550
2024-07-11 16:32:44,977 [INFO    ] __main__: train step 9102: loss: 1.0528, policy_loss: 1.1457, value_loss: 0.7549
2024-07-11 16:32:45,180 [INFO    ] __main__: train step 9103: loss: 1.0528, policy_loss: 1.1456, value_loss: 0.7549
2024-07-11 16:32:45,415 [INFO    ] __main__: train step 9104: loss: 1.0528, policy_loss: 1.1455, value_loss: 0.7549
2024-07-11 16:32:45,623 [INFO    ] __main__: train step 9105: loss: 1.0528, policy_loss: 1.1455, value_loss: 0.7548
2024-07-11 16:32:45,823 [INFO    ] __main__: train step 9106: loss: 1.0528, policy_loss: 1.1454, value_loss: 0.7548
2024-07-11 16:32:46,029 [INFO    ] __main__: train step 9107: loss: 1.0528, policy_loss: 1.1453, value_loss: 0.7548
2024-07-11 16:32:46,237 [INFO    ] __main__: train step 9108: loss: 1.0528, policy_loss: 1.1452, value_loss: 0.7547
2024-07-11 16:32:46,475 [INFO    ] __main__: train step 9109: loss: 1.0528, policy_loss: 1.1452, value_loss: 0.7547
2024-07-11 16:32:46,681 [INFO    ] __main__: train step 9110: loss: 1.0528, policy_loss: 1.1451, value_loss: 0.7547
2024-07-11 16:32:46,899 [INFO    ] __main__: train step 9111: loss: 1.0527, policy_loss: 1.1450, value_loss: 0.7546
2024-07-11 16:32:48,344 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:32:48,716 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:32:48,771 [INFO    ] __main__: train step 9112: loss: 1.0527, policy_loss: 1.1450, value_loss: 0.7546
2024-07-11 16:32:48,949 [INFO    ] __main__: train step 9113: loss: 1.0527, policy_loss: 1.1449, value_loss: 0.7546
2024-07-11 16:32:49,159 [INFO    ] __main__: train step 9114: loss: 1.0527, policy_loss: 1.1448, value_loss: 0.7545
2024-07-11 16:32:49,357 [INFO    ] __main__: train step 9115: loss: 1.0527, policy_loss: 1.1448, value_loss: 0.7545
2024-07-11 16:32:49,560 [INFO    ] __main__: train step 9116: loss: 1.0527, policy_loss: 1.1447, value_loss: 0.7544
2024-07-11 16:32:49,761 [INFO    ] __main__: train step 9117: loss: 1.0527, policy_loss: 1.1446, value_loss: 0.7544
2024-07-11 16:32:49,971 [INFO    ] __main__: train step 9118: loss: 1.0527, policy_loss: 1.1446, value_loss: 0.7544
2024-07-11 16:32:50,176 [INFO    ] __main__: train step 9119: loss: 1.0527, policy_loss: 1.1445, value_loss: 0.7543
2024-07-11 16:32:50,389 [INFO    ] __main__: train step 9120: loss: 1.0526, policy_loss: 1.1444, value_loss: 0.7543
2024-07-11 16:32:50,605 [INFO    ] __main__: train step 9121: loss: 1.0526, policy_loss: 1.1443, value_loss: 0.7543
2024-07-11 16:32:50,819 [INFO    ] __main__: train step 9122: loss: 1.0526, policy_loss: 1.1443, value_loss: 0.7542
2024-07-11 16:32:51,016 [INFO    ] __main__: train step 9123: loss: 1.0526, policy_loss: 1.1442, value_loss: 0.7542
2024-07-11 16:32:51,244 [INFO    ] __main__: train step 9124: loss: 1.0526, policy_loss: 1.1441, value_loss: 0.7542
2024-07-11 16:32:51,465 [INFO    ] __main__: train step 9125: loss: 1.0526, policy_loss: 1.1441, value_loss: 0.7541
2024-07-11 16:32:51,671 [INFO    ] __main__: train step 9126: loss: 1.0526, policy_loss: 1.1440, value_loss: 0.7541
2024-07-11 16:32:51,874 [INFO    ] __main__: train step 9127: loss: 1.0526, policy_loss: 1.1439, value_loss: 0.7541
2024-07-11 16:32:52,060 [INFO    ] __main__: train step 9128: loss: 1.0526, policy_loss: 1.1439, value_loss: 0.7540
2024-07-11 16:32:53,499 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:32:53,921 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:32:53,983 [INFO    ] __main__: train step 9129: loss: 1.0526, policy_loss: 1.1438, value_loss: 0.7540
2024-07-11 16:32:54,156 [INFO    ] __main__: train step 9130: loss: 1.0525, policy_loss: 1.1437, value_loss: 0.7540
2024-07-11 16:32:54,373 [INFO    ] __main__: train step 9131: loss: 1.0525, policy_loss: 1.1437, value_loss: 0.7539
2024-07-11 16:32:54,598 [INFO    ] __main__: train step 9132: loss: 1.0525, policy_loss: 1.1436, value_loss: 0.7539
2024-07-11 16:32:55,618 [INFO    ] __main__: train step 9133: loss: 1.0525, policy_loss: 1.1435, value_loss: 0.7539
2024-07-11 16:32:55,828 [INFO    ] __main__: train step 9134: loss: 1.0525, policy_loss: 1.1435, value_loss: 0.7538
2024-07-11 16:32:56,039 [INFO    ] __main__: train step 9135: loss: 1.0525, policy_loss: 1.1434, value_loss: 0.7538
2024-07-11 16:32:56,246 [INFO    ] __main__: train step 9136: loss: 1.0525, policy_loss: 1.1433, value_loss: 0.7538
2024-07-11 16:32:56,451 [INFO    ] __main__: train step 9137: loss: 1.0525, policy_loss: 1.1432, value_loss: 0.7537
2024-07-11 16:32:56,659 [INFO    ] __main__: train step 9138: loss: 1.0525, policy_loss: 1.1432, value_loss: 0.7537
2024-07-11 16:32:56,860 [INFO    ] __main__: train step 9139: loss: 1.0525, policy_loss: 1.1431, value_loss: 0.7537
2024-07-11 16:32:57,060 [INFO    ] __main__: train step 9140: loss: 1.0524, policy_loss: 1.1430, value_loss: 0.7536
2024-07-11 16:32:57,267 [INFO    ] __main__: train step 9141: loss: 1.0524, policy_loss: 1.1430, value_loss: 0.7536
2024-07-11 16:32:57,463 [INFO    ] __main__: train step 9142: loss: 1.0524, policy_loss: 1.1429, value_loss: 0.7536
2024-07-11 16:32:57,672 [INFO    ] __main__: train step 9143: loss: 1.0524, policy_loss: 1.1428, value_loss: 0.7535
2024-07-11 16:32:57,880 [INFO    ] __main__: train step 9144: loss: 1.0524, policy_loss: 1.1428, value_loss: 0.7535
2024-07-11 16:32:58,078 [INFO    ] __main__: train step 9145: loss: 1.0524, policy_loss: 1.1427, value_loss: 0.7535
2024-07-11 16:32:59,506 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:32:59,879 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:32:59,936 [INFO    ] __main__: train step 9146: loss: 1.0524, policy_loss: 1.1426, value_loss: 0.7534
2024-07-11 16:33:00,103 [INFO    ] __main__: train step 9147: loss: 1.0524, policy_loss: 1.1426, value_loss: 0.7534
2024-07-11 16:33:00,306 [INFO    ] __main__: train step 9148: loss: 1.0524, policy_loss: 1.1425, value_loss: 0.7534
2024-07-11 16:33:00,509 [INFO    ] __main__: train step 9149: loss: 1.0523, policy_loss: 1.1424, value_loss: 0.7533
2024-07-11 16:33:00,710 [INFO    ] __main__: train step 9150: loss: 1.0523, policy_loss: 1.1424, value_loss: 0.7533
2024-07-11 16:33:00,909 [INFO    ] __main__: train step 9151: loss: 1.0523, policy_loss: 1.1423, value_loss: 0.7533
2024-07-11 16:33:01,111 [INFO    ] __main__: train step 9152: loss: 1.0523, policy_loss: 1.1422, value_loss: 0.7532
2024-07-11 16:33:01,320 [INFO    ] __main__: train step 9153: loss: 1.0523, policy_loss: 1.1421, value_loss: 0.7532
2024-07-11 16:33:01,520 [INFO    ] __main__: train step 9154: loss: 1.0523, policy_loss: 1.1421, value_loss: 0.7531
2024-07-11 16:33:01,723 [INFO    ] __main__: train step 9155: loss: 1.0523, policy_loss: 1.1420, value_loss: 0.7531
2024-07-11 16:33:01,942 [INFO    ] __main__: train step 9156: loss: 1.0523, policy_loss: 1.1419, value_loss: 0.7531
2024-07-11 16:33:02,168 [INFO    ] __main__: train step 9157: loss: 1.0522, policy_loss: 1.1419, value_loss: 0.7530
2024-07-11 16:33:02,371 [INFO    ] __main__: train step 9158: loss: 1.0522, policy_loss: 1.1418, value_loss: 0.7530
2024-07-11 16:33:02,584 [INFO    ] __main__: train step 9159: loss: 1.0522, policy_loss: 1.1417, value_loss: 0.7530
2024-07-11 16:33:02,790 [INFO    ] __main__: train step 9160: loss: 1.0522, policy_loss: 1.1417, value_loss: 0.7529
2024-07-11 16:33:02,990 [INFO    ] __main__: train step 9161: loss: 1.0522, policy_loss: 1.1416, value_loss: 0.7529
2024-07-11 16:33:03,196 [INFO    ] __main__: train step 9162: loss: 1.0522, policy_loss: 1.1415, value_loss: 0.7529
2024-07-11 16:33:04,630 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:33:05,022 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:33:05,079 [INFO    ] __main__: train step 9163: loss: 1.0522, policy_loss: 1.1415, value_loss: 0.7528
2024-07-11 16:33:05,262 [INFO    ] __main__: train step 9164: loss: 1.0522, policy_loss: 1.1414, value_loss: 0.7528
2024-07-11 16:33:05,498 [INFO    ] __main__: train step 9165: loss: 1.0522, policy_loss: 1.1413, value_loss: 0.7528
2024-07-11 16:33:05,701 [INFO    ] __main__: train step 9166: loss: 1.0521, policy_loss: 1.1412, value_loss: 0.7527
2024-07-11 16:33:05,906 [INFO    ] __main__: train step 9167: loss: 1.0521, policy_loss: 1.1412, value_loss: 0.7527
2024-07-11 16:33:06,103 [INFO    ] __main__: train step 9168: loss: 1.0521, policy_loss: 1.1411, value_loss: 0.7527
2024-07-11 16:33:06,307 [INFO    ] __main__: train step 9169: loss: 1.0521, policy_loss: 1.1410, value_loss: 0.7526
2024-07-11 16:33:06,517 [INFO    ] __main__: train step 9170: loss: 1.0521, policy_loss: 1.1410, value_loss: 0.7526
2024-07-11 16:33:06,718 [INFO    ] __main__: train step 9171: loss: 1.0521, policy_loss: 1.1409, value_loss: 0.7526
2024-07-11 16:33:06,920 [INFO    ] __main__: train step 9172: loss: 1.0521, policy_loss: 1.1408, value_loss: 0.7525
2024-07-11 16:33:07,122 [INFO    ] __main__: train step 9173: loss: 1.0521, policy_loss: 1.1408, value_loss: 0.7525
2024-07-11 16:33:07,345 [INFO    ] __main__: train step 9174: loss: 1.0521, policy_loss: 1.1407, value_loss: 0.7525
2024-07-11 16:33:07,547 [INFO    ] __main__: train step 9175: loss: 1.0520, policy_loss: 1.1406, value_loss: 0.7524
2024-07-11 16:33:07,742 [INFO    ] __main__: train step 9176: loss: 1.0520, policy_loss: 1.1406, value_loss: 0.7524
2024-07-11 16:33:07,956 [INFO    ] __main__: train step 9177: loss: 1.0520, policy_loss: 1.1405, value_loss: 0.7523
2024-07-11 16:33:08,156 [INFO    ] __main__: train step 9178: loss: 1.0520, policy_loss: 1.1404, value_loss: 0.7523
2024-07-11 16:33:08,363 [INFO    ] __main__: train step 9179: loss: 1.0520, policy_loss: 1.1404, value_loss: 0.7523
2024-07-11 16:33:09,798 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:33:10,193 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:33:10,248 [INFO    ] __main__: train step 9180: loss: 1.0520, policy_loss: 1.1403, value_loss: 0.7522
2024-07-11 16:33:10,417 [INFO    ] __main__: train step 9181: loss: 1.0520, policy_loss: 1.1402, value_loss: 0.7522
2024-07-11 16:33:10,622 [INFO    ] __main__: train step 9182: loss: 1.0520, policy_loss: 1.1402, value_loss: 0.7522
2024-07-11 16:33:10,825 [INFO    ] __main__: train step 9183: loss: 1.0519, policy_loss: 1.1401, value_loss: 0.7521
2024-07-11 16:33:11,040 [INFO    ] __main__: train step 9184: loss: 1.0519, policy_loss: 1.1400, value_loss: 0.7521
2024-07-11 16:33:11,244 [INFO    ] __main__: train step 9185: loss: 1.0519, policy_loss: 1.1399, value_loss: 0.7521
2024-07-11 16:33:11,443 [INFO    ] __main__: train step 9186: loss: 1.0519, policy_loss: 1.1399, value_loss: 0.7520
2024-07-11 16:33:11,693 [INFO    ] __main__: train step 9187: loss: 1.0519, policy_loss: 1.1398, value_loss: 0.7520
2024-07-11 16:33:11,916 [INFO    ] __main__: train step 9188: loss: 1.0519, policy_loss: 1.1397, value_loss: 0.7520
2024-07-11 16:33:12,109 [INFO    ] __main__: train step 9189: loss: 1.0519, policy_loss: 1.1397, value_loss: 0.7519
2024-07-11 16:33:12,319 [INFO    ] __main__: train step 9190: loss: 1.0519, policy_loss: 1.1396, value_loss: 0.7519
2024-07-11 16:33:12,516 [INFO    ] __main__: train step 9191: loss: 1.0518, policy_loss: 1.1395, value_loss: 0.7518
2024-07-11 16:33:12,722 [INFO    ] __main__: train step 9192: loss: 1.0518, policy_loss: 1.1395, value_loss: 0.7518
2024-07-11 16:33:12,922 [INFO    ] __main__: train step 9193: loss: 1.0518, policy_loss: 1.1394, value_loss: 0.7518
2024-07-11 16:33:13,124 [INFO    ] __main__: train step 9194: loss: 1.0518, policy_loss: 1.1393, value_loss: 0.7517
2024-07-11 16:33:13,321 [INFO    ] __main__: train step 9195: loss: 1.0518, policy_loss: 1.1393, value_loss: 0.7517
2024-07-11 16:33:13,515 [INFO    ] __main__: train step 9196: loss: 1.0518, policy_loss: 1.1392, value_loss: 0.7517
2024-07-11 16:33:14,954 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:33:15,329 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:33:15,384 [INFO    ] __main__: train step 9197: loss: 1.0518, policy_loss: 1.1391, value_loss: 0.7516
2024-07-11 16:33:15,558 [INFO    ] __main__: train step 9198: loss: 1.0518, policy_loss: 1.1391, value_loss: 0.7516
2024-07-11 16:33:15,761 [INFO    ] __main__: train step 9199: loss: 1.0517, policy_loss: 1.1390, value_loss: 0.7516
2024-07-11 16:33:15,959 [INFO    ] __main__: train step 9200: loss: 1.0517, policy_loss: 1.1389, value_loss: 0.7515
2024-07-11 16:33:16,160 [INFO    ] __main__: train step 9201: loss: 1.0517, policy_loss: 1.1389, value_loss: 0.7515
2024-07-11 16:33:16,364 [INFO    ] __main__: train step 9202: loss: 1.0517, policy_loss: 1.1388, value_loss: 0.7515
2024-07-11 16:33:16,558 [INFO    ] __main__: train step 9203: loss: 1.0517, policy_loss: 1.1387, value_loss: 0.7514
2024-07-11 16:33:16,788 [INFO    ] __main__: train step 9204: loss: 1.0517, policy_loss: 1.1386, value_loss: 0.7514
2024-07-11 16:33:17,016 [INFO    ] __main__: train step 9205: loss: 1.0517, policy_loss: 1.1386, value_loss: 0.7514
2024-07-11 16:33:18,077 [INFO    ] __main__: train step 9206: loss: 1.0517, policy_loss: 1.1385, value_loss: 0.7513
2024-07-11 16:33:18,305 [INFO    ] __main__: train step 9207: loss: 1.0517, policy_loss: 1.1384, value_loss: 0.7513
2024-07-11 16:33:18,501 [INFO    ] __main__: train step 9208: loss: 1.0516, policy_loss: 1.1384, value_loss: 0.7513
2024-07-11 16:33:18,718 [INFO    ] __main__: train step 9209: loss: 1.0516, policy_loss: 1.1383, value_loss: 0.7512
2024-07-11 16:33:18,906 [INFO    ] __main__: train step 9210: loss: 1.0516, policy_loss: 1.1382, value_loss: 0.7512
2024-07-11 16:33:19,110 [INFO    ] __main__: train step 9211: loss: 1.0516, policy_loss: 1.1382, value_loss: 0.7512
2024-07-11 16:33:19,314 [INFO    ] __main__: train step 9212: loss: 1.0516, policy_loss: 1.1381, value_loss: 0.7511
2024-07-11 16:33:19,511 [INFO    ] __main__: train step 9213: loss: 1.0516, policy_loss: 1.1380, value_loss: 0.7511
2024-07-11 16:33:20,931 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:33:21,306 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:33:21,364 [INFO    ] __main__: train step 9214: loss: 1.0516, policy_loss: 1.1380, value_loss: 0.7510
2024-07-11 16:33:21,530 [INFO    ] __main__: train step 9215: loss: 1.0515, policy_loss: 1.1379, value_loss: 0.7510
2024-07-11 16:33:21,737 [INFO    ] __main__: train step 9216: loss: 1.0515, policy_loss: 1.1378, value_loss: 0.7510
2024-07-11 16:33:21,946 [INFO    ] __main__: train step 9217: loss: 1.0515, policy_loss: 1.1378, value_loss: 0.7509
2024-07-11 16:33:22,145 [INFO    ] __main__: train step 9218: loss: 1.0515, policy_loss: 1.1377, value_loss: 0.7509
2024-07-11 16:33:22,342 [INFO    ] __main__: train step 9219: loss: 1.0515, policy_loss: 1.1376, value_loss: 0.7509
2024-07-11 16:33:22,547 [INFO    ] __main__: train step 9220: loss: 1.0515, policy_loss: 1.1375, value_loss: 0.7508
2024-07-11 16:33:22,744 [INFO    ] __main__: train step 9221: loss: 1.0515, policy_loss: 1.1375, value_loss: 0.7508
2024-07-11 16:33:22,954 [INFO    ] __main__: train step 9222: loss: 1.0515, policy_loss: 1.1374, value_loss: 0.7508
2024-07-11 16:33:23,150 [INFO    ] __main__: train step 9223: loss: 1.0514, policy_loss: 1.1373, value_loss: 0.7507
2024-07-11 16:33:23,376 [INFO    ] __main__: train step 9224: loss: 1.0514, policy_loss: 1.1373, value_loss: 0.7507
2024-07-11 16:33:23,607 [INFO    ] __main__: train step 9225: loss: 1.0514, policy_loss: 1.1372, value_loss: 0.7507
2024-07-11 16:33:23,854 [INFO    ] __main__: train step 9226: loss: 1.0514, policy_loss: 1.1371, value_loss: 0.7506
2024-07-11 16:33:24,071 [INFO    ] __main__: train step 9227: loss: 1.0514, policy_loss: 1.1371, value_loss: 0.7506
2024-07-11 16:33:24,278 [INFO    ] __main__: train step 9228: loss: 1.0514, policy_loss: 1.1370, value_loss: 0.7506
2024-07-11 16:33:24,494 [INFO    ] __main__: train step 9229: loss: 1.0514, policy_loss: 1.1369, value_loss: 0.7505
2024-07-11 16:33:24,727 [INFO    ] __main__: train step 9230: loss: 1.0514, policy_loss: 1.1369, value_loss: 0.7505
2024-07-11 16:33:26,142 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:33:26,514 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:33:26,570 [INFO    ] __main__: train step 9231: loss: 1.0513, policy_loss: 1.1368, value_loss: 0.7504
2024-07-11 16:33:26,758 [INFO    ] __main__: train step 9232: loss: 1.0513, policy_loss: 1.1367, value_loss: 0.7504
2024-07-11 16:33:26,960 [INFO    ] __main__: train step 9233: loss: 1.0513, policy_loss: 1.1367, value_loss: 0.7504
2024-07-11 16:33:27,151 [INFO    ] __main__: train step 9234: loss: 1.0513, policy_loss: 1.1366, value_loss: 0.7503
2024-07-11 16:33:27,353 [INFO    ] __main__: train step 9235: loss: 1.0513, policy_loss: 1.1365, value_loss: 0.7503
2024-07-11 16:33:27,560 [INFO    ] __main__: train step 9236: loss: 1.0513, policy_loss: 1.1365, value_loss: 0.7503
2024-07-11 16:33:27,752 [INFO    ] __main__: train step 9237: loss: 1.0513, policy_loss: 1.1364, value_loss: 0.7502
2024-07-11 16:33:27,949 [INFO    ] __main__: train step 9238: loss: 1.0513, policy_loss: 1.1363, value_loss: 0.7502
2024-07-11 16:33:28,155 [INFO    ] __main__: train step 9239: loss: 1.0512, policy_loss: 1.1363, value_loss: 0.7502
2024-07-11 16:33:28,356 [INFO    ] __main__: train step 9240: loss: 1.0512, policy_loss: 1.1362, value_loss: 0.7501
2024-07-11 16:33:28,569 [INFO    ] __main__: train step 9241: loss: 1.0512, policy_loss: 1.1361, value_loss: 0.7501
2024-07-11 16:33:28,802 [INFO    ] __main__: train step 9242: loss: 1.0512, policy_loss: 1.1361, value_loss: 0.7501
2024-07-11 16:33:28,998 [INFO    ] __main__: train step 9243: loss: 1.0512, policy_loss: 1.1360, value_loss: 0.7500
2024-07-11 16:33:29,224 [INFO    ] __main__: train step 9244: loss: 1.0512, policy_loss: 1.1359, value_loss: 0.7500
2024-07-11 16:33:29,468 [INFO    ] __main__: train step 9245: loss: 1.0512, policy_loss: 1.1358, value_loss: 0.7500
2024-07-11 16:33:29,717 [INFO    ] __main__: train step 9246: loss: 1.0511, policy_loss: 1.1358, value_loss: 0.7499
2024-07-11 16:33:29,922 [INFO    ] __main__: train step 9247: loss: 1.0511, policy_loss: 1.1357, value_loss: 0.7499
2024-07-11 16:33:31,343 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:33:31,742 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:33:31,796 [INFO    ] __main__: train step 9248: loss: 1.0511, policy_loss: 1.1356, value_loss: 0.7498
2024-07-11 16:33:31,973 [INFO    ] __main__: train step 9249: loss: 1.0511, policy_loss: 1.1356, value_loss: 0.7498
2024-07-11 16:33:32,176 [INFO    ] __main__: train step 9250: loss: 1.0511, policy_loss: 1.1355, value_loss: 0.7498
2024-07-11 16:33:32,382 [INFO    ] __main__: train step 9251: loss: 1.0511, policy_loss: 1.1354, value_loss: 0.7497
2024-07-11 16:33:32,595 [INFO    ] __main__: train step 9252: loss: 1.0511, policy_loss: 1.1354, value_loss: 0.7497
2024-07-11 16:33:32,810 [INFO    ] __main__: train step 9253: loss: 1.0511, policy_loss: 1.1353, value_loss: 0.7497
2024-07-11 16:33:33,017 [INFO    ] __main__: train step 9254: loss: 1.0510, policy_loss: 1.1352, value_loss: 0.7496
2024-07-11 16:33:33,221 [INFO    ] __main__: train step 9255: loss: 1.0510, policy_loss: 1.1352, value_loss: 0.7496
2024-07-11 16:33:33,424 [INFO    ] __main__: train step 9256: loss: 1.0510, policy_loss: 1.1351, value_loss: 0.7496
2024-07-11 16:33:33,626 [INFO    ] __main__: train step 9257: loss: 1.0510, policy_loss: 1.1350, value_loss: 0.7495
2024-07-11 16:33:33,830 [INFO    ] __main__: train step 9258: loss: 1.0510, policy_loss: 1.1350, value_loss: 0.7495
2024-07-11 16:33:34,025 [INFO    ] __main__: train step 9259: loss: 1.0510, policy_loss: 1.1349, value_loss: 0.7495
2024-07-11 16:33:34,223 [INFO    ] __main__: train step 9260: loss: 1.0510, policy_loss: 1.1348, value_loss: 0.7494
2024-07-11 16:33:34,434 [INFO    ] __main__: train step 9261: loss: 1.0510, policy_loss: 1.1348, value_loss: 0.7494
2024-07-11 16:33:34,642 [INFO    ] __main__: train step 9262: loss: 1.0509, policy_loss: 1.1347, value_loss: 0.7494
2024-07-11 16:33:34,838 [INFO    ] __main__: train step 9263: loss: 1.0509, policy_loss: 1.1346, value_loss: 0.7493
2024-07-11 16:33:35,044 [INFO    ] __main__: train step 9264: loss: 1.0509, policy_loss: 1.1346, value_loss: 0.7493
2024-07-11 16:33:36,484 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:33:36,911 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:33:36,973 [INFO    ] __main__: train step 9265: loss: 1.0509, policy_loss: 1.1345, value_loss: 0.7493
2024-07-11 16:33:37,141 [INFO    ] __main__: train step 9266: loss: 1.0509, policy_loss: 1.1344, value_loss: 0.7492
2024-07-11 16:33:37,339 [INFO    ] __main__: train step 9267: loss: 1.0509, policy_loss: 1.1343, value_loss: 0.7492
2024-07-11 16:33:37,543 [INFO    ] __main__: train step 9268: loss: 1.0509, policy_loss: 1.1343, value_loss: 0.7491
2024-07-11 16:33:37,776 [INFO    ] __main__: train step 9269: loss: 1.0508, policy_loss: 1.1342, value_loss: 0.7491
2024-07-11 16:33:37,983 [INFO    ] __main__: train step 9270: loss: 1.0508, policy_loss: 1.1341, value_loss: 0.7491
2024-07-11 16:33:38,181 [INFO    ] __main__: train step 9271: loss: 1.0508, policy_loss: 1.1341, value_loss: 0.7490
2024-07-11 16:33:38,373 [INFO    ] __main__: train step 9272: loss: 1.0508, policy_loss: 1.1340, value_loss: 0.7490
2024-07-11 16:33:38,580 [INFO    ] __main__: train step 9273: loss: 1.0508, policy_loss: 1.1339, value_loss: 0.7490
2024-07-11 16:33:38,777 [INFO    ] __main__: train step 9274: loss: 1.0508, policy_loss: 1.1339, value_loss: 0.7489
2024-07-11 16:33:38,985 [INFO    ] __main__: train step 9275: loss: 1.0508, policy_loss: 1.1338, value_loss: 0.7489
2024-07-11 16:33:39,190 [INFO    ] __main__: train step 9276: loss: 1.0507, policy_loss: 1.1337, value_loss: 0.7489
2024-07-11 16:33:39,405 [INFO    ] __main__: train step 9277: loss: 1.0507, policy_loss: 1.1337, value_loss: 0.7488
2024-07-11 16:33:39,601 [INFO    ] __main__: train step 9278: loss: 1.0507, policy_loss: 1.1336, value_loss: 0.7488
2024-07-11 16:33:40,648 [INFO    ] __main__: train step 9279: loss: 1.0507, policy_loss: 1.1335, value_loss: 0.7488
2024-07-11 16:33:40,851 [INFO    ] __main__: train step 9280: loss: 1.0507, policy_loss: 1.1335, value_loss: 0.7487
2024-07-11 16:33:41,062 [INFO    ] __main__: train step 9281: loss: 1.0507, policy_loss: 1.1334, value_loss: 0.7487
2024-07-11 16:33:42,489 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:33:42,909 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:33:42,964 [INFO    ] __main__: train step 9282: loss: 1.0507, policy_loss: 1.1333, value_loss: 0.7486
2024-07-11 16:33:43,146 [INFO    ] __main__: train step 9283: loss: 1.0506, policy_loss: 1.1333, value_loss: 0.7486
2024-07-11 16:33:43,358 [INFO    ] __main__: train step 9284: loss: 1.0506, policy_loss: 1.1332, value_loss: 0.7486
2024-07-11 16:33:43,600 [INFO    ] __main__: train step 9285: loss: 1.0506, policy_loss: 1.1331, value_loss: 0.7485
2024-07-11 16:33:43,806 [INFO    ] __main__: train step 9286: loss: 1.0506, policy_loss: 1.1331, value_loss: 0.7485
2024-07-11 16:33:44,022 [INFO    ] __main__: train step 9287: loss: 1.0506, policy_loss: 1.1330, value_loss: 0.7485
2024-07-11 16:33:44,274 [INFO    ] __main__: train step 9288: loss: 1.0506, policy_loss: 1.1329, value_loss: 0.7484
2024-07-11 16:33:44,468 [INFO    ] __main__: train step 9289: loss: 1.0506, policy_loss: 1.1328, value_loss: 0.7484
2024-07-11 16:33:44,683 [INFO    ] __main__: train step 9290: loss: 1.0505, policy_loss: 1.1328, value_loss: 0.7484
2024-07-11 16:33:44,914 [INFO    ] __main__: train step 9291: loss: 1.0505, policy_loss: 1.1327, value_loss: 0.7483
2024-07-11 16:33:45,108 [INFO    ] __main__: train step 9292: loss: 1.0505, policy_loss: 1.1326, value_loss: 0.7483
2024-07-11 16:33:45,307 [INFO    ] __main__: train step 9293: loss: 1.0505, policy_loss: 1.1326, value_loss: 0.7483
2024-07-11 16:33:45,506 [INFO    ] __main__: train step 9294: loss: 1.0505, policy_loss: 1.1325, value_loss: 0.7482
2024-07-11 16:33:45,709 [INFO    ] __main__: train step 9295: loss: 1.0505, policy_loss: 1.1324, value_loss: 0.7482
2024-07-11 16:33:45,912 [INFO    ] __main__: train step 9296: loss: 1.0505, policy_loss: 1.1324, value_loss: 0.7481
2024-07-11 16:33:46,119 [INFO    ] __main__: train step 9297: loss: 1.0504, policy_loss: 1.1323, value_loss: 0.7481
2024-07-11 16:33:46,318 [INFO    ] __main__: train step 9298: loss: 1.0504, policy_loss: 1.1322, value_loss: 0.7481
2024-07-11 16:33:47,749 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:33:48,184 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:33:48,240 [INFO    ] __main__: train step 9299: loss: 1.0504, policy_loss: 1.1322, value_loss: 0.7480
2024-07-11 16:33:48,412 [INFO    ] __main__: train step 9300: loss: 1.0504, policy_loss: 1.1321, value_loss: 0.7480
2024-07-11 16:33:48,623 [INFO    ] __main__: train step 9301: loss: 1.0504, policy_loss: 1.1320, value_loss: 0.7480
2024-07-11 16:33:48,825 [INFO    ] __main__: train step 9302: loss: 1.0504, policy_loss: 1.1320, value_loss: 0.7479
2024-07-11 16:33:49,032 [INFO    ] __main__: train step 9303: loss: 1.0504, policy_loss: 1.1319, value_loss: 0.7479
2024-07-11 16:33:49,237 [INFO    ] __main__: train step 9304: loss: 1.0503, policy_loss: 1.1318, value_loss: 0.7479
2024-07-11 16:33:49,441 [INFO    ] __main__: train step 9305: loss: 1.0503, policy_loss: 1.1318, value_loss: 0.7478
2024-07-11 16:33:49,664 [INFO    ] __main__: train step 9306: loss: 1.0503, policy_loss: 1.1317, value_loss: 0.7478
2024-07-11 16:33:49,895 [INFO    ] __main__: train step 9307: loss: 1.0503, policy_loss: 1.1316, value_loss: 0.7477
2024-07-11 16:33:50,114 [INFO    ] __main__: train step 9308: loss: 1.0503, policy_loss: 1.1316, value_loss: 0.7477
2024-07-11 16:33:50,351 [INFO    ] __main__: train step 9309: loss: 1.0503, policy_loss: 1.1315, value_loss: 0.7477
2024-07-11 16:33:50,554 [INFO    ] __main__: train step 9310: loss: 1.0502, policy_loss: 1.1314, value_loss: 0.7476
2024-07-11 16:33:50,759 [INFO    ] __main__: train step 9311: loss: 1.0502, policy_loss: 1.1314, value_loss: 0.7476
2024-07-11 16:33:50,955 [INFO    ] __main__: train step 9312: loss: 1.0502, policy_loss: 1.1313, value_loss: 0.7476
2024-07-11 16:33:51,158 [INFO    ] __main__: train step 9313: loss: 1.0502, policy_loss: 1.1312, value_loss: 0.7475
2024-07-11 16:33:51,369 [INFO    ] __main__: train step 9314: loss: 1.0502, policy_loss: 1.1312, value_loss: 0.7475
2024-07-11 16:33:51,569 [INFO    ] __main__: train step 9315: loss: 1.0502, policy_loss: 1.1311, value_loss: 0.7475
2024-07-11 16:33:53,011 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:33:53,428 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:33:53,484 [INFO    ] __main__: train step 9316: loss: 1.0502, policy_loss: 1.1310, value_loss: 0.7474
2024-07-11 16:33:53,663 [INFO    ] __main__: train step 9317: loss: 1.0501, policy_loss: 1.1310, value_loss: 0.7474
2024-07-11 16:33:53,897 [INFO    ] __main__: train step 9318: loss: 1.0501, policy_loss: 1.1309, value_loss: 0.7474
2024-07-11 16:33:54,100 [INFO    ] __main__: train step 9319: loss: 1.0501, policy_loss: 1.1308, value_loss: 0.7473
2024-07-11 16:33:54,303 [INFO    ] __main__: train step 9320: loss: 1.0501, policy_loss: 1.1307, value_loss: 0.7473
2024-07-11 16:33:54,502 [INFO    ] __main__: train step 9321: loss: 1.0501, policy_loss: 1.1307, value_loss: 0.7472
2024-07-11 16:33:54,718 [INFO    ] __main__: train step 9322: loss: 1.0501, policy_loss: 1.1306, value_loss: 0.7472
2024-07-11 16:33:54,910 [INFO    ] __main__: train step 9323: loss: 1.0501, policy_loss: 1.1306, value_loss: 0.7472
2024-07-11 16:33:55,103 [INFO    ] __main__: train step 9324: loss: 1.0500, policy_loss: 1.1305, value_loss: 0.7471
2024-07-11 16:33:55,308 [INFO    ] __main__: train step 9325: loss: 1.0500, policy_loss: 1.1304, value_loss: 0.7471
2024-07-11 16:33:55,544 [INFO    ] __main__: train step 9326: loss: 1.0500, policy_loss: 1.1303, value_loss: 0.7471
2024-07-11 16:33:55,737 [INFO    ] __main__: train step 9327: loss: 1.0500, policy_loss: 1.1303, value_loss: 0.7470
2024-07-11 16:33:55,942 [INFO    ] __main__: train step 9328: loss: 1.0500, policy_loss: 1.1302, value_loss: 0.7470
2024-07-11 16:33:56,144 [INFO    ] __main__: train step 9329: loss: 1.0500, policy_loss: 1.1301, value_loss: 0.7470
2024-07-11 16:33:56,379 [INFO    ] __main__: train step 9330: loss: 1.0500, policy_loss: 1.1301, value_loss: 0.7469
2024-07-11 16:33:56,578 [INFO    ] __main__: train step 9331: loss: 1.0499, policy_loss: 1.1300, value_loss: 0.7469
2024-07-11 16:33:56,806 [INFO    ] __main__: train step 9332: loss: 1.0499, policy_loss: 1.1299, value_loss: 0.7468
2024-07-11 16:33:58,238 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:33:58,640 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:33:58,696 [INFO    ] __main__: train step 9333: loss: 1.0499, policy_loss: 1.1299, value_loss: 0.7468
2024-07-11 16:33:58,866 [INFO    ] __main__: train step 9334: loss: 1.0499, policy_loss: 1.1298, value_loss: 0.7468
2024-07-11 16:33:59,090 [INFO    ] __main__: train step 9335: loss: 1.0499, policy_loss: 1.1297, value_loss: 0.7467
2024-07-11 16:33:59,289 [INFO    ] __main__: train step 9336: loss: 1.0499, policy_loss: 1.1297, value_loss: 0.7467
2024-07-11 16:33:59,503 [INFO    ] __main__: train step 9337: loss: 1.0498, policy_loss: 1.1296, value_loss: 0.7467
2024-07-11 16:33:59,761 [INFO    ] __main__: train step 9338: loss: 1.0498, policy_loss: 1.1295, value_loss: 0.7466
2024-07-11 16:33:59,975 [INFO    ] __main__: train step 9339: loss: 1.0498, policy_loss: 1.1295, value_loss: 0.7466
2024-07-11 16:34:00,185 [INFO    ] __main__: train step 9340: loss: 1.0498, policy_loss: 1.1294, value_loss: 0.7466
2024-07-11 16:34:00,390 [INFO    ] __main__: train step 9341: loss: 1.0498, policy_loss: 1.1293, value_loss: 0.7465
2024-07-11 16:34:00,631 [INFO    ] __main__: train step 9342: loss: 1.0498, policy_loss: 1.1293, value_loss: 0.7465
2024-07-11 16:34:00,839 [INFO    ] __main__: train step 9343: loss: 1.0498, policy_loss: 1.1292, value_loss: 0.7464
2024-07-11 16:34:01,034 [INFO    ] __main__: train step 9344: loss: 1.0497, policy_loss: 1.1291, value_loss: 0.7464
2024-07-11 16:34:01,242 [INFO    ] __main__: train step 9345: loss: 1.0497, policy_loss: 1.1291, value_loss: 0.7464
2024-07-11 16:34:01,447 [INFO    ] __main__: train step 9346: loss: 1.0497, policy_loss: 1.1290, value_loss: 0.7463
2024-07-11 16:34:01,642 [INFO    ] __main__: train step 9347: loss: 1.0497, policy_loss: 1.1289, value_loss: 0.7463
2024-07-11 16:34:01,842 [INFO    ] __main__: train step 9348: loss: 1.0497, policy_loss: 1.1289, value_loss: 0.7463
2024-07-11 16:34:02,045 [INFO    ] __main__: train step 9349: loss: 1.0497, policy_loss: 1.1288, value_loss: 0.7462
2024-07-11 16:34:03,496 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:34:03,873 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:34:03,930 [INFO    ] __main__: train step 9350: loss: 1.0496, policy_loss: 1.1287, value_loss: 0.7462
2024-07-11 16:34:04,114 [INFO    ] __main__: train step 9351: loss: 1.0496, policy_loss: 1.1287, value_loss: 0.7462
2024-07-11 16:34:05,182 [INFO    ] __main__: train step 9352: loss: 1.0496, policy_loss: 1.1286, value_loss: 0.7461
2024-07-11 16:34:05,399 [INFO    ] __main__: train step 9353: loss: 1.0496, policy_loss: 1.1285, value_loss: 0.7461
2024-07-11 16:34:05,620 [INFO    ] __main__: train step 9354: loss: 1.0496, policy_loss: 1.1285, value_loss: 0.7460
2024-07-11 16:34:05,833 [INFO    ] __main__: train step 9355: loss: 1.0496, policy_loss: 1.1284, value_loss: 0.7460
2024-07-11 16:34:06,025 [INFO    ] __main__: train step 9356: loss: 1.0495, policy_loss: 1.1283, value_loss: 0.7460
2024-07-11 16:34:06,233 [INFO    ] __main__: train step 9357: loss: 1.0495, policy_loss: 1.1283, value_loss: 0.7459
2024-07-11 16:34:06,445 [INFO    ] __main__: train step 9358: loss: 1.0495, policy_loss: 1.1282, value_loss: 0.7459
2024-07-11 16:34:06,643 [INFO    ] __main__: train step 9359: loss: 1.0495, policy_loss: 1.1281, value_loss: 0.7459
2024-07-11 16:34:06,849 [INFO    ] __main__: train step 9360: loss: 1.0495, policy_loss: 1.1281, value_loss: 0.7458
2024-07-11 16:34:07,079 [INFO    ] __main__: train step 9361: loss: 1.0495, policy_loss: 1.1280, value_loss: 0.7458
2024-07-11 16:34:07,282 [INFO    ] __main__: train step 9362: loss: 1.0495, policy_loss: 1.1279, value_loss: 0.7458
2024-07-11 16:34:07,488 [INFO    ] __main__: train step 9363: loss: 1.0494, policy_loss: 1.1278, value_loss: 0.7457
2024-07-11 16:34:07,682 [INFO    ] __main__: train step 9364: loss: 1.0494, policy_loss: 1.1278, value_loss: 0.7457
2024-07-11 16:34:07,887 [INFO    ] __main__: train step 9365: loss: 1.0494, policy_loss: 1.1277, value_loss: 0.7456
2024-07-11 16:34:08,090 [INFO    ] __main__: train step 9366: loss: 1.0494, policy_loss: 1.1277, value_loss: 0.7456
2024-07-11 16:34:09,532 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:34:09,974 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:34:10,033 [INFO    ] __main__: train step 9367: loss: 1.0494, policy_loss: 1.1276, value_loss: 0.7456
2024-07-11 16:34:10,202 [INFO    ] __main__: train step 9368: loss: 1.0494, policy_loss: 1.1275, value_loss: 0.7455
2024-07-11 16:34:10,409 [INFO    ] __main__: train step 9369: loss: 1.0493, policy_loss: 1.1275, value_loss: 0.7455
2024-07-11 16:34:10,629 [INFO    ] __main__: train step 9370: loss: 1.0493, policy_loss: 1.1274, value_loss: 0.7455
2024-07-11 16:34:10,839 [INFO    ] __main__: train step 9371: loss: 1.0493, policy_loss: 1.1273, value_loss: 0.7454
2024-07-11 16:34:11,055 [INFO    ] __main__: train step 9372: loss: 1.0493, policy_loss: 1.1273, value_loss: 0.7454
2024-07-11 16:34:11,278 [INFO    ] __main__: train step 9373: loss: 1.0493, policy_loss: 1.1272, value_loss: 0.7453
2024-07-11 16:34:11,487 [INFO    ] __main__: train step 9374: loss: 1.0493, policy_loss: 1.1271, value_loss: 0.7453
2024-07-11 16:34:11,718 [INFO    ] __main__: train step 9375: loss: 1.0493, policy_loss: 1.1271, value_loss: 0.7453
2024-07-11 16:34:11,930 [INFO    ] __main__: train step 9376: loss: 1.0492, policy_loss: 1.1270, value_loss: 0.7452
2024-07-11 16:34:12,123 [INFO    ] __main__: train step 9377: loss: 1.0492, policy_loss: 1.1269, value_loss: 0.7452
2024-07-11 16:34:12,318 [INFO    ] __main__: train step 9378: loss: 1.0492, policy_loss: 1.1269, value_loss: 0.7452
2024-07-11 16:34:12,644 [INFO    ] __main__: train step 9379: loss: 1.0492, policy_loss: 1.1268, value_loss: 0.7451
2024-07-11 16:34:12,861 [INFO    ] __main__: train step 9380: loss: 1.0492, policy_loss: 1.1267, value_loss: 0.7451
2024-07-11 16:34:13,076 [INFO    ] __main__: train step 9381: loss: 1.0492, policy_loss: 1.1267, value_loss: 0.7451
2024-07-11 16:34:13,282 [INFO    ] __main__: train step 9382: loss: 1.0491, policy_loss: 1.1266, value_loss: 0.7450
2024-07-11 16:34:13,480 [INFO    ] __main__: train step 9383: loss: 1.0491, policy_loss: 1.1265, value_loss: 0.7450
2024-07-11 16:34:14,928 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:34:15,316 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:34:15,372 [INFO    ] __main__: train step 9384: loss: 1.0491, policy_loss: 1.1265, value_loss: 0.7449
2024-07-11 16:34:15,547 [INFO    ] __main__: train step 9385: loss: 1.0491, policy_loss: 1.1264, value_loss: 0.7449
2024-07-11 16:34:15,740 [INFO    ] __main__: train step 9386: loss: 1.0491, policy_loss: 1.1263, value_loss: 0.7449
2024-07-11 16:34:15,940 [INFO    ] __main__: train step 9387: loss: 1.0491, policy_loss: 1.1263, value_loss: 0.7448
2024-07-11 16:34:16,153 [INFO    ] __main__: train step 9388: loss: 1.0491, policy_loss: 1.1262, value_loss: 0.7448
2024-07-11 16:34:16,342 [INFO    ] __main__: train step 9389: loss: 1.0490, policy_loss: 1.1261, value_loss: 0.7448
2024-07-11 16:34:16,549 [INFO    ] __main__: train step 9390: loss: 1.0490, policy_loss: 1.1261, value_loss: 0.7447
2024-07-11 16:34:16,746 [INFO    ] __main__: train step 9391: loss: 1.0490, policy_loss: 1.1260, value_loss: 0.7447
2024-07-11 16:34:16,962 [INFO    ] __main__: train step 9392: loss: 1.0490, policy_loss: 1.1259, value_loss: 0.7446
2024-07-11 16:34:17,201 [INFO    ] __main__: train step 9393: loss: 1.0490, policy_loss: 1.1259, value_loss: 0.7446
2024-07-11 16:34:17,415 [INFO    ] __main__: train step 9394: loss: 1.0490, policy_loss: 1.1258, value_loss: 0.7446
2024-07-11 16:34:17,654 [INFO    ] __main__: train step 9395: loss: 1.0489, policy_loss: 1.1257, value_loss: 0.7445
2024-07-11 16:34:17,878 [INFO    ] __main__: train step 9396: loss: 1.0489, policy_loss: 1.1257, value_loss: 0.7445
2024-07-11 16:34:18,078 [INFO    ] __main__: train step 9397: loss: 1.0489, policy_loss: 1.1256, value_loss: 0.7445
2024-07-11 16:34:18,284 [INFO    ] __main__: train step 9398: loss: 1.0489, policy_loss: 1.1255, value_loss: 0.7444
2024-07-11 16:34:18,497 [INFO    ] __main__: train step 9399: loss: 1.0489, policy_loss: 1.1255, value_loss: 0.7444
2024-07-11 16:34:18,691 [INFO    ] __main__: train step 9400: loss: 1.0489, policy_loss: 1.1254, value_loss: 0.7444
2024-07-11 16:34:20,133 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:34:20,583 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:34:20,650 [INFO    ] __main__: train step 9401: loss: 1.0488, policy_loss: 1.1253, value_loss: 0.7443
2024-07-11 16:34:20,830 [INFO    ] __main__: train step 9402: loss: 1.0488, policy_loss: 1.1253, value_loss: 0.7443
2024-07-11 16:34:21,037 [INFO    ] __main__: train step 9403: loss: 1.0488, policy_loss: 1.1252, value_loss: 0.7442
2024-07-11 16:34:21,239 [INFO    ] __main__: train step 9404: loss: 1.0488, policy_loss: 1.1251, value_loss: 0.7442
2024-07-11 16:34:21,441 [INFO    ] __main__: train step 9405: loss: 1.0488, policy_loss: 1.1251, value_loss: 0.7442
2024-07-11 16:34:21,642 [INFO    ] __main__: train step 9406: loss: 1.0488, policy_loss: 1.1250, value_loss: 0.7441
2024-07-11 16:34:21,846 [INFO    ] __main__: train step 9407: loss: 1.0487, policy_loss: 1.1249, value_loss: 0.7441
2024-07-11 16:34:22,049 [INFO    ] __main__: train step 9408: loss: 1.0487, policy_loss: 1.1249, value_loss: 0.7441
2024-07-11 16:34:22,255 [INFO    ] __main__: train step 9409: loss: 1.0487, policy_loss: 1.1248, value_loss: 0.7440
2024-07-11 16:34:22,455 [INFO    ] __main__: train step 9410: loss: 1.0487, policy_loss: 1.1247, value_loss: 0.7440
2024-07-11 16:34:22,661 [INFO    ] __main__: train step 9411: loss: 1.0487, policy_loss: 1.1247, value_loss: 0.7439
2024-07-11 16:34:22,869 [INFO    ] __main__: train step 9412: loss: 1.0487, policy_loss: 1.1246, value_loss: 0.7439
2024-07-11 16:34:23,073 [INFO    ] __main__: train step 9413: loss: 1.0486, policy_loss: 1.1245, value_loss: 0.7439
2024-07-11 16:34:23,301 [INFO    ] __main__: train step 9414: loss: 1.0486, policy_loss: 1.1245, value_loss: 0.7438
2024-07-11 16:34:23,512 [INFO    ] __main__: train step 9415: loss: 1.0486, policy_loss: 1.1244, value_loss: 0.7438
2024-07-11 16:34:23,724 [INFO    ] __main__: train step 9416: loss: 1.0486, policy_loss: 1.1243, value_loss: 0.7438
2024-07-11 16:34:23,966 [INFO    ] __main__: train step 9417: loss: 1.0486, policy_loss: 1.1243, value_loss: 0.7437
2024-07-11 16:34:25,405 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:34:25,802 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:34:25,860 [INFO    ] __main__: train step 9418: loss: 1.0486, policy_loss: 1.1242, value_loss: 0.7437
2024-07-11 16:34:26,035 [INFO    ] __main__: train step 9419: loss: 1.0485, policy_loss: 1.1241, value_loss: 0.7436
2024-07-11 16:34:26,236 [INFO    ] __main__: train step 9420: loss: 1.0485, policy_loss: 1.1241, value_loss: 0.7436
2024-07-11 16:34:26,453 [INFO    ] __main__: train step 9421: loss: 1.0485, policy_loss: 1.1240, value_loss: 0.7436
2024-07-11 16:34:26,653 [INFO    ] __main__: train step 9422: loss: 1.0485, policy_loss: 1.1239, value_loss: 0.7435
2024-07-11 16:34:26,852 [INFO    ] __main__: train step 9423: loss: 1.0485, policy_loss: 1.1238, value_loss: 0.7435
2024-07-11 16:34:27,053 [INFO    ] __main__: train step 9424: loss: 1.0485, policy_loss: 1.1238, value_loss: 0.7435
2024-07-11 16:34:27,264 [INFO    ] __main__: train step 9425: loss: 1.0484, policy_loss: 1.1237, value_loss: 0.7434
2024-07-11 16:34:28,297 [INFO    ] __main__: train step 9426: loss: 1.0484, policy_loss: 1.1237, value_loss: 0.7434
2024-07-11 16:34:28,514 [INFO    ] __main__: train step 9427: loss: 1.0484, policy_loss: 1.1236, value_loss: 0.7433
2024-07-11 16:34:28,724 [INFO    ] __main__: train step 9428: loss: 1.0484, policy_loss: 1.1235, value_loss: 0.7433
2024-07-11 16:34:28,929 [INFO    ] __main__: train step 9429: loss: 1.0484, policy_loss: 1.1235, value_loss: 0.7433
2024-07-11 16:34:29,152 [INFO    ] __main__: train step 9430: loss: 1.0484, policy_loss: 1.1234, value_loss: 0.7432
2024-07-11 16:34:29,382 [INFO    ] __main__: train step 9431: loss: 1.0483, policy_loss: 1.1233, value_loss: 0.7432
2024-07-11 16:34:29,583 [INFO    ] __main__: train step 9432: loss: 1.0483, policy_loss: 1.1232, value_loss: 0.7432
2024-07-11 16:34:29,814 [INFO    ] __main__: train step 9433: loss: 1.0483, policy_loss: 1.1232, value_loss: 0.7431
2024-07-11 16:34:30,014 [INFO    ] __main__: train step 9434: loss: 1.0483, policy_loss: 1.1231, value_loss: 0.7431
2024-07-11 16:34:31,444 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:34:31,846 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:34:31,903 [INFO    ] __main__: train step 9435: loss: 1.0483, policy_loss: 1.1230, value_loss: 0.7431
2024-07-11 16:34:32,082 [INFO    ] __main__: train step 9436: loss: 1.0482, policy_loss: 1.1230, value_loss: 0.7430
2024-07-11 16:34:32,298 [INFO    ] __main__: train step 9437: loss: 1.0482, policy_loss: 1.1229, value_loss: 0.7430
2024-07-11 16:34:32,496 [INFO    ] __main__: train step 9438: loss: 1.0482, policy_loss: 1.1228, value_loss: 0.7429
2024-07-11 16:34:32,727 [INFO    ] __main__: train step 9439: loss: 1.0482, policy_loss: 1.1228, value_loss: 0.7429
2024-07-11 16:34:32,941 [INFO    ] __main__: train step 9440: loss: 1.0482, policy_loss: 1.1227, value_loss: 0.7429
2024-07-11 16:34:33,146 [INFO    ] __main__: train step 9441: loss: 1.0481, policy_loss: 1.1226, value_loss: 0.7428
2024-07-11 16:34:33,350 [INFO    ] __main__: train step 9442: loss: 1.0481, policy_loss: 1.1226, value_loss: 0.7428
2024-07-11 16:34:33,556 [INFO    ] __main__: train step 9443: loss: 1.0481, policy_loss: 1.1225, value_loss: 0.7427
2024-07-11 16:34:33,764 [INFO    ] __main__: train step 9444: loss: 1.0481, policy_loss: 1.1224, value_loss: 0.7427
2024-07-11 16:34:33,979 [INFO    ] __main__: train step 9445: loss: 1.0481, policy_loss: 1.1224, value_loss: 0.7427
2024-07-11 16:34:34,209 [INFO    ] __main__: train step 9446: loss: 1.0481, policy_loss: 1.1223, value_loss: 0.7426
2024-07-11 16:34:34,414 [INFO    ] __main__: train step 9447: loss: 1.0480, policy_loss: 1.1222, value_loss: 0.7426
2024-07-11 16:34:34,614 [INFO    ] __main__: train step 9448: loss: 1.0480, policy_loss: 1.1222, value_loss: 0.7426
2024-07-11 16:34:34,822 [INFO    ] __main__: train step 9449: loss: 1.0480, policy_loss: 1.1221, value_loss: 0.7425
2024-07-11 16:34:35,019 [INFO    ] __main__: train step 9450: loss: 1.0480, policy_loss: 1.1220, value_loss: 0.7425
2024-07-11 16:34:35,235 [INFO    ] __main__: train step 9451: loss: 1.0480, policy_loss: 1.1220, value_loss: 0.7424
2024-07-11 16:34:36,662 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:34:36,934 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:34:36,988 [INFO    ] __main__: train step 9452: loss: 1.0480, policy_loss: 1.1219, value_loss: 0.7424
2024-07-11 16:34:37,155 [INFO    ] __main__: train step 9453: loss: 1.0479, policy_loss: 1.1218, value_loss: 0.7424
2024-07-11 16:34:37,372 [INFO    ] __main__: train step 9454: loss: 1.0479, policy_loss: 1.1218, value_loss: 0.7423
2024-07-11 16:34:37,572 [INFO    ] __main__: train step 9455: loss: 1.0479, policy_loss: 1.1217, value_loss: 0.7423
2024-07-11 16:34:37,782 [INFO    ] __main__: train step 9456: loss: 1.0479, policy_loss: 1.1216, value_loss: 0.7423
2024-07-11 16:34:38,017 [INFO    ] __main__: train step 9457: loss: 1.0479, policy_loss: 1.1216, value_loss: 0.7422
2024-07-11 16:34:38,221 [INFO    ] __main__: train step 9458: loss: 1.0478, policy_loss: 1.1215, value_loss: 0.7422
2024-07-11 16:34:38,425 [INFO    ] __main__: train step 9459: loss: 1.0478, policy_loss: 1.1214, value_loss: 0.7421
2024-07-11 16:34:38,634 [INFO    ] __main__: train step 9460: loss: 1.0478, policy_loss: 1.1214, value_loss: 0.7421
2024-07-11 16:34:38,865 [INFO    ] __main__: train step 9461: loss: 1.0478, policy_loss: 1.1213, value_loss: 0.7421
2024-07-11 16:34:39,080 [INFO    ] __main__: train step 9462: loss: 1.0478, policy_loss: 1.1212, value_loss: 0.7420
2024-07-11 16:34:39,299 [INFO    ] __main__: train step 9463: loss: 1.0477, policy_loss: 1.1212, value_loss: 0.7420
2024-07-11 16:34:39,515 [INFO    ] __main__: train step 9464: loss: 1.0477, policy_loss: 1.1211, value_loss: 0.7419
2024-07-11 16:34:39,704 [INFO    ] __main__: train step 9465: loss: 1.0477, policy_loss: 1.1210, value_loss: 0.7419
2024-07-11 16:34:39,911 [INFO    ] __main__: train step 9466: loss: 1.0477, policy_loss: 1.1210, value_loss: 0.7419
2024-07-11 16:34:40,140 [INFO    ] __main__: train step 9467: loss: 1.0477, policy_loss: 1.1209, value_loss: 0.7418
2024-07-11 16:34:40,336 [INFO    ] __main__: train step 9468: loss: 1.0477, policy_loss: 1.1208, value_loss: 0.7418
2024-07-11 16:34:41,778 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:34:42,173 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:34:42,229 [INFO    ] __main__: train step 9469: loss: 1.0476, policy_loss: 1.1208, value_loss: 0.7418
2024-07-11 16:34:42,408 [INFO    ] __main__: train step 9470: loss: 1.0476, policy_loss: 1.1207, value_loss: 0.7417
2024-07-11 16:34:42,605 [INFO    ] __main__: train step 9471: loss: 1.0476, policy_loss: 1.1206, value_loss: 0.7417
2024-07-11 16:34:42,806 [INFO    ] __main__: train step 9472: loss: 1.0476, policy_loss: 1.1206, value_loss: 0.7416
2024-07-11 16:34:43,006 [INFO    ] __main__: train step 9473: loss: 1.0476, policy_loss: 1.1205, value_loss: 0.7416
2024-07-11 16:34:43,208 [INFO    ] __main__: train step 9474: loss: 1.0475, policy_loss: 1.1204, value_loss: 0.7416
2024-07-11 16:34:43,409 [INFO    ] __main__: train step 9475: loss: 1.0475, policy_loss: 1.1204, value_loss: 0.7415
2024-07-11 16:34:43,617 [INFO    ] __main__: train step 9476: loss: 1.0475, policy_loss: 1.1203, value_loss: 0.7415
2024-07-11 16:34:43,814 [INFO    ] __main__: train step 9477: loss: 1.0475, policy_loss: 1.1202, value_loss: 0.7414
2024-07-11 16:34:44,030 [INFO    ] __main__: train step 9478: loss: 1.0475, policy_loss: 1.1202, value_loss: 0.7414
2024-07-11 16:34:44,278 [INFO    ] __main__: train step 9479: loss: 1.0474, policy_loss: 1.1201, value_loss: 0.7414
2024-07-11 16:34:44,517 [INFO    ] __main__: train step 9480: loss: 1.0474, policy_loss: 1.1200, value_loss: 0.7413
2024-07-11 16:34:44,730 [INFO    ] __main__: train step 9481: loss: 1.0474, policy_loss: 1.1200, value_loss: 0.7413
2024-07-11 16:34:44,964 [INFO    ] __main__: train step 9482: loss: 1.0474, policy_loss: 1.1199, value_loss: 0.7413
2024-07-11 16:34:45,161 [INFO    ] __main__: train step 9483: loss: 1.0474, policy_loss: 1.1198, value_loss: 0.7412
2024-07-11 16:34:45,369 [INFO    ] __main__: train step 9484: loss: 1.0473, policy_loss: 1.1198, value_loss: 0.7412
2024-07-11 16:34:45,567 [INFO    ] __main__: train step 9485: loss: 1.0473, policy_loss: 1.1197, value_loss: 0.7411
2024-07-11 16:34:47,025 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:34:47,384 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:34:47,440 [INFO    ] __main__: train step 9486: loss: 1.0473, policy_loss: 1.1196, value_loss: 0.7411
2024-07-11 16:34:47,620 [INFO    ] __main__: train step 9487: loss: 1.0473, policy_loss: 1.1196, value_loss: 0.7411
2024-07-11 16:34:47,838 [INFO    ] __main__: train step 9488: loss: 1.0473, policy_loss: 1.1195, value_loss: 0.7410
2024-07-11 16:34:48,069 [INFO    ] __main__: train step 9489: loss: 1.0472, policy_loss: 1.1194, value_loss: 0.7410
2024-07-11 16:34:48,269 [INFO    ] __main__: train step 9490: loss: 1.0472, policy_loss: 1.1194, value_loss: 0.7409
2024-07-11 16:34:48,493 [INFO    ] __main__: train step 9491: loss: 1.0472, policy_loss: 1.1193, value_loss: 0.7409
2024-07-11 16:34:48,728 [INFO    ] __main__: train step 9492: loss: 1.0472, policy_loss: 1.1192, value_loss: 0.7409
2024-07-11 16:34:48,958 [INFO    ] __main__: train step 9493: loss: 1.0472, policy_loss: 1.1192, value_loss: 0.7408
2024-07-11 16:34:49,148 [INFO    ] __main__: train step 9494: loss: 1.0472, policy_loss: 1.1191, value_loss: 0.7408
2024-07-11 16:34:49,349 [INFO    ] __main__: train step 9495: loss: 1.0471, policy_loss: 1.1191, value_loss: 0.7407
2024-07-11 16:34:49,544 [INFO    ] __main__: train step 9496: loss: 1.0471, policy_loss: 1.1190, value_loss: 0.7407
2024-07-11 16:34:49,753 [INFO    ] __main__: train step 9497: loss: 1.0471, policy_loss: 1.1189, value_loss: 0.7407
2024-07-11 16:34:49,950 [INFO    ] __main__: train step 9498: loss: 1.0471, policy_loss: 1.1189, value_loss: 0.7406
2024-07-11 16:34:51,031 [INFO    ] __main__: train step 9499: loss: 1.0470, policy_loss: 1.1188, value_loss: 0.7406
2024-07-11 16:34:51,262 [INFO    ] __main__: train step 9500: loss: 1.0470, policy_loss: 1.1187, value_loss: 0.7406
2024-07-11 16:34:51,468 [INFO    ] __main__: train step 9501: loss: 1.0470, policy_loss: 1.1187, value_loss: 0.7405
2024-07-11 16:34:51,661 [INFO    ] __main__: train step 9502: loss: 1.0470, policy_loss: 1.1186, value_loss: 0.7405
2024-07-11 16:34:53,092 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:34:53,511 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:34:53,568 [INFO    ] __main__: train step 9503: loss: 1.0470, policy_loss: 1.1185, value_loss: 0.7404
2024-07-11 16:34:53,751 [INFO    ] __main__: train step 9504: loss: 1.0469, policy_loss: 1.1185, value_loss: 0.7404
2024-07-11 16:34:53,961 [INFO    ] __main__: train step 9505: loss: 1.0469, policy_loss: 1.1184, value_loss: 0.7404
2024-07-11 16:34:54,163 [INFO    ] __main__: train step 9506: loss: 1.0469, policy_loss: 1.1183, value_loss: 0.7403
2024-07-11 16:34:54,375 [INFO    ] __main__: train step 9507: loss: 1.0469, policy_loss: 1.1183, value_loss: 0.7403
2024-07-11 16:34:54,591 [INFO    ] __main__: train step 9508: loss: 1.0469, policy_loss: 1.1182, value_loss: 0.7402
2024-07-11 16:34:54,792 [INFO    ] __main__: train step 9509: loss: 1.0468, policy_loss: 1.1181, value_loss: 0.7402
2024-07-11 16:34:55,022 [INFO    ] __main__: train step 9510: loss: 1.0468, policy_loss: 1.1181, value_loss: 0.7402
2024-07-11 16:34:55,226 [INFO    ] __main__: train step 9511: loss: 1.0468, policy_loss: 1.1180, value_loss: 0.7401
2024-07-11 16:34:55,440 [INFO    ] __main__: train step 9512: loss: 1.0468, policy_loss: 1.1179, value_loss: 0.7401
2024-07-11 16:34:55,646 [INFO    ] __main__: train step 9513: loss: 1.0468, policy_loss: 1.1179, value_loss: 0.7400
2024-07-11 16:34:55,862 [INFO    ] __main__: train step 9514: loss: 1.0467, policy_loss: 1.1178, value_loss: 0.7400
2024-07-11 16:34:56,061 [INFO    ] __main__: train step 9515: loss: 1.0467, policy_loss: 1.1177, value_loss: 0.7400
2024-07-11 16:34:56,275 [INFO    ] __main__: train step 9516: loss: 1.0467, policy_loss: 1.1177, value_loss: 0.7399
2024-07-11 16:34:56,494 [INFO    ] __main__: train step 9517: loss: 1.0467, policy_loss: 1.1176, value_loss: 0.7399
2024-07-11 16:34:56,723 [INFO    ] __main__: train step 9518: loss: 1.0467, policy_loss: 1.1175, value_loss: 0.7398
2024-07-11 16:34:56,923 [INFO    ] __main__: train step 9519: loss: 1.0466, policy_loss: 1.1175, value_loss: 0.7398
2024-07-11 16:34:58,376 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:34:58,811 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:34:58,872 [INFO    ] __main__: train step 9520: loss: 1.0466, policy_loss: 1.1174, value_loss: 0.7398
2024-07-11 16:34:59,053 [INFO    ] __main__: train step 9521: loss: 1.0466, policy_loss: 1.1173, value_loss: 0.7397
2024-07-11 16:34:59,303 [INFO    ] __main__: train step 9522: loss: 1.0466, policy_loss: 1.1173, value_loss: 0.7397
2024-07-11 16:34:59,545 [INFO    ] __main__: train step 9523: loss: 1.0466, policy_loss: 1.1172, value_loss: 0.7396
2024-07-11 16:34:59,738 [INFO    ] __main__: train step 9524: loss: 1.0465, policy_loss: 1.1171, value_loss: 0.7396
2024-07-11 16:34:59,946 [INFO    ] __main__: train step 9525: loss: 1.0465, policy_loss: 1.1171, value_loss: 0.7396
2024-07-11 16:35:00,159 [INFO    ] __main__: train step 9526: loss: 1.0465, policy_loss: 1.1170, value_loss: 0.7395
2024-07-11 16:35:00,366 [INFO    ] __main__: train step 9527: loss: 1.0465, policy_loss: 1.1169, value_loss: 0.7395
2024-07-11 16:35:00,568 [INFO    ] __main__: train step 9528: loss: 1.0465, policy_loss: 1.1169, value_loss: 0.7395
2024-07-11 16:35:00,762 [INFO    ] __main__: train step 9529: loss: 1.0464, policy_loss: 1.1168, value_loss: 0.7394
2024-07-11 16:35:00,966 [INFO    ] __main__: train step 9530: loss: 1.0464, policy_loss: 1.1167, value_loss: 0.7394
2024-07-11 16:35:01,170 [INFO    ] __main__: train step 9531: loss: 1.0464, policy_loss: 1.1167, value_loss: 0.7393
2024-07-11 16:35:01,374 [INFO    ] __main__: train step 9532: loss: 1.0464, policy_loss: 1.1166, value_loss: 0.7393
2024-07-11 16:35:01,578 [INFO    ] __main__: train step 9533: loss: 1.0464, policy_loss: 1.1165, value_loss: 0.7393
2024-07-11 16:35:01,778 [INFO    ] __main__: train step 9534: loss: 1.0463, policy_loss: 1.1165, value_loss: 0.7392
2024-07-11 16:35:01,996 [INFO    ] __main__: train step 9535: loss: 1.0463, policy_loss: 1.1164, value_loss: 0.7392
2024-07-11 16:35:02,206 [INFO    ] __main__: train step 9536: loss: 1.0463, policy_loss: 1.1163, value_loss: 0.7391
2024-07-11 16:35:03,661 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:35:04,031 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:35:04,086 [INFO    ] __main__: train step 9537: loss: 1.0463, policy_loss: 1.1163, value_loss: 0.7391
2024-07-11 16:35:04,258 [INFO    ] __main__: train step 9538: loss: 1.0463, policy_loss: 1.1162, value_loss: 0.7391
2024-07-11 16:35:04,463 [INFO    ] __main__: train step 9539: loss: 1.0462, policy_loss: 1.1161, value_loss: 0.7390
2024-07-11 16:35:04,661 [INFO    ] __main__: train step 9540: loss: 1.0462, policy_loss: 1.1161, value_loss: 0.7390
2024-07-11 16:35:04,860 [INFO    ] __main__: train step 9541: loss: 1.0462, policy_loss: 1.1160, value_loss: 0.7389
2024-07-11 16:35:05,076 [INFO    ] __main__: train step 9542: loss: 1.0462, policy_loss: 1.1159, value_loss: 0.7389
2024-07-11 16:35:05,283 [INFO    ] __main__: train step 9543: loss: 1.0461, policy_loss: 1.1159, value_loss: 0.7389
2024-07-11 16:35:05,516 [INFO    ] __main__: train step 9544: loss: 1.0461, policy_loss: 1.1158, value_loss: 0.7388
2024-07-11 16:35:05,730 [INFO    ] __main__: train step 9545: loss: 1.0461, policy_loss: 1.1157, value_loss: 0.7388
2024-07-11 16:35:05,927 [INFO    ] __main__: train step 9546: loss: 1.0461, policy_loss: 1.1157, value_loss: 0.7387
2024-07-11 16:35:06,130 [INFO    ] __main__: train step 9547: loss: 1.0461, policy_loss: 1.1156, value_loss: 0.7387
2024-07-11 16:35:06,331 [INFO    ] __main__: train step 9548: loss: 1.0460, policy_loss: 1.1155, value_loss: 0.7387
2024-07-11 16:35:06,524 [INFO    ] __main__: train step 9549: loss: 1.0460, policy_loss: 1.1155, value_loss: 0.7386
2024-07-11 16:35:06,731 [INFO    ] __main__: train step 9550: loss: 1.0460, policy_loss: 1.1154, value_loss: 0.7386
2024-07-11 16:35:06,935 [INFO    ] __main__: train step 9551: loss: 1.0460, policy_loss: 1.1153, value_loss: 0.7385
2024-07-11 16:35:07,142 [INFO    ] __main__: train step 9552: loss: 1.0460, policy_loss: 1.1153, value_loss: 0.7385
2024-07-11 16:35:07,336 [INFO    ] __main__: train step 9553: loss: 1.0459, policy_loss: 1.1152, value_loss: 0.7385
2024-07-11 16:35:08,785 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:35:09,153 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:35:09,209 [INFO    ] __main__: train step 9554: loss: 1.0459, policy_loss: 1.1151, value_loss: 0.7384
2024-07-11 16:35:09,381 [INFO    ] __main__: train step 9555: loss: 1.0459, policy_loss: 1.1151, value_loss: 0.7384
2024-07-11 16:35:09,580 [INFO    ] __main__: train step 9556: loss: 1.0459, policy_loss: 1.1150, value_loss: 0.7383
2024-07-11 16:35:09,784 [INFO    ] __main__: train step 9557: loss: 1.0458, policy_loss: 1.1149, value_loss: 0.7383
2024-07-11 16:35:09,983 [INFO    ] __main__: train step 9558: loss: 1.0458, policy_loss: 1.1149, value_loss: 0.7383
2024-07-11 16:35:10,180 [INFO    ] __main__: train step 9559: loss: 1.0458, policy_loss: 1.1148, value_loss: 0.7382
2024-07-11 16:35:10,384 [INFO    ] __main__: train step 9560: loss: 1.0458, policy_loss: 1.1147, value_loss: 0.7382
2024-07-11 16:35:10,591 [INFO    ] __main__: train step 9561: loss: 1.0458, policy_loss: 1.1147, value_loss: 0.7381
2024-07-11 16:35:10,786 [INFO    ] __main__: train step 9562: loss: 1.0457, policy_loss: 1.1146, value_loss: 0.7381
2024-07-11 16:35:10,993 [INFO    ] __main__: train step 9563: loss: 1.0457, policy_loss: 1.1145, value_loss: 0.7381
2024-07-11 16:35:11,191 [INFO    ] __main__: train step 9564: loss: 1.0457, policy_loss: 1.1145, value_loss: 0.7380
2024-07-11 16:35:11,402 [INFO    ] __main__: train step 9565: loss: 1.0457, policy_loss: 1.1144, value_loss: 0.7380
2024-07-11 16:35:11,600 [INFO    ] __main__: train step 9566: loss: 1.0456, policy_loss: 1.1143, value_loss: 0.7379
2024-07-11 16:35:11,811 [INFO    ] __main__: train step 9567: loss: 1.0456, policy_loss: 1.1143, value_loss: 0.7379
2024-07-11 16:35:12,017 [INFO    ] __main__: train step 9568: loss: 1.0456, policy_loss: 1.1142, value_loss: 0.7379
2024-07-11 16:35:12,263 [INFO    ] __main__: train step 9569: loss: 1.0456, policy_loss: 1.1142, value_loss: 0.7378
2024-07-11 16:35:12,505 [INFO    ] __main__: train step 9570: loss: 1.0456, policy_loss: 1.1141, value_loss: 0.7378
2024-07-11 16:35:13,939 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:35:14,351 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:35:14,408 [INFO    ] __main__: train step 9571: loss: 1.0455, policy_loss: 1.1140, value_loss: 0.7377
2024-07-11 16:35:14,583 [INFO    ] __main__: train step 9572: loss: 1.0455, policy_loss: 1.1140, value_loss: 0.7377
2024-07-11 16:35:15,632 [INFO    ] __main__: train step 9573: loss: 1.0455, policy_loss: 1.1139, value_loss: 0.7376
2024-07-11 16:35:15,844 [INFO    ] __main__: train step 9574: loss: 1.0455, policy_loss: 1.1138, value_loss: 0.7376
2024-07-11 16:35:16,043 [INFO    ] __main__: train step 9575: loss: 1.0454, policy_loss: 1.1138, value_loss: 0.7376
2024-07-11 16:35:16,246 [INFO    ] __main__: train step 9576: loss: 1.0454, policy_loss: 1.1137, value_loss: 0.7375
2024-07-11 16:35:16,455 [INFO    ] __main__: train step 9577: loss: 1.0454, policy_loss: 1.1136, value_loss: 0.7375
2024-07-11 16:35:16,645 [INFO    ] __main__: train step 9578: loss: 1.0454, policy_loss: 1.1136, value_loss: 0.7374
2024-07-11 16:35:16,861 [INFO    ] __main__: train step 9579: loss: 1.0453, policy_loss: 1.1135, value_loss: 0.7374
2024-07-11 16:35:17,058 [INFO    ] __main__: train step 9580: loss: 1.0453, policy_loss: 1.1134, value_loss: 0.7374
2024-07-11 16:35:17,278 [INFO    ] __main__: train step 9581: loss: 1.0453, policy_loss: 1.1134, value_loss: 0.7373
2024-07-11 16:35:17,507 [INFO    ] __main__: train step 9582: loss: 1.0453, policy_loss: 1.1133, value_loss: 0.7373
2024-07-11 16:35:17,704 [INFO    ] __main__: train step 9583: loss: 1.0453, policy_loss: 1.1132, value_loss: 0.7372
2024-07-11 16:35:17,905 [INFO    ] __main__: train step 9584: loss: 1.0452, policy_loss: 1.1132, value_loss: 0.7372
2024-07-11 16:35:18,112 [INFO    ] __main__: train step 9585: loss: 1.0452, policy_loss: 1.1131, value_loss: 0.7372
2024-07-11 16:35:18,311 [INFO    ] __main__: train step 9586: loss: 1.0452, policy_loss: 1.1130, value_loss: 0.7371
2024-07-11 16:35:18,526 [INFO    ] __main__: train step 9587: loss: 1.0452, policy_loss: 1.1130, value_loss: 0.7371
2024-07-11 16:35:20,010 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:35:20,407 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:35:20,467 [INFO    ] __main__: train step 9588: loss: 1.0451, policy_loss: 1.1129, value_loss: 0.7370
2024-07-11 16:35:20,657 [INFO    ] __main__: train step 9589: loss: 1.0451, policy_loss: 1.1128, value_loss: 0.7370
2024-07-11 16:35:20,859 [INFO    ] __main__: train step 9590: loss: 1.0451, policy_loss: 1.1128, value_loss: 0.7369
2024-07-11 16:35:21,053 [INFO    ] __main__: train step 9591: loss: 1.0451, policy_loss: 1.1127, value_loss: 0.7369
2024-07-11 16:35:21,259 [INFO    ] __main__: train step 9592: loss: 1.0450, policy_loss: 1.1126, value_loss: 0.7369
2024-07-11 16:35:21,459 [INFO    ] __main__: train step 9593: loss: 1.0450, policy_loss: 1.1126, value_loss: 0.7368
2024-07-11 16:35:21,667 [INFO    ] __main__: train step 9594: loss: 1.0450, policy_loss: 1.1125, value_loss: 0.7368
2024-07-11 16:35:21,864 [INFO    ] __main__: train step 9595: loss: 1.0450, policy_loss: 1.1124, value_loss: 0.7367
2024-07-11 16:35:22,063 [INFO    ] __main__: train step 9596: loss: 1.0450, policy_loss: 1.1124, value_loss: 0.7367
2024-07-11 16:35:22,256 [INFO    ] __main__: train step 9597: loss: 1.0449, policy_loss: 1.1123, value_loss: 0.7367
2024-07-11 16:35:22,447 [INFO    ] __main__: train step 9598: loss: 1.0449, policy_loss: 1.1122, value_loss: 0.7366
2024-07-11 16:35:22,648 [INFO    ] __main__: train step 9599: loss: 1.0449, policy_loss: 1.1122, value_loss: 0.7366
2024-07-11 16:35:22,852 [INFO    ] __main__: train step 9600: loss: 1.0449, policy_loss: 1.1121, value_loss: 0.7365
2024-07-11 16:35:23,053 [INFO    ] __main__: train step 9601: loss: 1.0448, policy_loss: 1.1121, value_loss: 0.7365
2024-07-11 16:35:23,248 [INFO    ] __main__: train step 9602: loss: 1.0448, policy_loss: 1.1120, value_loss: 0.7364
2024-07-11 16:35:23,450 [INFO    ] __main__: train step 9603: loss: 1.0448, policy_loss: 1.1119, value_loss: 0.7364
2024-07-11 16:35:23,662 [INFO    ] __main__: train step 9604: loss: 1.0448, policy_loss: 1.1119, value_loss: 0.7364
2024-07-11 16:35:25,088 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:35:25,445 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:35:25,502 [INFO    ] __main__: train step 9605: loss: 1.0448, policy_loss: 1.1118, value_loss: 0.7363
2024-07-11 16:35:25,670 [INFO    ] __main__: train step 9606: loss: 1.0447, policy_loss: 1.1117, value_loss: 0.7363
2024-07-11 16:35:25,872 [INFO    ] __main__: train step 9607: loss: 1.0447, policy_loss: 1.1117, value_loss: 0.7362
2024-07-11 16:35:26,079 [INFO    ] __main__: train step 9608: loss: 1.0447, policy_loss: 1.1116, value_loss: 0.7362
2024-07-11 16:35:26,297 [INFO    ] __main__: train step 9609: loss: 1.0447, policy_loss: 1.1115, value_loss: 0.7362
2024-07-11 16:35:26,524 [INFO    ] __main__: train step 9610: loss: 1.0446, policy_loss: 1.1115, value_loss: 0.7361
2024-07-11 16:35:26,731 [INFO    ] __main__: train step 9611: loss: 1.0446, policy_loss: 1.1114, value_loss: 0.7361
2024-07-11 16:35:26,933 [INFO    ] __main__: train step 9612: loss: 1.0446, policy_loss: 1.1113, value_loss: 0.7360
2024-07-11 16:35:27,142 [INFO    ] __main__: train step 9613: loss: 1.0446, policy_loss: 1.1113, value_loss: 0.7360
2024-07-11 16:35:27,346 [INFO    ] __main__: train step 9614: loss: 1.0446, policy_loss: 1.1112, value_loss: 0.7360
2024-07-11 16:35:27,556 [INFO    ] __main__: train step 9615: loss: 1.0445, policy_loss: 1.1111, value_loss: 0.7359
2024-07-11 16:35:27,759 [INFO    ] __main__: train step 9616: loss: 1.0445, policy_loss: 1.1111, value_loss: 0.7359
2024-07-11 16:35:27,966 [INFO    ] __main__: train step 9617: loss: 1.0445, policy_loss: 1.1110, value_loss: 0.7358
2024-07-11 16:35:28,170 [INFO    ] __main__: train step 9618: loss: 1.0445, policy_loss: 1.1109, value_loss: 0.7358
2024-07-11 16:35:28,372 [INFO    ] __main__: train step 9619: loss: 1.0444, policy_loss: 1.1109, value_loss: 0.7358
2024-07-11 16:35:28,568 [INFO    ] __main__: train step 9620: loss: 1.0444, policy_loss: 1.1108, value_loss: 0.7357
2024-07-11 16:35:28,770 [INFO    ] __main__: train step 9621: loss: 1.0444, policy_loss: 1.1107, value_loss: 0.7357
2024-07-11 16:35:30,198 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:35:30,602 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:35:30,662 [INFO    ] __main__: train step 9622: loss: 1.0444, policy_loss: 1.1107, value_loss: 0.7356
2024-07-11 16:35:30,839 [INFO    ] __main__: train step 9623: loss: 1.0443, policy_loss: 1.1106, value_loss: 0.7356
2024-07-11 16:35:31,038 [INFO    ] __main__: train step 9624: loss: 1.0443, policy_loss: 1.1106, value_loss: 0.7355
2024-07-11 16:35:31,245 [INFO    ] __main__: train step 9625: loss: 1.0443, policy_loss: 1.1105, value_loss: 0.7355
2024-07-11 16:35:31,452 [INFO    ] __main__: train step 9626: loss: 1.0443, policy_loss: 1.1104, value_loss: 0.7355
2024-07-11 16:35:31,657 [INFO    ] __main__: train step 9627: loss: 1.0442, policy_loss: 1.1104, value_loss: 0.7354
2024-07-11 16:35:31,885 [INFO    ] __main__: train step 9628: loss: 1.0442, policy_loss: 1.1103, value_loss: 0.7354
2024-07-11 16:35:32,089 [INFO    ] __main__: train step 9629: loss: 1.0442, policy_loss: 1.1102, value_loss: 0.7353
2024-07-11 16:35:32,305 [INFO    ] __main__: train step 9630: loss: 1.0442, policy_loss: 1.1102, value_loss: 0.7353
2024-07-11 16:35:32,530 [INFO    ] __main__: train step 9631: loss: 1.0442, policy_loss: 1.1101, value_loss: 0.7353
2024-07-11 16:35:32,728 [INFO    ] __main__: train step 9632: loss: 1.0441, policy_loss: 1.1100, value_loss: 0.7352
2024-07-11 16:35:32,932 [INFO    ] __main__: train step 9633: loss: 1.0441, policy_loss: 1.1100, value_loss: 0.7352
2024-07-11 16:35:33,137 [INFO    ] __main__: train step 9634: loss: 1.0441, policy_loss: 1.1099, value_loss: 0.7351
2024-07-11 16:35:33,345 [INFO    ] __main__: train step 9635: loss: 1.0441, policy_loss: 1.1098, value_loss: 0.7351
2024-07-11 16:35:33,540 [INFO    ] __main__: train step 9636: loss: 1.0440, policy_loss: 1.1098, value_loss: 0.7350
2024-07-11 16:35:33,744 [INFO    ] __main__: train step 9637: loss: 1.0440, policy_loss: 1.1097, value_loss: 0.7350
2024-07-11 16:35:33,942 [INFO    ] __main__: train step 9638: loss: 1.0440, policy_loss: 1.1096, value_loss: 0.7350
2024-07-11 16:35:35,386 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:35:35,748 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:35:35,802 [INFO    ] __main__: train step 9639: loss: 1.0440, policy_loss: 1.1096, value_loss: 0.7349
2024-07-11 16:35:35,973 [INFO    ] __main__: train step 9640: loss: 1.0439, policy_loss: 1.1095, value_loss: 0.7349
2024-07-11 16:35:36,193 [INFO    ] __main__: train step 9641: loss: 1.0439, policy_loss: 1.1094, value_loss: 0.7348
2024-07-11 16:35:36,392 [INFO    ] __main__: train step 9642: loss: 1.0439, policy_loss: 1.1094, value_loss: 0.7348
2024-07-11 16:35:36,595 [INFO    ] __main__: train step 9643: loss: 1.0439, policy_loss: 1.1093, value_loss: 0.7348
2024-07-11 16:35:36,798 [INFO    ] __main__: train step 9644: loss: 1.0438, policy_loss: 1.1092, value_loss: 0.7347
2024-07-11 16:35:37,000 [INFO    ] __main__: train step 9645: loss: 1.0438, policy_loss: 1.1092, value_loss: 0.7347
2024-07-11 16:35:37,208 [INFO    ] __main__: train step 9646: loss: 1.0438, policy_loss: 1.1091, value_loss: 0.7346
2024-07-11 16:35:38,334 [INFO    ] __main__: train step 9647: loss: 1.0438, policy_loss: 1.1090, value_loss: 0.7346
2024-07-11 16:35:38,532 [INFO    ] __main__: train step 9648: loss: 1.0437, policy_loss: 1.1090, value_loss: 0.7345
2024-07-11 16:35:38,747 [INFO    ] __main__: train step 9649: loss: 1.0437, policy_loss: 1.1089, value_loss: 0.7345
2024-07-11 16:35:38,953 [INFO    ] __main__: train step 9650: loss: 1.0437, policy_loss: 1.1089, value_loss: 0.7345
2024-07-11 16:35:39,161 [INFO    ] __main__: train step 9651: loss: 1.0437, policy_loss: 1.1088, value_loss: 0.7344
2024-07-11 16:35:39,364 [INFO    ] __main__: train step 9652: loss: 1.0437, policy_loss: 1.1087, value_loss: 0.7344
2024-07-11 16:35:39,564 [INFO    ] __main__: train step 9653: loss: 1.0436, policy_loss: 1.1087, value_loss: 0.7343
2024-07-11 16:35:39,769 [INFO    ] __main__: train step 9654: loss: 1.0436, policy_loss: 1.1086, value_loss: 0.7343
2024-07-11 16:35:39,967 [INFO    ] __main__: train step 9655: loss: 1.0436, policy_loss: 1.1085, value_loss: 0.7343
2024-07-11 16:35:41,392 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:35:41,769 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:35:41,824 [INFO    ] __main__: train step 9656: loss: 1.0436, policy_loss: 1.1085, value_loss: 0.7342
2024-07-11 16:35:42,002 [INFO    ] __main__: train step 9657: loss: 1.0435, policy_loss: 1.1084, value_loss: 0.7342
2024-07-11 16:35:42,196 [INFO    ] __main__: train step 9658: loss: 1.0435, policy_loss: 1.1083, value_loss: 0.7341
2024-07-11 16:35:42,401 [INFO    ] __main__: train step 9659: loss: 1.0435, policy_loss: 1.1083, value_loss: 0.7341
2024-07-11 16:35:42,600 [INFO    ] __main__: train step 9660: loss: 1.0435, policy_loss: 1.1082, value_loss: 0.7340
2024-07-11 16:35:42,798 [INFO    ] __main__: train step 9661: loss: 1.0434, policy_loss: 1.1081, value_loss: 0.7340
2024-07-11 16:35:43,008 [INFO    ] __main__: train step 9662: loss: 1.0434, policy_loss: 1.1081, value_loss: 0.7340
2024-07-11 16:35:43,221 [INFO    ] __main__: train step 9663: loss: 1.0434, policy_loss: 1.1080, value_loss: 0.7339
2024-07-11 16:35:43,422 [INFO    ] __main__: train step 9664: loss: 1.0434, policy_loss: 1.1079, value_loss: 0.7339
2024-07-11 16:35:43,623 [INFO    ] __main__: train step 9665: loss: 1.0433, policy_loss: 1.1079, value_loss: 0.7338
2024-07-11 16:35:43,818 [INFO    ] __main__: train step 9666: loss: 1.0433, policy_loss: 1.1078, value_loss: 0.7338
2024-07-11 16:35:44,030 [INFO    ] __main__: train step 9667: loss: 1.0433, policy_loss: 1.1077, value_loss: 0.7338
2024-07-11 16:35:44,229 [INFO    ] __main__: train step 9668: loss: 1.0433, policy_loss: 1.1077, value_loss: 0.7337
2024-07-11 16:35:44,430 [INFO    ] __main__: train step 9669: loss: 1.0432, policy_loss: 1.1076, value_loss: 0.7337
2024-07-11 16:35:44,661 [INFO    ] __main__: train step 9670: loss: 1.0432, policy_loss: 1.1075, value_loss: 0.7336
2024-07-11 16:35:44,894 [INFO    ] __main__: train step 9671: loss: 1.0432, policy_loss: 1.1075, value_loss: 0.7336
2024-07-11 16:35:45,135 [INFO    ] __main__: train step 9672: loss: 1.0432, policy_loss: 1.1074, value_loss: 0.7335
2024-07-11 16:35:46,570 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:35:46,900 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:35:46,958 [INFO    ] __main__: train step 9673: loss: 1.0431, policy_loss: 1.1073, value_loss: 0.7335
2024-07-11 16:35:47,158 [INFO    ] __main__: train step 9674: loss: 1.0431, policy_loss: 1.1073, value_loss: 0.7335
2024-07-11 16:35:47,383 [INFO    ] __main__: train step 9675: loss: 1.0431, policy_loss: 1.1072, value_loss: 0.7334
2024-07-11 16:35:47,584 [INFO    ] __main__: train step 9676: loss: 1.0431, policy_loss: 1.1072, value_loss: 0.7334
2024-07-11 16:35:47,804 [INFO    ] __main__: train step 9677: loss: 1.0430, policy_loss: 1.1071, value_loss: 0.7333
2024-07-11 16:35:48,032 [INFO    ] __main__: train step 9678: loss: 1.0430, policy_loss: 1.1070, value_loss: 0.7333
2024-07-11 16:35:48,243 [INFO    ] __main__: train step 9679: loss: 1.0430, policy_loss: 1.1070, value_loss: 0.7333
2024-07-11 16:35:48,439 [INFO    ] __main__: train step 9680: loss: 1.0430, policy_loss: 1.1069, value_loss: 0.7332
2024-07-11 16:35:48,645 [INFO    ] __main__: train step 9681: loss: 1.0429, policy_loss: 1.1068, value_loss: 0.7332
2024-07-11 16:35:48,859 [INFO    ] __main__: train step 9682: loss: 1.0429, policy_loss: 1.1068, value_loss: 0.7331
2024-07-11 16:35:49,074 [INFO    ] __main__: train step 9683: loss: 1.0429, policy_loss: 1.1067, value_loss: 0.7331
2024-07-11 16:35:49,310 [INFO    ] __main__: train step 9684: loss: 1.0429, policy_loss: 1.1066, value_loss: 0.7330
2024-07-11 16:35:49,516 [INFO    ] __main__: train step 9685: loss: 1.0428, policy_loss: 1.1066, value_loss: 0.7330
2024-07-11 16:35:49,715 [INFO    ] __main__: train step 9686: loss: 1.0428, policy_loss: 1.1065, value_loss: 0.7330
2024-07-11 16:35:49,921 [INFO    ] __main__: train step 9687: loss: 1.0428, policy_loss: 1.1064, value_loss: 0.7329
2024-07-11 16:35:50,122 [INFO    ] __main__: train step 9688: loss: 1.0428, policy_loss: 1.1064, value_loss: 0.7329
2024-07-11 16:35:50,334 [INFO    ] __main__: train step 9689: loss: 1.0427, policy_loss: 1.1063, value_loss: 0.7328
2024-07-11 16:35:51,781 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:35:52,179 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:35:52,240 [INFO    ] __main__: train step 9690: loss: 1.0427, policy_loss: 1.1062, value_loss: 0.7328
2024-07-11 16:35:52,413 [INFO    ] __main__: train step 9691: loss: 1.0427, policy_loss: 1.1062, value_loss: 0.7328
2024-07-11 16:35:52,636 [INFO    ] __main__: train step 9692: loss: 1.0427, policy_loss: 1.1061, value_loss: 0.7327
2024-07-11 16:35:52,865 [INFO    ] __main__: train step 9693: loss: 1.0426, policy_loss: 1.1060, value_loss: 0.7327
2024-07-11 16:35:53,080 [INFO    ] __main__: train step 9694: loss: 1.0426, policy_loss: 1.1060, value_loss: 0.7326
2024-07-11 16:35:53,297 [INFO    ] __main__: train step 9695: loss: 1.0426, policy_loss: 1.1059, value_loss: 0.7326
2024-07-11 16:35:53,535 [INFO    ] __main__: train step 9696: loss: 1.0426, policy_loss: 1.1058, value_loss: 0.7325
2024-07-11 16:35:53,744 [INFO    ] __main__: train step 9697: loss: 1.0425, policy_loss: 1.1058, value_loss: 0.7325
2024-07-11 16:35:53,942 [INFO    ] __main__: train step 9698: loss: 1.0425, policy_loss: 1.1057, value_loss: 0.7325
2024-07-11 16:35:54,155 [INFO    ] __main__: train step 9699: loss: 1.0425, policy_loss: 1.1057, value_loss: 0.7324
2024-07-11 16:35:54,358 [INFO    ] __main__: train step 9700: loss: 1.0425, policy_loss: 1.1056, value_loss: 0.7324
2024-07-11 16:35:54,563 [INFO    ] __main__: train step 9701: loss: 1.0424, policy_loss: 1.1055, value_loss: 0.7323
2024-07-11 16:35:54,768 [INFO    ] __main__: train step 9702: loss: 1.0424, policy_loss: 1.1055, value_loss: 0.7323
2024-07-11 16:35:54,974 [INFO    ] __main__: train step 9703: loss: 1.0424, policy_loss: 1.1054, value_loss: 0.7322
2024-07-11 16:35:55,182 [INFO    ] __main__: train step 9704: loss: 1.0424, policy_loss: 1.1053, value_loss: 0.7322
2024-07-11 16:35:55,391 [INFO    ] __main__: train step 9705: loss: 1.0423, policy_loss: 1.1053, value_loss: 0.7322
2024-07-11 16:35:55,588 [INFO    ] __main__: train step 9706: loss: 1.0423, policy_loss: 1.1052, value_loss: 0.7321
2024-07-11 16:35:57,039 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:35:57,470 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:35:57,533 [INFO    ] __main__: train step 9707: loss: 1.0423, policy_loss: 1.1051, value_loss: 0.7321
2024-07-11 16:35:57,701 [INFO    ] __main__: train step 9708: loss: 1.0423, policy_loss: 1.1051, value_loss: 0.7320
2024-07-11 16:35:57,905 [INFO    ] __main__: train step 9709: loss: 1.0422, policy_loss: 1.1050, value_loss: 0.7320
2024-07-11 16:35:58,101 [INFO    ] __main__: train step 9710: loss: 1.0422, policy_loss: 1.1049, value_loss: 0.7320
2024-07-11 16:35:58,311 [INFO    ] __main__: train step 9711: loss: 1.0422, policy_loss: 1.1049, value_loss: 0.7319
2024-07-11 16:35:58,518 [INFO    ] __main__: train step 9712: loss: 1.0422, policy_loss: 1.1048, value_loss: 0.7319
2024-07-11 16:35:58,736 [INFO    ] __main__: train step 9713: loss: 1.0421, policy_loss: 1.1047, value_loss: 0.7318
2024-07-11 16:35:58,939 [INFO    ] __main__: train step 9714: loss: 1.0421, policy_loss: 1.1047, value_loss: 0.7318
2024-07-11 16:35:59,142 [INFO    ] __main__: train step 9715: loss: 1.0421, policy_loss: 1.1046, value_loss: 0.7318
2024-07-11 16:35:59,391 [INFO    ] __main__: train step 9716: loss: 1.0421, policy_loss: 1.1045, value_loss: 0.7317
2024-07-11 16:35:59,622 [INFO    ] __main__: train step 9717: loss: 1.0420, policy_loss: 1.1045, value_loss: 0.7317
2024-07-11 16:35:59,851 [INFO    ] __main__: train step 9718: loss: 1.0420, policy_loss: 1.1044, value_loss: 0.7316
2024-07-11 16:36:00,062 [INFO    ] __main__: train step 9719: loss: 1.0420, policy_loss: 1.1043, value_loss: 0.7316
2024-07-11 16:36:01,130 [INFO    ] __main__: train step 9720: loss: 1.0420, policy_loss: 1.1043, value_loss: 0.7315
2024-07-11 16:36:01,351 [INFO    ] __main__: train step 9721: loss: 1.0419, policy_loss: 1.1042, value_loss: 0.7315
2024-07-11 16:36:01,573 [INFO    ] __main__: train step 9722: loss: 1.0419, policy_loss: 1.1042, value_loss: 0.7315
2024-07-11 16:36:01,779 [INFO    ] __main__: train step 9723: loss: 1.0419, policy_loss: 1.1041, value_loss: 0.7314
2024-07-11 16:36:03,234 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:36:03,661 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:36:03,726 [INFO    ] __main__: train step 9724: loss: 1.0419, policy_loss: 1.1040, value_loss: 0.7314
2024-07-11 16:36:03,904 [INFO    ] __main__: train step 9725: loss: 1.0418, policy_loss: 1.1040, value_loss: 0.7313
2024-07-11 16:36:04,105 [INFO    ] __main__: train step 9726: loss: 1.0418, policy_loss: 1.1039, value_loss: 0.7313
2024-07-11 16:36:04,307 [INFO    ] __main__: train step 9727: loss: 1.0418, policy_loss: 1.1038, value_loss: 0.7313
2024-07-11 16:36:04,502 [INFO    ] __main__: train step 9728: loss: 1.0418, policy_loss: 1.1038, value_loss: 0.7312
2024-07-11 16:36:04,697 [INFO    ] __main__: train step 9729: loss: 1.0417, policy_loss: 1.1037, value_loss: 0.7312
2024-07-11 16:36:04,899 [INFO    ] __main__: train step 9730: loss: 1.0417, policy_loss: 1.1036, value_loss: 0.7311
2024-07-11 16:36:05,115 [INFO    ] __main__: train step 9731: loss: 1.0417, policy_loss: 1.1036, value_loss: 0.7311
2024-07-11 16:36:05,317 [INFO    ] __main__: train step 9732: loss: 1.0417, policy_loss: 1.1035, value_loss: 0.7310
2024-07-11 16:36:05,519 [INFO    ] __main__: train step 9733: loss: 1.0416, policy_loss: 1.1034, value_loss: 0.7310
2024-07-11 16:36:05,728 [INFO    ] __main__: train step 9734: loss: 1.0416, policy_loss: 1.1034, value_loss: 0.7310
2024-07-11 16:36:05,945 [INFO    ] __main__: train step 9735: loss: 1.0416, policy_loss: 1.1033, value_loss: 0.7309
2024-07-11 16:36:06,142 [INFO    ] __main__: train step 9736: loss: 1.0416, policy_loss: 1.1032, value_loss: 0.7309
2024-07-11 16:36:06,347 [INFO    ] __main__: train step 9737: loss: 1.0415, policy_loss: 1.1032, value_loss: 0.7308
2024-07-11 16:36:06,559 [INFO    ] __main__: train step 9738: loss: 1.0415, policy_loss: 1.1031, value_loss: 0.7308
2024-07-11 16:36:06,757 [INFO    ] __main__: train step 9739: loss: 1.0415, policy_loss: 1.1030, value_loss: 0.7308
2024-07-11 16:36:06,964 [INFO    ] __main__: train step 9740: loss: 1.0415, policy_loss: 1.1030, value_loss: 0.7307
2024-07-11 16:36:08,407 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:36:08,820 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:36:08,879 [INFO    ] __main__: train step 9741: loss: 1.0414, policy_loss: 1.1029, value_loss: 0.7307
2024-07-11 16:36:09,053 [INFO    ] __main__: train step 9742: loss: 1.0414, policy_loss: 1.1029, value_loss: 0.7306
2024-07-11 16:36:09,260 [INFO    ] __main__: train step 9743: loss: 1.0414, policy_loss: 1.1028, value_loss: 0.7306
2024-07-11 16:36:09,460 [INFO    ] __main__: train step 9744: loss: 1.0414, policy_loss: 1.1027, value_loss: 0.7306
2024-07-11 16:36:09,662 [INFO    ] __main__: train step 9745: loss: 1.0413, policy_loss: 1.1027, value_loss: 0.7305
2024-07-11 16:36:09,866 [INFO    ] __main__: train step 9746: loss: 1.0413, policy_loss: 1.1026, value_loss: 0.7305
2024-07-11 16:36:10,068 [INFO    ] __main__: train step 9747: loss: 1.0413, policy_loss: 1.1025, value_loss: 0.7304
2024-07-11 16:36:10,267 [INFO    ] __main__: train step 9748: loss: 1.0413, policy_loss: 1.1025, value_loss: 0.7304
2024-07-11 16:36:10,474 [INFO    ] __main__: train step 9749: loss: 1.0412, policy_loss: 1.1024, value_loss: 0.7303
2024-07-11 16:36:10,681 [INFO    ] __main__: train step 9750: loss: 1.0412, policy_loss: 1.1023, value_loss: 0.7303
2024-07-11 16:36:10,878 [INFO    ] __main__: train step 9751: loss: 1.0412, policy_loss: 1.1023, value_loss: 0.7303
2024-07-11 16:36:11,106 [INFO    ] __main__: train step 9752: loss: 1.0412, policy_loss: 1.1022, value_loss: 0.7302
2024-07-11 16:36:11,341 [INFO    ] __main__: train step 9753: loss: 1.0411, policy_loss: 1.1021, value_loss: 0.7302
2024-07-11 16:36:11,537 [INFO    ] __main__: train step 9754: loss: 1.0411, policy_loss: 1.1021, value_loss: 0.7301
2024-07-11 16:36:11,754 [INFO    ] __main__: train step 9755: loss: 1.0411, policy_loss: 1.1020, value_loss: 0.7301
2024-07-11 16:36:11,973 [INFO    ] __main__: train step 9756: loss: 1.0411, policy_loss: 1.1019, value_loss: 0.7301
2024-07-11 16:36:12,177 [INFO    ] __main__: train step 9757: loss: 1.0410, policy_loss: 1.1019, value_loss: 0.7300
2024-07-11 16:36:13,621 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:36:14,031 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:36:14,093 [INFO    ] __main__: train step 9758: loss: 1.0410, policy_loss: 1.1018, value_loss: 0.7300
2024-07-11 16:36:14,269 [INFO    ] __main__: train step 9759: loss: 1.0410, policy_loss: 1.1018, value_loss: 0.7299
2024-07-11 16:36:14,489 [INFO    ] __main__: train step 9760: loss: 1.0410, policy_loss: 1.1017, value_loss: 0.7299
2024-07-11 16:36:14,701 [INFO    ] __main__: train step 9761: loss: 1.0409, policy_loss: 1.1016, value_loss: 0.7298
2024-07-11 16:36:14,930 [INFO    ] __main__: train step 9762: loss: 1.0409, policy_loss: 1.1016, value_loss: 0.7298
2024-07-11 16:36:15,159 [INFO    ] __main__: train step 9763: loss: 1.0409, policy_loss: 1.1015, value_loss: 0.7298
2024-07-11 16:36:15,359 [INFO    ] __main__: train step 9764: loss: 1.0409, policy_loss: 1.1014, value_loss: 0.7297
2024-07-11 16:36:15,565 [INFO    ] __main__: train step 9765: loss: 1.0408, policy_loss: 1.1014, value_loss: 0.7297
2024-07-11 16:36:15,764 [INFO    ] __main__: train step 9766: loss: 1.0408, policy_loss: 1.1013, value_loss: 0.7296
2024-07-11 16:36:15,973 [INFO    ] __main__: train step 9767: loss: 1.0408, policy_loss: 1.1012, value_loss: 0.7296
2024-07-11 16:36:16,177 [INFO    ] __main__: train step 9768: loss: 1.0408, policy_loss: 1.1012, value_loss: 0.7296
2024-07-11 16:36:16,381 [INFO    ] __main__: train step 9769: loss: 1.0407, policy_loss: 1.1011, value_loss: 0.7295
2024-07-11 16:36:16,581 [INFO    ] __main__: train step 9770: loss: 1.0407, policy_loss: 1.1010, value_loss: 0.7295
2024-07-11 16:36:16,808 [INFO    ] __main__: train step 9771: loss: 1.0407, policy_loss: 1.1010, value_loss: 0.7294
2024-07-11 16:36:17,005 [INFO    ] __main__: train step 9772: loss: 1.0407, policy_loss: 1.1009, value_loss: 0.7294
2024-07-11 16:36:17,211 [INFO    ] __main__: train step 9773: loss: 1.0406, policy_loss: 1.1008, value_loss: 0.7293
2024-07-11 16:36:17,412 [INFO    ] __main__: train step 9774: loss: 1.0406, policy_loss: 1.1008, value_loss: 0.7293
2024-07-11 16:36:18,862 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:36:19,149 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:36:19,204 [INFO    ] __main__: train step 9775: loss: 1.0406, policy_loss: 1.1007, value_loss: 0.7293
2024-07-11 16:36:19,373 [INFO    ] __main__: train step 9776: loss: 1.0406, policy_loss: 1.1006, value_loss: 0.7292
2024-07-11 16:36:19,566 [INFO    ] __main__: train step 9777: loss: 1.0405, policy_loss: 1.1006, value_loss: 0.7292
2024-07-11 16:36:19,789 [INFO    ] __main__: train step 9778: loss: 1.0405, policy_loss: 1.1005, value_loss: 0.7291
2024-07-11 16:36:19,992 [INFO    ] __main__: train step 9779: loss: 1.0405, policy_loss: 1.1004, value_loss: 0.7291
2024-07-11 16:36:20,195 [INFO    ] __main__: train step 9780: loss: 1.0404, policy_loss: 1.1004, value_loss: 0.7291
2024-07-11 16:36:20,397 [INFO    ] __main__: train step 9781: loss: 1.0404, policy_loss: 1.1003, value_loss: 0.7290
2024-07-11 16:36:20,591 [INFO    ] __main__: train step 9782: loss: 1.0404, policy_loss: 1.1003, value_loss: 0.7290
2024-07-11 16:36:20,803 [INFO    ] __main__: train step 9783: loss: 1.0404, policy_loss: 1.1002, value_loss: 0.7289
2024-07-11 16:36:21,005 [INFO    ] __main__: train step 9784: loss: 1.0403, policy_loss: 1.1001, value_loss: 0.7289
2024-07-11 16:36:21,207 [INFO    ] __main__: train step 9785: loss: 1.0403, policy_loss: 1.1001, value_loss: 0.7288
2024-07-11 16:36:21,420 [INFO    ] __main__: train step 9786: loss: 1.0403, policy_loss: 1.1000, value_loss: 0.7288
2024-07-11 16:36:21,649 [INFO    ] __main__: train step 9787: loss: 1.0403, policy_loss: 1.0999, value_loss: 0.7288
2024-07-11 16:36:21,854 [INFO    ] __main__: train step 9788: loss: 1.0402, policy_loss: 1.0999, value_loss: 0.7287
2024-07-11 16:36:22,047 [INFO    ] __main__: train step 9789: loss: 1.0402, policy_loss: 1.0998, value_loss: 0.7287
2024-07-11 16:36:22,250 [INFO    ] __main__: train step 9790: loss: 1.0402, policy_loss: 1.0997, value_loss: 0.7286
2024-07-11 16:36:22,458 [INFO    ] __main__: train step 9791: loss: 1.0402, policy_loss: 1.0997, value_loss: 0.7286
2024-07-11 16:36:23,894 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:36:24,294 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:36:24,347 [INFO    ] __main__: train step 9792: loss: 1.0401, policy_loss: 1.0996, value_loss: 0.7286
2024-07-11 16:36:25,349 [INFO    ] __main__: train step 9793: loss: 1.0401, policy_loss: 1.0995, value_loss: 0.7285
2024-07-11 16:36:25,561 [INFO    ] __main__: train step 9794: loss: 1.0401, policy_loss: 1.0995, value_loss: 0.7285
2024-07-11 16:36:25,767 [INFO    ] __main__: train step 9795: loss: 1.0401, policy_loss: 1.0994, value_loss: 0.7284
2024-07-11 16:36:25,986 [INFO    ] __main__: train step 9796: loss: 1.0400, policy_loss: 1.0993, value_loss: 0.7284
2024-07-11 16:36:26,215 [INFO    ] __main__: train step 9797: loss: 1.0400, policy_loss: 1.0993, value_loss: 0.7284
2024-07-11 16:36:26,420 [INFO    ] __main__: train step 9798: loss: 1.0400, policy_loss: 1.0992, value_loss: 0.7283
2024-07-11 16:36:26,634 [INFO    ] __main__: train step 9799: loss: 1.0400, policy_loss: 1.0992, value_loss: 0.7283
2024-07-11 16:36:26,835 [INFO    ] __main__: train step 9800: loss: 1.0399, policy_loss: 1.0991, value_loss: 0.7282
2024-07-11 16:36:27,050 [INFO    ] __main__: train step 9801: loss: 1.0399, policy_loss: 1.0990, value_loss: 0.7282
2024-07-11 16:36:27,248 [INFO    ] __main__: train step 9802: loss: 1.0399, policy_loss: 1.0990, value_loss: 0.7281
2024-07-11 16:36:27,444 [INFO    ] __main__: train step 9803: loss: 1.0399, policy_loss: 1.0989, value_loss: 0.7281
2024-07-11 16:36:27,645 [INFO    ] __main__: train step 9804: loss: 1.0398, policy_loss: 1.0988, value_loss: 0.7281
2024-07-11 16:36:27,847 [INFO    ] __main__: train step 9805: loss: 1.0398, policy_loss: 1.0988, value_loss: 0.7280
2024-07-11 16:36:28,047 [INFO    ] __main__: train step 9806: loss: 1.0398, policy_loss: 1.0987, value_loss: 0.7280
2024-07-11 16:36:28,252 [INFO    ] __main__: train step 9807: loss: 1.0398, policy_loss: 1.0986, value_loss: 0.7279
2024-07-11 16:36:28,446 [INFO    ] __main__: train step 9808: loss: 1.0397, policy_loss: 1.0986, value_loss: 0.7279
2024-07-11 16:36:29,881 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:36:30,280 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:36:30,336 [INFO    ] __main__: train step 9809: loss: 1.0397, policy_loss: 1.0985, value_loss: 0.7279
2024-07-11 16:36:30,513 [INFO    ] __main__: train step 9810: loss: 1.0397, policy_loss: 1.0984, value_loss: 0.7278
2024-07-11 16:36:30,721 [INFO    ] __main__: train step 9811: loss: 1.0397, policy_loss: 1.0984, value_loss: 0.7278
2024-07-11 16:36:30,915 [INFO    ] __main__: train step 9812: loss: 1.0396, policy_loss: 1.0983, value_loss: 0.7277
2024-07-11 16:36:31,118 [INFO    ] __main__: train step 9813: loss: 1.0396, policy_loss: 1.0982, value_loss: 0.7277
2024-07-11 16:36:31,315 [INFO    ] __main__: train step 9814: loss: 1.0396, policy_loss: 1.0982, value_loss: 0.7277
2024-07-11 16:36:31,524 [INFO    ] __main__: train step 9815: loss: 1.0396, policy_loss: 1.0981, value_loss: 0.7276
2024-07-11 16:36:31,721 [INFO    ] __main__: train step 9816: loss: 1.0395, policy_loss: 1.0981, value_loss: 0.7276
2024-07-11 16:36:31,927 [INFO    ] __main__: train step 9817: loss: 1.0395, policy_loss: 1.0980, value_loss: 0.7275
2024-07-11 16:36:32,148 [INFO    ] __main__: train step 9818: loss: 1.0395, policy_loss: 1.0979, value_loss: 0.7275
2024-07-11 16:36:32,377 [INFO    ] __main__: train step 9819: loss: 1.0395, policy_loss: 1.0979, value_loss: 0.7274
2024-07-11 16:36:32,578 [INFO    ] __main__: train step 9820: loss: 1.0394, policy_loss: 1.0978, value_loss: 0.7274
2024-07-11 16:36:32,781 [INFO    ] __main__: train step 9821: loss: 1.0394, policy_loss: 1.0977, value_loss: 0.7274
2024-07-11 16:36:32,994 [INFO    ] __main__: train step 9822: loss: 1.0394, policy_loss: 1.0977, value_loss: 0.7273
2024-07-11 16:36:33,205 [INFO    ] __main__: train step 9823: loss: 1.0394, policy_loss: 1.0976, value_loss: 0.7273
2024-07-11 16:36:33,415 [INFO    ] __main__: train step 9824: loss: 1.0393, policy_loss: 1.0975, value_loss: 0.7272
2024-07-11 16:36:33,613 [INFO    ] __main__: train step 9825: loss: 1.0393, policy_loss: 1.0975, value_loss: 0.7272
2024-07-11 16:36:35,063 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:36:35,477 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:36:35,533 [INFO    ] __main__: train step 9826: loss: 1.0393, policy_loss: 1.0974, value_loss: 0.7272
2024-07-11 16:36:35,728 [INFO    ] __main__: train step 9827: loss: 1.0393, policy_loss: 1.0974, value_loss: 0.7271
2024-07-11 16:36:35,953 [INFO    ] __main__: train step 9828: loss: 1.0392, policy_loss: 1.0973, value_loss: 0.7271
2024-07-11 16:36:36,181 [INFO    ] __main__: train step 9829: loss: 1.0392, policy_loss: 1.0972, value_loss: 0.7270
2024-07-11 16:36:36,410 [INFO    ] __main__: train step 9830: loss: 1.0392, policy_loss: 1.0972, value_loss: 0.7270
2024-07-11 16:36:36,613 [INFO    ] __main__: train step 9831: loss: 1.0392, policy_loss: 1.0971, value_loss: 0.7270
2024-07-11 16:36:36,828 [INFO    ] __main__: train step 9832: loss: 1.0391, policy_loss: 1.0970, value_loss: 0.7269
2024-07-11 16:36:37,035 [INFO    ] __main__: train step 9833: loss: 1.0391, policy_loss: 1.0970, value_loss: 0.7269
2024-07-11 16:36:37,253 [INFO    ] __main__: train step 9834: loss: 1.0391, policy_loss: 1.0969, value_loss: 0.7268
2024-07-11 16:36:37,445 [INFO    ] __main__: train step 9835: loss: 1.0391, policy_loss: 1.0968, value_loss: 0.7268
2024-07-11 16:36:37,654 [INFO    ] __main__: train step 9836: loss: 1.0390, policy_loss: 1.0968, value_loss: 0.7268
2024-07-11 16:36:37,854 [INFO    ] __main__: train step 9837: loss: 1.0390, policy_loss: 1.0967, value_loss: 0.7267
2024-07-11 16:36:38,071 [INFO    ] __main__: train step 9838: loss: 1.0390, policy_loss: 1.0966, value_loss: 0.7267
2024-07-11 16:36:38,284 [INFO    ] __main__: train step 9839: loss: 1.0390, policy_loss: 1.0966, value_loss: 0.7266
2024-07-11 16:36:38,487 [INFO    ] __main__: train step 9840: loss: 1.0389, policy_loss: 1.0965, value_loss: 0.7266
2024-07-11 16:36:38,694 [INFO    ] __main__: train step 9841: loss: 1.0389, policy_loss: 1.0965, value_loss: 0.7265
2024-07-11 16:36:38,907 [INFO    ] __main__: train step 9842: loss: 1.0389, policy_loss: 1.0964, value_loss: 0.7265
2024-07-11 16:36:40,359 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:36:40,782 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:36:40,836 [INFO    ] __main__: train step 9843: loss: 1.0389, policy_loss: 1.0963, value_loss: 0.7265
2024-07-11 16:36:41,023 [INFO    ] __main__: train step 9844: loss: 1.0388, policy_loss: 1.0963, value_loss: 0.7264
2024-07-11 16:36:41,217 [INFO    ] __main__: train step 9845: loss: 1.0388, policy_loss: 1.0962, value_loss: 0.7264
2024-07-11 16:36:41,437 [INFO    ] __main__: train step 9846: loss: 1.0388, policy_loss: 1.0961, value_loss: 0.7263
2024-07-11 16:36:41,667 [INFO    ] __main__: train step 9847: loss: 1.0388, policy_loss: 1.0961, value_loss: 0.7263
2024-07-11 16:36:41,874 [INFO    ] __main__: train step 9848: loss: 1.0387, policy_loss: 1.0960, value_loss: 0.7263
2024-07-11 16:36:42,071 [INFO    ] __main__: train step 9849: loss: 1.0387, policy_loss: 1.0959, value_loss: 0.7262
2024-07-11 16:36:42,268 [INFO    ] __main__: train step 9850: loss: 1.0387, policy_loss: 1.0959, value_loss: 0.7262
2024-07-11 16:36:42,483 [INFO    ] __main__: train step 9851: loss: 1.0386, policy_loss: 1.0958, value_loss: 0.7261
2024-07-11 16:36:42,678 [INFO    ] __main__: train step 9852: loss: 1.0386, policy_loss: 1.0958, value_loss: 0.7261
2024-07-11 16:36:42,875 [INFO    ] __main__: train step 9853: loss: 1.0386, policy_loss: 1.0957, value_loss: 0.7261
2024-07-11 16:36:43,077 [INFO    ] __main__: train step 9854: loss: 1.0386, policy_loss: 1.0956, value_loss: 0.7260
2024-07-11 16:36:43,271 [INFO    ] __main__: train step 9855: loss: 1.0385, policy_loss: 1.0956, value_loss: 0.7260
2024-07-11 16:36:43,477 [INFO    ] __main__: train step 9856: loss: 1.0385, policy_loss: 1.0955, value_loss: 0.7259
2024-07-11 16:36:43,676 [INFO    ] __main__: train step 9857: loss: 1.0385, policy_loss: 1.0954, value_loss: 0.7259
2024-07-11 16:36:43,881 [INFO    ] __main__: train step 9858: loss: 1.0385, policy_loss: 1.0954, value_loss: 0.7258
2024-07-11 16:36:44,082 [INFO    ] __main__: train step 9859: loss: 1.0385, policy_loss: 1.0953, value_loss: 0.7258
2024-07-11 16:36:45,559 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:36:45,979 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:36:46,038 [INFO    ] __main__: train step 9860: loss: 1.0384, policy_loss: 1.0953, value_loss: 0.7258
2024-07-11 16:36:46,209 [INFO    ] __main__: train step 9861: loss: 1.0384, policy_loss: 1.0952, value_loss: 0.7257
2024-07-11 16:36:46,417 [INFO    ] __main__: train step 9862: loss: 1.0384, policy_loss: 1.0951, value_loss: 0.7257
2024-07-11 16:36:46,616 [INFO    ] __main__: train step 9863: loss: 1.0384, policy_loss: 1.0951, value_loss: 0.7256
2024-07-11 16:36:46,823 [INFO    ] __main__: train step 9864: loss: 1.0383, policy_loss: 1.0950, value_loss: 0.7256
2024-07-11 16:36:47,939 [INFO    ] __main__: train step 9865: loss: 1.0383, policy_loss: 1.0949, value_loss: 0.7256
2024-07-11 16:36:48,144 [INFO    ] __main__: train step 9866: loss: 1.0383, policy_loss: 1.0949, value_loss: 0.7255
2024-07-11 16:36:48,359 [INFO    ] __main__: train step 9867: loss: 1.0383, policy_loss: 1.0948, value_loss: 0.7255
2024-07-11 16:36:48,582 [INFO    ] __main__: train step 9868: loss: 1.0382, policy_loss: 1.0947, value_loss: 0.7254
2024-07-11 16:36:48,785 [INFO    ] __main__: train step 9869: loss: 1.0382, policy_loss: 1.0947, value_loss: 0.7254
2024-07-11 16:36:48,977 [INFO    ] __main__: train step 9870: loss: 1.0382, policy_loss: 1.0946, value_loss: 0.7254
2024-07-11 16:36:49,182 [INFO    ] __main__: train step 9871: loss: 1.0382, policy_loss: 1.0946, value_loss: 0.7253
2024-07-11 16:36:49,388 [INFO    ] __main__: train step 9872: loss: 1.0381, policy_loss: 1.0945, value_loss: 0.7253
2024-07-11 16:36:49,591 [INFO    ] __main__: train step 9873: loss: 1.0381, policy_loss: 1.0944, value_loss: 0.7252
2024-07-11 16:36:49,794 [INFO    ] __main__: train step 9874: loss: 1.0381, policy_loss: 1.0944, value_loss: 0.7252
2024-07-11 16:36:49,991 [INFO    ] __main__: train step 9875: loss: 1.0381, policy_loss: 1.0943, value_loss: 0.7252
2024-07-11 16:36:50,215 [INFO    ] __main__: train step 9876: loss: 1.0380, policy_loss: 1.0942, value_loss: 0.7251
2024-07-11 16:36:51,679 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:36:52,119 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:36:52,179 [INFO    ] __main__: train step 9877: loss: 1.0380, policy_loss: 1.0942, value_loss: 0.7251
2024-07-11 16:36:52,349 [INFO    ] __main__: train step 9878: loss: 1.0380, policy_loss: 1.0941, value_loss: 0.7250
2024-07-11 16:36:52,557 [INFO    ] __main__: train step 9879: loss: 1.0380, policy_loss: 1.0940, value_loss: 0.7250
2024-07-11 16:36:52,761 [INFO    ] __main__: train step 9880: loss: 1.0379, policy_loss: 1.0940, value_loss: 0.7250
2024-07-11 16:36:52,969 [INFO    ] __main__: train step 9881: loss: 1.0379, policy_loss: 1.0939, value_loss: 0.7249
2024-07-11 16:36:53,184 [INFO    ] __main__: train step 9882: loss: 1.0379, policy_loss: 1.0939, value_loss: 0.7249
2024-07-11 16:36:53,378 [INFO    ] __main__: train step 9883: loss: 1.0379, policy_loss: 1.0938, value_loss: 0.7248
2024-07-11 16:36:53,588 [INFO    ] __main__: train step 9884: loss: 1.0378, policy_loss: 1.0937, value_loss: 0.7248
2024-07-11 16:36:53,797 [INFO    ] __main__: train step 9885: loss: 1.0378, policy_loss: 1.0937, value_loss: 0.7247
2024-07-11 16:36:54,007 [INFO    ] __main__: train step 9886: loss: 1.0378, policy_loss: 1.0936, value_loss: 0.7247
2024-07-11 16:36:54,200 [INFO    ] __main__: train step 9887: loss: 1.0377, policy_loss: 1.0935, value_loss: 0.7247
2024-07-11 16:36:54,407 [INFO    ] __main__: train step 9888: loss: 1.0377, policy_loss: 1.0935, value_loss: 0.7246
2024-07-11 16:36:54,637 [INFO    ] __main__: train step 9889: loss: 1.0377, policy_loss: 1.0934, value_loss: 0.7246
2024-07-11 16:36:54,840 [INFO    ] __main__: train step 9890: loss: 1.0377, policy_loss: 1.0933, value_loss: 0.7245
2024-07-11 16:36:55,039 [INFO    ] __main__: train step 9891: loss: 1.0376, policy_loss: 1.0933, value_loss: 0.7245
2024-07-11 16:36:55,235 [INFO    ] __main__: train step 9892: loss: 1.0376, policy_loss: 1.0932, value_loss: 0.7245
2024-07-11 16:36:55,434 [INFO    ] __main__: train step 9893: loss: 1.0376, policy_loss: 1.0932, value_loss: 0.7244
2024-07-11 16:36:56,875 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:36:57,323 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:36:57,388 [INFO    ] __main__: train step 9894: loss: 1.0376, policy_loss: 1.0931, value_loss: 0.7244
2024-07-11 16:36:57,570 [INFO    ] __main__: train step 9895: loss: 1.0376, policy_loss: 1.0930, value_loss: 0.7243
2024-07-11 16:36:57,778 [INFO    ] __main__: train step 9896: loss: 1.0375, policy_loss: 1.0930, value_loss: 0.7243
2024-07-11 16:36:57,983 [INFO    ] __main__: train step 9897: loss: 1.0375, policy_loss: 1.0929, value_loss: 0.7243
2024-07-11 16:36:58,189 [INFO    ] __main__: train step 9898: loss: 1.0375, policy_loss: 1.0928, value_loss: 0.7242
2024-07-11 16:36:58,401 [INFO    ] __main__: train step 9899: loss: 1.0375, policy_loss: 1.0928, value_loss: 0.7242
2024-07-11 16:36:58,608 [INFO    ] __main__: train step 9900: loss: 1.0374, policy_loss: 1.0927, value_loss: 0.7241
2024-07-11 16:36:58,807 [INFO    ] __main__: train step 9901: loss: 1.0374, policy_loss: 1.0927, value_loss: 0.7241
2024-07-11 16:36:59,028 [INFO    ] __main__: train step 9902: loss: 1.0374, policy_loss: 1.0926, value_loss: 0.7241
2024-07-11 16:36:59,240 [INFO    ] __main__: train step 9903: loss: 1.0374, policy_loss: 1.0925, value_loss: 0.7240
2024-07-11 16:36:59,439 [INFO    ] __main__: train step 9904: loss: 1.0373, policy_loss: 1.0925, value_loss: 0.7240
2024-07-11 16:36:59,654 [INFO    ] __main__: train step 9905: loss: 1.0373, policy_loss: 1.0924, value_loss: 0.7239
2024-07-11 16:36:59,875 [INFO    ] __main__: train step 9906: loss: 1.0373, policy_loss: 1.0923, value_loss: 0.7239
2024-07-11 16:37:00,100 [INFO    ] __main__: train step 9907: loss: 1.0373, policy_loss: 1.0923, value_loss: 0.7239
2024-07-11 16:37:00,301 [INFO    ] __main__: train step 9908: loss: 1.0372, policy_loss: 1.0922, value_loss: 0.7238
2024-07-11 16:37:00,516 [INFO    ] __main__: train step 9909: loss: 1.0372, policy_loss: 1.0922, value_loss: 0.7238
2024-07-11 16:37:00,752 [INFO    ] __main__: train step 9910: loss: 1.0372, policy_loss: 1.0921, value_loss: 0.7237
2024-07-11 16:37:02,204 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:37:02,750 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:37:02,810 [INFO    ] __main__: train step 9911: loss: 1.0372, policy_loss: 1.0920, value_loss: 0.7237
2024-07-11 16:37:02,977 [INFO    ] __main__: train step 9912: loss: 1.0371, policy_loss: 1.0920, value_loss: 0.7237
2024-07-11 16:37:03,186 [INFO    ] __main__: train step 9913: loss: 1.0371, policy_loss: 1.0919, value_loss: 0.7236
2024-07-11 16:37:03,379 [INFO    ] __main__: train step 9914: loss: 1.0371, policy_loss: 1.0918, value_loss: 0.7236
2024-07-11 16:37:03,571 [INFO    ] __main__: train step 9915: loss: 1.0371, policy_loss: 1.0918, value_loss: 0.7235
2024-07-11 16:37:03,773 [INFO    ] __main__: train step 9916: loss: 1.0371, policy_loss: 1.0917, value_loss: 0.7235
2024-07-11 16:37:03,972 [INFO    ] __main__: train step 9917: loss: 1.0370, policy_loss: 1.0917, value_loss: 0.7235
2024-07-11 16:37:04,180 [INFO    ] __main__: train step 9918: loss: 1.0370, policy_loss: 1.0916, value_loss: 0.7234
2024-07-11 16:37:04,388 [INFO    ] __main__: train step 9919: loss: 1.0370, policy_loss: 1.0915, value_loss: 0.7234
2024-07-11 16:37:04,595 [INFO    ] __main__: train step 9920: loss: 1.0370, policy_loss: 1.0915, value_loss: 0.7233
2024-07-11 16:37:04,803 [INFO    ] __main__: train step 9921: loss: 1.0369, policy_loss: 1.0914, value_loss: 0.7233
2024-07-11 16:37:05,007 [INFO    ] __main__: train step 9922: loss: 1.0369, policy_loss: 1.0913, value_loss: 0.7233
2024-07-11 16:37:05,216 [INFO    ] __main__: train step 9923: loss: 1.0369, policy_loss: 1.0913, value_loss: 0.7232
2024-07-11 16:37:05,428 [INFO    ] __main__: train step 9924: loss: 1.0369, policy_loss: 1.0912, value_loss: 0.7232
2024-07-11 16:37:05,618 [INFO    ] __main__: train step 9925: loss: 1.0368, policy_loss: 1.0912, value_loss: 0.7231
2024-07-11 16:37:05,821 [INFO    ] __main__: train step 9926: loss: 1.0368, policy_loss: 1.0911, value_loss: 0.7231
2024-07-11 16:37:06,020 [INFO    ] __main__: train step 9927: loss: 1.0368, policy_loss: 1.0910, value_loss: 0.7231
2024-07-11 16:37:07,463 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:37:07,902 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:37:07,962 [INFO    ] __main__: train step 9928: loss: 1.0368, policy_loss: 1.0910, value_loss: 0.7230
2024-07-11 16:37:08,145 [INFO    ] __main__: train step 9929: loss: 1.0367, policy_loss: 1.0909, value_loss: 0.7230
2024-07-11 16:37:08,348 [INFO    ] __main__: train step 9930: loss: 1.0367, policy_loss: 1.0908, value_loss: 0.7229
2024-07-11 16:37:08,548 [INFO    ] __main__: train step 9931: loss: 1.0367, policy_loss: 1.0908, value_loss: 0.7229
2024-07-11 16:37:08,747 [INFO    ] __main__: train step 9932: loss: 1.0367, policy_loss: 1.0907, value_loss: 0.7229
2024-07-11 16:37:08,959 [INFO    ] __main__: train step 9933: loss: 1.0366, policy_loss: 1.0907, value_loss: 0.7228
2024-07-11 16:37:09,183 [INFO    ] __main__: train step 9934: loss: 1.0366, policy_loss: 1.0906, value_loss: 0.7228
2024-07-11 16:37:09,390 [INFO    ] __main__: train step 9935: loss: 1.0366, policy_loss: 1.0905, value_loss: 0.7227
2024-07-11 16:37:09,589 [INFO    ] __main__: train step 9936: loss: 1.0366, policy_loss: 1.0905, value_loss: 0.7227
2024-07-11 16:37:09,791 [INFO    ] __main__: train step 9937: loss: 1.0366, policy_loss: 1.0904, value_loss: 0.7227
2024-07-11 16:37:10,832 [INFO    ] __main__: train step 9938: loss: 1.0365, policy_loss: 1.0904, value_loss: 0.7226
2024-07-11 16:37:11,058 [INFO    ] __main__: train step 9939: loss: 1.0365, policy_loss: 1.0903, value_loss: 0.7226
2024-07-11 16:37:11,267 [INFO    ] __main__: train step 9940: loss: 1.0365, policy_loss: 1.0902, value_loss: 0.7225
2024-07-11 16:37:11,463 [INFO    ] __main__: train step 9941: loss: 1.0365, policy_loss: 1.0902, value_loss: 0.7225
2024-07-11 16:37:11,669 [INFO    ] __main__: train step 9942: loss: 1.0364, policy_loss: 1.0901, value_loss: 0.7225
2024-07-11 16:37:11,867 [INFO    ] __main__: train step 9943: loss: 1.0364, policy_loss: 1.0900, value_loss: 0.7224
2024-07-11 16:37:12,078 [INFO    ] __main__: train step 9944: loss: 1.0364, policy_loss: 1.0900, value_loss: 0.7224
2024-07-11 16:37:13,525 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:37:13,965 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:37:14,026 [INFO    ] __main__: train step 9945: loss: 1.0364, policy_loss: 1.0899, value_loss: 0.7223
2024-07-11 16:37:14,205 [INFO    ] __main__: train step 9946: loss: 1.0363, policy_loss: 1.0899, value_loss: 0.7223
2024-07-11 16:37:14,424 [INFO    ] __main__: train step 9947: loss: 1.0363, policy_loss: 1.0898, value_loss: 0.7223
2024-07-11 16:37:14,658 [INFO    ] __main__: train step 9948: loss: 1.0363, policy_loss: 1.0897, value_loss: 0.7222
2024-07-11 16:37:14,886 [INFO    ] __main__: train step 9949: loss: 1.0363, policy_loss: 1.0897, value_loss: 0.7222
2024-07-11 16:37:15,124 [INFO    ] __main__: train step 9950: loss: 1.0363, policy_loss: 1.0896, value_loss: 0.7221
2024-07-11 16:37:15,353 [INFO    ] __main__: train step 9951: loss: 1.0362, policy_loss: 1.0896, value_loss: 0.7221
2024-07-11 16:37:15,590 [INFO    ] __main__: train step 9952: loss: 1.0362, policy_loss: 1.0895, value_loss: 0.7221
2024-07-11 16:37:15,835 [INFO    ] __main__: train step 9953: loss: 1.0362, policy_loss: 1.0894, value_loss: 0.7220
2024-07-11 16:37:16,072 [INFO    ] __main__: train step 9954: loss: 1.0362, policy_loss: 1.0894, value_loss: 0.7220
2024-07-11 16:37:16,293 [INFO    ] __main__: train step 9955: loss: 1.0361, policy_loss: 1.0893, value_loss: 0.7219
2024-07-11 16:37:16,495 [INFO    ] __main__: train step 9956: loss: 1.0361, policy_loss: 1.0892, value_loss: 0.7219
2024-07-11 16:37:16,728 [INFO    ] __main__: train step 9957: loss: 1.0361, policy_loss: 1.0892, value_loss: 0.7219
2024-07-11 16:37:16,943 [INFO    ] __main__: train step 9958: loss: 1.0361, policy_loss: 1.0891, value_loss: 0.7218
2024-07-11 16:37:17,173 [INFO    ] __main__: train step 9959: loss: 1.0360, policy_loss: 1.0891, value_loss: 0.7218
2024-07-11 16:37:17,428 [INFO    ] __main__: train step 9960: loss: 1.0360, policy_loss: 1.0890, value_loss: 0.7217
2024-07-11 16:37:17,639 [INFO    ] __main__: train step 9961: loss: 1.0360, policy_loss: 1.0889, value_loss: 0.7217
2024-07-11 16:37:19,081 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:37:19,491 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:37:19,549 [INFO    ] __main__: train step 9962: loss: 1.0360, policy_loss: 1.0889, value_loss: 0.7217
2024-07-11 16:37:19,718 [INFO    ] __main__: train step 9963: loss: 1.0359, policy_loss: 1.0888, value_loss: 0.7216
2024-07-11 16:37:19,919 [INFO    ] __main__: train step 9964: loss: 1.0359, policy_loss: 1.0888, value_loss: 0.7216
2024-07-11 16:37:20,150 [INFO    ] __main__: train step 9965: loss: 1.0359, policy_loss: 1.0887, value_loss: 0.7216
2024-07-11 16:37:20,386 [INFO    ] __main__: train step 9966: loss: 1.0359, policy_loss: 1.0886, value_loss: 0.7215
2024-07-11 16:37:20,622 [INFO    ] __main__: train step 9967: loss: 1.0359, policy_loss: 1.0886, value_loss: 0.7215
2024-07-11 16:37:20,844 [INFO    ] __main__: train step 9968: loss: 1.0358, policy_loss: 1.0885, value_loss: 0.7214
2024-07-11 16:37:21,078 [INFO    ] __main__: train step 9969: loss: 1.0358, policy_loss: 1.0885, value_loss: 0.7214
2024-07-11 16:37:21,278 [INFO    ] __main__: train step 9970: loss: 1.0358, policy_loss: 1.0884, value_loss: 0.7214
2024-07-11 16:37:21,479 [INFO    ] __main__: train step 9971: loss: 1.0358, policy_loss: 1.0883, value_loss: 0.7213
2024-07-11 16:37:21,682 [INFO    ] __main__: train step 9972: loss: 1.0357, policy_loss: 1.0883, value_loss: 0.7213
2024-07-11 16:37:21,875 [INFO    ] __main__: train step 9973: loss: 1.0357, policy_loss: 1.0882, value_loss: 0.7212
2024-07-11 16:37:22,079 [INFO    ] __main__: train step 9974: loss: 1.0357, policy_loss: 1.0881, value_loss: 0.7212
2024-07-11 16:37:22,281 [INFO    ] __main__: train step 9975: loss: 1.0357, policy_loss: 1.0881, value_loss: 0.7212
2024-07-11 16:37:22,521 [INFO    ] __main__: train step 9976: loss: 1.0357, policy_loss: 1.0880, value_loss: 0.7211
2024-07-11 16:37:22,759 [INFO    ] __main__: train step 9977: loss: 1.0356, policy_loss: 1.0880, value_loss: 0.7211
2024-07-11 16:37:22,954 [INFO    ] __main__: train step 9978: loss: 1.0356, policy_loss: 1.0879, value_loss: 0.7210
2024-07-11 16:37:24,401 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:37:24,806 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:37:24,860 [INFO    ] __main__: train step 9979: loss: 1.0356, policy_loss: 1.0878, value_loss: 0.7210
2024-07-11 16:37:25,041 [INFO    ] __main__: train step 9980: loss: 1.0356, policy_loss: 1.0878, value_loss: 0.7210
2024-07-11 16:37:25,234 [INFO    ] __main__: train step 9981: loss: 1.0355, policy_loss: 1.0877, value_loss: 0.7209
2024-07-11 16:37:25,440 [INFO    ] __main__: train step 9982: loss: 1.0355, policy_loss: 1.0877, value_loss: 0.7209
2024-07-11 16:37:25,636 [INFO    ] __main__: train step 9983: loss: 1.0355, policy_loss: 1.0876, value_loss: 0.7208
2024-07-11 16:37:25,833 [INFO    ] __main__: train step 9984: loss: 1.0355, policy_loss: 1.0875, value_loss: 0.7208
2024-07-11 16:37:26,038 [INFO    ] __main__: train step 9985: loss: 1.0354, policy_loss: 1.0875, value_loss: 0.7208
2024-07-11 16:37:26,256 [INFO    ] __main__: train step 9986: loss: 1.0354, policy_loss: 1.0874, value_loss: 0.7207
2024-07-11 16:37:26,488 [INFO    ] __main__: train step 9987: loss: 1.0354, policy_loss: 1.0874, value_loss: 0.7207
2024-07-11 16:37:26,707 [INFO    ] __main__: train step 9988: loss: 1.0354, policy_loss: 1.0873, value_loss: 0.7206
2024-07-11 16:37:26,902 [INFO    ] __main__: train step 9989: loss: 1.0353, policy_loss: 1.0872, value_loss: 0.7206
2024-07-11 16:37:27,101 [INFO    ] __main__: train step 9990: loss: 1.0353, policy_loss: 1.0872, value_loss: 0.7206
2024-07-11 16:37:27,291 [INFO    ] __main__: train step 9991: loss: 1.0353, policy_loss: 1.0871, value_loss: 0.7205
2024-07-11 16:37:27,490 [INFO    ] __main__: train step 9992: loss: 1.0353, policy_loss: 1.0870, value_loss: 0.7205
2024-07-11 16:37:27,690 [INFO    ] __main__: train step 9993: loss: 1.0352, policy_loss: 1.0870, value_loss: 0.7204
2024-07-11 16:37:27,927 [INFO    ] __main__: train step 9994: loss: 1.0352, policy_loss: 1.0869, value_loss: 0.7204
2024-07-11 16:37:28,116 [INFO    ] __main__: train step 9995: loss: 1.0352, policy_loss: 1.0869, value_loss: 0.7204
2024-07-11 16:37:29,563 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:37:29,964 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:37:30,018 [INFO    ] __main__: train step 9996: loss: 1.0352, policy_loss: 1.0868, value_loss: 0.7203
2024-07-11 16:37:30,186 [INFO    ] __main__: train step 9997: loss: 1.0351, policy_loss: 1.0867, value_loss: 0.7203
2024-07-11 16:37:30,387 [INFO    ] __main__: train step 9998: loss: 1.0351, policy_loss: 1.0867, value_loss: 0.7202
2024-07-11 16:37:30,606 [INFO    ] __main__: train step 9999: loss: 1.0351, policy_loss: 1.0866, value_loss: 0.7202
2024-07-11 16:37:30,807 [INFO    ] __main__: train step 10000: loss: 1.0351, policy_loss: 1.0866, value_loss: 0.7202
2024-07-11 16:37:30,920 [INFO    ] __main__: restored step 9000 for evaluation
2024-07-11 16:37:38,790 [INFO    ] __main__: later network ELO difference from earlier network: +108 (+8/-8) ELO from 32000 self-played games
2024-07-11 16:37:38,790 [INFO    ] __main__: game outcomes: W: 19353, D: 1415, L: 11232
2024-07-11 16:37:38,791 [INFO    ] __main__: validation_elo_delta: 108, validation_elo: 1992
2024-07-11 16:37:39,124 [INFO    ] __main__: running self-play game for SVG generation
2024-07-11 16:39:38,468 [INFO    ] __main__: saved self-play game in animations/run1_baseline/10000.svg
2024-07-11 16:39:38,639 [INFO    ] __main__: train step 10001: loss: 1.0351, policy_loss: 1.0865, value_loss: 0.7201
2024-07-11 16:39:38,849 [INFO    ] __main__: train step 10002: loss: 1.0350, policy_loss: 1.0864, value_loss: 0.7201
2024-07-11 16:39:39,059 [INFO    ] __main__: train step 10003: loss: 1.0350, policy_loss: 1.0864, value_loss: 0.7200
2024-07-11 16:39:39,267 [INFO    ] __main__: train step 10004: loss: 1.0350, policy_loss: 1.0863, value_loss: 0.7200
2024-07-11 16:39:39,469 [INFO    ] __main__: train step 10005: loss: 1.0350, policy_loss: 1.0863, value_loss: 0.7200
2024-07-11 16:39:39,696 [INFO    ] __main__: train step 10006: loss: 1.0349, policy_loss: 1.0862, value_loss: 0.7199
2024-07-11 16:39:39,905 [INFO    ] __main__: train step 10007: loss: 1.0349, policy_loss: 1.0861, value_loss: 0.7199
2024-07-11 16:39:40,111 [INFO    ] __main__: train step 10008: loss: 1.0349, policy_loss: 1.0861, value_loss: 0.7198
2024-07-11 16:39:40,323 [INFO    ] __main__: train step 10009: loss: 1.0349, policy_loss: 1.0860, value_loss: 0.7198
2024-07-11 16:39:40,513 [INFO    ] __main__: train step 10010: loss: 1.0348, policy_loss: 1.0859, value_loss: 0.7198
2024-07-11 16:39:40,722 [INFO    ] __main__: train step 10011: loss: 1.0348, policy_loss: 1.0859, value_loss: 0.7197
2024-07-11 16:39:40,918 [INFO    ] __main__: train step 10012: loss: 1.0348, policy_loss: 1.0858, value_loss: 0.7197
2024-07-11 16:39:42,364 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:39:42,751 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:39:42,806 [INFO    ] __main__: train step 10013: loss: 1.0348, policy_loss: 1.0858, value_loss: 0.7196
2024-07-11 16:39:42,981 [INFO    ] __main__: train step 10014: loss: 1.0347, policy_loss: 1.0857, value_loss: 0.7196
2024-07-11 16:39:43,185 [INFO    ] __main__: train step 10015: loss: 1.0347, policy_loss: 1.0856, value_loss: 0.7196
2024-07-11 16:39:43,389 [INFO    ] __main__: train step 10016: loss: 1.0347, policy_loss: 1.0856, value_loss: 0.7195
2024-07-11 16:39:43,599 [INFO    ] __main__: train step 10017: loss: 1.0347, policy_loss: 1.0855, value_loss: 0.7195
2024-07-11 16:39:43,807 [INFO    ] __main__: train step 10018: loss: 1.0347, policy_loss: 1.0855, value_loss: 0.7194
2024-07-11 16:39:44,014 [INFO    ] __main__: train step 10019: loss: 1.0346, policy_loss: 1.0854, value_loss: 0.7194
2024-07-11 16:39:44,251 [INFO    ] __main__: train step 10020: loss: 1.0346, policy_loss: 1.0853, value_loss: 0.7194
2024-07-11 16:39:44,503 [INFO    ] __main__: train step 10021: loss: 1.0346, policy_loss: 1.0853, value_loss: 0.7193
2024-07-11 16:39:44,762 [INFO    ] __main__: train step 10022: loss: 1.0345, policy_loss: 1.0852, value_loss: 0.7193
2024-07-11 16:39:44,981 [INFO    ] __main__: train step 10023: loss: 1.0345, policy_loss: 1.0852, value_loss: 0.7192
2024-07-11 16:39:45,192 [INFO    ] __main__: train step 10024: loss: 1.0345, policy_loss: 1.0851, value_loss: 0.7192
2024-07-11 16:39:45,393 [INFO    ] __main__: train step 10025: loss: 1.0345, policy_loss: 1.0850, value_loss: 0.7192
2024-07-11 16:39:45,599 [INFO    ] __main__: train step 10026: loss: 1.0345, policy_loss: 1.0850, value_loss: 0.7191
2024-07-11 16:39:45,805 [INFO    ] __main__: train step 10027: loss: 1.0344, policy_loss: 1.0849, value_loss: 0.7191
2024-07-11 16:39:46,003 [INFO    ] __main__: train step 10028: loss: 1.0344, policy_loss: 1.0849, value_loss: 0.7190
2024-07-11 16:39:46,207 [INFO    ] __main__: train step 10029: loss: 1.0344, policy_loss: 1.0848, value_loss: 0.7190
2024-07-11 16:39:47,677 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:39:48,087 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:39:48,142 [INFO    ] __main__: train step 10030: loss: 1.0344, policy_loss: 1.0847, value_loss: 0.7190
2024-07-11 16:39:48,320 [INFO    ] __main__: train step 10031: loss: 1.0343, policy_loss: 1.0847, value_loss: 0.7189
2024-07-11 16:39:48,514 [INFO    ] __main__: train step 10032: loss: 1.0343, policy_loss: 1.0846, value_loss: 0.7189
2024-07-11 16:39:48,718 [INFO    ] __main__: train step 10033: loss: 1.0343, policy_loss: 1.0845, value_loss: 0.7188
2024-07-11 16:39:48,919 [INFO    ] __main__: train step 10034: loss: 1.0343, policy_loss: 1.0845, value_loss: 0.7188
2024-07-11 16:39:49,117 [INFO    ] __main__: train step 10035: loss: 1.0342, policy_loss: 1.0844, value_loss: 0.7188
2024-07-11 16:39:49,318 [INFO    ] __main__: train step 10036: loss: 1.0342, policy_loss: 1.0844, value_loss: 0.7187
2024-07-11 16:39:49,533 [INFO    ] __main__: train step 10037: loss: 1.0342, policy_loss: 1.0843, value_loss: 0.7187
2024-07-11 16:39:49,734 [INFO    ] __main__: train step 10038: loss: 1.0342, policy_loss: 1.0842, value_loss: 0.7186
2024-07-11 16:39:49,950 [INFO    ] __main__: train step 10039: loss: 1.0341, policy_loss: 1.0842, value_loss: 0.7186
2024-07-11 16:39:50,156 [INFO    ] __main__: train step 10040: loss: 1.0341, policy_loss: 1.0841, value_loss: 0.7186
2024-07-11 16:39:50,371 [INFO    ] __main__: train step 10041: loss: 1.0341, policy_loss: 1.0841, value_loss: 0.7185
2024-07-11 16:39:50,612 [INFO    ] __main__: train step 10042: loss: 1.0341, policy_loss: 1.0840, value_loss: 0.7185
2024-07-11 16:39:50,820 [INFO    ] __main__: train step 10043: loss: 1.0340, policy_loss: 1.0839, value_loss: 0.7184
2024-07-11 16:39:51,024 [INFO    ] __main__: train step 10044: loss: 1.0340, policy_loss: 1.0839, value_loss: 0.7184
2024-07-11 16:39:51,231 [INFO    ] __main__: train step 10045: loss: 1.0340, policy_loss: 1.0838, value_loss: 0.7184
2024-07-11 16:39:51,435 [INFO    ] __main__: train step 10046: loss: 1.0340, policy_loss: 1.0837, value_loss: 0.7183
2024-07-11 16:39:52,884 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:39:53,270 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:39:53,329 [INFO    ] __main__: train step 10047: loss: 1.0339, policy_loss: 1.0837, value_loss: 0.7183
2024-07-11 16:39:53,511 [INFO    ] __main__: train step 10048: loss: 1.0339, policy_loss: 1.0836, value_loss: 0.7182
2024-07-11 16:39:53,743 [INFO    ] __main__: train step 10049: loss: 1.0339, policy_loss: 1.0836, value_loss: 0.7182
2024-07-11 16:39:53,980 [INFO    ] __main__: train step 10050: loss: 1.0339, policy_loss: 1.0835, value_loss: 0.7182
2024-07-11 16:39:54,185 [INFO    ] __main__: train step 10051: loss: 1.0338, policy_loss: 1.0834, value_loss: 0.7181
2024-07-11 16:39:54,391 [INFO    ] __main__: train step 10052: loss: 1.0338, policy_loss: 1.0834, value_loss: 0.7181
2024-07-11 16:39:54,606 [INFO    ] __main__: train step 10053: loss: 1.0338, policy_loss: 1.0833, value_loss: 0.7180
2024-07-11 16:39:54,799 [INFO    ] __main__: train step 10054: loss: 1.0338, policy_loss: 1.0833, value_loss: 0.7180
2024-07-11 16:39:55,011 [INFO    ] __main__: train step 10055: loss: 1.0337, policy_loss: 1.0832, value_loss: 0.7180
2024-07-11 16:39:55,211 [INFO    ] __main__: train step 10056: loss: 1.0337, policy_loss: 1.0831, value_loss: 0.7179
2024-07-11 16:39:55,416 [INFO    ] __main__: train step 10057: loss: 1.0337, policy_loss: 1.0831, value_loss: 0.7179
2024-07-11 16:39:55,628 [INFO    ] __main__: train step 10058: loss: 1.0337, policy_loss: 1.0830, value_loss: 0.7178
2024-07-11 16:39:55,825 [INFO    ] __main__: train step 10059: loss: 1.0337, policy_loss: 1.0830, value_loss: 0.7178
2024-07-11 16:39:56,030 [INFO    ] __main__: train step 10060: loss: 1.0336, policy_loss: 1.0829, value_loss: 0.7178
2024-07-11 16:39:56,245 [INFO    ] __main__: train step 10061: loss: 1.0336, policy_loss: 1.0828, value_loss: 0.7177
2024-07-11 16:39:56,445 [INFO    ] __main__: train step 10062: loss: 1.0336, policy_loss: 1.0828, value_loss: 0.7177
2024-07-11 16:39:56,650 [INFO    ] __main__: train step 10063: loss: 1.0335, policy_loss: 1.0827, value_loss: 0.7176
2024-07-11 16:39:58,077 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:39:58,488 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:39:58,546 [INFO    ] __main__: train step 10064: loss: 1.0335, policy_loss: 1.0827, value_loss: 0.7176
2024-07-11 16:39:58,710 [INFO    ] __main__: train step 10065: loss: 1.0335, policy_loss: 1.0826, value_loss: 0.7176
2024-07-11 16:39:58,927 [INFO    ] __main__: train step 10066: loss: 1.0335, policy_loss: 1.0825, value_loss: 0.7175
2024-07-11 16:39:59,135 [INFO    ] __main__: train step 10067: loss: 1.0335, policy_loss: 1.0825, value_loss: 0.7175
2024-07-11 16:39:59,353 [INFO    ] __main__: train step 10068: loss: 1.0334, policy_loss: 1.0824, value_loss: 0.7174
2024-07-11 16:39:59,587 [INFO    ] __main__: train step 10069: loss: 1.0334, policy_loss: 1.0823, value_loss: 0.7174
2024-07-11 16:39:59,798 [INFO    ] __main__: train step 10070: loss: 1.0334, policy_loss: 1.0823, value_loss: 0.7174
2024-07-11 16:40:00,009 [INFO    ] __main__: train step 10071: loss: 1.0333, policy_loss: 1.0822, value_loss: 0.7173
2024-07-11 16:40:00,207 [INFO    ] __main__: train step 10072: loss: 1.0333, policy_loss: 1.0822, value_loss: 0.7173
2024-07-11 16:40:00,404 [INFO    ] __main__: train step 10073: loss: 1.0333, policy_loss: 1.0821, value_loss: 0.7172
2024-07-11 16:40:00,614 [INFO    ] __main__: train step 10074: loss: 1.0333, policy_loss: 1.0820, value_loss: 0.7172
2024-07-11 16:40:00,811 [INFO    ] __main__: train step 10075: loss: 1.0333, policy_loss: 1.0820, value_loss: 0.7172
2024-07-11 16:40:01,011 [INFO    ] __main__: train step 10076: loss: 1.0332, policy_loss: 1.0819, value_loss: 0.7171
2024-07-11 16:40:01,216 [INFO    ] __main__: train step 10077: loss: 1.0332, policy_loss: 1.0819, value_loss: 0.7171
2024-07-11 16:40:01,410 [INFO    ] __main__: train step 10078: loss: 1.0332, policy_loss: 1.0818, value_loss: 0.7170
2024-07-11 16:40:01,623 [INFO    ] __main__: train step 10079: loss: 1.0332, policy_loss: 1.0817, value_loss: 0.7170
2024-07-11 16:40:01,812 [INFO    ] __main__: train step 10080: loss: 1.0331, policy_loss: 1.0817, value_loss: 0.7170
2024-07-11 16:40:03,274 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:40:03,691 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:40:03,754 [INFO    ] __main__: train step 10081: loss: 1.0331, policy_loss: 1.0816, value_loss: 0.7169
2024-07-11 16:40:03,931 [INFO    ] __main__: train step 10082: loss: 1.0331, policy_loss: 1.0816, value_loss: 0.7169
2024-07-11 16:40:04,129 [INFO    ] __main__: train step 10083: loss: 1.0331, policy_loss: 1.0815, value_loss: 0.7168
2024-07-11 16:40:04,338 [INFO    ] __main__: train step 10084: loss: 1.0330, policy_loss: 1.0814, value_loss: 0.7168
2024-07-11 16:40:04,553 [INFO    ] __main__: train step 10085: loss: 1.0330, policy_loss: 1.0814, value_loss: 0.7168
2024-07-11 16:40:04,760 [INFO    ] __main__: train step 10086: loss: 1.0330, policy_loss: 1.0813, value_loss: 0.7167
2024-07-11 16:40:04,963 [INFO    ] __main__: train step 10087: loss: 1.0330, policy_loss: 1.0813, value_loss: 0.7167
2024-07-11 16:40:05,195 [INFO    ] __main__: train step 10088: loss: 1.0329, policy_loss: 1.0812, value_loss: 0.7166
2024-07-11 16:40:05,428 [INFO    ] __main__: train step 10089: loss: 1.0329, policy_loss: 1.0811, value_loss: 0.7166
2024-07-11 16:40:05,624 [INFO    ] __main__: train step 10090: loss: 1.0329, policy_loss: 1.0811, value_loss: 0.7166
2024-07-11 16:40:05,852 [INFO    ] __main__: train step 10091: loss: 1.0329, policy_loss: 1.0810, value_loss: 0.7165
2024-07-11 16:40:07,447 [INFO    ] __main__: train step 10092: loss: 1.0328, policy_loss: 1.0810, value_loss: 0.7165
2024-07-11 16:40:07,667 [INFO    ] __main__: train step 10093: loss: 1.0328, policy_loss: 1.0809, value_loss: 0.7164
2024-07-11 16:40:07,876 [INFO    ] __main__: train step 10094: loss: 1.0328, policy_loss: 1.0808, value_loss: 0.7164
2024-07-11 16:40:08,095 [INFO    ] __main__: train step 10095: loss: 1.0328, policy_loss: 1.0808, value_loss: 0.7164
2024-07-11 16:40:08,308 [INFO    ] __main__: train step 10096: loss: 1.0327, policy_loss: 1.0807, value_loss: 0.7163
2024-07-11 16:40:08,531 [INFO    ] __main__: train step 10097: loss: 1.0327, policy_loss: 1.0807, value_loss: 0.7163
2024-07-11 16:40:09,966 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:40:10,344 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:40:10,401 [INFO    ] __main__: train step 10098: loss: 1.0327, policy_loss: 1.0806, value_loss: 0.7162
2024-07-11 16:40:10,577 [INFO    ] __main__: train step 10099: loss: 1.0327, policy_loss: 1.0805, value_loss: 0.7162
2024-07-11 16:40:10,785 [INFO    ] __main__: train step 10100: loss: 1.0327, policy_loss: 1.0805, value_loss: 0.7162
2024-07-11 16:40:10,998 [INFO    ] __main__: train step 10101: loss: 1.0326, policy_loss: 1.0804, value_loss: 0.7161
2024-07-11 16:40:11,197 [INFO    ] __main__: train step 10102: loss: 1.0326, policy_loss: 1.0804, value_loss: 0.7161
2024-07-11 16:40:11,388 [INFO    ] __main__: train step 10103: loss: 1.0326, policy_loss: 1.0803, value_loss: 0.7161
2024-07-11 16:40:11,586 [INFO    ] __main__: train step 10104: loss: 1.0326, policy_loss: 1.0802, value_loss: 0.7160
2024-07-11 16:40:11,791 [INFO    ] __main__: train step 10105: loss: 1.0325, policy_loss: 1.0802, value_loss: 0.7160
2024-07-11 16:40:11,990 [INFO    ] __main__: train step 10106: loss: 1.0325, policy_loss: 1.0801, value_loss: 0.7159
2024-07-11 16:40:12,198 [INFO    ] __main__: train step 10107: loss: 1.0325, policy_loss: 1.0801, value_loss: 0.7159
2024-07-11 16:40:12,401 [INFO    ] __main__: train step 10108: loss: 1.0325, policy_loss: 1.0800, value_loss: 0.7159
2024-07-11 16:40:12,594 [INFO    ] __main__: train step 10109: loss: 1.0324, policy_loss: 1.0799, value_loss: 0.7158
2024-07-11 16:40:12,804 [INFO    ] __main__: train step 10110: loss: 1.0324, policy_loss: 1.0799, value_loss: 0.7158
2024-07-11 16:40:12,998 [INFO    ] __main__: train step 10111: loss: 1.0324, policy_loss: 1.0798, value_loss: 0.7157
2024-07-11 16:40:13,201 [INFO    ] __main__: train step 10112: loss: 1.0324, policy_loss: 1.0798, value_loss: 0.7157
2024-07-11 16:40:13,405 [INFO    ] __main__: train step 10113: loss: 1.0323, policy_loss: 1.0797, value_loss: 0.7157
2024-07-11 16:40:13,606 [INFO    ] __main__: train step 10114: loss: 1.0323, policy_loss: 1.0796, value_loss: 0.7156
2024-07-11 16:40:15,030 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:40:15,384 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:40:15,443 [INFO    ] __main__: train step 10115: loss: 1.0323, policy_loss: 1.0796, value_loss: 0.7156
2024-07-11 16:40:15,619 [INFO    ] __main__: train step 10116: loss: 1.0323, policy_loss: 1.0795, value_loss: 0.7155
2024-07-11 16:40:15,824 [INFO    ] __main__: train step 10117: loss: 1.0322, policy_loss: 1.0795, value_loss: 0.7155
2024-07-11 16:40:16,027 [INFO    ] __main__: train step 10118: loss: 1.0322, policy_loss: 1.0794, value_loss: 0.7155
2024-07-11 16:40:16,231 [INFO    ] __main__: train step 10119: loss: 1.0322, policy_loss: 1.0793, value_loss: 0.7154
2024-07-11 16:40:16,473 [INFO    ] __main__: train step 10120: loss: 1.0322, policy_loss: 1.0793, value_loss: 0.7154
2024-07-11 16:40:16,664 [INFO    ] __main__: train step 10121: loss: 1.0321, policy_loss: 1.0792, value_loss: 0.7153
2024-07-11 16:40:16,872 [INFO    ] __main__: train step 10122: loss: 1.0321, policy_loss: 1.0792, value_loss: 0.7153
2024-07-11 16:40:17,080 [INFO    ] __main__: train step 10123: loss: 1.0321, policy_loss: 1.0791, value_loss: 0.7153
2024-07-11 16:40:17,293 [INFO    ] __main__: train step 10124: loss: 1.0321, policy_loss: 1.0790, value_loss: 0.7152
2024-07-11 16:40:17,487 [INFO    ] __main__: train step 10125: loss: 1.0321, policy_loss: 1.0790, value_loss: 0.7152
2024-07-11 16:40:17,704 [INFO    ] __main__: train step 10126: loss: 1.0320, policy_loss: 1.0789, value_loss: 0.7151
2024-07-11 16:40:17,897 [INFO    ] __main__: train step 10127: loss: 1.0320, policy_loss: 1.0789, value_loss: 0.7151
2024-07-11 16:40:18,104 [INFO    ] __main__: train step 10128: loss: 1.0320, policy_loss: 1.0788, value_loss: 0.7151
2024-07-11 16:40:18,308 [INFO    ] __main__: train step 10129: loss: 1.0320, policy_loss: 1.0787, value_loss: 0.7150
2024-07-11 16:40:18,513 [INFO    ] __main__: train step 10130: loss: 1.0319, policy_loss: 1.0787, value_loss: 0.7150
2024-07-11 16:40:18,713 [INFO    ] __main__: train step 10131: loss: 1.0319, policy_loss: 1.0786, value_loss: 0.7149
2024-07-11 16:40:20,151 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:40:20,550 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:40:20,616 [INFO    ] __main__: train step 10132: loss: 1.0319, policy_loss: 1.0786, value_loss: 0.7149
2024-07-11 16:40:20,801 [INFO    ] __main__: train step 10133: loss: 1.0319, policy_loss: 1.0785, value_loss: 0.7149
2024-07-11 16:40:21,014 [INFO    ] __main__: train step 10134: loss: 1.0318, policy_loss: 1.0784, value_loss: 0.7148
2024-07-11 16:40:21,239 [INFO    ] __main__: train step 10135: loss: 1.0318, policy_loss: 1.0784, value_loss: 0.7148
2024-07-11 16:40:21,436 [INFO    ] __main__: train step 10136: loss: 1.0318, policy_loss: 1.0783, value_loss: 0.7147
2024-07-11 16:40:21,653 [INFO    ] __main__: train step 10137: loss: 1.0318, policy_loss: 1.0783, value_loss: 0.7147
2024-07-11 16:40:21,861 [INFO    ] __main__: train step 10138: loss: 1.0317, policy_loss: 1.0782, value_loss: 0.7147
2024-07-11 16:40:22,064 [INFO    ] __main__: train step 10139: loss: 1.0317, policy_loss: 1.0781, value_loss: 0.7146
2024-07-11 16:40:22,268 [INFO    ] __main__: train step 10140: loss: 1.0317, policy_loss: 1.0781, value_loss: 0.7146
2024-07-11 16:40:22,461 [INFO    ] __main__: train step 10141: loss: 1.0317, policy_loss: 1.0780, value_loss: 0.7145
2024-07-11 16:40:22,665 [INFO    ] __main__: train step 10142: loss: 1.0316, policy_loss: 1.0780, value_loss: 0.7145
2024-07-11 16:40:22,870 [INFO    ] __main__: train step 10143: loss: 1.0316, policy_loss: 1.0779, value_loss: 0.7145
2024-07-11 16:40:23,085 [INFO    ] __main__: train step 10144: loss: 1.0316, policy_loss: 1.0778, value_loss: 0.7144
2024-07-11 16:40:23,292 [INFO    ] __main__: train step 10145: loss: 1.0316, policy_loss: 1.0778, value_loss: 0.7144
2024-07-11 16:40:23,493 [INFO    ] __main__: train step 10146: loss: 1.0315, policy_loss: 1.0777, value_loss: 0.7143
2024-07-11 16:40:23,697 [INFO    ] __main__: train step 10147: loss: 1.0315, policy_loss: 1.0777, value_loss: 0.7143
2024-07-11 16:40:23,904 [INFO    ] __main__: train step 10148: loss: 1.0315, policy_loss: 1.0776, value_loss: 0.7143
2024-07-11 16:40:25,326 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:40:25,686 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:40:25,748 [INFO    ] __main__: train step 10149: loss: 1.0315, policy_loss: 1.0775, value_loss: 0.7142
2024-07-11 16:40:25,921 [INFO    ] __main__: train step 10150: loss: 1.0315, policy_loss: 1.0775, value_loss: 0.7142
2024-07-11 16:40:26,128 [INFO    ] __main__: train step 10151: loss: 1.0314, policy_loss: 1.0774, value_loss: 0.7142
2024-07-11 16:40:26,346 [INFO    ] __main__: train step 10152: loss: 1.0314, policy_loss: 1.0774, value_loss: 0.7141
2024-07-11 16:40:26,563 [INFO    ] __main__: train step 10153: loss: 1.0314, policy_loss: 1.0773, value_loss: 0.7141
2024-07-11 16:40:26,776 [INFO    ] __main__: train step 10154: loss: 1.0313, policy_loss: 1.0772, value_loss: 0.7140
2024-07-11 16:40:26,991 [INFO    ] __main__: train step 10155: loss: 1.0313, policy_loss: 1.0772, value_loss: 0.7140
2024-07-11 16:40:27,201 [INFO    ] __main__: train step 10156: loss: 1.0313, policy_loss: 1.0771, value_loss: 0.7140
2024-07-11 16:40:27,464 [INFO    ] __main__: train step 10157: loss: 1.0313, policy_loss: 1.0771, value_loss: 0.7139
2024-07-11 16:40:27,661 [INFO    ] __main__: train step 10158: loss: 1.0313, policy_loss: 1.0770, value_loss: 0.7139
2024-07-11 16:40:27,851 [INFO    ] __main__: train step 10159: loss: 1.0312, policy_loss: 1.0769, value_loss: 0.7138
2024-07-11 16:40:28,062 [INFO    ] __main__: train step 10160: loss: 1.0312, policy_loss: 1.0769, value_loss: 0.7138
2024-07-11 16:40:28,296 [INFO    ] __main__: train step 10161: loss: 1.0312, policy_loss: 1.0768, value_loss: 0.7138
2024-07-11 16:40:28,486 [INFO    ] __main__: train step 10162: loss: 1.0312, policy_loss: 1.0768, value_loss: 0.7137
2024-07-11 16:40:28,710 [INFO    ] __main__: train step 10163: loss: 1.0311, policy_loss: 1.0767, value_loss: 0.7137
2024-07-11 16:40:28,940 [INFO    ] __main__: train step 10164: loss: 1.0311, policy_loss: 1.0767, value_loss: 0.7136
2024-07-11 16:40:29,150 [INFO    ] __main__: train step 10165: loss: 1.0311, policy_loss: 1.0766, value_loss: 0.7136
2024-07-11 16:40:30,582 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:40:30,969 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:40:31,025 [INFO    ] __main__: train step 10166: loss: 1.0311, policy_loss: 1.0765, value_loss: 0.7136
2024-07-11 16:40:31,198 [INFO    ] __main__: train step 10167: loss: 1.0310, policy_loss: 1.0765, value_loss: 0.7135
2024-07-11 16:40:31,400 [INFO    ] __main__: train step 10168: loss: 1.0310, policy_loss: 1.0764, value_loss: 0.7135
2024-07-11 16:40:31,639 [INFO    ] __main__: train step 10169: loss: 1.0310, policy_loss: 1.0764, value_loss: 0.7135
2024-07-11 16:40:31,873 [INFO    ] __main__: train step 10170: loss: 1.0310, policy_loss: 1.0763, value_loss: 0.7134
2024-07-11 16:40:32,087 [INFO    ] __main__: train step 10171: loss: 1.0309, policy_loss: 1.0762, value_loss: 0.7134
2024-07-11 16:40:32,336 [INFO    ] __main__: train step 10172: loss: 1.0309, policy_loss: 1.0762, value_loss: 0.7133
2024-07-11 16:40:32,564 [INFO    ] __main__: train step 10173: loss: 1.0309, policy_loss: 1.0761, value_loss: 0.7133
2024-07-11 16:40:32,776 [INFO    ] __main__: train step 10174: loss: 1.0309, policy_loss: 1.0761, value_loss: 0.7133
2024-07-11 16:40:32,984 [INFO    ] __main__: train step 10175: loss: 1.0309, policy_loss: 1.0760, value_loss: 0.7132
2024-07-11 16:40:33,182 [INFO    ] __main__: train step 10176: loss: 1.0308, policy_loss: 1.0759, value_loss: 0.7132
2024-07-11 16:40:33,387 [INFO    ] __main__: train step 10177: loss: 1.0308, policy_loss: 1.0759, value_loss: 0.7131
2024-07-11 16:40:33,596 [INFO    ] __main__: train step 10178: loss: 1.0308, policy_loss: 1.0758, value_loss: 0.7131
2024-07-11 16:40:33,806 [INFO    ] __main__: train step 10179: loss: 1.0308, policy_loss: 1.0758, value_loss: 0.7131
2024-07-11 16:40:34,003 [INFO    ] __main__: train step 10180: loss: 1.0307, policy_loss: 1.0757, value_loss: 0.7130
2024-07-11 16:40:34,208 [INFO    ] __main__: train step 10181: loss: 1.0307, policy_loss: 1.0756, value_loss: 0.7130
2024-07-11 16:40:34,408 [INFO    ] __main__: train step 10182: loss: 1.0307, policy_loss: 1.0756, value_loss: 0.7129
2024-07-11 16:40:35,858 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:40:36,210 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:40:36,269 [INFO    ] __main__: train step 10183: loss: 1.0307, policy_loss: 1.0755, value_loss: 0.7129
2024-07-11 16:40:36,437 [INFO    ] __main__: train step 10184: loss: 1.0306, policy_loss: 1.0755, value_loss: 0.7129
2024-07-11 16:40:36,639 [INFO    ] __main__: train step 10185: loss: 1.0306, policy_loss: 1.0754, value_loss: 0.7128
2024-07-11 16:40:36,834 [INFO    ] __main__: train step 10186: loss: 1.0306, policy_loss: 1.0754, value_loss: 0.7128
2024-07-11 16:40:37,036 [INFO    ] __main__: train step 10187: loss: 1.0306, policy_loss: 1.0753, value_loss: 0.7127
2024-07-11 16:40:37,235 [INFO    ] __main__: train step 10188: loss: 1.0305, policy_loss: 1.0752, value_loss: 0.7127
2024-07-11 16:40:37,439 [INFO    ] __main__: train step 10189: loss: 1.0305, policy_loss: 1.0752, value_loss: 0.7127
2024-07-11 16:40:37,637 [INFO    ] __main__: train step 10190: loss: 1.0305, policy_loss: 1.0751, value_loss: 0.7126
2024-07-11 16:40:37,835 [INFO    ] __main__: train step 10191: loss: 1.0305, policy_loss: 1.0751, value_loss: 0.7126
2024-07-11 16:40:38,047 [INFO    ] __main__: train step 10192: loss: 1.0304, policy_loss: 1.0750, value_loss: 0.7126
2024-07-11 16:40:39,635 [INFO    ] __main__: train step 10193: loss: 1.0304, policy_loss: 1.0749, value_loss: 0.7125
2024-07-11 16:40:39,839 [INFO    ] __main__: train step 10194: loss: 1.0304, policy_loss: 1.0749, value_loss: 0.7125
2024-07-11 16:40:40,037 [INFO    ] __main__: train step 10195: loss: 1.0304, policy_loss: 1.0748, value_loss: 0.7124
2024-07-11 16:40:40,244 [INFO    ] __main__: train step 10196: loss: 1.0304, policy_loss: 1.0748, value_loss: 0.7124
2024-07-11 16:40:40,435 [INFO    ] __main__: train step 10197: loss: 1.0303, policy_loss: 1.0747, value_loss: 0.7124
2024-07-11 16:40:40,632 [INFO    ] __main__: train step 10198: loss: 1.0303, policy_loss: 1.0746, value_loss: 0.7123
2024-07-11 16:40:40,835 [INFO    ] __main__: train step 10199: loss: 1.0303, policy_loss: 1.0746, value_loss: 0.7123
2024-07-11 16:40:42,284 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:40:42,655 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:40:42,715 [INFO    ] __main__: train step 10200: loss: 1.0303, policy_loss: 1.0745, value_loss: 0.7122
2024-07-11 16:40:42,887 [INFO    ] __main__: train step 10201: loss: 1.0302, policy_loss: 1.0745, value_loss: 0.7122
2024-07-11 16:40:43,098 [INFO    ] __main__: train step 10202: loss: 1.0302, policy_loss: 1.0744, value_loss: 0.7122
2024-07-11 16:40:43,296 [INFO    ] __main__: train step 10203: loss: 1.0302, policy_loss: 1.0744, value_loss: 0.7121
2024-07-11 16:40:43,501 [INFO    ] __main__: train step 10204: loss: 1.0302, policy_loss: 1.0743, value_loss: 0.7121
2024-07-11 16:40:43,711 [INFO    ] __main__: train step 10205: loss: 1.0301, policy_loss: 1.0742, value_loss: 0.7121
2024-07-11 16:40:43,917 [INFO    ] __main__: train step 10206: loss: 1.0301, policy_loss: 1.0742, value_loss: 0.7120
2024-07-11 16:40:44,142 [INFO    ] __main__: train step 10207: loss: 1.0301, policy_loss: 1.0741, value_loss: 0.7120
2024-07-11 16:40:44,344 [INFO    ] __main__: train step 10208: loss: 1.0301, policy_loss: 1.0741, value_loss: 0.7119
2024-07-11 16:40:44,548 [INFO    ] __main__: train step 10209: loss: 1.0301, policy_loss: 1.0740, value_loss: 0.7119
2024-07-11 16:40:44,774 [INFO    ] __main__: train step 10210: loss: 1.0300, policy_loss: 1.0739, value_loss: 0.7119
2024-07-11 16:40:44,968 [INFO    ] __main__: train step 10211: loss: 1.0300, policy_loss: 1.0739, value_loss: 0.7118
2024-07-11 16:40:45,176 [INFO    ] __main__: train step 10212: loss: 1.0300, policy_loss: 1.0738, value_loss: 0.7118
2024-07-11 16:40:45,382 [INFO    ] __main__: train step 10213: loss: 1.0300, policy_loss: 1.0738, value_loss: 0.7117
2024-07-11 16:40:45,591 [INFO    ] __main__: train step 10214: loss: 1.0299, policy_loss: 1.0737, value_loss: 0.7117
2024-07-11 16:40:45,799 [INFO    ] __main__: train step 10215: loss: 1.0299, policy_loss: 1.0736, value_loss: 0.7117
2024-07-11 16:40:46,012 [INFO    ] __main__: train step 10216: loss: 1.0299, policy_loss: 1.0736, value_loss: 0.7116
2024-07-11 16:40:47,462 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:40:47,855 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:40:47,915 [INFO    ] __main__: train step 10217: loss: 1.0299, policy_loss: 1.0735, value_loss: 0.7116
2024-07-11 16:40:48,101 [INFO    ] __main__: train step 10218: loss: 1.0298, policy_loss: 1.0735, value_loss: 0.7115
2024-07-11 16:40:48,332 [INFO    ] __main__: train step 10219: loss: 1.0298, policy_loss: 1.0734, value_loss: 0.7115
2024-07-11 16:40:48,531 [INFO    ] __main__: train step 10220: loss: 1.0298, policy_loss: 1.0734, value_loss: 0.7115
2024-07-11 16:40:48,731 [INFO    ] __main__: train step 10221: loss: 1.0298, policy_loss: 1.0733, value_loss: 0.7114
2024-07-11 16:40:48,925 [INFO    ] __main__: train step 10222: loss: 1.0298, policy_loss: 1.0732, value_loss: 0.7114
2024-07-11 16:40:49,133 [INFO    ] __main__: train step 10223: loss: 1.0297, policy_loss: 1.0732, value_loss: 0.7114
2024-07-11 16:40:49,331 [INFO    ] __main__: train step 10224: loss: 1.0297, policy_loss: 1.0731, value_loss: 0.7113
2024-07-11 16:40:49,532 [INFO    ] __main__: train step 10225: loss: 1.0297, policy_loss: 1.0731, value_loss: 0.7113
2024-07-11 16:40:49,733 [INFO    ] __main__: train step 10226: loss: 1.0297, policy_loss: 1.0730, value_loss: 0.7112
2024-07-11 16:40:49,938 [INFO    ] __main__: train step 10227: loss: 1.0296, policy_loss: 1.0729, value_loss: 0.7112
2024-07-11 16:40:50,138 [INFO    ] __main__: train step 10228: loss: 1.0296, policy_loss: 1.0729, value_loss: 0.7112
2024-07-11 16:40:50,342 [INFO    ] __main__: train step 10229: loss: 1.0296, policy_loss: 1.0728, value_loss: 0.7111
2024-07-11 16:40:50,557 [INFO    ] __main__: train step 10230: loss: 1.0296, policy_loss: 1.0728, value_loss: 0.7111
2024-07-11 16:40:50,769 [INFO    ] __main__: train step 10231: loss: 1.0295, policy_loss: 1.0727, value_loss: 0.7110
2024-07-11 16:40:51,000 [INFO    ] __main__: train step 10232: loss: 1.0295, policy_loss: 1.0727, value_loss: 0.7110
2024-07-11 16:40:51,193 [INFO    ] __main__: train step 10233: loss: 1.0295, policy_loss: 1.0726, value_loss: 0.7110
2024-07-11 16:40:52,616 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:40:52,980 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:40:53,040 [INFO    ] __main__: train step 10234: loss: 1.0295, policy_loss: 1.0725, value_loss: 0.7109
2024-07-11 16:40:53,223 [INFO    ] __main__: train step 10235: loss: 1.0295, policy_loss: 1.0725, value_loss: 0.7109
2024-07-11 16:40:53,432 [INFO    ] __main__: train step 10236: loss: 1.0294, policy_loss: 1.0724, value_loss: 0.7109
2024-07-11 16:40:53,654 [INFO    ] __main__: train step 10237: loss: 1.0294, policy_loss: 1.0724, value_loss: 0.7108
2024-07-11 16:40:53,847 [INFO    ] __main__: train step 10238: loss: 1.0294, policy_loss: 1.0723, value_loss: 0.7108
2024-07-11 16:40:54,056 [INFO    ] __main__: train step 10239: loss: 1.0294, policy_loss: 1.0722, value_loss: 0.7107
2024-07-11 16:40:54,253 [INFO    ] __main__: train step 10240: loss: 1.0293, policy_loss: 1.0722, value_loss: 0.7107
2024-07-11 16:40:54,450 [INFO    ] __main__: train step 10241: loss: 1.0293, policy_loss: 1.0721, value_loss: 0.7107
2024-07-11 16:40:54,678 [INFO    ] __main__: train step 10242: loss: 1.0293, policy_loss: 1.0721, value_loss: 0.7106
2024-07-11 16:40:54,879 [INFO    ] __main__: train step 10243: loss: 1.0293, policy_loss: 1.0720, value_loss: 0.7106
2024-07-11 16:40:55,082 [INFO    ] __main__: train step 10244: loss: 1.0292, policy_loss: 1.0720, value_loss: 0.7106
2024-07-11 16:40:55,284 [INFO    ] __main__: train step 10245: loss: 1.0292, policy_loss: 1.0719, value_loss: 0.7105
2024-07-11 16:40:55,496 [INFO    ] __main__: train step 10246: loss: 1.0292, policy_loss: 1.0718, value_loss: 0.7105
2024-07-11 16:40:55,703 [INFO    ] __main__: train step 10247: loss: 1.0292, policy_loss: 1.0718, value_loss: 0.7104
2024-07-11 16:40:55,927 [INFO    ] __main__: train step 10248: loss: 1.0292, policy_loss: 1.0717, value_loss: 0.7104
2024-07-11 16:40:56,147 [INFO    ] __main__: train step 10249: loss: 1.0291, policy_loss: 1.0717, value_loss: 0.7104
2024-07-11 16:40:56,346 [INFO    ] __main__: train step 10250: loss: 1.0291, policy_loss: 1.0716, value_loss: 0.7103
2024-07-11 16:40:57,780 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:40:58,153 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:40:58,210 [INFO    ] __main__: train step 10251: loss: 1.0291, policy_loss: 1.0715, value_loss: 0.7103
2024-07-11 16:40:58,389 [INFO    ] __main__: train step 10252: loss: 1.0291, policy_loss: 1.0715, value_loss: 0.7102
2024-07-11 16:40:58,583 [INFO    ] __main__: train step 10253: loss: 1.0290, policy_loss: 1.0714, value_loss: 0.7102
2024-07-11 16:40:58,788 [INFO    ] __main__: train step 10254: loss: 1.0290, policy_loss: 1.0714, value_loss: 0.7102
2024-07-11 16:40:58,994 [INFO    ] __main__: train step 10255: loss: 1.0290, policy_loss: 1.0713, value_loss: 0.7101
2024-07-11 16:40:59,191 [INFO    ] __main__: train step 10256: loss: 1.0290, policy_loss: 1.0712, value_loss: 0.7101
2024-07-11 16:40:59,407 [INFO    ] __main__: train step 10257: loss: 1.0289, policy_loss: 1.0712, value_loss: 0.7101
2024-07-11 16:40:59,639 [INFO    ] __main__: train step 10258: loss: 1.0289, policy_loss: 1.0711, value_loss: 0.7100
2024-07-11 16:40:59,873 [INFO    ] __main__: train step 10259: loss: 1.0289, policy_loss: 1.0711, value_loss: 0.7100
2024-07-11 16:41:00,099 [INFO    ] __main__: train step 10260: loss: 1.0289, policy_loss: 1.0710, value_loss: 0.7099
2024-07-11 16:41:00,304 [INFO    ] __main__: train step 10261: loss: 1.0289, policy_loss: 1.0710, value_loss: 0.7099
2024-07-11 16:41:00,505 [INFO    ] __main__: train step 10262: loss: 1.0288, policy_loss: 1.0709, value_loss: 0.7099
2024-07-11 16:41:00,707 [INFO    ] __main__: train step 10263: loss: 1.0288, policy_loss: 1.0708, value_loss: 0.7098
2024-07-11 16:41:00,924 [INFO    ] __main__: train step 10264: loss: 1.0288, policy_loss: 1.0708, value_loss: 0.7098
2024-07-11 16:41:01,125 [INFO    ] __main__: train step 10265: loss: 1.0288, policy_loss: 1.0707, value_loss: 0.7098
2024-07-11 16:41:01,351 [INFO    ] __main__: train step 10266: loss: 1.0287, policy_loss: 1.0707, value_loss: 0.7097
2024-07-11 16:41:01,559 [INFO    ] __main__: train step 10267: loss: 1.0287, policy_loss: 1.0706, value_loss: 0.7097
2024-07-11 16:41:02,993 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:41:03,366 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:41:03,420 [INFO    ] __main__: train step 10268: loss: 1.0287, policy_loss: 1.0706, value_loss: 0.7096
2024-07-11 16:41:03,587 [INFO    ] __main__: train step 10269: loss: 1.0287, policy_loss: 1.0705, value_loss: 0.7096
2024-07-11 16:41:03,784 [INFO    ] __main__: train step 10270: loss: 1.0287, policy_loss: 1.0704, value_loss: 0.7096
2024-07-11 16:41:03,989 [INFO    ] __main__: train step 10271: loss: 1.0286, policy_loss: 1.0704, value_loss: 0.7095
2024-07-11 16:41:04,205 [INFO    ] __main__: train step 10272: loss: 1.0286, policy_loss: 1.0703, value_loss: 0.7095
2024-07-11 16:41:04,409 [INFO    ] __main__: train step 10273: loss: 1.0286, policy_loss: 1.0703, value_loss: 0.7095
2024-07-11 16:41:04,617 [INFO    ] __main__: train step 10274: loss: 1.0286, policy_loss: 1.0702, value_loss: 0.7094
2024-07-11 16:41:04,820 [INFO    ] __main__: train step 10275: loss: 1.0285, policy_loss: 1.0702, value_loss: 0.7094
2024-07-11 16:41:05,038 [INFO    ] __main__: train step 10276: loss: 1.0285, policy_loss: 1.0701, value_loss: 0.7093
2024-07-11 16:41:05,258 [INFO    ] __main__: train step 10277: loss: 1.0285, policy_loss: 1.0700, value_loss: 0.7093
2024-07-11 16:41:05,463 [INFO    ] __main__: train step 10278: loss: 1.0285, policy_loss: 1.0700, value_loss: 0.7093
2024-07-11 16:41:05,679 [INFO    ] __main__: train step 10279: loss: 1.0285, policy_loss: 1.0699, value_loss: 0.7092
2024-07-11 16:41:05,889 [INFO    ] __main__: train step 10280: loss: 1.0284, policy_loss: 1.0699, value_loss: 0.7092
2024-07-11 16:41:06,102 [INFO    ] __main__: train step 10281: loss: 1.0284, policy_loss: 1.0698, value_loss: 0.7092
2024-07-11 16:41:06,308 [INFO    ] __main__: train step 10282: loss: 1.0284, policy_loss: 1.0698, value_loss: 0.7091
2024-07-11 16:41:06,509 [INFO    ] __main__: train step 10283: loss: 1.0284, policy_loss: 1.0697, value_loss: 0.7091
2024-07-11 16:41:06,715 [INFO    ] __main__: train step 10284: loss: 1.0283, policy_loss: 1.0696, value_loss: 0.7090
2024-07-11 16:41:08,158 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:41:08,575 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:41:08,635 [INFO    ] __main__: train step 10285: loss: 1.0283, policy_loss: 1.0696, value_loss: 0.7090
2024-07-11 16:41:08,822 [INFO    ] __main__: train step 10286: loss: 1.0283, policy_loss: 1.0695, value_loss: 0.7090
2024-07-11 16:41:09,033 [INFO    ] __main__: train step 10287: loss: 1.0283, policy_loss: 1.0695, value_loss: 0.7089
2024-07-11 16:41:09,227 [INFO    ] __main__: train step 10288: loss: 1.0283, policy_loss: 1.0694, value_loss: 0.7089
2024-07-11 16:41:09,425 [INFO    ] __main__: train step 10289: loss: 1.0282, policy_loss: 1.0693, value_loss: 0.7089
2024-07-11 16:41:09,634 [INFO    ] __main__: train step 10290: loss: 1.0282, policy_loss: 1.0693, value_loss: 0.7088
2024-07-11 16:41:09,828 [INFO    ] __main__: train step 10291: loss: 1.0282, policy_loss: 1.0692, value_loss: 0.7088
2024-07-11 16:41:10,031 [INFO    ] __main__: train step 10292: loss: 1.0282, policy_loss: 1.0692, value_loss: 0.7087
2024-07-11 16:41:11,614 [INFO    ] __main__: train step 10293: loss: 1.0282, policy_loss: 1.0691, value_loss: 0.7087
2024-07-11 16:41:11,847 [INFO    ] __main__: train step 10294: loss: 1.0281, policy_loss: 1.0691, value_loss: 0.7087
2024-07-11 16:41:12,078 [INFO    ] __main__: train step 10295: loss: 1.0281, policy_loss: 1.0690, value_loss: 0.7086
2024-07-11 16:41:12,274 [INFO    ] __main__: train step 10296: loss: 1.0281, policy_loss: 1.0690, value_loss: 0.7086
2024-07-11 16:41:12,469 [INFO    ] __main__: train step 10297: loss: 1.0281, policy_loss: 1.0689, value_loss: 0.7086
2024-07-11 16:41:12,671 [INFO    ] __main__: train step 10298: loss: 1.0281, policy_loss: 1.0688, value_loss: 0.7085
2024-07-11 16:41:12,878 [INFO    ] __main__: train step 10299: loss: 1.0280, policy_loss: 1.0688, value_loss: 0.7085
2024-07-11 16:41:13,078 [INFO    ] __main__: train step 10300: loss: 1.0280, policy_loss: 1.0687, value_loss: 0.7084
2024-07-11 16:41:13,285 [INFO    ] __main__: train step 10301: loss: 1.0280, policy_loss: 1.0687, value_loss: 0.7084
2024-07-11 16:41:14,753 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:41:15,156 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:41:15,214 [INFO    ] __main__: train step 10302: loss: 1.0280, policy_loss: 1.0686, value_loss: 0.7084
2024-07-11 16:41:15,381 [INFO    ] __main__: train step 10303: loss: 1.0279, policy_loss: 1.0686, value_loss: 0.7083
2024-07-11 16:41:15,582 [INFO    ] __main__: train step 10304: loss: 1.0279, policy_loss: 1.0685, value_loss: 0.7083
2024-07-11 16:41:15,785 [INFO    ] __main__: train step 10305: loss: 1.0279, policy_loss: 1.0684, value_loss: 0.7083
2024-07-11 16:41:15,996 [INFO    ] __main__: train step 10306: loss: 1.0279, policy_loss: 1.0684, value_loss: 0.7082
2024-07-11 16:41:16,191 [INFO    ] __main__: train step 10307: loss: 1.0279, policy_loss: 1.0683, value_loss: 0.7082
2024-07-11 16:41:16,395 [INFO    ] __main__: train step 10308: loss: 1.0278, policy_loss: 1.0683, value_loss: 0.7081
2024-07-11 16:41:16,600 [INFO    ] __main__: train step 10309: loss: 1.0278, policy_loss: 1.0682, value_loss: 0.7081
2024-07-11 16:41:16,795 [INFO    ] __main__: train step 10310: loss: 1.0278, policy_loss: 1.0682, value_loss: 0.7081
2024-07-11 16:41:17,006 [INFO    ] __main__: train step 10311: loss: 1.0278, policy_loss: 1.0681, value_loss: 0.7080
2024-07-11 16:41:17,200 [INFO    ] __main__: train step 10312: loss: 1.0278, policy_loss: 1.0680, value_loss: 0.7080
2024-07-11 16:41:17,414 [INFO    ] __main__: train step 10313: loss: 1.0277, policy_loss: 1.0680, value_loss: 0.7080
2024-07-11 16:41:17,608 [INFO    ] __main__: train step 10314: loss: 1.0277, policy_loss: 1.0679, value_loss: 0.7079
2024-07-11 16:41:17,829 [INFO    ] __main__: train step 10315: loss: 1.0277, policy_loss: 1.0679, value_loss: 0.7079
2024-07-11 16:41:18,037 [INFO    ] __main__: train step 10316: loss: 1.0277, policy_loss: 1.0678, value_loss: 0.7078
2024-07-11 16:41:18,263 [INFO    ] __main__: train step 10317: loss: 1.0276, policy_loss: 1.0678, value_loss: 0.7078
2024-07-11 16:41:18,460 [INFO    ] __main__: train step 10318: loss: 1.0276, policy_loss: 1.0677, value_loss: 0.7078
2024-07-11 16:41:19,903 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:41:20,291 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:41:20,346 [INFO    ] __main__: train step 10319: loss: 1.0276, policy_loss: 1.0676, value_loss: 0.7077
2024-07-11 16:41:20,528 [INFO    ] __main__: train step 10320: loss: 1.0276, policy_loss: 1.0676, value_loss: 0.7077
2024-07-11 16:41:20,748 [INFO    ] __main__: train step 10321: loss: 1.0276, policy_loss: 1.0675, value_loss: 0.7077
2024-07-11 16:41:20,975 [INFO    ] __main__: train step 10322: loss: 1.0275, policy_loss: 1.0675, value_loss: 0.7076
2024-07-11 16:41:21,175 [INFO    ] __main__: train step 10323: loss: 1.0275, policy_loss: 1.0674, value_loss: 0.7076
2024-07-11 16:41:21,380 [INFO    ] __main__: train step 10324: loss: 1.0275, policy_loss: 1.0674, value_loss: 0.7075
2024-07-11 16:41:21,580 [INFO    ] __main__: train step 10325: loss: 1.0275, policy_loss: 1.0673, value_loss: 0.7075
2024-07-11 16:41:21,788 [INFO    ] __main__: train step 10326: loss: 1.0275, policy_loss: 1.0673, value_loss: 0.7075
2024-07-11 16:41:21,982 [INFO    ] __main__: train step 10327: loss: 1.0274, policy_loss: 1.0672, value_loss: 0.7074
2024-07-11 16:41:22,191 [INFO    ] __main__: train step 10328: loss: 1.0274, policy_loss: 1.0671, value_loss: 0.7074
2024-07-11 16:41:22,394 [INFO    ] __main__: train step 10329: loss: 1.0274, policy_loss: 1.0671, value_loss: 0.7074
2024-07-11 16:41:22,595 [INFO    ] __main__: train step 10330: loss: 1.0274, policy_loss: 1.0670, value_loss: 0.7073
2024-07-11 16:41:22,796 [INFO    ] __main__: train step 10331: loss: 1.0273, policy_loss: 1.0670, value_loss: 0.7073
2024-07-11 16:41:23,005 [INFO    ] __main__: train step 10332: loss: 1.0273, policy_loss: 1.0669, value_loss: 0.7072
2024-07-11 16:41:23,204 [INFO    ] __main__: train step 10333: loss: 1.0273, policy_loss: 1.0669, value_loss: 0.7072
2024-07-11 16:41:23,430 [INFO    ] __main__: train step 10334: loss: 1.0273, policy_loss: 1.0668, value_loss: 0.7072
2024-07-11 16:41:23,625 [INFO    ] __main__: train step 10335: loss: 1.0272, policy_loss: 1.0667, value_loss: 0.7071
2024-07-11 16:41:25,075 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:41:25,442 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:41:25,499 [INFO    ] __main__: train step 10336: loss: 1.0272, policy_loss: 1.0667, value_loss: 0.7071
2024-07-11 16:41:25,679 [INFO    ] __main__: train step 10337: loss: 1.0272, policy_loss: 1.0666, value_loss: 0.7071
2024-07-11 16:41:25,884 [INFO    ] __main__: train step 10338: loss: 1.0272, policy_loss: 1.0666, value_loss: 0.7070
2024-07-11 16:41:26,088 [INFO    ] __main__: train step 10339: loss: 1.0272, policy_loss: 1.0665, value_loss: 0.7070
2024-07-11 16:41:26,294 [INFO    ] __main__: train step 10340: loss: 1.0271, policy_loss: 1.0665, value_loss: 0.7069
2024-07-11 16:41:26,491 [INFO    ] __main__: train step 10341: loss: 1.0271, policy_loss: 1.0664, value_loss: 0.7069
2024-07-11 16:41:26,712 [INFO    ] __main__: train step 10342: loss: 1.0271, policy_loss: 1.0663, value_loss: 0.7069
2024-07-11 16:41:26,922 [INFO    ] __main__: train step 10343: loss: 1.0271, policy_loss: 1.0663, value_loss: 0.7068
2024-07-11 16:41:27,129 [INFO    ] __main__: train step 10344: loss: 1.0271, policy_loss: 1.0662, value_loss: 0.7068
2024-07-11 16:41:27,357 [INFO    ] __main__: train step 10345: loss: 1.0270, policy_loss: 1.0662, value_loss: 0.7068
2024-07-11 16:41:27,584 [INFO    ] __main__: train step 10346: loss: 1.0270, policy_loss: 1.0661, value_loss: 0.7067
2024-07-11 16:41:27,830 [INFO    ] __main__: train step 10347: loss: 1.0270, policy_loss: 1.0661, value_loss: 0.7067
2024-07-11 16:41:28,019 [INFO    ] __main__: train step 10348: loss: 1.0270, policy_loss: 1.0660, value_loss: 0.7066
2024-07-11 16:41:28,234 [INFO    ] __main__: train step 10349: loss: 1.0269, policy_loss: 1.0660, value_loss: 0.7066
2024-07-11 16:41:28,448 [INFO    ] __main__: train step 10350: loss: 1.0269, policy_loss: 1.0659, value_loss: 0.7066
2024-07-11 16:41:28,676 [INFO    ] __main__: train step 10351: loss: 1.0269, policy_loss: 1.0658, value_loss: 0.7065
2024-07-11 16:41:28,877 [INFO    ] __main__: train step 10352: loss: 1.0269, policy_loss: 1.0658, value_loss: 0.7065
2024-07-11 16:41:30,313 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:41:30,709 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:41:30,769 [INFO    ] __main__: train step 10353: loss: 1.0269, policy_loss: 1.0657, value_loss: 0.7065
2024-07-11 16:41:30,936 [INFO    ] __main__: train step 10354: loss: 1.0269, policy_loss: 1.0657, value_loss: 0.7064
2024-07-11 16:41:31,141 [INFO    ] __main__: train step 10355: loss: 1.0268, policy_loss: 1.0656, value_loss: 0.7064
2024-07-11 16:41:31,342 [INFO    ] __main__: train step 10356: loss: 1.0268, policy_loss: 1.0656, value_loss: 0.7064
2024-07-11 16:41:31,545 [INFO    ] __main__: train step 10357: loss: 1.0268, policy_loss: 1.0655, value_loss: 0.7063
2024-07-11 16:41:31,741 [INFO    ] __main__: train step 10358: loss: 1.0268, policy_loss: 1.0655, value_loss: 0.7063
2024-07-11 16:41:31,942 [INFO    ] __main__: train step 10359: loss: 1.0267, policy_loss: 1.0654, value_loss: 0.7062
2024-07-11 16:41:32,158 [INFO    ] __main__: train step 10360: loss: 1.0267, policy_loss: 1.0653, value_loss: 0.7062
2024-07-11 16:41:32,386 [INFO    ] __main__: train step 10361: loss: 1.0267, policy_loss: 1.0653, value_loss: 0.7062
2024-07-11 16:41:32,583 [INFO    ] __main__: train step 10362: loss: 1.0267, policy_loss: 1.0652, value_loss: 0.7061
2024-07-11 16:41:32,795 [INFO    ] __main__: train step 10363: loss: 1.0267, policy_loss: 1.0652, value_loss: 0.7061
2024-07-11 16:41:33,013 [INFO    ] __main__: train step 10364: loss: 1.0266, policy_loss: 1.0651, value_loss: 0.7061
2024-07-11 16:41:33,210 [INFO    ] __main__: train step 10365: loss: 1.0266, policy_loss: 1.0651, value_loss: 0.7060
2024-07-11 16:41:33,416 [INFO    ] __main__: train step 10366: loss: 1.0266, policy_loss: 1.0650, value_loss: 0.7060
2024-07-11 16:41:33,653 [INFO    ] __main__: train step 10367: loss: 1.0266, policy_loss: 1.0649, value_loss: 0.7059
2024-07-11 16:41:33,879 [INFO    ] __main__: train step 10368: loss: 1.0265, policy_loss: 1.0649, value_loss: 0.7059
2024-07-11 16:41:34,082 [INFO    ] __main__: train step 10369: loss: 1.0265, policy_loss: 1.0648, value_loss: 0.7059
2024-07-11 16:41:35,517 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:41:35,866 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:41:35,922 [INFO    ] __main__: train step 10370: loss: 1.0265, policy_loss: 1.0648, value_loss: 0.7058
2024-07-11 16:41:36,099 [INFO    ] __main__: train step 10371: loss: 1.0265, policy_loss: 1.0647, value_loss: 0.7058
2024-07-11 16:41:36,305 [INFO    ] __main__: train step 10372: loss: 1.0265, policy_loss: 1.0647, value_loss: 0.7057
2024-07-11 16:41:36,510 [INFO    ] __main__: train step 10373: loss: 1.0264, policy_loss: 1.0646, value_loss: 0.7057
2024-07-11 16:41:36,704 [INFO    ] __main__: train step 10374: loss: 1.0264, policy_loss: 1.0646, value_loss: 0.7057
2024-07-11 16:41:36,913 [INFO    ] __main__: train step 10375: loss: 1.0264, policy_loss: 1.0645, value_loss: 0.7056
2024-07-11 16:41:37,106 [INFO    ] __main__: train step 10376: loss: 1.0264, policy_loss: 1.0644, value_loss: 0.7056
2024-07-11 16:41:37,304 [INFO    ] __main__: train step 10377: loss: 1.0264, policy_loss: 1.0644, value_loss: 0.7056
2024-07-11 16:41:37,507 [INFO    ] __main__: train step 10378: loss: 1.0263, policy_loss: 1.0643, value_loss: 0.7055
2024-07-11 16:41:37,716 [INFO    ] __main__: train step 10379: loss: 1.0263, policy_loss: 1.0643, value_loss: 0.7055
2024-07-11 16:41:37,915 [INFO    ] __main__: train step 10380: loss: 1.0263, policy_loss: 1.0642, value_loss: 0.7055
2024-07-11 16:41:38,130 [INFO    ] __main__: train step 10381: loss: 1.0263, policy_loss: 1.0642, value_loss: 0.7054
2024-07-11 16:41:38,333 [INFO    ] __main__: train step 10382: loss: 1.0263, policy_loss: 1.0641, value_loss: 0.7054
2024-07-11 16:41:38,553 [INFO    ] __main__: train step 10383: loss: 1.0262, policy_loss: 1.0641, value_loss: 0.7053
2024-07-11 16:41:38,797 [INFO    ] __main__: train step 10384: loss: 1.0262, policy_loss: 1.0640, value_loss: 0.7053
2024-07-11 16:41:39,018 [INFO    ] __main__: train step 10385: loss: 1.0262, policy_loss: 1.0640, value_loss: 0.7053
2024-07-11 16:41:39,235 [INFO    ] __main__: train step 10386: loss: 1.0262, policy_loss: 1.0639, value_loss: 0.7052
2024-07-11 16:41:40,678 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:41:41,045 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:41:41,100 [INFO    ] __main__: train step 10387: loss: 1.0261, policy_loss: 1.0638, value_loss: 0.7052
2024-07-11 16:41:41,276 [INFO    ] __main__: train step 10388: loss: 1.0261, policy_loss: 1.0638, value_loss: 0.7052
2024-07-11 16:41:41,498 [INFO    ] __main__: train step 10389: loss: 1.0261, policy_loss: 1.0637, value_loss: 0.7051
2024-07-11 16:41:41,703 [INFO    ] __main__: train step 10390: loss: 1.0261, policy_loss: 1.0637, value_loss: 0.7051
2024-07-11 16:41:41,915 [INFO    ] __main__: train step 10391: loss: 1.0261, policy_loss: 1.0636, value_loss: 0.7050
2024-07-11 16:41:43,505 [INFO    ] __main__: train step 10392: loss: 1.0260, policy_loss: 1.0636, value_loss: 0.7050
2024-07-11 16:41:43,704 [INFO    ] __main__: train step 10393: loss: 1.0260, policy_loss: 1.0635, value_loss: 0.7050
2024-07-11 16:41:43,926 [INFO    ] __main__: train step 10394: loss: 1.0260, policy_loss: 1.0635, value_loss: 0.7049
2024-07-11 16:41:44,150 [INFO    ] __main__: train step 10395: loss: 1.0260, policy_loss: 1.0634, value_loss: 0.7049
2024-07-11 16:41:44,365 [INFO    ] __main__: train step 10396: loss: 1.0260, policy_loss: 1.0633, value_loss: 0.7049
2024-07-11 16:41:44,565 [INFO    ] __main__: train step 10397: loss: 1.0259, policy_loss: 1.0633, value_loss: 0.7048
2024-07-11 16:41:44,780 [INFO    ] __main__: train step 10398: loss: 1.0259, policy_loss: 1.0632, value_loss: 0.7048
2024-07-11 16:41:45,008 [INFO    ] __main__: train step 10399: loss: 1.0259, policy_loss: 1.0632, value_loss: 0.7047
2024-07-11 16:41:45,205 [INFO    ] __main__: train step 10400: loss: 1.0259, policy_loss: 1.0631, value_loss: 0.7047
2024-07-11 16:41:45,408 [INFO    ] __main__: train step 10401: loss: 1.0259, policy_loss: 1.0631, value_loss: 0.7047
2024-07-11 16:41:45,612 [INFO    ] __main__: train step 10402: loss: 1.0258, policy_loss: 1.0630, value_loss: 0.7046
2024-07-11 16:41:45,809 [INFO    ] __main__: train step 10403: loss: 1.0258, policy_loss: 1.0630, value_loss: 0.7046
2024-07-11 16:41:47,249 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:41:47,631 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:41:47,689 [INFO    ] __main__: train step 10404: loss: 1.0258, policy_loss: 1.0629, value_loss: 0.7046
2024-07-11 16:41:47,873 [INFO    ] __main__: train step 10405: loss: 1.0258, policy_loss: 1.0628, value_loss: 0.7045
2024-07-11 16:41:48,097 [INFO    ] __main__: train step 10406: loss: 1.0258, policy_loss: 1.0628, value_loss: 0.7045
2024-07-11 16:41:48,393 [INFO    ] __main__: train step 10407: loss: 1.0257, policy_loss: 1.0627, value_loss: 0.7045
2024-07-11 16:41:48,594 [INFO    ] __main__: train step 10408: loss: 1.0257, policy_loss: 1.0627, value_loss: 0.7044
2024-07-11 16:41:48,792 [INFO    ] __main__: train step 10409: loss: 1.0257, policy_loss: 1.0626, value_loss: 0.7044
2024-07-11 16:41:49,025 [INFO    ] __main__: train step 10410: loss: 1.0257, policy_loss: 1.0626, value_loss: 0.7043
2024-07-11 16:41:49,258 [INFO    ] __main__: train step 10411: loss: 1.0256, policy_loss: 1.0625, value_loss: 0.7043
2024-07-11 16:41:49,459 [INFO    ] __main__: train step 10412: loss: 1.0256, policy_loss: 1.0625, value_loss: 0.7043
2024-07-11 16:41:49,668 [INFO    ] __main__: train step 10413: loss: 1.0256, policy_loss: 1.0624, value_loss: 0.7042
2024-07-11 16:41:49,875 [INFO    ] __main__: train step 10414: loss: 1.0256, policy_loss: 1.0623, value_loss: 0.7042
2024-07-11 16:41:50,091 [INFO    ] __main__: train step 10415: loss: 1.0256, policy_loss: 1.0623, value_loss: 0.7042
2024-07-11 16:41:50,289 [INFO    ] __main__: train step 10416: loss: 1.0255, policy_loss: 1.0622, value_loss: 0.7041
2024-07-11 16:41:50,504 [INFO    ] __main__: train step 10417: loss: 1.0255, policy_loss: 1.0622, value_loss: 0.7041
2024-07-11 16:41:50,717 [INFO    ] __main__: train step 10418: loss: 1.0255, policy_loss: 1.0621, value_loss: 0.7041
2024-07-11 16:41:50,927 [INFO    ] __main__: train step 10419: loss: 1.0255, policy_loss: 1.0621, value_loss: 0.7040
2024-07-11 16:41:51,148 [INFO    ] __main__: train step 10420: loss: 1.0255, policy_loss: 1.0620, value_loss: 0.7040
2024-07-11 16:41:52,576 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:41:52,941 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:41:52,997 [INFO    ] __main__: train step 10421: loss: 1.0254, policy_loss: 1.0620, value_loss: 0.7039
2024-07-11 16:41:53,182 [INFO    ] __main__: train step 10422: loss: 1.0254, policy_loss: 1.0619, value_loss: 0.7039
2024-07-11 16:41:53,413 [INFO    ] __main__: train step 10423: loss: 1.0254, policy_loss: 1.0619, value_loss: 0.7039
2024-07-11 16:41:53,655 [INFO    ] __main__: train step 10424: loss: 1.0254, policy_loss: 1.0618, value_loss: 0.7038
2024-07-11 16:41:53,862 [INFO    ] __main__: train step 10425: loss: 1.0254, policy_loss: 1.0617, value_loss: 0.7038
2024-07-11 16:41:54,090 [INFO    ] __main__: train step 10426: loss: 1.0253, policy_loss: 1.0617, value_loss: 0.7038
2024-07-11 16:41:54,295 [INFO    ] __main__: train step 10427: loss: 1.0253, policy_loss: 1.0616, value_loss: 0.7037
2024-07-11 16:41:54,505 [INFO    ] __main__: train step 10428: loss: 1.0253, policy_loss: 1.0616, value_loss: 0.7037
2024-07-11 16:41:54,741 [INFO    ] __main__: train step 10429: loss: 1.0253, policy_loss: 1.0615, value_loss: 0.7037
2024-07-11 16:41:54,963 [INFO    ] __main__: train step 10430: loss: 1.0253, policy_loss: 1.0615, value_loss: 0.7036
2024-07-11 16:41:55,192 [INFO    ] __main__: train step 10431: loss: 1.0252, policy_loss: 1.0614, value_loss: 0.7036
2024-07-11 16:41:55,391 [INFO    ] __main__: train step 10432: loss: 1.0252, policy_loss: 1.0614, value_loss: 0.7035
2024-07-11 16:41:55,582 [INFO    ] __main__: train step 10433: loss: 1.0252, policy_loss: 1.0613, value_loss: 0.7035
2024-07-11 16:41:55,786 [INFO    ] __main__: train step 10434: loss: 1.0252, policy_loss: 1.0613, value_loss: 0.7035
2024-07-11 16:41:55,998 [INFO    ] __main__: train step 10435: loss: 1.0252, policy_loss: 1.0612, value_loss: 0.7034
2024-07-11 16:41:56,231 [INFO    ] __main__: train step 10436: loss: 1.0251, policy_loss: 1.0611, value_loss: 0.7034
2024-07-11 16:41:56,435 [INFO    ] __main__: train step 10437: loss: 1.0251, policy_loss: 1.0611, value_loss: 0.7034
2024-07-11 16:41:57,884 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:41:58,260 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:41:58,316 [INFO    ] __main__: train step 10438: loss: 1.0251, policy_loss: 1.0610, value_loss: 0.7033
2024-07-11 16:41:58,486 [INFO    ] __main__: train step 10439: loss: 1.0251, policy_loss: 1.0610, value_loss: 0.7033
2024-07-11 16:41:58,687 [INFO    ] __main__: train step 10440: loss: 1.0251, policy_loss: 1.0609, value_loss: 0.7033
2024-07-11 16:41:58,879 [INFO    ] __main__: train step 10441: loss: 1.0250, policy_loss: 1.0609, value_loss: 0.7032
2024-07-11 16:41:59,104 [INFO    ] __main__: train step 10442: loss: 1.0250, policy_loss: 1.0608, value_loss: 0.7032
2024-07-11 16:41:59,312 [INFO    ] __main__: train step 10443: loss: 1.0250, policy_loss: 1.0608, value_loss: 0.7031
2024-07-11 16:41:59,547 [INFO    ] __main__: train step 10444: loss: 1.0250, policy_loss: 1.0607, value_loss: 0.7031
2024-07-11 16:41:59,759 [INFO    ] __main__: train step 10445: loss: 1.0250, policy_loss: 1.0606, value_loss: 0.7031
2024-07-11 16:41:59,966 [INFO    ] __main__: train step 10446: loss: 1.0249, policy_loss: 1.0606, value_loss: 0.7030
2024-07-11 16:42:00,173 [INFO    ] __main__: train step 10447: loss: 1.0249, policy_loss: 1.0605, value_loss: 0.7030
2024-07-11 16:42:00,395 [INFO    ] __main__: train step 10448: loss: 1.0249, policy_loss: 1.0605, value_loss: 0.7030
2024-07-11 16:42:00,624 [INFO    ] __main__: train step 10449: loss: 1.0249, policy_loss: 1.0604, value_loss: 0.7029
2024-07-11 16:42:00,824 [INFO    ] __main__: train step 10450: loss: 1.0249, policy_loss: 1.0604, value_loss: 0.7029
2024-07-11 16:42:01,026 [INFO    ] __main__: train step 10451: loss: 1.0248, policy_loss: 1.0603, value_loss: 0.7029
2024-07-11 16:42:01,231 [INFO    ] __main__: train step 10452: loss: 1.0248, policy_loss: 1.0603, value_loss: 0.7028
2024-07-11 16:42:01,434 [INFO    ] __main__: train step 10453: loss: 1.0248, policy_loss: 1.0602, value_loss: 0.7028
2024-07-11 16:42:01,651 [INFO    ] __main__: train step 10454: loss: 1.0248, policy_loss: 1.0602, value_loss: 0.7027
2024-07-11 16:42:03,085 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:42:03,461 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:42:03,516 [INFO    ] __main__: train step 10455: loss: 1.0248, policy_loss: 1.0601, value_loss: 0.7027
2024-07-11 16:42:03,685 [INFO    ] __main__: train step 10456: loss: 1.0247, policy_loss: 1.0600, value_loss: 0.7027
2024-07-11 16:42:03,887 [INFO    ] __main__: train step 10457: loss: 1.0247, policy_loss: 1.0600, value_loss: 0.7026
2024-07-11 16:42:04,091 [INFO    ] __main__: train step 10458: loss: 1.0247, policy_loss: 1.0599, value_loss: 0.7026
2024-07-11 16:42:04,294 [INFO    ] __main__: train step 10459: loss: 1.0247, policy_loss: 1.0599, value_loss: 0.7026
2024-07-11 16:42:04,500 [INFO    ] __main__: train step 10460: loss: 1.0246, policy_loss: 1.0598, value_loss: 0.7025
2024-07-11 16:42:04,713 [INFO    ] __main__: train step 10461: loss: 1.0246, policy_loss: 1.0598, value_loss: 0.7025
2024-07-11 16:42:04,920 [INFO    ] __main__: train step 10462: loss: 1.0246, policy_loss: 1.0597, value_loss: 0.7025
2024-07-11 16:42:05,137 [INFO    ] __main__: train step 10463: loss: 1.0246, policy_loss: 1.0597, value_loss: 0.7024
2024-07-11 16:42:05,387 [INFO    ] __main__: train step 10464: loss: 1.0246, policy_loss: 1.0596, value_loss: 0.7024
2024-07-11 16:42:05,606 [INFO    ] __main__: train step 10465: loss: 1.0245, policy_loss: 1.0595, value_loss: 0.7024
2024-07-11 16:42:05,856 [INFO    ] __main__: train step 10466: loss: 1.0245, policy_loss: 1.0595, value_loss: 0.7023
2024-07-11 16:42:06,068 [INFO    ] __main__: train step 10467: loss: 1.0245, policy_loss: 1.0594, value_loss: 0.7023
2024-07-11 16:42:06,265 [INFO    ] __main__: train step 10468: loss: 1.0245, policy_loss: 1.0594, value_loss: 0.7022
2024-07-11 16:42:06,476 [INFO    ] __main__: train step 10469: loss: 1.0245, policy_loss: 1.0593, value_loss: 0.7022
2024-07-11 16:42:06,680 [INFO    ] __main__: train step 10470: loss: 1.0244, policy_loss: 1.0593, value_loss: 0.7022
2024-07-11 16:42:06,878 [INFO    ] __main__: train step 10471: loss: 1.0244, policy_loss: 1.0592, value_loss: 0.7021
2024-07-11 16:42:08,330 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:42:08,686 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:42:08,744 [INFO    ] __main__: train step 10472: loss: 1.0244, policy_loss: 1.0592, value_loss: 0.7021
2024-07-11 16:42:08,926 [INFO    ] __main__: train step 10473: loss: 1.0244, policy_loss: 1.0591, value_loss: 0.7021
2024-07-11 16:42:09,135 [INFO    ] __main__: train step 10474: loss: 1.0244, policy_loss: 1.0591, value_loss: 0.7020
2024-07-11 16:42:09,365 [INFO    ] __main__: train step 10475: loss: 1.0243, policy_loss: 1.0590, value_loss: 0.7020
2024-07-11 16:42:09,561 [INFO    ] __main__: train step 10476: loss: 1.0243, policy_loss: 1.0589, value_loss: 0.7020
2024-07-11 16:42:09,762 [INFO    ] __main__: train step 10477: loss: 1.0243, policy_loss: 1.0589, value_loss: 0.7019
2024-07-11 16:42:09,956 [INFO    ] __main__: train step 10478: loss: 1.0243, policy_loss: 1.0588, value_loss: 0.7019
2024-07-11 16:42:10,158 [INFO    ] __main__: train step 10479: loss: 1.0243, policy_loss: 1.0588, value_loss: 0.7018
2024-07-11 16:42:10,365 [INFO    ] __main__: train step 10480: loss: 1.0242, policy_loss: 1.0587, value_loss: 0.7018
2024-07-11 16:42:10,564 [INFO    ] __main__: train step 10481: loss: 1.0242, policy_loss: 1.0587, value_loss: 0.7018
2024-07-11 16:42:10,770 [INFO    ] __main__: train step 10482: loss: 1.0242, policy_loss: 1.0586, value_loss: 0.7017
2024-07-11 16:42:10,982 [INFO    ] __main__: train step 10483: loss: 1.0242, policy_loss: 1.0586, value_loss: 0.7017
2024-07-11 16:42:11,202 [INFO    ] __main__: train step 10484: loss: 1.0242, policy_loss: 1.0585, value_loss: 0.7017
2024-07-11 16:42:11,412 [INFO    ] __main__: train step 10485: loss: 1.0241, policy_loss: 1.0585, value_loss: 0.7016
2024-07-11 16:42:11,635 [INFO    ] __main__: train step 10486: loss: 1.0241, policy_loss: 1.0584, value_loss: 0.7016
2024-07-11 16:42:11,854 [INFO    ] __main__: train step 10487: loss: 1.0241, policy_loss: 1.0583, value_loss: 0.7016
2024-07-11 16:42:12,074 [INFO    ] __main__: train step 10488: loss: 1.0241, policy_loss: 1.0583, value_loss: 0.7015
2024-07-11 16:42:13,514 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:42:13,879 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:42:13,935 [INFO    ] __main__: train step 10489: loss: 1.0241, policy_loss: 1.0582, value_loss: 0.7015
2024-07-11 16:42:14,122 [INFO    ] __main__: train step 10490: loss: 1.0240, policy_loss: 1.0582, value_loss: 0.7015
2024-07-11 16:42:14,322 [INFO    ] __main__: train step 10491: loss: 1.0240, policy_loss: 1.0581, value_loss: 0.7014
2024-07-11 16:42:14,532 [INFO    ] __main__: train step 10492: loss: 1.0240, policy_loss: 1.0581, value_loss: 0.7014
2024-07-11 16:42:14,784 [INFO    ] __main__: train step 10493: loss: 1.0240, policy_loss: 1.0580, value_loss: 0.7014
2024-07-11 16:42:16,328 [INFO    ] __main__: train step 10494: loss: 1.0240, policy_loss: 1.0580, value_loss: 0.7013
2024-07-11 16:42:16,540 [INFO    ] __main__: train step 10495: loss: 1.0240, policy_loss: 1.0579, value_loss: 0.7013
2024-07-11 16:42:16,746 [INFO    ] __main__: train step 10496: loss: 1.0239, policy_loss: 1.0579, value_loss: 0.7012
2024-07-11 16:42:16,947 [INFO    ] __main__: train step 10497: loss: 1.0239, policy_loss: 1.0578, value_loss: 0.7012
2024-07-11 16:42:17,175 [INFO    ] __main__: train step 10498: loss: 1.0239, policy_loss: 1.0577, value_loss: 0.7012
2024-07-11 16:42:17,414 [INFO    ] __main__: train step 10499: loss: 1.0239, policy_loss: 1.0577, value_loss: 0.7011
2024-07-11 16:42:17,635 [INFO    ] __main__: train step 10500: loss: 1.0239, policy_loss: 1.0576, value_loss: 0.7011
2024-07-11 16:42:17,843 [INFO    ] __main__: train step 10501: loss: 1.0238, policy_loss: 1.0576, value_loss: 0.7011
2024-07-11 16:42:18,047 [INFO    ] __main__: train step 10502: loss: 1.0238, policy_loss: 1.0575, value_loss: 0.7010
2024-07-11 16:42:18,257 [INFO    ] __main__: train step 10503: loss: 1.0238, policy_loss: 1.0575, value_loss: 0.7010
2024-07-11 16:42:18,453 [INFO    ] __main__: train step 10504: loss: 1.0238, policy_loss: 1.0574, value_loss: 0.7010
2024-07-11 16:42:18,662 [INFO    ] __main__: train step 10505: loss: 1.0238, policy_loss: 1.0574, value_loss: 0.7009
2024-07-11 16:42:20,098 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:42:20,465 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:42:20,524 [INFO    ] __main__: train step 10506: loss: 1.0237, policy_loss: 1.0573, value_loss: 0.7009
2024-07-11 16:42:20,709 [INFO    ] __main__: train step 10507: loss: 1.0237, policy_loss: 1.0573, value_loss: 0.7009
2024-07-11 16:42:20,953 [INFO    ] __main__: train step 10508: loss: 1.0237, policy_loss: 1.0572, value_loss: 0.7008
2024-07-11 16:42:21,178 [INFO    ] __main__: train step 10509: loss: 1.0237, policy_loss: 1.0572, value_loss: 0.7008
2024-07-11 16:42:21,372 [INFO    ] __main__: train step 10510: loss: 1.0237, policy_loss: 1.0571, value_loss: 0.7008
2024-07-11 16:42:21,572 [INFO    ] __main__: train step 10511: loss: 1.0236, policy_loss: 1.0570, value_loss: 0.7007
2024-07-11 16:42:21,781 [INFO    ] __main__: train step 10512: loss: 1.0236, policy_loss: 1.0570, value_loss: 0.7007
2024-07-11 16:42:21,982 [INFO    ] __main__: train step 10513: loss: 1.0236, policy_loss: 1.0569, value_loss: 0.7006
2024-07-11 16:42:22,190 [INFO    ] __main__: train step 10514: loss: 1.0236, policy_loss: 1.0569, value_loss: 0.7006
2024-07-11 16:42:22,395 [INFO    ] __main__: train step 10515: loss: 1.0236, policy_loss: 1.0568, value_loss: 0.7006
2024-07-11 16:42:22,600 [INFO    ] __main__: train step 10516: loss: 1.0235, policy_loss: 1.0568, value_loss: 0.7005
2024-07-11 16:42:22,802 [INFO    ] __main__: train step 10517: loss: 1.0235, policy_loss: 1.0567, value_loss: 0.7005
2024-07-11 16:42:23,003 [INFO    ] __main__: train step 10518: loss: 1.0235, policy_loss: 1.0567, value_loss: 0.7005
2024-07-11 16:42:23,207 [INFO    ] __main__: train step 10519: loss: 1.0235, policy_loss: 1.0566, value_loss: 0.7004
2024-07-11 16:42:23,425 [INFO    ] __main__: train step 10520: loss: 1.0235, policy_loss: 1.0566, value_loss: 0.7004
2024-07-11 16:42:23,646 [INFO    ] __main__: train step 10521: loss: 1.0234, policy_loss: 1.0565, value_loss: 0.7004
2024-07-11 16:42:23,861 [INFO    ] __main__: train step 10522: loss: 1.0234, policy_loss: 1.0564, value_loss: 0.7003
2024-07-11 16:42:25,296 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:42:25,676 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:42:25,734 [INFO    ] __main__: train step 10523: loss: 1.0234, policy_loss: 1.0564, value_loss: 0.7003
2024-07-11 16:42:25,902 [INFO    ] __main__: train step 10524: loss: 1.0234, policy_loss: 1.0563, value_loss: 0.7003
2024-07-11 16:42:26,103 [INFO    ] __main__: train step 10525: loss: 1.0234, policy_loss: 1.0563, value_loss: 0.7002
2024-07-11 16:42:26,325 [INFO    ] __main__: train step 10526: loss: 1.0233, policy_loss: 1.0562, value_loss: 0.7002
2024-07-11 16:42:26,564 [INFO    ] __main__: train step 10527: loss: 1.0233, policy_loss: 1.0562, value_loss: 0.7001
2024-07-11 16:42:26,775 [INFO    ] __main__: train step 10528: loss: 1.0233, policy_loss: 1.0561, value_loss: 0.7001
2024-07-11 16:42:26,982 [INFO    ] __main__: train step 10529: loss: 1.0233, policy_loss: 1.0561, value_loss: 0.7001
2024-07-11 16:42:27,192 [INFO    ] __main__: train step 10530: loss: 1.0233, policy_loss: 1.0560, value_loss: 0.7000
2024-07-11 16:42:27,394 [INFO    ] __main__: train step 10531: loss: 1.0232, policy_loss: 1.0560, value_loss: 0.7000
2024-07-11 16:42:27,605 [INFO    ] __main__: train step 10532: loss: 1.0232, policy_loss: 1.0559, value_loss: 0.7000
2024-07-11 16:42:27,816 [INFO    ] __main__: train step 10533: loss: 1.0232, policy_loss: 1.0559, value_loss: 0.6999
2024-07-11 16:42:28,029 [INFO    ] __main__: train step 10534: loss: 1.0232, policy_loss: 1.0558, value_loss: 0.6999
2024-07-11 16:42:28,240 [INFO    ] __main__: train step 10535: loss: 1.0231, policy_loss: 1.0557, value_loss: 0.6999
2024-07-11 16:42:28,452 [INFO    ] __main__: train step 10536: loss: 1.0231, policy_loss: 1.0557, value_loss: 0.6998
2024-07-11 16:42:28,648 [INFO    ] __main__: train step 10537: loss: 1.0231, policy_loss: 1.0556, value_loss: 0.6998
2024-07-11 16:42:28,852 [INFO    ] __main__: train step 10538: loss: 1.0231, policy_loss: 1.0556, value_loss: 0.6997
2024-07-11 16:42:29,079 [INFO    ] __main__: train step 10539: loss: 1.0231, policy_loss: 1.0555, value_loss: 0.6997
2024-07-11 16:42:30,514 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:42:30,947 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:42:31,011 [INFO    ] __main__: train step 10540: loss: 1.0230, policy_loss: 1.0555, value_loss: 0.6997
2024-07-11 16:42:31,181 [INFO    ] __main__: train step 10541: loss: 1.0230, policy_loss: 1.0554, value_loss: 0.6996
2024-07-11 16:42:31,392 [INFO    ] __main__: train step 10542: loss: 1.0230, policy_loss: 1.0554, value_loss: 0.6996
2024-07-11 16:42:31,588 [INFO    ] __main__: train step 10543: loss: 1.0230, policy_loss: 1.0553, value_loss: 0.6996
2024-07-11 16:42:31,792 [INFO    ] __main__: train step 10544: loss: 1.0230, policy_loss: 1.0553, value_loss: 0.6995
2024-07-11 16:42:31,994 [INFO    ] __main__: train step 10545: loss: 1.0229, policy_loss: 1.0552, value_loss: 0.6995
2024-07-11 16:42:32,207 [INFO    ] __main__: train step 10546: loss: 1.0229, policy_loss: 1.0552, value_loss: 0.6995
2024-07-11 16:42:32,422 [INFO    ] __main__: train step 10547: loss: 1.0229, policy_loss: 1.0551, value_loss: 0.6994
2024-07-11 16:42:32,616 [INFO    ] __main__: train step 10548: loss: 1.0229, policy_loss: 1.0550, value_loss: 0.6994
2024-07-11 16:42:32,825 [INFO    ] __main__: train step 10549: loss: 1.0229, policy_loss: 1.0550, value_loss: 0.6994
2024-07-11 16:42:33,030 [INFO    ] __main__: train step 10550: loss: 1.0229, policy_loss: 1.0549, value_loss: 0.6993
2024-07-11 16:42:33,239 [INFO    ] __main__: train step 10551: loss: 1.0228, policy_loss: 1.0549, value_loss: 0.6993
2024-07-11 16:42:33,428 [INFO    ] __main__: train step 10552: loss: 1.0228, policy_loss: 1.0548, value_loss: 0.6993
2024-07-11 16:42:33,637 [INFO    ] __main__: train step 10553: loss: 1.0228, policy_loss: 1.0548, value_loss: 0.6992
2024-07-11 16:42:33,842 [INFO    ] __main__: train step 10554: loss: 1.0228, policy_loss: 1.0547, value_loss: 0.6992
2024-07-11 16:42:34,033 [INFO    ] __main__: train step 10555: loss: 1.0228, policy_loss: 1.0547, value_loss: 0.6991
2024-07-11 16:42:34,238 [INFO    ] __main__: train step 10556: loss: 1.0227, policy_loss: 1.0546, value_loss: 0.6991
2024-07-11 16:42:35,686 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:42:36,058 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:42:36,113 [INFO    ] __main__: train step 10557: loss: 1.0227, policy_loss: 1.0546, value_loss: 0.6991
2024-07-11 16:42:36,292 [INFO    ] __main__: train step 10558: loss: 1.0227, policy_loss: 1.0545, value_loss: 0.6990
2024-07-11 16:42:36,488 [INFO    ] __main__: train step 10559: loss: 1.0227, policy_loss: 1.0545, value_loss: 0.6990
2024-07-11 16:42:36,691 [INFO    ] __main__: train step 10560: loss: 1.0227, policy_loss: 1.0544, value_loss: 0.6990
2024-07-11 16:42:36,904 [INFO    ] __main__: train step 10561: loss: 1.0226, policy_loss: 1.0543, value_loss: 0.6989
2024-07-11 16:42:37,124 [INFO    ] __main__: train step 10562: loss: 1.0226, policy_loss: 1.0543, value_loss: 0.6989
2024-07-11 16:42:37,318 [INFO    ] __main__: train step 10563: loss: 1.0226, policy_loss: 1.0542, value_loss: 0.6989
2024-07-11 16:42:37,522 [INFO    ] __main__: train step 10564: loss: 1.0226, policy_loss: 1.0542, value_loss: 0.6988
2024-07-11 16:42:37,730 [INFO    ] __main__: train step 10565: loss: 1.0226, policy_loss: 1.0541, value_loss: 0.6988
2024-07-11 16:42:37,920 [INFO    ] __main__: train step 10566: loss: 1.0225, policy_loss: 1.0541, value_loss: 0.6988
2024-07-11 16:42:38,144 [INFO    ] __main__: train step 10567: loss: 1.0225, policy_loss: 1.0540, value_loss: 0.6987
2024-07-11 16:42:38,353 [INFO    ] __main__: train step 10568: loss: 1.0225, policy_loss: 1.0540, value_loss: 0.6987
2024-07-11 16:42:38,584 [INFO    ] __main__: train step 10569: loss: 1.0225, policy_loss: 1.0539, value_loss: 0.6987
2024-07-11 16:42:38,807 [INFO    ] __main__: train step 10570: loss: 1.0225, policy_loss: 1.0539, value_loss: 0.6986
2024-07-11 16:42:39,035 [INFO    ] __main__: train step 10571: loss: 1.0224, policy_loss: 1.0538, value_loss: 0.6986
2024-07-11 16:42:39,239 [INFO    ] __main__: train step 10572: loss: 1.0224, policy_loss: 1.0538, value_loss: 0.6985
2024-07-11 16:42:39,435 [INFO    ] __main__: train step 10573: loss: 1.0224, policy_loss: 1.0537, value_loss: 0.6985
2024-07-11 16:42:40,868 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:42:41,300 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:42:41,362 [INFO    ] __main__: train step 10574: loss: 1.0224, policy_loss: 1.0536, value_loss: 0.6985
2024-07-11 16:42:41,542 [INFO    ] __main__: train step 10575: loss: 1.0224, policy_loss: 1.0536, value_loss: 0.6984
2024-07-11 16:42:41,745 [INFO    ] __main__: train step 10576: loss: 1.0223, policy_loss: 1.0535, value_loss: 0.6984
2024-07-11 16:42:41,936 [INFO    ] __main__: train step 10577: loss: 1.0223, policy_loss: 1.0535, value_loss: 0.6984
2024-07-11 16:42:42,140 [INFO    ] __main__: train step 10578: loss: 1.0223, policy_loss: 1.0534, value_loss: 0.6983
2024-07-11 16:42:42,340 [INFO    ] __main__: train step 10579: loss: 1.0223, policy_loss: 1.0534, value_loss: 0.6983
2024-07-11 16:42:42,532 [INFO    ] __main__: train step 10580: loss: 1.0223, policy_loss: 1.0533, value_loss: 0.6983
2024-07-11 16:42:42,747 [INFO    ] __main__: train step 10581: loss: 1.0222, policy_loss: 1.0533, value_loss: 0.6982
2024-07-11 16:42:42,945 [INFO    ] __main__: train step 10582: loss: 1.0222, policy_loss: 1.0532, value_loss: 0.6982
2024-07-11 16:42:43,147 [INFO    ] __main__: train step 10583: loss: 1.0222, policy_loss: 1.0532, value_loss: 0.6982
2024-07-11 16:42:43,346 [INFO    ] __main__: train step 10584: loss: 1.0222, policy_loss: 1.0531, value_loss: 0.6981
2024-07-11 16:42:43,541 [INFO    ] __main__: train step 10585: loss: 1.0222, policy_loss: 1.0531, value_loss: 0.6981
2024-07-11 16:42:43,762 [INFO    ] __main__: train step 10586: loss: 1.0221, policy_loss: 1.0530, value_loss: 0.6981
2024-07-11 16:42:43,970 [INFO    ] __main__: train step 10587: loss: 1.0221, policy_loss: 1.0530, value_loss: 0.6980
2024-07-11 16:42:44,181 [INFO    ] __main__: train step 10588: loss: 1.0221, policy_loss: 1.0529, value_loss: 0.6980
2024-07-11 16:42:44,402 [INFO    ] __main__: train step 10589: loss: 1.0221, policy_loss: 1.0529, value_loss: 0.6979
2024-07-11 16:42:44,601 [INFO    ] __main__: train step 10590: loss: 1.0221, policy_loss: 1.0528, value_loss: 0.6979
2024-07-11 16:42:46,065 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:42:46,501 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:42:46,563 [INFO    ] __main__: train step 10591: loss: 1.0221, policy_loss: 1.0528, value_loss: 0.6979
2024-07-11 16:42:46,739 [INFO    ] __main__: train step 10592: loss: 1.0220, policy_loss: 1.0527, value_loss: 0.6978
2024-07-11 16:42:46,943 [INFO    ] __main__: train step 10593: loss: 1.0220, policy_loss: 1.0526, value_loss: 0.6978
2024-07-11 16:42:47,160 [INFO    ] __main__: train step 10594: loss: 1.0220, policy_loss: 1.0526, value_loss: 0.6978
2024-07-11 16:42:48,771 [INFO    ] __main__: train step 10595: loss: 1.0220, policy_loss: 1.0525, value_loss: 0.6977
2024-07-11 16:42:48,970 [INFO    ] __main__: train step 10596: loss: 1.0220, policy_loss: 1.0525, value_loss: 0.6977
2024-07-11 16:42:49,177 [INFO    ] __main__: train step 10597: loss: 1.0219, policy_loss: 1.0524, value_loss: 0.6977
2024-07-11 16:42:49,378 [INFO    ] __main__: train step 10598: loss: 1.0219, policy_loss: 1.0524, value_loss: 0.6976
2024-07-11 16:42:49,585 [INFO    ] __main__: train step 10599: loss: 1.0219, policy_loss: 1.0523, value_loss: 0.6976
2024-07-11 16:42:49,798 [INFO    ] __main__: train step 10600: loss: 1.0219, policy_loss: 1.0523, value_loss: 0.6976
2024-07-11 16:42:50,012 [INFO    ] __main__: train step 10601: loss: 1.0219, policy_loss: 1.0522, value_loss: 0.6975
2024-07-11 16:42:50,227 [INFO    ] __main__: train step 10602: loss: 1.0219, policy_loss: 1.0522, value_loss: 0.6975
2024-07-11 16:42:50,445 [INFO    ] __main__: train step 10603: loss: 1.0218, policy_loss: 1.0521, value_loss: 0.6975
2024-07-11 16:42:50,698 [INFO    ] __main__: train step 10604: loss: 1.0218, policy_loss: 1.0521, value_loss: 0.6974
2024-07-11 16:42:50,938 [INFO    ] __main__: train step 10605: loss: 1.0218, policy_loss: 1.0520, value_loss: 0.6974
2024-07-11 16:42:51,162 [INFO    ] __main__: train step 10606: loss: 1.0218, policy_loss: 1.0520, value_loss: 0.6974
2024-07-11 16:42:51,364 [INFO    ] __main__: train step 10607: loss: 1.0218, policy_loss: 1.0519, value_loss: 0.6973
2024-07-11 16:42:52,787 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:42:53,173 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:42:53,229 [INFO    ] __main__: train step 10608: loss: 1.0217, policy_loss: 1.0519, value_loss: 0.6973
2024-07-11 16:42:53,408 [INFO    ] __main__: train step 10609: loss: 1.0217, policy_loss: 1.0518, value_loss: 0.6973
2024-07-11 16:42:53,614 [INFO    ] __main__: train step 10610: loss: 1.0217, policy_loss: 1.0518, value_loss: 0.6972
2024-07-11 16:42:53,825 [INFO    ] __main__: train step 10611: loss: 1.0217, policy_loss: 1.0517, value_loss: 0.6972
2024-07-11 16:42:54,016 [INFO    ] __main__: train step 10612: loss: 1.0217, policy_loss: 1.0517, value_loss: 0.6971
2024-07-11 16:42:54,214 [INFO    ] __main__: train step 10613: loss: 1.0216, policy_loss: 1.0516, value_loss: 0.6971
2024-07-11 16:42:54,428 [INFO    ] __main__: train step 10614: loss: 1.0216, policy_loss: 1.0515, value_loss: 0.6971
2024-07-11 16:42:54,654 [INFO    ] __main__: train step 10615: loss: 1.0216, policy_loss: 1.0515, value_loss: 0.6970
2024-07-11 16:42:54,855 [INFO    ] __main__: train step 10616: loss: 1.0216, policy_loss: 1.0514, value_loss: 0.6970
2024-07-11 16:42:55,050 [INFO    ] __main__: train step 10617: loss: 1.0216, policy_loss: 1.0514, value_loss: 0.6970
2024-07-11 16:42:55,257 [INFO    ] __main__: train step 10618: loss: 1.0216, policy_loss: 1.0513, value_loss: 0.6969
2024-07-11 16:42:55,450 [INFO    ] __main__: train step 10619: loss: 1.0215, policy_loss: 1.0513, value_loss: 0.6969
2024-07-11 16:42:55,647 [INFO    ] __main__: train step 10620: loss: 1.0215, policy_loss: 1.0512, value_loss: 0.6969
2024-07-11 16:42:55,852 [INFO    ] __main__: train step 10621: loss: 1.0215, policy_loss: 1.0512, value_loss: 0.6968
2024-07-11 16:42:56,077 [INFO    ] __main__: train step 10622: loss: 1.0215, policy_loss: 1.0511, value_loss: 0.6968
2024-07-11 16:42:56,285 [INFO    ] __main__: train step 10623: loss: 1.0215, policy_loss: 1.0511, value_loss: 0.6968
2024-07-11 16:42:56,494 [INFO    ] __main__: train step 10624: loss: 1.0214, policy_loss: 1.0510, value_loss: 0.6967
2024-07-11 16:42:57,931 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:42:58,321 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:42:58,376 [INFO    ] __main__: train step 10625: loss: 1.0214, policy_loss: 1.0510, value_loss: 0.6967
2024-07-11 16:42:58,546 [INFO    ] __main__: train step 10626: loss: 1.0214, policy_loss: 1.0509, value_loss: 0.6967
2024-07-11 16:42:58,764 [INFO    ] __main__: train step 10627: loss: 1.0214, policy_loss: 1.0509, value_loss: 0.6966
2024-07-11 16:42:58,967 [INFO    ] __main__: train step 10628: loss: 1.0214, policy_loss: 1.0508, value_loss: 0.6966
2024-07-11 16:42:59,193 [INFO    ] __main__: train step 10629: loss: 1.0214, policy_loss: 1.0508, value_loss: 0.6966
2024-07-11 16:42:59,434 [INFO    ] __main__: train step 10630: loss: 1.0213, policy_loss: 1.0507, value_loss: 0.6965
2024-07-11 16:42:59,637 [INFO    ] __main__: train step 10631: loss: 1.0213, policy_loss: 1.0507, value_loss: 0.6965
2024-07-11 16:42:59,864 [INFO    ] __main__: train step 10632: loss: 1.0213, policy_loss: 1.0506, value_loss: 0.6965
2024-07-11 16:43:00,090 [INFO    ] __main__: train step 10633: loss: 1.0213, policy_loss: 1.0506, value_loss: 0.6964
2024-07-11 16:43:00,297 [INFO    ] __main__: train step 10634: loss: 1.0213, policy_loss: 1.0505, value_loss: 0.6964
2024-07-11 16:43:00,499 [INFO    ] __main__: train step 10635: loss: 1.0212, policy_loss: 1.0505, value_loss: 0.6964
2024-07-11 16:43:00,696 [INFO    ] __main__: train step 10636: loss: 1.0212, policy_loss: 1.0504, value_loss: 0.6963
2024-07-11 16:43:00,905 [INFO    ] __main__: train step 10637: loss: 1.0212, policy_loss: 1.0504, value_loss: 0.6963
2024-07-11 16:43:01,106 [INFO    ] __main__: train step 10638: loss: 1.0212, policy_loss: 1.0503, value_loss: 0.6962
2024-07-11 16:43:01,315 [INFO    ] __main__: train step 10639: loss: 1.0212, policy_loss: 1.0502, value_loss: 0.6962
2024-07-11 16:43:01,529 [INFO    ] __main__: train step 10640: loss: 1.0211, policy_loss: 1.0502, value_loss: 0.6962
2024-07-11 16:43:01,733 [INFO    ] __main__: train step 10641: loss: 1.0211, policy_loss: 1.0501, value_loss: 0.6961
2024-07-11 16:43:03,162 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:43:03,588 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:43:03,649 [INFO    ] __main__: train step 10642: loss: 1.0211, policy_loss: 1.0501, value_loss: 0.6961
2024-07-11 16:43:03,819 [INFO    ] __main__: train step 10643: loss: 1.0211, policy_loss: 1.0500, value_loss: 0.6961
2024-07-11 16:43:04,017 [INFO    ] __main__: train step 10644: loss: 1.0211, policy_loss: 1.0500, value_loss: 0.6960
2024-07-11 16:43:04,216 [INFO    ] __main__: train step 10645: loss: 1.0211, policy_loss: 1.0499, value_loss: 0.6960
2024-07-11 16:43:04,408 [INFO    ] __main__: train step 10646: loss: 1.0210, policy_loss: 1.0499, value_loss: 0.6960
2024-07-11 16:43:04,614 [INFO    ] __main__: train step 10647: loss: 1.0210, policy_loss: 1.0498, value_loss: 0.6959
2024-07-11 16:43:04,849 [INFO    ] __main__: train step 10648: loss: 1.0210, policy_loss: 1.0498, value_loss: 0.6959
2024-07-11 16:43:05,066 [INFO    ] __main__: train step 10649: loss: 1.0210, policy_loss: 1.0497, value_loss: 0.6959
2024-07-11 16:43:05,283 [INFO    ] __main__: train step 10650: loss: 1.0210, policy_loss: 1.0497, value_loss: 0.6958
2024-07-11 16:43:05,496 [INFO    ] __main__: train step 10651: loss: 1.0209, policy_loss: 1.0496, value_loss: 0.6958
2024-07-11 16:43:05,694 [INFO    ] __main__: train step 10652: loss: 1.0209, policy_loss: 1.0496, value_loss: 0.6958
2024-07-11 16:43:05,901 [INFO    ] __main__: train step 10653: loss: 1.0209, policy_loss: 1.0495, value_loss: 0.6957
2024-07-11 16:43:06,134 [INFO    ] __main__: train step 10654: loss: 1.0209, policy_loss: 1.0495, value_loss: 0.6957
2024-07-11 16:43:06,337 [INFO    ] __main__: train step 10655: loss: 1.0209, policy_loss: 1.0494, value_loss: 0.6957
2024-07-11 16:43:06,536 [INFO    ] __main__: train step 10656: loss: 1.0209, policy_loss: 1.0494, value_loss: 0.6956
2024-07-11 16:43:06,739 [INFO    ] __main__: train step 10657: loss: 1.0208, policy_loss: 1.0493, value_loss: 0.6956
2024-07-11 16:43:06,931 [INFO    ] __main__: train step 10658: loss: 1.0208, policy_loss: 1.0493, value_loss: 0.6956
2024-07-11 16:43:08,373 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:43:08,812 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:43:08,871 [INFO    ] __main__: train step 10659: loss: 1.0208, policy_loss: 1.0492, value_loss: 0.6955
2024-07-11 16:43:09,041 [INFO    ] __main__: train step 10660: loss: 1.0208, policy_loss: 1.0492, value_loss: 0.6955
2024-07-11 16:43:09,239 [INFO    ] __main__: train step 10661: loss: 1.0208, policy_loss: 1.0491, value_loss: 0.6955
2024-07-11 16:43:09,435 [INFO    ] __main__: train step 10662: loss: 1.0207, policy_loss: 1.0490, value_loss: 0.6954
2024-07-11 16:43:09,649 [INFO    ] __main__: train step 10663: loss: 1.0207, policy_loss: 1.0490, value_loss: 0.6954
2024-07-11 16:43:09,870 [INFO    ] __main__: train step 10664: loss: 1.0207, policy_loss: 1.0489, value_loss: 0.6954
2024-07-11 16:43:10,090 [INFO    ] __main__: train step 10665: loss: 1.0207, policy_loss: 1.0489, value_loss: 0.6953
2024-07-11 16:43:10,302 [INFO    ] __main__: train step 10666: loss: 1.0207, policy_loss: 1.0488, value_loss: 0.6953
2024-07-11 16:43:10,507 [INFO    ] __main__: train step 10667: loss: 1.0207, policy_loss: 1.0488, value_loss: 0.6953
2024-07-11 16:43:10,705 [INFO    ] __main__: train step 10668: loss: 1.0206, policy_loss: 1.0487, value_loss: 0.6952
2024-07-11 16:43:10,921 [INFO    ] __main__: train step 10669: loss: 1.0206, policy_loss: 1.0487, value_loss: 0.6952
2024-07-11 16:43:11,153 [INFO    ] __main__: train step 10670: loss: 1.0206, policy_loss: 1.0486, value_loss: 0.6951
2024-07-11 16:43:11,360 [INFO    ] __main__: train step 10671: loss: 1.0206, policy_loss: 1.0486, value_loss: 0.6951
2024-07-11 16:43:11,565 [INFO    ] __main__: train step 10672: loss: 1.0206, policy_loss: 1.0485, value_loss: 0.6951
2024-07-11 16:43:11,777 [INFO    ] __main__: train step 10673: loss: 1.0206, policy_loss: 1.0485, value_loss: 0.6950
2024-07-11 16:43:11,977 [INFO    ] __main__: train step 10674: loss: 1.0205, policy_loss: 1.0484, value_loss: 0.6950
2024-07-11 16:43:12,196 [INFO    ] __main__: train step 10675: loss: 1.0205, policy_loss: 1.0484, value_loss: 0.6950
2024-07-11 16:43:13,644 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:43:14,034 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:43:14,092 [INFO    ] __main__: train step 10676: loss: 1.0205, policy_loss: 1.0483, value_loss: 0.6949
2024-07-11 16:43:14,270 [INFO    ] __main__: train step 10677: loss: 1.0205, policy_loss: 1.0483, value_loss: 0.6949
2024-07-11 16:43:14,477 [INFO    ] __main__: train step 10678: loss: 1.0205, policy_loss: 1.0482, value_loss: 0.6949
2024-07-11 16:43:14,690 [INFO    ] __main__: train step 10679: loss: 1.0204, policy_loss: 1.0482, value_loss: 0.6948
2024-07-11 16:43:14,895 [INFO    ] __main__: train step 10680: loss: 1.0204, policy_loss: 1.0481, value_loss: 0.6948
2024-07-11 16:43:15,087 [INFO    ] __main__: train step 10681: loss: 1.0204, policy_loss: 1.0481, value_loss: 0.6948
2024-07-11 16:43:15,287 [INFO    ] __main__: train step 10682: loss: 1.0204, policy_loss: 1.0480, value_loss: 0.6947
2024-07-11 16:43:15,493 [INFO    ] __main__: train step 10683: loss: 1.0204, policy_loss: 1.0480, value_loss: 0.6947
2024-07-11 16:43:15,703 [INFO    ] __main__: train step 10684: loss: 1.0204, policy_loss: 1.0479, value_loss: 0.6947
2024-07-11 16:43:15,904 [INFO    ] __main__: train step 10685: loss: 1.0203, policy_loss: 1.0479, value_loss: 0.6946
2024-07-11 16:43:16,116 [INFO    ] __main__: train step 10686: loss: 1.0203, policy_loss: 1.0478, value_loss: 0.6946
2024-07-11 16:43:16,322 [INFO    ] __main__: train step 10687: loss: 1.0203, policy_loss: 1.0478, value_loss: 0.6946
2024-07-11 16:43:16,533 [INFO    ] __main__: train step 10688: loss: 1.0203, policy_loss: 1.0477, value_loss: 0.6945
2024-07-11 16:43:16,740 [INFO    ] __main__: train step 10689: loss: 1.0203, policy_loss: 1.0477, value_loss: 0.6945
2024-07-11 16:43:16,941 [INFO    ] __main__: train step 10690: loss: 1.0203, policy_loss: 1.0476, value_loss: 0.6945
2024-07-11 16:43:17,154 [INFO    ] __main__: train step 10691: loss: 1.0202, policy_loss: 1.0476, value_loss: 0.6944
2024-07-11 16:43:17,366 [INFO    ] __main__: train step 10692: loss: 1.0202, policy_loss: 1.0475, value_loss: 0.6944
2024-07-11 16:43:18,804 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:43:19,216 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:43:19,280 [INFO    ] __main__: train step 10693: loss: 1.0202, policy_loss: 1.0475, value_loss: 0.6944
2024-07-11 16:43:19,449 [INFO    ] __main__: train step 10694: loss: 1.0202, policy_loss: 1.0474, value_loss: 0.6943
2024-07-11 16:43:19,654 [INFO    ] __main__: train step 10695: loss: 1.0202, policy_loss: 1.0474, value_loss: 0.6943
2024-07-11 16:43:21,252 [INFO    ] __main__: train step 10696: loss: 1.0202, policy_loss: 1.0473, value_loss: 0.6943
2024-07-11 16:43:21,465 [INFO    ] __main__: train step 10697: loss: 1.0201, policy_loss: 1.0473, value_loss: 0.6942
2024-07-11 16:43:21,684 [INFO    ] __main__: train step 10698: loss: 1.0201, policy_loss: 1.0472, value_loss: 0.6942
2024-07-11 16:43:21,920 [INFO    ] __main__: train step 10699: loss: 1.0201, policy_loss: 1.0472, value_loss: 0.6942
2024-07-11 16:43:22,133 [INFO    ] __main__: train step 10700: loss: 1.0201, policy_loss: 1.0471, value_loss: 0.6941
2024-07-11 16:43:22,330 [INFO    ] __main__: train step 10701: loss: 1.0201, policy_loss: 1.0471, value_loss: 0.6941
2024-07-11 16:43:22,536 [INFO    ] __main__: train step 10702: loss: 1.0201, policy_loss: 1.0470, value_loss: 0.6941
2024-07-11 16:43:22,741 [INFO    ] __main__: train step 10703: loss: 1.0200, policy_loss: 1.0470, value_loss: 0.6940
2024-07-11 16:43:22,943 [INFO    ] __main__: train step 10704: loss: 1.0200, policy_loss: 1.0469, value_loss: 0.6940
2024-07-11 16:43:23,167 [INFO    ] __main__: train step 10705: loss: 1.0200, policy_loss: 1.0469, value_loss: 0.6940
2024-07-11 16:43:23,414 [INFO    ] __main__: train step 10706: loss: 1.0200, policy_loss: 1.0468, value_loss: 0.6939
2024-07-11 16:43:23,661 [INFO    ] __main__: train step 10707: loss: 1.0200, policy_loss: 1.0468, value_loss: 0.6939
2024-07-11 16:43:23,890 [INFO    ] __main__: train step 10708: loss: 1.0200, policy_loss: 1.0467, value_loss: 0.6938
2024-07-11 16:43:24,104 [INFO    ] __main__: train step 10709: loss: 1.0199, policy_loss: 1.0467, value_loss: 0.6938
2024-07-11 16:43:25,536 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:43:25,934 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:43:25,991 [INFO    ] __main__: train step 10710: loss: 1.0199, policy_loss: 1.0466, value_loss: 0.6938
2024-07-11 16:43:26,171 [INFO    ] __main__: train step 10711: loss: 1.0199, policy_loss: 1.0466, value_loss: 0.6937
2024-07-11 16:43:26,381 [INFO    ] __main__: train step 10712: loss: 1.0199, policy_loss: 1.0465, value_loss: 0.6937
2024-07-11 16:43:26,595 [INFO    ] __main__: train step 10713: loss: 1.0199, policy_loss: 1.0465, value_loss: 0.6937
2024-07-11 16:43:26,799 [INFO    ] __main__: train step 10714: loss: 1.0198, policy_loss: 1.0464, value_loss: 0.6936
2024-07-11 16:43:27,008 [INFO    ] __main__: train step 10715: loss: 1.0198, policy_loss: 1.0464, value_loss: 0.6936
2024-07-11 16:43:27,225 [INFO    ] __main__: train step 10716: loss: 1.0198, policy_loss: 1.0463, value_loss: 0.6936
2024-07-11 16:43:27,435 [INFO    ] __main__: train step 10717: loss: 1.0198, policy_loss: 1.0463, value_loss: 0.6935
2024-07-11 16:43:27,642 [INFO    ] __main__: train step 10718: loss: 1.0198, policy_loss: 1.0462, value_loss: 0.6935
2024-07-11 16:43:27,852 [INFO    ] __main__: train step 10719: loss: 1.0198, policy_loss: 1.0462, value_loss: 0.6935
2024-07-11 16:43:28,054 [INFO    ] __main__: train step 10720: loss: 1.0198, policy_loss: 1.0461, value_loss: 0.6934
2024-07-11 16:43:28,262 [INFO    ] __main__: train step 10721: loss: 1.0197, policy_loss: 1.0461, value_loss: 0.6934
2024-07-11 16:43:28,466 [INFO    ] __main__: train step 10722: loss: 1.0197, policy_loss: 1.0460, value_loss: 0.6934
2024-07-11 16:43:28,684 [INFO    ] __main__: train step 10723: loss: 1.0197, policy_loss: 1.0460, value_loss: 0.6933
2024-07-11 16:43:28,881 [INFO    ] __main__: train step 10724: loss: 1.0197, policy_loss: 1.0459, value_loss: 0.6933
2024-07-11 16:43:29,086 [INFO    ] __main__: train step 10725: loss: 1.0197, policy_loss: 1.0459, value_loss: 0.6933
2024-07-11 16:43:29,297 [INFO    ] __main__: train step 10726: loss: 1.0196, policy_loss: 1.0458, value_loss: 0.6932
2024-07-11 16:43:30,729 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:43:31,131 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:43:31,187 [INFO    ] __main__: train step 10727: loss: 1.0196, policy_loss: 1.0458, value_loss: 0.6932
2024-07-11 16:43:31,359 [INFO    ] __main__: train step 10728: loss: 1.0196, policy_loss: 1.0457, value_loss: 0.6932
2024-07-11 16:43:31,563 [INFO    ] __main__: train step 10729: loss: 1.0196, policy_loss: 1.0457, value_loss: 0.6931
2024-07-11 16:43:31,761 [INFO    ] __main__: train step 10730: loss: 1.0196, policy_loss: 1.0456, value_loss: 0.6931
2024-07-11 16:43:31,959 [INFO    ] __main__: train step 10731: loss: 1.0196, policy_loss: 1.0456, value_loss: 0.6931
2024-07-11 16:43:32,169 [INFO    ] __main__: train step 10732: loss: 1.0195, policy_loss: 1.0455, value_loss: 0.6930
2024-07-11 16:43:32,391 [INFO    ] __main__: train step 10733: loss: 1.0195, policy_loss: 1.0455, value_loss: 0.6930
2024-07-11 16:43:32,623 [INFO    ] __main__: train step 10734: loss: 1.0195, policy_loss: 1.0454, value_loss: 0.6930
2024-07-11 16:43:32,821 [INFO    ] __main__: train step 10735: loss: 1.0195, policy_loss: 1.0454, value_loss: 0.6929
2024-07-11 16:43:33,027 [INFO    ] __main__: train step 10736: loss: 1.0195, policy_loss: 1.0453, value_loss: 0.6929
2024-07-11 16:43:33,227 [INFO    ] __main__: train step 10737: loss: 1.0195, policy_loss: 1.0453, value_loss: 0.6929
2024-07-11 16:43:33,426 [INFO    ] __main__: train step 10738: loss: 1.0194, policy_loss: 1.0452, value_loss: 0.6928
2024-07-11 16:43:33,631 [INFO    ] __main__: train step 10739: loss: 1.0194, policy_loss: 1.0452, value_loss: 0.6928
2024-07-11 16:43:33,835 [INFO    ] __main__: train step 10740: loss: 1.0194, policy_loss: 1.0451, value_loss: 0.6928
2024-07-11 16:43:34,039 [INFO    ] __main__: train step 10741: loss: 1.0194, policy_loss: 1.0451, value_loss: 0.6927
2024-07-11 16:43:34,231 [INFO    ] __main__: train step 10742: loss: 1.0194, policy_loss: 1.0450, value_loss: 0.6927
2024-07-11 16:43:34,436 [INFO    ] __main__: train step 10743: loss: 1.0194, policy_loss: 1.0450, value_loss: 0.6927
2024-07-11 16:43:35,877 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:43:36,248 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:43:36,306 [INFO    ] __main__: train step 10744: loss: 1.0193, policy_loss: 1.0449, value_loss: 0.6926
2024-07-11 16:43:36,477 [INFO    ] __main__: train step 10745: loss: 1.0193, policy_loss: 1.0449, value_loss: 0.6926
2024-07-11 16:43:36,683 [INFO    ] __main__: train step 10746: loss: 1.0193, policy_loss: 1.0448, value_loss: 0.6926
2024-07-11 16:43:36,880 [INFO    ] __main__: train step 10747: loss: 1.0193, policy_loss: 1.0448, value_loss: 0.6925
2024-07-11 16:43:37,084 [INFO    ] __main__: train step 10748: loss: 1.0193, policy_loss: 1.0447, value_loss: 0.6925
2024-07-11 16:43:37,277 [INFO    ] __main__: train step 10749: loss: 1.0193, policy_loss: 1.0447, value_loss: 0.6924
2024-07-11 16:43:37,476 [INFO    ] __main__: train step 10750: loss: 1.0192, policy_loss: 1.0446, value_loss: 0.6924
2024-07-11 16:43:37,677 [INFO    ] __main__: train step 10751: loss: 1.0192, policy_loss: 1.0446, value_loss: 0.6924
2024-07-11 16:43:37,885 [INFO    ] __main__: train step 10752: loss: 1.0192, policy_loss: 1.0445, value_loss: 0.6923
2024-07-11 16:43:38,109 [INFO    ] __main__: train step 10753: loss: 1.0192, policy_loss: 1.0445, value_loss: 0.6923
2024-07-11 16:43:38,299 [INFO    ] __main__: train step 10754: loss: 1.0192, policy_loss: 1.0444, value_loss: 0.6923
2024-07-11 16:43:38,520 [INFO    ] __main__: train step 10755: loss: 1.0192, policy_loss: 1.0444, value_loss: 0.6922
2024-07-11 16:43:38,754 [INFO    ] __main__: train step 10756: loss: 1.0191, policy_loss: 1.0443, value_loss: 0.6922
2024-07-11 16:43:38,967 [INFO    ] __main__: train step 10757: loss: 1.0191, policy_loss: 1.0443, value_loss: 0.6922
2024-07-11 16:43:39,168 [INFO    ] __main__: train step 10758: loss: 1.0191, policy_loss: 1.0442, value_loss: 0.6921
2024-07-11 16:43:39,375 [INFO    ] __main__: train step 10759: loss: 1.0191, policy_loss: 1.0442, value_loss: 0.6921
2024-07-11 16:43:39,570 [INFO    ] __main__: train step 10760: loss: 1.0191, policy_loss: 1.0441, value_loss: 0.6921
2024-07-11 16:43:41,025 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:43:41,420 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:43:41,475 [INFO    ] __main__: train step 10761: loss: 1.0190, policy_loss: 1.0441, value_loss: 0.6920
2024-07-11 16:43:41,649 [INFO    ] __main__: train step 10762: loss: 1.0190, policy_loss: 1.0440, value_loss: 0.6920
2024-07-11 16:43:41,860 [INFO    ] __main__: train step 10763: loss: 1.0190, policy_loss: 1.0440, value_loss: 0.6920
2024-07-11 16:43:42,064 [INFO    ] __main__: train step 10764: loss: 1.0190, policy_loss: 1.0439, value_loss: 0.6919
2024-07-11 16:43:42,268 [INFO    ] __main__: train step 10765: loss: 1.0190, policy_loss: 1.0439, value_loss: 0.6919
2024-07-11 16:43:42,464 [INFO    ] __main__: train step 10766: loss: 1.0190, policy_loss: 1.0438, value_loss: 0.6919
2024-07-11 16:43:42,661 [INFO    ] __main__: train step 10767: loss: 1.0189, policy_loss: 1.0438, value_loss: 0.6918
2024-07-11 16:43:42,882 [INFO    ] __main__: train step 10768: loss: 1.0189, policy_loss: 1.0437, value_loss: 0.6918
2024-07-11 16:43:43,075 [INFO    ] __main__: train step 10769: loss: 1.0189, policy_loss: 1.0437, value_loss: 0.6918
2024-07-11 16:43:43,269 [INFO    ] __main__: train step 10770: loss: 1.0189, policy_loss: 1.0436, value_loss: 0.6917
2024-07-11 16:43:43,475 [INFO    ] __main__: train step 10771: loss: 1.0189, policy_loss: 1.0436, value_loss: 0.6917
2024-07-11 16:43:43,672 [INFO    ] __main__: train step 10772: loss: 1.0189, policy_loss: 1.0435, value_loss: 0.6917
2024-07-11 16:43:43,884 [INFO    ] __main__: train step 10773: loss: 1.0188, policy_loss: 1.0435, value_loss: 0.6916
2024-07-11 16:43:44,082 [INFO    ] __main__: train step 10774: loss: 1.0188, policy_loss: 1.0434, value_loss: 0.6916
2024-07-11 16:43:44,290 [INFO    ] __main__: train step 10775: loss: 1.0188, policy_loss: 1.0434, value_loss: 0.6915
2024-07-11 16:43:44,492 [INFO    ] __main__: train step 10776: loss: 1.0188, policy_loss: 1.0434, value_loss: 0.6915
2024-07-11 16:43:44,701 [INFO    ] __main__: train step 10777: loss: 1.0188, policy_loss: 1.0433, value_loss: 0.6915
2024-07-11 16:43:46,132 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:43:46,532 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:43:46,587 [INFO    ] __main__: train step 10778: loss: 1.0188, policy_loss: 1.0433, value_loss: 0.6914
2024-07-11 16:43:46,763 [INFO    ] __main__: train step 10779: loss: 1.0187, policy_loss: 1.0432, value_loss: 0.6914
2024-07-11 16:43:46,992 [INFO    ] __main__: train step 10780: loss: 1.0187, policy_loss: 1.0432, value_loss: 0.6914
2024-07-11 16:43:47,197 [INFO    ] __main__: train step 10781: loss: 1.0187, policy_loss: 1.0431, value_loss: 0.6913
2024-07-11 16:43:47,416 [INFO    ] __main__: train step 10782: loss: 1.0187, policy_loss: 1.0431, value_loss: 0.6913
2024-07-11 16:43:47,657 [INFO    ] __main__: train step 10783: loss: 1.0187, policy_loss: 1.0430, value_loss: 0.6913
2024-07-11 16:43:47,875 [INFO    ] __main__: train step 10784: loss: 1.0187, policy_loss: 1.0430, value_loss: 0.6912
2024-07-11 16:43:48,083 [INFO    ] __main__: train step 10785: loss: 1.0186, policy_loss: 1.0429, value_loss: 0.6912
2024-07-11 16:43:48,289 [INFO    ] __main__: train step 10786: loss: 1.0186, policy_loss: 1.0429, value_loss: 0.6912
2024-07-11 16:43:48,495 [INFO    ] __main__: train step 10787: loss: 1.0186, policy_loss: 1.0428, value_loss: 0.6911
2024-07-11 16:43:48,704 [INFO    ] __main__: train step 10788: loss: 1.0186, policy_loss: 1.0428, value_loss: 0.6911
2024-07-11 16:43:48,901 [INFO    ] __main__: train step 10789: loss: 1.0186, policy_loss: 1.0427, value_loss: 0.6911
2024-07-11 16:43:49,110 [INFO    ] __main__: train step 10790: loss: 1.0186, policy_loss: 1.0427, value_loss: 0.6910
2024-07-11 16:43:49,313 [INFO    ] __main__: train step 10791: loss: 1.0185, policy_loss: 1.0426, value_loss: 0.6910
2024-07-11 16:43:49,519 [INFO    ] __main__: train step 10792: loss: 1.0185, policy_loss: 1.0426, value_loss: 0.6910
2024-07-11 16:43:49,713 [INFO    ] __main__: train step 10793: loss: 1.0185, policy_loss: 1.0425, value_loss: 0.6909
2024-07-11 16:43:49,915 [INFO    ] __main__: train step 10794: loss: 1.0185, policy_loss: 1.0425, value_loss: 0.6909
2024-07-11 16:43:51,355 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:43:51,757 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:43:51,814 [INFO    ] __main__: train step 10795: loss: 1.0185, policy_loss: 1.0424, value_loss: 0.6909
2024-07-11 16:43:51,983 [INFO    ] __main__: train step 10796: loss: 1.0185, policy_loss: 1.0424, value_loss: 0.6908
2024-07-11 16:43:52,178 [INFO    ] __main__: train step 10797: loss: 1.0184, policy_loss: 1.0423, value_loss: 0.6908
2024-07-11 16:43:53,779 [INFO    ] __main__: train step 10798: loss: 1.0184, policy_loss: 1.0423, value_loss: 0.6908
2024-07-11 16:43:53,982 [INFO    ] __main__: train step 10799: loss: 1.0184, policy_loss: 1.0422, value_loss: 0.6907
2024-07-11 16:43:54,181 [INFO    ] __main__: train step 10800: loss: 1.0184, policy_loss: 1.0422, value_loss: 0.6907
2024-07-11 16:43:54,383 [INFO    ] __main__: train step 10801: loss: 1.0184, policy_loss: 1.0421, value_loss: 0.6907
2024-07-11 16:43:54,583 [INFO    ] __main__: train step 10802: loss: 1.0184, policy_loss: 1.0421, value_loss: 0.6906
2024-07-11 16:43:54,800 [INFO    ] __main__: train step 10803: loss: 1.0183, policy_loss: 1.0420, value_loss: 0.6906
2024-07-11 16:43:55,005 [INFO    ] __main__: train step 10804: loss: 1.0183, policy_loss: 1.0420, value_loss: 0.6906
2024-07-11 16:43:55,205 [INFO    ] __main__: train step 10805: loss: 1.0183, policy_loss: 1.0419, value_loss: 0.6905
2024-07-11 16:43:55,395 [INFO    ] __main__: train step 10806: loss: 1.0183, policy_loss: 1.0419, value_loss: 0.6905
2024-07-11 16:43:55,617 [INFO    ] __main__: train step 10807: loss: 1.0183, policy_loss: 1.0418, value_loss: 0.6905
2024-07-11 16:43:55,820 [INFO    ] __main__: train step 10808: loss: 1.0183, policy_loss: 1.0418, value_loss: 0.6904
2024-07-11 16:43:56,032 [INFO    ] __main__: train step 10809: loss: 1.0183, policy_loss: 1.0417, value_loss: 0.6904
2024-07-11 16:43:56,238 [INFO    ] __main__: train step 10810: loss: 1.0182, policy_loss: 1.0417, value_loss: 0.6904
2024-07-11 16:43:56,450 [INFO    ] __main__: train step 10811: loss: 1.0182, policy_loss: 1.0416, value_loss: 0.6903
2024-07-11 16:43:57,903 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:43:58,279 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:43:58,335 [INFO    ] __main__: train step 10812: loss: 1.0182, policy_loss: 1.0416, value_loss: 0.6903
2024-07-11 16:43:58,513 [INFO    ] __main__: train step 10813: loss: 1.0182, policy_loss: 1.0415, value_loss: 0.6903
2024-07-11 16:43:58,703 [INFO    ] __main__: train step 10814: loss: 1.0182, policy_loss: 1.0415, value_loss: 0.6902
2024-07-11 16:43:58,901 [INFO    ] __main__: train step 10815: loss: 1.0182, policy_loss: 1.0414, value_loss: 0.6902
2024-07-11 16:43:59,122 [INFO    ] __main__: train step 10816: loss: 1.0181, policy_loss: 1.0414, value_loss: 0.6902
2024-07-11 16:43:59,332 [INFO    ] __main__: train step 10817: loss: 1.0181, policy_loss: 1.0414, value_loss: 0.6901
2024-07-11 16:43:59,533 [INFO    ] __main__: train step 10818: loss: 1.0181, policy_loss: 1.0413, value_loss: 0.6901
2024-07-11 16:43:59,748 [INFO    ] __main__: train step 10819: loss: 1.0181, policy_loss: 1.0413, value_loss: 0.6901
2024-07-11 16:43:59,999 [INFO    ] __main__: train step 10820: loss: 1.0181, policy_loss: 1.0412, value_loss: 0.6900
2024-07-11 16:44:00,197 [INFO    ] __main__: train step 10821: loss: 1.0181, policy_loss: 1.0412, value_loss: 0.6900
2024-07-11 16:44:00,404 [INFO    ] __main__: train step 10822: loss: 1.0180, policy_loss: 1.0411, value_loss: 0.6900
2024-07-11 16:44:00,617 [INFO    ] __main__: train step 10823: loss: 1.0180, policy_loss: 1.0411, value_loss: 0.6899
2024-07-11 16:44:00,851 [INFO    ] __main__: train step 10824: loss: 1.0180, policy_loss: 1.0410, value_loss: 0.6899
2024-07-11 16:44:01,047 [INFO    ] __main__: train step 10825: loss: 1.0180, policy_loss: 1.0410, value_loss: 0.6899
2024-07-11 16:44:01,243 [INFO    ] __main__: train step 10826: loss: 1.0180, policy_loss: 1.0409, value_loss: 0.6898
2024-07-11 16:44:01,450 [INFO    ] __main__: train step 10827: loss: 1.0180, policy_loss: 1.0409, value_loss: 0.6898
2024-07-11 16:44:01,655 [INFO    ] __main__: train step 10828: loss: 1.0179, policy_loss: 1.0408, value_loss: 0.6897
2024-07-11 16:44:03,090 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:44:03,485 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:44:03,546 [INFO    ] __main__: train step 10829: loss: 1.0179, policy_loss: 1.0408, value_loss: 0.6897
2024-07-11 16:44:03,724 [INFO    ] __main__: train step 10830: loss: 1.0179, policy_loss: 1.0407, value_loss: 0.6897
2024-07-11 16:44:03,921 [INFO    ] __main__: train step 10831: loss: 1.0179, policy_loss: 1.0407, value_loss: 0.6896
2024-07-11 16:44:04,120 [INFO    ] __main__: train step 10832: loss: 1.0179, policy_loss: 1.0406, value_loss: 0.6896
2024-07-11 16:44:04,330 [INFO    ] __main__: train step 10833: loss: 1.0179, policy_loss: 1.0406, value_loss: 0.6896
2024-07-11 16:44:04,533 [INFO    ] __main__: train step 10834: loss: 1.0178, policy_loss: 1.0405, value_loss: 0.6895
2024-07-11 16:44:04,733 [INFO    ] __main__: train step 10835: loss: 1.0178, policy_loss: 1.0405, value_loss: 0.6895
2024-07-11 16:44:04,928 [INFO    ] __main__: train step 10836: loss: 1.0178, policy_loss: 1.0404, value_loss: 0.6895
2024-07-11 16:44:05,139 [INFO    ] __main__: train step 10837: loss: 1.0178, policy_loss: 1.0404, value_loss: 0.6894
2024-07-11 16:44:05,348 [INFO    ] __main__: train step 10838: loss: 1.0178, policy_loss: 1.0403, value_loss: 0.6894
2024-07-11 16:44:05,550 [INFO    ] __main__: train step 10839: loss: 1.0178, policy_loss: 1.0403, value_loss: 0.6894
2024-07-11 16:44:05,770 [INFO    ] __main__: train step 10840: loss: 1.0177, policy_loss: 1.0402, value_loss: 0.6893
2024-07-11 16:44:05,971 [INFO    ] __main__: train step 10841: loss: 1.0177, policy_loss: 1.0402, value_loss: 0.6893
2024-07-11 16:44:06,178 [INFO    ] __main__: train step 10842: loss: 1.0177, policy_loss: 1.0402, value_loss: 0.6893
2024-07-11 16:44:06,376 [INFO    ] __main__: train step 10843: loss: 1.0177, policy_loss: 1.0401, value_loss: 0.6892
2024-07-11 16:44:06,569 [INFO    ] __main__: train step 10844: loss: 1.0177, policy_loss: 1.0401, value_loss: 0.6892
2024-07-11 16:44:06,782 [INFO    ] __main__: train step 10845: loss: 1.0177, policy_loss: 1.0400, value_loss: 0.6892
2024-07-11 16:44:08,224 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:44:08,631 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:44:08,690 [INFO    ] __main__: train step 10846: loss: 1.0176, policy_loss: 1.0400, value_loss: 0.6891
2024-07-11 16:44:08,872 [INFO    ] __main__: train step 10847: loss: 1.0176, policy_loss: 1.0399, value_loss: 0.6891
2024-07-11 16:44:09,071 [INFO    ] __main__: train step 10848: loss: 1.0176, policy_loss: 1.0399, value_loss: 0.6891
2024-07-11 16:44:09,286 [INFO    ] __main__: train step 10849: loss: 1.0176, policy_loss: 1.0398, value_loss: 0.6890
2024-07-11 16:44:09,487 [INFO    ] __main__: train step 10850: loss: 1.0176, policy_loss: 1.0398, value_loss: 0.6890
2024-07-11 16:44:09,702 [INFO    ] __main__: train step 10851: loss: 1.0176, policy_loss: 1.0397, value_loss: 0.6890
2024-07-11 16:44:09,938 [INFO    ] __main__: train step 10852: loss: 1.0176, policy_loss: 1.0397, value_loss: 0.6889
2024-07-11 16:44:10,144 [INFO    ] __main__: train step 10853: loss: 1.0175, policy_loss: 1.0396, value_loss: 0.6889
2024-07-11 16:44:10,349 [INFO    ] __main__: train step 10854: loss: 1.0175, policy_loss: 1.0396, value_loss: 0.6889
2024-07-11 16:44:10,555 [INFO    ] __main__: train step 10855: loss: 1.0175, policy_loss: 1.0395, value_loss: 0.6888
2024-07-11 16:44:10,763 [INFO    ] __main__: train step 10856: loss: 1.0175, policy_loss: 1.0395, value_loss: 0.6888
2024-07-11 16:44:10,961 [INFO    ] __main__: train step 10857: loss: 1.0175, policy_loss: 1.0394, value_loss: 0.6888
2024-07-11 16:44:11,170 [INFO    ] __main__: train step 10858: loss: 1.0175, policy_loss: 1.0394, value_loss: 0.6887
2024-07-11 16:44:11,399 [INFO    ] __main__: train step 10859: loss: 1.0174, policy_loss: 1.0393, value_loss: 0.6887
2024-07-11 16:44:11,616 [INFO    ] __main__: train step 10860: loss: 1.0174, policy_loss: 1.0393, value_loss: 0.6887
2024-07-11 16:44:11,848 [INFO    ] __main__: train step 10861: loss: 1.0174, policy_loss: 1.0392, value_loss: 0.6886
2024-07-11 16:44:12,054 [INFO    ] __main__: train step 10862: loss: 1.0174, policy_loss: 1.0392, value_loss: 0.6886
2024-07-11 16:44:13,490 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:44:13,848 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:44:13,905 [INFO    ] __main__: train step 10863: loss: 1.0174, policy_loss: 1.0391, value_loss: 0.6886
2024-07-11 16:44:14,088 [INFO    ] __main__: train step 10864: loss: 1.0174, policy_loss: 1.0391, value_loss: 0.6885
2024-07-11 16:44:14,317 [INFO    ] __main__: train step 10865: loss: 1.0173, policy_loss: 1.0391, value_loss: 0.6885
2024-07-11 16:44:14,513 [INFO    ] __main__: train step 10866: loss: 1.0173, policy_loss: 1.0390, value_loss: 0.6885
2024-07-11 16:44:14,715 [INFO    ] __main__: train step 10867: loss: 1.0173, policy_loss: 1.0390, value_loss: 0.6884
2024-07-11 16:44:14,917 [INFO    ] __main__: train step 10868: loss: 1.0173, policy_loss: 1.0389, value_loss: 0.6884
2024-07-11 16:44:15,122 [INFO    ] __main__: train step 10869: loss: 1.0173, policy_loss: 1.0389, value_loss: 0.6884
2024-07-11 16:44:15,330 [INFO    ] __main__: train step 10870: loss: 1.0173, policy_loss: 1.0388, value_loss: 0.6883
2024-07-11 16:44:15,531 [INFO    ] __main__: train step 10871: loss: 1.0172, policy_loss: 1.0388, value_loss: 0.6883
2024-07-11 16:44:15,738 [INFO    ] __main__: train step 10872: loss: 1.0172, policy_loss: 1.0387, value_loss: 0.6883
2024-07-11 16:44:15,937 [INFO    ] __main__: train step 10873: loss: 1.0172, policy_loss: 1.0387, value_loss: 0.6882
2024-07-11 16:44:16,163 [INFO    ] __main__: train step 10874: loss: 1.0172, policy_loss: 1.0386, value_loss: 0.6882
2024-07-11 16:44:16,363 [INFO    ] __main__: train step 10875: loss: 1.0172, policy_loss: 1.0386, value_loss: 0.6882
2024-07-11 16:44:16,568 [INFO    ] __main__: train step 10876: loss: 1.0172, policy_loss: 1.0385, value_loss: 0.6881
2024-07-11 16:44:16,779 [INFO    ] __main__: train step 10877: loss: 1.0171, policy_loss: 1.0385, value_loss: 0.6881
2024-07-11 16:44:16,977 [INFO    ] __main__: train step 10878: loss: 1.0171, policy_loss: 1.0384, value_loss: 0.6881
2024-07-11 16:44:17,179 [INFO    ] __main__: train step 10879: loss: 1.0171, policy_loss: 1.0384, value_loss: 0.6880
2024-07-11 16:44:18,632 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:44:18,980 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:44:19,036 [INFO    ] __main__: train step 10880: loss: 1.0171, policy_loss: 1.0383, value_loss: 0.6880
2024-07-11 16:44:19,207 [INFO    ] __main__: train step 10881: loss: 1.0171, policy_loss: 1.0383, value_loss: 0.6879
2024-07-11 16:44:19,412 [INFO    ] __main__: train step 10882: loss: 1.0171, policy_loss: 1.0383, value_loss: 0.6879
2024-07-11 16:44:19,612 [INFO    ] __main__: train step 10883: loss: 1.0171, policy_loss: 1.0382, value_loss: 0.6879
2024-07-11 16:44:19,815 [INFO    ] __main__: train step 10884: loss: 1.0170, policy_loss: 1.0382, value_loss: 0.6878
2024-07-11 16:44:20,020 [INFO    ] __main__: train step 10885: loss: 1.0170, policy_loss: 1.0381, value_loss: 0.6878
2024-07-11 16:44:20,214 [INFO    ] __main__: train step 10886: loss: 1.0170, policy_loss: 1.0381, value_loss: 0.6878
2024-07-11 16:44:20,443 [INFO    ] __main__: train step 10887: loss: 1.0170, policy_loss: 1.0380, value_loss: 0.6877
2024-07-11 16:44:20,660 [INFO    ] __main__: train step 10888: loss: 1.0170, policy_loss: 1.0380, value_loss: 0.6877
2024-07-11 16:44:20,874 [INFO    ] __main__: train step 10889: loss: 1.0170, policy_loss: 1.0379, value_loss: 0.6877
2024-07-11 16:44:21,109 [INFO    ] __main__: train step 10890: loss: 1.0169, policy_loss: 1.0379, value_loss: 0.6876
2024-07-11 16:44:21,308 [INFO    ] __main__: train step 10891: loss: 1.0169, policy_loss: 1.0378, value_loss: 0.6876
2024-07-11 16:44:21,511 [INFO    ] __main__: train step 10892: loss: 1.0169, policy_loss: 1.0378, value_loss: 0.6876
2024-07-11 16:44:21,714 [INFO    ] __main__: train step 10893: loss: 1.0169, policy_loss: 1.0377, value_loss: 0.6875
2024-07-11 16:44:21,914 [INFO    ] __main__: train step 10894: loss: 1.0169, policy_loss: 1.0377, value_loss: 0.6875
2024-07-11 16:44:22,120 [INFO    ] __main__: train step 10895: loss: 1.0169, policy_loss: 1.0376, value_loss: 0.6875
2024-07-11 16:44:22,318 [INFO    ] __main__: train step 10896: loss: 1.0168, policy_loss: 1.0376, value_loss: 0.6874
2024-07-11 16:44:23,758 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:44:24,159 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:44:24,221 [INFO    ] __main__: train step 10897: loss: 1.0168, policy_loss: 1.0375, value_loss: 0.6874
2024-07-11 16:44:24,386 [INFO    ] __main__: train step 10898: loss: 1.0168, policy_loss: 1.0375, value_loss: 0.6874
2024-07-11 16:44:24,586 [INFO    ] __main__: train step 10899: loss: 1.0168, policy_loss: 1.0375, value_loss: 0.6873
2024-07-11 16:44:26,149 [INFO    ] __main__: train step 10900: loss: 1.0168, policy_loss: 1.0374, value_loss: 0.6873
2024-07-11 16:44:26,376 [INFO    ] __main__: train step 10901: loss: 1.0168, policy_loss: 1.0374, value_loss: 0.6873
2024-07-11 16:44:26,582 [INFO    ] __main__: train step 10902: loss: 1.0167, policy_loss: 1.0373, value_loss: 0.6872
2024-07-11 16:44:26,798 [INFO    ] __main__: train step 10903: loss: 1.0167, policy_loss: 1.0373, value_loss: 0.6872
2024-07-11 16:44:26,991 [INFO    ] __main__: train step 10904: loss: 1.0167, policy_loss: 1.0372, value_loss: 0.6872
2024-07-11 16:44:27,187 [INFO    ] __main__: train step 10905: loss: 1.0167, policy_loss: 1.0372, value_loss: 0.6871
2024-07-11 16:44:27,388 [INFO    ] __main__: train step 10906: loss: 1.0167, policy_loss: 1.0371, value_loss: 0.6871
2024-07-11 16:44:27,592 [INFO    ] __main__: train step 10907: loss: 1.0167, policy_loss: 1.0371, value_loss: 0.6871
2024-07-11 16:44:27,789 [INFO    ] __main__: train step 10908: loss: 1.0167, policy_loss: 1.0370, value_loss: 0.6870
2024-07-11 16:44:27,989 [INFO    ] __main__: train step 10909: loss: 1.0166, policy_loss: 1.0370, value_loss: 0.6870
2024-07-11 16:44:28,190 [INFO    ] __main__: train step 10910: loss: 1.0166, policy_loss: 1.0369, value_loss: 0.6870
2024-07-11 16:44:28,391 [INFO    ] __main__: train step 10911: loss: 1.0166, policy_loss: 1.0369, value_loss: 0.6869
2024-07-11 16:44:28,609 [INFO    ] __main__: train step 10912: loss: 1.0166, policy_loss: 1.0368, value_loss: 0.6869
2024-07-11 16:44:28,803 [INFO    ] __main__: train step 10913: loss: 1.0166, policy_loss: 1.0368, value_loss: 0.6868
2024-07-11 16:44:30,247 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:44:30,662 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:44:30,721 [INFO    ] __main__: train step 10914: loss: 1.0165, policy_loss: 1.0367, value_loss: 0.6868
2024-07-11 16:44:30,896 [INFO    ] __main__: train step 10915: loss: 1.0165, policy_loss: 1.0367, value_loss: 0.6868
2024-07-11 16:44:31,095 [INFO    ] __main__: train step 10916: loss: 1.0165, policy_loss: 1.0367, value_loss: 0.6867
2024-07-11 16:44:31,303 [INFO    ] __main__: train step 10917: loss: 1.0165, policy_loss: 1.0366, value_loss: 0.6867
2024-07-11 16:44:31,509 [INFO    ] __main__: train step 10918: loss: 1.0165, policy_loss: 1.0366, value_loss: 0.6867
2024-07-11 16:44:31,720 [INFO    ] __main__: train step 10919: loss: 1.0165, policy_loss: 1.0365, value_loss: 0.6866
2024-07-11 16:44:31,920 [INFO    ] __main__: train step 10920: loss: 1.0164, policy_loss: 1.0365, value_loss: 0.6866
2024-07-11 16:44:32,134 [INFO    ] __main__: train step 10921: loss: 1.0164, policy_loss: 1.0364, value_loss: 0.6866
2024-07-11 16:44:32,347 [INFO    ] __main__: train step 10922: loss: 1.0164, policy_loss: 1.0364, value_loss: 0.6865
2024-07-11 16:44:32,559 [INFO    ] __main__: train step 10923: loss: 1.0164, policy_loss: 1.0363, value_loss: 0.6865
2024-07-11 16:44:32,773 [INFO    ] __main__: train step 10924: loss: 1.0164, policy_loss: 1.0363, value_loss: 0.6865
2024-07-11 16:44:32,989 [INFO    ] __main__: train step 10925: loss: 1.0164, policy_loss: 1.0362, value_loss: 0.6864
2024-07-11 16:44:33,185 [INFO    ] __main__: train step 10926: loss: 1.0163, policy_loss: 1.0362, value_loss: 0.6864
2024-07-11 16:44:33,395 [INFO    ] __main__: train step 10927: loss: 1.0163, policy_loss: 1.0361, value_loss: 0.6864
2024-07-11 16:44:33,594 [INFO    ] __main__: train step 10928: loss: 1.0163, policy_loss: 1.0361, value_loss: 0.6863
2024-07-11 16:44:33,791 [INFO    ] __main__: train step 10929: loss: 1.0163, policy_loss: 1.0361, value_loss: 0.6863
2024-07-11 16:44:34,009 [INFO    ] __main__: train step 10930: loss: 1.0163, policy_loss: 1.0360, value_loss: 0.6863
2024-07-11 16:44:35,454 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:44:35,842 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:44:35,901 [INFO    ] __main__: train step 10931: loss: 1.0163, policy_loss: 1.0360, value_loss: 0.6862
2024-07-11 16:44:36,075 [INFO    ] __main__: train step 10932: loss: 1.0162, policy_loss: 1.0359, value_loss: 0.6862
2024-07-11 16:44:36,268 [INFO    ] __main__: train step 10933: loss: 1.0162, policy_loss: 1.0359, value_loss: 0.6862
2024-07-11 16:44:36,465 [INFO    ] __main__: train step 10934: loss: 1.0162, policy_loss: 1.0358, value_loss: 0.6861
2024-07-11 16:44:36,672 [INFO    ] __main__: train step 10935: loss: 1.0162, policy_loss: 1.0358, value_loss: 0.6861
2024-07-11 16:44:36,872 [INFO    ] __main__: train step 10936: loss: 1.0162, policy_loss: 1.0357, value_loss: 0.6861
2024-07-11 16:44:37,068 [INFO    ] __main__: train step 10937: loss: 1.0162, policy_loss: 1.0357, value_loss: 0.6860
2024-07-11 16:44:37,277 [INFO    ] __main__: train step 10938: loss: 1.0162, policy_loss: 1.0356, value_loss: 0.6860
2024-07-11 16:44:37,472 [INFO    ] __main__: train step 10939: loss: 1.0161, policy_loss: 1.0356, value_loss: 0.6860
2024-07-11 16:44:37,685 [INFO    ] __main__: train step 10940: loss: 1.0161, policy_loss: 1.0355, value_loss: 0.6859
2024-07-11 16:44:37,891 [INFO    ] __main__: train step 10941: loss: 1.0161, policy_loss: 1.0355, value_loss: 0.6859
2024-07-11 16:44:38,104 [INFO    ] __main__: train step 10942: loss: 1.0161, policy_loss: 1.0355, value_loss: 0.6859
2024-07-11 16:44:38,330 [INFO    ] __main__: train step 10943: loss: 1.0161, policy_loss: 1.0354, value_loss: 0.6858
2024-07-11 16:44:38,550 [INFO    ] __main__: train step 10944: loss: 1.0161, policy_loss: 1.0354, value_loss: 0.6858
2024-07-11 16:44:38,807 [INFO    ] __main__: train step 10945: loss: 1.0161, policy_loss: 1.0353, value_loss: 0.6858
2024-07-11 16:44:39,042 [INFO    ] __main__: train step 10946: loss: 1.0160, policy_loss: 1.0353, value_loss: 0.6857
2024-07-11 16:44:39,256 [INFO    ] __main__: train step 10947: loss: 1.0160, policy_loss: 1.0352, value_loss: 0.6857
2024-07-11 16:44:40,687 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:44:41,055 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:44:41,115 [INFO    ] __main__: train step 10948: loss: 1.0160, policy_loss: 1.0352, value_loss: 0.6857
2024-07-11 16:44:41,305 [INFO    ] __main__: train step 10949: loss: 1.0160, policy_loss: 1.0351, value_loss: 0.6856
2024-07-11 16:44:41,547 [INFO    ] __main__: train step 10950: loss: 1.0160, policy_loss: 1.0351, value_loss: 0.6856
2024-07-11 16:44:41,755 [INFO    ] __main__: train step 10951: loss: 1.0160, policy_loss: 1.0350, value_loss: 0.6856
2024-07-11 16:44:41,955 [INFO    ] __main__: train step 10952: loss: 1.0159, policy_loss: 1.0350, value_loss: 0.6855
2024-07-11 16:44:42,164 [INFO    ] __main__: train step 10953: loss: 1.0159, policy_loss: 1.0350, value_loss: 0.6855
2024-07-11 16:44:42,374 [INFO    ] __main__: train step 10954: loss: 1.0159, policy_loss: 1.0349, value_loss: 0.6855
2024-07-11 16:44:42,578 [INFO    ] __main__: train step 10955: loss: 1.0159, policy_loss: 1.0349, value_loss: 0.6854
2024-07-11 16:44:42,784 [INFO    ] __main__: train step 10956: loss: 1.0159, policy_loss: 1.0348, value_loss: 0.6854
2024-07-11 16:44:42,990 [INFO    ] __main__: train step 10957: loss: 1.0159, policy_loss: 1.0348, value_loss: 0.6854
2024-07-11 16:44:43,191 [INFO    ] __main__: train step 10958: loss: 1.0159, policy_loss: 1.0347, value_loss: 0.6853
2024-07-11 16:44:43,397 [INFO    ] __main__: train step 10959: loss: 1.0158, policy_loss: 1.0347, value_loss: 0.6853
2024-07-11 16:44:43,598 [INFO    ] __main__: train step 10960: loss: 1.0158, policy_loss: 1.0346, value_loss: 0.6852
2024-07-11 16:44:43,801 [INFO    ] __main__: train step 10961: loss: 1.0158, policy_loss: 1.0346, value_loss: 0.6852
2024-07-11 16:44:44,005 [INFO    ] __main__: train step 10962: loss: 1.0158, policy_loss: 1.0345, value_loss: 0.6852
2024-07-11 16:44:44,218 [INFO    ] __main__: train step 10963: loss: 1.0158, policy_loss: 1.0345, value_loss: 0.6851
2024-07-11 16:44:44,449 [INFO    ] __main__: train step 10964: loss: 1.0158, policy_loss: 1.0345, value_loss: 0.6851
2024-07-11 16:44:45,912 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:44:46,348 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:44:46,410 [INFO    ] __main__: train step 10965: loss: 1.0158, policy_loss: 1.0344, value_loss: 0.6851
2024-07-11 16:44:46,583 [INFO    ] __main__: train step 10966: loss: 1.0157, policy_loss: 1.0344, value_loss: 0.6850
2024-07-11 16:44:46,777 [INFO    ] __main__: train step 10967: loss: 1.0157, policy_loss: 1.0343, value_loss: 0.6850
2024-07-11 16:44:46,976 [INFO    ] __main__: train step 10968: loss: 1.0157, policy_loss: 1.0343, value_loss: 0.6850
2024-07-11 16:44:47,196 [INFO    ] __main__: train step 10969: loss: 1.0157, policy_loss: 1.0342, value_loss: 0.6849
2024-07-11 16:44:47,408 [INFO    ] __main__: train step 10970: loss: 1.0157, policy_loss: 1.0342, value_loss: 0.6849
2024-07-11 16:44:47,622 [INFO    ] __main__: train step 10971: loss: 1.0157, policy_loss: 1.0341, value_loss: 0.6849
2024-07-11 16:44:47,834 [INFO    ] __main__: train step 10972: loss: 1.0157, policy_loss: 1.0341, value_loss: 0.6848
2024-07-11 16:44:48,031 [INFO    ] __main__: train step 10973: loss: 1.0156, policy_loss: 1.0340, value_loss: 0.6848
2024-07-11 16:44:48,233 [INFO    ] __main__: train step 10974: loss: 1.0156, policy_loss: 1.0340, value_loss: 0.6848
2024-07-11 16:44:48,440 [INFO    ] __main__: train step 10975: loss: 1.0156, policy_loss: 1.0340, value_loss: 0.6847
2024-07-11 16:44:48,654 [INFO    ] __main__: train step 10976: loss: 1.0156, policy_loss: 1.0339, value_loss: 0.6847
2024-07-11 16:44:48,853 [INFO    ] __main__: train step 10977: loss: 1.0156, policy_loss: 1.0339, value_loss: 0.6847
2024-07-11 16:44:49,062 [INFO    ] __main__: train step 10978: loss: 1.0156, policy_loss: 1.0338, value_loss: 0.6846
2024-07-11 16:44:49,270 [INFO    ] __main__: train step 10979: loss: 1.0155, policy_loss: 1.0338, value_loss: 0.6846
2024-07-11 16:44:49,472 [INFO    ] __main__: train step 10980: loss: 1.0155, policy_loss: 1.0337, value_loss: 0.6846
2024-07-11 16:44:49,672 [INFO    ] __main__: train step 10981: loss: 1.0155, policy_loss: 1.0337, value_loss: 0.6845
2024-07-11 16:44:51,115 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:44:51,508 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:44:51,564 [INFO    ] __main__: train step 10982: loss: 1.0155, policy_loss: 1.0336, value_loss: 0.6845
2024-07-11 16:44:51,736 [INFO    ] __main__: train step 10983: loss: 1.0155, policy_loss: 1.0336, value_loss: 0.6845
2024-07-11 16:44:51,941 [INFO    ] __main__: train step 10984: loss: 1.0155, policy_loss: 1.0336, value_loss: 0.6844
2024-07-11 16:44:52,151 [INFO    ] __main__: train step 10985: loss: 1.0155, policy_loss: 1.0335, value_loss: 0.6844
2024-07-11 16:44:52,350 [INFO    ] __main__: train step 10986: loss: 1.0154, policy_loss: 1.0335, value_loss: 0.6844
2024-07-11 16:44:52,544 [INFO    ] __main__: train step 10987: loss: 1.0154, policy_loss: 1.0334, value_loss: 0.6843
2024-07-11 16:44:52,741 [INFO    ] __main__: train step 10988: loss: 1.0154, policy_loss: 1.0334, value_loss: 0.6843
2024-07-11 16:44:52,945 [INFO    ] __main__: train step 10989: loss: 1.0154, policy_loss: 1.0333, value_loss: 0.6843
2024-07-11 16:44:53,156 [INFO    ] __main__: train step 10990: loss: 1.0154, policy_loss: 1.0333, value_loss: 0.6842
2024-07-11 16:44:53,361 [INFO    ] __main__: train step 10991: loss: 1.0154, policy_loss: 1.0332, value_loss: 0.6842
2024-07-11 16:44:53,569 [INFO    ] __main__: train step 10992: loss: 1.0154, policy_loss: 1.0332, value_loss: 0.6842
2024-07-11 16:44:53,807 [INFO    ] __main__: train step 10993: loss: 1.0153, policy_loss: 1.0332, value_loss: 0.6841
2024-07-11 16:44:54,010 [INFO    ] __main__: train step 10994: loss: 1.0153, policy_loss: 1.0331, value_loss: 0.6841
2024-07-11 16:44:54,213 [INFO    ] __main__: train step 10995: loss: 1.0153, policy_loss: 1.0331, value_loss: 0.6841
2024-07-11 16:44:54,406 [INFO    ] __main__: train step 10996: loss: 1.0153, policy_loss: 1.0330, value_loss: 0.6840
2024-07-11 16:44:54,610 [INFO    ] __main__: train step 10997: loss: 1.0153, policy_loss: 1.0330, value_loss: 0.6840
2024-07-11 16:44:54,817 [INFO    ] __main__: train step 10998: loss: 1.0153, policy_loss: 1.0329, value_loss: 0.6840
2024-07-11 16:44:56,251 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:44:56,678 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:44:56,742 [INFO    ] __main__: train step 10999: loss: 1.0153, policy_loss: 1.0329, value_loss: 0.6839
2024-07-11 16:44:56,917 [INFO    ] __main__: train step 11000: loss: 1.0152, policy_loss: 1.0328, value_loss: 0.6839
2024-07-11 16:44:57,049 [INFO    ] __main__: restored step 10000 for evaluation
2024-07-11 16:45:04,576 [INFO    ] __main__: later network ELO difference from earlier network: +134 (+8/-8) ELO from 32000 self-played games
2024-07-11 16:45:04,576 [INFO    ] __main__: game outcomes: W: 20596, D: 813, L: 10591
2024-07-11 16:45:04,577 [INFO    ] __main__: validation_elo_delta: 134, validation_elo: 2126
2024-07-11 16:45:06,440 [INFO    ] __main__: train step 11001: loss: 1.0152, policy_loss: 1.0328, value_loss: 0.6839
2024-07-11 16:45:06,649 [INFO    ] __main__: train step 11002: loss: 1.0152, policy_loss: 1.0328, value_loss: 0.6838
2024-07-11 16:45:06,850 [INFO    ] __main__: train step 11003: loss: 1.0152, policy_loss: 1.0327, value_loss: 0.6838
2024-07-11 16:45:07,057 [INFO    ] __main__: train step 11004: loss: 1.0152, policy_loss: 1.0327, value_loss: 0.6838
2024-07-11 16:45:07,259 [INFO    ] __main__: train step 11005: loss: 1.0152, policy_loss: 1.0326, value_loss: 0.6837
2024-07-11 16:45:07,494 [INFO    ] __main__: train step 11006: loss: 1.0152, policy_loss: 1.0326, value_loss: 0.6837
2024-07-11 16:45:07,698 [INFO    ] __main__: train step 11007: loss: 1.0151, policy_loss: 1.0325, value_loss: 0.6837
2024-07-11 16:45:07,902 [INFO    ] __main__: train step 11008: loss: 1.0151, policy_loss: 1.0325, value_loss: 0.6836
2024-07-11 16:45:08,108 [INFO    ] __main__: train step 11009: loss: 1.0151, policy_loss: 1.0324, value_loss: 0.6836
2024-07-11 16:45:08,325 [INFO    ] __main__: train step 11010: loss: 1.0151, policy_loss: 1.0324, value_loss: 0.6836
2024-07-11 16:45:08,565 [INFO    ] __main__: train step 11011: loss: 1.0151, policy_loss: 1.0324, value_loss: 0.6835
2024-07-11 16:45:08,778 [INFO    ] __main__: train step 11012: loss: 1.0151, policy_loss: 1.0323, value_loss: 0.6835
2024-07-11 16:45:09,011 [INFO    ] __main__: train step 11013: loss: 1.0151, policy_loss: 1.0323, value_loss: 0.6835
2024-07-11 16:45:09,204 [INFO    ] __main__: train step 11014: loss: 1.0150, policy_loss: 1.0322, value_loss: 0.6834
2024-07-11 16:45:09,409 [INFO    ] __main__: train step 11015: loss: 1.0150, policy_loss: 1.0322, value_loss: 0.6834
2024-07-11 16:45:10,851 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:45:11,270 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:45:11,326 [INFO    ] __main__: train step 11016: loss: 1.0150, policy_loss: 1.0321, value_loss: 0.6834
2024-07-11 16:45:11,508 [INFO    ] __main__: train step 11017: loss: 1.0150, policy_loss: 1.0321, value_loss: 0.6833
2024-07-11 16:45:11,722 [INFO    ] __main__: train step 11018: loss: 1.0150, policy_loss: 1.0320, value_loss: 0.6833
2024-07-11 16:45:11,952 [INFO    ] __main__: train step 11019: loss: 1.0150, policy_loss: 1.0320, value_loss: 0.6833
2024-07-11 16:45:12,152 [INFO    ] __main__: train step 11020: loss: 1.0150, policy_loss: 1.0320, value_loss: 0.6832
2024-07-11 16:45:12,360 [INFO    ] __main__: train step 11021: loss: 1.0149, policy_loss: 1.0319, value_loss: 0.6832
2024-07-11 16:45:12,588 [INFO    ] __main__: train step 11022: loss: 1.0149, policy_loss: 1.0319, value_loss: 0.6832
2024-07-11 16:45:12,793 [INFO    ] __main__: train step 11023: loss: 1.0149, policy_loss: 1.0318, value_loss: 0.6831
2024-07-11 16:45:12,995 [INFO    ] __main__: train step 11024: loss: 1.0149, policy_loss: 1.0318, value_loss: 0.6831
2024-07-11 16:45:13,196 [INFO    ] __main__: train step 11025: loss: 1.0149, policy_loss: 1.0317, value_loss: 0.6831
2024-07-11 16:45:13,402 [INFO    ] __main__: train step 11026: loss: 1.0149, policy_loss: 1.0317, value_loss: 0.6830
2024-07-11 16:45:13,605 [INFO    ] __main__: train step 11027: loss: 1.0149, policy_loss: 1.0316, value_loss: 0.6830
2024-07-11 16:45:13,812 [INFO    ] __main__: train step 11028: loss: 1.0148, policy_loss: 1.0316, value_loss: 0.6830
2024-07-11 16:45:14,016 [INFO    ] __main__: train step 11029: loss: 1.0148, policy_loss: 1.0316, value_loss: 0.6829
2024-07-11 16:45:14,237 [INFO    ] __main__: train step 11030: loss: 1.0148, policy_loss: 1.0315, value_loss: 0.6829
2024-07-11 16:45:14,476 [INFO    ] __main__: train step 11031: loss: 1.0148, policy_loss: 1.0315, value_loss: 0.6829
2024-07-11 16:45:14,679 [INFO    ] __main__: train step 11032: loss: 1.0148, policy_loss: 1.0314, value_loss: 0.6828
2024-07-11 16:45:16,121 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:45:16,500 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:45:16,557 [INFO    ] __main__: train step 11033: loss: 1.0148, policy_loss: 1.0314, value_loss: 0.6828
2024-07-11 16:45:16,732 [INFO    ] __main__: train step 11034: loss: 1.0148, policy_loss: 1.0313, value_loss: 0.6828
2024-07-11 16:45:16,940 [INFO    ] __main__: train step 11035: loss: 1.0147, policy_loss: 1.0313, value_loss: 0.6827
2024-07-11 16:45:17,144 [INFO    ] __main__: train step 11036: loss: 1.0147, policy_loss: 1.0312, value_loss: 0.6827
2024-07-11 16:45:17,353 [INFO    ] __main__: train step 11037: loss: 1.0147, policy_loss: 1.0312, value_loss: 0.6827
2024-07-11 16:45:17,557 [INFO    ] __main__: train step 11038: loss: 1.0147, policy_loss: 1.0312, value_loss: 0.6826
2024-07-11 16:45:17,769 [INFO    ] __main__: train step 11039: loss: 1.0147, policy_loss: 1.0311, value_loss: 0.6826
2024-07-11 16:45:17,972 [INFO    ] __main__: train step 11040: loss: 1.0147, policy_loss: 1.0311, value_loss: 0.6826
2024-07-11 16:45:18,185 [INFO    ] __main__: train step 11041: loss: 1.0147, policy_loss: 1.0310, value_loss: 0.6825
2024-07-11 16:45:18,396 [INFO    ] __main__: train step 11042: loss: 1.0147, policy_loss: 1.0310, value_loss: 0.6825
2024-07-11 16:45:18,594 [INFO    ] __main__: train step 11043: loss: 1.0146, policy_loss: 1.0309, value_loss: 0.6825
2024-07-11 16:45:18,802 [INFO    ] __main__: train step 11044: loss: 1.0146, policy_loss: 1.0309, value_loss: 0.6824
2024-07-11 16:45:19,016 [INFO    ] __main__: train step 11045: loss: 1.0146, policy_loss: 1.0309, value_loss: 0.6824
2024-07-11 16:45:19,212 [INFO    ] __main__: train step 11046: loss: 1.0146, policy_loss: 1.0308, value_loss: 0.6824
2024-07-11 16:45:19,429 [INFO    ] __main__: train step 11047: loss: 1.0146, policy_loss: 1.0308, value_loss: 0.6823
2024-07-11 16:45:19,618 [INFO    ] __main__: train step 11048: loss: 1.0146, policy_loss: 1.0307, value_loss: 0.6823
2024-07-11 16:45:19,810 [INFO    ] __main__: train step 11049: loss: 1.0146, policy_loss: 1.0307, value_loss: 0.6823
2024-07-11 16:45:21,239 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:45:21,620 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:45:21,674 [INFO    ] __main__: train step 11050: loss: 1.0145, policy_loss: 1.0306, value_loss: 0.6822
2024-07-11 16:45:21,861 [INFO    ] __main__: train step 11051: loss: 1.0145, policy_loss: 1.0306, value_loss: 0.6822
2024-07-11 16:45:22,060 [INFO    ] __main__: train step 11052: loss: 1.0145, policy_loss: 1.0305, value_loss: 0.6822
2024-07-11 16:45:22,273 [INFO    ] __main__: train step 11053: loss: 1.0145, policy_loss: 1.0305, value_loss: 0.6821
2024-07-11 16:45:22,470 [INFO    ] __main__: train step 11054: loss: 1.0145, policy_loss: 1.0305, value_loss: 0.6821
2024-07-11 16:45:22,679 [INFO    ] __main__: train step 11055: loss: 1.0145, policy_loss: 1.0304, value_loss: 0.6821
2024-07-11 16:45:22,881 [INFO    ] __main__: train step 11056: loss: 1.0145, policy_loss: 1.0304, value_loss: 0.6820
2024-07-11 16:45:23,084 [INFO    ] __main__: train step 11057: loss: 1.0144, policy_loss: 1.0303, value_loss: 0.6820
2024-07-11 16:45:23,289 [INFO    ] __main__: train step 11058: loss: 1.0144, policy_loss: 1.0303, value_loss: 0.6820
2024-07-11 16:45:23,495 [INFO    ] __main__: train step 11059: loss: 1.0144, policy_loss: 1.0302, value_loss: 0.6819
2024-07-11 16:45:23,697 [INFO    ] __main__: train step 11060: loss: 1.0144, policy_loss: 1.0302, value_loss: 0.6819
2024-07-11 16:45:23,905 [INFO    ] __main__: train step 11061: loss: 1.0144, policy_loss: 1.0302, value_loss: 0.6819
2024-07-11 16:45:24,111 [INFO    ] __main__: train step 11062: loss: 1.0144, policy_loss: 1.0301, value_loss: 0.6818
2024-07-11 16:45:24,314 [INFO    ] __main__: train step 11063: loss: 1.0144, policy_loss: 1.0301, value_loss: 0.6818
2024-07-11 16:45:24,514 [INFO    ] __main__: train step 11064: loss: 1.0144, policy_loss: 1.0300, value_loss: 0.6818
2024-07-11 16:45:24,719 [INFO    ] __main__: train step 11065: loss: 1.0143, policy_loss: 1.0300, value_loss: 0.6817
2024-07-11 16:45:24,920 [INFO    ] __main__: train step 11066: loss: 1.0143, policy_loss: 1.0299, value_loss: 0.6817
2024-07-11 16:45:26,370 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:45:26,800 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:45:26,860 [INFO    ] __main__: train step 11067: loss: 1.0143, policy_loss: 1.0299, value_loss: 0.6817
2024-07-11 16:45:27,033 [INFO    ] __main__: train step 11068: loss: 1.0143, policy_loss: 1.0299, value_loss: 0.6816
2024-07-11 16:45:27,229 [INFO    ] __main__: train step 11069: loss: 1.0143, policy_loss: 1.0298, value_loss: 0.6816
2024-07-11 16:45:27,447 [INFO    ] __main__: train step 11070: loss: 1.0143, policy_loss: 1.0298, value_loss: 0.6816
2024-07-11 16:45:27,642 [INFO    ] __main__: train step 11071: loss: 1.0143, policy_loss: 1.0297, value_loss: 0.6815
2024-07-11 16:45:27,843 [INFO    ] __main__: train step 11072: loss: 1.0143, policy_loss: 1.0297, value_loss: 0.6815
2024-07-11 16:45:28,040 [INFO    ] __main__: train step 11073: loss: 1.0142, policy_loss: 1.0296, value_loss: 0.6815
2024-07-11 16:45:28,248 [INFO    ] __main__: train step 11074: loss: 1.0142, policy_loss: 1.0296, value_loss: 0.6814
2024-07-11 16:45:28,453 [INFO    ] __main__: train step 11075: loss: 1.0142, policy_loss: 1.0296, value_loss: 0.6814
2024-07-11 16:45:28,656 [INFO    ] __main__: train step 11076: loss: 1.0142, policy_loss: 1.0295, value_loss: 0.6814
2024-07-11 16:45:28,853 [INFO    ] __main__: train step 11077: loss: 1.0142, policy_loss: 1.0295, value_loss: 0.6813
2024-07-11 16:45:29,050 [INFO    ] __main__: train step 11078: loss: 1.0142, policy_loss: 1.0294, value_loss: 0.6813
2024-07-11 16:45:29,261 [INFO    ] __main__: train step 11079: loss: 1.0142, policy_loss: 1.0294, value_loss: 0.6813
2024-07-11 16:45:29,474 [INFO    ] __main__: train step 11080: loss: 1.0142, policy_loss: 1.0293, value_loss: 0.6812
2024-07-11 16:45:29,671 [INFO    ] __main__: train step 11081: loss: 1.0141, policy_loss: 1.0293, value_loss: 0.6812
2024-07-11 16:45:29,866 [INFO    ] __main__: train step 11082: loss: 1.0141, policy_loss: 1.0293, value_loss: 0.6812
2024-07-11 16:45:30,079 [INFO    ] __main__: train step 11083: loss: 1.0141, policy_loss: 1.0292, value_loss: 0.6811
2024-07-11 16:45:31,517 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:45:31,913 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:45:31,971 [INFO    ] __main__: train step 11084: loss: 1.0141, policy_loss: 1.0292, value_loss: 0.6811
2024-07-11 16:45:32,154 [INFO    ] __main__: train step 11085: loss: 1.0141, policy_loss: 1.0291, value_loss: 0.6811
2024-07-11 16:45:32,359 [INFO    ] __main__: train step 11086: loss: 1.0141, policy_loss: 1.0291, value_loss: 0.6810
2024-07-11 16:45:32,557 [INFO    ] __main__: train step 11087: loss: 1.0141, policy_loss: 1.0290, value_loss: 0.6810
2024-07-11 16:45:32,759 [INFO    ] __main__: train step 11088: loss: 1.0141, policy_loss: 1.0290, value_loss: 0.6810
2024-07-11 16:45:32,961 [INFO    ] __main__: train step 11089: loss: 1.0140, policy_loss: 1.0290, value_loss: 0.6809
2024-07-11 16:45:33,174 [INFO    ] __main__: train step 11090: loss: 1.0140, policy_loss: 1.0289, value_loss: 0.6809
2024-07-11 16:45:33,372 [INFO    ] __main__: train step 11091: loss: 1.0140, policy_loss: 1.0289, value_loss: 0.6809
2024-07-11 16:45:33,582 [INFO    ] __main__: train step 11092: loss: 1.0140, policy_loss: 1.0288, value_loss: 0.6808
2024-07-11 16:45:33,776 [INFO    ] __main__: train step 11093: loss: 1.0140, policy_loss: 1.0288, value_loss: 0.6808
2024-07-11 16:45:33,975 [INFO    ] __main__: train step 11094: loss: 1.0140, policy_loss: 1.0288, value_loss: 0.6808
2024-07-11 16:45:34,174 [INFO    ] __main__: train step 11095: loss: 1.0140, policy_loss: 1.0287, value_loss: 0.6807
2024-07-11 16:45:34,382 [INFO    ] __main__: train step 11096: loss: 1.0139, policy_loss: 1.0287, value_loss: 0.6807
2024-07-11 16:45:34,598 [INFO    ] __main__: train step 11097: loss: 1.0139, policy_loss: 1.0286, value_loss: 0.6807
2024-07-11 16:45:34,804 [INFO    ] __main__: train step 11098: loss: 1.0139, policy_loss: 1.0286, value_loss: 0.6806
2024-07-11 16:45:34,996 [INFO    ] __main__: train step 11099: loss: 1.0139, policy_loss: 1.0285, value_loss: 0.6806
2024-07-11 16:45:36,592 [INFO    ] __main__: train step 11100: loss: 1.0139, policy_loss: 1.0285, value_loss: 0.6806
2024-07-11 16:45:38,038 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:45:38,475 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:45:38,542 [INFO    ] __main__: train step 11101: loss: 1.0139, policy_loss: 1.0284, value_loss: 0.6805
2024-07-11 16:45:38,731 [INFO    ] __main__: train step 11102: loss: 1.0139, policy_loss: 1.0284, value_loss: 0.6805
2024-07-11 16:45:38,935 [INFO    ] __main__: train step 11103: loss: 1.0139, policy_loss: 1.0284, value_loss: 0.6805
2024-07-11 16:45:39,134 [INFO    ] __main__: train step 11104: loss: 1.0138, policy_loss: 1.0283, value_loss: 0.6804
2024-07-11 16:45:39,339 [INFO    ] __main__: train step 11105: loss: 1.0138, policy_loss: 1.0283, value_loss: 0.6804
2024-07-11 16:45:39,540 [INFO    ] __main__: train step 11106: loss: 1.0138, policy_loss: 1.0282, value_loss: 0.6804
2024-07-11 16:45:39,739 [INFO    ] __main__: train step 11107: loss: 1.0138, policy_loss: 1.0282, value_loss: 0.6803
2024-07-11 16:45:39,943 [INFO    ] __main__: train step 11108: loss: 1.0138, policy_loss: 1.0282, value_loss: 0.6803
2024-07-11 16:45:40,153 [INFO    ] __main__: train step 11109: loss: 1.0138, policy_loss: 1.0281, value_loss: 0.6803
2024-07-11 16:45:40,366 [INFO    ] __main__: train step 11110: loss: 1.0138, policy_loss: 1.0281, value_loss: 0.6802
2024-07-11 16:45:40,566 [INFO    ] __main__: train step 11111: loss: 1.0138, policy_loss: 1.0280, value_loss: 0.6802
2024-07-11 16:45:40,771 [INFO    ] __main__: train step 11112: loss: 1.0137, policy_loss: 1.0280, value_loss: 0.6802
2024-07-11 16:45:40,978 [INFO    ] __main__: train step 11113: loss: 1.0137, policy_loss: 1.0279, value_loss: 0.6801
2024-07-11 16:45:41,181 [INFO    ] __main__: train step 11114: loss: 1.0137, policy_loss: 1.0279, value_loss: 0.6801
2024-07-11 16:45:41,386 [INFO    ] __main__: train step 11115: loss: 1.0137, policy_loss: 1.0279, value_loss: 0.6801
2024-07-11 16:45:41,581 [INFO    ] __main__: train step 11116: loss: 1.0137, policy_loss: 1.0278, value_loss: 0.6800
2024-07-11 16:45:41,796 [INFO    ] __main__: train step 11117: loss: 1.0137, policy_loss: 1.0278, value_loss: 0.6800
2024-07-11 16:45:43,243 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:45:43,597 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:45:43,657 [INFO    ] __main__: train step 11118: loss: 1.0137, policy_loss: 1.0277, value_loss: 0.6800
2024-07-11 16:45:43,825 [INFO    ] __main__: train step 11119: loss: 1.0136, policy_loss: 1.0277, value_loss: 0.6799
2024-07-11 16:45:44,039 [INFO    ] __main__: train step 11120: loss: 1.0136, policy_loss: 1.0276, value_loss: 0.6799
2024-07-11 16:45:44,255 [INFO    ] __main__: train step 11121: loss: 1.0136, policy_loss: 1.0276, value_loss: 0.6799
2024-07-11 16:45:44,457 [INFO    ] __main__: train step 11122: loss: 1.0136, policy_loss: 1.0276, value_loss: 0.6798
2024-07-11 16:45:44,648 [INFO    ] __main__: train step 11123: loss: 1.0136, policy_loss: 1.0275, value_loss: 0.6798
2024-07-11 16:45:44,862 [INFO    ] __main__: train step 11124: loss: 1.0136, policy_loss: 1.0275, value_loss: 0.6798
2024-07-11 16:45:45,076 [INFO    ] __main__: train step 11125: loss: 1.0136, policy_loss: 1.0274, value_loss: 0.6798
2024-07-11 16:45:45,305 [INFO    ] __main__: train step 11126: loss: 1.0136, policy_loss: 1.0274, value_loss: 0.6797
2024-07-11 16:45:45,503 [INFO    ] __main__: train step 11127: loss: 1.0136, policy_loss: 1.0274, value_loss: 0.6797
2024-07-11 16:45:45,705 [INFO    ] __main__: train step 11128: loss: 1.0135, policy_loss: 1.0273, value_loss: 0.6797
2024-07-11 16:45:45,901 [INFO    ] __main__: train step 11129: loss: 1.0135, policy_loss: 1.0273, value_loss: 0.6796
2024-07-11 16:45:46,112 [INFO    ] __main__: train step 11130: loss: 1.0135, policy_loss: 1.0272, value_loss: 0.6796
2024-07-11 16:45:46,312 [INFO    ] __main__: train step 11131: loss: 1.0135, policy_loss: 1.0272, value_loss: 0.6796
2024-07-11 16:45:46,508 [INFO    ] __main__: train step 11132: loss: 1.0135, policy_loss: 1.0271, value_loss: 0.6795
2024-07-11 16:45:46,709 [INFO    ] __main__: train step 11133: loss: 1.0135, policy_loss: 1.0271, value_loss: 0.6795
2024-07-11 16:45:46,925 [INFO    ] __main__: train step 11134: loss: 1.0135, policy_loss: 1.0271, value_loss: 0.6795
2024-07-11 16:45:48,390 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:45:48,787 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:45:48,851 [INFO    ] __main__: train step 11135: loss: 1.0134, policy_loss: 1.0270, value_loss: 0.6794
2024-07-11 16:45:49,027 [INFO    ] __main__: train step 11136: loss: 1.0134, policy_loss: 1.0270, value_loss: 0.6794
2024-07-11 16:45:49,228 [INFO    ] __main__: train step 11137: loss: 1.0134, policy_loss: 1.0269, value_loss: 0.6794
2024-07-11 16:45:49,434 [INFO    ] __main__: train step 11138: loss: 1.0134, policy_loss: 1.0269, value_loss: 0.6793
2024-07-11 16:45:49,651 [INFO    ] __main__: train step 11139: loss: 1.0134, policy_loss: 1.0269, value_loss: 0.6793
2024-07-11 16:45:49,873 [INFO    ] __main__: train step 11140: loss: 1.0134, policy_loss: 1.0268, value_loss: 0.6793
2024-07-11 16:45:50,074 [INFO    ] __main__: train step 11141: loss: 1.0134, policy_loss: 1.0268, value_loss: 0.6792
2024-07-11 16:45:50,276 [INFO    ] __main__: train step 11142: loss: 1.0134, policy_loss: 1.0267, value_loss: 0.6792
2024-07-11 16:45:50,477 [INFO    ] __main__: train step 11143: loss: 1.0134, policy_loss: 1.0267, value_loss: 0.6792
2024-07-11 16:45:50,692 [INFO    ] __main__: train step 11144: loss: 1.0133, policy_loss: 1.0266, value_loss: 0.6791
2024-07-11 16:45:50,896 [INFO    ] __main__: train step 11145: loss: 1.0133, policy_loss: 1.0266, value_loss: 0.6791
2024-07-11 16:45:51,098 [INFO    ] __main__: train step 11146: loss: 1.0133, policy_loss: 1.0266, value_loss: 0.6791
2024-07-11 16:45:51,307 [INFO    ] __main__: train step 11147: loss: 1.0133, policy_loss: 1.0265, value_loss: 0.6790
2024-07-11 16:45:51,507 [INFO    ] __main__: train step 11148: loss: 1.0133, policy_loss: 1.0265, value_loss: 0.6790
2024-07-11 16:45:51,706 [INFO    ] __main__: train step 11149: loss: 1.0133, policy_loss: 1.0264, value_loss: 0.6790
2024-07-11 16:45:51,910 [INFO    ] __main__: train step 11150: loss: 1.0133, policy_loss: 1.0264, value_loss: 0.6789
2024-07-11 16:45:52,126 [INFO    ] __main__: train step 11151: loss: 1.0132, policy_loss: 1.0264, value_loss: 0.6789
2024-07-11 16:45:53,567 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:45:53,925 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:45:53,981 [INFO    ] __main__: train step 11152: loss: 1.0132, policy_loss: 1.0263, value_loss: 0.6789
2024-07-11 16:45:54,176 [INFO    ] __main__: train step 11153: loss: 1.0132, policy_loss: 1.0263, value_loss: 0.6788
2024-07-11 16:45:54,376 [INFO    ] __main__: train step 11154: loss: 1.0132, policy_loss: 1.0262, value_loss: 0.6788
2024-07-11 16:45:54,582 [INFO    ] __main__: train step 11155: loss: 1.0132, policy_loss: 1.0262, value_loss: 0.6788
2024-07-11 16:45:54,780 [INFO    ] __main__: train step 11156: loss: 1.0132, policy_loss: 1.0261, value_loss: 0.6787
2024-07-11 16:45:54,981 [INFO    ] __main__: train step 11157: loss: 1.0132, policy_loss: 1.0261, value_loss: 0.6787
2024-07-11 16:45:55,184 [INFO    ] __main__: train step 11158: loss: 1.0132, policy_loss: 1.0261, value_loss: 0.6787
2024-07-11 16:45:55,389 [INFO    ] __main__: train step 11159: loss: 1.0131, policy_loss: 1.0260, value_loss: 0.6786
2024-07-11 16:45:55,612 [INFO    ] __main__: train step 11160: loss: 1.0131, policy_loss: 1.0260, value_loss: 0.6786
2024-07-11 16:45:55,813 [INFO    ] __main__: train step 11161: loss: 1.0131, policy_loss: 1.0259, value_loss: 0.6786
2024-07-11 16:45:56,012 [INFO    ] __main__: train step 11162: loss: 1.0131, policy_loss: 1.0259, value_loss: 0.6785
2024-07-11 16:45:56,219 [INFO    ] __main__: train step 11163: loss: 1.0131, policy_loss: 1.0259, value_loss: 0.6785
2024-07-11 16:45:56,438 [INFO    ] __main__: train step 11164: loss: 1.0131, policy_loss: 1.0258, value_loss: 0.6785
2024-07-11 16:45:56,664 [INFO    ] __main__: train step 11165: loss: 1.0131, policy_loss: 1.0258, value_loss: 0.6784
2024-07-11 16:45:56,862 [INFO    ] __main__: train step 11166: loss: 1.0131, policy_loss: 1.0257, value_loss: 0.6784
2024-07-11 16:45:57,069 [INFO    ] __main__: train step 11167: loss: 1.0130, policy_loss: 1.0257, value_loss: 0.6784
2024-07-11 16:45:57,264 [INFO    ] __main__: train step 11168: loss: 1.0130, policy_loss: 1.0256, value_loss: 0.6783
2024-07-11 16:45:58,699 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:45:59,130 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:45:59,192 [INFO    ] __main__: train step 11169: loss: 1.0130, policy_loss: 1.0256, value_loss: 0.6783
2024-07-11 16:45:59,373 [INFO    ] __main__: train step 11170: loss: 1.0130, policy_loss: 1.0256, value_loss: 0.6783
2024-07-11 16:45:59,576 [INFO    ] __main__: train step 11171: loss: 1.0130, policy_loss: 1.0255, value_loss: 0.6782
2024-07-11 16:45:59,780 [INFO    ] __main__: train step 11172: loss: 1.0130, policy_loss: 1.0255, value_loss: 0.6782
2024-07-11 16:45:59,982 [INFO    ] __main__: train step 11173: loss: 1.0130, policy_loss: 1.0254, value_loss: 0.6782
2024-07-11 16:46:00,181 [INFO    ] __main__: train step 11174: loss: 1.0130, policy_loss: 1.0254, value_loss: 0.6781
2024-07-11 16:46:00,386 [INFO    ] __main__: train step 11175: loss: 1.0129, policy_loss: 1.0254, value_loss: 0.6781
2024-07-11 16:46:00,598 [INFO    ] __main__: train step 11176: loss: 1.0129, policy_loss: 1.0253, value_loss: 0.6781
2024-07-11 16:46:00,795 [INFO    ] __main__: train step 11177: loss: 1.0129, policy_loss: 1.0253, value_loss: 0.6780
2024-07-11 16:46:01,000 [INFO    ] __main__: train step 11178: loss: 1.0129, policy_loss: 1.0252, value_loss: 0.6780
2024-07-11 16:46:01,201 [INFO    ] __main__: train step 11179: loss: 1.0129, policy_loss: 1.0252, value_loss: 0.6780
2024-07-11 16:46:01,405 [INFO    ] __main__: train step 11180: loss: 1.0129, policy_loss: 1.0252, value_loss: 0.6779
2024-07-11 16:46:01,604 [INFO    ] __main__: train step 11181: loss: 1.0129, policy_loss: 1.0251, value_loss: 0.6779
2024-07-11 16:46:01,813 [INFO    ] __main__: train step 11182: loss: 1.0129, policy_loss: 1.0251, value_loss: 0.6779
2024-07-11 16:46:02,023 [INFO    ] __main__: train step 11183: loss: 1.0129, policy_loss: 1.0250, value_loss: 0.6778
2024-07-11 16:46:02,224 [INFO    ] __main__: train step 11184: loss: 1.0128, policy_loss: 1.0250, value_loss: 0.6778
2024-07-11 16:46:02,436 [INFO    ] __main__: train step 11185: loss: 1.0128, policy_loss: 1.0249, value_loss: 0.6778
2024-07-11 16:46:03,872 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:46:04,123 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:46:04,176 [INFO    ] __main__: train step 11186: loss: 1.0128, policy_loss: 1.0249, value_loss: 0.6777
2024-07-11 16:46:04,349 [INFO    ] __main__: train step 11187: loss: 1.0128, policy_loss: 1.0249, value_loss: 0.6777
2024-07-11 16:46:04,565 [INFO    ] __main__: train step 11188: loss: 1.0128, policy_loss: 1.0248, value_loss: 0.6777
2024-07-11 16:46:04,761 [INFO    ] __main__: train step 11189: loss: 1.0128, policy_loss: 1.0248, value_loss: 0.6776
2024-07-11 16:46:04,966 [INFO    ] __main__: train step 11190: loss: 1.0128, policy_loss: 1.0247, value_loss: 0.6776
2024-07-11 16:46:05,176 [INFO    ] __main__: train step 11191: loss: 1.0128, policy_loss: 1.0247, value_loss: 0.6776
2024-07-11 16:46:05,380 [INFO    ] __main__: train step 11192: loss: 1.0127, policy_loss: 1.0247, value_loss: 0.6776
2024-07-11 16:46:05,599 [INFO    ] __main__: train step 11193: loss: 1.0127, policy_loss: 1.0246, value_loss: 0.6775
2024-07-11 16:46:05,840 [INFO    ] __main__: train step 11194: loss: 1.0127, policy_loss: 1.0246, value_loss: 0.6775
2024-07-11 16:46:06,042 [INFO    ] __main__: train step 11195: loss: 1.0127, policy_loss: 1.0245, value_loss: 0.6775
2024-07-11 16:46:06,240 [INFO    ] __main__: train step 11196: loss: 1.0127, policy_loss: 1.0245, value_loss: 0.6774
2024-07-11 16:46:06,448 [INFO    ] __main__: train step 11197: loss: 1.0127, policy_loss: 1.0245, value_loss: 0.6774
2024-07-11 16:46:06,656 [INFO    ] __main__: train step 11198: loss: 1.0127, policy_loss: 1.0244, value_loss: 0.6774
2024-07-11 16:46:06,893 [INFO    ] __main__: train step 11199: loss: 1.0127, policy_loss: 1.0244, value_loss: 0.6773
2024-07-11 16:46:07,099 [INFO    ] __main__: train step 11200: loss: 1.0127, policy_loss: 1.0243, value_loss: 0.6773
2024-07-11 16:46:07,304 [INFO    ] __main__: train step 11201: loss: 1.0126, policy_loss: 1.0243, value_loss: 0.6773
2024-07-11 16:46:08,888 [INFO    ] __main__: train step 11202: loss: 1.0126, policy_loss: 1.0242, value_loss: 0.6772
2024-07-11 16:46:10,327 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:46:10,725 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:46:10,780 [INFO    ] __main__: train step 11203: loss: 1.0126, policy_loss: 1.0242, value_loss: 0.6772
2024-07-11 16:46:10,956 [INFO    ] __main__: train step 11204: loss: 1.0126, policy_loss: 1.0242, value_loss: 0.6772
2024-07-11 16:46:11,178 [INFO    ] __main__: train step 11205: loss: 1.0126, policy_loss: 1.0241, value_loss: 0.6771
2024-07-11 16:46:11,421 [INFO    ] __main__: train step 11206: loss: 1.0126, policy_loss: 1.0241, value_loss: 0.6771
2024-07-11 16:46:11,647 [INFO    ] __main__: train step 11207: loss: 1.0126, policy_loss: 1.0240, value_loss: 0.6771
2024-07-11 16:46:11,846 [INFO    ] __main__: train step 11208: loss: 1.0126, policy_loss: 1.0240, value_loss: 0.6770
2024-07-11 16:46:12,050 [INFO    ] __main__: train step 11209: loss: 1.0126, policy_loss: 1.0240, value_loss: 0.6770
2024-07-11 16:46:12,263 [INFO    ] __main__: train step 11210: loss: 1.0125, policy_loss: 1.0239, value_loss: 0.6770
2024-07-11 16:46:12,499 [INFO    ] __main__: train step 11211: loss: 1.0125, policy_loss: 1.0239, value_loss: 0.6769
2024-07-11 16:46:12,726 [INFO    ] __main__: train step 11212: loss: 1.0125, policy_loss: 1.0238, value_loss: 0.6769
2024-07-11 16:46:12,949 [INFO    ] __main__: train step 11213: loss: 1.0125, policy_loss: 1.0238, value_loss: 0.6769
2024-07-11 16:46:13,151 [INFO    ] __main__: train step 11214: loss: 1.0125, policy_loss: 1.0238, value_loss: 0.6768
2024-07-11 16:46:13,353 [INFO    ] __main__: train step 11215: loss: 1.0125, policy_loss: 1.0237, value_loss: 0.6768
2024-07-11 16:46:13,557 [INFO    ] __main__: train step 11216: loss: 1.0125, policy_loss: 1.0237, value_loss: 0.6768
2024-07-11 16:46:13,772 [INFO    ] __main__: train step 11217: loss: 1.0125, policy_loss: 1.0236, value_loss: 0.6768
2024-07-11 16:46:14,002 [INFO    ] __main__: train step 11218: loss: 1.0125, policy_loss: 1.0236, value_loss: 0.6767
2024-07-11 16:46:14,215 [INFO    ] __main__: train step 11219: loss: 1.0124, policy_loss: 1.0236, value_loss: 0.6767
2024-07-11 16:46:15,657 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:46:16,015 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:46:16,074 [INFO    ] __main__: train step 11220: loss: 1.0124, policy_loss: 1.0235, value_loss: 0.6767
2024-07-11 16:46:16,246 [INFO    ] __main__: train step 11221: loss: 1.0124, policy_loss: 1.0235, value_loss: 0.6766
2024-07-11 16:46:16,455 [INFO    ] __main__: train step 11222: loss: 1.0124, policy_loss: 1.0234, value_loss: 0.6766
2024-07-11 16:46:16,671 [INFO    ] __main__: train step 11223: loss: 1.0124, policy_loss: 1.0234, value_loss: 0.6766
2024-07-11 16:46:16,868 [INFO    ] __main__: train step 11224: loss: 1.0124, policy_loss: 1.0234, value_loss: 0.6765
2024-07-11 16:46:17,096 [INFO    ] __main__: train step 11225: loss: 1.0124, policy_loss: 1.0233, value_loss: 0.6765
2024-07-11 16:46:17,335 [INFO    ] __main__: train step 11226: loss: 1.0124, policy_loss: 1.0233, value_loss: 0.6765
2024-07-11 16:46:17,555 [INFO    ] __main__: train step 11227: loss: 1.0124, policy_loss: 1.0232, value_loss: 0.6764
2024-07-11 16:46:17,763 [INFO    ] __main__: train step 11228: loss: 1.0124, policy_loss: 1.0232, value_loss: 0.6764
2024-07-11 16:46:17,992 [INFO    ] __main__: train step 11229: loss: 1.0123, policy_loss: 1.0232, value_loss: 0.6764
2024-07-11 16:46:18,205 [INFO    ] __main__: train step 11230: loss: 1.0123, policy_loss: 1.0231, value_loss: 0.6763
2024-07-11 16:46:18,399 [INFO    ] __main__: train step 11231: loss: 1.0123, policy_loss: 1.0231, value_loss: 0.6763
2024-07-11 16:46:18,600 [INFO    ] __main__: train step 11232: loss: 1.0123, policy_loss: 1.0230, value_loss: 0.6763
2024-07-11 16:46:18,799 [INFO    ] __main__: train step 11233: loss: 1.0123, policy_loss: 1.0230, value_loss: 0.6762
2024-07-11 16:46:19,012 [INFO    ] __main__: train step 11234: loss: 1.0123, policy_loss: 1.0230, value_loss: 0.6762
2024-07-11 16:46:19,221 [INFO    ] __main__: train step 11235: loss: 1.0123, policy_loss: 1.0229, value_loss: 0.6762
2024-07-11 16:46:19,419 [INFO    ] __main__: train step 11236: loss: 1.0123, policy_loss: 1.0229, value_loss: 0.6761
2024-07-11 16:46:20,859 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:46:21,237 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:46:21,293 [INFO    ] __main__: train step 11237: loss: 1.0123, policy_loss: 1.0228, value_loss: 0.6761
2024-07-11 16:46:21,465 [INFO    ] __main__: train step 11238: loss: 1.0122, policy_loss: 1.0228, value_loss: 0.6761
2024-07-11 16:46:21,677 [INFO    ] __main__: train step 11239: loss: 1.0122, policy_loss: 1.0228, value_loss: 0.6760
2024-07-11 16:46:21,878 [INFO    ] __main__: train step 11240: loss: 1.0122, policy_loss: 1.0227, value_loss: 0.6760
2024-07-11 16:46:22,086 [INFO    ] __main__: train step 11241: loss: 1.0122, policy_loss: 1.0227, value_loss: 0.6760
2024-07-11 16:46:22,279 [INFO    ] __main__: train step 11242: loss: 1.0122, policy_loss: 1.0226, value_loss: 0.6759
2024-07-11 16:46:22,494 [INFO    ] __main__: train step 11243: loss: 1.0122, policy_loss: 1.0226, value_loss: 0.6759
2024-07-11 16:46:22,705 [INFO    ] __main__: train step 11244: loss: 1.0122, policy_loss: 1.0226, value_loss: 0.6759
2024-07-11 16:46:22,923 [INFO    ] __main__: train step 11245: loss: 1.0122, policy_loss: 1.0225, value_loss: 0.6759
2024-07-11 16:46:23,124 [INFO    ] __main__: train step 11246: loss: 1.0122, policy_loss: 1.0225, value_loss: 0.6758
2024-07-11 16:46:23,341 [INFO    ] __main__: train step 11247: loss: 1.0121, policy_loss: 1.0224, value_loss: 0.6758
2024-07-11 16:46:23,579 [INFO    ] __main__: train step 11248: loss: 1.0121, policy_loss: 1.0224, value_loss: 0.6758
2024-07-11 16:46:23,780 [INFO    ] __main__: train step 11249: loss: 1.0121, policy_loss: 1.0224, value_loss: 0.6757
2024-07-11 16:46:23,989 [INFO    ] __main__: train step 11250: loss: 1.0121, policy_loss: 1.0223, value_loss: 0.6757
2024-07-11 16:46:24,196 [INFO    ] __main__: train step 11251: loss: 1.0121, policy_loss: 1.0223, value_loss: 0.6757
2024-07-11 16:46:24,395 [INFO    ] __main__: train step 11252: loss: 1.0121, policy_loss: 1.0223, value_loss: 0.6756
2024-07-11 16:46:24,599 [INFO    ] __main__: train step 11253: loss: 1.0121, policy_loss: 1.0222, value_loss: 0.6756
2024-07-11 16:46:26,034 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:46:26,426 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:46:26,484 [INFO    ] __main__: train step 11254: loss: 1.0121, policy_loss: 1.0222, value_loss: 0.6756
2024-07-11 16:46:26,657 [INFO    ] __main__: train step 11255: loss: 1.0121, policy_loss: 1.0221, value_loss: 0.6755
2024-07-11 16:46:26,866 [INFO    ] __main__: train step 11256: loss: 1.0120, policy_loss: 1.0221, value_loss: 0.6755
2024-07-11 16:46:27,060 [INFO    ] __main__: train step 11257: loss: 1.0120, policy_loss: 1.0221, value_loss: 0.6755
2024-07-11 16:46:27,271 [INFO    ] __main__: train step 11258: loss: 1.0120, policy_loss: 1.0220, value_loss: 0.6754
2024-07-11 16:46:27,465 [INFO    ] __main__: train step 11259: loss: 1.0120, policy_loss: 1.0220, value_loss: 0.6754
2024-07-11 16:46:27,678 [INFO    ] __main__: train step 11260: loss: 1.0120, policy_loss: 1.0219, value_loss: 0.6754
2024-07-11 16:46:27,875 [INFO    ] __main__: train step 11261: loss: 1.0120, policy_loss: 1.0219, value_loss: 0.6753
2024-07-11 16:46:28,078 [INFO    ] __main__: train step 11262: loss: 1.0120, policy_loss: 1.0219, value_loss: 0.6753
2024-07-11 16:46:28,304 [INFO    ] __main__: train step 11263: loss: 1.0120, policy_loss: 1.0218, value_loss: 0.6753
2024-07-11 16:46:28,507 [INFO    ] __main__: train step 11264: loss: 1.0120, policy_loss: 1.0218, value_loss: 0.6752
2024-07-11 16:46:28,704 [INFO    ] __main__: train step 11265: loss: 1.0120, policy_loss: 1.0217, value_loss: 0.6752
2024-07-11 16:46:28,902 [INFO    ] __main__: train step 11266: loss: 1.0119, policy_loss: 1.0217, value_loss: 0.6752
2024-07-11 16:46:29,102 [INFO    ] __main__: train step 11267: loss: 1.0119, policy_loss: 1.0217, value_loss: 0.6751
2024-07-11 16:46:29,312 [INFO    ] __main__: train step 11268: loss: 1.0119, policy_loss: 1.0216, value_loss: 0.6751
2024-07-11 16:46:29,542 [INFO    ] __main__: train step 11269: loss: 1.0119, policy_loss: 1.0216, value_loss: 0.6751
2024-07-11 16:46:29,744 [INFO    ] __main__: train step 11270: loss: 1.0119, policy_loss: 1.0215, value_loss: 0.6750
2024-07-11 16:46:31,186 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:46:31,561 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:46:31,625 [INFO    ] __main__: train step 11271: loss: 1.0119, policy_loss: 1.0215, value_loss: 0.6750
2024-07-11 16:46:31,800 [INFO    ] __main__: train step 11272: loss: 1.0119, policy_loss: 1.0215, value_loss: 0.6750
2024-07-11 16:46:31,990 [INFO    ] __main__: train step 11273: loss: 1.0119, policy_loss: 1.0214, value_loss: 0.6749
2024-07-11 16:46:32,200 [INFO    ] __main__: train step 11274: loss: 1.0119, policy_loss: 1.0214, value_loss: 0.6749
2024-07-11 16:46:32,406 [INFO    ] __main__: train step 11275: loss: 1.0119, policy_loss: 1.0214, value_loss: 0.6749
2024-07-11 16:46:32,617 [INFO    ] __main__: train step 11276: loss: 1.0118, policy_loss: 1.0213, value_loss: 0.6749
2024-07-11 16:46:32,830 [INFO    ] __main__: train step 11277: loss: 1.0118, policy_loss: 1.0213, value_loss: 0.6748
2024-07-11 16:46:33,062 [INFO    ] __main__: train step 11278: loss: 1.0118, policy_loss: 1.0212, value_loss: 0.6748
2024-07-11 16:46:33,280 [INFO    ] __main__: train step 11279: loss: 1.0118, policy_loss: 1.0212, value_loss: 0.6748
2024-07-11 16:46:33,480 [INFO    ] __main__: train step 11280: loss: 1.0118, policy_loss: 1.0212, value_loss: 0.6747
2024-07-11 16:46:33,689 [INFO    ] __main__: train step 11281: loss: 1.0118, policy_loss: 1.0211, value_loss: 0.6747
2024-07-11 16:46:33,890 [INFO    ] __main__: train step 11282: loss: 1.0118, policy_loss: 1.0211, value_loss: 0.6747
2024-07-11 16:46:34,086 [INFO    ] __main__: train step 11283: loss: 1.0118, policy_loss: 1.0210, value_loss: 0.6746
2024-07-11 16:46:34,295 [INFO    ] __main__: train step 11284: loss: 1.0117, policy_loss: 1.0210, value_loss: 0.6746
2024-07-11 16:46:34,500 [INFO    ] __main__: train step 11285: loss: 1.0117, policy_loss: 1.0210, value_loss: 0.6746
2024-07-11 16:46:34,707 [INFO    ] __main__: train step 11286: loss: 1.0117, policy_loss: 1.0209, value_loss: 0.6745
2024-07-11 16:46:34,910 [INFO    ] __main__: train step 11287: loss: 1.0117, policy_loss: 1.0209, value_loss: 0.6745
2024-07-11 16:46:36,349 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:46:36,738 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:46:36,800 [INFO    ] __main__: train step 11288: loss: 1.0117, policy_loss: 1.0208, value_loss: 0.6745
2024-07-11 16:46:36,972 [INFO    ] __main__: train step 11289: loss: 1.0117, policy_loss: 1.0208, value_loss: 0.6744
2024-07-11 16:46:37,179 [INFO    ] __main__: train step 11290: loss: 1.0117, policy_loss: 1.0208, value_loss: 0.6744
2024-07-11 16:46:37,377 [INFO    ] __main__: train step 11291: loss: 1.0117, policy_loss: 1.0207, value_loss: 0.6744
2024-07-11 16:46:37,581 [INFO    ] __main__: train step 11292: loss: 1.0117, policy_loss: 1.0207, value_loss: 0.6743
2024-07-11 16:46:37,781 [INFO    ] __main__: train step 11293: loss: 1.0117, policy_loss: 1.0206, value_loss: 0.6743
2024-07-11 16:46:37,987 [INFO    ] __main__: train step 11294: loss: 1.0117, policy_loss: 1.0206, value_loss: 0.6743
2024-07-11 16:46:38,184 [INFO    ] __main__: train step 11295: loss: 1.0116, policy_loss: 1.0206, value_loss: 0.6742
2024-07-11 16:46:38,405 [INFO    ] __main__: train step 11296: loss: 1.0116, policy_loss: 1.0205, value_loss: 0.6742
2024-07-11 16:46:38,607 [INFO    ] __main__: train step 11297: loss: 1.0116, policy_loss: 1.0205, value_loss: 0.6742
2024-07-11 16:46:38,807 [INFO    ] __main__: train step 11298: loss: 1.0116, policy_loss: 1.0205, value_loss: 0.6742
2024-07-11 16:46:39,000 [INFO    ] __main__: train step 11299: loss: 1.0116, policy_loss: 1.0204, value_loss: 0.6741
2024-07-11 16:46:39,197 [INFO    ] __main__: train step 11300: loss: 1.0116, policy_loss: 1.0204, value_loss: 0.6741
2024-07-11 16:46:39,409 [INFO    ] __main__: train step 11301: loss: 1.0116, policy_loss: 1.0203, value_loss: 0.6741
2024-07-11 16:46:39,608 [INFO    ] __main__: train step 11302: loss: 1.0116, policy_loss: 1.0203, value_loss: 0.6740
2024-07-11 16:46:41,159 [INFO    ] __main__: train step 11303: loss: 1.0116, policy_loss: 1.0203, value_loss: 0.6740
2024-07-11 16:46:41,370 [INFO    ] __main__: train step 11304: loss: 1.0116, policy_loss: 1.0202, value_loss: 0.6740
2024-07-11 16:46:42,811 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:46:43,217 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:46:43,272 [INFO    ] __main__: train step 11305: loss: 1.0115, policy_loss: 1.0202, value_loss: 0.6739
2024-07-11 16:46:43,457 [INFO    ] __main__: train step 11306: loss: 1.0115, policy_loss: 1.0201, value_loss: 0.6739
2024-07-11 16:46:43,700 [INFO    ] __main__: train step 11307: loss: 1.0115, policy_loss: 1.0201, value_loss: 0.6739
2024-07-11 16:46:43,896 [INFO    ] __main__: train step 11308: loss: 1.0115, policy_loss: 1.0201, value_loss: 0.6738
2024-07-11 16:46:44,104 [INFO    ] __main__: train step 11309: loss: 1.0115, policy_loss: 1.0200, value_loss: 0.6738
2024-07-11 16:46:44,303 [INFO    ] __main__: train step 11310: loss: 1.0115, policy_loss: 1.0200, value_loss: 0.6738
2024-07-11 16:46:44,522 [INFO    ] __main__: train step 11311: loss: 1.0115, policy_loss: 1.0200, value_loss: 0.6737
2024-07-11 16:46:44,738 [INFO    ] __main__: train step 11312: loss: 1.0115, policy_loss: 1.0199, value_loss: 0.6737
2024-07-11 16:46:44,948 [INFO    ] __main__: train step 11313: loss: 1.0115, policy_loss: 1.0199, value_loss: 0.6737
2024-07-11 16:46:45,156 [INFO    ] __main__: train step 11314: loss: 1.0115, policy_loss: 1.0198, value_loss: 0.6737
2024-07-11 16:46:45,357 [INFO    ] __main__: train step 11315: loss: 1.0115, policy_loss: 1.0198, value_loss: 0.6736
2024-07-11 16:46:45,567 [INFO    ] __main__: train step 11316: loss: 1.0114, policy_loss: 1.0198, value_loss: 0.6736
2024-07-11 16:46:45,784 [INFO    ] __main__: train step 11317: loss: 1.0114, policy_loss: 1.0197, value_loss: 0.6736
2024-07-11 16:46:45,980 [INFO    ] __main__: train step 11318: loss: 1.0114, policy_loss: 1.0197, value_loss: 0.6735
2024-07-11 16:46:46,185 [INFO    ] __main__: train step 11319: loss: 1.0114, policy_loss: 1.0196, value_loss: 0.6735
2024-07-11 16:46:46,386 [INFO    ] __main__: train step 11320: loss: 1.0114, policy_loss: 1.0196, value_loss: 0.6735
2024-07-11 16:46:46,588 [INFO    ] __main__: train step 11321: loss: 1.0114, policy_loss: 1.0196, value_loss: 0.6734
2024-07-11 16:46:48,035 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:46:48,421 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:46:48,479 [INFO    ] __main__: train step 11322: loss: 1.0114, policy_loss: 1.0195, value_loss: 0.6734
2024-07-11 16:46:48,652 [INFO    ] __main__: train step 11323: loss: 1.0114, policy_loss: 1.0195, value_loss: 0.6734
2024-07-11 16:46:48,849 [INFO    ] __main__: train step 11324: loss: 1.0114, policy_loss: 1.0195, value_loss: 0.6733
2024-07-11 16:46:49,054 [INFO    ] __main__: train step 11325: loss: 1.0114, policy_loss: 1.0194, value_loss: 0.6733
2024-07-11 16:46:49,257 [INFO    ] __main__: train step 11326: loss: 1.0114, policy_loss: 1.0194, value_loss: 0.6733
2024-07-11 16:46:49,457 [INFO    ] __main__: train step 11327: loss: 1.0113, policy_loss: 1.0193, value_loss: 0.6732
2024-07-11 16:46:49,663 [INFO    ] __main__: train step 11328: loss: 1.0113, policy_loss: 1.0193, value_loss: 0.6732
2024-07-11 16:46:49,866 [INFO    ] __main__: train step 11329: loss: 1.0113, policy_loss: 1.0193, value_loss: 0.6732
2024-07-11 16:46:50,073 [INFO    ] __main__: train step 11330: loss: 1.0113, policy_loss: 1.0192, value_loss: 0.6732
2024-07-11 16:46:50,270 [INFO    ] __main__: train step 11331: loss: 1.0113, policy_loss: 1.0192, value_loss: 0.6731
2024-07-11 16:46:50,485 [INFO    ] __main__: train step 11332: loss: 1.0113, policy_loss: 1.0192, value_loss: 0.6731
2024-07-11 16:46:50,701 [INFO    ] __main__: train step 11333: loss: 1.0113, policy_loss: 1.0191, value_loss: 0.6731
2024-07-11 16:46:50,920 [INFO    ] __main__: train step 11334: loss: 1.0113, policy_loss: 1.0191, value_loss: 0.6730
2024-07-11 16:46:51,146 [INFO    ] __main__: train step 11335: loss: 1.0113, policy_loss: 1.0190, value_loss: 0.6730
2024-07-11 16:46:51,345 [INFO    ] __main__: train step 11336: loss: 1.0113, policy_loss: 1.0190, value_loss: 0.6730
2024-07-11 16:46:51,545 [INFO    ] __main__: train step 11337: loss: 1.0112, policy_loss: 1.0190, value_loss: 0.6729
2024-07-11 16:46:51,743 [INFO    ] __main__: train step 11338: loss: 1.0112, policy_loss: 1.0189, value_loss: 0.6729
2024-07-11 16:46:53,173 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:46:53,549 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:46:53,605 [INFO    ] __main__: train step 11339: loss: 1.0112, policy_loss: 1.0189, value_loss: 0.6729
2024-07-11 16:46:53,778 [INFO    ] __main__: train step 11340: loss: 1.0112, policy_loss: 1.0188, value_loss: 0.6728
2024-07-11 16:46:53,990 [INFO    ] __main__: train step 11341: loss: 1.0112, policy_loss: 1.0188, value_loss: 0.6728
2024-07-11 16:46:54,221 [INFO    ] __main__: train step 11342: loss: 1.0112, policy_loss: 1.0188, value_loss: 0.6728
2024-07-11 16:46:54,416 [INFO    ] __main__: train step 11343: loss: 1.0112, policy_loss: 1.0187, value_loss: 0.6727
2024-07-11 16:46:54,616 [INFO    ] __main__: train step 11344: loss: 1.0112, policy_loss: 1.0187, value_loss: 0.6727
2024-07-11 16:46:54,820 [INFO    ] __main__: train step 11345: loss: 1.0112, policy_loss: 1.0187, value_loss: 0.6727
2024-07-11 16:46:55,025 [INFO    ] __main__: train step 11346: loss: 1.0112, policy_loss: 1.0186, value_loss: 0.6727
2024-07-11 16:46:55,231 [INFO    ] __main__: train step 11347: loss: 1.0112, policy_loss: 1.0186, value_loss: 0.6726
2024-07-11 16:46:55,445 [INFO    ] __main__: train step 11348: loss: 1.0112, policy_loss: 1.0185, value_loss: 0.6726
2024-07-11 16:46:55,639 [INFO    ] __main__: train step 11349: loss: 1.0111, policy_loss: 1.0185, value_loss: 0.6726
2024-07-11 16:46:55,859 [INFO    ] __main__: train step 11350: loss: 1.0111, policy_loss: 1.0185, value_loss: 0.6725
2024-07-11 16:46:56,071 [INFO    ] __main__: train step 11351: loss: 1.0111, policy_loss: 1.0184, value_loss: 0.6725
2024-07-11 16:46:56,283 [INFO    ] __main__: train step 11352: loss: 1.0111, policy_loss: 1.0184, value_loss: 0.6725
2024-07-11 16:46:56,498 [INFO    ] __main__: train step 11353: loss: 1.0111, policy_loss: 1.0184, value_loss: 0.6724
2024-07-11 16:46:56,701 [INFO    ] __main__: train step 11354: loss: 1.0111, policy_loss: 1.0183, value_loss: 0.6724
2024-07-11 16:46:56,911 [INFO    ] __main__: train step 11355: loss: 1.0111, policy_loss: 1.0183, value_loss: 0.6724
2024-07-11 16:46:58,352 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:46:58,727 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:46:58,782 [INFO    ] __main__: train step 11356: loss: 1.0111, policy_loss: 1.0182, value_loss: 0.6723
2024-07-11 16:46:58,960 [INFO    ] __main__: train step 11357: loss: 1.0111, policy_loss: 1.0182, value_loss: 0.6723
2024-07-11 16:46:59,166 [INFO    ] __main__: train step 11358: loss: 1.0111, policy_loss: 1.0182, value_loss: 0.6723
2024-07-11 16:46:59,402 [INFO    ] __main__: train step 11359: loss: 1.0111, policy_loss: 1.0181, value_loss: 0.6723
2024-07-11 16:46:59,635 [INFO    ] __main__: train step 11360: loss: 1.0110, policy_loss: 1.0181, value_loss: 0.6722
2024-07-11 16:46:59,836 [INFO    ] __main__: train step 11361: loss: 1.0110, policy_loss: 1.0181, value_loss: 0.6722
2024-07-11 16:47:00,037 [INFO    ] __main__: train step 11362: loss: 1.0110, policy_loss: 1.0180, value_loss: 0.6722
2024-07-11 16:47:00,248 [INFO    ] __main__: train step 11363: loss: 1.0110, policy_loss: 1.0180, value_loss: 0.6721
2024-07-11 16:47:00,483 [INFO    ] __main__: train step 11364: loss: 1.0110, policy_loss: 1.0179, value_loss: 0.6721
2024-07-11 16:47:00,697 [INFO    ] __main__: train step 11365: loss: 1.0110, policy_loss: 1.0179, value_loss: 0.6721
2024-07-11 16:47:00,898 [INFO    ] __main__: train step 11366: loss: 1.0110, policy_loss: 1.0179, value_loss: 0.6720
2024-07-11 16:47:01,112 [INFO    ] __main__: train step 11367: loss: 1.0110, policy_loss: 1.0178, value_loss: 0.6720
2024-07-11 16:47:01,318 [INFO    ] __main__: train step 11368: loss: 1.0110, policy_loss: 1.0178, value_loss: 0.6720
2024-07-11 16:47:01,520 [INFO    ] __main__: train step 11369: loss: 1.0110, policy_loss: 1.0178, value_loss: 0.6719
2024-07-11 16:47:01,726 [INFO    ] __main__: train step 11370: loss: 1.0110, policy_loss: 1.0177, value_loss: 0.6719
2024-07-11 16:47:01,936 [INFO    ] __main__: train step 11371: loss: 1.0109, policy_loss: 1.0177, value_loss: 0.6719
2024-07-11 16:47:02,144 [INFO    ] __main__: train step 11372: loss: 1.0109, policy_loss: 1.0176, value_loss: 0.6719
2024-07-11 16:47:03,616 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:47:04,025 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:47:04,084 [INFO    ] __main__: train step 11373: loss: 1.0109, policy_loss: 1.0176, value_loss: 0.6718
2024-07-11 16:47:04,251 [INFO    ] __main__: train step 11374: loss: 1.0109, policy_loss: 1.0176, value_loss: 0.6718
2024-07-11 16:47:04,470 [INFO    ] __main__: train step 11375: loss: 1.0109, policy_loss: 1.0175, value_loss: 0.6718
2024-07-11 16:47:04,701 [INFO    ] __main__: train step 11376: loss: 1.0109, policy_loss: 1.0175, value_loss: 0.6717
2024-07-11 16:47:04,901 [INFO    ] __main__: train step 11377: loss: 1.0109, policy_loss: 1.0175, value_loss: 0.6717
2024-07-11 16:47:05,125 [INFO    ] __main__: train step 11378: loss: 1.0109, policy_loss: 1.0174, value_loss: 0.6717
2024-07-11 16:47:05,357 [INFO    ] __main__: train step 11379: loss: 1.0109, policy_loss: 1.0174, value_loss: 0.6716
2024-07-11 16:47:05,615 [INFO    ] __main__: train step 11380: loss: 1.0109, policy_loss: 1.0173, value_loss: 0.6716
2024-07-11 16:47:05,827 [INFO    ] __main__: train step 11381: loss: 1.0109, policy_loss: 1.0173, value_loss: 0.6716
2024-07-11 16:47:06,068 [INFO    ] __main__: train step 11382: loss: 1.0108, policy_loss: 1.0173, value_loss: 0.6715
2024-07-11 16:47:06,308 [INFO    ] __main__: train step 11383: loss: 1.0108, policy_loss: 1.0172, value_loss: 0.6715
2024-07-11 16:47:06,527 [INFO    ] __main__: train step 11384: loss: 1.0108, policy_loss: 1.0172, value_loss: 0.6715
2024-07-11 16:47:06,724 [INFO    ] __main__: train step 11385: loss: 1.0108, policy_loss: 1.0172, value_loss: 0.6714
2024-07-11 16:47:06,929 [INFO    ] __main__: train step 11386: loss: 1.0108, policy_loss: 1.0171, value_loss: 0.6714
2024-07-11 16:47:07,128 [INFO    ] __main__: train step 11387: loss: 1.0108, policy_loss: 1.0171, value_loss: 0.6714
2024-07-11 16:47:07,336 [INFO    ] __main__: train step 11388: loss: 1.0108, policy_loss: 1.0170, value_loss: 0.6714
2024-07-11 16:47:07,557 [INFO    ] __main__: train step 11389: loss: 1.0108, policy_loss: 1.0170, value_loss: 0.6713
2024-07-11 16:47:09,023 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:47:09,373 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:47:09,434 [INFO    ] __main__: train step 11390: loss: 1.0108, policy_loss: 1.0170, value_loss: 0.6713
2024-07-11 16:47:09,605 [INFO    ] __main__: train step 11391: loss: 1.0108, policy_loss: 1.0169, value_loss: 0.6713
2024-07-11 16:47:09,820 [INFO    ] __main__: train step 11392: loss: 1.0108, policy_loss: 1.0169, value_loss: 0.6712
2024-07-11 16:47:10,037 [INFO    ] __main__: train step 11393: loss: 1.0108, policy_loss: 1.0169, value_loss: 0.6712
2024-07-11 16:47:10,237 [INFO    ] __main__: train step 11394: loss: 1.0108, policy_loss: 1.0168, value_loss: 0.6712
2024-07-11 16:47:10,447 [INFO    ] __main__: train step 11395: loss: 1.0108, policy_loss: 1.0168, value_loss: 0.6711
2024-07-11 16:47:10,639 [INFO    ] __main__: train step 11396: loss: 1.0107, policy_loss: 1.0167, value_loss: 0.6711
2024-07-11 16:47:10,838 [INFO    ] __main__: train step 11397: loss: 1.0107, policy_loss: 1.0167, value_loss: 0.6711
2024-07-11 16:47:11,057 [INFO    ] __main__: train step 11398: loss: 1.0107, policy_loss: 1.0167, value_loss: 0.6711
2024-07-11 16:47:11,277 [INFO    ] __main__: train step 11399: loss: 1.0107, policy_loss: 1.0166, value_loss: 0.6710
2024-07-11 16:47:11,481 [INFO    ] __main__: train step 11400: loss: 1.0107, policy_loss: 1.0166, value_loss: 0.6710
2024-07-11 16:47:11,686 [INFO    ] __main__: train step 11401: loss: 1.0107, policy_loss: 1.0166, value_loss: 0.6710
2024-07-11 16:47:11,896 [INFO    ] __main__: train step 11402: loss: 1.0107, policy_loss: 1.0165, value_loss: 0.6709
2024-07-11 16:47:12,111 [INFO    ] __main__: train step 11403: loss: 1.0107, policy_loss: 1.0165, value_loss: 0.6709
2024-07-11 16:47:13,664 [INFO    ] __main__: train step 11404: loss: 1.0107, policy_loss: 1.0165, value_loss: 0.6709
2024-07-11 16:47:13,887 [INFO    ] __main__: train step 11405: loss: 1.0107, policy_loss: 1.0164, value_loss: 0.6708
2024-07-11 16:47:14,094 [INFO    ] __main__: train step 11406: loss: 1.0107, policy_loss: 1.0164, value_loss: 0.6708
2024-07-11 16:47:15,563 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:47:15,903 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:47:15,960 [INFO    ] __main__: train step 11407: loss: 1.0107, policy_loss: 1.0163, value_loss: 0.6708
2024-07-11 16:47:16,146 [INFO    ] __main__: train step 11408: loss: 1.0107, policy_loss: 1.0163, value_loss: 0.6708
2024-07-11 16:47:16,378 [INFO    ] __main__: train step 11409: loss: 1.0106, policy_loss: 1.0163, value_loss: 0.6707
2024-07-11 16:47:16,576 [INFO    ] __main__: train step 11410: loss: 1.0106, policy_loss: 1.0162, value_loss: 0.6707
2024-07-11 16:47:16,813 [INFO    ] __main__: train step 11411: loss: 1.0106, policy_loss: 1.0162, value_loss: 0.6707
2024-07-11 16:47:17,041 [INFO    ] __main__: train step 11412: loss: 1.0106, policy_loss: 1.0162, value_loss: 0.6706
2024-07-11 16:47:17,259 [INFO    ] __main__: train step 11413: loss: 1.0106, policy_loss: 1.0161, value_loss: 0.6706
2024-07-11 16:47:17,512 [INFO    ] __main__: train step 11414: loss: 1.0106, policy_loss: 1.0161, value_loss: 0.6706
2024-07-11 16:47:17,735 [INFO    ] __main__: train step 11415: loss: 1.0106, policy_loss: 1.0161, value_loss: 0.6705
2024-07-11 16:47:17,954 [INFO    ] __main__: train step 11416: loss: 1.0106, policy_loss: 1.0160, value_loss: 0.6705
2024-07-11 16:47:18,196 [INFO    ] __main__: train step 11417: loss: 1.0106, policy_loss: 1.0160, value_loss: 0.6705
2024-07-11 16:47:18,401 [INFO    ] __main__: train step 11418: loss: 1.0106, policy_loss: 1.0159, value_loss: 0.6704
2024-07-11 16:47:18,604 [INFO    ] __main__: train step 11419: loss: 1.0106, policy_loss: 1.0159, value_loss: 0.6704
2024-07-11 16:47:18,817 [INFO    ] __main__: train step 11420: loss: 1.0106, policy_loss: 1.0159, value_loss: 0.6704
2024-07-11 16:47:19,015 [INFO    ] __main__: train step 11421: loss: 1.0106, policy_loss: 1.0158, value_loss: 0.6704
2024-07-11 16:47:19,217 [INFO    ] __main__: train step 11422: loss: 1.0105, policy_loss: 1.0158, value_loss: 0.6703
2024-07-11 16:47:19,425 [INFO    ] __main__: train step 11423: loss: 1.0105, policy_loss: 1.0158, value_loss: 0.6703
2024-07-11 16:47:20,855 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:47:21,250 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:47:21,305 [INFO    ] __main__: train step 11424: loss: 1.0105, policy_loss: 1.0157, value_loss: 0.6703
2024-07-11 16:47:21,479 [INFO    ] __main__: train step 11425: loss: 1.0105, policy_loss: 1.0157, value_loss: 0.6702
2024-07-11 16:47:21,689 [INFO    ] __main__: train step 11426: loss: 1.0105, policy_loss: 1.0157, value_loss: 0.6702
2024-07-11 16:47:21,899 [INFO    ] __main__: train step 11427: loss: 1.0105, policy_loss: 1.0156, value_loss: 0.6702
2024-07-11 16:47:22,108 [INFO    ] __main__: train step 11428: loss: 1.0105, policy_loss: 1.0156, value_loss: 0.6701
2024-07-11 16:47:22,317 [INFO    ] __main__: train step 11429: loss: 1.0105, policy_loss: 1.0155, value_loss: 0.6701
2024-07-11 16:47:22,529 [INFO    ] __main__: train step 11430: loss: 1.0105, policy_loss: 1.0155, value_loss: 0.6701
2024-07-11 16:47:22,742 [INFO    ] __main__: train step 11431: loss: 1.0105, policy_loss: 1.0155, value_loss: 0.6701
2024-07-11 16:47:22,946 [INFO    ] __main__: train step 11432: loss: 1.0105, policy_loss: 1.0154, value_loss: 0.6700
2024-07-11 16:47:23,155 [INFO    ] __main__: train step 11433: loss: 1.0105, policy_loss: 1.0154, value_loss: 0.6700
2024-07-11 16:47:23,351 [INFO    ] __main__: train step 11434: loss: 1.0105, policy_loss: 1.0154, value_loss: 0.6700
2024-07-11 16:47:23,583 [INFO    ] __main__: train step 11435: loss: 1.0105, policy_loss: 1.0153, value_loss: 0.6699
2024-07-11 16:47:23,784 [INFO    ] __main__: train step 11436: loss: 1.0105, policy_loss: 1.0153, value_loss: 0.6699
2024-07-11 16:47:23,996 [INFO    ] __main__: train step 11437: loss: 1.0104, policy_loss: 1.0153, value_loss: 0.6699
2024-07-11 16:47:24,208 [INFO    ] __main__: train step 11438: loss: 1.0104, policy_loss: 1.0152, value_loss: 0.6698
2024-07-11 16:47:24,424 [INFO    ] __main__: train step 11439: loss: 1.0104, policy_loss: 1.0152, value_loss: 0.6698
2024-07-11 16:47:24,619 [INFO    ] __main__: train step 11440: loss: 1.0104, policy_loss: 1.0151, value_loss: 0.6698
2024-07-11 16:47:26,061 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:47:26,604 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:47:26,668 [INFO    ] __main__: train step 11441: loss: 1.0104, policy_loss: 1.0151, value_loss: 0.6698
2024-07-11 16:47:26,861 [INFO    ] __main__: train step 11442: loss: 1.0104, policy_loss: 1.0151, value_loss: 0.6697
2024-07-11 16:47:27,093 [INFO    ] __main__: train step 11443: loss: 1.0104, policy_loss: 1.0150, value_loss: 0.6697
2024-07-11 16:47:27,292 [INFO    ] __main__: train step 11444: loss: 1.0104, policy_loss: 1.0150, value_loss: 0.6697
2024-07-11 16:47:27,502 [INFO    ] __main__: train step 11445: loss: 1.0104, policy_loss: 1.0150, value_loss: 0.6696
2024-07-11 16:47:27,707 [INFO    ] __main__: train step 11446: loss: 1.0104, policy_loss: 1.0149, value_loss: 0.6696
2024-07-11 16:47:27,906 [INFO    ] __main__: train step 11447: loss: 1.0104, policy_loss: 1.0149, value_loss: 0.6696
2024-07-11 16:47:28,113 [INFO    ] __main__: train step 11448: loss: 1.0104, policy_loss: 1.0149, value_loss: 0.6696
2024-07-11 16:47:28,333 [INFO    ] __main__: train step 11449: loss: 1.0104, policy_loss: 1.0148, value_loss: 0.6695
2024-07-11 16:47:28,564 [INFO    ] __main__: train step 11450: loss: 1.0104, policy_loss: 1.0148, value_loss: 0.6695
2024-07-11 16:47:28,770 [INFO    ] __main__: train step 11451: loss: 1.0104, policy_loss: 1.0148, value_loss: 0.6695
2024-07-11 16:47:28,973 [INFO    ] __main__: train step 11452: loss: 1.0103, policy_loss: 1.0147, value_loss: 0.6694
2024-07-11 16:47:29,204 [INFO    ] __main__: train step 11453: loss: 1.0103, policy_loss: 1.0147, value_loss: 0.6694
2024-07-11 16:47:29,418 [INFO    ] __main__: train step 11454: loss: 1.0103, policy_loss: 1.0146, value_loss: 0.6694
2024-07-11 16:47:29,617 [INFO    ] __main__: train step 11455: loss: 1.0103, policy_loss: 1.0146, value_loss: 0.6693
2024-07-11 16:47:29,823 [INFO    ] __main__: train step 11456: loss: 1.0103, policy_loss: 1.0146, value_loss: 0.6693
2024-07-11 16:47:30,017 [INFO    ] __main__: train step 11457: loss: 1.0103, policy_loss: 1.0145, value_loss: 0.6693
2024-07-11 16:47:31,462 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:47:31,885 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:47:31,949 [INFO    ] __main__: train step 11458: loss: 1.0103, policy_loss: 1.0145, value_loss: 0.6693
2024-07-11 16:47:32,126 [INFO    ] __main__: train step 11459: loss: 1.0103, policy_loss: 1.0145, value_loss: 0.6692
2024-07-11 16:47:32,326 [INFO    ] __main__: train step 11460: loss: 1.0103, policy_loss: 1.0144, value_loss: 0.6692
2024-07-11 16:47:32,531 [INFO    ] __main__: train step 11461: loss: 1.0103, policy_loss: 1.0144, value_loss: 0.6692
2024-07-11 16:47:32,729 [INFO    ] __main__: train step 11462: loss: 1.0103, policy_loss: 1.0144, value_loss: 0.6691
2024-07-11 16:47:32,936 [INFO    ] __main__: train step 11463: loss: 1.0103, policy_loss: 1.0143, value_loss: 0.6691
2024-07-11 16:47:33,136 [INFO    ] __main__: train step 11464: loss: 1.0103, policy_loss: 1.0143, value_loss: 0.6691
2024-07-11 16:47:33,338 [INFO    ] __main__: train step 11465: loss: 1.0102, policy_loss: 1.0142, value_loss: 0.6690
2024-07-11 16:47:33,535 [INFO    ] __main__: train step 11466: loss: 1.0102, policy_loss: 1.0142, value_loss: 0.6690
2024-07-11 16:47:33,742 [INFO    ] __main__: train step 11467: loss: 1.0102, policy_loss: 1.0142, value_loss: 0.6690
2024-07-11 16:47:33,939 [INFO    ] __main__: train step 11468: loss: 1.0102, policy_loss: 1.0141, value_loss: 0.6690
2024-07-11 16:47:34,140 [INFO    ] __main__: train step 11469: loss: 1.0102, policy_loss: 1.0141, value_loss: 0.6689
2024-07-11 16:47:34,336 [INFO    ] __main__: train step 11470: loss: 1.0102, policy_loss: 1.0141, value_loss: 0.6689
2024-07-11 16:47:34,546 [INFO    ] __main__: train step 11471: loss: 1.0102, policy_loss: 1.0140, value_loss: 0.6689
2024-07-11 16:47:34,742 [INFO    ] __main__: train step 11472: loss: 1.0102, policy_loss: 1.0140, value_loss: 0.6688
2024-07-11 16:47:34,939 [INFO    ] __main__: train step 11473: loss: 1.0102, policy_loss: 1.0140, value_loss: 0.6688
2024-07-11 16:47:35,142 [INFO    ] __main__: train step 11474: loss: 1.0102, policy_loss: 1.0139, value_loss: 0.6688
2024-07-11 16:47:36,590 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:47:36,928 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:47:36,982 [INFO    ] __main__: train step 11475: loss: 1.0102, policy_loss: 1.0139, value_loss: 0.6687
2024-07-11 16:47:37,173 [INFO    ] __main__: train step 11476: loss: 1.0102, policy_loss: 1.0139, value_loss: 0.6687
2024-07-11 16:47:37,407 [INFO    ] __main__: train step 11477: loss: 1.0102, policy_loss: 1.0138, value_loss: 0.6687
2024-07-11 16:47:37,617 [INFO    ] __main__: train step 11478: loss: 1.0102, policy_loss: 1.0138, value_loss: 0.6687
2024-07-11 16:47:37,813 [INFO    ] __main__: train step 11479: loss: 1.0102, policy_loss: 1.0138, value_loss: 0.6686
2024-07-11 16:47:38,010 [INFO    ] __main__: train step 11480: loss: 1.0101, policy_loss: 1.0137, value_loss: 0.6686
2024-07-11 16:47:38,225 [INFO    ] __main__: train step 11481: loss: 1.0101, policy_loss: 1.0137, value_loss: 0.6686
2024-07-11 16:47:38,422 [INFO    ] __main__: train step 11482: loss: 1.0101, policy_loss: 1.0136, value_loss: 0.6685
2024-07-11 16:47:38,633 [INFO    ] __main__: train step 11483: loss: 1.0101, policy_loss: 1.0136, value_loss: 0.6685
2024-07-11 16:47:38,828 [INFO    ] __main__: train step 11484: loss: 1.0101, policy_loss: 1.0136, value_loss: 0.6685
2024-07-11 16:47:39,031 [INFO    ] __main__: train step 11485: loss: 1.0101, policy_loss: 1.0135, value_loss: 0.6684
2024-07-11 16:47:39,225 [INFO    ] __main__: train step 11486: loss: 1.0101, policy_loss: 1.0135, value_loss: 0.6684
2024-07-11 16:47:39,427 [INFO    ] __main__: train step 11487: loss: 1.0101, policy_loss: 1.0135, value_loss: 0.6684
2024-07-11 16:47:39,622 [INFO    ] __main__: train step 11488: loss: 1.0101, policy_loss: 1.0134, value_loss: 0.6684
2024-07-11 16:47:39,828 [INFO    ] __main__: train step 11489: loss: 1.0101, policy_loss: 1.0134, value_loss: 0.6683
2024-07-11 16:47:40,027 [INFO    ] __main__: train step 11490: loss: 1.0101, policy_loss: 1.0134, value_loss: 0.6683
2024-07-11 16:47:40,229 [INFO    ] __main__: train step 11491: loss: 1.0101, policy_loss: 1.0133, value_loss: 0.6683
2024-07-11 16:47:41,692 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:47:42,114 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:47:42,171 [INFO    ] __main__: train step 11492: loss: 1.0101, policy_loss: 1.0133, value_loss: 0.6682
2024-07-11 16:47:42,342 [INFO    ] __main__: train step 11493: loss: 1.0101, policy_loss: 1.0132, value_loss: 0.6682
2024-07-11 16:47:42,589 [INFO    ] __main__: train step 11494: loss: 1.0101, policy_loss: 1.0132, value_loss: 0.6682
2024-07-11 16:47:42,827 [INFO    ] __main__: train step 11495: loss: 1.0100, policy_loss: 1.0132, value_loss: 0.6682
2024-07-11 16:47:43,049 [INFO    ] __main__: train step 11496: loss: 1.0100, policy_loss: 1.0131, value_loss: 0.6681
2024-07-11 16:47:43,286 [INFO    ] __main__: train step 11497: loss: 1.0100, policy_loss: 1.0131, value_loss: 0.6681
2024-07-11 16:47:43,493 [INFO    ] __main__: train step 11498: loss: 1.0100, policy_loss: 1.0131, value_loss: 0.6681
2024-07-11 16:47:43,702 [INFO    ] __main__: train step 11499: loss: 1.0100, policy_loss: 1.0130, value_loss: 0.6680
2024-07-11 16:47:43,904 [INFO    ] __main__: train step 11500: loss: 1.0100, policy_loss: 1.0130, value_loss: 0.6680
2024-07-11 16:47:44,103 [INFO    ] __main__: train step 11501: loss: 1.0100, policy_loss: 1.0130, value_loss: 0.6680
2024-07-11 16:47:44,321 [INFO    ] __main__: train step 11502: loss: 1.0100, policy_loss: 1.0129, value_loss: 0.6679
2024-07-11 16:47:45,915 [INFO    ] __main__: train step 11503: loss: 1.0100, policy_loss: 1.0129, value_loss: 0.6679
2024-07-11 16:47:46,093 [INFO    ] __main__: train step 11504: loss: 1.0100, policy_loss: 1.0129, value_loss: 0.6679
2024-07-11 16:47:46,297 [INFO    ] __main__: train step 11505: loss: 1.0100, policy_loss: 1.0128, value_loss: 0.6679
2024-07-11 16:47:46,507 [INFO    ] __main__: train step 11506: loss: 1.0100, policy_loss: 1.0128, value_loss: 0.6678
2024-07-11 16:47:46,711 [INFO    ] __main__: train step 11507: loss: 1.0100, policy_loss: 1.0128, value_loss: 0.6678
2024-07-11 16:47:46,912 [INFO    ] __main__: train step 11508: loss: 1.0100, policy_loss: 1.0127, value_loss: 0.6678
2024-07-11 16:47:48,367 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:47:48,762 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:47:48,822 [INFO    ] __main__: train step 11509: loss: 1.0100, policy_loss: 1.0127, value_loss: 0.6677
2024-07-11 16:47:48,990 [INFO    ] __main__: train step 11510: loss: 1.0100, policy_loss: 1.0126, value_loss: 0.6677
2024-07-11 16:47:49,188 [INFO    ] __main__: train step 11511: loss: 1.0099, policy_loss: 1.0126, value_loss: 0.6677
2024-07-11 16:47:49,390 [INFO    ] __main__: train step 11512: loss: 1.0099, policy_loss: 1.0126, value_loss: 0.6677
2024-07-11 16:47:49,601 [INFO    ] __main__: train step 11513: loss: 1.0099, policy_loss: 1.0125, value_loss: 0.6676
2024-07-11 16:47:49,787 [INFO    ] __main__: train step 11514: loss: 1.0099, policy_loss: 1.0125, value_loss: 0.6676
2024-07-11 16:47:49,996 [INFO    ] __main__: train step 11515: loss: 1.0099, policy_loss: 1.0125, value_loss: 0.6676
2024-07-11 16:47:50,206 [INFO    ] __main__: train step 11516: loss: 1.0099, policy_loss: 1.0124, value_loss: 0.6675
2024-07-11 16:47:50,415 [INFO    ] __main__: train step 11517: loss: 1.0099, policy_loss: 1.0124, value_loss: 0.6675
2024-07-11 16:47:50,635 [INFO    ] __main__: train step 11518: loss: 1.0099, policy_loss: 1.0124, value_loss: 0.6675
2024-07-11 16:47:50,851 [INFO    ] __main__: train step 11519: loss: 1.0099, policy_loss: 1.0123, value_loss: 0.6675
2024-07-11 16:47:51,068 [INFO    ] __main__: train step 11520: loss: 1.0099, policy_loss: 1.0123, value_loss: 0.6674
2024-07-11 16:47:51,262 [INFO    ] __main__: train step 11521: loss: 1.0099, policy_loss: 1.0123, value_loss: 0.6674
2024-07-11 16:47:51,465 [INFO    ] __main__: train step 11522: loss: 1.0099, policy_loss: 1.0122, value_loss: 0.6674
2024-07-11 16:47:51,675 [INFO    ] __main__: train step 11523: loss: 1.0099, policy_loss: 1.0122, value_loss: 0.6673
2024-07-11 16:47:51,873 [INFO    ] __main__: train step 11524: loss: 1.0099, policy_loss: 1.0122, value_loss: 0.6673
2024-07-11 16:47:52,077 [INFO    ] __main__: train step 11525: loss: 1.0099, policy_loss: 1.0121, value_loss: 0.6673
2024-07-11 16:47:53,523 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:47:53,985 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:47:54,044 [INFO    ] __main__: train step 11526: loss: 1.0099, policy_loss: 1.0121, value_loss: 0.6672
2024-07-11 16:47:54,224 [INFO    ] __main__: train step 11527: loss: 1.0099, policy_loss: 1.0121, value_loss: 0.6672
2024-07-11 16:47:54,418 [INFO    ] __main__: train step 11528: loss: 1.0098, policy_loss: 1.0120, value_loss: 0.6672
2024-07-11 16:47:54,620 [INFO    ] __main__: train step 11529: loss: 1.0098, policy_loss: 1.0120, value_loss: 0.6672
2024-07-11 16:47:54,831 [INFO    ] __main__: train step 11530: loss: 1.0098, policy_loss: 1.0120, value_loss: 0.6671
2024-07-11 16:47:55,029 [INFO    ] __main__: train step 11531: loss: 1.0098, policy_loss: 1.0119, value_loss: 0.6671
2024-07-11 16:47:55,267 [INFO    ] __main__: train step 11532: loss: 1.0098, policy_loss: 1.0119, value_loss: 0.6671
2024-07-11 16:47:55,525 [INFO    ] __main__: train step 11533: loss: 1.0098, policy_loss: 1.0119, value_loss: 0.6670
2024-07-11 16:47:55,725 [INFO    ] __main__: train step 11534: loss: 1.0098, policy_loss: 1.0118, value_loss: 0.6670
2024-07-11 16:47:55,929 [INFO    ] __main__: train step 11535: loss: 1.0098, policy_loss: 1.0118, value_loss: 0.6670
2024-07-11 16:47:56,147 [INFO    ] __main__: train step 11536: loss: 1.0098, policy_loss: 1.0117, value_loss: 0.6670
2024-07-11 16:47:56,371 [INFO    ] __main__: train step 11537: loss: 1.0098, policy_loss: 1.0117, value_loss: 0.6669
2024-07-11 16:47:56,566 [INFO    ] __main__: train step 11538: loss: 1.0098, policy_loss: 1.0117, value_loss: 0.6669
2024-07-11 16:47:56,776 [INFO    ] __main__: train step 11539: loss: 1.0098, policy_loss: 1.0116, value_loss: 0.6669
2024-07-11 16:47:56,983 [INFO    ] __main__: train step 11540: loss: 1.0098, policy_loss: 1.0116, value_loss: 0.6668
2024-07-11 16:47:57,191 [INFO    ] __main__: train step 11541: loss: 1.0098, policy_loss: 1.0116, value_loss: 0.6668
2024-07-11 16:47:57,406 [INFO    ] __main__: train step 11542: loss: 1.0098, policy_loss: 1.0115, value_loss: 0.6668
2024-07-11 16:47:58,837 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:47:59,212 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:47:59,271 [INFO    ] __main__: train step 11543: loss: 1.0098, policy_loss: 1.0115, value_loss: 0.6667
2024-07-11 16:47:59,466 [INFO    ] __main__: train step 11544: loss: 1.0097, policy_loss: 1.0115, value_loss: 0.6667
2024-07-11 16:47:59,698 [INFO    ] __main__: train step 11545: loss: 1.0097, policy_loss: 1.0114, value_loss: 0.6667
2024-07-11 16:47:59,910 [INFO    ] __main__: train step 11546: loss: 1.0097, policy_loss: 1.0114, value_loss: 0.6667
2024-07-11 16:48:00,112 [INFO    ] __main__: train step 11547: loss: 1.0097, policy_loss: 1.0114, value_loss: 0.6666
2024-07-11 16:48:00,305 [INFO    ] __main__: train step 11548: loss: 1.0097, policy_loss: 1.0113, value_loss: 0.6666
2024-07-11 16:48:00,509 [INFO    ] __main__: train step 11549: loss: 1.0097, policy_loss: 1.0113, value_loss: 0.6666
2024-07-11 16:48:00,717 [INFO    ] __main__: train step 11550: loss: 1.0097, policy_loss: 1.0113, value_loss: 0.6665
2024-07-11 16:48:00,928 [INFO    ] __main__: train step 11551: loss: 1.0097, policy_loss: 1.0112, value_loss: 0.6665
2024-07-11 16:48:01,125 [INFO    ] __main__: train step 11552: loss: 1.0097, policy_loss: 1.0112, value_loss: 0.6665
2024-07-11 16:48:01,323 [INFO    ] __main__: train step 11553: loss: 1.0097, policy_loss: 1.0112, value_loss: 0.6665
2024-07-11 16:48:01,522 [INFO    ] __main__: train step 11554: loss: 1.0097, policy_loss: 1.0111, value_loss: 0.6664
2024-07-11 16:48:01,730 [INFO    ] __main__: train step 11555: loss: 1.0097, policy_loss: 1.0111, value_loss: 0.6664
2024-07-11 16:48:01,937 [INFO    ] __main__: train step 11556: loss: 1.0097, policy_loss: 1.0111, value_loss: 0.6664
2024-07-11 16:48:02,151 [INFO    ] __main__: train step 11557: loss: 1.0097, policy_loss: 1.0110, value_loss: 0.6663
2024-07-11 16:48:02,374 [INFO    ] __main__: train step 11558: loss: 1.0097, policy_loss: 1.0110, value_loss: 0.6663
2024-07-11 16:48:02,610 [INFO    ] __main__: train step 11559: loss: 1.0097, policy_loss: 1.0110, value_loss: 0.6663
2024-07-11 16:48:04,074 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:48:04,461 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:48:04,519 [INFO    ] __main__: train step 11560: loss: 1.0097, policy_loss: 1.0109, value_loss: 0.6662
2024-07-11 16:48:04,696 [INFO    ] __main__: train step 11561: loss: 1.0097, policy_loss: 1.0109, value_loss: 0.6662
2024-07-11 16:48:04,926 [INFO    ] __main__: train step 11562: loss: 1.0096, policy_loss: 1.0109, value_loss: 0.6662
2024-07-11 16:48:05,146 [INFO    ] __main__: train step 11563: loss: 1.0096, policy_loss: 1.0108, value_loss: 0.6662
2024-07-11 16:48:05,382 [INFO    ] __main__: train step 11564: loss: 1.0096, policy_loss: 1.0108, value_loss: 0.6661
2024-07-11 16:48:05,595 [INFO    ] __main__: train step 11565: loss: 1.0096, policy_loss: 1.0108, value_loss: 0.6661
2024-07-11 16:48:05,804 [INFO    ] __main__: train step 11566: loss: 1.0096, policy_loss: 1.0107, value_loss: 0.6661
2024-07-11 16:48:06,018 [INFO    ] __main__: train step 11567: loss: 1.0096, policy_loss: 1.0107, value_loss: 0.6660
2024-07-11 16:48:06,211 [INFO    ] __main__: train step 11568: loss: 1.0096, policy_loss: 1.0107, value_loss: 0.6660
2024-07-11 16:48:06,421 [INFO    ] __main__: train step 11569: loss: 1.0096, policy_loss: 1.0106, value_loss: 0.6660
2024-07-11 16:48:06,626 [INFO    ] __main__: train step 11570: loss: 1.0096, policy_loss: 1.0106, value_loss: 0.6660
2024-07-11 16:48:06,827 [INFO    ] __main__: train step 11571: loss: 1.0096, policy_loss: 1.0106, value_loss: 0.6659
2024-07-11 16:48:07,031 [INFO    ] __main__: train step 11572: loss: 1.0096, policy_loss: 1.0105, value_loss: 0.6659
2024-07-11 16:48:07,233 [INFO    ] __main__: train step 11573: loss: 1.0096, policy_loss: 1.0105, value_loss: 0.6659
2024-07-11 16:48:07,440 [INFO    ] __main__: train step 11574: loss: 1.0096, policy_loss: 1.0104, value_loss: 0.6658
2024-07-11 16:48:07,655 [INFO    ] __main__: train step 11575: loss: 1.0096, policy_loss: 1.0104, value_loss: 0.6658
2024-07-11 16:48:07,857 [INFO    ] __main__: train step 11576: loss: 1.0096, policy_loss: 1.0104, value_loss: 0.6658
2024-07-11 16:48:09,274 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:48:09,645 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:48:09,700 [INFO    ] __main__: train step 11577: loss: 1.0096, policy_loss: 1.0103, value_loss: 0.6658
2024-07-11 16:48:09,877 [INFO    ] __main__: train step 11578: loss: 1.0096, policy_loss: 1.0103, value_loss: 0.6657
2024-07-11 16:48:10,079 [INFO    ] __main__: train step 11579: loss: 1.0096, policy_loss: 1.0103, value_loss: 0.6657
2024-07-11 16:48:10,292 [INFO    ] __main__: train step 11580: loss: 1.0096, policy_loss: 1.0102, value_loss: 0.6657
2024-07-11 16:48:10,498 [INFO    ] __main__: train step 11581: loss: 1.0096, policy_loss: 1.0102, value_loss: 0.6656
2024-07-11 16:48:10,701 [INFO    ] __main__: train step 11582: loss: 1.0095, policy_loss: 1.0102, value_loss: 0.6656
2024-07-11 16:48:10,895 [INFO    ] __main__: train step 11583: loss: 1.0095, policy_loss: 1.0101, value_loss: 0.6656
2024-07-11 16:48:11,104 [INFO    ] __main__: train step 11584: loss: 1.0095, policy_loss: 1.0101, value_loss: 0.6656
2024-07-11 16:48:11,317 [INFO    ] __main__: train step 11585: loss: 1.0095, policy_loss: 1.0101, value_loss: 0.6655
2024-07-11 16:48:11,555 [INFO    ] __main__: train step 11586: loss: 1.0095, policy_loss: 1.0100, value_loss: 0.6655
2024-07-11 16:48:11,795 [INFO    ] __main__: train step 11587: loss: 1.0095, policy_loss: 1.0100, value_loss: 0.6655
2024-07-11 16:48:12,028 [INFO    ] __main__: train step 11588: loss: 1.0095, policy_loss: 1.0100, value_loss: 0.6655
2024-07-11 16:48:12,232 [INFO    ] __main__: train step 11589: loss: 1.0095, policy_loss: 1.0099, value_loss: 0.6654
2024-07-11 16:48:12,436 [INFO    ] __main__: train step 11590: loss: 1.0095, policy_loss: 1.0099, value_loss: 0.6654
2024-07-11 16:48:12,645 [INFO    ] __main__: train step 11591: loss: 1.0095, policy_loss: 1.0099, value_loss: 0.6654
2024-07-11 16:48:12,861 [INFO    ] __main__: train step 11592: loss: 1.0095, policy_loss: 1.0098, value_loss: 0.6653
2024-07-11 16:48:13,056 [INFO    ] __main__: train step 11593: loss: 1.0095, policy_loss: 1.0098, value_loss: 0.6653
2024-07-11 16:48:14,503 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:48:14,870 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:48:14,926 [INFO    ] __main__: train step 11594: loss: 1.0095, policy_loss: 1.0098, value_loss: 0.6653
2024-07-11 16:48:15,106 [INFO    ] __main__: train step 11595: loss: 1.0095, policy_loss: 1.0097, value_loss: 0.6653
2024-07-11 16:48:15,308 [INFO    ] __main__: train step 11596: loss: 1.0095, policy_loss: 1.0097, value_loss: 0.6652
2024-07-11 16:48:15,517 [INFO    ] __main__: train step 11597: loss: 1.0095, policy_loss: 1.0097, value_loss: 0.6652
2024-07-11 16:48:15,733 [INFO    ] __main__: train step 11598: loss: 1.0095, policy_loss: 1.0096, value_loss: 0.6652
2024-07-11 16:48:15,931 [INFO    ] __main__: train step 11599: loss: 1.0095, policy_loss: 1.0096, value_loss: 0.6651
2024-07-11 16:48:16,130 [INFO    ] __main__: train step 11600: loss: 1.0095, policy_loss: 1.0096, value_loss: 0.6651
2024-07-11 16:48:16,334 [INFO    ] __main__: train step 11601: loss: 1.0095, policy_loss: 1.0095, value_loss: 0.6651
2024-07-11 16:48:16,548 [INFO    ] __main__: train step 11602: loss: 1.0095, policy_loss: 1.0095, value_loss: 0.6651
2024-07-11 16:48:18,183 [INFO    ] __main__: train step 11603: loss: 1.0095, policy_loss: 1.0095, value_loss: 0.6650
2024-07-11 16:48:18,371 [INFO    ] __main__: train step 11604: loss: 1.0094, policy_loss: 1.0094, value_loss: 0.6650
2024-07-11 16:48:18,571 [INFO    ] __main__: train step 11605: loss: 1.0094, policy_loss: 1.0094, value_loss: 0.6650
2024-07-11 16:48:18,776 [INFO    ] __main__: train step 11606: loss: 1.0094, policy_loss: 1.0094, value_loss: 0.6649
2024-07-11 16:48:18,979 [INFO    ] __main__: train step 11607: loss: 1.0094, policy_loss: 1.0093, value_loss: 0.6649
2024-07-11 16:48:19,184 [INFO    ] __main__: train step 11608: loss: 1.0094, policy_loss: 1.0093, value_loss: 0.6649
2024-07-11 16:48:19,397 [INFO    ] __main__: train step 11609: loss: 1.0094, policy_loss: 1.0093, value_loss: 0.6649
2024-07-11 16:48:19,596 [INFO    ] __main__: train step 11610: loss: 1.0094, policy_loss: 1.0092, value_loss: 0.6648
2024-07-11 16:48:21,033 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:48:21,449 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:48:21,514 [INFO    ] __main__: train step 11611: loss: 1.0094, policy_loss: 1.0092, value_loss: 0.6648
2024-07-11 16:48:21,687 [INFO    ] __main__: train step 11612: loss: 1.0094, policy_loss: 1.0092, value_loss: 0.6648
2024-07-11 16:48:21,889 [INFO    ] __main__: train step 11613: loss: 1.0094, policy_loss: 1.0091, value_loss: 0.6647
2024-07-11 16:48:22,102 [INFO    ] __main__: train step 11614: loss: 1.0094, policy_loss: 1.0091, value_loss: 0.6647
2024-07-11 16:48:22,300 [INFO    ] __main__: train step 11615: loss: 1.0094, policy_loss: 1.0091, value_loss: 0.6647
2024-07-11 16:48:22,501 [INFO    ] __main__: train step 11616: loss: 1.0094, policy_loss: 1.0090, value_loss: 0.6647
2024-07-11 16:48:22,706 [INFO    ] __main__: train step 11617: loss: 1.0094, policy_loss: 1.0090, value_loss: 0.6646
2024-07-11 16:48:22,917 [INFO    ] __main__: train step 11618: loss: 1.0094, policy_loss: 1.0090, value_loss: 0.6646
2024-07-11 16:48:23,129 [INFO    ] __main__: train step 11619: loss: 1.0094, policy_loss: 1.0089, value_loss: 0.6646
2024-07-11 16:48:23,338 [INFO    ] __main__: train step 11620: loss: 1.0094, policy_loss: 1.0089, value_loss: 0.6645
2024-07-11 16:48:23,539 [INFO    ] __main__: train step 11621: loss: 1.0094, policy_loss: 1.0089, value_loss: 0.6645
2024-07-11 16:48:23,740 [INFO    ] __main__: train step 11622: loss: 1.0094, policy_loss: 1.0088, value_loss: 0.6645
2024-07-11 16:48:23,958 [INFO    ] __main__: train step 11623: loss: 1.0094, policy_loss: 1.0088, value_loss: 0.6644
2024-07-11 16:48:24,151 [INFO    ] __main__: train step 11624: loss: 1.0094, policy_loss: 1.0088, value_loss: 0.6644
2024-07-11 16:48:24,352 [INFO    ] __main__: train step 11625: loss: 1.0093, policy_loss: 1.0087, value_loss: 0.6644
2024-07-11 16:48:24,564 [INFO    ] __main__: train step 11626: loss: 1.0093, policy_loss: 1.0087, value_loss: 0.6644
2024-07-11 16:48:24,772 [INFO    ] __main__: train step 11627: loss: 1.0093, policy_loss: 1.0087, value_loss: 0.6643
2024-07-11 16:48:26,214 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:48:26,585 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:48:26,642 [INFO    ] __main__: train step 11628: loss: 1.0093, policy_loss: 1.0086, value_loss: 0.6643
2024-07-11 16:48:26,827 [INFO    ] __main__: train step 11629: loss: 1.0093, policy_loss: 1.0086, value_loss: 0.6643
2024-07-11 16:48:27,018 [INFO    ] __main__: train step 11630: loss: 1.0093, policy_loss: 1.0086, value_loss: 0.6642
2024-07-11 16:48:27,232 [INFO    ] __main__: train step 11631: loss: 1.0093, policy_loss: 1.0085, value_loss: 0.6642
2024-07-11 16:48:27,446 [INFO    ] __main__: train step 11632: loss: 1.0093, policy_loss: 1.0085, value_loss: 0.6642
2024-07-11 16:48:27,649 [INFO    ] __main__: train step 11633: loss: 1.0093, policy_loss: 1.0085, value_loss: 0.6642
2024-07-11 16:48:27,885 [INFO    ] __main__: train step 11634: loss: 1.0093, policy_loss: 1.0084, value_loss: 0.6641
2024-07-11 16:48:28,090 [INFO    ] __main__: train step 11635: loss: 1.0093, policy_loss: 1.0084, value_loss: 0.6641
2024-07-11 16:48:28,306 [INFO    ] __main__: train step 11636: loss: 1.0093, policy_loss: 1.0084, value_loss: 0.6641
2024-07-11 16:48:28,521 [INFO    ] __main__: train step 11637: loss: 1.0093, policy_loss: 1.0083, value_loss: 0.6641
2024-07-11 16:48:28,729 [INFO    ] __main__: train step 11638: loss: 1.0093, policy_loss: 1.0083, value_loss: 0.6640
2024-07-11 16:48:28,931 [INFO    ] __main__: train step 11639: loss: 1.0093, policy_loss: 1.0083, value_loss: 0.6640
2024-07-11 16:48:29,135 [INFO    ] __main__: train step 11640: loss: 1.0093, policy_loss: 1.0082, value_loss: 0.6640
2024-07-11 16:48:29,326 [INFO    ] __main__: train step 11641: loss: 1.0093, policy_loss: 1.0082, value_loss: 0.6639
2024-07-11 16:48:29,543 [INFO    ] __main__: train step 11642: loss: 1.0093, policy_loss: 1.0082, value_loss: 0.6639
2024-07-11 16:48:29,786 [INFO    ] __main__: train step 11643: loss: 1.0093, policy_loss: 1.0081, value_loss: 0.6639
2024-07-11 16:48:29,987 [INFO    ] __main__: train step 11644: loss: 1.0093, policy_loss: 1.0081, value_loss: 0.6639
2024-07-11 16:48:31,429 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:48:31,783 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:48:31,842 [INFO    ] __main__: train step 11645: loss: 1.0093, policy_loss: 1.0081, value_loss: 0.6638
2024-07-11 16:48:32,017 [INFO    ] __main__: train step 11646: loss: 1.0093, policy_loss: 1.0081, value_loss: 0.6638
2024-07-11 16:48:32,240 [INFO    ] __main__: train step 11647: loss: 1.0093, policy_loss: 1.0080, value_loss: 0.6638
2024-07-11 16:48:32,463 [INFO    ] __main__: train step 11648: loss: 1.0092, policy_loss: 1.0080, value_loss: 0.6637
2024-07-11 16:48:32,685 [INFO    ] __main__: train step 11649: loss: 1.0092, policy_loss: 1.0080, value_loss: 0.6637
2024-07-11 16:48:32,886 [INFO    ] __main__: train step 11650: loss: 1.0092, policy_loss: 1.0079, value_loss: 0.6637
2024-07-11 16:48:33,089 [INFO    ] __main__: train step 11651: loss: 1.0092, policy_loss: 1.0079, value_loss: 0.6636
2024-07-11 16:48:33,294 [INFO    ] __main__: train step 11652: loss: 1.0092, policy_loss: 1.0079, value_loss: 0.6636
2024-07-11 16:48:33,496 [INFO    ] __main__: train step 11653: loss: 1.0092, policy_loss: 1.0078, value_loss: 0.6636
2024-07-11 16:48:33,700 [INFO    ] __main__: train step 11654: loss: 1.0092, policy_loss: 1.0078, value_loss: 0.6636
2024-07-11 16:48:33,909 [INFO    ] __main__: train step 11655: loss: 1.0092, policy_loss: 1.0078, value_loss: 0.6635
2024-07-11 16:48:34,103 [INFO    ] __main__: train step 11656: loss: 1.0092, policy_loss: 1.0077, value_loss: 0.6635
2024-07-11 16:48:34,312 [INFO    ] __main__: train step 11657: loss: 1.0092, policy_loss: 1.0077, value_loss: 0.6635
2024-07-11 16:48:34,515 [INFO    ] __main__: train step 11658: loss: 1.0092, policy_loss: 1.0077, value_loss: 0.6634
2024-07-11 16:48:34,720 [INFO    ] __main__: train step 11659: loss: 1.0092, policy_loss: 1.0076, value_loss: 0.6634
2024-07-11 16:48:34,919 [INFO    ] __main__: train step 11660: loss: 1.0092, policy_loss: 1.0076, value_loss: 0.6634
2024-07-11 16:48:35,134 [INFO    ] __main__: train step 11661: loss: 1.0092, policy_loss: 1.0076, value_loss: 0.6634
2024-07-11 16:48:36,581 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:48:36,980 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:48:37,042 [INFO    ] __main__: train step 11662: loss: 1.0092, policy_loss: 1.0075, value_loss: 0.6633
2024-07-11 16:48:37,210 [INFO    ] __main__: train step 11663: loss: 1.0092, policy_loss: 1.0075, value_loss: 0.6633
2024-07-11 16:48:37,417 [INFO    ] __main__: train step 11664: loss: 1.0092, policy_loss: 1.0075, value_loss: 0.6633
2024-07-11 16:48:37,620 [INFO    ] __main__: train step 11665: loss: 1.0092, policy_loss: 1.0074, value_loss: 0.6632
2024-07-11 16:48:37,827 [INFO    ] __main__: train step 11666: loss: 1.0092, policy_loss: 1.0074, value_loss: 0.6632
2024-07-11 16:48:38,057 [INFO    ] __main__: train step 11667: loss: 1.0092, policy_loss: 1.0074, value_loss: 0.6632
2024-07-11 16:48:38,286 [INFO    ] __main__: train step 11668: loss: 1.0092, policy_loss: 1.0073, value_loss: 0.6632
2024-07-11 16:48:38,528 [INFO    ] __main__: train step 11669: loss: 1.0092, policy_loss: 1.0073, value_loss: 0.6631
2024-07-11 16:48:38,767 [INFO    ] __main__: train step 11670: loss: 1.0092, policy_loss: 1.0073, value_loss: 0.6631
2024-07-11 16:48:39,014 [INFO    ] __main__: train step 11671: loss: 1.0092, policy_loss: 1.0072, value_loss: 0.6631
2024-07-11 16:48:39,232 [INFO    ] __main__: train step 11672: loss: 1.0091, policy_loss: 1.0072, value_loss: 0.6631
2024-07-11 16:48:39,439 [INFO    ] __main__: train step 11673: loss: 1.0091, policy_loss: 1.0072, value_loss: 0.6630
2024-07-11 16:48:39,633 [INFO    ] __main__: train step 11674: loss: 1.0091, policy_loss: 1.0071, value_loss: 0.6630
2024-07-11 16:48:39,842 [INFO    ] __main__: train step 11675: loss: 1.0091, policy_loss: 1.0071, value_loss: 0.6630
2024-07-11 16:48:40,041 [INFO    ] __main__: train step 11676: loss: 1.0091, policy_loss: 1.0071, value_loss: 0.6629
2024-07-11 16:48:40,240 [INFO    ] __main__: train step 11677: loss: 1.0091, policy_loss: 1.0070, value_loss: 0.6629
2024-07-11 16:48:40,447 [INFO    ] __main__: train step 11678: loss: 1.0091, policy_loss: 1.0070, value_loss: 0.6629
2024-07-11 16:48:41,889 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:48:42,305 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:48:42,369 [INFO    ] __main__: train step 11679: loss: 1.0091, policy_loss: 1.0070, value_loss: 0.6629
2024-07-11 16:48:42,546 [INFO    ] __main__: train step 11680: loss: 1.0091, policy_loss: 1.0069, value_loss: 0.6628
2024-07-11 16:48:42,753 [INFO    ] __main__: train step 11681: loss: 1.0091, policy_loss: 1.0069, value_loss: 0.6628
2024-07-11 16:48:43,002 [INFO    ] __main__: train step 11682: loss: 1.0091, policy_loss: 1.0069, value_loss: 0.6628
2024-07-11 16:48:43,200 [INFO    ] __main__: train step 11683: loss: 1.0091, policy_loss: 1.0068, value_loss: 0.6627
2024-07-11 16:48:43,410 [INFO    ] __main__: train step 11684: loss: 1.0091, policy_loss: 1.0068, value_loss: 0.6627
2024-07-11 16:48:43,609 [INFO    ] __main__: train step 11685: loss: 1.0091, policy_loss: 1.0068, value_loss: 0.6627
2024-07-11 16:48:43,824 [INFO    ] __main__: train step 11686: loss: 1.0091, policy_loss: 1.0067, value_loss: 0.6627
2024-07-11 16:48:44,026 [INFO    ] __main__: train step 11687: loss: 1.0091, policy_loss: 1.0067, value_loss: 0.6626
2024-07-11 16:48:44,234 [INFO    ] __main__: train step 11688: loss: 1.0091, policy_loss: 1.0067, value_loss: 0.6626
2024-07-11 16:48:44,443 [INFO    ] __main__: train step 11689: loss: 1.0091, policy_loss: 1.0067, value_loss: 0.6626
2024-07-11 16:48:44,648 [INFO    ] __main__: train step 11690: loss: 1.0091, policy_loss: 1.0066, value_loss: 0.6626
2024-07-11 16:48:44,884 [INFO    ] __main__: train step 11691: loss: 1.0091, policy_loss: 1.0066, value_loss: 0.6625
2024-07-11 16:48:45,069 [INFO    ] __main__: train step 11692: loss: 1.0091, policy_loss: 1.0066, value_loss: 0.6625
2024-07-11 16:48:45,258 [INFO    ] __main__: train step 11693: loss: 1.0091, policy_loss: 1.0065, value_loss: 0.6625
2024-07-11 16:48:45,459 [INFO    ] __main__: train step 11694: loss: 1.0091, policy_loss: 1.0065, value_loss: 0.6624
2024-07-11 16:48:45,671 [INFO    ] __main__: train step 11695: loss: 1.0091, policy_loss: 1.0065, value_loss: 0.6624
2024-07-11 16:48:47,112 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:48:47,545 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:48:47,601 [INFO    ] __main__: train step 11696: loss: 1.0090, policy_loss: 1.0064, value_loss: 0.6624
2024-07-11 16:48:47,788 [INFO    ] __main__: train step 11697: loss: 1.0090, policy_loss: 1.0064, value_loss: 0.6624
2024-07-11 16:48:47,979 [INFO    ] __main__: train step 11698: loss: 1.0090, policy_loss: 1.0064, value_loss: 0.6623
2024-07-11 16:48:48,173 [INFO    ] __main__: train step 11699: loss: 1.0090, policy_loss: 1.0063, value_loss: 0.6623
2024-07-11 16:48:48,377 [INFO    ] __main__: train step 11700: loss: 1.0090, policy_loss: 1.0063, value_loss: 0.6623
2024-07-11 16:48:48,585 [INFO    ] __main__: train step 11701: loss: 1.0090, policy_loss: 1.0063, value_loss: 0.6622
2024-07-11 16:48:48,792 [INFO    ] __main__: train step 11702: loss: 1.0090, policy_loss: 1.0062, value_loss: 0.6622
2024-07-11 16:48:48,988 [INFO    ] __main__: train step 11703: loss: 1.0090, policy_loss: 1.0062, value_loss: 0.6622
2024-07-11 16:48:49,200 [INFO    ] __main__: train step 11704: loss: 1.0090, policy_loss: 1.0062, value_loss: 0.6622
2024-07-11 16:48:50,777 [INFO    ] __main__: train step 11705: loss: 1.0090, policy_loss: 1.0061, value_loss: 0.6621
2024-07-11 16:48:51,000 [INFO    ] __main__: train step 11706: loss: 1.0090, policy_loss: 1.0061, value_loss: 0.6621
2024-07-11 16:48:51,202 [INFO    ] __main__: train step 11707: loss: 1.0090, policy_loss: 1.0061, value_loss: 0.6621
2024-07-11 16:48:51,407 [INFO    ] __main__: train step 11708: loss: 1.0090, policy_loss: 1.0060, value_loss: 0.6620
2024-07-11 16:48:51,602 [INFO    ] __main__: train step 11709: loss: 1.0090, policy_loss: 1.0060, value_loss: 0.6620
2024-07-11 16:48:51,814 [INFO    ] __main__: train step 11710: loss: 1.0090, policy_loss: 1.0060, value_loss: 0.6620
2024-07-11 16:48:52,011 [INFO    ] __main__: train step 11711: loss: 1.0090, policy_loss: 1.0059, value_loss: 0.6620
2024-07-11 16:48:52,217 [INFO    ] __main__: train step 11712: loss: 1.0090, policy_loss: 1.0059, value_loss: 0.6619
2024-07-11 16:48:53,649 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:48:53,995 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:48:54,051 [INFO    ] __main__: train step 11713: loss: 1.0090, policy_loss: 1.0059, value_loss: 0.6619
2024-07-11 16:48:54,228 [INFO    ] __main__: train step 11714: loss: 1.0090, policy_loss: 1.0058, value_loss: 0.6619
2024-07-11 16:48:54,431 [INFO    ] __main__: train step 11715: loss: 1.0090, policy_loss: 1.0058, value_loss: 0.6618
2024-07-11 16:48:54,637 [INFO    ] __main__: train step 11716: loss: 1.0090, policy_loss: 1.0058, value_loss: 0.6618
2024-07-11 16:48:54,851 [INFO    ] __main__: train step 11717: loss: 1.0090, policy_loss: 1.0058, value_loss: 0.6618
2024-07-11 16:48:55,082 [INFO    ] __main__: train step 11718: loss: 1.0090, policy_loss: 1.0057, value_loss: 0.6618
2024-07-11 16:48:55,290 [INFO    ] __main__: train step 11719: loss: 1.0090, policy_loss: 1.0057, value_loss: 0.6617
2024-07-11 16:48:55,531 [INFO    ] __main__: train step 11720: loss: 1.0089, policy_loss: 1.0057, value_loss: 0.6617
2024-07-11 16:48:55,734 [INFO    ] __main__: train step 11721: loss: 1.0089, policy_loss: 1.0056, value_loss: 0.6617
2024-07-11 16:48:55,979 [INFO    ] __main__: train step 11722: loss: 1.0089, policy_loss: 1.0056, value_loss: 0.6616
2024-07-11 16:48:56,184 [INFO    ] __main__: train step 11723: loss: 1.0089, policy_loss: 1.0056, value_loss: 0.6616
2024-07-11 16:48:56,433 [INFO    ] __main__: train step 11724: loss: 1.0089, policy_loss: 1.0055, value_loss: 0.6616
2024-07-11 16:48:56,669 [INFO    ] __main__: train step 11725: loss: 1.0089, policy_loss: 1.0055, value_loss: 0.6616
2024-07-11 16:48:56,914 [INFO    ] __main__: train step 11726: loss: 1.0089, policy_loss: 1.0055, value_loss: 0.6615
2024-07-11 16:48:57,149 [INFO    ] __main__: train step 11727: loss: 1.0089, policy_loss: 1.0054, value_loss: 0.6615
2024-07-11 16:48:57,377 [INFO    ] __main__: train step 11728: loss: 1.0089, policy_loss: 1.0054, value_loss: 0.6615
2024-07-11 16:48:57,584 [INFO    ] __main__: train step 11729: loss: 1.0089, policy_loss: 1.0054, value_loss: 0.6614
2024-07-11 16:48:59,025 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:48:59,471 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:48:59,533 [INFO    ] __main__: train step 11730: loss: 1.0089, policy_loss: 1.0053, value_loss: 0.6614
2024-07-11 16:48:59,705 [INFO    ] __main__: train step 11731: loss: 1.0089, policy_loss: 1.0053, value_loss: 0.6614
2024-07-11 16:48:59,926 [INFO    ] __main__: train step 11732: loss: 1.0089, policy_loss: 1.0053, value_loss: 0.6614
2024-07-11 16:49:00,134 [INFO    ] __main__: train step 11733: loss: 1.0089, policy_loss: 1.0053, value_loss: 0.6613
2024-07-11 16:49:00,351 [INFO    ] __main__: train step 11734: loss: 1.0089, policy_loss: 1.0052, value_loss: 0.6613
2024-07-11 16:49:00,591 [INFO    ] __main__: train step 11735: loss: 1.0089, policy_loss: 1.0052, value_loss: 0.6613
2024-07-11 16:49:00,825 [INFO    ] __main__: train step 11736: loss: 1.0089, policy_loss: 1.0052, value_loss: 0.6613
2024-07-11 16:49:01,028 [INFO    ] __main__: train step 11737: loss: 1.0089, policy_loss: 1.0051, value_loss: 0.6612
2024-07-11 16:49:01,230 [INFO    ] __main__: train step 11738: loss: 1.0089, policy_loss: 1.0051, value_loss: 0.6612
2024-07-11 16:49:01,434 [INFO    ] __main__: train step 11739: loss: 1.0089, policy_loss: 1.0051, value_loss: 0.6612
2024-07-11 16:49:01,641 [INFO    ] __main__: train step 11740: loss: 1.0089, policy_loss: 1.0050, value_loss: 0.6611
2024-07-11 16:49:01,854 [INFO    ] __main__: train step 11741: loss: 1.0089, policy_loss: 1.0050, value_loss: 0.6611
2024-07-11 16:49:02,102 [INFO    ] __main__: train step 11742: loss: 1.0089, policy_loss: 1.0050, value_loss: 0.6611
2024-07-11 16:49:02,299 [INFO    ] __main__: train step 11743: loss: 1.0089, policy_loss: 1.0049, value_loss: 0.6610
2024-07-11 16:49:02,511 [INFO    ] __main__: train step 11744: loss: 1.0089, policy_loss: 1.0049, value_loss: 0.6610
2024-07-11 16:49:02,761 [INFO    ] __main__: train step 11745: loss: 1.0089, policy_loss: 1.0049, value_loss: 0.6610
2024-07-11 16:49:03,016 [INFO    ] __main__: train step 11746: loss: 1.0089, policy_loss: 1.0048, value_loss: 0.6610
2024-07-11 16:49:04,456 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:49:04,889 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:49:04,944 [INFO    ] __main__: train step 11747: loss: 1.0089, policy_loss: 1.0048, value_loss: 0.6609
2024-07-11 16:49:05,118 [INFO    ] __main__: train step 11748: loss: 1.0089, policy_loss: 1.0048, value_loss: 0.6609
2024-07-11 16:49:05,358 [INFO    ] __main__: train step 11749: loss: 1.0089, policy_loss: 1.0048, value_loss: 0.6609
2024-07-11 16:49:05,581 [INFO    ] __main__: train step 11750: loss: 1.0089, policy_loss: 1.0047, value_loss: 0.6609
2024-07-11 16:49:05,809 [INFO    ] __main__: train step 11751: loss: 1.0088, policy_loss: 1.0047, value_loss: 0.6608
2024-07-11 16:49:06,009 [INFO    ] __main__: train step 11752: loss: 1.0088, policy_loss: 1.0047, value_loss: 0.6608
2024-07-11 16:49:06,201 [INFO    ] __main__: train step 11753: loss: 1.0088, policy_loss: 1.0046, value_loss: 0.6608
2024-07-11 16:49:06,403 [INFO    ] __main__: train step 11754: loss: 1.0088, policy_loss: 1.0046, value_loss: 0.6607
2024-07-11 16:49:06,614 [INFO    ] __main__: train step 11755: loss: 1.0088, policy_loss: 1.0046, value_loss: 0.6607
2024-07-11 16:49:06,816 [INFO    ] __main__: train step 11756: loss: 1.0088, policy_loss: 1.0045, value_loss: 0.6607
2024-07-11 16:49:07,013 [INFO    ] __main__: train step 11757: loss: 1.0088, policy_loss: 1.0045, value_loss: 0.6607
2024-07-11 16:49:07,225 [INFO    ] __main__: train step 11758: loss: 1.0088, policy_loss: 1.0045, value_loss: 0.6606
2024-07-11 16:49:07,424 [INFO    ] __main__: train step 11759: loss: 1.0088, policy_loss: 1.0044, value_loss: 0.6606
2024-07-11 16:49:07,659 [INFO    ] __main__: train step 11760: loss: 1.0088, policy_loss: 1.0044, value_loss: 0.6606
2024-07-11 16:49:07,860 [INFO    ] __main__: train step 11761: loss: 1.0088, policy_loss: 1.0044, value_loss: 0.6605
2024-07-11 16:49:08,065 [INFO    ] __main__: train step 11762: loss: 1.0088, policy_loss: 1.0043, value_loss: 0.6605
2024-07-11 16:49:08,279 [INFO    ] __main__: train step 11763: loss: 1.0088, policy_loss: 1.0043, value_loss: 0.6605
2024-07-11 16:49:09,758 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:49:10,186 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:49:10,252 [INFO    ] __main__: train step 11764: loss: 1.0088, policy_loss: 1.0043, value_loss: 0.6605
2024-07-11 16:49:10,438 [INFO    ] __main__: train step 11765: loss: 1.0088, policy_loss: 1.0043, value_loss: 0.6604
2024-07-11 16:49:10,639 [INFO    ] __main__: train step 11766: loss: 1.0088, policy_loss: 1.0042, value_loss: 0.6604
2024-07-11 16:49:10,838 [INFO    ] __main__: train step 11767: loss: 1.0088, policy_loss: 1.0042, value_loss: 0.6604
2024-07-11 16:49:11,038 [INFO    ] __main__: train step 11768: loss: 1.0088, policy_loss: 1.0042, value_loss: 0.6603
2024-07-11 16:49:11,251 [INFO    ] __main__: train step 11769: loss: 1.0088, policy_loss: 1.0041, value_loss: 0.6603
2024-07-11 16:49:11,456 [INFO    ] __main__: train step 11770: loss: 1.0088, policy_loss: 1.0041, value_loss: 0.6603
2024-07-11 16:49:11,694 [INFO    ] __main__: train step 11771: loss: 1.0088, policy_loss: 1.0041, value_loss: 0.6603
2024-07-11 16:49:11,936 [INFO    ] __main__: train step 11772: loss: 1.0088, policy_loss: 1.0040, value_loss: 0.6602
2024-07-11 16:49:12,162 [INFO    ] __main__: train step 11773: loss: 1.0088, policy_loss: 1.0040, value_loss: 0.6602
2024-07-11 16:49:12,361 [INFO    ] __main__: train step 11774: loss: 1.0088, policy_loss: 1.0040, value_loss: 0.6602
2024-07-11 16:49:12,571 [INFO    ] __main__: train step 11775: loss: 1.0088, policy_loss: 1.0039, value_loss: 0.6602
2024-07-11 16:49:12,779 [INFO    ] __main__: train step 11776: loss: 1.0088, policy_loss: 1.0039, value_loss: 0.6601
2024-07-11 16:49:12,983 [INFO    ] __main__: train step 11777: loss: 1.0088, policy_loss: 1.0039, value_loss: 0.6601
2024-07-11 16:49:13,188 [INFO    ] __main__: train step 11778: loss: 1.0088, policy_loss: 1.0039, value_loss: 0.6601
2024-07-11 16:49:13,387 [INFO    ] __main__: train step 11779: loss: 1.0088, policy_loss: 1.0038, value_loss: 0.6600
2024-07-11 16:49:13,588 [INFO    ] __main__: train step 11780: loss: 1.0088, policy_loss: 1.0038, value_loss: 0.6600
2024-07-11 16:49:15,019 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:49:15,451 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:49:15,511 [INFO    ] __main__: train step 11781: loss: 1.0088, policy_loss: 1.0038, value_loss: 0.6600
2024-07-11 16:49:15,685 [INFO    ] __main__: train step 11782: loss: 1.0088, policy_loss: 1.0037, value_loss: 0.6600
2024-07-11 16:49:15,891 [INFO    ] __main__: train step 11783: loss: 1.0087, policy_loss: 1.0037, value_loss: 0.6599
2024-07-11 16:49:16,100 [INFO    ] __main__: train step 11784: loss: 1.0087, policy_loss: 1.0037, value_loss: 0.6599
2024-07-11 16:49:16,301 [INFO    ] __main__: train step 11785: loss: 1.0087, policy_loss: 1.0036, value_loss: 0.6599
2024-07-11 16:49:16,505 [INFO    ] __main__: train step 11786: loss: 1.0087, policy_loss: 1.0036, value_loss: 0.6598
2024-07-11 16:49:16,714 [INFO    ] __main__: train step 11787: loss: 1.0087, policy_loss: 1.0036, value_loss: 0.6598
2024-07-11 16:49:16,945 [INFO    ] __main__: train step 11788: loss: 1.0087, policy_loss: 1.0036, value_loss: 0.6598
2024-07-11 16:49:17,160 [INFO    ] __main__: train step 11789: loss: 1.0087, policy_loss: 1.0035, value_loss: 0.6598
2024-07-11 16:49:17,396 [INFO    ] __main__: train step 11790: loss: 1.0087, policy_loss: 1.0035, value_loss: 0.6597
2024-07-11 16:49:17,626 [INFO    ] __main__: train step 11791: loss: 1.0087, policy_loss: 1.0035, value_loss: 0.6597
2024-07-11 16:49:17,832 [INFO    ] __main__: train step 11792: loss: 1.0087, policy_loss: 1.0034, value_loss: 0.6597
2024-07-11 16:49:18,031 [INFO    ] __main__: train step 11793: loss: 1.0087, policy_loss: 1.0034, value_loss: 0.6596
2024-07-11 16:49:18,233 [INFO    ] __main__: train step 11794: loss: 1.0087, policy_loss: 1.0034, value_loss: 0.6596
2024-07-11 16:49:18,443 [INFO    ] __main__: train step 11795: loss: 1.0087, policy_loss: 1.0033, value_loss: 0.6596
2024-07-11 16:49:18,671 [INFO    ] __main__: train step 11796: loss: 1.0087, policy_loss: 1.0033, value_loss: 0.6596
2024-07-11 16:49:18,880 [INFO    ] __main__: train step 11797: loss: 1.0087, policy_loss: 1.0033, value_loss: 0.6595
2024-07-11 16:49:20,309 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:49:20,749 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:49:20,810 [INFO    ] __main__: train step 11798: loss: 1.0087, policy_loss: 1.0032, value_loss: 0.6595
2024-07-11 16:49:20,998 [INFO    ] __main__: train step 11799: loss: 1.0087, policy_loss: 1.0032, value_loss: 0.6595
2024-07-11 16:49:21,205 [INFO    ] __main__: train step 11800: loss: 1.0087, policy_loss: 1.0032, value_loss: 0.6595
2024-07-11 16:49:21,402 [INFO    ] __main__: train step 11801: loss: 1.0087, policy_loss: 1.0032, value_loss: 0.6594
2024-07-11 16:49:21,614 [INFO    ] __main__: train step 11802: loss: 1.0087, policy_loss: 1.0031, value_loss: 0.6594
2024-07-11 16:49:21,814 [INFO    ] __main__: train step 11803: loss: 1.0087, policy_loss: 1.0031, value_loss: 0.6594
2024-07-11 16:49:22,011 [INFO    ] __main__: train step 11804: loss: 1.0087, policy_loss: 1.0031, value_loss: 0.6593
2024-07-11 16:49:22,218 [INFO    ] __main__: train step 11805: loss: 1.0087, policy_loss: 1.0030, value_loss: 0.6593
2024-07-11 16:49:23,762 [INFO    ] __main__: train step 11806: loss: 1.0087, policy_loss: 1.0030, value_loss: 0.6593
2024-07-11 16:49:23,978 [INFO    ] __main__: train step 11807: loss: 1.0087, policy_loss: 1.0030, value_loss: 0.6593
2024-07-11 16:49:24,184 [INFO    ] __main__: train step 11808: loss: 1.0087, policy_loss: 1.0029, value_loss: 0.6592
2024-07-11 16:49:24,391 [INFO    ] __main__: train step 11809: loss: 1.0087, policy_loss: 1.0029, value_loss: 0.6592
2024-07-11 16:49:24,601 [INFO    ] __main__: train step 11810: loss: 1.0087, policy_loss: 1.0029, value_loss: 0.6592
2024-07-11 16:49:24,822 [INFO    ] __main__: train step 11811: loss: 1.0087, policy_loss: 1.0028, value_loss: 0.6591
2024-07-11 16:49:25,055 [INFO    ] __main__: train step 11812: loss: 1.0087, policy_loss: 1.0028, value_loss: 0.6591
2024-07-11 16:49:25,255 [INFO    ] __main__: train step 11813: loss: 1.0087, policy_loss: 1.0028, value_loss: 0.6591
2024-07-11 16:49:25,472 [INFO    ] __main__: train step 11814: loss: 1.0087, policy_loss: 1.0028, value_loss: 0.6591
2024-07-11 16:49:26,922 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:49:27,385 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:49:27,444 [INFO    ] __main__: train step 11815: loss: 1.0086, policy_loss: 1.0027, value_loss: 0.6590
2024-07-11 16:49:27,622 [INFO    ] __main__: train step 11816: loss: 1.0086, policy_loss: 1.0027, value_loss: 0.6590
2024-07-11 16:49:27,836 [INFO    ] __main__: train step 11817: loss: 1.0086, policy_loss: 1.0027, value_loss: 0.6590
2024-07-11 16:49:28,041 [INFO    ] __main__: train step 11818: loss: 1.0086, policy_loss: 1.0026, value_loss: 0.6589
2024-07-11 16:49:28,235 [INFO    ] __main__: train step 11819: loss: 1.0086, policy_loss: 1.0026, value_loss: 0.6589
2024-07-11 16:49:28,439 [INFO    ] __main__: train step 11820: loss: 1.0086, policy_loss: 1.0026, value_loss: 0.6589
2024-07-11 16:49:28,641 [INFO    ] __main__: train step 11821: loss: 1.0086, policy_loss: 1.0025, value_loss: 0.6589
2024-07-11 16:49:28,853 [INFO    ] __main__: train step 11822: loss: 1.0086, policy_loss: 1.0025, value_loss: 0.6588
2024-07-11 16:49:29,049 [INFO    ] __main__: train step 11823: loss: 1.0086, policy_loss: 1.0025, value_loss: 0.6588
2024-07-11 16:49:29,256 [INFO    ] __main__: train step 11824: loss: 1.0086, policy_loss: 1.0025, value_loss: 0.6588
2024-07-11 16:49:29,462 [INFO    ] __main__: train step 11825: loss: 1.0086, policy_loss: 1.0024, value_loss: 0.6588
2024-07-11 16:49:29,670 [INFO    ] __main__: train step 11826: loss: 1.0086, policy_loss: 1.0024, value_loss: 0.6587
2024-07-11 16:49:29,880 [INFO    ] __main__: train step 11827: loss: 1.0086, policy_loss: 1.0024, value_loss: 0.6587
2024-07-11 16:49:30,081 [INFO    ] __main__: train step 11828: loss: 1.0086, policy_loss: 1.0023, value_loss: 0.6587
2024-07-11 16:49:30,288 [INFO    ] __main__: train step 11829: loss: 1.0086, policy_loss: 1.0023, value_loss: 0.6586
2024-07-11 16:49:30,489 [INFO    ] __main__: train step 11830: loss: 1.0086, policy_loss: 1.0023, value_loss: 0.6586
2024-07-11 16:49:30,699 [INFO    ] __main__: train step 11831: loss: 1.0086, policy_loss: 1.0022, value_loss: 0.6586
2024-07-11 16:49:32,144 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:49:32,592 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:49:32,652 [INFO    ] __main__: train step 11832: loss: 1.0086, policy_loss: 1.0022, value_loss: 0.6586
2024-07-11 16:49:32,836 [INFO    ] __main__: train step 11833: loss: 1.0086, policy_loss: 1.0022, value_loss: 0.6585
2024-07-11 16:49:33,063 [INFO    ] __main__: train step 11834: loss: 1.0086, policy_loss: 1.0022, value_loss: 0.6585
2024-07-11 16:49:33,264 [INFO    ] __main__: train step 11835: loss: 1.0086, policy_loss: 1.0021, value_loss: 0.6585
2024-07-11 16:49:33,459 [INFO    ] __main__: train step 11836: loss: 1.0086, policy_loss: 1.0021, value_loss: 0.6584
2024-07-11 16:49:33,658 [INFO    ] __main__: train step 11837: loss: 1.0086, policy_loss: 1.0021, value_loss: 0.6584
2024-07-11 16:49:33,867 [INFO    ] __main__: train step 11838: loss: 1.0086, policy_loss: 1.0020, value_loss: 0.6584
2024-07-11 16:49:34,093 [INFO    ] __main__: train step 11839: loss: 1.0086, policy_loss: 1.0020, value_loss: 0.6584
2024-07-11 16:49:34,291 [INFO    ] __main__: train step 11840: loss: 1.0086, policy_loss: 1.0020, value_loss: 0.6583
2024-07-11 16:49:34,505 [INFO    ] __main__: train step 11841: loss: 1.0086, policy_loss: 1.0020, value_loss: 0.6583
2024-07-11 16:49:34,695 [INFO    ] __main__: train step 11842: loss: 1.0086, policy_loss: 1.0019, value_loss: 0.6583
2024-07-11 16:49:34,899 [INFO    ] __main__: train step 11843: loss: 1.0086, policy_loss: 1.0019, value_loss: 0.6582
2024-07-11 16:49:35,124 [INFO    ] __main__: train step 11844: loss: 1.0086, policy_loss: 1.0019, value_loss: 0.6582
2024-07-11 16:49:35,321 [INFO    ] __main__: train step 11845: loss: 1.0086, policy_loss: 1.0018, value_loss: 0.6582
2024-07-11 16:49:35,523 [INFO    ] __main__: train step 11846: loss: 1.0086, policy_loss: 1.0018, value_loss: 0.6582
2024-07-11 16:49:35,734 [INFO    ] __main__: train step 11847: loss: 1.0086, policy_loss: 1.0018, value_loss: 0.6581
2024-07-11 16:49:35,969 [INFO    ] __main__: train step 11848: loss: 1.0086, policy_loss: 1.0017, value_loss: 0.6581
2024-07-11 16:49:37,397 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:49:37,845 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:49:37,904 [INFO    ] __main__: train step 11849: loss: 1.0086, policy_loss: 1.0017, value_loss: 0.6581
2024-07-11 16:49:38,081 [INFO    ] __main__: train step 11850: loss: 1.0086, policy_loss: 1.0017, value_loss: 0.6581
2024-07-11 16:49:38,307 [INFO    ] __main__: train step 11851: loss: 1.0086, policy_loss: 1.0017, value_loss: 0.6580
2024-07-11 16:49:38,528 [INFO    ] __main__: train step 11852: loss: 1.0086, policy_loss: 1.0016, value_loss: 0.6580
2024-07-11 16:49:38,771 [INFO    ] __main__: train step 11853: loss: 1.0086, policy_loss: 1.0016, value_loss: 0.6580
2024-07-11 16:49:38,987 [INFO    ] __main__: train step 11854: loss: 1.0085, policy_loss: 1.0016, value_loss: 0.6579
2024-07-11 16:49:39,179 [INFO    ] __main__: train step 11855: loss: 1.0085, policy_loss: 1.0015, value_loss: 0.6579
2024-07-11 16:49:39,385 [INFO    ] __main__: train step 11856: loss: 1.0085, policy_loss: 1.0015, value_loss: 0.6579
2024-07-11 16:49:39,595 [INFO    ] __main__: train step 11857: loss: 1.0085, policy_loss: 1.0015, value_loss: 0.6579
2024-07-11 16:49:39,798 [INFO    ] __main__: train step 11858: loss: 1.0085, policy_loss: 1.0015, value_loss: 0.6578
2024-07-11 16:49:40,007 [INFO    ] __main__: train step 11859: loss: 1.0085, policy_loss: 1.0014, value_loss: 0.6578
2024-07-11 16:49:40,209 [INFO    ] __main__: train step 11860: loss: 1.0085, policy_loss: 1.0014, value_loss: 0.6578
2024-07-11 16:49:40,413 [INFO    ] __main__: train step 11861: loss: 1.0085, policy_loss: 1.0014, value_loss: 0.6577
2024-07-11 16:49:40,607 [INFO    ] __main__: train step 11862: loss: 1.0085, policy_loss: 1.0013, value_loss: 0.6577
2024-07-11 16:49:40,812 [INFO    ] __main__: train step 11863: loss: 1.0085, policy_loss: 1.0013, value_loss: 0.6577
2024-07-11 16:49:41,007 [INFO    ] __main__: train step 11864: loss: 1.0085, policy_loss: 1.0013, value_loss: 0.6577
2024-07-11 16:49:41,226 [INFO    ] __main__: train step 11865: loss: 1.0085, policy_loss: 1.0012, value_loss: 0.6576
2024-07-11 16:49:42,677 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:49:43,114 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:49:43,176 [INFO    ] __main__: train step 11866: loss: 1.0085, policy_loss: 1.0012, value_loss: 0.6576
2024-07-11 16:49:43,356 [INFO    ] __main__: train step 11867: loss: 1.0085, policy_loss: 1.0012, value_loss: 0.6576
2024-07-11 16:49:43,558 [INFO    ] __main__: train step 11868: loss: 1.0085, policy_loss: 1.0012, value_loss: 0.6575
2024-07-11 16:49:43,766 [INFO    ] __main__: train step 11869: loss: 1.0085, policy_loss: 1.0011, value_loss: 0.6575
2024-07-11 16:49:43,978 [INFO    ] __main__: train step 11870: loss: 1.0085, policy_loss: 1.0011, value_loss: 0.6575
2024-07-11 16:49:44,201 [INFO    ] __main__: train step 11871: loss: 1.0085, policy_loss: 1.0011, value_loss: 0.6575
2024-07-11 16:49:44,444 [INFO    ] __main__: train step 11872: loss: 1.0085, policy_loss: 1.0010, value_loss: 0.6574
2024-07-11 16:49:44,644 [INFO    ] __main__: train step 11873: loss: 1.0085, policy_loss: 1.0010, value_loss: 0.6574
2024-07-11 16:49:44,858 [INFO    ] __main__: train step 11874: loss: 1.0085, policy_loss: 1.0010, value_loss: 0.6574
2024-07-11 16:49:45,082 [INFO    ] __main__: train step 11875: loss: 1.0085, policy_loss: 1.0009, value_loss: 0.6574
2024-07-11 16:49:45,283 [INFO    ] __main__: train step 11876: loss: 1.0085, policy_loss: 1.0009, value_loss: 0.6573
2024-07-11 16:49:45,480 [INFO    ] __main__: train step 11877: loss: 1.0085, policy_loss: 1.0009, value_loss: 0.6573
2024-07-11 16:49:45,690 [INFO    ] __main__: train step 11878: loss: 1.0085, policy_loss: 1.0009, value_loss: 0.6573
2024-07-11 16:49:45,902 [INFO    ] __main__: train step 11879: loss: 1.0085, policy_loss: 1.0008, value_loss: 0.6573
2024-07-11 16:49:46,103 [INFO    ] __main__: train step 11880: loss: 1.0085, policy_loss: 1.0008, value_loss: 0.6572
2024-07-11 16:49:46,308 [INFO    ] __main__: train step 11881: loss: 1.0085, policy_loss: 1.0008, value_loss: 0.6572
2024-07-11 16:49:46,515 [INFO    ] __main__: train step 11882: loss: 1.0085, policy_loss: 1.0007, value_loss: 0.6572
2024-07-11 16:49:47,961 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:49:48,386 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:49:48,447 [INFO    ] __main__: train step 11883: loss: 1.0085, policy_loss: 1.0007, value_loss: 0.6571
2024-07-11 16:49:48,626 [INFO    ] __main__: train step 11884: loss: 1.0085, policy_loss: 1.0007, value_loss: 0.6571
2024-07-11 16:49:48,829 [INFO    ] __main__: train step 11885: loss: 1.0085, policy_loss: 1.0007, value_loss: 0.6571
2024-07-11 16:49:49,027 [INFO    ] __main__: train step 11886: loss: 1.0085, policy_loss: 1.0006, value_loss: 0.6571
2024-07-11 16:49:49,238 [INFO    ] __main__: train step 11887: loss: 1.0085, policy_loss: 1.0006, value_loss: 0.6570
2024-07-11 16:49:49,433 [INFO    ] __main__: train step 11888: loss: 1.0085, policy_loss: 1.0006, value_loss: 0.6570
2024-07-11 16:49:49,646 [INFO    ] __main__: train step 11889: loss: 1.0085, policy_loss: 1.0005, value_loss: 0.6570
2024-07-11 16:49:49,883 [INFO    ] __main__: train step 11890: loss: 1.0085, policy_loss: 1.0005, value_loss: 0.6569
2024-07-11 16:49:50,124 [INFO    ] __main__: train step 11891: loss: 1.0085, policy_loss: 1.0005, value_loss: 0.6569
2024-07-11 16:49:50,320 [INFO    ] __main__: train step 11892: loss: 1.0085, policy_loss: 1.0005, value_loss: 0.6569
2024-07-11 16:49:50,525 [INFO    ] __main__: train step 11893: loss: 1.0085, policy_loss: 1.0004, value_loss: 0.6569
2024-07-11 16:49:50,724 [INFO    ] __main__: train step 11894: loss: 1.0085, policy_loss: 1.0004, value_loss: 0.6568
2024-07-11 16:49:50,935 [INFO    ] __main__: train step 11895: loss: 1.0085, policy_loss: 1.0004, value_loss: 0.6568
2024-07-11 16:49:51,136 [INFO    ] __main__: train step 11896: loss: 1.0085, policy_loss: 1.0003, value_loss: 0.6568
2024-07-11 16:49:51,335 [INFO    ] __main__: train step 11897: loss: 1.0085, policy_loss: 1.0003, value_loss: 0.6568
2024-07-11 16:49:51,538 [INFO    ] __main__: train step 11898: loss: 1.0085, policy_loss: 1.0003, value_loss: 0.6567
2024-07-11 16:49:51,747 [INFO    ] __main__: train step 11899: loss: 1.0085, policy_loss: 1.0003, value_loss: 0.6567
2024-07-11 16:49:53,176 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:49:53,611 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:49:53,677 [INFO    ] __main__: train step 11900: loss: 1.0085, policy_loss: 1.0002, value_loss: 0.6567
2024-07-11 16:49:53,857 [INFO    ] __main__: train step 11901: loss: 1.0084, policy_loss: 1.0002, value_loss: 0.6566
2024-07-11 16:49:54,064 [INFO    ] __main__: train step 11902: loss: 1.0084, policy_loss: 1.0002, value_loss: 0.6566
2024-07-11 16:49:54,285 [INFO    ] __main__: train step 11903: loss: 1.0084, policy_loss: 1.0001, value_loss: 0.6566
2024-07-11 16:49:54,476 [INFO    ] __main__: train step 11904: loss: 1.0084, policy_loss: 1.0001, value_loss: 0.6566
2024-07-11 16:49:54,680 [INFO    ] __main__: train step 11905: loss: 1.0084, policy_loss: 1.0001, value_loss: 0.6565
2024-07-11 16:49:56,230 [INFO    ] __main__: train step 11906: loss: 1.0084, policy_loss: 1.0000, value_loss: 0.6565
2024-07-11 16:49:56,438 [INFO    ] __main__: train step 11907: loss: 1.0084, policy_loss: 1.0000, value_loss: 0.6565
2024-07-11 16:49:56,649 [INFO    ] __main__: train step 11908: loss: 1.0084, policy_loss: 1.0000, value_loss: 0.6564
2024-07-11 16:49:56,872 [INFO    ] __main__: train step 11909: loss: 1.0084, policy_loss: 1.0000, value_loss: 0.6564
2024-07-11 16:49:57,070 [INFO    ] __main__: train step 11910: loss: 1.0084, policy_loss: 0.9999, value_loss: 0.6564
2024-07-11 16:49:57,271 [INFO    ] __main__: train step 11911: loss: 1.0084, policy_loss: 0.9999, value_loss: 0.6564
2024-07-11 16:49:57,475 [INFO    ] __main__: train step 11912: loss: 1.0084, policy_loss: 0.9999, value_loss: 0.6563
2024-07-11 16:49:57,675 [INFO    ] __main__: train step 11913: loss: 1.0084, policy_loss: 0.9998, value_loss: 0.6563
2024-07-11 16:49:57,884 [INFO    ] __main__: train step 11914: loss: 1.0084, policy_loss: 0.9998, value_loss: 0.6563
2024-07-11 16:49:58,089 [INFO    ] __main__: train step 11915: loss: 1.0084, policy_loss: 0.9998, value_loss: 0.6562
2024-07-11 16:49:58,295 [INFO    ] __main__: train step 11916: loss: 1.0084, policy_loss: 0.9998, value_loss: 0.6562
2024-07-11 16:49:59,731 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:50:00,115 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:50:00,174 [INFO    ] __main__: train step 11917: loss: 1.0084, policy_loss: 0.9997, value_loss: 0.6562
2024-07-11 16:50:00,350 [INFO    ] __main__: train step 11918: loss: 1.0084, policy_loss: 0.9997, value_loss: 0.6562
2024-07-11 16:50:00,552 [INFO    ] __main__: train step 11919: loss: 1.0084, policy_loss: 0.9997, value_loss: 0.6561
2024-07-11 16:50:00,755 [INFO    ] __main__: train step 11920: loss: 1.0084, policy_loss: 0.9996, value_loss: 0.6561
2024-07-11 16:50:00,956 [INFO    ] __main__: train step 11921: loss: 1.0084, policy_loss: 0.9996, value_loss: 0.6561
2024-07-11 16:50:01,163 [INFO    ] __main__: train step 11922: loss: 1.0084, policy_loss: 0.9996, value_loss: 0.6561
2024-07-11 16:50:01,375 [INFO    ] __main__: train step 11923: loss: 1.0084, policy_loss: 0.9995, value_loss: 0.6560
2024-07-11 16:50:01,581 [INFO    ] __main__: train step 11924: loss: 1.0084, policy_loss: 0.9995, value_loss: 0.6560
2024-07-11 16:50:01,806 [INFO    ] __main__: train step 11925: loss: 1.0084, policy_loss: 0.9995, value_loss: 0.6560
2024-07-11 16:50:02,017 [INFO    ] __main__: train step 11926: loss: 1.0084, policy_loss: 0.9995, value_loss: 0.6559
2024-07-11 16:50:02,224 [INFO    ] __main__: train step 11927: loss: 1.0084, policy_loss: 0.9994, value_loss: 0.6559
2024-07-11 16:50:02,429 [INFO    ] __main__: train step 11928: loss: 1.0084, policy_loss: 0.9994, value_loss: 0.6559
2024-07-11 16:50:02,626 [INFO    ] __main__: train step 11929: loss: 1.0084, policy_loss: 0.9994, value_loss: 0.6559
2024-07-11 16:50:02,856 [INFO    ] __main__: train step 11930: loss: 1.0084, policy_loss: 0.9993, value_loss: 0.6558
2024-07-11 16:50:03,090 [INFO    ] __main__: train step 11931: loss: 1.0084, policy_loss: 0.9993, value_loss: 0.6558
2024-07-11 16:50:03,319 [INFO    ] __main__: train step 11932: loss: 1.0084, policy_loss: 0.9993, value_loss: 0.6558
2024-07-11 16:50:03,512 [INFO    ] __main__: train step 11933: loss: 1.0084, policy_loss: 0.9993, value_loss: 0.6558
2024-07-11 16:50:04,963 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:50:05,397 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:50:05,457 [INFO    ] __main__: train step 11934: loss: 1.0084, policy_loss: 0.9992, value_loss: 0.6557
2024-07-11 16:50:05,628 [INFO    ] __main__: train step 11935: loss: 1.0084, policy_loss: 0.9992, value_loss: 0.6557
2024-07-11 16:50:05,850 [INFO    ] __main__: train step 11936: loss: 1.0083, policy_loss: 0.9992, value_loss: 0.6557
2024-07-11 16:50:06,055 [INFO    ] __main__: train step 11937: loss: 1.0083, policy_loss: 0.9991, value_loss: 0.6556
2024-07-11 16:50:06,295 [INFO    ] __main__: train step 11938: loss: 1.0083, policy_loss: 0.9991, value_loss: 0.6556
2024-07-11 16:50:06,513 [INFO    ] __main__: train step 11939: loss: 1.0083, policy_loss: 0.9991, value_loss: 0.6556
2024-07-11 16:50:06,721 [INFO    ] __main__: train step 11940: loss: 1.0083, policy_loss: 0.9991, value_loss: 0.6556
2024-07-11 16:50:06,920 [INFO    ] __main__: train step 11941: loss: 1.0083, policy_loss: 0.9990, value_loss: 0.6555
2024-07-11 16:50:07,120 [INFO    ] __main__: train step 11942: loss: 1.0083, policy_loss: 0.9990, value_loss: 0.6555
2024-07-11 16:50:07,328 [INFO    ] __main__: train step 11943: loss: 1.0083, policy_loss: 0.9990, value_loss: 0.6555
2024-07-11 16:50:07,534 [INFO    ] __main__: train step 11944: loss: 1.0083, policy_loss: 0.9989, value_loss: 0.6555
2024-07-11 16:50:07,757 [INFO    ] __main__: train step 11945: loss: 1.0083, policy_loss: 0.9989, value_loss: 0.6554
2024-07-11 16:50:07,980 [INFO    ] __main__: train step 11946: loss: 1.0083, policy_loss: 0.9989, value_loss: 0.6554
2024-07-11 16:50:08,276 [INFO    ] __main__: train step 11947: loss: 1.0083, policy_loss: 0.9988, value_loss: 0.6554
2024-07-11 16:50:08,498 [INFO    ] __main__: train step 11948: loss: 1.0083, policy_loss: 0.9988, value_loss: 0.6553
2024-07-11 16:50:08,721 [INFO    ] __main__: train step 11949: loss: 1.0083, policy_loss: 0.9988, value_loss: 0.6553
2024-07-11 16:50:08,949 [INFO    ] __main__: train step 11950: loss: 1.0083, policy_loss: 0.9988, value_loss: 0.6553
2024-07-11 16:50:10,383 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:50:10,778 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:50:10,832 [INFO    ] __main__: train step 11951: loss: 1.0083, policy_loss: 0.9987, value_loss: 0.6553
2024-07-11 16:50:11,016 [INFO    ] __main__: train step 11952: loss: 1.0083, policy_loss: 0.9987, value_loss: 0.6552
2024-07-11 16:50:11,222 [INFO    ] __main__: train step 11953: loss: 1.0083, policy_loss: 0.9987, value_loss: 0.6552
2024-07-11 16:50:11,434 [INFO    ] __main__: train step 11954: loss: 1.0083, policy_loss: 0.9986, value_loss: 0.6552
2024-07-11 16:50:11,650 [INFO    ] __main__: train step 11955: loss: 1.0083, policy_loss: 0.9986, value_loss: 0.6552
2024-07-11 16:50:11,881 [INFO    ] __main__: train step 11956: loss: 1.0083, policy_loss: 0.9986, value_loss: 0.6551
2024-07-11 16:50:12,090 [INFO    ] __main__: train step 11957: loss: 1.0083, policy_loss: 0.9986, value_loss: 0.6551
2024-07-11 16:50:12,335 [INFO    ] __main__: train step 11958: loss: 1.0083, policy_loss: 0.9985, value_loss: 0.6551
2024-07-11 16:50:12,530 [INFO    ] __main__: train step 11959: loss: 1.0083, policy_loss: 0.9985, value_loss: 0.6550
2024-07-11 16:50:12,736 [INFO    ] __main__: train step 11960: loss: 1.0083, policy_loss: 0.9985, value_loss: 0.6550
2024-07-11 16:50:12,933 [INFO    ] __main__: train step 11961: loss: 1.0083, policy_loss: 0.9984, value_loss: 0.6550
2024-07-11 16:50:13,141 [INFO    ] __main__: train step 11962: loss: 1.0083, policy_loss: 0.9984, value_loss: 0.6550
2024-07-11 16:50:13,342 [INFO    ] __main__: train step 11963: loss: 1.0083, policy_loss: 0.9984, value_loss: 0.6549
2024-07-11 16:50:13,542 [INFO    ] __main__: train step 11964: loss: 1.0083, policy_loss: 0.9984, value_loss: 0.6549
2024-07-11 16:50:13,743 [INFO    ] __main__: train step 11965: loss: 1.0083, policy_loss: 0.9983, value_loss: 0.6549
2024-07-11 16:50:13,959 [INFO    ] __main__: train step 11966: loss: 1.0083, policy_loss: 0.9983, value_loss: 0.6548
2024-07-11 16:50:14,208 [INFO    ] __main__: train step 11967: loss: 1.0083, policy_loss: 0.9983, value_loss: 0.6548
2024-07-11 16:50:15,679 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:50:16,100 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:50:16,156 [INFO    ] __main__: train step 11968: loss: 1.0083, policy_loss: 0.9982, value_loss: 0.6548
2024-07-11 16:50:16,335 [INFO    ] __main__: train step 11969: loss: 1.0083, policy_loss: 0.9982, value_loss: 0.6548
2024-07-11 16:50:16,544 [INFO    ] __main__: train step 11970: loss: 1.0083, policy_loss: 0.9982, value_loss: 0.6547
2024-07-11 16:50:16,738 [INFO    ] __main__: train step 11971: loss: 1.0083, policy_loss: 0.9982, value_loss: 0.6547
2024-07-11 16:50:16,941 [INFO    ] __main__: train step 11972: loss: 1.0083, policy_loss: 0.9981, value_loss: 0.6547
2024-07-11 16:50:17,160 [INFO    ] __main__: train step 11973: loss: 1.0083, policy_loss: 0.9981, value_loss: 0.6546
2024-07-11 16:50:17,419 [INFO    ] __main__: train step 11974: loss: 1.0083, policy_loss: 0.9981, value_loss: 0.6546
2024-07-11 16:50:17,660 [INFO    ] __main__: train step 11975: loss: 1.0083, policy_loss: 0.9980, value_loss: 0.6546
2024-07-11 16:50:17,897 [INFO    ] __main__: train step 11976: loss: 1.0082, policy_loss: 0.9980, value_loss: 0.6546
2024-07-11 16:50:18,127 [INFO    ] __main__: train step 11977: loss: 1.0082, policy_loss: 0.9980, value_loss: 0.6545
2024-07-11 16:50:18,329 [INFO    ] __main__: train step 11978: loss: 1.0082, policy_loss: 0.9980, value_loss: 0.6545
2024-07-11 16:50:18,529 [INFO    ] __main__: train step 11979: loss: 1.0082, policy_loss: 0.9979, value_loss: 0.6545
2024-07-11 16:50:18,728 [INFO    ] __main__: train step 11980: loss: 1.0082, policy_loss: 0.9979, value_loss: 0.6545
2024-07-11 16:50:18,927 [INFO    ] __main__: train step 11981: loss: 1.0082, policy_loss: 0.9979, value_loss: 0.6544
2024-07-11 16:50:19,123 [INFO    ] __main__: train step 11982: loss: 1.0082, policy_loss: 0.9978, value_loss: 0.6544
2024-07-11 16:50:19,327 [INFO    ] __main__: train step 11983: loss: 1.0082, policy_loss: 0.9978, value_loss: 0.6544
2024-07-11 16:50:19,527 [INFO    ] __main__: train step 11984: loss: 1.0082, policy_loss: 0.9978, value_loss: 0.6543
2024-07-11 16:50:20,970 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:50:21,413 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:50:21,474 [INFO    ] __main__: train step 11985: loss: 1.0082, policy_loss: 0.9978, value_loss: 0.6543
2024-07-11 16:50:21,652 [INFO    ] __main__: train step 11986: loss: 1.0082, policy_loss: 0.9977, value_loss: 0.6543
2024-07-11 16:50:21,851 [INFO    ] __main__: train step 11987: loss: 1.0082, policy_loss: 0.9977, value_loss: 0.6543
2024-07-11 16:50:22,056 [INFO    ] __main__: train step 11988: loss: 1.0082, policy_loss: 0.9977, value_loss: 0.6542
2024-07-11 16:50:22,255 [INFO    ] __main__: train step 11989: loss: 1.0082, policy_loss: 0.9976, value_loss: 0.6542
2024-07-11 16:50:22,455 [INFO    ] __main__: train step 11990: loss: 1.0082, policy_loss: 0.9976, value_loss: 0.6542
2024-07-11 16:50:22,653 [INFO    ] __main__: train step 11991: loss: 1.0082, policy_loss: 0.9976, value_loss: 0.6541
2024-07-11 16:50:22,858 [INFO    ] __main__: train step 11992: loss: 1.0082, policy_loss: 0.9976, value_loss: 0.6541
2024-07-11 16:50:23,062 [INFO    ] __main__: train step 11993: loss: 1.0082, policy_loss: 0.9975, value_loss: 0.6541
2024-07-11 16:50:23,264 [INFO    ] __main__: train step 11994: loss: 1.0082, policy_loss: 0.9975, value_loss: 0.6541
2024-07-11 16:50:23,482 [INFO    ] __main__: train step 11995: loss: 1.0082, policy_loss: 0.9975, value_loss: 0.6540
2024-07-11 16:50:23,689 [INFO    ] __main__: train step 11996: loss: 1.0082, policy_loss: 0.9974, value_loss: 0.6540
2024-07-11 16:50:23,901 [INFO    ] __main__: train step 11997: loss: 1.0082, policy_loss: 0.9974, value_loss: 0.6540
2024-07-11 16:50:24,103 [INFO    ] __main__: train step 11998: loss: 1.0082, policy_loss: 0.9974, value_loss: 0.6540
2024-07-11 16:50:24,302 [INFO    ] __main__: train step 11999: loss: 1.0082, policy_loss: 0.9973, value_loss: 0.6539
2024-07-11 16:50:24,507 [INFO    ] __main__: train step 12000: loss: 1.0082, policy_loss: 0.9973, value_loss: 0.6539
2024-07-11 16:50:24,632 [INFO    ] __main__: restored step 11000 for evaluation
2024-07-11 16:50:32,014 [INFO    ] __main__: later network ELO difference from earlier network: +72 (+8/-8) ELO from 32000 self-played games
2024-07-11 16:50:32,015 [INFO    ] __main__: game outcomes: W: 18378, D: 740, L: 12882
2024-07-11 16:50:32,017 [INFO    ] __main__: validation_elo_delta: 72, validation_elo: 2198
2024-07-11 16:50:32,546 [INFO    ] __main__: train step 12001: loss: 1.0082, policy_loss: 0.9973, value_loss: 0.6539
2024-07-11 16:50:33,981 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:50:34,409 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:50:34,464 [INFO    ] __main__: train step 12002: loss: 1.0082, policy_loss: 0.9973, value_loss: 0.6538
2024-07-11 16:50:34,644 [INFO    ] __main__: train step 12003: loss: 1.0082, policy_loss: 0.9972, value_loss: 0.6538
2024-07-11 16:50:34,854 [INFO    ] __main__: train step 12004: loss: 1.0082, policy_loss: 0.9972, value_loss: 0.6538
2024-07-11 16:50:35,060 [INFO    ] __main__: train step 12005: loss: 1.0082, policy_loss: 0.9972, value_loss: 0.6538
2024-07-11 16:50:35,295 [INFO    ] __main__: train step 12006: loss: 1.0081, policy_loss: 0.9971, value_loss: 0.6537
2024-07-11 16:50:36,904 [INFO    ] __main__: train step 12007: loss: 1.0081, policy_loss: 0.9971, value_loss: 0.6537
2024-07-11 16:50:37,128 [INFO    ] __main__: train step 12008: loss: 1.0081, policy_loss: 0.9971, value_loss: 0.6537
2024-07-11 16:50:37,352 [INFO    ] __main__: train step 12009: loss: 1.0081, policy_loss: 0.9971, value_loss: 0.6536
2024-07-11 16:50:37,557 [INFO    ] __main__: train step 12010: loss: 1.0081, policy_loss: 0.9970, value_loss: 0.6536
2024-07-11 16:50:37,761 [INFO    ] __main__: train step 12011: loss: 1.0081, policy_loss: 0.9970, value_loss: 0.6536
2024-07-11 16:50:37,966 [INFO    ] __main__: train step 12012: loss: 1.0081, policy_loss: 0.9970, value_loss: 0.6536
2024-07-11 16:50:38,177 [INFO    ] __main__: train step 12013: loss: 1.0081, policy_loss: 0.9969, value_loss: 0.6535
2024-07-11 16:50:38,407 [INFO    ] __main__: train step 12014: loss: 1.0081, policy_loss: 0.9969, value_loss: 0.6535
2024-07-11 16:50:38,632 [INFO    ] __main__: train step 12015: loss: 1.0081, policy_loss: 0.9969, value_loss: 0.6535
2024-07-11 16:50:38,861 [INFO    ] __main__: train step 12016: loss: 1.0081, policy_loss: 0.9969, value_loss: 0.6534
2024-07-11 16:50:39,057 [INFO    ] __main__: train step 12017: loss: 1.0081, policy_loss: 0.9968, value_loss: 0.6534
2024-07-11 16:50:39,262 [INFO    ] __main__: train step 12018: loss: 1.0081, policy_loss: 0.9968, value_loss: 0.6534
2024-07-11 16:50:40,697 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:50:41,068 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:50:41,125 [INFO    ] __main__: train step 12019: loss: 1.0081, policy_loss: 0.9968, value_loss: 0.6534
2024-07-11 16:50:41,303 [INFO    ] __main__: train step 12020: loss: 1.0081, policy_loss: 0.9967, value_loss: 0.6533
2024-07-11 16:50:41,515 [INFO    ] __main__: train step 12021: loss: 1.0081, policy_loss: 0.9967, value_loss: 0.6533
2024-07-11 16:50:41,758 [INFO    ] __main__: train step 12022: loss: 1.0081, policy_loss: 0.9967, value_loss: 0.6533
2024-07-11 16:50:41,977 [INFO    ] __main__: train step 12023: loss: 1.0081, policy_loss: 0.9967, value_loss: 0.6532
2024-07-11 16:50:42,183 [INFO    ] __main__: train step 12024: loss: 1.0081, policy_loss: 0.9966, value_loss: 0.6532
2024-07-11 16:50:42,392 [INFO    ] __main__: train step 12025: loss: 1.0081, policy_loss: 0.9966, value_loss: 0.6532
2024-07-11 16:50:42,629 [INFO    ] __main__: train step 12026: loss: 1.0081, policy_loss: 0.9966, value_loss: 0.6532
2024-07-11 16:50:42,826 [INFO    ] __main__: train step 12027: loss: 1.0081, policy_loss: 0.9965, value_loss: 0.6531
2024-07-11 16:50:43,026 [INFO    ] __main__: train step 12028: loss: 1.0081, policy_loss: 0.9965, value_loss: 0.6531
2024-07-11 16:50:43,222 [INFO    ] __main__: train step 12029: loss: 1.0081, policy_loss: 0.9965, value_loss: 0.6531
2024-07-11 16:50:43,432 [INFO    ] __main__: train step 12030: loss: 1.0081, policy_loss: 0.9965, value_loss: 0.6530
2024-07-11 16:50:43,658 [INFO    ] __main__: train step 12031: loss: 1.0081, policy_loss: 0.9964, value_loss: 0.6530
2024-07-11 16:50:43,854 [INFO    ] __main__: train step 12032: loss: 1.0081, policy_loss: 0.9964, value_loss: 0.6530
2024-07-11 16:50:44,067 [INFO    ] __main__: train step 12033: loss: 1.0081, policy_loss: 0.9964, value_loss: 0.6530
2024-07-11 16:50:44,324 [INFO    ] __main__: train step 12034: loss: 1.0080, policy_loss: 0.9963, value_loss: 0.6529
2024-07-11 16:50:44,548 [INFO    ] __main__: train step 12035: loss: 1.0080, policy_loss: 0.9963, value_loss: 0.6529
2024-07-11 16:50:45,987 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:50:46,388 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:50:46,444 [INFO    ] __main__: train step 12036: loss: 1.0080, policy_loss: 0.9963, value_loss: 0.6529
2024-07-11 16:50:46,621 [INFO    ] __main__: train step 12037: loss: 1.0080, policy_loss: 0.9963, value_loss: 0.6529
2024-07-11 16:50:46,827 [INFO    ] __main__: train step 12038: loss: 1.0080, policy_loss: 0.9962, value_loss: 0.6528
2024-07-11 16:50:47,032 [INFO    ] __main__: train step 12039: loss: 1.0080, policy_loss: 0.9962, value_loss: 0.6528
2024-07-11 16:50:47,273 [INFO    ] __main__: train step 12040: loss: 1.0080, policy_loss: 0.9962, value_loss: 0.6528
2024-07-11 16:50:47,474 [INFO    ] __main__: train step 12041: loss: 1.0080, policy_loss: 0.9961, value_loss: 0.6527
2024-07-11 16:50:47,669 [INFO    ] __main__: train step 12042: loss: 1.0080, policy_loss: 0.9961, value_loss: 0.6527
2024-07-11 16:50:47,892 [INFO    ] __main__: train step 12043: loss: 1.0080, policy_loss: 0.9961, value_loss: 0.6527
2024-07-11 16:50:48,090 [INFO    ] __main__: train step 12044: loss: 1.0080, policy_loss: 0.9960, value_loss: 0.6527
2024-07-11 16:50:48,305 [INFO    ] __main__: train step 12045: loss: 1.0080, policy_loss: 0.9960, value_loss: 0.6526
2024-07-11 16:50:48,506 [INFO    ] __main__: train step 12046: loss: 1.0080, policy_loss: 0.9960, value_loss: 0.6526
2024-07-11 16:50:48,711 [INFO    ] __main__: train step 12047: loss: 1.0080, policy_loss: 0.9960, value_loss: 0.6526
2024-07-11 16:50:48,913 [INFO    ] __main__: train step 12048: loss: 1.0080, policy_loss: 0.9959, value_loss: 0.6525
2024-07-11 16:50:49,108 [INFO    ] __main__: train step 12049: loss: 1.0080, policy_loss: 0.9959, value_loss: 0.6525
2024-07-11 16:50:49,312 [INFO    ] __main__: train step 12050: loss: 1.0080, policy_loss: 0.9959, value_loss: 0.6525
2024-07-11 16:50:49,505 [INFO    ] __main__: train step 12051: loss: 1.0080, policy_loss: 0.9958, value_loss: 0.6525
2024-07-11 16:50:49,708 [INFO    ] __main__: train step 12052: loss: 1.0080, policy_loss: 0.9958, value_loss: 0.6524
2024-07-11 16:50:51,151 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:50:51,514 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:50:51,576 [INFO    ] __main__: train step 12053: loss: 1.0080, policy_loss: 0.9958, value_loss: 0.6524
2024-07-11 16:50:51,756 [INFO    ] __main__: train step 12054: loss: 1.0080, policy_loss: 0.9958, value_loss: 0.6524
2024-07-11 16:50:52,008 [INFO    ] __main__: train step 12055: loss: 1.0080, policy_loss: 0.9957, value_loss: 0.6523
2024-07-11 16:50:52,198 [INFO    ] __main__: train step 12056: loss: 1.0080, policy_loss: 0.9957, value_loss: 0.6523
2024-07-11 16:50:52,409 [INFO    ] __main__: train step 12057: loss: 1.0080, policy_loss: 0.9957, value_loss: 0.6523
2024-07-11 16:50:52,627 [INFO    ] __main__: train step 12058: loss: 1.0080, policy_loss: 0.9956, value_loss: 0.6523
2024-07-11 16:50:52,835 [INFO    ] __main__: train step 12059: loss: 1.0080, policy_loss: 0.9956, value_loss: 0.6522
2024-07-11 16:50:53,041 [INFO    ] __main__: train step 12060: loss: 1.0080, policy_loss: 0.9956, value_loss: 0.6522
2024-07-11 16:50:53,253 [INFO    ] __main__: train step 12061: loss: 1.0079, policy_loss: 0.9956, value_loss: 0.6522
2024-07-11 16:50:53,467 [INFO    ] __main__: train step 12062: loss: 1.0079, policy_loss: 0.9955, value_loss: 0.6521
2024-07-11 16:50:53,701 [INFO    ] __main__: train step 12063: loss: 1.0079, policy_loss: 0.9955, value_loss: 0.6521
2024-07-11 16:50:53,903 [INFO    ] __main__: train step 12064: loss: 1.0079, policy_loss: 0.9955, value_loss: 0.6521
2024-07-11 16:50:54,118 [INFO    ] __main__: train step 12065: loss: 1.0079, policy_loss: 0.9954, value_loss: 0.6521
2024-07-11 16:50:54,335 [INFO    ] __main__: train step 12066: loss: 1.0079, policy_loss: 0.9954, value_loss: 0.6520
2024-07-11 16:50:54,558 [INFO    ] __main__: train step 12067: loss: 1.0079, policy_loss: 0.9954, value_loss: 0.6520
2024-07-11 16:50:54,754 [INFO    ] __main__: train step 12068: loss: 1.0079, policy_loss: 0.9954, value_loss: 0.6520
2024-07-11 16:50:54,964 [INFO    ] __main__: train step 12069: loss: 1.0079, policy_loss: 0.9953, value_loss: 0.6520
2024-07-11 16:50:56,394 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:50:56,748 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:50:56,810 [INFO    ] __main__: train step 12070: loss: 1.0079, policy_loss: 0.9953, value_loss: 0.6519
2024-07-11 16:50:56,996 [INFO    ] __main__: train step 12071: loss: 1.0079, policy_loss: 0.9953, value_loss: 0.6519
2024-07-11 16:50:57,215 [INFO    ] __main__: train step 12072: loss: 1.0079, policy_loss: 0.9952, value_loss: 0.6519
2024-07-11 16:50:57,424 [INFO    ] __main__: train step 12073: loss: 1.0079, policy_loss: 0.9952, value_loss: 0.6518
2024-07-11 16:50:57,642 [INFO    ] __main__: train step 12074: loss: 1.0079, policy_loss: 0.9952, value_loss: 0.6518
2024-07-11 16:50:57,840 [INFO    ] __main__: train step 12075: loss: 1.0079, policy_loss: 0.9952, value_loss: 0.6518
2024-07-11 16:50:58,076 [INFO    ] __main__: train step 12076: loss: 1.0079, policy_loss: 0.9951, value_loss: 0.6518
2024-07-11 16:50:58,286 [INFO    ] __main__: train step 12077: loss: 1.0079, policy_loss: 0.9951, value_loss: 0.6517
2024-07-11 16:50:58,495 [INFO    ] __main__: train step 12078: loss: 1.0079, policy_loss: 0.9951, value_loss: 0.6517
2024-07-11 16:50:58,728 [INFO    ] __main__: train step 12079: loss: 1.0079, policy_loss: 0.9950, value_loss: 0.6517
2024-07-11 16:50:58,933 [INFO    ] __main__: train step 12080: loss: 1.0079, policy_loss: 0.9950, value_loss: 0.6516
2024-07-11 16:50:59,135 [INFO    ] __main__: train step 12081: loss: 1.0079, policy_loss: 0.9950, value_loss: 0.6516
2024-07-11 16:50:59,345 [INFO    ] __main__: train step 12082: loss: 1.0079, policy_loss: 0.9950, value_loss: 0.6516
2024-07-11 16:50:59,562 [INFO    ] __main__: train step 12083: loss: 1.0079, policy_loss: 0.9949, value_loss: 0.6516
2024-07-11 16:50:59,784 [INFO    ] __main__: train step 12084: loss: 1.0079, policy_loss: 0.9949, value_loss: 0.6515
2024-07-11 16:50:59,961 [INFO    ] __main__: train step 12085: loss: 1.0079, policy_loss: 0.9949, value_loss: 0.6515
2024-07-11 16:51:00,165 [INFO    ] __main__: train step 12086: loss: 1.0079, policy_loss: 0.9948, value_loss: 0.6515
2024-07-11 16:51:01,597 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:51:02,048 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:51:02,117 [INFO    ] __main__: train step 12087: loss: 1.0079, policy_loss: 0.9948, value_loss: 0.6515
2024-07-11 16:51:02,294 [INFO    ] __main__: train step 12088: loss: 1.0078, policy_loss: 0.9948, value_loss: 0.6514
2024-07-11 16:51:02,514 [INFO    ] __main__: train step 12089: loss: 1.0078, policy_loss: 0.9948, value_loss: 0.6514
2024-07-11 16:51:02,743 [INFO    ] __main__: train step 12090: loss: 1.0078, policy_loss: 0.9947, value_loss: 0.6514
2024-07-11 16:51:02,946 [INFO    ] __main__: train step 12091: loss: 1.0078, policy_loss: 0.9947, value_loss: 0.6513
2024-07-11 16:51:03,145 [INFO    ] __main__: train step 12092: loss: 1.0078, policy_loss: 0.9947, value_loss: 0.6513
2024-07-11 16:51:03,350 [INFO    ] __main__: train step 12093: loss: 1.0078, policy_loss: 0.9946, value_loss: 0.6513
2024-07-11 16:51:03,554 [INFO    ] __main__: train step 12094: loss: 1.0078, policy_loss: 0.9946, value_loss: 0.6513
2024-07-11 16:51:03,757 [INFO    ] __main__: train step 12095: loss: 1.0078, policy_loss: 0.9946, value_loss: 0.6512
2024-07-11 16:51:03,954 [INFO    ] __main__: train step 12096: loss: 1.0078, policy_loss: 0.9946, value_loss: 0.6512
2024-07-11 16:51:04,161 [INFO    ] __main__: train step 12097: loss: 1.0078, policy_loss: 0.9945, value_loss: 0.6512
2024-07-11 16:51:04,361 [INFO    ] __main__: train step 12098: loss: 1.0078, policy_loss: 0.9945, value_loss: 0.6511
2024-07-11 16:51:04,569 [INFO    ] __main__: train step 12099: loss: 1.0078, policy_loss: 0.9945, value_loss: 0.6511
2024-07-11 16:51:04,772 [INFO    ] __main__: train step 12100: loss: 1.0078, policy_loss: 0.9944, value_loss: 0.6511
2024-07-11 16:51:04,978 [INFO    ] __main__: train step 12101: loss: 1.0078, policy_loss: 0.9944, value_loss: 0.6511
2024-07-11 16:51:05,211 [INFO    ] __main__: train step 12102: loss: 1.0078, policy_loss: 0.9944, value_loss: 0.6510
2024-07-11 16:51:05,440 [INFO    ] __main__: train step 12103: loss: 1.0078, policy_loss: 0.9944, value_loss: 0.6510
2024-07-11 16:51:06,895 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:51:07,314 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:51:07,370 [INFO    ] __main__: train step 12104: loss: 1.0078, policy_loss: 0.9943, value_loss: 0.6510
2024-07-11 16:51:07,542 [INFO    ] __main__: train step 12105: loss: 1.0078, policy_loss: 0.9943, value_loss: 0.6509
2024-07-11 16:51:09,136 [INFO    ] __main__: train step 12106: loss: 1.0078, policy_loss: 0.9943, value_loss: 0.6509
2024-07-11 16:51:09,372 [INFO    ] __main__: train step 12107: loss: 1.0078, policy_loss: 0.9943, value_loss: 0.6509
2024-07-11 16:51:09,595 [INFO    ] __main__: train step 12108: loss: 1.0078, policy_loss: 0.9942, value_loss: 0.6509
2024-07-11 16:51:09,805 [INFO    ] __main__: train step 12109: loss: 1.0078, policy_loss: 0.9942, value_loss: 0.6508
2024-07-11 16:51:10,012 [INFO    ] __main__: train step 12110: loss: 1.0078, policy_loss: 0.9942, value_loss: 0.6508
2024-07-11 16:51:10,217 [INFO    ] __main__: train step 12111: loss: 1.0078, policy_loss: 0.9941, value_loss: 0.6508
2024-07-11 16:51:10,456 [INFO    ] __main__: train step 12112: loss: 1.0078, policy_loss: 0.9941, value_loss: 0.6507
2024-07-11 16:51:10,660 [INFO    ] __main__: train step 12113: loss: 1.0078, policy_loss: 0.9941, value_loss: 0.6507
2024-07-11 16:51:10,860 [INFO    ] __main__: train step 12114: loss: 1.0078, policy_loss: 0.9941, value_loss: 0.6507
2024-07-11 16:51:11,062 [INFO    ] __main__: train step 12115: loss: 1.0078, policy_loss: 0.9940, value_loss: 0.6507
2024-07-11 16:51:11,273 [INFO    ] __main__: train step 12116: loss: 1.0078, policy_loss: 0.9940, value_loss: 0.6506
2024-07-11 16:51:11,498 [INFO    ] __main__: train step 12117: loss: 1.0077, policy_loss: 0.9940, value_loss: 0.6506
2024-07-11 16:51:11,723 [INFO    ] __main__: train step 12118: loss: 1.0077, policy_loss: 0.9940, value_loss: 0.6506
2024-07-11 16:51:11,921 [INFO    ] __main__: train step 12119: loss: 1.0077, policy_loss: 0.9939, value_loss: 0.6505
2024-07-11 16:51:12,139 [INFO    ] __main__: train step 12120: loss: 1.0077, policy_loss: 0.9939, value_loss: 0.6505
2024-07-11 16:51:13,572 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:51:14,023 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:51:14,084 [INFO    ] __main__: train step 12121: loss: 1.0077, policy_loss: 0.9939, value_loss: 0.6505
2024-07-11 16:51:14,269 [INFO    ] __main__: train step 12122: loss: 1.0077, policy_loss: 0.9938, value_loss: 0.6505
2024-07-11 16:51:14,513 [INFO    ] __main__: train step 12123: loss: 1.0077, policy_loss: 0.9938, value_loss: 0.6504
2024-07-11 16:51:14,716 [INFO    ] __main__: train step 12124: loss: 1.0077, policy_loss: 0.9938, value_loss: 0.6504
2024-07-11 16:51:14,922 [INFO    ] __main__: train step 12125: loss: 1.0077, policy_loss: 0.9938, value_loss: 0.6504
2024-07-11 16:51:15,167 [INFO    ] __main__: train step 12126: loss: 1.0077, policy_loss: 0.9937, value_loss: 0.6503
2024-07-11 16:51:15,374 [INFO    ] __main__: train step 12127: loss: 1.0077, policy_loss: 0.9937, value_loss: 0.6503
2024-07-11 16:51:15,583 [INFO    ] __main__: train step 12128: loss: 1.0077, policy_loss: 0.9937, value_loss: 0.6503
2024-07-11 16:51:15,792 [INFO    ] __main__: train step 12129: loss: 1.0077, policy_loss: 0.9936, value_loss: 0.6503
2024-07-11 16:51:16,008 [INFO    ] __main__: train step 12130: loss: 1.0077, policy_loss: 0.9936, value_loss: 0.6502
2024-07-11 16:51:16,214 [INFO    ] __main__: train step 12131: loss: 1.0077, policy_loss: 0.9936, value_loss: 0.6502
2024-07-11 16:51:16,427 [INFO    ] __main__: train step 12132: loss: 1.0077, policy_loss: 0.9936, value_loss: 0.6502
2024-07-11 16:51:16,631 [INFO    ] __main__: train step 12133: loss: 1.0077, policy_loss: 0.9935, value_loss: 0.6502
2024-07-11 16:51:16,837 [INFO    ] __main__: train step 12134: loss: 1.0077, policy_loss: 0.9935, value_loss: 0.6501
2024-07-11 16:51:17,046 [INFO    ] __main__: train step 12135: loss: 1.0077, policy_loss: 0.9935, value_loss: 0.6501
2024-07-11 16:51:17,268 [INFO    ] __main__: train step 12136: loss: 1.0077, policy_loss: 0.9935, value_loss: 0.6501
2024-07-11 16:51:17,482 [INFO    ] __main__: train step 12137: loss: 1.0077, policy_loss: 0.9934, value_loss: 0.6500
2024-07-11 16:51:18,903 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:51:19,335 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:51:19,399 [INFO    ] __main__: train step 12138: loss: 1.0077, policy_loss: 0.9934, value_loss: 0.6500
2024-07-11 16:51:19,582 [INFO    ] __main__: train step 12139: loss: 1.0077, policy_loss: 0.9934, value_loss: 0.6500
2024-07-11 16:51:19,808 [INFO    ] __main__: train step 12140: loss: 1.0077, policy_loss: 0.9933, value_loss: 0.6500
2024-07-11 16:51:20,000 [INFO    ] __main__: train step 12141: loss: 1.0077, policy_loss: 0.9933, value_loss: 0.6499
2024-07-11 16:51:20,222 [INFO    ] __main__: train step 12142: loss: 1.0077, policy_loss: 0.9933, value_loss: 0.6499
2024-07-11 16:51:20,417 [INFO    ] __main__: train step 12143: loss: 1.0077, policy_loss: 0.9933, value_loss: 0.6499
2024-07-11 16:51:20,625 [INFO    ] __main__: train step 12144: loss: 1.0077, policy_loss: 0.9932, value_loss: 0.6498
2024-07-11 16:51:20,847 [INFO    ] __main__: train step 12145: loss: 1.0077, policy_loss: 0.9932, value_loss: 0.6498
2024-07-11 16:51:21,077 [INFO    ] __main__: train step 12146: loss: 1.0076, policy_loss: 0.9932, value_loss: 0.6498
2024-07-11 16:51:21,271 [INFO    ] __main__: train step 12147: loss: 1.0076, policy_loss: 0.9931, value_loss: 0.6498
2024-07-11 16:51:21,469 [INFO    ] __main__: train step 12148: loss: 1.0076, policy_loss: 0.9931, value_loss: 0.6497
2024-07-11 16:51:21,666 [INFO    ] __main__: train step 12149: loss: 1.0076, policy_loss: 0.9931, value_loss: 0.6497
2024-07-11 16:51:21,866 [INFO    ] __main__: train step 12150: loss: 1.0076, policy_loss: 0.9931, value_loss: 0.6497
2024-07-11 16:51:22,070 [INFO    ] __main__: train step 12151: loss: 1.0076, policy_loss: 0.9930, value_loss: 0.6496
2024-07-11 16:51:22,274 [INFO    ] __main__: train step 12152: loss: 1.0076, policy_loss: 0.9930, value_loss: 0.6496
2024-07-11 16:51:22,479 [INFO    ] __main__: train step 12153: loss: 1.0076, policy_loss: 0.9930, value_loss: 0.6496
2024-07-11 16:51:22,688 [INFO    ] __main__: train step 12154: loss: 1.0076, policy_loss: 0.9929, value_loss: 0.6496
2024-07-11 16:51:24,151 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:51:24,554 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:51:24,609 [INFO    ] __main__: train step 12155: loss: 1.0076, policy_loss: 0.9929, value_loss: 0.6495
2024-07-11 16:51:24,791 [INFO    ] __main__: train step 12156: loss: 1.0076, policy_loss: 0.9929, value_loss: 0.6495
2024-07-11 16:51:24,994 [INFO    ] __main__: train step 12157: loss: 1.0076, policy_loss: 0.9929, value_loss: 0.6495
2024-07-11 16:51:25,200 [INFO    ] __main__: train step 12158: loss: 1.0076, policy_loss: 0.9928, value_loss: 0.6495
2024-07-11 16:51:25,407 [INFO    ] __main__: train step 12159: loss: 1.0076, policy_loss: 0.9928, value_loss: 0.6494
2024-07-11 16:51:25,613 [INFO    ] __main__: train step 12160: loss: 1.0076, policy_loss: 0.9928, value_loss: 0.6494
2024-07-11 16:51:25,810 [INFO    ] __main__: train step 12161: loss: 1.0076, policy_loss: 0.9928, value_loss: 0.6494
2024-07-11 16:51:26,017 [INFO    ] __main__: train step 12162: loss: 1.0076, policy_loss: 0.9927, value_loss: 0.6493
2024-07-11 16:51:26,234 [INFO    ] __main__: train step 12163: loss: 1.0076, policy_loss: 0.9927, value_loss: 0.6493
2024-07-11 16:51:26,427 [INFO    ] __main__: train step 12164: loss: 1.0076, policy_loss: 0.9927, value_loss: 0.6493
2024-07-11 16:51:26,633 [INFO    ] __main__: train step 12165: loss: 1.0076, policy_loss: 0.9927, value_loss: 0.6493
2024-07-11 16:51:26,841 [INFO    ] __main__: train step 12166: loss: 1.0076, policy_loss: 0.9926, value_loss: 0.6492
2024-07-11 16:51:27,049 [INFO    ] __main__: train step 12167: loss: 1.0076, policy_loss: 0.9926, value_loss: 0.6492
2024-07-11 16:51:27,283 [INFO    ] __main__: train step 12168: loss: 1.0076, policy_loss: 0.9926, value_loss: 0.6492
2024-07-11 16:51:27,483 [INFO    ] __main__: train step 12169: loss: 1.0076, policy_loss: 0.9925, value_loss: 0.6491
2024-07-11 16:51:27,681 [INFO    ] __main__: train step 12170: loss: 1.0076, policy_loss: 0.9925, value_loss: 0.6491
2024-07-11 16:51:27,885 [INFO    ] __main__: train step 12171: loss: 1.0076, policy_loss: 0.9925, value_loss: 0.6491
2024-07-11 16:51:29,318 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:51:29,716 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:51:29,771 [INFO    ] __main__: train step 12172: loss: 1.0076, policy_loss: 0.9925, value_loss: 0.6491
2024-07-11 16:51:29,951 [INFO    ] __main__: train step 12173: loss: 1.0076, policy_loss: 0.9924, value_loss: 0.6490
2024-07-11 16:51:30,153 [INFO    ] __main__: train step 12174: loss: 1.0076, policy_loss: 0.9924, value_loss: 0.6490
2024-07-11 16:51:30,353 [INFO    ] __main__: train step 12175: loss: 1.0076, policy_loss: 0.9924, value_loss: 0.6490
2024-07-11 16:51:30,559 [INFO    ] __main__: train step 12176: loss: 1.0076, policy_loss: 0.9924, value_loss: 0.6490
2024-07-11 16:51:30,759 [INFO    ] __main__: train step 12177: loss: 1.0076, policy_loss: 0.9923, value_loss: 0.6489
2024-07-11 16:51:30,974 [INFO    ] __main__: train step 12178: loss: 1.0075, policy_loss: 0.9923, value_loss: 0.6489
2024-07-11 16:51:31,193 [INFO    ] __main__: train step 12179: loss: 1.0075, policy_loss: 0.9923, value_loss: 0.6489
2024-07-11 16:51:31,382 [INFO    ] __main__: train step 12180: loss: 1.0075, policy_loss: 0.9922, value_loss: 0.6488
2024-07-11 16:51:31,580 [INFO    ] __main__: train step 12181: loss: 1.0075, policy_loss: 0.9922, value_loss: 0.6488
2024-07-11 16:51:31,793 [INFO    ] __main__: train step 12182: loss: 1.0075, policy_loss: 0.9922, value_loss: 0.6488
2024-07-11 16:51:31,997 [INFO    ] __main__: train step 12183: loss: 1.0075, policy_loss: 0.9922, value_loss: 0.6488
2024-07-11 16:51:32,212 [INFO    ] __main__: train step 12184: loss: 1.0075, policy_loss: 0.9921, value_loss: 0.6487
2024-07-11 16:51:32,411 [INFO    ] __main__: train step 12185: loss: 1.0075, policy_loss: 0.9921, value_loss: 0.6487
2024-07-11 16:51:32,636 [INFO    ] __main__: train step 12186: loss: 1.0075, policy_loss: 0.9921, value_loss: 0.6487
2024-07-11 16:51:32,875 [INFO    ] __main__: train step 12187: loss: 1.0075, policy_loss: 0.9921, value_loss: 0.6486
2024-07-11 16:51:33,114 [INFO    ] __main__: train step 12188: loss: 1.0075, policy_loss: 0.9920, value_loss: 0.6486
2024-07-11 16:51:34,557 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:51:34,984 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:51:35,047 [INFO    ] __main__: train step 12189: loss: 1.0075, policy_loss: 0.9920, value_loss: 0.6486
2024-07-11 16:51:35,224 [INFO    ] __main__: train step 12190: loss: 1.0075, policy_loss: 0.9920, value_loss: 0.6486
2024-07-11 16:51:35,424 [INFO    ] __main__: train step 12191: loss: 1.0075, policy_loss: 0.9919, value_loss: 0.6485
2024-07-11 16:51:35,638 [INFO    ] __main__: train step 12192: loss: 1.0075, policy_loss: 0.9919, value_loss: 0.6485
2024-07-11 16:51:35,884 [INFO    ] __main__: train step 12193: loss: 1.0075, policy_loss: 0.9919, value_loss: 0.6485
2024-07-11 16:51:36,097 [INFO    ] __main__: train step 12194: loss: 1.0075, policy_loss: 0.9919, value_loss: 0.6484
2024-07-11 16:51:36,291 [INFO    ] __main__: train step 12195: loss: 1.0075, policy_loss: 0.9918, value_loss: 0.6484
2024-07-11 16:51:36,506 [INFO    ] __main__: train step 12196: loss: 1.0075, policy_loss: 0.9918, value_loss: 0.6484
2024-07-11 16:51:36,738 [INFO    ] __main__: train step 12197: loss: 1.0075, policy_loss: 0.9918, value_loss: 0.6484
2024-07-11 16:51:36,951 [INFO    ] __main__: train step 12198: loss: 1.0075, policy_loss: 0.9918, value_loss: 0.6483
2024-07-11 16:51:37,147 [INFO    ] __main__: train step 12199: loss: 1.0075, policy_loss: 0.9917, value_loss: 0.6483
2024-07-11 16:51:37,357 [INFO    ] __main__: train step 12200: loss: 1.0075, policy_loss: 0.9917, value_loss: 0.6483
2024-07-11 16:51:37,588 [INFO    ] __main__: train step 12201: loss: 1.0075, policy_loss: 0.9917, value_loss: 0.6483
2024-07-11 16:51:37,788 [INFO    ] __main__: train step 12202: loss: 1.0075, policy_loss: 0.9917, value_loss: 0.6482
2024-07-11 16:51:37,988 [INFO    ] __main__: train step 12203: loss: 1.0075, policy_loss: 0.9916, value_loss: 0.6482
2024-07-11 16:51:38,213 [INFO    ] __main__: train step 12204: loss: 1.0075, policy_loss: 0.9916, value_loss: 0.6482
2024-07-11 16:51:38,443 [INFO    ] __main__: train step 12205: loss: 1.0075, policy_loss: 0.9916, value_loss: 0.6481
2024-07-11 16:51:41,244 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:51:41,655 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:51:41,709 [INFO    ] __main__: train step 12206: loss: 1.0075, policy_loss: 0.9915, value_loss: 0.6481
2024-07-11 16:51:41,879 [INFO    ] __main__: train step 12207: loss: 1.0075, policy_loss: 0.9915, value_loss: 0.6481
2024-07-11 16:51:42,089 [INFO    ] __main__: train step 12208: loss: 1.0075, policy_loss: 0.9915, value_loss: 0.6481
2024-07-11 16:51:42,285 [INFO    ] __main__: train step 12209: loss: 1.0075, policy_loss: 0.9915, value_loss: 0.6480
2024-07-11 16:51:42,490 [INFO    ] __main__: train step 12210: loss: 1.0075, policy_loss: 0.9914, value_loss: 0.6480
2024-07-11 16:51:42,692 [INFO    ] __main__: train step 12211: loss: 1.0075, policy_loss: 0.9914, value_loss: 0.6480
2024-07-11 16:51:42,895 [INFO    ] __main__: train step 12212: loss: 1.0074, policy_loss: 0.9914, value_loss: 0.6479
2024-07-11 16:51:43,095 [INFO    ] __main__: train step 12213: loss: 1.0074, policy_loss: 0.9914, value_loss: 0.6479
2024-07-11 16:51:43,306 [INFO    ] __main__: train step 12214: loss: 1.0074, policy_loss: 0.9913, value_loss: 0.6479
2024-07-11 16:51:43,504 [INFO    ] __main__: train step 12215: loss: 1.0074, policy_loss: 0.9913, value_loss: 0.6479
2024-07-11 16:51:43,707 [INFO    ] __main__: train step 12216: loss: 1.0074, policy_loss: 0.9913, value_loss: 0.6478
2024-07-11 16:51:43,909 [INFO    ] __main__: train step 12217: loss: 1.0074, policy_loss: 0.9913, value_loss: 0.6478
2024-07-11 16:51:44,117 [INFO    ] __main__: train step 12218: loss: 1.0074, policy_loss: 0.9912, value_loss: 0.6478
2024-07-11 16:51:44,329 [INFO    ] __main__: train step 12219: loss: 1.0074, policy_loss: 0.9912, value_loss: 0.6477
2024-07-11 16:51:44,524 [INFO    ] __main__: train step 12220: loss: 1.0074, policy_loss: 0.9912, value_loss: 0.6477
2024-07-11 16:51:44,728 [INFO    ] __main__: train step 12221: loss: 1.0074, policy_loss: 0.9911, value_loss: 0.6477
2024-07-11 16:51:44,932 [INFO    ] __main__: train step 12222: loss: 1.0074, policy_loss: 0.9911, value_loss: 0.6477
2024-07-11 16:51:46,374 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:51:46,768 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:51:46,827 [INFO    ] __main__: train step 12223: loss: 1.0074, policy_loss: 0.9911, value_loss: 0.6476
2024-07-11 16:51:47,015 [INFO    ] __main__: train step 12224: loss: 1.0074, policy_loss: 0.9911, value_loss: 0.6476
2024-07-11 16:51:47,231 [INFO    ] __main__: train step 12225: loss: 1.0074, policy_loss: 0.9910, value_loss: 0.6476
2024-07-11 16:51:47,466 [INFO    ] __main__: train step 12226: loss: 1.0074, policy_loss: 0.9910, value_loss: 0.6475
2024-07-11 16:51:47,668 [INFO    ] __main__: train step 12227: loss: 1.0074, policy_loss: 0.9910, value_loss: 0.6475
2024-07-11 16:51:47,877 [INFO    ] __main__: train step 12228: loss: 1.0074, policy_loss: 0.9910, value_loss: 0.6475
2024-07-11 16:51:48,109 [INFO    ] __main__: train step 12229: loss: 1.0074, policy_loss: 0.9909, value_loss: 0.6475
2024-07-11 16:51:48,306 [INFO    ] __main__: train step 12230: loss: 1.0074, policy_loss: 0.9909, value_loss: 0.6474
2024-07-11 16:51:48,510 [INFO    ] __main__: train step 12231: loss: 1.0074, policy_loss: 0.9909, value_loss: 0.6474
2024-07-11 16:51:48,706 [INFO    ] __main__: train step 12232: loss: 1.0074, policy_loss: 0.9909, value_loss: 0.6474
2024-07-11 16:51:48,910 [INFO    ] __main__: train step 12233: loss: 1.0074, policy_loss: 0.9908, value_loss: 0.6474
2024-07-11 16:51:49,103 [INFO    ] __main__: train step 12234: loss: 1.0074, policy_loss: 0.9908, value_loss: 0.6473
2024-07-11 16:51:49,303 [INFO    ] __main__: train step 12235: loss: 1.0074, policy_loss: 0.9908, value_loss: 0.6473
2024-07-11 16:51:49,508 [INFO    ] __main__: train step 12236: loss: 1.0074, policy_loss: 0.9908, value_loss: 0.6473
2024-07-11 16:51:49,707 [INFO    ] __main__: train step 12237: loss: 1.0074, policy_loss: 0.9907, value_loss: 0.6472
2024-07-11 16:51:49,915 [INFO    ] __main__: train step 12238: loss: 1.0074, policy_loss: 0.9907, value_loss: 0.6472
2024-07-11 16:51:50,124 [INFO    ] __main__: train step 12239: loss: 1.0074, policy_loss: 0.9907, value_loss: 0.6472
2024-07-11 16:51:51,559 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:51:51,973 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:51:52,029 [INFO    ] __main__: train step 12240: loss: 1.0074, policy_loss: 0.9906, value_loss: 0.6472
2024-07-11 16:51:52,205 [INFO    ] __main__: train step 12241: loss: 1.0074, policy_loss: 0.9906, value_loss: 0.6471
2024-07-11 16:51:52,400 [INFO    ] __main__: train step 12242: loss: 1.0074, policy_loss: 0.9906, value_loss: 0.6471
2024-07-11 16:51:52,607 [INFO    ] __main__: train step 12243: loss: 1.0074, policy_loss: 0.9906, value_loss: 0.6471
2024-07-11 16:51:52,814 [INFO    ] __main__: train step 12244: loss: 1.0074, policy_loss: 0.9905, value_loss: 0.6470
2024-07-11 16:51:53,015 [INFO    ] __main__: train step 12245: loss: 1.0074, policy_loss: 0.9905, value_loss: 0.6470
2024-07-11 16:51:53,237 [INFO    ] __main__: train step 12246: loss: 1.0073, policy_loss: 0.9905, value_loss: 0.6470
2024-07-11 16:51:53,484 [INFO    ] __main__: train step 12247: loss: 1.0073, policy_loss: 0.9905, value_loss: 0.6470
2024-07-11 16:51:53,684 [INFO    ] __main__: train step 12248: loss: 1.0073, policy_loss: 0.9904, value_loss: 0.6469
2024-07-11 16:51:53,906 [INFO    ] __main__: train step 12249: loss: 1.0073, policy_loss: 0.9904, value_loss: 0.6469
2024-07-11 16:51:54,120 [INFO    ] __main__: train step 12250: loss: 1.0073, policy_loss: 0.9904, value_loss: 0.6469
2024-07-11 16:51:54,321 [INFO    ] __main__: train step 12251: loss: 1.0073, policy_loss: 0.9904, value_loss: 0.6468
2024-07-11 16:51:54,518 [INFO    ] __main__: train step 12252: loss: 1.0073, policy_loss: 0.9903, value_loss: 0.6468
2024-07-11 16:51:54,722 [INFO    ] __main__: train step 12253: loss: 1.0073, policy_loss: 0.9903, value_loss: 0.6468
2024-07-11 16:51:54,931 [INFO    ] __main__: train step 12254: loss: 1.0073, policy_loss: 0.9903, value_loss: 0.6468
2024-07-11 16:51:55,133 [INFO    ] __main__: train step 12255: loss: 1.0073, policy_loss: 0.9902, value_loss: 0.6467
2024-07-11 16:51:55,327 [INFO    ] __main__: train step 12256: loss: 1.0073, policy_loss: 0.9902, value_loss: 0.6467
2024-07-11 16:51:56,766 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:51:57,175 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:51:57,229 [INFO    ] __main__: train step 12257: loss: 1.0073, policy_loss: 0.9902, value_loss: 0.6467
2024-07-11 16:51:57,411 [INFO    ] __main__: train step 12258: loss: 1.0073, policy_loss: 0.9902, value_loss: 0.6467
2024-07-11 16:51:57,605 [INFO    ] __main__: train step 12259: loss: 1.0073, policy_loss: 0.9901, value_loss: 0.6466
2024-07-11 16:51:57,810 [INFO    ] __main__: train step 12260: loss: 1.0073, policy_loss: 0.9901, value_loss: 0.6466
2024-07-11 16:51:58,011 [INFO    ] __main__: train step 12261: loss: 1.0073, policy_loss: 0.9901, value_loss: 0.6466
2024-07-11 16:51:58,217 [INFO    ] __main__: train step 12262: loss: 1.0073, policy_loss: 0.9901, value_loss: 0.6465
2024-07-11 16:51:58,409 [INFO    ] __main__: train step 12263: loss: 1.0073, policy_loss: 0.9900, value_loss: 0.6465
2024-07-11 16:51:58,622 [INFO    ] __main__: train step 12264: loss: 1.0073, policy_loss: 0.9900, value_loss: 0.6465
2024-07-11 16:51:58,817 [INFO    ] __main__: train step 12265: loss: 1.0073, policy_loss: 0.9900, value_loss: 0.6465
2024-07-11 16:51:59,019 [INFO    ] __main__: train step 12266: loss: 1.0073, policy_loss: 0.9900, value_loss: 0.6464
2024-07-11 16:51:59,229 [INFO    ] __main__: train step 12267: loss: 1.0073, policy_loss: 0.9899, value_loss: 0.6464
2024-07-11 16:51:59,445 [INFO    ] __main__: train step 12268: loss: 1.0073, policy_loss: 0.9899, value_loss: 0.6464
2024-07-11 16:51:59,639 [INFO    ] __main__: train step 12269: loss: 1.0073, policy_loss: 0.9899, value_loss: 0.6464
2024-07-11 16:51:59,848 [INFO    ] __main__: train step 12270: loss: 1.0073, policy_loss: 0.9898, value_loss: 0.6463
2024-07-11 16:52:00,053 [INFO    ] __main__: train step 12271: loss: 1.0073, policy_loss: 0.9898, value_loss: 0.6463
2024-07-11 16:52:00,252 [INFO    ] __main__: train step 12272: loss: 1.0073, policy_loss: 0.9898, value_loss: 0.6463
2024-07-11 16:52:00,446 [INFO    ] __main__: train step 12273: loss: 1.0073, policy_loss: 0.9898, value_loss: 0.6462
2024-07-11 16:52:01,891 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:52:02,297 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:52:02,358 [INFO    ] __main__: train step 12274: loss: 1.0073, policy_loss: 0.9897, value_loss: 0.6462
2024-07-11 16:52:02,546 [INFO    ] __main__: train step 12275: loss: 1.0073, policy_loss: 0.9897, value_loss: 0.6462
2024-07-11 16:52:02,782 [INFO    ] __main__: train step 12276: loss: 1.0073, policy_loss: 0.9897, value_loss: 0.6462
2024-07-11 16:52:03,005 [INFO    ] __main__: train step 12277: loss: 1.0073, policy_loss: 0.9897, value_loss: 0.6461
2024-07-11 16:52:03,202 [INFO    ] __main__: train step 12278: loss: 1.0073, policy_loss: 0.9896, value_loss: 0.6461
2024-07-11 16:52:03,406 [INFO    ] __main__: train step 12279: loss: 1.0072, policy_loss: 0.9896, value_loss: 0.6461
2024-07-11 16:52:03,610 [INFO    ] __main__: train step 12280: loss: 1.0072, policy_loss: 0.9896, value_loss: 0.6460
2024-07-11 16:52:03,827 [INFO    ] __main__: train step 12281: loss: 1.0072, policy_loss: 0.9896, value_loss: 0.6460
2024-07-11 16:52:04,025 [INFO    ] __main__: train step 12282: loss: 1.0072, policy_loss: 0.9895, value_loss: 0.6460
2024-07-11 16:52:04,249 [INFO    ] __main__: train step 12283: loss: 1.0072, policy_loss: 0.9895, value_loss: 0.6460
2024-07-11 16:52:04,457 [INFO    ] __main__: train step 12284: loss: 1.0072, policy_loss: 0.9895, value_loss: 0.6459
2024-07-11 16:52:04,660 [INFO    ] __main__: train step 12285: loss: 1.0072, policy_loss: 0.9895, value_loss: 0.6459
2024-07-11 16:52:04,858 [INFO    ] __main__: train step 12286: loss: 1.0072, policy_loss: 0.9894, value_loss: 0.6459
2024-07-11 16:52:05,066 [INFO    ] __main__: train step 12287: loss: 1.0072, policy_loss: 0.9894, value_loss: 0.6458
2024-07-11 16:52:05,272 [INFO    ] __main__: train step 12288: loss: 1.0072, policy_loss: 0.9894, value_loss: 0.6458
2024-07-11 16:52:05,488 [INFO    ] __main__: train step 12289: loss: 1.0072, policy_loss: 0.9893, value_loss: 0.6458
2024-07-11 16:52:05,692 [INFO    ] __main__: train step 12290: loss: 1.0072, policy_loss: 0.9893, value_loss: 0.6458
2024-07-11 16:52:07,138 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:52:07,515 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:52:07,573 [INFO    ] __main__: train step 12291: loss: 1.0072, policy_loss: 0.9893, value_loss: 0.6457
2024-07-11 16:52:07,742 [INFO    ] __main__: train step 12292: loss: 1.0072, policy_loss: 0.9893, value_loss: 0.6457
2024-07-11 16:52:07,948 [INFO    ] __main__: train step 12293: loss: 1.0072, policy_loss: 0.9892, value_loss: 0.6457
2024-07-11 16:52:08,157 [INFO    ] __main__: train step 12294: loss: 1.0072, policy_loss: 0.9892, value_loss: 0.6457
2024-07-11 16:52:08,360 [INFO    ] __main__: train step 12295: loss: 1.0072, policy_loss: 0.9892, value_loss: 0.6456
2024-07-11 16:52:08,552 [INFO    ] __main__: train step 12296: loss: 1.0072, policy_loss: 0.9892, value_loss: 0.6456
2024-07-11 16:52:08,750 [INFO    ] __main__: train step 12297: loss: 1.0072, policy_loss: 0.9891, value_loss: 0.6456
2024-07-11 16:52:08,966 [INFO    ] __main__: train step 12298: loss: 1.0072, policy_loss: 0.9891, value_loss: 0.6455
2024-07-11 16:52:09,169 [INFO    ] __main__: train step 12299: loss: 1.0072, policy_loss: 0.9891, value_loss: 0.6455
2024-07-11 16:52:09,376 [INFO    ] __main__: train step 12300: loss: 1.0072, policy_loss: 0.9891, value_loss: 0.6455
2024-07-11 16:52:09,579 [INFO    ] __main__: train step 12301: loss: 1.0072, policy_loss: 0.9890, value_loss: 0.6455
2024-07-11 16:52:09,772 [INFO    ] __main__: train step 12302: loss: 1.0072, policy_loss: 0.9890, value_loss: 0.6454
2024-07-11 16:52:09,972 [INFO    ] __main__: train step 12303: loss: 1.0072, policy_loss: 0.9890, value_loss: 0.6454
2024-07-11 16:52:11,550 [INFO    ] __main__: train step 12304: loss: 1.0072, policy_loss: 0.9890, value_loss: 0.6454
2024-07-11 16:52:11,777 [INFO    ] __main__: train step 12305: loss: 1.0072, policy_loss: 0.9889, value_loss: 0.6453
2024-07-11 16:52:11,975 [INFO    ] __main__: train step 12306: loss: 1.0072, policy_loss: 0.9889, value_loss: 0.6453
2024-07-11 16:52:12,175 [INFO    ] __main__: train step 12307: loss: 1.0072, policy_loss: 0.9889, value_loss: 0.6453
2024-07-11 16:52:13,624 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:52:14,032 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:52:14,089 [INFO    ] __main__: train step 12308: loss: 1.0072, policy_loss: 0.9889, value_loss: 0.6453
2024-07-11 16:52:14,273 [INFO    ] __main__: train step 12309: loss: 1.0072, policy_loss: 0.9888, value_loss: 0.6452
2024-07-11 16:52:14,516 [INFO    ] __main__: train step 12310: loss: 1.0072, policy_loss: 0.9888, value_loss: 0.6452
2024-07-11 16:52:14,726 [INFO    ] __main__: train step 12311: loss: 1.0072, policy_loss: 0.9888, value_loss: 0.6452
2024-07-11 16:52:14,956 [INFO    ] __main__: train step 12312: loss: 1.0071, policy_loss: 0.9888, value_loss: 0.6451
2024-07-11 16:52:15,191 [INFO    ] __main__: train step 12313: loss: 1.0071, policy_loss: 0.9887, value_loss: 0.6451
2024-07-11 16:52:15,396 [INFO    ] __main__: train step 12314: loss: 1.0071, policy_loss: 0.9887, value_loss: 0.6451
2024-07-11 16:52:15,617 [INFO    ] __main__: train step 12315: loss: 1.0071, policy_loss: 0.9887, value_loss: 0.6451
2024-07-11 16:52:15,823 [INFO    ] __main__: train step 12316: loss: 1.0071, policy_loss: 0.9886, value_loss: 0.6450
2024-07-11 16:52:16,036 [INFO    ] __main__: train step 12317: loss: 1.0071, policy_loss: 0.9886, value_loss: 0.6450
2024-07-11 16:52:16,250 [INFO    ] __main__: train step 12318: loss: 1.0071, policy_loss: 0.9886, value_loss: 0.6450
2024-07-11 16:52:16,459 [INFO    ] __main__: train step 12319: loss: 1.0071, policy_loss: 0.9886, value_loss: 0.6450
2024-07-11 16:52:16,668 [INFO    ] __main__: train step 12320: loss: 1.0071, policy_loss: 0.9885, value_loss: 0.6449
2024-07-11 16:52:16,877 [INFO    ] __main__: train step 12321: loss: 1.0071, policy_loss: 0.9885, value_loss: 0.6449
2024-07-11 16:52:17,100 [INFO    ] __main__: train step 12322: loss: 1.0071, policy_loss: 0.9885, value_loss: 0.6449
2024-07-11 16:52:17,301 [INFO    ] __main__: train step 12323: loss: 1.0071, policy_loss: 0.9885, value_loss: 0.6448
2024-07-11 16:52:17,508 [INFO    ] __main__: train step 12324: loss: 1.0071, policy_loss: 0.9884, value_loss: 0.6448
2024-07-11 16:52:18,934 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:52:19,358 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:52:19,413 [INFO    ] __main__: train step 12325: loss: 1.0071, policy_loss: 0.9884, value_loss: 0.6448
2024-07-11 16:52:19,595 [INFO    ] __main__: train step 12326: loss: 1.0071, policy_loss: 0.9884, value_loss: 0.6448
2024-07-11 16:52:19,801 [INFO    ] __main__: train step 12327: loss: 1.0071, policy_loss: 0.9884, value_loss: 0.6447
2024-07-11 16:52:20,001 [INFO    ] __main__: train step 12328: loss: 1.0071, policy_loss: 0.9883, value_loss: 0.6447
2024-07-11 16:52:20,212 [INFO    ] __main__: train step 12329: loss: 1.0071, policy_loss: 0.9883, value_loss: 0.6447
2024-07-11 16:52:20,415 [INFO    ] __main__: train step 12330: loss: 1.0071, policy_loss: 0.9883, value_loss: 0.6446
2024-07-11 16:52:20,624 [INFO    ] __main__: train step 12331: loss: 1.0071, policy_loss: 0.9883, value_loss: 0.6446
2024-07-11 16:52:20,829 [INFO    ] __main__: train step 12332: loss: 1.0071, policy_loss: 0.9882, value_loss: 0.6446
2024-07-11 16:52:21,040 [INFO    ] __main__: train step 12333: loss: 1.0071, policy_loss: 0.9882, value_loss: 0.6446
2024-07-11 16:52:21,240 [INFO    ] __main__: train step 12334: loss: 1.0071, policy_loss: 0.9882, value_loss: 0.6445
2024-07-11 16:52:21,456 [INFO    ] __main__: train step 12335: loss: 1.0071, policy_loss: 0.9882, value_loss: 0.6445
2024-07-11 16:52:21,655 [INFO    ] __main__: train step 12336: loss: 1.0071, policy_loss: 0.9881, value_loss: 0.6445
2024-07-11 16:52:21,859 [INFO    ] __main__: train step 12337: loss: 1.0071, policy_loss: 0.9881, value_loss: 0.6445
2024-07-11 16:52:22,074 [INFO    ] __main__: train step 12338: loss: 1.0071, policy_loss: 0.9881, value_loss: 0.6444
2024-07-11 16:52:22,270 [INFO    ] __main__: train step 12339: loss: 1.0071, policy_loss: 0.9881, value_loss: 0.6444
2024-07-11 16:52:22,469 [INFO    ] __main__: train step 12340: loss: 1.0071, policy_loss: 0.9880, value_loss: 0.6444
2024-07-11 16:52:22,665 [INFO    ] __main__: train step 12341: loss: 1.0071, policy_loss: 0.9880, value_loss: 0.6443
2024-07-11 16:52:24,116 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:52:24,494 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:52:24,552 [INFO    ] __main__: train step 12342: loss: 1.0071, policy_loss: 0.9880, value_loss: 0.6443
2024-07-11 16:52:24,724 [INFO    ] __main__: train step 12343: loss: 1.0071, policy_loss: 0.9880, value_loss: 0.6443
2024-07-11 16:52:24,938 [INFO    ] __main__: train step 12344: loss: 1.0071, policy_loss: 0.9879, value_loss: 0.6443
2024-07-11 16:52:25,141 [INFO    ] __main__: train step 12345: loss: 1.0071, policy_loss: 0.9879, value_loss: 0.6442
2024-07-11 16:52:25,347 [INFO    ] __main__: train step 12346: loss: 1.0071, policy_loss: 0.9879, value_loss: 0.6442
2024-07-11 16:52:25,552 [INFO    ] __main__: train step 12347: loss: 1.0071, policy_loss: 0.9879, value_loss: 0.6442
2024-07-11 16:52:25,764 [INFO    ] __main__: train step 12348: loss: 1.0071, policy_loss: 0.9878, value_loss: 0.6442
2024-07-11 16:52:25,962 [INFO    ] __main__: train step 12349: loss: 1.0071, policy_loss: 0.9878, value_loss: 0.6441
2024-07-11 16:52:26,187 [INFO    ] __main__: train step 12350: loss: 1.0071, policy_loss: 0.9878, value_loss: 0.6441
2024-07-11 16:52:26,399 [INFO    ] __main__: train step 12351: loss: 1.0071, policy_loss: 0.9878, value_loss: 0.6441
2024-07-11 16:52:26,624 [INFO    ] __main__: train step 12352: loss: 1.0071, policy_loss: 0.9877, value_loss: 0.6440
2024-07-11 16:52:26,862 [INFO    ] __main__: train step 12353: loss: 1.0070, policy_loss: 0.9877, value_loss: 0.6440
2024-07-11 16:52:27,105 [INFO    ] __main__: train step 12354: loss: 1.0070, policy_loss: 0.9877, value_loss: 0.6440
2024-07-11 16:52:27,327 [INFO    ] __main__: train step 12355: loss: 1.0070, policy_loss: 0.9877, value_loss: 0.6440
2024-07-11 16:52:27,540 [INFO    ] __main__: train step 12356: loss: 1.0070, policy_loss: 0.9876, value_loss: 0.6439
2024-07-11 16:52:27,737 [INFO    ] __main__: train step 12357: loss: 1.0070, policy_loss: 0.9876, value_loss: 0.6439
2024-07-11 16:52:27,939 [INFO    ] __main__: train step 12358: loss: 1.0070, policy_loss: 0.9876, value_loss: 0.6439
2024-07-11 16:52:29,379 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:52:29,779 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:52:29,836 [INFO    ] __main__: train step 12359: loss: 1.0070, policy_loss: 0.9876, value_loss: 0.6439
2024-07-11 16:52:30,014 [INFO    ] __main__: train step 12360: loss: 1.0070, policy_loss: 0.9875, value_loss: 0.6438
2024-07-11 16:52:30,215 [INFO    ] __main__: train step 12361: loss: 1.0070, policy_loss: 0.9875, value_loss: 0.6438
2024-07-11 16:52:30,421 [INFO    ] __main__: train step 12362: loss: 1.0070, policy_loss: 0.9875, value_loss: 0.6438
2024-07-11 16:52:30,629 [INFO    ] __main__: train step 12363: loss: 1.0070, policy_loss: 0.9875, value_loss: 0.6437
2024-07-11 16:52:30,839 [INFO    ] __main__: train step 12364: loss: 1.0070, policy_loss: 0.9874, value_loss: 0.6437
2024-07-11 16:52:31,043 [INFO    ] __main__: train step 12365: loss: 1.0070, policy_loss: 0.9874, value_loss: 0.6437
2024-07-11 16:52:31,242 [INFO    ] __main__: train step 12366: loss: 1.0070, policy_loss: 0.9874, value_loss: 0.6437
2024-07-11 16:52:31,443 [INFO    ] __main__: train step 12367: loss: 1.0070, policy_loss: 0.9873, value_loss: 0.6436
2024-07-11 16:52:31,649 [INFO    ] __main__: train step 12368: loss: 1.0070, policy_loss: 0.9873, value_loss: 0.6436
2024-07-11 16:52:31,849 [INFO    ] __main__: train step 12369: loss: 1.0070, policy_loss: 0.9873, value_loss: 0.6436
2024-07-11 16:52:32,047 [INFO    ] __main__: train step 12370: loss: 1.0070, policy_loss: 0.9873, value_loss: 0.6436
2024-07-11 16:52:32,266 [INFO    ] __main__: train step 12371: loss: 1.0070, policy_loss: 0.9872, value_loss: 0.6435
2024-07-11 16:52:32,472 [INFO    ] __main__: train step 12372: loss: 1.0070, policy_loss: 0.9872, value_loss: 0.6435
2024-07-11 16:52:32,713 [INFO    ] __main__: train step 12373: loss: 1.0070, policy_loss: 0.9872, value_loss: 0.6435
2024-07-11 16:52:32,916 [INFO    ] __main__: train step 12374: loss: 1.0070, policy_loss: 0.9872, value_loss: 0.6434
2024-07-11 16:52:33,122 [INFO    ] __main__: train step 12375: loss: 1.0070, policy_loss: 0.9871, value_loss: 0.6434
2024-07-11 16:52:34,557 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:52:34,987 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:52:35,052 [INFO    ] __main__: train step 12376: loss: 1.0070, policy_loss: 0.9871, value_loss: 0.6434
2024-07-11 16:52:35,228 [INFO    ] __main__: train step 12377: loss: 1.0070, policy_loss: 0.9871, value_loss: 0.6434
2024-07-11 16:52:35,434 [INFO    ] __main__: train step 12378: loss: 1.0070, policy_loss: 0.9871, value_loss: 0.6433
2024-07-11 16:52:35,638 [INFO    ] __main__: train step 12379: loss: 1.0070, policy_loss: 0.9870, value_loss: 0.6433
2024-07-11 16:52:35,867 [INFO    ] __main__: train step 12380: loss: 1.0070, policy_loss: 0.9870, value_loss: 0.6433
2024-07-11 16:52:36,105 [INFO    ] __main__: train step 12381: loss: 1.0070, policy_loss: 0.9870, value_loss: 0.6433
2024-07-11 16:52:36,306 [INFO    ] __main__: train step 12382: loss: 1.0070, policy_loss: 0.9870, value_loss: 0.6432
2024-07-11 16:52:36,523 [INFO    ] __main__: train step 12383: loss: 1.0070, policy_loss: 0.9869, value_loss: 0.6432
2024-07-11 16:52:36,736 [INFO    ] __main__: train step 12384: loss: 1.0070, policy_loss: 0.9869, value_loss: 0.6432
2024-07-11 16:52:36,936 [INFO    ] __main__: train step 12385: loss: 1.0070, policy_loss: 0.9869, value_loss: 0.6432
2024-07-11 16:52:37,135 [INFO    ] __main__: train step 12386: loss: 1.0070, policy_loss: 0.9869, value_loss: 0.6431
2024-07-11 16:52:37,339 [INFO    ] __main__: train step 12387: loss: 1.0070, policy_loss: 0.9868, value_loss: 0.6431
2024-07-11 16:52:37,548 [INFO    ] __main__: train step 12388: loss: 1.0070, policy_loss: 0.9868, value_loss: 0.6431
2024-07-11 16:52:37,750 [INFO    ] __main__: train step 12389: loss: 1.0070, policy_loss: 0.9868, value_loss: 0.6430
2024-07-11 16:52:37,952 [INFO    ] __main__: train step 12390: loss: 1.0070, policy_loss: 0.9868, value_loss: 0.6430
2024-07-11 16:52:38,168 [INFO    ] __main__: train step 12391: loss: 1.0070, policy_loss: 0.9867, value_loss: 0.6430
2024-07-11 16:52:38,370 [INFO    ] __main__: train step 12392: loss: 1.0070, policy_loss: 0.9867, value_loss: 0.6430
2024-07-11 16:52:39,826 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:52:40,224 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:52:40,279 [INFO    ] __main__: train step 12393: loss: 1.0070, policy_loss: 0.9867, value_loss: 0.6429
2024-07-11 16:52:40,450 [INFO    ] __main__: train step 12394: loss: 1.0070, policy_loss: 0.9867, value_loss: 0.6429
2024-07-11 16:52:40,647 [INFO    ] __main__: train step 12395: loss: 1.0070, policy_loss: 0.9866, value_loss: 0.6429
2024-07-11 16:52:40,855 [INFO    ] __main__: train step 12396: loss: 1.0070, policy_loss: 0.9866, value_loss: 0.6428
2024-07-11 16:52:41,064 [INFO    ] __main__: train step 12397: loss: 1.0070, policy_loss: 0.9866, value_loss: 0.6428
2024-07-11 16:52:41,293 [INFO    ] __main__: train step 12398: loss: 1.0070, policy_loss: 0.9866, value_loss: 0.6428
2024-07-11 16:52:41,512 [INFO    ] __main__: train step 12399: loss: 1.0070, policy_loss: 0.9865, value_loss: 0.6428
2024-07-11 16:52:41,736 [INFO    ] __main__: train step 12400: loss: 1.0070, policy_loss: 0.9865, value_loss: 0.6427
2024-07-11 16:52:41,943 [INFO    ] __main__: train step 12401: loss: 1.0070, policy_loss: 0.9865, value_loss: 0.6427
2024-07-11 16:52:43,483 [INFO    ] __main__: train step 12402: loss: 1.0069, policy_loss: 0.9865, value_loss: 0.6427
2024-07-11 16:52:43,693 [INFO    ] __main__: train step 12403: loss: 1.0069, policy_loss: 0.9864, value_loss: 0.6427
2024-07-11 16:52:43,929 [INFO    ] __main__: train step 12404: loss: 1.0069, policy_loss: 0.9864, value_loss: 0.6426
2024-07-11 16:52:44,148 [INFO    ] __main__: train step 12405: loss: 1.0069, policy_loss: 0.9864, value_loss: 0.6426
2024-07-11 16:52:44,381 [INFO    ] __main__: train step 12406: loss: 1.0069, policy_loss: 0.9864, value_loss: 0.6426
2024-07-11 16:52:44,612 [INFO    ] __main__: train step 12407: loss: 1.0069, policy_loss: 0.9863, value_loss: 0.6425
2024-07-11 16:52:44,841 [INFO    ] __main__: train step 12408: loss: 1.0069, policy_loss: 0.9863, value_loss: 0.6425
2024-07-11 16:52:45,041 [INFO    ] __main__: train step 12409: loss: 1.0069, policy_loss: 0.9863, value_loss: 0.6425
2024-07-11 16:52:46,481 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:52:46,867 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:52:46,925 [INFO    ] __main__: train step 12410: loss: 1.0069, policy_loss: 0.9863, value_loss: 0.6425
2024-07-11 16:52:47,100 [INFO    ] __main__: train step 12411: loss: 1.0069, policy_loss: 0.9862, value_loss: 0.6424
2024-07-11 16:52:47,314 [INFO    ] __main__: train step 12412: loss: 1.0069, policy_loss: 0.9862, value_loss: 0.6424
2024-07-11 16:52:47,573 [INFO    ] __main__: train step 12413: loss: 1.0069, policy_loss: 0.9862, value_loss: 0.6424
2024-07-11 16:52:47,810 [INFO    ] __main__: train step 12414: loss: 1.0069, policy_loss: 0.9862, value_loss: 0.6424
2024-07-11 16:52:48,013 [INFO    ] __main__: train step 12415: loss: 1.0069, policy_loss: 0.9861, value_loss: 0.6423
2024-07-11 16:52:48,233 [INFO    ] __main__: train step 12416: loss: 1.0069, policy_loss: 0.9861, value_loss: 0.6423
2024-07-11 16:52:48,437 [INFO    ] __main__: train step 12417: loss: 1.0069, policy_loss: 0.9861, value_loss: 0.6423
2024-07-11 16:52:48,643 [INFO    ] __main__: train step 12418: loss: 1.0069, policy_loss: 0.9861, value_loss: 0.6423
2024-07-11 16:52:48,853 [INFO    ] __main__: train step 12419: loss: 1.0069, policy_loss: 0.9860, value_loss: 0.6422
2024-07-11 16:52:49,054 [INFO    ] __main__: train step 12420: loss: 1.0069, policy_loss: 0.9860, value_loss: 0.6422
2024-07-11 16:52:49,259 [INFO    ] __main__: train step 12421: loss: 1.0069, policy_loss: 0.9860, value_loss: 0.6422
2024-07-11 16:52:49,464 [INFO    ] __main__: train step 12422: loss: 1.0069, policy_loss: 0.9860, value_loss: 0.6421
2024-07-11 16:52:49,681 [INFO    ] __main__: train step 12423: loss: 1.0069, policy_loss: 0.9859, value_loss: 0.6421
2024-07-11 16:52:49,890 [INFO    ] __main__: train step 12424: loss: 1.0069, policy_loss: 0.9859, value_loss: 0.6421
2024-07-11 16:52:50,087 [INFO    ] __main__: train step 12425: loss: 1.0069, policy_loss: 0.9859, value_loss: 0.6421
2024-07-11 16:52:50,319 [INFO    ] __main__: train step 12426: loss: 1.0069, policy_loss: 0.9859, value_loss: 0.6420
2024-07-11 16:52:51,785 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:52:52,185 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:52:52,246 [INFO    ] __main__: train step 12427: loss: 1.0069, policy_loss: 0.9858, value_loss: 0.6420
2024-07-11 16:52:52,423 [INFO    ] __main__: train step 12428: loss: 1.0069, policy_loss: 0.9858, value_loss: 0.6420
2024-07-11 16:52:52,623 [INFO    ] __main__: train step 12429: loss: 1.0069, policy_loss: 0.9858, value_loss: 0.6419
2024-07-11 16:52:52,818 [INFO    ] __main__: train step 12430: loss: 1.0069, policy_loss: 0.9858, value_loss: 0.6419
2024-07-11 16:52:53,029 [INFO    ] __main__: train step 12431: loss: 1.0069, policy_loss: 0.9857, value_loss: 0.6419
2024-07-11 16:52:53,237 [INFO    ] __main__: train step 12432: loss: 1.0069, policy_loss: 0.9857, value_loss: 0.6419
2024-07-11 16:52:53,438 [INFO    ] __main__: train step 12433: loss: 1.0069, policy_loss: 0.9857, value_loss: 0.6418
2024-07-11 16:52:53,639 [INFO    ] __main__: train step 12434: loss: 1.0069, policy_loss: 0.9857, value_loss: 0.6418
2024-07-11 16:52:53,845 [INFO    ] __main__: train step 12435: loss: 1.0069, policy_loss: 0.9856, value_loss: 0.6418
2024-07-11 16:52:54,066 [INFO    ] __main__: train step 12436: loss: 1.0069, policy_loss: 0.9856, value_loss: 0.6418
2024-07-11 16:52:54,299 [INFO    ] __main__: train step 12437: loss: 1.0069, policy_loss: 0.9856, value_loss: 0.6417
2024-07-11 16:52:54,506 [INFO    ] __main__: train step 12438: loss: 1.0069, policy_loss: 0.9856, value_loss: 0.6417
2024-07-11 16:52:54,698 [INFO    ] __main__: train step 12439: loss: 1.0069, policy_loss: 0.9855, value_loss: 0.6417
2024-07-11 16:52:54,904 [INFO    ] __main__: train step 12440: loss: 1.0069, policy_loss: 0.9855, value_loss: 0.6416
2024-07-11 16:52:55,115 [INFO    ] __main__: train step 12441: loss: 1.0069, policy_loss: 0.9855, value_loss: 0.6416
2024-07-11 16:52:55,313 [INFO    ] __main__: train step 12442: loss: 1.0068, policy_loss: 0.9855, value_loss: 0.6416
2024-07-11 16:52:55,524 [INFO    ] __main__: train step 12443: loss: 1.0068, policy_loss: 0.9854, value_loss: 0.6416
2024-07-11 16:52:56,949 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:52:57,323 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:52:57,382 [INFO    ] __main__: train step 12444: loss: 1.0068, policy_loss: 0.9854, value_loss: 0.6415
2024-07-11 16:52:57,572 [INFO    ] __main__: train step 12445: loss: 1.0068, policy_loss: 0.9854, value_loss: 0.6415
2024-07-11 16:52:57,769 [INFO    ] __main__: train step 12446: loss: 1.0068, policy_loss: 0.9854, value_loss: 0.6415
2024-07-11 16:52:58,000 [INFO    ] __main__: train step 12447: loss: 1.0068, policy_loss: 0.9853, value_loss: 0.6415
2024-07-11 16:52:58,189 [INFO    ] __main__: train step 12448: loss: 1.0068, policy_loss: 0.9853, value_loss: 0.6414
2024-07-11 16:52:58,398 [INFO    ] __main__: train step 12449: loss: 1.0068, policy_loss: 0.9853, value_loss: 0.6414
2024-07-11 16:52:58,602 [INFO    ] __main__: train step 12450: loss: 1.0068, policy_loss: 0.9853, value_loss: 0.6414
2024-07-11 16:52:58,800 [INFO    ] __main__: train step 12451: loss: 1.0068, policy_loss: 0.9852, value_loss: 0.6413
2024-07-11 16:52:59,014 [INFO    ] __main__: train step 12452: loss: 1.0068, policy_loss: 0.9852, value_loss: 0.6413
2024-07-11 16:52:59,216 [INFO    ] __main__: train step 12453: loss: 1.0068, policy_loss: 0.9852, value_loss: 0.6413
2024-07-11 16:52:59,431 [INFO    ] __main__: train step 12454: loss: 1.0068, policy_loss: 0.9852, value_loss: 0.6413
2024-07-11 16:52:59,634 [INFO    ] __main__: train step 12455: loss: 1.0068, policy_loss: 0.9851, value_loss: 0.6412
2024-07-11 16:52:59,836 [INFO    ] __main__: train step 12456: loss: 1.0068, policy_loss: 0.9851, value_loss: 0.6412
2024-07-11 16:53:00,049 [INFO    ] __main__: train step 12457: loss: 1.0068, policy_loss: 0.9851, value_loss: 0.6412
2024-07-11 16:53:00,258 [INFO    ] __main__: train step 12458: loss: 1.0068, policy_loss: 0.9851, value_loss: 0.6412
2024-07-11 16:53:00,458 [INFO    ] __main__: train step 12459: loss: 1.0068, policy_loss: 0.9850, value_loss: 0.6411
2024-07-11 16:53:00,663 [INFO    ] __main__: train step 12460: loss: 1.0068, policy_loss: 0.9850, value_loss: 0.6411
2024-07-11 16:53:02,101 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:53:02,498 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:53:02,553 [INFO    ] __main__: train step 12461: loss: 1.0068, policy_loss: 0.9850, value_loss: 0.6411
2024-07-11 16:53:02,729 [INFO    ] __main__: train step 12462: loss: 1.0068, policy_loss: 0.9850, value_loss: 0.6411
2024-07-11 16:53:02,953 [INFO    ] __main__: train step 12463: loss: 1.0068, policy_loss: 0.9849, value_loss: 0.6410
2024-07-11 16:53:03,158 [INFO    ] __main__: train step 12464: loss: 1.0068, policy_loss: 0.9849, value_loss: 0.6410
2024-07-11 16:53:03,377 [INFO    ] __main__: train step 12465: loss: 1.0068, policy_loss: 0.9849, value_loss: 0.6410
2024-07-11 16:53:03,577 [INFO    ] __main__: train step 12466: loss: 1.0068, policy_loss: 0.9849, value_loss: 0.6409
2024-07-11 16:53:03,800 [INFO    ] __main__: train step 12467: loss: 1.0068, policy_loss: 0.9848, value_loss: 0.6409
2024-07-11 16:53:03,989 [INFO    ] __main__: train step 12468: loss: 1.0068, policy_loss: 0.9848, value_loss: 0.6409
2024-07-11 16:53:04,192 [INFO    ] __main__: train step 12469: loss: 1.0068, policy_loss: 0.9848, value_loss: 0.6409
2024-07-11 16:53:04,394 [INFO    ] __main__: train step 12470: loss: 1.0068, policy_loss: 0.9847, value_loss: 0.6408
2024-07-11 16:53:04,598 [INFO    ] __main__: train step 12471: loss: 1.0068, policy_loss: 0.9847, value_loss: 0.6408
2024-07-11 16:53:04,789 [INFO    ] __main__: train step 12472: loss: 1.0068, policy_loss: 0.9847, value_loss: 0.6408
2024-07-11 16:53:04,994 [INFO    ] __main__: train step 12473: loss: 1.0068, policy_loss: 0.9847, value_loss: 0.6407
2024-07-11 16:53:05,196 [INFO    ] __main__: train step 12474: loss: 1.0068, policy_loss: 0.9847, value_loss: 0.6407
2024-07-11 16:53:05,412 [INFO    ] __main__: train step 12475: loss: 1.0068, policy_loss: 0.9846, value_loss: 0.6407
2024-07-11 16:53:05,610 [INFO    ] __main__: train step 12476: loss: 1.0068, policy_loss: 0.9846, value_loss: 0.6407
2024-07-11 16:53:05,813 [INFO    ] __main__: train step 12477: loss: 1.0068, policy_loss: 0.9846, value_loss: 0.6406
2024-07-11 16:53:07,265 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:53:07,625 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:53:07,682 [INFO    ] __main__: train step 12478: loss: 1.0068, policy_loss: 0.9846, value_loss: 0.6406
2024-07-11 16:53:07,856 [INFO    ] __main__: train step 12479: loss: 1.0068, policy_loss: 0.9845, value_loss: 0.6406
2024-07-11 16:53:08,059 [INFO    ] __main__: train step 12480: loss: 1.0067, policy_loss: 0.9845, value_loss: 0.6406
2024-07-11 16:53:08,265 [INFO    ] __main__: train step 12481: loss: 1.0067, policy_loss: 0.9845, value_loss: 0.6405
2024-07-11 16:53:08,466 [INFO    ] __main__: train step 12482: loss: 1.0067, policy_loss: 0.9845, value_loss: 0.6405
2024-07-11 16:53:08,666 [INFO    ] __main__: train step 12483: loss: 1.0067, policy_loss: 0.9844, value_loss: 0.6405
2024-07-11 16:53:08,877 [INFO    ] __main__: train step 12484: loss: 1.0067, policy_loss: 0.9844, value_loss: 0.6404
2024-07-11 16:53:09,091 [INFO    ] __main__: train step 12485: loss: 1.0067, policy_loss: 0.9844, value_loss: 0.6404
2024-07-11 16:53:09,287 [INFO    ] __main__: train step 12486: loss: 1.0067, policy_loss: 0.9844, value_loss: 0.6404
2024-07-11 16:53:09,491 [INFO    ] __main__: train step 12487: loss: 1.0067, policy_loss: 0.9843, value_loss: 0.6404
2024-07-11 16:53:09,717 [INFO    ] __main__: train step 12488: loss: 1.0067, policy_loss: 0.9843, value_loss: 0.6403
2024-07-11 16:53:09,917 [INFO    ] __main__: train step 12489: loss: 1.0067, policy_loss: 0.9843, value_loss: 0.6403
2024-07-11 16:53:10,127 [INFO    ] __main__: train step 12490: loss: 1.0067, policy_loss: 0.9843, value_loss: 0.6403
2024-07-11 16:53:10,329 [INFO    ] __main__: train step 12491: loss: 1.0067, policy_loss: 0.9842, value_loss: 0.6403
2024-07-11 16:53:10,547 [INFO    ] __main__: train step 12492: loss: 1.0067, policy_loss: 0.9842, value_loss: 0.6402
2024-07-11 16:53:10,741 [INFO    ] __main__: train step 12493: loss: 1.0067, policy_loss: 0.9842, value_loss: 0.6402
2024-07-11 16:53:10,943 [INFO    ] __main__: train step 12494: loss: 1.0067, policy_loss: 0.9842, value_loss: 0.6402
2024-07-11 16:53:12,390 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:53:12,812 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:53:12,873 [INFO    ] __main__: train step 12495: loss: 1.0067, policy_loss: 0.9841, value_loss: 0.6401
2024-07-11 16:53:13,039 [INFO    ] __main__: train step 12496: loss: 1.0067, policy_loss: 0.9841, value_loss: 0.6401
2024-07-11 16:53:13,245 [INFO    ] __main__: train step 12497: loss: 1.0067, policy_loss: 0.9841, value_loss: 0.6401
2024-07-11 16:53:13,448 [INFO    ] __main__: train step 12498: loss: 1.0067, policy_loss: 0.9841, value_loss: 0.6401
2024-07-11 16:53:13,657 [INFO    ] __main__: train step 12499: loss: 1.0067, policy_loss: 0.9840, value_loss: 0.6400
2024-07-11 16:53:13,870 [INFO    ] __main__: train step 12500: loss: 1.0067, policy_loss: 0.9840, value_loss: 0.6400
2024-07-11 16:53:15,439 [INFO    ] __main__: train step 12501: loss: 1.0067, policy_loss: 0.9840, value_loss: 0.6400
2024-07-11 16:53:15,663 [INFO    ] __main__: train step 12502: loss: 1.0067, policy_loss: 0.9840, value_loss: 0.6400
2024-07-11 16:53:15,861 [INFO    ] __main__: train step 12503: loss: 1.0067, policy_loss: 0.9839, value_loss: 0.6399
2024-07-11 16:53:16,058 [INFO    ] __main__: train step 12504: loss: 1.0067, policy_loss: 0.9839, value_loss: 0.6399
2024-07-11 16:53:16,269 [INFO    ] __main__: train step 12505: loss: 1.0067, policy_loss: 0.9839, value_loss: 0.6399
2024-07-11 16:53:16,466 [INFO    ] __main__: train step 12506: loss: 1.0067, policy_loss: 0.9839, value_loss: 0.6398
2024-07-11 16:53:16,681 [INFO    ] __main__: train step 12507: loss: 1.0067, policy_loss: 0.9838, value_loss: 0.6398
2024-07-11 16:53:16,886 [INFO    ] __main__: train step 12508: loss: 1.0067, policy_loss: 0.9838, value_loss: 0.6398
2024-07-11 16:53:17,088 [INFO    ] __main__: train step 12509: loss: 1.0067, policy_loss: 0.9838, value_loss: 0.6398
2024-07-11 16:53:17,297 [INFO    ] __main__: train step 12510: loss: 1.0067, policy_loss: 0.9838, value_loss: 0.6397
2024-07-11 16:53:17,510 [INFO    ] __main__: train step 12511: loss: 1.0067, policy_loss: 0.9837, value_loss: 0.6397
2024-07-11 16:53:18,947 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:53:19,322 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:53:19,378 [INFO    ] __main__: train step 12512: loss: 1.0067, policy_loss: 0.9837, value_loss: 0.6397
2024-07-11 16:53:19,557 [INFO    ] __main__: train step 12513: loss: 1.0067, policy_loss: 0.9837, value_loss: 0.6397
2024-07-11 16:53:19,765 [INFO    ] __main__: train step 12514: loss: 1.0067, policy_loss: 0.9837, value_loss: 0.6396
2024-07-11 16:53:19,986 [INFO    ] __main__: train step 12515: loss: 1.0066, policy_loss: 0.9836, value_loss: 0.6396
2024-07-11 16:53:20,196 [INFO    ] __main__: train step 12516: loss: 1.0066, policy_loss: 0.9836, value_loss: 0.6396
2024-07-11 16:53:20,410 [INFO    ] __main__: train step 12517: loss: 1.0066, policy_loss: 0.9836, value_loss: 0.6395
2024-07-11 16:53:20,611 [INFO    ] __main__: train step 12518: loss: 1.0066, policy_loss: 0.9836, value_loss: 0.6395
2024-07-11 16:53:20,828 [INFO    ] __main__: train step 12519: loss: 1.0066, policy_loss: 0.9835, value_loss: 0.6395
2024-07-11 16:53:21,059 [INFO    ] __main__: train step 12520: loss: 1.0066, policy_loss: 0.9835, value_loss: 0.6395
2024-07-11 16:53:21,265 [INFO    ] __main__: train step 12521: loss: 1.0066, policy_loss: 0.9835, value_loss: 0.6394
2024-07-11 16:53:21,468 [INFO    ] __main__: train step 12522: loss: 1.0066, policy_loss: 0.9835, value_loss: 0.6394
2024-07-11 16:53:21,667 [INFO    ] __main__: train step 12523: loss: 1.0066, policy_loss: 0.9834, value_loss: 0.6394
2024-07-11 16:53:21,872 [INFO    ] __main__: train step 12524: loss: 1.0066, policy_loss: 0.9834, value_loss: 0.6393
2024-07-11 16:53:22,074 [INFO    ] __main__: train step 12525: loss: 1.0066, policy_loss: 0.9834, value_loss: 0.6393
2024-07-11 16:53:22,279 [INFO    ] __main__: train step 12526: loss: 1.0066, policy_loss: 0.9834, value_loss: 0.6393
2024-07-11 16:53:22,475 [INFO    ] __main__: train step 12527: loss: 1.0066, policy_loss: 0.9833, value_loss: 0.6393
2024-07-11 16:53:22,670 [INFO    ] __main__: train step 12528: loss: 1.0066, policy_loss: 0.9833, value_loss: 0.6392
2024-07-11 16:53:24,111 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:53:24,505 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:53:24,566 [INFO    ] __main__: train step 12529: loss: 1.0066, policy_loss: 0.9833, value_loss: 0.6392
2024-07-11 16:53:24,746 [INFO    ] __main__: train step 12530: loss: 1.0066, policy_loss: 0.9833, value_loss: 0.6392
2024-07-11 16:53:24,985 [INFO    ] __main__: train step 12531: loss: 1.0066, policy_loss: 0.9832, value_loss: 0.6392
2024-07-11 16:53:25,176 [INFO    ] __main__: train step 12532: loss: 1.0066, policy_loss: 0.9832, value_loss: 0.6391
2024-07-11 16:53:25,378 [INFO    ] __main__: train step 12533: loss: 1.0066, policy_loss: 0.9832, value_loss: 0.6391
2024-07-11 16:53:25,612 [INFO    ] __main__: train step 12534: loss: 1.0066, policy_loss: 0.9832, value_loss: 0.6391
2024-07-11 16:53:25,813 [INFO    ] __main__: train step 12535: loss: 1.0066, policy_loss: 0.9831, value_loss: 0.6391
2024-07-11 16:53:26,023 [INFO    ] __main__: train step 12536: loss: 1.0066, policy_loss: 0.9831, value_loss: 0.6390
2024-07-11 16:53:26,229 [INFO    ] __main__: train step 12537: loss: 1.0066, policy_loss: 0.9831, value_loss: 0.6390
2024-07-11 16:53:26,442 [INFO    ] __main__: train step 12538: loss: 1.0066, policy_loss: 0.9831, value_loss: 0.6390
2024-07-11 16:53:26,653 [INFO    ] __main__: train step 12539: loss: 1.0066, policy_loss: 0.9830, value_loss: 0.6389
2024-07-11 16:53:26,863 [INFO    ] __main__: train step 12540: loss: 1.0066, policy_loss: 0.9830, value_loss: 0.6389
2024-07-11 16:53:27,083 [INFO    ] __main__: train step 12541: loss: 1.0066, policy_loss: 0.9830, value_loss: 0.6389
2024-07-11 16:53:27,331 [INFO    ] __main__: train step 12542: loss: 1.0066, policy_loss: 0.9830, value_loss: 0.6389
2024-07-11 16:53:27,565 [INFO    ] __main__: train step 12543: loss: 1.0066, policy_loss: 0.9829, value_loss: 0.6388
2024-07-11 16:53:27,767 [INFO    ] __main__: train step 12544: loss: 1.0066, policy_loss: 0.9829, value_loss: 0.6388
2024-07-11 16:53:27,974 [INFO    ] __main__: train step 12545: loss: 1.0066, policy_loss: 0.9829, value_loss: 0.6388
2024-07-11 16:53:29,423 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:53:29,825 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:53:29,892 [INFO    ] __main__: train step 12546: loss: 1.0066, policy_loss: 0.9829, value_loss: 0.6388
2024-07-11 16:53:30,085 [INFO    ] __main__: train step 12547: loss: 1.0066, policy_loss: 0.9829, value_loss: 0.6387
2024-07-11 16:53:30,290 [INFO    ] __main__: train step 12548: loss: 1.0066, policy_loss: 0.9828, value_loss: 0.6387
2024-07-11 16:53:30,531 [INFO    ] __main__: train step 12549: loss: 1.0066, policy_loss: 0.9828, value_loss: 0.6387
2024-07-11 16:53:30,753 [INFO    ] __main__: train step 12550: loss: 1.0066, policy_loss: 0.9828, value_loss: 0.6386
2024-07-11 16:53:30,965 [INFO    ] __main__: train step 12551: loss: 1.0066, policy_loss: 0.9828, value_loss: 0.6386
2024-07-11 16:53:31,175 [INFO    ] __main__: train step 12552: loss: 1.0066, policy_loss: 0.9827, value_loss: 0.6386
2024-07-11 16:53:31,377 [INFO    ] __main__: train step 12553: loss: 1.0066, policy_loss: 0.9827, value_loss: 0.6386
2024-07-11 16:53:31,578 [INFO    ] __main__: train step 12554: loss: 1.0066, policy_loss: 0.9827, value_loss: 0.6385
2024-07-11 16:53:31,777 [INFO    ] __main__: train step 12555: loss: 1.0066, policy_loss: 0.9827, value_loss: 0.6385
2024-07-11 16:53:31,981 [INFO    ] __main__: train step 12556: loss: 1.0066, policy_loss: 0.9826, value_loss: 0.6385
2024-07-11 16:53:32,204 [INFO    ] __main__: train step 12557: loss: 1.0065, policy_loss: 0.9826, value_loss: 0.6385
2024-07-11 16:53:32,421 [INFO    ] __main__: train step 12558: loss: 1.0065, policy_loss: 0.9826, value_loss: 0.6384
2024-07-11 16:53:32,660 [INFO    ] __main__: train step 12559: loss: 1.0065, policy_loss: 0.9826, value_loss: 0.6384
2024-07-11 16:53:32,881 [INFO    ] __main__: train step 12560: loss: 1.0065, policy_loss: 0.9825, value_loss: 0.6384
2024-07-11 16:53:33,120 [INFO    ] __main__: train step 12561: loss: 1.0065, policy_loss: 0.9825, value_loss: 0.6383
2024-07-11 16:53:33,351 [INFO    ] __main__: train step 12562: loss: 1.0065, policy_loss: 0.9825, value_loss: 0.6383
2024-07-11 16:53:34,801 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:53:35,186 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:53:35,241 [INFO    ] __main__: train step 12563: loss: 1.0065, policy_loss: 0.9825, value_loss: 0.6383
2024-07-11 16:53:35,419 [INFO    ] __main__: train step 12564: loss: 1.0065, policy_loss: 0.9824, value_loss: 0.6383
2024-07-11 16:53:35,626 [INFO    ] __main__: train step 12565: loss: 1.0065, policy_loss: 0.9824, value_loss: 0.6382
2024-07-11 16:53:35,869 [INFO    ] __main__: train step 12566: loss: 1.0065, policy_loss: 0.9824, value_loss: 0.6382
2024-07-11 16:53:36,103 [INFO    ] __main__: train step 12567: loss: 1.0065, policy_loss: 0.9824, value_loss: 0.6382
2024-07-11 16:53:36,307 [INFO    ] __main__: train step 12568: loss: 1.0065, policy_loss: 0.9823, value_loss: 0.6382
2024-07-11 16:53:36,511 [INFO    ] __main__: train step 12569: loss: 1.0065, policy_loss: 0.9823, value_loss: 0.6381
2024-07-11 16:53:36,712 [INFO    ] __main__: train step 12570: loss: 1.0065, policy_loss: 0.9823, value_loss: 0.6381
2024-07-11 16:53:36,927 [INFO    ] __main__: train step 12571: loss: 1.0065, policy_loss: 0.9823, value_loss: 0.6381
2024-07-11 16:53:37,135 [INFO    ] __main__: train step 12572: loss: 1.0065, policy_loss: 0.9823, value_loss: 0.6380
2024-07-11 16:53:37,334 [INFO    ] __main__: train step 12573: loss: 1.0065, policy_loss: 0.9822, value_loss: 0.6380
2024-07-11 16:53:37,540 [INFO    ] __main__: train step 12574: loss: 1.0065, policy_loss: 0.9822, value_loss: 0.6380
2024-07-11 16:53:37,742 [INFO    ] __main__: train step 12575: loss: 1.0065, policy_loss: 0.9822, value_loss: 0.6380
2024-07-11 16:53:37,950 [INFO    ] __main__: train step 12576: loss: 1.0065, policy_loss: 0.9822, value_loss: 0.6379
2024-07-11 16:53:38,177 [INFO    ] __main__: train step 12577: loss: 1.0065, policy_loss: 0.9821, value_loss: 0.6379
2024-07-11 16:53:38,373 [INFO    ] __main__: train step 12578: loss: 1.0065, policy_loss: 0.9821, value_loss: 0.6379
2024-07-11 16:53:38,592 [INFO    ] __main__: train step 12579: loss: 1.0065, policy_loss: 0.9821, value_loss: 0.6378
2024-07-11 16:53:40,029 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:53:40,465 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:53:40,529 [INFO    ] __main__: train step 12580: loss: 1.0065, policy_loss: 0.9821, value_loss: 0.6378
2024-07-11 16:53:40,703 [INFO    ] __main__: train step 12581: loss: 1.0065, policy_loss: 0.9820, value_loss: 0.6378
2024-07-11 16:53:40,915 [INFO    ] __main__: train step 12582: loss: 1.0065, policy_loss: 0.9820, value_loss: 0.6378
2024-07-11 16:53:41,151 [INFO    ] __main__: train step 12583: loss: 1.0065, policy_loss: 0.9820, value_loss: 0.6377
2024-07-11 16:53:41,355 [INFO    ] __main__: train step 12584: loss: 1.0065, policy_loss: 0.9820, value_loss: 0.6377
2024-07-11 16:53:41,594 [INFO    ] __main__: train step 12585: loss: 1.0065, policy_loss: 0.9819, value_loss: 0.6377
2024-07-11 16:53:41,798 [INFO    ] __main__: train step 12586: loss: 1.0065, policy_loss: 0.9819, value_loss: 0.6377
2024-07-11 16:53:42,018 [INFO    ] __main__: train step 12587: loss: 1.0065, policy_loss: 0.9819, value_loss: 0.6376
2024-07-11 16:53:42,243 [INFO    ] __main__: train step 12588: loss: 1.0064, policy_loss: 0.9819, value_loss: 0.6376
2024-07-11 16:53:42,442 [INFO    ] __main__: train step 12589: loss: 1.0064, policy_loss: 0.9818, value_loss: 0.6376
2024-07-11 16:53:42,650 [INFO    ] __main__: train step 12590: loss: 1.0064, policy_loss: 0.9818, value_loss: 0.6375
2024-07-11 16:53:42,855 [INFO    ] __main__: train step 12591: loss: 1.0064, policy_loss: 0.9818, value_loss: 0.6375
2024-07-11 16:53:43,064 [INFO    ] __main__: train step 12592: loss: 1.0064, policy_loss: 0.9818, value_loss: 0.6375
2024-07-11 16:53:43,261 [INFO    ] __main__: train step 12593: loss: 1.0064, policy_loss: 0.9817, value_loss: 0.6375
2024-07-11 16:53:43,468 [INFO    ] __main__: train step 12594: loss: 1.0064, policy_loss: 0.9817, value_loss: 0.6374
2024-07-11 16:53:43,664 [INFO    ] __main__: train step 12595: loss: 1.0064, policy_loss: 0.9817, value_loss: 0.6374
2024-07-11 16:53:43,875 [INFO    ] __main__: train step 12596: loss: 1.0064, policy_loss: 0.9817, value_loss: 0.6374
2024-07-11 16:53:45,302 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:53:45,684 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:53:45,739 [INFO    ] __main__: train step 12597: loss: 1.0064, policy_loss: 0.9816, value_loss: 0.6374
2024-07-11 16:53:45,913 [INFO    ] __main__: train step 12598: loss: 1.0064, policy_loss: 0.9816, value_loss: 0.6373
2024-07-11 16:53:46,121 [INFO    ] __main__: train step 12599: loss: 1.0064, policy_loss: 0.9816, value_loss: 0.6373
2024-07-11 16:53:47,664 [INFO    ] __main__: train step 12600: loss: 1.0064, policy_loss: 0.9816, value_loss: 0.6373
2024-07-11 16:53:47,871 [INFO    ] __main__: train step 12601: loss: 1.0064, policy_loss: 0.9815, value_loss: 0.6372
2024-07-11 16:53:48,092 [INFO    ] __main__: train step 12602: loss: 1.0064, policy_loss: 0.9815, value_loss: 0.6372
2024-07-11 16:53:48,288 [INFO    ] __main__: train step 12603: loss: 1.0064, policy_loss: 0.9815, value_loss: 0.6372
2024-07-11 16:53:48,497 [INFO    ] __main__: train step 12604: loss: 1.0064, policy_loss: 0.9815, value_loss: 0.6372
2024-07-11 16:53:48,695 [INFO    ] __main__: train step 12605: loss: 1.0064, policy_loss: 0.9815, value_loss: 0.6371
2024-07-11 16:53:48,895 [INFO    ] __main__: train step 12606: loss: 1.0064, policy_loss: 0.9814, value_loss: 0.6371
2024-07-11 16:53:49,103 [INFO    ] __main__: train step 12607: loss: 1.0064, policy_loss: 0.9814, value_loss: 0.6371
2024-07-11 16:53:49,307 [INFO    ] __main__: train step 12608: loss: 1.0064, policy_loss: 0.9814, value_loss: 0.6370
2024-07-11 16:53:49,519 [INFO    ] __main__: train step 12609: loss: 1.0064, policy_loss: 0.9814, value_loss: 0.6370
2024-07-11 16:53:49,770 [INFO    ] __main__: train step 12610: loss: 1.0064, policy_loss: 0.9813, value_loss: 0.6370
2024-07-11 16:53:50,012 [INFO    ] __main__: train step 12611: loss: 1.0064, policy_loss: 0.9813, value_loss: 0.6370
2024-07-11 16:53:50,229 [INFO    ] __main__: train step 12612: loss: 1.0064, policy_loss: 0.9813, value_loss: 0.6369
2024-07-11 16:53:50,472 [INFO    ] __main__: train step 12613: loss: 1.0064, policy_loss: 0.9813, value_loss: 0.6369
2024-07-11 16:53:51,943 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:53:52,341 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:53:52,399 [INFO    ] __main__: train step 12614: loss: 1.0064, policy_loss: 0.9812, value_loss: 0.6369
2024-07-11 16:53:52,574 [INFO    ] __main__: train step 12615: loss: 1.0064, policy_loss: 0.9812, value_loss: 0.6369
2024-07-11 16:53:52,774 [INFO    ] __main__: train step 12616: loss: 1.0064, policy_loss: 0.9812, value_loss: 0.6368
2024-07-11 16:53:52,968 [INFO    ] __main__: train step 12617: loss: 1.0064, policy_loss: 0.9812, value_loss: 0.6368
2024-07-11 16:53:53,184 [INFO    ] __main__: train step 12618: loss: 1.0064, policy_loss: 0.9811, value_loss: 0.6368
2024-07-11 16:53:53,391 [INFO    ] __main__: train step 12619: loss: 1.0064, policy_loss: 0.9811, value_loss: 0.6368
2024-07-11 16:53:53,590 [INFO    ] __main__: train step 12620: loss: 1.0064, policy_loss: 0.9811, value_loss: 0.6367
2024-07-11 16:53:53,786 [INFO    ] __main__: train step 12621: loss: 1.0064, policy_loss: 0.9811, value_loss: 0.6367
2024-07-11 16:53:54,000 [INFO    ] __main__: train step 12622: loss: 1.0064, policy_loss: 0.9811, value_loss: 0.6367
2024-07-11 16:53:54,214 [INFO    ] __main__: train step 12623: loss: 1.0064, policy_loss: 0.9810, value_loss: 0.6366
2024-07-11 16:53:54,457 [INFO    ] __main__: train step 12624: loss: 1.0064, policy_loss: 0.9810, value_loss: 0.6366
2024-07-11 16:53:54,687 [INFO    ] __main__: train step 12625: loss: 1.0064, policy_loss: 0.9810, value_loss: 0.6366
2024-07-11 16:53:54,888 [INFO    ] __main__: train step 12626: loss: 1.0064, policy_loss: 0.9810, value_loss: 0.6366
2024-07-11 16:53:55,094 [INFO    ] __main__: train step 12627: loss: 1.0064, policy_loss: 0.9809, value_loss: 0.6365
2024-07-11 16:53:55,291 [INFO    ] __main__: train step 12628: loss: 1.0064, policy_loss: 0.9809, value_loss: 0.6365
2024-07-11 16:53:55,504 [INFO    ] __main__: train step 12629: loss: 1.0064, policy_loss: 0.9809, value_loss: 0.6365
2024-07-11 16:53:55,698 [INFO    ] __main__: train step 12630: loss: 1.0064, policy_loss: 0.9809, value_loss: 0.6365
2024-07-11 16:53:57,131 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:53:57,543 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:53:57,606 [INFO    ] __main__: train step 12631: loss: 1.0063, policy_loss: 0.9808, value_loss: 0.6364
2024-07-11 16:53:57,776 [INFO    ] __main__: train step 12632: loss: 1.0063, policy_loss: 0.9808, value_loss: 0.6364
2024-07-11 16:53:57,985 [INFO    ] __main__: train step 12633: loss: 1.0063, policy_loss: 0.9808, value_loss: 0.6364
2024-07-11 16:53:58,192 [INFO    ] __main__: train step 12634: loss: 1.0063, policy_loss: 0.9808, value_loss: 0.6363
2024-07-11 16:53:58,405 [INFO    ] __main__: train step 12635: loss: 1.0063, policy_loss: 0.9807, value_loss: 0.6363
2024-07-11 16:53:58,605 [INFO    ] __main__: train step 12636: loss: 1.0063, policy_loss: 0.9807, value_loss: 0.6363
2024-07-11 16:53:58,805 [INFO    ] __main__: train step 12637: loss: 1.0063, policy_loss: 0.9807, value_loss: 0.6363
2024-07-11 16:53:59,013 [INFO    ] __main__: train step 12638: loss: 1.0063, policy_loss: 0.9807, value_loss: 0.6362
2024-07-11 16:53:59,223 [INFO    ] __main__: train step 12639: loss: 1.0063, policy_loss: 0.9807, value_loss: 0.6362
2024-07-11 16:53:59,430 [INFO    ] __main__: train step 12640: loss: 1.0063, policy_loss: 0.9806, value_loss: 0.6362
2024-07-11 16:53:59,664 [INFO    ] __main__: train step 12641: loss: 1.0063, policy_loss: 0.9806, value_loss: 0.6362
2024-07-11 16:53:59,901 [INFO    ] __main__: train step 12642: loss: 1.0063, policy_loss: 0.9806, value_loss: 0.6361
2024-07-11 16:54:00,105 [INFO    ] __main__: train step 12643: loss: 1.0063, policy_loss: 0.9806, value_loss: 0.6361
2024-07-11 16:54:00,303 [INFO    ] __main__: train step 12644: loss: 1.0063, policy_loss: 0.9805, value_loss: 0.6361
2024-07-11 16:54:00,505 [INFO    ] __main__: train step 12645: loss: 1.0063, policy_loss: 0.9805, value_loss: 0.6360
2024-07-11 16:54:00,714 [INFO    ] __main__: train step 12646: loss: 1.0063, policy_loss: 0.9805, value_loss: 0.6360
2024-07-11 16:54:00,919 [INFO    ] __main__: train step 12647: loss: 1.0063, policy_loss: 0.9805, value_loss: 0.6360
2024-07-11 16:54:02,350 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:54:02,758 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:54:02,823 [INFO    ] __main__: train step 12648: loss: 1.0063, policy_loss: 0.9804, value_loss: 0.6360
2024-07-11 16:54:02,996 [INFO    ] __main__: train step 12649: loss: 1.0063, policy_loss: 0.9804, value_loss: 0.6359
2024-07-11 16:54:03,211 [INFO    ] __main__: train step 12650: loss: 1.0063, policy_loss: 0.9804, value_loss: 0.6359
2024-07-11 16:54:03,408 [INFO    ] __main__: train step 12651: loss: 1.0063, policy_loss: 0.9804, value_loss: 0.6359
2024-07-11 16:54:03,606 [INFO    ] __main__: train step 12652: loss: 1.0063, policy_loss: 0.9803, value_loss: 0.6358
2024-07-11 16:54:03,805 [INFO    ] __main__: train step 12653: loss: 1.0063, policy_loss: 0.9803, value_loss: 0.6358
2024-07-11 16:54:04,009 [INFO    ] __main__: train step 12654: loss: 1.0063, policy_loss: 0.9803, value_loss: 0.6358
2024-07-11 16:54:04,209 [INFO    ] __main__: train step 12655: loss: 1.0063, policy_loss: 0.9803, value_loss: 0.6358
2024-07-11 16:54:04,411 [INFO    ] __main__: train step 12656: loss: 1.0063, policy_loss: 0.9803, value_loss: 0.6357
2024-07-11 16:54:04,613 [INFO    ] __main__: train step 12657: loss: 1.0063, policy_loss: 0.9802, value_loss: 0.6357
2024-07-11 16:54:04,811 [INFO    ] __main__: train step 12658: loss: 1.0063, policy_loss: 0.9802, value_loss: 0.6357
2024-07-11 16:54:05,013 [INFO    ] __main__: train step 12659: loss: 1.0063, policy_loss: 0.9802, value_loss: 0.6357
2024-07-11 16:54:05,208 [INFO    ] __main__: train step 12660: loss: 1.0063, policy_loss: 0.9802, value_loss: 0.6356
2024-07-11 16:54:05,410 [INFO    ] __main__: train step 12661: loss: 1.0063, policy_loss: 0.9801, value_loss: 0.6356
2024-07-11 16:54:05,621 [INFO    ] __main__: train step 12662: loss: 1.0063, policy_loss: 0.9801, value_loss: 0.6356
2024-07-11 16:54:05,860 [INFO    ] __main__: train step 12663: loss: 1.0063, policy_loss: 0.9801, value_loss: 0.6355
2024-07-11 16:54:06,067 [INFO    ] __main__: train step 12664: loss: 1.0063, policy_loss: 0.9801, value_loss: 0.6355
2024-07-11 16:54:07,519 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:54:07,893 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:54:07,947 [INFO    ] __main__: train step 12665: loss: 1.0062, policy_loss: 0.9800, value_loss: 0.6355
2024-07-11 16:54:08,123 [INFO    ] __main__: train step 12666: loss: 1.0062, policy_loss: 0.9800, value_loss: 0.6355
2024-07-11 16:54:08,331 [INFO    ] __main__: train step 12667: loss: 1.0062, policy_loss: 0.9800, value_loss: 0.6354
2024-07-11 16:54:08,530 [INFO    ] __main__: train step 12668: loss: 1.0062, policy_loss: 0.9800, value_loss: 0.6354
2024-07-11 16:54:08,734 [INFO    ] __main__: train step 12669: loss: 1.0062, policy_loss: 0.9799, value_loss: 0.6354
2024-07-11 16:54:08,943 [INFO    ] __main__: train step 12670: loss: 1.0062, policy_loss: 0.9799, value_loss: 0.6353
2024-07-11 16:54:09,176 [INFO    ] __main__: train step 12671: loss: 1.0062, policy_loss: 0.9799, value_loss: 0.6353
2024-07-11 16:54:09,385 [INFO    ] __main__: train step 12672: loss: 1.0062, policy_loss: 0.9799, value_loss: 0.6353
2024-07-11 16:54:09,590 [INFO    ] __main__: train step 12673: loss: 1.0062, policy_loss: 0.9798, value_loss: 0.6353
2024-07-11 16:54:09,794 [INFO    ] __main__: train step 12674: loss: 1.0062, policy_loss: 0.9798, value_loss: 0.6352
2024-07-11 16:54:09,991 [INFO    ] __main__: train step 12675: loss: 1.0062, policy_loss: 0.9798, value_loss: 0.6352
2024-07-11 16:54:10,193 [INFO    ] __main__: train step 12676: loss: 1.0062, policy_loss: 0.9798, value_loss: 0.6352
2024-07-11 16:54:10,395 [INFO    ] __main__: train step 12677: loss: 1.0062, policy_loss: 0.9798, value_loss: 0.6352
2024-07-11 16:54:10,603 [INFO    ] __main__: train step 12678: loss: 1.0062, policy_loss: 0.9797, value_loss: 0.6351
2024-07-11 16:54:10,835 [INFO    ] __main__: train step 12679: loss: 1.0062, policy_loss: 0.9797, value_loss: 0.6351
2024-07-11 16:54:11,031 [INFO    ] __main__: train step 12680: loss: 1.0062, policy_loss: 0.9797, value_loss: 0.6351
2024-07-11 16:54:11,246 [INFO    ] __main__: train step 12681: loss: 1.0062, policy_loss: 0.9797, value_loss: 0.6350
2024-07-11 16:54:12,674 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:54:13,036 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:54:13,094 [INFO    ] __main__: train step 12682: loss: 1.0062, policy_loss: 0.9796, value_loss: 0.6350
2024-07-11 16:54:13,276 [INFO    ] __main__: train step 12683: loss: 1.0062, policy_loss: 0.9796, value_loss: 0.6350
2024-07-11 16:54:13,499 [INFO    ] __main__: train step 12684: loss: 1.0062, policy_loss: 0.9796, value_loss: 0.6350
2024-07-11 16:54:13,705 [INFO    ] __main__: train step 12685: loss: 1.0062, policy_loss: 0.9796, value_loss: 0.6349
2024-07-11 16:54:13,902 [INFO    ] __main__: train step 12686: loss: 1.0062, policy_loss: 0.9795, value_loss: 0.6349
2024-07-11 16:54:14,111 [INFO    ] __main__: train step 12687: loss: 1.0062, policy_loss: 0.9795, value_loss: 0.6349
2024-07-11 16:54:14,321 [INFO    ] __main__: train step 12688: loss: 1.0062, policy_loss: 0.9795, value_loss: 0.6349
2024-07-11 16:54:14,531 [INFO    ] __main__: train step 12689: loss: 1.0062, policy_loss: 0.9795, value_loss: 0.6348
2024-07-11 16:54:14,741 [INFO    ] __main__: train step 12690: loss: 1.0062, policy_loss: 0.9794, value_loss: 0.6348
2024-07-11 16:54:14,942 [INFO    ] __main__: train step 12691: loss: 1.0062, policy_loss: 0.9794, value_loss: 0.6348
2024-07-11 16:54:15,151 [INFO    ] __main__: train step 12692: loss: 1.0062, policy_loss: 0.9794, value_loss: 0.6347
2024-07-11 16:54:15,347 [INFO    ] __main__: train step 12693: loss: 1.0062, policy_loss: 0.9794, value_loss: 0.6347
2024-07-11 16:54:15,546 [INFO    ] __main__: train step 12694: loss: 1.0062, policy_loss: 0.9794, value_loss: 0.6347
2024-07-11 16:54:15,752 [INFO    ] __main__: train step 12695: loss: 1.0061, policy_loss: 0.9793, value_loss: 0.6347
2024-07-11 16:54:15,960 [INFO    ] __main__: train step 12696: loss: 1.0061, policy_loss: 0.9793, value_loss: 0.6346
2024-07-11 16:54:16,153 [INFO    ] __main__: train step 12697: loss: 1.0061, policy_loss: 0.9793, value_loss: 0.6346
2024-07-11 16:54:17,737 [INFO    ] __main__: train step 12698: loss: 1.0061, policy_loss: 0.9793, value_loss: 0.6346
2024-07-11 16:54:19,190 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:54:19,579 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:54:19,634 [INFO    ] __main__: train step 12699: loss: 1.0061, policy_loss: 0.9792, value_loss: 0.6345
2024-07-11 16:54:19,812 [INFO    ] __main__: train step 12700: loss: 1.0061, policy_loss: 0.9792, value_loss: 0.6345
2024-07-11 16:54:20,009 [INFO    ] __main__: train step 12701: loss: 1.0061, policy_loss: 0.9792, value_loss: 0.6345
2024-07-11 16:54:20,223 [INFO    ] __main__: train step 12702: loss: 1.0061, policy_loss: 0.9792, value_loss: 0.6345
2024-07-11 16:54:20,472 [INFO    ] __main__: train step 12703: loss: 1.0061, policy_loss: 0.9791, value_loss: 0.6344
2024-07-11 16:54:20,706 [INFO    ] __main__: train step 12704: loss: 1.0061, policy_loss: 0.9791, value_loss: 0.6344
2024-07-11 16:54:20,921 [INFO    ] __main__: train step 12705: loss: 1.0061, policy_loss: 0.9791, value_loss: 0.6344
2024-07-11 16:54:21,136 [INFO    ] __main__: train step 12706: loss: 1.0061, policy_loss: 0.9791, value_loss: 0.6344
2024-07-11 16:54:21,341 [INFO    ] __main__: train step 12707: loss: 1.0061, policy_loss: 0.9790, value_loss: 0.6343
2024-07-11 16:54:21,543 [INFO    ] __main__: train step 12708: loss: 1.0061, policy_loss: 0.9790, value_loss: 0.6343
2024-07-11 16:54:21,751 [INFO    ] __main__: train step 12709: loss: 1.0061, policy_loss: 0.9790, value_loss: 0.6343
2024-07-11 16:54:21,951 [INFO    ] __main__: train step 12710: loss: 1.0061, policy_loss: 0.9790, value_loss: 0.6342
2024-07-11 16:54:22,154 [INFO    ] __main__: train step 12711: loss: 1.0061, policy_loss: 0.9790, value_loss: 0.6342
2024-07-11 16:54:22,345 [INFO    ] __main__: train step 12712: loss: 1.0061, policy_loss: 0.9789, value_loss: 0.6342
2024-07-11 16:54:22,554 [INFO    ] __main__: train step 12713: loss: 1.0061, policy_loss: 0.9789, value_loss: 0.6342
2024-07-11 16:54:22,746 [INFO    ] __main__: train step 12714: loss: 1.0061, policy_loss: 0.9789, value_loss: 0.6341
2024-07-11 16:54:22,951 [INFO    ] __main__: train step 12715: loss: 1.0061, policy_loss: 0.9789, value_loss: 0.6341
2024-07-11 16:54:24,397 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:54:24,786 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:54:24,842 [INFO    ] __main__: train step 12716: loss: 1.0061, policy_loss: 0.9788, value_loss: 0.6341
2024-07-11 16:54:25,026 [INFO    ] __main__: train step 12717: loss: 1.0061, policy_loss: 0.9788, value_loss: 0.6341
2024-07-11 16:54:25,257 [INFO    ] __main__: train step 12718: loss: 1.0061, policy_loss: 0.9788, value_loss: 0.6340
2024-07-11 16:54:25,475 [INFO    ] __main__: train step 12719: loss: 1.0061, policy_loss: 0.9788, value_loss: 0.6340
2024-07-11 16:54:25,664 [INFO    ] __main__: train step 12720: loss: 1.0061, policy_loss: 0.9787, value_loss: 0.6340
2024-07-11 16:54:25,866 [INFO    ] __main__: train step 12721: loss: 1.0061, policy_loss: 0.9787, value_loss: 0.6339
2024-07-11 16:54:26,073 [INFO    ] __main__: train step 12722: loss: 1.0061, policy_loss: 0.9787, value_loss: 0.6339
2024-07-11 16:54:26,277 [INFO    ] __main__: train step 12723: loss: 1.0061, policy_loss: 0.9787, value_loss: 0.6339
2024-07-11 16:54:26,492 [INFO    ] __main__: train step 12724: loss: 1.0061, policy_loss: 0.9787, value_loss: 0.6339
2024-07-11 16:54:26,703 [INFO    ] __main__: train step 12725: loss: 1.0060, policy_loss: 0.9786, value_loss: 0.6338
2024-07-11 16:54:26,920 [INFO    ] __main__: train step 12726: loss: 1.0060, policy_loss: 0.9786, value_loss: 0.6338
2024-07-11 16:54:27,147 [INFO    ] __main__: train step 12727: loss: 1.0060, policy_loss: 0.9786, value_loss: 0.6338
2024-07-11 16:54:27,341 [INFO    ] __main__: train step 12728: loss: 1.0060, policy_loss: 0.9786, value_loss: 0.6337
2024-07-11 16:54:27,559 [INFO    ] __main__: train step 12729: loss: 1.0060, policy_loss: 0.9785, value_loss: 0.6337
2024-07-11 16:54:27,760 [INFO    ] __main__: train step 12730: loss: 1.0060, policy_loss: 0.9785, value_loss: 0.6337
2024-07-11 16:54:28,000 [INFO    ] __main__: train step 12731: loss: 1.0060, policy_loss: 0.9785, value_loss: 0.6337
2024-07-11 16:54:28,227 [INFO    ] __main__: train step 12732: loss: 1.0060, policy_loss: 0.9785, value_loss: 0.6336
2024-07-11 16:54:29,663 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:54:30,027 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:54:30,090 [INFO    ] __main__: train step 12733: loss: 1.0060, policy_loss: 0.9784, value_loss: 0.6336
2024-07-11 16:54:30,265 [INFO    ] __main__: train step 12734: loss: 1.0060, policy_loss: 0.9784, value_loss: 0.6336
2024-07-11 16:54:30,469 [INFO    ] __main__: train step 12735: loss: 1.0060, policy_loss: 0.9784, value_loss: 0.6335
2024-07-11 16:54:30,671 [INFO    ] __main__: train step 12736: loss: 1.0060, policy_loss: 0.9784, value_loss: 0.6335
2024-07-11 16:54:30,886 [INFO    ] __main__: train step 12737: loss: 1.0060, policy_loss: 0.9783, value_loss: 0.6335
2024-07-11 16:54:31,094 [INFO    ] __main__: train step 12738: loss: 1.0060, policy_loss: 0.9783, value_loss: 0.6335
2024-07-11 16:54:31,310 [INFO    ] __main__: train step 12739: loss: 1.0060, policy_loss: 0.9783, value_loss: 0.6334
2024-07-11 16:54:31,511 [INFO    ] __main__: train step 12740: loss: 1.0060, policy_loss: 0.9783, value_loss: 0.6334
2024-07-11 16:54:31,719 [INFO    ] __main__: train step 12741: loss: 1.0060, policy_loss: 0.9783, value_loss: 0.6334
2024-07-11 16:54:31,926 [INFO    ] __main__: train step 12742: loss: 1.0060, policy_loss: 0.9782, value_loss: 0.6334
2024-07-11 16:54:32,158 [INFO    ] __main__: train step 12743: loss: 1.0060, policy_loss: 0.9782, value_loss: 0.6333
2024-07-11 16:54:32,355 [INFO    ] __main__: train step 12744: loss: 1.0060, policy_loss: 0.9782, value_loss: 0.6333
2024-07-11 16:54:32,581 [INFO    ] __main__: train step 12745: loss: 1.0060, policy_loss: 0.9782, value_loss: 0.6333
2024-07-11 16:54:32,784 [INFO    ] __main__: train step 12746: loss: 1.0060, policy_loss: 0.9781, value_loss: 0.6332
2024-07-11 16:54:33,006 [INFO    ] __main__: train step 12747: loss: 1.0060, policy_loss: 0.9781, value_loss: 0.6332
2024-07-11 16:54:33,201 [INFO    ] __main__: train step 12748: loss: 1.0060, policy_loss: 0.9781, value_loss: 0.6332
2024-07-11 16:54:33,406 [INFO    ] __main__: train step 12749: loss: 1.0060, policy_loss: 0.9781, value_loss: 0.6332
2024-07-11 16:54:34,848 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:54:35,229 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:54:35,283 [INFO    ] __main__: train step 12750: loss: 1.0060, policy_loss: 0.9780, value_loss: 0.6331
2024-07-11 16:54:35,466 [INFO    ] __main__: train step 12751: loss: 1.0060, policy_loss: 0.9780, value_loss: 0.6331
2024-07-11 16:54:35,659 [INFO    ] __main__: train step 12752: loss: 1.0059, policy_loss: 0.9780, value_loss: 0.6331
2024-07-11 16:54:35,879 [INFO    ] __main__: train step 12753: loss: 1.0059, policy_loss: 0.9780, value_loss: 0.6330
2024-07-11 16:54:36,083 [INFO    ] __main__: train step 12754: loss: 1.0059, policy_loss: 0.9779, value_loss: 0.6330
2024-07-11 16:54:36,294 [INFO    ] __main__: train step 12755: loss: 1.0059, policy_loss: 0.9779, value_loss: 0.6330
2024-07-11 16:54:36,504 [INFO    ] __main__: train step 12756: loss: 1.0059, policy_loss: 0.9779, value_loss: 0.6330
2024-07-11 16:54:36,710 [INFO    ] __main__: train step 12757: loss: 1.0059, policy_loss: 0.9779, value_loss: 0.6329
2024-07-11 16:54:36,922 [INFO    ] __main__: train step 12758: loss: 1.0059, policy_loss: 0.9779, value_loss: 0.6329
2024-07-11 16:54:37,130 [INFO    ] __main__: train step 12759: loss: 1.0059, policy_loss: 0.9778, value_loss: 0.6329
2024-07-11 16:54:37,328 [INFO    ] __main__: train step 12760: loss: 1.0059, policy_loss: 0.9778, value_loss: 0.6329
2024-07-11 16:54:37,532 [INFO    ] __main__: train step 12761: loss: 1.0059, policy_loss: 0.9778, value_loss: 0.6328
2024-07-11 16:54:37,746 [INFO    ] __main__: train step 12762: loss: 1.0059, policy_loss: 0.9778, value_loss: 0.6328
2024-07-11 16:54:37,949 [INFO    ] __main__: train step 12763: loss: 1.0059, policy_loss: 0.9777, value_loss: 0.6328
2024-07-11 16:54:38,166 [INFO    ] __main__: train step 12764: loss: 1.0059, policy_loss: 0.9777, value_loss: 0.6327
2024-07-11 16:54:38,380 [INFO    ] __main__: train step 12765: loss: 1.0059, policy_loss: 0.9777, value_loss: 0.6327
2024-07-11 16:54:38,585 [INFO    ] __main__: train step 12766: loss: 1.0059, policy_loss: 0.9777, value_loss: 0.6327
2024-07-11 16:54:40,021 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:54:40,417 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:54:40,480 [INFO    ] __main__: train step 12767: loss: 1.0059, policy_loss: 0.9776, value_loss: 0.6327
2024-07-11 16:54:40,654 [INFO    ] __main__: train step 12768: loss: 1.0059, policy_loss: 0.9776, value_loss: 0.6326
2024-07-11 16:54:40,857 [INFO    ] __main__: train step 12769: loss: 1.0059, policy_loss: 0.9776, value_loss: 0.6326
2024-07-11 16:54:41,054 [INFO    ] __main__: train step 12770: loss: 1.0059, policy_loss: 0.9776, value_loss: 0.6326
2024-07-11 16:54:41,255 [INFO    ] __main__: train step 12771: loss: 1.0059, policy_loss: 0.9775, value_loss: 0.6325
2024-07-11 16:54:41,465 [INFO    ] __main__: train step 12772: loss: 1.0059, policy_loss: 0.9775, value_loss: 0.6325
2024-07-11 16:54:41,658 [INFO    ] __main__: train step 12773: loss: 1.0059, policy_loss: 0.9775, value_loss: 0.6325
2024-07-11 16:54:41,871 [INFO    ] __main__: train step 12774: loss: 1.0059, policy_loss: 0.9775, value_loss: 0.6325
2024-07-11 16:54:42,076 [INFO    ] __main__: train step 12775: loss: 1.0059, policy_loss: 0.9775, value_loss: 0.6324
2024-07-11 16:54:42,282 [INFO    ] __main__: train step 12776: loss: 1.0059, policy_loss: 0.9774, value_loss: 0.6324
2024-07-11 16:54:42,488 [INFO    ] __main__: train step 12777: loss: 1.0058, policy_loss: 0.9774, value_loss: 0.6324
2024-07-11 16:54:42,711 [INFO    ] __main__: train step 12778: loss: 1.0058, policy_loss: 0.9774, value_loss: 0.6323
2024-07-11 16:54:42,910 [INFO    ] __main__: train step 12779: loss: 1.0058, policy_loss: 0.9774, value_loss: 0.6323
2024-07-11 16:54:43,133 [INFO    ] __main__: train step 12780: loss: 1.0058, policy_loss: 0.9773, value_loss: 0.6323
2024-07-11 16:54:43,344 [INFO    ] __main__: train step 12781: loss: 1.0058, policy_loss: 0.9773, value_loss: 0.6323
2024-07-11 16:54:43,574 [INFO    ] __main__: train step 12782: loss: 1.0058, policy_loss: 0.9773, value_loss: 0.6322
2024-07-11 16:54:43,776 [INFO    ] __main__: train step 12783: loss: 1.0058, policy_loss: 0.9773, value_loss: 0.6322
2024-07-11 16:54:45,214 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:54:45,569 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:54:45,625 [INFO    ] __main__: train step 12784: loss: 1.0058, policy_loss: 0.9772, value_loss: 0.6322
2024-07-11 16:54:45,793 [INFO    ] __main__: train step 12785: loss: 1.0058, policy_loss: 0.9772, value_loss: 0.6322
2024-07-11 16:54:46,004 [INFO    ] __main__: train step 12786: loss: 1.0058, policy_loss: 0.9772, value_loss: 0.6321
2024-07-11 16:54:46,208 [INFO    ] __main__: train step 12787: loss: 1.0058, policy_loss: 0.9772, value_loss: 0.6321
2024-07-11 16:54:46,407 [INFO    ] __main__: train step 12788: loss: 1.0058, policy_loss: 0.9772, value_loss: 0.6321
2024-07-11 16:54:46,612 [INFO    ] __main__: train step 12789: loss: 1.0058, policy_loss: 0.9771, value_loss: 0.6320
2024-07-11 16:54:46,817 [INFO    ] __main__: train step 12790: loss: 1.0058, policy_loss: 0.9771, value_loss: 0.6320
2024-07-11 16:54:47,024 [INFO    ] __main__: train step 12791: loss: 1.0058, policy_loss: 0.9771, value_loss: 0.6320
2024-07-11 16:54:47,233 [INFO    ] __main__: train step 12792: loss: 1.0058, policy_loss: 0.9771, value_loss: 0.6320
2024-07-11 16:54:47,443 [INFO    ] __main__: train step 12793: loss: 1.0058, policy_loss: 0.9770, value_loss: 0.6319
2024-07-11 16:54:47,652 [INFO    ] __main__: train step 12794: loss: 1.0058, policy_loss: 0.9770, value_loss: 0.6319
2024-07-11 16:54:47,851 [INFO    ] __main__: train step 12795: loss: 1.0058, policy_loss: 0.9770, value_loss: 0.6319
2024-07-11 16:54:48,063 [INFO    ] __main__: train step 12796: loss: 1.0058, policy_loss: 0.9770, value_loss: 0.6318
2024-07-11 16:54:49,600 [INFO    ] __main__: train step 12797: loss: 1.0058, policy_loss: 0.9769, value_loss: 0.6318
2024-07-11 16:54:49,840 [INFO    ] __main__: train step 12798: loss: 1.0058, policy_loss: 0.9769, value_loss: 0.6318
2024-07-11 16:54:50,038 [INFO    ] __main__: train step 12799: loss: 1.0057, policy_loss: 0.9769, value_loss: 0.6318
2024-07-11 16:54:50,257 [INFO    ] __main__: train step 12800: loss: 1.0057, policy_loss: 0.9769, value_loss: 0.6317
2024-07-11 16:54:51,690 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:54:52,058 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:54:52,113 [INFO    ] __main__: train step 12801: loss: 1.0057, policy_loss: 0.9768, value_loss: 0.6317
2024-07-11 16:54:52,284 [INFO    ] __main__: train step 12802: loss: 1.0057, policy_loss: 0.9768, value_loss: 0.6317
2024-07-11 16:54:52,504 [INFO    ] __main__: train step 12803: loss: 1.0057, policy_loss: 0.9768, value_loss: 0.6316
2024-07-11 16:54:52,733 [INFO    ] __main__: train step 12804: loss: 1.0057, policy_loss: 0.9768, value_loss: 0.6316
2024-07-11 16:54:52,938 [INFO    ] __main__: train step 12805: loss: 1.0057, policy_loss: 0.9768, value_loss: 0.6316
2024-07-11 16:54:53,155 [INFO    ] __main__: train step 12806: loss: 1.0057, policy_loss: 0.9767, value_loss: 0.6316
2024-07-11 16:54:53,355 [INFO    ] __main__: train step 12807: loss: 1.0057, policy_loss: 0.9767, value_loss: 0.6315
2024-07-11 16:54:53,552 [INFO    ] __main__: train step 12808: loss: 1.0057, policy_loss: 0.9767, value_loss: 0.6315
2024-07-11 16:54:53,766 [INFO    ] __main__: train step 12809: loss: 1.0057, policy_loss: 0.9767, value_loss: 0.6315
2024-07-11 16:54:53,981 [INFO    ] __main__: train step 12810: loss: 1.0057, policy_loss: 0.9766, value_loss: 0.6314
2024-07-11 16:54:54,210 [INFO    ] __main__: train step 12811: loss: 1.0057, policy_loss: 0.9766, value_loss: 0.6314
2024-07-11 16:54:54,409 [INFO    ] __main__: train step 12812: loss: 1.0057, policy_loss: 0.9766, value_loss: 0.6314
2024-07-11 16:54:54,613 [INFO    ] __main__: train step 12813: loss: 1.0057, policy_loss: 0.9766, value_loss: 0.6314
2024-07-11 16:54:54,820 [INFO    ] __main__: train step 12814: loss: 1.0057, policy_loss: 0.9765, value_loss: 0.6313
2024-07-11 16:54:55,037 [INFO    ] __main__: train step 12815: loss: 1.0057, policy_loss: 0.9765, value_loss: 0.6313
2024-07-11 16:54:55,267 [INFO    ] __main__: train step 12816: loss: 1.0057, policy_loss: 0.9765, value_loss: 0.6313
2024-07-11 16:54:55,474 [INFO    ] __main__: train step 12817: loss: 1.0057, policy_loss: 0.9765, value_loss: 0.6312
2024-07-11 16:54:56,913 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:54:57,321 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:54:57,385 [INFO    ] __main__: train step 12818: loss: 1.0057, policy_loss: 0.9765, value_loss: 0.6312
2024-07-11 16:54:57,555 [INFO    ] __main__: train step 12819: loss: 1.0057, policy_loss: 0.9764, value_loss: 0.6312
2024-07-11 16:54:57,775 [INFO    ] __main__: train step 12820: loss: 1.0057, policy_loss: 0.9764, value_loss: 0.6312
2024-07-11 16:54:57,983 [INFO    ] __main__: train step 12821: loss: 1.0056, policy_loss: 0.9764, value_loss: 0.6311
2024-07-11 16:54:58,183 [INFO    ] __main__: train step 12822: loss: 1.0056, policy_loss: 0.9764, value_loss: 0.6311
2024-07-11 16:54:58,409 [INFO    ] __main__: train step 12823: loss: 1.0056, policy_loss: 0.9763, value_loss: 0.6311
2024-07-11 16:54:58,604 [INFO    ] __main__: train step 12824: loss: 1.0056, policy_loss: 0.9763, value_loss: 0.6310
2024-07-11 16:54:58,818 [INFO    ] __main__: train step 12825: loss: 1.0056, policy_loss: 0.9763, value_loss: 0.6310
2024-07-11 16:54:59,014 [INFO    ] __main__: train step 12826: loss: 1.0056, policy_loss: 0.9763, value_loss: 0.6310
2024-07-11 16:54:59,242 [INFO    ] __main__: train step 12827: loss: 1.0056, policy_loss: 0.9763, value_loss: 0.6310
2024-07-11 16:54:59,495 [INFO    ] __main__: train step 12828: loss: 1.0056, policy_loss: 0.9762, value_loss: 0.6309
2024-07-11 16:54:59,729 [INFO    ] __main__: train step 12829: loss: 1.0056, policy_loss: 0.9762, value_loss: 0.6309
2024-07-11 16:54:59,952 [INFO    ] __main__: train step 12830: loss: 1.0056, policy_loss: 0.9762, value_loss: 0.6309
2024-07-11 16:55:00,186 [INFO    ] __main__: train step 12831: loss: 1.0056, policy_loss: 0.9762, value_loss: 0.6308
2024-07-11 16:55:00,380 [INFO    ] __main__: train step 12832: loss: 1.0056, policy_loss: 0.9761, value_loss: 0.6308
2024-07-11 16:55:00,607 [INFO    ] __main__: train step 12833: loss: 1.0056, policy_loss: 0.9761, value_loss: 0.6308
2024-07-11 16:55:00,827 [INFO    ] __main__: train step 12834: loss: 1.0056, policy_loss: 0.9761, value_loss: 0.6308
2024-07-11 16:55:02,254 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:55:02,649 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:55:02,702 [INFO    ] __main__: train step 12835: loss: 1.0056, policy_loss: 0.9761, value_loss: 0.6307
2024-07-11 16:55:02,886 [INFO    ] __main__: train step 12836: loss: 1.0056, policy_loss: 0.9760, value_loss: 0.6307
2024-07-11 16:55:03,107 [INFO    ] __main__: train step 12837: loss: 1.0056, policy_loss: 0.9760, value_loss: 0.6307
2024-07-11 16:55:03,309 [INFO    ] __main__: train step 12838: loss: 1.0056, policy_loss: 0.9760, value_loss: 0.6306
2024-07-11 16:55:03,521 [INFO    ] __main__: train step 12839: loss: 1.0056, policy_loss: 0.9760, value_loss: 0.6306
2024-07-11 16:55:03,719 [INFO    ] __main__: train step 12840: loss: 1.0056, policy_loss: 0.9760, value_loss: 0.6306
2024-07-11 16:55:03,924 [INFO    ] __main__: train step 12841: loss: 1.0056, policy_loss: 0.9759, value_loss: 0.6306
2024-07-11 16:55:04,127 [INFO    ] __main__: train step 12842: loss: 1.0056, policy_loss: 0.9759, value_loss: 0.6305
2024-07-11 16:55:04,330 [INFO    ] __main__: train step 12843: loss: 1.0056, policy_loss: 0.9759, value_loss: 0.6305
2024-07-11 16:55:04,543 [INFO    ] __main__: train step 12844: loss: 1.0055, policy_loss: 0.9759, value_loss: 0.6305
2024-07-11 16:55:04,744 [INFO    ] __main__: train step 12845: loss: 1.0055, policy_loss: 0.9758, value_loss: 0.6304
2024-07-11 16:55:04,946 [INFO    ] __main__: train step 12846: loss: 1.0055, policy_loss: 0.9758, value_loss: 0.6304
2024-07-11 16:55:05,160 [INFO    ] __main__: train step 12847: loss: 1.0055, policy_loss: 0.9758, value_loss: 0.6304
2024-07-11 16:55:05,355 [INFO    ] __main__: train step 12848: loss: 1.0055, policy_loss: 0.9758, value_loss: 0.6304
2024-07-11 16:55:05,576 [INFO    ] __main__: train step 12849: loss: 1.0055, policy_loss: 0.9757, value_loss: 0.6303
2024-07-11 16:55:05,813 [INFO    ] __main__: train step 12850: loss: 1.0055, policy_loss: 0.9757, value_loss: 0.6303
2024-07-11 16:55:06,032 [INFO    ] __main__: train step 12851: loss: 1.0055, policy_loss: 0.9757, value_loss: 0.6303
2024-07-11 16:55:07,483 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:55:07,846 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:55:07,907 [INFO    ] __main__: train step 12852: loss: 1.0055, policy_loss: 0.9757, value_loss: 0.6303
2024-07-11 16:55:08,077 [INFO    ] __main__: train step 12853: loss: 1.0055, policy_loss: 0.9756, value_loss: 0.6302
2024-07-11 16:55:08,292 [INFO    ] __main__: train step 12854: loss: 1.0055, policy_loss: 0.9756, value_loss: 0.6302
2024-07-11 16:55:08,509 [INFO    ] __main__: train step 12855: loss: 1.0055, policy_loss: 0.9756, value_loss: 0.6302
2024-07-11 16:55:08,715 [INFO    ] __main__: train step 12856: loss: 1.0055, policy_loss: 0.9756, value_loss: 0.6301
2024-07-11 16:55:08,927 [INFO    ] __main__: train step 12857: loss: 1.0055, policy_loss: 0.9756, value_loss: 0.6301
2024-07-11 16:55:09,124 [INFO    ] __main__: train step 12858: loss: 1.0055, policy_loss: 0.9755, value_loss: 0.6301
2024-07-11 16:55:09,332 [INFO    ] __main__: train step 12859: loss: 1.0055, policy_loss: 0.9755, value_loss: 0.6301
2024-07-11 16:55:09,539 [INFO    ] __main__: train step 12860: loss: 1.0055, policy_loss: 0.9755, value_loss: 0.6300
2024-07-11 16:55:09,741 [INFO    ] __main__: train step 12861: loss: 1.0055, policy_loss: 0.9755, value_loss: 0.6300
2024-07-11 16:55:09,938 [INFO    ] __main__: train step 12862: loss: 1.0055, policy_loss: 0.9754, value_loss: 0.6300
2024-07-11 16:55:10,131 [INFO    ] __main__: train step 12863: loss: 1.0055, policy_loss: 0.9754, value_loss: 0.6300
2024-07-11 16:55:10,340 [INFO    ] __main__: train step 12864: loss: 1.0055, policy_loss: 0.9754, value_loss: 0.6299
2024-07-11 16:55:10,537 [INFO    ] __main__: train step 12865: loss: 1.0055, policy_loss: 0.9754, value_loss: 0.6299
2024-07-11 16:55:10,758 [INFO    ] __main__: train step 12866: loss: 1.0055, policy_loss: 0.9754, value_loss: 0.6299
2024-07-11 16:55:10,953 [INFO    ] __main__: train step 12867: loss: 1.0054, policy_loss: 0.9753, value_loss: 0.6298
2024-07-11 16:55:11,167 [INFO    ] __main__: train step 12868: loss: 1.0054, policy_loss: 0.9753, value_loss: 0.6298
2024-07-11 16:55:12,627 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:55:13,032 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:55:13,093 [INFO    ] __main__: train step 12869: loss: 1.0054, policy_loss: 0.9753, value_loss: 0.6298
2024-07-11 16:55:13,270 [INFO    ] __main__: train step 12870: loss: 1.0054, policy_loss: 0.9753, value_loss: 0.6298
2024-07-11 16:55:13,468 [INFO    ] __main__: train step 12871: loss: 1.0054, policy_loss: 0.9752, value_loss: 0.6297
2024-07-11 16:55:13,672 [INFO    ] __main__: train step 12872: loss: 1.0054, policy_loss: 0.9752, value_loss: 0.6297
2024-07-11 16:55:13,907 [INFO    ] __main__: train step 12873: loss: 1.0054, policy_loss: 0.9752, value_loss: 0.6297
2024-07-11 16:55:14,126 [INFO    ] __main__: train step 12874: loss: 1.0054, policy_loss: 0.9752, value_loss: 0.6296
2024-07-11 16:55:14,332 [INFO    ] __main__: train step 12875: loss: 1.0054, policy_loss: 0.9751, value_loss: 0.6296
2024-07-11 16:55:14,535 [INFO    ] __main__: train step 12876: loss: 1.0054, policy_loss: 0.9751, value_loss: 0.6296
2024-07-11 16:55:14,735 [INFO    ] __main__: train step 12877: loss: 1.0054, policy_loss: 0.9751, value_loss: 0.6296
2024-07-11 16:55:14,950 [INFO    ] __main__: train step 12878: loss: 1.0054, policy_loss: 0.9751, value_loss: 0.6295
2024-07-11 16:55:15,137 [INFO    ] __main__: train step 12879: loss: 1.0054, policy_loss: 0.9751, value_loss: 0.6295
2024-07-11 16:55:15,347 [INFO    ] __main__: train step 12880: loss: 1.0054, policy_loss: 0.9750, value_loss: 0.6295
2024-07-11 16:55:15,561 [INFO    ] __main__: train step 12881: loss: 1.0054, policy_loss: 0.9750, value_loss: 0.6294
2024-07-11 16:55:15,772 [INFO    ] __main__: train step 12882: loss: 1.0054, policy_loss: 0.9750, value_loss: 0.6294
2024-07-11 16:55:15,974 [INFO    ] __main__: train step 12883: loss: 1.0054, policy_loss: 0.9750, value_loss: 0.6294
2024-07-11 16:55:16,186 [INFO    ] __main__: train step 12884: loss: 1.0054, policy_loss: 0.9749, value_loss: 0.6294
2024-07-11 16:55:16,380 [INFO    ] __main__: train step 12885: loss: 1.0054, policy_loss: 0.9749, value_loss: 0.6293
2024-07-11 16:55:17,826 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:55:18,240 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:55:18,306 [INFO    ] __main__: train step 12886: loss: 1.0054, policy_loss: 0.9749, value_loss: 0.6293
2024-07-11 16:55:18,486 [INFO    ] __main__: train step 12887: loss: 1.0053, policy_loss: 0.9749, value_loss: 0.6293
2024-07-11 16:55:18,694 [INFO    ] __main__: train step 12888: loss: 1.0053, policy_loss: 0.9748, value_loss: 0.6292
2024-07-11 16:55:18,896 [INFO    ] __main__: train step 12889: loss: 1.0053, policy_loss: 0.9748, value_loss: 0.6292
2024-07-11 16:55:19,104 [INFO    ] __main__: train step 12890: loss: 1.0053, policy_loss: 0.9748, value_loss: 0.6292
2024-07-11 16:55:19,311 [INFO    ] __main__: train step 12891: loss: 1.0053, policy_loss: 0.9748, value_loss: 0.6292
2024-07-11 16:55:19,514 [INFO    ] __main__: train step 12892: loss: 1.0053, policy_loss: 0.9748, value_loss: 0.6291
2024-07-11 16:55:19,724 [INFO    ] __main__: train step 12893: loss: 1.0053, policy_loss: 0.9747, value_loss: 0.6291
2024-07-11 16:55:19,916 [INFO    ] __main__: train step 12894: loss: 1.0053, policy_loss: 0.9747, value_loss: 0.6291
2024-07-11 16:55:20,122 [INFO    ] __main__: train step 12895: loss: 1.0053, policy_loss: 0.9747, value_loss: 0.6290
2024-07-11 16:55:20,323 [INFO    ] __main__: train step 12896: loss: 1.0053, policy_loss: 0.9747, value_loss: 0.6290
2024-07-11 16:55:21,874 [INFO    ] __main__: train step 12897: loss: 1.0053, policy_loss: 0.9746, value_loss: 0.6290
2024-07-11 16:55:22,094 [INFO    ] __main__: train step 12898: loss: 1.0053, policy_loss: 0.9746, value_loss: 0.6290
2024-07-11 16:55:22,303 [INFO    ] __main__: train step 12899: loss: 1.0053, policy_loss: 0.9746, value_loss: 0.6289
2024-07-11 16:55:22,504 [INFO    ] __main__: train step 12900: loss: 1.0053, policy_loss: 0.9746, value_loss: 0.6289
2024-07-11 16:55:22,707 [INFO    ] __main__: train step 12901: loss: 1.0053, policy_loss: 0.9746, value_loss: 0.6289
2024-07-11 16:55:22,907 [INFO    ] __main__: train step 12902: loss: 1.0053, policy_loss: 0.9745, value_loss: 0.6288
2024-07-11 16:55:24,341 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:55:24,702 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:55:24,761 [INFO    ] __main__: train step 12903: loss: 1.0053, policy_loss: 0.9745, value_loss: 0.6288
2024-07-11 16:55:24,938 [INFO    ] __main__: train step 12904: loss: 1.0053, policy_loss: 0.9745, value_loss: 0.6288
2024-07-11 16:55:25,149 [INFO    ] __main__: train step 12905: loss: 1.0053, policy_loss: 0.9745, value_loss: 0.6288
2024-07-11 16:55:25,348 [INFO    ] __main__: train step 12906: loss: 1.0053, policy_loss: 0.9744, value_loss: 0.6287
2024-07-11 16:55:25,541 [INFO    ] __main__: train step 12907: loss: 1.0053, policy_loss: 0.9744, value_loss: 0.6287
2024-07-11 16:55:25,758 [INFO    ] __main__: train step 12908: loss: 1.0053, policy_loss: 0.9744, value_loss: 0.6287
2024-07-11 16:55:25,986 [INFO    ] __main__: train step 12909: loss: 1.0053, policy_loss: 0.9744, value_loss: 0.6286
2024-07-11 16:55:26,201 [INFO    ] __main__: train step 12910: loss: 1.0052, policy_loss: 0.9743, value_loss: 0.6286
2024-07-11 16:55:26,425 [INFO    ] __main__: train step 12911: loss: 1.0052, policy_loss: 0.9743, value_loss: 0.6286
2024-07-11 16:55:26,620 [INFO    ] __main__: train step 12912: loss: 1.0052, policy_loss: 0.9743, value_loss: 0.6286
2024-07-11 16:55:26,828 [INFO    ] __main__: train step 12913: loss: 1.0052, policy_loss: 0.9743, value_loss: 0.6285
2024-07-11 16:55:27,048 [INFO    ] __main__: train step 12914: loss: 1.0052, policy_loss: 0.9743, value_loss: 0.6285
2024-07-11 16:55:27,280 [INFO    ] __main__: train step 12915: loss: 1.0052, policy_loss: 0.9742, value_loss: 0.6285
2024-07-11 16:55:27,493 [INFO    ] __main__: train step 12916: loss: 1.0052, policy_loss: 0.9742, value_loss: 0.6285
2024-07-11 16:55:27,722 [INFO    ] __main__: train step 12917: loss: 1.0052, policy_loss: 0.9742, value_loss: 0.6284
2024-07-11 16:55:27,935 [INFO    ] __main__: train step 12918: loss: 1.0052, policy_loss: 0.9742, value_loss: 0.6284
2024-07-11 16:55:28,136 [INFO    ] __main__: train step 12919: loss: 1.0052, policy_loss: 0.9741, value_loss: 0.6284
2024-07-11 16:55:29,582 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:55:29,931 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:55:29,987 [INFO    ] __main__: train step 12920: loss: 1.0052, policy_loss: 0.9741, value_loss: 0.6283
2024-07-11 16:55:30,165 [INFO    ] __main__: train step 12921: loss: 1.0052, policy_loss: 0.9741, value_loss: 0.6283
2024-07-11 16:55:30,373 [INFO    ] __main__: train step 12922: loss: 1.0052, policy_loss: 0.9741, value_loss: 0.6283
2024-07-11 16:55:30,576 [INFO    ] __main__: train step 12923: loss: 1.0052, policy_loss: 0.9741, value_loss: 0.6283
2024-07-11 16:55:30,786 [INFO    ] __main__: train step 12924: loss: 1.0052, policy_loss: 0.9740, value_loss: 0.6282
2024-07-11 16:55:30,980 [INFO    ] __main__: train step 12925: loss: 1.0052, policy_loss: 0.9740, value_loss: 0.6282
2024-07-11 16:55:31,185 [INFO    ] __main__: train step 12926: loss: 1.0052, policy_loss: 0.9740, value_loss: 0.6282
2024-07-11 16:55:31,405 [INFO    ] __main__: train step 12927: loss: 1.0052, policy_loss: 0.9740, value_loss: 0.6281
2024-07-11 16:55:31,600 [INFO    ] __main__: train step 12928: loss: 1.0052, policy_loss: 0.9739, value_loss: 0.6281
2024-07-11 16:55:31,804 [INFO    ] __main__: train step 12929: loss: 1.0052, policy_loss: 0.9739, value_loss: 0.6281
2024-07-11 16:55:32,017 [INFO    ] __main__: train step 12930: loss: 1.0052, policy_loss: 0.9739, value_loss: 0.6281
2024-07-11 16:55:32,226 [INFO    ] __main__: train step 12931: loss: 1.0052, policy_loss: 0.9739, value_loss: 0.6280
2024-07-11 16:55:32,426 [INFO    ] __main__: train step 12932: loss: 1.0051, policy_loss: 0.9738, value_loss: 0.6280
2024-07-11 16:55:32,646 [INFO    ] __main__: train step 12933: loss: 1.0051, policy_loss: 0.9738, value_loss: 0.6280
2024-07-11 16:55:32,882 [INFO    ] __main__: train step 12934: loss: 1.0051, policy_loss: 0.9738, value_loss: 0.6279
2024-07-11 16:55:33,097 [INFO    ] __main__: train step 12935: loss: 1.0051, policy_loss: 0.9738, value_loss: 0.6279
2024-07-11 16:55:33,324 [INFO    ] __main__: train step 12936: loss: 1.0051, policy_loss: 0.9738, value_loss: 0.6279
2024-07-11 16:55:34,758 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:55:35,150 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:55:35,211 [INFO    ] __main__: train step 12937: loss: 1.0051, policy_loss: 0.9737, value_loss: 0.6279
2024-07-11 16:55:35,395 [INFO    ] __main__: train step 12938: loss: 1.0051, policy_loss: 0.9737, value_loss: 0.6278
2024-07-11 16:55:35,602 [INFO    ] __main__: train step 12939: loss: 1.0051, policy_loss: 0.9737, value_loss: 0.6278
2024-07-11 16:55:35,853 [INFO    ] __main__: train step 12940: loss: 1.0051, policy_loss: 0.9737, value_loss: 0.6278
2024-07-11 16:55:36,075 [INFO    ] __main__: train step 12941: loss: 1.0051, policy_loss: 0.9736, value_loss: 0.6277
2024-07-11 16:55:36,285 [INFO    ] __main__: train step 12942: loss: 1.0051, policy_loss: 0.9736, value_loss: 0.6277
2024-07-11 16:55:36,484 [INFO    ] __main__: train step 12943: loss: 1.0051, policy_loss: 0.9736, value_loss: 0.6277
2024-07-11 16:55:36,703 [INFO    ] __main__: train step 12944: loss: 1.0051, policy_loss: 0.9736, value_loss: 0.6277
2024-07-11 16:55:36,933 [INFO    ] __main__: train step 12945: loss: 1.0051, policy_loss: 0.9735, value_loss: 0.6276
2024-07-11 16:55:37,143 [INFO    ] __main__: train step 12946: loss: 1.0051, policy_loss: 0.9735, value_loss: 0.6276
2024-07-11 16:55:37,377 [INFO    ] __main__: train step 12947: loss: 1.0051, policy_loss: 0.9735, value_loss: 0.6276
2024-07-11 16:55:37,587 [INFO    ] __main__: train step 12948: loss: 1.0051, policy_loss: 0.9735, value_loss: 0.6275
2024-07-11 16:55:37,788 [INFO    ] __main__: train step 12949: loss: 1.0051, policy_loss: 0.9735, value_loss: 0.6275
2024-07-11 16:55:37,999 [INFO    ] __main__: train step 12950: loss: 1.0051, policy_loss: 0.9734, value_loss: 0.6275
2024-07-11 16:55:38,211 [INFO    ] __main__: train step 12951: loss: 1.0051, policy_loss: 0.9734, value_loss: 0.6275
2024-07-11 16:55:38,409 [INFO    ] __main__: train step 12952: loss: 1.0051, policy_loss: 0.9734, value_loss: 0.6274
2024-07-11 16:55:38,611 [INFO    ] __main__: train step 12953: loss: 1.0050, policy_loss: 0.9734, value_loss: 0.6274
2024-07-11 16:55:40,061 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:55:40,492 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:55:40,552 [INFO    ] __main__: train step 12954: loss: 1.0050, policy_loss: 0.9734, value_loss: 0.6274
2024-07-11 16:55:40,735 [INFO    ] __main__: train step 12955: loss: 1.0050, policy_loss: 0.9733, value_loss: 0.6274
2024-07-11 16:55:40,940 [INFO    ] __main__: train step 12956: loss: 1.0050, policy_loss: 0.9733, value_loss: 0.6273
2024-07-11 16:55:41,157 [INFO    ] __main__: train step 12957: loss: 1.0050, policy_loss: 0.9733, value_loss: 0.6273
2024-07-11 16:55:41,358 [INFO    ] __main__: train step 12958: loss: 1.0050, policy_loss: 0.9733, value_loss: 0.6273
2024-07-11 16:55:41,590 [INFO    ] __main__: train step 12959: loss: 1.0050, policy_loss: 0.9732, value_loss: 0.6272
2024-07-11 16:55:41,821 [INFO    ] __main__: train step 12960: loss: 1.0050, policy_loss: 0.9732, value_loss: 0.6272
2024-07-11 16:55:42,026 [INFO    ] __main__: train step 12961: loss: 1.0050, policy_loss: 0.9732, value_loss: 0.6272
2024-07-11 16:55:42,243 [INFO    ] __main__: train step 12962: loss: 1.0050, policy_loss: 0.9732, value_loss: 0.6272
2024-07-11 16:55:42,450 [INFO    ] __main__: train step 12963: loss: 1.0050, policy_loss: 0.9731, value_loss: 0.6271
2024-07-11 16:55:42,679 [INFO    ] __main__: train step 12964: loss: 1.0050, policy_loss: 0.9731, value_loss: 0.6271
2024-07-11 16:55:42,901 [INFO    ] __main__: train step 12965: loss: 1.0050, policy_loss: 0.9731, value_loss: 0.6271
2024-07-11 16:55:43,095 [INFO    ] __main__: train step 12966: loss: 1.0050, policy_loss: 0.9731, value_loss: 0.6270
2024-07-11 16:55:43,294 [INFO    ] __main__: train step 12967: loss: 1.0050, policy_loss: 0.9731, value_loss: 0.6270
2024-07-11 16:55:43,500 [INFO    ] __main__: train step 12968: loss: 1.0050, policy_loss: 0.9730, value_loss: 0.6270
2024-07-11 16:55:43,711 [INFO    ] __main__: train step 12969: loss: 1.0050, policy_loss: 0.9730, value_loss: 0.6270
2024-07-11 16:55:43,910 [INFO    ] __main__: train step 12970: loss: 1.0050, policy_loss: 0.9730, value_loss: 0.6269
2024-07-11 16:55:45,333 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:55:45,681 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:55:45,737 [INFO    ] __main__: train step 12971: loss: 1.0050, policy_loss: 0.9730, value_loss: 0.6269
2024-07-11 16:55:45,915 [INFO    ] __main__: train step 12972: loss: 1.0050, policy_loss: 0.9729, value_loss: 0.6269
2024-07-11 16:55:46,116 [INFO    ] __main__: train step 12973: loss: 1.0049, policy_loss: 0.9729, value_loss: 0.6268
2024-07-11 16:55:46,312 [INFO    ] __main__: train step 12974: loss: 1.0049, policy_loss: 0.9729, value_loss: 0.6268
2024-07-11 16:55:46,508 [INFO    ] __main__: train step 12975: loss: 1.0049, policy_loss: 0.9729, value_loss: 0.6268
2024-07-11 16:55:46,712 [INFO    ] __main__: train step 12976: loss: 1.0049, policy_loss: 0.9729, value_loss: 0.6268
2024-07-11 16:55:46,935 [INFO    ] __main__: train step 12977: loss: 1.0049, policy_loss: 0.9728, value_loss: 0.6267
2024-07-11 16:55:47,138 [INFO    ] __main__: train step 12978: loss: 1.0049, policy_loss: 0.9728, value_loss: 0.6267
2024-07-11 16:55:47,349 [INFO    ] __main__: train step 12979: loss: 1.0049, policy_loss: 0.9728, value_loss: 0.6267
2024-07-11 16:55:47,558 [INFO    ] __main__: train step 12980: loss: 1.0049, policy_loss: 0.9728, value_loss: 0.6266
2024-07-11 16:55:47,775 [INFO    ] __main__: train step 12981: loss: 1.0049, policy_loss: 0.9727, value_loss: 0.6266
2024-07-11 16:55:47,989 [INFO    ] __main__: train step 12982: loss: 1.0049, policy_loss: 0.9727, value_loss: 0.6266
2024-07-11 16:55:48,210 [INFO    ] __main__: train step 12983: loss: 1.0049, policy_loss: 0.9727, value_loss: 0.6266
2024-07-11 16:55:48,413 [INFO    ] __main__: train step 12984: loss: 1.0049, policy_loss: 0.9727, value_loss: 0.6265
2024-07-11 16:55:48,615 [INFO    ] __main__: train step 12985: loss: 1.0049, policy_loss: 0.9726, value_loss: 0.6265
2024-07-11 16:55:48,819 [INFO    ] __main__: train step 12986: loss: 1.0049, policy_loss: 0.9726, value_loss: 0.6265
2024-07-11 16:55:49,032 [INFO    ] __main__: train step 12987: loss: 1.0049, policy_loss: 0.9726, value_loss: 0.6264
2024-07-11 16:55:50,468 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:55:50,877 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:55:50,937 [INFO    ] __main__: train step 12988: loss: 1.0049, policy_loss: 0.9726, value_loss: 0.6264
2024-07-11 16:55:51,110 [INFO    ] __main__: train step 12989: loss: 1.0049, policy_loss: 0.9726, value_loss: 0.6264
2024-07-11 16:55:51,321 [INFO    ] __main__: train step 12990: loss: 1.0049, policy_loss: 0.9725, value_loss: 0.6264
2024-07-11 16:55:51,529 [INFO    ] __main__: train step 12991: loss: 1.0048, policy_loss: 0.9725, value_loss: 0.6263
2024-07-11 16:55:51,743 [INFO    ] __main__: train step 12992: loss: 1.0048, policy_loss: 0.9725, value_loss: 0.6263
2024-07-11 16:55:51,942 [INFO    ] __main__: train step 12993: loss: 1.0048, policy_loss: 0.9725, value_loss: 0.6263
2024-07-11 16:55:52,156 [INFO    ] __main__: train step 12994: loss: 1.0048, policy_loss: 0.9724, value_loss: 0.6262
2024-07-11 16:55:52,357 [INFO    ] __main__: train step 12995: loss: 1.0048, policy_loss: 0.9724, value_loss: 0.6262
2024-07-11 16:55:52,574 [INFO    ] __main__: train step 12996: loss: 1.0048, policy_loss: 0.9724, value_loss: 0.6262
2024-07-11 16:55:52,771 [INFO    ] __main__: train step 12997: loss: 1.0048, policy_loss: 0.9724, value_loss: 0.6262
2024-07-11 16:55:54,397 [INFO    ] __main__: train step 12998: loss: 1.0048, policy_loss: 0.9724, value_loss: 0.6261
2024-07-11 16:55:54,615 [INFO    ] __main__: train step 12999: loss: 1.0048, policy_loss: 0.9723, value_loss: 0.6261
2024-07-11 16:55:54,815 [INFO    ] __main__: train step 13000: loss: 1.0048, policy_loss: 0.9723, value_loss: 0.6261
2024-07-11 16:55:54,930 [INFO    ] __main__: restored step 12000 for evaluation
2024-07-11 16:56:02,257 [INFO    ] __main__: later network ELO difference from earlier network: +76 (+8/-8) ELO from 32000 self-played games
2024-07-11 16:56:02,257 [INFO    ] __main__: game outcomes: W: 18355, D: 997, L: 12648
2024-07-11 16:56:02,259 [INFO    ] __main__: validation_elo_delta: 76, validation_elo: 2274
2024-07-11 16:56:02,794 [INFO    ] __main__: train step 13001: loss: 1.0048, policy_loss: 0.9723, value_loss: 0.6260
2024-07-11 16:56:03,000 [INFO    ] __main__: train step 13002: loss: 1.0048, policy_loss: 0.9723, value_loss: 0.6260
2024-07-11 16:56:03,200 [INFO    ] __main__: train step 13003: loss: 1.0048, policy_loss: 0.9722, value_loss: 0.6260
2024-07-11 16:56:03,395 [INFO    ] __main__: train step 13004: loss: 1.0048, policy_loss: 0.9722, value_loss: 0.6260
2024-07-11 16:56:04,837 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:56:05,197 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:56:05,256 [INFO    ] __main__: train step 13005: loss: 1.0048, policy_loss: 0.9722, value_loss: 0.6259
2024-07-11 16:56:05,455 [INFO    ] __main__: train step 13006: loss: 1.0048, policy_loss: 0.9722, value_loss: 0.6259
2024-07-11 16:56:05,695 [INFO    ] __main__: train step 13007: loss: 1.0048, policy_loss: 0.9721, value_loss: 0.6259
2024-07-11 16:56:05,916 [INFO    ] __main__: train step 13008: loss: 1.0047, policy_loss: 0.9721, value_loss: 0.6258
2024-07-11 16:56:06,148 [INFO    ] __main__: train step 13009: loss: 1.0047, policy_loss: 0.9721, value_loss: 0.6258
2024-07-11 16:56:06,359 [INFO    ] __main__: train step 13010: loss: 1.0047, policy_loss: 0.9721, value_loss: 0.6258
2024-07-11 16:56:06,567 [INFO    ] __main__: train step 13011: loss: 1.0047, policy_loss: 0.9721, value_loss: 0.6257
2024-07-11 16:56:06,771 [INFO    ] __main__: train step 13012: loss: 1.0047, policy_loss: 0.9720, value_loss: 0.6257
2024-07-11 16:56:06,979 [INFO    ] __main__: train step 13013: loss: 1.0047, policy_loss: 0.9720, value_loss: 0.6257
2024-07-11 16:56:07,180 [INFO    ] __main__: train step 13014: loss: 1.0047, policy_loss: 0.9720, value_loss: 0.6257
2024-07-11 16:56:07,388 [INFO    ] __main__: train step 13015: loss: 1.0047, policy_loss: 0.9720, value_loss: 0.6256
2024-07-11 16:56:07,589 [INFO    ] __main__: train step 13016: loss: 1.0047, policy_loss: 0.9719, value_loss: 0.6256
2024-07-11 16:56:07,810 [INFO    ] __main__: train step 13017: loss: 1.0047, policy_loss: 0.9719, value_loss: 0.6256
2024-07-11 16:56:08,010 [INFO    ] __main__: train step 13018: loss: 1.0047, policy_loss: 0.9719, value_loss: 0.6255
2024-07-11 16:56:08,228 [INFO    ] __main__: train step 13019: loss: 1.0047, policy_loss: 0.9719, value_loss: 0.6255
2024-07-11 16:56:08,483 [INFO    ] __main__: train step 13020: loss: 1.0047, policy_loss: 0.9719, value_loss: 0.6255
2024-07-11 16:56:08,724 [INFO    ] __main__: train step 13021: loss: 1.0047, policy_loss: 0.9718, value_loss: 0.6255
2024-07-11 16:56:10,165 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:56:10,522 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:56:10,585 [INFO    ] __main__: train step 13022: loss: 1.0047, policy_loss: 0.9718, value_loss: 0.6254
2024-07-11 16:56:10,756 [INFO    ] __main__: train step 13023: loss: 1.0047, policy_loss: 0.9718, value_loss: 0.6254
2024-07-11 16:56:10,953 [INFO    ] __main__: train step 13024: loss: 1.0046, policy_loss: 0.9718, value_loss: 0.6254
2024-07-11 16:56:11,167 [INFO    ] __main__: train step 13025: loss: 1.0046, policy_loss: 0.9717, value_loss: 0.6253
2024-07-11 16:56:11,364 [INFO    ] __main__: train step 13026: loss: 1.0046, policy_loss: 0.9717, value_loss: 0.6253
2024-07-11 16:56:11,576 [INFO    ] __main__: train step 13027: loss: 1.0046, policy_loss: 0.9717, value_loss: 0.6253
2024-07-11 16:56:11,781 [INFO    ] __main__: train step 13028: loss: 1.0046, policy_loss: 0.9717, value_loss: 0.6253
2024-07-11 16:56:11,988 [INFO    ] __main__: train step 13029: loss: 1.0046, policy_loss: 0.9717, value_loss: 0.6252
2024-07-11 16:56:12,217 [INFO    ] __main__: train step 13030: loss: 1.0046, policy_loss: 0.9716, value_loss: 0.6252
2024-07-11 16:56:12,420 [INFO    ] __main__: train step 13031: loss: 1.0046, policy_loss: 0.9716, value_loss: 0.6252
2024-07-11 16:56:12,623 [INFO    ] __main__: train step 13032: loss: 1.0046, policy_loss: 0.9716, value_loss: 0.6251
2024-07-11 16:56:12,828 [INFO    ] __main__: train step 13033: loss: 1.0046, policy_loss: 0.9716, value_loss: 0.6251
2024-07-11 16:56:13,027 [INFO    ] __main__: train step 13034: loss: 1.0046, policy_loss: 0.9715, value_loss: 0.6251
2024-07-11 16:56:13,230 [INFO    ] __main__: train step 13035: loss: 1.0046, policy_loss: 0.9715, value_loss: 0.6251
2024-07-11 16:56:13,423 [INFO    ] __main__: train step 13036: loss: 1.0046, policy_loss: 0.9715, value_loss: 0.6250
2024-07-11 16:56:13,630 [INFO    ] __main__: train step 13037: loss: 1.0046, policy_loss: 0.9715, value_loss: 0.6250
2024-07-11 16:56:13,841 [INFO    ] __main__: train step 13038: loss: 1.0046, policy_loss: 0.9714, value_loss: 0.6250
2024-07-11 16:56:15,279 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:56:15,702 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:56:15,764 [INFO    ] __main__: train step 13039: loss: 1.0046, policy_loss: 0.9714, value_loss: 0.6249
2024-07-11 16:56:15,936 [INFO    ] __main__: train step 13040: loss: 1.0046, policy_loss: 0.9714, value_loss: 0.6249
2024-07-11 16:56:16,143 [INFO    ] __main__: train step 13041: loss: 1.0045, policy_loss: 0.9714, value_loss: 0.6249
2024-07-11 16:56:16,360 [INFO    ] __main__: train step 13042: loss: 1.0045, policy_loss: 0.9714, value_loss: 0.6249
2024-07-11 16:56:16,559 [INFO    ] __main__: train step 13043: loss: 1.0045, policy_loss: 0.9713, value_loss: 0.6248
2024-07-11 16:56:16,760 [INFO    ] __main__: train step 13044: loss: 1.0045, policy_loss: 0.9713, value_loss: 0.6248
2024-07-11 16:56:16,962 [INFO    ] __main__: train step 13045: loss: 1.0045, policy_loss: 0.9713, value_loss: 0.6248
2024-07-11 16:56:17,178 [INFO    ] __main__: train step 13046: loss: 1.0045, policy_loss: 0.9713, value_loss: 0.6247
2024-07-11 16:56:17,387 [INFO    ] __main__: train step 13047: loss: 1.0045, policy_loss: 0.9712, value_loss: 0.6247
2024-07-11 16:56:17,623 [INFO    ] __main__: train step 13048: loss: 1.0045, policy_loss: 0.9712, value_loss: 0.6247
2024-07-11 16:56:17,821 [INFO    ] __main__: train step 13049: loss: 1.0045, policy_loss: 0.9712, value_loss: 0.6246
2024-07-11 16:56:18,030 [INFO    ] __main__: train step 13050: loss: 1.0045, policy_loss: 0.9712, value_loss: 0.6246
2024-07-11 16:56:18,236 [INFO    ] __main__: train step 13051: loss: 1.0045, policy_loss: 0.9711, value_loss: 0.6246
2024-07-11 16:56:18,434 [INFO    ] __main__: train step 13052: loss: 1.0045, policy_loss: 0.9711, value_loss: 0.6246
2024-07-11 16:56:18,636 [INFO    ] __main__: train step 13053: loss: 1.0045, policy_loss: 0.9711, value_loss: 0.6245
2024-07-11 16:56:18,834 [INFO    ] __main__: train step 13054: loss: 1.0045, policy_loss: 0.9711, value_loss: 0.6245
2024-07-11 16:56:19,042 [INFO    ] __main__: train step 13055: loss: 1.0044, policy_loss: 0.9711, value_loss: 0.6245
2024-07-11 16:56:20,482 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:56:20,884 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:56:20,939 [INFO    ] __main__: train step 13056: loss: 1.0044, policy_loss: 0.9710, value_loss: 0.6244
2024-07-11 16:56:21,133 [INFO    ] __main__: train step 13057: loss: 1.0044, policy_loss: 0.9710, value_loss: 0.6244
2024-07-11 16:56:21,363 [INFO    ] __main__: train step 13058: loss: 1.0044, policy_loss: 0.9710, value_loss: 0.6244
2024-07-11 16:56:21,567 [INFO    ] __main__: train step 13059: loss: 1.0044, policy_loss: 0.9710, value_loss: 0.6244
2024-07-11 16:56:21,775 [INFO    ] __main__: train step 13060: loss: 1.0044, policy_loss: 0.9709, value_loss: 0.6243
2024-07-11 16:56:21,980 [INFO    ] __main__: train step 13061: loss: 1.0044, policy_loss: 0.9709, value_loss: 0.6243
2024-07-11 16:56:22,183 [INFO    ] __main__: train step 13062: loss: 1.0044, policy_loss: 0.9709, value_loss: 0.6243
2024-07-11 16:56:22,387 [INFO    ] __main__: train step 13063: loss: 1.0044, policy_loss: 0.9709, value_loss: 0.6242
2024-07-11 16:56:22,587 [INFO    ] __main__: train step 13064: loss: 1.0044, policy_loss: 0.9709, value_loss: 0.6242
2024-07-11 16:56:22,793 [INFO    ] __main__: train step 13065: loss: 1.0044, policy_loss: 0.9708, value_loss: 0.6242
2024-07-11 16:56:22,993 [INFO    ] __main__: train step 13066: loss: 1.0044, policy_loss: 0.9708, value_loss: 0.6242
2024-07-11 16:56:23,208 [INFO    ] __main__: train step 13067: loss: 1.0044, policy_loss: 0.9708, value_loss: 0.6241
2024-07-11 16:56:23,435 [INFO    ] __main__: train step 13068: loss: 1.0044, policy_loss: 0.9708, value_loss: 0.6241
2024-07-11 16:56:23,638 [INFO    ] __main__: train step 13069: loss: 1.0044, policy_loss: 0.9707, value_loss: 0.6241
2024-07-11 16:56:23,842 [INFO    ] __main__: train step 13070: loss: 1.0044, policy_loss: 0.9707, value_loss: 0.6240
2024-07-11 16:56:24,035 [INFO    ] __main__: train step 13071: loss: 1.0043, policy_loss: 0.9707, value_loss: 0.6240
2024-07-11 16:56:24,239 [INFO    ] __main__: train step 13072: loss: 1.0043, policy_loss: 0.9707, value_loss: 0.6240
2024-07-11 16:56:25,648 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:56:26,044 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:56:26,101 [INFO    ] __main__: train step 13073: loss: 1.0043, policy_loss: 0.9706, value_loss: 0.6240
2024-07-11 16:56:26,305 [INFO    ] __main__: train step 13074: loss: 1.0043, policy_loss: 0.9706, value_loss: 0.6239
2024-07-11 16:56:26,537 [INFO    ] __main__: train step 13075: loss: 1.0043, policy_loss: 0.9706, value_loss: 0.6239
2024-07-11 16:56:26,747 [INFO    ] __main__: train step 13076: loss: 1.0043, policy_loss: 0.9706, value_loss: 0.6239
2024-07-11 16:56:26,964 [INFO    ] __main__: train step 13077: loss: 1.0043, policy_loss: 0.9706, value_loss: 0.6238
2024-07-11 16:56:27,181 [INFO    ] __main__: train step 13078: loss: 1.0043, policy_loss: 0.9705, value_loss: 0.6238
2024-07-11 16:56:27,370 [INFO    ] __main__: train step 13079: loss: 1.0043, policy_loss: 0.9705, value_loss: 0.6238
2024-07-11 16:56:27,564 [INFO    ] __main__: train step 13080: loss: 1.0043, policy_loss: 0.9705, value_loss: 0.6238
2024-07-11 16:56:27,757 [INFO    ] __main__: train step 13081: loss: 1.0043, policy_loss: 0.9705, value_loss: 0.6237
2024-07-11 16:56:27,979 [INFO    ] __main__: train step 13082: loss: 1.0043, policy_loss: 0.9704, value_loss: 0.6237
2024-07-11 16:56:28,175 [INFO    ] __main__: train step 13083: loss: 1.0043, policy_loss: 0.9704, value_loss: 0.6237
2024-07-11 16:56:28,368 [INFO    ] __main__: train step 13084: loss: 1.0043, policy_loss: 0.9704, value_loss: 0.6236
2024-07-11 16:56:28,608 [INFO    ] __main__: train step 13085: loss: 1.0043, policy_loss: 0.9704, value_loss: 0.6236
2024-07-11 16:56:28,810 [INFO    ] __main__: train step 13086: loss: 1.0043, policy_loss: 0.9704, value_loss: 0.6236
2024-07-11 16:56:29,002 [INFO    ] __main__: train step 13087: loss: 1.0043, policy_loss: 0.9703, value_loss: 0.6235
2024-07-11 16:56:29,239 [INFO    ] __main__: train step 13088: loss: 1.0042, policy_loss: 0.9703, value_loss: 0.6235
2024-07-11 16:56:29,465 [INFO    ] __main__: train step 13089: loss: 1.0042, policy_loss: 0.9703, value_loss: 0.6235
2024-07-11 16:56:30,902 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:56:31,334 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:56:31,396 [INFO    ] __main__: train step 13090: loss: 1.0042, policy_loss: 0.9703, value_loss: 0.6235
2024-07-11 16:56:31,565 [INFO    ] __main__: train step 13091: loss: 1.0042, policy_loss: 0.9702, value_loss: 0.6234
2024-07-11 16:56:31,770 [INFO    ] __main__: train step 13092: loss: 1.0042, policy_loss: 0.9702, value_loss: 0.6234
2024-07-11 16:56:31,971 [INFO    ] __main__: train step 13093: loss: 1.0042, policy_loss: 0.9702, value_loss: 0.6234
2024-07-11 16:56:32,172 [INFO    ] __main__: train step 13094: loss: 1.0042, policy_loss: 0.9702, value_loss: 0.6233
2024-07-11 16:56:32,383 [INFO    ] __main__: train step 13095: loss: 1.0042, policy_loss: 0.9702, value_loss: 0.6233
2024-07-11 16:56:32,584 [INFO    ] __main__: train step 13096: loss: 1.0042, policy_loss: 0.9701, value_loss: 0.6233
2024-07-11 16:56:32,795 [INFO    ] __main__: train step 13097: loss: 1.0042, policy_loss: 0.9701, value_loss: 0.6233
2024-07-11 16:56:33,029 [INFO    ] __main__: train step 13098: loss: 1.0042, policy_loss: 0.9701, value_loss: 0.6232
2024-07-11 16:56:34,548 [INFO    ] __main__: train step 13099: loss: 1.0042, policy_loss: 0.9701, value_loss: 0.6232
2024-07-11 16:56:34,749 [INFO    ] __main__: train step 13100: loss: 1.0042, policy_loss: 0.9700, value_loss: 0.6232
2024-07-11 16:56:34,955 [INFO    ] __main__: train step 13101: loss: 1.0042, policy_loss: 0.9700, value_loss: 0.6231
2024-07-11 16:56:35,165 [INFO    ] __main__: train step 13102: loss: 1.0042, policy_loss: 0.9700, value_loss: 0.6231
2024-07-11 16:56:35,370 [INFO    ] __main__: train step 13103: loss: 1.0041, policy_loss: 0.9700, value_loss: 0.6231
2024-07-11 16:56:35,583 [INFO    ] __main__: train step 13104: loss: 1.0041, policy_loss: 0.9700, value_loss: 0.6231
2024-07-11 16:56:35,786 [INFO    ] __main__: train step 13105: loss: 1.0041, policy_loss: 0.9699, value_loss: 0.6230
2024-07-11 16:56:35,984 [INFO    ] __main__: train step 13106: loss: 1.0041, policy_loss: 0.9699, value_loss: 0.6230
2024-07-11 16:56:37,433 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:56:37,836 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:56:37,891 [INFO    ] __main__: train step 13107: loss: 1.0041, policy_loss: 0.9699, value_loss: 0.6230
2024-07-11 16:56:38,070 [INFO    ] __main__: train step 13108: loss: 1.0041, policy_loss: 0.9699, value_loss: 0.6229
2024-07-11 16:56:38,316 [INFO    ] __main__: train step 13109: loss: 1.0041, policy_loss: 0.9698, value_loss: 0.6229
2024-07-11 16:56:38,554 [INFO    ] __main__: train step 13110: loss: 1.0041, policy_loss: 0.9698, value_loss: 0.6229
2024-07-11 16:56:38,785 [INFO    ] __main__: train step 13111: loss: 1.0041, policy_loss: 0.9698, value_loss: 0.6229
2024-07-11 16:56:38,986 [INFO    ] __main__: train step 13112: loss: 1.0041, policy_loss: 0.9698, value_loss: 0.6228
2024-07-11 16:56:39,194 [INFO    ] __main__: train step 13113: loss: 1.0041, policy_loss: 0.9697, value_loss: 0.6228
2024-07-11 16:56:39,401 [INFO    ] __main__: train step 13114: loss: 1.0041, policy_loss: 0.9697, value_loss: 0.6228
2024-07-11 16:56:39,597 [INFO    ] __main__: train step 13115: loss: 1.0041, policy_loss: 0.9697, value_loss: 0.6227
2024-07-11 16:56:39,801 [INFO    ] __main__: train step 13116: loss: 1.0041, policy_loss: 0.9697, value_loss: 0.6227
2024-07-11 16:56:39,999 [INFO    ] __main__: train step 13117: loss: 1.0041, policy_loss: 0.9697, value_loss: 0.6227
2024-07-11 16:56:40,217 [INFO    ] __main__: train step 13118: loss: 1.0040, policy_loss: 0.9696, value_loss: 0.6226
2024-07-11 16:56:40,408 [INFO    ] __main__: train step 13119: loss: 1.0040, policy_loss: 0.9696, value_loss: 0.6226
2024-07-11 16:56:40,615 [INFO    ] __main__: train step 13120: loss: 1.0040, policy_loss: 0.9696, value_loss: 0.6226
2024-07-11 16:56:40,816 [INFO    ] __main__: train step 13121: loss: 1.0040, policy_loss: 0.9696, value_loss: 0.6226
2024-07-11 16:56:41,017 [INFO    ] __main__: train step 13122: loss: 1.0040, policy_loss: 0.9695, value_loss: 0.6225
2024-07-11 16:56:41,228 [INFO    ] __main__: train step 13123: loss: 1.0040, policy_loss: 0.9695, value_loss: 0.6225
2024-07-11 16:56:42,693 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:56:43,111 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:56:43,167 [INFO    ] __main__: train step 13124: loss: 1.0040, policy_loss: 0.9695, value_loss: 0.6225
2024-07-11 16:56:43,338 [INFO    ] __main__: train step 13125: loss: 1.0040, policy_loss: 0.9695, value_loss: 0.6224
2024-07-11 16:56:43,550 [INFO    ] __main__: train step 13126: loss: 1.0040, policy_loss: 0.9695, value_loss: 0.6224
2024-07-11 16:56:43,751 [INFO    ] __main__: train step 13127: loss: 1.0040, policy_loss: 0.9694, value_loss: 0.6224
2024-07-11 16:56:43,961 [INFO    ] __main__: train step 13128: loss: 1.0040, policy_loss: 0.9694, value_loss: 0.6224
2024-07-11 16:56:44,183 [INFO    ] __main__: train step 13129: loss: 1.0040, policy_loss: 0.9694, value_loss: 0.6223
2024-07-11 16:56:44,379 [INFO    ] __main__: train step 13130: loss: 1.0040, policy_loss: 0.9694, value_loss: 0.6223
2024-07-11 16:56:44,586 [INFO    ] __main__: train step 13131: loss: 1.0040, policy_loss: 0.9693, value_loss: 0.6223
2024-07-11 16:56:44,800 [INFO    ] __main__: train step 13132: loss: 1.0040, policy_loss: 0.9693, value_loss: 0.6222
2024-07-11 16:56:44,996 [INFO    ] __main__: train step 13133: loss: 1.0039, policy_loss: 0.9693, value_loss: 0.6222
2024-07-11 16:56:45,206 [INFO    ] __main__: train step 13134: loss: 1.0039, policy_loss: 0.9693, value_loss: 0.6222
2024-07-11 16:56:45,415 [INFO    ] __main__: train step 13135: loss: 1.0039, policy_loss: 0.9693, value_loss: 0.6222
2024-07-11 16:56:45,620 [INFO    ] __main__: train step 13136: loss: 1.0039, policy_loss: 0.9692, value_loss: 0.6221
2024-07-11 16:56:45,829 [INFO    ] __main__: train step 13137: loss: 1.0039, policy_loss: 0.9692, value_loss: 0.6221
2024-07-11 16:56:46,052 [INFO    ] __main__: train step 13138: loss: 1.0039, policy_loss: 0.9692, value_loss: 0.6221
2024-07-11 16:56:46,259 [INFO    ] __main__: train step 13139: loss: 1.0039, policy_loss: 0.9692, value_loss: 0.6220
2024-07-11 16:56:46,456 [INFO    ] __main__: train step 13140: loss: 1.0039, policy_loss: 0.9691, value_loss: 0.6220
2024-07-11 16:56:47,901 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:56:48,320 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:56:48,374 [INFO    ] __main__: train step 13141: loss: 1.0039, policy_loss: 0.9691, value_loss: 0.6220
2024-07-11 16:56:48,545 [INFO    ] __main__: train step 13142: loss: 1.0039, policy_loss: 0.9691, value_loss: 0.6220
2024-07-11 16:56:48,745 [INFO    ] __main__: train step 13143: loss: 1.0039, policy_loss: 0.9691, value_loss: 0.6219
2024-07-11 16:56:48,950 [INFO    ] __main__: train step 13144: loss: 1.0039, policy_loss: 0.9691, value_loss: 0.6219
2024-07-11 16:56:49,146 [INFO    ] __main__: train step 13145: loss: 1.0039, policy_loss: 0.9690, value_loss: 0.6219
2024-07-11 16:56:49,346 [INFO    ] __main__: train step 13146: loss: 1.0039, policy_loss: 0.9690, value_loss: 0.6218
2024-07-11 16:56:49,542 [INFO    ] __main__: train step 13147: loss: 1.0039, policy_loss: 0.9690, value_loss: 0.6218
2024-07-11 16:56:49,749 [INFO    ] __main__: train step 13148: loss: 1.0039, policy_loss: 0.9690, value_loss: 0.6218
2024-07-11 16:56:49,951 [INFO    ] __main__: train step 13149: loss: 1.0038, policy_loss: 0.9689, value_loss: 0.6218
2024-07-11 16:56:50,158 [INFO    ] __main__: train step 13150: loss: 1.0038, policy_loss: 0.9689, value_loss: 0.6217
2024-07-11 16:56:50,361 [INFO    ] __main__: train step 13151: loss: 1.0038, policy_loss: 0.9689, value_loss: 0.6217
2024-07-11 16:56:50,576 [INFO    ] __main__: train step 13152: loss: 1.0038, policy_loss: 0.9689, value_loss: 0.6217
2024-07-11 16:56:50,777 [INFO    ] __main__: train step 13153: loss: 1.0038, policy_loss: 0.9688, value_loss: 0.6216
2024-07-11 16:56:50,991 [INFO    ] __main__: train step 13154: loss: 1.0038, policy_loss: 0.9688, value_loss: 0.6216
2024-07-11 16:56:51,186 [INFO    ] __main__: train step 13155: loss: 1.0038, policy_loss: 0.9688, value_loss: 0.6216
2024-07-11 16:56:51,393 [INFO    ] __main__: train step 13156: loss: 1.0038, policy_loss: 0.9688, value_loss: 0.6216
2024-07-11 16:56:51,609 [INFO    ] __main__: train step 13157: loss: 1.0038, policy_loss: 0.9688, value_loss: 0.6215
2024-07-11 16:56:53,072 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:56:53,460 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:56:53,515 [INFO    ] __main__: train step 13158: loss: 1.0038, policy_loss: 0.9687, value_loss: 0.6215
2024-07-11 16:56:53,690 [INFO    ] __main__: train step 13159: loss: 1.0038, policy_loss: 0.9687, value_loss: 0.6215
2024-07-11 16:56:53,902 [INFO    ] __main__: train step 13160: loss: 1.0038, policy_loss: 0.9687, value_loss: 0.6214
2024-07-11 16:56:54,107 [INFO    ] __main__: train step 13161: loss: 1.0038, policy_loss: 0.9687, value_loss: 0.6214
2024-07-11 16:56:54,317 [INFO    ] __main__: train step 13162: loss: 1.0038, policy_loss: 0.9686, value_loss: 0.6214
2024-07-11 16:56:54,510 [INFO    ] __main__: train step 13163: loss: 1.0038, policy_loss: 0.9686, value_loss: 0.6214
2024-07-11 16:56:54,708 [INFO    ] __main__: train step 13164: loss: 1.0037, policy_loss: 0.9686, value_loss: 0.6213
2024-07-11 16:56:54,907 [INFO    ] __main__: train step 13165: loss: 1.0037, policy_loss: 0.9686, value_loss: 0.6213
2024-07-11 16:56:55,122 [INFO    ] __main__: train step 13166: loss: 1.0037, policy_loss: 0.9686, value_loss: 0.6213
2024-07-11 16:56:55,312 [INFO    ] __main__: train step 13167: loss: 1.0037, policy_loss: 0.9685, value_loss: 0.6212
2024-07-11 16:56:55,516 [INFO    ] __main__: train step 13168: loss: 1.0037, policy_loss: 0.9685, value_loss: 0.6212
2024-07-11 16:56:55,725 [INFO    ] __main__: train step 13169: loss: 1.0037, policy_loss: 0.9685, value_loss: 0.6212
2024-07-11 16:56:55,922 [INFO    ] __main__: train step 13170: loss: 1.0037, policy_loss: 0.9685, value_loss: 0.6212
2024-07-11 16:56:56,123 [INFO    ] __main__: train step 13171: loss: 1.0037, policy_loss: 0.9684, value_loss: 0.6211
2024-07-11 16:56:56,343 [INFO    ] __main__: train step 13172: loss: 1.0037, policy_loss: 0.9684, value_loss: 0.6211
2024-07-11 16:56:56,575 [INFO    ] __main__: train step 13173: loss: 1.0037, policy_loss: 0.9684, value_loss: 0.6211
2024-07-11 16:56:56,777 [INFO    ] __main__: train step 13174: loss: 1.0037, policy_loss: 0.9684, value_loss: 0.6210
2024-07-11 16:56:58,205 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:56:58,622 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:56:58,684 [INFO    ] __main__: train step 13175: loss: 1.0037, policy_loss: 0.9684, value_loss: 0.6210
2024-07-11 16:56:58,859 [INFO    ] __main__: train step 13176: loss: 1.0037, policy_loss: 0.9683, value_loss: 0.6210
2024-07-11 16:56:59,053 [INFO    ] __main__: train step 13177: loss: 1.0037, policy_loss: 0.9683, value_loss: 0.6210
2024-07-11 16:56:59,256 [INFO    ] __main__: train step 13178: loss: 1.0037, policy_loss: 0.9683, value_loss: 0.6209
2024-07-11 16:56:59,476 [INFO    ] __main__: train step 13179: loss: 1.0036, policy_loss: 0.9683, value_loss: 0.6209
2024-07-11 16:56:59,707 [INFO    ] __main__: train step 13180: loss: 1.0036, policy_loss: 0.9682, value_loss: 0.6209
2024-07-11 16:56:59,910 [INFO    ] __main__: train step 13181: loss: 1.0036, policy_loss: 0.9682, value_loss: 0.6208
2024-07-11 16:57:00,133 [INFO    ] __main__: train step 13182: loss: 1.0036, policy_loss: 0.9682, value_loss: 0.6208
2024-07-11 16:57:00,363 [INFO    ] __main__: train step 13183: loss: 1.0036, policy_loss: 0.9682, value_loss: 0.6208
2024-07-11 16:57:00,559 [INFO    ] __main__: train step 13184: loss: 1.0036, policy_loss: 0.9682, value_loss: 0.6208
2024-07-11 16:57:00,761 [INFO    ] __main__: train step 13185: loss: 1.0036, policy_loss: 0.9681, value_loss: 0.6207
2024-07-11 16:57:00,972 [INFO    ] __main__: train step 13186: loss: 1.0036, policy_loss: 0.9681, value_loss: 0.6207
2024-07-11 16:57:01,178 [INFO    ] __main__: train step 13187: loss: 1.0036, policy_loss: 0.9681, value_loss: 0.6207
2024-07-11 16:57:01,378 [INFO    ] __main__: train step 13188: loss: 1.0036, policy_loss: 0.9681, value_loss: 0.6206
2024-07-11 16:57:01,583 [INFO    ] __main__: train step 13189: loss: 1.0036, policy_loss: 0.9680, value_loss: 0.6206
2024-07-11 16:57:01,786 [INFO    ] __main__: train step 13190: loss: 1.0036, policy_loss: 0.9680, value_loss: 0.6206
2024-07-11 16:57:01,999 [INFO    ] __main__: train step 13191: loss: 1.0036, policy_loss: 0.9680, value_loss: 0.6206
2024-07-11 16:57:03,438 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:57:03,835 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:57:03,902 [INFO    ] __main__: train step 13192: loss: 1.0036, policy_loss: 0.9680, value_loss: 0.6205
2024-07-11 16:57:04,073 [INFO    ] __main__: train step 13193: loss: 1.0036, policy_loss: 0.9680, value_loss: 0.6205
2024-07-11 16:57:04,273 [INFO    ] __main__: train step 13194: loss: 1.0036, policy_loss: 0.9679, value_loss: 0.6205
2024-07-11 16:57:04,486 [INFO    ] __main__: train step 13195: loss: 1.0035, policy_loss: 0.9679, value_loss: 0.6204
2024-07-11 16:57:04,690 [INFO    ] __main__: train step 13196: loss: 1.0035, policy_loss: 0.9679, value_loss: 0.6204
2024-07-11 16:57:04,896 [INFO    ] __main__: train step 13197: loss: 1.0035, policy_loss: 0.9679, value_loss: 0.6204
2024-07-11 16:57:05,096 [INFO    ] __main__: train step 13198: loss: 1.0035, policy_loss: 0.9678, value_loss: 0.6204
2024-07-11 16:57:06,712 [INFO    ] __main__: train step 13199: loss: 1.0035, policy_loss: 0.9678, value_loss: 0.6203
2024-07-11 16:57:06,924 [INFO    ] __main__: train step 13200: loss: 1.0035, policy_loss: 0.9678, value_loss: 0.6203
2024-07-11 16:57:07,134 [INFO    ] __main__: train step 13201: loss: 1.0035, policy_loss: 0.9678, value_loss: 0.6203
2024-07-11 16:57:07,339 [INFO    ] __main__: train step 13202: loss: 1.0035, policy_loss: 0.9678, value_loss: 0.6202
2024-07-11 16:57:07,548 [INFO    ] __main__: train step 13203: loss: 1.0035, policy_loss: 0.9677, value_loss: 0.6202
2024-07-11 16:57:07,755 [INFO    ] __main__: train step 13204: loss: 1.0035, policy_loss: 0.9677, value_loss: 0.6202
2024-07-11 16:57:07,964 [INFO    ] __main__: train step 13205: loss: 1.0035, policy_loss: 0.9677, value_loss: 0.6202
2024-07-11 16:57:08,183 [INFO    ] __main__: train step 13206: loss: 1.0035, policy_loss: 0.9677, value_loss: 0.6201
2024-07-11 16:57:08,398 [INFO    ] __main__: train step 13207: loss: 1.0035, policy_loss: 0.9676, value_loss: 0.6201
2024-07-11 16:57:08,608 [INFO    ] __main__: train step 13208: loss: 1.0035, policy_loss: 0.9676, value_loss: 0.6201
2024-07-11 16:57:10,060 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:57:10,431 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:57:10,484 [INFO    ] __main__: train step 13209: loss: 1.0035, policy_loss: 0.9676, value_loss: 0.6200
2024-07-11 16:57:10,660 [INFO    ] __main__: train step 13210: loss: 1.0034, policy_loss: 0.9676, value_loss: 0.6200
2024-07-11 16:57:10,885 [INFO    ] __main__: train step 13211: loss: 1.0034, policy_loss: 0.9676, value_loss: 0.6200
2024-07-11 16:57:11,086 [INFO    ] __main__: train step 13212: loss: 1.0034, policy_loss: 0.9675, value_loss: 0.6200
2024-07-11 16:57:11,309 [INFO    ] __main__: train step 13213: loss: 1.0034, policy_loss: 0.9675, value_loss: 0.6199
2024-07-11 16:57:11,526 [INFO    ] __main__: train step 13214: loss: 1.0034, policy_loss: 0.9675, value_loss: 0.6199
2024-07-11 16:57:11,765 [INFO    ] __main__: train step 13215: loss: 1.0034, policy_loss: 0.9675, value_loss: 0.6199
2024-07-11 16:57:11,976 [INFO    ] __main__: train step 13216: loss: 1.0034, policy_loss: 0.9674, value_loss: 0.6198
2024-07-11 16:57:12,213 [INFO    ] __main__: train step 13217: loss: 1.0034, policy_loss: 0.9674, value_loss: 0.6198
2024-07-11 16:57:12,413 [INFO    ] __main__: train step 13218: loss: 1.0034, policy_loss: 0.9674, value_loss: 0.6198
2024-07-11 16:57:12,632 [INFO    ] __main__: train step 13219: loss: 1.0034, policy_loss: 0.9674, value_loss: 0.6198
2024-07-11 16:57:12,830 [INFO    ] __main__: train step 13220: loss: 1.0034, policy_loss: 0.9674, value_loss: 0.6197
2024-07-11 16:57:13,039 [INFO    ] __main__: train step 13221: loss: 1.0034, policy_loss: 0.9673, value_loss: 0.6197
2024-07-11 16:57:13,242 [INFO    ] __main__: train step 13222: loss: 1.0034, policy_loss: 0.9673, value_loss: 0.6197
2024-07-11 16:57:13,442 [INFO    ] __main__: train step 13223: loss: 1.0034, policy_loss: 0.9673, value_loss: 0.6196
2024-07-11 16:57:13,645 [INFO    ] __main__: train step 13224: loss: 1.0034, policy_loss: 0.9673, value_loss: 0.6196
2024-07-11 16:57:13,852 [INFO    ] __main__: train step 13225: loss: 1.0033, policy_loss: 0.9672, value_loss: 0.6196
2024-07-11 16:57:15,281 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:57:15,641 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:57:15,698 [INFO    ] __main__: train step 13226: loss: 1.0033, policy_loss: 0.9672, value_loss: 0.6196
2024-07-11 16:57:15,876 [INFO    ] __main__: train step 13227: loss: 1.0033, policy_loss: 0.9672, value_loss: 0.6195
2024-07-11 16:57:16,086 [INFO    ] __main__: train step 13228: loss: 1.0033, policy_loss: 0.9672, value_loss: 0.6195
2024-07-11 16:57:16,285 [INFO    ] __main__: train step 13229: loss: 1.0033, policy_loss: 0.9672, value_loss: 0.6195
2024-07-11 16:57:16,491 [INFO    ] __main__: train step 13230: loss: 1.0033, policy_loss: 0.9671, value_loss: 0.6194
2024-07-11 16:57:16,749 [INFO    ] __main__: train step 13231: loss: 1.0033, policy_loss: 0.9671, value_loss: 0.6194
2024-07-11 16:57:16,962 [INFO    ] __main__: train step 13232: loss: 1.0033, policy_loss: 0.9671, value_loss: 0.6194
2024-07-11 16:57:17,213 [INFO    ] __main__: train step 13233: loss: 1.0033, policy_loss: 0.9671, value_loss: 0.6194
2024-07-11 16:57:17,431 [INFO    ] __main__: train step 13234: loss: 1.0033, policy_loss: 0.9670, value_loss: 0.6193
2024-07-11 16:57:17,666 [INFO    ] __main__: train step 13235: loss: 1.0033, policy_loss: 0.9670, value_loss: 0.6193
2024-07-11 16:57:17,872 [INFO    ] __main__: train step 13236: loss: 1.0033, policy_loss: 0.9670, value_loss: 0.6193
2024-07-11 16:57:18,110 [INFO    ] __main__: train step 13237: loss: 1.0033, policy_loss: 0.9670, value_loss: 0.6192
2024-07-11 16:57:18,338 [INFO    ] __main__: train step 13238: loss: 1.0033, policy_loss: 0.9670, value_loss: 0.6192
2024-07-11 16:57:18,573 [INFO    ] __main__: train step 13239: loss: 1.0032, policy_loss: 0.9669, value_loss: 0.6192
2024-07-11 16:57:18,816 [INFO    ] __main__: train step 13240: loss: 1.0032, policy_loss: 0.9669, value_loss: 0.6191
2024-07-11 16:57:19,058 [INFO    ] __main__: train step 13241: loss: 1.0032, policy_loss: 0.9669, value_loss: 0.6191
2024-07-11 16:57:19,283 [INFO    ] __main__: train step 13242: loss: 1.0032, policy_loss: 0.9669, value_loss: 0.6191
2024-07-11 16:57:20,726 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:57:21,150 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:57:21,212 [INFO    ] __main__: train step 13243: loss: 1.0032, policy_loss: 0.9668, value_loss: 0.6191
2024-07-11 16:57:21,395 [INFO    ] __main__: train step 13244: loss: 1.0032, policy_loss: 0.9668, value_loss: 0.6190
2024-07-11 16:57:21,636 [INFO    ] __main__: train step 13245: loss: 1.0032, policy_loss: 0.9668, value_loss: 0.6190
2024-07-11 16:57:21,833 [INFO    ] __main__: train step 13246: loss: 1.0032, policy_loss: 0.9668, value_loss: 0.6190
2024-07-11 16:57:22,034 [INFO    ] __main__: train step 13247: loss: 1.0032, policy_loss: 0.9668, value_loss: 0.6189
2024-07-11 16:57:22,236 [INFO    ] __main__: train step 13248: loss: 1.0032, policy_loss: 0.9667, value_loss: 0.6189
2024-07-11 16:57:22,434 [INFO    ] __main__: train step 13249: loss: 1.0032, policy_loss: 0.9667, value_loss: 0.6189
2024-07-11 16:57:22,647 [INFO    ] __main__: train step 13250: loss: 1.0032, policy_loss: 0.9667, value_loss: 0.6189
2024-07-11 16:57:22,876 [INFO    ] __main__: train step 13251: loss: 1.0032, policy_loss: 0.9667, value_loss: 0.6188
2024-07-11 16:57:23,075 [INFO    ] __main__: train step 13252: loss: 1.0032, policy_loss: 0.9666, value_loss: 0.6188
2024-07-11 16:57:23,288 [INFO    ] __main__: train step 13253: loss: 1.0031, policy_loss: 0.9666, value_loss: 0.6188
2024-07-11 16:57:23,500 [INFO    ] __main__: train step 13254: loss: 1.0031, policy_loss: 0.9666, value_loss: 0.6187
2024-07-11 16:57:23,735 [INFO    ] __main__: train step 13255: loss: 1.0031, policy_loss: 0.9666, value_loss: 0.6187
2024-07-11 16:57:23,950 [INFO    ] __main__: train step 13256: loss: 1.0031, policy_loss: 0.9666, value_loss: 0.6187
2024-07-11 16:57:24,184 [INFO    ] __main__: train step 13257: loss: 1.0031, policy_loss: 0.9665, value_loss: 0.6187
2024-07-11 16:57:24,402 [INFO    ] __main__: train step 13258: loss: 1.0031, policy_loss: 0.9665, value_loss: 0.6186
2024-07-11 16:57:24,608 [INFO    ] __main__: train step 13259: loss: 1.0031, policy_loss: 0.9665, value_loss: 0.6186
2024-07-11 16:57:26,085 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:57:26,477 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:57:26,534 [INFO    ] __main__: train step 13260: loss: 1.0031, policy_loss: 0.9665, value_loss: 0.6186
2024-07-11 16:57:26,707 [INFO    ] __main__: train step 13261: loss: 1.0031, policy_loss: 0.9664, value_loss: 0.6185
2024-07-11 16:57:26,920 [INFO    ] __main__: train step 13262: loss: 1.0031, policy_loss: 0.9664, value_loss: 0.6185
2024-07-11 16:57:27,125 [INFO    ] __main__: train step 13263: loss: 1.0031, policy_loss: 0.9664, value_loss: 0.6185
2024-07-11 16:57:27,328 [INFO    ] __main__: train step 13264: loss: 1.0031, policy_loss: 0.9664, value_loss: 0.6185
2024-07-11 16:57:27,538 [INFO    ] __main__: train step 13265: loss: 1.0031, policy_loss: 0.9664, value_loss: 0.6184
2024-07-11 16:57:27,744 [INFO    ] __main__: train step 13266: loss: 1.0031, policy_loss: 0.9663, value_loss: 0.6184
2024-07-11 16:57:27,949 [INFO    ] __main__: train step 13267: loss: 1.0030, policy_loss: 0.9663, value_loss: 0.6184
2024-07-11 16:57:28,156 [INFO    ] __main__: train step 13268: loss: 1.0030, policy_loss: 0.9663, value_loss: 0.6183
2024-07-11 16:57:28,359 [INFO    ] __main__: train step 13269: loss: 1.0030, policy_loss: 0.9663, value_loss: 0.6183
2024-07-11 16:57:28,563 [INFO    ] __main__: train step 13270: loss: 1.0030, policy_loss: 0.9662, value_loss: 0.6183
2024-07-11 16:57:28,766 [INFO    ] __main__: train step 13271: loss: 1.0030, policy_loss: 0.9662, value_loss: 0.6183
2024-07-11 16:57:28,968 [INFO    ] __main__: train step 13272: loss: 1.0030, policy_loss: 0.9662, value_loss: 0.6182
2024-07-11 16:57:29,186 [INFO    ] __main__: train step 13273: loss: 1.0030, policy_loss: 0.9662, value_loss: 0.6182
2024-07-11 16:57:29,389 [INFO    ] __main__: train step 13274: loss: 1.0030, policy_loss: 0.9662, value_loss: 0.6182
2024-07-11 16:57:29,613 [INFO    ] __main__: train step 13275: loss: 1.0030, policy_loss: 0.9661, value_loss: 0.6181
2024-07-11 16:57:29,823 [INFO    ] __main__: train step 13276: loss: 1.0030, policy_loss: 0.9661, value_loss: 0.6181
2024-07-11 16:57:31,259 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:57:31,649 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:57:31,705 [INFO    ] __main__: train step 13277: loss: 1.0030, policy_loss: 0.9661, value_loss: 0.6181
2024-07-11 16:57:31,884 [INFO    ] __main__: train step 13278: loss: 1.0030, policy_loss: 0.9661, value_loss: 0.6181
2024-07-11 16:57:32,123 [INFO    ] __main__: train step 13279: loss: 1.0030, policy_loss: 0.9660, value_loss: 0.6180
2024-07-11 16:57:32,327 [INFO    ] __main__: train step 13280: loss: 1.0030, policy_loss: 0.9660, value_loss: 0.6180
2024-07-11 16:57:32,567 [INFO    ] __main__: train step 13281: loss: 1.0029, policy_loss: 0.9660, value_loss: 0.6180
2024-07-11 16:57:32,811 [INFO    ] __main__: train step 13282: loss: 1.0029, policy_loss: 0.9660, value_loss: 0.6179
2024-07-11 16:57:33,038 [INFO    ] __main__: train step 13283: loss: 1.0029, policy_loss: 0.9660, value_loss: 0.6179
2024-07-11 16:57:33,250 [INFO    ] __main__: train step 13284: loss: 1.0029, policy_loss: 0.9659, value_loss: 0.6179
2024-07-11 16:57:33,473 [INFO    ] __main__: train step 13285: loss: 1.0029, policy_loss: 0.9659, value_loss: 0.6178
2024-07-11 16:57:33,684 [INFO    ] __main__: train step 13286: loss: 1.0029, policy_loss: 0.9659, value_loss: 0.6178
2024-07-11 16:57:33,890 [INFO    ] __main__: train step 13287: loss: 1.0029, policy_loss: 0.9659, value_loss: 0.6178
2024-07-11 16:57:34,113 [INFO    ] __main__: train step 13288: loss: 1.0029, policy_loss: 0.9659, value_loss: 0.6178
2024-07-11 16:57:34,328 [INFO    ] __main__: train step 13289: loss: 1.0029, policy_loss: 0.9658, value_loss: 0.6177
2024-07-11 16:57:34,547 [INFO    ] __main__: train step 13290: loss: 1.0029, policy_loss: 0.9658, value_loss: 0.6177
2024-07-11 16:57:34,749 [INFO    ] __main__: train step 13291: loss: 1.0029, policy_loss: 0.9658, value_loss: 0.6177
2024-07-11 16:57:34,951 [INFO    ] __main__: train step 13292: loss: 1.0029, policy_loss: 0.9658, value_loss: 0.6177
2024-07-11 16:57:35,149 [INFO    ] __main__: train step 13293: loss: 1.0029, policy_loss: 0.9657, value_loss: 0.6176
2024-07-11 16:57:36,569 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:57:36,972 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:57:37,035 [INFO    ] __main__: train step 13294: loss: 1.0029, policy_loss: 0.9657, value_loss: 0.6176
2024-07-11 16:57:37,219 [INFO    ] __main__: train step 13295: loss: 1.0029, policy_loss: 0.9657, value_loss: 0.6176
2024-07-11 16:57:37,423 [INFO    ] __main__: train step 13296: loss: 1.0028, policy_loss: 0.9657, value_loss: 0.6175
2024-07-11 16:57:37,626 [INFO    ] __main__: train step 13297: loss: 1.0028, policy_loss: 0.9657, value_loss: 0.6175
2024-07-11 16:57:37,829 [INFO    ] __main__: train step 13298: loss: 1.0028, policy_loss: 0.9656, value_loss: 0.6175
2024-07-11 16:57:39,382 [INFO    ] __main__: train step 13299: loss: 1.0028, policy_loss: 0.9656, value_loss: 0.6174
2024-07-11 16:57:39,604 [INFO    ] __main__: train step 13300: loss: 1.0028, policy_loss: 0.9656, value_loss: 0.6174
2024-07-11 16:57:39,814 [INFO    ] __main__: train step 13301: loss: 1.0028, policy_loss: 0.9656, value_loss: 0.6174
2024-07-11 16:57:40,022 [INFO    ] __main__: train step 13302: loss: 1.0028, policy_loss: 0.9655, value_loss: 0.6174
2024-07-11 16:57:40,217 [INFO    ] __main__: train step 13303: loss: 1.0028, policy_loss: 0.9655, value_loss: 0.6173
2024-07-11 16:57:40,420 [INFO    ] __main__: train step 13304: loss: 1.0028, policy_loss: 0.9655, value_loss: 0.6173
2024-07-11 16:57:40,636 [INFO    ] __main__: train step 13305: loss: 1.0028, policy_loss: 0.9655, value_loss: 0.6173
2024-07-11 16:57:40,849 [INFO    ] __main__: train step 13306: loss: 1.0028, policy_loss: 0.9655, value_loss: 0.6172
2024-07-11 16:57:41,101 [INFO    ] __main__: train step 13307: loss: 1.0028, policy_loss: 0.9654, value_loss: 0.6172
2024-07-11 16:57:41,330 [INFO    ] __main__: train step 13308: loss: 1.0028, policy_loss: 0.9654, value_loss: 0.6172
2024-07-11 16:57:41,541 [INFO    ] __main__: train step 13309: loss: 1.0028, policy_loss: 0.9654, value_loss: 0.6172
2024-07-11 16:57:41,763 [INFO    ] __main__: train step 13310: loss: 1.0027, policy_loss: 0.9654, value_loss: 0.6171
2024-07-11 16:57:43,234 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:57:43,662 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:57:43,717 [INFO    ] __main__: train step 13311: loss: 1.0027, policy_loss: 0.9653, value_loss: 0.6171
2024-07-11 16:57:43,894 [INFO    ] __main__: train step 13312: loss: 1.0027, policy_loss: 0.9653, value_loss: 0.6171
2024-07-11 16:57:44,091 [INFO    ] __main__: train step 13313: loss: 1.0027, policy_loss: 0.9653, value_loss: 0.6171
2024-07-11 16:57:44,318 [INFO    ] __main__: train step 13314: loss: 1.0027, policy_loss: 0.9653, value_loss: 0.6170
2024-07-11 16:57:44,502 [INFO    ] __main__: train step 13315: loss: 1.0027, policy_loss: 0.9653, value_loss: 0.6170
2024-07-11 16:57:44,702 [INFO    ] __main__: train step 13316: loss: 1.0027, policy_loss: 0.9652, value_loss: 0.6170
2024-07-11 16:57:44,913 [INFO    ] __main__: train step 13317: loss: 1.0027, policy_loss: 0.9652, value_loss: 0.6169
2024-07-11 16:57:45,111 [INFO    ] __main__: train step 13318: loss: 1.0027, policy_loss: 0.9652, value_loss: 0.6169
2024-07-11 16:57:45,322 [INFO    ] __main__: train step 13319: loss: 1.0027, policy_loss: 0.9652, value_loss: 0.6169
2024-07-11 16:57:45,524 [INFO    ] __main__: train step 13320: loss: 1.0027, policy_loss: 0.9651, value_loss: 0.6169
2024-07-11 16:57:45,733 [INFO    ] __main__: train step 13321: loss: 1.0027, policy_loss: 0.9651, value_loss: 0.6168
2024-07-11 16:57:45,980 [INFO    ] __main__: train step 13322: loss: 1.0027, policy_loss: 0.9651, value_loss: 0.6168
2024-07-11 16:57:46,176 [INFO    ] __main__: train step 13323: loss: 1.0027, policy_loss: 0.9651, value_loss: 0.6168
2024-07-11 16:57:46,387 [INFO    ] __main__: train step 13324: loss: 1.0027, policy_loss: 0.9651, value_loss: 0.6167
2024-07-11 16:57:46,584 [INFO    ] __main__: train step 13325: loss: 1.0026, policy_loss: 0.9650, value_loss: 0.6167
2024-07-11 16:57:46,787 [INFO    ] __main__: train step 13326: loss: 1.0026, policy_loss: 0.9650, value_loss: 0.6167
2024-07-11 16:57:46,993 [INFO    ] __main__: train step 13327: loss: 1.0026, policy_loss: 0.9650, value_loss: 0.6167
2024-07-11 16:57:48,436 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:57:48,879 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:57:48,942 [INFO    ] __main__: train step 13328: loss: 1.0026, policy_loss: 0.9650, value_loss: 0.6166
2024-07-11 16:57:49,124 [INFO    ] __main__: train step 13329: loss: 1.0026, policy_loss: 0.9649, value_loss: 0.6166
2024-07-11 16:57:49,350 [INFO    ] __main__: train step 13330: loss: 1.0026, policy_loss: 0.9649, value_loss: 0.6166
2024-07-11 16:57:49,587 [INFO    ] __main__: train step 13331: loss: 1.0026, policy_loss: 0.9649, value_loss: 0.6165
2024-07-11 16:57:49,803 [INFO    ] __main__: train step 13332: loss: 1.0026, policy_loss: 0.9649, value_loss: 0.6165
2024-07-11 16:57:49,993 [INFO    ] __main__: train step 13333: loss: 1.0026, policy_loss: 0.9649, value_loss: 0.6165
2024-07-11 16:57:50,311 [INFO    ] __main__: train step 13334: loss: 1.0026, policy_loss: 0.9648, value_loss: 0.6165
2024-07-11 16:57:50,532 [INFO    ] __main__: train step 13335: loss: 1.0026, policy_loss: 0.9648, value_loss: 0.6164
2024-07-11 16:57:50,744 [INFO    ] __main__: train step 13336: loss: 1.0026, policy_loss: 0.9648, value_loss: 0.6164
2024-07-11 16:57:50,934 [INFO    ] __main__: train step 13337: loss: 1.0026, policy_loss: 0.9648, value_loss: 0.6164
2024-07-11 16:57:51,149 [INFO    ] __main__: train step 13338: loss: 1.0026, policy_loss: 0.9647, value_loss: 0.6163
2024-07-11 16:57:51,351 [INFO    ] __main__: train step 13339: loss: 1.0025, policy_loss: 0.9647, value_loss: 0.6163
2024-07-11 16:57:51,550 [INFO    ] __main__: train step 13340: loss: 1.0025, policy_loss: 0.9647, value_loss: 0.6163
2024-07-11 16:57:51,743 [INFO    ] __main__: train step 13341: loss: 1.0025, policy_loss: 0.9647, value_loss: 0.6163
2024-07-11 16:57:51,957 [INFO    ] __main__: train step 13342: loss: 1.0025, policy_loss: 0.9647, value_loss: 0.6162
2024-07-11 16:57:52,154 [INFO    ] __main__: train step 13343: loss: 1.0025, policy_loss: 0.9646, value_loss: 0.6162
2024-07-11 16:57:52,359 [INFO    ] __main__: train step 13344: loss: 1.0025, policy_loss: 0.9646, value_loss: 0.6162
2024-07-11 16:57:53,785 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:57:54,221 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:57:54,286 [INFO    ] __main__: train step 13345: loss: 1.0025, policy_loss: 0.9646, value_loss: 0.6161
2024-07-11 16:57:54,500 [INFO    ] __main__: train step 13346: loss: 1.0025, policy_loss: 0.9646, value_loss: 0.6161
2024-07-11 16:57:54,749 [INFO    ] __main__: train step 13347: loss: 1.0025, policy_loss: 0.9646, value_loss: 0.6161
2024-07-11 16:57:54,934 [INFO    ] __main__: train step 13348: loss: 1.0025, policy_loss: 0.9645, value_loss: 0.6161
2024-07-11 16:57:55,150 [INFO    ] __main__: train step 13349: loss: 1.0025, policy_loss: 0.9645, value_loss: 0.6160
2024-07-11 16:57:55,358 [INFO    ] __main__: train step 13350: loss: 1.0025, policy_loss: 0.9645, value_loss: 0.6160
2024-07-11 16:57:55,591 [INFO    ] __main__: train step 13351: loss: 1.0025, policy_loss: 0.9645, value_loss: 0.6160
2024-07-11 16:57:55,801 [INFO    ] __main__: train step 13352: loss: 1.0025, policy_loss: 0.9644, value_loss: 0.6159
2024-07-11 16:57:56,016 [INFO    ] __main__: train step 13353: loss: 1.0025, policy_loss: 0.9644, value_loss: 0.6159
2024-07-11 16:57:56,249 [INFO    ] __main__: train step 13354: loss: 1.0024, policy_loss: 0.9644, value_loss: 0.6159
2024-07-11 16:57:56,532 [INFO    ] __main__: train step 13355: loss: 1.0024, policy_loss: 0.9644, value_loss: 0.6159
2024-07-11 16:57:56,737 [INFO    ] __main__: train step 13356: loss: 1.0024, policy_loss: 0.9644, value_loss: 0.6158
2024-07-11 16:57:56,950 [INFO    ] __main__: train step 13357: loss: 1.0024, policy_loss: 0.9643, value_loss: 0.6158
2024-07-11 16:57:57,172 [INFO    ] __main__: train step 13358: loss: 1.0024, policy_loss: 0.9643, value_loss: 0.6158
2024-07-11 16:57:57,386 [INFO    ] __main__: train step 13359: loss: 1.0024, policy_loss: 0.9643, value_loss: 0.6158
2024-07-11 16:57:57,589 [INFO    ] __main__: train step 13360: loss: 1.0024, policy_loss: 0.9643, value_loss: 0.6157
2024-07-11 16:57:57,793 [INFO    ] __main__: train step 13361: loss: 1.0024, policy_loss: 0.9642, value_loss: 0.6157
2024-07-11 16:57:59,230 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:57:59,641 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:57:59,698 [INFO    ] __main__: train step 13362: loss: 1.0024, policy_loss: 0.9642, value_loss: 0.6157
2024-07-11 16:57:59,884 [INFO    ] __main__: train step 13363: loss: 1.0024, policy_loss: 0.9642, value_loss: 0.6156
2024-07-11 16:58:00,091 [INFO    ] __main__: train step 13364: loss: 1.0024, policy_loss: 0.9642, value_loss: 0.6156
2024-07-11 16:58:00,293 [INFO    ] __main__: train step 13365: loss: 1.0024, policy_loss: 0.9642, value_loss: 0.6156
2024-07-11 16:58:00,498 [INFO    ] __main__: train step 13366: loss: 1.0024, policy_loss: 0.9641, value_loss: 0.6156
2024-07-11 16:58:00,700 [INFO    ] __main__: train step 13367: loss: 1.0024, policy_loss: 0.9641, value_loss: 0.6155
2024-07-11 16:58:00,906 [INFO    ] __main__: train step 13368: loss: 1.0024, policy_loss: 0.9641, value_loss: 0.6155
2024-07-11 16:58:01,142 [INFO    ] __main__: train step 13369: loss: 1.0023, policy_loss: 0.9641, value_loss: 0.6155
2024-07-11 16:58:01,370 [INFO    ] __main__: train step 13370: loss: 1.0023, policy_loss: 0.9641, value_loss: 0.6154
2024-07-11 16:58:01,580 [INFO    ] __main__: train step 13371: loss: 1.0023, policy_loss: 0.9640, value_loss: 0.6154
2024-07-11 16:58:01,780 [INFO    ] __main__: train step 13372: loss: 1.0023, policy_loss: 0.9640, value_loss: 0.6154
2024-07-11 16:58:01,979 [INFO    ] __main__: train step 13373: loss: 1.0023, policy_loss: 0.9640, value_loss: 0.6154
2024-07-11 16:58:02,191 [INFO    ] __main__: train step 13374: loss: 1.0023, policy_loss: 0.9640, value_loss: 0.6153
2024-07-11 16:58:02,395 [INFO    ] __main__: train step 13375: loss: 1.0023, policy_loss: 0.9639, value_loss: 0.6153
2024-07-11 16:58:02,606 [INFO    ] __main__: train step 13376: loss: 1.0023, policy_loss: 0.9639, value_loss: 0.6153
2024-07-11 16:58:02,806 [INFO    ] __main__: train step 13377: loss: 1.0023, policy_loss: 0.9639, value_loss: 0.6152
2024-07-11 16:58:03,014 [INFO    ] __main__: train step 13378: loss: 1.0023, policy_loss: 0.9639, value_loss: 0.6152
2024-07-11 16:58:04,455 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:58:04,854 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:58:04,910 [INFO    ] __main__: train step 13379: loss: 1.0023, policy_loss: 0.9639, value_loss: 0.6152
2024-07-11 16:58:05,079 [INFO    ] __main__: train step 13380: loss: 1.0023, policy_loss: 0.9638, value_loss: 0.6152
2024-07-11 16:58:05,284 [INFO    ] __main__: train step 13381: loss: 1.0023, policy_loss: 0.9638, value_loss: 0.6151
2024-07-11 16:58:05,488 [INFO    ] __main__: train step 13382: loss: 1.0023, policy_loss: 0.9638, value_loss: 0.6151
2024-07-11 16:58:05,700 [INFO    ] __main__: train step 13383: loss: 1.0022, policy_loss: 0.9638, value_loss: 0.6151
2024-07-11 16:58:05,903 [INFO    ] __main__: train step 13384: loss: 1.0022, policy_loss: 0.9637, value_loss: 0.6150
2024-07-11 16:58:06,111 [INFO    ] __main__: train step 13385: loss: 1.0022, policy_loss: 0.9637, value_loss: 0.6150
2024-07-11 16:58:06,314 [INFO    ] __main__: train step 13386: loss: 1.0022, policy_loss: 0.9637, value_loss: 0.6150
2024-07-11 16:58:06,523 [INFO    ] __main__: train step 13387: loss: 1.0022, policy_loss: 0.9637, value_loss: 0.6150
2024-07-11 16:58:06,732 [INFO    ] __main__: train step 13388: loss: 1.0022, policy_loss: 0.9637, value_loss: 0.6149
2024-07-11 16:58:06,939 [INFO    ] __main__: train step 13389: loss: 1.0022, policy_loss: 0.9636, value_loss: 0.6149
2024-07-11 16:58:07,148 [INFO    ] __main__: train step 13390: loss: 1.0022, policy_loss: 0.9636, value_loss: 0.6149
2024-07-11 16:58:07,354 [INFO    ] __main__: train step 13391: loss: 1.0022, policy_loss: 0.9636, value_loss: 0.6148
2024-07-11 16:58:07,554 [INFO    ] __main__: train step 13392: loss: 1.0022, policy_loss: 0.9636, value_loss: 0.6148
2024-07-11 16:58:07,769 [INFO    ] __main__: train step 13393: loss: 1.0022, policy_loss: 0.9636, value_loss: 0.6148
2024-07-11 16:58:07,965 [INFO    ] __main__: train step 13394: loss: 1.0022, policy_loss: 0.9635, value_loss: 0.6148
2024-07-11 16:58:08,176 [INFO    ] __main__: train step 13395: loss: 1.0022, policy_loss: 0.9635, value_loss: 0.6147
2024-07-11 16:58:09,625 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:58:10,060 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:58:10,120 [INFO    ] __main__: train step 13396: loss: 1.0022, policy_loss: 0.9635, value_loss: 0.6147
2024-07-11 16:58:10,301 [INFO    ] __main__: train step 13397: loss: 1.0021, policy_loss: 0.9635, value_loss: 0.6147
2024-07-11 16:58:11,909 [INFO    ] __main__: train step 13398: loss: 1.0021, policy_loss: 0.9634, value_loss: 0.6146
2024-07-11 16:58:12,120 [INFO    ] __main__: train step 13399: loss: 1.0021, policy_loss: 0.9634, value_loss: 0.6146
2024-07-11 16:58:12,330 [INFO    ] __main__: train step 13400: loss: 1.0021, policy_loss: 0.9634, value_loss: 0.6146
2024-07-11 16:58:12,538 [INFO    ] __main__: train step 13401: loss: 1.0021, policy_loss: 0.9634, value_loss: 0.6146
2024-07-11 16:58:12,737 [INFO    ] __main__: train step 13402: loss: 1.0021, policy_loss: 0.9634, value_loss: 0.6145
2024-07-11 16:58:12,942 [INFO    ] __main__: train step 13403: loss: 1.0021, policy_loss: 0.9633, value_loss: 0.6145
2024-07-11 16:58:13,150 [INFO    ] __main__: train step 13404: loss: 1.0021, policy_loss: 0.9633, value_loss: 0.6145
2024-07-11 16:58:13,385 [INFO    ] __main__: train step 13405: loss: 1.0021, policy_loss: 0.9633, value_loss: 0.6144
2024-07-11 16:58:13,601 [INFO    ] __main__: train step 13406: loss: 1.0021, policy_loss: 0.9633, value_loss: 0.6144
2024-07-11 16:58:13,846 [INFO    ] __main__: train step 13407: loss: 1.0021, policy_loss: 0.9633, value_loss: 0.6144
2024-07-11 16:58:14,063 [INFO    ] __main__: train step 13408: loss: 1.0021, policy_loss: 0.9632, value_loss: 0.6144
2024-07-11 16:58:14,294 [INFO    ] __main__: train step 13409: loss: 1.0021, policy_loss: 0.9632, value_loss: 0.6143
2024-07-11 16:58:14,536 [INFO    ] __main__: train step 13410: loss: 1.0021, policy_loss: 0.9632, value_loss: 0.6143
2024-07-11 16:58:14,762 [INFO    ] __main__: train step 13411: loss: 1.0021, policy_loss: 0.9632, value_loss: 0.6143
2024-07-11 16:58:14,999 [INFO    ] __main__: train step 13412: loss: 1.0020, policy_loss: 0.9631, value_loss: 0.6142
2024-07-11 16:58:16,433 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:58:16,875 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:58:16,935 [INFO    ] __main__: train step 13413: loss: 1.0020, policy_loss: 0.9631, value_loss: 0.6142
2024-07-11 16:58:17,124 [INFO    ] __main__: train step 13414: loss: 1.0020, policy_loss: 0.9631, value_loss: 0.6142
2024-07-11 16:58:17,327 [INFO    ] __main__: train step 13415: loss: 1.0020, policy_loss: 0.9631, value_loss: 0.6142
2024-07-11 16:58:17,574 [INFO    ] __main__: train step 13416: loss: 1.0020, policy_loss: 0.9631, value_loss: 0.6141
2024-07-11 16:58:17,808 [INFO    ] __main__: train step 13417: loss: 1.0020, policy_loss: 0.9630, value_loss: 0.6141
2024-07-11 16:58:18,015 [INFO    ] __main__: train step 13418: loss: 1.0020, policy_loss: 0.9630, value_loss: 0.6141
2024-07-11 16:58:18,219 [INFO    ] __main__: train step 13419: loss: 1.0020, policy_loss: 0.9630, value_loss: 0.6140
2024-07-11 16:58:18,415 [INFO    ] __main__: train step 13420: loss: 1.0020, policy_loss: 0.9630, value_loss: 0.6140
2024-07-11 16:58:18,633 [INFO    ] __main__: train step 13421: loss: 1.0020, policy_loss: 0.9629, value_loss: 0.6140
2024-07-11 16:58:18,866 [INFO    ] __main__: train step 13422: loss: 1.0020, policy_loss: 0.9629, value_loss: 0.6140
2024-07-11 16:58:19,060 [INFO    ] __main__: train step 13423: loss: 1.0020, policy_loss: 0.9629, value_loss: 0.6139
2024-07-11 16:58:19,259 [INFO    ] __main__: train step 13424: loss: 1.0020, policy_loss: 0.9629, value_loss: 0.6139
2024-07-11 16:58:19,464 [INFO    ] __main__: train step 13425: loss: 1.0020, policy_loss: 0.9629, value_loss: 0.6139
2024-07-11 16:58:19,656 [INFO    ] __main__: train step 13426: loss: 1.0019, policy_loss: 0.9628, value_loss: 0.6138
2024-07-11 16:58:19,860 [INFO    ] __main__: train step 13427: loss: 1.0019, policy_loss: 0.9628, value_loss: 0.6138
2024-07-11 16:58:20,055 [INFO    ] __main__: train step 13428: loss: 1.0019, policy_loss: 0.9628, value_loss: 0.6138
2024-07-11 16:58:20,270 [INFO    ] __main__: train step 13429: loss: 1.0019, policy_loss: 0.9628, value_loss: 0.6138
2024-07-11 16:58:21,755 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:58:22,188 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:58:22,255 [INFO    ] __main__: train step 13430: loss: 1.0019, policy_loss: 0.9628, value_loss: 0.6137
2024-07-11 16:58:22,432 [INFO    ] __main__: train step 13431: loss: 1.0019, policy_loss: 0.9627, value_loss: 0.6137
2024-07-11 16:58:22,640 [INFO    ] __main__: train step 13432: loss: 1.0019, policy_loss: 0.9627, value_loss: 0.6137
2024-07-11 16:58:22,841 [INFO    ] __main__: train step 13433: loss: 1.0019, policy_loss: 0.9627, value_loss: 0.6137
2024-07-11 16:58:23,036 [INFO    ] __main__: train step 13434: loss: 1.0019, policy_loss: 0.9627, value_loss: 0.6136
2024-07-11 16:58:23,256 [INFO    ] __main__: train step 13435: loss: 1.0019, policy_loss: 0.9626, value_loss: 0.6136
2024-07-11 16:58:23,477 [INFO    ] __main__: train step 13436: loss: 1.0019, policy_loss: 0.9626, value_loss: 0.6136
2024-07-11 16:58:23,693 [INFO    ] __main__: train step 13437: loss: 1.0019, policy_loss: 0.9626, value_loss: 0.6135
2024-07-11 16:58:23,945 [INFO    ] __main__: train step 13438: loss: 1.0019, policy_loss: 0.9626, value_loss: 0.6135
2024-07-11 16:58:24,179 [INFO    ] __main__: train step 13439: loss: 1.0019, policy_loss: 0.9626, value_loss: 0.6135
2024-07-11 16:58:24,428 [INFO    ] __main__: train step 13440: loss: 1.0018, policy_loss: 0.9625, value_loss: 0.6135
2024-07-11 16:58:24,656 [INFO    ] __main__: train step 13441: loss: 1.0018, policy_loss: 0.9625, value_loss: 0.6134
2024-07-11 16:58:24,872 [INFO    ] __main__: train step 13442: loss: 1.0018, policy_loss: 0.9625, value_loss: 0.6134
2024-07-11 16:58:25,100 [INFO    ] __main__: train step 13443: loss: 1.0018, policy_loss: 0.9625, value_loss: 0.6134
2024-07-11 16:58:25,303 [INFO    ] __main__: train step 13444: loss: 1.0018, policy_loss: 0.9625, value_loss: 0.6133
2024-07-11 16:58:25,506 [INFO    ] __main__: train step 13445: loss: 1.0018, policy_loss: 0.9624, value_loss: 0.6133
2024-07-11 16:58:25,711 [INFO    ] __main__: train step 13446: loss: 1.0018, policy_loss: 0.9624, value_loss: 0.6133
2024-07-11 16:58:27,156 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:58:27,592 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:58:27,655 [INFO    ] __main__: train step 13447: loss: 1.0018, policy_loss: 0.9624, value_loss: 0.6133
2024-07-11 16:58:27,829 [INFO    ] __main__: train step 13448: loss: 1.0018, policy_loss: 0.9624, value_loss: 0.6132
2024-07-11 16:58:28,039 [INFO    ] __main__: train step 13449: loss: 1.0018, policy_loss: 0.9623, value_loss: 0.6132
2024-07-11 16:58:28,231 [INFO    ] __main__: train step 13450: loss: 1.0018, policy_loss: 0.9623, value_loss: 0.6132
2024-07-11 16:58:28,443 [INFO    ] __main__: train step 13451: loss: 1.0018, policy_loss: 0.9623, value_loss: 0.6131
2024-07-11 16:58:28,651 [INFO    ] __main__: train step 13452: loss: 1.0018, policy_loss: 0.9623, value_loss: 0.6131
2024-07-11 16:58:28,851 [INFO    ] __main__: train step 13453: loss: 1.0018, policy_loss: 0.9623, value_loss: 0.6131
2024-07-11 16:58:29,051 [INFO    ] __main__: train step 13454: loss: 1.0017, policy_loss: 0.9622, value_loss: 0.6131
2024-07-11 16:58:29,284 [INFO    ] __main__: train step 13455: loss: 1.0017, policy_loss: 0.9622, value_loss: 0.6130
2024-07-11 16:58:29,514 [INFO    ] __main__: train step 13456: loss: 1.0017, policy_loss: 0.9622, value_loss: 0.6130
2024-07-11 16:58:29,726 [INFO    ] __main__: train step 13457: loss: 1.0017, policy_loss: 0.9622, value_loss: 0.6130
2024-07-11 16:58:29,966 [INFO    ] __main__: train step 13458: loss: 1.0017, policy_loss: 0.9621, value_loss: 0.6129
2024-07-11 16:58:30,202 [INFO    ] __main__: train step 13459: loss: 1.0017, policy_loss: 0.9621, value_loss: 0.6129
2024-07-11 16:58:30,408 [INFO    ] __main__: train step 13460: loss: 1.0017, policy_loss: 0.9621, value_loss: 0.6129
2024-07-11 16:58:30,615 [INFO    ] __main__: train step 13461: loss: 1.0017, policy_loss: 0.9621, value_loss: 0.6129
2024-07-11 16:58:30,826 [INFO    ] __main__: train step 13462: loss: 1.0017, policy_loss: 0.9621, value_loss: 0.6128
2024-07-11 16:58:31,037 [INFO    ] __main__: train step 13463: loss: 1.0017, policy_loss: 0.9620, value_loss: 0.6128
2024-07-11 16:58:32,503 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:58:32,977 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:58:33,031 [INFO    ] __main__: train step 13464: loss: 1.0017, policy_loss: 0.9620, value_loss: 0.6128
2024-07-11 16:58:33,222 [INFO    ] __main__: train step 13465: loss: 1.0017, policy_loss: 0.9620, value_loss: 0.6127
2024-07-11 16:58:33,438 [INFO    ] __main__: train step 13466: loss: 1.0017, policy_loss: 0.9620, value_loss: 0.6127
2024-07-11 16:58:33,662 [INFO    ] __main__: train step 13467: loss: 1.0016, policy_loss: 0.9620, value_loss: 0.6127
2024-07-11 16:58:33,893 [INFO    ] __main__: train step 13468: loss: 1.0016, policy_loss: 0.9619, value_loss: 0.6127
2024-07-11 16:58:34,096 [INFO    ] __main__: train step 13469: loss: 1.0016, policy_loss: 0.9619, value_loss: 0.6126
2024-07-11 16:58:34,304 [INFO    ] __main__: train step 13470: loss: 1.0016, policy_loss: 0.9619, value_loss: 0.6126
2024-07-11 16:58:34,504 [INFO    ] __main__: train step 13471: loss: 1.0016, policy_loss: 0.9619, value_loss: 0.6126
2024-07-11 16:58:34,706 [INFO    ] __main__: train step 13472: loss: 1.0016, policy_loss: 0.9619, value_loss: 0.6125
2024-07-11 16:58:34,915 [INFO    ] __main__: train step 13473: loss: 1.0016, policy_loss: 0.9618, value_loss: 0.6125
2024-07-11 16:58:35,114 [INFO    ] __main__: train step 13474: loss: 1.0016, policy_loss: 0.9618, value_loss: 0.6125
2024-07-11 16:58:35,334 [INFO    ] __main__: train step 13475: loss: 1.0016, policy_loss: 0.9618, value_loss: 0.6125
2024-07-11 16:58:35,569 [INFO    ] __main__: train step 13476: loss: 1.0016, policy_loss: 0.9618, value_loss: 0.6124
2024-07-11 16:58:35,805 [INFO    ] __main__: train step 13477: loss: 1.0016, policy_loss: 0.9617, value_loss: 0.6124
2024-07-11 16:58:36,052 [INFO    ] __main__: train step 13478: loss: 1.0016, policy_loss: 0.9617, value_loss: 0.6124
2024-07-11 16:58:36,284 [INFO    ] __main__: train step 13479: loss: 1.0016, policy_loss: 0.9617, value_loss: 0.6123
2024-07-11 16:58:36,486 [INFO    ] __main__: train step 13480: loss: 1.0016, policy_loss: 0.9617, value_loss: 0.6123
2024-07-11 16:58:37,937 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:58:38,397 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:58:38,465 [INFO    ] __main__: train step 13481: loss: 1.0015, policy_loss: 0.9617, value_loss: 0.6123
2024-07-11 16:58:38,649 [INFO    ] __main__: train step 13482: loss: 1.0015, policy_loss: 0.9616, value_loss: 0.6123
2024-07-11 16:58:38,861 [INFO    ] __main__: train step 13483: loss: 1.0015, policy_loss: 0.9616, value_loss: 0.6122
2024-07-11 16:58:39,063 [INFO    ] __main__: train step 13484: loss: 1.0015, policy_loss: 0.9616, value_loss: 0.6122
2024-07-11 16:58:39,276 [INFO    ] __main__: train step 13485: loss: 1.0015, policy_loss: 0.9616, value_loss: 0.6122
2024-07-11 16:58:39,473 [INFO    ] __main__: train step 13486: loss: 1.0015, policy_loss: 0.9616, value_loss: 0.6121
2024-07-11 16:58:39,676 [INFO    ] __main__: train step 13487: loss: 1.0015, policy_loss: 0.9615, value_loss: 0.6121
2024-07-11 16:58:39,879 [INFO    ] __main__: train step 13488: loss: 1.0015, policy_loss: 0.9615, value_loss: 0.6121
2024-07-11 16:58:40,094 [INFO    ] __main__: train step 13489: loss: 1.0015, policy_loss: 0.9615, value_loss: 0.6121
2024-07-11 16:58:40,295 [INFO    ] __main__: train step 13490: loss: 1.0015, policy_loss: 0.9615, value_loss: 0.6120
2024-07-11 16:58:40,540 [INFO    ] __main__: train step 13491: loss: 1.0015, policy_loss: 0.9614, value_loss: 0.6120
2024-07-11 16:58:40,733 [INFO    ] __main__: train step 13492: loss: 1.0015, policy_loss: 0.9614, value_loss: 0.6120
2024-07-11 16:58:40,932 [INFO    ] __main__: train step 13493: loss: 1.0015, policy_loss: 0.9614, value_loss: 0.6119
2024-07-11 16:58:41,143 [INFO    ] __main__: train step 13494: loss: 1.0015, policy_loss: 0.9614, value_loss: 0.6119
2024-07-11 16:58:41,351 [INFO    ] __main__: train step 13495: loss: 1.0014, policy_loss: 0.9614, value_loss: 0.6119
2024-07-11 16:58:41,582 [INFO    ] __main__: train step 13496: loss: 1.0014, policy_loss: 0.9613, value_loss: 0.6119
2024-07-11 16:58:41,781 [INFO    ] __main__: train step 13497: loss: 1.0014, policy_loss: 0.9613, value_loss: 0.6118
2024-07-11 16:58:44,562 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:58:45,012 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:58:45,074 [INFO    ] __main__: train step 13498: loss: 1.0014, policy_loss: 0.9613, value_loss: 0.6118
2024-07-11 16:58:45,261 [INFO    ] __main__: train step 13499: loss: 1.0014, policy_loss: 0.9613, value_loss: 0.6118
2024-07-11 16:58:45,497 [INFO    ] __main__: train step 13500: loss: 1.0014, policy_loss: 0.9613, value_loss: 0.6117
2024-07-11 16:58:45,707 [INFO    ] __main__: train step 13501: loss: 1.0014, policy_loss: 0.9612, value_loss: 0.6117
2024-07-11 16:58:45,916 [INFO    ] __main__: train step 13502: loss: 1.0014, policy_loss: 0.9612, value_loss: 0.6117
2024-07-11 16:58:46,123 [INFO    ] __main__: train step 13503: loss: 1.0014, policy_loss: 0.9612, value_loss: 0.6117
2024-07-11 16:58:46,328 [INFO    ] __main__: train step 13504: loss: 1.0014, policy_loss: 0.9612, value_loss: 0.6116
2024-07-11 16:58:46,536 [INFO    ] __main__: train step 13505: loss: 1.0014, policy_loss: 0.9612, value_loss: 0.6116
2024-07-11 16:58:46,743 [INFO    ] __main__: train step 13506: loss: 1.0014, policy_loss: 0.9611, value_loss: 0.6116
2024-07-11 16:58:46,949 [INFO    ] __main__: train step 13507: loss: 1.0014, policy_loss: 0.9611, value_loss: 0.6116
2024-07-11 16:58:47,160 [INFO    ] __main__: train step 13508: loss: 1.0014, policy_loss: 0.9611, value_loss: 0.6115
2024-07-11 16:58:47,378 [INFO    ] __main__: train step 13509: loss: 1.0014, policy_loss: 0.9611, value_loss: 0.6115
2024-07-11 16:58:47,588 [INFO    ] __main__: train step 13510: loss: 1.0013, policy_loss: 0.9611, value_loss: 0.6115
2024-07-11 16:58:47,816 [INFO    ] __main__: train step 13511: loss: 1.0013, policy_loss: 0.9610, value_loss: 0.6114
2024-07-11 16:58:48,035 [INFO    ] __main__: train step 13512: loss: 1.0013, policy_loss: 0.9610, value_loss: 0.6114
2024-07-11 16:58:48,242 [INFO    ] __main__: train step 13513: loss: 1.0013, policy_loss: 0.9610, value_loss: 0.6114
2024-07-11 16:58:48,447 [INFO    ] __main__: train step 13514: loss: 1.0013, policy_loss: 0.9610, value_loss: 0.6114
2024-07-11 16:58:49,929 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:58:50,364 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:58:50,421 [INFO    ] __main__: train step 13515: loss: 1.0013, policy_loss: 0.9609, value_loss: 0.6113
2024-07-11 16:58:50,613 [INFO    ] __main__: train step 13516: loss: 1.0013, policy_loss: 0.9609, value_loss: 0.6113
2024-07-11 16:58:50,851 [INFO    ] __main__: train step 13517: loss: 1.0013, policy_loss: 0.9609, value_loss: 0.6113
2024-07-11 16:58:51,104 [INFO    ] __main__: train step 13518: loss: 1.0013, policy_loss: 0.9609, value_loss: 0.6112
2024-07-11 16:58:51,305 [INFO    ] __main__: train step 13519: loss: 1.0013, policy_loss: 0.9609, value_loss: 0.6112
2024-07-11 16:58:51,512 [INFO    ] __main__: train step 13520: loss: 1.0013, policy_loss: 0.9608, value_loss: 0.6112
2024-07-11 16:58:51,712 [INFO    ] __main__: train step 13521: loss: 1.0013, policy_loss: 0.9608, value_loss: 0.6112
2024-07-11 16:58:51,927 [INFO    ] __main__: train step 13522: loss: 1.0013, policy_loss: 0.9608, value_loss: 0.6111
2024-07-11 16:58:52,129 [INFO    ] __main__: train step 13523: loss: 1.0013, policy_loss: 0.9608, value_loss: 0.6111
2024-07-11 16:58:52,332 [INFO    ] __main__: train step 13524: loss: 1.0012, policy_loss: 0.9608, value_loss: 0.6111
2024-07-11 16:58:52,552 [INFO    ] __main__: train step 13525: loss: 1.0012, policy_loss: 0.9607, value_loss: 0.6110
2024-07-11 16:58:52,792 [INFO    ] __main__: train step 13526: loss: 1.0012, policy_loss: 0.9607, value_loss: 0.6110
2024-07-11 16:58:52,989 [INFO    ] __main__: train step 13527: loss: 1.0012, policy_loss: 0.9607, value_loss: 0.6110
2024-07-11 16:58:53,215 [INFO    ] __main__: train step 13528: loss: 1.0012, policy_loss: 0.9607, value_loss: 0.6110
2024-07-11 16:58:53,433 [INFO    ] __main__: train step 13529: loss: 1.0012, policy_loss: 0.9607, value_loss: 0.6109
2024-07-11 16:58:53,649 [INFO    ] __main__: train step 13530: loss: 1.0012, policy_loss: 0.9606, value_loss: 0.6109
2024-07-11 16:58:53,886 [INFO    ] __main__: train step 13531: loss: 1.0012, policy_loss: 0.9606, value_loss: 0.6109
2024-07-11 16:58:55,331 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:58:55,731 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:58:55,790 [INFO    ] __main__: train step 13532: loss: 1.0012, policy_loss: 0.9606, value_loss: 0.6108
2024-07-11 16:58:55,970 [INFO    ] __main__: train step 13533: loss: 1.0012, policy_loss: 0.9606, value_loss: 0.6108
2024-07-11 16:58:56,185 [INFO    ] __main__: train step 13534: loss: 1.0012, policy_loss: 0.9605, value_loss: 0.6108
2024-07-11 16:58:56,385 [INFO    ] __main__: train step 13535: loss: 1.0012, policy_loss: 0.9605, value_loss: 0.6108
2024-07-11 16:58:56,604 [INFO    ] __main__: train step 13536: loss: 1.0012, policy_loss: 0.9605, value_loss: 0.6107
2024-07-11 16:58:56,800 [INFO    ] __main__: train step 13537: loss: 1.0012, policy_loss: 0.9605, value_loss: 0.6107
2024-07-11 16:58:57,001 [INFO    ] __main__: train step 13538: loss: 1.0012, policy_loss: 0.9605, value_loss: 0.6107
2024-07-11 16:58:57,201 [INFO    ] __main__: train step 13539: loss: 1.0011, policy_loss: 0.9604, value_loss: 0.6107
2024-07-11 16:58:57,409 [INFO    ] __main__: train step 13540: loss: 1.0011, policy_loss: 0.9604, value_loss: 0.6106
2024-07-11 16:58:57,613 [INFO    ] __main__: train step 13541: loss: 1.0011, policy_loss: 0.9604, value_loss: 0.6106
2024-07-11 16:58:57,808 [INFO    ] __main__: train step 13542: loss: 1.0011, policy_loss: 0.9604, value_loss: 0.6106
2024-07-11 16:58:58,010 [INFO    ] __main__: train step 13543: loss: 1.0011, policy_loss: 0.9604, value_loss: 0.6105
2024-07-11 16:58:58,226 [INFO    ] __main__: train step 13544: loss: 1.0011, policy_loss: 0.9603, value_loss: 0.6105
2024-07-11 16:58:58,456 [INFO    ] __main__: train step 13545: loss: 1.0011, policy_loss: 0.9603, value_loss: 0.6105
2024-07-11 16:58:58,661 [INFO    ] __main__: train step 13546: loss: 1.0011, policy_loss: 0.9603, value_loss: 0.6105
2024-07-11 16:58:58,867 [INFO    ] __main__: train step 13547: loss: 1.0011, policy_loss: 0.9603, value_loss: 0.6104
2024-07-11 16:58:59,064 [INFO    ] __main__: train step 13548: loss: 1.0011, policy_loss: 0.9603, value_loss: 0.6104
2024-07-11 16:59:00,516 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:59:00,940 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:59:01,002 [INFO    ] __main__: train step 13549: loss: 1.0011, policy_loss: 0.9602, value_loss: 0.6104
2024-07-11 16:59:01,178 [INFO    ] __main__: train step 13550: loss: 1.0011, policy_loss: 0.9602, value_loss: 0.6103
2024-07-11 16:59:01,372 [INFO    ] __main__: train step 13551: loss: 1.0011, policy_loss: 0.9602, value_loss: 0.6103
2024-07-11 16:59:01,574 [INFO    ] __main__: train step 13552: loss: 1.0010, policy_loss: 0.9602, value_loss: 0.6103
2024-07-11 16:59:01,780 [INFO    ] __main__: train step 13553: loss: 1.0010, policy_loss: 0.9601, value_loss: 0.6103
2024-07-11 16:59:01,978 [INFO    ] __main__: train step 13554: loss: 1.0010, policy_loss: 0.9601, value_loss: 0.6102
2024-07-11 16:59:02,185 [INFO    ] __main__: train step 13555: loss: 1.0010, policy_loss: 0.9601, value_loss: 0.6102
2024-07-11 16:59:02,399 [INFO    ] __main__: train step 13556: loss: 1.0010, policy_loss: 0.9601, value_loss: 0.6102
2024-07-11 16:59:02,601 [INFO    ] __main__: train step 13557: loss: 1.0010, policy_loss: 0.9601, value_loss: 0.6101
2024-07-11 16:59:02,818 [INFO    ] __main__: train step 13558: loss: 1.0010, policy_loss: 0.9600, value_loss: 0.6101
2024-07-11 16:59:03,021 [INFO    ] __main__: train step 13559: loss: 1.0010, policy_loss: 0.9600, value_loss: 0.6101
2024-07-11 16:59:03,251 [INFO    ] __main__: train step 13560: loss: 1.0010, policy_loss: 0.9600, value_loss: 0.6101
2024-07-11 16:59:03,456 [INFO    ] __main__: train step 13561: loss: 1.0010, policy_loss: 0.9600, value_loss: 0.6100
2024-07-11 16:59:03,658 [INFO    ] __main__: train step 13562: loss: 1.0010, policy_loss: 0.9600, value_loss: 0.6100
2024-07-11 16:59:03,860 [INFO    ] __main__: train step 13563: loss: 1.0010, policy_loss: 0.9599, value_loss: 0.6100
2024-07-11 16:59:04,064 [INFO    ] __main__: train step 13564: loss: 1.0010, policy_loss: 0.9599, value_loss: 0.6099
2024-07-11 16:59:04,260 [INFO    ] __main__: train step 13565: loss: 1.0010, policy_loss: 0.9599, value_loss: 0.6099
2024-07-11 16:59:05,712 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:59:06,143 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:59:06,201 [INFO    ] __main__: train step 13566: loss: 1.0010, policy_loss: 0.9599, value_loss: 0.6099
2024-07-11 16:59:06,372 [INFO    ] __main__: train step 13567: loss: 1.0009, policy_loss: 0.9599, value_loss: 0.6099
2024-07-11 16:59:06,589 [INFO    ] __main__: train step 13568: loss: 1.0009, policy_loss: 0.9598, value_loss: 0.6098
2024-07-11 16:59:06,795 [INFO    ] __main__: train step 13569: loss: 1.0009, policy_loss: 0.9598, value_loss: 0.6098
2024-07-11 16:59:07,000 [INFO    ] __main__: train step 13570: loss: 1.0009, policy_loss: 0.9598, value_loss: 0.6098
2024-07-11 16:59:07,205 [INFO    ] __main__: train step 13571: loss: 1.0009, policy_loss: 0.9598, value_loss: 0.6098
2024-07-11 16:59:07,400 [INFO    ] __main__: train step 13572: loss: 1.0009, policy_loss: 0.9597, value_loss: 0.6097
2024-07-11 16:59:07,612 [INFO    ] __main__: train step 13573: loss: 1.0009, policy_loss: 0.9597, value_loss: 0.6097
2024-07-11 16:59:07,819 [INFO    ] __main__: train step 13574: loss: 1.0009, policy_loss: 0.9597, value_loss: 0.6097
2024-07-11 16:59:08,015 [INFO    ] __main__: train step 13575: loss: 1.0009, policy_loss: 0.9597, value_loss: 0.6096
2024-07-11 16:59:08,234 [INFO    ] __main__: train step 13576: loss: 1.0009, policy_loss: 0.9597, value_loss: 0.6096
2024-07-11 16:59:08,430 [INFO    ] __main__: train step 13577: loss: 1.0009, policy_loss: 0.9596, value_loss: 0.6096
2024-07-11 16:59:08,630 [INFO    ] __main__: train step 13578: loss: 1.0009, policy_loss: 0.9596, value_loss: 0.6096
2024-07-11 16:59:08,834 [INFO    ] __main__: train step 13579: loss: 1.0009, policy_loss: 0.9596, value_loss: 0.6095
2024-07-11 16:59:09,033 [INFO    ] __main__: train step 13580: loss: 1.0009, policy_loss: 0.9596, value_loss: 0.6095
2024-07-11 16:59:09,232 [INFO    ] __main__: train step 13581: loss: 1.0008, policy_loss: 0.9596, value_loss: 0.6095
2024-07-11 16:59:09,437 [INFO    ] __main__: train step 13582: loss: 1.0008, policy_loss: 0.9595, value_loss: 0.6094
2024-07-11 16:59:10,873 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:59:11,294 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:59:11,351 [INFO    ] __main__: train step 13583: loss: 1.0008, policy_loss: 0.9595, value_loss: 0.6094
2024-07-11 16:59:11,542 [INFO    ] __main__: train step 13584: loss: 1.0008, policy_loss: 0.9595, value_loss: 0.6094
2024-07-11 16:59:11,781 [INFO    ] __main__: train step 13585: loss: 1.0008, policy_loss: 0.9595, value_loss: 0.6094
2024-07-11 16:59:11,976 [INFO    ] __main__: train step 13586: loss: 1.0008, policy_loss: 0.9595, value_loss: 0.6093
2024-07-11 16:59:12,179 [INFO    ] __main__: train step 13587: loss: 1.0008, policy_loss: 0.9594, value_loss: 0.6093
2024-07-11 16:59:12,382 [INFO    ] __main__: train step 13588: loss: 1.0008, policy_loss: 0.9594, value_loss: 0.6093
2024-07-11 16:59:12,591 [INFO    ] __main__: train step 13589: loss: 1.0008, policy_loss: 0.9594, value_loss: 0.6093
2024-07-11 16:59:12,789 [INFO    ] __main__: train step 13590: loss: 1.0008, policy_loss: 0.9594, value_loss: 0.6092
2024-07-11 16:59:12,985 [INFO    ] __main__: train step 13591: loss: 1.0008, policy_loss: 0.9594, value_loss: 0.6092
2024-07-11 16:59:13,187 [INFO    ] __main__: train step 13592: loss: 1.0008, policy_loss: 0.9593, value_loss: 0.6092
2024-07-11 16:59:13,390 [INFO    ] __main__: train step 13593: loss: 1.0008, policy_loss: 0.9593, value_loss: 0.6091
2024-07-11 16:59:13,589 [INFO    ] __main__: train step 13594: loss: 1.0008, policy_loss: 0.9593, value_loss: 0.6091
2024-07-11 16:59:13,803 [INFO    ] __main__: train step 13595: loss: 1.0007, policy_loss: 0.9593, value_loss: 0.6091
2024-07-11 16:59:14,007 [INFO    ] __main__: train step 13596: loss: 1.0007, policy_loss: 0.9592, value_loss: 0.6091
2024-07-11 16:59:14,206 [INFO    ] __main__: train step 13597: loss: 1.0007, policy_loss: 0.9592, value_loss: 0.6090
2024-07-11 16:59:14,431 [INFO    ] __main__: train step 13598: loss: 1.0007, policy_loss: 0.9592, value_loss: 0.6090
2024-07-11 16:59:15,997 [INFO    ] __main__: train step 13599: loss: 1.0007, policy_loss: 0.9592, value_loss: 0.6090
2024-07-11 16:59:17,448 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:59:17,863 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:59:17,922 [INFO    ] __main__: train step 13600: loss: 1.0007, policy_loss: 0.9592, value_loss: 0.6089
2024-07-11 16:59:18,101 [INFO    ] __main__: train step 13601: loss: 1.0007, policy_loss: 0.9591, value_loss: 0.6089
2024-07-11 16:59:18,298 [INFO    ] __main__: train step 13602: loss: 1.0007, policy_loss: 0.9591, value_loss: 0.6089
2024-07-11 16:59:18,500 [INFO    ] __main__: train step 13603: loss: 1.0007, policy_loss: 0.9591, value_loss: 0.6089
2024-07-11 16:59:18,699 [INFO    ] __main__: train step 13604: loss: 1.0007, policy_loss: 0.9591, value_loss: 0.6088
2024-07-11 16:59:18,897 [INFO    ] __main__: train step 13605: loss: 1.0007, policy_loss: 0.9591, value_loss: 0.6088
2024-07-11 16:59:19,096 [INFO    ] __main__: train step 13606: loss: 1.0007, policy_loss: 0.9590, value_loss: 0.6088
2024-07-11 16:59:19,294 [INFO    ] __main__: train step 13607: loss: 1.0007, policy_loss: 0.9590, value_loss: 0.6087
2024-07-11 16:59:19,502 [INFO    ] __main__: train step 13608: loss: 1.0007, policy_loss: 0.9590, value_loss: 0.6087
2024-07-11 16:59:19,703 [INFO    ] __main__: train step 13609: loss: 1.0006, policy_loss: 0.9590, value_loss: 0.6087
2024-07-11 16:59:19,908 [INFO    ] __main__: train step 13610: loss: 1.0006, policy_loss: 0.9590, value_loss: 0.6087
2024-07-11 16:59:20,116 [INFO    ] __main__: train step 13611: loss: 1.0006, policy_loss: 0.9589, value_loss: 0.6086
2024-07-11 16:59:20,352 [INFO    ] __main__: train step 13612: loss: 1.0006, policy_loss: 0.9589, value_loss: 0.6086
2024-07-11 16:59:20,592 [INFO    ] __main__: train step 13613: loss: 1.0006, policy_loss: 0.9589, value_loss: 0.6086
2024-07-11 16:59:20,827 [INFO    ] __main__: train step 13614: loss: 1.0006, policy_loss: 0.9589, value_loss: 0.6086
2024-07-11 16:59:21,031 [INFO    ] __main__: train step 13615: loss: 1.0006, policy_loss: 0.9588, value_loss: 0.6085
2024-07-11 16:59:21,238 [INFO    ] __main__: train step 13616: loss: 1.0006, policy_loss: 0.9588, value_loss: 0.6085
2024-07-11 16:59:22,695 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:59:23,139 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:59:23,206 [INFO    ] __main__: train step 13617: loss: 1.0006, policy_loss: 0.9588, value_loss: 0.6085
2024-07-11 16:59:23,395 [INFO    ] __main__: train step 13618: loss: 1.0006, policy_loss: 0.9588, value_loss: 0.6084
2024-07-11 16:59:23,639 [INFO    ] __main__: train step 13619: loss: 1.0006, policy_loss: 0.9588, value_loss: 0.6084
2024-07-11 16:59:23,863 [INFO    ] __main__: train step 13620: loss: 1.0006, policy_loss: 0.9587, value_loss: 0.6084
2024-07-11 16:59:24,073 [INFO    ] __main__: train step 13621: loss: 1.0006, policy_loss: 0.9587, value_loss: 0.6084
2024-07-11 16:59:24,305 [INFO    ] __main__: train step 13622: loss: 1.0006, policy_loss: 0.9587, value_loss: 0.6083
2024-07-11 16:59:24,543 [INFO    ] __main__: train step 13623: loss: 1.0005, policy_loss: 0.9587, value_loss: 0.6083
2024-07-11 16:59:24,780 [INFO    ] __main__: train step 13624: loss: 1.0005, policy_loss: 0.9587, value_loss: 0.6083
2024-07-11 16:59:24,997 [INFO    ] __main__: train step 13625: loss: 1.0005, policy_loss: 0.9586, value_loss: 0.6082
2024-07-11 16:59:25,191 [INFO    ] __main__: train step 13626: loss: 1.0005, policy_loss: 0.9586, value_loss: 0.6082
2024-07-11 16:59:25,407 [INFO    ] __main__: train step 13627: loss: 1.0005, policy_loss: 0.9586, value_loss: 0.6082
2024-07-11 16:59:25,608 [INFO    ] __main__: train step 13628: loss: 1.0005, policy_loss: 0.9586, value_loss: 0.6082
2024-07-11 16:59:25,852 [INFO    ] __main__: train step 13629: loss: 1.0005, policy_loss: 0.9586, value_loss: 0.6081
2024-07-11 16:59:26,075 [INFO    ] __main__: train step 13630: loss: 1.0005, policy_loss: 0.9585, value_loss: 0.6081
2024-07-11 16:59:26,291 [INFO    ] __main__: train step 13631: loss: 1.0005, policy_loss: 0.9585, value_loss: 0.6081
2024-07-11 16:59:26,521 [INFO    ] __main__: train step 13632: loss: 1.0005, policy_loss: 0.9585, value_loss: 0.6081
2024-07-11 16:59:26,728 [INFO    ] __main__: train step 13633: loss: 1.0005, policy_loss: 0.9585, value_loss: 0.6080
2024-07-11 16:59:28,179 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:59:28,551 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:59:28,606 [INFO    ] __main__: train step 13634: loss: 1.0005, policy_loss: 0.9585, value_loss: 0.6080
2024-07-11 16:59:28,781 [INFO    ] __main__: train step 13635: loss: 1.0005, policy_loss: 0.9584, value_loss: 0.6080
2024-07-11 16:59:28,994 [INFO    ] __main__: train step 13636: loss: 1.0005, policy_loss: 0.9584, value_loss: 0.6079
2024-07-11 16:59:29,201 [INFO    ] __main__: train step 13637: loss: 1.0005, policy_loss: 0.9584, value_loss: 0.6079
2024-07-11 16:59:29,404 [INFO    ] __main__: train step 13638: loss: 1.0004, policy_loss: 0.9584, value_loss: 0.6079
2024-07-11 16:59:29,624 [INFO    ] __main__: train step 13639: loss: 1.0004, policy_loss: 0.9584, value_loss: 0.6079
2024-07-11 16:59:29,820 [INFO    ] __main__: train step 13640: loss: 1.0004, policy_loss: 0.9583, value_loss: 0.6078
2024-07-11 16:59:30,047 [INFO    ] __main__: train step 13641: loss: 1.0004, policy_loss: 0.9583, value_loss: 0.6078
2024-07-11 16:59:30,279 [INFO    ] __main__: train step 13642: loss: 1.0004, policy_loss: 0.9583, value_loss: 0.6078
2024-07-11 16:59:30,489 [INFO    ] __main__: train step 13643: loss: 1.0004, policy_loss: 0.9583, value_loss: 0.6077
2024-07-11 16:59:30,692 [INFO    ] __main__: train step 13644: loss: 1.0004, policy_loss: 0.9583, value_loss: 0.6077
2024-07-11 16:59:30,894 [INFO    ] __main__: train step 13645: loss: 1.0004, policy_loss: 0.9582, value_loss: 0.6077
2024-07-11 16:59:31,117 [INFO    ] __main__: train step 13646: loss: 1.0004, policy_loss: 0.9582, value_loss: 0.6077
2024-07-11 16:59:31,317 [INFO    ] __main__: train step 13647: loss: 1.0004, policy_loss: 0.9582, value_loss: 0.6076
2024-07-11 16:59:31,516 [INFO    ] __main__: train step 13648: loss: 1.0004, policy_loss: 0.9582, value_loss: 0.6076
2024-07-11 16:59:31,733 [INFO    ] __main__: train step 13649: loss: 1.0004, policy_loss: 0.9581, value_loss: 0.6076
2024-07-11 16:59:31,948 [INFO    ] __main__: train step 13650: loss: 1.0004, policy_loss: 0.9581, value_loss: 0.6076
2024-07-11 16:59:33,399 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:59:33,812 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:59:33,868 [INFO    ] __main__: train step 13651: loss: 1.0004, policy_loss: 0.9581, value_loss: 0.6075
2024-07-11 16:59:34,038 [INFO    ] __main__: train step 13652: loss: 1.0004, policy_loss: 0.9581, value_loss: 0.6075
2024-07-11 16:59:34,234 [INFO    ] __main__: train step 13653: loss: 1.0003, policy_loss: 0.9581, value_loss: 0.6075
2024-07-11 16:59:34,453 [INFO    ] __main__: train step 13654: loss: 1.0003, policy_loss: 0.9580, value_loss: 0.6074
2024-07-11 16:59:34,693 [INFO    ] __main__: train step 13655: loss: 1.0003, policy_loss: 0.9580, value_loss: 0.6074
2024-07-11 16:59:34,928 [INFO    ] __main__: train step 13656: loss: 1.0003, policy_loss: 0.9580, value_loss: 0.6074
2024-07-11 16:59:35,128 [INFO    ] __main__: train step 13657: loss: 1.0003, policy_loss: 0.9580, value_loss: 0.6074
2024-07-11 16:59:35,363 [INFO    ] __main__: train step 13658: loss: 1.0003, policy_loss: 0.9580, value_loss: 0.6073
2024-07-11 16:59:35,606 [INFO    ] __main__: train step 13659: loss: 1.0003, policy_loss: 0.9579, value_loss: 0.6073
2024-07-11 16:59:35,845 [INFO    ] __main__: train step 13660: loss: 1.0003, policy_loss: 0.9579, value_loss: 0.6073
2024-07-11 16:59:36,079 [INFO    ] __main__: train step 13661: loss: 1.0003, policy_loss: 0.9579, value_loss: 0.6072
2024-07-11 16:59:36,305 [INFO    ] __main__: train step 13662: loss: 1.0003, policy_loss: 0.9579, value_loss: 0.6072
2024-07-11 16:59:36,508 [INFO    ] __main__: train step 13663: loss: 1.0003, policy_loss: 0.9579, value_loss: 0.6072
2024-07-11 16:59:36,705 [INFO    ] __main__: train step 13664: loss: 1.0003, policy_loss: 0.9578, value_loss: 0.6072
2024-07-11 16:59:36,915 [INFO    ] __main__: train step 13665: loss: 1.0003, policy_loss: 0.9578, value_loss: 0.6071
2024-07-11 16:59:37,113 [INFO    ] __main__: train step 13666: loss: 1.0003, policy_loss: 0.9578, value_loss: 0.6071
2024-07-11 16:59:37,315 [INFO    ] __main__: train step 13667: loss: 1.0002, policy_loss: 0.9578, value_loss: 0.6071
2024-07-11 16:59:38,765 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:59:39,189 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:59:39,248 [INFO    ] __main__: train step 13668: loss: 1.0002, policy_loss: 0.9578, value_loss: 0.6071
2024-07-11 16:59:39,427 [INFO    ] __main__: train step 13669: loss: 1.0002, policy_loss: 0.9577, value_loss: 0.6070
2024-07-11 16:59:39,637 [INFO    ] __main__: train step 13670: loss: 1.0002, policy_loss: 0.9577, value_loss: 0.6070
2024-07-11 16:59:39,865 [INFO    ] __main__: train step 13671: loss: 1.0002, policy_loss: 0.9577, value_loss: 0.6070
2024-07-11 16:59:40,089 [INFO    ] __main__: train step 13672: loss: 1.0002, policy_loss: 0.9577, value_loss: 0.6069
2024-07-11 16:59:40,292 [INFO    ] __main__: train step 13673: loss: 1.0002, policy_loss: 0.9577, value_loss: 0.6069
2024-07-11 16:59:40,495 [INFO    ] __main__: train step 13674: loss: 1.0002, policy_loss: 0.9576, value_loss: 0.6069
2024-07-11 16:59:40,701 [INFO    ] __main__: train step 13675: loss: 1.0002, policy_loss: 0.9576, value_loss: 0.6069
2024-07-11 16:59:40,904 [INFO    ] __main__: train step 13676: loss: 1.0002, policy_loss: 0.9576, value_loss: 0.6068
2024-07-11 16:59:41,116 [INFO    ] __main__: train step 13677: loss: 1.0002, policy_loss: 0.9576, value_loss: 0.6068
2024-07-11 16:59:41,318 [INFO    ] __main__: train step 13678: loss: 1.0002, policy_loss: 0.9576, value_loss: 0.6068
2024-07-11 16:59:41,542 [INFO    ] __main__: train step 13679: loss: 1.0002, policy_loss: 0.9575, value_loss: 0.6067
2024-07-11 16:59:41,764 [INFO    ] __main__: train step 13680: loss: 1.0002, policy_loss: 0.9575, value_loss: 0.6067
2024-07-11 16:59:41,972 [INFO    ] __main__: train step 13681: loss: 1.0001, policy_loss: 0.9575, value_loss: 0.6067
2024-07-11 16:59:42,180 [INFO    ] __main__: train step 13682: loss: 1.0001, policy_loss: 0.9575, value_loss: 0.6067
2024-07-11 16:59:42,394 [INFO    ] __main__: train step 13683: loss: 1.0001, policy_loss: 0.9574, value_loss: 0.6066
2024-07-11 16:59:42,586 [INFO    ] __main__: train step 13684: loss: 1.0001, policy_loss: 0.9574, value_loss: 0.6066
2024-07-11 16:59:44,029 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:59:44,434 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:59:44,491 [INFO    ] __main__: train step 13685: loss: 1.0001, policy_loss: 0.9574, value_loss: 0.6066
2024-07-11 16:59:44,668 [INFO    ] __main__: train step 13686: loss: 1.0001, policy_loss: 0.9574, value_loss: 0.6065
2024-07-11 16:59:44,875 [INFO    ] __main__: train step 13687: loss: 1.0001, policy_loss: 0.9574, value_loss: 0.6065
2024-07-11 16:59:45,078 [INFO    ] __main__: train step 13688: loss: 1.0001, policy_loss: 0.9573, value_loss: 0.6065
2024-07-11 16:59:45,280 [INFO    ] __main__: train step 13689: loss: 1.0001, policy_loss: 0.9573, value_loss: 0.6065
2024-07-11 16:59:45,486 [INFO    ] __main__: train step 13690: loss: 1.0001, policy_loss: 0.9573, value_loss: 0.6064
2024-07-11 16:59:45,684 [INFO    ] __main__: train step 13691: loss: 1.0001, policy_loss: 0.9573, value_loss: 0.6064
2024-07-11 16:59:45,895 [INFO    ] __main__: train step 13692: loss: 1.0001, policy_loss: 0.9573, value_loss: 0.6064
2024-07-11 16:59:46,089 [INFO    ] __main__: train step 13693: loss: 1.0001, policy_loss: 0.9572, value_loss: 0.6064
2024-07-11 16:59:46,298 [INFO    ] __main__: train step 13694: loss: 1.0001, policy_loss: 0.9572, value_loss: 0.6063
2024-07-11 16:59:46,507 [INFO    ] __main__: train step 13695: loss: 1.0000, policy_loss: 0.9572, value_loss: 0.6063
2024-07-11 16:59:46,696 [INFO    ] __main__: train step 13696: loss: 1.0000, policy_loss: 0.9572, value_loss: 0.6063
2024-07-11 16:59:46,901 [INFO    ] __main__: train step 13697: loss: 1.0000, policy_loss: 0.9572, value_loss: 0.6062
2024-07-11 16:59:48,545 [INFO    ] __main__: train step 13698: loss: 1.0000, policy_loss: 0.9571, value_loss: 0.6062
2024-07-11 16:59:48,755 [INFO    ] __main__: train step 13699: loss: 1.0000, policy_loss: 0.9571, value_loss: 0.6062
2024-07-11 16:59:48,948 [INFO    ] __main__: train step 13700: loss: 1.0000, policy_loss: 0.9571, value_loss: 0.6062
2024-07-11 16:59:49,153 [INFO    ] __main__: train step 13701: loss: 1.0000, policy_loss: 0.9571, value_loss: 0.6061
2024-07-11 16:59:50,602 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:59:50,997 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:59:51,055 [INFO    ] __main__: train step 13702: loss: 1.0000, policy_loss: 0.9571, value_loss: 0.6061
2024-07-11 16:59:51,243 [INFO    ] __main__: train step 13703: loss: 1.0000, policy_loss: 0.9570, value_loss: 0.6061
2024-07-11 16:59:51,481 [INFO    ] __main__: train step 13704: loss: 1.0000, policy_loss: 0.9570, value_loss: 0.6060
2024-07-11 16:59:51,700 [INFO    ] __main__: train step 13705: loss: 1.0000, policy_loss: 0.9570, value_loss: 0.6060
2024-07-11 16:59:51,904 [INFO    ] __main__: train step 13706: loss: 1.0000, policy_loss: 0.9570, value_loss: 0.6060
2024-07-11 16:59:52,105 [INFO    ] __main__: train step 13707: loss: 1.0000, policy_loss: 0.9570, value_loss: 0.6060
2024-07-11 16:59:52,322 [INFO    ] __main__: train step 13708: loss: 1.0000, policy_loss: 0.9569, value_loss: 0.6059
2024-07-11 16:59:52,534 [INFO    ] __main__: train step 13709: loss: 0.9999, policy_loss: 0.9569, value_loss: 0.6059
2024-07-11 16:59:52,741 [INFO    ] __main__: train step 13710: loss: 0.9999, policy_loss: 0.9569, value_loss: 0.6059
2024-07-11 16:59:52,954 [INFO    ] __main__: train step 13711: loss: 0.9999, policy_loss: 0.9569, value_loss: 0.6059
2024-07-11 16:59:53,157 [INFO    ] __main__: train step 13712: loss: 0.9999, policy_loss: 0.9569, value_loss: 0.6058
2024-07-11 16:59:53,367 [INFO    ] __main__: train step 13713: loss: 0.9999, policy_loss: 0.9568, value_loss: 0.6058
2024-07-11 16:59:53,595 [INFO    ] __main__: train step 13714: loss: 0.9999, policy_loss: 0.9568, value_loss: 0.6058
2024-07-11 16:59:53,832 [INFO    ] __main__: train step 13715: loss: 0.9999, policy_loss: 0.9568, value_loss: 0.6057
2024-07-11 16:59:54,037 [INFO    ] __main__: train step 13716: loss: 0.9999, policy_loss: 0.9568, value_loss: 0.6057
2024-07-11 16:59:54,240 [INFO    ] __main__: train step 13717: loss: 0.9999, policy_loss: 0.9568, value_loss: 0.6057
2024-07-11 16:59:54,443 [INFO    ] __main__: train step 13718: loss: 0.9999, policy_loss: 0.9567, value_loss: 0.6057
2024-07-11 16:59:55,887 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 16:59:56,426 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 16:59:56,486 [INFO    ] __main__: train step 13719: loss: 0.9999, policy_loss: 0.9567, value_loss: 0.6056
2024-07-11 16:59:56,682 [INFO    ] __main__: train step 13720: loss: 0.9999, policy_loss: 0.9567, value_loss: 0.6056
2024-07-11 16:59:56,920 [INFO    ] __main__: train step 13721: loss: 0.9999, policy_loss: 0.9567, value_loss: 0.6056
2024-07-11 16:59:57,131 [INFO    ] __main__: train step 13722: loss: 0.9999, policy_loss: 0.9567, value_loss: 0.6056
2024-07-11 16:59:57,321 [INFO    ] __main__: train step 13723: loss: 0.9999, policy_loss: 0.9566, value_loss: 0.6055
2024-07-11 16:59:57,521 [INFO    ] __main__: train step 13724: loss: 0.9998, policy_loss: 0.9566, value_loss: 0.6055
2024-07-11 16:59:57,731 [INFO    ] __main__: train step 13725: loss: 0.9998, policy_loss: 0.9566, value_loss: 0.6055
2024-07-11 16:59:57,941 [INFO    ] __main__: train step 13726: loss: 0.9998, policy_loss: 0.9566, value_loss: 0.6055
2024-07-11 16:59:58,164 [INFO    ] __main__: train step 13727: loss: 0.9998, policy_loss: 0.9565, value_loss: 0.6054
2024-07-11 16:59:58,372 [INFO    ] __main__: train step 13728: loss: 0.9998, policy_loss: 0.9565, value_loss: 0.6054
2024-07-11 16:59:58,581 [INFO    ] __main__: train step 13729: loss: 0.9998, policy_loss: 0.9565, value_loss: 0.6054
2024-07-11 16:59:58,783 [INFO    ] __main__: train step 13730: loss: 0.9998, policy_loss: 0.9565, value_loss: 0.6053
2024-07-11 16:59:58,989 [INFO    ] __main__: train step 13731: loss: 0.9998, policy_loss: 0.9565, value_loss: 0.6053
2024-07-11 16:59:59,204 [INFO    ] __main__: train step 13732: loss: 0.9998, policy_loss: 0.9564, value_loss: 0.6053
2024-07-11 16:59:59,413 [INFO    ] __main__: train step 13733: loss: 0.9998, policy_loss: 0.9564, value_loss: 0.6053
2024-07-11 16:59:59,626 [INFO    ] __main__: train step 13734: loss: 0.9998, policy_loss: 0.9564, value_loss: 0.6052
2024-07-11 16:59:59,863 [INFO    ] __main__: train step 13735: loss: 0.9998, policy_loss: 0.9564, value_loss: 0.6052
2024-07-11 17:00:01,299 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:00:01,697 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:00:01,753 [INFO    ] __main__: train step 13736: loss: 0.9998, policy_loss: 0.9564, value_loss: 0.6052
2024-07-11 17:00:01,937 [INFO    ] __main__: train step 13737: loss: 0.9998, policy_loss: 0.9563, value_loss: 0.6052
2024-07-11 17:00:02,167 [INFO    ] __main__: train step 13738: loss: 0.9998, policy_loss: 0.9563, value_loss: 0.6051
2024-07-11 17:00:02,370 [INFO    ] __main__: train step 13739: loss: 0.9997, policy_loss: 0.9563, value_loss: 0.6051
2024-07-11 17:00:02,584 [INFO    ] __main__: train step 13740: loss: 0.9997, policy_loss: 0.9563, value_loss: 0.6051
2024-07-11 17:00:02,835 [INFO    ] __main__: train step 13741: loss: 0.9997, policy_loss: 0.9563, value_loss: 0.6050
2024-07-11 17:00:03,065 [INFO    ] __main__: train step 13742: loss: 0.9997, policy_loss: 0.9562, value_loss: 0.6050
2024-07-11 17:00:03,267 [INFO    ] __main__: train step 13743: loss: 0.9997, policy_loss: 0.9562, value_loss: 0.6050
2024-07-11 17:00:03,470 [INFO    ] __main__: train step 13744: loss: 0.9997, policy_loss: 0.9562, value_loss: 0.6050
2024-07-11 17:00:03,675 [INFO    ] __main__: train step 13745: loss: 0.9997, policy_loss: 0.9562, value_loss: 0.6049
2024-07-11 17:00:03,885 [INFO    ] __main__: train step 13746: loss: 0.9997, policy_loss: 0.9562, value_loss: 0.6049
2024-07-11 17:00:04,083 [INFO    ] __main__: train step 13747: loss: 0.9997, policy_loss: 0.9561, value_loss: 0.6049
2024-07-11 17:00:04,294 [INFO    ] __main__: train step 13748: loss: 0.9997, policy_loss: 0.9561, value_loss: 0.6049
2024-07-11 17:00:04,489 [INFO    ] __main__: train step 13749: loss: 0.9997, policy_loss: 0.9561, value_loss: 0.6048
2024-07-11 17:00:04,695 [INFO    ] __main__: train step 13750: loss: 0.9997, policy_loss: 0.9561, value_loss: 0.6048
2024-07-11 17:00:04,899 [INFO    ] __main__: train step 13751: loss: 0.9997, policy_loss: 0.9561, value_loss: 0.6048
2024-07-11 17:00:05,104 [INFO    ] __main__: train step 13752: loss: 0.9997, policy_loss: 0.9560, value_loss: 0.6048
2024-07-11 17:00:06,552 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:00:06,930 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:00:06,992 [INFO    ] __main__: train step 13753: loss: 0.9997, policy_loss: 0.9560, value_loss: 0.6047
2024-07-11 17:00:07,171 [INFO    ] __main__: train step 13754: loss: 0.9997, policy_loss: 0.9560, value_loss: 0.6047
2024-07-11 17:00:07,388 [INFO    ] __main__: train step 13755: loss: 0.9996, policy_loss: 0.9560, value_loss: 0.6047
2024-07-11 17:00:07,619 [INFO    ] __main__: train step 13756: loss: 0.9996, policy_loss: 0.9560, value_loss: 0.6046
2024-07-11 17:00:07,824 [INFO    ] __main__: train step 13757: loss: 0.9996, policy_loss: 0.9559, value_loss: 0.6046
2024-07-11 17:00:08,020 [INFO    ] __main__: train step 13758: loss: 0.9996, policy_loss: 0.9559, value_loss: 0.6046
2024-07-11 17:00:08,232 [INFO    ] __main__: train step 13759: loss: 0.9996, policy_loss: 0.9559, value_loss: 0.6046
2024-07-11 17:00:08,441 [INFO    ] __main__: train step 13760: loss: 0.9996, policy_loss: 0.9559, value_loss: 0.6045
2024-07-11 17:00:08,656 [INFO    ] __main__: train step 13761: loss: 0.9996, policy_loss: 0.9559, value_loss: 0.6045
2024-07-11 17:00:08,896 [INFO    ] __main__: train step 13762: loss: 0.9996, policy_loss: 0.9558, value_loss: 0.6045
2024-07-11 17:00:09,139 [INFO    ] __main__: train step 13763: loss: 0.9996, policy_loss: 0.9558, value_loss: 0.6045
2024-07-11 17:00:09,342 [INFO    ] __main__: train step 13764: loss: 0.9996, policy_loss: 0.9558, value_loss: 0.6044
2024-07-11 17:00:09,556 [INFO    ] __main__: train step 13765: loss: 0.9996, policy_loss: 0.9558, value_loss: 0.6044
2024-07-11 17:00:09,783 [INFO    ] __main__: train step 13766: loss: 0.9996, policy_loss: 0.9558, value_loss: 0.6044
2024-07-11 17:00:09,990 [INFO    ] __main__: train step 13767: loss: 0.9996, policy_loss: 0.9557, value_loss: 0.6043
2024-07-11 17:00:10,183 [INFO    ] __main__: train step 13768: loss: 0.9996, policy_loss: 0.9557, value_loss: 0.6043
2024-07-11 17:00:10,380 [INFO    ] __main__: train step 13769: loss: 0.9996, policy_loss: 0.9557, value_loss: 0.6043
2024-07-11 17:00:11,809 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:00:12,217 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:00:12,272 [INFO    ] __main__: train step 13770: loss: 0.9995, policy_loss: 0.9557, value_loss: 0.6043
2024-07-11 17:00:12,448 [INFO    ] __main__: train step 13771: loss: 0.9995, policy_loss: 0.9557, value_loss: 0.6042
2024-07-11 17:00:12,655 [INFO    ] __main__: train step 13772: loss: 0.9995, policy_loss: 0.9556, value_loss: 0.6042
2024-07-11 17:00:12,861 [INFO    ] __main__: train step 13773: loss: 0.9995, policy_loss: 0.9556, value_loss: 0.6042
2024-07-11 17:00:13,064 [INFO    ] __main__: train step 13774: loss: 0.9995, policy_loss: 0.9556, value_loss: 0.6042
2024-07-11 17:00:13,272 [INFO    ] __main__: train step 13775: loss: 0.9995, policy_loss: 0.9556, value_loss: 0.6041
2024-07-11 17:00:13,481 [INFO    ] __main__: train step 13776: loss: 0.9995, policy_loss: 0.9556, value_loss: 0.6041
2024-07-11 17:00:13,682 [INFO    ] __main__: train step 13777: loss: 0.9995, policy_loss: 0.9555, value_loss: 0.6041
2024-07-11 17:00:13,883 [INFO    ] __main__: train step 13778: loss: 0.9995, policy_loss: 0.9555, value_loss: 0.6040
2024-07-11 17:00:14,092 [INFO    ] __main__: train step 13779: loss: 0.9995, policy_loss: 0.9555, value_loss: 0.6040
2024-07-11 17:00:14,304 [INFO    ] __main__: train step 13780: loss: 0.9995, policy_loss: 0.9555, value_loss: 0.6040
2024-07-11 17:00:14,554 [INFO    ] __main__: train step 13781: loss: 0.9995, policy_loss: 0.9554, value_loss: 0.6040
2024-07-11 17:00:14,786 [INFO    ] __main__: train step 13782: loss: 0.9995, policy_loss: 0.9554, value_loss: 0.6039
2024-07-11 17:00:15,007 [INFO    ] __main__: train step 13783: loss: 0.9995, policy_loss: 0.9554, value_loss: 0.6039
2024-07-11 17:00:15,242 [INFO    ] __main__: train step 13784: loss: 0.9995, policy_loss: 0.9554, value_loss: 0.6039
2024-07-11 17:00:15,470 [INFO    ] __main__: train step 13785: loss: 0.9994, policy_loss: 0.9554, value_loss: 0.6039
2024-07-11 17:00:15,709 [INFO    ] __main__: train step 13786: loss: 0.9994, policy_loss: 0.9554, value_loss: 0.6038
2024-07-11 17:00:17,145 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:00:17,554 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:00:17,612 [INFO    ] __main__: train step 13787: loss: 0.9994, policy_loss: 0.9553, value_loss: 0.6038
2024-07-11 17:00:17,791 [INFO    ] __main__: train step 13788: loss: 0.9994, policy_loss: 0.9553, value_loss: 0.6038
2024-07-11 17:00:18,003 [INFO    ] __main__: train step 13789: loss: 0.9994, policy_loss: 0.9553, value_loss: 0.6038
2024-07-11 17:00:18,240 [INFO    ] __main__: train step 13790: loss: 0.9994, policy_loss: 0.9553, value_loss: 0.6037
2024-07-11 17:00:18,451 [INFO    ] __main__: train step 13791: loss: 0.9994, policy_loss: 0.9553, value_loss: 0.6037
2024-07-11 17:00:18,683 [INFO    ] __main__: train step 13792: loss: 0.9994, policy_loss: 0.9552, value_loss: 0.6037
2024-07-11 17:00:18,886 [INFO    ] __main__: train step 13793: loss: 0.9994, policy_loss: 0.9552, value_loss: 0.6036
2024-07-11 17:00:19,097 [INFO    ] __main__: train step 13794: loss: 0.9994, policy_loss: 0.9552, value_loss: 0.6036
2024-07-11 17:00:19,293 [INFO    ] __main__: train step 13795: loss: 0.9994, policy_loss: 0.9552, value_loss: 0.6036
2024-07-11 17:00:19,509 [INFO    ] __main__: train step 13796: loss: 0.9994, policy_loss: 0.9552, value_loss: 0.6036
2024-07-11 17:00:21,165 [INFO    ] __main__: train step 13797: loss: 0.9994, policy_loss: 0.9551, value_loss: 0.6035
2024-07-11 17:00:21,379 [INFO    ] __main__: train step 13798: loss: 0.9994, policy_loss: 0.9551, value_loss: 0.6035
2024-07-11 17:00:21,586 [INFO    ] __main__: train step 13799: loss: 0.9994, policy_loss: 0.9551, value_loss: 0.6035
2024-07-11 17:00:21,813 [INFO    ] __main__: train step 13800: loss: 0.9994, policy_loss: 0.9551, value_loss: 0.6035
2024-07-11 17:00:22,026 [INFO    ] __main__: train step 13801: loss: 0.9994, policy_loss: 0.9550, value_loss: 0.6034
2024-07-11 17:00:22,233 [INFO    ] __main__: train step 13802: loss: 0.9993, policy_loss: 0.9550, value_loss: 0.6034
2024-07-11 17:00:22,428 [INFO    ] __main__: train step 13803: loss: 0.9993, policy_loss: 0.9550, value_loss: 0.6034
2024-07-11 17:00:23,859 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:00:24,260 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:00:24,318 [INFO    ] __main__: train step 13804: loss: 0.9993, policy_loss: 0.9550, value_loss: 0.6034
2024-07-11 17:00:24,504 [INFO    ] __main__: train step 13805: loss: 0.9993, policy_loss: 0.9550, value_loss: 0.6033
2024-07-11 17:00:24,731 [INFO    ] __main__: train step 13806: loss: 0.9993, policy_loss: 0.9549, value_loss: 0.6033
2024-07-11 17:00:24,945 [INFO    ] __main__: train step 13807: loss: 0.9993, policy_loss: 0.9549, value_loss: 0.6033
2024-07-11 17:00:25,174 [INFO    ] __main__: train step 13808: loss: 0.9993, policy_loss: 0.9549, value_loss: 0.6032
2024-07-11 17:00:25,371 [INFO    ] __main__: train step 13809: loss: 0.9993, policy_loss: 0.9549, value_loss: 0.6032
2024-07-11 17:00:25,577 [INFO    ] __main__: train step 13810: loss: 0.9993, policy_loss: 0.9549, value_loss: 0.6032
2024-07-11 17:00:25,787 [INFO    ] __main__: train step 13811: loss: 0.9993, policy_loss: 0.9548, value_loss: 0.6032
2024-07-11 17:00:26,014 [INFO    ] __main__: train step 13812: loss: 0.9993, policy_loss: 0.9548, value_loss: 0.6031
2024-07-11 17:00:26,223 [INFO    ] __main__: train step 13813: loss: 0.9993, policy_loss: 0.9548, value_loss: 0.6031
2024-07-11 17:00:26,433 [INFO    ] __main__: train step 13814: loss: 0.9993, policy_loss: 0.9548, value_loss: 0.6031
2024-07-11 17:00:26,685 [INFO    ] __main__: train step 13815: loss: 0.9993, policy_loss: 0.9548, value_loss: 0.6031
2024-07-11 17:00:26,924 [INFO    ] __main__: train step 13816: loss: 0.9993, policy_loss: 0.9547, value_loss: 0.6030
2024-07-11 17:00:27,160 [INFO    ] __main__: train step 13817: loss: 0.9993, policy_loss: 0.9547, value_loss: 0.6030
2024-07-11 17:00:27,357 [INFO    ] __main__: train step 13818: loss: 0.9992, policy_loss: 0.9547, value_loss: 0.6030
2024-07-11 17:00:27,575 [INFO    ] __main__: train step 13819: loss: 0.9992, policy_loss: 0.9547, value_loss: 0.6030
2024-07-11 17:00:27,807 [INFO    ] __main__: train step 13820: loss: 0.9992, policy_loss: 0.9547, value_loss: 0.6029
2024-07-11 17:00:29,237 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:00:29,619 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:00:29,674 [INFO    ] __main__: train step 13821: loss: 0.9992, policy_loss: 0.9547, value_loss: 0.6029
2024-07-11 17:00:29,857 [INFO    ] __main__: train step 13822: loss: 0.9992, policy_loss: 0.9546, value_loss: 0.6029
2024-07-11 17:00:30,077 [INFO    ] __main__: train step 13823: loss: 0.9992, policy_loss: 0.9546, value_loss: 0.6028
2024-07-11 17:00:30,279 [INFO    ] __main__: train step 13824: loss: 0.9992, policy_loss: 0.9546, value_loss: 0.6028
2024-07-11 17:00:30,475 [INFO    ] __main__: train step 13825: loss: 0.9992, policy_loss: 0.9546, value_loss: 0.6028
2024-07-11 17:00:30,674 [INFO    ] __main__: train step 13826: loss: 0.9992, policy_loss: 0.9545, value_loss: 0.6028
2024-07-11 17:00:30,883 [INFO    ] __main__: train step 13827: loss: 0.9992, policy_loss: 0.9545, value_loss: 0.6027
2024-07-11 17:00:31,087 [INFO    ] __main__: train step 13828: loss: 0.9992, policy_loss: 0.9545, value_loss: 0.6027
2024-07-11 17:00:31,292 [INFO    ] __main__: train step 13829: loss: 0.9992, policy_loss: 0.9545, value_loss: 0.6027
2024-07-11 17:00:31,501 [INFO    ] __main__: train step 13830: loss: 0.9992, policy_loss: 0.9545, value_loss: 0.6027
2024-07-11 17:00:31,719 [INFO    ] __main__: train step 13831: loss: 0.9992, policy_loss: 0.9544, value_loss: 0.6026
2024-07-11 17:00:31,922 [INFO    ] __main__: train step 13832: loss: 0.9992, policy_loss: 0.9544, value_loss: 0.6026
2024-07-11 17:00:32,133 [INFO    ] __main__: train step 13833: loss: 0.9992, policy_loss: 0.9544, value_loss: 0.6026
2024-07-11 17:00:32,349 [INFO    ] __main__: train step 13834: loss: 0.9991, policy_loss: 0.9544, value_loss: 0.6026
2024-07-11 17:00:32,583 [INFO    ] __main__: train step 13835: loss: 0.9991, policy_loss: 0.9544, value_loss: 0.6025
2024-07-11 17:00:32,833 [INFO    ] __main__: train step 13836: loss: 0.9991, policy_loss: 0.9543, value_loss: 0.6025
2024-07-11 17:00:33,033 [INFO    ] __main__: train step 13837: loss: 0.9991, policy_loss: 0.9543, value_loss: 0.6025
2024-07-11 17:00:34,474 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:00:34,929 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:00:34,990 [INFO    ] __main__: train step 13838: loss: 0.9991, policy_loss: 0.9543, value_loss: 0.6025
2024-07-11 17:00:35,177 [INFO    ] __main__: train step 13839: loss: 0.9991, policy_loss: 0.9543, value_loss: 0.6024
2024-07-11 17:00:35,382 [INFO    ] __main__: train step 13840: loss: 0.9991, policy_loss: 0.9543, value_loss: 0.6024
2024-07-11 17:00:35,600 [INFO    ] __main__: train step 13841: loss: 0.9991, policy_loss: 0.9542, value_loss: 0.6024
2024-07-11 17:00:35,832 [INFO    ] __main__: train step 13842: loss: 0.9991, policy_loss: 0.9542, value_loss: 0.6024
2024-07-11 17:00:36,026 [INFO    ] __main__: train step 13843: loss: 0.9991, policy_loss: 0.9542, value_loss: 0.6023
2024-07-11 17:00:36,231 [INFO    ] __main__: train step 13844: loss: 0.9991, policy_loss: 0.9542, value_loss: 0.6023
2024-07-11 17:00:36,438 [INFO    ] __main__: train step 13845: loss: 0.9991, policy_loss: 0.9542, value_loss: 0.6023
2024-07-11 17:00:36,683 [INFO    ] __main__: train step 13846: loss: 0.9991, policy_loss: 0.9541, value_loss: 0.6023
2024-07-11 17:00:36,897 [INFO    ] __main__: train step 13847: loss: 0.9991, policy_loss: 0.9541, value_loss: 0.6022
2024-07-11 17:00:37,096 [INFO    ] __main__: train step 13848: loss: 0.9991, policy_loss: 0.9541, value_loss: 0.6022
2024-07-11 17:00:37,308 [INFO    ] __main__: train step 13849: loss: 0.9991, policy_loss: 0.9541, value_loss: 0.6022
2024-07-11 17:00:37,517 [INFO    ] __main__: train step 13850: loss: 0.9991, policy_loss: 0.9541, value_loss: 0.6021
2024-07-11 17:00:37,739 [INFO    ] __main__: train step 13851: loss: 0.9990, policy_loss: 0.9540, value_loss: 0.6021
2024-07-11 17:00:37,968 [INFO    ] __main__: train step 13852: loss: 0.9990, policy_loss: 0.9540, value_loss: 0.6021
2024-07-11 17:00:38,188 [INFO    ] __main__: train step 13853: loss: 0.9990, policy_loss: 0.9540, value_loss: 0.6021
2024-07-11 17:00:38,416 [INFO    ] __main__: train step 13854: loss: 0.9990, policy_loss: 0.9540, value_loss: 0.6020
2024-07-11 17:00:39,859 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:00:40,246 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:00:40,301 [INFO    ] __main__: train step 13855: loss: 0.9990, policy_loss: 0.9540, value_loss: 0.6020
2024-07-11 17:00:40,485 [INFO    ] __main__: train step 13856: loss: 0.9990, policy_loss: 0.9539, value_loss: 0.6020
2024-07-11 17:00:40,719 [INFO    ] __main__: train step 13857: loss: 0.9990, policy_loss: 0.9539, value_loss: 0.6020
2024-07-11 17:00:40,917 [INFO    ] __main__: train step 13858: loss: 0.9990, policy_loss: 0.9539, value_loss: 0.6019
2024-07-11 17:00:41,121 [INFO    ] __main__: train step 13859: loss: 0.9990, policy_loss: 0.9539, value_loss: 0.6019
2024-07-11 17:00:41,336 [INFO    ] __main__: train step 13860: loss: 0.9990, policy_loss: 0.9539, value_loss: 0.6019
2024-07-11 17:00:41,544 [INFO    ] __main__: train step 13861: loss: 0.9990, policy_loss: 0.9538, value_loss: 0.6019
2024-07-11 17:00:41,785 [INFO    ] __main__: train step 13862: loss: 0.9990, policy_loss: 0.9538, value_loss: 0.6018
2024-07-11 17:00:42,005 [INFO    ] __main__: train step 13863: loss: 0.9990, policy_loss: 0.9538, value_loss: 0.6018
2024-07-11 17:00:42,233 [INFO    ] __main__: train step 13864: loss: 0.9990, policy_loss: 0.9538, value_loss: 0.6018
2024-07-11 17:00:42,426 [INFO    ] __main__: train step 13865: loss: 0.9990, policy_loss: 0.9538, value_loss: 0.6018
2024-07-11 17:00:42,666 [INFO    ] __main__: train step 13866: loss: 0.9990, policy_loss: 0.9537, value_loss: 0.6017
2024-07-11 17:00:42,875 [INFO    ] __main__: train step 13867: loss: 0.9990, policy_loss: 0.9537, value_loss: 0.6017
2024-07-11 17:00:43,076 [INFO    ] __main__: train step 13868: loss: 0.9990, policy_loss: 0.9537, value_loss: 0.6017
2024-07-11 17:00:43,273 [INFO    ] __main__: train step 13869: loss: 0.9989, policy_loss: 0.9537, value_loss: 0.6017
2024-07-11 17:00:43,481 [INFO    ] __main__: train step 13870: loss: 0.9989, policy_loss: 0.9537, value_loss: 0.6016
2024-07-11 17:00:43,695 [INFO    ] __main__: train step 13871: loss: 0.9989, policy_loss: 0.9536, value_loss: 0.6016
2024-07-11 17:00:45,114 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:00:45,512 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:00:45,567 [INFO    ] __main__: train step 13872: loss: 0.9989, policy_loss: 0.9536, value_loss: 0.6016
2024-07-11 17:00:45,744 [INFO    ] __main__: train step 13873: loss: 0.9989, policy_loss: 0.9536, value_loss: 0.6015
2024-07-11 17:00:45,949 [INFO    ] __main__: train step 13874: loss: 0.9989, policy_loss: 0.9536, value_loss: 0.6015
2024-07-11 17:00:46,164 [INFO    ] __main__: train step 13875: loss: 0.9989, policy_loss: 0.9536, value_loss: 0.6015
2024-07-11 17:00:46,371 [INFO    ] __main__: train step 13876: loss: 0.9989, policy_loss: 0.9535, value_loss: 0.6015
2024-07-11 17:00:46,574 [INFO    ] __main__: train step 13877: loss: 0.9989, policy_loss: 0.9535, value_loss: 0.6014
2024-07-11 17:00:46,775 [INFO    ] __main__: train step 13878: loss: 0.9989, policy_loss: 0.9535, value_loss: 0.6014
2024-07-11 17:00:46,990 [INFO    ] __main__: train step 13879: loss: 0.9989, policy_loss: 0.9535, value_loss: 0.6014
2024-07-11 17:00:47,217 [INFO    ] __main__: train step 13880: loss: 0.9989, policy_loss: 0.9535, value_loss: 0.6014
2024-07-11 17:00:47,455 [INFO    ] __main__: train step 13881: loss: 0.9989, policy_loss: 0.9534, value_loss: 0.6013
2024-07-11 17:00:47,677 [INFO    ] __main__: train step 13882: loss: 0.9989, policy_loss: 0.9534, value_loss: 0.6013
2024-07-11 17:00:47,918 [INFO    ] __main__: train step 13883: loss: 0.9989, policy_loss: 0.9534, value_loss: 0.6013
2024-07-11 17:00:48,116 [INFO    ] __main__: train step 13884: loss: 0.9989, policy_loss: 0.9534, value_loss: 0.6013
2024-07-11 17:00:48,325 [INFO    ] __main__: train step 13885: loss: 0.9988, policy_loss: 0.9534, value_loss: 0.6012
2024-07-11 17:00:48,522 [INFO    ] __main__: train step 13886: loss: 0.9988, policy_loss: 0.9533, value_loss: 0.6012
2024-07-11 17:00:48,730 [INFO    ] __main__: train step 13887: loss: 0.9988, policy_loss: 0.9533, value_loss: 0.6012
2024-07-11 17:00:48,939 [INFO    ] __main__: train step 13888: loss: 0.9988, policy_loss: 0.9533, value_loss: 0.6012
2024-07-11 17:00:50,354 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:00:50,792 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:00:50,857 [INFO    ] __main__: train step 13889: loss: 0.9988, policy_loss: 0.9533, value_loss: 0.6011
2024-07-11 17:00:51,033 [INFO    ] __main__: train step 13890: loss: 0.9988, policy_loss: 0.9533, value_loss: 0.6011
2024-07-11 17:00:51,234 [INFO    ] __main__: train step 13891: loss: 0.9988, policy_loss: 0.9532, value_loss: 0.6011
2024-07-11 17:00:51,446 [INFO    ] __main__: train step 13892: loss: 0.9988, policy_loss: 0.9532, value_loss: 0.6011
2024-07-11 17:00:51,666 [INFO    ] __main__: train step 13893: loss: 0.9988, policy_loss: 0.9532, value_loss: 0.6010
2024-07-11 17:00:51,861 [INFO    ] __main__: train step 13894: loss: 0.9988, policy_loss: 0.9532, value_loss: 0.6010
2024-07-11 17:00:52,065 [INFO    ] __main__: train step 13895: loss: 0.9988, policy_loss: 0.9532, value_loss: 0.6010
2024-07-11 17:00:53,700 [INFO    ] __main__: train step 13896: loss: 0.9988, policy_loss: 0.9531, value_loss: 0.6010
2024-07-11 17:00:53,951 [INFO    ] __main__: train step 13897: loss: 0.9988, policy_loss: 0.9531, value_loss: 0.6009
2024-07-11 17:00:54,176 [INFO    ] __main__: train step 13898: loss: 0.9988, policy_loss: 0.9531, value_loss: 0.6009
2024-07-11 17:00:54,377 [INFO    ] __main__: train step 13899: loss: 0.9988, policy_loss: 0.9531, value_loss: 0.6009
2024-07-11 17:00:54,591 [INFO    ] __main__: train step 13900: loss: 0.9987, policy_loss: 0.9530, value_loss: 0.6008
2024-07-11 17:00:54,795 [INFO    ] __main__: train step 13901: loss: 0.9987, policy_loss: 0.9530, value_loss: 0.6008
2024-07-11 17:00:55,010 [INFO    ] __main__: train step 13902: loss: 0.9987, policy_loss: 0.9530, value_loss: 0.6008
2024-07-11 17:00:55,209 [INFO    ] __main__: train step 13903: loss: 0.9987, policy_loss: 0.9530, value_loss: 0.6008
2024-07-11 17:00:55,420 [INFO    ] __main__: train step 13904: loss: 0.9987, policy_loss: 0.9530, value_loss: 0.6007
2024-07-11 17:00:55,623 [INFO    ] __main__: train step 13905: loss: 0.9987, policy_loss: 0.9529, value_loss: 0.6007
2024-07-11 17:00:57,061 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:00:57,442 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:00:57,501 [INFO    ] __main__: train step 13906: loss: 0.9987, policy_loss: 0.9529, value_loss: 0.6007
2024-07-11 17:00:57,688 [INFO    ] __main__: train step 13907: loss: 0.9987, policy_loss: 0.9529, value_loss: 0.6007
2024-07-11 17:00:57,915 [INFO    ] __main__: train step 13908: loss: 0.9987, policy_loss: 0.9529, value_loss: 0.6006
2024-07-11 17:00:58,129 [INFO    ] __main__: train step 13909: loss: 0.9987, policy_loss: 0.9529, value_loss: 0.6006
2024-07-11 17:00:58,329 [INFO    ] __main__: train step 13910: loss: 0.9987, policy_loss: 0.9528, value_loss: 0.6006
2024-07-11 17:00:58,536 [INFO    ] __main__: train step 13911: loss: 0.9987, policy_loss: 0.9528, value_loss: 0.6006
2024-07-11 17:00:58,749 [INFO    ] __main__: train step 13912: loss: 0.9987, policy_loss: 0.9528, value_loss: 0.6005
2024-07-11 17:00:58,982 [INFO    ] __main__: train step 13913: loss: 0.9987, policy_loss: 0.9528, value_loss: 0.6005
2024-07-11 17:00:59,194 [INFO    ] __main__: train step 13914: loss: 0.9987, policy_loss: 0.9528, value_loss: 0.6005
2024-07-11 17:00:59,429 [INFO    ] __main__: train step 13915: loss: 0.9986, policy_loss: 0.9527, value_loss: 0.6005
2024-07-11 17:00:59,652 [INFO    ] __main__: train step 13916: loss: 0.9986, policy_loss: 0.9527, value_loss: 0.6004
2024-07-11 17:00:59,874 [INFO    ] __main__: train step 13917: loss: 0.9986, policy_loss: 0.9527, value_loss: 0.6004
2024-07-11 17:01:00,077 [INFO    ] __main__: train step 13918: loss: 0.9986, policy_loss: 0.9527, value_loss: 0.6004
2024-07-11 17:01:00,278 [INFO    ] __main__: train step 13919: loss: 0.9986, policy_loss: 0.9527, value_loss: 0.6004
2024-07-11 17:01:00,475 [INFO    ] __main__: train step 13920: loss: 0.9986, policy_loss: 0.9526, value_loss: 0.6003
2024-07-11 17:01:00,673 [INFO    ] __main__: train step 13921: loss: 0.9986, policy_loss: 0.9526, value_loss: 0.6003
2024-07-11 17:01:00,891 [INFO    ] __main__: train step 13922: loss: 0.9986, policy_loss: 0.9526, value_loss: 0.6003
2024-07-11 17:01:02,360 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:01:02,805 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:01:02,869 [INFO    ] __main__: train step 13923: loss: 0.9986, policy_loss: 0.9526, value_loss: 0.6003
2024-07-11 17:01:03,046 [INFO    ] __main__: train step 13924: loss: 0.9986, policy_loss: 0.9525, value_loss: 0.6002
2024-07-11 17:01:03,255 [INFO    ] __main__: train step 13925: loss: 0.9986, policy_loss: 0.9525, value_loss: 0.6002
2024-07-11 17:01:03,471 [INFO    ] __main__: train step 13926: loss: 0.9986, policy_loss: 0.9525, value_loss: 0.6002
2024-07-11 17:01:03,671 [INFO    ] __main__: train step 13927: loss: 0.9986, policy_loss: 0.9525, value_loss: 0.6001
2024-07-11 17:01:03,893 [INFO    ] __main__: train step 13928: loss: 0.9986, policy_loss: 0.9525, value_loss: 0.6001
2024-07-11 17:01:04,129 [INFO    ] __main__: train step 13929: loss: 0.9986, policy_loss: 0.9524, value_loss: 0.6001
2024-07-11 17:01:04,360 [INFO    ] __main__: train step 13930: loss: 0.9985, policy_loss: 0.9524, value_loss: 0.6001
2024-07-11 17:01:04,564 [INFO    ] __main__: train step 13931: loss: 0.9985, policy_loss: 0.9524, value_loss: 0.6000
2024-07-11 17:01:04,773 [INFO    ] __main__: train step 13932: loss: 0.9985, policy_loss: 0.9524, value_loss: 0.6000
2024-07-11 17:01:05,002 [INFO    ] __main__: train step 13933: loss: 0.9985, policy_loss: 0.9524, value_loss: 0.6000
2024-07-11 17:01:05,224 [INFO    ] __main__: train step 13934: loss: 0.9985, policy_loss: 0.9523, value_loss: 0.6000
2024-07-11 17:01:05,436 [INFO    ] __main__: train step 13935: loss: 0.9985, policy_loss: 0.9523, value_loss: 0.5999
2024-07-11 17:01:05,668 [INFO    ] __main__: train step 13936: loss: 0.9985, policy_loss: 0.9523, value_loss: 0.5999
2024-07-11 17:01:05,885 [INFO    ] __main__: train step 13937: loss: 0.9985, policy_loss: 0.9523, value_loss: 0.5999
2024-07-11 17:01:06,141 [INFO    ] __main__: train step 13938: loss: 0.9985, policy_loss: 0.9523, value_loss: 0.5999
2024-07-11 17:01:06,370 [INFO    ] __main__: train step 13939: loss: 0.9985, policy_loss: 0.9522, value_loss: 0.5998
2024-07-11 17:01:07,807 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:01:08,238 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:01:08,300 [INFO    ] __main__: train step 13940: loss: 0.9985, policy_loss: 0.9522, value_loss: 0.5998
2024-07-11 17:01:08,477 [INFO    ] __main__: train step 13941: loss: 0.9985, policy_loss: 0.9522, value_loss: 0.5998
2024-07-11 17:01:08,714 [INFO    ] __main__: train step 13942: loss: 0.9985, policy_loss: 0.9522, value_loss: 0.5998
2024-07-11 17:01:08,913 [INFO    ] __main__: train step 13943: loss: 0.9985, policy_loss: 0.9522, value_loss: 0.5997
2024-07-11 17:01:09,123 [INFO    ] __main__: train step 13944: loss: 0.9985, policy_loss: 0.9521, value_loss: 0.5997
2024-07-11 17:01:09,335 [INFO    ] __main__: train step 13945: loss: 0.9984, policy_loss: 0.9521, value_loss: 0.5997
2024-07-11 17:01:09,564 [INFO    ] __main__: train step 13946: loss: 0.9984, policy_loss: 0.9521, value_loss: 0.5997
2024-07-11 17:01:09,769 [INFO    ] __main__: train step 13947: loss: 0.9984, policy_loss: 0.9521, value_loss: 0.5996
2024-07-11 17:01:09,977 [INFO    ] __main__: train step 13948: loss: 0.9984, policy_loss: 0.9521, value_loss: 0.5996
2024-07-11 17:01:10,182 [INFO    ] __main__: train step 13949: loss: 0.9984, policy_loss: 0.9520, value_loss: 0.5996
2024-07-11 17:01:10,383 [INFO    ] __main__: train step 13950: loss: 0.9984, policy_loss: 0.9520, value_loss: 0.5996
2024-07-11 17:01:10,601 [INFO    ] __main__: train step 13951: loss: 0.9984, policy_loss: 0.9520, value_loss: 0.5995
2024-07-11 17:01:10,817 [INFO    ] __main__: train step 13952: loss: 0.9984, policy_loss: 0.9520, value_loss: 0.5995
2024-07-11 17:01:11,057 [INFO    ] __main__: train step 13953: loss: 0.9984, policy_loss: 0.9519, value_loss: 0.5995
2024-07-11 17:01:11,299 [INFO    ] __main__: train step 13954: loss: 0.9984, policy_loss: 0.9519, value_loss: 0.5995
2024-07-11 17:01:11,519 [INFO    ] __main__: train step 13955: loss: 0.9984, policy_loss: 0.9519, value_loss: 0.5994
2024-07-11 17:01:11,753 [INFO    ] __main__: train step 13956: loss: 0.9984, policy_loss: 0.9519, value_loss: 0.5994
2024-07-11 17:01:13,195 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:01:13,609 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:01:13,666 [INFO    ] __main__: train step 13957: loss: 0.9984, policy_loss: 0.9519, value_loss: 0.5994
2024-07-11 17:01:13,850 [INFO    ] __main__: train step 13958: loss: 0.9984, policy_loss: 0.9518, value_loss: 0.5994
2024-07-11 17:01:14,057 [INFO    ] __main__: train step 13959: loss: 0.9984, policy_loss: 0.9518, value_loss: 0.5993
2024-07-11 17:01:14,289 [INFO    ] __main__: train step 13960: loss: 0.9983, policy_loss: 0.9518, value_loss: 0.5993
2024-07-11 17:01:14,514 [INFO    ] __main__: train step 13961: loss: 0.9983, policy_loss: 0.9518, value_loss: 0.5993
2024-07-11 17:01:14,724 [INFO    ] __main__: train step 13962: loss: 0.9983, policy_loss: 0.9518, value_loss: 0.5993
2024-07-11 17:01:14,935 [INFO    ] __main__: train step 13963: loss: 0.9983, policy_loss: 0.9517, value_loss: 0.5992
2024-07-11 17:01:15,160 [INFO    ] __main__: train step 13964: loss: 0.9983, policy_loss: 0.9517, value_loss: 0.5992
2024-07-11 17:01:15,407 [INFO    ] __main__: train step 13965: loss: 0.9983, policy_loss: 0.9517, value_loss: 0.5992
2024-07-11 17:01:15,626 [INFO    ] __main__: train step 13966: loss: 0.9983, policy_loss: 0.9517, value_loss: 0.5992
2024-07-11 17:01:15,837 [INFO    ] __main__: train step 13967: loss: 0.9983, policy_loss: 0.9517, value_loss: 0.5991
2024-07-11 17:01:16,033 [INFO    ] __main__: train step 13968: loss: 0.9983, policy_loss: 0.9516, value_loss: 0.5991
2024-07-11 17:01:16,254 [INFO    ] __main__: train step 13969: loss: 0.9983, policy_loss: 0.9516, value_loss: 0.5991
2024-07-11 17:01:16,479 [INFO    ] __main__: train step 13970: loss: 0.9983, policy_loss: 0.9516, value_loss: 0.5990
2024-07-11 17:01:16,696 [INFO    ] __main__: train step 13971: loss: 0.9983, policy_loss: 0.9516, value_loss: 0.5990
2024-07-11 17:01:16,969 [INFO    ] __main__: train step 13972: loss: 0.9983, policy_loss: 0.9516, value_loss: 0.5990
2024-07-11 17:01:17,199 [INFO    ] __main__: train step 13973: loss: 0.9983, policy_loss: 0.9515, value_loss: 0.5990
2024-07-11 17:01:18,669 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:01:19,068 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:01:19,125 [INFO    ] __main__: train step 13974: loss: 0.9983, policy_loss: 0.9515, value_loss: 0.5989
2024-07-11 17:01:19,305 [INFO    ] __main__: train step 13975: loss: 0.9983, policy_loss: 0.9515, value_loss: 0.5989
2024-07-11 17:01:19,523 [INFO    ] __main__: train step 13976: loss: 0.9982, policy_loss: 0.9515, value_loss: 0.5989
2024-07-11 17:01:19,764 [INFO    ] __main__: train step 13977: loss: 0.9982, policy_loss: 0.9515, value_loss: 0.5989
2024-07-11 17:01:19,997 [INFO    ] __main__: train step 13978: loss: 0.9982, policy_loss: 0.9514, value_loss: 0.5988
2024-07-11 17:01:20,208 [INFO    ] __main__: train step 13979: loss: 0.9982, policy_loss: 0.9514, value_loss: 0.5988
2024-07-11 17:01:20,412 [INFO    ] __main__: train step 13980: loss: 0.9982, policy_loss: 0.9514, value_loss: 0.5988
2024-07-11 17:01:20,633 [INFO    ] __main__: train step 13981: loss: 0.9982, policy_loss: 0.9514, value_loss: 0.5988
2024-07-11 17:01:20,879 [INFO    ] __main__: train step 13982: loss: 0.9982, policy_loss: 0.9514, value_loss: 0.5987
2024-07-11 17:01:21,125 [INFO    ] __main__: train step 13983: loss: 0.9982, policy_loss: 0.9513, value_loss: 0.5987
2024-07-11 17:01:21,363 [INFO    ] __main__: train step 13984: loss: 0.9982, policy_loss: 0.9513, value_loss: 0.5987
2024-07-11 17:01:21,563 [INFO    ] __main__: train step 13985: loss: 0.9982, policy_loss: 0.9513, value_loss: 0.5987
2024-07-11 17:01:21,773 [INFO    ] __main__: train step 13986: loss: 0.9982, policy_loss: 0.9513, value_loss: 0.5986
2024-07-11 17:01:21,981 [INFO    ] __main__: train step 13987: loss: 0.9982, policy_loss: 0.9513, value_loss: 0.5986
2024-07-11 17:01:22,190 [INFO    ] __main__: train step 13988: loss: 0.9982, policy_loss: 0.9512, value_loss: 0.5986
2024-07-11 17:01:22,396 [INFO    ] __main__: train step 13989: loss: 0.9981, policy_loss: 0.9512, value_loss: 0.5986
2024-07-11 17:01:22,594 [INFO    ] __main__: train step 13990: loss: 0.9981, policy_loss: 0.9512, value_loss: 0.5985
2024-07-11 17:01:24,014 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:01:24,435 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:01:24,494 [INFO    ] __main__: train step 13991: loss: 0.9981, policy_loss: 0.9512, value_loss: 0.5985
2024-07-11 17:01:24,672 [INFO    ] __main__: train step 13992: loss: 0.9981, policy_loss: 0.9511, value_loss: 0.5985
2024-07-11 17:01:24,870 [INFO    ] __main__: train step 13993: loss: 0.9981, policy_loss: 0.9511, value_loss: 0.5985
2024-07-11 17:01:25,072 [INFO    ] __main__: train step 13994: loss: 0.9981, policy_loss: 0.9511, value_loss: 0.5984
2024-07-11 17:01:26,631 [INFO    ] __main__: train step 13995: loss: 0.9981, policy_loss: 0.9511, value_loss: 0.5984
2024-07-11 17:01:26,833 [INFO    ] __main__: train step 13996: loss: 0.9981, policy_loss: 0.9511, value_loss: 0.5984
2024-07-11 17:01:27,070 [INFO    ] __main__: train step 13997: loss: 0.9981, policy_loss: 0.9510, value_loss: 0.5983
2024-07-11 17:01:27,300 [INFO    ] __main__: train step 13998: loss: 0.9981, policy_loss: 0.9510, value_loss: 0.5983
2024-07-11 17:01:27,535 [INFO    ] __main__: train step 13999: loss: 0.9981, policy_loss: 0.9510, value_loss: 0.5983
2024-07-11 17:01:27,738 [INFO    ] __main__: train step 14000: loss: 0.9981, policy_loss: 0.9510, value_loss: 0.5983
2024-07-11 17:01:27,865 [INFO    ] __main__: restored step 13000 for evaluation
2024-07-11 17:01:35,248 [INFO    ] __main__: later network ELO difference from earlier network: +108 (+8/-8) ELO from 32000 self-played games
2024-07-11 17:01:35,249 [INFO    ] __main__: game outcomes: W: 19808, D: 432, L: 11760
2024-07-11 17:01:35,251 [INFO    ] __main__: validation_elo_delta: 108, validation_elo: 2382
2024-07-11 17:01:35,804 [INFO    ] __main__: train step 14001: loss: 0.9981, policy_loss: 0.9510, value_loss: 0.5982
2024-07-11 17:01:36,042 [INFO    ] __main__: train step 14002: loss: 0.9981, policy_loss: 0.9509, value_loss: 0.5982
2024-07-11 17:01:36,279 [INFO    ] __main__: train step 14003: loss: 0.9980, policy_loss: 0.9509, value_loss: 0.5982
2024-07-11 17:01:36,473 [INFO    ] __main__: train step 14004: loss: 0.9980, policy_loss: 0.9509, value_loss: 0.5982
2024-07-11 17:01:36,684 [INFO    ] __main__: train step 14005: loss: 0.9980, policy_loss: 0.9509, value_loss: 0.5981
2024-07-11 17:01:36,915 [INFO    ] __main__: train step 14006: loss: 0.9980, policy_loss: 0.9509, value_loss: 0.5981
2024-07-11 17:01:37,123 [INFO    ] __main__: train step 14007: loss: 0.9980, policy_loss: 0.9508, value_loss: 0.5981
2024-07-11 17:01:38,567 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:01:38,993 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:01:39,049 [INFO    ] __main__: train step 14008: loss: 0.9980, policy_loss: 0.9508, value_loss: 0.5981
2024-07-11 17:01:39,224 [INFO    ] __main__: train step 14009: loss: 0.9980, policy_loss: 0.9508, value_loss: 0.5980
2024-07-11 17:01:39,432 [INFO    ] __main__: train step 14010: loss: 0.9980, policy_loss: 0.9508, value_loss: 0.5980
2024-07-11 17:01:39,673 [INFO    ] __main__: train step 14011: loss: 0.9980, policy_loss: 0.9508, value_loss: 0.5980
2024-07-11 17:01:39,874 [INFO    ] __main__: train step 14012: loss: 0.9980, policy_loss: 0.9507, value_loss: 0.5980
2024-07-11 17:01:40,076 [INFO    ] __main__: train step 14013: loss: 0.9980, policy_loss: 0.9507, value_loss: 0.5979
2024-07-11 17:01:40,287 [INFO    ] __main__: train step 14014: loss: 0.9980, policy_loss: 0.9507, value_loss: 0.5979
2024-07-11 17:01:40,493 [INFO    ] __main__: train step 14015: loss: 0.9980, policy_loss: 0.9507, value_loss: 0.5979
2024-07-11 17:01:40,702 [INFO    ] __main__: train step 14016: loss: 0.9980, policy_loss: 0.9507, value_loss: 0.5979
2024-07-11 17:01:40,905 [INFO    ] __main__: train step 14017: loss: 0.9980, policy_loss: 0.9506, value_loss: 0.5978
2024-07-11 17:01:41,110 [INFO    ] __main__: train step 14018: loss: 0.9979, policy_loss: 0.9506, value_loss: 0.5978
2024-07-11 17:01:41,314 [INFO    ] __main__: train step 14019: loss: 0.9979, policy_loss: 0.9506, value_loss: 0.5978
2024-07-11 17:01:41,537 [INFO    ] __main__: train step 14020: loss: 0.9979, policy_loss: 0.9506, value_loss: 0.5978
2024-07-11 17:01:41,730 [INFO    ] __main__: train step 14021: loss: 0.9979, policy_loss: 0.9506, value_loss: 0.5977
2024-07-11 17:01:41,932 [INFO    ] __main__: train step 14022: loss: 0.9979, policy_loss: 0.9505, value_loss: 0.5977
2024-07-11 17:01:42,146 [INFO    ] __main__: train step 14023: loss: 0.9979, policy_loss: 0.9505, value_loss: 0.5977
2024-07-11 17:01:42,356 [INFO    ] __main__: train step 14024: loss: 0.9979, policy_loss: 0.9505, value_loss: 0.5977
2024-07-11 17:01:43,786 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:01:44,208 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:01:44,267 [INFO    ] __main__: train step 14025: loss: 0.9979, policy_loss: 0.9505, value_loss: 0.5976
2024-07-11 17:01:44,468 [INFO    ] __main__: train step 14026: loss: 0.9979, policy_loss: 0.9504, value_loss: 0.5976
2024-07-11 17:01:44,671 [INFO    ] __main__: train step 14027: loss: 0.9979, policy_loss: 0.9504, value_loss: 0.5976
2024-07-11 17:01:44,885 [INFO    ] __main__: train step 14028: loss: 0.9979, policy_loss: 0.9504, value_loss: 0.5976
2024-07-11 17:01:45,095 [INFO    ] __main__: train step 14029: loss: 0.9979, policy_loss: 0.9504, value_loss: 0.5975
2024-07-11 17:01:45,329 [INFO    ] __main__: train step 14030: loss: 0.9979, policy_loss: 0.9504, value_loss: 0.5975
2024-07-11 17:01:45,535 [INFO    ] __main__: train step 14031: loss: 0.9979, policy_loss: 0.9503, value_loss: 0.5975
2024-07-11 17:01:45,734 [INFO    ] __main__: train step 14032: loss: 0.9978, policy_loss: 0.9503, value_loss: 0.5975
2024-07-11 17:01:45,943 [INFO    ] __main__: train step 14033: loss: 0.9978, policy_loss: 0.9503, value_loss: 0.5974
2024-07-11 17:01:46,146 [INFO    ] __main__: train step 14034: loss: 0.9978, policy_loss: 0.9503, value_loss: 0.5974
2024-07-11 17:01:46,350 [INFO    ] __main__: train step 14035: loss: 0.9978, policy_loss: 0.9503, value_loss: 0.5974
2024-07-11 17:01:46,556 [INFO    ] __main__: train step 14036: loss: 0.9978, policy_loss: 0.9502, value_loss: 0.5974
2024-07-11 17:01:46,777 [INFO    ] __main__: train step 14037: loss: 0.9978, policy_loss: 0.9502, value_loss: 0.5973
2024-07-11 17:01:47,006 [INFO    ] __main__: train step 14038: loss: 0.9978, policy_loss: 0.9502, value_loss: 0.5973
2024-07-11 17:01:47,264 [INFO    ] __main__: train step 14039: loss: 0.9978, policy_loss: 0.9502, value_loss: 0.5973
2024-07-11 17:01:47,489 [INFO    ] __main__: train step 14040: loss: 0.9978, policy_loss: 0.9502, value_loss: 0.5972
2024-07-11 17:01:47,688 [INFO    ] __main__: train step 14041: loss: 0.9978, policy_loss: 0.9501, value_loss: 0.5972
2024-07-11 17:01:49,122 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:01:49,506 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:01:49,563 [INFO    ] __main__: train step 14042: loss: 0.9978, policy_loss: 0.9501, value_loss: 0.5972
2024-07-11 17:01:49,745 [INFO    ] __main__: train step 14043: loss: 0.9978, policy_loss: 0.9501, value_loss: 0.5972
2024-07-11 17:01:49,971 [INFO    ] __main__: train step 14044: loss: 0.9978, policy_loss: 0.9501, value_loss: 0.5971
2024-07-11 17:01:50,187 [INFO    ] __main__: train step 14045: loss: 0.9978, policy_loss: 0.9501, value_loss: 0.5971
2024-07-11 17:01:50,398 [INFO    ] __main__: train step 14046: loss: 0.9977, policy_loss: 0.9500, value_loss: 0.5971
2024-07-11 17:01:50,627 [INFO    ] __main__: train step 14047: loss: 0.9977, policy_loss: 0.9500, value_loss: 0.5971
2024-07-11 17:01:50,853 [INFO    ] __main__: train step 14048: loss: 0.9977, policy_loss: 0.9500, value_loss: 0.5970
2024-07-11 17:01:51,098 [INFO    ] __main__: train step 14049: loss: 0.9977, policy_loss: 0.9500, value_loss: 0.5970
2024-07-11 17:01:51,323 [INFO    ] __main__: train step 14050: loss: 0.9977, policy_loss: 0.9499, value_loss: 0.5970
2024-07-11 17:01:51,538 [INFO    ] __main__: train step 14051: loss: 0.9977, policy_loss: 0.9499, value_loss: 0.5970
2024-07-11 17:01:51,772 [INFO    ] __main__: train step 14052: loss: 0.9977, policy_loss: 0.9499, value_loss: 0.5969
2024-07-11 17:01:51,981 [INFO    ] __main__: train step 14053: loss: 0.9977, policy_loss: 0.9499, value_loss: 0.5969
2024-07-11 17:01:52,210 [INFO    ] __main__: train step 14054: loss: 0.9977, policy_loss: 0.9499, value_loss: 0.5969
2024-07-11 17:01:52,410 [INFO    ] __main__: train step 14055: loss: 0.9977, policy_loss: 0.9498, value_loss: 0.5969
2024-07-11 17:01:52,612 [INFO    ] __main__: train step 14056: loss: 0.9977, policy_loss: 0.9498, value_loss: 0.5968
2024-07-11 17:01:52,843 [INFO    ] __main__: train step 14057: loss: 0.9977, policy_loss: 0.9498, value_loss: 0.5968
2024-07-11 17:01:53,054 [INFO    ] __main__: train step 14058: loss: 0.9977, policy_loss: 0.9498, value_loss: 0.5968
2024-07-11 17:01:54,529 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:01:54,922 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:01:54,976 [INFO    ] __main__: train step 14059: loss: 0.9977, policy_loss: 0.9498, value_loss: 0.5968
2024-07-11 17:01:55,149 [INFO    ] __main__: train step 14060: loss: 0.9976, policy_loss: 0.9497, value_loss: 0.5967
2024-07-11 17:01:55,351 [INFO    ] __main__: train step 14061: loss: 0.9976, policy_loss: 0.9497, value_loss: 0.5967
2024-07-11 17:01:55,564 [INFO    ] __main__: train step 14062: loss: 0.9976, policy_loss: 0.9497, value_loss: 0.5967
2024-07-11 17:01:55,761 [INFO    ] __main__: train step 14063: loss: 0.9976, policy_loss: 0.9497, value_loss: 0.5967
2024-07-11 17:01:55,957 [INFO    ] __main__: train step 14064: loss: 0.9976, policy_loss: 0.9497, value_loss: 0.5966
2024-07-11 17:01:56,166 [INFO    ] __main__: train step 14065: loss: 0.9976, policy_loss: 0.9496, value_loss: 0.5966
2024-07-11 17:01:56,373 [INFO    ] __main__: train step 14066: loss: 0.9976, policy_loss: 0.9496, value_loss: 0.5966
2024-07-11 17:01:56,616 [INFO    ] __main__: train step 14067: loss: 0.9976, policy_loss: 0.9496, value_loss: 0.5966
2024-07-11 17:01:56,815 [INFO    ] __main__: train step 14068: loss: 0.9976, policy_loss: 0.9496, value_loss: 0.5965
2024-07-11 17:01:57,031 [INFO    ] __main__: train step 14069: loss: 0.9976, policy_loss: 0.9496, value_loss: 0.5965
2024-07-11 17:01:57,258 [INFO    ] __main__: train step 14070: loss: 0.9976, policy_loss: 0.9495, value_loss: 0.5965
2024-07-11 17:01:57,464 [INFO    ] __main__: train step 14071: loss: 0.9976, policy_loss: 0.9495, value_loss: 0.5965
2024-07-11 17:01:57,655 [INFO    ] __main__: train step 14072: loss: 0.9976, policy_loss: 0.9495, value_loss: 0.5964
2024-07-11 17:01:57,862 [INFO    ] __main__: train step 14073: loss: 0.9975, policy_loss: 0.9495, value_loss: 0.5964
2024-07-11 17:01:58,074 [INFO    ] __main__: train step 14074: loss: 0.9975, policy_loss: 0.9494, value_loss: 0.5964
2024-07-11 17:01:58,267 [INFO    ] __main__: train step 14075: loss: 0.9975, policy_loss: 0.9494, value_loss: 0.5964
2024-07-11 17:01:59,688 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:02:00,134 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:02:00,198 [INFO    ] __main__: train step 14076: loss: 0.9975, policy_loss: 0.9494, value_loss: 0.5963
2024-07-11 17:02:00,383 [INFO    ] __main__: train step 14077: loss: 0.9975, policy_loss: 0.9494, value_loss: 0.5963
2024-07-11 17:02:00,613 [INFO    ] __main__: train step 14078: loss: 0.9975, policy_loss: 0.9494, value_loss: 0.5963
2024-07-11 17:02:00,819 [INFO    ] __main__: train step 14079: loss: 0.9975, policy_loss: 0.9493, value_loss: 0.5962
2024-07-11 17:02:01,027 [INFO    ] __main__: train step 14080: loss: 0.9975, policy_loss: 0.9493, value_loss: 0.5962
2024-07-11 17:02:01,229 [INFO    ] __main__: train step 14081: loss: 0.9975, policy_loss: 0.9493, value_loss: 0.5962
2024-07-11 17:02:01,433 [INFO    ] __main__: train step 14082: loss: 0.9975, policy_loss: 0.9493, value_loss: 0.5962
2024-07-11 17:02:01,633 [INFO    ] __main__: train step 14083: loss: 0.9975, policy_loss: 0.9493, value_loss: 0.5961
2024-07-11 17:02:01,837 [INFO    ] __main__: train step 14084: loss: 0.9975, policy_loss: 0.9492, value_loss: 0.5961
2024-07-11 17:02:02,039 [INFO    ] __main__: train step 14085: loss: 0.9975, policy_loss: 0.9492, value_loss: 0.5961
2024-07-11 17:02:02,251 [INFO    ] __main__: train step 14086: loss: 0.9974, policy_loss: 0.9492, value_loss: 0.5961
2024-07-11 17:02:02,473 [INFO    ] __main__: train step 14087: loss: 0.9974, policy_loss: 0.9492, value_loss: 0.5960
2024-07-11 17:02:02,721 [INFO    ] __main__: train step 14088: loss: 0.9974, policy_loss: 0.9492, value_loss: 0.5960
2024-07-11 17:02:02,942 [INFO    ] __main__: train step 14089: loss: 0.9974, policy_loss: 0.9491, value_loss: 0.5960
2024-07-11 17:02:03,155 [INFO    ] __main__: train step 14090: loss: 0.9974, policy_loss: 0.9491, value_loss: 0.5960
2024-07-11 17:02:03,364 [INFO    ] __main__: train step 14091: loss: 0.9974, policy_loss: 0.9491, value_loss: 0.5959
2024-07-11 17:02:03,589 [INFO    ] __main__: train step 14092: loss: 0.9974, policy_loss: 0.9491, value_loss: 0.5959
2024-07-11 17:02:05,055 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:02:05,477 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:02:05,536 [INFO    ] __main__: train step 14093: loss: 0.9974, policy_loss: 0.9491, value_loss: 0.5959
2024-07-11 17:02:05,714 [INFO    ] __main__: train step 14094: loss: 0.9974, policy_loss: 0.9490, value_loss: 0.5959
2024-07-11 17:02:07,280 [INFO    ] __main__: train step 14095: loss: 0.9974, policy_loss: 0.9490, value_loss: 0.5958
2024-07-11 17:02:07,492 [INFO    ] __main__: train step 14096: loss: 0.9974, policy_loss: 0.9490, value_loss: 0.5958
2024-07-11 17:02:07,693 [INFO    ] __main__: train step 14097: loss: 0.9974, policy_loss: 0.9490, value_loss: 0.5958
2024-07-11 17:02:07,899 [INFO    ] __main__: train step 14098: loss: 0.9974, policy_loss: 0.9489, value_loss: 0.5958
2024-07-11 17:02:08,108 [INFO    ] __main__: train step 14099: loss: 0.9973, policy_loss: 0.9489, value_loss: 0.5957
2024-07-11 17:02:08,321 [INFO    ] __main__: train step 14100: loss: 0.9973, policy_loss: 0.9489, value_loss: 0.5957
2024-07-11 17:02:08,537 [INFO    ] __main__: train step 14101: loss: 0.9973, policy_loss: 0.9489, value_loss: 0.5957
2024-07-11 17:02:08,756 [INFO    ] __main__: train step 14102: loss: 0.9973, policy_loss: 0.9489, value_loss: 0.5957
2024-07-11 17:02:08,979 [INFO    ] __main__: train step 14103: loss: 0.9973, policy_loss: 0.9488, value_loss: 0.5956
2024-07-11 17:02:09,191 [INFO    ] __main__: train step 14104: loss: 0.9973, policy_loss: 0.9488, value_loss: 0.5956
2024-07-11 17:02:09,437 [INFO    ] __main__: train step 14105: loss: 0.9973, policy_loss: 0.9488, value_loss: 0.5956
2024-07-11 17:02:09,672 [INFO    ] __main__: train step 14106: loss: 0.9973, policy_loss: 0.9488, value_loss: 0.5956
2024-07-11 17:02:09,893 [INFO    ] __main__: train step 14107: loss: 0.9973, policy_loss: 0.9488, value_loss: 0.5955
2024-07-11 17:02:10,123 [INFO    ] __main__: train step 14108: loss: 0.9973, policy_loss: 0.9487, value_loss: 0.5955
2024-07-11 17:02:10,327 [INFO    ] __main__: train step 14109: loss: 0.9973, policy_loss: 0.9487, value_loss: 0.5955
2024-07-11 17:02:11,742 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:02:12,136 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:02:12,192 [INFO    ] __main__: train step 14110: loss: 0.9973, policy_loss: 0.9487, value_loss: 0.5955
2024-07-11 17:02:12,366 [INFO    ] __main__: train step 14111: loss: 0.9973, policy_loss: 0.9487, value_loss: 0.5954
2024-07-11 17:02:12,573 [INFO    ] __main__: train step 14112: loss: 0.9972, policy_loss: 0.9487, value_loss: 0.5954
2024-07-11 17:02:12,767 [INFO    ] __main__: train step 14113: loss: 0.9972, policy_loss: 0.9486, value_loss: 0.5954
2024-07-11 17:02:12,981 [INFO    ] __main__: train step 14114: loss: 0.9972, policy_loss: 0.9486, value_loss: 0.5953
2024-07-11 17:02:13,193 [INFO    ] __main__: train step 14115: loss: 0.9972, policy_loss: 0.9486, value_loss: 0.5953
2024-07-11 17:02:13,405 [INFO    ] __main__: train step 14116: loss: 0.9972, policy_loss: 0.9486, value_loss: 0.5953
2024-07-11 17:02:13,642 [INFO    ] __main__: train step 14117: loss: 0.9972, policy_loss: 0.9486, value_loss: 0.5953
2024-07-11 17:02:13,844 [INFO    ] __main__: train step 14118: loss: 0.9972, policy_loss: 0.9485, value_loss: 0.5952
2024-07-11 17:02:14,046 [INFO    ] __main__: train step 14119: loss: 0.9972, policy_loss: 0.9485, value_loss: 0.5952
2024-07-11 17:02:14,268 [INFO    ] __main__: train step 14120: loss: 0.9972, policy_loss: 0.9485, value_loss: 0.5952
2024-07-11 17:02:14,483 [INFO    ] __main__: train step 14121: loss: 0.9972, policy_loss: 0.9485, value_loss: 0.5952
2024-07-11 17:02:14,718 [INFO    ] __main__: train step 14122: loss: 0.9972, policy_loss: 0.9484, value_loss: 0.5951
2024-07-11 17:02:14,933 [INFO    ] __main__: train step 14123: loss: 0.9972, policy_loss: 0.9484, value_loss: 0.5951
2024-07-11 17:02:15,172 [INFO    ] __main__: train step 14124: loss: 0.9972, policy_loss: 0.9484, value_loss: 0.5951
2024-07-11 17:02:15,387 [INFO    ] __main__: train step 14125: loss: 0.9971, policy_loss: 0.9484, value_loss: 0.5951
2024-07-11 17:02:15,584 [INFO    ] __main__: train step 14126: loss: 0.9971, policy_loss: 0.9484, value_loss: 0.5950
2024-07-11 17:02:17,024 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:02:17,434 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:02:17,491 [INFO    ] __main__: train step 14127: loss: 0.9971, policy_loss: 0.9483, value_loss: 0.5950
2024-07-11 17:02:17,668 [INFO    ] __main__: train step 14128: loss: 0.9971, policy_loss: 0.9483, value_loss: 0.5950
2024-07-11 17:02:17,877 [INFO    ] __main__: train step 14129: loss: 0.9971, policy_loss: 0.9483, value_loss: 0.5950
2024-07-11 17:02:18,080 [INFO    ] __main__: train step 14130: loss: 0.9971, policy_loss: 0.9483, value_loss: 0.5949
2024-07-11 17:02:18,290 [INFO    ] __main__: train step 14131: loss: 0.9971, policy_loss: 0.9483, value_loss: 0.5949
2024-07-11 17:02:18,495 [INFO    ] __main__: train step 14132: loss: 0.9971, policy_loss: 0.9482, value_loss: 0.5949
2024-07-11 17:02:18,707 [INFO    ] __main__: train step 14133: loss: 0.9971, policy_loss: 0.9482, value_loss: 0.5949
2024-07-11 17:02:18,911 [INFO    ] __main__: train step 14134: loss: 0.9971, policy_loss: 0.9482, value_loss: 0.5948
2024-07-11 17:02:19,115 [INFO    ] __main__: train step 14135: loss: 0.9971, policy_loss: 0.9482, value_loss: 0.5948
2024-07-11 17:02:19,321 [INFO    ] __main__: train step 14136: loss: 0.9971, policy_loss: 0.9482, value_loss: 0.5948
2024-07-11 17:02:19,529 [INFO    ] __main__: train step 14137: loss: 0.9971, policy_loss: 0.9481, value_loss: 0.5948
2024-07-11 17:02:19,737 [INFO    ] __main__: train step 14138: loss: 0.9971, policy_loss: 0.9481, value_loss: 0.5947
2024-07-11 17:02:19,949 [INFO    ] __main__: train step 14139: loss: 0.9970, policy_loss: 0.9481, value_loss: 0.5947
2024-07-11 17:02:20,163 [INFO    ] __main__: train step 14140: loss: 0.9970, policy_loss: 0.9481, value_loss: 0.5947
2024-07-11 17:02:20,378 [INFO    ] __main__: train step 14141: loss: 0.9970, policy_loss: 0.9481, value_loss: 0.5947
2024-07-11 17:02:20,612 [INFO    ] __main__: train step 14142: loss: 0.9970, policy_loss: 0.9480, value_loss: 0.5946
2024-07-11 17:02:20,809 [INFO    ] __main__: train step 14143: loss: 0.9970, policy_loss: 0.9480, value_loss: 0.5946
2024-07-11 17:02:22,259 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:02:22,668 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:02:22,732 [INFO    ] __main__: train step 14144: loss: 0.9970, policy_loss: 0.9480, value_loss: 0.5946
2024-07-11 17:02:22,909 [INFO    ] __main__: train step 14145: loss: 0.9970, policy_loss: 0.9480, value_loss: 0.5946
2024-07-11 17:02:23,112 [INFO    ] __main__: train step 14146: loss: 0.9970, policy_loss: 0.9479, value_loss: 0.5945
2024-07-11 17:02:23,332 [INFO    ] __main__: train step 14147: loss: 0.9970, policy_loss: 0.9479, value_loss: 0.5945
2024-07-11 17:02:23,536 [INFO    ] __main__: train step 14148: loss: 0.9970, policy_loss: 0.9479, value_loss: 0.5945
2024-07-11 17:02:23,747 [INFO    ] __main__: train step 14149: loss: 0.9970, policy_loss: 0.9479, value_loss: 0.5945
2024-07-11 17:02:23,950 [INFO    ] __main__: train step 14150: loss: 0.9970, policy_loss: 0.9479, value_loss: 0.5944
2024-07-11 17:02:24,190 [INFO    ] __main__: train step 14151: loss: 0.9970, policy_loss: 0.9478, value_loss: 0.5944
2024-07-11 17:02:24,420 [INFO    ] __main__: train step 14152: loss: 0.9969, policy_loss: 0.9478, value_loss: 0.5944
2024-07-11 17:02:24,630 [INFO    ] __main__: train step 14153: loss: 0.9969, policy_loss: 0.9478, value_loss: 0.5944
2024-07-11 17:02:24,843 [INFO    ] __main__: train step 14154: loss: 0.9969, policy_loss: 0.9478, value_loss: 0.5943
2024-07-11 17:02:25,039 [INFO    ] __main__: train step 14155: loss: 0.9969, policy_loss: 0.9478, value_loss: 0.5943
2024-07-11 17:02:25,254 [INFO    ] __main__: train step 14156: loss: 0.9969, policy_loss: 0.9477, value_loss: 0.5943
2024-07-11 17:02:25,451 [INFO    ] __main__: train step 14157: loss: 0.9969, policy_loss: 0.9477, value_loss: 0.5943
2024-07-11 17:02:25,661 [INFO    ] __main__: train step 14158: loss: 0.9969, policy_loss: 0.9477, value_loss: 0.5942
2024-07-11 17:02:25,871 [INFO    ] __main__: train step 14159: loss: 0.9969, policy_loss: 0.9477, value_loss: 0.5942
2024-07-11 17:02:26,075 [INFO    ] __main__: train step 14160: loss: 0.9969, policy_loss: 0.9477, value_loss: 0.5942
2024-07-11 17:02:27,507 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:02:27,930 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:02:27,991 [INFO    ] __main__: train step 14161: loss: 0.9969, policy_loss: 0.9476, value_loss: 0.5942
2024-07-11 17:02:28,176 [INFO    ] __main__: train step 14162: loss: 0.9969, policy_loss: 0.9476, value_loss: 0.5941
2024-07-11 17:02:28,414 [INFO    ] __main__: train step 14163: loss: 0.9969, policy_loss: 0.9476, value_loss: 0.5941
2024-07-11 17:02:28,655 [INFO    ] __main__: train step 14164: loss: 0.9969, policy_loss: 0.9476, value_loss: 0.5941
2024-07-11 17:02:28,879 [INFO    ] __main__: train step 14165: loss: 0.9968, policy_loss: 0.9476, value_loss: 0.5941
2024-07-11 17:02:29,077 [INFO    ] __main__: train step 14166: loss: 0.9968, policy_loss: 0.9475, value_loss: 0.5940
2024-07-11 17:02:29,283 [INFO    ] __main__: train step 14167: loss: 0.9968, policy_loss: 0.9475, value_loss: 0.5940
2024-07-11 17:02:29,490 [INFO    ] __main__: train step 14168: loss: 0.9968, policy_loss: 0.9475, value_loss: 0.5940
2024-07-11 17:02:29,702 [INFO    ] __main__: train step 14169: loss: 0.9968, policy_loss: 0.9475, value_loss: 0.5940
2024-07-11 17:02:29,927 [INFO    ] __main__: train step 14170: loss: 0.9968, policy_loss: 0.9475, value_loss: 0.5939
2024-07-11 17:02:30,142 [INFO    ] __main__: train step 14171: loss: 0.9968, policy_loss: 0.9474, value_loss: 0.5939
2024-07-11 17:02:30,373 [INFO    ] __main__: train step 14172: loss: 0.9968, policy_loss: 0.9474, value_loss: 0.5939
2024-07-11 17:02:30,602 [INFO    ] __main__: train step 14173: loss: 0.9968, policy_loss: 0.9474, value_loss: 0.5939
2024-07-11 17:02:30,798 [INFO    ] __main__: train step 14174: loss: 0.9968, policy_loss: 0.9474, value_loss: 0.5938
2024-07-11 17:02:31,005 [INFO    ] __main__: train step 14175: loss: 0.9968, policy_loss: 0.9474, value_loss: 0.5938
2024-07-11 17:02:31,212 [INFO    ] __main__: train step 14176: loss: 0.9968, policy_loss: 0.9473, value_loss: 0.5938
2024-07-11 17:02:31,419 [INFO    ] __main__: train step 14177: loss: 0.9968, policy_loss: 0.9473, value_loss: 0.5938
2024-07-11 17:02:32,872 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:02:33,294 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:02:33,350 [INFO    ] __main__: train step 14178: loss: 0.9968, policy_loss: 0.9473, value_loss: 0.5937
2024-07-11 17:02:33,529 [INFO    ] __main__: train step 14179: loss: 0.9967, policy_loss: 0.9473, value_loss: 0.5937
2024-07-11 17:02:33,737 [INFO    ] __main__: train step 14180: loss: 0.9967, policy_loss: 0.9472, value_loss: 0.5937
2024-07-11 17:02:33,942 [INFO    ] __main__: train step 14181: loss: 0.9967, policy_loss: 0.9472, value_loss: 0.5937
2024-07-11 17:02:34,178 [INFO    ] __main__: train step 14182: loss: 0.9967, policy_loss: 0.9472, value_loss: 0.5936
2024-07-11 17:02:34,380 [INFO    ] __main__: train step 14183: loss: 0.9967, policy_loss: 0.9472, value_loss: 0.5936
2024-07-11 17:02:34,589 [INFO    ] __main__: train step 14184: loss: 0.9967, policy_loss: 0.9472, value_loss: 0.5936
2024-07-11 17:02:34,816 [INFO    ] __main__: train step 14185: loss: 0.9967, policy_loss: 0.9471, value_loss: 0.5936
2024-07-11 17:02:35,017 [INFO    ] __main__: train step 14186: loss: 0.9967, policy_loss: 0.9471, value_loss: 0.5935
2024-07-11 17:02:35,220 [INFO    ] __main__: train step 14187: loss: 0.9967, policy_loss: 0.9471, value_loss: 0.5935
2024-07-11 17:02:35,431 [INFO    ] __main__: train step 14188: loss: 0.9967, policy_loss: 0.9471, value_loss: 0.5935
2024-07-11 17:02:35,642 [INFO    ] __main__: train step 14189: loss: 0.9967, policy_loss: 0.9471, value_loss: 0.5935
2024-07-11 17:02:35,858 [INFO    ] __main__: train step 14190: loss: 0.9967, policy_loss: 0.9470, value_loss: 0.5934
2024-07-11 17:02:36,077 [INFO    ] __main__: train step 14191: loss: 0.9967, policy_loss: 0.9470, value_loss: 0.5934
2024-07-11 17:02:36,307 [INFO    ] __main__: train step 14192: loss: 0.9966, policy_loss: 0.9470, value_loss: 0.5934
2024-07-11 17:02:36,509 [INFO    ] __main__: train step 14193: loss: 0.9966, policy_loss: 0.9470, value_loss: 0.5933
2024-07-11 17:02:36,711 [INFO    ] __main__: train step 14194: loss: 0.9966, policy_loss: 0.9470, value_loss: 0.5933
2024-07-11 17:02:38,159 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:02:38,598 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:02:38,657 [INFO    ] __main__: train step 14195: loss: 0.9966, policy_loss: 0.9469, value_loss: 0.5933
2024-07-11 17:02:40,193 [INFO    ] __main__: train step 14196: loss: 0.9966, policy_loss: 0.9469, value_loss: 0.5933
2024-07-11 17:02:40,414 [INFO    ] __main__: train step 14197: loss: 0.9966, policy_loss: 0.9469, value_loss: 0.5932
2024-07-11 17:02:40,617 [INFO    ] __main__: train step 14198: loss: 0.9966, policy_loss: 0.9469, value_loss: 0.5932
2024-07-11 17:02:40,827 [INFO    ] __main__: train step 14199: loss: 0.9966, policy_loss: 0.9469, value_loss: 0.5932
2024-07-11 17:02:41,062 [INFO    ] __main__: train step 14200: loss: 0.9966, policy_loss: 0.9468, value_loss: 0.5932
2024-07-11 17:02:41,267 [INFO    ] __main__: train step 14201: loss: 0.9966, policy_loss: 0.9468, value_loss: 0.5931
2024-07-11 17:02:41,484 [INFO    ] __main__: train step 14202: loss: 0.9966, policy_loss: 0.9468, value_loss: 0.5931
2024-07-11 17:02:41,703 [INFO    ] __main__: train step 14203: loss: 0.9966, policy_loss: 0.9468, value_loss: 0.5931
2024-07-11 17:02:41,927 [INFO    ] __main__: train step 14204: loss: 0.9966, policy_loss: 0.9468, value_loss: 0.5931
2024-07-11 17:02:42,145 [INFO    ] __main__: train step 14205: loss: 0.9965, policy_loss: 0.9467, value_loss: 0.5930
2024-07-11 17:02:42,373 [INFO    ] __main__: train step 14206: loss: 0.9965, policy_loss: 0.9467, value_loss: 0.5930
2024-07-11 17:02:42,572 [INFO    ] __main__: train step 14207: loss: 0.9965, policy_loss: 0.9467, value_loss: 0.5930
2024-07-11 17:02:42,789 [INFO    ] __main__: train step 14208: loss: 0.9965, policy_loss: 0.9467, value_loss: 0.5930
2024-07-11 17:02:43,018 [INFO    ] __main__: train step 14209: loss: 0.9965, policy_loss: 0.9467, value_loss: 0.5929
2024-07-11 17:02:43,222 [INFO    ] __main__: train step 14210: loss: 0.9965, policy_loss: 0.9466, value_loss: 0.5929
2024-07-11 17:02:43,459 [INFO    ] __main__: train step 14211: loss: 0.9965, policy_loss: 0.9466, value_loss: 0.5929
2024-07-11 17:02:44,895 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:02:45,338 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:02:45,397 [INFO    ] __main__: train step 14212: loss: 0.9965, policy_loss: 0.9466, value_loss: 0.5929
2024-07-11 17:02:45,565 [INFO    ] __main__: train step 14213: loss: 0.9965, policy_loss: 0.9466, value_loss: 0.5928
2024-07-11 17:02:45,773 [INFO    ] __main__: train step 14214: loss: 0.9965, policy_loss: 0.9465, value_loss: 0.5928
2024-07-11 17:02:46,052 [INFO    ] __main__: train step 14215: loss: 0.9965, policy_loss: 0.9465, value_loss: 0.5928
2024-07-11 17:02:46,249 [INFO    ] __main__: train step 14216: loss: 0.9965, policy_loss: 0.9465, value_loss: 0.5928
2024-07-11 17:02:46,441 [INFO    ] __main__: train step 14217: loss: 0.9964, policy_loss: 0.9465, value_loss: 0.5927
2024-07-11 17:02:46,632 [INFO    ] __main__: train step 14218: loss: 0.9964, policy_loss: 0.9465, value_loss: 0.5927
2024-07-11 17:02:46,842 [INFO    ] __main__: train step 14219: loss: 0.9964, policy_loss: 0.9464, value_loss: 0.5927
2024-07-11 17:02:47,039 [INFO    ] __main__: train step 14220: loss: 0.9964, policy_loss: 0.9464, value_loss: 0.5927
2024-07-11 17:02:47,259 [INFO    ] __main__: train step 14221: loss: 0.9964, policy_loss: 0.9464, value_loss: 0.5926
2024-07-11 17:02:47,476 [INFO    ] __main__: train step 14222: loss: 0.9964, policy_loss: 0.9464, value_loss: 0.5926
2024-07-11 17:02:47,707 [INFO    ] __main__: train step 14223: loss: 0.9964, policy_loss: 0.9464, value_loss: 0.5926
2024-07-11 17:02:47,927 [INFO    ] __main__: train step 14224: loss: 0.9964, policy_loss: 0.9463, value_loss: 0.5926
2024-07-11 17:02:48,164 [INFO    ] __main__: train step 14225: loss: 0.9964, policy_loss: 0.9463, value_loss: 0.5925
2024-07-11 17:02:48,373 [INFO    ] __main__: train step 14226: loss: 0.9964, policy_loss: 0.9463, value_loss: 0.5925
2024-07-11 17:02:48,585 [INFO    ] __main__: train step 14227: loss: 0.9964, policy_loss: 0.9463, value_loss: 0.5925
2024-07-11 17:02:48,796 [INFO    ] __main__: train step 14228: loss: 0.9964, policy_loss: 0.9463, value_loss: 0.5925
2024-07-11 17:02:50,239 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:02:50,697 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:02:50,755 [INFO    ] __main__: train step 14229: loss: 0.9963, policy_loss: 0.9462, value_loss: 0.5924
2024-07-11 17:02:50,936 [INFO    ] __main__: train step 14230: loss: 0.9963, policy_loss: 0.9462, value_loss: 0.5924
2024-07-11 17:02:51,142 [INFO    ] __main__: train step 14231: loss: 0.9963, policy_loss: 0.9462, value_loss: 0.5924
2024-07-11 17:02:51,351 [INFO    ] __main__: train step 14232: loss: 0.9963, policy_loss: 0.9462, value_loss: 0.5924
2024-07-11 17:02:51,560 [INFO    ] __main__: train step 14233: loss: 0.9963, policy_loss: 0.9461, value_loss: 0.5923
2024-07-11 17:02:51,794 [INFO    ] __main__: train step 14234: loss: 0.9963, policy_loss: 0.9461, value_loss: 0.5923
2024-07-11 17:02:51,999 [INFO    ] __main__: train step 14235: loss: 0.9963, policy_loss: 0.9461, value_loss: 0.5923
2024-07-11 17:02:52,208 [INFO    ] __main__: train step 14236: loss: 0.9963, policy_loss: 0.9461, value_loss: 0.5922
2024-07-11 17:02:52,424 [INFO    ] __main__: train step 14237: loss: 0.9963, policy_loss: 0.9461, value_loss: 0.5922
2024-07-11 17:02:52,637 [INFO    ] __main__: train step 14238: loss: 0.9963, policy_loss: 0.9460, value_loss: 0.5922
2024-07-11 17:02:52,841 [INFO    ] __main__: train step 14239: loss: 0.9963, policy_loss: 0.9460, value_loss: 0.5922
2024-07-11 17:02:53,050 [INFO    ] __main__: train step 14240: loss: 0.9963, policy_loss: 0.9460, value_loss: 0.5921
2024-07-11 17:02:53,288 [INFO    ] __main__: train step 14241: loss: 0.9962, policy_loss: 0.9460, value_loss: 0.5921
2024-07-11 17:02:53,506 [INFO    ] __main__: train step 14242: loss: 0.9962, policy_loss: 0.9460, value_loss: 0.5921
2024-07-11 17:02:53,710 [INFO    ] __main__: train step 14243: loss: 0.9962, policy_loss: 0.9459, value_loss: 0.5921
2024-07-11 17:02:53,927 [INFO    ] __main__: train step 14244: loss: 0.9962, policy_loss: 0.9459, value_loss: 0.5920
2024-07-11 17:02:54,159 [INFO    ] __main__: train step 14245: loss: 0.9962, policy_loss: 0.9459, value_loss: 0.5920
2024-07-11 17:02:55,578 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:02:56,005 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:02:56,068 [INFO    ] __main__: train step 14246: loss: 0.9962, policy_loss: 0.9459, value_loss: 0.5920
2024-07-11 17:02:56,259 [INFO    ] __main__: train step 14247: loss: 0.9962, policy_loss: 0.9459, value_loss: 0.5920
2024-07-11 17:02:56,495 [INFO    ] __main__: train step 14248: loss: 0.9962, policy_loss: 0.9458, value_loss: 0.5919
2024-07-11 17:02:56,703 [INFO    ] __main__: train step 14249: loss: 0.9962, policy_loss: 0.9458, value_loss: 0.5919
2024-07-11 17:02:56,928 [INFO    ] __main__: train step 14250: loss: 0.9962, policy_loss: 0.9458, value_loss: 0.5919
2024-07-11 17:02:57,152 [INFO    ] __main__: train step 14251: loss: 0.9962, policy_loss: 0.9458, value_loss: 0.5919
2024-07-11 17:02:57,361 [INFO    ] __main__: train step 14252: loss: 0.9961, policy_loss: 0.9457, value_loss: 0.5918
2024-07-11 17:02:57,572 [INFO    ] __main__: train step 14253: loss: 0.9961, policy_loss: 0.9457, value_loss: 0.5918
2024-07-11 17:02:57,771 [INFO    ] __main__: train step 14254: loss: 0.9961, policy_loss: 0.9457, value_loss: 0.5918
2024-07-11 17:02:57,970 [INFO    ] __main__: train step 14255: loss: 0.9961, policy_loss: 0.9457, value_loss: 0.5918
2024-07-11 17:02:58,185 [INFO    ] __main__: train step 14256: loss: 0.9961, policy_loss: 0.9457, value_loss: 0.5917
2024-07-11 17:02:58,390 [INFO    ] __main__: train step 14257: loss: 0.9961, policy_loss: 0.9456, value_loss: 0.5917
2024-07-11 17:02:58,616 [INFO    ] __main__: train step 14258: loss: 0.9961, policy_loss: 0.9456, value_loss: 0.5917
2024-07-11 17:02:58,820 [INFO    ] __main__: train step 14259: loss: 0.9961, policy_loss: 0.9456, value_loss: 0.5917
2024-07-11 17:02:59,027 [INFO    ] __main__: train step 14260: loss: 0.9961, policy_loss: 0.9456, value_loss: 0.5916
2024-07-11 17:02:59,228 [INFO    ] __main__: train step 14261: loss: 0.9961, policy_loss: 0.9456, value_loss: 0.5916
2024-07-11 17:02:59,432 [INFO    ] __main__: train step 14262: loss: 0.9961, policy_loss: 0.9455, value_loss: 0.5916
2024-07-11 17:03:00,884 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:03:01,318 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:03:01,378 [INFO    ] __main__: train step 14263: loss: 0.9961, policy_loss: 0.9455, value_loss: 0.5916
2024-07-11 17:03:01,555 [INFO    ] __main__: train step 14264: loss: 0.9960, policy_loss: 0.9455, value_loss: 0.5915
2024-07-11 17:03:01,763 [INFO    ] __main__: train step 14265: loss: 0.9960, policy_loss: 0.9455, value_loss: 0.5915
2024-07-11 17:03:01,975 [INFO    ] __main__: train step 14266: loss: 0.9960, policy_loss: 0.9455, value_loss: 0.5915
2024-07-11 17:03:02,177 [INFO    ] __main__: train step 14267: loss: 0.9960, policy_loss: 0.9454, value_loss: 0.5915
2024-07-11 17:03:02,386 [INFO    ] __main__: train step 14268: loss: 0.9960, policy_loss: 0.9454, value_loss: 0.5914
2024-07-11 17:03:02,627 [INFO    ] __main__: train step 14269: loss: 0.9960, policy_loss: 0.9454, value_loss: 0.5914
2024-07-11 17:03:02,834 [INFO    ] __main__: train step 14270: loss: 0.9960, policy_loss: 0.9454, value_loss: 0.5914
2024-07-11 17:03:03,060 [INFO    ] __main__: train step 14271: loss: 0.9960, policy_loss: 0.9454, value_loss: 0.5913
2024-07-11 17:03:03,298 [INFO    ] __main__: train step 14272: loss: 0.9960, policy_loss: 0.9453, value_loss: 0.5913
2024-07-11 17:03:03,510 [INFO    ] __main__: train step 14273: loss: 0.9960, policy_loss: 0.9453, value_loss: 0.5913
2024-07-11 17:03:03,728 [INFO    ] __main__: train step 14274: loss: 0.9960, policy_loss: 0.9453, value_loss: 0.5913
2024-07-11 17:03:03,977 [INFO    ] __main__: train step 14275: loss: 0.9960, policy_loss: 0.9453, value_loss: 0.5912
2024-07-11 17:03:04,206 [INFO    ] __main__: train step 14276: loss: 0.9959, policy_loss: 0.9453, value_loss: 0.5912
2024-07-11 17:03:04,411 [INFO    ] __main__: train step 14277: loss: 0.9959, policy_loss: 0.9452, value_loss: 0.5912
2024-07-11 17:03:04,625 [INFO    ] __main__: train step 14278: loss: 0.9959, policy_loss: 0.9452, value_loss: 0.5912
2024-07-11 17:03:04,869 [INFO    ] __main__: train step 14279: loss: 0.9959, policy_loss: 0.9452, value_loss: 0.5911
2024-07-11 17:03:06,298 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:03:06,742 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:03:06,807 [INFO    ] __main__: train step 14280: loss: 0.9959, policy_loss: 0.9452, value_loss: 0.5911
2024-07-11 17:03:06,984 [INFO    ] __main__: train step 14281: loss: 0.9959, policy_loss: 0.9451, value_loss: 0.5911
2024-07-11 17:03:07,187 [INFO    ] __main__: train step 14282: loss: 0.9959, policy_loss: 0.9451, value_loss: 0.5911
2024-07-11 17:03:07,419 [INFO    ] __main__: train step 14283: loss: 0.9959, policy_loss: 0.9451, value_loss: 0.5910
2024-07-11 17:03:07,621 [INFO    ] __main__: train step 14284: loss: 0.9959, policy_loss: 0.9451, value_loss: 0.5910
2024-07-11 17:03:07,825 [INFO    ] __main__: train step 14285: loss: 0.9959, policy_loss: 0.9451, value_loss: 0.5910
2024-07-11 17:03:08,036 [INFO    ] __main__: train step 14286: loss: 0.9959, policy_loss: 0.9450, value_loss: 0.5910
2024-07-11 17:03:08,255 [INFO    ] __main__: train step 14287: loss: 0.9959, policy_loss: 0.9450, value_loss: 0.5909
2024-07-11 17:03:08,511 [INFO    ] __main__: train step 14288: loss: 0.9958, policy_loss: 0.9450, value_loss: 0.5909
2024-07-11 17:03:08,741 [INFO    ] __main__: train step 14289: loss: 0.9958, policy_loss: 0.9450, value_loss: 0.5909
2024-07-11 17:03:08,962 [INFO    ] __main__: train step 14290: loss: 0.9958, policy_loss: 0.9450, value_loss: 0.5909
2024-07-11 17:03:09,188 [INFO    ] __main__: train step 14291: loss: 0.9958, policy_loss: 0.9449, value_loss: 0.5908
2024-07-11 17:03:09,396 [INFO    ] __main__: train step 14292: loss: 0.9958, policy_loss: 0.9449, value_loss: 0.5908
2024-07-11 17:03:09,607 [INFO    ] __main__: train step 14293: loss: 0.9958, policy_loss: 0.9449, value_loss: 0.5908
2024-07-11 17:03:09,844 [INFO    ] __main__: train step 14294: loss: 0.9958, policy_loss: 0.9449, value_loss: 0.5908
2024-07-11 17:03:10,041 [INFO    ] __main__: train step 14295: loss: 0.9958, policy_loss: 0.9448, value_loss: 0.5907
2024-07-11 17:03:10,273 [INFO    ] __main__: train step 14296: loss: 0.9958, policy_loss: 0.9448, value_loss: 0.5907
2024-07-11 17:03:13,074 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:03:13,511 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:03:13,573 [INFO    ] __main__: train step 14297: loss: 0.9958, policy_loss: 0.9448, value_loss: 0.5907
2024-07-11 17:03:13,757 [INFO    ] __main__: train step 14298: loss: 0.9958, policy_loss: 0.9448, value_loss: 0.5907
2024-07-11 17:03:13,952 [INFO    ] __main__: train step 14299: loss: 0.9957, policy_loss: 0.9448, value_loss: 0.5906
2024-07-11 17:03:14,157 [INFO    ] __main__: train step 14300: loss: 0.9957, policy_loss: 0.9447, value_loss: 0.5906
2024-07-11 17:03:14,371 [INFO    ] __main__: train step 14301: loss: 0.9957, policy_loss: 0.9447, value_loss: 0.5906
2024-07-11 17:03:14,599 [INFO    ] __main__: train step 14302: loss: 0.9957, policy_loss: 0.9447, value_loss: 0.5906
2024-07-11 17:03:14,837 [INFO    ] __main__: train step 14303: loss: 0.9957, policy_loss: 0.9447, value_loss: 0.5905
2024-07-11 17:03:15,087 [INFO    ] __main__: train step 14304: loss: 0.9957, policy_loss: 0.9447, value_loss: 0.5905
2024-07-11 17:03:15,319 [INFO    ] __main__: train step 14305: loss: 0.9957, policy_loss: 0.9446, value_loss: 0.5905
2024-07-11 17:03:15,516 [INFO    ] __main__: train step 14306: loss: 0.9957, policy_loss: 0.9446, value_loss: 0.5905
2024-07-11 17:03:15,719 [INFO    ] __main__: train step 14307: loss: 0.9957, policy_loss: 0.9446, value_loss: 0.5904
2024-07-11 17:03:15,947 [INFO    ] __main__: train step 14308: loss: 0.9957, policy_loss: 0.9446, value_loss: 0.5904
2024-07-11 17:03:16,160 [INFO    ] __main__: train step 14309: loss: 0.9957, policy_loss: 0.9446, value_loss: 0.5904
2024-07-11 17:03:16,392 [INFO    ] __main__: train step 14310: loss: 0.9956, policy_loss: 0.9445, value_loss: 0.5904
2024-07-11 17:03:16,598 [INFO    ] __main__: train step 14311: loss: 0.9956, policy_loss: 0.9445, value_loss: 0.5903
2024-07-11 17:03:16,801 [INFO    ] __main__: train step 14312: loss: 0.9956, policy_loss: 0.9445, value_loss: 0.5903
2024-07-11 17:03:16,998 [INFO    ] __main__: train step 14313: loss: 0.9956, policy_loss: 0.9445, value_loss: 0.5903
2024-07-11 17:03:18,420 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:03:18,794 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:03:18,855 [INFO    ] __main__: train step 14314: loss: 0.9956, policy_loss: 0.9445, value_loss: 0.5903
2024-07-11 17:03:19,029 [INFO    ] __main__: train step 14315: loss: 0.9956, policy_loss: 0.9444, value_loss: 0.5902
2024-07-11 17:03:19,235 [INFO    ] __main__: train step 14316: loss: 0.9956, policy_loss: 0.9444, value_loss: 0.5902
2024-07-11 17:03:19,439 [INFO    ] __main__: train step 14317: loss: 0.9956, policy_loss: 0.9444, value_loss: 0.5902
2024-07-11 17:03:19,637 [INFO    ] __main__: train step 14318: loss: 0.9956, policy_loss: 0.9444, value_loss: 0.5902
2024-07-11 17:03:19,839 [INFO    ] __main__: train step 14319: loss: 0.9956, policy_loss: 0.9443, value_loss: 0.5901
2024-07-11 17:03:20,047 [INFO    ] __main__: train step 14320: loss: 0.9956, policy_loss: 0.9443, value_loss: 0.5901
2024-07-11 17:03:20,247 [INFO    ] __main__: train step 14321: loss: 0.9956, policy_loss: 0.9443, value_loss: 0.5901
2024-07-11 17:03:20,464 [INFO    ] __main__: train step 14322: loss: 0.9955, policy_loss: 0.9443, value_loss: 0.5901
2024-07-11 17:03:20,688 [INFO    ] __main__: train step 14323: loss: 0.9955, policy_loss: 0.9443, value_loss: 0.5900
2024-07-11 17:03:20,903 [INFO    ] __main__: train step 14324: loss: 0.9955, policy_loss: 0.9442, value_loss: 0.5900
2024-07-11 17:03:21,135 [INFO    ] __main__: train step 14325: loss: 0.9955, policy_loss: 0.9442, value_loss: 0.5900
2024-07-11 17:03:21,340 [INFO    ] __main__: train step 14326: loss: 0.9955, policy_loss: 0.9442, value_loss: 0.5900
2024-07-11 17:03:21,542 [INFO    ] __main__: train step 14327: loss: 0.9955, policy_loss: 0.9442, value_loss: 0.5899
2024-07-11 17:03:21,741 [INFO    ] __main__: train step 14328: loss: 0.9955, policy_loss: 0.9442, value_loss: 0.5899
2024-07-11 17:03:21,945 [INFO    ] __main__: train step 14329: loss: 0.9955, policy_loss: 0.9441, value_loss: 0.5899
2024-07-11 17:03:22,154 [INFO    ] __main__: train step 14330: loss: 0.9955, policy_loss: 0.9441, value_loss: 0.5899
2024-07-11 17:03:23,620 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:03:24,002 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:03:24,063 [INFO    ] __main__: train step 14331: loss: 0.9955, policy_loss: 0.9441, value_loss: 0.5898
2024-07-11 17:03:24,253 [INFO    ] __main__: train step 14332: loss: 0.9955, policy_loss: 0.9441, value_loss: 0.5898
2024-07-11 17:03:24,460 [INFO    ] __main__: train step 14333: loss: 0.9955, policy_loss: 0.9441, value_loss: 0.5898
2024-07-11 17:03:24,666 [INFO    ] __main__: train step 14334: loss: 0.9954, policy_loss: 0.9440, value_loss: 0.5897
2024-07-11 17:03:24,876 [INFO    ] __main__: train step 14335: loss: 0.9954, policy_loss: 0.9440, value_loss: 0.5897
2024-07-11 17:03:25,076 [INFO    ] __main__: train step 14336: loss: 0.9954, policy_loss: 0.9440, value_loss: 0.5897
2024-07-11 17:03:25,301 [INFO    ] __main__: train step 14337: loss: 0.9954, policy_loss: 0.9440, value_loss: 0.5897
2024-07-11 17:03:25,519 [INFO    ] __main__: train step 14338: loss: 0.9954, policy_loss: 0.9440, value_loss: 0.5896
2024-07-11 17:03:25,723 [INFO    ] __main__: train step 14339: loss: 0.9954, policy_loss: 0.9439, value_loss: 0.5896
2024-07-11 17:03:25,961 [INFO    ] __main__: train step 14340: loss: 0.9954, policy_loss: 0.9439, value_loss: 0.5896
2024-07-11 17:03:26,157 [INFO    ] __main__: train step 14341: loss: 0.9954, policy_loss: 0.9439, value_loss: 0.5896
2024-07-11 17:03:26,382 [INFO    ] __main__: train step 14342: loss: 0.9954, policy_loss: 0.9439, value_loss: 0.5895
2024-07-11 17:03:26,630 [INFO    ] __main__: train step 14343: loss: 0.9954, policy_loss: 0.9438, value_loss: 0.5895
2024-07-11 17:03:26,839 [INFO    ] __main__: train step 14344: loss: 0.9954, policy_loss: 0.9438, value_loss: 0.5895
2024-07-11 17:03:27,056 [INFO    ] __main__: train step 14345: loss: 0.9953, policy_loss: 0.9438, value_loss: 0.5895
2024-07-11 17:03:27,259 [INFO    ] __main__: train step 14346: loss: 0.9953, policy_loss: 0.9438, value_loss: 0.5894
2024-07-11 17:03:27,485 [INFO    ] __main__: train step 14347: loss: 0.9953, policy_loss: 0.9438, value_loss: 0.5894
2024-07-11 17:03:28,912 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:03:29,359 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:03:29,417 [INFO    ] __main__: train step 14348: loss: 0.9953, policy_loss: 0.9437, value_loss: 0.5894
2024-07-11 17:03:29,599 [INFO    ] __main__: train step 14349: loss: 0.9953, policy_loss: 0.9437, value_loss: 0.5894
2024-07-11 17:03:29,840 [INFO    ] __main__: train step 14350: loss: 0.9953, policy_loss: 0.9437, value_loss: 0.5893
2024-07-11 17:03:30,076 [INFO    ] __main__: train step 14351: loss: 0.9953, policy_loss: 0.9437, value_loss: 0.5893
2024-07-11 17:03:30,291 [INFO    ] __main__: train step 14352: loss: 0.9953, policy_loss: 0.9437, value_loss: 0.5893
2024-07-11 17:03:30,489 [INFO    ] __main__: train step 14353: loss: 0.9953, policy_loss: 0.9436, value_loss: 0.5893
2024-07-11 17:03:30,692 [INFO    ] __main__: train step 14354: loss: 0.9953, policy_loss: 0.9436, value_loss: 0.5892
2024-07-11 17:03:30,894 [INFO    ] __main__: train step 14355: loss: 0.9953, policy_loss: 0.9436, value_loss: 0.5892
2024-07-11 17:03:31,107 [INFO    ] __main__: train step 14356: loss: 0.9953, policy_loss: 0.9436, value_loss: 0.5892
2024-07-11 17:03:31,303 [INFO    ] __main__: train step 14357: loss: 0.9952, policy_loss: 0.9436, value_loss: 0.5892
2024-07-11 17:03:31,510 [INFO    ] __main__: train step 14358: loss: 0.9952, policy_loss: 0.9435, value_loss: 0.5891
2024-07-11 17:03:31,718 [INFO    ] __main__: train step 14359: loss: 0.9952, policy_loss: 0.9435, value_loss: 0.5891
2024-07-11 17:03:31,924 [INFO    ] __main__: train step 14360: loss: 0.9952, policy_loss: 0.9435, value_loss: 0.5891
2024-07-11 17:03:32,156 [INFO    ] __main__: train step 14361: loss: 0.9952, policy_loss: 0.9435, value_loss: 0.5891
2024-07-11 17:03:32,363 [INFO    ] __main__: train step 14362: loss: 0.9952, policy_loss: 0.9434, value_loss: 0.5890
2024-07-11 17:03:32,577 [INFO    ] __main__: train step 14363: loss: 0.9952, policy_loss: 0.9434, value_loss: 0.5890
2024-07-11 17:03:32,805 [INFO    ] __main__: train step 14364: loss: 0.9952, policy_loss: 0.9434, value_loss: 0.5890
2024-07-11 17:03:34,256 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:03:34,666 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:03:34,722 [INFO    ] __main__: train step 14365: loss: 0.9952, policy_loss: 0.9434, value_loss: 0.5890
2024-07-11 17:03:34,893 [INFO    ] __main__: train step 14366: loss: 0.9952, policy_loss: 0.9434, value_loss: 0.5889
2024-07-11 17:03:35,095 [INFO    ] __main__: train step 14367: loss: 0.9952, policy_loss: 0.9433, value_loss: 0.5889
2024-07-11 17:03:35,311 [INFO    ] __main__: train step 14368: loss: 0.9952, policy_loss: 0.9433, value_loss: 0.5889
2024-07-11 17:03:35,522 [INFO    ] __main__: train step 14369: loss: 0.9951, policy_loss: 0.9433, value_loss: 0.5889
2024-07-11 17:03:35,737 [INFO    ] __main__: train step 14370: loss: 0.9951, policy_loss: 0.9433, value_loss: 0.5888
2024-07-11 17:03:35,949 [INFO    ] __main__: train step 14371: loss: 0.9951, policy_loss: 0.9433, value_loss: 0.5888
2024-07-11 17:03:36,179 [INFO    ] __main__: train step 14372: loss: 0.9951, policy_loss: 0.9432, value_loss: 0.5888
2024-07-11 17:03:36,395 [INFO    ] __main__: train step 14373: loss: 0.9951, policy_loss: 0.9432, value_loss: 0.5888
2024-07-11 17:03:36,592 [INFO    ] __main__: train step 14374: loss: 0.9951, policy_loss: 0.9432, value_loss: 0.5887
2024-07-11 17:03:36,800 [INFO    ] __main__: train step 14375: loss: 0.9951, policy_loss: 0.9432, value_loss: 0.5887
2024-07-11 17:03:37,015 [INFO    ] __main__: train step 14376: loss: 0.9951, policy_loss: 0.9432, value_loss: 0.5887
2024-07-11 17:03:37,228 [INFO    ] __main__: train step 14377: loss: 0.9951, policy_loss: 0.9431, value_loss: 0.5887
2024-07-11 17:03:37,435 [INFO    ] __main__: train step 14378: loss: 0.9951, policy_loss: 0.9431, value_loss: 0.5886
2024-07-11 17:03:37,652 [INFO    ] __main__: train step 14379: loss: 0.9951, policy_loss: 0.9431, value_loss: 0.5886
2024-07-11 17:03:37,843 [INFO    ] __main__: train step 14380: loss: 0.9950, policy_loss: 0.9431, value_loss: 0.5886
2024-07-11 17:03:38,046 [INFO    ] __main__: train step 14381: loss: 0.9950, policy_loss: 0.9431, value_loss: 0.5886
2024-07-11 17:03:39,487 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:03:39,918 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:03:39,977 [INFO    ] __main__: train step 14382: loss: 0.9950, policy_loss: 0.9430, value_loss: 0.5885
2024-07-11 17:03:40,149 [INFO    ] __main__: train step 14383: loss: 0.9950, policy_loss: 0.9430, value_loss: 0.5885
2024-07-11 17:03:40,354 [INFO    ] __main__: train step 14384: loss: 0.9950, policy_loss: 0.9430, value_loss: 0.5885
2024-07-11 17:03:40,557 [INFO    ] __main__: train step 14385: loss: 0.9950, policy_loss: 0.9430, value_loss: 0.5885
2024-07-11 17:03:40,758 [INFO    ] __main__: train step 14386: loss: 0.9950, policy_loss: 0.9429, value_loss: 0.5884
2024-07-11 17:03:40,961 [INFO    ] __main__: train step 14387: loss: 0.9950, policy_loss: 0.9429, value_loss: 0.5884
2024-07-11 17:03:41,161 [INFO    ] __main__: train step 14388: loss: 0.9950, policy_loss: 0.9429, value_loss: 0.5884
2024-07-11 17:03:41,366 [INFO    ] __main__: train step 14389: loss: 0.9950, policy_loss: 0.9429, value_loss: 0.5884
2024-07-11 17:03:41,569 [INFO    ] __main__: train step 14390: loss: 0.9950, policy_loss: 0.9429, value_loss: 0.5883
2024-07-11 17:03:41,781 [INFO    ] __main__: train step 14391: loss: 0.9949, policy_loss: 0.9428, value_loss: 0.5883
2024-07-11 17:03:41,985 [INFO    ] __main__: train step 14392: loss: 0.9949, policy_loss: 0.9428, value_loss: 0.5883
2024-07-11 17:03:42,196 [INFO    ] __main__: train step 14393: loss: 0.9949, policy_loss: 0.9428, value_loss: 0.5883
2024-07-11 17:03:42,416 [INFO    ] __main__: train step 14394: loss: 0.9949, policy_loss: 0.9428, value_loss: 0.5882
2024-07-11 17:03:42,626 [INFO    ] __main__: train step 14395: loss: 0.9949, policy_loss: 0.9428, value_loss: 0.5882
2024-07-11 17:03:44,184 [INFO    ] __main__: train step 14396: loss: 0.9949, policy_loss: 0.9427, value_loss: 0.5882
2024-07-11 17:03:44,405 [INFO    ] __main__: train step 14397: loss: 0.9949, policy_loss: 0.9427, value_loss: 0.5882
2024-07-11 17:03:44,627 [INFO    ] __main__: train step 14398: loss: 0.9949, policy_loss: 0.9427, value_loss: 0.5881
2024-07-11 17:03:46,086 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:03:46,506 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:03:46,560 [INFO    ] __main__: train step 14399: loss: 0.9949, policy_loss: 0.9427, value_loss: 0.5881
2024-07-11 17:03:46,749 [INFO    ] __main__: train step 14400: loss: 0.9949, policy_loss: 0.9426, value_loss: 0.5881
2024-07-11 17:03:46,951 [INFO    ] __main__: train step 14401: loss: 0.9948, policy_loss: 0.9426, value_loss: 0.5881
2024-07-11 17:03:47,156 [INFO    ] __main__: train step 14402: loss: 0.9948, policy_loss: 0.9426, value_loss: 0.5880
2024-07-11 17:03:47,359 [INFO    ] __main__: train step 14403: loss: 0.9948, policy_loss: 0.9426, value_loss: 0.5880
2024-07-11 17:03:47,568 [INFO    ] __main__: train step 14404: loss: 0.9948, policy_loss: 0.9426, value_loss: 0.5880
2024-07-11 17:03:47,772 [INFO    ] __main__: train step 14405: loss: 0.9948, policy_loss: 0.9425, value_loss: 0.5880
2024-07-11 17:03:47,988 [INFO    ] __main__: train step 14406: loss: 0.9948, policy_loss: 0.9425, value_loss: 0.5879
2024-07-11 17:03:48,195 [INFO    ] __main__: train step 14407: loss: 0.9948, policy_loss: 0.9425, value_loss: 0.5879
2024-07-11 17:03:48,392 [INFO    ] __main__: train step 14408: loss: 0.9948, policy_loss: 0.9425, value_loss: 0.5879
2024-07-11 17:03:48,603 [INFO    ] __main__: train step 14409: loss: 0.9948, policy_loss: 0.9425, value_loss: 0.5879
2024-07-11 17:03:48,801 [INFO    ] __main__: train step 14410: loss: 0.9948, policy_loss: 0.9424, value_loss: 0.5878
2024-07-11 17:03:49,009 [INFO    ] __main__: train step 14411: loss: 0.9948, policy_loss: 0.9424, value_loss: 0.5878
2024-07-11 17:03:49,211 [INFO    ] __main__: train step 14412: loss: 0.9947, policy_loss: 0.9424, value_loss: 0.5878
2024-07-11 17:03:49,414 [INFO    ] __main__: train step 14413: loss: 0.9947, policy_loss: 0.9424, value_loss: 0.5878
2024-07-11 17:03:49,613 [INFO    ] __main__: train step 14414: loss: 0.9947, policy_loss: 0.9423, value_loss: 0.5877
2024-07-11 17:03:49,816 [INFO    ] __main__: train step 14415: loss: 0.9947, policy_loss: 0.9423, value_loss: 0.5877
2024-07-11 17:03:51,253 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:03:51,671 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:03:51,726 [INFO    ] __main__: train step 14416: loss: 0.9947, policy_loss: 0.9423, value_loss: 0.5877
2024-07-11 17:03:51,908 [INFO    ] __main__: train step 14417: loss: 0.9947, policy_loss: 0.9423, value_loss: 0.5876
2024-07-11 17:03:52,103 [INFO    ] __main__: train step 14418: loss: 0.9947, policy_loss: 0.9423, value_loss: 0.5876
2024-07-11 17:03:52,305 [INFO    ] __main__: train step 14419: loss: 0.9947, policy_loss: 0.9422, value_loss: 0.5876
2024-07-11 17:03:52,506 [INFO    ] __main__: train step 14420: loss: 0.9947, policy_loss: 0.9422, value_loss: 0.5876
2024-07-11 17:03:52,708 [INFO    ] __main__: train step 14421: loss: 0.9947, policy_loss: 0.9422, value_loss: 0.5875
2024-07-11 17:03:52,913 [INFO    ] __main__: train step 14422: loss: 0.9946, policy_loss: 0.9422, value_loss: 0.5875
2024-07-11 17:03:53,120 [INFO    ] __main__: train step 14423: loss: 0.9946, policy_loss: 0.9422, value_loss: 0.5875
2024-07-11 17:03:53,342 [INFO    ] __main__: train step 14424: loss: 0.9946, policy_loss: 0.9421, value_loss: 0.5875
2024-07-11 17:03:53,560 [INFO    ] __main__: train step 14425: loss: 0.9946, policy_loss: 0.9421, value_loss: 0.5874
2024-07-11 17:03:53,764 [INFO    ] __main__: train step 14426: loss: 0.9946, policy_loss: 0.9421, value_loss: 0.5874
2024-07-11 17:03:53,964 [INFO    ] __main__: train step 14427: loss: 0.9946, policy_loss: 0.9421, value_loss: 0.5874
2024-07-11 17:03:54,168 [INFO    ] __main__: train step 14428: loss: 0.9946, policy_loss: 0.9421, value_loss: 0.5874
2024-07-11 17:03:54,371 [INFO    ] __main__: train step 14429: loss: 0.9946, policy_loss: 0.9420, value_loss: 0.5873
2024-07-11 17:03:54,577 [INFO    ] __main__: train step 14430: loss: 0.9946, policy_loss: 0.9420, value_loss: 0.5873
2024-07-11 17:03:54,788 [INFO    ] __main__: train step 14431: loss: 0.9946, policy_loss: 0.9420, value_loss: 0.5873
2024-07-11 17:03:55,023 [INFO    ] __main__: train step 14432: loss: 0.9946, policy_loss: 0.9420, value_loss: 0.5873
2024-07-11 17:03:56,444 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:03:56,873 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:03:56,931 [INFO    ] __main__: train step 14433: loss: 0.9945, policy_loss: 0.9419, value_loss: 0.5872
2024-07-11 17:03:57,112 [INFO    ] __main__: train step 14434: loss: 0.9945, policy_loss: 0.9419, value_loss: 0.5872
2024-07-11 17:03:57,343 [INFO    ] __main__: train step 14435: loss: 0.9945, policy_loss: 0.9419, value_loss: 0.5872
2024-07-11 17:03:57,544 [INFO    ] __main__: train step 14436: loss: 0.9945, policy_loss: 0.9419, value_loss: 0.5872
2024-07-11 17:03:57,757 [INFO    ] __main__: train step 14437: loss: 0.9945, policy_loss: 0.9419, value_loss: 0.5871
2024-07-11 17:03:57,958 [INFO    ] __main__: train step 14438: loss: 0.9945, policy_loss: 0.9418, value_loss: 0.5871
2024-07-11 17:03:58,165 [INFO    ] __main__: train step 14439: loss: 0.9945, policy_loss: 0.9418, value_loss: 0.5871
2024-07-11 17:03:58,363 [INFO    ] __main__: train step 14440: loss: 0.9945, policy_loss: 0.9418, value_loss: 0.5871
2024-07-11 17:03:58,566 [INFO    ] __main__: train step 14441: loss: 0.9945, policy_loss: 0.9418, value_loss: 0.5870
2024-07-11 17:03:58,768 [INFO    ] __main__: train step 14442: loss: 0.9945, policy_loss: 0.9418, value_loss: 0.5870
2024-07-11 17:03:58,976 [INFO    ] __main__: train step 14443: loss: 0.9944, policy_loss: 0.9417, value_loss: 0.5870
2024-07-11 17:03:59,175 [INFO    ] __main__: train step 14444: loss: 0.9944, policy_loss: 0.9417, value_loss: 0.5870
2024-07-11 17:03:59,387 [INFO    ] __main__: train step 14445: loss: 0.9944, policy_loss: 0.9417, value_loss: 0.5869
2024-07-11 17:03:59,588 [INFO    ] __main__: train step 14446: loss: 0.9944, policy_loss: 0.9417, value_loss: 0.5869
2024-07-11 17:03:59,787 [INFO    ] __main__: train step 14447: loss: 0.9944, policy_loss: 0.9417, value_loss: 0.5869
2024-07-11 17:04:00,005 [INFO    ] __main__: train step 14448: loss: 0.9944, policy_loss: 0.9416, value_loss: 0.5869
2024-07-11 17:04:00,210 [INFO    ] __main__: train step 14449: loss: 0.9944, policy_loss: 0.9416, value_loss: 0.5868
2024-07-11 17:04:01,679 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:04:02,090 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:04:02,146 [INFO    ] __main__: train step 14450: loss: 0.9944, policy_loss: 0.9416, value_loss: 0.5868
2024-07-11 17:04:02,338 [INFO    ] __main__: train step 14451: loss: 0.9944, policy_loss: 0.9416, value_loss: 0.5868
2024-07-11 17:04:02,574 [INFO    ] __main__: train step 14452: loss: 0.9944, policy_loss: 0.9416, value_loss: 0.5868
2024-07-11 17:04:02,780 [INFO    ] __main__: train step 14453: loss: 0.9944, policy_loss: 0.9415, value_loss: 0.5867
2024-07-11 17:04:03,022 [INFO    ] __main__: train step 14454: loss: 0.9943, policy_loss: 0.9415, value_loss: 0.5867
2024-07-11 17:04:03,225 [INFO    ] __main__: train step 14455: loss: 0.9943, policy_loss: 0.9415, value_loss: 0.5867
2024-07-11 17:04:03,425 [INFO    ] __main__: train step 14456: loss: 0.9943, policy_loss: 0.9415, value_loss: 0.5867
2024-07-11 17:04:03,625 [INFO    ] __main__: train step 14457: loss: 0.9943, policy_loss: 0.9414, value_loss: 0.5866
2024-07-11 17:04:03,821 [INFO    ] __main__: train step 14458: loss: 0.9943, policy_loss: 0.9414, value_loss: 0.5866
2024-07-11 17:04:04,035 [INFO    ] __main__: train step 14459: loss: 0.9943, policy_loss: 0.9414, value_loss: 0.5866
2024-07-11 17:04:04,239 [INFO    ] __main__: train step 14460: loss: 0.9943, policy_loss: 0.9414, value_loss: 0.5866
2024-07-11 17:04:04,441 [INFO    ] __main__: train step 14461: loss: 0.9943, policy_loss: 0.9414, value_loss: 0.5865
2024-07-11 17:04:04,648 [INFO    ] __main__: train step 14462: loss: 0.9943, policy_loss: 0.9413, value_loss: 0.5865
2024-07-11 17:04:04,864 [INFO    ] __main__: train step 14463: loss: 0.9943, policy_loss: 0.9413, value_loss: 0.5865
2024-07-11 17:04:05,074 [INFO    ] __main__: train step 14464: loss: 0.9942, policy_loss: 0.9413, value_loss: 0.5865
2024-07-11 17:04:05,324 [INFO    ] __main__: train step 14465: loss: 0.9942, policy_loss: 0.9413, value_loss: 0.5864
2024-07-11 17:04:05,562 [INFO    ] __main__: train step 14466: loss: 0.9942, policy_loss: 0.9413, value_loss: 0.5864
2024-07-11 17:04:07,034 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:04:07,448 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:04:07,502 [INFO    ] __main__: train step 14467: loss: 0.9942, policy_loss: 0.9412, value_loss: 0.5864
2024-07-11 17:04:07,692 [INFO    ] __main__: train step 14468: loss: 0.9942, policy_loss: 0.9412, value_loss: 0.5864
2024-07-11 17:04:07,898 [INFO    ] __main__: train step 14469: loss: 0.9942, policy_loss: 0.9412, value_loss: 0.5863
2024-07-11 17:04:08,095 [INFO    ] __main__: train step 14470: loss: 0.9942, policy_loss: 0.9412, value_loss: 0.5863
2024-07-11 17:04:08,346 [INFO    ] __main__: train step 14471: loss: 0.9942, policy_loss: 0.9411, value_loss: 0.5863
2024-07-11 17:04:08,596 [INFO    ] __main__: train step 14472: loss: 0.9942, policy_loss: 0.9411, value_loss: 0.5862
2024-07-11 17:04:08,833 [INFO    ] __main__: train step 14473: loss: 0.9942, policy_loss: 0.9411, value_loss: 0.5862
2024-07-11 17:04:09,047 [INFO    ] __main__: train step 14474: loss: 0.9941, policy_loss: 0.9411, value_loss: 0.5862
2024-07-11 17:04:09,284 [INFO    ] __main__: train step 14475: loss: 0.9941, policy_loss: 0.9411, value_loss: 0.5862
2024-07-11 17:04:09,482 [INFO    ] __main__: train step 14476: loss: 0.9941, policy_loss: 0.9410, value_loss: 0.5861
2024-07-11 17:04:09,687 [INFO    ] __main__: train step 14477: loss: 0.9941, policy_loss: 0.9410, value_loss: 0.5861
2024-07-11 17:04:09,894 [INFO    ] __main__: train step 14478: loss: 0.9941, policy_loss: 0.9410, value_loss: 0.5861
2024-07-11 17:04:10,106 [INFO    ] __main__: train step 14479: loss: 0.9941, policy_loss: 0.9410, value_loss: 0.5861
2024-07-11 17:04:10,307 [INFO    ] __main__: train step 14480: loss: 0.9941, policy_loss: 0.9409, value_loss: 0.5860
2024-07-11 17:04:10,524 [INFO    ] __main__: train step 14481: loss: 0.9941, policy_loss: 0.9409, value_loss: 0.5860
2024-07-11 17:04:10,726 [INFO    ] __main__: train step 14482: loss: 0.9941, policy_loss: 0.9409, value_loss: 0.5860
2024-07-11 17:04:10,931 [INFO    ] __main__: train step 14483: loss: 0.9941, policy_loss: 0.9409, value_loss: 0.5860
2024-07-11 17:04:12,363 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:04:12,799 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:04:12,862 [INFO    ] __main__: train step 14484: loss: 0.9940, policy_loss: 0.9409, value_loss: 0.5859
2024-07-11 17:04:13,043 [INFO    ] __main__: train step 14485: loss: 0.9940, policy_loss: 0.9408, value_loss: 0.5859
2024-07-11 17:04:13,279 [INFO    ] __main__: train step 14486: loss: 0.9940, policy_loss: 0.9408, value_loss: 0.5859
2024-07-11 17:04:13,493 [INFO    ] __main__: train step 14487: loss: 0.9940, policy_loss: 0.9408, value_loss: 0.5859
2024-07-11 17:04:13,735 [INFO    ] __main__: train step 14488: loss: 0.9940, policy_loss: 0.9408, value_loss: 0.5858
2024-07-11 17:04:13,937 [INFO    ] __main__: train step 14489: loss: 0.9940, policy_loss: 0.9408, value_loss: 0.5858
2024-07-11 17:04:14,137 [INFO    ] __main__: train step 14490: loss: 0.9940, policy_loss: 0.9407, value_loss: 0.5858
2024-07-11 17:04:14,352 [INFO    ] __main__: train step 14491: loss: 0.9940, policy_loss: 0.9407, value_loss: 0.5858
2024-07-11 17:04:14,570 [INFO    ] __main__: train step 14492: loss: 0.9940, policy_loss: 0.9407, value_loss: 0.5857
2024-07-11 17:04:14,812 [INFO    ] __main__: train step 14493: loss: 0.9939, policy_loss: 0.9407, value_loss: 0.5857
2024-07-11 17:04:16,395 [INFO    ] __main__: train step 14494: loss: 0.9939, policy_loss: 0.9406, value_loss: 0.5857
2024-07-11 17:04:16,615 [INFO    ] __main__: train step 14495: loss: 0.9939, policy_loss: 0.9406, value_loss: 0.5857
2024-07-11 17:04:16,848 [INFO    ] __main__: train step 14496: loss: 0.9939, policy_loss: 0.9406, value_loss: 0.5856
2024-07-11 17:04:17,053 [INFO    ] __main__: train step 14497: loss: 0.9939, policy_loss: 0.9406, value_loss: 0.5856
2024-07-11 17:04:17,280 [INFO    ] __main__: train step 14498: loss: 0.9939, policy_loss: 0.9406, value_loss: 0.5856
2024-07-11 17:04:17,479 [INFO    ] __main__: train step 14499: loss: 0.9939, policy_loss: 0.9405, value_loss: 0.5856
2024-07-11 17:04:17,723 [INFO    ] __main__: train step 14500: loss: 0.9939, policy_loss: 0.9405, value_loss: 0.5855
2024-07-11 17:04:19,159 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:04:19,585 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:04:19,646 [INFO    ] __main__: train step 14501: loss: 0.9939, policy_loss: 0.9405, value_loss: 0.5855
2024-07-11 17:04:19,817 [INFO    ] __main__: train step 14502: loss: 0.9939, policy_loss: 0.9405, value_loss: 0.5855
2024-07-11 17:04:20,026 [INFO    ] __main__: train step 14503: loss: 0.9939, policy_loss: 0.9405, value_loss: 0.5855
2024-07-11 17:04:20,237 [INFO    ] __main__: train step 14504: loss: 0.9938, policy_loss: 0.9404, value_loss: 0.5854
2024-07-11 17:04:20,469 [INFO    ] __main__: train step 14505: loss: 0.9938, policy_loss: 0.9404, value_loss: 0.5854
2024-07-11 17:04:20,696 [INFO    ] __main__: train step 14506: loss: 0.9938, policy_loss: 0.9404, value_loss: 0.5854
2024-07-11 17:04:20,929 [INFO    ] __main__: train step 14507: loss: 0.9938, policy_loss: 0.9404, value_loss: 0.5854
2024-07-11 17:04:21,137 [INFO    ] __main__: train step 14508: loss: 0.9938, policy_loss: 0.9403, value_loss: 0.5853
2024-07-11 17:04:21,342 [INFO    ] __main__: train step 14509: loss: 0.9938, policy_loss: 0.9403, value_loss: 0.5853
2024-07-11 17:04:21,550 [INFO    ] __main__: train step 14510: loss: 0.9938, policy_loss: 0.9403, value_loss: 0.5853
2024-07-11 17:04:21,759 [INFO    ] __main__: train step 14511: loss: 0.9938, policy_loss: 0.9403, value_loss: 0.5853
2024-07-11 17:04:21,961 [INFO    ] __main__: train step 14512: loss: 0.9938, policy_loss: 0.9403, value_loss: 0.5852
2024-07-11 17:04:22,165 [INFO    ] __main__: train step 14513: loss: 0.9937, policy_loss: 0.9402, value_loss: 0.5852
2024-07-11 17:04:22,377 [INFO    ] __main__: train step 14514: loss: 0.9937, policy_loss: 0.9402, value_loss: 0.5852
2024-07-11 17:04:22,612 [INFO    ] __main__: train step 14515: loss: 0.9937, policy_loss: 0.9402, value_loss: 0.5852
2024-07-11 17:04:22,830 [INFO    ] __main__: train step 14516: loss: 0.9937, policy_loss: 0.9402, value_loss: 0.5851
2024-07-11 17:04:23,026 [INFO    ] __main__: train step 14517: loss: 0.9937, policy_loss: 0.9402, value_loss: 0.5851
2024-07-11 17:04:24,470 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:04:24,898 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:04:24,956 [INFO    ] __main__: train step 14518: loss: 0.9937, policy_loss: 0.9401, value_loss: 0.5851
2024-07-11 17:04:25,148 [INFO    ] __main__: train step 14519: loss: 0.9937, policy_loss: 0.9401, value_loss: 0.5851
2024-07-11 17:04:25,346 [INFO    ] __main__: train step 14520: loss: 0.9937, policy_loss: 0.9401, value_loss: 0.5850
2024-07-11 17:04:25,551 [INFO    ] __main__: train step 14521: loss: 0.9937, policy_loss: 0.9401, value_loss: 0.5850
2024-07-11 17:04:25,769 [INFO    ] __main__: train step 14522: loss: 0.9936, policy_loss: 0.9400, value_loss: 0.5850
2024-07-11 17:04:26,001 [INFO    ] __main__: train step 14523: loss: 0.9936, policy_loss: 0.9400, value_loss: 0.5850
2024-07-11 17:04:26,211 [INFO    ] __main__: train step 14524: loss: 0.9936, policy_loss: 0.9400, value_loss: 0.5849
2024-07-11 17:04:26,417 [INFO    ] __main__: train step 14525: loss: 0.9936, policy_loss: 0.9400, value_loss: 0.5849
2024-07-11 17:04:26,640 [INFO    ] __main__: train step 14526: loss: 0.9936, policy_loss: 0.9400, value_loss: 0.5849
2024-07-11 17:04:26,880 [INFO    ] __main__: train step 14527: loss: 0.9936, policy_loss: 0.9399, value_loss: 0.5849
2024-07-11 17:04:27,097 [INFO    ] __main__: train step 14528: loss: 0.9936, policy_loss: 0.9399, value_loss: 0.5848
2024-07-11 17:04:27,337 [INFO    ] __main__: train step 14529: loss: 0.9936, policy_loss: 0.9399, value_loss: 0.5848
2024-07-11 17:04:27,542 [INFO    ] __main__: train step 14530: loss: 0.9936, policy_loss: 0.9399, value_loss: 0.5848
2024-07-11 17:04:27,743 [INFO    ] __main__: train step 14531: loss: 0.9936, policy_loss: 0.9398, value_loss: 0.5848
2024-07-11 17:04:27,953 [INFO    ] __main__: train step 14532: loss: 0.9935, policy_loss: 0.9398, value_loss: 0.5847
2024-07-11 17:04:28,163 [INFO    ] __main__: train step 14533: loss: 0.9935, policy_loss: 0.9398, value_loss: 0.5847
2024-07-11 17:04:28,382 [INFO    ] __main__: train step 14534: loss: 0.9935, policy_loss: 0.9398, value_loss: 0.5847
2024-07-11 17:04:29,840 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:04:30,132 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:04:30,186 [INFO    ] __main__: train step 14535: loss: 0.9935, policy_loss: 0.9398, value_loss: 0.5846
2024-07-11 17:04:30,363 [INFO    ] __main__: train step 14536: loss: 0.9935, policy_loss: 0.9397, value_loss: 0.5846
2024-07-11 17:04:30,580 [INFO    ] __main__: train step 14537: loss: 0.9935, policy_loss: 0.9397, value_loss: 0.5846
2024-07-11 17:04:30,784 [INFO    ] __main__: train step 14538: loss: 0.9935, policy_loss: 0.9397, value_loss: 0.5846
2024-07-11 17:04:30,991 [INFO    ] __main__: train step 14539: loss: 0.9935, policy_loss: 0.9397, value_loss: 0.5845
2024-07-11 17:04:31,203 [INFO    ] __main__: train step 14540: loss: 0.9935, policy_loss: 0.9397, value_loss: 0.5845
2024-07-11 17:04:31,418 [INFO    ] __main__: train step 14541: loss: 0.9935, policy_loss: 0.9396, value_loss: 0.5845
2024-07-11 17:04:31,673 [INFO    ] __main__: train step 14542: loss: 0.9934, policy_loss: 0.9396, value_loss: 0.5845
2024-07-11 17:04:31,898 [INFO    ] __main__: train step 14543: loss: 0.9934, policy_loss: 0.9396, value_loss: 0.5844
2024-07-11 17:04:32,104 [INFO    ] __main__: train step 14544: loss: 0.9934, policy_loss: 0.9396, value_loss: 0.5844
2024-07-11 17:04:32,318 [INFO    ] __main__: train step 14545: loss: 0.9934, policy_loss: 0.9396, value_loss: 0.5844
2024-07-11 17:04:32,529 [INFO    ] __main__: train step 14546: loss: 0.9934, policy_loss: 0.9395, value_loss: 0.5844
2024-07-11 17:04:32,769 [INFO    ] __main__: train step 14547: loss: 0.9934, policy_loss: 0.9395, value_loss: 0.5843
2024-07-11 17:04:32,988 [INFO    ] __main__: train step 14548: loss: 0.9934, policy_loss: 0.9395, value_loss: 0.5843
2024-07-11 17:04:33,194 [INFO    ] __main__: train step 14549: loss: 0.9934, policy_loss: 0.9395, value_loss: 0.5843
2024-07-11 17:04:33,433 [INFO    ] __main__: train step 14550: loss: 0.9934, policy_loss: 0.9394, value_loss: 0.5843
2024-07-11 17:04:33,638 [INFO    ] __main__: train step 14551: loss: 0.9934, policy_loss: 0.9394, value_loss: 0.5842
2024-07-11 17:04:35,069 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:04:35,461 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:04:35,517 [INFO    ] __main__: train step 14552: loss: 0.9933, policy_loss: 0.9394, value_loss: 0.5842
2024-07-11 17:04:35,698 [INFO    ] __main__: train step 14553: loss: 0.9933, policy_loss: 0.9394, value_loss: 0.5842
2024-07-11 17:04:35,913 [INFO    ] __main__: train step 14554: loss: 0.9933, policy_loss: 0.9394, value_loss: 0.5842
2024-07-11 17:04:36,144 [INFO    ] __main__: train step 14555: loss: 0.9933, policy_loss: 0.9393, value_loss: 0.5841
2024-07-11 17:04:36,375 [INFO    ] __main__: train step 14556: loss: 0.9933, policy_loss: 0.9393, value_loss: 0.5841
2024-07-11 17:04:36,573 [INFO    ] __main__: train step 14557: loss: 0.9933, policy_loss: 0.9393, value_loss: 0.5841
2024-07-11 17:04:36,771 [INFO    ] __main__: train step 14558: loss: 0.9933, policy_loss: 0.9393, value_loss: 0.5841
2024-07-11 17:04:36,985 [INFO    ] __main__: train step 14559: loss: 0.9933, policy_loss: 0.9393, value_loss: 0.5840
2024-07-11 17:04:37,212 [INFO    ] __main__: train step 14560: loss: 0.9933, policy_loss: 0.9392, value_loss: 0.5840
2024-07-11 17:04:37,417 [INFO    ] __main__: train step 14561: loss: 0.9933, policy_loss: 0.9392, value_loss: 0.5840
2024-07-11 17:04:37,616 [INFO    ] __main__: train step 14562: loss: 0.9932, policy_loss: 0.9392, value_loss: 0.5840
2024-07-11 17:04:37,816 [INFO    ] __main__: train step 14563: loss: 0.9932, policy_loss: 0.9392, value_loss: 0.5839
2024-07-11 17:04:38,023 [INFO    ] __main__: train step 14564: loss: 0.9932, policy_loss: 0.9392, value_loss: 0.5839
2024-07-11 17:04:38,268 [INFO    ] __main__: train step 14565: loss: 0.9932, policy_loss: 0.9391, value_loss: 0.5839
2024-07-11 17:04:38,497 [INFO    ] __main__: train step 14566: loss: 0.9932, policy_loss: 0.9391, value_loss: 0.5839
2024-07-11 17:04:38,708 [INFO    ] __main__: train step 14567: loss: 0.9932, policy_loss: 0.9391, value_loss: 0.5838
2024-07-11 17:04:38,948 [INFO    ] __main__: train step 14568: loss: 0.9932, policy_loss: 0.9391, value_loss: 0.5838
2024-07-11 17:04:40,405 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:04:40,791 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:04:40,848 [INFO    ] __main__: train step 14569: loss: 0.9932, policy_loss: 0.9390, value_loss: 0.5838
2024-07-11 17:04:41,021 [INFO    ] __main__: train step 14570: loss: 0.9932, policy_loss: 0.9390, value_loss: 0.5838
2024-07-11 17:04:41,223 [INFO    ] __main__: train step 14571: loss: 0.9931, policy_loss: 0.9390, value_loss: 0.5837
2024-07-11 17:04:41,434 [INFO    ] __main__: train step 14572: loss: 0.9931, policy_loss: 0.9390, value_loss: 0.5837
2024-07-11 17:04:41,679 [INFO    ] __main__: train step 14573: loss: 0.9931, policy_loss: 0.9390, value_loss: 0.5837
2024-07-11 17:04:41,913 [INFO    ] __main__: train step 14574: loss: 0.9931, policy_loss: 0.9389, value_loss: 0.5837
2024-07-11 17:04:42,157 [INFO    ] __main__: train step 14575: loss: 0.9931, policy_loss: 0.9389, value_loss: 0.5836
2024-07-11 17:04:42,361 [INFO    ] __main__: train step 14576: loss: 0.9931, policy_loss: 0.9389, value_loss: 0.5836
2024-07-11 17:04:42,574 [INFO    ] __main__: train step 14577: loss: 0.9931, policy_loss: 0.9389, value_loss: 0.5836
2024-07-11 17:04:42,778 [INFO    ] __main__: train step 14578: loss: 0.9931, policy_loss: 0.9389, value_loss: 0.5836
2024-07-11 17:04:42,983 [INFO    ] __main__: train step 14579: loss: 0.9931, policy_loss: 0.9388, value_loss: 0.5835
2024-07-11 17:04:43,181 [INFO    ] __main__: train step 14580: loss: 0.9931, policy_loss: 0.9388, value_loss: 0.5835
2024-07-11 17:04:43,388 [INFO    ] __main__: train step 14581: loss: 0.9930, policy_loss: 0.9388, value_loss: 0.5835
2024-07-11 17:04:43,579 [INFO    ] __main__: train step 14582: loss: 0.9930, policy_loss: 0.9388, value_loss: 0.5834
2024-07-11 17:04:43,800 [INFO    ] __main__: train step 14583: loss: 0.9930, policy_loss: 0.9387, value_loss: 0.5834
2024-07-11 17:04:44,001 [INFO    ] __main__: train step 14584: loss: 0.9930, policy_loss: 0.9387, value_loss: 0.5834
2024-07-11 17:04:44,237 [INFO    ] __main__: train step 14585: loss: 0.9930, policy_loss: 0.9387, value_loss: 0.5834
2024-07-11 17:04:45,673 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:04:46,082 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:04:46,144 [INFO    ] __main__: train step 14586: loss: 0.9930, policy_loss: 0.9387, value_loss: 0.5833
2024-07-11 17:04:46,323 [INFO    ] __main__: train step 14587: loss: 0.9930, policy_loss: 0.9387, value_loss: 0.5833
2024-07-11 17:04:46,522 [INFO    ] __main__: train step 14588: loss: 0.9930, policy_loss: 0.9386, value_loss: 0.5833
2024-07-11 17:04:46,728 [INFO    ] __main__: train step 14589: loss: 0.9930, policy_loss: 0.9386, value_loss: 0.5833
2024-07-11 17:04:46,938 [INFO    ] __main__: train step 14590: loss: 0.9929, policy_loss: 0.9386, value_loss: 0.5832
2024-07-11 17:04:47,165 [INFO    ] __main__: train step 14591: loss: 0.9929, policy_loss: 0.9386, value_loss: 0.5832
2024-07-11 17:04:47,380 [INFO    ] __main__: train step 14592: loss: 0.9929, policy_loss: 0.9386, value_loss: 0.5832
2024-07-11 17:04:48,975 [INFO    ] __main__: train step 14593: loss: 0.9929, policy_loss: 0.9385, value_loss: 0.5832
2024-07-11 17:04:49,189 [INFO    ] __main__: train step 14594: loss: 0.9929, policy_loss: 0.9385, value_loss: 0.5831
2024-07-11 17:04:49,391 [INFO    ] __main__: train step 14595: loss: 0.9929, policy_loss: 0.9385, value_loss: 0.5831
2024-07-11 17:04:49,599 [INFO    ] __main__: train step 14596: loss: 0.9929, policy_loss: 0.9385, value_loss: 0.5831
2024-07-11 17:04:49,804 [INFO    ] __main__: train step 14597: loss: 0.9929, policy_loss: 0.9384, value_loss: 0.5831
2024-07-11 17:04:50,009 [INFO    ] __main__: train step 14598: loss: 0.9929, policy_loss: 0.9384, value_loss: 0.5830
2024-07-11 17:04:50,215 [INFO    ] __main__: train step 14599: loss: 0.9928, policy_loss: 0.9384, value_loss: 0.5830
2024-07-11 17:04:50,425 [INFO    ] __main__: train step 14600: loss: 0.9928, policy_loss: 0.9384, value_loss: 0.5830
2024-07-11 17:04:50,638 [INFO    ] __main__: train step 14601: loss: 0.9928, policy_loss: 0.9384, value_loss: 0.5830
2024-07-11 17:04:50,843 [INFO    ] __main__: train step 14602: loss: 0.9928, policy_loss: 0.9383, value_loss: 0.5829
2024-07-11 17:04:52,265 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:04:52,709 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:04:52,764 [INFO    ] __main__: train step 14603: loss: 0.9928, policy_loss: 0.9383, value_loss: 0.5829
2024-07-11 17:04:52,945 [INFO    ] __main__: train step 14604: loss: 0.9928, policy_loss: 0.9383, value_loss: 0.5829
2024-07-11 17:04:53,135 [INFO    ] __main__: train step 14605: loss: 0.9928, policy_loss: 0.9383, value_loss: 0.5829
2024-07-11 17:04:53,346 [INFO    ] __main__: train step 14606: loss: 0.9928, policy_loss: 0.9383, value_loss: 0.5828
2024-07-11 17:04:53,561 [INFO    ] __main__: train step 14607: loss: 0.9928, policy_loss: 0.9382, value_loss: 0.5828
2024-07-11 17:04:53,760 [INFO    ] __main__: train step 14608: loss: 0.9927, policy_loss: 0.9382, value_loss: 0.5828
2024-07-11 17:04:53,966 [INFO    ] __main__: train step 14609: loss: 0.9927, policy_loss: 0.9382, value_loss: 0.5828
2024-07-11 17:04:54,176 [INFO    ] __main__: train step 14610: loss: 0.9927, policy_loss: 0.9382, value_loss: 0.5827
2024-07-11 17:04:54,373 [INFO    ] __main__: train step 14611: loss: 0.9927, policy_loss: 0.9381, value_loss: 0.5827
2024-07-11 17:04:54,573 [INFO    ] __main__: train step 14612: loss: 0.9927, policy_loss: 0.9381, value_loss: 0.5827
2024-07-11 17:04:54,787 [INFO    ] __main__: train step 14613: loss: 0.9927, policy_loss: 0.9381, value_loss: 0.5827
2024-07-11 17:04:54,987 [INFO    ] __main__: train step 14614: loss: 0.9927, policy_loss: 0.9381, value_loss: 0.5826
2024-07-11 17:04:55,191 [INFO    ] __main__: train step 14615: loss: 0.9927, policy_loss: 0.9381, value_loss: 0.5826
2024-07-11 17:04:55,406 [INFO    ] __main__: train step 14616: loss: 0.9927, policy_loss: 0.9380, value_loss: 0.5826
2024-07-11 17:04:55,642 [INFO    ] __main__: train step 14617: loss: 0.9927, policy_loss: 0.9380, value_loss: 0.5826
2024-07-11 17:04:55,846 [INFO    ] __main__: train step 14618: loss: 0.9926, policy_loss: 0.9380, value_loss: 0.5825
2024-07-11 17:04:56,044 [INFO    ] __main__: train step 14619: loss: 0.9926, policy_loss: 0.9380, value_loss: 0.5825
2024-07-11 17:04:57,483 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:04:57,864 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:04:57,919 [INFO    ] __main__: train step 14620: loss: 0.9926, policy_loss: 0.9380, value_loss: 0.5825
2024-07-11 17:04:58,098 [INFO    ] __main__: train step 14621: loss: 0.9926, policy_loss: 0.9379, value_loss: 0.5824
2024-07-11 17:04:58,306 [INFO    ] __main__: train step 14622: loss: 0.9926, policy_loss: 0.9379, value_loss: 0.5824
2024-07-11 17:04:58,542 [INFO    ] __main__: train step 14623: loss: 0.9926, policy_loss: 0.9379, value_loss: 0.5824
2024-07-11 17:04:58,749 [INFO    ] __main__: train step 14624: loss: 0.9926, policy_loss: 0.9379, value_loss: 0.5824
2024-07-11 17:04:58,980 [INFO    ] __main__: train step 14625: loss: 0.9926, policy_loss: 0.9379, value_loss: 0.5823
2024-07-11 17:04:59,184 [INFO    ] __main__: train step 14626: loss: 0.9926, policy_loss: 0.9378, value_loss: 0.5823
2024-07-11 17:04:59,387 [INFO    ] __main__: train step 14627: loss: 0.9925, policy_loss: 0.9378, value_loss: 0.5823
2024-07-11 17:04:59,607 [INFO    ] __main__: train step 14628: loss: 0.9925, policy_loss: 0.9378, value_loss: 0.5823
2024-07-11 17:04:59,809 [INFO    ] __main__: train step 14629: loss: 0.9925, policy_loss: 0.9378, value_loss: 0.5822
2024-07-11 17:05:00,027 [INFO    ] __main__: train step 14630: loss: 0.9925, policy_loss: 0.9377, value_loss: 0.5822
2024-07-11 17:05:00,227 [INFO    ] __main__: train step 14631: loss: 0.9925, policy_loss: 0.9377, value_loss: 0.5822
2024-07-11 17:05:00,433 [INFO    ] __main__: train step 14632: loss: 0.9925, policy_loss: 0.9377, value_loss: 0.5822
2024-07-11 17:05:00,646 [INFO    ] __main__: train step 14633: loss: 0.9925, policy_loss: 0.9377, value_loss: 0.5821
2024-07-11 17:05:00,846 [INFO    ] __main__: train step 14634: loss: 0.9925, policy_loss: 0.9377, value_loss: 0.5821
2024-07-11 17:05:01,047 [INFO    ] __main__: train step 14635: loss: 0.9925, policy_loss: 0.9376, value_loss: 0.5821
2024-07-11 17:05:01,260 [INFO    ] __main__: train step 14636: loss: 0.9925, policy_loss: 0.9376, value_loss: 0.5821
2024-07-11 17:05:02,675 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:05:03,276 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:05:03,339 [INFO    ] __main__: train step 14637: loss: 0.9924, policy_loss: 0.9376, value_loss: 0.5820
2024-07-11 17:05:03,536 [INFO    ] __main__: train step 14638: loss: 0.9924, policy_loss: 0.9376, value_loss: 0.5820
2024-07-11 17:05:03,746 [INFO    ] __main__: train step 14639: loss: 0.9924, policy_loss: 0.9376, value_loss: 0.5820
2024-07-11 17:05:03,953 [INFO    ] __main__: train step 14640: loss: 0.9924, policy_loss: 0.9375, value_loss: 0.5820
2024-07-11 17:05:04,176 [INFO    ] __main__: train step 14641: loss: 0.9924, policy_loss: 0.9375, value_loss: 0.5819
2024-07-11 17:05:05,243 [INFO    ] __main__: train step 14642: loss: 0.9924, policy_loss: 0.9375, value_loss: 0.5819
2024-07-11 17:05:05,460 [INFO    ] __main__: train step 14643: loss: 0.9924, policy_loss: 0.9375, value_loss: 0.5819
2024-07-11 17:05:05,677 [INFO    ] __main__: train step 14644: loss: 0.9924, policy_loss: 0.9374, value_loss: 0.5819
2024-07-11 17:05:05,894 [INFO    ] __main__: train step 14645: loss: 0.9924, policy_loss: 0.9374, value_loss: 0.5818
2024-07-11 17:05:06,095 [INFO    ] __main__: train step 14646: loss: 0.9923, policy_loss: 0.9374, value_loss: 0.5818
2024-07-11 17:05:06,307 [INFO    ] __main__: train step 14647: loss: 0.9923, policy_loss: 0.9374, value_loss: 0.5818
2024-07-11 17:05:06,512 [INFO    ] __main__: train step 14648: loss: 0.9923, policy_loss: 0.9374, value_loss: 0.5818
2024-07-11 17:05:06,720 [INFO    ] __main__: train step 14649: loss: 0.9923, policy_loss: 0.9373, value_loss: 0.5817
2024-07-11 17:05:06,931 [INFO    ] __main__: train step 14650: loss: 0.9923, policy_loss: 0.9373, value_loss: 0.5817
2024-07-11 17:05:07,136 [INFO    ] __main__: train step 14651: loss: 0.9923, policy_loss: 0.9373, value_loss: 0.5817
2024-07-11 17:05:07,346 [INFO    ] __main__: train step 14652: loss: 0.9923, policy_loss: 0.9373, value_loss: 0.5817
2024-07-11 17:05:07,543 [INFO    ] __main__: train step 14653: loss: 0.9923, policy_loss: 0.9373, value_loss: 0.5816
2024-07-11 17:05:09,009 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:05:09,506 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:05:09,565 [INFO    ] __main__: train step 14654: loss: 0.9923, policy_loss: 0.9372, value_loss: 0.5816
2024-07-11 17:05:09,740 [INFO    ] __main__: train step 14655: loss: 0.9922, policy_loss: 0.9372, value_loss: 0.5816
2024-07-11 17:05:09,946 [INFO    ] __main__: train step 14656: loss: 0.9922, policy_loss: 0.9372, value_loss: 0.5816
2024-07-11 17:05:10,161 [INFO    ] __main__: train step 14657: loss: 0.9922, policy_loss: 0.9372, value_loss: 0.5815
2024-07-11 17:05:10,396 [INFO    ] __main__: train step 14658: loss: 0.9922, policy_loss: 0.9371, value_loss: 0.5815
2024-07-11 17:05:10,594 [INFO    ] __main__: train step 14659: loss: 0.9922, policy_loss: 0.9371, value_loss: 0.5815
2024-07-11 17:05:10,806 [INFO    ] __main__: train step 14660: loss: 0.9922, policy_loss: 0.9371, value_loss: 0.5815
2024-07-11 17:05:11,013 [INFO    ] __main__: train step 14661: loss: 0.9922, policy_loss: 0.9371, value_loss: 0.5814
2024-07-11 17:05:11,215 [INFO    ] __main__: train step 14662: loss: 0.9922, policy_loss: 0.9371, value_loss: 0.5814
2024-07-11 17:05:11,429 [INFO    ] __main__: train step 14663: loss: 0.9922, policy_loss: 0.9370, value_loss: 0.5814
2024-07-11 17:05:11,663 [INFO    ] __main__: train step 14664: loss: 0.9921, policy_loss: 0.9370, value_loss: 0.5814
2024-07-11 17:05:11,869 [INFO    ] __main__: train step 14665: loss: 0.9921, policy_loss: 0.9370, value_loss: 0.5813
2024-07-11 17:05:12,085 [INFO    ] __main__: train step 14666: loss: 0.9921, policy_loss: 0.9370, value_loss: 0.5813
2024-07-11 17:05:12,310 [INFO    ] __main__: train step 14667: loss: 0.9921, policy_loss: 0.9370, value_loss: 0.5813
2024-07-11 17:05:12,511 [INFO    ] __main__: train step 14668: loss: 0.9921, policy_loss: 0.9369, value_loss: 0.5813
2024-07-11 17:05:12,705 [INFO    ] __main__: train step 14669: loss: 0.9921, policy_loss: 0.9369, value_loss: 0.5812
2024-07-11 17:05:12,907 [INFO    ] __main__: train step 14670: loss: 0.9921, policy_loss: 0.9369, value_loss: 0.5812
2024-07-11 17:05:14,337 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:05:14,783 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:05:14,842 [INFO    ] __main__: train step 14671: loss: 0.9921, policy_loss: 0.9369, value_loss: 0.5812
2024-07-11 17:05:15,038 [INFO    ] __main__: train step 14672: loss: 0.9921, policy_loss: 0.9368, value_loss: 0.5812
2024-07-11 17:05:15,266 [INFO    ] __main__: train step 14673: loss: 0.9920, policy_loss: 0.9368, value_loss: 0.5811
2024-07-11 17:05:15,471 [INFO    ] __main__: train step 14674: loss: 0.9920, policy_loss: 0.9368, value_loss: 0.5811
2024-07-11 17:05:15,680 [INFO    ] __main__: train step 14675: loss: 0.9920, policy_loss: 0.9368, value_loss: 0.5811
2024-07-11 17:05:15,885 [INFO    ] __main__: train step 14676: loss: 0.9920, policy_loss: 0.9368, value_loss: 0.5811
2024-07-11 17:05:16,090 [INFO    ] __main__: train step 14677: loss: 0.9920, policy_loss: 0.9367, value_loss: 0.5810
2024-07-11 17:05:16,297 [INFO    ] __main__: train step 14678: loss: 0.9920, policy_loss: 0.9367, value_loss: 0.5810
2024-07-11 17:05:16,504 [INFO    ] __main__: train step 14679: loss: 0.9920, policy_loss: 0.9367, value_loss: 0.5810
2024-07-11 17:05:16,703 [INFO    ] __main__: train step 14680: loss: 0.9920, policy_loss: 0.9367, value_loss: 0.5810
2024-07-11 17:05:16,907 [INFO    ] __main__: train step 14681: loss: 0.9920, policy_loss: 0.9367, value_loss: 0.5809
2024-07-11 17:05:17,114 [INFO    ] __main__: train step 14682: loss: 0.9920, policy_loss: 0.9366, value_loss: 0.5809
2024-07-11 17:05:17,329 [INFO    ] __main__: train step 14683: loss: 0.9919, policy_loss: 0.9366, value_loss: 0.5809
2024-07-11 17:05:17,556 [INFO    ] __main__: train step 14684: loss: 0.9919, policy_loss: 0.9366, value_loss: 0.5808
2024-07-11 17:05:17,757 [INFO    ] __main__: train step 14685: loss: 0.9919, policy_loss: 0.9366, value_loss: 0.5808
2024-07-11 17:05:17,980 [INFO    ] __main__: train step 14686: loss: 0.9919, policy_loss: 0.9365, value_loss: 0.5808
2024-07-11 17:05:18,181 [INFO    ] __main__: train step 14687: loss: 0.9919, policy_loss: 0.9365, value_loss: 0.5808
2024-07-11 17:05:19,663 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:05:20,100 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:05:20,157 [INFO    ] __main__: train step 14688: loss: 0.9919, policy_loss: 0.9365, value_loss: 0.5807
2024-07-11 17:05:20,342 [INFO    ] __main__: train step 14689: loss: 0.9919, policy_loss: 0.9365, value_loss: 0.5807
2024-07-11 17:05:21,913 [INFO    ] __main__: train step 14690: loss: 0.9919, policy_loss: 0.9365, value_loss: 0.5807
2024-07-11 17:05:22,124 [INFO    ] __main__: train step 14691: loss: 0.9918, policy_loss: 0.9364, value_loss: 0.5807
2024-07-11 17:05:22,330 [INFO    ] __main__: train step 14692: loss: 0.9918, policy_loss: 0.9364, value_loss: 0.5806
2024-07-11 17:05:22,530 [INFO    ] __main__: train step 14693: loss: 0.9918, policy_loss: 0.9364, value_loss: 0.5806
2024-07-11 17:05:22,732 [INFO    ] __main__: train step 14694: loss: 0.9918, policy_loss: 0.9364, value_loss: 0.5806
2024-07-11 17:05:22,933 [INFO    ] __main__: train step 14695: loss: 0.9918, policy_loss: 0.9363, value_loss: 0.5806
2024-07-11 17:05:23,140 [INFO    ] __main__: train step 14696: loss: 0.9918, policy_loss: 0.9363, value_loss: 0.5805
2024-07-11 17:05:23,345 [INFO    ] __main__: train step 14697: loss: 0.9918, policy_loss: 0.9363, value_loss: 0.5805
2024-07-11 17:05:23,539 [INFO    ] __main__: train step 14698: loss: 0.9918, policy_loss: 0.9363, value_loss: 0.5805
2024-07-11 17:05:23,757 [INFO    ] __main__: train step 14699: loss: 0.9918, policy_loss: 0.9363, value_loss: 0.5805
2024-07-11 17:05:24,010 [INFO    ] __main__: train step 14700: loss: 0.9917, policy_loss: 0.9362, value_loss: 0.5804
2024-07-11 17:05:24,207 [INFO    ] __main__: train step 14701: loss: 0.9917, policy_loss: 0.9362, value_loss: 0.5804
2024-07-11 17:05:24,423 [INFO    ] __main__: train step 14702: loss: 0.9917, policy_loss: 0.9362, value_loss: 0.5804
2024-07-11 17:05:24,623 [INFO    ] __main__: train step 14703: loss: 0.9917, policy_loss: 0.9362, value_loss: 0.5804
2024-07-11 17:05:24,828 [INFO    ] __main__: train step 14704: loss: 0.9917, policy_loss: 0.9362, value_loss: 0.5803
2024-07-11 17:05:26,244 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:05:26,704 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:05:26,766 [INFO    ] __main__: train step 14705: loss: 0.9917, policy_loss: 0.9361, value_loss: 0.5803
2024-07-11 17:05:26,937 [INFO    ] __main__: train step 14706: loss: 0.9917, policy_loss: 0.9361, value_loss: 0.5803
2024-07-11 17:05:27,152 [INFO    ] __main__: train step 14707: loss: 0.9917, policy_loss: 0.9361, value_loss: 0.5803
2024-07-11 17:05:27,364 [INFO    ] __main__: train step 14708: loss: 0.9917, policy_loss: 0.9361, value_loss: 0.5802
2024-07-11 17:05:27,602 [INFO    ] __main__: train step 14709: loss: 0.9916, policy_loss: 0.9361, value_loss: 0.5802
2024-07-11 17:05:27,811 [INFO    ] __main__: train step 14710: loss: 0.9916, policy_loss: 0.9360, value_loss: 0.5802
2024-07-11 17:05:28,016 [INFO    ] __main__: train step 14711: loss: 0.9916, policy_loss: 0.9360, value_loss: 0.5802
2024-07-11 17:05:28,217 [INFO    ] __main__: train step 14712: loss: 0.9916, policy_loss: 0.9360, value_loss: 0.5801
2024-07-11 17:05:28,423 [INFO    ] __main__: train step 14713: loss: 0.9916, policy_loss: 0.9360, value_loss: 0.5801
2024-07-11 17:05:28,623 [INFO    ] __main__: train step 14714: loss: 0.9916, policy_loss: 0.9359, value_loss: 0.5801
2024-07-11 17:05:28,821 [INFO    ] __main__: train step 14715: loss: 0.9916, policy_loss: 0.9359, value_loss: 0.5801
2024-07-11 17:05:29,035 [INFO    ] __main__: train step 14716: loss: 0.9916, policy_loss: 0.9359, value_loss: 0.5800
2024-07-11 17:05:29,232 [INFO    ] __main__: train step 14717: loss: 0.9916, policy_loss: 0.9359, value_loss: 0.5800
2024-07-11 17:05:29,448 [INFO    ] __main__: train step 14718: loss: 0.9915, policy_loss: 0.9359, value_loss: 0.5800
2024-07-11 17:05:29,653 [INFO    ] __main__: train step 14719: loss: 0.9915, policy_loss: 0.9358, value_loss: 0.5800
2024-07-11 17:05:29,869 [INFO    ] __main__: train step 14720: loss: 0.9915, policy_loss: 0.9358, value_loss: 0.5799
2024-07-11 17:05:30,081 [INFO    ] __main__: train step 14721: loss: 0.9915, policy_loss: 0.9358, value_loss: 0.5799
2024-07-11 17:05:31,537 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:05:31,973 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:05:32,035 [INFO    ] __main__: train step 14722: loss: 0.9915, policy_loss: 0.9358, value_loss: 0.5799
2024-07-11 17:05:32,213 [INFO    ] __main__: train step 14723: loss: 0.9915, policy_loss: 0.9357, value_loss: 0.5799
2024-07-11 17:05:32,416 [INFO    ] __main__: train step 14724: loss: 0.9915, policy_loss: 0.9357, value_loss: 0.5798
2024-07-11 17:05:32,624 [INFO    ] __main__: train step 14725: loss: 0.9915, policy_loss: 0.9357, value_loss: 0.5798
2024-07-11 17:05:32,836 [INFO    ] __main__: train step 14726: loss: 0.9915, policy_loss: 0.9357, value_loss: 0.5798
2024-07-11 17:05:33,048 [INFO    ] __main__: train step 14727: loss: 0.9914, policy_loss: 0.9357, value_loss: 0.5798
2024-07-11 17:05:33,280 [INFO    ] __main__: train step 14728: loss: 0.9914, policy_loss: 0.9356, value_loss: 0.5797
2024-07-11 17:05:33,482 [INFO    ] __main__: train step 14729: loss: 0.9914, policy_loss: 0.9356, value_loss: 0.5797
2024-07-11 17:05:33,687 [INFO    ] __main__: train step 14730: loss: 0.9914, policy_loss: 0.9356, value_loss: 0.5797
2024-07-11 17:05:33,898 [INFO    ] __main__: train step 14731: loss: 0.9914, policy_loss: 0.9356, value_loss: 0.5797
2024-07-11 17:05:34,117 [INFO    ] __main__: train step 14732: loss: 0.9914, policy_loss: 0.9356, value_loss: 0.5796
2024-07-11 17:05:34,320 [INFO    ] __main__: train step 14733: loss: 0.9914, policy_loss: 0.9355, value_loss: 0.5796
2024-07-11 17:05:34,529 [INFO    ] __main__: train step 14734: loss: 0.9914, policy_loss: 0.9355, value_loss: 0.5796
2024-07-11 17:05:34,736 [INFO    ] __main__: train step 14735: loss: 0.9914, policy_loss: 0.9355, value_loss: 0.5796
2024-07-11 17:05:34,952 [INFO    ] __main__: train step 14736: loss: 0.9913, policy_loss: 0.9355, value_loss: 0.5795
2024-07-11 17:05:35,180 [INFO    ] __main__: train step 14737: loss: 0.9913, policy_loss: 0.9354, value_loss: 0.5795
2024-07-11 17:05:35,380 [INFO    ] __main__: train step 14738: loss: 0.9913, policy_loss: 0.9354, value_loss: 0.5795
2024-07-11 17:05:36,810 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:05:37,194 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:05:37,249 [INFO    ] __main__: train step 14739: loss: 0.9913, policy_loss: 0.9354, value_loss: 0.5795
2024-07-11 17:05:37,421 [INFO    ] __main__: train step 14740: loss: 0.9913, policy_loss: 0.9354, value_loss: 0.5794
2024-07-11 17:05:37,630 [INFO    ] __main__: train step 14741: loss: 0.9913, policy_loss: 0.9354, value_loss: 0.5794
2024-07-11 17:05:37,835 [INFO    ] __main__: train step 14742: loss: 0.9913, policy_loss: 0.9353, value_loss: 0.5794
2024-07-11 17:05:38,023 [INFO    ] __main__: train step 14743: loss: 0.9913, policy_loss: 0.9353, value_loss: 0.5794
2024-07-11 17:05:38,243 [INFO    ] __main__: train step 14744: loss: 0.9912, policy_loss: 0.9353, value_loss: 0.5793
2024-07-11 17:05:38,460 [INFO    ] __main__: train step 14745: loss: 0.9912, policy_loss: 0.9353, value_loss: 0.5793
2024-07-11 17:05:38,690 [INFO    ] __main__: train step 14746: loss: 0.9912, policy_loss: 0.9352, value_loss: 0.5793
2024-07-11 17:05:38,900 [INFO    ] __main__: train step 14747: loss: 0.9912, policy_loss: 0.9352, value_loss: 0.5793
2024-07-11 17:05:39,124 [INFO    ] __main__: train step 14748: loss: 0.9912, policy_loss: 0.9352, value_loss: 0.5792
2024-07-11 17:05:39,329 [INFO    ] __main__: train step 14749: loss: 0.9912, policy_loss: 0.9352, value_loss: 0.5792
2024-07-11 17:05:39,526 [INFO    ] __main__: train step 14750: loss: 0.9912, policy_loss: 0.9352, value_loss: 0.5792
2024-07-11 17:05:39,728 [INFO    ] __main__: train step 14751: loss: 0.9912, policy_loss: 0.9351, value_loss: 0.5791
2024-07-11 17:05:39,924 [INFO    ] __main__: train step 14752: loss: 0.9912, policy_loss: 0.9351, value_loss: 0.5791
2024-07-11 17:05:40,133 [INFO    ] __main__: train step 14753: loss: 0.9911, policy_loss: 0.9351, value_loss: 0.5791
2024-07-11 17:05:40,343 [INFO    ] __main__: train step 14754: loss: 0.9911, policy_loss: 0.9351, value_loss: 0.5791
2024-07-11 17:05:40,536 [INFO    ] __main__: train step 14755: loss: 0.9911, policy_loss: 0.9351, value_loss: 0.5790
2024-07-11 17:05:41,991 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:05:42,428 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:05:42,492 [INFO    ] __main__: train step 14756: loss: 0.9911, policy_loss: 0.9350, value_loss: 0.5790
2024-07-11 17:05:42,667 [INFO    ] __main__: train step 14757: loss: 0.9911, policy_loss: 0.9350, value_loss: 0.5790
2024-07-11 17:05:42,881 [INFO    ] __main__: train step 14758: loss: 0.9911, policy_loss: 0.9350, value_loss: 0.5790
2024-07-11 17:05:43,085 [INFO    ] __main__: train step 14759: loss: 0.9911, policy_loss: 0.9350, value_loss: 0.5789
2024-07-11 17:05:43,280 [INFO    ] __main__: train step 14760: loss: 0.9911, policy_loss: 0.9349, value_loss: 0.5789
2024-07-11 17:05:43,483 [INFO    ] __main__: train step 14761: loss: 0.9911, policy_loss: 0.9349, value_loss: 0.5789
2024-07-11 17:05:43,697 [INFO    ] __main__: train step 14762: loss: 0.9910, policy_loss: 0.9349, value_loss: 0.5789
2024-07-11 17:05:43,900 [INFO    ] __main__: train step 14763: loss: 0.9910, policy_loss: 0.9349, value_loss: 0.5788
2024-07-11 17:05:44,136 [INFO    ] __main__: train step 14764: loss: 0.9910, policy_loss: 0.9349, value_loss: 0.5788
2024-07-11 17:05:44,343 [INFO    ] __main__: train step 14765: loss: 0.9910, policy_loss: 0.9348, value_loss: 0.5788
2024-07-11 17:05:44,556 [INFO    ] __main__: train step 14766: loss: 0.9910, policy_loss: 0.9348, value_loss: 0.5788
2024-07-11 17:05:44,758 [INFO    ] __main__: train step 14767: loss: 0.9910, policy_loss: 0.9348, value_loss: 0.5787
2024-07-11 17:05:44,963 [INFO    ] __main__: train step 14768: loss: 0.9910, policy_loss: 0.9348, value_loss: 0.5787
2024-07-11 17:05:45,179 [INFO    ] __main__: train step 14769: loss: 0.9910, policy_loss: 0.9347, value_loss: 0.5787
2024-07-11 17:05:45,419 [INFO    ] __main__: train step 14770: loss: 0.9909, policy_loss: 0.9347, value_loss: 0.5787
2024-07-11 17:05:45,617 [INFO    ] __main__: train step 14771: loss: 0.9909, policy_loss: 0.9347, value_loss: 0.5786
2024-07-11 17:05:45,825 [INFO    ] __main__: train step 14772: loss: 0.9909, policy_loss: 0.9347, value_loss: 0.5786
2024-07-11 17:05:47,263 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:05:47,676 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:05:47,731 [INFO    ] __main__: train step 14773: loss: 0.9909, policy_loss: 0.9347, value_loss: 0.5786
2024-07-11 17:05:47,912 [INFO    ] __main__: train step 14774: loss: 0.9909, policy_loss: 0.9346, value_loss: 0.5786
2024-07-11 17:05:48,139 [INFO    ] __main__: train step 14775: loss: 0.9909, policy_loss: 0.9346, value_loss: 0.5785
2024-07-11 17:05:48,338 [INFO    ] __main__: train step 14776: loss: 0.9909, policy_loss: 0.9346, value_loss: 0.5785
2024-07-11 17:05:48,545 [INFO    ] __main__: train step 14777: loss: 0.9909, policy_loss: 0.9346, value_loss: 0.5785
2024-07-11 17:05:48,749 [INFO    ] __main__: train step 14778: loss: 0.9909, policy_loss: 0.9346, value_loss: 0.5785
2024-07-11 17:05:48,946 [INFO    ] __main__: train step 14779: loss: 0.9908, policy_loss: 0.9345, value_loss: 0.5784
2024-07-11 17:05:49,147 [INFO    ] __main__: train step 14780: loss: 0.9908, policy_loss: 0.9345, value_loss: 0.5784
2024-07-11 17:05:49,351 [INFO    ] __main__: train step 14781: loss: 0.9908, policy_loss: 0.9345, value_loss: 0.5784
2024-07-11 17:05:49,563 [INFO    ] __main__: train step 14782: loss: 0.9908, policy_loss: 0.9345, value_loss: 0.5784
2024-07-11 17:05:49,801 [INFO    ] __main__: train step 14783: loss: 0.9908, policy_loss: 0.9344, value_loss: 0.5783
2024-07-11 17:05:50,010 [INFO    ] __main__: train step 14784: loss: 0.9908, policy_loss: 0.9344, value_loss: 0.5783
2024-07-11 17:05:50,246 [INFO    ] __main__: train step 14785: loss: 0.9908, policy_loss: 0.9344, value_loss: 0.5783
2024-07-11 17:05:50,463 [INFO    ] __main__: train step 14786: loss: 0.9908, policy_loss: 0.9344, value_loss: 0.5783
2024-07-11 17:05:50,699 [INFO    ] __main__: train step 14787: loss: 0.9908, policy_loss: 0.9344, value_loss: 0.5782
2024-07-11 17:05:52,242 [INFO    ] __main__: train step 14788: loss: 0.9907, policy_loss: 0.9343, value_loss: 0.5782
2024-07-11 17:05:52,455 [INFO    ] __main__: train step 14789: loss: 0.9907, policy_loss: 0.9343, value_loss: 0.5782
2024-07-11 17:05:53,888 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:05:54,298 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:05:54,353 [INFO    ] __main__: train step 14790: loss: 0.9907, policy_loss: 0.9343, value_loss: 0.5782
2024-07-11 17:05:54,530 [INFO    ] __main__: train step 14791: loss: 0.9907, policy_loss: 0.9343, value_loss: 0.5781
2024-07-11 17:05:54,732 [INFO    ] __main__: train step 14792: loss: 0.9907, policy_loss: 0.9343, value_loss: 0.5781
2024-07-11 17:05:54,932 [INFO    ] __main__: train step 14793: loss: 0.9907, policy_loss: 0.9342, value_loss: 0.5781
2024-07-11 17:05:55,130 [INFO    ] __main__: train step 14794: loss: 0.9907, policy_loss: 0.9342, value_loss: 0.5781
2024-07-11 17:05:55,333 [INFO    ] __main__: train step 14795: loss: 0.9907, policy_loss: 0.9342, value_loss: 0.5780
2024-07-11 17:05:55,534 [INFO    ] __main__: train step 14796: loss: 0.9906, policy_loss: 0.9342, value_loss: 0.5780
2024-07-11 17:05:55,744 [INFO    ] __main__: train step 14797: loss: 0.9906, policy_loss: 0.9341, value_loss: 0.5780
2024-07-11 17:05:55,981 [INFO    ] __main__: train step 14798: loss: 0.9906, policy_loss: 0.9341, value_loss: 0.5780
2024-07-11 17:05:56,181 [INFO    ] __main__: train step 14799: loss: 0.9906, policy_loss: 0.9341, value_loss: 0.5779
2024-07-11 17:05:56,386 [INFO    ] __main__: train step 14800: loss: 0.9906, policy_loss: 0.9341, value_loss: 0.5779
2024-07-11 17:05:56,608 [INFO    ] __main__: train step 14801: loss: 0.9906, policy_loss: 0.9341, value_loss: 0.5779
2024-07-11 17:05:56,806 [INFO    ] __main__: train step 14802: loss: 0.9906, policy_loss: 0.9340, value_loss: 0.5779
2024-07-11 17:05:57,036 [INFO    ] __main__: train step 14803: loss: 0.9906, policy_loss: 0.9340, value_loss: 0.5778
2024-07-11 17:05:57,275 [INFO    ] __main__: train step 14804: loss: 0.9906, policy_loss: 0.9340, value_loss: 0.5778
2024-07-11 17:05:57,473 [INFO    ] __main__: train step 14805: loss: 0.9905, policy_loss: 0.9340, value_loss: 0.5778
2024-07-11 17:05:57,678 [INFO    ] __main__: train step 14806: loss: 0.9905, policy_loss: 0.9340, value_loss: 0.5778
2024-07-11 17:05:59,120 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:05:59,526 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:05:59,582 [INFO    ] __main__: train step 14807: loss: 0.9905, policy_loss: 0.9339, value_loss: 0.5777
2024-07-11 17:05:59,762 [INFO    ] __main__: train step 14808: loss: 0.9905, policy_loss: 0.9339, value_loss: 0.5777
2024-07-11 17:06:00,018 [INFO    ] __main__: train step 14809: loss: 0.9905, policy_loss: 0.9339, value_loss: 0.5777
2024-07-11 17:06:00,224 [INFO    ] __main__: train step 14810: loss: 0.9905, policy_loss: 0.9339, value_loss: 0.5777
2024-07-11 17:06:00,430 [INFO    ] __main__: train step 14811: loss: 0.9905, policy_loss: 0.9338, value_loss: 0.5776
2024-07-11 17:06:00,635 [INFO    ] __main__: train step 14812: loss: 0.9905, policy_loss: 0.9338, value_loss: 0.5776
2024-07-11 17:06:00,842 [INFO    ] __main__: train step 14813: loss: 0.9904, policy_loss: 0.9338, value_loss: 0.5776
2024-07-11 17:06:01,065 [INFO    ] __main__: train step 14814: loss: 0.9904, policy_loss: 0.9338, value_loss: 0.5776
2024-07-11 17:06:01,259 [INFO    ] __main__: train step 14815: loss: 0.9904, policy_loss: 0.9338, value_loss: 0.5775
2024-07-11 17:06:01,460 [INFO    ] __main__: train step 14816: loss: 0.9904, policy_loss: 0.9337, value_loss: 0.5775
2024-07-11 17:06:01,665 [INFO    ] __main__: train step 14817: loss: 0.9904, policy_loss: 0.9337, value_loss: 0.5775
2024-07-11 17:06:01,866 [INFO    ] __main__: train step 14818: loss: 0.9904, policy_loss: 0.9337, value_loss: 0.5775
2024-07-11 17:06:02,074 [INFO    ] __main__: train step 14819: loss: 0.9904, policy_loss: 0.9337, value_loss: 0.5774
2024-07-11 17:06:02,292 [INFO    ] __main__: train step 14820: loss: 0.9904, policy_loss: 0.9336, value_loss: 0.5774
2024-07-11 17:06:02,530 [INFO    ] __main__: train step 14821: loss: 0.9904, policy_loss: 0.9336, value_loss: 0.5774
2024-07-11 17:06:02,733 [INFO    ] __main__: train step 14822: loss: 0.9903, policy_loss: 0.9336, value_loss: 0.5774
2024-07-11 17:06:02,940 [INFO    ] __main__: train step 14823: loss: 0.9903, policy_loss: 0.9336, value_loss: 0.5773
2024-07-11 17:06:04,382 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:06:04,818 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:06:04,881 [INFO    ] __main__: train step 14824: loss: 0.9903, policy_loss: 0.9336, value_loss: 0.5773
2024-07-11 17:06:05,054 [INFO    ] __main__: train step 14825: loss: 0.9903, policy_loss: 0.9335, value_loss: 0.5773
2024-07-11 17:06:05,259 [INFO    ] __main__: train step 14826: loss: 0.9903, policy_loss: 0.9335, value_loss: 0.5773
2024-07-11 17:06:05,459 [INFO    ] __main__: train step 14827: loss: 0.9903, policy_loss: 0.9335, value_loss: 0.5772
2024-07-11 17:06:05,672 [INFO    ] __main__: train step 14828: loss: 0.9903, policy_loss: 0.9335, value_loss: 0.5772
2024-07-11 17:06:05,873 [INFO    ] __main__: train step 14829: loss: 0.9903, policy_loss: 0.9335, value_loss: 0.5772
2024-07-11 17:06:06,096 [INFO    ] __main__: train step 14830: loss: 0.9903, policy_loss: 0.9334, value_loss: 0.5772
2024-07-11 17:06:06,314 [INFO    ] __main__: train step 14831: loss: 0.9902, policy_loss: 0.9334, value_loss: 0.5771
2024-07-11 17:06:06,513 [INFO    ] __main__: train step 14832: loss: 0.9902, policy_loss: 0.9334, value_loss: 0.5771
2024-07-11 17:06:06,715 [INFO    ] __main__: train step 14833: loss: 0.9902, policy_loss: 0.9334, value_loss: 0.5771
2024-07-11 17:06:06,922 [INFO    ] __main__: train step 14834: loss: 0.9902, policy_loss: 0.9333, value_loss: 0.5771
2024-07-11 17:06:07,122 [INFO    ] __main__: train step 14835: loss: 0.9902, policy_loss: 0.9333, value_loss: 0.5770
2024-07-11 17:06:07,325 [INFO    ] __main__: train step 14836: loss: 0.9902, policy_loss: 0.9333, value_loss: 0.5770
2024-07-11 17:06:07,523 [INFO    ] __main__: train step 14837: loss: 0.9902, policy_loss: 0.9333, value_loss: 0.5770
2024-07-11 17:06:07,720 [INFO    ] __main__: train step 14838: loss: 0.9902, policy_loss: 0.9333, value_loss: 0.5770
2024-07-11 17:06:07,934 [INFO    ] __main__: train step 14839: loss: 0.9901, policy_loss: 0.9332, value_loss: 0.5769
2024-07-11 17:06:08,136 [INFO    ] __main__: train step 14840: loss: 0.9901, policy_loss: 0.9332, value_loss: 0.5769
2024-07-11 17:06:09,596 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:06:09,988 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:06:10,046 [INFO    ] __main__: train step 14841: loss: 0.9901, policy_loss: 0.9332, value_loss: 0.5769
2024-07-11 17:06:10,220 [INFO    ] __main__: train step 14842: loss: 0.9901, policy_loss: 0.9332, value_loss: 0.5769
2024-07-11 17:06:10,419 [INFO    ] __main__: train step 14843: loss: 0.9901, policy_loss: 0.9331, value_loss: 0.5768
2024-07-11 17:06:10,626 [INFO    ] __main__: train step 14844: loss: 0.9901, policy_loss: 0.9331, value_loss: 0.5768
2024-07-11 17:06:10,864 [INFO    ] __main__: train step 14845: loss: 0.9901, policy_loss: 0.9331, value_loss: 0.5768
2024-07-11 17:06:11,064 [INFO    ] __main__: train step 14846: loss: 0.9901, policy_loss: 0.9331, value_loss: 0.5768
2024-07-11 17:06:11,268 [INFO    ] __main__: train step 14847: loss: 0.9901, policy_loss: 0.9331, value_loss: 0.5767
2024-07-11 17:06:11,508 [INFO    ] __main__: train step 14848: loss: 0.9900, policy_loss: 0.9330, value_loss: 0.5767
2024-07-11 17:06:11,727 [INFO    ] __main__: train step 14849: loss: 0.9900, policy_loss: 0.9330, value_loss: 0.5767
2024-07-11 17:06:11,969 [INFO    ] __main__: train step 14850: loss: 0.9900, policy_loss: 0.9330, value_loss: 0.5767
2024-07-11 17:06:12,165 [INFO    ] __main__: train step 14851: loss: 0.9900, policy_loss: 0.9330, value_loss: 0.5766
2024-07-11 17:06:12,373 [INFO    ] __main__: train step 14852: loss: 0.9900, policy_loss: 0.9330, value_loss: 0.5766
2024-07-11 17:06:12,609 [INFO    ] __main__: train step 14853: loss: 0.9900, policy_loss: 0.9329, value_loss: 0.5766
2024-07-11 17:06:12,815 [INFO    ] __main__: train step 14854: loss: 0.9900, policy_loss: 0.9329, value_loss: 0.5766
2024-07-11 17:06:13,018 [INFO    ] __main__: train step 14855: loss: 0.9900, policy_loss: 0.9329, value_loss: 0.5765
2024-07-11 17:06:13,223 [INFO    ] __main__: train step 14856: loss: 0.9899, policy_loss: 0.9329, value_loss: 0.5765
2024-07-11 17:06:13,457 [INFO    ] __main__: train step 14857: loss: 0.9899, policy_loss: 0.9328, value_loss: 0.5765
2024-07-11 17:06:14,893 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:06:15,293 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:06:15,349 [INFO    ] __main__: train step 14858: loss: 0.9899, policy_loss: 0.9328, value_loss: 0.5765
2024-07-11 17:06:15,521 [INFO    ] __main__: train step 14859: loss: 0.9899, policy_loss: 0.9328, value_loss: 0.5764
2024-07-11 17:06:15,724 [INFO    ] __main__: train step 14860: loss: 0.9899, policy_loss: 0.9328, value_loss: 0.5764
2024-07-11 17:06:15,927 [INFO    ] __main__: train step 14861: loss: 0.9899, policy_loss: 0.9328, value_loss: 0.5764
2024-07-11 17:06:16,126 [INFO    ] __main__: train step 14862: loss: 0.9899, policy_loss: 0.9327, value_loss: 0.5764
2024-07-11 17:06:16,332 [INFO    ] __main__: train step 14863: loss: 0.9899, policy_loss: 0.9327, value_loss: 0.5763
2024-07-11 17:06:16,533 [INFO    ] __main__: train step 14864: loss: 0.9898, policy_loss: 0.9327, value_loss: 0.5763
2024-07-11 17:06:16,743 [INFO    ] __main__: train step 14865: loss: 0.9898, policy_loss: 0.9327, value_loss: 0.5763
2024-07-11 17:06:16,989 [INFO    ] __main__: train step 14866: loss: 0.9898, policy_loss: 0.9326, value_loss: 0.5763
2024-07-11 17:06:17,221 [INFO    ] __main__: train step 14867: loss: 0.9898, policy_loss: 0.9326, value_loss: 0.5762
2024-07-11 17:06:17,433 [INFO    ] __main__: train step 14868: loss: 0.9898, policy_loss: 0.9326, value_loss: 0.5762
2024-07-11 17:06:17,657 [INFO    ] __main__: train step 14869: loss: 0.9898, policy_loss: 0.9326, value_loss: 0.5762
2024-07-11 17:06:17,883 [INFO    ] __main__: train step 14870: loss: 0.9898, policy_loss: 0.9326, value_loss: 0.5762
2024-07-11 17:06:18,092 [INFO    ] __main__: train step 14871: loss: 0.9898, policy_loss: 0.9325, value_loss: 0.5761
2024-07-11 17:06:18,333 [INFO    ] __main__: train step 14872: loss: 0.9898, policy_loss: 0.9325, value_loss: 0.5761
2024-07-11 17:06:18,547 [INFO    ] __main__: train step 14873: loss: 0.9897, policy_loss: 0.9325, value_loss: 0.5761
2024-07-11 17:06:18,747 [INFO    ] __main__: train step 14874: loss: 0.9897, policy_loss: 0.9325, value_loss: 0.5761
2024-07-11 17:06:20,190 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:06:20,602 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:06:20,658 [INFO    ] __main__: train step 14875: loss: 0.9897, policy_loss: 0.9324, value_loss: 0.5760
2024-07-11 17:06:20,846 [INFO    ] __main__: train step 14876: loss: 0.9897, policy_loss: 0.9324, value_loss: 0.5760
2024-07-11 17:06:21,091 [INFO    ] __main__: train step 14877: loss: 0.9897, policy_loss: 0.9324, value_loss: 0.5760
2024-07-11 17:06:21,315 [INFO    ] __main__: train step 14878: loss: 0.9897, policy_loss: 0.9324, value_loss: 0.5760
2024-07-11 17:06:21,510 [INFO    ] __main__: train step 14879: loss: 0.9897, policy_loss: 0.9324, value_loss: 0.5759
2024-07-11 17:06:21,707 [INFO    ] __main__: train step 14880: loss: 0.9897, policy_loss: 0.9323, value_loss: 0.5759
2024-07-11 17:06:21,924 [INFO    ] __main__: train step 14881: loss: 0.9896, policy_loss: 0.9323, value_loss: 0.5759
2024-07-11 17:06:22,127 [INFO    ] __main__: train step 14882: loss: 0.9896, policy_loss: 0.9323, value_loss: 0.5759
2024-07-11 17:06:22,326 [INFO    ] __main__: train step 14883: loss: 0.9896, policy_loss: 0.9323, value_loss: 0.5758
2024-07-11 17:06:22,534 [INFO    ] __main__: train step 14884: loss: 0.9896, policy_loss: 0.9323, value_loss: 0.5758
2024-07-11 17:06:22,730 [INFO    ] __main__: train step 14885: loss: 0.9896, policy_loss: 0.9322, value_loss: 0.5758
2024-07-11 17:06:22,942 [INFO    ] __main__: train step 14886: loss: 0.9896, policy_loss: 0.9322, value_loss: 0.5758
2024-07-11 17:06:24,521 [INFO    ] __main__: train step 14887: loss: 0.9896, policy_loss: 0.9322, value_loss: 0.5757
2024-07-11 17:06:24,736 [INFO    ] __main__: train step 14888: loss: 0.9896, policy_loss: 0.9322, value_loss: 0.5757
2024-07-11 17:06:24,936 [INFO    ] __main__: train step 14889: loss: 0.9895, policy_loss: 0.9321, value_loss: 0.5757
2024-07-11 17:06:25,151 [INFO    ] __main__: train step 14890: loss: 0.9895, policy_loss: 0.9321, value_loss: 0.5757
2024-07-11 17:06:25,381 [INFO    ] __main__: train step 14891: loss: 0.9895, policy_loss: 0.9321, value_loss: 0.5756
2024-07-11 17:06:26,824 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:06:27,259 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:06:27,317 [INFO    ] __main__: train step 14892: loss: 0.9895, policy_loss: 0.9321, value_loss: 0.5756
2024-07-11 17:06:27,489 [INFO    ] __main__: train step 14893: loss: 0.9895, policy_loss: 0.9321, value_loss: 0.5756
2024-07-11 17:06:27,701 [INFO    ] __main__: train step 14894: loss: 0.9895, policy_loss: 0.9320, value_loss: 0.5756
2024-07-11 17:06:27,916 [INFO    ] __main__: train step 14895: loss: 0.9895, policy_loss: 0.9320, value_loss: 0.5755
2024-07-11 17:06:28,126 [INFO    ] __main__: train step 14896: loss: 0.9895, policy_loss: 0.9320, value_loss: 0.5755
2024-07-11 17:06:28,336 [INFO    ] __main__: train step 14897: loss: 0.9895, policy_loss: 0.9320, value_loss: 0.5755
2024-07-11 17:06:28,539 [INFO    ] __main__: train step 14898: loss: 0.9894, policy_loss: 0.9319, value_loss: 0.5755
2024-07-11 17:06:28,747 [INFO    ] __main__: train step 14899: loss: 0.9894, policy_loss: 0.9319, value_loss: 0.5754
2024-07-11 17:06:28,954 [INFO    ] __main__: train step 14900: loss: 0.9894, policy_loss: 0.9319, value_loss: 0.5754
2024-07-11 17:06:29,163 [INFO    ] __main__: train step 14901: loss: 0.9894, policy_loss: 0.9319, value_loss: 0.5754
2024-07-11 17:06:29,376 [INFO    ] __main__: train step 14902: loss: 0.9894, policy_loss: 0.9319, value_loss: 0.5754
2024-07-11 17:06:29,577 [INFO    ] __main__: train step 14903: loss: 0.9894, policy_loss: 0.9318, value_loss: 0.5753
2024-07-11 17:06:29,787 [INFO    ] __main__: train step 14904: loss: 0.9894, policy_loss: 0.9318, value_loss: 0.5753
2024-07-11 17:06:29,996 [INFO    ] __main__: train step 14905: loss: 0.9894, policy_loss: 0.9318, value_loss: 0.5753
2024-07-11 17:06:30,204 [INFO    ] __main__: train step 14906: loss: 0.9893, policy_loss: 0.9318, value_loss: 0.5753
2024-07-11 17:06:30,407 [INFO    ] __main__: train step 14907: loss: 0.9893, policy_loss: 0.9318, value_loss: 0.5752
2024-07-11 17:06:30,600 [INFO    ] __main__: train step 14908: loss: 0.9893, policy_loss: 0.9317, value_loss: 0.5752
2024-07-11 17:06:32,035 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:06:32,501 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:06:32,556 [INFO    ] __main__: train step 14909: loss: 0.9893, policy_loss: 0.9317, value_loss: 0.5752
2024-07-11 17:06:32,743 [INFO    ] __main__: train step 14910: loss: 0.9893, policy_loss: 0.9317, value_loss: 0.5752
2024-07-11 17:06:32,981 [INFO    ] __main__: train step 14911: loss: 0.9893, policy_loss: 0.9317, value_loss: 0.5751
2024-07-11 17:06:33,179 [INFO    ] __main__: train step 14912: loss: 0.9893, policy_loss: 0.9316, value_loss: 0.5751
2024-07-11 17:06:33,393 [INFO    ] __main__: train step 14913: loss: 0.9893, policy_loss: 0.9316, value_loss: 0.5751
2024-07-11 17:06:33,594 [INFO    ] __main__: train step 14914: loss: 0.9893, policy_loss: 0.9316, value_loss: 0.5751
2024-07-11 17:06:33,799 [INFO    ] __main__: train step 14915: loss: 0.9892, policy_loss: 0.9316, value_loss: 0.5750
2024-07-11 17:06:34,005 [INFO    ] __main__: train step 14916: loss: 0.9892, policy_loss: 0.9316, value_loss: 0.5750
2024-07-11 17:06:34,214 [INFO    ] __main__: train step 14917: loss: 0.9892, policy_loss: 0.9315, value_loss: 0.5750
2024-07-11 17:06:34,420 [INFO    ] __main__: train step 14918: loss: 0.9892, policy_loss: 0.9315, value_loss: 0.5750
2024-07-11 17:06:34,626 [INFO    ] __main__: train step 14919: loss: 0.9892, policy_loss: 0.9315, value_loss: 0.5749
2024-07-11 17:06:34,825 [INFO    ] __main__: train step 14920: loss: 0.9892, policy_loss: 0.9315, value_loss: 0.5749
2024-07-11 17:06:35,032 [INFO    ] __main__: train step 14921: loss: 0.9892, policy_loss: 0.9315, value_loss: 0.5749
2024-07-11 17:06:35,242 [INFO    ] __main__: train step 14922: loss: 0.9892, policy_loss: 0.9314, value_loss: 0.5749
2024-07-11 17:06:35,453 [INFO    ] __main__: train step 14923: loss: 0.9892, policy_loss: 0.9314, value_loss: 0.5748
2024-07-11 17:06:35,689 [INFO    ] __main__: train step 14924: loss: 0.9891, policy_loss: 0.9314, value_loss: 0.5748
2024-07-11 17:06:35,900 [INFO    ] __main__: train step 14925: loss: 0.9891, policy_loss: 0.9314, value_loss: 0.5748
2024-07-11 17:06:37,323 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:06:37,701 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:06:37,756 [INFO    ] __main__: train step 14926: loss: 0.9891, policy_loss: 0.9313, value_loss: 0.5748
2024-07-11 17:06:37,943 [INFO    ] __main__: train step 14927: loss: 0.9891, policy_loss: 0.9313, value_loss: 0.5747
2024-07-11 17:06:38,177 [INFO    ] __main__: train step 14928: loss: 0.9891, policy_loss: 0.9313, value_loss: 0.5747
2024-07-11 17:06:38,377 [INFO    ] __main__: train step 14929: loss: 0.9891, policy_loss: 0.9313, value_loss: 0.5747
2024-07-11 17:06:38,591 [INFO    ] __main__: train step 14930: loss: 0.9891, policy_loss: 0.9313, value_loss: 0.5747
2024-07-11 17:06:38,791 [INFO    ] __main__: train step 14931: loss: 0.9891, policy_loss: 0.9312, value_loss: 0.5746
2024-07-11 17:06:39,013 [INFO    ] __main__: train step 14932: loss: 0.9890, policy_loss: 0.9312, value_loss: 0.5746
2024-07-11 17:06:39,213 [INFO    ] __main__: train step 14933: loss: 0.9890, policy_loss: 0.9312, value_loss: 0.5746
2024-07-11 17:06:39,454 [INFO    ] __main__: train step 14934: loss: 0.9890, policy_loss: 0.9312, value_loss: 0.5746
2024-07-11 17:06:39,649 [INFO    ] __main__: train step 14935: loss: 0.9890, policy_loss: 0.9312, value_loss: 0.5745
2024-07-11 17:06:39,845 [INFO    ] __main__: train step 14936: loss: 0.9890, policy_loss: 0.9311, value_loss: 0.5745
2024-07-11 17:06:40,055 [INFO    ] __main__: train step 14937: loss: 0.9890, policy_loss: 0.9311, value_loss: 0.5745
2024-07-11 17:06:40,262 [INFO    ] __main__: train step 14938: loss: 0.9890, policy_loss: 0.9311, value_loss: 0.5745
2024-07-11 17:06:40,499 [INFO    ] __main__: train step 14939: loss: 0.9890, policy_loss: 0.9311, value_loss: 0.5744
2024-07-11 17:06:40,705 [INFO    ] __main__: train step 14940: loss: 0.9889, policy_loss: 0.9310, value_loss: 0.5744
2024-07-11 17:06:40,911 [INFO    ] __main__: train step 14941: loss: 0.9889, policy_loss: 0.9310, value_loss: 0.5744
2024-07-11 17:06:41,109 [INFO    ] __main__: train step 14942: loss: 0.9889, policy_loss: 0.9310, value_loss: 0.5744
2024-07-11 17:06:42,562 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:06:42,939 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:06:42,995 [INFO    ] __main__: train step 14943: loss: 0.9889, policy_loss: 0.9310, value_loss: 0.5743
2024-07-11 17:06:43,172 [INFO    ] __main__: train step 14944: loss: 0.9889, policy_loss: 0.9310, value_loss: 0.5743
2024-07-11 17:06:43,376 [INFO    ] __main__: train step 14945: loss: 0.9889, policy_loss: 0.9309, value_loss: 0.5743
2024-07-11 17:06:43,591 [INFO    ] __main__: train step 14946: loss: 0.9889, policy_loss: 0.9309, value_loss: 0.5743
2024-07-11 17:06:43,802 [INFO    ] __main__: train step 14947: loss: 0.9889, policy_loss: 0.9309, value_loss: 0.5742
2024-07-11 17:06:43,992 [INFO    ] __main__: train step 14948: loss: 0.9889, policy_loss: 0.9309, value_loss: 0.5742
2024-07-11 17:06:44,197 [INFO    ] __main__: train step 14949: loss: 0.9888, policy_loss: 0.9308, value_loss: 0.5742
2024-07-11 17:06:44,402 [INFO    ] __main__: train step 14950: loss: 0.9888, policy_loss: 0.9308, value_loss: 0.5742
2024-07-11 17:06:44,615 [INFO    ] __main__: train step 14951: loss: 0.9888, policy_loss: 0.9308, value_loss: 0.5741
2024-07-11 17:06:44,813 [INFO    ] __main__: train step 14952: loss: 0.9888, policy_loss: 0.9308, value_loss: 0.5741
2024-07-11 17:06:45,027 [INFO    ] __main__: train step 14953: loss: 0.9888, policy_loss: 0.9308, value_loss: 0.5741
2024-07-11 17:06:45,230 [INFO    ] __main__: train step 14954: loss: 0.9888, policy_loss: 0.9307, value_loss: 0.5741
2024-07-11 17:06:45,431 [INFO    ] __main__: train step 14955: loss: 0.9888, policy_loss: 0.9307, value_loss: 0.5740
2024-07-11 17:06:45,637 [INFO    ] __main__: train step 14956: loss: 0.9888, policy_loss: 0.9307, value_loss: 0.5740
2024-07-11 17:06:45,846 [INFO    ] __main__: train step 14957: loss: 0.9887, policy_loss: 0.9307, value_loss: 0.5740
2024-07-11 17:06:46,044 [INFO    ] __main__: train step 14958: loss: 0.9887, policy_loss: 0.9306, value_loss: 0.5740
2024-07-11 17:06:46,246 [INFO    ] __main__: train step 14959: loss: 0.9887, policy_loss: 0.9306, value_loss: 0.5739
2024-07-11 17:06:47,681 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:06:48,124 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:06:48,186 [INFO    ] __main__: train step 14960: loss: 0.9887, policy_loss: 0.9306, value_loss: 0.5739
2024-07-11 17:06:48,365 [INFO    ] __main__: train step 14961: loss: 0.9887, policy_loss: 0.9306, value_loss: 0.5739
2024-07-11 17:06:48,566 [INFO    ] __main__: train step 14962: loss: 0.9887, policy_loss: 0.9306, value_loss: 0.5739
2024-07-11 17:06:48,765 [INFO    ] __main__: train step 14963: loss: 0.9887, policy_loss: 0.9305, value_loss: 0.5739
2024-07-11 17:06:48,969 [INFO    ] __main__: train step 14964: loss: 0.9887, policy_loss: 0.9305, value_loss: 0.5738
2024-07-11 17:06:49,170 [INFO    ] __main__: train step 14965: loss: 0.9887, policy_loss: 0.9305, value_loss: 0.5738
2024-07-11 17:06:49,363 [INFO    ] __main__: train step 14966: loss: 0.9886, policy_loss: 0.9305, value_loss: 0.5738
2024-07-11 17:06:49,572 [INFO    ] __main__: train step 14967: loss: 0.9886, policy_loss: 0.9305, value_loss: 0.5738
2024-07-11 17:06:49,767 [INFO    ] __main__: train step 14968: loss: 0.9886, policy_loss: 0.9304, value_loss: 0.5737
2024-07-11 17:06:49,972 [INFO    ] __main__: train step 14969: loss: 0.9886, policy_loss: 0.9304, value_loss: 0.5737
2024-07-11 17:06:50,174 [INFO    ] __main__: train step 14970: loss: 0.9886, policy_loss: 0.9304, value_loss: 0.5737
2024-07-11 17:06:50,373 [INFO    ] __main__: train step 14971: loss: 0.9886, policy_loss: 0.9304, value_loss: 0.5737
2024-07-11 17:06:50,585 [INFO    ] __main__: train step 14972: loss: 0.9886, policy_loss: 0.9303, value_loss: 0.5736
2024-07-11 17:06:50,785 [INFO    ] __main__: train step 14973: loss: 0.9886, policy_loss: 0.9303, value_loss: 0.5736
2024-07-11 17:06:51,028 [INFO    ] __main__: train step 14974: loss: 0.9885, policy_loss: 0.9303, value_loss: 0.5736
2024-07-11 17:06:51,254 [INFO    ] __main__: train step 14975: loss: 0.9885, policy_loss: 0.9303, value_loss: 0.5736
2024-07-11 17:06:51,460 [INFO    ] __main__: train step 14976: loss: 0.9885, policy_loss: 0.9303, value_loss: 0.5735
2024-07-11 17:06:52,889 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:06:53,270 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:06:53,329 [INFO    ] __main__: train step 14977: loss: 0.9885, policy_loss: 0.9302, value_loss: 0.5735
2024-07-11 17:06:53,515 [INFO    ] __main__: train step 14978: loss: 0.9885, policy_loss: 0.9302, value_loss: 0.5735
2024-07-11 17:06:53,712 [INFO    ] __main__: train step 14979: loss: 0.9885, policy_loss: 0.9302, value_loss: 0.5735
2024-07-11 17:06:53,933 [INFO    ] __main__: train step 14980: loss: 0.9885, policy_loss: 0.9302, value_loss: 0.5734
2024-07-11 17:06:54,163 [INFO    ] __main__: train step 14981: loss: 0.9885, policy_loss: 0.9301, value_loss: 0.5734
2024-07-11 17:06:54,369 [INFO    ] __main__: train step 14982: loss: 0.9884, policy_loss: 0.9301, value_loss: 0.5734
2024-07-11 17:06:54,606 [INFO    ] __main__: train step 14983: loss: 0.9884, policy_loss: 0.9301, value_loss: 0.5734
2024-07-11 17:06:54,801 [INFO    ] __main__: train step 14984: loss: 0.9884, policy_loss: 0.9301, value_loss: 0.5733
2024-07-11 17:06:55,025 [INFO    ] __main__: train step 14985: loss: 0.9884, policy_loss: 0.9301, value_loss: 0.5733
2024-07-11 17:06:55,254 [INFO    ] __main__: train step 14986: loss: 0.9884, policy_loss: 0.9300, value_loss: 0.5733
2024-07-11 17:06:56,784 [INFO    ] __main__: train step 14987: loss: 0.9884, policy_loss: 0.9300, value_loss: 0.5733
2024-07-11 17:06:57,013 [INFO    ] __main__: train step 14988: loss: 0.9884, policy_loss: 0.9300, value_loss: 0.5732
2024-07-11 17:06:57,205 [INFO    ] __main__: train step 14989: loss: 0.9884, policy_loss: 0.9300, value_loss: 0.5732
2024-07-11 17:06:57,416 [INFO    ] __main__: train step 14990: loss: 0.9883, policy_loss: 0.9299, value_loss: 0.5732
2024-07-11 17:06:57,610 [INFO    ] __main__: train step 14991: loss: 0.9883, policy_loss: 0.9299, value_loss: 0.5732
2024-07-11 17:06:57,811 [INFO    ] __main__: train step 14992: loss: 0.9883, policy_loss: 0.9299, value_loss: 0.5731
2024-07-11 17:06:58,011 [INFO    ] __main__: train step 14993: loss: 0.9883, policy_loss: 0.9299, value_loss: 0.5731
2024-07-11 17:06:59,428 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:06:59,820 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:06:59,878 [INFO    ] __main__: train step 14994: loss: 0.9883, policy_loss: 0.9299, value_loss: 0.5731
2024-07-11 17:07:00,072 [INFO    ] __main__: train step 14995: loss: 0.9883, policy_loss: 0.9298, value_loss: 0.5731
2024-07-11 17:07:00,281 [INFO    ] __main__: train step 14996: loss: 0.9883, policy_loss: 0.9298, value_loss: 0.5730
2024-07-11 17:07:00,482 [INFO    ] __main__: train step 14997: loss: 0.9883, policy_loss: 0.9298, value_loss: 0.5730
2024-07-11 17:07:00,702 [INFO    ] __main__: train step 14998: loss: 0.9882, policy_loss: 0.9298, value_loss: 0.5730
2024-07-11 17:07:00,898 [INFO    ] __main__: train step 14999: loss: 0.9882, policy_loss: 0.9297, value_loss: 0.5730
2024-07-11 17:07:01,097 [INFO    ] __main__: train step 15000: loss: 0.9882, policy_loss: 0.9297, value_loss: 0.5729
2024-07-11 17:07:01,223 [INFO    ] __main__: restored step 14000 for evaluation
2024-07-11 17:07:08,826 [INFO    ] __main__: later network ELO difference from earlier network: +48 (+8/-8) ELO from 32000 self-played games
2024-07-11 17:07:08,826 [INFO    ] __main__: game outcomes: W: 17654, D: 320, L: 14026
2024-07-11 17:07:08,827 [INFO    ] __main__: validation_elo_delta: 48, validation_elo: 2430
2024-07-11 17:07:09,154 [INFO    ] __main__: running self-play game for SVG generation
2024-07-11 17:08:31,283 [INFO    ] __main__: saved self-play game in animations/run1_baseline/15000.svg
2024-07-11 17:08:31,454 [INFO    ] __main__: train step 15001: loss: 0.9882, policy_loss: 0.9297, value_loss: 0.5729
2024-07-11 17:08:31,658 [INFO    ] __main__: train step 15002: loss: 0.9882, policy_loss: 0.9297, value_loss: 0.5729
2024-07-11 17:08:31,873 [INFO    ] __main__: train step 15003: loss: 0.9882, policy_loss: 0.9297, value_loss: 0.5729
2024-07-11 17:08:32,099 [INFO    ] __main__: train step 15004: loss: 0.9882, policy_loss: 0.9296, value_loss: 0.5728
2024-07-11 17:08:32,302 [INFO    ] __main__: train step 15005: loss: 0.9882, policy_loss: 0.9296, value_loss: 0.5728
2024-07-11 17:08:32,545 [INFO    ] __main__: train step 15006: loss: 0.9881, policy_loss: 0.9296, value_loss: 0.5728
2024-07-11 17:08:32,748 [INFO    ] __main__: train step 15007: loss: 0.9881, policy_loss: 0.9296, value_loss: 0.5728
2024-07-11 17:08:32,960 [INFO    ] __main__: train step 15008: loss: 0.9881, policy_loss: 0.9296, value_loss: 0.5727
2024-07-11 17:08:33,160 [INFO    ] __main__: train step 15009: loss: 0.9881, policy_loss: 0.9295, value_loss: 0.5727
2024-07-11 17:08:33,368 [INFO    ] __main__: train step 15010: loss: 0.9881, policy_loss: 0.9295, value_loss: 0.5727
2024-07-11 17:08:34,782 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:08:35,142 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:08:35,202 [INFO    ] __main__: train step 15011: loss: 0.9881, policy_loss: 0.9295, value_loss: 0.5727
2024-07-11 17:08:35,392 [INFO    ] __main__: train step 15012: loss: 0.9881, policy_loss: 0.9295, value_loss: 0.5726
2024-07-11 17:08:35,626 [INFO    ] __main__: train step 15013: loss: 0.9881, policy_loss: 0.9294, value_loss: 0.5726
2024-07-11 17:08:35,842 [INFO    ] __main__: train step 15014: loss: 0.9881, policy_loss: 0.9294, value_loss: 0.5726
2024-07-11 17:08:36,095 [INFO    ] __main__: train step 15015: loss: 0.9880, policy_loss: 0.9294, value_loss: 0.5726
2024-07-11 17:08:36,332 [INFO    ] __main__: train step 15016: loss: 0.9880, policy_loss: 0.9294, value_loss: 0.5725
2024-07-11 17:08:36,523 [INFO    ] __main__: train step 15017: loss: 0.9880, policy_loss: 0.9294, value_loss: 0.5725
2024-07-11 17:08:36,726 [INFO    ] __main__: train step 15018: loss: 0.9880, policy_loss: 0.9293, value_loss: 0.5725
2024-07-11 17:08:36,935 [INFO    ] __main__: train step 15019: loss: 0.9880, policy_loss: 0.9293, value_loss: 0.5725
2024-07-11 17:08:37,142 [INFO    ] __main__: train step 15020: loss: 0.9880, policy_loss: 0.9293, value_loss: 0.5724
2024-07-11 17:08:37,376 [INFO    ] __main__: train step 15021: loss: 0.9880, policy_loss: 0.9293, value_loss: 0.5724
2024-07-11 17:08:37,588 [INFO    ] __main__: train step 15022: loss: 0.9879, policy_loss: 0.9292, value_loss: 0.5724
2024-07-11 17:08:37,790 [INFO    ] __main__: train step 15023: loss: 0.9879, policy_loss: 0.9292, value_loss: 0.5724
2024-07-11 17:08:38,010 [INFO    ] __main__: train step 15024: loss: 0.9879, policy_loss: 0.9292, value_loss: 0.5723
2024-07-11 17:08:38,205 [INFO    ] __main__: train step 15025: loss: 0.9879, policy_loss: 0.9292, value_loss: 0.5723
2024-07-11 17:08:38,435 [INFO    ] __main__: train step 15026: loss: 0.9879, policy_loss: 0.9292, value_loss: 0.5723
2024-07-11 17:08:38,680 [INFO    ] __main__: train step 15027: loss: 0.9879, policy_loss: 0.9291, value_loss: 0.5723
2024-07-11 17:08:40,132 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:08:40,560 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:08:40,622 [INFO    ] __main__: train step 15028: loss: 0.9879, policy_loss: 0.9291, value_loss: 0.5722
2024-07-11 17:08:40,797 [INFO    ] __main__: train step 15029: loss: 0.9879, policy_loss: 0.9291, value_loss: 0.5722
2024-07-11 17:08:41,006 [INFO    ] __main__: train step 15030: loss: 0.9878, policy_loss: 0.9291, value_loss: 0.5722
2024-07-11 17:08:41,204 [INFO    ] __main__: train step 15031: loss: 0.9878, policy_loss: 0.9290, value_loss: 0.5722
2024-07-11 17:08:41,402 [INFO    ] __main__: train step 15032: loss: 0.9878, policy_loss: 0.9290, value_loss: 0.5721
2024-07-11 17:08:41,613 [INFO    ] __main__: train step 15033: loss: 0.9878, policy_loss: 0.9290, value_loss: 0.5721
2024-07-11 17:08:41,841 [INFO    ] __main__: train step 15034: loss: 0.9878, policy_loss: 0.9290, value_loss: 0.5721
2024-07-11 17:08:42,055 [INFO    ] __main__: train step 15035: loss: 0.9878, policy_loss: 0.9290, value_loss: 0.5721
2024-07-11 17:08:42,247 [INFO    ] __main__: train step 15036: loss: 0.9878, policy_loss: 0.9289, value_loss: 0.5720
2024-07-11 17:08:42,449 [INFO    ] __main__: train step 15037: loss: 0.9878, policy_loss: 0.9289, value_loss: 0.5720
2024-07-11 17:08:42,648 [INFO    ] __main__: train step 15038: loss: 0.9877, policy_loss: 0.9289, value_loss: 0.5720
2024-07-11 17:08:42,849 [INFO    ] __main__: train step 15039: loss: 0.9877, policy_loss: 0.9289, value_loss: 0.5720
2024-07-11 17:08:43,061 [INFO    ] __main__: train step 15040: loss: 0.9877, policy_loss: 0.9288, value_loss: 0.5719
2024-07-11 17:08:43,266 [INFO    ] __main__: train step 15041: loss: 0.9877, policy_loss: 0.9288, value_loss: 0.5719
2024-07-11 17:08:43,468 [INFO    ] __main__: train step 15042: loss: 0.9877, policy_loss: 0.9288, value_loss: 0.5719
2024-07-11 17:08:43,667 [INFO    ] __main__: train step 15043: loss: 0.9877, policy_loss: 0.9288, value_loss: 0.5719
2024-07-11 17:08:43,876 [INFO    ] __main__: train step 15044: loss: 0.9877, policy_loss: 0.9288, value_loss: 0.5718
2024-07-11 17:08:45,331 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:08:45,670 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:08:45,724 [INFO    ] __main__: train step 15045: loss: 0.9876, policy_loss: 0.9287, value_loss: 0.5718
2024-07-11 17:08:45,903 [INFO    ] __main__: train step 15046: loss: 0.9876, policy_loss: 0.9287, value_loss: 0.5718
2024-07-11 17:08:46,106 [INFO    ] __main__: train step 15047: loss: 0.9876, policy_loss: 0.9287, value_loss: 0.5718
2024-07-11 17:08:46,317 [INFO    ] __main__: train step 15048: loss: 0.9876, policy_loss: 0.9287, value_loss: 0.5717
2024-07-11 17:08:46,518 [INFO    ] __main__: train step 15049: loss: 0.9876, policy_loss: 0.9286, value_loss: 0.5717
2024-07-11 17:08:46,725 [INFO    ] __main__: train step 15050: loss: 0.9876, policy_loss: 0.9286, value_loss: 0.5717
2024-07-11 17:08:46,931 [INFO    ] __main__: train step 15051: loss: 0.9876, policy_loss: 0.9286, value_loss: 0.5717
2024-07-11 17:08:47,137 [INFO    ] __main__: train step 15052: loss: 0.9876, policy_loss: 0.9286, value_loss: 0.5716
2024-07-11 17:08:47,365 [INFO    ] __main__: train step 15053: loss: 0.9875, policy_loss: 0.9286, value_loss: 0.5716
2024-07-11 17:08:47,592 [INFO    ] __main__: train step 15054: loss: 0.9875, policy_loss: 0.9285, value_loss: 0.5716
2024-07-11 17:08:47,791 [INFO    ] __main__: train step 15055: loss: 0.9875, policy_loss: 0.9285, value_loss: 0.5716
2024-07-11 17:08:47,994 [INFO    ] __main__: train step 15056: loss: 0.9875, policy_loss: 0.9285, value_loss: 0.5715
2024-07-11 17:08:48,190 [INFO    ] __main__: train step 15057: loss: 0.9875, policy_loss: 0.9285, value_loss: 0.5715
2024-07-11 17:08:48,395 [INFO    ] __main__: train step 15058: loss: 0.9875, policy_loss: 0.9284, value_loss: 0.5715
2024-07-11 17:08:48,597 [INFO    ] __main__: train step 15059: loss: 0.9875, policy_loss: 0.9284, value_loss: 0.5715
2024-07-11 17:08:48,798 [INFO    ] __main__: train step 15060: loss: 0.9875, policy_loss: 0.9284, value_loss: 0.5715
2024-07-11 17:08:49,006 [INFO    ] __main__: train step 15061: loss: 0.9874, policy_loss: 0.9284, value_loss: 0.5714
2024-07-11 17:08:50,440 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:08:50,812 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:08:50,868 [INFO    ] __main__: train step 15062: loss: 0.9874, policy_loss: 0.9284, value_loss: 0.5714
2024-07-11 17:08:51,052 [INFO    ] __main__: train step 15063: loss: 0.9874, policy_loss: 0.9283, value_loss: 0.5714
2024-07-11 17:08:51,252 [INFO    ] __main__: train step 15064: loss: 0.9874, policy_loss: 0.9283, value_loss: 0.5714
2024-07-11 17:08:51,472 [INFO    ] __main__: train step 15065: loss: 0.9874, policy_loss: 0.9283, value_loss: 0.5713
2024-07-11 17:08:51,666 [INFO    ] __main__: train step 15066: loss: 0.9874, policy_loss: 0.9283, value_loss: 0.5713
2024-07-11 17:08:51,861 [INFO    ] __main__: train step 15067: loss: 0.9874, policy_loss: 0.9282, value_loss: 0.5713
2024-07-11 17:08:52,064 [INFO    ] __main__: train step 15068: loss: 0.9874, policy_loss: 0.9282, value_loss: 0.5713
2024-07-11 17:08:52,264 [INFO    ] __main__: train step 15069: loss: 0.9873, policy_loss: 0.9282, value_loss: 0.5712
2024-07-11 17:08:52,469 [INFO    ] __main__: train step 15070: loss: 0.9873, policy_loss: 0.9282, value_loss: 0.5712
2024-07-11 17:08:52,672 [INFO    ] __main__: train step 15071: loss: 0.9873, policy_loss: 0.9282, value_loss: 0.5712
2024-07-11 17:08:52,873 [INFO    ] __main__: train step 15072: loss: 0.9873, policy_loss: 0.9281, value_loss: 0.5712
2024-07-11 17:08:53,076 [INFO    ] __main__: train step 15073: loss: 0.9873, policy_loss: 0.9281, value_loss: 0.5711
2024-07-11 17:08:53,281 [INFO    ] __main__: train step 15074: loss: 0.9873, policy_loss: 0.9281, value_loss: 0.5711
2024-07-11 17:08:53,488 [INFO    ] __main__: train step 15075: loss: 0.9873, policy_loss: 0.9281, value_loss: 0.5711
2024-07-11 17:08:53,712 [INFO    ] __main__: train step 15076: loss: 0.9873, policy_loss: 0.9280, value_loss: 0.5711
2024-07-11 17:08:53,908 [INFO    ] __main__: train step 15077: loss: 0.9872, policy_loss: 0.9280, value_loss: 0.5710
2024-07-11 17:08:54,109 [INFO    ] __main__: train step 15078: loss: 0.9872, policy_loss: 0.9280, value_loss: 0.5710
2024-07-11 17:08:55,559 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:08:55,934 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:08:55,990 [INFO    ] __main__: train step 15079: loss: 0.9872, policy_loss: 0.9280, value_loss: 0.5710
2024-07-11 17:08:56,170 [INFO    ] __main__: train step 15080: loss: 0.9872, policy_loss: 0.9280, value_loss: 0.5710
2024-07-11 17:08:56,384 [INFO    ] __main__: train step 15081: loss: 0.9872, policy_loss: 0.9279, value_loss: 0.5709
2024-07-11 17:08:56,587 [INFO    ] __main__: train step 15082: loss: 0.9872, policy_loss: 0.9279, value_loss: 0.5709
2024-07-11 17:08:56,808 [INFO    ] __main__: train step 15083: loss: 0.9872, policy_loss: 0.9279, value_loss: 0.5709
2024-07-11 17:08:57,011 [INFO    ] __main__: train step 15084: loss: 0.9872, policy_loss: 0.9279, value_loss: 0.5709
2024-07-11 17:08:57,215 [INFO    ] __main__: train step 15085: loss: 0.9871, policy_loss: 0.9278, value_loss: 0.5708
2024-07-11 17:08:57,414 [INFO    ] __main__: train step 15086: loss: 0.9871, policy_loss: 0.9278, value_loss: 0.5708
2024-07-11 17:08:57,632 [INFO    ] __main__: train step 15087: loss: 0.9871, policy_loss: 0.9278, value_loss: 0.5708
2024-07-11 17:08:57,839 [INFO    ] __main__: train step 15088: loss: 0.9871, policy_loss: 0.9278, value_loss: 0.5708
2024-07-11 17:08:58,040 [INFO    ] __main__: train step 15089: loss: 0.9871, policy_loss: 0.9278, value_loss: 0.5707
2024-07-11 17:08:58,249 [INFO    ] __main__: train step 15090: loss: 0.9871, policy_loss: 0.9277, value_loss: 0.5707
2024-07-11 17:08:58,457 [INFO    ] __main__: train step 15091: loss: 0.9871, policy_loss: 0.9277, value_loss: 0.5707
2024-07-11 17:08:58,658 [INFO    ] __main__: train step 15092: loss: 0.9871, policy_loss: 0.9277, value_loss: 0.5707
2024-07-11 17:08:58,875 [INFO    ] __main__: train step 15093: loss: 0.9870, policy_loss: 0.9277, value_loss: 0.5706
2024-07-11 17:08:59,075 [INFO    ] __main__: train step 15094: loss: 0.9870, policy_loss: 0.9277, value_loss: 0.5706
2024-07-11 17:08:59,297 [INFO    ] __main__: train step 15095: loss: 0.9870, policy_loss: 0.9276, value_loss: 0.5706
2024-07-11 17:09:00,749 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:09:01,142 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:09:01,203 [INFO    ] __main__: train step 15096: loss: 0.9870, policy_loss: 0.9276, value_loss: 0.5706
2024-07-11 17:09:01,374 [INFO    ] __main__: train step 15097: loss: 0.9870, policy_loss: 0.9276, value_loss: 0.5705
2024-07-11 17:09:01,570 [INFO    ] __main__: train step 15098: loss: 0.9870, policy_loss: 0.9276, value_loss: 0.5705
2024-07-11 17:09:01,772 [INFO    ] __main__: train step 15099: loss: 0.9870, policy_loss: 0.9275, value_loss: 0.5705
2024-07-11 17:09:01,966 [INFO    ] __main__: train step 15100: loss: 0.9870, policy_loss: 0.9275, value_loss: 0.5705
2024-07-11 17:09:03,923 [INFO    ] __main__: train step 15101: loss: 0.9869, policy_loss: 0.9275, value_loss: 0.5704
2024-07-11 17:09:04,123 [INFO    ] __main__: train step 15102: loss: 0.9869, policy_loss: 0.9275, value_loss: 0.5704
2024-07-11 17:09:04,325 [INFO    ] __main__: train step 15103: loss: 0.9869, policy_loss: 0.9275, value_loss: 0.5704
2024-07-11 17:09:04,535 [INFO    ] __main__: train step 15104: loss: 0.9869, policy_loss: 0.9274, value_loss: 0.5704
2024-07-11 17:09:04,729 [INFO    ] __main__: train step 15105: loss: 0.9869, policy_loss: 0.9274, value_loss: 0.5703
2024-07-11 17:09:04,933 [INFO    ] __main__: train step 15106: loss: 0.9869, policy_loss: 0.9274, value_loss: 0.5703
2024-07-11 17:09:05,135 [INFO    ] __main__: train step 15107: loss: 0.9869, policy_loss: 0.9274, value_loss: 0.5703
2024-07-11 17:09:05,362 [INFO    ] __main__: train step 15108: loss: 0.9869, policy_loss: 0.9273, value_loss: 0.5703
2024-07-11 17:09:05,565 [INFO    ] __main__: train step 15109: loss: 0.9868, policy_loss: 0.9273, value_loss: 0.5702
2024-07-11 17:09:05,766 [INFO    ] __main__: train step 15110: loss: 0.9868, policy_loss: 0.9273, value_loss: 0.5702
2024-07-11 17:09:05,966 [INFO    ] __main__: train step 15111: loss: 0.9868, policy_loss: 0.9273, value_loss: 0.5702
2024-07-11 17:09:06,167 [INFO    ] __main__: train step 15112: loss: 0.9868, policy_loss: 0.9273, value_loss: 0.5702
2024-07-11 17:09:07,601 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:09:07,949 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:09:08,007 [INFO    ] __main__: train step 15113: loss: 0.9868, policy_loss: 0.9272, value_loss: 0.5702
2024-07-11 17:09:08,180 [INFO    ] __main__: train step 15114: loss: 0.9868, policy_loss: 0.9272, value_loss: 0.5701
2024-07-11 17:09:08,377 [INFO    ] __main__: train step 15115: loss: 0.9868, policy_loss: 0.9272, value_loss: 0.5701
2024-07-11 17:09:08,590 [INFO    ] __main__: train step 15116: loss: 0.9867, policy_loss: 0.9272, value_loss: 0.5701
2024-07-11 17:09:08,792 [INFO    ] __main__: train step 15117: loss: 0.9867, policy_loss: 0.9271, value_loss: 0.5701
2024-07-11 17:09:08,994 [INFO    ] __main__: train step 15118: loss: 0.9867, policy_loss: 0.9271, value_loss: 0.5700
2024-07-11 17:09:09,251 [INFO    ] __main__: train step 15119: loss: 0.9867, policy_loss: 0.9271, value_loss: 0.5700
2024-07-11 17:09:09,471 [INFO    ] __main__: train step 15120: loss: 0.9867, policy_loss: 0.9271, value_loss: 0.5700
2024-07-11 17:09:09,669 [INFO    ] __main__: train step 15121: loss: 0.9867, policy_loss: 0.9271, value_loss: 0.5700
2024-07-11 17:09:09,872 [INFO    ] __main__: train step 15122: loss: 0.9867, policy_loss: 0.9270, value_loss: 0.5699
2024-07-11 17:09:10,077 [INFO    ] __main__: train step 15123: loss: 0.9867, policy_loss: 0.9270, value_loss: 0.5699
2024-07-11 17:09:10,276 [INFO    ] __main__: train step 15124: loss: 0.9866, policy_loss: 0.9270, value_loss: 0.5699
2024-07-11 17:09:10,473 [INFO    ] __main__: train step 15125: loss: 0.9866, policy_loss: 0.9270, value_loss: 0.5699
2024-07-11 17:09:10,671 [INFO    ] __main__: train step 15126: loss: 0.9866, policy_loss: 0.9269, value_loss: 0.5698
2024-07-11 17:09:10,882 [INFO    ] __main__: train step 15127: loss: 0.9866, policy_loss: 0.9269, value_loss: 0.5698
2024-07-11 17:09:11,073 [INFO    ] __main__: train step 15128: loss: 0.9866, policy_loss: 0.9269, value_loss: 0.5698
2024-07-11 17:09:11,279 [INFO    ] __main__: train step 15129: loss: 0.9866, policy_loss: 0.9269, value_loss: 0.5698
2024-07-11 17:09:12,732 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:09:13,122 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:09:13,185 [INFO    ] __main__: train step 15130: loss: 0.9866, policy_loss: 0.9269, value_loss: 0.5697
2024-07-11 17:09:13,362 [INFO    ] __main__: train step 15131: loss: 0.9866, policy_loss: 0.9268, value_loss: 0.5697
2024-07-11 17:09:13,566 [INFO    ] __main__: train step 15132: loss: 0.9865, policy_loss: 0.9268, value_loss: 0.5697
2024-07-11 17:09:13,767 [INFO    ] __main__: train step 15133: loss: 0.9865, policy_loss: 0.9268, value_loss: 0.5697
2024-07-11 17:09:13,960 [INFO    ] __main__: train step 15134: loss: 0.9865, policy_loss: 0.9268, value_loss: 0.5696
2024-07-11 17:09:14,162 [INFO    ] __main__: train step 15135: loss: 0.9865, policy_loss: 0.9267, value_loss: 0.5696
2024-07-11 17:09:14,389 [INFO    ] __main__: train step 15136: loss: 0.9865, policy_loss: 0.9267, value_loss: 0.5696
2024-07-11 17:09:14,626 [INFO    ] __main__: train step 15137: loss: 0.9865, policy_loss: 0.9267, value_loss: 0.5696
2024-07-11 17:09:14,859 [INFO    ] __main__: train step 15138: loss: 0.9865, policy_loss: 0.9267, value_loss: 0.5695
2024-07-11 17:09:15,100 [INFO    ] __main__: train step 15139: loss: 0.9865, policy_loss: 0.9267, value_loss: 0.5695
2024-07-11 17:09:15,329 [INFO    ] __main__: train step 15140: loss: 0.9864, policy_loss: 0.9266, value_loss: 0.5695
2024-07-11 17:09:15,539 [INFO    ] __main__: train step 15141: loss: 0.9864, policy_loss: 0.9266, value_loss: 0.5695
2024-07-11 17:09:15,777 [INFO    ] __main__: train step 15142: loss: 0.9864, policy_loss: 0.9266, value_loss: 0.5694
2024-07-11 17:09:15,975 [INFO    ] __main__: train step 15143: loss: 0.9864, policy_loss: 0.9266, value_loss: 0.5694
2024-07-11 17:09:16,174 [INFO    ] __main__: train step 15144: loss: 0.9864, policy_loss: 0.9266, value_loss: 0.5694
2024-07-11 17:09:16,381 [INFO    ] __main__: train step 15145: loss: 0.9864, policy_loss: 0.9265, value_loss: 0.5694
2024-07-11 17:09:16,588 [INFO    ] __main__: train step 15146: loss: 0.9864, policy_loss: 0.9265, value_loss: 0.5694
2024-07-11 17:09:18,014 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:09:18,375 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:09:18,431 [INFO    ] __main__: train step 15147: loss: 0.9864, policy_loss: 0.9265, value_loss: 0.5693
2024-07-11 17:09:18,607 [INFO    ] __main__: train step 15148: loss: 0.9863, policy_loss: 0.9265, value_loss: 0.5693
2024-07-11 17:09:18,806 [INFO    ] __main__: train step 15149: loss: 0.9863, policy_loss: 0.9264, value_loss: 0.5693
2024-07-11 17:09:18,996 [INFO    ] __main__: train step 15150: loss: 0.9863, policy_loss: 0.9264, value_loss: 0.5693
2024-07-11 17:09:19,217 [INFO    ] __main__: train step 15151: loss: 0.9863, policy_loss: 0.9264, value_loss: 0.5692
2024-07-11 17:09:19,414 [INFO    ] __main__: train step 15152: loss: 0.9863, policy_loss: 0.9264, value_loss: 0.5692
2024-07-11 17:09:19,610 [INFO    ] __main__: train step 15153: loss: 0.9863, policy_loss: 0.9263, value_loss: 0.5692
2024-07-11 17:09:19,826 [INFO    ] __main__: train step 15154: loss: 0.9863, policy_loss: 0.9263, value_loss: 0.5692
2024-07-11 17:09:20,015 [INFO    ] __main__: train step 15155: loss: 0.9863, policy_loss: 0.9263, value_loss: 0.5691
2024-07-11 17:09:20,212 [INFO    ] __main__: train step 15156: loss: 0.9862, policy_loss: 0.9263, value_loss: 0.5691
2024-07-11 17:09:20,428 [INFO    ] __main__: train step 15157: loss: 0.9862, policy_loss: 0.9263, value_loss: 0.5691
2024-07-11 17:09:20,636 [INFO    ] __main__: train step 15158: loss: 0.9862, policy_loss: 0.9262, value_loss: 0.5691
2024-07-11 17:09:20,846 [INFO    ] __main__: train step 15159: loss: 0.9862, policy_loss: 0.9262, value_loss: 0.5690
2024-07-11 17:09:21,070 [INFO    ] __main__: train step 15160: loss: 0.9862, policy_loss: 0.9262, value_loss: 0.5690
2024-07-11 17:09:21,301 [INFO    ] __main__: train step 15161: loss: 0.9862, policy_loss: 0.9262, value_loss: 0.5690
2024-07-11 17:09:21,501 [INFO    ] __main__: train step 15162: loss: 0.9862, policy_loss: 0.9262, value_loss: 0.5690
2024-07-11 17:09:21,711 [INFO    ] __main__: train step 15163: loss: 0.9862, policy_loss: 0.9261, value_loss: 0.5689
2024-07-11 17:09:23,148 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:09:23,545 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:09:23,604 [INFO    ] __main__: train step 15164: loss: 0.9861, policy_loss: 0.9261, value_loss: 0.5689
2024-07-11 17:09:23,788 [INFO    ] __main__: train step 15165: loss: 0.9861, policy_loss: 0.9261, value_loss: 0.5689
2024-07-11 17:09:24,024 [INFO    ] __main__: train step 15166: loss: 0.9861, policy_loss: 0.9261, value_loss: 0.5689
2024-07-11 17:09:24,259 [INFO    ] __main__: train step 15167: loss: 0.9861, policy_loss: 0.9260, value_loss: 0.5688
2024-07-11 17:09:24,467 [INFO    ] __main__: train step 15168: loss: 0.9861, policy_loss: 0.9260, value_loss: 0.5688
2024-07-11 17:09:24,707 [INFO    ] __main__: train step 15169: loss: 0.9861, policy_loss: 0.9260, value_loss: 0.5688
2024-07-11 17:09:24,945 [INFO    ] __main__: train step 15170: loss: 0.9861, policy_loss: 0.9260, value_loss: 0.5688
2024-07-11 17:09:25,147 [INFO    ] __main__: train step 15171: loss: 0.9861, policy_loss: 0.9260, value_loss: 0.5688
2024-07-11 17:09:25,345 [INFO    ] __main__: train step 15172: loss: 0.9860, policy_loss: 0.9259, value_loss: 0.5687
2024-07-11 17:09:25,550 [INFO    ] __main__: train step 15173: loss: 0.9860, policy_loss: 0.9259, value_loss: 0.5687
2024-07-11 17:09:25,751 [INFO    ] __main__: train step 15174: loss: 0.9860, policy_loss: 0.9259, value_loss: 0.5687
2024-07-11 17:09:25,943 [INFO    ] __main__: train step 15175: loss: 0.9860, policy_loss: 0.9259, value_loss: 0.5687
2024-07-11 17:09:26,142 [INFO    ] __main__: train step 15176: loss: 0.9860, policy_loss: 0.9258, value_loss: 0.5686
2024-07-11 17:09:26,350 [INFO    ] __main__: train step 15177: loss: 0.9860, policy_loss: 0.9258, value_loss: 0.5686
2024-07-11 17:09:26,555 [INFO    ] __main__: train step 15178: loss: 0.9860, policy_loss: 0.9258, value_loss: 0.5686
2024-07-11 17:09:26,758 [INFO    ] __main__: train step 15179: loss: 0.9860, policy_loss: 0.9258, value_loss: 0.5686
2024-07-11 17:09:26,964 [INFO    ] __main__: train step 15180: loss: 0.9859, policy_loss: 0.9258, value_loss: 0.5685
2024-07-11 17:09:28,402 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:09:28,766 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:09:28,822 [INFO    ] __main__: train step 15181: loss: 0.9859, policy_loss: 0.9257, value_loss: 0.5685
2024-07-11 17:09:29,001 [INFO    ] __main__: train step 15182: loss: 0.9859, policy_loss: 0.9257, value_loss: 0.5685
2024-07-11 17:09:29,206 [INFO    ] __main__: train step 15183: loss: 0.9859, policy_loss: 0.9257, value_loss: 0.5685
2024-07-11 17:09:29,417 [INFO    ] __main__: train step 15184: loss: 0.9859, policy_loss: 0.9257, value_loss: 0.5684
2024-07-11 17:09:29,611 [INFO    ] __main__: train step 15185: loss: 0.9859, policy_loss: 0.9256, value_loss: 0.5684
2024-07-11 17:09:29,819 [INFO    ] __main__: train step 15186: loss: 0.9859, policy_loss: 0.9256, value_loss: 0.5684
2024-07-11 17:09:30,016 [INFO    ] __main__: train step 15187: loss: 0.9859, policy_loss: 0.9256, value_loss: 0.5684
2024-07-11 17:09:30,214 [INFO    ] __main__: train step 15188: loss: 0.9859, policy_loss: 0.9256, value_loss: 0.5683
2024-07-11 17:09:30,425 [INFO    ] __main__: train step 15189: loss: 0.9858, policy_loss: 0.9256, value_loss: 0.5683
2024-07-11 17:09:30,627 [INFO    ] __main__: train step 15190: loss: 0.9858, policy_loss: 0.9255, value_loss: 0.5683
2024-07-11 17:09:30,827 [INFO    ] __main__: train step 15191: loss: 0.9858, policy_loss: 0.9255, value_loss: 0.5683
2024-07-11 17:09:31,034 [INFO    ] __main__: train step 15192: loss: 0.9858, policy_loss: 0.9255, value_loss: 0.5682
2024-07-11 17:09:31,233 [INFO    ] __main__: train step 15193: loss: 0.9858, policy_loss: 0.9255, value_loss: 0.5682
2024-07-11 17:09:31,439 [INFO    ] __main__: train step 15194: loss: 0.9858, policy_loss: 0.9254, value_loss: 0.5682
2024-07-11 17:09:31,637 [INFO    ] __main__: train step 15195: loss: 0.9858, policy_loss: 0.9254, value_loss: 0.5682
2024-07-11 17:09:31,858 [INFO    ] __main__: train step 15196: loss: 0.9858, policy_loss: 0.9254, value_loss: 0.5682
2024-07-11 17:09:32,051 [INFO    ] __main__: train step 15197: loss: 0.9857, policy_loss: 0.9254, value_loss: 0.5681
2024-07-11 17:09:33,507 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:09:33,901 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:09:33,965 [INFO    ] __main__: train step 15198: loss: 0.9857, policy_loss: 0.9254, value_loss: 0.5681
2024-07-11 17:09:34,138 [INFO    ] __main__: train step 15199: loss: 0.9857, policy_loss: 0.9253, value_loss: 0.5681
2024-07-11 17:09:34,370 [INFO    ] __main__: train step 15200: loss: 0.9857, policy_loss: 0.9253, value_loss: 0.5681
2024-07-11 17:09:34,574 [INFO    ] __main__: train step 15201: loss: 0.9857, policy_loss: 0.9253, value_loss: 0.5680
2024-07-11 17:09:34,772 [INFO    ] __main__: train step 15202: loss: 0.9857, policy_loss: 0.9253, value_loss: 0.5680
2024-07-11 17:09:34,975 [INFO    ] __main__: train step 15203: loss: 0.9857, policy_loss: 0.9253, value_loss: 0.5680
2024-07-11 17:09:35,173 [INFO    ] __main__: train step 15204: loss: 0.9857, policy_loss: 0.9252, value_loss: 0.5680
2024-07-11 17:09:35,378 [INFO    ] __main__: train step 15205: loss: 0.9856, policy_loss: 0.9252, value_loss: 0.5679
2024-07-11 17:09:35,591 [INFO    ] __main__: train step 15206: loss: 0.9856, policy_loss: 0.9252, value_loss: 0.5679
2024-07-11 17:09:35,793 [INFO    ] __main__: train step 15207: loss: 0.9856, policy_loss: 0.9252, value_loss: 0.5679
2024-07-11 17:09:35,997 [INFO    ] __main__: train step 15208: loss: 0.9856, policy_loss: 0.9251, value_loss: 0.5679
2024-07-11 17:09:36,213 [INFO    ] __main__: train step 15209: loss: 0.9856, policy_loss: 0.9251, value_loss: 0.5678
2024-07-11 17:09:36,434 [INFO    ] __main__: train step 15210: loss: 0.9856, policy_loss: 0.9251, value_loss: 0.5678
2024-07-11 17:09:36,628 [INFO    ] __main__: train step 15211: loss: 0.9856, policy_loss: 0.9251, value_loss: 0.5678
2024-07-11 17:09:36,837 [INFO    ] __main__: train step 15212: loss: 0.9856, policy_loss: 0.9251, value_loss: 0.5678
2024-07-11 17:09:38,793 [INFO    ] __main__: train step 15213: loss: 0.9855, policy_loss: 0.9250, value_loss: 0.5677
2024-07-11 17:09:39,002 [INFO    ] __main__: train step 15214: loss: 0.9855, policy_loss: 0.9250, value_loss: 0.5677
2024-07-11 17:09:40,426 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:09:40,832 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:09:40,893 [INFO    ] __main__: train step 15215: loss: 0.9855, policy_loss: 0.9250, value_loss: 0.5677
2024-07-11 17:09:41,072 [INFO    ] __main__: train step 15216: loss: 0.9855, policy_loss: 0.9250, value_loss: 0.5677
2024-07-11 17:09:41,275 [INFO    ] __main__: train step 15217: loss: 0.9855, policy_loss: 0.9249, value_loss: 0.5677
2024-07-11 17:09:41,479 [INFO    ] __main__: train step 15218: loss: 0.9855, policy_loss: 0.9249, value_loss: 0.5676
2024-07-11 17:09:41,702 [INFO    ] __main__: train step 15219: loss: 0.9855, policy_loss: 0.9249, value_loss: 0.5676
2024-07-11 17:09:41,920 [INFO    ] __main__: train step 15220: loss: 0.9855, policy_loss: 0.9249, value_loss: 0.5676
2024-07-11 17:09:42,142 [INFO    ] __main__: train step 15221: loss: 0.9854, policy_loss: 0.9249, value_loss: 0.5676
2024-07-11 17:09:42,341 [INFO    ] __main__: train step 15222: loss: 0.9854, policy_loss: 0.9248, value_loss: 0.5675
2024-07-11 17:09:42,549 [INFO    ] __main__: train step 15223: loss: 0.9854, policy_loss: 0.9248, value_loss: 0.5675
2024-07-11 17:09:42,748 [INFO    ] __main__: train step 15224: loss: 0.9854, policy_loss: 0.9248, value_loss: 0.5675
2024-07-11 17:09:42,964 [INFO    ] __main__: train step 15225: loss: 0.9854, policy_loss: 0.9248, value_loss: 0.5675
2024-07-11 17:09:43,160 [INFO    ] __main__: train step 15226: loss: 0.9854, policy_loss: 0.9248, value_loss: 0.5674
2024-07-11 17:09:43,373 [INFO    ] __main__: train step 15227: loss: 0.9854, policy_loss: 0.9247, value_loss: 0.5674
2024-07-11 17:09:43,578 [INFO    ] __main__: train step 15228: loss: 0.9854, policy_loss: 0.9247, value_loss: 0.5674
2024-07-11 17:09:43,781 [INFO    ] __main__: train step 15229: loss: 0.9854, policy_loss: 0.9247, value_loss: 0.5674
2024-07-11 17:09:43,988 [INFO    ] __main__: train step 15230: loss: 0.9853, policy_loss: 0.9247, value_loss: 0.5674
2024-07-11 17:09:44,198 [INFO    ] __main__: train step 15231: loss: 0.9853, policy_loss: 0.9246, value_loss: 0.5673
2024-07-11 17:09:45,605 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:09:45,962 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:09:46,022 [INFO    ] __main__: train step 15232: loss: 0.9853, policy_loss: 0.9246, value_loss: 0.5673
2024-07-11 17:09:46,200 [INFO    ] __main__: train step 15233: loss: 0.9853, policy_loss: 0.9246, value_loss: 0.5673
2024-07-11 17:09:46,400 [INFO    ] __main__: train step 15234: loss: 0.9853, policy_loss: 0.9246, value_loss: 0.5673
2024-07-11 17:09:46,596 [INFO    ] __main__: train step 15235: loss: 0.9853, policy_loss: 0.9246, value_loss: 0.5672
2024-07-11 17:09:46,786 [INFO    ] __main__: train step 15236: loss: 0.9853, policy_loss: 0.9245, value_loss: 0.5672
2024-07-11 17:09:46,995 [INFO    ] __main__: train step 15237: loss: 0.9853, policy_loss: 0.9245, value_loss: 0.5672
2024-07-11 17:09:47,203 [INFO    ] __main__: train step 15238: loss: 0.9852, policy_loss: 0.9245, value_loss: 0.5672
2024-07-11 17:09:47,445 [INFO    ] __main__: train step 15239: loss: 0.9852, policy_loss: 0.9245, value_loss: 0.5671
2024-07-11 17:09:47,688 [INFO    ] __main__: train step 15240: loss: 0.9852, policy_loss: 0.9244, value_loss: 0.5671
2024-07-11 17:09:47,917 [INFO    ] __main__: train step 15241: loss: 0.9852, policy_loss: 0.9244, value_loss: 0.5671
2024-07-11 17:09:48,126 [INFO    ] __main__: train step 15242: loss: 0.9852, policy_loss: 0.9244, value_loss: 0.5671
2024-07-11 17:09:48,331 [INFO    ] __main__: train step 15243: loss: 0.9852, policy_loss: 0.9244, value_loss: 0.5670
2024-07-11 17:09:48,531 [INFO    ] __main__: train step 15244: loss: 0.9852, policy_loss: 0.9244, value_loss: 0.5670
2024-07-11 17:09:48,738 [INFO    ] __main__: train step 15245: loss: 0.9852, policy_loss: 0.9243, value_loss: 0.5670
2024-07-11 17:09:48,930 [INFO    ] __main__: train step 15246: loss: 0.9851, policy_loss: 0.9243, value_loss: 0.5670
2024-07-11 17:09:49,129 [INFO    ] __main__: train step 15247: loss: 0.9851, policy_loss: 0.9243, value_loss: 0.5669
2024-07-11 17:09:49,341 [INFO    ] __main__: train step 15248: loss: 0.9851, policy_loss: 0.9243, value_loss: 0.5669
2024-07-11 17:09:50,787 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:09:51,171 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:09:51,235 [INFO    ] __main__: train step 15249: loss: 0.9851, policy_loss: 0.9242, value_loss: 0.5669
2024-07-11 17:09:51,421 [INFO    ] __main__: train step 15250: loss: 0.9851, policy_loss: 0.9242, value_loss: 0.5669
2024-07-11 17:09:51,651 [INFO    ] __main__: train step 15251: loss: 0.9851, policy_loss: 0.9242, value_loss: 0.5668
2024-07-11 17:09:51,849 [INFO    ] __main__: train step 15252: loss: 0.9851, policy_loss: 0.9242, value_loss: 0.5668
2024-07-11 17:09:52,060 [INFO    ] __main__: train step 15253: loss: 0.9851, policy_loss: 0.9242, value_loss: 0.5668
2024-07-11 17:09:52,298 [INFO    ] __main__: train step 15254: loss: 0.9850, policy_loss: 0.9241, value_loss: 0.5668
2024-07-11 17:09:52,502 [INFO    ] __main__: train step 15255: loss: 0.9850, policy_loss: 0.9241, value_loss: 0.5668
2024-07-11 17:09:52,697 [INFO    ] __main__: train step 15256: loss: 0.9850, policy_loss: 0.9241, value_loss: 0.5667
2024-07-11 17:09:52,901 [INFO    ] __main__: train step 15257: loss: 0.9850, policy_loss: 0.9241, value_loss: 0.5667
2024-07-11 17:09:53,096 [INFO    ] __main__: train step 15258: loss: 0.9850, policy_loss: 0.9241, value_loss: 0.5667
2024-07-11 17:09:53,310 [INFO    ] __main__: train step 15259: loss: 0.9850, policy_loss: 0.9240, value_loss: 0.5667
2024-07-11 17:09:53,514 [INFO    ] __main__: train step 15260: loss: 0.9850, policy_loss: 0.9240, value_loss: 0.5666
2024-07-11 17:09:53,733 [INFO    ] __main__: train step 15261: loss: 0.9850, policy_loss: 0.9240, value_loss: 0.5666
2024-07-11 17:09:53,942 [INFO    ] __main__: train step 15262: loss: 0.9849, policy_loss: 0.9240, value_loss: 0.5666
2024-07-11 17:09:54,166 [INFO    ] __main__: train step 15263: loss: 0.9849, policy_loss: 0.9239, value_loss: 0.5666
2024-07-11 17:09:54,377 [INFO    ] __main__: train step 15264: loss: 0.9849, policy_loss: 0.9239, value_loss: 0.5665
2024-07-11 17:09:54,612 [INFO    ] __main__: train step 15265: loss: 0.9849, policy_loss: 0.9239, value_loss: 0.5665
2024-07-11 17:09:56,064 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:09:56,461 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:09:56,517 [INFO    ] __main__: train step 15266: loss: 0.9849, policy_loss: 0.9239, value_loss: 0.5665
2024-07-11 17:09:56,699 [INFO    ] __main__: train step 15267: loss: 0.9849, policy_loss: 0.9239, value_loss: 0.5665
2024-07-11 17:09:56,898 [INFO    ] __main__: train step 15268: loss: 0.9849, policy_loss: 0.9238, value_loss: 0.5664
2024-07-11 17:09:57,117 [INFO    ] __main__: train step 15269: loss: 0.9849, policy_loss: 0.9238, value_loss: 0.5664
2024-07-11 17:09:57,319 [INFO    ] __main__: train step 15270: loss: 0.9848, policy_loss: 0.9238, value_loss: 0.5664
2024-07-11 17:09:57,542 [INFO    ] __main__: train step 15271: loss: 0.9848, policy_loss: 0.9238, value_loss: 0.5664
2024-07-11 17:09:57,740 [INFO    ] __main__: train step 15272: loss: 0.9848, policy_loss: 0.9237, value_loss: 0.5664
2024-07-11 17:09:57,944 [INFO    ] __main__: train step 15273: loss: 0.9848, policy_loss: 0.9237, value_loss: 0.5663
2024-07-11 17:09:58,163 [INFO    ] __main__: train step 15274: loss: 0.9848, policy_loss: 0.9237, value_loss: 0.5663
2024-07-11 17:09:58,368 [INFO    ] __main__: train step 15275: loss: 0.9848, policy_loss: 0.9237, value_loss: 0.5663
2024-07-11 17:09:58,576 [INFO    ] __main__: train step 15276: loss: 0.9848, policy_loss: 0.9237, value_loss: 0.5663
2024-07-11 17:09:58,775 [INFO    ] __main__: train step 15277: loss: 0.9848, policy_loss: 0.9236, value_loss: 0.5662
2024-07-11 17:09:58,980 [INFO    ] __main__: train step 15278: loss: 0.9847, policy_loss: 0.9236, value_loss: 0.5662
2024-07-11 17:09:59,191 [INFO    ] __main__: train step 15279: loss: 0.9847, policy_loss: 0.9236, value_loss: 0.5662
2024-07-11 17:09:59,404 [INFO    ] __main__: train step 15280: loss: 0.9847, policy_loss: 0.9236, value_loss: 0.5662
2024-07-11 17:09:59,613 [INFO    ] __main__: train step 15281: loss: 0.9847, policy_loss: 0.9235, value_loss: 0.5661
2024-07-11 17:09:59,817 [INFO    ] __main__: train step 15282: loss: 0.9847, policy_loss: 0.9235, value_loss: 0.5661
2024-07-11 17:10:01,228 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:10:01,624 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:10:01,681 [INFO    ] __main__: train step 15283: loss: 0.9847, policy_loss: 0.9235, value_loss: 0.5661
2024-07-11 17:10:01,861 [INFO    ] __main__: train step 15284: loss: 0.9847, policy_loss: 0.9235, value_loss: 0.5661
2024-07-11 17:10:02,061 [INFO    ] __main__: train step 15285: loss: 0.9847, policy_loss: 0.9235, value_loss: 0.5660
2024-07-11 17:10:02,258 [INFO    ] __main__: train step 15286: loss: 0.9846, policy_loss: 0.9234, value_loss: 0.5660
2024-07-11 17:10:02,471 [INFO    ] __main__: train step 15287: loss: 0.9846, policy_loss: 0.9234, value_loss: 0.5660
2024-07-11 17:10:02,676 [INFO    ] __main__: train step 15288: loss: 0.9846, policy_loss: 0.9234, value_loss: 0.5660
2024-07-11 17:10:02,874 [INFO    ] __main__: train step 15289: loss: 0.9846, policy_loss: 0.9234, value_loss: 0.5660
2024-07-11 17:10:03,082 [INFO    ] __main__: train step 15290: loss: 0.9846, policy_loss: 0.9234, value_loss: 0.5659
2024-07-11 17:10:03,287 [INFO    ] __main__: train step 15291: loss: 0.9846, policy_loss: 0.9233, value_loss: 0.5659
2024-07-11 17:10:03,492 [INFO    ] __main__: train step 15292: loss: 0.9846, policy_loss: 0.9233, value_loss: 0.5659
2024-07-11 17:10:03,693 [INFO    ] __main__: train step 15293: loss: 0.9846, policy_loss: 0.9233, value_loss: 0.5659
2024-07-11 17:10:03,891 [INFO    ] __main__: train step 15294: loss: 0.9845, policy_loss: 0.9233, value_loss: 0.5658
2024-07-11 17:10:04,101 [INFO    ] __main__: train step 15295: loss: 0.9845, policy_loss: 0.9232, value_loss: 0.5658
2024-07-11 17:10:04,307 [INFO    ] __main__: train step 15296: loss: 0.9845, policy_loss: 0.9232, value_loss: 0.5658
2024-07-11 17:10:04,504 [INFO    ] __main__: train step 15297: loss: 0.9845, policy_loss: 0.9232, value_loss: 0.5658
2024-07-11 17:10:04,705 [INFO    ] __main__: train step 15298: loss: 0.9845, policy_loss: 0.9232, value_loss: 0.5657
2024-07-11 17:10:04,900 [INFO    ] __main__: train step 15299: loss: 0.9845, policy_loss: 0.9232, value_loss: 0.5657
2024-07-11 17:10:06,332 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:10:06,731 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:10:06,787 [INFO    ] __main__: train step 15300: loss: 0.9845, policy_loss: 0.9231, value_loss: 0.5657
2024-07-11 17:10:06,965 [INFO    ] __main__: train step 15301: loss: 0.9845, policy_loss: 0.9231, value_loss: 0.5657
2024-07-11 17:10:07,173 [INFO    ] __main__: train step 15302: loss: 0.9845, policy_loss: 0.9231, value_loss: 0.5657
2024-07-11 17:10:07,368 [INFO    ] __main__: train step 15303: loss: 0.9844, policy_loss: 0.9231, value_loss: 0.5656
2024-07-11 17:10:07,577 [INFO    ] __main__: train step 15304: loss: 0.9844, policy_loss: 0.9230, value_loss: 0.5656
2024-07-11 17:10:07,775 [INFO    ] __main__: train step 15305: loss: 0.9844, policy_loss: 0.9230, value_loss: 0.5656
2024-07-11 17:10:07,973 [INFO    ] __main__: train step 15306: loss: 0.9844, policy_loss: 0.9230, value_loss: 0.5656
2024-07-11 17:10:08,177 [INFO    ] __main__: train step 15307: loss: 0.9844, policy_loss: 0.9230, value_loss: 0.5655
2024-07-11 17:10:08,392 [INFO    ] __main__: train step 15308: loss: 0.9844, policy_loss: 0.9230, value_loss: 0.5655
2024-07-11 17:10:08,600 [INFO    ] __main__: train step 15309: loss: 0.9844, policy_loss: 0.9229, value_loss: 0.5655
2024-07-11 17:10:08,812 [INFO    ] __main__: train step 15310: loss: 0.9844, policy_loss: 0.9229, value_loss: 0.5655
2024-07-11 17:10:09,023 [INFO    ] __main__: train step 15311: loss: 0.9843, policy_loss: 0.9229, value_loss: 0.5654
2024-07-11 17:10:09,259 [INFO    ] __main__: train step 15312: loss: 0.9843, policy_loss: 0.9229, value_loss: 0.5654
2024-07-11 17:10:09,460 [INFO    ] __main__: train step 15313: loss: 0.9843, policy_loss: 0.9229, value_loss: 0.5654
2024-07-11 17:10:09,652 [INFO    ] __main__: train step 15314: loss: 0.9843, policy_loss: 0.9228, value_loss: 0.5654
2024-07-11 17:10:09,860 [INFO    ] __main__: train step 15315: loss: 0.9843, policy_loss: 0.9228, value_loss: 0.5653
2024-07-11 17:10:10,064 [INFO    ] __main__: train step 15316: loss: 0.9843, policy_loss: 0.9228, value_loss: 0.5653
2024-07-11 17:10:11,476 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:10:11,882 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:10:11,943 [INFO    ] __main__: train step 15317: loss: 0.9843, policy_loss: 0.9228, value_loss: 0.5653
2024-07-11 17:10:12,128 [INFO    ] __main__: train step 15318: loss: 0.9843, policy_loss: 0.9227, value_loss: 0.5653
2024-07-11 17:10:12,349 [INFO    ] __main__: train step 15319: loss: 0.9842, policy_loss: 0.9227, value_loss: 0.5653
2024-07-11 17:10:12,570 [INFO    ] __main__: train step 15320: loss: 0.9842, policy_loss: 0.9227, value_loss: 0.5652
2024-07-11 17:10:12,771 [INFO    ] __main__: train step 15321: loss: 0.9842, policy_loss: 0.9227, value_loss: 0.5652
2024-07-11 17:10:12,983 [INFO    ] __main__: train step 15322: loss: 0.9842, policy_loss: 0.9227, value_loss: 0.5652
2024-07-11 17:10:13,188 [INFO    ] __main__: train step 15323: loss: 0.9842, policy_loss: 0.9226, value_loss: 0.5652
2024-07-11 17:10:13,388 [INFO    ] __main__: train step 15324: loss: 0.9842, policy_loss: 0.9226, value_loss: 0.5651
2024-07-11 17:10:13,591 [INFO    ] __main__: train step 15325: loss: 0.9842, policy_loss: 0.9226, value_loss: 0.5651
2024-07-11 17:10:13,791 [INFO    ] __main__: train step 15326: loss: 0.9842, policy_loss: 0.9226, value_loss: 0.5651
2024-07-11 17:10:14,007 [INFO    ] __main__: train step 15327: loss: 0.9841, policy_loss: 0.9225, value_loss: 0.5651
2024-07-11 17:10:15,985 [INFO    ] __main__: train step 15328: loss: 0.9841, policy_loss: 0.9225, value_loss: 0.5650
2024-07-11 17:10:16,203 [INFO    ] __main__: train step 15329: loss: 0.9841, policy_loss: 0.9225, value_loss: 0.5650
2024-07-11 17:10:16,404 [INFO    ] __main__: train step 15330: loss: 0.9841, policy_loss: 0.9225, value_loss: 0.5650
2024-07-11 17:10:16,611 [INFO    ] __main__: train step 15331: loss: 0.9841, policy_loss: 0.9225, value_loss: 0.5650
2024-07-11 17:10:16,813 [INFO    ] __main__: train step 15332: loss: 0.9841, policy_loss: 0.9224, value_loss: 0.5650
2024-07-11 17:10:17,025 [INFO    ] __main__: train step 15333: loss: 0.9841, policy_loss: 0.9224, value_loss: 0.5649
2024-07-11 17:10:18,432 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:10:18,871 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:10:18,935 [INFO    ] __main__: train step 15334: loss: 0.9841, policy_loss: 0.9224, value_loss: 0.5649
2024-07-11 17:10:19,107 [INFO    ] __main__: train step 15335: loss: 0.9841, policy_loss: 0.9224, value_loss: 0.5649
2024-07-11 17:10:19,326 [INFO    ] __main__: train step 15336: loss: 0.9840, policy_loss: 0.9224, value_loss: 0.5649
2024-07-11 17:10:19,526 [INFO    ] __main__: train step 15337: loss: 0.9840, policy_loss: 0.9223, value_loss: 0.5648
2024-07-11 17:10:19,730 [INFO    ] __main__: train step 15338: loss: 0.9840, policy_loss: 0.9223, value_loss: 0.5648
2024-07-11 17:10:19,938 [INFO    ] __main__: train step 15339: loss: 0.9840, policy_loss: 0.9223, value_loss: 0.5648
2024-07-11 17:10:20,141 [INFO    ] __main__: train step 15340: loss: 0.9840, policy_loss: 0.9223, value_loss: 0.5648
2024-07-11 17:10:20,357 [INFO    ] __main__: train step 15341: loss: 0.9840, policy_loss: 0.9222, value_loss: 0.5647
2024-07-11 17:10:20,598 [INFO    ] __main__: train step 15342: loss: 0.9840, policy_loss: 0.9222, value_loss: 0.5647
2024-07-11 17:10:20,813 [INFO    ] __main__: train step 15343: loss: 0.9840, policy_loss: 0.9222, value_loss: 0.5647
2024-07-11 17:10:21,029 [INFO    ] __main__: train step 15344: loss: 0.9839, policy_loss: 0.9222, value_loss: 0.5647
2024-07-11 17:10:21,269 [INFO    ] __main__: train step 15345: loss: 0.9839, policy_loss: 0.9222, value_loss: 0.5647
2024-07-11 17:10:21,505 [INFO    ] __main__: train step 15346: loss: 0.9839, policy_loss: 0.9221, value_loss: 0.5646
2024-07-11 17:10:21,705 [INFO    ] __main__: train step 15347: loss: 0.9839, policy_loss: 0.9221, value_loss: 0.5646
2024-07-11 17:10:21,925 [INFO    ] __main__: train step 15348: loss: 0.9839, policy_loss: 0.9221, value_loss: 0.5646
2024-07-11 17:10:22,128 [INFO    ] __main__: train step 15349: loss: 0.9839, policy_loss: 0.9221, value_loss: 0.5646
2024-07-11 17:10:22,321 [INFO    ] __main__: train step 15350: loss: 0.9839, policy_loss: 0.9220, value_loss: 0.5645
2024-07-11 17:10:23,745 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:10:24,171 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:10:24,232 [INFO    ] __main__: train step 15351: loss: 0.9839, policy_loss: 0.9220, value_loss: 0.5645
2024-07-11 17:10:24,406 [INFO    ] __main__: train step 15352: loss: 0.9838, policy_loss: 0.9220, value_loss: 0.5645
2024-07-11 17:10:24,604 [INFO    ] __main__: train step 15353: loss: 0.9838, policy_loss: 0.9220, value_loss: 0.5645
2024-07-11 17:10:24,806 [INFO    ] __main__: train step 15354: loss: 0.9838, policy_loss: 0.9220, value_loss: 0.5644
2024-07-11 17:10:25,002 [INFO    ] __main__: train step 15355: loss: 0.9838, policy_loss: 0.9219, value_loss: 0.5644
2024-07-11 17:10:25,220 [INFO    ] __main__: train step 15356: loss: 0.9838, policy_loss: 0.9219, value_loss: 0.5644
2024-07-11 17:10:25,460 [INFO    ] __main__: train step 15357: loss: 0.9838, policy_loss: 0.9219, value_loss: 0.5644
2024-07-11 17:10:25,667 [INFO    ] __main__: train step 15358: loss: 0.9838, policy_loss: 0.9219, value_loss: 0.5643
2024-07-11 17:10:25,907 [INFO    ] __main__: train step 15359: loss: 0.9838, policy_loss: 0.9218, value_loss: 0.5643
2024-07-11 17:10:26,113 [INFO    ] __main__: train step 15360: loss: 0.9837, policy_loss: 0.9218, value_loss: 0.5643
2024-07-11 17:10:26,317 [INFO    ] __main__: train step 15361: loss: 0.9837, policy_loss: 0.9218, value_loss: 0.5643
2024-07-11 17:10:26,522 [INFO    ] __main__: train step 15362: loss: 0.9837, policy_loss: 0.9218, value_loss: 0.5643
2024-07-11 17:10:26,731 [INFO    ] __main__: train step 15363: loss: 0.9837, policy_loss: 0.9218, value_loss: 0.5642
2024-07-11 17:10:26,930 [INFO    ] __main__: train step 15364: loss: 0.9837, policy_loss: 0.9217, value_loss: 0.5642
2024-07-11 17:10:27,133 [INFO    ] __main__: train step 15365: loss: 0.9837, policy_loss: 0.9217, value_loss: 0.5642
2024-07-11 17:10:27,337 [INFO    ] __main__: train step 15366: loss: 0.9837, policy_loss: 0.9217, value_loss: 0.5642
2024-07-11 17:10:27,529 [INFO    ] __main__: train step 15367: loss: 0.9837, policy_loss: 0.9217, value_loss: 0.5641
2024-07-11 17:10:28,945 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:10:29,331 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:10:29,389 [INFO    ] __main__: train step 15368: loss: 0.9836, policy_loss: 0.9217, value_loss: 0.5641
2024-07-11 17:10:29,570 [INFO    ] __main__: train step 15369: loss: 0.9836, policy_loss: 0.9216, value_loss: 0.5641
2024-07-11 17:10:29,821 [INFO    ] __main__: train step 15370: loss: 0.9836, policy_loss: 0.9216, value_loss: 0.5641
2024-07-11 17:10:30,026 [INFO    ] __main__: train step 15371: loss: 0.9836, policy_loss: 0.9216, value_loss: 0.5641
2024-07-11 17:10:30,249 [INFO    ] __main__: train step 15372: loss: 0.9836, policy_loss: 0.9216, value_loss: 0.5640
2024-07-11 17:10:30,447 [INFO    ] __main__: train step 15373: loss: 0.9836, policy_loss: 0.9215, value_loss: 0.5640
2024-07-11 17:10:30,640 [INFO    ] __main__: train step 15374: loss: 0.9836, policy_loss: 0.9215, value_loss: 0.5640
2024-07-11 17:10:30,847 [INFO    ] __main__: train step 15375: loss: 0.9836, policy_loss: 0.9215, value_loss: 0.5640
2024-07-11 17:10:31,052 [INFO    ] __main__: train step 15376: loss: 0.9835, policy_loss: 0.9215, value_loss: 0.5639
2024-07-11 17:10:31,261 [INFO    ] __main__: train step 15377: loss: 0.9835, policy_loss: 0.9215, value_loss: 0.5639
2024-07-11 17:10:31,456 [INFO    ] __main__: train step 15378: loss: 0.9835, policy_loss: 0.9214, value_loss: 0.5639
2024-07-11 17:10:31,656 [INFO    ] __main__: train step 15379: loss: 0.9835, policy_loss: 0.9214, value_loss: 0.5639
2024-07-11 17:10:31,860 [INFO    ] __main__: train step 15380: loss: 0.9835, policy_loss: 0.9214, value_loss: 0.5638
2024-07-11 17:10:32,055 [INFO    ] __main__: train step 15381: loss: 0.9835, policy_loss: 0.9214, value_loss: 0.5638
2024-07-11 17:10:32,257 [INFO    ] __main__: train step 15382: loss: 0.9835, policy_loss: 0.9213, value_loss: 0.5638
2024-07-11 17:10:32,476 [INFO    ] __main__: train step 15383: loss: 0.9835, policy_loss: 0.9213, value_loss: 0.5638
2024-07-11 17:10:32,721 [INFO    ] __main__: train step 15384: loss: 0.9834, policy_loss: 0.9213, value_loss: 0.5637
2024-07-11 17:10:34,143 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:10:34,525 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:10:34,582 [INFO    ] __main__: train step 15385: loss: 0.9834, policy_loss: 0.9213, value_loss: 0.5637
2024-07-11 17:10:34,752 [INFO    ] __main__: train step 15386: loss: 0.9834, policy_loss: 0.9213, value_loss: 0.5637
2024-07-11 17:10:34,956 [INFO    ] __main__: train step 15387: loss: 0.9834, policy_loss: 0.9212, value_loss: 0.5637
2024-07-11 17:10:35,159 [INFO    ] __main__: train step 15388: loss: 0.9834, policy_loss: 0.9212, value_loss: 0.5637
2024-07-11 17:10:35,367 [INFO    ] __main__: train step 15389: loss: 0.9834, policy_loss: 0.9212, value_loss: 0.5636
2024-07-11 17:10:35,586 [INFO    ] __main__: train step 15390: loss: 0.9834, policy_loss: 0.9212, value_loss: 0.5636
2024-07-11 17:10:35,838 [INFO    ] __main__: train step 15391: loss: 0.9834, policy_loss: 0.9211, value_loss: 0.5636
2024-07-11 17:10:36,073 [INFO    ] __main__: train step 15392: loss: 0.9834, policy_loss: 0.9211, value_loss: 0.5636
2024-07-11 17:10:36,281 [INFO    ] __main__: train step 15393: loss: 0.9833, policy_loss: 0.9211, value_loss: 0.5635
2024-07-11 17:10:36,471 [INFO    ] __main__: train step 15394: loss: 0.9833, policy_loss: 0.9211, value_loss: 0.5635
2024-07-11 17:10:36,679 [INFO    ] __main__: train step 15395: loss: 0.9833, policy_loss: 0.9211, value_loss: 0.5635
2024-07-11 17:10:36,880 [INFO    ] __main__: train step 15396: loss: 0.9833, policy_loss: 0.9210, value_loss: 0.5635
2024-07-11 17:10:37,079 [INFO    ] __main__: train step 15397: loss: 0.9833, policy_loss: 0.9210, value_loss: 0.5635
2024-07-11 17:10:37,284 [INFO    ] __main__: train step 15398: loss: 0.9833, policy_loss: 0.9210, value_loss: 0.5634
2024-07-11 17:10:37,485 [INFO    ] __main__: train step 15399: loss: 0.9833, policy_loss: 0.9210, value_loss: 0.5634
2024-07-11 17:10:37,686 [INFO    ] __main__: train step 15400: loss: 0.9833, policy_loss: 0.9209, value_loss: 0.5634
2024-07-11 17:10:37,896 [INFO    ] __main__: train step 15401: loss: 0.9832, policy_loss: 0.9209, value_loss: 0.5634
2024-07-11 17:10:39,282 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:10:39,704 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:10:39,758 [INFO    ] __main__: train step 15402: loss: 0.9832, policy_loss: 0.9209, value_loss: 0.5633
2024-07-11 17:10:39,938 [INFO    ] __main__: train step 15403: loss: 0.9832, policy_loss: 0.9209, value_loss: 0.5633
2024-07-11 17:10:40,137 [INFO    ] __main__: train step 15404: loss: 0.9832, policy_loss: 0.9209, value_loss: 0.5633
2024-07-11 17:10:40,353 [INFO    ] __main__: train step 15405: loss: 0.9832, policy_loss: 0.9208, value_loss: 0.5633
2024-07-11 17:10:40,570 [INFO    ] __main__: train step 15406: loss: 0.9832, policy_loss: 0.9208, value_loss: 0.5633
2024-07-11 17:10:40,777 [INFO    ] __main__: train step 15407: loss: 0.9832, policy_loss: 0.9208, value_loss: 0.5632
2024-07-11 17:10:41,004 [INFO    ] __main__: train step 15408: loss: 0.9832, policy_loss: 0.9208, value_loss: 0.5632
2024-07-11 17:10:41,203 [INFO    ] __main__: train step 15409: loss: 0.9831, policy_loss: 0.9207, value_loss: 0.5632
2024-07-11 17:10:41,423 [INFO    ] __main__: train step 15410: loss: 0.9831, policy_loss: 0.9207, value_loss: 0.5632
2024-07-11 17:10:41,659 [INFO    ] __main__: train step 15411: loss: 0.9831, policy_loss: 0.9207, value_loss: 0.5631
2024-07-11 17:10:41,858 [INFO    ] __main__: train step 15412: loss: 0.9831, policy_loss: 0.9207, value_loss: 0.5631
2024-07-11 17:10:42,085 [INFO    ] __main__: train step 15413: loss: 0.9831, policy_loss: 0.9207, value_loss: 0.5631
2024-07-11 17:10:42,298 [INFO    ] __main__: train step 15414: loss: 0.9831, policy_loss: 0.9206, value_loss: 0.5631
2024-07-11 17:10:42,512 [INFO    ] __main__: train step 15415: loss: 0.9831, policy_loss: 0.9206, value_loss: 0.5630
2024-07-11 17:10:42,719 [INFO    ] __main__: train step 15416: loss: 0.9831, policy_loss: 0.9206, value_loss: 0.5630
2024-07-11 17:10:42,912 [INFO    ] __main__: train step 15417: loss: 0.9831, policy_loss: 0.9206, value_loss: 0.5630
2024-07-11 17:10:43,118 [INFO    ] __main__: train step 15418: loss: 0.9830, policy_loss: 0.9206, value_loss: 0.5630
2024-07-11 17:10:44,551 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:10:44,946 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:10:45,006 [INFO    ] __main__: train step 15419: loss: 0.9830, policy_loss: 0.9205, value_loss: 0.5630
2024-07-11 17:10:45,181 [INFO    ] __main__: train step 15420: loss: 0.9830, policy_loss: 0.9205, value_loss: 0.5629
2024-07-11 17:10:45,400 [INFO    ] __main__: train step 15421: loss: 0.9830, policy_loss: 0.9205, value_loss: 0.5629
2024-07-11 17:10:45,645 [INFO    ] __main__: train step 15422: loss: 0.9830, policy_loss: 0.9205, value_loss: 0.5629
2024-07-11 17:10:45,871 [INFO    ] __main__: train step 15423: loss: 0.9830, policy_loss: 0.9204, value_loss: 0.5629
2024-07-11 17:10:46,062 [INFO    ] __main__: train step 15424: loss: 0.9830, policy_loss: 0.9204, value_loss: 0.5628
2024-07-11 17:10:46,270 [INFO    ] __main__: train step 15425: loss: 0.9830, policy_loss: 0.9204, value_loss: 0.5628
2024-07-11 17:10:46,474 [INFO    ] __main__: train step 15426: loss: 0.9829, policy_loss: 0.9204, value_loss: 0.5628
2024-07-11 17:10:46,685 [INFO    ] __main__: train step 15427: loss: 0.9829, policy_loss: 0.9204, value_loss: 0.5628
2024-07-11 17:10:46,914 [INFO    ] __main__: train step 15428: loss: 0.9829, policy_loss: 0.9203, value_loss: 0.5628
2024-07-11 17:10:47,117 [INFO    ] __main__: train step 15429: loss: 0.9829, policy_loss: 0.9203, value_loss: 0.5627
2024-07-11 17:10:47,342 [INFO    ] __main__: train step 15430: loss: 0.9829, policy_loss: 0.9203, value_loss: 0.5627
2024-07-11 17:10:47,582 [INFO    ] __main__: train step 15431: loss: 0.9829, policy_loss: 0.9203, value_loss: 0.5627
2024-07-11 17:10:47,822 [INFO    ] __main__: train step 15432: loss: 0.9829, policy_loss: 0.9202, value_loss: 0.5627
2024-07-11 17:10:48,025 [INFO    ] __main__: train step 15433: loss: 0.9829, policy_loss: 0.9202, value_loss: 0.5626
2024-07-11 17:10:48,269 [INFO    ] __main__: train step 15434: loss: 0.9829, policy_loss: 0.9202, value_loss: 0.5626
2024-07-11 17:10:48,465 [INFO    ] __main__: train step 15435: loss: 0.9828, policy_loss: 0.9202, value_loss: 0.5626
2024-07-11 17:10:49,842 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:10:50,219 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:10:50,277 [INFO    ] __main__: train step 15436: loss: 0.9828, policy_loss: 0.9202, value_loss: 0.5626
2024-07-11 17:10:50,470 [INFO    ] __main__: train step 15437: loss: 0.9828, policy_loss: 0.9201, value_loss: 0.5626
2024-07-11 17:10:50,673 [INFO    ] __main__: train step 15438: loss: 0.9828, policy_loss: 0.9201, value_loss: 0.5625
2024-07-11 17:10:50,886 [INFO    ] __main__: train step 15439: loss: 0.9828, policy_loss: 0.9201, value_loss: 0.5625
2024-07-11 17:10:51,099 [INFO    ] __main__: train step 15440: loss: 0.9828, policy_loss: 0.9201, value_loss: 0.5625
2024-07-11 17:10:51,333 [INFO    ] __main__: train step 15441: loss: 0.9828, policy_loss: 0.9200, value_loss: 0.5625
2024-07-11 17:10:51,555 [INFO    ] __main__: train step 15442: loss: 0.9828, policy_loss: 0.9200, value_loss: 0.5625
2024-07-11 17:10:53,476 [INFO    ] __main__: train step 15443: loss: 0.9827, policy_loss: 0.9200, value_loss: 0.5624
2024-07-11 17:10:53,695 [INFO    ] __main__: train step 15444: loss: 0.9827, policy_loss: 0.9200, value_loss: 0.5624
2024-07-11 17:10:53,939 [INFO    ] __main__: train step 15445: loss: 0.9827, policy_loss: 0.9200, value_loss: 0.5624
2024-07-11 17:10:54,159 [INFO    ] __main__: train step 15446: loss: 0.9827, policy_loss: 0.9199, value_loss: 0.5624
2024-07-11 17:10:54,406 [INFO    ] __main__: train step 15447: loss: 0.9827, policy_loss: 0.9199, value_loss: 0.5623
2024-07-11 17:10:54,616 [INFO    ] __main__: train step 15448: loss: 0.9827, policy_loss: 0.9199, value_loss: 0.5623
2024-07-11 17:10:54,824 [INFO    ] __main__: train step 15449: loss: 0.9827, policy_loss: 0.9199, value_loss: 0.5623
2024-07-11 17:10:55,039 [INFO    ] __main__: train step 15450: loss: 0.9827, policy_loss: 0.9198, value_loss: 0.5623
2024-07-11 17:10:55,242 [INFO    ] __main__: train step 15451: loss: 0.9827, policy_loss: 0.9198, value_loss: 0.5623
2024-07-11 17:10:55,450 [INFO    ] __main__: train step 15452: loss: 0.9826, policy_loss: 0.9198, value_loss: 0.5622
2024-07-11 17:10:56,874 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:10:57,254 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:10:57,314 [INFO    ] __main__: train step 15453: loss: 0.9826, policy_loss: 0.9198, value_loss: 0.5622
2024-07-11 17:10:57,499 [INFO    ] __main__: train step 15454: loss: 0.9826, policy_loss: 0.9198, value_loss: 0.5622
2024-07-11 17:10:57,702 [INFO    ] __main__: train step 15455: loss: 0.9826, policy_loss: 0.9197, value_loss: 0.5622
2024-07-11 17:10:57,900 [INFO    ] __main__: train step 15456: loss: 0.9826, policy_loss: 0.9197, value_loss: 0.5621
2024-07-11 17:10:58,115 [INFO    ] __main__: train step 15457: loss: 0.9826, policy_loss: 0.9197, value_loss: 0.5621
2024-07-11 17:10:58,346 [INFO    ] __main__: train step 15458: loss: 0.9826, policy_loss: 0.9197, value_loss: 0.5621
2024-07-11 17:10:58,554 [INFO    ] __main__: train step 15459: loss: 0.9826, policy_loss: 0.9196, value_loss: 0.5621
2024-07-11 17:10:58,761 [INFO    ] __main__: train step 15460: loss: 0.9825, policy_loss: 0.9196, value_loss: 0.5621
2024-07-11 17:10:58,972 [INFO    ] __main__: train step 15461: loss: 0.9825, policy_loss: 0.9196, value_loss: 0.5620
2024-07-11 17:10:59,173 [INFO    ] __main__: train step 15462: loss: 0.9825, policy_loss: 0.9196, value_loss: 0.5620
2024-07-11 17:10:59,390 [INFO    ] __main__: train step 15463: loss: 0.9825, policy_loss: 0.9196, value_loss: 0.5620
2024-07-11 17:10:59,593 [INFO    ] __main__: train step 15464: loss: 0.9825, policy_loss: 0.9195, value_loss: 0.5620
2024-07-11 17:10:59,798 [INFO    ] __main__: train step 15465: loss: 0.9825, policy_loss: 0.9195, value_loss: 0.5620
2024-07-11 17:11:00,007 [INFO    ] __main__: train step 15466: loss: 0.9825, policy_loss: 0.9195, value_loss: 0.5619
2024-07-11 17:11:00,226 [INFO    ] __main__: train step 15467: loss: 0.9825, policy_loss: 0.9195, value_loss: 0.5619
2024-07-11 17:11:00,428 [INFO    ] __main__: train step 15468: loss: 0.9825, policy_loss: 0.9194, value_loss: 0.5619
2024-07-11 17:11:00,631 [INFO    ] __main__: train step 15469: loss: 0.9824, policy_loss: 0.9194, value_loss: 0.5619
2024-07-11 17:11:02,076 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:11:02,466 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:11:02,526 [INFO    ] __main__: train step 15470: loss: 0.9824, policy_loss: 0.9194, value_loss: 0.5618
2024-07-11 17:11:02,726 [INFO    ] __main__: train step 15471: loss: 0.9824, policy_loss: 0.9194, value_loss: 0.5618
2024-07-11 17:11:02,946 [INFO    ] __main__: train step 15472: loss: 0.9824, policy_loss: 0.9193, value_loss: 0.5618
2024-07-11 17:11:03,155 [INFO    ] __main__: train step 15473: loss: 0.9824, policy_loss: 0.9193, value_loss: 0.5618
2024-07-11 17:11:03,353 [INFO    ] __main__: train step 15474: loss: 0.9824, policy_loss: 0.9193, value_loss: 0.5618
2024-07-11 17:11:03,561 [INFO    ] __main__: train step 15475: loss: 0.9824, policy_loss: 0.9193, value_loss: 0.5617
2024-07-11 17:11:03,759 [INFO    ] __main__: train step 15476: loss: 0.9824, policy_loss: 0.9193, value_loss: 0.5617
2024-07-11 17:11:03,959 [INFO    ] __main__: train step 15477: loss: 0.9823, policy_loss: 0.9192, value_loss: 0.5617
2024-07-11 17:11:04,154 [INFO    ] __main__: train step 15478: loss: 0.9823, policy_loss: 0.9192, value_loss: 0.5617
2024-07-11 17:11:04,351 [INFO    ] __main__: train step 15479: loss: 0.9823, policy_loss: 0.9192, value_loss: 0.5616
2024-07-11 17:11:04,552 [INFO    ] __main__: train step 15480: loss: 0.9823, policy_loss: 0.9192, value_loss: 0.5616
2024-07-11 17:11:04,753 [INFO    ] __main__: train step 15481: loss: 0.9823, policy_loss: 0.9192, value_loss: 0.5616
2024-07-11 17:11:04,956 [INFO    ] __main__: train step 15482: loss: 0.9823, policy_loss: 0.9191, value_loss: 0.5616
2024-07-11 17:11:05,167 [INFO    ] __main__: train step 15483: loss: 0.9823, policy_loss: 0.9191, value_loss: 0.5616
2024-07-11 17:11:05,365 [INFO    ] __main__: train step 15484: loss: 0.9823, policy_loss: 0.9191, value_loss: 0.5615
2024-07-11 17:11:05,563 [INFO    ] __main__: train step 15485: loss: 0.9822, policy_loss: 0.9191, value_loss: 0.5615
2024-07-11 17:11:05,770 [INFO    ] __main__: train step 15486: loss: 0.9822, policy_loss: 0.9190, value_loss: 0.5615
2024-07-11 17:11:07,215 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:11:07,583 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:11:07,645 [INFO    ] __main__: train step 15487: loss: 0.9822, policy_loss: 0.9190, value_loss: 0.5615
2024-07-11 17:11:07,823 [INFO    ] __main__: train step 15488: loss: 0.9822, policy_loss: 0.9190, value_loss: 0.5615
2024-07-11 17:11:08,017 [INFO    ] __main__: train step 15489: loss: 0.9822, policy_loss: 0.9190, value_loss: 0.5614
2024-07-11 17:11:08,216 [INFO    ] __main__: train step 15490: loss: 0.9822, policy_loss: 0.9190, value_loss: 0.5614
2024-07-11 17:11:08,437 [INFO    ] __main__: train step 15491: loss: 0.9822, policy_loss: 0.9189, value_loss: 0.5614
2024-07-11 17:11:08,665 [INFO    ] __main__: train step 15492: loss: 0.9822, policy_loss: 0.9189, value_loss: 0.5614
2024-07-11 17:11:08,895 [INFO    ] __main__: train step 15493: loss: 0.9822, policy_loss: 0.9189, value_loss: 0.5613
2024-07-11 17:11:09,116 [INFO    ] __main__: train step 15494: loss: 0.9821, policy_loss: 0.9189, value_loss: 0.5613
2024-07-11 17:11:09,364 [INFO    ] __main__: train step 15495: loss: 0.9821, policy_loss: 0.9188, value_loss: 0.5613
2024-07-11 17:11:09,597 [INFO    ] __main__: train step 15496: loss: 0.9821, policy_loss: 0.9188, value_loss: 0.5613
2024-07-11 17:11:09,794 [INFO    ] __main__: train step 15497: loss: 0.9821, policy_loss: 0.9188, value_loss: 0.5613
2024-07-11 17:11:09,997 [INFO    ] __main__: train step 15498: loss: 0.9821, policy_loss: 0.9188, value_loss: 0.5612
2024-07-11 17:11:10,198 [INFO    ] __main__: train step 15499: loss: 0.9821, policy_loss: 0.9187, value_loss: 0.5612
2024-07-11 17:11:10,410 [INFO    ] __main__: train step 15500: loss: 0.9821, policy_loss: 0.9187, value_loss: 0.5612
2024-07-11 17:11:10,607 [INFO    ] __main__: train step 15501: loss: 0.9821, policy_loss: 0.9187, value_loss: 0.5612
2024-07-11 17:11:10,803 [INFO    ] __main__: train step 15502: loss: 0.9820, policy_loss: 0.9187, value_loss: 0.5611
2024-07-11 17:11:11,002 [INFO    ] __main__: train step 15503: loss: 0.9820, policy_loss: 0.9187, value_loss: 0.5611
2024-07-11 17:11:12,409 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:11:12,777 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:11:12,833 [INFO    ] __main__: train step 15504: loss: 0.9820, policy_loss: 0.9186, value_loss: 0.5611
2024-07-11 17:11:13,014 [INFO    ] __main__: train step 15505: loss: 0.9820, policy_loss: 0.9186, value_loss: 0.5611
2024-07-11 17:11:13,212 [INFO    ] __main__: train step 15506: loss: 0.9820, policy_loss: 0.9186, value_loss: 0.5611
2024-07-11 17:11:13,412 [INFO    ] __main__: train step 15507: loss: 0.9820, policy_loss: 0.9186, value_loss: 0.5610
2024-07-11 17:11:13,611 [INFO    ] __main__: train step 15508: loss: 0.9820, policy_loss: 0.9185, value_loss: 0.5610
2024-07-11 17:11:13,823 [INFO    ] __main__: train step 15509: loss: 0.9820, policy_loss: 0.9185, value_loss: 0.5610
2024-07-11 17:11:14,022 [INFO    ] __main__: train step 15510: loss: 0.9820, policy_loss: 0.9185, value_loss: 0.5610
2024-07-11 17:11:14,221 [INFO    ] __main__: train step 15511: loss: 0.9819, policy_loss: 0.9185, value_loss: 0.5610
2024-07-11 17:11:14,439 [INFO    ] __main__: train step 15512: loss: 0.9819, policy_loss: 0.9185, value_loss: 0.5609
2024-07-11 17:11:14,639 [INFO    ] __main__: train step 15513: loss: 0.9819, policy_loss: 0.9184, value_loss: 0.5609
2024-07-11 17:11:14,846 [INFO    ] __main__: train step 15514: loss: 0.9819, policy_loss: 0.9184, value_loss: 0.5609
2024-07-11 17:11:15,052 [INFO    ] __main__: train step 15515: loss: 0.9819, policy_loss: 0.9184, value_loss: 0.5609
2024-07-11 17:11:15,286 [INFO    ] __main__: train step 15516: loss: 0.9819, policy_loss: 0.9184, value_loss: 0.5608
2024-07-11 17:11:15,485 [INFO    ] __main__: train step 15517: loss: 0.9819, policy_loss: 0.9183, value_loss: 0.5608
2024-07-11 17:11:15,691 [INFO    ] __main__: train step 15518: loss: 0.9819, policy_loss: 0.9183, value_loss: 0.5608
2024-07-11 17:11:15,891 [INFO    ] __main__: train step 15519: loss: 0.9818, policy_loss: 0.9183, value_loss: 0.5608
2024-07-11 17:11:16,091 [INFO    ] __main__: train step 15520: loss: 0.9818, policy_loss: 0.9183, value_loss: 0.5608
2024-07-11 17:11:17,531 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:11:17,883 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:11:17,938 [INFO    ] __main__: train step 15521: loss: 0.9818, policy_loss: 0.9183, value_loss: 0.5607
2024-07-11 17:11:18,137 [INFO    ] __main__: train step 15522: loss: 0.9818, policy_loss: 0.9182, value_loss: 0.5607
2024-07-11 17:11:18,374 [INFO    ] __main__: train step 15523: loss: 0.9818, policy_loss: 0.9182, value_loss: 0.5607
2024-07-11 17:11:18,577 [INFO    ] __main__: train step 15524: loss: 0.9818, policy_loss: 0.9182, value_loss: 0.5607
2024-07-11 17:11:18,779 [INFO    ] __main__: train step 15525: loss: 0.9818, policy_loss: 0.9182, value_loss: 0.5607
2024-07-11 17:11:18,982 [INFO    ] __main__: train step 15526: loss: 0.9818, policy_loss: 0.9181, value_loss: 0.5606
2024-07-11 17:11:19,203 [INFO    ] __main__: train step 15527: loss: 0.9817, policy_loss: 0.9181, value_loss: 0.5606
2024-07-11 17:11:19,412 [INFO    ] __main__: train step 15528: loss: 0.9817, policy_loss: 0.9181, value_loss: 0.5606
2024-07-11 17:11:19,620 [INFO    ] __main__: train step 15529: loss: 0.9817, policy_loss: 0.9181, value_loss: 0.5606
2024-07-11 17:11:19,832 [INFO    ] __main__: train step 15530: loss: 0.9817, policy_loss: 0.9181, value_loss: 0.5605
2024-07-11 17:11:20,027 [INFO    ] __main__: train step 15531: loss: 0.9817, policy_loss: 0.9180, value_loss: 0.5605
2024-07-11 17:11:20,245 [INFO    ] __main__: train step 15532: loss: 0.9817, policy_loss: 0.9180, value_loss: 0.5605
2024-07-11 17:11:20,464 [INFO    ] __main__: train step 15533: loss: 0.9817, policy_loss: 0.9180, value_loss: 0.5605
2024-07-11 17:11:20,675 [INFO    ] __main__: train step 15534: loss: 0.9817, policy_loss: 0.9180, value_loss: 0.5605
2024-07-11 17:11:20,894 [INFO    ] __main__: train step 15535: loss: 0.9817, policy_loss: 0.9179, value_loss: 0.5604
2024-07-11 17:11:21,136 [INFO    ] __main__: train step 15536: loss: 0.9816, policy_loss: 0.9179, value_loss: 0.5604
2024-07-11 17:11:21,404 [INFO    ] __main__: train step 15537: loss: 0.9816, policy_loss: 0.9179, value_loss: 0.5604
2024-07-11 17:11:22,853 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:11:23,290 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:11:23,354 [INFO    ] __main__: train step 15538: loss: 0.9816, policy_loss: 0.9179, value_loss: 0.5604
2024-07-11 17:11:23,542 [INFO    ] __main__: train step 15539: loss: 0.9816, policy_loss: 0.9179, value_loss: 0.5604
2024-07-11 17:11:23,778 [INFO    ] __main__: train step 15540: loss: 0.9816, policy_loss: 0.9178, value_loss: 0.5603
2024-07-11 17:11:24,001 [INFO    ] __main__: train step 15541: loss: 0.9816, policy_loss: 0.9178, value_loss: 0.5603
2024-07-11 17:11:24,198 [INFO    ] __main__: train step 15542: loss: 0.9816, policy_loss: 0.9178, value_loss: 0.5603
2024-07-11 17:11:24,413 [INFO    ] __main__: train step 15543: loss: 0.9816, policy_loss: 0.9178, value_loss: 0.5603
2024-07-11 17:11:24,612 [INFO    ] __main__: train step 15544: loss: 0.9816, policy_loss: 0.9177, value_loss: 0.5602
2024-07-11 17:11:24,820 [INFO    ] __main__: train step 15545: loss: 0.9815, policy_loss: 0.9177, value_loss: 0.5602
2024-07-11 17:11:25,028 [INFO    ] __main__: train step 15546: loss: 0.9815, policy_loss: 0.9177, value_loss: 0.5602
2024-07-11 17:11:25,227 [INFO    ] __main__: train step 15547: loss: 0.9815, policy_loss: 0.9177, value_loss: 0.5602
2024-07-11 17:11:25,423 [INFO    ] __main__: train step 15548: loss: 0.9815, policy_loss: 0.9177, value_loss: 0.5602
2024-07-11 17:11:25,628 [INFO    ] __main__: train step 15549: loss: 0.9815, policy_loss: 0.9176, value_loss: 0.5601
2024-07-11 17:11:25,831 [INFO    ] __main__: train step 15550: loss: 0.9815, policy_loss: 0.9176, value_loss: 0.5601
2024-07-11 17:11:26,027 [INFO    ] __main__: train step 15551: loss: 0.9815, policy_loss: 0.9176, value_loss: 0.5601
2024-07-11 17:11:26,237 [INFO    ] __main__: train step 15552: loss: 0.9815, policy_loss: 0.9176, value_loss: 0.5601
2024-07-11 17:11:26,459 [INFO    ] __main__: train step 15553: loss: 0.9814, policy_loss: 0.9175, value_loss: 0.5601
2024-07-11 17:11:26,693 [INFO    ] __main__: train step 15554: loss: 0.9814, policy_loss: 0.9175, value_loss: 0.5600
2024-07-11 17:11:28,128 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:11:28,511 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:11:28,568 [INFO    ] __main__: train step 15555: loss: 0.9814, policy_loss: 0.9175, value_loss: 0.5600
2024-07-11 17:11:28,736 [INFO    ] __main__: train step 15556: loss: 0.9814, policy_loss: 0.9175, value_loss: 0.5600
2024-07-11 17:11:28,931 [INFO    ] __main__: train step 15557: loss: 0.9814, policy_loss: 0.9175, value_loss: 0.5600
2024-07-11 17:11:29,131 [INFO    ] __main__: train step 15558: loss: 0.9814, policy_loss: 0.9174, value_loss: 0.5600
2024-07-11 17:11:31,049 [INFO    ] __main__: train step 15559: loss: 0.9814, policy_loss: 0.9174, value_loss: 0.5599
2024-07-11 17:11:31,255 [INFO    ] __main__: train step 15560: loss: 0.9814, policy_loss: 0.9174, value_loss: 0.5599
2024-07-11 17:11:31,476 [INFO    ] __main__: train step 15561: loss: 0.9814, policy_loss: 0.9174, value_loss: 0.5599
2024-07-11 17:11:31,676 [INFO    ] __main__: train step 15562: loss: 0.9813, policy_loss: 0.9173, value_loss: 0.5599
2024-07-11 17:11:31,872 [INFO    ] __main__: train step 15563: loss: 0.9813, policy_loss: 0.9173, value_loss: 0.5598
2024-07-11 17:11:32,070 [INFO    ] __main__: train step 15564: loss: 0.9813, policy_loss: 0.9173, value_loss: 0.5598
2024-07-11 17:11:32,278 [INFO    ] __main__: train step 15565: loss: 0.9813, policy_loss: 0.9173, value_loss: 0.5598
2024-07-11 17:11:32,490 [INFO    ] __main__: train step 15566: loss: 0.9813, policy_loss: 0.9172, value_loss: 0.5598
2024-07-11 17:11:32,699 [INFO    ] __main__: train step 15567: loss: 0.9813, policy_loss: 0.9172, value_loss: 0.5598
2024-07-11 17:11:32,905 [INFO    ] __main__: train step 15568: loss: 0.9813, policy_loss: 0.9172, value_loss: 0.5597
2024-07-11 17:11:33,121 [INFO    ] __main__: train step 15569: loss: 0.9813, policy_loss: 0.9172, value_loss: 0.5597
2024-07-11 17:11:33,333 [INFO    ] __main__: train step 15570: loss: 0.9813, policy_loss: 0.9172, value_loss: 0.5597
2024-07-11 17:11:33,535 [INFO    ] __main__: train step 15571: loss: 0.9812, policy_loss: 0.9171, value_loss: 0.5597
2024-07-11 17:11:34,925 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:11:35,294 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:11:35,349 [INFO    ] __main__: train step 15572: loss: 0.9812, policy_loss: 0.9171, value_loss: 0.5597
2024-07-11 17:11:35,531 [INFO    ] __main__: train step 15573: loss: 0.9812, policy_loss: 0.9171, value_loss: 0.5596
2024-07-11 17:11:35,740 [INFO    ] __main__: train step 15574: loss: 0.9812, policy_loss: 0.9171, value_loss: 0.5596
2024-07-11 17:11:35,940 [INFO    ] __main__: train step 15575: loss: 0.9812, policy_loss: 0.9170, value_loss: 0.5596
2024-07-11 17:11:36,155 [INFO    ] __main__: train step 15576: loss: 0.9812, policy_loss: 0.9170, value_loss: 0.5596
2024-07-11 17:11:36,363 [INFO    ] __main__: train step 15577: loss: 0.9812, policy_loss: 0.9170, value_loss: 0.5596
2024-07-11 17:11:36,601 [INFO    ] __main__: train step 15578: loss: 0.9812, policy_loss: 0.9170, value_loss: 0.5595
2024-07-11 17:11:36,812 [INFO    ] __main__: train step 15579: loss: 0.9811, policy_loss: 0.9170, value_loss: 0.5595
2024-07-11 17:11:37,009 [INFO    ] __main__: train step 15580: loss: 0.9811, policy_loss: 0.9169, value_loss: 0.5595
2024-07-11 17:11:37,216 [INFO    ] __main__: train step 15581: loss: 0.9811, policy_loss: 0.9169, value_loss: 0.5595
2024-07-11 17:11:37,418 [INFO    ] __main__: train step 15582: loss: 0.9811, policy_loss: 0.9169, value_loss: 0.5595
2024-07-11 17:11:37,619 [INFO    ] __main__: train step 15583: loss: 0.9811, policy_loss: 0.9169, value_loss: 0.5594
2024-07-11 17:11:37,818 [INFO    ] __main__: train step 15584: loss: 0.9811, policy_loss: 0.9168, value_loss: 0.5594
2024-07-11 17:11:38,022 [INFO    ] __main__: train step 15585: loss: 0.9811, policy_loss: 0.9168, value_loss: 0.5594
2024-07-11 17:11:38,223 [INFO    ] __main__: train step 15586: loss: 0.9811, policy_loss: 0.9168, value_loss: 0.5594
2024-07-11 17:11:38,447 [INFO    ] __main__: train step 15587: loss: 0.9810, policy_loss: 0.9168, value_loss: 0.5593
2024-07-11 17:11:38,668 [INFO    ] __main__: train step 15588: loss: 0.9810, policy_loss: 0.9167, value_loss: 0.5593
2024-07-11 17:11:40,093 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:11:40,420 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:11:40,476 [INFO    ] __main__: train step 15589: loss: 0.9810, policy_loss: 0.9167, value_loss: 0.5593
2024-07-11 17:11:40,660 [INFO    ] __main__: train step 15590: loss: 0.9810, policy_loss: 0.9167, value_loss: 0.5593
2024-07-11 17:11:40,861 [INFO    ] __main__: train step 15591: loss: 0.9810, policy_loss: 0.9167, value_loss: 0.5593
2024-07-11 17:11:41,072 [INFO    ] __main__: train step 15592: loss: 0.9810, policy_loss: 0.9167, value_loss: 0.5592
2024-07-11 17:11:41,274 [INFO    ] __main__: train step 15593: loss: 0.9810, policy_loss: 0.9166, value_loss: 0.5592
2024-07-11 17:11:41,488 [INFO    ] __main__: train step 15594: loss: 0.9810, policy_loss: 0.9166, value_loss: 0.5592
2024-07-11 17:11:41,688 [INFO    ] __main__: train step 15595: loss: 0.9810, policy_loss: 0.9166, value_loss: 0.5592
2024-07-11 17:11:41,899 [INFO    ] __main__: train step 15596: loss: 0.9809, policy_loss: 0.9166, value_loss: 0.5592
2024-07-11 17:11:42,110 [INFO    ] __main__: train step 15597: loss: 0.9809, policy_loss: 0.9165, value_loss: 0.5591
2024-07-11 17:11:42,340 [INFO    ] __main__: train step 15598: loss: 0.9809, policy_loss: 0.9165, value_loss: 0.5591
2024-07-11 17:11:42,532 [INFO    ] __main__: train step 15599: loss: 0.9809, policy_loss: 0.9165, value_loss: 0.5591
2024-07-11 17:11:42,737 [INFO    ] __main__: train step 15600: loss: 0.9809, policy_loss: 0.9165, value_loss: 0.5591
2024-07-11 17:11:42,935 [INFO    ] __main__: train step 15601: loss: 0.9809, policy_loss: 0.9165, value_loss: 0.5591
2024-07-11 17:11:43,135 [INFO    ] __main__: train step 15602: loss: 0.9809, policy_loss: 0.9164, value_loss: 0.5590
2024-07-11 17:11:43,339 [INFO    ] __main__: train step 15603: loss: 0.9809, policy_loss: 0.9164, value_loss: 0.5590
2024-07-11 17:11:43,539 [INFO    ] __main__: train step 15604: loss: 0.9809, policy_loss: 0.9164, value_loss: 0.5590
2024-07-11 17:11:43,729 [INFO    ] __main__: train step 15605: loss: 0.9808, policy_loss: 0.9164, value_loss: 0.5590
2024-07-11 17:11:45,165 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:11:45,534 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:11:45,594 [INFO    ] __main__: train step 15606: loss: 0.9808, policy_loss: 0.9163, value_loss: 0.5590
2024-07-11 17:11:45,767 [INFO    ] __main__: train step 15607: loss: 0.9808, policy_loss: 0.9163, value_loss: 0.5589
2024-07-11 17:11:45,973 [INFO    ] __main__: train step 15608: loss: 0.9808, policy_loss: 0.9163, value_loss: 0.5589
2024-07-11 17:11:46,173 [INFO    ] __main__: train step 15609: loss: 0.9808, policy_loss: 0.9163, value_loss: 0.5589
2024-07-11 17:11:46,371 [INFO    ] __main__: train step 15610: loss: 0.9808, policy_loss: 0.9163, value_loss: 0.5589
2024-07-11 17:11:46,576 [INFO    ] __main__: train step 15611: loss: 0.9808, policy_loss: 0.9162, value_loss: 0.5589
2024-07-11 17:11:46,779 [INFO    ] __main__: train step 15612: loss: 0.9808, policy_loss: 0.9162, value_loss: 0.5588
2024-07-11 17:11:46,991 [INFO    ] __main__: train step 15613: loss: 0.9808, policy_loss: 0.9162, value_loss: 0.5588
2024-07-11 17:11:47,184 [INFO    ] __main__: train step 15614: loss: 0.9807, policy_loss: 0.9162, value_loss: 0.5588
2024-07-11 17:11:47,418 [INFO    ] __main__: train step 15615: loss: 0.9807, policy_loss: 0.9161, value_loss: 0.5588
2024-07-11 17:11:47,641 [INFO    ] __main__: train step 15616: loss: 0.9807, policy_loss: 0.9161, value_loss: 0.5588
2024-07-11 17:11:47,886 [INFO    ] __main__: train step 15617: loss: 0.9807, policy_loss: 0.9161, value_loss: 0.5587
2024-07-11 17:11:48,092 [INFO    ] __main__: train step 15618: loss: 0.9807, policy_loss: 0.9161, value_loss: 0.5587
2024-07-11 17:11:48,291 [INFO    ] __main__: train step 15619: loss: 0.9807, policy_loss: 0.9161, value_loss: 0.5587
2024-07-11 17:11:48,499 [INFO    ] __main__: train step 15620: loss: 0.9807, policy_loss: 0.9160, value_loss: 0.5587
2024-07-11 17:11:48,692 [INFO    ] __main__: train step 15621: loss: 0.9807, policy_loss: 0.9160, value_loss: 0.5587
2024-07-11 17:11:48,892 [INFO    ] __main__: train step 15622: loss: 0.9807, policy_loss: 0.9160, value_loss: 0.5586
2024-07-11 17:11:50,310 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:11:50,744 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:11:50,804 [INFO    ] __main__: train step 15623: loss: 0.9806, policy_loss: 0.9160, value_loss: 0.5586
2024-07-11 17:11:50,976 [INFO    ] __main__: train step 15624: loss: 0.9806, policy_loss: 0.9159, value_loss: 0.5586
2024-07-11 17:11:51,198 [INFO    ] __main__: train step 15625: loss: 0.9806, policy_loss: 0.9159, value_loss: 0.5586
2024-07-11 17:11:51,405 [INFO    ] __main__: train step 15626: loss: 0.9806, policy_loss: 0.9159, value_loss: 0.5586
2024-07-11 17:11:51,601 [INFO    ] __main__: train step 15627: loss: 0.9806, policy_loss: 0.9159, value_loss: 0.5585
2024-07-11 17:11:51,800 [INFO    ] __main__: train step 15628: loss: 0.9806, policy_loss: 0.9158, value_loss: 0.5585
2024-07-11 17:11:52,001 [INFO    ] __main__: train step 15629: loss: 0.9806, policy_loss: 0.9158, value_loss: 0.5585
2024-07-11 17:11:52,211 [INFO    ] __main__: train step 15630: loss: 0.9806, policy_loss: 0.9158, value_loss: 0.5585
2024-07-11 17:11:52,416 [INFO    ] __main__: train step 15631: loss: 0.9806, policy_loss: 0.9158, value_loss: 0.5585
2024-07-11 17:11:52,636 [INFO    ] __main__: train step 15632: loss: 0.9805, policy_loss: 0.9158, value_loss: 0.5584
2024-07-11 17:11:52,834 [INFO    ] __main__: train step 15633: loss: 0.9805, policy_loss: 0.9157, value_loss: 0.5584
2024-07-11 17:11:53,029 [INFO    ] __main__: train step 15634: loss: 0.9805, policy_loss: 0.9157, value_loss: 0.5584
2024-07-11 17:11:53,243 [INFO    ] __main__: train step 15635: loss: 0.9805, policy_loss: 0.9157, value_loss: 0.5584
2024-07-11 17:11:53,458 [INFO    ] __main__: train step 15636: loss: 0.9805, policy_loss: 0.9157, value_loss: 0.5583
2024-07-11 17:11:53,671 [INFO    ] __main__: train step 15637: loss: 0.9805, policy_loss: 0.9156, value_loss: 0.5583
2024-07-11 17:11:53,894 [INFO    ] __main__: train step 15638: loss: 0.9805, policy_loss: 0.9156, value_loss: 0.5583
2024-07-11 17:11:54,097 [INFO    ] __main__: train step 15639: loss: 0.9805, policy_loss: 0.9156, value_loss: 0.5583
2024-07-11 17:11:55,506 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:11:55,917 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:11:55,972 [INFO    ] __main__: train step 15640: loss: 0.9804, policy_loss: 0.9156, value_loss: 0.5583
2024-07-11 17:11:56,142 [INFO    ] __main__: train step 15641: loss: 0.9804, policy_loss: 0.9155, value_loss: 0.5582
2024-07-11 17:11:56,346 [INFO    ] __main__: train step 15642: loss: 0.9804, policy_loss: 0.9155, value_loss: 0.5582
2024-07-11 17:11:56,538 [INFO    ] __main__: train step 15643: loss: 0.9804, policy_loss: 0.9155, value_loss: 0.5582
2024-07-11 17:11:56,755 [INFO    ] __main__: train step 15644: loss: 0.9804, policy_loss: 0.9155, value_loss: 0.5582
2024-07-11 17:11:56,953 [INFO    ] __main__: train step 15645: loss: 0.9804, policy_loss: 0.9155, value_loss: 0.5582
2024-07-11 17:11:57,161 [INFO    ] __main__: train step 15646: loss: 0.9804, policy_loss: 0.9154, value_loss: 0.5581
2024-07-11 17:11:57,355 [INFO    ] __main__: train step 15647: loss: 0.9804, policy_loss: 0.9154, value_loss: 0.5581
2024-07-11 17:11:57,567 [INFO    ] __main__: train step 15648: loss: 0.9804, policy_loss: 0.9154, value_loss: 0.5581
2024-07-11 17:11:57,772 [INFO    ] __main__: train step 15649: loss: 0.9803, policy_loss: 0.9154, value_loss: 0.5581
2024-07-11 17:11:57,968 [INFO    ] __main__: train step 15650: loss: 0.9803, policy_loss: 0.9153, value_loss: 0.5581
2024-07-11 17:11:58,170 [INFO    ] __main__: train step 15651: loss: 0.9803, policy_loss: 0.9153, value_loss: 0.5581
2024-07-11 17:11:58,376 [INFO    ] __main__: train step 15652: loss: 0.9803, policy_loss: 0.9153, value_loss: 0.5580
2024-07-11 17:11:58,579 [INFO    ] __main__: train step 15653: loss: 0.9803, policy_loss: 0.9153, value_loss: 0.5580
2024-07-11 17:11:58,777 [INFO    ] __main__: train step 15654: loss: 0.9803, policy_loss: 0.9153, value_loss: 0.5580
2024-07-11 17:11:58,990 [INFO    ] __main__: train step 15655: loss: 0.9803, policy_loss: 0.9152, value_loss: 0.5580
2024-07-11 17:11:59,188 [INFO    ] __main__: train step 15656: loss: 0.9803, policy_loss: 0.9152, value_loss: 0.5580
2024-07-11 17:12:00,640 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:12:01,072 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:12:01,127 [INFO    ] __main__: train step 15657: loss: 0.9803, policy_loss: 0.9152, value_loss: 0.5579
2024-07-11 17:12:01,302 [INFO    ] __main__: train step 15658: loss: 0.9802, policy_loss: 0.9152, value_loss: 0.5579
2024-07-11 17:12:01,550 [INFO    ] __main__: train step 15659: loss: 0.9802, policy_loss: 0.9151, value_loss: 0.5579
2024-07-11 17:12:01,772 [INFO    ] __main__: train step 15660: loss: 0.9802, policy_loss: 0.9151, value_loss: 0.5579
2024-07-11 17:12:02,006 [INFO    ] __main__: train step 15661: loss: 0.9802, policy_loss: 0.9151, value_loss: 0.5578
2024-07-11 17:12:02,205 [INFO    ] __main__: train step 15662: loss: 0.9802, policy_loss: 0.9151, value_loss: 0.5578
2024-07-11 17:12:02,416 [INFO    ] __main__: train step 15663: loss: 0.9802, policy_loss: 0.9150, value_loss: 0.5578
2024-07-11 17:12:02,621 [INFO    ] __main__: train step 15664: loss: 0.9802, policy_loss: 0.9150, value_loss: 0.5578
2024-07-11 17:12:02,831 [INFO    ] __main__: train step 15665: loss: 0.9802, policy_loss: 0.9150, value_loss: 0.5578
2024-07-11 17:12:03,047 [INFO    ] __main__: train step 15666: loss: 0.9802, policy_loss: 0.9150, value_loss: 0.5577
2024-07-11 17:12:03,282 [INFO    ] __main__: train step 15667: loss: 0.9801, policy_loss: 0.9150, value_loss: 0.5577
2024-07-11 17:12:03,483 [INFO    ] __main__: train step 15668: loss: 0.9801, policy_loss: 0.9149, value_loss: 0.5577
2024-07-11 17:12:03,681 [INFO    ] __main__: train step 15669: loss: 0.9801, policy_loss: 0.9149, value_loss: 0.5577
2024-07-11 17:12:03,889 [INFO    ] __main__: train step 15670: loss: 0.9801, policy_loss: 0.9149, value_loss: 0.5577
2024-07-11 17:12:04,099 [INFO    ] __main__: train step 15671: loss: 0.9801, policy_loss: 0.9149, value_loss: 0.5576
2024-07-11 17:12:04,332 [INFO    ] __main__: train step 15672: loss: 0.9801, policy_loss: 0.9148, value_loss: 0.5576
2024-07-11 17:12:06,278 [INFO    ] __main__: train step 15673: loss: 0.9801, policy_loss: 0.9148, value_loss: 0.5576
2024-07-11 17:12:07,728 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:12:08,151 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:12:08,207 [INFO    ] __main__: train step 15674: loss: 0.9801, policy_loss: 0.9148, value_loss: 0.5576
2024-07-11 17:12:08,389 [INFO    ] __main__: train step 15675: loss: 0.9800, policy_loss: 0.9148, value_loss: 0.5576
2024-07-11 17:12:08,629 [INFO    ] __main__: train step 15676: loss: 0.9800, policy_loss: 0.9147, value_loss: 0.5575
2024-07-11 17:12:08,838 [INFO    ] __main__: train step 15677: loss: 0.9800, policy_loss: 0.9147, value_loss: 0.5575
2024-07-11 17:12:09,051 [INFO    ] __main__: train step 15678: loss: 0.9800, policy_loss: 0.9147, value_loss: 0.5575
2024-07-11 17:12:09,263 [INFO    ] __main__: train step 15679: loss: 0.9800, policy_loss: 0.9147, value_loss: 0.5575
2024-07-11 17:12:09,458 [INFO    ] __main__: train step 15680: loss: 0.9800, policy_loss: 0.9147, value_loss: 0.5575
2024-07-11 17:12:09,662 [INFO    ] __main__: train step 15681: loss: 0.9800, policy_loss: 0.9146, value_loss: 0.5574
2024-07-11 17:12:09,864 [INFO    ] __main__: train step 15682: loss: 0.9800, policy_loss: 0.9146, value_loss: 0.5574
2024-07-11 17:12:10,082 [INFO    ] __main__: train step 15683: loss: 0.9800, policy_loss: 0.9146, value_loss: 0.5574
2024-07-11 17:12:10,275 [INFO    ] __main__: train step 15684: loss: 0.9799, policy_loss: 0.9146, value_loss: 0.5574
2024-07-11 17:12:10,474 [INFO    ] __main__: train step 15685: loss: 0.9799, policy_loss: 0.9145, value_loss: 0.5574
2024-07-11 17:12:10,679 [INFO    ] __main__: train step 15686: loss: 0.9799, policy_loss: 0.9145, value_loss: 0.5573
2024-07-11 17:12:10,892 [INFO    ] __main__: train step 15687: loss: 0.9799, policy_loss: 0.9145, value_loss: 0.5573
2024-07-11 17:12:11,099 [INFO    ] __main__: train step 15688: loss: 0.9799, policy_loss: 0.9145, value_loss: 0.5573
2024-07-11 17:12:11,304 [INFO    ] __main__: train step 15689: loss: 0.9799, policy_loss: 0.9144, value_loss: 0.5573
2024-07-11 17:12:11,540 [INFO    ] __main__: train step 15690: loss: 0.9799, policy_loss: 0.9144, value_loss: 0.5573
2024-07-11 17:12:12,985 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:12:13,422 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:12:13,489 [INFO    ] __main__: train step 15691: loss: 0.9799, policy_loss: 0.9144, value_loss: 0.5572
2024-07-11 17:12:13,654 [INFO    ] __main__: train step 15692: loss: 0.9798, policy_loss: 0.9144, value_loss: 0.5572
2024-07-11 17:12:13,888 [INFO    ] __main__: train step 15693: loss: 0.9798, policy_loss: 0.9144, value_loss: 0.5572
2024-07-11 17:12:14,104 [INFO    ] __main__: train step 15694: loss: 0.9798, policy_loss: 0.9143, value_loss: 0.5572
2024-07-11 17:12:14,338 [INFO    ] __main__: train step 15695: loss: 0.9798, policy_loss: 0.9143, value_loss: 0.5572
2024-07-11 17:12:14,551 [INFO    ] __main__: train step 15696: loss: 0.9798, policy_loss: 0.9143, value_loss: 0.5571
2024-07-11 17:12:14,761 [INFO    ] __main__: train step 15697: loss: 0.9798, policy_loss: 0.9143, value_loss: 0.5571
2024-07-11 17:12:14,971 [INFO    ] __main__: train step 15698: loss: 0.9798, policy_loss: 0.9142, value_loss: 0.5571
2024-07-11 17:12:15,187 [INFO    ] __main__: train step 15699: loss: 0.9798, policy_loss: 0.9142, value_loss: 0.5571
2024-07-11 17:12:15,397 [INFO    ] __main__: train step 15700: loss: 0.9798, policy_loss: 0.9142, value_loss: 0.5571
2024-07-11 17:12:15,608 [INFO    ] __main__: train step 15701: loss: 0.9797, policy_loss: 0.9142, value_loss: 0.5570
2024-07-11 17:12:15,801 [INFO    ] __main__: train step 15702: loss: 0.9797, policy_loss: 0.9142, value_loss: 0.5570
2024-07-11 17:12:16,001 [INFO    ] __main__: train step 15703: loss: 0.9797, policy_loss: 0.9141, value_loss: 0.5570
2024-07-11 17:12:16,200 [INFO    ] __main__: train step 15704: loss: 0.9797, policy_loss: 0.9141, value_loss: 0.5570
2024-07-11 17:12:16,405 [INFO    ] __main__: train step 15705: loss: 0.9797, policy_loss: 0.9141, value_loss: 0.5570
2024-07-11 17:12:16,608 [INFO    ] __main__: train step 15706: loss: 0.9797, policy_loss: 0.9141, value_loss: 0.5569
2024-07-11 17:12:16,807 [INFO    ] __main__: train step 15707: loss: 0.9797, policy_loss: 0.9140, value_loss: 0.5569
2024-07-11 17:12:18,178 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:12:18,572 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:12:18,626 [INFO    ] __main__: train step 15708: loss: 0.9797, policy_loss: 0.9140, value_loss: 0.5569
2024-07-11 17:12:18,806 [INFO    ] __main__: train step 15709: loss: 0.9797, policy_loss: 0.9140, value_loss: 0.5569
2024-07-11 17:12:19,009 [INFO    ] __main__: train step 15710: loss: 0.9796, policy_loss: 0.9140, value_loss: 0.5569
2024-07-11 17:12:19,221 [INFO    ] __main__: train step 15711: loss: 0.9796, policy_loss: 0.9139, value_loss: 0.5569
2024-07-11 17:12:19,432 [INFO    ] __main__: train step 15712: loss: 0.9796, policy_loss: 0.9139, value_loss: 0.5568
2024-07-11 17:12:19,645 [INFO    ] __main__: train step 15713: loss: 0.9796, policy_loss: 0.9139, value_loss: 0.5568
2024-07-11 17:12:19,846 [INFO    ] __main__: train step 15714: loss: 0.9796, policy_loss: 0.9139, value_loss: 0.5568
2024-07-11 17:12:20,056 [INFO    ] __main__: train step 15715: loss: 0.9796, policy_loss: 0.9138, value_loss: 0.5568
2024-07-11 17:12:20,264 [INFO    ] __main__: train step 15716: loss: 0.9796, policy_loss: 0.9138, value_loss: 0.5568
2024-07-11 17:12:20,471 [INFO    ] __main__: train step 15717: loss: 0.9796, policy_loss: 0.9138, value_loss: 0.5567
2024-07-11 17:12:20,678 [INFO    ] __main__: train step 15718: loss: 0.9795, policy_loss: 0.9138, value_loss: 0.5567
2024-07-11 17:12:20,877 [INFO    ] __main__: train step 15719: loss: 0.9795, policy_loss: 0.9138, value_loss: 0.5567
2024-07-11 17:12:21,085 [INFO    ] __main__: train step 15720: loss: 0.9795, policy_loss: 0.9137, value_loss: 0.5567
2024-07-11 17:12:21,299 [INFO    ] __main__: train step 15721: loss: 0.9795, policy_loss: 0.9137, value_loss: 0.5567
2024-07-11 17:12:21,499 [INFO    ] __main__: train step 15722: loss: 0.9795, policy_loss: 0.9137, value_loss: 0.5566
2024-07-11 17:12:21,695 [INFO    ] __main__: train step 15723: loss: 0.9795, policy_loss: 0.9137, value_loss: 0.5566
2024-07-11 17:12:21,910 [INFO    ] __main__: train step 15724: loss: 0.9795, policy_loss: 0.9136, value_loss: 0.5566
2024-07-11 17:12:23,327 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:12:23,774 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:12:23,840 [INFO    ] __main__: train step 15725: loss: 0.9795, policy_loss: 0.9136, value_loss: 0.5566
2024-07-11 17:12:24,017 [INFO    ] __main__: train step 15726: loss: 0.9795, policy_loss: 0.9136, value_loss: 0.5566
2024-07-11 17:12:24,244 [INFO    ] __main__: train step 15727: loss: 0.9794, policy_loss: 0.9136, value_loss: 0.5565
2024-07-11 17:12:24,459 [INFO    ] __main__: train step 15728: loss: 0.9794, policy_loss: 0.9135, value_loss: 0.5565
2024-07-11 17:12:24,657 [INFO    ] __main__: train step 15729: loss: 0.9794, policy_loss: 0.9135, value_loss: 0.5565
2024-07-11 17:12:24,855 [INFO    ] __main__: train step 15730: loss: 0.9794, policy_loss: 0.9135, value_loss: 0.5565
2024-07-11 17:12:25,067 [INFO    ] __main__: train step 15731: loss: 0.9794, policy_loss: 0.9135, value_loss: 0.5565
2024-07-11 17:12:25,269 [INFO    ] __main__: train step 15732: loss: 0.9794, policy_loss: 0.9134, value_loss: 0.5564
2024-07-11 17:12:25,469 [INFO    ] __main__: train step 15733: loss: 0.9794, policy_loss: 0.9134, value_loss: 0.5564
2024-07-11 17:12:25,671 [INFO    ] __main__: train step 15734: loss: 0.9794, policy_loss: 0.9134, value_loss: 0.5564
2024-07-11 17:12:25,883 [INFO    ] __main__: train step 15735: loss: 0.9794, policy_loss: 0.9134, value_loss: 0.5564
2024-07-11 17:12:26,124 [INFO    ] __main__: train step 15736: loss: 0.9793, policy_loss: 0.9134, value_loss: 0.5564
2024-07-11 17:12:26,328 [INFO    ] __main__: train step 15737: loss: 0.9793, policy_loss: 0.9133, value_loss: 0.5564
2024-07-11 17:12:26,541 [INFO    ] __main__: train step 15738: loss: 0.9793, policy_loss: 0.9133, value_loss: 0.5563
2024-07-11 17:12:26,771 [INFO    ] __main__: train step 15739: loss: 0.9793, policy_loss: 0.9133, value_loss: 0.5563
2024-07-11 17:12:26,978 [INFO    ] __main__: train step 15740: loss: 0.9793, policy_loss: 0.9133, value_loss: 0.5563
2024-07-11 17:12:27,195 [INFO    ] __main__: train step 15741: loss: 0.9793, policy_loss: 0.9132, value_loss: 0.5563
2024-07-11 17:12:28,563 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:12:28,990 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:12:29,054 [INFO    ] __main__: train step 15742: loss: 0.9793, policy_loss: 0.9132, value_loss: 0.5563
2024-07-11 17:12:29,226 [INFO    ] __main__: train step 15743: loss: 0.9793, policy_loss: 0.9132, value_loss: 0.5562
2024-07-11 17:12:29,446 [INFO    ] __main__: train step 15744: loss: 0.9793, policy_loss: 0.9132, value_loss: 0.5562
2024-07-11 17:12:29,655 [INFO    ] __main__: train step 15745: loss: 0.9792, policy_loss: 0.9131, value_loss: 0.5562
2024-07-11 17:12:29,854 [INFO    ] __main__: train step 15746: loss: 0.9792, policy_loss: 0.9131, value_loss: 0.5562
2024-07-11 17:12:30,067 [INFO    ] __main__: train step 15747: loss: 0.9792, policy_loss: 0.9131, value_loss: 0.5562
2024-07-11 17:12:30,266 [INFO    ] __main__: train step 15748: loss: 0.9792, policy_loss: 0.9131, value_loss: 0.5561
2024-07-11 17:12:30,466 [INFO    ] __main__: train step 15749: loss: 0.9792, policy_loss: 0.9131, value_loss: 0.5561
2024-07-11 17:12:30,670 [INFO    ] __main__: train step 15750: loss: 0.9792, policy_loss: 0.9130, value_loss: 0.5561
2024-07-11 17:12:30,874 [INFO    ] __main__: train step 15751: loss: 0.9792, policy_loss: 0.9130, value_loss: 0.5561
2024-07-11 17:12:31,073 [INFO    ] __main__: train step 15752: loss: 0.9792, policy_loss: 0.9130, value_loss: 0.5561
2024-07-11 17:12:31,280 [INFO    ] __main__: train step 15753: loss: 0.9791, policy_loss: 0.9130, value_loss: 0.5560
2024-07-11 17:12:31,486 [INFO    ] __main__: train step 15754: loss: 0.9791, policy_loss: 0.9129, value_loss: 0.5560
2024-07-11 17:12:31,685 [INFO    ] __main__: train step 15755: loss: 0.9791, policy_loss: 0.9129, value_loss: 0.5560
2024-07-11 17:12:31,893 [INFO    ] __main__: train step 15756: loss: 0.9791, policy_loss: 0.9129, value_loss: 0.5560
2024-07-11 17:12:32,092 [INFO    ] __main__: train step 15757: loss: 0.9791, policy_loss: 0.9129, value_loss: 0.5560
2024-07-11 17:12:32,298 [INFO    ] __main__: train step 15758: loss: 0.9791, policy_loss: 0.9128, value_loss: 0.5559
2024-07-11 17:12:33,687 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:12:34,104 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:12:34,170 [INFO    ] __main__: train step 15759: loss: 0.9791, policy_loss: 0.9128, value_loss: 0.5559
2024-07-11 17:12:34,349 [INFO    ] __main__: train step 15760: loss: 0.9791, policy_loss: 0.9128, value_loss: 0.5559
2024-07-11 17:12:34,562 [INFO    ] __main__: train step 15761: loss: 0.9791, policy_loss: 0.9128, value_loss: 0.5559
2024-07-11 17:12:34,756 [INFO    ] __main__: train step 15762: loss: 0.9790, policy_loss: 0.9127, value_loss: 0.5559
2024-07-11 17:12:34,961 [INFO    ] __main__: train step 15763: loss: 0.9790, policy_loss: 0.9127, value_loss: 0.5559
2024-07-11 17:12:35,161 [INFO    ] __main__: train step 15764: loss: 0.9790, policy_loss: 0.9127, value_loss: 0.5558
2024-07-11 17:12:35,366 [INFO    ] __main__: train step 15765: loss: 0.9790, policy_loss: 0.9127, value_loss: 0.5558
2024-07-11 17:12:35,576 [INFO    ] __main__: train step 15766: loss: 0.9790, policy_loss: 0.9127, value_loss: 0.5558
2024-07-11 17:12:35,784 [INFO    ] __main__: train step 15767: loss: 0.9790, policy_loss: 0.9126, value_loss: 0.5558
2024-07-11 17:12:35,988 [INFO    ] __main__: train step 15768: loss: 0.9790, policy_loss: 0.9126, value_loss: 0.5558
2024-07-11 17:12:36,203 [INFO    ] __main__: train step 15769: loss: 0.9790, policy_loss: 0.9126, value_loss: 0.5557
2024-07-11 17:12:36,405 [INFO    ] __main__: train step 15770: loss: 0.9790, policy_loss: 0.9126, value_loss: 0.5557
2024-07-11 17:12:36,602 [INFO    ] __main__: train step 15771: loss: 0.9789, policy_loss: 0.9125, value_loss: 0.5557
2024-07-11 17:12:36,812 [INFO    ] __main__: train step 15772: loss: 0.9789, policy_loss: 0.9125, value_loss: 0.5557
2024-07-11 17:12:37,005 [INFO    ] __main__: train step 15773: loss: 0.9789, policy_loss: 0.9125, value_loss: 0.5557
2024-07-11 17:12:37,213 [INFO    ] __main__: train step 15774: loss: 0.9789, policy_loss: 0.9125, value_loss: 0.5556
2024-07-11 17:12:37,410 [INFO    ] __main__: train step 15775: loss: 0.9789, policy_loss: 0.9124, value_loss: 0.5556
2024-07-11 17:12:38,818 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:12:39,249 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:12:39,310 [INFO    ] __main__: train step 15776: loss: 0.9789, policy_loss: 0.9124, value_loss: 0.5556
2024-07-11 17:12:39,482 [INFO    ] __main__: train step 15777: loss: 0.9789, policy_loss: 0.9124, value_loss: 0.5556
2024-07-11 17:12:39,687 [INFO    ] __main__: train step 15778: loss: 0.9789, policy_loss: 0.9124, value_loss: 0.5556
2024-07-11 17:12:39,895 [INFO    ] __main__: train step 15779: loss: 0.9788, policy_loss: 0.9123, value_loss: 0.5555
2024-07-11 17:12:40,096 [INFO    ] __main__: train step 15780: loss: 0.9788, policy_loss: 0.9123, value_loss: 0.5555
2024-07-11 17:12:40,304 [INFO    ] __main__: train step 15781: loss: 0.9788, policy_loss: 0.9123, value_loss: 0.5555
2024-07-11 17:12:40,523 [INFO    ] __main__: train step 15782: loss: 0.9788, policy_loss: 0.9123, value_loss: 0.5555
2024-07-11 17:12:40,725 [INFO    ] __main__: train step 15783: loss: 0.9788, policy_loss: 0.9122, value_loss: 0.5555
2024-07-11 17:12:40,924 [INFO    ] __main__: train step 15784: loss: 0.9788, policy_loss: 0.9122, value_loss: 0.5555
2024-07-11 17:12:41,133 [INFO    ] __main__: train step 15785: loss: 0.9788, policy_loss: 0.9122, value_loss: 0.5554
2024-07-11 17:12:41,353 [INFO    ] __main__: train step 15786: loss: 0.9788, policy_loss: 0.9122, value_loss: 0.5554
2024-07-11 17:12:41,563 [INFO    ] __main__: train step 15787: loss: 0.9788, policy_loss: 0.9122, value_loss: 0.5554
2024-07-11 17:12:41,806 [INFO    ] __main__: train step 15788: loss: 0.9787, policy_loss: 0.9121, value_loss: 0.5554
2024-07-11 17:12:42,032 [INFO    ] __main__: train step 15789: loss: 0.9787, policy_loss: 0.9121, value_loss: 0.5554
2024-07-11 17:12:44,002 [INFO    ] __main__: train step 15790: loss: 0.9787, policy_loss: 0.9121, value_loss: 0.5553
2024-07-11 17:12:44,205 [INFO    ] __main__: train step 15791: loss: 0.9787, policy_loss: 0.9121, value_loss: 0.5553
2024-07-11 17:12:44,417 [INFO    ] __main__: train step 15792: loss: 0.9787, policy_loss: 0.9120, value_loss: 0.5553
2024-07-11 17:12:45,811 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:12:46,240 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:12:46,301 [INFO    ] __main__: train step 15793: loss: 0.9787, policy_loss: 0.9120, value_loss: 0.5553
2024-07-11 17:12:46,474 [INFO    ] __main__: train step 15794: loss: 0.9787, policy_loss: 0.9120, value_loss: 0.5553
2024-07-11 17:12:46,672 [INFO    ] __main__: train step 15795: loss: 0.9787, policy_loss: 0.9120, value_loss: 0.5552
2024-07-11 17:12:46,875 [INFO    ] __main__: train step 15796: loss: 0.9787, policy_loss: 0.9119, value_loss: 0.5552
2024-07-11 17:12:47,080 [INFO    ] __main__: train step 15797: loss: 0.9786, policy_loss: 0.9119, value_loss: 0.5552
2024-07-11 17:12:47,278 [INFO    ] __main__: train step 15798: loss: 0.9786, policy_loss: 0.9119, value_loss: 0.5552
2024-07-11 17:12:47,471 [INFO    ] __main__: train step 15799: loss: 0.9786, policy_loss: 0.9119, value_loss: 0.5552
2024-07-11 17:12:47,695 [INFO    ] __main__: train step 15800: loss: 0.9786, policy_loss: 0.9119, value_loss: 0.5551
2024-07-11 17:12:47,931 [INFO    ] __main__: train step 15801: loss: 0.9786, policy_loss: 0.9118, value_loss: 0.5551
2024-07-11 17:12:48,140 [INFO    ] __main__: train step 15802: loss: 0.9786, policy_loss: 0.9118, value_loss: 0.5551
2024-07-11 17:12:48,371 [INFO    ] __main__: train step 15803: loss: 0.9786, policy_loss: 0.9118, value_loss: 0.5551
2024-07-11 17:12:48,603 [INFO    ] __main__: train step 15804: loss: 0.9786, policy_loss: 0.9118, value_loss: 0.5551
2024-07-11 17:12:48,801 [INFO    ] __main__: train step 15805: loss: 0.9785, policy_loss: 0.9117, value_loss: 0.5551
2024-07-11 17:12:49,003 [INFO    ] __main__: train step 15806: loss: 0.9785, policy_loss: 0.9117, value_loss: 0.5550
2024-07-11 17:12:49,203 [INFO    ] __main__: train step 15807: loss: 0.9785, policy_loss: 0.9117, value_loss: 0.5550
2024-07-11 17:12:49,408 [INFO    ] __main__: train step 15808: loss: 0.9785, policy_loss: 0.9117, value_loss: 0.5550
2024-07-11 17:12:49,600 [INFO    ] __main__: train step 15809: loss: 0.9785, policy_loss: 0.9116, value_loss: 0.5550
2024-07-11 17:12:51,025 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:12:51,445 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:12:51,509 [INFO    ] __main__: train step 15810: loss: 0.9785, policy_loss: 0.9116, value_loss: 0.5550
2024-07-11 17:12:51,695 [INFO    ] __main__: train step 15811: loss: 0.9785, policy_loss: 0.9116, value_loss: 0.5549
2024-07-11 17:12:51,896 [INFO    ] __main__: train step 15812: loss: 0.9785, policy_loss: 0.9116, value_loss: 0.5549
2024-07-11 17:12:52,091 [INFO    ] __main__: train step 15813: loss: 0.9785, policy_loss: 0.9115, value_loss: 0.5549
2024-07-11 17:12:52,298 [INFO    ] __main__: train step 15814: loss: 0.9784, policy_loss: 0.9115, value_loss: 0.5549
2024-07-11 17:12:52,489 [INFO    ] __main__: train step 15815: loss: 0.9784, policy_loss: 0.9115, value_loss: 0.5549
2024-07-11 17:12:52,699 [INFO    ] __main__: train step 15816: loss: 0.9784, policy_loss: 0.9115, value_loss: 0.5548
2024-07-11 17:12:52,907 [INFO    ] __main__: train step 15817: loss: 0.9784, policy_loss: 0.9115, value_loss: 0.5548
2024-07-11 17:12:53,110 [INFO    ] __main__: train step 15818: loss: 0.9784, policy_loss: 0.9114, value_loss: 0.5548
2024-07-11 17:12:53,326 [INFO    ] __main__: train step 15819: loss: 0.9784, policy_loss: 0.9114, value_loss: 0.5548
2024-07-11 17:12:53,523 [INFO    ] __main__: train step 15820: loss: 0.9784, policy_loss: 0.9114, value_loss: 0.5548
2024-07-11 17:12:53,734 [INFO    ] __main__: train step 15821: loss: 0.9784, policy_loss: 0.9114, value_loss: 0.5548
2024-07-11 17:12:53,964 [INFO    ] __main__: train step 15822: loss: 0.9783, policy_loss: 0.9113, value_loss: 0.5547
2024-07-11 17:12:54,183 [INFO    ] __main__: train step 15823: loss: 0.9783, policy_loss: 0.9113, value_loss: 0.5547
2024-07-11 17:12:54,384 [INFO    ] __main__: train step 15824: loss: 0.9783, policy_loss: 0.9113, value_loss: 0.5547
2024-07-11 17:12:54,576 [INFO    ] __main__: train step 15825: loss: 0.9783, policy_loss: 0.9113, value_loss: 0.5547
2024-07-11 17:12:54,774 [INFO    ] __main__: train step 15826: loss: 0.9783, policy_loss: 0.9112, value_loss: 0.5547
2024-07-11 17:12:56,164 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:12:56,566 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:12:56,626 [INFO    ] __main__: train step 15827: loss: 0.9783, policy_loss: 0.9112, value_loss: 0.5546
2024-07-11 17:12:56,807 [INFO    ] __main__: train step 15828: loss: 0.9783, policy_loss: 0.9112, value_loss: 0.5546
2024-07-11 17:12:57,005 [INFO    ] __main__: train step 15829: loss: 0.9783, policy_loss: 0.9112, value_loss: 0.5546
2024-07-11 17:12:57,211 [INFO    ] __main__: train step 15830: loss: 0.9783, policy_loss: 0.9111, value_loss: 0.5546
2024-07-11 17:12:57,446 [INFO    ] __main__: train step 15831: loss: 0.9782, policy_loss: 0.9111, value_loss: 0.5546
2024-07-11 17:12:57,649 [INFO    ] __main__: train step 15832: loss: 0.9782, policy_loss: 0.9111, value_loss: 0.5545
2024-07-11 17:12:57,860 [INFO    ] __main__: train step 15833: loss: 0.9782, policy_loss: 0.9111, value_loss: 0.5545
2024-07-11 17:12:58,071 [INFO    ] __main__: train step 15834: loss: 0.9782, policy_loss: 0.9110, value_loss: 0.5545
2024-07-11 17:12:58,270 [INFO    ] __main__: train step 15835: loss: 0.9782, policy_loss: 0.9110, value_loss: 0.5545
2024-07-11 17:12:58,478 [INFO    ] __main__: train step 15836: loss: 0.9782, policy_loss: 0.9110, value_loss: 0.5545
2024-07-11 17:12:58,679 [INFO    ] __main__: train step 15837: loss: 0.9782, policy_loss: 0.9110, value_loss: 0.5544
2024-07-11 17:12:58,878 [INFO    ] __main__: train step 15838: loss: 0.9782, policy_loss: 0.9110, value_loss: 0.5544
2024-07-11 17:12:59,086 [INFO    ] __main__: train step 15839: loss: 0.9781, policy_loss: 0.9109, value_loss: 0.5544
2024-07-11 17:12:59,315 [INFO    ] __main__: train step 15840: loss: 0.9781, policy_loss: 0.9109, value_loss: 0.5544
2024-07-11 17:12:59,521 [INFO    ] __main__: train step 15841: loss: 0.9781, policy_loss: 0.9109, value_loss: 0.5544
2024-07-11 17:12:59,730 [INFO    ] __main__: train step 15842: loss: 0.9781, policy_loss: 0.9109, value_loss: 0.5544
2024-07-11 17:12:59,940 [INFO    ] __main__: train step 15843: loss: 0.9781, policy_loss: 0.9108, value_loss: 0.5543
2024-07-11 17:13:01,353 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:13:01,763 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:13:01,821 [INFO    ] __main__: train step 15844: loss: 0.9781, policy_loss: 0.9108, value_loss: 0.5543
2024-07-11 17:13:01,998 [INFO    ] __main__: train step 15845: loss: 0.9781, policy_loss: 0.9108, value_loss: 0.5543
2024-07-11 17:13:02,200 [INFO    ] __main__: train step 15846: loss: 0.9781, policy_loss: 0.9108, value_loss: 0.5543
2024-07-11 17:13:02,410 [INFO    ] __main__: train step 15847: loss: 0.9781, policy_loss: 0.9107, value_loss: 0.5543
2024-07-11 17:13:02,615 [INFO    ] __main__: train step 15848: loss: 0.9780, policy_loss: 0.9107, value_loss: 0.5542
2024-07-11 17:13:02,863 [INFO    ] __main__: train step 15849: loss: 0.9780, policy_loss: 0.9107, value_loss: 0.5542
2024-07-11 17:13:03,109 [INFO    ] __main__: train step 15850: loss: 0.9780, policy_loss: 0.9107, value_loss: 0.5542
2024-07-11 17:13:03,339 [INFO    ] __main__: train step 15851: loss: 0.9780, policy_loss: 0.9106, value_loss: 0.5542
2024-07-11 17:13:03,541 [INFO    ] __main__: train step 15852: loss: 0.9780, policy_loss: 0.9106, value_loss: 0.5542
2024-07-11 17:13:03,740 [INFO    ] __main__: train step 15853: loss: 0.9780, policy_loss: 0.9106, value_loss: 0.5541
2024-07-11 17:13:03,952 [INFO    ] __main__: train step 15854: loss: 0.9780, policy_loss: 0.9106, value_loss: 0.5541
2024-07-11 17:13:04,155 [INFO    ] __main__: train step 15855: loss: 0.9780, policy_loss: 0.9106, value_loss: 0.5541
2024-07-11 17:13:04,350 [INFO    ] __main__: train step 15856: loss: 0.9779, policy_loss: 0.9105, value_loss: 0.5541
2024-07-11 17:13:04,549 [INFO    ] __main__: train step 15857: loss: 0.9779, policy_loss: 0.9105, value_loss: 0.5541
2024-07-11 17:13:04,756 [INFO    ] __main__: train step 15858: loss: 0.9779, policy_loss: 0.9105, value_loss: 0.5540
2024-07-11 17:13:04,953 [INFO    ] __main__: train step 15859: loss: 0.9779, policy_loss: 0.9105, value_loss: 0.5540
2024-07-11 17:13:05,155 [INFO    ] __main__: train step 15860: loss: 0.9779, policy_loss: 0.9104, value_loss: 0.5540
2024-07-11 17:13:06,589 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:13:06,965 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:13:07,022 [INFO    ] __main__: train step 15861: loss: 0.9779, policy_loss: 0.9104, value_loss: 0.5540
2024-07-11 17:13:07,204 [INFO    ] __main__: train step 15862: loss: 0.9779, policy_loss: 0.9104, value_loss: 0.5540
2024-07-11 17:13:07,399 [INFO    ] __main__: train step 15863: loss: 0.9779, policy_loss: 0.9104, value_loss: 0.5540
2024-07-11 17:13:07,591 [INFO    ] __main__: train step 15864: loss: 0.9778, policy_loss: 0.9103, value_loss: 0.5539
2024-07-11 17:13:07,794 [INFO    ] __main__: train step 15865: loss: 0.9778, policy_loss: 0.9103, value_loss: 0.5539
2024-07-11 17:13:07,992 [INFO    ] __main__: train step 15866: loss: 0.9778, policy_loss: 0.9103, value_loss: 0.5539
2024-07-11 17:13:08,186 [INFO    ] __main__: train step 15867: loss: 0.9778, policy_loss: 0.9103, value_loss: 0.5539
2024-07-11 17:13:08,406 [INFO    ] __main__: train step 15868: loss: 0.9778, policy_loss: 0.9102, value_loss: 0.5539
2024-07-11 17:13:08,639 [INFO    ] __main__: train step 15869: loss: 0.9778, policy_loss: 0.9102, value_loss: 0.5538
2024-07-11 17:13:08,848 [INFO    ] __main__: train step 15870: loss: 0.9778, policy_loss: 0.9102, value_loss: 0.5538
2024-07-11 17:13:09,075 [INFO    ] __main__: train step 15871: loss: 0.9778, policy_loss: 0.9102, value_loss: 0.5538
2024-07-11 17:13:09,280 [INFO    ] __main__: train step 15872: loss: 0.9778, policy_loss: 0.9102, value_loss: 0.5538
2024-07-11 17:13:09,479 [INFO    ] __main__: train step 15873: loss: 0.9777, policy_loss: 0.9101, value_loss: 0.5538
2024-07-11 17:13:09,674 [INFO    ] __main__: train step 15874: loss: 0.9777, policy_loss: 0.9101, value_loss: 0.5537
2024-07-11 17:13:09,878 [INFO    ] __main__: train step 15875: loss: 0.9777, policy_loss: 0.9101, value_loss: 0.5537
2024-07-11 17:13:10,074 [INFO    ] __main__: train step 15876: loss: 0.9777, policy_loss: 0.9101, value_loss: 0.5537
2024-07-11 17:13:10,278 [INFO    ] __main__: train step 15877: loss: 0.9777, policy_loss: 0.9100, value_loss: 0.5537
2024-07-11 17:13:11,720 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:13:12,094 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:13:12,149 [INFO    ] __main__: train step 15878: loss: 0.9777, policy_loss: 0.9100, value_loss: 0.5537
2024-07-11 17:13:12,330 [INFO    ] __main__: train step 15879: loss: 0.9777, policy_loss: 0.9100, value_loss: 0.5537
2024-07-11 17:13:12,533 [INFO    ] __main__: train step 15880: loss: 0.9777, policy_loss: 0.9100, value_loss: 0.5536
2024-07-11 17:13:12,754 [INFO    ] __main__: train step 15881: loss: 0.9776, policy_loss: 0.9099, value_loss: 0.5536
2024-07-11 17:13:12,952 [INFO    ] __main__: train step 15882: loss: 0.9776, policy_loss: 0.9099, value_loss: 0.5536
2024-07-11 17:13:13,158 [INFO    ] __main__: train step 15883: loss: 0.9776, policy_loss: 0.9099, value_loss: 0.5536
2024-07-11 17:13:13,357 [INFO    ] __main__: train step 15884: loss: 0.9776, policy_loss: 0.9099, value_loss: 0.5536
2024-07-11 17:13:13,563 [INFO    ] __main__: train step 15885: loss: 0.9776, policy_loss: 0.9098, value_loss: 0.5535
2024-07-11 17:13:13,764 [INFO    ] __main__: train step 15886: loss: 0.9776, policy_loss: 0.9098, value_loss: 0.5535
2024-07-11 17:13:13,958 [INFO    ] __main__: train step 15887: loss: 0.9776, policy_loss: 0.9098, value_loss: 0.5535
2024-07-11 17:13:14,169 [INFO    ] __main__: train step 15888: loss: 0.9776, policy_loss: 0.9098, value_loss: 0.5535
2024-07-11 17:13:14,363 [INFO    ] __main__: train step 15889: loss: 0.9776, policy_loss: 0.9097, value_loss: 0.5535
2024-07-11 17:13:14,578 [INFO    ] __main__: train step 15890: loss: 0.9775, policy_loss: 0.9097, value_loss: 0.5534
2024-07-11 17:13:14,807 [INFO    ] __main__: train step 15891: loss: 0.9775, policy_loss: 0.9097, value_loss: 0.5534
2024-07-11 17:13:15,004 [INFO    ] __main__: train step 15892: loss: 0.9775, policy_loss: 0.9097, value_loss: 0.5534
2024-07-11 17:13:15,204 [INFO    ] __main__: train step 15893: loss: 0.9775, policy_loss: 0.9097, value_loss: 0.5534
2024-07-11 17:13:15,419 [INFO    ] __main__: train step 15894: loss: 0.9775, policy_loss: 0.9096, value_loss: 0.5534
2024-07-11 17:13:16,802 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:13:17,173 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:13:17,229 [INFO    ] __main__: train step 15895: loss: 0.9775, policy_loss: 0.9096, value_loss: 0.5533
2024-07-11 17:13:17,409 [INFO    ] __main__: train step 15896: loss: 0.9775, policy_loss: 0.9096, value_loss: 0.5533
2024-07-11 17:13:17,606 [INFO    ] __main__: train step 15897: loss: 0.9775, policy_loss: 0.9096, value_loss: 0.5533
2024-07-11 17:13:17,827 [INFO    ] __main__: train step 15898: loss: 0.9774, policy_loss: 0.9095, value_loss: 0.5533
2024-07-11 17:13:18,039 [INFO    ] __main__: train step 15899: loss: 0.9774, policy_loss: 0.9095, value_loss: 0.5533
2024-07-11 17:13:18,267 [INFO    ] __main__: train step 15900: loss: 0.9774, policy_loss: 0.9095, value_loss: 0.5533
2024-07-11 17:13:18,476 [INFO    ] __main__: train step 15901: loss: 0.9774, policy_loss: 0.9095, value_loss: 0.5532
2024-07-11 17:13:18,685 [INFO    ] __main__: train step 15902: loss: 0.9774, policy_loss: 0.9094, value_loss: 0.5532
2024-07-11 17:13:18,886 [INFO    ] __main__: train step 15903: loss: 0.9774, policy_loss: 0.9094, value_loss: 0.5532
2024-07-11 17:13:19,088 [INFO    ] __main__: train step 15904: loss: 0.9774, policy_loss: 0.9094, value_loss: 0.5532
2024-07-11 17:13:19,298 [INFO    ] __main__: train step 15905: loss: 0.9774, policy_loss: 0.9094, value_loss: 0.5532
2024-07-11 17:13:21,272 [INFO    ] __main__: train step 15906: loss: 0.9773, policy_loss: 0.9094, value_loss: 0.5531
2024-07-11 17:13:21,467 [INFO    ] __main__: train step 15907: loss: 0.9773, policy_loss: 0.9093, value_loss: 0.5531
2024-07-11 17:13:21,666 [INFO    ] __main__: train step 15908: loss: 0.9773, policy_loss: 0.9093, value_loss: 0.5531
2024-07-11 17:13:21,869 [INFO    ] __main__: train step 15909: loss: 0.9773, policy_loss: 0.9093, value_loss: 0.5531
2024-07-11 17:13:22,076 [INFO    ] __main__: train step 15910: loss: 0.9773, policy_loss: 0.9093, value_loss: 0.5531
2024-07-11 17:13:22,280 [INFO    ] __main__: train step 15911: loss: 0.9773, policy_loss: 0.9092, value_loss: 0.5530
2024-07-11 17:13:23,700 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:13:24,069 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:13:24,126 [INFO    ] __main__: train step 15912: loss: 0.9773, policy_loss: 0.9092, value_loss: 0.5530
2024-07-11 17:13:24,309 [INFO    ] __main__: train step 15913: loss: 0.9773, policy_loss: 0.9092, value_loss: 0.5530
2024-07-11 17:13:24,534 [INFO    ] __main__: train step 15914: loss: 0.9773, policy_loss: 0.9092, value_loss: 0.5530
2024-07-11 17:13:24,741 [INFO    ] __main__: train step 15915: loss: 0.9772, policy_loss: 0.9091, value_loss: 0.5530
2024-07-11 17:13:24,940 [INFO    ] __main__: train step 15916: loss: 0.9772, policy_loss: 0.9091, value_loss: 0.5529
2024-07-11 17:13:25,149 [INFO    ] __main__: train step 15917: loss: 0.9772, policy_loss: 0.9091, value_loss: 0.5529
2024-07-11 17:13:25,349 [INFO    ] __main__: train step 15918: loss: 0.9772, policy_loss: 0.9091, value_loss: 0.5529
2024-07-11 17:13:25,553 [INFO    ] __main__: train step 15919: loss: 0.9772, policy_loss: 0.9090, value_loss: 0.5529
2024-07-11 17:13:25,748 [INFO    ] __main__: train step 15920: loss: 0.9772, policy_loss: 0.9090, value_loss: 0.5529
2024-07-11 17:13:25,955 [INFO    ] __main__: train step 15921: loss: 0.9772, policy_loss: 0.9090, value_loss: 0.5529
2024-07-11 17:13:26,161 [INFO    ] __main__: train step 15922: loss: 0.9772, policy_loss: 0.9090, value_loss: 0.5528
2024-07-11 17:13:26,383 [INFO    ] __main__: train step 15923: loss: 0.9771, policy_loss: 0.9090, value_loss: 0.5528
2024-07-11 17:13:26,619 [INFO    ] __main__: train step 15924: loss: 0.9771, policy_loss: 0.9089, value_loss: 0.5528
2024-07-11 17:13:26,834 [INFO    ] __main__: train step 15925: loss: 0.9771, policy_loss: 0.9089, value_loss: 0.5528
2024-07-11 17:13:27,071 [INFO    ] __main__: train step 15926: loss: 0.9771, policy_loss: 0.9089, value_loss: 0.5528
2024-07-11 17:13:27,289 [INFO    ] __main__: train step 15927: loss: 0.9771, policy_loss: 0.9089, value_loss: 0.5527
2024-07-11 17:13:27,488 [INFO    ] __main__: train step 15928: loss: 0.9771, policy_loss: 0.9088, value_loss: 0.5527
2024-07-11 17:13:28,855 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:13:29,239 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:13:29,294 [INFO    ] __main__: train step 15929: loss: 0.9771, policy_loss: 0.9088, value_loss: 0.5527
2024-07-11 17:13:29,477 [INFO    ] __main__: train step 15930: loss: 0.9771, policy_loss: 0.9088, value_loss: 0.5527
2024-07-11 17:13:29,696 [INFO    ] __main__: train step 15931: loss: 0.9770, policy_loss: 0.9088, value_loss: 0.5527
2024-07-11 17:13:29,931 [INFO    ] __main__: train step 15932: loss: 0.9770, policy_loss: 0.9087, value_loss: 0.5526
2024-07-11 17:13:30,138 [INFO    ] __main__: train step 15933: loss: 0.9770, policy_loss: 0.9087, value_loss: 0.5526
2024-07-11 17:13:30,341 [INFO    ] __main__: train step 15934: loss: 0.9770, policy_loss: 0.9087, value_loss: 0.5526
2024-07-11 17:13:30,543 [INFO    ] __main__: train step 15935: loss: 0.9770, policy_loss: 0.9087, value_loss: 0.5526
2024-07-11 17:13:30,741 [INFO    ] __main__: train step 15936: loss: 0.9770, policy_loss: 0.9086, value_loss: 0.5526
2024-07-11 17:13:30,937 [INFO    ] __main__: train step 15937: loss: 0.9770, policy_loss: 0.9086, value_loss: 0.5525
2024-07-11 17:13:31,137 [INFO    ] __main__: train step 15938: loss: 0.9770, policy_loss: 0.9086, value_loss: 0.5525
2024-07-11 17:13:31,340 [INFO    ] __main__: train step 15939: loss: 0.9769, policy_loss: 0.9086, value_loss: 0.5525
2024-07-11 17:13:31,543 [INFO    ] __main__: train step 15940: loss: 0.9769, policy_loss: 0.9086, value_loss: 0.5525
2024-07-11 17:13:31,753 [INFO    ] __main__: train step 15941: loss: 0.9769, policy_loss: 0.9085, value_loss: 0.5525
2024-07-11 17:13:31,956 [INFO    ] __main__: train step 15942: loss: 0.9769, policy_loss: 0.9085, value_loss: 0.5525
2024-07-11 17:13:32,148 [INFO    ] __main__: train step 15943: loss: 0.9769, policy_loss: 0.9085, value_loss: 0.5524
2024-07-11 17:13:32,359 [INFO    ] __main__: train step 15944: loss: 0.9769, policy_loss: 0.9085, value_loss: 0.5524
2024-07-11 17:13:32,561 [INFO    ] __main__: train step 15945: loss: 0.9769, policy_loss: 0.9084, value_loss: 0.5524
2024-07-11 17:13:33,969 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:13:34,347 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:13:34,401 [INFO    ] __main__: train step 15946: loss: 0.9769, policy_loss: 0.9084, value_loss: 0.5524
2024-07-11 17:13:34,575 [INFO    ] __main__: train step 15947: loss: 0.9768, policy_loss: 0.9084, value_loss: 0.5524
2024-07-11 17:13:34,785 [INFO    ] __main__: train step 15948: loss: 0.9768, policy_loss: 0.9084, value_loss: 0.5523
2024-07-11 17:13:34,997 [INFO    ] __main__: train step 15949: loss: 0.9768, policy_loss: 0.9083, value_loss: 0.5523
2024-07-11 17:13:35,207 [INFO    ] __main__: train step 15950: loss: 0.9768, policy_loss: 0.9083, value_loss: 0.5523
2024-07-11 17:13:35,414 [INFO    ] __main__: train step 15951: loss: 0.9768, policy_loss: 0.9083, value_loss: 0.5523
2024-07-11 17:13:35,628 [INFO    ] __main__: train step 15952: loss: 0.9768, policy_loss: 0.9083, value_loss: 0.5523
2024-07-11 17:13:35,826 [INFO    ] __main__: train step 15953: loss: 0.9768, policy_loss: 0.9083, value_loss: 0.5522
2024-07-11 17:13:36,029 [INFO    ] __main__: train step 15954: loss: 0.9768, policy_loss: 0.9082, value_loss: 0.5522
2024-07-11 17:13:36,228 [INFO    ] __main__: train step 15955: loss: 0.9768, policy_loss: 0.9082, value_loss: 0.5522
2024-07-11 17:13:36,426 [INFO    ] __main__: train step 15956: loss: 0.9767, policy_loss: 0.9082, value_loss: 0.5522
2024-07-11 17:13:36,630 [INFO    ] __main__: train step 15957: loss: 0.9767, policy_loss: 0.9082, value_loss: 0.5522
2024-07-11 17:13:36,829 [INFO    ] __main__: train step 15958: loss: 0.9767, policy_loss: 0.9081, value_loss: 0.5521
2024-07-11 17:13:37,040 [INFO    ] __main__: train step 15959: loss: 0.9767, policy_loss: 0.9081, value_loss: 0.5521
2024-07-11 17:13:37,241 [INFO    ] __main__: train step 15960: loss: 0.9767, policy_loss: 0.9081, value_loss: 0.5521
2024-07-11 17:13:37,439 [INFO    ] __main__: train step 15961: loss: 0.9767, policy_loss: 0.9081, value_loss: 0.5521
2024-07-11 17:13:37,649 [INFO    ] __main__: train step 15962: loss: 0.9767, policy_loss: 0.9080, value_loss: 0.5521
2024-07-11 17:13:39,057 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:13:39,467 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:13:39,531 [INFO    ] __main__: train step 15963: loss: 0.9767, policy_loss: 0.9080, value_loss: 0.5520
2024-07-11 17:13:39,700 [INFO    ] __main__: train step 15964: loss: 0.9766, policy_loss: 0.9080, value_loss: 0.5520
2024-07-11 17:13:39,900 [INFO    ] __main__: train step 15965: loss: 0.9766, policy_loss: 0.9080, value_loss: 0.5520
2024-07-11 17:13:40,113 [INFO    ] __main__: train step 15966: loss: 0.9766, policy_loss: 0.9079, value_loss: 0.5520
2024-07-11 17:13:40,314 [INFO    ] __main__: train step 15967: loss: 0.9766, policy_loss: 0.9079, value_loss: 0.5520
2024-07-11 17:13:40,513 [INFO    ] __main__: train step 15968: loss: 0.9766, policy_loss: 0.9079, value_loss: 0.5520
2024-07-11 17:13:40,705 [INFO    ] __main__: train step 15969: loss: 0.9766, policy_loss: 0.9079, value_loss: 0.5519
2024-07-11 17:13:40,916 [INFO    ] __main__: train step 15970: loss: 0.9766, policy_loss: 0.9079, value_loss: 0.5519
2024-07-11 17:13:41,137 [INFO    ] __main__: train step 15971: loss: 0.9766, policy_loss: 0.9078, value_loss: 0.5519
2024-07-11 17:13:41,389 [INFO    ] __main__: train step 15972: loss: 0.9766, policy_loss: 0.9078, value_loss: 0.5519
2024-07-11 17:13:41,622 [INFO    ] __main__: train step 15973: loss: 0.9765, policy_loss: 0.9078, value_loss: 0.5519
2024-07-11 17:13:41,828 [INFO    ] __main__: train step 15974: loss: 0.9765, policy_loss: 0.9078, value_loss: 0.5518
2024-07-11 17:13:42,043 [INFO    ] __main__: train step 15975: loss: 0.9765, policy_loss: 0.9077, value_loss: 0.5518
2024-07-11 17:13:42,299 [INFO    ] __main__: train step 15976: loss: 0.9765, policy_loss: 0.9077, value_loss: 0.5518
2024-07-11 17:13:42,533 [INFO    ] __main__: train step 15977: loss: 0.9765, policy_loss: 0.9077, value_loss: 0.5518
2024-07-11 17:13:42,740 [INFO    ] __main__: train step 15978: loss: 0.9765, policy_loss: 0.9077, value_loss: 0.5518
2024-07-11 17:13:42,943 [INFO    ] __main__: train step 15979: loss: 0.9765, policy_loss: 0.9076, value_loss: 0.5518
2024-07-11 17:13:44,371 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:13:44,771 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:13:44,830 [INFO    ] __main__: train step 15980: loss: 0.9765, policy_loss: 0.9076, value_loss: 0.5517
2024-07-11 17:13:45,010 [INFO    ] __main__: train step 15981: loss: 0.9765, policy_loss: 0.9076, value_loss: 0.5517
2024-07-11 17:13:45,229 [INFO    ] __main__: train step 15982: loss: 0.9764, policy_loss: 0.9076, value_loss: 0.5517
2024-07-11 17:13:45,459 [INFO    ] __main__: train step 15983: loss: 0.9764, policy_loss: 0.9076, value_loss: 0.5517
2024-07-11 17:13:45,662 [INFO    ] __main__: train step 15984: loss: 0.9764, policy_loss: 0.9075, value_loss: 0.5517
2024-07-11 17:13:45,859 [INFO    ] __main__: train step 15985: loss: 0.9764, policy_loss: 0.9075, value_loss: 0.5516
2024-07-11 17:13:46,059 [INFO    ] __main__: train step 15986: loss: 0.9764, policy_loss: 0.9075, value_loss: 0.5516
2024-07-11 17:13:46,267 [INFO    ] __main__: train step 15987: loss: 0.9764, policy_loss: 0.9075, value_loss: 0.5516
2024-07-11 17:13:46,463 [INFO    ] __main__: train step 15988: loss: 0.9764, policy_loss: 0.9074, value_loss: 0.5516
2024-07-11 17:13:46,673 [INFO    ] __main__: train step 15989: loss: 0.9764, policy_loss: 0.9074, value_loss: 0.5516
2024-07-11 17:13:46,877 [INFO    ] __main__: train step 15990: loss: 0.9763, policy_loss: 0.9074, value_loss: 0.5515
2024-07-11 17:13:47,092 [INFO    ] __main__: train step 15991: loss: 0.9763, policy_loss: 0.9074, value_loss: 0.5515
2024-07-11 17:13:47,288 [INFO    ] __main__: train step 15992: loss: 0.9763, policy_loss: 0.9073, value_loss: 0.5515
2024-07-11 17:13:47,513 [INFO    ] __main__: train step 15993: loss: 0.9763, policy_loss: 0.9073, value_loss: 0.5515
2024-07-11 17:13:47,747 [INFO    ] __main__: train step 15994: loss: 0.9763, policy_loss: 0.9073, value_loss: 0.5515
2024-07-11 17:13:47,946 [INFO    ] __main__: train step 15995: loss: 0.9763, policy_loss: 0.9073, value_loss: 0.5515
2024-07-11 17:13:48,170 [INFO    ] __main__: train step 15996: loss: 0.9763, policy_loss: 0.9073, value_loss: 0.5514
2024-07-11 17:13:49,604 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:13:49,980 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:13:50,044 [INFO    ] __main__: train step 15997: loss: 0.9763, policy_loss: 0.9072, value_loss: 0.5514
2024-07-11 17:13:50,216 [INFO    ] __main__: train step 15998: loss: 0.9762, policy_loss: 0.9072, value_loss: 0.5514
2024-07-11 17:13:50,434 [INFO    ] __main__: train step 15999: loss: 0.9762, policy_loss: 0.9072, value_loss: 0.5514
2024-07-11 17:13:50,674 [INFO    ] __main__: train step 16000: loss: 0.9762, policy_loss: 0.9072, value_loss: 0.5514
2024-07-11 17:13:50,819 [INFO    ] __main__: restored step 15000 for evaluation
2024-07-11 17:13:58,593 [INFO    ] __main__: later network ELO difference from earlier network: +20 (+8/-8) ELO from 32000 self-played games
2024-07-11 17:13:58,593 [INFO    ] __main__: game outcomes: W: 16625, D: 214, L: 15161
2024-07-11 17:13:58,595 [INFO    ] __main__: validation_elo_delta: 20, validation_elo: 2450
2024-07-11 17:13:59,091 [INFO    ] __main__: train step 16001: loss: 0.9762, policy_loss: 0.9071, value_loss: 0.5513
2024-07-11 17:13:59,287 [INFO    ] __main__: train step 16002: loss: 0.9762, policy_loss: 0.9071, value_loss: 0.5513
2024-07-11 17:13:59,497 [INFO    ] __main__: train step 16003: loss: 0.9762, policy_loss: 0.9071, value_loss: 0.5513
2024-07-11 17:13:59,711 [INFO    ] __main__: train step 16004: loss: 0.9762, policy_loss: 0.9071, value_loss: 0.5513
2024-07-11 17:13:59,912 [INFO    ] __main__: train step 16005: loss: 0.9762, policy_loss: 0.9070, value_loss: 0.5513
2024-07-11 17:14:00,156 [INFO    ] __main__: train step 16006: loss: 0.9761, policy_loss: 0.9070, value_loss: 0.5512
2024-07-11 17:14:00,392 [INFO    ] __main__: train step 16007: loss: 0.9761, policy_loss: 0.9070, value_loss: 0.5512
2024-07-11 17:14:00,595 [INFO    ] __main__: train step 16008: loss: 0.9761, policy_loss: 0.9070, value_loss: 0.5512
2024-07-11 17:14:00,826 [INFO    ] __main__: train step 16009: loss: 0.9761, policy_loss: 0.9069, value_loss: 0.5512
2024-07-11 17:14:01,029 [INFO    ] __main__: train step 16010: loss: 0.9761, policy_loss: 0.9069, value_loss: 0.5512
2024-07-11 17:14:01,240 [INFO    ] __main__: train step 16011: loss: 0.9761, policy_loss: 0.9069, value_loss: 0.5511
2024-07-11 17:14:01,438 [INFO    ] __main__: train step 16012: loss: 0.9761, policy_loss: 0.9069, value_loss: 0.5511
2024-07-11 17:14:01,649 [INFO    ] __main__: train step 16013: loss: 0.9761, policy_loss: 0.9069, value_loss: 0.5511
2024-07-11 17:14:03,088 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:14:03,478 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:14:03,537 [INFO    ] __main__: train step 16014: loss: 0.9761, policy_loss: 0.9068, value_loss: 0.5511
2024-07-11 17:14:03,713 [INFO    ] __main__: train step 16015: loss: 0.9760, policy_loss: 0.9068, value_loss: 0.5511
2024-07-11 17:14:03,916 [INFO    ] __main__: train step 16016: loss: 0.9760, policy_loss: 0.9068, value_loss: 0.5511
2024-07-11 17:14:04,127 [INFO    ] __main__: train step 16017: loss: 0.9760, policy_loss: 0.9068, value_loss: 0.5510
2024-07-11 17:14:04,337 [INFO    ] __main__: train step 16018: loss: 0.9760, policy_loss: 0.9067, value_loss: 0.5510
2024-07-11 17:14:06,321 [INFO    ] __main__: train step 16019: loss: 0.9760, policy_loss: 0.9067, value_loss: 0.5510
2024-07-11 17:14:06,533 [INFO    ] __main__: train step 16020: loss: 0.9760, policy_loss: 0.9067, value_loss: 0.5510
2024-07-11 17:14:06,740 [INFO    ] __main__: train step 16021: loss: 0.9760, policy_loss: 0.9067, value_loss: 0.5510
2024-07-11 17:14:06,960 [INFO    ] __main__: train step 16022: loss: 0.9760, policy_loss: 0.9066, value_loss: 0.5509
2024-07-11 17:14:07,155 [INFO    ] __main__: train step 16023: loss: 0.9759, policy_loss: 0.9066, value_loss: 0.5509
2024-07-11 17:14:07,359 [INFO    ] __main__: train step 16024: loss: 0.9759, policy_loss: 0.9066, value_loss: 0.5509
2024-07-11 17:14:07,561 [INFO    ] __main__: train step 16025: loss: 0.9759, policy_loss: 0.9066, value_loss: 0.5509
2024-07-11 17:14:07,762 [INFO    ] __main__: train step 16026: loss: 0.9759, policy_loss: 0.9066, value_loss: 0.5509
2024-07-11 17:14:07,980 [INFO    ] __main__: train step 16027: loss: 0.9759, policy_loss: 0.9065, value_loss: 0.5509
2024-07-11 17:14:08,214 [INFO    ] __main__: train step 16028: loss: 0.9759, policy_loss: 0.9065, value_loss: 0.5508
2024-07-11 17:14:08,425 [INFO    ] __main__: train step 16029: loss: 0.9759, policy_loss: 0.9065, value_loss: 0.5508
2024-07-11 17:14:08,639 [INFO    ] __main__: train step 16030: loss: 0.9759, policy_loss: 0.9065, value_loss: 0.5508
2024-07-11 17:14:10,048 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:14:10,373 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:14:10,428 [INFO    ] __main__: train step 16031: loss: 0.9759, policy_loss: 0.9064, value_loss: 0.5508
2024-07-11 17:14:10,613 [INFO    ] __main__: train step 16032: loss: 0.9758, policy_loss: 0.9064, value_loss: 0.5508
2024-07-11 17:14:10,812 [INFO    ] __main__: train step 16033: loss: 0.9758, policy_loss: 0.9064, value_loss: 0.5507
2024-07-11 17:14:11,019 [INFO    ] __main__: train step 16034: loss: 0.9758, policy_loss: 0.9064, value_loss: 0.5507
2024-07-11 17:14:11,214 [INFO    ] __main__: train step 16035: loss: 0.9758, policy_loss: 0.9063, value_loss: 0.5507
2024-07-11 17:14:11,432 [INFO    ] __main__: train step 16036: loss: 0.9758, policy_loss: 0.9063, value_loss: 0.5507
2024-07-11 17:14:11,632 [INFO    ] __main__: train step 16037: loss: 0.9758, policy_loss: 0.9063, value_loss: 0.5507
2024-07-11 17:14:11,861 [INFO    ] __main__: train step 16038: loss: 0.9758, policy_loss: 0.9063, value_loss: 0.5507
2024-07-11 17:14:12,060 [INFO    ] __main__: train step 16039: loss: 0.9758, policy_loss: 0.9062, value_loss: 0.5506
2024-07-11 17:14:12,248 [INFO    ] __main__: train step 16040: loss: 0.9757, policy_loss: 0.9062, value_loss: 0.5506
2024-07-11 17:14:12,468 [INFO    ] __main__: train step 16041: loss: 0.9757, policy_loss: 0.9062, value_loss: 0.5506
2024-07-11 17:14:12,668 [INFO    ] __main__: train step 16042: loss: 0.9757, policy_loss: 0.9062, value_loss: 0.5506
2024-07-11 17:14:12,862 [INFO    ] __main__: train step 16043: loss: 0.9757, policy_loss: 0.9062, value_loss: 0.5506
2024-07-11 17:14:13,131 [INFO    ] __main__: train step 16044: loss: 0.9757, policy_loss: 0.9061, value_loss: 0.5505
2024-07-11 17:14:13,323 [INFO    ] __main__: train step 16045: loss: 0.9757, policy_loss: 0.9061, value_loss: 0.5505
2024-07-11 17:14:13,516 [INFO    ] __main__: train step 16046: loss: 0.9757, policy_loss: 0.9061, value_loss: 0.5505
2024-07-11 17:14:13,717 [INFO    ] __main__: train step 16047: loss: 0.9757, policy_loss: 0.9061, value_loss: 0.5505
2024-07-11 17:14:15,140 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:14:15,494 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:14:15,550 [INFO    ] __main__: train step 16048: loss: 0.9757, policy_loss: 0.9060, value_loss: 0.5505
2024-07-11 17:14:15,726 [INFO    ] __main__: train step 16049: loss: 0.9756, policy_loss: 0.9060, value_loss: 0.5504
2024-07-11 17:14:15,937 [INFO    ] __main__: train step 16050: loss: 0.9756, policy_loss: 0.9060, value_loss: 0.5504
2024-07-11 17:14:16,135 [INFO    ] __main__: train step 16051: loss: 0.9756, policy_loss: 0.9060, value_loss: 0.5504
2024-07-11 17:14:16,342 [INFO    ] __main__: train step 16052: loss: 0.9756, policy_loss: 0.9059, value_loss: 0.5504
2024-07-11 17:14:16,540 [INFO    ] __main__: train step 16053: loss: 0.9756, policy_loss: 0.9059, value_loss: 0.5504
2024-07-11 17:14:16,738 [INFO    ] __main__: train step 16054: loss: 0.9756, policy_loss: 0.9059, value_loss: 0.5504
2024-07-11 17:14:16,939 [INFO    ] __main__: train step 16055: loss: 0.9756, policy_loss: 0.9059, value_loss: 0.5503
2024-07-11 17:14:17,145 [INFO    ] __main__: train step 16056: loss: 0.9756, policy_loss: 0.9058, value_loss: 0.5503
2024-07-11 17:14:17,346 [INFO    ] __main__: train step 16057: loss: 0.9755, policy_loss: 0.9058, value_loss: 0.5503
2024-07-11 17:14:17,566 [INFO    ] __main__: train step 16058: loss: 0.9755, policy_loss: 0.9058, value_loss: 0.5503
2024-07-11 17:14:17,804 [INFO    ] __main__: train step 16059: loss: 0.9755, policy_loss: 0.9058, value_loss: 0.5503
2024-07-11 17:14:18,036 [INFO    ] __main__: train step 16060: loss: 0.9755, policy_loss: 0.9058, value_loss: 0.5502
2024-07-11 17:14:18,246 [INFO    ] __main__: train step 16061: loss: 0.9755, policy_loss: 0.9057, value_loss: 0.5502
2024-07-11 17:14:18,443 [INFO    ] __main__: train step 16062: loss: 0.9755, policy_loss: 0.9057, value_loss: 0.5502
2024-07-11 17:14:18,644 [INFO    ] __main__: train step 16063: loss: 0.9755, policy_loss: 0.9057, value_loss: 0.5502
2024-07-11 17:14:18,841 [INFO    ] __main__: train step 16064: loss: 0.9755, policy_loss: 0.9057, value_loss: 0.5502
2024-07-11 17:14:20,265 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:14:20,664 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:14:20,722 [INFO    ] __main__: train step 16065: loss: 0.9755, policy_loss: 0.9056, value_loss: 0.5502
2024-07-11 17:14:20,901 [INFO    ] __main__: train step 16066: loss: 0.9754, policy_loss: 0.9056, value_loss: 0.5501
2024-07-11 17:14:21,097 [INFO    ] __main__: train step 16067: loss: 0.9754, policy_loss: 0.9056, value_loss: 0.5501
2024-07-11 17:14:21,305 [INFO    ] __main__: train step 16068: loss: 0.9754, policy_loss: 0.9056, value_loss: 0.5501
2024-07-11 17:14:21,512 [INFO    ] __main__: train step 16069: loss: 0.9754, policy_loss: 0.9055, value_loss: 0.5501
2024-07-11 17:14:21,716 [INFO    ] __main__: train step 16070: loss: 0.9754, policy_loss: 0.9055, value_loss: 0.5501
2024-07-11 17:14:21,914 [INFO    ] __main__: train step 16071: loss: 0.9754, policy_loss: 0.9055, value_loss: 0.5500
2024-07-11 17:14:22,122 [INFO    ] __main__: train step 16072: loss: 0.9754, policy_loss: 0.9055, value_loss: 0.5500
2024-07-11 17:14:22,324 [INFO    ] __main__: train step 16073: loss: 0.9754, policy_loss: 0.9055, value_loss: 0.5500
2024-07-11 17:14:22,534 [INFO    ] __main__: train step 16074: loss: 0.9754, policy_loss: 0.9054, value_loss: 0.5500
2024-07-11 17:14:22,734 [INFO    ] __main__: train step 16075: loss: 0.9753, policy_loss: 0.9054, value_loss: 0.5500
2024-07-11 17:14:22,943 [INFO    ] __main__: train step 16076: loss: 0.9753, policy_loss: 0.9054, value_loss: 0.5500
2024-07-11 17:14:23,156 [INFO    ] __main__: train step 16077: loss: 0.9753, policy_loss: 0.9054, value_loss: 0.5499
2024-07-11 17:14:23,402 [INFO    ] __main__: train step 16078: loss: 0.9753, policy_loss: 0.9053, value_loss: 0.5499
2024-07-11 17:14:23,610 [INFO    ] __main__: train step 16079: loss: 0.9753, policy_loss: 0.9053, value_loss: 0.5499
2024-07-11 17:14:23,856 [INFO    ] __main__: train step 16080: loss: 0.9753, policy_loss: 0.9053, value_loss: 0.5499
2024-07-11 17:14:24,094 [INFO    ] __main__: train step 16081: loss: 0.9753, policy_loss: 0.9053, value_loss: 0.5499
2024-07-11 17:14:25,501 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:14:25,867 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:14:25,923 [INFO    ] __main__: train step 16082: loss: 0.9753, policy_loss: 0.9053, value_loss: 0.5499
2024-07-11 17:14:26,105 [INFO    ] __main__: train step 16083: loss: 0.9753, policy_loss: 0.9052, value_loss: 0.5498
2024-07-11 17:14:26,313 [INFO    ] __main__: train step 16084: loss: 0.9752, policy_loss: 0.9052, value_loss: 0.5498
2024-07-11 17:14:26,525 [INFO    ] __main__: train step 16085: loss: 0.9752, policy_loss: 0.9052, value_loss: 0.5498
2024-07-11 17:14:26,722 [INFO    ] __main__: train step 16086: loss: 0.9752, policy_loss: 0.9052, value_loss: 0.5498
2024-07-11 17:14:26,928 [INFO    ] __main__: train step 16087: loss: 0.9752, policy_loss: 0.9051, value_loss: 0.5498
2024-07-11 17:14:27,147 [INFO    ] __main__: train step 16088: loss: 0.9752, policy_loss: 0.9051, value_loss: 0.5497
2024-07-11 17:14:27,388 [INFO    ] __main__: train step 16089: loss: 0.9752, policy_loss: 0.9051, value_loss: 0.5497
2024-07-11 17:14:27,597 [INFO    ] __main__: train step 16090: loss: 0.9752, policy_loss: 0.9051, value_loss: 0.5497
2024-07-11 17:14:27,793 [INFO    ] __main__: train step 16091: loss: 0.9752, policy_loss: 0.9050, value_loss: 0.5497
2024-07-11 17:14:27,991 [INFO    ] __main__: train step 16092: loss: 0.9752, policy_loss: 0.9050, value_loss: 0.5497
2024-07-11 17:14:28,201 [INFO    ] __main__: train step 16093: loss: 0.9751, policy_loss: 0.9050, value_loss: 0.5497
2024-07-11 17:14:28,400 [INFO    ] __main__: train step 16094: loss: 0.9751, policy_loss: 0.9050, value_loss: 0.5496
2024-07-11 17:14:28,604 [INFO    ] __main__: train step 16095: loss: 0.9751, policy_loss: 0.9050, value_loss: 0.5496
2024-07-11 17:14:28,806 [INFO    ] __main__: train step 16096: loss: 0.9751, policy_loss: 0.9049, value_loss: 0.5496
2024-07-11 17:14:29,007 [INFO    ] __main__: train step 16097: loss: 0.9751, policy_loss: 0.9049, value_loss: 0.5496
2024-07-11 17:14:29,219 [INFO    ] __main__: train step 16098: loss: 0.9751, policy_loss: 0.9049, value_loss: 0.5496
2024-07-11 17:14:30,653 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:14:31,007 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:14:31,062 [INFO    ] __main__: train step 16099: loss: 0.9751, policy_loss: 0.9049, value_loss: 0.5495
2024-07-11 17:14:31,244 [INFO    ] __main__: train step 16100: loss: 0.9751, policy_loss: 0.9048, value_loss: 0.5495
2024-07-11 17:14:31,450 [INFO    ] __main__: train step 16101: loss: 0.9751, policy_loss: 0.9048, value_loss: 0.5495
2024-07-11 17:14:31,656 [INFO    ] __main__: train step 16102: loss: 0.9750, policy_loss: 0.9048, value_loss: 0.5495
2024-07-11 17:14:31,887 [INFO    ] __main__: train step 16103: loss: 0.9750, policy_loss: 0.9048, value_loss: 0.5495
2024-07-11 17:14:32,095 [INFO    ] __main__: train step 16104: loss: 0.9750, policy_loss: 0.9047, value_loss: 0.5495
2024-07-11 17:14:32,309 [INFO    ] __main__: train step 16105: loss: 0.9750, policy_loss: 0.9047, value_loss: 0.5494
2024-07-11 17:14:32,506 [INFO    ] __main__: train step 16106: loss: 0.9750, policy_loss: 0.9047, value_loss: 0.5494
2024-07-11 17:14:32,718 [INFO    ] __main__: train step 16107: loss: 0.9750, policy_loss: 0.9047, value_loss: 0.5494
2024-07-11 17:14:32,919 [INFO    ] __main__: train step 16108: loss: 0.9750, policy_loss: 0.9047, value_loss: 0.5494
2024-07-11 17:14:33,152 [INFO    ] __main__: train step 16109: loss: 0.9750, policy_loss: 0.9046, value_loss: 0.5494
2024-07-11 17:14:33,382 [INFO    ] __main__: train step 16110: loss: 0.9750, policy_loss: 0.9046, value_loss: 0.5493
2024-07-11 17:14:33,604 [INFO    ] __main__: train step 16111: loss: 0.9749, policy_loss: 0.9046, value_loss: 0.5493
2024-07-11 17:14:33,799 [INFO    ] __main__: train step 16112: loss: 0.9749, policy_loss: 0.9046, value_loss: 0.5493
2024-07-11 17:14:33,999 [INFO    ] __main__: train step 16113: loss: 0.9749, policy_loss: 0.9045, value_loss: 0.5493
2024-07-11 17:14:34,203 [INFO    ] __main__: train step 16114: loss: 0.9749, policy_loss: 0.9045, value_loss: 0.5493
2024-07-11 17:14:34,403 [INFO    ] __main__: train step 16115: loss: 0.9749, policy_loss: 0.9045, value_loss: 0.5493
2024-07-11 17:14:35,836 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:14:36,190 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:14:36,247 [INFO    ] __main__: train step 16116: loss: 0.9749, policy_loss: 0.9045, value_loss: 0.5492
2024-07-11 17:14:36,424 [INFO    ] __main__: train step 16117: loss: 0.9749, policy_loss: 0.9045, value_loss: 0.5492
2024-07-11 17:14:36,615 [INFO    ] __main__: train step 16118: loss: 0.9749, policy_loss: 0.9044, value_loss: 0.5492
2024-07-11 17:14:36,810 [INFO    ] __main__: train step 16119: loss: 0.9749, policy_loss: 0.9044, value_loss: 0.5492
2024-07-11 17:14:37,014 [INFO    ] __main__: train step 16120: loss: 0.9748, policy_loss: 0.9044, value_loss: 0.5492
2024-07-11 17:14:37,204 [INFO    ] __main__: train step 16121: loss: 0.9748, policy_loss: 0.9044, value_loss: 0.5491
2024-07-11 17:14:37,411 [INFO    ] __main__: train step 16122: loss: 0.9748, policy_loss: 0.9043, value_loss: 0.5491
2024-07-11 17:14:37,612 [INFO    ] __main__: train step 16123: loss: 0.9748, policy_loss: 0.9043, value_loss: 0.5491
2024-07-11 17:14:37,816 [INFO    ] __main__: train step 16124: loss: 0.9748, policy_loss: 0.9043, value_loss: 0.5491
2024-07-11 17:14:38,018 [INFO    ] __main__: train step 16125: loss: 0.9748, policy_loss: 0.9043, value_loss: 0.5491
2024-07-11 17:14:38,217 [INFO    ] __main__: train step 16126: loss: 0.9748, policy_loss: 0.9042, value_loss: 0.5491
2024-07-11 17:14:38,442 [INFO    ] __main__: train step 16127: loss: 0.9748, policy_loss: 0.9042, value_loss: 0.5490
2024-07-11 17:14:38,660 [INFO    ] __main__: train step 16128: loss: 0.9748, policy_loss: 0.9042, value_loss: 0.5490
2024-07-11 17:14:38,874 [INFO    ] __main__: train step 16129: loss: 0.9747, policy_loss: 0.9042, value_loss: 0.5490
2024-07-11 17:14:39,069 [INFO    ] __main__: train step 16130: loss: 0.9747, policy_loss: 0.9042, value_loss: 0.5490
2024-07-11 17:14:39,273 [INFO    ] __main__: train step 16131: loss: 0.9747, policy_loss: 0.9041, value_loss: 0.5490
2024-07-11 17:14:39,513 [INFO    ] __main__: train step 16132: loss: 0.9747, policy_loss: 0.9041, value_loss: 0.5490
2024-07-11 17:14:40,943 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:14:41,313 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:14:41,368 [INFO    ] __main__: train step 16133: loss: 0.9747, policy_loss: 0.9041, value_loss: 0.5489
2024-07-11 17:14:41,552 [INFO    ] __main__: train step 16134: loss: 0.9747, policy_loss: 0.9041, value_loss: 0.5489
2024-07-11 17:14:41,773 [INFO    ] __main__: train step 16135: loss: 0.9747, policy_loss: 0.9040, value_loss: 0.5489
2024-07-11 17:14:41,986 [INFO    ] __main__: train step 16136: loss: 0.9747, policy_loss: 0.9040, value_loss: 0.5489
2024-07-11 17:14:43,915 [INFO    ] __main__: train step 16137: loss: 0.9747, policy_loss: 0.9040, value_loss: 0.5489
2024-07-11 17:14:44,121 [INFO    ] __main__: train step 16138: loss: 0.9746, policy_loss: 0.9040, value_loss: 0.5488
2024-07-11 17:14:44,321 [INFO    ] __main__: train step 16139: loss: 0.9746, policy_loss: 0.9039, value_loss: 0.5488
2024-07-11 17:14:44,521 [INFO    ] __main__: train step 16140: loss: 0.9746, policy_loss: 0.9039, value_loss: 0.5488
2024-07-11 17:14:44,743 [INFO    ] __main__: train step 16141: loss: 0.9746, policy_loss: 0.9039, value_loss: 0.5488
2024-07-11 17:14:44,956 [INFO    ] __main__: train step 16142: loss: 0.9746, policy_loss: 0.9039, value_loss: 0.5488
2024-07-11 17:14:45,184 [INFO    ] __main__: train step 16143: loss: 0.9746, policy_loss: 0.9039, value_loss: 0.5488
2024-07-11 17:14:45,405 [INFO    ] __main__: train step 16144: loss: 0.9746, policy_loss: 0.9038, value_loss: 0.5487
2024-07-11 17:14:45,614 [INFO    ] __main__: train step 16145: loss: 0.9746, policy_loss: 0.9038, value_loss: 0.5487
2024-07-11 17:14:45,851 [INFO    ] __main__: train step 16146: loss: 0.9746, policy_loss: 0.9038, value_loss: 0.5487
2024-07-11 17:14:46,051 [INFO    ] __main__: train step 16147: loss: 0.9745, policy_loss: 0.9038, value_loss: 0.5487
2024-07-11 17:14:46,245 [INFO    ] __main__: train step 16148: loss: 0.9745, policy_loss: 0.9037, value_loss: 0.5487
2024-07-11 17:14:46,459 [INFO    ] __main__: train step 16149: loss: 0.9745, policy_loss: 0.9037, value_loss: 0.5487
2024-07-11 17:14:47,871 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:14:48,270 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:14:48,326 [INFO    ] __main__: train step 16150: loss: 0.9745, policy_loss: 0.9037, value_loss: 0.5486
2024-07-11 17:14:48,496 [INFO    ] __main__: train step 16151: loss: 0.9745, policy_loss: 0.9037, value_loss: 0.5486
2024-07-11 17:14:48,709 [INFO    ] __main__: train step 16152: loss: 0.9745, policy_loss: 0.9036, value_loss: 0.5486
2024-07-11 17:14:48,917 [INFO    ] __main__: train step 16153: loss: 0.9745, policy_loss: 0.9036, value_loss: 0.5486
2024-07-11 17:14:49,117 [INFO    ] __main__: train step 16154: loss: 0.9745, policy_loss: 0.9036, value_loss: 0.5486
2024-07-11 17:14:49,312 [INFO    ] __main__: train step 16155: loss: 0.9745, policy_loss: 0.9036, value_loss: 0.5486
2024-07-11 17:14:49,517 [INFO    ] __main__: train step 16156: loss: 0.9744, policy_loss: 0.9036, value_loss: 0.5485
2024-07-11 17:14:49,728 [INFO    ] __main__: train step 16157: loss: 0.9744, policy_loss: 0.9035, value_loss: 0.5485
2024-07-11 17:14:49,936 [INFO    ] __main__: train step 16158: loss: 0.9744, policy_loss: 0.9035, value_loss: 0.5485
2024-07-11 17:14:50,141 [INFO    ] __main__: train step 16159: loss: 0.9744, policy_loss: 0.9035, value_loss: 0.5485
2024-07-11 17:14:50,349 [INFO    ] __main__: train step 16160: loss: 0.9744, policy_loss: 0.9035, value_loss: 0.5485
2024-07-11 17:14:50,550 [INFO    ] __main__: train step 16161: loss: 0.9744, policy_loss: 0.9034, value_loss: 0.5484
2024-07-11 17:14:50,774 [INFO    ] __main__: train step 16162: loss: 0.9744, policy_loss: 0.9034, value_loss: 0.5484
2024-07-11 17:14:50,984 [INFO    ] __main__: train step 16163: loss: 0.9744, policy_loss: 0.9034, value_loss: 0.5484
2024-07-11 17:14:51,205 [INFO    ] __main__: train step 16164: loss: 0.9744, policy_loss: 0.9034, value_loss: 0.5484
2024-07-11 17:14:51,418 [INFO    ] __main__: train step 16165: loss: 0.9744, policy_loss: 0.9033, value_loss: 0.5484
2024-07-11 17:14:51,621 [INFO    ] __main__: train step 16166: loss: 0.9743, policy_loss: 0.9033, value_loss: 0.5484
2024-07-11 17:14:53,044 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:14:53,401 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:14:53,461 [INFO    ] __main__: train step 16167: loss: 0.9743, policy_loss: 0.9033, value_loss: 0.5483
2024-07-11 17:14:53,639 [INFO    ] __main__: train step 16168: loss: 0.9743, policy_loss: 0.9033, value_loss: 0.5483
2024-07-11 17:14:53,863 [INFO    ] __main__: train step 16169: loss: 0.9743, policy_loss: 0.9033, value_loss: 0.5483
2024-07-11 17:14:54,074 [INFO    ] __main__: train step 16170: loss: 0.9743, policy_loss: 0.9032, value_loss: 0.5483
2024-07-11 17:14:54,274 [INFO    ] __main__: train step 16171: loss: 0.9743, policy_loss: 0.9032, value_loss: 0.5483
2024-07-11 17:14:54,479 [INFO    ] __main__: train step 16172: loss: 0.9743, policy_loss: 0.9032, value_loss: 0.5483
2024-07-11 17:14:54,693 [INFO    ] __main__: train step 16173: loss: 0.9743, policy_loss: 0.9032, value_loss: 0.5482
2024-07-11 17:14:54,935 [INFO    ] __main__: train step 16174: loss: 0.9743, policy_loss: 0.9031, value_loss: 0.5482
2024-07-11 17:14:55,135 [INFO    ] __main__: train step 16175: loss: 0.9742, policy_loss: 0.9031, value_loss: 0.5482
2024-07-11 17:14:55,335 [INFO    ] __main__: train step 16176: loss: 0.9742, policy_loss: 0.9031, value_loss: 0.5482
2024-07-11 17:14:55,532 [INFO    ] __main__: train step 16177: loss: 0.9742, policy_loss: 0.9031, value_loss: 0.5482
2024-07-11 17:14:55,743 [INFO    ] __main__: train step 16178: loss: 0.9742, policy_loss: 0.9031, value_loss: 0.5482
2024-07-11 17:14:55,941 [INFO    ] __main__: train step 16179: loss: 0.9742, policy_loss: 0.9030, value_loss: 0.5481
2024-07-11 17:14:56,146 [INFO    ] __main__: train step 16180: loss: 0.9742, policy_loss: 0.9030, value_loss: 0.5481
2024-07-11 17:14:56,351 [INFO    ] __main__: train step 16181: loss: 0.9742, policy_loss: 0.9030, value_loss: 0.5481
2024-07-11 17:14:56,552 [INFO    ] __main__: train step 16182: loss: 0.9742, policy_loss: 0.9030, value_loss: 0.5481
2024-07-11 17:14:56,764 [INFO    ] __main__: train step 16183: loss: 0.9742, policy_loss: 0.9029, value_loss: 0.5481
2024-07-11 17:14:58,174 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:14:58,521 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:14:58,577 [INFO    ] __main__: train step 16184: loss: 0.9742, policy_loss: 0.9029, value_loss: 0.5481
2024-07-11 17:14:58,766 [INFO    ] __main__: train step 16185: loss: 0.9741, policy_loss: 0.9029, value_loss: 0.5480
2024-07-11 17:14:58,977 [INFO    ] __main__: train step 16186: loss: 0.9741, policy_loss: 0.9029, value_loss: 0.5480
2024-07-11 17:14:59,164 [INFO    ] __main__: train step 16187: loss: 0.9741, policy_loss: 0.9028, value_loss: 0.5480
2024-07-11 17:14:59,372 [INFO    ] __main__: train step 16188: loss: 0.9741, policy_loss: 0.9028, value_loss: 0.5480
2024-07-11 17:14:59,590 [INFO    ] __main__: train step 16189: loss: 0.9741, policy_loss: 0.9028, value_loss: 0.5480
2024-07-11 17:14:59,804 [INFO    ] __main__: train step 16190: loss: 0.9741, policy_loss: 0.9028, value_loss: 0.5479
2024-07-11 17:15:00,004 [INFO    ] __main__: train step 16191: loss: 0.9741, policy_loss: 0.9027, value_loss: 0.5479
2024-07-11 17:15:00,227 [INFO    ] __main__: train step 16192: loss: 0.9741, policy_loss: 0.9027, value_loss: 0.5479
2024-07-11 17:15:00,459 [INFO    ] __main__: train step 16193: loss: 0.9741, policy_loss: 0.9027, value_loss: 0.5479
2024-07-11 17:15:00,665 [INFO    ] __main__: train step 16194: loss: 0.9740, policy_loss: 0.9027, value_loss: 0.5479
2024-07-11 17:15:00,877 [INFO    ] __main__: train step 16195: loss: 0.9740, policy_loss: 0.9027, value_loss: 0.5479
2024-07-11 17:15:01,131 [INFO    ] __main__: train step 16196: loss: 0.9740, policy_loss: 0.9026, value_loss: 0.5478
2024-07-11 17:15:01,358 [INFO    ] __main__: train step 16197: loss: 0.9740, policy_loss: 0.9026, value_loss: 0.5478
2024-07-11 17:15:01,556 [INFO    ] __main__: train step 16198: loss: 0.9740, policy_loss: 0.9026, value_loss: 0.5478
2024-07-11 17:15:01,765 [INFO    ] __main__: train step 16199: loss: 0.9740, policy_loss: 0.9026, value_loss: 0.5478
2024-07-11 17:15:01,974 [INFO    ] __main__: train step 16200: loss: 0.9740, policy_loss: 0.9025, value_loss: 0.5478
2024-07-11 17:15:03,355 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:15:03,701 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:15:03,756 [INFO    ] __main__: train step 16201: loss: 0.9740, policy_loss: 0.9025, value_loss: 0.5478
2024-07-11 17:15:03,942 [INFO    ] __main__: train step 16202: loss: 0.9740, policy_loss: 0.9025, value_loss: 0.5477
2024-07-11 17:15:04,163 [INFO    ] __main__: train step 16203: loss: 0.9739, policy_loss: 0.9025, value_loss: 0.5477
2024-07-11 17:15:04,360 [INFO    ] __main__: train step 16204: loss: 0.9739, policy_loss: 0.9024, value_loss: 0.5477
2024-07-11 17:15:04,563 [INFO    ] __main__: train step 16205: loss: 0.9739, policy_loss: 0.9024, value_loss: 0.5477
2024-07-11 17:15:04,764 [INFO    ] __main__: train step 16206: loss: 0.9739, policy_loss: 0.9024, value_loss: 0.5477
2024-07-11 17:15:04,973 [INFO    ] __main__: train step 16207: loss: 0.9739, policy_loss: 0.9024, value_loss: 0.5477
2024-07-11 17:15:05,180 [INFO    ] __main__: train step 16208: loss: 0.9739, policy_loss: 0.9024, value_loss: 0.5476
2024-07-11 17:15:05,393 [INFO    ] __main__: train step 16209: loss: 0.9739, policy_loss: 0.9023, value_loss: 0.5476
2024-07-11 17:15:05,597 [INFO    ] __main__: train step 16210: loss: 0.9739, policy_loss: 0.9023, value_loss: 0.5476
2024-07-11 17:15:05,819 [INFO    ] __main__: train step 16211: loss: 0.9739, policy_loss: 0.9023, value_loss: 0.5476
2024-07-11 17:15:06,063 [INFO    ] __main__: train step 16212: loss: 0.9738, policy_loss: 0.9023, value_loss: 0.5476
2024-07-11 17:15:06,273 [INFO    ] __main__: train step 16213: loss: 0.9738, policy_loss: 0.9022, value_loss: 0.5476
2024-07-11 17:15:06,509 [INFO    ] __main__: train step 16214: loss: 0.9738, policy_loss: 0.9022, value_loss: 0.5475
2024-07-11 17:15:06,709 [INFO    ] __main__: train step 16215: loss: 0.9738, policy_loss: 0.9022, value_loss: 0.5475
2024-07-11 17:15:06,905 [INFO    ] __main__: train step 16216: loss: 0.9738, policy_loss: 0.9022, value_loss: 0.5475
2024-07-11 17:15:07,115 [INFO    ] __main__: train step 16217: loss: 0.9738, policy_loss: 0.9022, value_loss: 0.5475
2024-07-11 17:15:08,517 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:15:08,939 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:15:08,993 [INFO    ] __main__: train step 16218: loss: 0.9738, policy_loss: 0.9021, value_loss: 0.5475
2024-07-11 17:15:09,179 [INFO    ] __main__: train step 16219: loss: 0.9738, policy_loss: 0.9021, value_loss: 0.5475
2024-07-11 17:15:09,382 [INFO    ] __main__: train step 16220: loss: 0.9738, policy_loss: 0.9021, value_loss: 0.5474
2024-07-11 17:15:09,579 [INFO    ] __main__: train step 16221: loss: 0.9738, policy_loss: 0.9021, value_loss: 0.5474
2024-07-11 17:15:09,779 [INFO    ] __main__: train step 16222: loss: 0.9737, policy_loss: 0.9020, value_loss: 0.5474
2024-07-11 17:15:09,986 [INFO    ] __main__: train step 16223: loss: 0.9737, policy_loss: 0.9020, value_loss: 0.5474
2024-07-11 17:15:10,200 [INFO    ] __main__: train step 16224: loss: 0.9737, policy_loss: 0.9020, value_loss: 0.5474
2024-07-11 17:15:10,397 [INFO    ] __main__: train step 16225: loss: 0.9737, policy_loss: 0.9020, value_loss: 0.5473
2024-07-11 17:15:10,603 [INFO    ] __main__: train step 16226: loss: 0.9737, policy_loss: 0.9019, value_loss: 0.5473
2024-07-11 17:15:10,821 [INFO    ] __main__: train step 16227: loss: 0.9737, policy_loss: 0.9019, value_loss: 0.5473
2024-07-11 17:15:11,018 [INFO    ] __main__: train step 16228: loss: 0.9737, policy_loss: 0.9019, value_loss: 0.5473
2024-07-11 17:15:11,236 [INFO    ] __main__: train step 16229: loss: 0.9737, policy_loss: 0.9019, value_loss: 0.5473
2024-07-11 17:15:11,448 [INFO    ] __main__: train step 16230: loss: 0.9737, policy_loss: 0.9019, value_loss: 0.5473
2024-07-11 17:15:11,667 [INFO    ] __main__: train step 16231: loss: 0.9736, policy_loss: 0.9018, value_loss: 0.5472
2024-07-11 17:15:11,867 [INFO    ] __main__: train step 16232: loss: 0.9736, policy_loss: 0.9018, value_loss: 0.5472
2024-07-11 17:15:12,078 [INFO    ] __main__: train step 16233: loss: 0.9736, policy_loss: 0.9018, value_loss: 0.5472
2024-07-11 17:15:12,274 [INFO    ] __main__: train step 16234: loss: 0.9736, policy_loss: 0.9018, value_loss: 0.5472
2024-07-11 17:15:13,689 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:15:14,092 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:15:14,148 [INFO    ] __main__: train step 16235: loss: 0.9736, policy_loss: 0.9017, value_loss: 0.5472
2024-07-11 17:15:14,320 [INFO    ] __main__: train step 16236: loss: 0.9736, policy_loss: 0.9017, value_loss: 0.5472
2024-07-11 17:15:14,521 [INFO    ] __main__: train step 16237: loss: 0.9736, policy_loss: 0.9017, value_loss: 0.5471
2024-07-11 17:15:14,734 [INFO    ] __main__: train step 16238: loss: 0.9736, policy_loss: 0.9017, value_loss: 0.5471
2024-07-11 17:15:14,965 [INFO    ] __main__: train step 16239: loss: 0.9736, policy_loss: 0.9016, value_loss: 0.5471
2024-07-11 17:15:15,169 [INFO    ] __main__: train step 16240: loss: 0.9735, policy_loss: 0.9016, value_loss: 0.5471
2024-07-11 17:15:15,372 [INFO    ] __main__: train step 16241: loss: 0.9735, policy_loss: 0.9016, value_loss: 0.5471
2024-07-11 17:15:15,568 [INFO    ] __main__: train step 16242: loss: 0.9735, policy_loss: 0.9016, value_loss: 0.5471
2024-07-11 17:15:15,773 [INFO    ] __main__: train step 16243: loss: 0.9735, policy_loss: 0.9016, value_loss: 0.5470
2024-07-11 17:15:15,980 [INFO    ] __main__: train step 16244: loss: 0.9735, policy_loss: 0.9015, value_loss: 0.5470
2024-07-11 17:15:16,185 [INFO    ] __main__: train step 16245: loss: 0.9735, policy_loss: 0.9015, value_loss: 0.5470
2024-07-11 17:15:16,389 [INFO    ] __main__: train step 16246: loss: 0.9735, policy_loss: 0.9015, value_loss: 0.5470
2024-07-11 17:15:16,581 [INFO    ] __main__: train step 16247: loss: 0.9735, policy_loss: 0.9015, value_loss: 0.5470
2024-07-11 17:15:16,784 [INFO    ] __main__: train step 16248: loss: 0.9735, policy_loss: 0.9014, value_loss: 0.5469
2024-07-11 17:15:16,981 [INFO    ] __main__: train step 16249: loss: 0.9734, policy_loss: 0.9014, value_loss: 0.5469
2024-07-11 17:15:17,183 [INFO    ] __main__: train step 16250: loss: 0.9734, policy_loss: 0.9014, value_loss: 0.5469
2024-07-11 17:15:17,394 [INFO    ] __main__: train step 16251: loss: 0.9734, policy_loss: 0.9014, value_loss: 0.5469
2024-07-11 17:15:18,854 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:15:19,257 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:15:19,313 [INFO    ] __main__: train step 16252: loss: 0.9734, policy_loss: 0.9013, value_loss: 0.5469
2024-07-11 17:15:19,490 [INFO    ] __main__: train step 16253: loss: 0.9734, policy_loss: 0.9013, value_loss: 0.5469
2024-07-11 17:15:21,480 [INFO    ] __main__: train step 16254: loss: 0.9734, policy_loss: 0.9013, value_loss: 0.5468
2024-07-11 17:15:21,698 [INFO    ] __main__: train step 16255: loss: 0.9734, policy_loss: 0.9013, value_loss: 0.5468
2024-07-11 17:15:21,891 [INFO    ] __main__: train step 16256: loss: 0.9734, policy_loss: 0.9013, value_loss: 0.5468
2024-07-11 17:15:22,109 [INFO    ] __main__: train step 16257: loss: 0.9734, policy_loss: 0.9012, value_loss: 0.5468
2024-07-11 17:15:22,321 [INFO    ] __main__: train step 16258: loss: 0.9733, policy_loss: 0.9012, value_loss: 0.5468
2024-07-11 17:15:22,548 [INFO    ] __main__: train step 16259: loss: 0.9733, policy_loss: 0.9012, value_loss: 0.5468
2024-07-11 17:15:22,758 [INFO    ] __main__: train step 16260: loss: 0.9733, policy_loss: 0.9012, value_loss: 0.5467
2024-07-11 17:15:22,961 [INFO    ] __main__: train step 16261: loss: 0.9733, policy_loss: 0.9011, value_loss: 0.5467
2024-07-11 17:15:23,175 [INFO    ] __main__: train step 16262: loss: 0.9733, policy_loss: 0.9011, value_loss: 0.5467
2024-07-11 17:15:23,399 [INFO    ] __main__: train step 16263: loss: 0.9733, policy_loss: 0.9011, value_loss: 0.5467
2024-07-11 17:15:23,593 [INFO    ] __main__: train step 16264: loss: 0.9733, policy_loss: 0.9011, value_loss: 0.5467
2024-07-11 17:15:23,819 [INFO    ] __main__: train step 16265: loss: 0.9733, policy_loss: 0.9010, value_loss: 0.5467
2024-07-11 17:15:24,016 [INFO    ] __main__: train step 16266: loss: 0.9733, policy_loss: 0.9010, value_loss: 0.5466
2024-07-11 17:15:24,220 [INFO    ] __main__: train step 16267: loss: 0.9732, policy_loss: 0.9010, value_loss: 0.5466
2024-07-11 17:15:24,426 [INFO    ] __main__: train step 16268: loss: 0.9732, policy_loss: 0.9010, value_loss: 0.5466
2024-07-11 17:15:25,843 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:15:26,252 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:15:26,308 [INFO    ] __main__: train step 16269: loss: 0.9732, policy_loss: 0.9010, value_loss: 0.5466
2024-07-11 17:15:26,483 [INFO    ] __main__: train step 16270: loss: 0.9732, policy_loss: 0.9009, value_loss: 0.5466
2024-07-11 17:15:26,683 [INFO    ] __main__: train step 16271: loss: 0.9732, policy_loss: 0.9009, value_loss: 0.5466
2024-07-11 17:15:26,890 [INFO    ] __main__: train step 16272: loss: 0.9732, policy_loss: 0.9009, value_loss: 0.5465
2024-07-11 17:15:27,092 [INFO    ] __main__: train step 16273: loss: 0.9732, policy_loss: 0.9009, value_loss: 0.5465
2024-07-11 17:15:27,308 [INFO    ] __main__: train step 16274: loss: 0.9732, policy_loss: 0.9008, value_loss: 0.5465
2024-07-11 17:15:27,501 [INFO    ] __main__: train step 16275: loss: 0.9732, policy_loss: 0.9008, value_loss: 0.5465
2024-07-11 17:15:27,708 [INFO    ] __main__: train step 16276: loss: 0.9731, policy_loss: 0.9008, value_loss: 0.5465
2024-07-11 17:15:27,906 [INFO    ] __main__: train step 16277: loss: 0.9731, policy_loss: 0.9008, value_loss: 0.5464
2024-07-11 17:15:28,124 [INFO    ] __main__: train step 16278: loss: 0.9731, policy_loss: 0.9007, value_loss: 0.5464
2024-07-11 17:15:28,355 [INFO    ] __main__: train step 16279: loss: 0.9731, policy_loss: 0.9007, value_loss: 0.5464
2024-07-11 17:15:28,547 [INFO    ] __main__: train step 16280: loss: 0.9731, policy_loss: 0.9007, value_loss: 0.5464
2024-07-11 17:15:28,753 [INFO    ] __main__: train step 16281: loss: 0.9731, policy_loss: 0.9007, value_loss: 0.5464
2024-07-11 17:15:28,961 [INFO    ] __main__: train step 16282: loss: 0.9731, policy_loss: 0.9007, value_loss: 0.5464
2024-07-11 17:15:29,165 [INFO    ] __main__: train step 16283: loss: 0.9731, policy_loss: 0.9006, value_loss: 0.5463
2024-07-11 17:15:29,376 [INFO    ] __main__: train step 16284: loss: 0.9731, policy_loss: 0.9006, value_loss: 0.5463
2024-07-11 17:15:29,589 [INFO    ] __main__: train step 16285: loss: 0.9730, policy_loss: 0.9006, value_loss: 0.5463
2024-07-11 17:15:31,027 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:15:31,453 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:15:31,508 [INFO    ] __main__: train step 16286: loss: 0.9730, policy_loss: 0.9006, value_loss: 0.5463
2024-07-11 17:15:31,699 [INFO    ] __main__: train step 16287: loss: 0.9730, policy_loss: 0.9005, value_loss: 0.5463
2024-07-11 17:15:31,912 [INFO    ] __main__: train step 16288: loss: 0.9730, policy_loss: 0.9005, value_loss: 0.5463
2024-07-11 17:15:32,131 [INFO    ] __main__: train step 16289: loss: 0.9730, policy_loss: 0.9005, value_loss: 0.5462
2024-07-11 17:15:32,353 [INFO    ] __main__: train step 16290: loss: 0.9730, policy_loss: 0.9005, value_loss: 0.5462
2024-07-11 17:15:32,549 [INFO    ] __main__: train step 16291: loss: 0.9730, policy_loss: 0.9004, value_loss: 0.5462
2024-07-11 17:15:32,781 [INFO    ] __main__: train step 16292: loss: 0.9730, policy_loss: 0.9004, value_loss: 0.5462
2024-07-11 17:15:33,021 [INFO    ] __main__: train step 16293: loss: 0.9729, policy_loss: 0.9004, value_loss: 0.5462
2024-07-11 17:15:33,221 [INFO    ] __main__: train step 16294: loss: 0.9729, policy_loss: 0.9004, value_loss: 0.5462
2024-07-11 17:15:33,445 [INFO    ] __main__: train step 16295: loss: 0.9729, policy_loss: 0.9004, value_loss: 0.5461
2024-07-11 17:15:33,685 [INFO    ] __main__: train step 16296: loss: 0.9729, policy_loss: 0.9003, value_loss: 0.5461
2024-07-11 17:15:33,884 [INFO    ] __main__: train step 16297: loss: 0.9729, policy_loss: 0.9003, value_loss: 0.5461
2024-07-11 17:15:34,084 [INFO    ] __main__: train step 16298: loss: 0.9729, policy_loss: 0.9003, value_loss: 0.5461
2024-07-11 17:15:34,296 [INFO    ] __main__: train step 16299: loss: 0.9729, policy_loss: 0.9003, value_loss: 0.5461
2024-07-11 17:15:34,506 [INFO    ] __main__: train step 16300: loss: 0.9729, policy_loss: 0.9002, value_loss: 0.5460
2024-07-11 17:15:34,706 [INFO    ] __main__: train step 16301: loss: 0.9729, policy_loss: 0.9002, value_loss: 0.5460
2024-07-11 17:15:34,924 [INFO    ] __main__: train step 16302: loss: 0.9728, policy_loss: 0.9002, value_loss: 0.5460
2024-07-11 17:15:36,322 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:15:36,731 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:15:36,786 [INFO    ] __main__: train step 16303: loss: 0.9728, policy_loss: 0.9002, value_loss: 0.5460
2024-07-11 17:15:36,958 [INFO    ] __main__: train step 16304: loss: 0.9728, policy_loss: 0.9001, value_loss: 0.5460
2024-07-11 17:15:37,161 [INFO    ] __main__: train step 16305: loss: 0.9728, policy_loss: 0.9001, value_loss: 0.5460
2024-07-11 17:15:37,373 [INFO    ] __main__: train step 16306: loss: 0.9728, policy_loss: 0.9001, value_loss: 0.5459
2024-07-11 17:15:37,567 [INFO    ] __main__: train step 16307: loss: 0.9728, policy_loss: 0.9001, value_loss: 0.5459
2024-07-11 17:15:37,769 [INFO    ] __main__: train step 16308: loss: 0.9728, policy_loss: 0.9001, value_loss: 0.5459
2024-07-11 17:15:37,970 [INFO    ] __main__: train step 16309: loss: 0.9728, policy_loss: 0.9000, value_loss: 0.5459
2024-07-11 17:15:38,172 [INFO    ] __main__: train step 16310: loss: 0.9728, policy_loss: 0.9000, value_loss: 0.5459
2024-07-11 17:15:38,393 [INFO    ] __main__: train step 16311: loss: 0.9727, policy_loss: 0.9000, value_loss: 0.5459
2024-07-11 17:15:38,587 [INFO    ] __main__: train step 16312: loss: 0.9727, policy_loss: 0.9000, value_loss: 0.5458
2024-07-11 17:15:38,811 [INFO    ] __main__: train step 16313: loss: 0.9727, policy_loss: 0.8999, value_loss: 0.5458
2024-07-11 17:15:39,037 [INFO    ] __main__: train step 16314: loss: 0.9727, policy_loss: 0.8999, value_loss: 0.5458
2024-07-11 17:15:39,265 [INFO    ] __main__: train step 16315: loss: 0.9727, policy_loss: 0.8999, value_loss: 0.5458
2024-07-11 17:15:39,470 [INFO    ] __main__: train step 16316: loss: 0.9727, policy_loss: 0.8999, value_loss: 0.5458
2024-07-11 17:15:39,681 [INFO    ] __main__: train step 16317: loss: 0.9727, policy_loss: 0.8998, value_loss: 0.5458
2024-07-11 17:15:39,909 [INFO    ] __main__: train step 16318: loss: 0.9727, policy_loss: 0.8998, value_loss: 0.5457
2024-07-11 17:15:40,111 [INFO    ] __main__: train step 16319: loss: 0.9727, policy_loss: 0.8998, value_loss: 0.5457
2024-07-11 17:15:41,494 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:15:41,880 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:15:41,936 [INFO    ] __main__: train step 16320: loss: 0.9726, policy_loss: 0.8998, value_loss: 0.5457
2024-07-11 17:15:42,114 [INFO    ] __main__: train step 16321: loss: 0.9726, policy_loss: 0.8998, value_loss: 0.5457
2024-07-11 17:15:42,350 [INFO    ] __main__: train step 16322: loss: 0.9726, policy_loss: 0.8997, value_loss: 0.5457
2024-07-11 17:15:42,565 [INFO    ] __main__: train step 16323: loss: 0.9726, policy_loss: 0.8997, value_loss: 0.5457
2024-07-11 17:15:42,763 [INFO    ] __main__: train step 16324: loss: 0.9726, policy_loss: 0.8997, value_loss: 0.5456
2024-07-11 17:15:42,963 [INFO    ] __main__: train step 16325: loss: 0.9726, policy_loss: 0.8997, value_loss: 0.5456
2024-07-11 17:15:43,165 [INFO    ] __main__: train step 16326: loss: 0.9726, policy_loss: 0.8996, value_loss: 0.5456
2024-07-11 17:15:43,364 [INFO    ] __main__: train step 16327: loss: 0.9726, policy_loss: 0.8996, value_loss: 0.5456
2024-07-11 17:15:43,575 [INFO    ] __main__: train step 16328: loss: 0.9726, policy_loss: 0.8996, value_loss: 0.5456
2024-07-11 17:15:43,782 [INFO    ] __main__: train step 16329: loss: 0.9725, policy_loss: 0.8996, value_loss: 0.5455
2024-07-11 17:15:43,985 [INFO    ] __main__: train step 16330: loss: 0.9725, policy_loss: 0.8995, value_loss: 0.5455
2024-07-11 17:15:44,209 [INFO    ] __main__: train step 16331: loss: 0.9725, policy_loss: 0.8995, value_loss: 0.5455
2024-07-11 17:15:44,440 [INFO    ] __main__: train step 16332: loss: 0.9725, policy_loss: 0.8995, value_loss: 0.5455
2024-07-11 17:15:44,639 [INFO    ] __main__: train step 16333: loss: 0.9725, policy_loss: 0.8995, value_loss: 0.5455
2024-07-11 17:15:44,849 [INFO    ] __main__: train step 16334: loss: 0.9725, policy_loss: 0.8995, value_loss: 0.5455
2024-07-11 17:15:45,051 [INFO    ] __main__: train step 16335: loss: 0.9725, policy_loss: 0.8994, value_loss: 0.5454
2024-07-11 17:15:45,266 [INFO    ] __main__: train step 16336: loss: 0.9725, policy_loss: 0.8994, value_loss: 0.5454
2024-07-11 17:15:46,665 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:15:47,048 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:15:47,101 [INFO    ] __main__: train step 16337: loss: 0.9725, policy_loss: 0.8994, value_loss: 0.5454
2024-07-11 17:15:47,284 [INFO    ] __main__: train step 16338: loss: 0.9724, policy_loss: 0.8994, value_loss: 0.5454
2024-07-11 17:15:47,494 [INFO    ] __main__: train step 16339: loss: 0.9724, policy_loss: 0.8993, value_loss: 0.5454
2024-07-11 17:15:47,708 [INFO    ] __main__: train step 16340: loss: 0.9724, policy_loss: 0.8993, value_loss: 0.5454
2024-07-11 17:15:47,946 [INFO    ] __main__: train step 16341: loss: 0.9724, policy_loss: 0.8993, value_loss: 0.5453
2024-07-11 17:15:48,150 [INFO    ] __main__: train step 16342: loss: 0.9724, policy_loss: 0.8993, value_loss: 0.5453
2024-07-11 17:15:48,349 [INFO    ] __main__: train step 16343: loss: 0.9724, policy_loss: 0.8993, value_loss: 0.5453
2024-07-11 17:15:48,551 [INFO    ] __main__: train step 16344: loss: 0.9724, policy_loss: 0.8992, value_loss: 0.5453
2024-07-11 17:15:48,761 [INFO    ] __main__: train step 16345: loss: 0.9724, policy_loss: 0.8992, value_loss: 0.5453
2024-07-11 17:15:48,966 [INFO    ] __main__: train step 16346: loss: 0.9724, policy_loss: 0.8992, value_loss: 0.5453
2024-07-11 17:15:49,200 [INFO    ] __main__: train step 16347: loss: 0.9723, policy_loss: 0.8992, value_loss: 0.5452
2024-07-11 17:15:49,395 [INFO    ] __main__: train step 16348: loss: 0.9723, policy_loss: 0.8991, value_loss: 0.5452
2024-07-11 17:15:49,604 [INFO    ] __main__: train step 16349: loss: 0.9723, policy_loss: 0.8991, value_loss: 0.5452
2024-07-11 17:15:49,810 [INFO    ] __main__: train step 16350: loss: 0.9723, policy_loss: 0.8991, value_loss: 0.5452
2024-07-11 17:15:50,034 [INFO    ] __main__: train step 16351: loss: 0.9723, policy_loss: 0.8991, value_loss: 0.5452
2024-07-11 17:15:50,267 [INFO    ] __main__: train step 16352: loss: 0.9723, policy_loss: 0.8990, value_loss: 0.5452
2024-07-11 17:15:50,475 [INFO    ] __main__: train step 16353: loss: 0.9723, policy_loss: 0.8990, value_loss: 0.5451
2024-07-11 17:15:51,926 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:15:52,365 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:15:52,431 [INFO    ] __main__: train step 16354: loss: 0.9723, policy_loss: 0.8990, value_loss: 0.5451
2024-07-11 17:15:52,607 [INFO    ] __main__: train step 16355: loss: 0.9723, policy_loss: 0.8990, value_loss: 0.5451
2024-07-11 17:15:52,808 [INFO    ] __main__: train step 16356: loss: 0.9722, policy_loss: 0.8990, value_loss: 0.5451
2024-07-11 17:15:53,006 [INFO    ] __main__: train step 16357: loss: 0.9722, policy_loss: 0.8989, value_loss: 0.5451
2024-07-11 17:15:53,199 [INFO    ] __main__: train step 16358: loss: 0.9722, policy_loss: 0.8989, value_loss: 0.5451
2024-07-11 17:15:53,416 [INFO    ] __main__: train step 16359: loss: 0.9722, policy_loss: 0.8989, value_loss: 0.5450
2024-07-11 17:15:53,615 [INFO    ] __main__: train step 16360: loss: 0.9722, policy_loss: 0.8989, value_loss: 0.5450
2024-07-11 17:15:53,835 [INFO    ] __main__: train step 16361: loss: 0.9722, policy_loss: 0.8988, value_loss: 0.5450
2024-07-11 17:15:54,033 [INFO    ] __main__: train step 16362: loss: 0.9722, policy_loss: 0.8988, value_loss: 0.5450
2024-07-11 17:15:54,249 [INFO    ] __main__: train step 16363: loss: 0.9722, policy_loss: 0.8988, value_loss: 0.5450
2024-07-11 17:15:54,446 [INFO    ] __main__: train step 16364: loss: 0.9722, policy_loss: 0.8988, value_loss: 0.5450
2024-07-11 17:15:54,647 [INFO    ] __main__: train step 16365: loss: 0.9721, policy_loss: 0.8987, value_loss: 0.5449
2024-07-11 17:15:54,857 [INFO    ] __main__: train step 16366: loss: 0.9721, policy_loss: 0.8987, value_loss: 0.5449
2024-07-11 17:15:55,063 [INFO    ] __main__: train step 16367: loss: 0.9721, policy_loss: 0.8987, value_loss: 0.5449
2024-07-11 17:15:55,265 [INFO    ] __main__: train step 16368: loss: 0.9721, policy_loss: 0.8987, value_loss: 0.5449
2024-07-11 17:15:57,230 [INFO    ] __main__: train step 16369: loss: 0.9721, policy_loss: 0.8987, value_loss: 0.5449
2024-07-11 17:15:57,446 [INFO    ] __main__: train step 16370: loss: 0.9721, policy_loss: 0.8986, value_loss: 0.5449
2024-07-11 17:15:58,857 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:15:59,239 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:15:59,296 [INFO    ] __main__: train step 16371: loss: 0.9721, policy_loss: 0.8986, value_loss: 0.5448
2024-07-11 17:15:59,481 [INFO    ] __main__: train step 16372: loss: 0.9721, policy_loss: 0.8986, value_loss: 0.5448
2024-07-11 17:15:59,698 [INFO    ] __main__: train step 16373: loss: 0.9721, policy_loss: 0.8986, value_loss: 0.5448
2024-07-11 17:15:59,943 [INFO    ] __main__: train step 16374: loss: 0.9720, policy_loss: 0.8985, value_loss: 0.5448
2024-07-11 17:16:00,183 [INFO    ] __main__: train step 16375: loss: 0.9720, policy_loss: 0.8985, value_loss: 0.5448
2024-07-11 17:16:00,388 [INFO    ] __main__: train step 16376: loss: 0.9720, policy_loss: 0.8985, value_loss: 0.5447
2024-07-11 17:16:00,603 [INFO    ] __main__: train step 16377: loss: 0.9720, policy_loss: 0.8985, value_loss: 0.5447
2024-07-11 17:16:00,835 [INFO    ] __main__: train step 16378: loss: 0.9720, policy_loss: 0.8984, value_loss: 0.5447
2024-07-11 17:16:01,034 [INFO    ] __main__: train step 16379: loss: 0.9720, policy_loss: 0.8984, value_loss: 0.5447
2024-07-11 17:16:01,234 [INFO    ] __main__: train step 16380: loss: 0.9720, policy_loss: 0.8984, value_loss: 0.5447
2024-07-11 17:16:01,437 [INFO    ] __main__: train step 16381: loss: 0.9720, policy_loss: 0.8984, value_loss: 0.5447
2024-07-11 17:16:01,636 [INFO    ] __main__: train step 16382: loss: 0.9720, policy_loss: 0.8984, value_loss: 0.5446
2024-07-11 17:16:01,843 [INFO    ] __main__: train step 16383: loss: 0.9719, policy_loss: 0.8983, value_loss: 0.5446
2024-07-11 17:16:02,037 [INFO    ] __main__: train step 16384: loss: 0.9719, policy_loss: 0.8983, value_loss: 0.5446
2024-07-11 17:16:02,239 [INFO    ] __main__: train step 16385: loss: 0.9719, policy_loss: 0.8983, value_loss: 0.5446
2024-07-11 17:16:02,460 [INFO    ] __main__: train step 16386: loss: 0.9719, policy_loss: 0.8983, value_loss: 0.5446
2024-07-11 17:16:02,691 [INFO    ] __main__: train step 16387: loss: 0.9719, policy_loss: 0.8982, value_loss: 0.5446
2024-07-11 17:16:04,088 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:16:04,470 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:16:04,524 [INFO    ] __main__: train step 16388: loss: 0.9719, policy_loss: 0.8982, value_loss: 0.5445
2024-07-11 17:16:04,693 [INFO    ] __main__: train step 16389: loss: 0.9719, policy_loss: 0.8982, value_loss: 0.5445
2024-07-11 17:16:04,897 [INFO    ] __main__: train step 16390: loss: 0.9719, policy_loss: 0.8982, value_loss: 0.5445
2024-07-11 17:16:05,100 [INFO    ] __main__: train step 16391: loss: 0.9718, policy_loss: 0.8981, value_loss: 0.5445
2024-07-11 17:16:05,303 [INFO    ] __main__: train step 16392: loss: 0.9718, policy_loss: 0.8981, value_loss: 0.5445
2024-07-11 17:16:05,518 [INFO    ] __main__: train step 16393: loss: 0.9718, policy_loss: 0.8981, value_loss: 0.5445
2024-07-11 17:16:05,729 [INFO    ] __main__: train step 16394: loss: 0.9718, policy_loss: 0.8981, value_loss: 0.5444
2024-07-11 17:16:05,974 [INFO    ] __main__: train step 16395: loss: 0.9718, policy_loss: 0.8981, value_loss: 0.5444
2024-07-11 17:16:06,213 [INFO    ] __main__: train step 16396: loss: 0.9718, policy_loss: 0.8980, value_loss: 0.5444
2024-07-11 17:16:06,420 [INFO    ] __main__: train step 16397: loss: 0.9718, policy_loss: 0.8980, value_loss: 0.5444
2024-07-11 17:16:06,629 [INFO    ] __main__: train step 16398: loss: 0.9718, policy_loss: 0.8980, value_loss: 0.5444
2024-07-11 17:16:06,856 [INFO    ] __main__: train step 16399: loss: 0.9718, policy_loss: 0.8980, value_loss: 0.5443
2024-07-11 17:16:07,058 [INFO    ] __main__: train step 16400: loss: 0.9717, policy_loss: 0.8979, value_loss: 0.5443
2024-07-11 17:16:07,273 [INFO    ] __main__: train step 16401: loss: 0.9717, policy_loss: 0.8979, value_loss: 0.5443
2024-07-11 17:16:07,479 [INFO    ] __main__: train step 16402: loss: 0.9717, policy_loss: 0.8979, value_loss: 0.5443
2024-07-11 17:16:07,677 [INFO    ] __main__: train step 16403: loss: 0.9717, policy_loss: 0.8979, value_loss: 0.5443
2024-07-11 17:16:07,888 [INFO    ] __main__: train step 16404: loss: 0.9717, policy_loss: 0.8978, value_loss: 0.5443
2024-07-11 17:16:09,310 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:16:09,693 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:16:09,753 [INFO    ] __main__: train step 16405: loss: 0.9717, policy_loss: 0.8978, value_loss: 0.5443
2024-07-11 17:16:09,932 [INFO    ] __main__: train step 16406: loss: 0.9717, policy_loss: 0.8978, value_loss: 0.5442
2024-07-11 17:16:10,134 [INFO    ] __main__: train step 16407: loss: 0.9717, policy_loss: 0.8978, value_loss: 0.5442
2024-07-11 17:16:10,339 [INFO    ] __main__: train step 16408: loss: 0.9717, policy_loss: 0.8978, value_loss: 0.5442
2024-07-11 17:16:10,547 [INFO    ] __main__: train step 16409: loss: 0.9716, policy_loss: 0.8977, value_loss: 0.5442
2024-07-11 17:16:10,751 [INFO    ] __main__: train step 16410: loss: 0.9716, policy_loss: 0.8977, value_loss: 0.5442
2024-07-11 17:16:10,956 [INFO    ] __main__: train step 16411: loss: 0.9716, policy_loss: 0.8977, value_loss: 0.5442
2024-07-11 17:16:11,160 [INFO    ] __main__: train step 16412: loss: 0.9716, policy_loss: 0.8977, value_loss: 0.5441
2024-07-11 17:16:11,377 [INFO    ] __main__: train step 16413: loss: 0.9716, policy_loss: 0.8976, value_loss: 0.5441
2024-07-11 17:16:11,591 [INFO    ] __main__: train step 16414: loss: 0.9716, policy_loss: 0.8976, value_loss: 0.5441
2024-07-11 17:16:11,802 [INFO    ] __main__: train step 16415: loss: 0.9716, policy_loss: 0.8976, value_loss: 0.5441
2024-07-11 17:16:12,012 [INFO    ] __main__: train step 16416: loss: 0.9716, policy_loss: 0.8976, value_loss: 0.5441
2024-07-11 17:16:12,220 [INFO    ] __main__: train step 16417: loss: 0.9716, policy_loss: 0.8975, value_loss: 0.5440
2024-07-11 17:16:12,429 [INFO    ] __main__: train step 16418: loss: 0.9715, policy_loss: 0.8975, value_loss: 0.5440
2024-07-11 17:16:12,638 [INFO    ] __main__: train step 16419: loss: 0.9715, policy_loss: 0.8975, value_loss: 0.5440
2024-07-11 17:16:12,880 [INFO    ] __main__: train step 16420: loss: 0.9715, policy_loss: 0.8975, value_loss: 0.5440
2024-07-11 17:16:13,082 [INFO    ] __main__: train step 16421: loss: 0.9715, policy_loss: 0.8975, value_loss: 0.5440
2024-07-11 17:16:14,467 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:16:14,904 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:16:14,959 [INFO    ] __main__: train step 16422: loss: 0.9715, policy_loss: 0.8974, value_loss: 0.5440
2024-07-11 17:16:15,148 [INFO    ] __main__: train step 16423: loss: 0.9715, policy_loss: 0.8974, value_loss: 0.5439
2024-07-11 17:16:15,372 [INFO    ] __main__: train step 16424: loss: 0.9715, policy_loss: 0.8974, value_loss: 0.5439
2024-07-11 17:16:15,565 [INFO    ] __main__: train step 16425: loss: 0.9715, policy_loss: 0.8974, value_loss: 0.5439
2024-07-11 17:16:15,766 [INFO    ] __main__: train step 16426: loss: 0.9715, policy_loss: 0.8973, value_loss: 0.5439
2024-07-11 17:16:15,964 [INFO    ] __main__: train step 16427: loss: 0.9714, policy_loss: 0.8973, value_loss: 0.5439
2024-07-11 17:16:16,164 [INFO    ] __main__: train step 16428: loss: 0.9714, policy_loss: 0.8973, value_loss: 0.5439
2024-07-11 17:16:16,363 [INFO    ] __main__: train step 16429: loss: 0.9714, policy_loss: 0.8973, value_loss: 0.5438
2024-07-11 17:16:16,563 [INFO    ] __main__: train step 16430: loss: 0.9714, policy_loss: 0.8972, value_loss: 0.5438
2024-07-11 17:16:16,774 [INFO    ] __main__: train step 16431: loss: 0.9714, policy_loss: 0.8972, value_loss: 0.5438
2024-07-11 17:16:16,969 [INFO    ] __main__: train step 16432: loss: 0.9714, policy_loss: 0.8972, value_loss: 0.5438
2024-07-11 17:16:17,179 [INFO    ] __main__: train step 16433: loss: 0.9714, policy_loss: 0.8972, value_loss: 0.5438
2024-07-11 17:16:17,408 [INFO    ] __main__: train step 16434: loss: 0.9714, policy_loss: 0.8972, value_loss: 0.5438
2024-07-11 17:16:17,630 [INFO    ] __main__: train step 16435: loss: 0.9713, policy_loss: 0.8971, value_loss: 0.5437
2024-07-11 17:16:17,839 [INFO    ] __main__: train step 16436: loss: 0.9713, policy_loss: 0.8971, value_loss: 0.5437
2024-07-11 17:16:18,058 [INFO    ] __main__: train step 16437: loss: 0.9713, policy_loss: 0.8971, value_loss: 0.5437
2024-07-11 17:16:18,266 [INFO    ] __main__: train step 16438: loss: 0.9713, policy_loss: 0.8971, value_loss: 0.5437
2024-07-11 17:16:19,680 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:16:20,104 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:16:20,162 [INFO    ] __main__: train step 16439: loss: 0.9713, policy_loss: 0.8970, value_loss: 0.5437
2024-07-11 17:16:20,343 [INFO    ] __main__: train step 16440: loss: 0.9713, policy_loss: 0.8970, value_loss: 0.5437
2024-07-11 17:16:20,541 [INFO    ] __main__: train step 16441: loss: 0.9713, policy_loss: 0.8970, value_loss: 0.5436
2024-07-11 17:16:20,764 [INFO    ] __main__: train step 16442: loss: 0.9713, policy_loss: 0.8970, value_loss: 0.5436
2024-07-11 17:16:20,995 [INFO    ] __main__: train step 16443: loss: 0.9713, policy_loss: 0.8969, value_loss: 0.5436
2024-07-11 17:16:21,194 [INFO    ] __main__: train step 16444: loss: 0.9712, policy_loss: 0.8969, value_loss: 0.5436
2024-07-11 17:16:21,403 [INFO    ] __main__: train step 16445: loss: 0.9712, policy_loss: 0.8969, value_loss: 0.5436
2024-07-11 17:16:21,604 [INFO    ] __main__: train step 16446: loss: 0.9712, policy_loss: 0.8969, value_loss: 0.5436
2024-07-11 17:16:21,811 [INFO    ] __main__: train step 16447: loss: 0.9712, policy_loss: 0.8969, value_loss: 0.5435
2024-07-11 17:16:22,024 [INFO    ] __main__: train step 16448: loss: 0.9712, policy_loss: 0.8968, value_loss: 0.5435
2024-07-11 17:16:22,224 [INFO    ] __main__: train step 16449: loss: 0.9712, policy_loss: 0.8968, value_loss: 0.5435
2024-07-11 17:16:22,424 [INFO    ] __main__: train step 16450: loss: 0.9712, policy_loss: 0.8968, value_loss: 0.5435
2024-07-11 17:16:22,634 [INFO    ] __main__: train step 16451: loss: 0.9712, policy_loss: 0.8968, value_loss: 0.5435
2024-07-11 17:16:22,830 [INFO    ] __main__: train step 16452: loss: 0.9711, policy_loss: 0.8967, value_loss: 0.5435
2024-07-11 17:16:23,031 [INFO    ] __main__: train step 16453: loss: 0.9711, policy_loss: 0.8967, value_loss: 0.5434
2024-07-11 17:16:23,227 [INFO    ] __main__: train step 16454: loss: 0.9711, policy_loss: 0.8967, value_loss: 0.5434
2024-07-11 17:16:23,441 [INFO    ] __main__: train step 16455: loss: 0.9711, policy_loss: 0.8967, value_loss: 0.5434
2024-07-11 17:16:24,824 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:16:25,265 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:16:25,326 [INFO    ] __main__: train step 16456: loss: 0.9711, policy_loss: 0.8966, value_loss: 0.5434
2024-07-11 17:16:25,495 [INFO    ] __main__: train step 16457: loss: 0.9711, policy_loss: 0.8966, value_loss: 0.5434
2024-07-11 17:16:25,690 [INFO    ] __main__: train step 16458: loss: 0.9711, policy_loss: 0.8966, value_loss: 0.5434
2024-07-11 17:16:25,895 [INFO    ] __main__: train step 16459: loss: 0.9711, policy_loss: 0.8966, value_loss: 0.5433
2024-07-11 17:16:26,111 [INFO    ] __main__: train step 16460: loss: 0.9711, policy_loss: 0.8966, value_loss: 0.5433
2024-07-11 17:16:26,346 [INFO    ] __main__: train step 16461: loss: 0.9710, policy_loss: 0.8965, value_loss: 0.5433
2024-07-11 17:16:26,545 [INFO    ] __main__: train step 16462: loss: 0.9710, policy_loss: 0.8965, value_loss: 0.5433
2024-07-11 17:16:26,771 [INFO    ] __main__: train step 16463: loss: 0.9710, policy_loss: 0.8965, value_loss: 0.5433
2024-07-11 17:16:26,984 [INFO    ] __main__: train step 16464: loss: 0.9710, policy_loss: 0.8965, value_loss: 0.5433
2024-07-11 17:16:27,200 [INFO    ] __main__: train step 16465: loss: 0.9710, policy_loss: 0.8964, value_loss: 0.5432
2024-07-11 17:16:27,405 [INFO    ] __main__: train step 16466: loss: 0.9710, policy_loss: 0.8964, value_loss: 0.5432
2024-07-11 17:16:27,596 [INFO    ] __main__: train step 16467: loss: 0.9710, policy_loss: 0.8964, value_loss: 0.5432
2024-07-11 17:16:27,803 [INFO    ] __main__: train step 16468: loss: 0.9710, policy_loss: 0.8964, value_loss: 0.5432
2024-07-11 17:16:28,011 [INFO    ] __main__: train step 16469: loss: 0.9710, policy_loss: 0.8963, value_loss: 0.5432
2024-07-11 17:16:28,214 [INFO    ] __main__: train step 16470: loss: 0.9709, policy_loss: 0.8963, value_loss: 0.5432
2024-07-11 17:16:28,411 [INFO    ] __main__: train step 16471: loss: 0.9709, policy_loss: 0.8963, value_loss: 0.5431
2024-07-11 17:16:28,615 [INFO    ] __main__: train step 16472: loss: 0.9709, policy_loss: 0.8963, value_loss: 0.5431
2024-07-11 17:16:30,028 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:16:30,470 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:16:30,527 [INFO    ] __main__: train step 16473: loss: 0.9709, policy_loss: 0.8963, value_loss: 0.5431
2024-07-11 17:16:30,703 [INFO    ] __main__: train step 16474: loss: 0.9709, policy_loss: 0.8962, value_loss: 0.5431
2024-07-11 17:16:30,909 [INFO    ] __main__: train step 16475: loss: 0.9709, policy_loss: 0.8962, value_loss: 0.5431
2024-07-11 17:16:31,119 [INFO    ] __main__: train step 16476: loss: 0.9709, policy_loss: 0.8962, value_loss: 0.5431
2024-07-11 17:16:31,338 [INFO    ] __main__: train step 16477: loss: 0.9709, policy_loss: 0.8962, value_loss: 0.5430
2024-07-11 17:16:31,549 [INFO    ] __main__: train step 16478: loss: 0.9709, policy_loss: 0.8961, value_loss: 0.5430
2024-07-11 17:16:31,754 [INFO    ] __main__: train step 16479: loss: 0.9708, policy_loss: 0.8961, value_loss: 0.5430
2024-07-11 17:16:31,956 [INFO    ] __main__: train step 16480: loss: 0.9708, policy_loss: 0.8961, value_loss: 0.5430
2024-07-11 17:16:32,160 [INFO    ] __main__: train step 16481: loss: 0.9708, policy_loss: 0.8961, value_loss: 0.5430
2024-07-11 17:16:32,399 [INFO    ] __main__: train step 16482: loss: 0.9708, policy_loss: 0.8960, value_loss: 0.5430
2024-07-11 17:16:34,368 [INFO    ] __main__: train step 16483: loss: 0.9708, policy_loss: 0.8960, value_loss: 0.5429
2024-07-11 17:16:34,591 [INFO    ] __main__: train step 16484: loss: 0.9708, policy_loss: 0.8960, value_loss: 0.5429
2024-07-11 17:16:34,794 [INFO    ] __main__: train step 16485: loss: 0.9708, policy_loss: 0.8960, value_loss: 0.5429
2024-07-11 17:16:34,995 [INFO    ] __main__: train step 16486: loss: 0.9708, policy_loss: 0.8960, value_loss: 0.5429
2024-07-11 17:16:35,198 [INFO    ] __main__: train step 16487: loss: 0.9708, policy_loss: 0.8959, value_loss: 0.5429
2024-07-11 17:16:35,415 [INFO    ] __main__: train step 16488: loss: 0.9708, policy_loss: 0.8959, value_loss: 0.5429
2024-07-11 17:16:35,655 [INFO    ] __main__: train step 16489: loss: 0.9707, policy_loss: 0.8959, value_loss: 0.5428
2024-07-11 17:16:37,088 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:16:37,506 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:16:37,566 [INFO    ] __main__: train step 16490: loss: 0.9707, policy_loss: 0.8959, value_loss: 0.5428
2024-07-11 17:16:37,743 [INFO    ] __main__: train step 16491: loss: 0.9707, policy_loss: 0.8958, value_loss: 0.5428
2024-07-11 17:16:37,941 [INFO    ] __main__: train step 16492: loss: 0.9707, policy_loss: 0.8958, value_loss: 0.5428
2024-07-11 17:16:38,143 [INFO    ] __main__: train step 16493: loss: 0.9707, policy_loss: 0.8958, value_loss: 0.5428
2024-07-11 17:16:38,348 [INFO    ] __main__: train step 16494: loss: 0.9707, policy_loss: 0.8958, value_loss: 0.5428
2024-07-11 17:16:38,564 [INFO    ] __main__: train step 16495: loss: 0.9707, policy_loss: 0.8957, value_loss: 0.5427
2024-07-11 17:16:38,796 [INFO    ] __main__: train step 16496: loss: 0.9707, policy_loss: 0.8957, value_loss: 0.5427
2024-07-11 17:16:38,992 [INFO    ] __main__: train step 16497: loss: 0.9706, policy_loss: 0.8957, value_loss: 0.5427
2024-07-11 17:16:39,204 [INFO    ] __main__: train step 16498: loss: 0.9706, policy_loss: 0.8957, value_loss: 0.5427
2024-07-11 17:16:39,440 [INFO    ] __main__: train step 16499: loss: 0.9706, policy_loss: 0.8957, value_loss: 0.5427
2024-07-11 17:16:39,671 [INFO    ] __main__: train step 16500: loss: 0.9706, policy_loss: 0.8956, value_loss: 0.5427
2024-07-11 17:16:39,873 [INFO    ] __main__: train step 16501: loss: 0.9706, policy_loss: 0.8956, value_loss: 0.5426
2024-07-11 17:16:40,092 [INFO    ] __main__: train step 16502: loss: 0.9706, policy_loss: 0.8956, value_loss: 0.5426
2024-07-11 17:16:40,290 [INFO    ] __main__: train step 16503: loss: 0.9706, policy_loss: 0.8956, value_loss: 0.5426
2024-07-11 17:16:40,486 [INFO    ] __main__: train step 16504: loss: 0.9706, policy_loss: 0.8955, value_loss: 0.5426
2024-07-11 17:16:40,689 [INFO    ] __main__: train step 16505: loss: 0.9706, policy_loss: 0.8955, value_loss: 0.5426
2024-07-11 17:16:40,888 [INFO    ] __main__: train step 16506: loss: 0.9705, policy_loss: 0.8955, value_loss: 0.5426
2024-07-11 17:16:42,289 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:16:42,671 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:16:42,725 [INFO    ] __main__: train step 16507: loss: 0.9705, policy_loss: 0.8955, value_loss: 0.5425
2024-07-11 17:16:42,908 [INFO    ] __main__: train step 16508: loss: 0.9705, policy_loss: 0.8954, value_loss: 0.5425
2024-07-11 17:16:43,116 [INFO    ] __main__: train step 16509: loss: 0.9705, policy_loss: 0.8954, value_loss: 0.5425
2024-07-11 17:16:43,315 [INFO    ] __main__: train step 16510: loss: 0.9705, policy_loss: 0.8954, value_loss: 0.5425
2024-07-11 17:16:43,525 [INFO    ] __main__: train step 16511: loss: 0.9705, policy_loss: 0.8954, value_loss: 0.5425
2024-07-11 17:16:43,722 [INFO    ] __main__: train step 16512: loss: 0.9705, policy_loss: 0.8954, value_loss: 0.5425
2024-07-11 17:16:43,927 [INFO    ] __main__: train step 16513: loss: 0.9705, policy_loss: 0.8953, value_loss: 0.5424
2024-07-11 17:16:44,131 [INFO    ] __main__: train step 16514: loss: 0.9705, policy_loss: 0.8953, value_loss: 0.5424
2024-07-11 17:16:44,327 [INFO    ] __main__: train step 16515: loss: 0.9704, policy_loss: 0.8953, value_loss: 0.5424
2024-07-11 17:16:44,547 [INFO    ] __main__: train step 16516: loss: 0.9704, policy_loss: 0.8953, value_loss: 0.5424
2024-07-11 17:16:44,743 [INFO    ] __main__: train step 16517: loss: 0.9704, policy_loss: 0.8952, value_loss: 0.5424
2024-07-11 17:16:44,940 [INFO    ] __main__: train step 16518: loss: 0.9704, policy_loss: 0.8952, value_loss: 0.5424
2024-07-11 17:16:45,155 [INFO    ] __main__: train step 16519: loss: 0.9704, policy_loss: 0.8952, value_loss: 0.5423
2024-07-11 17:16:45,346 [INFO    ] __main__: train step 16520: loss: 0.9704, policy_loss: 0.8952, value_loss: 0.5423
2024-07-11 17:16:45,548 [INFO    ] __main__: train step 16521: loss: 0.9704, policy_loss: 0.8951, value_loss: 0.5423
2024-07-11 17:16:45,749 [INFO    ] __main__: train step 16522: loss: 0.9704, policy_loss: 0.8951, value_loss: 0.5423
2024-07-11 17:16:45,953 [INFO    ] __main__: train step 16523: loss: 0.9704, policy_loss: 0.8951, value_loss: 0.5423
2024-07-11 17:16:47,372 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:16:47,812 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:16:47,874 [INFO    ] __main__: train step 16524: loss: 0.9703, policy_loss: 0.8951, value_loss: 0.5423
2024-07-11 17:16:48,056 [INFO    ] __main__: train step 16525: loss: 0.9703, policy_loss: 0.8951, value_loss: 0.5423
2024-07-11 17:16:48,255 [INFO    ] __main__: train step 16526: loss: 0.9703, policy_loss: 0.8950, value_loss: 0.5422
2024-07-11 17:16:48,454 [INFO    ] __main__: train step 16527: loss: 0.9703, policy_loss: 0.8950, value_loss: 0.5422
2024-07-11 17:16:48,660 [INFO    ] __main__: train step 16528: loss: 0.9703, policy_loss: 0.8950, value_loss: 0.5422
2024-07-11 17:16:48,862 [INFO    ] __main__: train step 16529: loss: 0.9703, policy_loss: 0.8950, value_loss: 0.5422
2024-07-11 17:16:49,060 [INFO    ] __main__: train step 16530: loss: 0.9703, policy_loss: 0.8949, value_loss: 0.5422
2024-07-11 17:16:49,267 [INFO    ] __main__: train step 16531: loss: 0.9703, policy_loss: 0.8949, value_loss: 0.5422
2024-07-11 17:16:49,466 [INFO    ] __main__: train step 16532: loss: 0.9703, policy_loss: 0.8949, value_loss: 0.5421
2024-07-11 17:16:49,672 [INFO    ] __main__: train step 16533: loss: 0.9702, policy_loss: 0.8949, value_loss: 0.5421
2024-07-11 17:16:49,905 [INFO    ] __main__: train step 16534: loss: 0.9702, policy_loss: 0.8948, value_loss: 0.5421
2024-07-11 17:16:50,110 [INFO    ] __main__: train step 16535: loss: 0.9702, policy_loss: 0.8948, value_loss: 0.5421
2024-07-11 17:16:50,312 [INFO    ] __main__: train step 16536: loss: 0.9702, policy_loss: 0.8948, value_loss: 0.5421
2024-07-11 17:16:50,533 [INFO    ] __main__: train step 16537: loss: 0.9702, policy_loss: 0.8948, value_loss: 0.5421
2024-07-11 17:16:50,768 [INFO    ] __main__: train step 16538: loss: 0.9702, policy_loss: 0.8948, value_loss: 0.5420
2024-07-11 17:16:50,975 [INFO    ] __main__: train step 16539: loss: 0.9702, policy_loss: 0.8947, value_loss: 0.5420
2024-07-11 17:16:51,186 [INFO    ] __main__: train step 16540: loss: 0.9702, policy_loss: 0.8947, value_loss: 0.5420
2024-07-11 17:16:52,573 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:16:53,035 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:16:53,097 [INFO    ] __main__: train step 16541: loss: 0.9702, policy_loss: 0.8947, value_loss: 0.5420
2024-07-11 17:16:53,271 [INFO    ] __main__: train step 16542: loss: 0.9701, policy_loss: 0.8947, value_loss: 0.5420
2024-07-11 17:16:53,491 [INFO    ] __main__: train step 16543: loss: 0.9701, policy_loss: 0.8946, value_loss: 0.5420
2024-07-11 17:16:53,714 [INFO    ] __main__: train step 16544: loss: 0.9701, policy_loss: 0.8946, value_loss: 0.5419
2024-07-11 17:16:53,959 [INFO    ] __main__: train step 16545: loss: 0.9701, policy_loss: 0.8946, value_loss: 0.5419
2024-07-11 17:16:54,173 [INFO    ] __main__: train step 16546: loss: 0.9701, policy_loss: 0.8946, value_loss: 0.5419
2024-07-11 17:16:54,375 [INFO    ] __main__: train step 16547: loss: 0.9701, policy_loss: 0.8945, value_loss: 0.5419
2024-07-11 17:16:54,585 [INFO    ] __main__: train step 16548: loss: 0.9701, policy_loss: 0.8945, value_loss: 0.5419
2024-07-11 17:16:54,793 [INFO    ] __main__: train step 16549: loss: 0.9701, policy_loss: 0.8945, value_loss: 0.5419
2024-07-11 17:16:55,001 [INFO    ] __main__: train step 16550: loss: 0.9701, policy_loss: 0.8945, value_loss: 0.5418
2024-07-11 17:16:55,214 [INFO    ] __main__: train step 16551: loss: 0.9700, policy_loss: 0.8945, value_loss: 0.5418
2024-07-11 17:16:55,409 [INFO    ] __main__: train step 16552: loss: 0.9700, policy_loss: 0.8944, value_loss: 0.5418
2024-07-11 17:16:55,613 [INFO    ] __main__: train step 16553: loss: 0.9700, policy_loss: 0.8944, value_loss: 0.5418
2024-07-11 17:16:55,805 [INFO    ] __main__: train step 16554: loss: 0.9700, policy_loss: 0.8944, value_loss: 0.5418
2024-07-11 17:16:56,002 [INFO    ] __main__: train step 16555: loss: 0.9700, policy_loss: 0.8944, value_loss: 0.5418
2024-07-11 17:16:56,198 [INFO    ] __main__: train step 16556: loss: 0.9700, policy_loss: 0.8943, value_loss: 0.5417
2024-07-11 17:16:56,412 [INFO    ] __main__: train step 16557: loss: 0.9700, policy_loss: 0.8943, value_loss: 0.5417
2024-07-11 17:16:57,790 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:16:58,206 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:16:58,261 [INFO    ] __main__: train step 16558: loss: 0.9700, policy_loss: 0.8943, value_loss: 0.5417
2024-07-11 17:16:58,434 [INFO    ] __main__: train step 16559: loss: 0.9700, policy_loss: 0.8943, value_loss: 0.5417
2024-07-11 17:16:58,637 [INFO    ] __main__: train step 16560: loss: 0.9699, policy_loss: 0.8942, value_loss: 0.5417
2024-07-11 17:16:58,839 [INFO    ] __main__: train step 16561: loss: 0.9699, policy_loss: 0.8942, value_loss: 0.5417
2024-07-11 17:16:59,044 [INFO    ] __main__: train step 16562: loss: 0.9699, policy_loss: 0.8942, value_loss: 0.5417
2024-07-11 17:16:59,243 [INFO    ] __main__: train step 16563: loss: 0.9699, policy_loss: 0.8942, value_loss: 0.5416
2024-07-11 17:16:59,448 [INFO    ] __main__: train step 16564: loss: 0.9699, policy_loss: 0.8941, value_loss: 0.5416
2024-07-11 17:16:59,660 [INFO    ] __main__: train step 16565: loss: 0.9699, policy_loss: 0.8941, value_loss: 0.5416
2024-07-11 17:16:59,860 [INFO    ] __main__: train step 16566: loss: 0.9699, policy_loss: 0.8941, value_loss: 0.5416
2024-07-11 17:17:00,069 [INFO    ] __main__: train step 16567: loss: 0.9699, policy_loss: 0.8941, value_loss: 0.5416
2024-07-11 17:17:00,274 [INFO    ] __main__: train step 16568: loss: 0.9699, policy_loss: 0.8941, value_loss: 0.5416
2024-07-11 17:17:00,515 [INFO    ] __main__: train step 16569: loss: 0.9698, policy_loss: 0.8940, value_loss: 0.5415
2024-07-11 17:17:00,715 [INFO    ] __main__: train step 16570: loss: 0.9698, policy_loss: 0.8940, value_loss: 0.5415
2024-07-11 17:17:00,916 [INFO    ] __main__: train step 16571: loss: 0.9698, policy_loss: 0.8940, value_loss: 0.5415
2024-07-11 17:17:01,125 [INFO    ] __main__: train step 16572: loss: 0.9698, policy_loss: 0.8940, value_loss: 0.5415
2024-07-11 17:17:01,328 [INFO    ] __main__: train step 16573: loss: 0.9698, policy_loss: 0.8939, value_loss: 0.5415
2024-07-11 17:17:01,524 [INFO    ] __main__: train step 16574: loss: 0.9698, policy_loss: 0.8939, value_loss: 0.5415
2024-07-11 17:17:02,970 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:17:03,369 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:17:03,428 [INFO    ] __main__: train step 16575: loss: 0.9698, policy_loss: 0.8939, value_loss: 0.5414
2024-07-11 17:17:03,603 [INFO    ] __main__: train step 16576: loss: 0.9698, policy_loss: 0.8939, value_loss: 0.5414
2024-07-11 17:17:03,802 [INFO    ] __main__: train step 16577: loss: 0.9698, policy_loss: 0.8938, value_loss: 0.5414
2024-07-11 17:17:04,014 [INFO    ] __main__: train step 16578: loss: 0.9697, policy_loss: 0.8938, value_loss: 0.5414
2024-07-11 17:17:04,243 [INFO    ] __main__: train step 16579: loss: 0.9697, policy_loss: 0.8938, value_loss: 0.5414
2024-07-11 17:17:04,455 [INFO    ] __main__: train step 16580: loss: 0.9697, policy_loss: 0.8938, value_loss: 0.5414
2024-07-11 17:17:04,696 [INFO    ] __main__: train step 16581: loss: 0.9697, policy_loss: 0.8938, value_loss: 0.5414
2024-07-11 17:17:04,934 [INFO    ] __main__: train step 16582: loss: 0.9697, policy_loss: 0.8937, value_loss: 0.5413
2024-07-11 17:17:05,136 [INFO    ] __main__: train step 16583: loss: 0.9697, policy_loss: 0.8937, value_loss: 0.5413
2024-07-11 17:17:05,348 [INFO    ] __main__: train step 16584: loss: 0.9697, policy_loss: 0.8937, value_loss: 0.5413
2024-07-11 17:17:05,552 [INFO    ] __main__: train step 16585: loss: 0.9697, policy_loss: 0.8937, value_loss: 0.5413
2024-07-11 17:17:05,750 [INFO    ] __main__: train step 16586: loss: 0.9697, policy_loss: 0.8936, value_loss: 0.5413
2024-07-11 17:17:05,957 [INFO    ] __main__: train step 16587: loss: 0.9696, policy_loss: 0.8936, value_loss: 0.5413
2024-07-11 17:17:06,178 [INFO    ] __main__: train step 16588: loss: 0.9696, policy_loss: 0.8936, value_loss: 0.5412
2024-07-11 17:17:06,377 [INFO    ] __main__: train step 16589: loss: 0.9696, policy_loss: 0.8936, value_loss: 0.5412
2024-07-11 17:17:06,592 [INFO    ] __main__: train step 16590: loss: 0.9696, policy_loss: 0.8935, value_loss: 0.5412
2024-07-11 17:17:06,788 [INFO    ] __main__: train step 16591: loss: 0.9696, policy_loss: 0.8935, value_loss: 0.5412
2024-07-11 17:17:08,196 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:17:08,653 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:17:08,713 [INFO    ] __main__: train step 16592: loss: 0.9696, policy_loss: 0.8935, value_loss: 0.5412
2024-07-11 17:17:08,898 [INFO    ] __main__: train step 16593: loss: 0.9696, policy_loss: 0.8935, value_loss: 0.5412
2024-07-11 17:17:09,099 [INFO    ] __main__: train step 16594: loss: 0.9696, policy_loss: 0.8935, value_loss: 0.5411
2024-07-11 17:17:09,307 [INFO    ] __main__: train step 16595: loss: 0.9696, policy_loss: 0.8934, value_loss: 0.5411
2024-07-11 17:17:09,515 [INFO    ] __main__: train step 16596: loss: 0.9695, policy_loss: 0.8934, value_loss: 0.5411
2024-07-11 17:17:09,717 [INFO    ] __main__: train step 16597: loss: 0.9695, policy_loss: 0.8934, value_loss: 0.5411
2024-07-11 17:17:11,663 [INFO    ] __main__: train step 16598: loss: 0.9695, policy_loss: 0.8934, value_loss: 0.5411
2024-07-11 17:17:11,886 [INFO    ] __main__: train step 16599: loss: 0.9695, policy_loss: 0.8933, value_loss: 0.5411
2024-07-11 17:17:12,130 [INFO    ] __main__: train step 16600: loss: 0.9695, policy_loss: 0.8933, value_loss: 0.5411
2024-07-11 17:17:12,363 [INFO    ] __main__: train step 16601: loss: 0.9695, policy_loss: 0.8933, value_loss: 0.5410
2024-07-11 17:17:12,578 [INFO    ] __main__: train step 16602: loss: 0.9695, policy_loss: 0.8933, value_loss: 0.5410
2024-07-11 17:17:12,786 [INFO    ] __main__: train step 16603: loss: 0.9695, policy_loss: 0.8932, value_loss: 0.5410
2024-07-11 17:17:12,994 [INFO    ] __main__: train step 16604: loss: 0.9695, policy_loss: 0.8932, value_loss: 0.5410
2024-07-11 17:17:13,208 [INFO    ] __main__: train step 16605: loss: 0.9695, policy_loss: 0.8932, value_loss: 0.5410
2024-07-11 17:17:13,410 [INFO    ] __main__: train step 16606: loss: 0.9694, policy_loss: 0.8932, value_loss: 0.5410
2024-07-11 17:17:13,613 [INFO    ] __main__: train step 16607: loss: 0.9694, policy_loss: 0.8932, value_loss: 0.5409
2024-07-11 17:17:13,824 [INFO    ] __main__: train step 16608: loss: 0.9694, policy_loss: 0.8931, value_loss: 0.5409
2024-07-11 17:17:15,237 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:17:15,674 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:17:15,735 [INFO    ] __main__: train step 16609: loss: 0.9694, policy_loss: 0.8931, value_loss: 0.5409
2024-07-11 17:17:15,915 [INFO    ] __main__: train step 16610: loss: 0.9694, policy_loss: 0.8931, value_loss: 0.5409
2024-07-11 17:17:16,154 [INFO    ] __main__: train step 16611: loss: 0.9694, policy_loss: 0.8931, value_loss: 0.5409
2024-07-11 17:17:16,352 [INFO    ] __main__: train step 16612: loss: 0.9694, policy_loss: 0.8930, value_loss: 0.5409
2024-07-11 17:17:16,569 [INFO    ] __main__: train step 16613: loss: 0.9694, policy_loss: 0.8930, value_loss: 0.5408
2024-07-11 17:17:16,788 [INFO    ] __main__: train step 16614: loss: 0.9693, policy_loss: 0.8930, value_loss: 0.5408
2024-07-11 17:17:16,998 [INFO    ] __main__: train step 16615: loss: 0.9693, policy_loss: 0.8930, value_loss: 0.5408
2024-07-11 17:17:17,202 [INFO    ] __main__: train step 16616: loss: 0.9693, policy_loss: 0.8929, value_loss: 0.5408
2024-07-11 17:17:17,413 [INFO    ] __main__: train step 16617: loss: 0.9693, policy_loss: 0.8929, value_loss: 0.5408
2024-07-11 17:17:17,625 [INFO    ] __main__: train step 16618: loss: 0.9693, policy_loss: 0.8929, value_loss: 0.5408
2024-07-11 17:17:17,820 [INFO    ] __main__: train step 16619: loss: 0.9693, policy_loss: 0.8929, value_loss: 0.5408
2024-07-11 17:17:18,024 [INFO    ] __main__: train step 16620: loss: 0.9693, policy_loss: 0.8928, value_loss: 0.5407
2024-07-11 17:17:18,241 [INFO    ] __main__: train step 16621: loss: 0.9693, policy_loss: 0.8928, value_loss: 0.5407
2024-07-11 17:17:18,442 [INFO    ] __main__: train step 16622: loss: 0.9693, policy_loss: 0.8928, value_loss: 0.5407
2024-07-11 17:17:18,698 [INFO    ] __main__: train step 16623: loss: 0.9692, policy_loss: 0.8928, value_loss: 0.5407
2024-07-11 17:17:18,939 [INFO    ] __main__: train step 16624: loss: 0.9692, policy_loss: 0.8928, value_loss: 0.5407
2024-07-11 17:17:19,150 [INFO    ] __main__: train step 16625: loss: 0.9692, policy_loss: 0.8927, value_loss: 0.5407
2024-07-11 17:17:20,634 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:17:21,073 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:17:21,128 [INFO    ] __main__: train step 16626: loss: 0.9692, policy_loss: 0.8927, value_loss: 0.5406
2024-07-11 17:17:21,313 [INFO    ] __main__: train step 16627: loss: 0.9692, policy_loss: 0.8927, value_loss: 0.5406
2024-07-11 17:17:21,515 [INFO    ] __main__: train step 16628: loss: 0.9692, policy_loss: 0.8927, value_loss: 0.5406
2024-07-11 17:17:21,752 [INFO    ] __main__: train step 16629: loss: 0.9692, policy_loss: 0.8926, value_loss: 0.5406
2024-07-11 17:17:21,953 [INFO    ] __main__: train step 16630: loss: 0.9692, policy_loss: 0.8926, value_loss: 0.5406
2024-07-11 17:17:22,154 [INFO    ] __main__: train step 16631: loss: 0.9692, policy_loss: 0.8926, value_loss: 0.5406
2024-07-11 17:17:22,382 [INFO    ] __main__: train step 16632: loss: 0.9691, policy_loss: 0.8926, value_loss: 0.5405
2024-07-11 17:17:22,579 [INFO    ] __main__: train step 16633: loss: 0.9691, policy_loss: 0.8925, value_loss: 0.5405
2024-07-11 17:17:22,774 [INFO    ] __main__: train step 16634: loss: 0.9691, policy_loss: 0.8925, value_loss: 0.5405
2024-07-11 17:17:22,974 [INFO    ] __main__: train step 16635: loss: 0.9691, policy_loss: 0.8925, value_loss: 0.5405
2024-07-11 17:17:23,181 [INFO    ] __main__: train step 16636: loss: 0.9691, policy_loss: 0.8925, value_loss: 0.5405
2024-07-11 17:17:23,382 [INFO    ] __main__: train step 16637: loss: 0.9691, policy_loss: 0.8925, value_loss: 0.5405
2024-07-11 17:17:23,609 [INFO    ] __main__: train step 16638: loss: 0.9691, policy_loss: 0.8924, value_loss: 0.5405
2024-07-11 17:17:23,843 [INFO    ] __main__: train step 16639: loss: 0.9691, policy_loss: 0.8924, value_loss: 0.5404
2024-07-11 17:17:24,045 [INFO    ] __main__: train step 16640: loss: 0.9691, policy_loss: 0.8924, value_loss: 0.5404
2024-07-11 17:17:24,250 [INFO    ] __main__: train step 16641: loss: 0.9690, policy_loss: 0.8924, value_loss: 0.5404
2024-07-11 17:17:24,454 [INFO    ] __main__: train step 16642: loss: 0.9690, policy_loss: 0.8923, value_loss: 0.5404
2024-07-11 17:17:25,865 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:17:26,310 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:17:26,372 [INFO    ] __main__: train step 16643: loss: 0.9690, policy_loss: 0.8923, value_loss: 0.5404
2024-07-11 17:17:26,554 [INFO    ] __main__: train step 16644: loss: 0.9690, policy_loss: 0.8923, value_loss: 0.5404
2024-07-11 17:17:26,764 [INFO    ] __main__: train step 16645: loss: 0.9690, policy_loss: 0.8923, value_loss: 0.5403
2024-07-11 17:17:27,006 [INFO    ] __main__: train step 16646: loss: 0.9690, policy_loss: 0.8922, value_loss: 0.5403
2024-07-11 17:17:27,217 [INFO    ] __main__: train step 16647: loss: 0.9690, policy_loss: 0.8922, value_loss: 0.5403
2024-07-11 17:17:27,419 [INFO    ] __main__: train step 16648: loss: 0.9690, policy_loss: 0.8922, value_loss: 0.5403
2024-07-11 17:17:27,619 [INFO    ] __main__: train step 16649: loss: 0.9690, policy_loss: 0.8922, value_loss: 0.5403
2024-07-11 17:17:27,824 [INFO    ] __main__: train step 16650: loss: 0.9689, policy_loss: 0.8921, value_loss: 0.5403
2024-07-11 17:17:28,025 [INFO    ] __main__: train step 16651: loss: 0.9689, policy_loss: 0.8921, value_loss: 0.5402
2024-07-11 17:17:28,224 [INFO    ] __main__: train step 16652: loss: 0.9689, policy_loss: 0.8921, value_loss: 0.5402
2024-07-11 17:17:28,429 [INFO    ] __main__: train step 16653: loss: 0.9689, policy_loss: 0.8921, value_loss: 0.5402
2024-07-11 17:17:28,631 [INFO    ] __main__: train step 16654: loss: 0.9689, policy_loss: 0.8921, value_loss: 0.5402
2024-07-11 17:17:28,832 [INFO    ] __main__: train step 16655: loss: 0.9689, policy_loss: 0.8920, value_loss: 0.5402
2024-07-11 17:17:29,047 [INFO    ] __main__: train step 16656: loss: 0.9689, policy_loss: 0.8920, value_loss: 0.5402
2024-07-11 17:17:29,245 [INFO    ] __main__: train step 16657: loss: 0.9689, policy_loss: 0.8920, value_loss: 0.5402
2024-07-11 17:17:29,461 [INFO    ] __main__: train step 16658: loss: 0.9689, policy_loss: 0.8920, value_loss: 0.5401
2024-07-11 17:17:29,692 [INFO    ] __main__: train step 16659: loss: 0.9688, policy_loss: 0.8919, value_loss: 0.5401
2024-07-11 17:17:31,149 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:17:31,574 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:17:31,630 [INFO    ] __main__: train step 16660: loss: 0.9688, policy_loss: 0.8919, value_loss: 0.5401
2024-07-11 17:17:31,807 [INFO    ] __main__: train step 16661: loss: 0.9688, policy_loss: 0.8919, value_loss: 0.5401
2024-07-11 17:17:32,021 [INFO    ] __main__: train step 16662: loss: 0.9688, policy_loss: 0.8919, value_loss: 0.5401
2024-07-11 17:17:32,236 [INFO    ] __main__: train step 16663: loss: 0.9688, policy_loss: 0.8918, value_loss: 0.5401
2024-07-11 17:17:32,452 [INFO    ] __main__: train step 16664: loss: 0.9688, policy_loss: 0.8918, value_loss: 0.5400
2024-07-11 17:17:32,672 [INFO    ] __main__: train step 16665: loss: 0.9688, policy_loss: 0.8918, value_loss: 0.5400
2024-07-11 17:17:32,868 [INFO    ] __main__: train step 16666: loss: 0.9688, policy_loss: 0.8918, value_loss: 0.5400
2024-07-11 17:17:33,080 [INFO    ] __main__: train step 16667: loss: 0.9688, policy_loss: 0.8917, value_loss: 0.5400
2024-07-11 17:17:33,282 [INFO    ] __main__: train step 16668: loss: 0.9687, policy_loss: 0.8917, value_loss: 0.5400
2024-07-11 17:17:33,486 [INFO    ] __main__: train step 16669: loss: 0.9687, policy_loss: 0.8917, value_loss: 0.5400
2024-07-11 17:17:33,692 [INFO    ] __main__: train step 16670: loss: 0.9687, policy_loss: 0.8917, value_loss: 0.5400
2024-07-11 17:17:33,888 [INFO    ] __main__: train step 16671: loss: 0.9687, policy_loss: 0.8917, value_loss: 0.5399
2024-07-11 17:17:34,089 [INFO    ] __main__: train step 16672: loss: 0.9687, policy_loss: 0.8916, value_loss: 0.5399
2024-07-11 17:17:34,296 [INFO    ] __main__: train step 16673: loss: 0.9687, policy_loss: 0.8916, value_loss: 0.5399
2024-07-11 17:17:34,514 [INFO    ] __main__: train step 16674: loss: 0.9687, policy_loss: 0.8916, value_loss: 0.5399
2024-07-11 17:17:34,716 [INFO    ] __main__: train step 16675: loss: 0.9687, policy_loss: 0.8916, value_loss: 0.5399
2024-07-11 17:17:34,925 [INFO    ] __main__: train step 16676: loss: 0.9686, policy_loss: 0.8915, value_loss: 0.5399
2024-07-11 17:17:36,349 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:17:36,906 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:17:36,971 [INFO    ] __main__: train step 16677: loss: 0.9686, policy_loss: 0.8915, value_loss: 0.5398
2024-07-11 17:17:37,149 [INFO    ] __main__: train step 16678: loss: 0.9686, policy_loss: 0.8915, value_loss: 0.5398
2024-07-11 17:17:37,354 [INFO    ] __main__: train step 16679: loss: 0.9686, policy_loss: 0.8915, value_loss: 0.5398
2024-07-11 17:17:37,557 [INFO    ] __main__: train step 16680: loss: 0.9686, policy_loss: 0.8914, value_loss: 0.5398
2024-07-11 17:17:37,753 [INFO    ] __main__: train step 16681: loss: 0.9686, policy_loss: 0.8914, value_loss: 0.5398
2024-07-11 17:17:37,964 [INFO    ] __main__: train step 16682: loss: 0.9686, policy_loss: 0.8914, value_loss: 0.5398
2024-07-11 17:17:38,175 [INFO    ] __main__: train step 16683: loss: 0.9686, policy_loss: 0.8914, value_loss: 0.5397
2024-07-11 17:17:38,375 [INFO    ] __main__: train step 16684: loss: 0.9686, policy_loss: 0.8914, value_loss: 0.5397
2024-07-11 17:17:38,588 [INFO    ] __main__: train step 16685: loss: 0.9685, policy_loss: 0.8913, value_loss: 0.5397
2024-07-11 17:17:38,806 [INFO    ] __main__: train step 16686: loss: 0.9685, policy_loss: 0.8913, value_loss: 0.5397
2024-07-11 17:17:39,022 [INFO    ] __main__: train step 16687: loss: 0.9685, policy_loss: 0.8913, value_loss: 0.5397
2024-07-11 17:17:39,220 [INFO    ] __main__: train step 16688: loss: 0.9685, policy_loss: 0.8913, value_loss: 0.5397
2024-07-11 17:17:39,437 [INFO    ] __main__: train step 16689: loss: 0.9685, policy_loss: 0.8912, value_loss: 0.5397
2024-07-11 17:17:39,652 [INFO    ] __main__: train step 16690: loss: 0.9685, policy_loss: 0.8912, value_loss: 0.5396
2024-07-11 17:17:39,845 [INFO    ] __main__: train step 16691: loss: 0.9685, policy_loss: 0.8912, value_loss: 0.5396
2024-07-11 17:17:40,060 [INFO    ] __main__: train step 16692: loss: 0.9685, policy_loss: 0.8912, value_loss: 0.5396
2024-07-11 17:17:40,266 [INFO    ] __main__: train step 16693: loss: 0.9685, policy_loss: 0.8911, value_loss: 0.5396
2024-07-11 17:17:41,675 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:17:42,093 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:17:42,149 [INFO    ] __main__: train step 16694: loss: 0.9684, policy_loss: 0.8911, value_loss: 0.5396
2024-07-11 17:17:42,331 [INFO    ] __main__: train step 16695: loss: 0.9684, policy_loss: 0.8911, value_loss: 0.5396
2024-07-11 17:17:42,530 [INFO    ] __main__: train step 16696: loss: 0.9684, policy_loss: 0.8911, value_loss: 0.5395
2024-07-11 17:17:42,727 [INFO    ] __main__: train step 16697: loss: 0.9684, policy_loss: 0.8910, value_loss: 0.5395
2024-07-11 17:17:42,922 [INFO    ] __main__: train step 16698: loss: 0.9684, policy_loss: 0.8910, value_loss: 0.5395
2024-07-11 17:17:43,127 [INFO    ] __main__: train step 16699: loss: 0.9684, policy_loss: 0.8910, value_loss: 0.5395
2024-07-11 17:17:43,329 [INFO    ] __main__: train step 16700: loss: 0.9684, policy_loss: 0.8910, value_loss: 0.5395
2024-07-11 17:17:43,537 [INFO    ] __main__: train step 16701: loss: 0.9684, policy_loss: 0.8910, value_loss: 0.5395
2024-07-11 17:17:43,750 [INFO    ] __main__: train step 16702: loss: 0.9684, policy_loss: 0.8909, value_loss: 0.5394
2024-07-11 17:17:43,966 [INFO    ] __main__: train step 16703: loss: 0.9683, policy_loss: 0.8909, value_loss: 0.5394
2024-07-11 17:17:44,161 [INFO    ] __main__: train step 16704: loss: 0.9683, policy_loss: 0.8909, value_loss: 0.5394
2024-07-11 17:17:44,385 [INFO    ] __main__: train step 16705: loss: 0.9683, policy_loss: 0.8909, value_loss: 0.5394
2024-07-11 17:17:44,590 [INFO    ] __main__: train step 16706: loss: 0.9683, policy_loss: 0.8908, value_loss: 0.5394
2024-07-11 17:17:44,831 [INFO    ] __main__: train step 16707: loss: 0.9683, policy_loss: 0.8908, value_loss: 0.5394
2024-07-11 17:17:45,038 [INFO    ] __main__: train step 16708: loss: 0.9683, policy_loss: 0.8908, value_loss: 0.5394
2024-07-11 17:17:45,254 [INFO    ] __main__: train step 16709: loss: 0.9683, policy_loss: 0.8908, value_loss: 0.5393
2024-07-11 17:17:45,495 [INFO    ] __main__: train step 16710: loss: 0.9683, policy_loss: 0.8907, value_loss: 0.5393
2024-07-11 17:17:46,938 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:17:47,352 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:17:47,414 [INFO    ] __main__: train step 16711: loss: 0.9683, policy_loss: 0.8907, value_loss: 0.5393
2024-07-11 17:17:47,593 [INFO    ] __main__: train step 16712: loss: 0.9682, policy_loss: 0.8907, value_loss: 0.5393
2024-07-11 17:17:47,800 [INFO    ] __main__: train step 16713: loss: 0.9682, policy_loss: 0.8907, value_loss: 0.5393
2024-07-11 17:17:49,744 [INFO    ] __main__: train step 16714: loss: 0.9682, policy_loss: 0.8906, value_loss: 0.5393
2024-07-11 17:17:49,957 [INFO    ] __main__: train step 16715: loss: 0.9682, policy_loss: 0.8906, value_loss: 0.5392
2024-07-11 17:17:50,167 [INFO    ] __main__: train step 16716: loss: 0.9682, policy_loss: 0.8906, value_loss: 0.5392
2024-07-11 17:17:50,373 [INFO    ] __main__: train step 16717: loss: 0.9682, policy_loss: 0.8906, value_loss: 0.5392
2024-07-11 17:17:50,574 [INFO    ] __main__: train step 16718: loss: 0.9682, policy_loss: 0.8906, value_loss: 0.5392
2024-07-11 17:17:50,799 [INFO    ] __main__: train step 16719: loss: 0.9682, policy_loss: 0.8905, value_loss: 0.5392
2024-07-11 17:17:51,024 [INFO    ] __main__: train step 16720: loss: 0.9682, policy_loss: 0.8905, value_loss: 0.5392
2024-07-11 17:17:51,232 [INFO    ] __main__: train step 16721: loss: 0.9681, policy_loss: 0.8905, value_loss: 0.5392
2024-07-11 17:17:51,437 [INFO    ] __main__: train step 16722: loss: 0.9681, policy_loss: 0.8905, value_loss: 0.5391
2024-07-11 17:17:51,652 [INFO    ] __main__: train step 16723: loss: 0.9681, policy_loss: 0.8904, value_loss: 0.5391
2024-07-11 17:17:51,854 [INFO    ] __main__: train step 16724: loss: 0.9681, policy_loss: 0.8904, value_loss: 0.5391
2024-07-11 17:17:52,071 [INFO    ] __main__: train step 16725: loss: 0.9681, policy_loss: 0.8904, value_loss: 0.5391
2024-07-11 17:17:52,274 [INFO    ] __main__: train step 16726: loss: 0.9681, policy_loss: 0.8904, value_loss: 0.5391
2024-07-11 17:17:52,474 [INFO    ] __main__: train step 16727: loss: 0.9681, policy_loss: 0.8903, value_loss: 0.5391
2024-07-11 17:17:53,885 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:17:54,245 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:17:54,305 [INFO    ] __main__: train step 16728: loss: 0.9681, policy_loss: 0.8903, value_loss: 0.5391
2024-07-11 17:17:54,481 [INFO    ] __main__: train step 16729: loss: 0.9681, policy_loss: 0.8903, value_loss: 0.5390
2024-07-11 17:17:54,685 [INFO    ] __main__: train step 16730: loss: 0.9680, policy_loss: 0.8903, value_loss: 0.5390
2024-07-11 17:17:54,889 [INFO    ] __main__: train step 16731: loss: 0.9680, policy_loss: 0.8902, value_loss: 0.5390
2024-07-11 17:17:55,090 [INFO    ] __main__: train step 16732: loss: 0.9680, policy_loss: 0.8902, value_loss: 0.5390
2024-07-11 17:17:55,335 [INFO    ] __main__: train step 16733: loss: 0.9680, policy_loss: 0.8902, value_loss: 0.5390
2024-07-11 17:17:55,565 [INFO    ] __main__: train step 16734: loss: 0.9680, policy_loss: 0.8902, value_loss: 0.5390
2024-07-11 17:17:55,789 [INFO    ] __main__: train step 16735: loss: 0.9680, policy_loss: 0.8901, value_loss: 0.5389
2024-07-11 17:17:56,029 [INFO    ] __main__: train step 16736: loss: 0.9680, policy_loss: 0.8901, value_loss: 0.5389
2024-07-11 17:17:56,229 [INFO    ] __main__: train step 16737: loss: 0.9680, policy_loss: 0.8901, value_loss: 0.5389
2024-07-11 17:17:56,437 [INFO    ] __main__: train step 16738: loss: 0.9679, policy_loss: 0.8901, value_loss: 0.5389
2024-07-11 17:17:56,638 [INFO    ] __main__: train step 16739: loss: 0.9679, policy_loss: 0.8901, value_loss: 0.5389
2024-07-11 17:17:56,860 [INFO    ] __main__: train step 16740: loss: 0.9679, policy_loss: 0.8900, value_loss: 0.5389
2024-07-11 17:17:57,122 [INFO    ] __main__: train step 16741: loss: 0.9679, policy_loss: 0.8900, value_loss: 0.5389
2024-07-11 17:17:57,322 [INFO    ] __main__: train step 16742: loss: 0.9679, policy_loss: 0.8900, value_loss: 0.5388
2024-07-11 17:17:57,536 [INFO    ] __main__: train step 16743: loss: 0.9679, policy_loss: 0.8900, value_loss: 0.5388
2024-07-11 17:17:57,747 [INFO    ] __main__: train step 16744: loss: 0.9679, policy_loss: 0.8899, value_loss: 0.5388
2024-07-11 17:17:59,174 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:17:59,597 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:17:59,662 [INFO    ] __main__: train step 16745: loss: 0.9679, policy_loss: 0.8899, value_loss: 0.5388
2024-07-11 17:17:59,844 [INFO    ] __main__: train step 16746: loss: 0.9679, policy_loss: 0.8899, value_loss: 0.5388
2024-07-11 17:18:00,093 [INFO    ] __main__: train step 16747: loss: 0.9678, policy_loss: 0.8899, value_loss: 0.5388
2024-07-11 17:18:00,322 [INFO    ] __main__: train step 16748: loss: 0.9678, policy_loss: 0.8898, value_loss: 0.5387
2024-07-11 17:18:00,518 [INFO    ] __main__: train step 16749: loss: 0.9678, policy_loss: 0.8898, value_loss: 0.5387
2024-07-11 17:18:00,713 [INFO    ] __main__: train step 16750: loss: 0.9678, policy_loss: 0.8898, value_loss: 0.5387
2024-07-11 17:18:00,911 [INFO    ] __main__: train step 16751: loss: 0.9678, policy_loss: 0.8898, value_loss: 0.5387
2024-07-11 17:18:01,126 [INFO    ] __main__: train step 16752: loss: 0.9678, policy_loss: 0.8898, value_loss: 0.5387
2024-07-11 17:18:01,315 [INFO    ] __main__: train step 16753: loss: 0.9678, policy_loss: 0.8897, value_loss: 0.5387
2024-07-11 17:18:01,514 [INFO    ] __main__: train step 16754: loss: 0.9678, policy_loss: 0.8897, value_loss: 0.5386
2024-07-11 17:18:01,719 [INFO    ] __main__: train step 16755: loss: 0.9678, policy_loss: 0.8897, value_loss: 0.5386
2024-07-11 17:18:01,920 [INFO    ] __main__: train step 16756: loss: 0.9677, policy_loss: 0.8897, value_loss: 0.5386
2024-07-11 17:18:02,136 [INFO    ] __main__: train step 16757: loss: 0.9677, policy_loss: 0.8896, value_loss: 0.5386
2024-07-11 17:18:02,372 [INFO    ] __main__: train step 16758: loss: 0.9677, policy_loss: 0.8896, value_loss: 0.5386
2024-07-11 17:18:02,585 [INFO    ] __main__: train step 16759: loss: 0.9677, policy_loss: 0.8896, value_loss: 0.5386
2024-07-11 17:18:02,814 [INFO    ] __main__: train step 16760: loss: 0.9677, policy_loss: 0.8896, value_loss: 0.5386
2024-07-11 17:18:03,023 [INFO    ] __main__: train step 16761: loss: 0.9677, policy_loss: 0.8895, value_loss: 0.5385
2024-07-11 17:18:04,445 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:18:04,859 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:18:04,919 [INFO    ] __main__: train step 16762: loss: 0.9677, policy_loss: 0.8895, value_loss: 0.5385
2024-07-11 17:18:05,092 [INFO    ] __main__: train step 16763: loss: 0.9677, policy_loss: 0.8895, value_loss: 0.5385
2024-07-11 17:18:05,287 [INFO    ] __main__: train step 16764: loss: 0.9676, policy_loss: 0.8895, value_loss: 0.5385
2024-07-11 17:18:05,489 [INFO    ] __main__: train step 16765: loss: 0.9676, policy_loss: 0.8894, value_loss: 0.5385
2024-07-11 17:18:05,699 [INFO    ] __main__: train step 16766: loss: 0.9676, policy_loss: 0.8894, value_loss: 0.5385
2024-07-11 17:18:05,895 [INFO    ] __main__: train step 16767: loss: 0.9676, policy_loss: 0.8894, value_loss: 0.5385
2024-07-11 17:18:06,092 [INFO    ] __main__: train step 16768: loss: 0.9676, policy_loss: 0.8894, value_loss: 0.5384
2024-07-11 17:18:06,296 [INFO    ] __main__: train step 16769: loss: 0.9676, policy_loss: 0.8893, value_loss: 0.5384
2024-07-11 17:18:06,513 [INFO    ] __main__: train step 16770: loss: 0.9676, policy_loss: 0.8893, value_loss: 0.5384
2024-07-11 17:18:06,760 [INFO    ] __main__: train step 16771: loss: 0.9676, policy_loss: 0.8893, value_loss: 0.5384
2024-07-11 17:18:06,973 [INFO    ] __main__: train step 16772: loss: 0.9676, policy_loss: 0.8893, value_loss: 0.5384
2024-07-11 17:18:07,168 [INFO    ] __main__: train step 16773: loss: 0.9675, policy_loss: 0.8893, value_loss: 0.5384
2024-07-11 17:18:07,375 [INFO    ] __main__: train step 16774: loss: 0.9675, policy_loss: 0.8892, value_loss: 0.5383
2024-07-11 17:18:07,603 [INFO    ] __main__: train step 16775: loss: 0.9675, policy_loss: 0.8892, value_loss: 0.5383
2024-07-11 17:18:07,808 [INFO    ] __main__: train step 16776: loss: 0.9675, policy_loss: 0.8892, value_loss: 0.5383
2024-07-11 17:18:08,015 [INFO    ] __main__: train step 16777: loss: 0.9675, policy_loss: 0.8892, value_loss: 0.5383
2024-07-11 17:18:08,223 [INFO    ] __main__: train step 16778: loss: 0.9675, policy_loss: 0.8891, value_loss: 0.5383
2024-07-11 17:18:09,645 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:18:10,034 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:18:10,089 [INFO    ] __main__: train step 16779: loss: 0.9675, policy_loss: 0.8891, value_loss: 0.5383
2024-07-11 17:18:10,260 [INFO    ] __main__: train step 16780: loss: 0.9675, policy_loss: 0.8891, value_loss: 0.5382
2024-07-11 17:18:10,467 [INFO    ] __main__: train step 16781: loss: 0.9674, policy_loss: 0.8891, value_loss: 0.5382
2024-07-11 17:18:10,661 [INFO    ] __main__: train step 16782: loss: 0.9674, policy_loss: 0.8890, value_loss: 0.5382
2024-07-11 17:18:10,863 [INFO    ] __main__: train step 16783: loss: 0.9674, policy_loss: 0.8890, value_loss: 0.5382
2024-07-11 17:18:11,071 [INFO    ] __main__: train step 16784: loss: 0.9674, policy_loss: 0.8890, value_loss: 0.5382
2024-07-11 17:18:11,271 [INFO    ] __main__: train step 16785: loss: 0.9674, policy_loss: 0.8890, value_loss: 0.5382
2024-07-11 17:18:11,489 [INFO    ] __main__: train step 16786: loss: 0.9674, policy_loss: 0.8889, value_loss: 0.5382
2024-07-11 17:18:11,689 [INFO    ] __main__: train step 16787: loss: 0.9674, policy_loss: 0.8889, value_loss: 0.5381
2024-07-11 17:18:11,916 [INFO    ] __main__: train step 16788: loss: 0.9674, policy_loss: 0.8889, value_loss: 0.5381
2024-07-11 17:18:12,123 [INFO    ] __main__: train step 16789: loss: 0.9674, policy_loss: 0.8889, value_loss: 0.5381
2024-07-11 17:18:12,332 [INFO    ] __main__: train step 16790: loss: 0.9673, policy_loss: 0.8888, value_loss: 0.5381
2024-07-11 17:18:12,529 [INFO    ] __main__: train step 16791: loss: 0.9673, policy_loss: 0.8888, value_loss: 0.5381
2024-07-11 17:18:12,733 [INFO    ] __main__: train step 16792: loss: 0.9673, policy_loss: 0.8888, value_loss: 0.5381
2024-07-11 17:18:12,942 [INFO    ] __main__: train step 16793: loss: 0.9673, policy_loss: 0.8888, value_loss: 0.5381
2024-07-11 17:18:13,152 [INFO    ] __main__: train step 16794: loss: 0.9673, policy_loss: 0.8888, value_loss: 0.5380
2024-07-11 17:18:13,355 [INFO    ] __main__: train step 16795: loss: 0.9673, policy_loss: 0.8887, value_loss: 0.5380
2024-07-11 17:18:14,751 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:18:15,191 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:18:15,247 [INFO    ] __main__: train step 16796: loss: 0.9673, policy_loss: 0.8887, value_loss: 0.5380
2024-07-11 17:18:15,433 [INFO    ] __main__: train step 16797: loss: 0.9673, policy_loss: 0.8887, value_loss: 0.5380
2024-07-11 17:18:15,627 [INFO    ] __main__: train step 16798: loss: 0.9673, policy_loss: 0.8887, value_loss: 0.5380
2024-07-11 17:18:15,830 [INFO    ] __main__: train step 16799: loss: 0.9672, policy_loss: 0.8886, value_loss: 0.5380
2024-07-11 17:18:16,030 [INFO    ] __main__: train step 16800: loss: 0.9672, policy_loss: 0.8886, value_loss: 0.5379
2024-07-11 17:18:16,233 [INFO    ] __main__: train step 16801: loss: 0.9672, policy_loss: 0.8886, value_loss: 0.5379
2024-07-11 17:18:16,431 [INFO    ] __main__: train step 16802: loss: 0.9672, policy_loss: 0.8886, value_loss: 0.5379
2024-07-11 17:18:16,638 [INFO    ] __main__: train step 16803: loss: 0.9672, policy_loss: 0.8885, value_loss: 0.5379
2024-07-11 17:18:16,838 [INFO    ] __main__: train step 16804: loss: 0.9672, policy_loss: 0.8885, value_loss: 0.5379
2024-07-11 17:18:17,058 [INFO    ] __main__: train step 16805: loss: 0.9672, policy_loss: 0.8885, value_loss: 0.5379
2024-07-11 17:18:17,267 [INFO    ] __main__: train step 16806: loss: 0.9672, policy_loss: 0.8885, value_loss: 0.5378
2024-07-11 17:18:17,486 [INFO    ] __main__: train step 16807: loss: 0.9671, policy_loss: 0.8885, value_loss: 0.5378
2024-07-11 17:18:17,722 [INFO    ] __main__: train step 16808: loss: 0.9671, policy_loss: 0.8884, value_loss: 0.5378
2024-07-11 17:18:17,949 [INFO    ] __main__: train step 16809: loss: 0.9671, policy_loss: 0.8884, value_loss: 0.5378
2024-07-11 17:18:18,186 [INFO    ] __main__: train step 16810: loss: 0.9671, policy_loss: 0.8884, value_loss: 0.5378
2024-07-11 17:18:18,390 [INFO    ] __main__: train step 16811: loss: 0.9671, policy_loss: 0.8884, value_loss: 0.5378
2024-07-11 17:18:18,588 [INFO    ] __main__: train step 16812: loss: 0.9671, policy_loss: 0.8883, value_loss: 0.5378
2024-07-11 17:18:20,025 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:18:20,372 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:18:20,429 [INFO    ] __main__: train step 16813: loss: 0.9671, policy_loss: 0.8883, value_loss: 0.5377
2024-07-11 17:18:20,622 [INFO    ] __main__: train step 16814: loss: 0.9671, policy_loss: 0.8883, value_loss: 0.5377
2024-07-11 17:18:20,834 [INFO    ] __main__: train step 16815: loss: 0.9671, policy_loss: 0.8883, value_loss: 0.5377
2024-07-11 17:18:21,074 [INFO    ] __main__: train step 16816: loss: 0.9670, policy_loss: 0.8882, value_loss: 0.5377
2024-07-11 17:18:21,290 [INFO    ] __main__: train step 16817: loss: 0.9670, policy_loss: 0.8882, value_loss: 0.5377
2024-07-11 17:18:21,487 [INFO    ] __main__: train step 16818: loss: 0.9670, policy_loss: 0.8882, value_loss: 0.5377
2024-07-11 17:18:21,693 [INFO    ] __main__: train step 16819: loss: 0.9670, policy_loss: 0.8882, value_loss: 0.5376
2024-07-11 17:18:21,888 [INFO    ] __main__: train step 16820: loss: 0.9670, policy_loss: 0.8881, value_loss: 0.5376
2024-07-11 17:18:22,096 [INFO    ] __main__: train step 16821: loss: 0.9670, policy_loss: 0.8881, value_loss: 0.5376
2024-07-11 17:18:22,309 [INFO    ] __main__: train step 16822: loss: 0.9670, policy_loss: 0.8881, value_loss: 0.5376
2024-07-11 17:18:22,508 [INFO    ] __main__: train step 16823: loss: 0.9670, policy_loss: 0.8881, value_loss: 0.5376
2024-07-11 17:18:22,705 [INFO    ] __main__: train step 16824: loss: 0.9669, policy_loss: 0.8880, value_loss: 0.5376
2024-07-11 17:18:22,911 [INFO    ] __main__: train step 16825: loss: 0.9669, policy_loss: 0.8880, value_loss: 0.5376
2024-07-11 17:18:23,113 [INFO    ] __main__: train step 16826: loss: 0.9669, policy_loss: 0.8880, value_loss: 0.5375
2024-07-11 17:18:23,319 [INFO    ] __main__: train step 16827: loss: 0.9669, policy_loss: 0.8880, value_loss: 0.5375
2024-07-11 17:18:23,526 [INFO    ] __main__: train step 16828: loss: 0.9669, policy_loss: 0.8880, value_loss: 0.5375
2024-07-11 17:18:23,728 [INFO    ] __main__: train step 16829: loss: 0.9669, policy_loss: 0.8879, value_loss: 0.5375
2024-07-11 17:18:26,853 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:18:27,232 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:18:27,287 [INFO    ] __main__: train step 16830: loss: 0.9669, policy_loss: 0.8879, value_loss: 0.5375
2024-07-11 17:18:27,466 [INFO    ] __main__: train step 16831: loss: 0.9669, policy_loss: 0.8879, value_loss: 0.5375
2024-07-11 17:18:27,681 [INFO    ] __main__: train step 16832: loss: 0.9669, policy_loss: 0.8879, value_loss: 0.5374
2024-07-11 17:18:27,876 [INFO    ] __main__: train step 16833: loss: 0.9668, policy_loss: 0.8878, value_loss: 0.5374
2024-07-11 17:18:28,091 [INFO    ] __main__: train step 16834: loss: 0.9668, policy_loss: 0.8878, value_loss: 0.5374
2024-07-11 17:18:28,289 [INFO    ] __main__: train step 16835: loss: 0.9668, policy_loss: 0.8878, value_loss: 0.5374
2024-07-11 17:18:28,495 [INFO    ] __main__: train step 16836: loss: 0.9668, policy_loss: 0.8878, value_loss: 0.5374
2024-07-11 17:18:28,697 [INFO    ] __main__: train step 16837: loss: 0.9668, policy_loss: 0.8877, value_loss: 0.5374
2024-07-11 17:18:28,910 [INFO    ] __main__: train step 16838: loss: 0.9668, policy_loss: 0.8877, value_loss: 0.5374
2024-07-11 17:18:29,104 [INFO    ] __main__: train step 16839: loss: 0.9668, policy_loss: 0.8877, value_loss: 0.5373
2024-07-11 17:18:29,314 [INFO    ] __main__: train step 16840: loss: 0.9668, policy_loss: 0.8877, value_loss: 0.5373
2024-07-11 17:18:29,528 [INFO    ] __main__: train step 16841: loss: 0.9667, policy_loss: 0.8876, value_loss: 0.5373
2024-07-11 17:18:29,772 [INFO    ] __main__: train step 16842: loss: 0.9667, policy_loss: 0.8876, value_loss: 0.5373
2024-07-11 17:18:29,979 [INFO    ] __main__: train step 16843: loss: 0.9667, policy_loss: 0.8876, value_loss: 0.5373
2024-07-11 17:18:30,200 [INFO    ] __main__: train step 16844: loss: 0.9667, policy_loss: 0.8876, value_loss: 0.5373
2024-07-11 17:18:30,434 [INFO    ] __main__: train step 16845: loss: 0.9667, policy_loss: 0.8875, value_loss: 0.5373
2024-07-11 17:18:30,639 [INFO    ] __main__: train step 16846: loss: 0.9667, policy_loss: 0.8875, value_loss: 0.5372
2024-07-11 17:18:32,050 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:18:32,433 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:18:32,496 [INFO    ] __main__: train step 16847: loss: 0.9667, policy_loss: 0.8875, value_loss: 0.5372
2024-07-11 17:18:32,690 [INFO    ] __main__: train step 16848: loss: 0.9667, policy_loss: 0.8875, value_loss: 0.5372
2024-07-11 17:18:32,936 [INFO    ] __main__: train step 16849: loss: 0.9667, policy_loss: 0.8875, value_loss: 0.5372
2024-07-11 17:18:33,145 [INFO    ] __main__: train step 16850: loss: 0.9666, policy_loss: 0.8874, value_loss: 0.5372
2024-07-11 17:18:33,351 [INFO    ] __main__: train step 16851: loss: 0.9666, policy_loss: 0.8874, value_loss: 0.5372
2024-07-11 17:18:33,558 [INFO    ] __main__: train step 16852: loss: 0.9666, policy_loss: 0.8874, value_loss: 0.5371
2024-07-11 17:18:33,764 [INFO    ] __main__: train step 16853: loss: 0.9666, policy_loss: 0.8874, value_loss: 0.5371
2024-07-11 17:18:33,971 [INFO    ] __main__: train step 16854: loss: 0.9666, policy_loss: 0.8873, value_loss: 0.5371
2024-07-11 17:18:34,183 [INFO    ] __main__: train step 16855: loss: 0.9666, policy_loss: 0.8873, value_loss: 0.5371
2024-07-11 17:18:34,395 [INFO    ] __main__: train step 16856: loss: 0.9666, policy_loss: 0.8873, value_loss: 0.5371
2024-07-11 17:18:34,604 [INFO    ] __main__: train step 16857: loss: 0.9666, policy_loss: 0.8873, value_loss: 0.5371
2024-07-11 17:18:34,812 [INFO    ] __main__: train step 16858: loss: 0.9665, policy_loss: 0.8872, value_loss: 0.5371
2024-07-11 17:18:35,020 [INFO    ] __main__: train step 16859: loss: 0.9665, policy_loss: 0.8872, value_loss: 0.5370
2024-07-11 17:18:35,232 [INFO    ] __main__: train step 16860: loss: 0.9665, policy_loss: 0.8872, value_loss: 0.5370
2024-07-11 17:18:35,434 [INFO    ] __main__: train step 16861: loss: 0.9665, policy_loss: 0.8872, value_loss: 0.5370
2024-07-11 17:18:35,652 [INFO    ] __main__: train step 16862: loss: 0.9665, policy_loss: 0.8871, value_loss: 0.5370
2024-07-11 17:18:35,861 [INFO    ] __main__: train step 16863: loss: 0.9665, policy_loss: 0.8871, value_loss: 0.5370
2024-07-11 17:18:37,277 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:18:37,650 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:18:37,709 [INFO    ] __main__: train step 16864: loss: 0.9665, policy_loss: 0.8871, value_loss: 0.5370
2024-07-11 17:18:37,880 [INFO    ] __main__: train step 16865: loss: 0.9665, policy_loss: 0.8871, value_loss: 0.5369
2024-07-11 17:18:38,084 [INFO    ] __main__: train step 16866: loss: 0.9665, policy_loss: 0.8870, value_loss: 0.5369
2024-07-11 17:18:38,279 [INFO    ] __main__: train step 16867: loss: 0.9664, policy_loss: 0.8870, value_loss: 0.5369
2024-07-11 17:18:38,497 [INFO    ] __main__: train step 16868: loss: 0.9664, policy_loss: 0.8870, value_loss: 0.5369
2024-07-11 17:18:38,733 [INFO    ] __main__: train step 16869: loss: 0.9664, policy_loss: 0.8870, value_loss: 0.5369
2024-07-11 17:18:38,935 [INFO    ] __main__: train step 16870: loss: 0.9664, policy_loss: 0.8870, value_loss: 0.5369
2024-07-11 17:18:39,138 [INFO    ] __main__: train step 16871: loss: 0.9664, policy_loss: 0.8869, value_loss: 0.5369
2024-07-11 17:18:39,345 [INFO    ] __main__: train step 16872: loss: 0.9664, policy_loss: 0.8869, value_loss: 0.5368
2024-07-11 17:18:39,543 [INFO    ] __main__: train step 16873: loss: 0.9664, policy_loss: 0.8869, value_loss: 0.5368
2024-07-11 17:18:39,736 [INFO    ] __main__: train step 16874: loss: 0.9664, policy_loss: 0.8869, value_loss: 0.5368
2024-07-11 17:18:39,934 [INFO    ] __main__: train step 16875: loss: 0.9663, policy_loss: 0.8868, value_loss: 0.5368
2024-07-11 17:18:40,141 [INFO    ] __main__: train step 16876: loss: 0.9663, policy_loss: 0.8868, value_loss: 0.5368
2024-07-11 17:18:40,342 [INFO    ] __main__: train step 16877: loss: 0.9663, policy_loss: 0.8868, value_loss: 0.5368
2024-07-11 17:18:40,547 [INFO    ] __main__: train step 16878: loss: 0.9663, policy_loss: 0.8868, value_loss: 0.5368
2024-07-11 17:18:40,743 [INFO    ] __main__: train step 16879: loss: 0.9663, policy_loss: 0.8867, value_loss: 0.5367
2024-07-11 17:18:40,949 [INFO    ] __main__: train step 16880: loss: 0.9663, policy_loss: 0.8867, value_loss: 0.5367
2024-07-11 17:18:42,364 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:18:42,765 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:18:42,822 [INFO    ] __main__: train step 16881: loss: 0.9663, policy_loss: 0.8867, value_loss: 0.5367
2024-07-11 17:18:42,998 [INFO    ] __main__: train step 16882: loss: 0.9663, policy_loss: 0.8867, value_loss: 0.5367
2024-07-11 17:18:43,213 [INFO    ] __main__: train step 16883: loss: 0.9663, policy_loss: 0.8866, value_loss: 0.5367
2024-07-11 17:18:43,449 [INFO    ] __main__: train step 16884: loss: 0.9662, policy_loss: 0.8866, value_loss: 0.5367
2024-07-11 17:18:43,687 [INFO    ] __main__: train step 16885: loss: 0.9662, policy_loss: 0.8866, value_loss: 0.5366
2024-07-11 17:18:43,922 [INFO    ] __main__: train step 16886: loss: 0.9662, policy_loss: 0.8866, value_loss: 0.5366
2024-07-11 17:18:44,123 [INFO    ] __main__: train step 16887: loss: 0.9662, policy_loss: 0.8865, value_loss: 0.5366
2024-07-11 17:18:44,335 [INFO    ] __main__: train step 16888: loss: 0.9662, policy_loss: 0.8865, value_loss: 0.5366
2024-07-11 17:18:44,549 [INFO    ] __main__: train step 16889: loss: 0.9662, policy_loss: 0.8865, value_loss: 0.5366
2024-07-11 17:18:44,749 [INFO    ] __main__: train step 16890: loss: 0.9662, policy_loss: 0.8865, value_loss: 0.5366
2024-07-11 17:18:44,955 [INFO    ] __main__: train step 16891: loss: 0.9662, policy_loss: 0.8865, value_loss: 0.5366
2024-07-11 17:18:45,166 [INFO    ] __main__: train step 16892: loss: 0.9661, policy_loss: 0.8864, value_loss: 0.5365
2024-07-11 17:18:45,396 [INFO    ] __main__: train step 16893: loss: 0.9661, policy_loss: 0.8864, value_loss: 0.5365
2024-07-11 17:18:45,604 [INFO    ] __main__: train step 16894: loss: 0.9661, policy_loss: 0.8864, value_loss: 0.5365
2024-07-11 17:18:45,795 [INFO    ] __main__: train step 16895: loss: 0.9661, policy_loss: 0.8864, value_loss: 0.5365
2024-07-11 17:18:45,997 [INFO    ] __main__: train step 16896: loss: 0.9661, policy_loss: 0.8863, value_loss: 0.5365
2024-07-11 17:18:46,194 [INFO    ] __main__: train step 16897: loss: 0.9661, policy_loss: 0.8863, value_loss: 0.5365
2024-07-11 17:18:47,605 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:18:48,035 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:18:48,095 [INFO    ] __main__: train step 16898: loss: 0.9661, policy_loss: 0.8863, value_loss: 0.5365
2024-07-11 17:18:48,274 [INFO    ] __main__: train step 16899: loss: 0.9661, policy_loss: 0.8863, value_loss: 0.5364
2024-07-11 17:18:48,509 [INFO    ] __main__: train step 16900: loss: 0.9660, policy_loss: 0.8862, value_loss: 0.5364
2024-07-11 17:18:48,706 [INFO    ] __main__: train step 16901: loss: 0.9660, policy_loss: 0.8862, value_loss: 0.5364
2024-07-11 17:18:48,921 [INFO    ] __main__: train step 16902: loss: 0.9660, policy_loss: 0.8862, value_loss: 0.5364
2024-07-11 17:18:49,119 [INFO    ] __main__: train step 16903: loss: 0.9660, policy_loss: 0.8862, value_loss: 0.5364
2024-07-11 17:18:49,324 [INFO    ] __main__: train step 16904: loss: 0.9660, policy_loss: 0.8861, value_loss: 0.5364
2024-07-11 17:18:49,537 [INFO    ] __main__: train step 16905: loss: 0.9660, policy_loss: 0.8861, value_loss: 0.5363
2024-07-11 17:18:49,733 [INFO    ] __main__: train step 16906: loss: 0.9660, policy_loss: 0.8861, value_loss: 0.5363
2024-07-11 17:18:49,950 [INFO    ] __main__: train step 16907: loss: 0.9660, policy_loss: 0.8861, value_loss: 0.5363
2024-07-11 17:18:50,145 [INFO    ] __main__: train step 16908: loss: 0.9659, policy_loss: 0.8860, value_loss: 0.5363
2024-07-11 17:18:50,364 [INFO    ] __main__: train step 16909: loss: 0.9659, policy_loss: 0.8860, value_loss: 0.5363
2024-07-11 17:18:50,578 [INFO    ] __main__: train step 16910: loss: 0.9659, policy_loss: 0.8860, value_loss: 0.5363
2024-07-11 17:18:50,804 [INFO    ] __main__: train step 16911: loss: 0.9659, policy_loss: 0.8860, value_loss: 0.5362
2024-07-11 17:18:51,001 [INFO    ] __main__: train step 16912: loss: 0.9659, policy_loss: 0.8860, value_loss: 0.5362
2024-07-11 17:18:51,209 [INFO    ] __main__: train step 16913: loss: 0.9659, policy_loss: 0.8859, value_loss: 0.5362
2024-07-11 17:18:51,408 [INFO    ] __main__: train step 16914: loss: 0.9659, policy_loss: 0.8859, value_loss: 0.5362
2024-07-11 17:18:52,803 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:18:53,236 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:18:53,294 [INFO    ] __main__: train step 16915: loss: 0.9659, policy_loss: 0.8859, value_loss: 0.5362
2024-07-11 17:18:53,489 [INFO    ] __main__: train step 16916: loss: 0.9658, policy_loss: 0.8859, value_loss: 0.5362
2024-07-11 17:18:53,692 [INFO    ] __main__: train step 16917: loss: 0.9658, policy_loss: 0.8858, value_loss: 0.5362
2024-07-11 17:18:53,900 [INFO    ] __main__: train step 16918: loss: 0.9658, policy_loss: 0.8858, value_loss: 0.5361
2024-07-11 17:18:54,109 [INFO    ] __main__: train step 16919: loss: 0.9658, policy_loss: 0.8858, value_loss: 0.5361
2024-07-11 17:18:54,326 [INFO    ] __main__: train step 16920: loss: 0.9658, policy_loss: 0.8858, value_loss: 0.5361
2024-07-11 17:18:54,561 [INFO    ] __main__: train step 16921: loss: 0.9658, policy_loss: 0.8857, value_loss: 0.5361
2024-07-11 17:18:54,775 [INFO    ] __main__: train step 16922: loss: 0.9658, policy_loss: 0.8857, value_loss: 0.5361
2024-07-11 17:18:54,986 [INFO    ] __main__: train step 16923: loss: 0.9658, policy_loss: 0.8857, value_loss: 0.5361
2024-07-11 17:18:55,197 [INFO    ] __main__: train step 16924: loss: 0.9657, policy_loss: 0.8857, value_loss: 0.5360
2024-07-11 17:18:55,412 [INFO    ] __main__: train step 16925: loss: 0.9657, policy_loss: 0.8856, value_loss: 0.5360
2024-07-11 17:18:55,622 [INFO    ] __main__: train step 16926: loss: 0.9657, policy_loss: 0.8856, value_loss: 0.5360
2024-07-11 17:18:55,809 [INFO    ] __main__: train step 16927: loss: 0.9657, policy_loss: 0.8856, value_loss: 0.5360
2024-07-11 17:18:56,001 [INFO    ] __main__: train step 16928: loss: 0.9657, policy_loss: 0.8856, value_loss: 0.5360
2024-07-11 17:18:56,228 [INFO    ] __main__: train step 16929: loss: 0.9657, policy_loss: 0.8855, value_loss: 0.5360
2024-07-11 17:18:56,429 [INFO    ] __main__: train step 16930: loss: 0.9657, policy_loss: 0.8855, value_loss: 0.5360
2024-07-11 17:18:56,644 [INFO    ] __main__: train step 16931: loss: 0.9657, policy_loss: 0.8855, value_loss: 0.5359
2024-07-11 17:18:58,162 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:18:58,594 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:18:58,653 [INFO    ] __main__: train step 16932: loss: 0.9656, policy_loss: 0.8855, value_loss: 0.5359
2024-07-11 17:18:58,830 [INFO    ] __main__: train step 16933: loss: 0.9656, policy_loss: 0.8854, value_loss: 0.5359
2024-07-11 17:18:59,037 [INFO    ] __main__: train step 16934: loss: 0.9656, policy_loss: 0.8854, value_loss: 0.5359
2024-07-11 17:18:59,244 [INFO    ] __main__: train step 16935: loss: 0.9656, policy_loss: 0.8854, value_loss: 0.5359
2024-07-11 17:18:59,463 [INFO    ] __main__: train step 16936: loss: 0.9656, policy_loss: 0.8854, value_loss: 0.5359
2024-07-11 17:18:59,657 [INFO    ] __main__: train step 16937: loss: 0.9656, policy_loss: 0.8853, value_loss: 0.5358
2024-07-11 17:18:59,874 [INFO    ] __main__: train step 16938: loss: 0.9656, policy_loss: 0.8853, value_loss: 0.5358
2024-07-11 17:19:00,082 [INFO    ] __main__: train step 16939: loss: 0.9656, policy_loss: 0.8853, value_loss: 0.5358
2024-07-11 17:19:00,290 [INFO    ] __main__: train step 16940: loss: 0.9655, policy_loss: 0.8853, value_loss: 0.5358
2024-07-11 17:19:00,489 [INFO    ] __main__: train step 16941: loss: 0.9655, policy_loss: 0.8853, value_loss: 0.5358
2024-07-11 17:19:00,694 [INFO    ] __main__: train step 16942: loss: 0.9655, policy_loss: 0.8852, value_loss: 0.5358
2024-07-11 17:19:00,900 [INFO    ] __main__: train step 16943: loss: 0.9655, policy_loss: 0.8852, value_loss: 0.5358
2024-07-11 17:19:01,107 [INFO    ] __main__: train step 16944: loss: 0.9655, policy_loss: 0.8852, value_loss: 0.5357
2024-07-11 17:19:03,003 [INFO    ] __main__: train step 16945: loss: 0.9655, policy_loss: 0.8852, value_loss: 0.5357
2024-07-11 17:19:03,217 [INFO    ] __main__: train step 16946: loss: 0.9655, policy_loss: 0.8851, value_loss: 0.5357
2024-07-11 17:19:03,424 [INFO    ] __main__: train step 16947: loss: 0.9655, policy_loss: 0.8851, value_loss: 0.5357
2024-07-11 17:19:03,633 [INFO    ] __main__: train step 16948: loss: 0.9654, policy_loss: 0.8851, value_loss: 0.5357
2024-07-11 17:19:05,033 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:19:05,462 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:19:05,525 [INFO    ] __main__: train step 16949: loss: 0.9654, policy_loss: 0.8851, value_loss: 0.5357
2024-07-11 17:19:05,704 [INFO    ] __main__: train step 16950: loss: 0.9654, policy_loss: 0.8850, value_loss: 0.5356
2024-07-11 17:19:05,918 [INFO    ] __main__: train step 16951: loss: 0.9654, policy_loss: 0.8850, value_loss: 0.5356
2024-07-11 17:19:06,119 [INFO    ] __main__: train step 16952: loss: 0.9654, policy_loss: 0.8850, value_loss: 0.5356
2024-07-11 17:19:06,343 [INFO    ] __main__: train step 16953: loss: 0.9654, policy_loss: 0.8850, value_loss: 0.5356
2024-07-11 17:19:06,539 [INFO    ] __main__: train step 16954: loss: 0.9654, policy_loss: 0.8849, value_loss: 0.5356
2024-07-11 17:19:06,751 [INFO    ] __main__: train step 16955: loss: 0.9654, policy_loss: 0.8849, value_loss: 0.5356
2024-07-11 17:19:06,955 [INFO    ] __main__: train step 16956: loss: 0.9653, policy_loss: 0.8849, value_loss: 0.5356
2024-07-11 17:19:07,161 [INFO    ] __main__: train step 16957: loss: 0.9653, policy_loss: 0.8849, value_loss: 0.5355
2024-07-11 17:19:07,378 [INFO    ] __main__: train step 16958: loss: 0.9653, policy_loss: 0.8848, value_loss: 0.5355
2024-07-11 17:19:07,577 [INFO    ] __main__: train step 16959: loss: 0.9653, policy_loss: 0.8848, value_loss: 0.5355
2024-07-11 17:19:07,779 [INFO    ] __main__: train step 16960: loss: 0.9653, policy_loss: 0.8848, value_loss: 0.5355
2024-07-11 17:19:07,978 [INFO    ] __main__: train step 16961: loss: 0.9653, policy_loss: 0.8848, value_loss: 0.5355
2024-07-11 17:19:08,188 [INFO    ] __main__: train step 16962: loss: 0.9653, policy_loss: 0.8847, value_loss: 0.5355
2024-07-11 17:19:08,400 [INFO    ] __main__: train step 16963: loss: 0.9653, policy_loss: 0.8847, value_loss: 0.5355
2024-07-11 17:19:08,612 [INFO    ] __main__: train step 16964: loss: 0.9652, policy_loss: 0.8847, value_loss: 0.5354
2024-07-11 17:19:08,812 [INFO    ] __main__: train step 16965: loss: 0.9652, policy_loss: 0.8847, value_loss: 0.5354
2024-07-11 17:19:10,231 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:19:10,625 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:19:10,680 [INFO    ] __main__: train step 16966: loss: 0.9652, policy_loss: 0.8847, value_loss: 0.5354
2024-07-11 17:19:10,859 [INFO    ] __main__: train step 16967: loss: 0.9652, policy_loss: 0.8846, value_loss: 0.5354
2024-07-11 17:19:11,065 [INFO    ] __main__: train step 16968: loss: 0.9652, policy_loss: 0.8846, value_loss: 0.5354
2024-07-11 17:19:11,276 [INFO    ] __main__: train step 16969: loss: 0.9652, policy_loss: 0.8846, value_loss: 0.5354
2024-07-11 17:19:11,487 [INFO    ] __main__: train step 16970: loss: 0.9652, policy_loss: 0.8846, value_loss: 0.5353
2024-07-11 17:19:11,692 [INFO    ] __main__: train step 16971: loss: 0.9652, policy_loss: 0.8845, value_loss: 0.5353
2024-07-11 17:19:11,900 [INFO    ] __main__: train step 16972: loss: 0.9651, policy_loss: 0.8845, value_loss: 0.5353
2024-07-11 17:19:12,108 [INFO    ] __main__: train step 16973: loss: 0.9651, policy_loss: 0.8845, value_loss: 0.5353
2024-07-11 17:19:12,313 [INFO    ] __main__: train step 16974: loss: 0.9651, policy_loss: 0.8845, value_loss: 0.5353
2024-07-11 17:19:12,519 [INFO    ] __main__: train step 16975: loss: 0.9651, policy_loss: 0.8844, value_loss: 0.5353
2024-07-11 17:19:12,722 [INFO    ] __main__: train step 16976: loss: 0.9651, policy_loss: 0.8844, value_loss: 0.5352
2024-07-11 17:19:12,929 [INFO    ] __main__: train step 16977: loss: 0.9651, policy_loss: 0.8844, value_loss: 0.5352
2024-07-11 17:19:13,143 [INFO    ] __main__: train step 16978: loss: 0.9651, policy_loss: 0.8844, value_loss: 0.5352
2024-07-11 17:19:13,342 [INFO    ] __main__: train step 16979: loss: 0.9651, policy_loss: 0.8843, value_loss: 0.5352
2024-07-11 17:19:13,539 [INFO    ] __main__: train step 16980: loss: 0.9650, policy_loss: 0.8843, value_loss: 0.5352
2024-07-11 17:19:13,757 [INFO    ] __main__: train step 16981: loss: 0.9650, policy_loss: 0.8843, value_loss: 0.5352
2024-07-11 17:19:13,984 [INFO    ] __main__: train step 16982: loss: 0.9650, policy_loss: 0.8843, value_loss: 0.5352
2024-07-11 17:19:15,400 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:19:15,836 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:19:15,899 [INFO    ] __main__: train step 16983: loss: 0.9650, policy_loss: 0.8842, value_loss: 0.5351
2024-07-11 17:19:16,081 [INFO    ] __main__: train step 16984: loss: 0.9650, policy_loss: 0.8842, value_loss: 0.5351
2024-07-11 17:19:16,278 [INFO    ] __main__: train step 16985: loss: 0.9650, policy_loss: 0.8842, value_loss: 0.5351
2024-07-11 17:19:16,480 [INFO    ] __main__: train step 16986: loss: 0.9650, policy_loss: 0.8842, value_loss: 0.5351
2024-07-11 17:19:16,689 [INFO    ] __main__: train step 16987: loss: 0.9650, policy_loss: 0.8841, value_loss: 0.5351
2024-07-11 17:19:16,886 [INFO    ] __main__: train step 16988: loss: 0.9649, policy_loss: 0.8841, value_loss: 0.5351
2024-07-11 17:19:17,093 [INFO    ] __main__: train step 16989: loss: 0.9649, policy_loss: 0.8841, value_loss: 0.5351
2024-07-11 17:19:17,293 [INFO    ] __main__: train step 16990: loss: 0.9649, policy_loss: 0.8841, value_loss: 0.5350
2024-07-11 17:19:17,498 [INFO    ] __main__: train step 16991: loss: 0.9649, policy_loss: 0.8840, value_loss: 0.5350
2024-07-11 17:19:17,737 [INFO    ] __main__: train step 16992: loss: 0.9649, policy_loss: 0.8840, value_loss: 0.5350
2024-07-11 17:19:17,944 [INFO    ] __main__: train step 16993: loss: 0.9649, policy_loss: 0.8840, value_loss: 0.5350
2024-07-11 17:19:18,175 [INFO    ] __main__: train step 16994: loss: 0.9649, policy_loss: 0.8840, value_loss: 0.5350
2024-07-11 17:19:18,375 [INFO    ] __main__: train step 16995: loss: 0.9649, policy_loss: 0.8839, value_loss: 0.5350
2024-07-11 17:19:18,579 [INFO    ] __main__: train step 16996: loss: 0.9648, policy_loss: 0.8839, value_loss: 0.5349
2024-07-11 17:19:18,781 [INFO    ] __main__: train step 16997: loss: 0.9648, policy_loss: 0.8839, value_loss: 0.5349
2024-07-11 17:19:18,990 [INFO    ] __main__: train step 16998: loss: 0.9648, policy_loss: 0.8839, value_loss: 0.5349
2024-07-11 17:19:19,213 [INFO    ] __main__: train step 16999: loss: 0.9648, policy_loss: 0.8839, value_loss: 0.5349
2024-07-11 17:19:20,634 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:19:20,924 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:19:20,978 [INFO    ] __main__: train step 17000: loss: 0.9648, policy_loss: 0.8838, value_loss: 0.5349
2024-07-11 17:19:21,061 [INFO    ] __main__: restored step 16000 for evaluation
2024-07-11 17:19:28,881 [INFO    ] __main__: later network ELO difference from earlier network: +66 (+8/-8) ELO from 32000 self-played games
2024-07-11 17:19:28,881 [INFO    ] __main__: game outcomes: W: 18292, D: 295, L: 13413
2024-07-11 17:19:28,882 [INFO    ] __main__: validation_elo_delta: 66, validation_elo: 2516
2024-07-11 17:19:29,378 [INFO    ] __main__: train step 17001: loss: 0.9648, policy_loss: 0.8838, value_loss: 0.5349
2024-07-11 17:19:29,585 [INFO    ] __main__: train step 17002: loss: 0.9648, policy_loss: 0.8838, value_loss: 0.5349
2024-07-11 17:19:29,793 [INFO    ] __main__: train step 17003: loss: 0.9647, policy_loss: 0.8838, value_loss: 0.5348
2024-07-11 17:19:30,002 [INFO    ] __main__: train step 17004: loss: 0.9647, policy_loss: 0.8837, value_loss: 0.5348
2024-07-11 17:19:30,202 [INFO    ] __main__: train step 17005: loss: 0.9647, policy_loss: 0.8837, value_loss: 0.5348
2024-07-11 17:19:30,428 [INFO    ] __main__: train step 17006: loss: 0.9647, policy_loss: 0.8837, value_loss: 0.5348
2024-07-11 17:19:30,636 [INFO    ] __main__: train step 17007: loss: 0.9647, policy_loss: 0.8837, value_loss: 0.5348
2024-07-11 17:19:30,833 [INFO    ] __main__: train step 17008: loss: 0.9647, policy_loss: 0.8836, value_loss: 0.5348
2024-07-11 17:19:31,026 [INFO    ] __main__: train step 17009: loss: 0.9647, policy_loss: 0.8836, value_loss: 0.5347
2024-07-11 17:19:31,232 [INFO    ] __main__: train step 17010: loss: 0.9647, policy_loss: 0.8836, value_loss: 0.5347
2024-07-11 17:19:31,438 [INFO    ] __main__: train step 17011: loss: 0.9646, policy_loss: 0.8836, value_loss: 0.5347
2024-07-11 17:19:31,641 [INFO    ] __main__: train step 17012: loss: 0.9646, policy_loss: 0.8835, value_loss: 0.5347
2024-07-11 17:19:31,839 [INFO    ] __main__: train step 17013: loss: 0.9646, policy_loss: 0.8835, value_loss: 0.5347
2024-07-11 17:19:32,061 [INFO    ] __main__: train step 17014: loss: 0.9646, policy_loss: 0.8835, value_loss: 0.5347
2024-07-11 17:19:32,283 [INFO    ] __main__: train step 17015: loss: 0.9646, policy_loss: 0.8835, value_loss: 0.5347
2024-07-11 17:19:32,494 [INFO    ] __main__: train step 17016: loss: 0.9646, policy_loss: 0.8834, value_loss: 0.5346
2024-07-11 17:19:33,907 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:19:34,314 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:19:34,369 [INFO    ] __main__: train step 17017: loss: 0.9646, policy_loss: 0.8834, value_loss: 0.5346
2024-07-11 17:19:34,543 [INFO    ] __main__: train step 17018: loss: 0.9646, policy_loss: 0.8834, value_loss: 0.5346
2024-07-11 17:19:34,746 [INFO    ] __main__: train step 17019: loss: 0.9645, policy_loss: 0.8834, value_loss: 0.5346
2024-07-11 17:19:34,938 [INFO    ] __main__: train step 17020: loss: 0.9645, policy_loss: 0.8833, value_loss: 0.5346
2024-07-11 17:19:35,147 [INFO    ] __main__: train step 17021: loss: 0.9645, policy_loss: 0.8833, value_loss: 0.5346
2024-07-11 17:19:35,353 [INFO    ] __main__: train step 17022: loss: 0.9645, policy_loss: 0.8833, value_loss: 0.5345
2024-07-11 17:19:35,591 [INFO    ] __main__: train step 17023: loss: 0.9645, policy_loss: 0.8833, value_loss: 0.5345
2024-07-11 17:19:35,800 [INFO    ] __main__: train step 17024: loss: 0.9645, policy_loss: 0.8832, value_loss: 0.5345
2024-07-11 17:19:35,994 [INFO    ] __main__: train step 17025: loss: 0.9645, policy_loss: 0.8832, value_loss: 0.5345
2024-07-11 17:19:36,207 [INFO    ] __main__: train step 17026: loss: 0.9645, policy_loss: 0.8832, value_loss: 0.5345
2024-07-11 17:19:36,433 [INFO    ] __main__: train step 17027: loss: 0.9644, policy_loss: 0.8832, value_loss: 0.5345
2024-07-11 17:19:36,637 [INFO    ] __main__: train step 17028: loss: 0.9644, policy_loss: 0.8831, value_loss: 0.5345
2024-07-11 17:19:36,851 [INFO    ] __main__: train step 17029: loss: 0.9644, policy_loss: 0.8831, value_loss: 0.5344
2024-07-11 17:19:37,051 [INFO    ] __main__: train step 17030: loss: 0.9644, policy_loss: 0.8831, value_loss: 0.5344
2024-07-11 17:19:37,258 [INFO    ] __main__: train step 17031: loss: 0.9644, policy_loss: 0.8831, value_loss: 0.5344
2024-07-11 17:19:37,488 [INFO    ] __main__: train step 17032: loss: 0.9644, policy_loss: 0.8830, value_loss: 0.5344
2024-07-11 17:19:37,690 [INFO    ] __main__: train step 17033: loss: 0.9644, policy_loss: 0.8830, value_loss: 0.5344
2024-07-11 17:19:39,137 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:19:39,541 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:19:39,600 [INFO    ] __main__: train step 17034: loss: 0.9643, policy_loss: 0.8830, value_loss: 0.5344
2024-07-11 17:19:39,770 [INFO    ] __main__: train step 17035: loss: 0.9643, policy_loss: 0.8830, value_loss: 0.5343
2024-07-11 17:19:39,972 [INFO    ] __main__: train step 17036: loss: 0.9643, policy_loss: 0.8829, value_loss: 0.5343
2024-07-11 17:19:40,178 [INFO    ] __main__: train step 17037: loss: 0.9643, policy_loss: 0.8829, value_loss: 0.5343
2024-07-11 17:19:40,380 [INFO    ] __main__: train step 17038: loss: 0.9643, policy_loss: 0.8829, value_loss: 0.5343
2024-07-11 17:19:40,593 [INFO    ] __main__: train step 17039: loss: 0.9643, policy_loss: 0.8829, value_loss: 0.5343
2024-07-11 17:19:40,798 [INFO    ] __main__: train step 17040: loss: 0.9643, policy_loss: 0.8828, value_loss: 0.5343
2024-07-11 17:19:41,008 [INFO    ] __main__: train step 17041: loss: 0.9642, policy_loss: 0.8828, value_loss: 0.5343
2024-07-11 17:19:41,218 [INFO    ] __main__: train step 17042: loss: 0.9642, policy_loss: 0.8828, value_loss: 0.5342
2024-07-11 17:19:41,437 [INFO    ] __main__: train step 17043: loss: 0.9642, policy_loss: 0.8828, value_loss: 0.5342
2024-07-11 17:19:41,662 [INFO    ] __main__: train step 17044: loss: 0.9642, policy_loss: 0.8828, value_loss: 0.5342
2024-07-11 17:19:41,883 [INFO    ] __main__: train step 17045: loss: 0.9642, policy_loss: 0.8827, value_loss: 0.5342
2024-07-11 17:19:42,110 [INFO    ] __main__: train step 17046: loss: 0.9642, policy_loss: 0.8827, value_loss: 0.5342
2024-07-11 17:19:42,315 [INFO    ] __main__: train step 17047: loss: 0.9642, policy_loss: 0.8827, value_loss: 0.5342
2024-07-11 17:19:42,511 [INFO    ] __main__: train step 17048: loss: 0.9642, policy_loss: 0.8827, value_loss: 0.5342
2024-07-11 17:19:42,717 [INFO    ] __main__: train step 17049: loss: 0.9641, policy_loss: 0.8826, value_loss: 0.5341
2024-07-11 17:19:42,925 [INFO    ] __main__: train step 17050: loss: 0.9641, policy_loss: 0.8826, value_loss: 0.5341
2024-07-11 17:19:44,357 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:19:44,748 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:19:44,805 [INFO    ] __main__: train step 17051: loss: 0.9641, policy_loss: 0.8826, value_loss: 0.5341
2024-07-11 17:19:44,987 [INFO    ] __main__: train step 17052: loss: 0.9641, policy_loss: 0.8826, value_loss: 0.5341
2024-07-11 17:19:45,189 [INFO    ] __main__: train step 17053: loss: 0.9641, policy_loss: 0.8825, value_loss: 0.5341
2024-07-11 17:19:45,387 [INFO    ] __main__: train step 17054: loss: 0.9641, policy_loss: 0.8825, value_loss: 0.5341
2024-07-11 17:19:45,594 [INFO    ] __main__: train step 17055: loss: 0.9641, policy_loss: 0.8825, value_loss: 0.5340
2024-07-11 17:19:45,807 [INFO    ] __main__: train step 17056: loss: 0.9641, policy_loss: 0.8825, value_loss: 0.5340
2024-07-11 17:19:46,021 [INFO    ] __main__: train step 17057: loss: 0.9640, policy_loss: 0.8824, value_loss: 0.5340
2024-07-11 17:19:46,228 [INFO    ] __main__: train step 17058: loss: 0.9640, policy_loss: 0.8824, value_loss: 0.5340
2024-07-11 17:19:48,229 [INFO    ] __main__: train step 17059: loss: 0.9640, policy_loss: 0.8824, value_loss: 0.5340
2024-07-11 17:19:48,463 [INFO    ] __main__: train step 17060: loss: 0.9640, policy_loss: 0.8824, value_loss: 0.5340
2024-07-11 17:19:48,694 [INFO    ] __main__: train step 17061: loss: 0.9640, policy_loss: 0.8823, value_loss: 0.5340
2024-07-11 17:19:48,906 [INFO    ] __main__: train step 17062: loss: 0.9640, policy_loss: 0.8823, value_loss: 0.5339
2024-07-11 17:19:49,105 [INFO    ] __main__: train step 17063: loss: 0.9640, policy_loss: 0.8823, value_loss: 0.5339
2024-07-11 17:19:49,309 [INFO    ] __main__: train step 17064: loss: 0.9639, policy_loss: 0.8823, value_loss: 0.5339
2024-07-11 17:19:49,519 [INFO    ] __main__: train step 17065: loss: 0.9639, policy_loss: 0.8822, value_loss: 0.5339
2024-07-11 17:19:49,724 [INFO    ] __main__: train step 17066: loss: 0.9639, policy_loss: 0.8822, value_loss: 0.5339
2024-07-11 17:19:49,928 [INFO    ] __main__: train step 17067: loss: 0.9639, policy_loss: 0.8822, value_loss: 0.5339
2024-07-11 17:19:51,343 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:19:51,623 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:19:51,682 [INFO    ] __main__: train step 17068: loss: 0.9639, policy_loss: 0.8822, value_loss: 0.5338
2024-07-11 17:19:51,853 [INFO    ] __main__: train step 17069: loss: 0.9639, policy_loss: 0.8821, value_loss: 0.5338
2024-07-11 17:19:52,059 [INFO    ] __main__: train step 17070: loss: 0.9639, policy_loss: 0.8821, value_loss: 0.5338
2024-07-11 17:19:52,255 [INFO    ] __main__: train step 17071: loss: 0.9639, policy_loss: 0.8821, value_loss: 0.5338
2024-07-11 17:19:52,466 [INFO    ] __main__: train step 17072: loss: 0.9638, policy_loss: 0.8821, value_loss: 0.5338
2024-07-11 17:19:52,659 [INFO    ] __main__: train step 17073: loss: 0.9638, policy_loss: 0.8820, value_loss: 0.5338
2024-07-11 17:19:52,871 [INFO    ] __main__: train step 17074: loss: 0.9638, policy_loss: 0.8820, value_loss: 0.5338
2024-07-11 17:19:53,093 [INFO    ] __main__: train step 17075: loss: 0.9638, policy_loss: 0.8820, value_loss: 0.5337
2024-07-11 17:19:53,300 [INFO    ] __main__: train step 17076: loss: 0.9638, policy_loss: 0.8820, value_loss: 0.5337
2024-07-11 17:19:53,534 [INFO    ] __main__: train step 17077: loss: 0.9638, policy_loss: 0.8819, value_loss: 0.5337
2024-07-11 17:19:53,765 [INFO    ] __main__: train step 17078: loss: 0.9638, policy_loss: 0.8819, value_loss: 0.5337
2024-07-11 17:19:54,033 [INFO    ] __main__: train step 17079: loss: 0.9638, policy_loss: 0.8819, value_loss: 0.5337
2024-07-11 17:19:54,287 [INFO    ] __main__: train step 17080: loss: 0.9637, policy_loss: 0.8819, value_loss: 0.5337
2024-07-11 17:19:54,493 [INFO    ] __main__: train step 17081: loss: 0.9637, policy_loss: 0.8818, value_loss: 0.5337
2024-07-11 17:19:54,727 [INFO    ] __main__: train step 17082: loss: 0.9637, policy_loss: 0.8818, value_loss: 0.5336
2024-07-11 17:19:54,972 [INFO    ] __main__: train step 17083: loss: 0.9637, policy_loss: 0.8818, value_loss: 0.5336
2024-07-11 17:19:55,210 [INFO    ] __main__: train step 17084: loss: 0.9637, policy_loss: 0.8818, value_loss: 0.5336
2024-07-11 17:19:56,622 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:19:57,039 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:19:57,098 [INFO    ] __main__: train step 17085: loss: 0.9637, policy_loss: 0.8817, value_loss: 0.5336
2024-07-11 17:19:57,287 [INFO    ] __main__: train step 17086: loss: 0.9637, policy_loss: 0.8817, value_loss: 0.5336
2024-07-11 17:19:57,527 [INFO    ] __main__: train step 17087: loss: 0.9636, policy_loss: 0.8817, value_loss: 0.5336
2024-07-11 17:19:57,745 [INFO    ] __main__: train step 17088: loss: 0.9636, policy_loss: 0.8817, value_loss: 0.5335
2024-07-11 17:19:57,974 [INFO    ] __main__: train step 17089: loss: 0.9636, policy_loss: 0.8816, value_loss: 0.5335
2024-07-11 17:19:58,181 [INFO    ] __main__: train step 17090: loss: 0.9636, policy_loss: 0.8816, value_loss: 0.5335
2024-07-11 17:19:58,378 [INFO    ] __main__: train step 17091: loss: 0.9636, policy_loss: 0.8816, value_loss: 0.5335
2024-07-11 17:19:58,586 [INFO    ] __main__: train step 17092: loss: 0.9636, policy_loss: 0.8816, value_loss: 0.5335
2024-07-11 17:19:58,790 [INFO    ] __main__: train step 17093: loss: 0.9636, policy_loss: 0.8816, value_loss: 0.5335
2024-07-11 17:19:58,992 [INFO    ] __main__: train step 17094: loss: 0.9635, policy_loss: 0.8815, value_loss: 0.5335
2024-07-11 17:19:59,212 [INFO    ] __main__: train step 17095: loss: 0.9635, policy_loss: 0.8815, value_loss: 0.5334
2024-07-11 17:19:59,415 [INFO    ] __main__: train step 17096: loss: 0.9635, policy_loss: 0.8815, value_loss: 0.5334
2024-07-11 17:19:59,623 [INFO    ] __main__: train step 17097: loss: 0.9635, policy_loss: 0.8815, value_loss: 0.5334
2024-07-11 17:19:59,834 [INFO    ] __main__: train step 17098: loss: 0.9635, policy_loss: 0.8814, value_loss: 0.5334
2024-07-11 17:20:00,047 [INFO    ] __main__: train step 17099: loss: 0.9635, policy_loss: 0.8814, value_loss: 0.5334
2024-07-11 17:20:00,254 [INFO    ] __main__: train step 17100: loss: 0.9635, policy_loss: 0.8814, value_loss: 0.5334
2024-07-11 17:20:00,458 [INFO    ] __main__: train step 17101: loss: 0.9635, policy_loss: 0.8814, value_loss: 0.5333
2024-07-11 17:20:01,890 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:20:02,231 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:20:02,287 [INFO    ] __main__: train step 17102: loss: 0.9634, policy_loss: 0.8813, value_loss: 0.5333
2024-07-11 17:20:02,495 [INFO    ] __main__: train step 17103: loss: 0.9634, policy_loss: 0.8813, value_loss: 0.5333
2024-07-11 17:20:02,740 [INFO    ] __main__: train step 17104: loss: 0.9634, policy_loss: 0.8813, value_loss: 0.5333
2024-07-11 17:20:02,972 [INFO    ] __main__: train step 17105: loss: 0.9634, policy_loss: 0.8813, value_loss: 0.5333
2024-07-11 17:20:03,185 [INFO    ] __main__: train step 17106: loss: 0.9634, policy_loss: 0.8812, value_loss: 0.5333
2024-07-11 17:20:03,387 [INFO    ] __main__: train step 17107: loss: 0.9634, policy_loss: 0.8812, value_loss: 0.5333
2024-07-11 17:20:03,587 [INFO    ] __main__: train step 17108: loss: 0.9634, policy_loss: 0.8812, value_loss: 0.5332
2024-07-11 17:20:03,805 [INFO    ] __main__: train step 17109: loss: 0.9633, policy_loss: 0.8812, value_loss: 0.5332
2024-07-11 17:20:04,038 [INFO    ] __main__: train step 17110: loss: 0.9633, policy_loss: 0.8811, value_loss: 0.5332
2024-07-11 17:20:04,239 [INFO    ] __main__: train step 17111: loss: 0.9633, policy_loss: 0.8811, value_loss: 0.5332
2024-07-11 17:20:04,450 [INFO    ] __main__: train step 17112: loss: 0.9633, policy_loss: 0.8811, value_loss: 0.5332
2024-07-11 17:20:04,664 [INFO    ] __main__: train step 17113: loss: 0.9633, policy_loss: 0.8811, value_loss: 0.5332
2024-07-11 17:20:04,891 [INFO    ] __main__: train step 17114: loss: 0.9633, policy_loss: 0.8810, value_loss: 0.5331
2024-07-11 17:20:05,086 [INFO    ] __main__: train step 17115: loss: 0.9633, policy_loss: 0.8810, value_loss: 0.5331
2024-07-11 17:20:05,290 [INFO    ] __main__: train step 17116: loss: 0.9632, policy_loss: 0.8810, value_loss: 0.5331
2024-07-11 17:20:05,500 [INFO    ] __main__: train step 17117: loss: 0.9632, policy_loss: 0.8810, value_loss: 0.5331
2024-07-11 17:20:05,750 [INFO    ] __main__: train step 17118: loss: 0.9632, policy_loss: 0.8809, value_loss: 0.5331
2024-07-11 17:20:07,152 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:20:07,543 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:20:07,599 [INFO    ] __main__: train step 17119: loss: 0.9632, policy_loss: 0.8809, value_loss: 0.5331
2024-07-11 17:20:07,772 [INFO    ] __main__: train step 17120: loss: 0.9632, policy_loss: 0.8809, value_loss: 0.5331
2024-07-11 17:20:07,974 [INFO    ] __main__: train step 17121: loss: 0.9632, policy_loss: 0.8809, value_loss: 0.5330
2024-07-11 17:20:08,187 [INFO    ] __main__: train step 17122: loss: 0.9632, policy_loss: 0.8808, value_loss: 0.5330
2024-07-11 17:20:08,383 [INFO    ] __main__: train step 17123: loss: 0.9632, policy_loss: 0.8808, value_loss: 0.5330
2024-07-11 17:20:08,590 [INFO    ] __main__: train step 17124: loss: 0.9631, policy_loss: 0.8808, value_loss: 0.5330
2024-07-11 17:20:08,810 [INFO    ] __main__: train step 17125: loss: 0.9631, policy_loss: 0.8808, value_loss: 0.5330
2024-07-11 17:20:09,036 [INFO    ] __main__: train step 17126: loss: 0.9631, policy_loss: 0.8807, value_loss: 0.5330
2024-07-11 17:20:09,268 [INFO    ] __main__: train step 17127: loss: 0.9631, policy_loss: 0.8807, value_loss: 0.5329
2024-07-11 17:20:09,467 [INFO    ] __main__: train step 17128: loss: 0.9631, policy_loss: 0.8807, value_loss: 0.5329
2024-07-11 17:20:09,673 [INFO    ] __main__: train step 17129: loss: 0.9631, policy_loss: 0.8807, value_loss: 0.5329
2024-07-11 17:20:09,874 [INFO    ] __main__: train step 17130: loss: 0.9631, policy_loss: 0.8806, value_loss: 0.5329
2024-07-11 17:20:10,078 [INFO    ] __main__: train step 17131: loss: 0.9630, policy_loss: 0.8806, value_loss: 0.5329
2024-07-11 17:20:10,289 [INFO    ] __main__: train step 17132: loss: 0.9630, policy_loss: 0.8806, value_loss: 0.5329
2024-07-11 17:20:10,502 [INFO    ] __main__: train step 17133: loss: 0.9630, policy_loss: 0.8806, value_loss: 0.5329
2024-07-11 17:20:10,696 [INFO    ] __main__: train step 17134: loss: 0.9630, policy_loss: 0.8805, value_loss: 0.5328
2024-07-11 17:20:10,915 [INFO    ] __main__: train step 17135: loss: 0.9630, policy_loss: 0.8805, value_loss: 0.5328
2024-07-11 17:20:12,353 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:20:12,758 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:20:12,816 [INFO    ] __main__: train step 17136: loss: 0.9630, policy_loss: 0.8805, value_loss: 0.5328
2024-07-11 17:20:12,993 [INFO    ] __main__: train step 17137: loss: 0.9630, policy_loss: 0.8805, value_loss: 0.5328
2024-07-11 17:20:13,193 [INFO    ] __main__: train step 17138: loss: 0.9629, policy_loss: 0.8804, value_loss: 0.5328
2024-07-11 17:20:13,401 [INFO    ] __main__: train step 17139: loss: 0.9629, policy_loss: 0.8804, value_loss: 0.5328
2024-07-11 17:20:13,603 [INFO    ] __main__: train step 17140: loss: 0.9629, policy_loss: 0.8804, value_loss: 0.5327
2024-07-11 17:20:13,808 [INFO    ] __main__: train step 17141: loss: 0.9629, policy_loss: 0.8804, value_loss: 0.5327
2024-07-11 17:20:14,001 [INFO    ] __main__: train step 17142: loss: 0.9629, policy_loss: 0.8803, value_loss: 0.5327
2024-07-11 17:20:14,208 [INFO    ] __main__: train step 17143: loss: 0.9629, policy_loss: 0.8803, value_loss: 0.5327
2024-07-11 17:20:14,398 [INFO    ] __main__: train step 17144: loss: 0.9629, policy_loss: 0.8803, value_loss: 0.5327
2024-07-11 17:20:14,605 [INFO    ] __main__: train step 17145: loss: 0.9628, policy_loss: 0.8803, value_loss: 0.5327
2024-07-11 17:20:14,830 [INFO    ] __main__: train step 17146: loss: 0.9628, policy_loss: 0.8802, value_loss: 0.5327
2024-07-11 17:20:15,032 [INFO    ] __main__: train step 17147: loss: 0.9628, policy_loss: 0.8802, value_loss: 0.5326
2024-07-11 17:20:15,276 [INFO    ] __main__: train step 17148: loss: 0.9628, policy_loss: 0.8802, value_loss: 0.5326
2024-07-11 17:20:15,505 [INFO    ] __main__: train step 17149: loss: 0.9628, policy_loss: 0.8802, value_loss: 0.5326
2024-07-11 17:20:15,703 [INFO    ] __main__: train step 17150: loss: 0.9628, policy_loss: 0.8801, value_loss: 0.5326
2024-07-11 17:20:15,909 [INFO    ] __main__: train step 17151: loss: 0.9628, policy_loss: 0.8801, value_loss: 0.5326
2024-07-11 17:20:16,120 [INFO    ] __main__: train step 17152: loss: 0.9628, policy_loss: 0.8801, value_loss: 0.5326
2024-07-11 17:20:17,536 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:20:17,929 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:20:17,984 [INFO    ] __main__: train step 17153: loss: 0.9627, policy_loss: 0.8801, value_loss: 0.5325
2024-07-11 17:20:18,182 [INFO    ] __main__: train step 17154: loss: 0.9627, policy_loss: 0.8800, value_loss: 0.5325
2024-07-11 17:20:18,415 [INFO    ] __main__: train step 17155: loss: 0.9627, policy_loss: 0.8800, value_loss: 0.5325
2024-07-11 17:20:18,619 [INFO    ] __main__: train step 17156: loss: 0.9627, policy_loss: 0.8800, value_loss: 0.5325
2024-07-11 17:20:18,818 [INFO    ] __main__: train step 17157: loss: 0.9627, policy_loss: 0.8800, value_loss: 0.5325
2024-07-11 17:20:19,011 [INFO    ] __main__: train step 17158: loss: 0.9627, policy_loss: 0.8799, value_loss: 0.5325
2024-07-11 17:20:19,223 [INFO    ] __main__: train step 17159: loss: 0.9627, policy_loss: 0.8799, value_loss: 0.5325
2024-07-11 17:20:19,425 [INFO    ] __main__: train step 17160: loss: 0.9626, policy_loss: 0.8799, value_loss: 0.5324
2024-07-11 17:20:19,626 [INFO    ] __main__: train step 17161: loss: 0.9626, policy_loss: 0.8799, value_loss: 0.5324
2024-07-11 17:20:19,832 [INFO    ] __main__: train step 17162: loss: 0.9626, policy_loss: 0.8798, value_loss: 0.5324
2024-07-11 17:20:20,039 [INFO    ] __main__: train step 17163: loss: 0.9626, policy_loss: 0.8798, value_loss: 0.5324
2024-07-11 17:20:20,244 [INFO    ] __main__: train step 17164: loss: 0.9626, policy_loss: 0.8798, value_loss: 0.5324
2024-07-11 17:20:20,441 [INFO    ] __main__: train step 17165: loss: 0.9626, policy_loss: 0.8798, value_loss: 0.5324
2024-07-11 17:20:20,658 [INFO    ] __main__: train step 17166: loss: 0.9626, policy_loss: 0.8797, value_loss: 0.5323
2024-07-11 17:20:20,870 [INFO    ] __main__: train step 17167: loss: 0.9625, policy_loss: 0.8797, value_loss: 0.5323
2024-07-11 17:20:21,082 [INFO    ] __main__: train step 17168: loss: 0.9625, policy_loss: 0.8797, value_loss: 0.5323
2024-07-11 17:20:21,290 [INFO    ] __main__: train step 17169: loss: 0.9625, policy_loss: 0.8797, value_loss: 0.5323
2024-07-11 17:20:22,726 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:20:23,084 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:20:23,146 [INFO    ] __main__: train step 17170: loss: 0.9625, policy_loss: 0.8796, value_loss: 0.5323
2024-07-11 17:20:23,326 [INFO    ] __main__: train step 17171: loss: 0.9625, policy_loss: 0.8796, value_loss: 0.5323
2024-07-11 17:20:23,536 [INFO    ] __main__: train step 17172: loss: 0.9625, policy_loss: 0.8796, value_loss: 0.5323
2024-07-11 17:20:23,746 [INFO    ] __main__: train step 17173: loss: 0.9625, policy_loss: 0.8796, value_loss: 0.5322
2024-07-11 17:20:25,668 [INFO    ] __main__: train step 17174: loss: 0.9624, policy_loss: 0.8795, value_loss: 0.5322
2024-07-11 17:20:25,884 [INFO    ] __main__: train step 17175: loss: 0.9624, policy_loss: 0.8795, value_loss: 0.5322
2024-07-11 17:20:26,098 [INFO    ] __main__: train step 17176: loss: 0.9624, policy_loss: 0.8795, value_loss: 0.5322
2024-07-11 17:20:26,299 [INFO    ] __main__: train step 17177: loss: 0.9624, policy_loss: 0.8795, value_loss: 0.5322
2024-07-11 17:20:26,514 [INFO    ] __main__: train step 17178: loss: 0.9624, policy_loss: 0.8794, value_loss: 0.5322
2024-07-11 17:20:26,717 [INFO    ] __main__: train step 17179: loss: 0.9624, policy_loss: 0.8794, value_loss: 0.5322
2024-07-11 17:20:26,923 [INFO    ] __main__: train step 17180: loss: 0.9624, policy_loss: 0.8794, value_loss: 0.5321
2024-07-11 17:20:27,126 [INFO    ] __main__: train step 17181: loss: 0.9623, policy_loss: 0.8794, value_loss: 0.5321
2024-07-11 17:20:27,365 [INFO    ] __main__: train step 17182: loss: 0.9623, policy_loss: 0.8793, value_loss: 0.5321
2024-07-11 17:20:27,564 [INFO    ] __main__: train step 17183: loss: 0.9623, policy_loss: 0.8793, value_loss: 0.5321
2024-07-11 17:20:27,799 [INFO    ] __main__: train step 17184: loss: 0.9623, policy_loss: 0.8793, value_loss: 0.5321
2024-07-11 17:20:28,006 [INFO    ] __main__: train step 17185: loss: 0.9623, policy_loss: 0.8793, value_loss: 0.5321
2024-07-11 17:20:28,214 [INFO    ] __main__: train step 17186: loss: 0.9623, policy_loss: 0.8792, value_loss: 0.5320
2024-07-11 17:20:29,639 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:20:30,049 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:20:30,114 [INFO    ] __main__: train step 17187: loss: 0.9623, policy_loss: 0.8792, value_loss: 0.5320
2024-07-11 17:20:30,301 [INFO    ] __main__: train step 17188: loss: 0.9622, policy_loss: 0.8792, value_loss: 0.5320
2024-07-11 17:20:30,496 [INFO    ] __main__: train step 17189: loss: 0.9622, policy_loss: 0.8792, value_loss: 0.5320
2024-07-11 17:20:30,714 [INFO    ] __main__: train step 17190: loss: 0.9622, policy_loss: 0.8791, value_loss: 0.5320
2024-07-11 17:20:30,947 [INFO    ] __main__: train step 17191: loss: 0.9622, policy_loss: 0.8791, value_loss: 0.5320
2024-07-11 17:20:31,162 [INFO    ] __main__: train step 17192: loss: 0.9622, policy_loss: 0.8791, value_loss: 0.5320
2024-07-11 17:20:31,375 [INFO    ] __main__: train step 17193: loss: 0.9622, policy_loss: 0.8791, value_loss: 0.5319
2024-07-11 17:20:31,593 [INFO    ] __main__: train step 17194: loss: 0.9622, policy_loss: 0.8790, value_loss: 0.5319
2024-07-11 17:20:31,807 [INFO    ] __main__: train step 17195: loss: 0.9621, policy_loss: 0.8790, value_loss: 0.5319
2024-07-11 17:20:32,056 [INFO    ] __main__: train step 17196: loss: 0.9621, policy_loss: 0.8790, value_loss: 0.5319
2024-07-11 17:20:32,263 [INFO    ] __main__: train step 17197: loss: 0.9621, policy_loss: 0.8790, value_loss: 0.5319
2024-07-11 17:20:32,476 [INFO    ] __main__: train step 17198: loss: 0.9621, policy_loss: 0.8789, value_loss: 0.5319
2024-07-11 17:20:32,694 [INFO    ] __main__: train step 17199: loss: 0.9621, policy_loss: 0.8789, value_loss: 0.5318
2024-07-11 17:20:32,909 [INFO    ] __main__: train step 17200: loss: 0.9621, policy_loss: 0.8789, value_loss: 0.5318
2024-07-11 17:20:33,137 [INFO    ] __main__: train step 17201: loss: 0.9621, policy_loss: 0.8789, value_loss: 0.5318
2024-07-11 17:20:33,347 [INFO    ] __main__: train step 17202: loss: 0.9620, policy_loss: 0.8788, value_loss: 0.5318
2024-07-11 17:20:33,549 [INFO    ] __main__: train step 17203: loss: 0.9620, policy_loss: 0.8788, value_loss: 0.5318
2024-07-11 17:20:34,981 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:20:35,398 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:20:35,454 [INFO    ] __main__: train step 17204: loss: 0.9620, policy_loss: 0.8788, value_loss: 0.5318
2024-07-11 17:20:35,632 [INFO    ] __main__: train step 17205: loss: 0.9620, policy_loss: 0.8788, value_loss: 0.5318
2024-07-11 17:20:35,854 [INFO    ] __main__: train step 17206: loss: 0.9620, policy_loss: 0.8787, value_loss: 0.5317
2024-07-11 17:20:36,069 [INFO    ] __main__: train step 17207: loss: 0.9620, policy_loss: 0.8787, value_loss: 0.5317
2024-07-11 17:20:36,282 [INFO    ] __main__: train step 17208: loss: 0.9620, policy_loss: 0.8787, value_loss: 0.5317
2024-07-11 17:20:36,486 [INFO    ] __main__: train step 17209: loss: 0.9619, policy_loss: 0.8787, value_loss: 0.5317
2024-07-11 17:20:36,698 [INFO    ] __main__: train step 17210: loss: 0.9619, policy_loss: 0.8786, value_loss: 0.5317
2024-07-11 17:20:36,908 [INFO    ] __main__: train step 17211: loss: 0.9619, policy_loss: 0.8786, value_loss: 0.5317
2024-07-11 17:20:37,117 [INFO    ] __main__: train step 17212: loss: 0.9619, policy_loss: 0.8786, value_loss: 0.5316
2024-07-11 17:20:37,318 [INFO    ] __main__: train step 17213: loss: 0.9619, policy_loss: 0.8786, value_loss: 0.5316
2024-07-11 17:20:37,523 [INFO    ] __main__: train step 17214: loss: 0.9619, policy_loss: 0.8785, value_loss: 0.5316
2024-07-11 17:20:37,719 [INFO    ] __main__: train step 17215: loss: 0.9618, policy_loss: 0.8785, value_loss: 0.5316
2024-07-11 17:20:37,936 [INFO    ] __main__: train step 17216: loss: 0.9618, policy_loss: 0.8785, value_loss: 0.5316
2024-07-11 17:20:38,140 [INFO    ] __main__: train step 17217: loss: 0.9618, policy_loss: 0.8785, value_loss: 0.5316
2024-07-11 17:20:38,343 [INFO    ] __main__: train step 17218: loss: 0.9618, policy_loss: 0.8784, value_loss: 0.5315
2024-07-11 17:20:38,553 [INFO    ] __main__: train step 17219: loss: 0.9618, policy_loss: 0.8784, value_loss: 0.5315
2024-07-11 17:20:38,771 [INFO    ] __main__: train step 17220: loss: 0.9618, policy_loss: 0.8784, value_loss: 0.5315
2024-07-11 17:20:40,173 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:20:40,576 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:20:40,635 [INFO    ] __main__: train step 17221: loss: 0.9618, policy_loss: 0.8784, value_loss: 0.5315
2024-07-11 17:20:40,820 [INFO    ] __main__: train step 17222: loss: 0.9617, policy_loss: 0.8783, value_loss: 0.5315
2024-07-11 17:20:41,017 [INFO    ] __main__: train step 17223: loss: 0.9617, policy_loss: 0.8783, value_loss: 0.5315
2024-07-11 17:20:41,224 [INFO    ] __main__: train step 17224: loss: 0.9617, policy_loss: 0.8783, value_loss: 0.5315
2024-07-11 17:20:41,428 [INFO    ] __main__: train step 17225: loss: 0.9617, policy_loss: 0.8783, value_loss: 0.5314
2024-07-11 17:20:41,638 [INFO    ] __main__: train step 17226: loss: 0.9617, policy_loss: 0.8782, value_loss: 0.5314
2024-07-11 17:20:41,874 [INFO    ] __main__: train step 17227: loss: 0.9617, policy_loss: 0.8782, value_loss: 0.5314
2024-07-11 17:20:42,076 [INFO    ] __main__: train step 17228: loss: 0.9617, policy_loss: 0.8782, value_loss: 0.5314
2024-07-11 17:20:42,287 [INFO    ] __main__: train step 17229: loss: 0.9616, policy_loss: 0.8782, value_loss: 0.5314
2024-07-11 17:20:42,507 [INFO    ] __main__: train step 17230: loss: 0.9616, policy_loss: 0.8781, value_loss: 0.5314
2024-07-11 17:20:42,753 [INFO    ] __main__: train step 17231: loss: 0.9616, policy_loss: 0.8781, value_loss: 0.5313
2024-07-11 17:20:42,954 [INFO    ] __main__: train step 17232: loss: 0.9616, policy_loss: 0.8781, value_loss: 0.5313
2024-07-11 17:20:43,163 [INFO    ] __main__: train step 17233: loss: 0.9616, policy_loss: 0.8781, value_loss: 0.5313
2024-07-11 17:20:43,409 [INFO    ] __main__: train step 17234: loss: 0.9616, policy_loss: 0.8780, value_loss: 0.5313
2024-07-11 17:20:43,657 [INFO    ] __main__: train step 17235: loss: 0.9616, policy_loss: 0.8780, value_loss: 0.5313
2024-07-11 17:20:43,890 [INFO    ] __main__: train step 17236: loss: 0.9615, policy_loss: 0.8780, value_loss: 0.5313
2024-07-11 17:20:44,102 [INFO    ] __main__: train step 17237: loss: 0.9615, policy_loss: 0.8779, value_loss: 0.5313
2024-07-11 17:20:45,533 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:20:45,891 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:20:45,946 [INFO    ] __main__: train step 17238: loss: 0.9615, policy_loss: 0.8779, value_loss: 0.5312
2024-07-11 17:20:46,142 [INFO    ] __main__: train step 17239: loss: 0.9615, policy_loss: 0.8779, value_loss: 0.5312
2024-07-11 17:20:46,339 [INFO    ] __main__: train step 17240: loss: 0.9615, policy_loss: 0.8779, value_loss: 0.5312
2024-07-11 17:20:46,546 [INFO    ] __main__: train step 17241: loss: 0.9615, policy_loss: 0.8778, value_loss: 0.5312
2024-07-11 17:20:46,762 [INFO    ] __main__: train step 17242: loss: 0.9614, policy_loss: 0.8778, value_loss: 0.5312
2024-07-11 17:20:46,967 [INFO    ] __main__: train step 17243: loss: 0.9614, policy_loss: 0.8778, value_loss: 0.5312
2024-07-11 17:20:47,176 [INFO    ] __main__: train step 17244: loss: 0.9614, policy_loss: 0.8778, value_loss: 0.5311
2024-07-11 17:20:47,408 [INFO    ] __main__: train step 17245: loss: 0.9614, policy_loss: 0.8777, value_loss: 0.5311
2024-07-11 17:20:47,619 [INFO    ] __main__: train step 17246: loss: 0.9614, policy_loss: 0.8777, value_loss: 0.5311
2024-07-11 17:20:47,830 [INFO    ] __main__: train step 17247: loss: 0.9614, policy_loss: 0.8777, value_loss: 0.5311
2024-07-11 17:20:48,026 [INFO    ] __main__: train step 17248: loss: 0.9614, policy_loss: 0.8777, value_loss: 0.5311
2024-07-11 17:20:48,235 [INFO    ] __main__: train step 17249: loss: 0.9613, policy_loss: 0.8776, value_loss: 0.5311
2024-07-11 17:20:48,429 [INFO    ] __main__: train step 17250: loss: 0.9613, policy_loss: 0.8776, value_loss: 0.5311
2024-07-11 17:20:48,632 [INFO    ] __main__: train step 17251: loss: 0.9613, policy_loss: 0.8776, value_loss: 0.5310
2024-07-11 17:20:48,849 [INFO    ] __main__: train step 17252: loss: 0.9613, policy_loss: 0.8776, value_loss: 0.5310
2024-07-11 17:20:49,079 [INFO    ] __main__: train step 17253: loss: 0.9613, policy_loss: 0.8775, value_loss: 0.5310
2024-07-11 17:20:49,273 [INFO    ] __main__: train step 17254: loss: 0.9613, policy_loss: 0.8775, value_loss: 0.5310
2024-07-11 17:20:50,725 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:20:51,105 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:20:51,168 [INFO    ] __main__: train step 17255: loss: 0.9612, policy_loss: 0.8775, value_loss: 0.5310
2024-07-11 17:20:51,342 [INFO    ] __main__: train step 17256: loss: 0.9612, policy_loss: 0.8775, value_loss: 0.5310
2024-07-11 17:20:51,543 [INFO    ] __main__: train step 17257: loss: 0.9612, policy_loss: 0.8774, value_loss: 0.5309
2024-07-11 17:20:51,748 [INFO    ] __main__: train step 17258: loss: 0.9612, policy_loss: 0.8774, value_loss: 0.5309
2024-07-11 17:20:51,957 [INFO    ] __main__: train step 17259: loss: 0.9612, policy_loss: 0.8774, value_loss: 0.5309
2024-07-11 17:20:52,154 [INFO    ] __main__: train step 17260: loss: 0.9612, policy_loss: 0.8774, value_loss: 0.5309
2024-07-11 17:20:52,361 [INFO    ] __main__: train step 17261: loss: 0.9612, policy_loss: 0.8773, value_loss: 0.5309
2024-07-11 17:20:52,574 [INFO    ] __main__: train step 17262: loss: 0.9611, policy_loss: 0.8773, value_loss: 0.5309
2024-07-11 17:20:52,773 [INFO    ] __main__: train step 17263: loss: 0.9611, policy_loss: 0.8773, value_loss: 0.5308
2024-07-11 17:20:52,984 [INFO    ] __main__: train step 17264: loss: 0.9611, policy_loss: 0.8773, value_loss: 0.5308
2024-07-11 17:20:53,194 [INFO    ] __main__: train step 17265: loss: 0.9611, policy_loss: 0.8772, value_loss: 0.5308
2024-07-11 17:20:53,406 [INFO    ] __main__: train step 17266: loss: 0.9611, policy_loss: 0.8772, value_loss: 0.5308
2024-07-11 17:20:53,614 [INFO    ] __main__: train step 17267: loss: 0.9611, policy_loss: 0.8772, value_loss: 0.5308
2024-07-11 17:20:53,826 [INFO    ] __main__: train step 17268: loss: 0.9610, policy_loss: 0.8772, value_loss: 0.5308
2024-07-11 17:20:54,032 [INFO    ] __main__: train step 17269: loss: 0.9610, policy_loss: 0.8771, value_loss: 0.5307
2024-07-11 17:20:54,252 [INFO    ] __main__: train step 17270: loss: 0.9610, policy_loss: 0.8771, value_loss: 0.5307
2024-07-11 17:20:54,446 [INFO    ] __main__: train step 17271: loss: 0.9610, policy_loss: 0.8771, value_loss: 0.5307
2024-07-11 17:20:55,891 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:20:56,247 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:20:56,306 [INFO    ] __main__: train step 17272: loss: 0.9610, policy_loss: 0.8771, value_loss: 0.5307
2024-07-11 17:20:56,483 [INFO    ] __main__: train step 17273: loss: 0.9610, policy_loss: 0.8770, value_loss: 0.5307
2024-07-11 17:20:56,682 [INFO    ] __main__: train step 17274: loss: 0.9609, policy_loss: 0.8770, value_loss: 0.5307
2024-07-11 17:20:56,901 [INFO    ] __main__: train step 17275: loss: 0.9609, policy_loss: 0.8770, value_loss: 0.5307
2024-07-11 17:20:57,107 [INFO    ] __main__: train step 17276: loss: 0.9609, policy_loss: 0.8770, value_loss: 0.5306
2024-07-11 17:20:57,315 [INFO    ] __main__: train step 17277: loss: 0.9609, policy_loss: 0.8769, value_loss: 0.5306
2024-07-11 17:20:57,535 [INFO    ] __main__: train step 17278: loss: 0.9609, policy_loss: 0.8769, value_loss: 0.5306
2024-07-11 17:20:57,751 [INFO    ] __main__: train step 17279: loss: 0.9609, policy_loss: 0.8769, value_loss: 0.5306
2024-07-11 17:20:57,979 [INFO    ] __main__: train step 17280: loss: 0.9608, policy_loss: 0.8768, value_loss: 0.5306
2024-07-11 17:20:58,192 [INFO    ] __main__: train step 17281: loss: 0.9608, policy_loss: 0.8768, value_loss: 0.5306
2024-07-11 17:20:58,432 [INFO    ] __main__: train step 17282: loss: 0.9608, policy_loss: 0.8768, value_loss: 0.5305
2024-07-11 17:20:58,660 [INFO    ] __main__: train step 17283: loss: 0.9608, policy_loss: 0.8768, value_loss: 0.5305
2024-07-11 17:20:58,875 [INFO    ] __main__: train step 17284: loss: 0.9608, policy_loss: 0.8767, value_loss: 0.5305
2024-07-11 17:20:59,076 [INFO    ] __main__: train step 17285: loss: 0.9608, policy_loss: 0.8767, value_loss: 0.5305
2024-07-11 17:20:59,283 [INFO    ] __main__: train step 17286: loss: 0.9608, policy_loss: 0.8767, value_loss: 0.5305
2024-07-11 17:20:59,498 [INFO    ] __main__: train step 17287: loss: 0.9607, policy_loss: 0.8767, value_loss: 0.5305
2024-07-11 17:20:59,737 [INFO    ] __main__: train step 17288: loss: 0.9607, policy_loss: 0.8766, value_loss: 0.5304
2024-07-11 17:21:01,202 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:21:01,561 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:21:01,617 [INFO    ] __main__: train step 17289: loss: 0.9607, policy_loss: 0.8766, value_loss: 0.5304
2024-07-11 17:21:01,794 [INFO    ] __main__: train step 17290: loss: 0.9607, policy_loss: 0.8766, value_loss: 0.5304
2024-07-11 17:21:02,009 [INFO    ] __main__: train step 17291: loss: 0.9607, policy_loss: 0.8766, value_loss: 0.5304
2024-07-11 17:21:03,938 [INFO    ] __main__: train step 17292: loss: 0.9607, policy_loss: 0.8765, value_loss: 0.5304
2024-07-11 17:21:04,155 [INFO    ] __main__: train step 17293: loss: 0.9606, policy_loss: 0.8765, value_loss: 0.5304
2024-07-11 17:21:04,386 [INFO    ] __main__: train step 17294: loss: 0.9606, policy_loss: 0.8765, value_loss: 0.5303
2024-07-11 17:21:04,599 [INFO    ] __main__: train step 17295: loss: 0.9606, policy_loss: 0.8765, value_loss: 0.5303
2024-07-11 17:21:04,831 [INFO    ] __main__: train step 17296: loss: 0.9606, policy_loss: 0.8764, value_loss: 0.5303
2024-07-11 17:21:05,031 [INFO    ] __main__: train step 17297: loss: 0.9606, policy_loss: 0.8764, value_loss: 0.5303
2024-07-11 17:21:05,234 [INFO    ] __main__: train step 17298: loss: 0.9606, policy_loss: 0.8764, value_loss: 0.5303
2024-07-11 17:21:05,439 [INFO    ] __main__: train step 17299: loss: 0.9605, policy_loss: 0.8764, value_loss: 0.5303
2024-07-11 17:21:05,645 [INFO    ] __main__: train step 17300: loss: 0.9605, policy_loss: 0.8763, value_loss: 0.5302
2024-07-11 17:21:05,857 [INFO    ] __main__: train step 17301: loss: 0.9605, policy_loss: 0.8763, value_loss: 0.5302
2024-07-11 17:21:06,092 [INFO    ] __main__: train step 17302: loss: 0.9605, policy_loss: 0.8763, value_loss: 0.5302
2024-07-11 17:21:06,326 [INFO    ] __main__: train step 17303: loss: 0.9605, policy_loss: 0.8763, value_loss: 0.5302
2024-07-11 17:21:06,527 [INFO    ] __main__: train step 17304: loss: 0.9605, policy_loss: 0.8762, value_loss: 0.5302
2024-07-11 17:21:06,755 [INFO    ] __main__: train step 17305: loss: 0.9604, policy_loss: 0.8762, value_loss: 0.5302
2024-07-11 17:21:08,187 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:21:08,545 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:21:08,602 [INFO    ] __main__: train step 17306: loss: 0.9604, policy_loss: 0.8762, value_loss: 0.5301
2024-07-11 17:21:08,800 [INFO    ] __main__: train step 17307: loss: 0.9604, policy_loss: 0.8761, value_loss: 0.5301
2024-07-11 17:21:08,996 [INFO    ] __main__: train step 17308: loss: 0.9604, policy_loss: 0.8761, value_loss: 0.5301
2024-07-11 17:21:09,216 [INFO    ] __main__: train step 17309: loss: 0.9604, policy_loss: 0.8761, value_loss: 0.5301
2024-07-11 17:21:09,450 [INFO    ] __main__: train step 17310: loss: 0.9604, policy_loss: 0.8761, value_loss: 0.5301
2024-07-11 17:21:09,677 [INFO    ] __main__: train step 17311: loss: 0.9603, policy_loss: 0.8760, value_loss: 0.5301
2024-07-11 17:21:09,883 [INFO    ] __main__: train step 17312: loss: 0.9603, policy_loss: 0.8760, value_loss: 0.5301
2024-07-11 17:21:10,086 [INFO    ] __main__: train step 17313: loss: 0.9603, policy_loss: 0.8760, value_loss: 0.5300
2024-07-11 17:21:10,327 [INFO    ] __main__: train step 17314: loss: 0.9603, policy_loss: 0.8760, value_loss: 0.5300
2024-07-11 17:21:10,527 [INFO    ] __main__: train step 17315: loss: 0.9603, policy_loss: 0.8759, value_loss: 0.5300
2024-07-11 17:21:10,737 [INFO    ] __main__: train step 17316: loss: 0.9603, policy_loss: 0.8759, value_loss: 0.5300
2024-07-11 17:21:10,949 [INFO    ] __main__: train step 17317: loss: 0.9603, policy_loss: 0.8759, value_loss: 0.5300
2024-07-11 17:21:11,144 [INFO    ] __main__: train step 17318: loss: 0.9602, policy_loss: 0.8759, value_loss: 0.5300
2024-07-11 17:21:11,348 [INFO    ] __main__: train step 17319: loss: 0.9602, policy_loss: 0.8758, value_loss: 0.5299
2024-07-11 17:21:11,555 [INFO    ] __main__: train step 17320: loss: 0.9602, policy_loss: 0.8758, value_loss: 0.5299
2024-07-11 17:21:11,770 [INFO    ] __main__: train step 17321: loss: 0.9602, policy_loss: 0.8758, value_loss: 0.5299
2024-07-11 17:21:12,002 [INFO    ] __main__: train step 17322: loss: 0.9602, policy_loss: 0.8758, value_loss: 0.5299
2024-07-11 17:21:13,439 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:21:13,836 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:21:13,895 [INFO    ] __main__: train step 17323: loss: 0.9602, policy_loss: 0.8757, value_loss: 0.5299
2024-07-11 17:21:14,074 [INFO    ] __main__: train step 17324: loss: 0.9601, policy_loss: 0.8757, value_loss: 0.5299
2024-07-11 17:21:14,268 [INFO    ] __main__: train step 17325: loss: 0.9601, policy_loss: 0.8757, value_loss: 0.5298
2024-07-11 17:21:14,482 [INFO    ] __main__: train step 17326: loss: 0.9601, policy_loss: 0.8757, value_loss: 0.5298
2024-07-11 17:21:14,721 [INFO    ] __main__: train step 17327: loss: 0.9601, policy_loss: 0.8756, value_loss: 0.5298
2024-07-11 17:21:14,943 [INFO    ] __main__: train step 17328: loss: 0.9601, policy_loss: 0.8756, value_loss: 0.5298
2024-07-11 17:21:15,143 [INFO    ] __main__: train step 17329: loss: 0.9601, policy_loss: 0.8756, value_loss: 0.5298
2024-07-11 17:21:15,358 [INFO    ] __main__: train step 17330: loss: 0.9600, policy_loss: 0.8756, value_loss: 0.5298
2024-07-11 17:21:15,556 [INFO    ] __main__: train step 17331: loss: 0.9600, policy_loss: 0.8755, value_loss: 0.5298
2024-07-11 17:21:15,751 [INFO    ] __main__: train step 17332: loss: 0.9600, policy_loss: 0.8755, value_loss: 0.5297
2024-07-11 17:21:15,962 [INFO    ] __main__: train step 17333: loss: 0.9600, policy_loss: 0.8755, value_loss: 0.5297
2024-07-11 17:21:16,171 [INFO    ] __main__: train step 17334: loss: 0.9600, policy_loss: 0.8755, value_loss: 0.5297
2024-07-11 17:21:16,369 [INFO    ] __main__: train step 17335: loss: 0.9600, policy_loss: 0.8754, value_loss: 0.5297
2024-07-11 17:21:16,580 [INFO    ] __main__: train step 17336: loss: 0.9599, policy_loss: 0.8754, value_loss: 0.5297
2024-07-11 17:21:16,784 [INFO    ] __main__: train step 17337: loss: 0.9599, policy_loss: 0.8754, value_loss: 0.5297
2024-07-11 17:21:16,985 [INFO    ] __main__: train step 17338: loss: 0.9599, policy_loss: 0.8754, value_loss: 0.5296
2024-07-11 17:21:17,183 [INFO    ] __main__: train step 17339: loss: 0.9599, policy_loss: 0.8753, value_loss: 0.5296
2024-07-11 17:21:18,623 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:21:18,969 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:21:19,028 [INFO    ] __main__: train step 17340: loss: 0.9599, policy_loss: 0.8753, value_loss: 0.5296
2024-07-11 17:21:19,202 [INFO    ] __main__: train step 17341: loss: 0.9599, policy_loss: 0.8753, value_loss: 0.5296
2024-07-11 17:21:19,407 [INFO    ] __main__: train step 17342: loss: 0.9599, policy_loss: 0.8752, value_loss: 0.5296
2024-07-11 17:21:19,608 [INFO    ] __main__: train step 17343: loss: 0.9598, policy_loss: 0.8752, value_loss: 0.5296
2024-07-11 17:21:19,815 [INFO    ] __main__: train step 17344: loss: 0.9598, policy_loss: 0.8752, value_loss: 0.5295
2024-07-11 17:21:20,023 [INFO    ] __main__: train step 17345: loss: 0.9598, policy_loss: 0.8752, value_loss: 0.5295
2024-07-11 17:21:20,224 [INFO    ] __main__: train step 17346: loss: 0.9598, policy_loss: 0.8751, value_loss: 0.5295
2024-07-11 17:21:20,444 [INFO    ] __main__: train step 17347: loss: 0.9598, policy_loss: 0.8751, value_loss: 0.5295
2024-07-11 17:21:20,650 [INFO    ] __main__: train step 17348: loss: 0.9597, policy_loss: 0.8751, value_loss: 0.5295
2024-07-11 17:21:20,869 [INFO    ] __main__: train step 17349: loss: 0.9597, policy_loss: 0.8751, value_loss: 0.5295
2024-07-11 17:21:21,098 [INFO    ] __main__: train step 17350: loss: 0.9597, policy_loss: 0.8750, value_loss: 0.5294
2024-07-11 17:21:21,303 [INFO    ] __main__: train step 17351: loss: 0.9597, policy_loss: 0.8750, value_loss: 0.5294
2024-07-11 17:21:21,514 [INFO    ] __main__: train step 17352: loss: 0.9597, policy_loss: 0.8750, value_loss: 0.5294
2024-07-11 17:21:21,705 [INFO    ] __main__: train step 17353: loss: 0.9597, policy_loss: 0.8750, value_loss: 0.5294
2024-07-11 17:21:21,919 [INFO    ] __main__: train step 17354: loss: 0.9597, policy_loss: 0.8749, value_loss: 0.5294
2024-07-11 17:21:22,129 [INFO    ] __main__: train step 17355: loss: 0.9596, policy_loss: 0.8749, value_loss: 0.5294
2024-07-11 17:21:22,365 [INFO    ] __main__: train step 17356: loss: 0.9596, policy_loss: 0.8749, value_loss: 0.5294
2024-07-11 17:21:23,797 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:21:24,158 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:21:24,213 [INFO    ] __main__: train step 17357: loss: 0.9596, policy_loss: 0.8749, value_loss: 0.5293
2024-07-11 17:21:24,388 [INFO    ] __main__: train step 17358: loss: 0.9596, policy_loss: 0.8748, value_loss: 0.5293
2024-07-11 17:21:24,590 [INFO    ] __main__: train step 17359: loss: 0.9596, policy_loss: 0.8748, value_loss: 0.5293
2024-07-11 17:21:24,790 [INFO    ] __main__: train step 17360: loss: 0.9596, policy_loss: 0.8748, value_loss: 0.5293
2024-07-11 17:21:24,984 [INFO    ] __main__: train step 17361: loss: 0.9595, policy_loss: 0.8747, value_loss: 0.5293
2024-07-11 17:21:25,187 [INFO    ] __main__: train step 17362: loss: 0.9595, policy_loss: 0.8747, value_loss: 0.5293
2024-07-11 17:21:25,396 [INFO    ] __main__: train step 17363: loss: 0.9595, policy_loss: 0.8747, value_loss: 0.5292
2024-07-11 17:21:25,594 [INFO    ] __main__: train step 17364: loss: 0.9595, policy_loss: 0.8747, value_loss: 0.5292
2024-07-11 17:21:25,800 [INFO    ] __main__: train step 17365: loss: 0.9595, policy_loss: 0.8746, value_loss: 0.5292
2024-07-11 17:21:26,005 [INFO    ] __main__: train step 17366: loss: 0.9595, policy_loss: 0.8746, value_loss: 0.5292
2024-07-11 17:21:26,200 [INFO    ] __main__: train step 17367: loss: 0.9594, policy_loss: 0.8746, value_loss: 0.5292
2024-07-11 17:21:26,412 [INFO    ] __main__: train step 17368: loss: 0.9594, policy_loss: 0.8746, value_loss: 0.5292
2024-07-11 17:21:26,616 [INFO    ] __main__: train step 17369: loss: 0.9594, policy_loss: 0.8745, value_loss: 0.5291
2024-07-11 17:21:26,847 [INFO    ] __main__: train step 17370: loss: 0.9594, policy_loss: 0.8745, value_loss: 0.5291
2024-07-11 17:21:27,045 [INFO    ] __main__: train step 17371: loss: 0.9594, policy_loss: 0.8745, value_loss: 0.5291
2024-07-11 17:21:27,280 [INFO    ] __main__: train step 17372: loss: 0.9594, policy_loss: 0.8745, value_loss: 0.5291
2024-07-11 17:21:27,511 [INFO    ] __main__: train step 17373: loss: 0.9593, policy_loss: 0.8744, value_loss: 0.5291
2024-07-11 17:21:28,946 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:21:29,283 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:21:29,337 [INFO    ] __main__: train step 17374: loss: 0.9593, policy_loss: 0.8744, value_loss: 0.5291
2024-07-11 17:21:29,526 [INFO    ] __main__: train step 17375: loss: 0.9593, policy_loss: 0.8744, value_loss: 0.5290
2024-07-11 17:21:29,735 [INFO    ] __main__: train step 17376: loss: 0.9593, policy_loss: 0.8744, value_loss: 0.5290
2024-07-11 17:21:29,939 [INFO    ] __main__: train step 17377: loss: 0.9593, policy_loss: 0.8743, value_loss: 0.5290
2024-07-11 17:21:30,154 [INFO    ] __main__: train step 17378: loss: 0.9592, policy_loss: 0.8743, value_loss: 0.5290
2024-07-11 17:21:30,391 [INFO    ] __main__: train step 17379: loss: 0.9592, policy_loss: 0.8743, value_loss: 0.5290
2024-07-11 17:21:30,597 [INFO    ] __main__: train step 17380: loss: 0.9592, policy_loss: 0.8743, value_loss: 0.5290
2024-07-11 17:21:30,804 [INFO    ] __main__: train step 17381: loss: 0.9592, policy_loss: 0.8742, value_loss: 0.5289
2024-07-11 17:21:31,010 [INFO    ] __main__: train step 17382: loss: 0.9592, policy_loss: 0.8742, value_loss: 0.5289
2024-07-11 17:21:31,221 [INFO    ] __main__: train step 17383: loss: 0.9592, policy_loss: 0.8742, value_loss: 0.5289
2024-07-11 17:21:31,425 [INFO    ] __main__: train step 17384: loss: 0.9591, policy_loss: 0.8741, value_loss: 0.5289
2024-07-11 17:21:31,626 [INFO    ] __main__: train step 17385: loss: 0.9591, policy_loss: 0.8741, value_loss: 0.5289
2024-07-11 17:21:31,837 [INFO    ] __main__: train step 17386: loss: 0.9591, policy_loss: 0.8741, value_loss: 0.5289
2024-07-11 17:21:32,038 [INFO    ] __main__: train step 17387: loss: 0.9591, policy_loss: 0.8741, value_loss: 0.5288
2024-07-11 17:21:32,252 [INFO    ] __main__: train step 17388: loss: 0.9591, policy_loss: 0.8740, value_loss: 0.5288
2024-07-11 17:21:32,462 [INFO    ] __main__: train step 17389: loss: 0.9591, policy_loss: 0.8740, value_loss: 0.5288
2024-07-11 17:21:32,681 [INFO    ] __main__: train step 17390: loss: 0.9590, policy_loss: 0.8740, value_loss: 0.5288
2024-07-11 17:21:34,138 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:21:34,506 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:21:34,564 [INFO    ] __main__: train step 17391: loss: 0.9590, policy_loss: 0.8740, value_loss: 0.5288
2024-07-11 17:21:34,733 [INFO    ] __main__: train step 17392: loss: 0.9590, policy_loss: 0.8739, value_loss: 0.5288
2024-07-11 17:21:34,945 [INFO    ] __main__: train step 17393: loss: 0.9590, policy_loss: 0.8739, value_loss: 0.5288
2024-07-11 17:21:35,149 [INFO    ] __main__: train step 17394: loss: 0.9590, policy_loss: 0.8739, value_loss: 0.5287
2024-07-11 17:21:35,350 [INFO    ] __main__: train step 17395: loss: 0.9590, policy_loss: 0.8739, value_loss: 0.5287
2024-07-11 17:21:35,559 [INFO    ] __main__: train step 17396: loss: 0.9589, policy_loss: 0.8738, value_loss: 0.5287
2024-07-11 17:21:35,782 [INFO    ] __main__: train step 17397: loss: 0.9589, policy_loss: 0.8738, value_loss: 0.5287
2024-07-11 17:21:36,024 [INFO    ] __main__: train step 17398: loss: 0.9589, policy_loss: 0.8738, value_loss: 0.5287
2024-07-11 17:21:36,248 [INFO    ] __main__: train step 17399: loss: 0.9589, policy_loss: 0.8738, value_loss: 0.5287
2024-07-11 17:21:36,468 [INFO    ] __main__: train step 17400: loss: 0.9589, policy_loss: 0.8737, value_loss: 0.5286
2024-07-11 17:21:36,679 [INFO    ] __main__: train step 17401: loss: 0.9589, policy_loss: 0.8737, value_loss: 0.5286
2024-07-11 17:21:36,875 [INFO    ] __main__: train step 17402: loss: 0.9588, policy_loss: 0.8737, value_loss: 0.5286
2024-07-11 17:21:37,080 [INFO    ] __main__: train step 17403: loss: 0.9588, policy_loss: 0.8737, value_loss: 0.5286
2024-07-11 17:21:37,276 [INFO    ] __main__: train step 17404: loss: 0.9588, policy_loss: 0.8736, value_loss: 0.5286
2024-07-11 17:21:37,481 [INFO    ] __main__: train step 17405: loss: 0.9588, policy_loss: 0.8736, value_loss: 0.5286
2024-07-11 17:21:37,675 [INFO    ] __main__: train step 17406: loss: 0.9588, policy_loss: 0.8736, value_loss: 0.5285
2024-07-11 17:21:37,883 [INFO    ] __main__: train step 17407: loss: 0.9588, policy_loss: 0.8735, value_loss: 0.5285
2024-07-11 17:21:41,026 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:21:41,394 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:21:41,453 [INFO    ] __main__: train step 17408: loss: 0.9587, policy_loss: 0.8735, value_loss: 0.5285
2024-07-11 17:21:41,637 [INFO    ] __main__: train step 17409: loss: 0.9587, policy_loss: 0.8735, value_loss: 0.5285
2024-07-11 17:21:41,850 [INFO    ] __main__: train step 17410: loss: 0.9587, policy_loss: 0.8735, value_loss: 0.5285
2024-07-11 17:21:42,056 [INFO    ] __main__: train step 17411: loss: 0.9587, policy_loss: 0.8734, value_loss: 0.5285
2024-07-11 17:21:42,266 [INFO    ] __main__: train step 17412: loss: 0.9587, policy_loss: 0.8734, value_loss: 0.5284
2024-07-11 17:21:42,504 [INFO    ] __main__: train step 17413: loss: 0.9587, policy_loss: 0.8734, value_loss: 0.5284
2024-07-11 17:21:42,738 [INFO    ] __main__: train step 17414: loss: 0.9586, policy_loss: 0.8734, value_loss: 0.5284
2024-07-11 17:21:42,958 [INFO    ] __main__: train step 17415: loss: 0.9586, policy_loss: 0.8733, value_loss: 0.5284
2024-07-11 17:21:43,196 [INFO    ] __main__: train step 17416: loss: 0.9586, policy_loss: 0.8733, value_loss: 0.5284
2024-07-11 17:21:43,424 [INFO    ] __main__: train step 17417: loss: 0.9586, policy_loss: 0.8733, value_loss: 0.5284
2024-07-11 17:21:43,634 [INFO    ] __main__: train step 17418: loss: 0.9586, policy_loss: 0.8733, value_loss: 0.5283
2024-07-11 17:21:43,849 [INFO    ] __main__: train step 17419: loss: 0.9586, policy_loss: 0.8732, value_loss: 0.5283
2024-07-11 17:21:44,042 [INFO    ] __main__: train step 17420: loss: 0.9585, policy_loss: 0.8732, value_loss: 0.5283
2024-07-11 17:21:44,251 [INFO    ] __main__: train step 17421: loss: 0.9585, policy_loss: 0.8732, value_loss: 0.5283
2024-07-11 17:21:44,450 [INFO    ] __main__: train step 17422: loss: 0.9585, policy_loss: 0.8732, value_loss: 0.5283
2024-07-11 17:21:44,663 [INFO    ] __main__: train step 17423: loss: 0.9585, policy_loss: 0.8731, value_loss: 0.5283
2024-07-11 17:21:44,881 [INFO    ] __main__: train step 17424: loss: 0.9585, policy_loss: 0.8731, value_loss: 0.5282
2024-07-11 17:21:46,292 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:21:46,667 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:21:46,732 [INFO    ] __main__: train step 17425: loss: 0.9584, policy_loss: 0.8731, value_loss: 0.5282
2024-07-11 17:21:46,901 [INFO    ] __main__: train step 17426: loss: 0.9584, policy_loss: 0.8730, value_loss: 0.5282
2024-07-11 17:21:47,093 [INFO    ] __main__: train step 17427: loss: 0.9584, policy_loss: 0.8730, value_loss: 0.5282
2024-07-11 17:21:47,292 [INFO    ] __main__: train step 17428: loss: 0.9584, policy_loss: 0.8730, value_loss: 0.5282
2024-07-11 17:21:47,503 [INFO    ] __main__: train step 17429: loss: 0.9584, policy_loss: 0.8730, value_loss: 0.5282
2024-07-11 17:21:47,693 [INFO    ] __main__: train step 17430: loss: 0.9584, policy_loss: 0.8729, value_loss: 0.5281
2024-07-11 17:21:47,921 [INFO    ] __main__: train step 17431: loss: 0.9583, policy_loss: 0.8729, value_loss: 0.5281
2024-07-11 17:21:48,170 [INFO    ] __main__: train step 17432: loss: 0.9583, policy_loss: 0.8729, value_loss: 0.5281
2024-07-11 17:21:48,403 [INFO    ] __main__: train step 17433: loss: 0.9583, policy_loss: 0.8729, value_loss: 0.5281
2024-07-11 17:21:48,605 [INFO    ] __main__: train step 17434: loss: 0.9583, policy_loss: 0.8728, value_loss: 0.5281
2024-07-11 17:21:48,805 [INFO    ] __main__: train step 17435: loss: 0.9583, policy_loss: 0.8728, value_loss: 0.5281
2024-07-11 17:21:49,009 [INFO    ] __main__: train step 17436: loss: 0.9583, policy_loss: 0.8728, value_loss: 0.5280
2024-07-11 17:21:49,213 [INFO    ] __main__: train step 17437: loss: 0.9582, policy_loss: 0.8728, value_loss: 0.5280
2024-07-11 17:21:49,410 [INFO    ] __main__: train step 17438: loss: 0.9582, policy_loss: 0.8727, value_loss: 0.5280
2024-07-11 17:21:49,610 [INFO    ] __main__: train step 17439: loss: 0.9582, policy_loss: 0.8727, value_loss: 0.5280
2024-07-11 17:21:49,815 [INFO    ] __main__: train step 17440: loss: 0.9582, policy_loss: 0.8727, value_loss: 0.5280
2024-07-11 17:21:50,020 [INFO    ] __main__: train step 17441: loss: 0.9582, policy_loss: 0.8727, value_loss: 0.5280
2024-07-11 17:21:51,443 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:21:51,810 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:21:51,864 [INFO    ] __main__: train step 17442: loss: 0.9582, policy_loss: 0.8726, value_loss: 0.5279
2024-07-11 17:21:52,037 [INFO    ] __main__: train step 17443: loss: 0.9581, policy_loss: 0.8726, value_loss: 0.5279
2024-07-11 17:21:52,249 [INFO    ] __main__: train step 17444: loss: 0.9581, policy_loss: 0.8726, value_loss: 0.5279
2024-07-11 17:21:52,455 [INFO    ] __main__: train step 17445: loss: 0.9581, policy_loss: 0.8726, value_loss: 0.5279
2024-07-11 17:21:52,664 [INFO    ] __main__: train step 17446: loss: 0.9581, policy_loss: 0.8725, value_loss: 0.5279
2024-07-11 17:21:52,865 [INFO    ] __main__: train step 17447: loss: 0.9581, policy_loss: 0.8725, value_loss: 0.5279
2024-07-11 17:21:53,077 [INFO    ] __main__: train step 17448: loss: 0.9580, policy_loss: 0.8725, value_loss: 0.5278
2024-07-11 17:21:53,316 [INFO    ] __main__: train step 17449: loss: 0.9580, policy_loss: 0.8724, value_loss: 0.5278
2024-07-11 17:21:53,529 [INFO    ] __main__: train step 17450: loss: 0.9580, policy_loss: 0.8724, value_loss: 0.5278
2024-07-11 17:21:53,800 [INFO    ] __main__: train step 17451: loss: 0.9580, policy_loss: 0.8724, value_loss: 0.5278
2024-07-11 17:21:54,037 [INFO    ] __main__: train step 17452: loss: 0.9580, policy_loss: 0.8724, value_loss: 0.5278
2024-07-11 17:21:54,265 [INFO    ] __main__: train step 17453: loss: 0.9580, policy_loss: 0.8723, value_loss: 0.5278
2024-07-11 17:21:54,496 [INFO    ] __main__: train step 17454: loss: 0.9579, policy_loss: 0.8723, value_loss: 0.5277
2024-07-11 17:21:54,708 [INFO    ] __main__: train step 17455: loss: 0.9579, policy_loss: 0.8723, value_loss: 0.5277
2024-07-11 17:21:54,964 [INFO    ] __main__: train step 17456: loss: 0.9579, policy_loss: 0.8723, value_loss: 0.5277
2024-07-11 17:21:55,204 [INFO    ] __main__: train step 17457: loss: 0.9579, policy_loss: 0.8722, value_loss: 0.5277
2024-07-11 17:21:55,411 [INFO    ] __main__: train step 17458: loss: 0.9579, policy_loss: 0.8722, value_loss: 0.5277
2024-07-11 17:21:56,809 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:21:57,231 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:21:57,285 [INFO    ] __main__: train step 17459: loss: 0.9579, policy_loss: 0.8722, value_loss: 0.5277
2024-07-11 17:21:57,466 [INFO    ] __main__: train step 17460: loss: 0.9578, policy_loss: 0.8722, value_loss: 0.5276
2024-07-11 17:21:57,670 [INFO    ] __main__: train step 17461: loss: 0.9578, policy_loss: 0.8721, value_loss: 0.5276
2024-07-11 17:21:57,877 [INFO    ] __main__: train step 17462: loss: 0.9578, policy_loss: 0.8721, value_loss: 0.5276
2024-07-11 17:21:58,075 [INFO    ] __main__: train step 17463: loss: 0.9578, policy_loss: 0.8721, value_loss: 0.5276
2024-07-11 17:21:58,267 [INFO    ] __main__: train step 17464: loss: 0.9578, policy_loss: 0.8721, value_loss: 0.5276
2024-07-11 17:21:58,462 [INFO    ] __main__: train step 17465: loss: 0.9577, policy_loss: 0.8720, value_loss: 0.5276
2024-07-11 17:21:58,665 [INFO    ] __main__: train step 17466: loss: 0.9577, policy_loss: 0.8720, value_loss: 0.5275
2024-07-11 17:21:58,865 [INFO    ] __main__: train step 17467: loss: 0.9577, policy_loss: 0.8720, value_loss: 0.5275
2024-07-11 17:21:59,071 [INFO    ] __main__: train step 17468: loss: 0.9577, policy_loss: 0.8719, value_loss: 0.5275
2024-07-11 17:21:59,275 [INFO    ] __main__: train step 17469: loss: 0.9577, policy_loss: 0.8719, value_loss: 0.5275
2024-07-11 17:21:59,498 [INFO    ] __main__: train step 17470: loss: 0.9577, policy_loss: 0.8719, value_loss: 0.5275
2024-07-11 17:21:59,723 [INFO    ] __main__: train step 17471: loss: 0.9576, policy_loss: 0.8719, value_loss: 0.5275
2024-07-11 17:21:59,928 [INFO    ] __main__: train step 17472: loss: 0.9576, policy_loss: 0.8718, value_loss: 0.5274
2024-07-11 17:22:00,141 [INFO    ] __main__: train step 17473: loss: 0.9576, policy_loss: 0.8718, value_loss: 0.5274
2024-07-11 17:22:00,349 [INFO    ] __main__: train step 17474: loss: 0.9576, policy_loss: 0.8718, value_loss: 0.5274
2024-07-11 17:22:00,581 [INFO    ] __main__: train step 17475: loss: 0.9576, policy_loss: 0.8718, value_loss: 0.5274
2024-07-11 17:22:01,945 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:22:02,292 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:22:02,349 [INFO    ] __main__: train step 17476: loss: 0.9575, policy_loss: 0.8717, value_loss: 0.5274
2024-07-11 17:22:02,550 [INFO    ] __main__: train step 17477: loss: 0.9575, policy_loss: 0.8717, value_loss: 0.5273
2024-07-11 17:22:02,772 [INFO    ] __main__: train step 17478: loss: 0.9575, policy_loss: 0.8717, value_loss: 0.5273
2024-07-11 17:22:02,996 [INFO    ] __main__: train step 17479: loss: 0.9575, policy_loss: 0.8717, value_loss: 0.5273
2024-07-11 17:22:03,217 [INFO    ] __main__: train step 17480: loss: 0.9575, policy_loss: 0.8716, value_loss: 0.5273
2024-07-11 17:22:03,451 [INFO    ] __main__: train step 17481: loss: 0.9574, policy_loss: 0.8716, value_loss: 0.5273
2024-07-11 17:22:03,680 [INFO    ] __main__: train step 17482: loss: 0.9574, policy_loss: 0.8716, value_loss: 0.5273
2024-07-11 17:22:03,884 [INFO    ] __main__: train step 17483: loss: 0.9574, policy_loss: 0.8716, value_loss: 0.5272
2024-07-11 17:22:04,114 [INFO    ] __main__: train step 17484: loss: 0.9574, policy_loss: 0.8715, value_loss: 0.5272
2024-07-11 17:22:04,326 [INFO    ] __main__: train step 17485: loss: 0.9574, policy_loss: 0.8715, value_loss: 0.5272
2024-07-11 17:22:04,533 [INFO    ] __main__: train step 17486: loss: 0.9574, policy_loss: 0.8715, value_loss: 0.5272
2024-07-11 17:22:04,741 [INFO    ] __main__: train step 17487: loss: 0.9573, policy_loss: 0.8714, value_loss: 0.5272
2024-07-11 17:22:04,942 [INFO    ] __main__: train step 17488: loss: 0.9573, policy_loss: 0.8714, value_loss: 0.5272
2024-07-11 17:22:05,148 [INFO    ] __main__: train step 17489: loss: 0.9573, policy_loss: 0.8714, value_loss: 0.5271
2024-07-11 17:22:05,347 [INFO    ] __main__: train step 17490: loss: 0.9573, policy_loss: 0.8714, value_loss: 0.5271
2024-07-11 17:22:05,562 [INFO    ] __main__: train step 17491: loss: 0.9573, policy_loss: 0.8713, value_loss: 0.5271
2024-07-11 17:22:05,814 [INFO    ] __main__: train step 17492: loss: 0.9572, policy_loss: 0.8713, value_loss: 0.5271
2024-07-11 17:22:07,186 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:22:07,595 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:22:07,655 [INFO    ] __main__: train step 17493: loss: 0.9572, policy_loss: 0.8713, value_loss: 0.5271
2024-07-11 17:22:07,835 [INFO    ] __main__: train step 17494: loss: 0.9572, policy_loss: 0.8713, value_loss: 0.5271
2024-07-11 17:22:08,034 [INFO    ] __main__: train step 17495: loss: 0.9572, policy_loss: 0.8712, value_loss: 0.5270
2024-07-11 17:22:08,246 [INFO    ] __main__: train step 17496: loss: 0.9572, policy_loss: 0.8712, value_loss: 0.5270
2024-07-11 17:22:08,462 [INFO    ] __main__: train step 17497: loss: 0.9572, policy_loss: 0.8712, value_loss: 0.5270
2024-07-11 17:22:08,714 [INFO    ] __main__: train step 17498: loss: 0.9571, policy_loss: 0.8712, value_loss: 0.5270
2024-07-11 17:22:08,928 [INFO    ] __main__: train step 17499: loss: 0.9571, policy_loss: 0.8711, value_loss: 0.5270
2024-07-11 17:22:09,168 [INFO    ] __main__: train step 17500: loss: 0.9571, policy_loss: 0.8711, value_loss: 0.5269
2024-07-11 17:22:09,385 [INFO    ] __main__: train step 17501: loss: 0.9571, policy_loss: 0.8711, value_loss: 0.5269
2024-07-11 17:22:09,572 [INFO    ] __main__: train step 17502: loss: 0.9571, policy_loss: 0.8711, value_loss: 0.5269
2024-07-11 17:22:09,782 [INFO    ] __main__: train step 17503: loss: 0.9570, policy_loss: 0.8710, value_loss: 0.5269
2024-07-11 17:22:09,980 [INFO    ] __main__: train step 17504: loss: 0.9570, policy_loss: 0.8710, value_loss: 0.5269
2024-07-11 17:22:10,200 [INFO    ] __main__: train step 17505: loss: 0.9570, policy_loss: 0.8710, value_loss: 0.5269
2024-07-11 17:22:10,423 [INFO    ] __main__: train step 17506: loss: 0.9570, policy_loss: 0.8709, value_loss: 0.5268
2024-07-11 17:22:10,624 [INFO    ] __main__: train step 17507: loss: 0.9570, policy_loss: 0.8709, value_loss: 0.5268
2024-07-11 17:22:10,824 [INFO    ] __main__: train step 17508: loss: 0.9569, policy_loss: 0.8709, value_loss: 0.5268
2024-07-11 17:22:11,025 [INFO    ] __main__: train step 17509: loss: 0.9569, policy_loss: 0.8709, value_loss: 0.5268
2024-07-11 17:22:12,439 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:22:12,821 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:22:12,876 [INFO    ] __main__: train step 17510: loss: 0.9569, policy_loss: 0.8708, value_loss: 0.5268
2024-07-11 17:22:13,052 [INFO    ] __main__: train step 17511: loss: 0.9569, policy_loss: 0.8708, value_loss: 0.5268
2024-07-11 17:22:13,263 [INFO    ] __main__: train step 17512: loss: 0.9569, policy_loss: 0.8708, value_loss: 0.5267
2024-07-11 17:22:13,471 [INFO    ] __main__: train step 17513: loss: 0.9569, policy_loss: 0.8708, value_loss: 0.5267
2024-07-11 17:22:13,667 [INFO    ] __main__: train step 17514: loss: 0.9568, policy_loss: 0.8707, value_loss: 0.5267
2024-07-11 17:22:13,871 [INFO    ] __main__: train step 17515: loss: 0.9568, policy_loss: 0.8707, value_loss: 0.5267
2024-07-11 17:22:14,077 [INFO    ] __main__: train step 17516: loss: 0.9568, policy_loss: 0.8707, value_loss: 0.5267
2024-07-11 17:22:14,292 [INFO    ] __main__: train step 17517: loss: 0.9568, policy_loss: 0.8707, value_loss: 0.5266
2024-07-11 17:22:14,508 [INFO    ] __main__: train step 17518: loss: 0.9568, policy_loss: 0.8706, value_loss: 0.5266
2024-07-11 17:22:14,727 [INFO    ] __main__: train step 17519: loss: 0.9567, policy_loss: 0.8706, value_loss: 0.5266
2024-07-11 17:22:14,950 [INFO    ] __main__: train step 17520: loss: 0.9567, policy_loss: 0.8706, value_loss: 0.5266
2024-07-11 17:22:15,156 [INFO    ] __main__: train step 17521: loss: 0.9567, policy_loss: 0.8706, value_loss: 0.5266
2024-07-11 17:22:15,373 [INFO    ] __main__: train step 17522: loss: 0.9567, policy_loss: 0.8705, value_loss: 0.5266
2024-07-11 17:22:15,596 [INFO    ] __main__: train step 17523: loss: 0.9567, policy_loss: 0.8705, value_loss: 0.5265
2024-07-11 17:22:15,810 [INFO    ] __main__: train step 17524: loss: 0.9566, policy_loss: 0.8705, value_loss: 0.5265
2024-07-11 17:22:16,041 [INFO    ] __main__: train step 17525: loss: 0.9566, policy_loss: 0.8704, value_loss: 0.5265
2024-07-11 17:22:17,966 [INFO    ] __main__: train step 17526: loss: 0.9566, policy_loss: 0.8704, value_loss: 0.5265
2024-07-11 17:22:19,377 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:22:19,718 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:22:19,778 [INFO    ] __main__: train step 17527: loss: 0.9566, policy_loss: 0.8704, value_loss: 0.5265
2024-07-11 17:22:19,961 [INFO    ] __main__: train step 17528: loss: 0.9566, policy_loss: 0.8704, value_loss: 0.5265
2024-07-11 17:22:20,198 [INFO    ] __main__: train step 17529: loss: 0.9566, policy_loss: 0.8703, value_loss: 0.5264
2024-07-11 17:22:20,404 [INFO    ] __main__: train step 17530: loss: 0.9565, policy_loss: 0.8703, value_loss: 0.5264
2024-07-11 17:22:20,649 [INFO    ] __main__: train step 17531: loss: 0.9565, policy_loss: 0.8703, value_loss: 0.5264
2024-07-11 17:22:20,842 [INFO    ] __main__: train step 17532: loss: 0.9565, policy_loss: 0.8703, value_loss: 0.5264
2024-07-11 17:22:21,052 [INFO    ] __main__: train step 17533: loss: 0.9565, policy_loss: 0.8702, value_loss: 0.5264
2024-07-11 17:22:21,284 [INFO    ] __main__: train step 17534: loss: 0.9565, policy_loss: 0.8702, value_loss: 0.5264
2024-07-11 17:22:21,512 [INFO    ] __main__: train step 17535: loss: 0.9564, policy_loss: 0.8702, value_loss: 0.5263
2024-07-11 17:22:21,725 [INFO    ] __main__: train step 17536: loss: 0.9564, policy_loss: 0.8701, value_loss: 0.5263
2024-07-11 17:22:21,926 [INFO    ] __main__: train step 17537: loss: 0.9564, policy_loss: 0.8701, value_loss: 0.5263
2024-07-11 17:22:22,132 [INFO    ] __main__: train step 17538: loss: 0.9564, policy_loss: 0.8701, value_loss: 0.5263
2024-07-11 17:22:22,336 [INFO    ] __main__: train step 17539: loss: 0.9564, policy_loss: 0.8701, value_loss: 0.5263
2024-07-11 17:22:22,571 [INFO    ] __main__: train step 17540: loss: 0.9563, policy_loss: 0.8700, value_loss: 0.5262
2024-07-11 17:22:22,806 [INFO    ] __main__: train step 17541: loss: 0.9563, policy_loss: 0.8700, value_loss: 0.5262
2024-07-11 17:22:23,005 [INFO    ] __main__: train step 17542: loss: 0.9563, policy_loss: 0.8700, value_loss: 0.5262
2024-07-11 17:22:23,197 [INFO    ] __main__: train step 17543: loss: 0.9563, policy_loss: 0.8700, value_loss: 0.5262
2024-07-11 17:22:24,596 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:22:24,937 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:22:24,995 [INFO    ] __main__: train step 17544: loss: 0.9563, policy_loss: 0.8699, value_loss: 0.5262
2024-07-11 17:22:25,174 [INFO    ] __main__: train step 17545: loss: 0.9562, policy_loss: 0.8699, value_loss: 0.5262
2024-07-11 17:22:25,394 [INFO    ] __main__: train step 17546: loss: 0.9562, policy_loss: 0.8699, value_loss: 0.5261
2024-07-11 17:22:25,641 [INFO    ] __main__: train step 17547: loss: 0.9562, policy_loss: 0.8699, value_loss: 0.5261
2024-07-11 17:22:25,843 [INFO    ] __main__: train step 17548: loss: 0.9562, policy_loss: 0.8698, value_loss: 0.5261
2024-07-11 17:22:26,038 [INFO    ] __main__: train step 17549: loss: 0.9562, policy_loss: 0.8698, value_loss: 0.5261
2024-07-11 17:22:26,254 [INFO    ] __main__: train step 17550: loss: 0.9561, policy_loss: 0.8698, value_loss: 0.5261
2024-07-11 17:22:26,469 [INFO    ] __main__: train step 17551: loss: 0.9561, policy_loss: 0.8698, value_loss: 0.5260
2024-07-11 17:22:26,704 [INFO    ] __main__: train step 17552: loss: 0.9561, policy_loss: 0.8697, value_loss: 0.5260
2024-07-11 17:22:26,924 [INFO    ] __main__: train step 17553: loss: 0.9561, policy_loss: 0.8697, value_loss: 0.5260
2024-07-11 17:22:27,163 [INFO    ] __main__: train step 17554: loss: 0.9561, policy_loss: 0.8697, value_loss: 0.5260
2024-07-11 17:22:27,363 [INFO    ] __main__: train step 17555: loss: 0.9560, policy_loss: 0.8696, value_loss: 0.5260
2024-07-11 17:22:27,575 [INFO    ] __main__: train step 17556: loss: 0.9560, policy_loss: 0.8696, value_loss: 0.5260
2024-07-11 17:22:27,778 [INFO    ] __main__: train step 17557: loss: 0.9560, policy_loss: 0.8696, value_loss: 0.5259
2024-07-11 17:22:27,974 [INFO    ] __main__: train step 17558: loss: 0.9560, policy_loss: 0.8696, value_loss: 0.5259
2024-07-11 17:22:28,174 [INFO    ] __main__: train step 17559: loss: 0.9560, policy_loss: 0.8695, value_loss: 0.5259
2024-07-11 17:22:28,379 [INFO    ] __main__: train step 17560: loss: 0.9559, policy_loss: 0.8695, value_loss: 0.5259
2024-07-11 17:22:29,792 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:22:30,154 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:22:30,216 [INFO    ] __main__: train step 17561: loss: 0.9559, policy_loss: 0.8695, value_loss: 0.5259
2024-07-11 17:22:30,389 [INFO    ] __main__: train step 17562: loss: 0.9559, policy_loss: 0.8695, value_loss: 0.5258
2024-07-11 17:22:30,609 [INFO    ] __main__: train step 17563: loss: 0.9559, policy_loss: 0.8694, value_loss: 0.5258
2024-07-11 17:22:30,804 [INFO    ] __main__: train step 17564: loss: 0.9559, policy_loss: 0.8694, value_loss: 0.5258
2024-07-11 17:22:31,013 [INFO    ] __main__: train step 17565: loss: 0.9559, policy_loss: 0.8694, value_loss: 0.5258
2024-07-11 17:22:31,214 [INFO    ] __main__: train step 17566: loss: 0.9558, policy_loss: 0.8694, value_loss: 0.5258
2024-07-11 17:22:31,423 [INFO    ] __main__: train step 17567: loss: 0.9558, policy_loss: 0.8693, value_loss: 0.5258
2024-07-11 17:22:31,626 [INFO    ] __main__: train step 17568: loss: 0.9558, policy_loss: 0.8693, value_loss: 0.5257
2024-07-11 17:22:31,834 [INFO    ] __main__: train step 17569: loss: 0.9558, policy_loss: 0.8693, value_loss: 0.5257
2024-07-11 17:22:32,032 [INFO    ] __main__: train step 17570: loss: 0.9558, policy_loss: 0.8692, value_loss: 0.5257
2024-07-11 17:22:32,230 [INFO    ] __main__: train step 17571: loss: 0.9557, policy_loss: 0.8692, value_loss: 0.5257
2024-07-11 17:22:32,457 [INFO    ] __main__: train step 17572: loss: 0.9557, policy_loss: 0.8692, value_loss: 0.5257
2024-07-11 17:22:32,649 [INFO    ] __main__: train step 17573: loss: 0.9557, policy_loss: 0.8692, value_loss: 0.5257
2024-07-11 17:22:32,857 [INFO    ] __main__: train step 17574: loss: 0.9557, policy_loss: 0.8691, value_loss: 0.5256
2024-07-11 17:22:33,065 [INFO    ] __main__: train step 17575: loss: 0.9557, policy_loss: 0.8691, value_loss: 0.5256
2024-07-11 17:22:33,285 [INFO    ] __main__: train step 17576: loss: 0.9556, policy_loss: 0.8691, value_loss: 0.5256
2024-07-11 17:22:33,518 [INFO    ] __main__: train step 17577: loss: 0.9556, policy_loss: 0.8691, value_loss: 0.5256
2024-07-11 17:22:34,891 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:22:35,244 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:22:35,299 [INFO    ] __main__: train step 17578: loss: 0.9556, policy_loss: 0.8690, value_loss: 0.5256
2024-07-11 17:22:35,492 [INFO    ] __main__: train step 17579: loss: 0.9556, policy_loss: 0.8690, value_loss: 0.5255
2024-07-11 17:22:35,688 [INFO    ] __main__: train step 17580: loss: 0.9556, policy_loss: 0.8690, value_loss: 0.5255
2024-07-11 17:22:35,897 [INFO    ] __main__: train step 17581: loss: 0.9555, policy_loss: 0.8689, value_loss: 0.5255
2024-07-11 17:22:36,099 [INFO    ] __main__: train step 17582: loss: 0.9555, policy_loss: 0.8689, value_loss: 0.5255
2024-07-11 17:22:36,312 [INFO    ] __main__: train step 17583: loss: 0.9555, policy_loss: 0.8689, value_loss: 0.5255
2024-07-11 17:22:36,528 [INFO    ] __main__: train step 17584: loss: 0.9555, policy_loss: 0.8689, value_loss: 0.5255
2024-07-11 17:22:36,732 [INFO    ] __main__: train step 17585: loss: 0.9555, policy_loss: 0.8688, value_loss: 0.5254
2024-07-11 17:22:36,933 [INFO    ] __main__: train step 17586: loss: 0.9554, policy_loss: 0.8688, value_loss: 0.5254
2024-07-11 17:22:37,135 [INFO    ] __main__: train step 17587: loss: 0.9554, policy_loss: 0.8688, value_loss: 0.5254
2024-07-11 17:22:37,335 [INFO    ] __main__: train step 17588: loss: 0.9554, policy_loss: 0.8688, value_loss: 0.5254
2024-07-11 17:22:37,537 [INFO    ] __main__: train step 17589: loss: 0.9554, policy_loss: 0.8687, value_loss: 0.5254
2024-07-11 17:22:37,748 [INFO    ] __main__: train step 17590: loss: 0.9554, policy_loss: 0.8687, value_loss: 0.5253
2024-07-11 17:22:37,951 [INFO    ] __main__: train step 17591: loss: 0.9553, policy_loss: 0.8687, value_loss: 0.5253
2024-07-11 17:22:38,158 [INFO    ] __main__: train step 17592: loss: 0.9553, policy_loss: 0.8687, value_loss: 0.5253
2024-07-11 17:22:38,367 [INFO    ] __main__: train step 17593: loss: 0.9553, policy_loss: 0.8686, value_loss: 0.5253
2024-07-11 17:22:38,577 [INFO    ] __main__: train step 17594: loss: 0.9553, policy_loss: 0.8686, value_loss: 0.5253
2024-07-11 17:22:39,993 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:22:40,350 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:22:40,406 [INFO    ] __main__: train step 17595: loss: 0.9553, policy_loss: 0.8686, value_loss: 0.5253
2024-07-11 17:22:40,584 [INFO    ] __main__: train step 17596: loss: 0.9552, policy_loss: 0.8685, value_loss: 0.5252
2024-07-11 17:22:40,793 [INFO    ] __main__: train step 17597: loss: 0.9552, policy_loss: 0.8685, value_loss: 0.5252
2024-07-11 17:22:41,019 [INFO    ] __main__: train step 17598: loss: 0.9552, policy_loss: 0.8685, value_loss: 0.5252
2024-07-11 17:22:41,229 [INFO    ] __main__: train step 17599: loss: 0.9552, policy_loss: 0.8685, value_loss: 0.5252
2024-07-11 17:22:41,428 [INFO    ] __main__: train step 17600: loss: 0.9551, policy_loss: 0.8684, value_loss: 0.5252
2024-07-11 17:22:41,657 [INFO    ] __main__: train step 17601: loss: 0.9551, policy_loss: 0.8684, value_loss: 0.5251
2024-07-11 17:22:41,893 [INFO    ] __main__: train step 17602: loss: 0.9551, policy_loss: 0.8684, value_loss: 0.5251
2024-07-11 17:22:42,092 [INFO    ] __main__: train step 17603: loss: 0.9551, policy_loss: 0.8684, value_loss: 0.5251
2024-07-11 17:22:42,305 [INFO    ] __main__: train step 17604: loss: 0.9551, policy_loss: 0.8683, value_loss: 0.5251
2024-07-11 17:22:42,496 [INFO    ] __main__: train step 17605: loss: 0.9550, policy_loss: 0.8683, value_loss: 0.5251
2024-07-11 17:22:42,710 [INFO    ] __main__: train step 17606: loss: 0.9550, policy_loss: 0.8683, value_loss: 0.5250
2024-07-11 17:22:42,937 [INFO    ] __main__: train step 17607: loss: 0.9550, policy_loss: 0.8683, value_loss: 0.5250
2024-07-11 17:22:43,141 [INFO    ] __main__: train step 17608: loss: 0.9550, policy_loss: 0.8682, value_loss: 0.5250
2024-07-11 17:22:43,341 [INFO    ] __main__: train step 17609: loss: 0.9550, policy_loss: 0.8682, value_loss: 0.5250
2024-07-11 17:22:43,545 [INFO    ] __main__: train step 17610: loss: 0.9549, policy_loss: 0.8682, value_loss: 0.5250
2024-07-11 17:22:43,749 [INFO    ] __main__: train step 17611: loss: 0.9549, policy_loss: 0.8681, value_loss: 0.5250
2024-07-11 17:22:45,197 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:22:45,550 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:22:45,606 [INFO    ] __main__: train step 17612: loss: 0.9549, policy_loss: 0.8681, value_loss: 0.5249
2024-07-11 17:22:45,781 [INFO    ] __main__: train step 17613: loss: 0.9549, policy_loss: 0.8681, value_loss: 0.5249
2024-07-11 17:22:45,991 [INFO    ] __main__: train step 17614: loss: 0.9549, policy_loss: 0.8681, value_loss: 0.5249
2024-07-11 17:22:46,195 [INFO    ] __main__: train step 17615: loss: 0.9548, policy_loss: 0.8680, value_loss: 0.5249
2024-07-11 17:22:46,396 [INFO    ] __main__: train step 17616: loss: 0.9548, policy_loss: 0.8680, value_loss: 0.5249
2024-07-11 17:22:46,600 [INFO    ] __main__: train step 17617: loss: 0.9548, policy_loss: 0.8680, value_loss: 0.5248
2024-07-11 17:22:46,801 [INFO    ] __main__: train step 17618: loss: 0.9548, policy_loss: 0.8680, value_loss: 0.5248
2024-07-11 17:22:47,010 [INFO    ] __main__: train step 17619: loss: 0.9548, policy_loss: 0.8679, value_loss: 0.5248
2024-07-11 17:22:47,220 [INFO    ] __main__: train step 17620: loss: 0.9547, policy_loss: 0.8679, value_loss: 0.5248
2024-07-11 17:22:47,421 [INFO    ] __main__: train step 17621: loss: 0.9547, policy_loss: 0.8679, value_loss: 0.5248
2024-07-11 17:22:47,639 [INFO    ] __main__: train step 17622: loss: 0.9547, policy_loss: 0.8678, value_loss: 0.5247
2024-07-11 17:22:47,873 [INFO    ] __main__: train step 17623: loss: 0.9547, policy_loss: 0.8678, value_loss: 0.5247
2024-07-11 17:22:48,085 [INFO    ] __main__: train step 17624: loss: 0.9546, policy_loss: 0.8678, value_loss: 0.5247
2024-07-11 17:22:48,304 [INFO    ] __main__: train step 17625: loss: 0.9546, policy_loss: 0.8678, value_loss: 0.5247
2024-07-11 17:22:48,512 [INFO    ] __main__: train step 17626: loss: 0.9546, policy_loss: 0.8677, value_loss: 0.5247
2024-07-11 17:22:48,738 [INFO    ] __main__: train step 17627: loss: 0.9546, policy_loss: 0.8677, value_loss: 0.5246
2024-07-11 17:22:48,943 [INFO    ] __main__: train step 17628: loss: 0.9546, policy_loss: 0.8677, value_loss: 0.5246
2024-07-11 17:22:50,359 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:22:50,776 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:22:50,838 [INFO    ] __main__: train step 17629: loss: 0.9545, policy_loss: 0.8677, value_loss: 0.5246
2024-07-11 17:22:51,016 [INFO    ] __main__: train step 17630: loss: 0.9545, policy_loss: 0.8676, value_loss: 0.5246
2024-07-11 17:22:51,222 [INFO    ] __main__: train step 17631: loss: 0.9545, policy_loss: 0.8676, value_loss: 0.5246
2024-07-11 17:22:51,429 [INFO    ] __main__: train step 17632: loss: 0.9545, policy_loss: 0.8676, value_loss: 0.5246
2024-07-11 17:22:51,638 [INFO    ] __main__: train step 17633: loss: 0.9545, policy_loss: 0.8676, value_loss: 0.5245
2024-07-11 17:22:51,841 [INFO    ] __main__: train step 17634: loss: 0.9544, policy_loss: 0.8675, value_loss: 0.5245
2024-07-11 17:22:52,045 [INFO    ] __main__: train step 17635: loss: 0.9544, policy_loss: 0.8675, value_loss: 0.5245
2024-07-11 17:22:52,249 [INFO    ] __main__: train step 17636: loss: 0.9544, policy_loss: 0.8675, value_loss: 0.5245
2024-07-11 17:22:52,461 [INFO    ] __main__: train step 17637: loss: 0.9544, policy_loss: 0.8674, value_loss: 0.5245
2024-07-11 17:22:52,671 [INFO    ] __main__: train step 17638: loss: 0.9544, policy_loss: 0.8674, value_loss: 0.5244
2024-07-11 17:22:54,602 [INFO    ] __main__: train step 17639: loss: 0.9543, policy_loss: 0.8674, value_loss: 0.5244
2024-07-11 17:22:54,811 [INFO    ] __main__: train step 17640: loss: 0.9543, policy_loss: 0.8674, value_loss: 0.5244
2024-07-11 17:22:55,018 [INFO    ] __main__: train step 17641: loss: 0.9543, policy_loss: 0.8673, value_loss: 0.5244
2024-07-11 17:22:55,219 [INFO    ] __main__: train step 17642: loss: 0.9543, policy_loss: 0.8673, value_loss: 0.5244
2024-07-11 17:22:55,433 [INFO    ] __main__: train step 17643: loss: 0.9543, policy_loss: 0.8673, value_loss: 0.5243
2024-07-11 17:22:55,636 [INFO    ] __main__: train step 17644: loss: 0.9542, policy_loss: 0.8673, value_loss: 0.5243
2024-07-11 17:22:55,838 [INFO    ] __main__: train step 17645: loss: 0.9542, policy_loss: 0.8672, value_loss: 0.5243
2024-07-11 17:22:57,243 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:22:57,649 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:22:57,713 [INFO    ] __main__: train step 17646: loss: 0.9542, policy_loss: 0.8672, value_loss: 0.5243
2024-07-11 17:22:57,892 [INFO    ] __main__: train step 17647: loss: 0.9542, policy_loss: 0.8672, value_loss: 0.5243
2024-07-11 17:22:58,098 [INFO    ] __main__: train step 17648: loss: 0.9541, policy_loss: 0.8671, value_loss: 0.5242
2024-07-11 17:22:58,290 [INFO    ] __main__: train step 17649: loss: 0.9541, policy_loss: 0.8671, value_loss: 0.5242
2024-07-11 17:22:58,497 [INFO    ] __main__: train step 17650: loss: 0.9541, policy_loss: 0.8671, value_loss: 0.5242
2024-07-11 17:22:58,695 [INFO    ] __main__: train step 17651: loss: 0.9541, policy_loss: 0.8671, value_loss: 0.5242
2024-07-11 17:22:58,895 [INFO    ] __main__: train step 17652: loss: 0.9541, policy_loss: 0.8670, value_loss: 0.5242
2024-07-11 17:22:59,096 [INFO    ] __main__: train step 17653: loss: 0.9540, policy_loss: 0.8670, value_loss: 0.5241
2024-07-11 17:22:59,301 [INFO    ] __main__: train step 17654: loss: 0.9540, policy_loss: 0.8670, value_loss: 0.5241
2024-07-11 17:22:59,517 [INFO    ] __main__: train step 17655: loss: 0.9540, policy_loss: 0.8670, value_loss: 0.5241
2024-07-11 17:22:59,746 [INFO    ] __main__: train step 17656: loss: 0.9540, policy_loss: 0.8669, value_loss: 0.5241
2024-07-11 17:22:59,955 [INFO    ] __main__: train step 17657: loss: 0.9539, policy_loss: 0.8669, value_loss: 0.5241
2024-07-11 17:23:00,197 [INFO    ] __main__: train step 17658: loss: 0.9539, policy_loss: 0.8669, value_loss: 0.5241
2024-07-11 17:23:00,423 [INFO    ] __main__: train step 17659: loss: 0.9539, policy_loss: 0.8669, value_loss: 0.5240
2024-07-11 17:23:00,638 [INFO    ] __main__: train step 17660: loss: 0.9539, policy_loss: 0.8668, value_loss: 0.5240
2024-07-11 17:23:00,846 [INFO    ] __main__: train step 17661: loss: 0.9539, policy_loss: 0.8668, value_loss: 0.5240
2024-07-11 17:23:01,071 [INFO    ] __main__: train step 17662: loss: 0.9538, policy_loss: 0.8668, value_loss: 0.5240
2024-07-11 17:23:02,494 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:23:02,860 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:23:02,918 [INFO    ] __main__: train step 17663: loss: 0.9538, policy_loss: 0.8667, value_loss: 0.5240
2024-07-11 17:23:03,106 [INFO    ] __main__: train step 17664: loss: 0.9538, policy_loss: 0.8667, value_loss: 0.5239
2024-07-11 17:23:03,358 [INFO    ] __main__: train step 17665: loss: 0.9538, policy_loss: 0.8667, value_loss: 0.5239
2024-07-11 17:23:03,579 [INFO    ] __main__: train step 17666: loss: 0.9537, policy_loss: 0.8667, value_loss: 0.5239
2024-07-11 17:23:03,793 [INFO    ] __main__: train step 17667: loss: 0.9537, policy_loss: 0.8666, value_loss: 0.5239
2024-07-11 17:23:03,988 [INFO    ] __main__: train step 17668: loss: 0.9537, policy_loss: 0.8666, value_loss: 0.5239
2024-07-11 17:23:04,214 [INFO    ] __main__: train step 17669: loss: 0.9537, policy_loss: 0.8666, value_loss: 0.5238
2024-07-11 17:23:04,436 [INFO    ] __main__: train step 17670: loss: 0.9537, policy_loss: 0.8666, value_loss: 0.5238
2024-07-11 17:23:04,638 [INFO    ] __main__: train step 17671: loss: 0.9536, policy_loss: 0.8665, value_loss: 0.5238
2024-07-11 17:23:04,844 [INFO    ] __main__: train step 17672: loss: 0.9536, policy_loss: 0.8665, value_loss: 0.5238
2024-07-11 17:23:05,054 [INFO    ] __main__: train step 17673: loss: 0.9536, policy_loss: 0.8665, value_loss: 0.5238
2024-07-11 17:23:05,260 [INFO    ] __main__: train step 17674: loss: 0.9536, policy_loss: 0.8664, value_loss: 0.5237
2024-07-11 17:23:05,467 [INFO    ] __main__: train step 17675: loss: 0.9536, policy_loss: 0.8664, value_loss: 0.5237
2024-07-11 17:23:05,680 [INFO    ] __main__: train step 17676: loss: 0.9535, policy_loss: 0.8664, value_loss: 0.5237
2024-07-11 17:23:05,910 [INFO    ] __main__: train step 17677: loss: 0.9535, policy_loss: 0.8664, value_loss: 0.5237
2024-07-11 17:23:06,115 [INFO    ] __main__: train step 17678: loss: 0.9535, policy_loss: 0.8663, value_loss: 0.5237
2024-07-11 17:23:06,332 [INFO    ] __main__: train step 17679: loss: 0.9535, policy_loss: 0.8663, value_loss: 0.5236
2024-07-11 17:23:07,720 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:23:08,080 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:23:08,139 [INFO    ] __main__: train step 17680: loss: 0.9534, policy_loss: 0.8663, value_loss: 0.5236
2024-07-11 17:23:08,310 [INFO    ] __main__: train step 17681: loss: 0.9534, policy_loss: 0.8663, value_loss: 0.5236
2024-07-11 17:23:08,518 [INFO    ] __main__: train step 17682: loss: 0.9534, policy_loss: 0.8662, value_loss: 0.5236
2024-07-11 17:23:08,730 [INFO    ] __main__: train step 17683: loss: 0.9534, policy_loss: 0.8662, value_loss: 0.5236
2024-07-11 17:23:08,969 [INFO    ] __main__: train step 17684: loss: 0.9534, policy_loss: 0.8662, value_loss: 0.5235
2024-07-11 17:23:09,175 [INFO    ] __main__: train step 17685: loss: 0.9533, policy_loss: 0.8661, value_loss: 0.5235
2024-07-11 17:23:09,386 [INFO    ] __main__: train step 17686: loss: 0.9533, policy_loss: 0.8661, value_loss: 0.5235
2024-07-11 17:23:09,623 [INFO    ] __main__: train step 17687: loss: 0.9533, policy_loss: 0.8661, value_loss: 0.5235
2024-07-11 17:23:09,833 [INFO    ] __main__: train step 17688: loss: 0.9533, policy_loss: 0.8661, value_loss: 0.5235
2024-07-11 17:23:10,034 [INFO    ] __main__: train step 17689: loss: 0.9532, policy_loss: 0.8660, value_loss: 0.5234
2024-07-11 17:23:10,246 [INFO    ] __main__: train step 17690: loss: 0.9532, policy_loss: 0.8660, value_loss: 0.5234
2024-07-11 17:23:10,445 [INFO    ] __main__: train step 17691: loss: 0.9532, policy_loss: 0.8660, value_loss: 0.5234
2024-07-11 17:23:10,642 [INFO    ] __main__: train step 17692: loss: 0.9532, policy_loss: 0.8660, value_loss: 0.5234
2024-07-11 17:23:10,843 [INFO    ] __main__: train step 17693: loss: 0.9531, policy_loss: 0.8659, value_loss: 0.5234
2024-07-11 17:23:11,049 [INFO    ] __main__: train step 17694: loss: 0.9531, policy_loss: 0.8659, value_loss: 0.5233
2024-07-11 17:23:11,260 [INFO    ] __main__: train step 17695: loss: 0.9531, policy_loss: 0.8659, value_loss: 0.5233
2024-07-11 17:23:11,470 [INFO    ] __main__: train step 17696: loss: 0.9531, policy_loss: 0.8658, value_loss: 0.5233
2024-07-11 17:23:12,867 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:23:13,216 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:23:13,273 [INFO    ] __main__: train step 17697: loss: 0.9531, policy_loss: 0.8658, value_loss: 0.5233
2024-07-11 17:23:13,451 [INFO    ] __main__: train step 17698: loss: 0.9530, policy_loss: 0.8658, value_loss: 0.5233
2024-07-11 17:23:13,661 [INFO    ] __main__: train step 17699: loss: 0.9530, policy_loss: 0.8658, value_loss: 0.5232
2024-07-11 17:23:13,866 [INFO    ] __main__: train step 17700: loss: 0.9530, policy_loss: 0.8657, value_loss: 0.5232
2024-07-11 17:23:14,074 [INFO    ] __main__: train step 17701: loss: 0.9530, policy_loss: 0.8657, value_loss: 0.5232
2024-07-11 17:23:14,275 [INFO    ] __main__: train step 17702: loss: 0.9529, policy_loss: 0.8657, value_loss: 0.5232
2024-07-11 17:23:14,493 [INFO    ] __main__: train step 17703: loss: 0.9529, policy_loss: 0.8657, value_loss: 0.5232
2024-07-11 17:23:14,761 [INFO    ] __main__: train step 17704: loss: 0.9529, policy_loss: 0.8656, value_loss: 0.5231
2024-07-11 17:23:14,995 [INFO    ] __main__: train step 17705: loss: 0.9529, policy_loss: 0.8656, value_loss: 0.5231
2024-07-11 17:23:15,219 [INFO    ] __main__: train step 17706: loss: 0.9529, policy_loss: 0.8656, value_loss: 0.5231
2024-07-11 17:23:15,426 [INFO    ] __main__: train step 17707: loss: 0.9528, policy_loss: 0.8656, value_loss: 0.5231
2024-07-11 17:23:15,631 [INFO    ] __main__: train step 17708: loss: 0.9528, policy_loss: 0.8655, value_loss: 0.5231
2024-07-11 17:23:15,842 [INFO    ] __main__: train step 17709: loss: 0.9528, policy_loss: 0.8655, value_loss: 0.5230
2024-07-11 17:23:16,050 [INFO    ] __main__: train step 17710: loss: 0.9528, policy_loss: 0.8655, value_loss: 0.5230
2024-07-11 17:23:16,249 [INFO    ] __main__: train step 17711: loss: 0.9528, policy_loss: 0.8654, value_loss: 0.5230
2024-07-11 17:23:16,461 [INFO    ] __main__: train step 17712: loss: 0.9527, policy_loss: 0.8654, value_loss: 0.5230
2024-07-11 17:23:16,686 [INFO    ] __main__: train step 17713: loss: 0.9527, policy_loss: 0.8654, value_loss: 0.5230
2024-07-11 17:23:18,102 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:23:18,536 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:23:18,592 [INFO    ] __main__: train step 17714: loss: 0.9527, policy_loss: 0.8654, value_loss: 0.5230
2024-07-11 17:23:18,772 [INFO    ] __main__: train step 17715: loss: 0.9527, policy_loss: 0.8653, value_loss: 0.5229
2024-07-11 17:23:18,975 [INFO    ] __main__: train step 17716: loss: 0.9526, policy_loss: 0.8653, value_loss: 0.5229
2024-07-11 17:23:19,181 [INFO    ] __main__: train step 17717: loss: 0.9526, policy_loss: 0.8653, value_loss: 0.5229
2024-07-11 17:23:19,379 [INFO    ] __main__: train step 17718: loss: 0.9526, policy_loss: 0.8653, value_loss: 0.5229
2024-07-11 17:23:19,588 [INFO    ] __main__: train step 17719: loss: 0.9526, policy_loss: 0.8652, value_loss: 0.5229
2024-07-11 17:23:19,793 [INFO    ] __main__: train step 17720: loss: 0.9526, policy_loss: 0.8652, value_loss: 0.5228
2024-07-11 17:23:20,002 [INFO    ] __main__: train step 17721: loss: 0.9525, policy_loss: 0.8652, value_loss: 0.5228
2024-07-11 17:23:20,202 [INFO    ] __main__: train step 17722: loss: 0.9525, policy_loss: 0.8651, value_loss: 0.5228
2024-07-11 17:23:20,406 [INFO    ] __main__: train step 17723: loss: 0.9525, policy_loss: 0.8651, value_loss: 0.5228
2024-07-11 17:23:20,608 [INFO    ] __main__: train step 17724: loss: 0.9525, policy_loss: 0.8651, value_loss: 0.5228
2024-07-11 17:23:20,814 [INFO    ] __main__: train step 17725: loss: 0.9524, policy_loss: 0.8651, value_loss: 0.5227
2024-07-11 17:23:21,018 [INFO    ] __main__: train step 17726: loss: 0.9524, policy_loss: 0.8650, value_loss: 0.5227
2024-07-11 17:23:21,249 [INFO    ] __main__: train step 17727: loss: 0.9524, policy_loss: 0.8650, value_loss: 0.5227
2024-07-11 17:23:21,478 [INFO    ] __main__: train step 17728: loss: 0.9524, policy_loss: 0.8650, value_loss: 0.5227
2024-07-11 17:23:21,682 [INFO    ] __main__: train step 17729: loss: 0.9523, policy_loss: 0.8650, value_loss: 0.5227
2024-07-11 17:23:21,884 [INFO    ] __main__: train step 17730: loss: 0.9523, policy_loss: 0.8649, value_loss: 0.5226
2024-07-11 17:23:23,328 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:23:23,702 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:23:23,759 [INFO    ] __main__: train step 17731: loss: 0.9523, policy_loss: 0.8649, value_loss: 0.5226
2024-07-11 17:23:23,937 [INFO    ] __main__: train step 17732: loss: 0.9523, policy_loss: 0.8649, value_loss: 0.5226
2024-07-11 17:23:24,185 [INFO    ] __main__: train step 17733: loss: 0.9523, policy_loss: 0.8648, value_loss: 0.5226
2024-07-11 17:23:24,390 [INFO    ] __main__: train step 17734: loss: 0.9522, policy_loss: 0.8648, value_loss: 0.5226
2024-07-11 17:23:24,591 [INFO    ] __main__: train step 17735: loss: 0.9522, policy_loss: 0.8648, value_loss: 0.5225
2024-07-11 17:23:24,822 [INFO    ] __main__: train step 17736: loss: 0.9522, policy_loss: 0.8648, value_loss: 0.5225
2024-07-11 17:23:25,025 [INFO    ] __main__: train step 17737: loss: 0.9522, policy_loss: 0.8647, value_loss: 0.5225
2024-07-11 17:23:25,220 [INFO    ] __main__: train step 17738: loss: 0.9521, policy_loss: 0.8647, value_loss: 0.5225
2024-07-11 17:23:25,424 [INFO    ] __main__: train step 17739: loss: 0.9521, policy_loss: 0.8647, value_loss: 0.5225
2024-07-11 17:23:25,625 [INFO    ] __main__: train step 17740: loss: 0.9521, policy_loss: 0.8647, value_loss: 0.5224
2024-07-11 17:23:25,823 [INFO    ] __main__: train step 17741: loss: 0.9521, policy_loss: 0.8646, value_loss: 0.5224
2024-07-11 17:23:26,018 [INFO    ] __main__: train step 17742: loss: 0.9521, policy_loss: 0.8646, value_loss: 0.5224
2024-07-11 17:23:26,229 [INFO    ] __main__: train step 17743: loss: 0.9520, policy_loss: 0.8646, value_loss: 0.5224
2024-07-11 17:23:26,439 [INFO    ] __main__: train step 17744: loss: 0.9520, policy_loss: 0.8645, value_loss: 0.5224
2024-07-11 17:23:26,667 [INFO    ] __main__: train step 17745: loss: 0.9520, policy_loss: 0.8645, value_loss: 0.5223
2024-07-11 17:23:26,890 [INFO    ] __main__: train step 17746: loss: 0.9520, policy_loss: 0.8645, value_loss: 0.5223
2024-07-11 17:23:27,102 [INFO    ] __main__: train step 17747: loss: 0.9519, policy_loss: 0.8645, value_loss: 0.5223
2024-07-11 17:23:28,541 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:23:28,927 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:23:28,985 [INFO    ] __main__: train step 17748: loss: 0.9519, policy_loss: 0.8644, value_loss: 0.5223
2024-07-11 17:23:29,166 [INFO    ] __main__: train step 17749: loss: 0.9519, policy_loss: 0.8644, value_loss: 0.5223
2024-07-11 17:23:29,375 [INFO    ] __main__: train step 17750: loss: 0.9519, policy_loss: 0.8644, value_loss: 0.5222
2024-07-11 17:23:29,618 [INFO    ] __main__: train step 17751: loss: 0.9519, policy_loss: 0.8644, value_loss: 0.5222
2024-07-11 17:23:29,839 [INFO    ] __main__: train step 17752: loss: 0.9518, policy_loss: 0.8643, value_loss: 0.5222
2024-07-11 17:23:30,050 [INFO    ] __main__: train step 17753: loss: 0.9518, policy_loss: 0.8643, value_loss: 0.5222
2024-07-11 17:23:31,973 [INFO    ] __main__: train step 17754: loss: 0.9518, policy_loss: 0.8643, value_loss: 0.5222
2024-07-11 17:23:32,159 [INFO    ] __main__: train step 17755: loss: 0.9518, policy_loss: 0.8642, value_loss: 0.5221
2024-07-11 17:23:32,373 [INFO    ] __main__: train step 17756: loss: 0.9517, policy_loss: 0.8642, value_loss: 0.5221
2024-07-11 17:23:32,617 [INFO    ] __main__: train step 17757: loss: 0.9517, policy_loss: 0.8642, value_loss: 0.5221
2024-07-11 17:23:32,826 [INFO    ] __main__: train step 17758: loss: 0.9517, policy_loss: 0.8642, value_loss: 0.5221
2024-07-11 17:23:33,055 [INFO    ] __main__: train step 17759: loss: 0.9517, policy_loss: 0.8641, value_loss: 0.5221
2024-07-11 17:23:33,258 [INFO    ] __main__: train step 17760: loss: 0.9517, policy_loss: 0.8641, value_loss: 0.5220
2024-07-11 17:23:33,460 [INFO    ] __main__: train step 17761: loss: 0.9516, policy_loss: 0.8641, value_loss: 0.5220
2024-07-11 17:23:33,666 [INFO    ] __main__: train step 17762: loss: 0.9516, policy_loss: 0.8641, value_loss: 0.5220
2024-07-11 17:23:33,873 [INFO    ] __main__: train step 17763: loss: 0.9516, policy_loss: 0.8640, value_loss: 0.5220
2024-07-11 17:23:34,075 [INFO    ] __main__: train step 17764: loss: 0.9516, policy_loss: 0.8640, value_loss: 0.5220
2024-07-11 17:23:35,513 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:23:35,913 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:23:35,969 [INFO    ] __main__: train step 17765: loss: 0.9515, policy_loss: 0.8640, value_loss: 0.5219
2024-07-11 17:23:36,159 [INFO    ] __main__: train step 17766: loss: 0.9515, policy_loss: 0.8639, value_loss: 0.5219
2024-07-11 17:23:36,357 [INFO    ] __main__: train step 17767: loss: 0.9515, policy_loss: 0.8639, value_loss: 0.5219
2024-07-11 17:23:36,567 [INFO    ] __main__: train step 17768: loss: 0.9515, policy_loss: 0.8639, value_loss: 0.5219
2024-07-11 17:23:36,779 [INFO    ] __main__: train step 17769: loss: 0.9514, policy_loss: 0.8639, value_loss: 0.5219
2024-07-11 17:23:36,973 [INFO    ] __main__: train step 17770: loss: 0.9514, policy_loss: 0.8638, value_loss: 0.5218
2024-07-11 17:23:37,183 [INFO    ] __main__: train step 17771: loss: 0.9514, policy_loss: 0.8638, value_loss: 0.5218
2024-07-11 17:23:37,388 [INFO    ] __main__: train step 17772: loss: 0.9514, policy_loss: 0.8638, value_loss: 0.5218
2024-07-11 17:23:37,582 [INFO    ] __main__: train step 17773: loss: 0.9514, policy_loss: 0.8638, value_loss: 0.5218
2024-07-11 17:23:37,786 [INFO    ] __main__: train step 17774: loss: 0.9513, policy_loss: 0.8637, value_loss: 0.5218
2024-07-11 17:23:37,992 [INFO    ] __main__: train step 17775: loss: 0.9513, policy_loss: 0.8637, value_loss: 0.5217
2024-07-11 17:23:38,205 [INFO    ] __main__: train step 17776: loss: 0.9513, policy_loss: 0.8637, value_loss: 0.5217
2024-07-11 17:23:38,449 [INFO    ] __main__: train step 17777: loss: 0.9513, policy_loss: 0.8637, value_loss: 0.5217
2024-07-11 17:23:38,653 [INFO    ] __main__: train step 17778: loss: 0.9512, policy_loss: 0.8636, value_loss: 0.5217
2024-07-11 17:23:38,866 [INFO    ] __main__: train step 17779: loss: 0.9512, policy_loss: 0.8636, value_loss: 0.5217
2024-07-11 17:23:39,080 [INFO    ] __main__: train step 17780: loss: 0.9512, policy_loss: 0.8636, value_loss: 0.5216
2024-07-11 17:23:39,321 [INFO    ] __main__: train step 17781: loss: 0.9512, policy_loss: 0.8635, value_loss: 0.5216
2024-07-11 17:23:40,778 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:23:41,142 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:23:41,202 [INFO    ] __main__: train step 17782: loss: 0.9511, policy_loss: 0.8635, value_loss: 0.5216
2024-07-11 17:23:41,371 [INFO    ] __main__: train step 17783: loss: 0.9511, policy_loss: 0.8635, value_loss: 0.5216
2024-07-11 17:23:41,593 [INFO    ] __main__: train step 17784: loss: 0.9511, policy_loss: 0.8635, value_loss: 0.5216
2024-07-11 17:23:41,805 [INFO    ] __main__: train step 17785: loss: 0.9511, policy_loss: 0.8634, value_loss: 0.5215
2024-07-11 17:23:42,010 [INFO    ] __main__: train step 17786: loss: 0.9511, policy_loss: 0.8634, value_loss: 0.5215
2024-07-11 17:23:42,215 [INFO    ] __main__: train step 17787: loss: 0.9510, policy_loss: 0.8634, value_loss: 0.5215
2024-07-11 17:23:42,411 [INFO    ] __main__: train step 17788: loss: 0.9510, policy_loss: 0.8634, value_loss: 0.5215
2024-07-11 17:23:42,612 [INFO    ] __main__: train step 17789: loss: 0.9510, policy_loss: 0.8633, value_loss: 0.5214
2024-07-11 17:23:42,822 [INFO    ] __main__: train step 17790: loss: 0.9510, policy_loss: 0.8633, value_loss: 0.5214
2024-07-11 17:23:43,020 [INFO    ] __main__: train step 17791: loss: 0.9509, policy_loss: 0.8633, value_loss: 0.5214
2024-07-11 17:23:43,225 [INFO    ] __main__: train step 17792: loss: 0.9509, policy_loss: 0.8632, value_loss: 0.5214
2024-07-11 17:23:43,430 [INFO    ] __main__: train step 17793: loss: 0.9509, policy_loss: 0.8632, value_loss: 0.5214
2024-07-11 17:23:43,658 [INFO    ] __main__: train step 17794: loss: 0.9509, policy_loss: 0.8632, value_loss: 0.5213
2024-07-11 17:23:43,853 [INFO    ] __main__: train step 17795: loss: 0.9508, policy_loss: 0.8632, value_loss: 0.5213
2024-07-11 17:23:44,049 [INFO    ] __main__: train step 17796: loss: 0.9508, policy_loss: 0.8631, value_loss: 0.5213
2024-07-11 17:23:44,243 [INFO    ] __main__: train step 17797: loss: 0.9508, policy_loss: 0.8631, value_loss: 0.5213
2024-07-11 17:23:44,446 [INFO    ] __main__: train step 17798: loss: 0.9508, policy_loss: 0.8631, value_loss: 0.5213
2024-07-11 17:23:45,892 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:23:46,247 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:23:46,304 [INFO    ] __main__: train step 17799: loss: 0.9508, policy_loss: 0.8631, value_loss: 0.5212
2024-07-11 17:23:46,489 [INFO    ] __main__: train step 17800: loss: 0.9507, policy_loss: 0.8630, value_loss: 0.5212
2024-07-11 17:23:46,687 [INFO    ] __main__: train step 17801: loss: 0.9507, policy_loss: 0.8630, value_loss: 0.5212
2024-07-11 17:23:46,891 [INFO    ] __main__: train step 17802: loss: 0.9507, policy_loss: 0.8630, value_loss: 0.5212
2024-07-11 17:23:47,095 [INFO    ] __main__: train step 17803: loss: 0.9507, policy_loss: 0.8630, value_loss: 0.5212
2024-07-11 17:23:47,301 [INFO    ] __main__: train step 17804: loss: 0.9506, policy_loss: 0.8629, value_loss: 0.5211
2024-07-11 17:23:47,520 [INFO    ] __main__: train step 17805: loss: 0.9506, policy_loss: 0.8629, value_loss: 0.5211
2024-07-11 17:23:47,761 [INFO    ] __main__: train step 17806: loss: 0.9506, policy_loss: 0.8629, value_loss: 0.5211
2024-07-11 17:23:47,995 [INFO    ] __main__: train step 17807: loss: 0.9506, policy_loss: 0.8628, value_loss: 0.5211
2024-07-11 17:23:48,200 [INFO    ] __main__: train step 17808: loss: 0.9506, policy_loss: 0.8628, value_loss: 0.5211
2024-07-11 17:23:48,425 [INFO    ] __main__: train step 17809: loss: 0.9505, policy_loss: 0.8628, value_loss: 0.5210
2024-07-11 17:23:48,642 [INFO    ] __main__: train step 17810: loss: 0.9505, policy_loss: 0.8628, value_loss: 0.5210
2024-07-11 17:23:48,849 [INFO    ] __main__: train step 17811: loss: 0.9505, policy_loss: 0.8627, value_loss: 0.5210
2024-07-11 17:23:49,053 [INFO    ] __main__: train step 17812: loss: 0.9505, policy_loss: 0.8627, value_loss: 0.5210
2024-07-11 17:23:49,267 [INFO    ] __main__: train step 17813: loss: 0.9504, policy_loss: 0.8627, value_loss: 0.5210
2024-07-11 17:23:49,495 [INFO    ] __main__: train step 17814: loss: 0.9504, policy_loss: 0.8627, value_loss: 0.5209
2024-07-11 17:23:49,715 [INFO    ] __main__: train step 17815: loss: 0.9504, policy_loss: 0.8626, value_loss: 0.5209
2024-07-11 17:23:51,158 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:23:51,532 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:23:51,589 [INFO    ] __main__: train step 17816: loss: 0.9504, policy_loss: 0.8626, value_loss: 0.5209
2024-07-11 17:23:51,759 [INFO    ] __main__: train step 17817: loss: 0.9503, policy_loss: 0.8626, value_loss: 0.5209
2024-07-11 17:23:51,969 [INFO    ] __main__: train step 17818: loss: 0.9503, policy_loss: 0.8626, value_loss: 0.5209
2024-07-11 17:23:52,178 [INFO    ] __main__: train step 17819: loss: 0.9503, policy_loss: 0.8625, value_loss: 0.5208
2024-07-11 17:23:52,379 [INFO    ] __main__: train step 17820: loss: 0.9503, policy_loss: 0.8625, value_loss: 0.5208
2024-07-11 17:23:52,575 [INFO    ] __main__: train step 17821: loss: 0.9502, policy_loss: 0.8625, value_loss: 0.5208
2024-07-11 17:23:52,782 [INFO    ] __main__: train step 17822: loss: 0.9502, policy_loss: 0.8624, value_loss: 0.5208
2024-07-11 17:23:52,981 [INFO    ] __main__: train step 17823: loss: 0.9502, policy_loss: 0.8624, value_loss: 0.5207
2024-07-11 17:23:53,184 [INFO    ] __main__: train step 17824: loss: 0.9502, policy_loss: 0.8624, value_loss: 0.5207
2024-07-11 17:23:53,398 [INFO    ] __main__: train step 17825: loss: 0.9502, policy_loss: 0.8624, value_loss: 0.5207
2024-07-11 17:23:53,612 [INFO    ] __main__: train step 17826: loss: 0.9501, policy_loss: 0.8623, value_loss: 0.5207
2024-07-11 17:23:53,858 [INFO    ] __main__: train step 17827: loss: 0.9501, policy_loss: 0.8623, value_loss: 0.5207
2024-07-11 17:23:54,070 [INFO    ] __main__: train step 17828: loss: 0.9501, policy_loss: 0.8623, value_loss: 0.5206
2024-07-11 17:23:54,307 [INFO    ] __main__: train step 17829: loss: 0.9501, policy_loss: 0.8623, value_loss: 0.5206
2024-07-11 17:23:54,538 [INFO    ] __main__: train step 17830: loss: 0.9500, policy_loss: 0.8622, value_loss: 0.5206
2024-07-11 17:23:54,748 [INFO    ] __main__: train step 17831: loss: 0.9500, policy_loss: 0.8622, value_loss: 0.5206
2024-07-11 17:23:54,988 [INFO    ] __main__: train step 17832: loss: 0.9500, policy_loss: 0.8622, value_loss: 0.5206
2024-07-11 17:23:56,432 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:23:56,866 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:23:56,933 [INFO    ] __main__: train step 17833: loss: 0.9500, policy_loss: 0.8621, value_loss: 0.5205
2024-07-11 17:23:57,106 [INFO    ] __main__: train step 17834: loss: 0.9499, policy_loss: 0.8621, value_loss: 0.5205
2024-07-11 17:23:57,309 [INFO    ] __main__: train step 17835: loss: 0.9499, policy_loss: 0.8621, value_loss: 0.5205
2024-07-11 17:23:57,514 [INFO    ] __main__: train step 17836: loss: 0.9499, policy_loss: 0.8621, value_loss: 0.5205
2024-07-11 17:23:57,715 [INFO    ] __main__: train step 17837: loss: 0.9499, policy_loss: 0.8620, value_loss: 0.5205
2024-07-11 17:23:57,914 [INFO    ] __main__: train step 17838: loss: 0.9498, policy_loss: 0.8620, value_loss: 0.5204
2024-07-11 17:23:58,117 [INFO    ] __main__: train step 17839: loss: 0.9498, policy_loss: 0.8620, value_loss: 0.5204
2024-07-11 17:23:58,320 [INFO    ] __main__: train step 17840: loss: 0.9498, policy_loss: 0.8620, value_loss: 0.5204
2024-07-11 17:23:58,518 [INFO    ] __main__: train step 17841: loss: 0.9498, policy_loss: 0.8619, value_loss: 0.5204
2024-07-11 17:23:58,717 [INFO    ] __main__: train step 17842: loss: 0.9498, policy_loss: 0.8619, value_loss: 0.5204
2024-07-11 17:23:58,923 [INFO    ] __main__: train step 17843: loss: 0.9497, policy_loss: 0.8619, value_loss: 0.5203
2024-07-11 17:23:59,131 [INFO    ] __main__: train step 17844: loss: 0.9497, policy_loss: 0.8618, value_loss: 0.5203
2024-07-11 17:23:59,338 [INFO    ] __main__: train step 17845: loss: 0.9497, policy_loss: 0.8618, value_loss: 0.5203
2024-07-11 17:23:59,551 [INFO    ] __main__: train step 17846: loss: 0.9497, policy_loss: 0.8618, value_loss: 0.5203
2024-07-11 17:23:59,768 [INFO    ] __main__: train step 17847: loss: 0.9496, policy_loss: 0.8618, value_loss: 0.5202
2024-07-11 17:23:59,972 [INFO    ] __main__: train step 17848: loss: 0.9496, policy_loss: 0.8617, value_loss: 0.5202
2024-07-11 17:24:00,178 [INFO    ] __main__: train step 17849: loss: 0.9496, policy_loss: 0.8617, value_loss: 0.5202
2024-07-11 17:24:01,590 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:24:01,950 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:24:02,006 [INFO    ] __main__: train step 17850: loss: 0.9496, policy_loss: 0.8617, value_loss: 0.5202
2024-07-11 17:24:02,185 [INFO    ] __main__: train step 17851: loss: 0.9495, policy_loss: 0.8617, value_loss: 0.5202
2024-07-11 17:24:02,429 [INFO    ] __main__: train step 17852: loss: 0.9495, policy_loss: 0.8616, value_loss: 0.5201
2024-07-11 17:24:02,667 [INFO    ] __main__: train step 17853: loss: 0.9495, policy_loss: 0.8616, value_loss: 0.5201
2024-07-11 17:24:02,875 [INFO    ] __main__: train step 17854: loss: 0.9495, policy_loss: 0.8616, value_loss: 0.5201
2024-07-11 17:24:03,076 [INFO    ] __main__: train step 17855: loss: 0.9494, policy_loss: 0.8616, value_loss: 0.5201
2024-07-11 17:24:03,286 [INFO    ] __main__: train step 17856: loss: 0.9494, policy_loss: 0.8615, value_loss: 0.5201
2024-07-11 17:24:03,487 [INFO    ] __main__: train step 17857: loss: 0.9494, policy_loss: 0.8615, value_loss: 0.5200
2024-07-11 17:24:03,688 [INFO    ] __main__: train step 17858: loss: 0.9494, policy_loss: 0.8615, value_loss: 0.5200
2024-07-11 17:24:03,891 [INFO    ] __main__: train step 17859: loss: 0.9493, policy_loss: 0.8614, value_loss: 0.5200
2024-07-11 17:24:04,093 [INFO    ] __main__: train step 17860: loss: 0.9493, policy_loss: 0.8614, value_loss: 0.5200
2024-07-11 17:24:04,294 [INFO    ] __main__: train step 17861: loss: 0.9493, policy_loss: 0.8614, value_loss: 0.5200
2024-07-11 17:24:04,494 [INFO    ] __main__: train step 17862: loss: 0.9493, policy_loss: 0.8614, value_loss: 0.5199
2024-07-11 17:24:04,698 [INFO    ] __main__: train step 17863: loss: 0.9493, policy_loss: 0.8613, value_loss: 0.5199
2024-07-11 17:24:04,905 [INFO    ] __main__: train step 17864: loss: 0.9492, policy_loss: 0.8613, value_loss: 0.5199
2024-07-11 17:24:05,130 [INFO    ] __main__: train step 17865: loss: 0.9492, policy_loss: 0.8613, value_loss: 0.5199
2024-07-11 17:24:05,345 [INFO    ] __main__: train step 17866: loss: 0.9492, policy_loss: 0.8613, value_loss: 0.5199
2024-07-11 17:24:08,500 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:24:08,951 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:24:09,013 [INFO    ] __main__: train step 17867: loss: 0.9492, policy_loss: 0.8612, value_loss: 0.5198
2024-07-11 17:24:09,198 [INFO    ] __main__: train step 17868: loss: 0.9491, policy_loss: 0.8612, value_loss: 0.5198
2024-07-11 17:24:09,414 [INFO    ] __main__: train step 17869: loss: 0.9491, policy_loss: 0.8612, value_loss: 0.5198
2024-07-11 17:24:09,613 [INFO    ] __main__: train step 17870: loss: 0.9491, policy_loss: 0.8611, value_loss: 0.5198
2024-07-11 17:24:09,830 [INFO    ] __main__: train step 17871: loss: 0.9491, policy_loss: 0.8611, value_loss: 0.5197
2024-07-11 17:24:10,044 [INFO    ] __main__: train step 17872: loss: 0.9490, policy_loss: 0.8611, value_loss: 0.5197
2024-07-11 17:24:10,253 [INFO    ] __main__: train step 17873: loss: 0.9490, policy_loss: 0.8611, value_loss: 0.5197
2024-07-11 17:24:10,465 [INFO    ] __main__: train step 17874: loss: 0.9490, policy_loss: 0.8610, value_loss: 0.5197
2024-07-11 17:24:10,692 [INFO    ] __main__: train step 17875: loss: 0.9490, policy_loss: 0.8610, value_loss: 0.5197
2024-07-11 17:24:10,896 [INFO    ] __main__: train step 17876: loss: 0.9489, policy_loss: 0.8610, value_loss: 0.5196
2024-07-11 17:24:11,107 [INFO    ] __main__: train step 17877: loss: 0.9489, policy_loss: 0.8610, value_loss: 0.5196
2024-07-11 17:24:11,308 [INFO    ] __main__: train step 17878: loss: 0.9489, policy_loss: 0.8609, value_loss: 0.5196
2024-07-11 17:24:11,544 [INFO    ] __main__: train step 17879: loss: 0.9489, policy_loss: 0.8609, value_loss: 0.5196
2024-07-11 17:24:11,791 [INFO    ] __main__: train step 17880: loss: 0.9488, policy_loss: 0.8609, value_loss: 0.5196
2024-07-11 17:24:12,023 [INFO    ] __main__: train step 17881: loss: 0.9488, policy_loss: 0.8608, value_loss: 0.5195
2024-07-11 17:24:12,245 [INFO    ] __main__: train step 17882: loss: 0.9488, policy_loss: 0.8608, value_loss: 0.5195
2024-07-11 17:24:12,449 [INFO    ] __main__: train step 17883: loss: 0.9488, policy_loss: 0.8608, value_loss: 0.5195
2024-07-11 17:24:13,904 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:24:14,325 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:24:14,386 [INFO    ] __main__: train step 17884: loss: 0.9487, policy_loss: 0.8608, value_loss: 0.5195
2024-07-11 17:24:14,579 [INFO    ] __main__: train step 17885: loss: 0.9487, policy_loss: 0.8607, value_loss: 0.5194
2024-07-11 17:24:14,835 [INFO    ] __main__: train step 17886: loss: 0.9487, policy_loss: 0.8607, value_loss: 0.5194
2024-07-11 17:24:15,076 [INFO    ] __main__: train step 17887: loss: 0.9487, policy_loss: 0.8607, value_loss: 0.5194
2024-07-11 17:24:15,291 [INFO    ] __main__: train step 17888: loss: 0.9487, policy_loss: 0.8607, value_loss: 0.5194
2024-07-11 17:24:15,497 [INFO    ] __main__: train step 17889: loss: 0.9486, policy_loss: 0.8606, value_loss: 0.5194
2024-07-11 17:24:15,709 [INFO    ] __main__: train step 17890: loss: 0.9486, policy_loss: 0.8606, value_loss: 0.5193
2024-07-11 17:24:15,915 [INFO    ] __main__: train step 17891: loss: 0.9486, policy_loss: 0.8606, value_loss: 0.5193
2024-07-11 17:24:16,129 [INFO    ] __main__: train step 17892: loss: 0.9486, policy_loss: 0.8606, value_loss: 0.5193
2024-07-11 17:24:16,368 [INFO    ] __main__: train step 17893: loss: 0.9485, policy_loss: 0.8605, value_loss: 0.5193
2024-07-11 17:24:16,569 [INFO    ] __main__: train step 17894: loss: 0.9485, policy_loss: 0.8605, value_loss: 0.5193
2024-07-11 17:24:16,772 [INFO    ] __main__: train step 17895: loss: 0.9485, policy_loss: 0.8605, value_loss: 0.5192
2024-07-11 17:24:16,980 [INFO    ] __main__: train step 17896: loss: 0.9485, policy_loss: 0.8604, value_loss: 0.5192
2024-07-11 17:24:17,192 [INFO    ] __main__: train step 17897: loss: 0.9484, policy_loss: 0.8604, value_loss: 0.5192
2024-07-11 17:24:17,389 [INFO    ] __main__: train step 17898: loss: 0.9484, policy_loss: 0.8604, value_loss: 0.5192
2024-07-11 17:24:17,627 [INFO    ] __main__: train step 17899: loss: 0.9484, policy_loss: 0.8604, value_loss: 0.5191
2024-07-11 17:24:17,869 [INFO    ] __main__: train step 17900: loss: 0.9484, policy_loss: 0.8603, value_loss: 0.5191
2024-07-11 17:24:19,312 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:24:19,703 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:24:19,760 [INFO    ] __main__: train step 17901: loss: 0.9483, policy_loss: 0.8603, value_loss: 0.5191
2024-07-11 17:24:19,946 [INFO    ] __main__: train step 17902: loss: 0.9483, policy_loss: 0.8603, value_loss: 0.5191
2024-07-11 17:24:20,143 [INFO    ] __main__: train step 17903: loss: 0.9483, policy_loss: 0.8603, value_loss: 0.5191
2024-07-11 17:24:20,349 [INFO    ] __main__: train step 17904: loss: 0.9483, policy_loss: 0.8602, value_loss: 0.5190
2024-07-11 17:24:20,569 [INFO    ] __main__: train step 17905: loss: 0.9482, policy_loss: 0.8602, value_loss: 0.5190
2024-07-11 17:24:20,811 [INFO    ] __main__: train step 17906: loss: 0.9482, policy_loss: 0.8602, value_loss: 0.5190
2024-07-11 17:24:21,039 [INFO    ] __main__: train step 17907: loss: 0.9482, policy_loss: 0.8601, value_loss: 0.5190
2024-07-11 17:24:21,248 [INFO    ] __main__: train step 17908: loss: 0.9482, policy_loss: 0.8601, value_loss: 0.5190
2024-07-11 17:24:21,451 [INFO    ] __main__: train step 17909: loss: 0.9481, policy_loss: 0.8601, value_loss: 0.5189
2024-07-11 17:24:21,651 [INFO    ] __main__: train step 17910: loss: 0.9481, policy_loss: 0.8601, value_loss: 0.5189
2024-07-11 17:24:21,861 [INFO    ] __main__: train step 17911: loss: 0.9481, policy_loss: 0.8600, value_loss: 0.5189
2024-07-11 17:24:22,064 [INFO    ] __main__: train step 17912: loss: 0.9481, policy_loss: 0.8600, value_loss: 0.5189
2024-07-11 17:24:22,270 [INFO    ] __main__: train step 17913: loss: 0.9480, policy_loss: 0.8600, value_loss: 0.5188
2024-07-11 17:24:22,475 [INFO    ] __main__: train step 17914: loss: 0.9480, policy_loss: 0.8600, value_loss: 0.5188
2024-07-11 17:24:22,684 [INFO    ] __main__: train step 17915: loss: 0.9480, policy_loss: 0.8599, value_loss: 0.5188
2024-07-11 17:24:22,881 [INFO    ] __main__: train step 17916: loss: 0.9480, policy_loss: 0.8599, value_loss: 0.5188
2024-07-11 17:24:23,078 [INFO    ] __main__: train step 17917: loss: 0.9479, policy_loss: 0.8599, value_loss: 0.5188
2024-07-11 17:24:24,515 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:24:24,907 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:24:24,963 [INFO    ] __main__: train step 17918: loss: 0.9479, policy_loss: 0.8598, value_loss: 0.5187
2024-07-11 17:24:25,149 [INFO    ] __main__: train step 17919: loss: 0.9479, policy_loss: 0.8598, value_loss: 0.5187
2024-07-11 17:24:25,377 [INFO    ] __main__: train step 17920: loss: 0.9479, policy_loss: 0.8598, value_loss: 0.5187
2024-07-11 17:24:25,580 [INFO    ] __main__: train step 17921: loss: 0.9478, policy_loss: 0.8598, value_loss: 0.5187
2024-07-11 17:24:25,782 [INFO    ] __main__: train step 17922: loss: 0.9478, policy_loss: 0.8597, value_loss: 0.5187
2024-07-11 17:24:25,983 [INFO    ] __main__: train step 17923: loss: 0.9478, policy_loss: 0.8597, value_loss: 0.5186
2024-07-11 17:24:26,206 [INFO    ] __main__: train step 17924: loss: 0.9478, policy_loss: 0.8597, value_loss: 0.5186
2024-07-11 17:24:26,396 [INFO    ] __main__: train step 17925: loss: 0.9477, policy_loss: 0.8597, value_loss: 0.5186
2024-07-11 17:24:26,620 [INFO    ] __main__: train step 17926: loss: 0.9477, policy_loss: 0.8596, value_loss: 0.5186
2024-07-11 17:24:26,843 [INFO    ] __main__: train step 17927: loss: 0.9477, policy_loss: 0.8596, value_loss: 0.5185
2024-07-11 17:24:27,069 [INFO    ] __main__: train step 17928: loss: 0.9477, policy_loss: 0.8596, value_loss: 0.5185
2024-07-11 17:24:27,292 [INFO    ] __main__: train step 17929: loss: 0.9477, policy_loss: 0.8596, value_loss: 0.5185
2024-07-11 17:24:27,508 [INFO    ] __main__: train step 17930: loss: 0.9476, policy_loss: 0.8595, value_loss: 0.5185
2024-07-11 17:24:27,716 [INFO    ] __main__: train step 17931: loss: 0.9476, policy_loss: 0.8595, value_loss: 0.5185
2024-07-11 17:24:27,916 [INFO    ] __main__: train step 17932: loss: 0.9476, policy_loss: 0.8595, value_loss: 0.5184
2024-07-11 17:24:28,119 [INFO    ] __main__: train step 17933: loss: 0.9476, policy_loss: 0.8594, value_loss: 0.5184
2024-07-11 17:24:28,321 [INFO    ] __main__: train step 17934: loss: 0.9475, policy_loss: 0.8594, value_loss: 0.5184
2024-07-11 17:24:29,765 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:24:30,177 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:24:30,234 [INFO    ] __main__: train step 17935: loss: 0.9475, policy_loss: 0.8594, value_loss: 0.5184
2024-07-11 17:24:30,417 [INFO    ] __main__: train step 17936: loss: 0.9475, policy_loss: 0.8594, value_loss: 0.5184
2024-07-11 17:24:30,623 [INFO    ] __main__: train step 17937: loss: 0.9475, policy_loss: 0.8593, value_loss: 0.5183
2024-07-11 17:24:30,859 [INFO    ] __main__: train step 17938: loss: 0.9474, policy_loss: 0.8593, value_loss: 0.5183
2024-07-11 17:24:31,059 [INFO    ] __main__: train step 17939: loss: 0.9474, policy_loss: 0.8593, value_loss: 0.5183
2024-07-11 17:24:31,266 [INFO    ] __main__: train step 17940: loss: 0.9474, policy_loss: 0.8593, value_loss: 0.5183
2024-07-11 17:24:31,470 [INFO    ] __main__: train step 17941: loss: 0.9474, policy_loss: 0.8592, value_loss: 0.5183
2024-07-11 17:24:31,674 [INFO    ] __main__: train step 17942: loss: 0.9473, policy_loss: 0.8592, value_loss: 0.5182
2024-07-11 17:24:31,882 [INFO    ] __main__: train step 17943: loss: 0.9473, policy_loss: 0.8592, value_loss: 0.5182
2024-07-11 17:24:32,093 [INFO    ] __main__: train step 17944: loss: 0.9473, policy_loss: 0.8592, value_loss: 0.5182
2024-07-11 17:24:32,299 [INFO    ] __main__: train step 17945: loss: 0.9473, policy_loss: 0.8591, value_loss: 0.5182
2024-07-11 17:24:32,496 [INFO    ] __main__: train step 17946: loss: 0.9472, policy_loss: 0.8591, value_loss: 0.5181
2024-07-11 17:24:32,695 [INFO    ] __main__: train step 17947: loss: 0.9472, policy_loss: 0.8591, value_loss: 0.5181
2024-07-11 17:24:32,924 [INFO    ] __main__: train step 17948: loss: 0.9472, policy_loss: 0.8590, value_loss: 0.5181
2024-07-11 17:24:33,146 [INFO    ] __main__: train step 17949: loss: 0.9472, policy_loss: 0.8590, value_loss: 0.5181
2024-07-11 17:24:33,384 [INFO    ] __main__: train step 17950: loss: 0.9471, policy_loss: 0.8590, value_loss: 0.5181
2024-07-11 17:24:33,588 [INFO    ] __main__: train step 17951: loss: 0.9471, policy_loss: 0.8590, value_loss: 0.5180
2024-07-11 17:24:35,043 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:24:35,485 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:24:35,548 [INFO    ] __main__: train step 17952: loss: 0.9471, policy_loss: 0.8589, value_loss: 0.5180
2024-07-11 17:24:35,735 [INFO    ] __main__: train step 17953: loss: 0.9471, policy_loss: 0.8589, value_loss: 0.5180
2024-07-11 17:24:35,938 [INFO    ] __main__: train step 17954: loss: 0.9471, policy_loss: 0.8589, value_loss: 0.5180
2024-07-11 17:24:36,146 [INFO    ] __main__: train step 17955: loss: 0.9470, policy_loss: 0.8589, value_loss: 0.5179
2024-07-11 17:24:36,362 [INFO    ] __main__: train step 17956: loss: 0.9470, policy_loss: 0.8588, value_loss: 0.5179
2024-07-11 17:24:36,565 [INFO    ] __main__: train step 17957: loss: 0.9470, policy_loss: 0.8588, value_loss: 0.5179
2024-07-11 17:24:36,773 [INFO    ] __main__: train step 17958: loss: 0.9470, policy_loss: 0.8588, value_loss: 0.5179
2024-07-11 17:24:36,976 [INFO    ] __main__: train step 17959: loss: 0.9469, policy_loss: 0.8588, value_loss: 0.5179
2024-07-11 17:24:37,180 [INFO    ] __main__: train step 17960: loss: 0.9469, policy_loss: 0.8587, value_loss: 0.5178
2024-07-11 17:24:37,389 [INFO    ] __main__: train step 17961: loss: 0.9469, policy_loss: 0.8587, value_loss: 0.5178
2024-07-11 17:24:37,596 [INFO    ] __main__: train step 17962: loss: 0.9469, policy_loss: 0.8587, value_loss: 0.5178
2024-07-11 17:24:37,813 [INFO    ] __main__: train step 17963: loss: 0.9468, policy_loss: 0.8587, value_loss: 0.5178
2024-07-11 17:24:38,009 [INFO    ] __main__: train step 17964: loss: 0.9468, policy_loss: 0.8586, value_loss: 0.5178
2024-07-11 17:24:38,225 [INFO    ] __main__: train step 17965: loss: 0.9468, policy_loss: 0.8586, value_loss: 0.5177
2024-07-11 17:24:38,439 [INFO    ] __main__: train step 17966: loss: 0.9468, policy_loss: 0.8586, value_loss: 0.5177
2024-07-11 17:24:38,649 [INFO    ] __main__: train step 17967: loss: 0.9467, policy_loss: 0.8585, value_loss: 0.5177
2024-07-11 17:24:38,864 [INFO    ] __main__: train step 17968: loss: 0.9467, policy_loss: 0.8585, value_loss: 0.5177
2024-07-11 17:24:40,292 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:24:40,740 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:24:40,794 [INFO    ] __main__: train step 17969: loss: 0.9467, policy_loss: 0.8585, value_loss: 0.5176
2024-07-11 17:24:40,973 [INFO    ] __main__: train step 17970: loss: 0.9467, policy_loss: 0.8585, value_loss: 0.5176
2024-07-11 17:24:41,183 [INFO    ] __main__: train step 17971: loss: 0.9467, policy_loss: 0.8584, value_loss: 0.5176
2024-07-11 17:24:41,382 [INFO    ] __main__: train step 17972: loss: 0.9466, policy_loss: 0.8584, value_loss: 0.5176
2024-07-11 17:24:41,585 [INFO    ] __main__: train step 17973: loss: 0.9466, policy_loss: 0.8584, value_loss: 0.5176
2024-07-11 17:24:41,799 [INFO    ] __main__: train step 17974: loss: 0.9466, policy_loss: 0.8584, value_loss: 0.5175
2024-07-11 17:24:41,993 [INFO    ] __main__: train step 17975: loss: 0.9466, policy_loss: 0.8583, value_loss: 0.5175
2024-07-11 17:24:42,200 [INFO    ] __main__: train step 17976: loss: 0.9465, policy_loss: 0.8583, value_loss: 0.5175
2024-07-11 17:24:42,404 [INFO    ] __main__: train step 17977: loss: 0.9465, policy_loss: 0.8583, value_loss: 0.5175
2024-07-11 17:24:42,606 [INFO    ] __main__: train step 17978: loss: 0.9465, policy_loss: 0.8583, value_loss: 0.5175
2024-07-11 17:24:42,810 [INFO    ] __main__: train step 17979: loss: 0.9465, policy_loss: 0.8582, value_loss: 0.5174
2024-07-11 17:24:43,015 [INFO    ] __main__: train step 17980: loss: 0.9464, policy_loss: 0.8582, value_loss: 0.5174
2024-07-11 17:24:43,220 [INFO    ] __main__: train step 17981: loss: 0.9464, policy_loss: 0.8582, value_loss: 0.5174
2024-07-11 17:24:43,421 [INFO    ] __main__: train step 17982: loss: 0.9464, policy_loss: 0.8582, value_loss: 0.5174
2024-07-11 17:24:45,334 [INFO    ] __main__: train step 17983: loss: 0.9464, policy_loss: 0.8581, value_loss: 0.5173
2024-07-11 17:24:45,545 [INFO    ] __main__: train step 17984: loss: 0.9463, policy_loss: 0.8581, value_loss: 0.5173
2024-07-11 17:24:45,749 [INFO    ] __main__: train step 17985: loss: 0.9463, policy_loss: 0.8581, value_loss: 0.5173
2024-07-11 17:24:47,176 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:24:47,579 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:24:47,636 [INFO    ] __main__: train step 17986: loss: 0.9463, policy_loss: 0.8581, value_loss: 0.5173
2024-07-11 17:24:47,824 [INFO    ] __main__: train step 17987: loss: 0.9463, policy_loss: 0.8580, value_loss: 0.5173
2024-07-11 17:24:48,052 [INFO    ] __main__: train step 17988: loss: 0.9462, policy_loss: 0.8580, value_loss: 0.5172
2024-07-11 17:24:48,265 [INFO    ] __main__: train step 17989: loss: 0.9462, policy_loss: 0.8580, value_loss: 0.5172
2024-07-11 17:24:48,468 [INFO    ] __main__: train step 17990: loss: 0.9462, policy_loss: 0.8579, value_loss: 0.5172
2024-07-11 17:24:48,682 [INFO    ] __main__: train step 17991: loss: 0.9462, policy_loss: 0.8579, value_loss: 0.5172
2024-07-11 17:24:48,879 [INFO    ] __main__: train step 17992: loss: 0.9461, policy_loss: 0.8579, value_loss: 0.5172
2024-07-11 17:24:49,106 [INFO    ] __main__: train step 17993: loss: 0.9461, policy_loss: 0.8579, value_loss: 0.5171
2024-07-11 17:24:49,306 [INFO    ] __main__: train step 17994: loss: 0.9461, policy_loss: 0.8578, value_loss: 0.5171
2024-07-11 17:24:49,522 [INFO    ] __main__: train step 17995: loss: 0.9461, policy_loss: 0.8578, value_loss: 0.5171
2024-07-11 17:24:49,721 [INFO    ] __main__: train step 17996: loss: 0.9461, policy_loss: 0.8578, value_loss: 0.5171
2024-07-11 17:24:49,945 [INFO    ] __main__: train step 17997: loss: 0.9460, policy_loss: 0.8578, value_loss: 0.5170
2024-07-11 17:24:50,177 [INFO    ] __main__: train step 17998: loss: 0.9460, policy_loss: 0.8577, value_loss: 0.5170
2024-07-11 17:24:50,373 [INFO    ] __main__: train step 17999: loss: 0.9460, policy_loss: 0.8577, value_loss: 0.5170
2024-07-11 17:24:50,589 [INFO    ] __main__: train step 18000: loss: 0.9460, policy_loss: 0.8577, value_loss: 0.5170
2024-07-11 17:24:50,698 [INFO    ] __main__: restored step 17000 for evaluation
2024-07-11 17:24:58,186 [INFO    ] __main__: later network ELO difference from earlier network: +98 (+8/-8) ELO from 32000 self-played games
2024-07-11 17:24:58,186 [INFO    ] __main__: game outcomes: W: 19608, D: 112, L: 12280
2024-07-11 17:24:58,188 [INFO    ] __main__: validation_elo_delta: 98, validation_elo: 2614
2024-07-11 17:24:58,675 [INFO    ] __main__: train step 18001: loss: 0.9459, policy_loss: 0.8577, value_loss: 0.5170
2024-07-11 17:24:58,876 [INFO    ] __main__: train step 18002: loss: 0.9459, policy_loss: 0.8576, value_loss: 0.5169
2024-07-11 17:25:00,310 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:25:00,701 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:25:00,757 [INFO    ] __main__: train step 18003: loss: 0.9459, policy_loss: 0.8576, value_loss: 0.5169
2024-07-11 17:25:00,930 [INFO    ] __main__: train step 18004: loss: 0.9459, policy_loss: 0.8576, value_loss: 0.5169
2024-07-11 17:25:01,141 [INFO    ] __main__: train step 18005: loss: 0.9458, policy_loss: 0.8576, value_loss: 0.5169
2024-07-11 17:25:01,378 [INFO    ] __main__: train step 18006: loss: 0.9458, policy_loss: 0.8575, value_loss: 0.5168
2024-07-11 17:25:01,579 [INFO    ] __main__: train step 18007: loss: 0.9458, policy_loss: 0.8575, value_loss: 0.5168
2024-07-11 17:25:01,780 [INFO    ] __main__: train step 18008: loss: 0.9458, policy_loss: 0.8575, value_loss: 0.5168
2024-07-11 17:25:01,989 [INFO    ] __main__: train step 18009: loss: 0.9457, policy_loss: 0.8574, value_loss: 0.5168
2024-07-11 17:25:02,188 [INFO    ] __main__: train step 18010: loss: 0.9457, policy_loss: 0.8574, value_loss: 0.5168
2024-07-11 17:25:02,405 [INFO    ] __main__: train step 18011: loss: 0.9457, policy_loss: 0.8574, value_loss: 0.5167
2024-07-11 17:25:02,643 [INFO    ] __main__: train step 18012: loss: 0.9457, policy_loss: 0.8574, value_loss: 0.5167
2024-07-11 17:25:02,861 [INFO    ] __main__: train step 18013: loss: 0.9456, policy_loss: 0.8573, value_loss: 0.5167
2024-07-11 17:25:03,052 [INFO    ] __main__: train step 18014: loss: 0.9456, policy_loss: 0.8573, value_loss: 0.5167
2024-07-11 17:25:03,285 [INFO    ] __main__: train step 18015: loss: 0.9456, policy_loss: 0.8573, value_loss: 0.5167
2024-07-11 17:25:03,517 [INFO    ] __main__: train step 18016: loss: 0.9456, policy_loss: 0.8573, value_loss: 0.5166
2024-07-11 17:25:03,723 [INFO    ] __main__: train step 18017: loss: 0.9456, policy_loss: 0.8572, value_loss: 0.5166
2024-07-11 17:25:03,927 [INFO    ] __main__: train step 18018: loss: 0.9455, policy_loss: 0.8572, value_loss: 0.5166
2024-07-11 17:25:04,138 [INFO    ] __main__: train step 18019: loss: 0.9455, policy_loss: 0.8572, value_loss: 0.5166
2024-07-11 17:25:05,574 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:25:06,003 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:25:06,064 [INFO    ] __main__: train step 18020: loss: 0.9455, policy_loss: 0.8572, value_loss: 0.5165
2024-07-11 17:25:06,265 [INFO    ] __main__: train step 18021: loss: 0.9455, policy_loss: 0.8571, value_loss: 0.5165
2024-07-11 17:25:06,498 [INFO    ] __main__: train step 18022: loss: 0.9454, policy_loss: 0.8571, value_loss: 0.5165
2024-07-11 17:25:06,695 [INFO    ] __main__: train step 18023: loss: 0.9454, policy_loss: 0.8571, value_loss: 0.5165
2024-07-11 17:25:06,903 [INFO    ] __main__: train step 18024: loss: 0.9454, policy_loss: 0.8571, value_loss: 0.5165
2024-07-11 17:25:07,102 [INFO    ] __main__: train step 18025: loss: 0.9454, policy_loss: 0.8570, value_loss: 0.5164
2024-07-11 17:25:07,294 [INFO    ] __main__: train step 18026: loss: 0.9453, policy_loss: 0.8570, value_loss: 0.5164
2024-07-11 17:25:07,505 [INFO    ] __main__: train step 18027: loss: 0.9453, policy_loss: 0.8570, value_loss: 0.5164
2024-07-11 17:25:07,706 [INFO    ] __main__: train step 18028: loss: 0.9453, policy_loss: 0.8570, value_loss: 0.5164
2024-07-11 17:25:07,904 [INFO    ] __main__: train step 18029: loss: 0.9453, policy_loss: 0.8569, value_loss: 0.5164
2024-07-11 17:25:08,106 [INFO    ] __main__: train step 18030: loss: 0.9453, policy_loss: 0.8569, value_loss: 0.5163
2024-07-11 17:25:08,304 [INFO    ] __main__: train step 18031: loss: 0.9452, policy_loss: 0.8569, value_loss: 0.5163
2024-07-11 17:25:08,511 [INFO    ] __main__: train step 18032: loss: 0.9452, policy_loss: 0.8569, value_loss: 0.5163
2024-07-11 17:25:08,710 [INFO    ] __main__: train step 18033: loss: 0.9452, policy_loss: 0.8568, value_loss: 0.5163
2024-07-11 17:25:08,912 [INFO    ] __main__: train step 18034: loss: 0.9452, policy_loss: 0.8568, value_loss: 0.5162
2024-07-11 17:25:09,117 [INFO    ] __main__: train step 18035: loss: 0.9451, policy_loss: 0.8568, value_loss: 0.5162
2024-07-11 17:25:09,324 [INFO    ] __main__: train step 18036: loss: 0.9451, policy_loss: 0.8568, value_loss: 0.5162
2024-07-11 17:25:10,768 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:25:11,137 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:25:11,193 [INFO    ] __main__: train step 18037: loss: 0.9451, policy_loss: 0.8567, value_loss: 0.5162
2024-07-11 17:25:11,380 [INFO    ] __main__: train step 18038: loss: 0.9451, policy_loss: 0.8567, value_loss: 0.5162
2024-07-11 17:25:11,605 [INFO    ] __main__: train step 18039: loss: 0.9450, policy_loss: 0.8567, value_loss: 0.5161
2024-07-11 17:25:11,832 [INFO    ] __main__: train step 18040: loss: 0.9450, policy_loss: 0.8567, value_loss: 0.5161
2024-07-11 17:25:12,035 [INFO    ] __main__: train step 18041: loss: 0.9450, policy_loss: 0.8566, value_loss: 0.5161
2024-07-11 17:25:12,263 [INFO    ] __main__: train step 18042: loss: 0.9450, policy_loss: 0.8566, value_loss: 0.5161
2024-07-11 17:25:12,483 [INFO    ] __main__: train step 18043: loss: 0.9449, policy_loss: 0.8566, value_loss: 0.5161
2024-07-11 17:25:12,693 [INFO    ] __main__: train step 18044: loss: 0.9449, policy_loss: 0.8565, value_loss: 0.5160
2024-07-11 17:25:12,913 [INFO    ] __main__: train step 18045: loss: 0.9449, policy_loss: 0.8565, value_loss: 0.5160
2024-07-11 17:25:13,116 [INFO    ] __main__: train step 18046: loss: 0.9449, policy_loss: 0.8565, value_loss: 0.5160
2024-07-11 17:25:13,317 [INFO    ] __main__: train step 18047: loss: 0.9449, policy_loss: 0.8565, value_loss: 0.5160
2024-07-11 17:25:13,521 [INFO    ] __main__: train step 18048: loss: 0.9448, policy_loss: 0.8564, value_loss: 0.5159
2024-07-11 17:25:13,760 [INFO    ] __main__: train step 18049: loss: 0.9448, policy_loss: 0.8564, value_loss: 0.5159
2024-07-11 17:25:13,970 [INFO    ] __main__: train step 18050: loss: 0.9448, policy_loss: 0.8564, value_loss: 0.5159
2024-07-11 17:25:14,199 [INFO    ] __main__: train step 18051: loss: 0.9448, policy_loss: 0.8564, value_loss: 0.5159
2024-07-11 17:25:14,406 [INFO    ] __main__: train step 18052: loss: 0.9447, policy_loss: 0.8563, value_loss: 0.5159
2024-07-11 17:25:14,618 [INFO    ] __main__: train step 18053: loss: 0.9447, policy_loss: 0.8563, value_loss: 0.5158
2024-07-11 17:25:16,101 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:25:16,449 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:25:16,508 [INFO    ] __main__: train step 18054: loss: 0.9447, policy_loss: 0.8563, value_loss: 0.5158
2024-07-11 17:25:16,682 [INFO    ] __main__: train step 18055: loss: 0.9447, policy_loss: 0.8563, value_loss: 0.5158
2024-07-11 17:25:16,887 [INFO    ] __main__: train step 18056: loss: 0.9446, policy_loss: 0.8562, value_loss: 0.5158
2024-07-11 17:25:17,094 [INFO    ] __main__: train step 18057: loss: 0.9446, policy_loss: 0.8562, value_loss: 0.5158
2024-07-11 17:25:17,302 [INFO    ] __main__: train step 18058: loss: 0.9446, policy_loss: 0.8562, value_loss: 0.5157
2024-07-11 17:25:17,557 [INFO    ] __main__: train step 18059: loss: 0.9446, policy_loss: 0.8562, value_loss: 0.5157
2024-07-11 17:25:17,783 [INFO    ] __main__: train step 18060: loss: 0.9445, policy_loss: 0.8561, value_loss: 0.5157
2024-07-11 17:25:17,986 [INFO    ] __main__: train step 18061: loss: 0.9445, policy_loss: 0.8561, value_loss: 0.5157
2024-07-11 17:25:18,199 [INFO    ] __main__: train step 18062: loss: 0.9445, policy_loss: 0.8561, value_loss: 0.5156
2024-07-11 17:25:18,418 [INFO    ] __main__: train step 18063: loss: 0.9445, policy_loss: 0.8561, value_loss: 0.5156
2024-07-11 17:25:18,610 [INFO    ] __main__: train step 18064: loss: 0.9445, policy_loss: 0.8560, value_loss: 0.5156
2024-07-11 17:25:18,860 [INFO    ] __main__: train step 18065: loss: 0.9444, policy_loss: 0.8560, value_loss: 0.5156
2024-07-11 17:25:19,090 [INFO    ] __main__: train step 18066: loss: 0.9444, policy_loss: 0.8560, value_loss: 0.5156
2024-07-11 17:25:19,291 [INFO    ] __main__: train step 18067: loss: 0.9444, policy_loss: 0.8560, value_loss: 0.5155
2024-07-11 17:25:19,497 [INFO    ] __main__: train step 18068: loss: 0.9444, policy_loss: 0.8559, value_loss: 0.5155
2024-07-11 17:25:19,700 [INFO    ] __main__: train step 18069: loss: 0.9443, policy_loss: 0.8559, value_loss: 0.5155
2024-07-11 17:25:19,913 [INFO    ] __main__: train step 18070: loss: 0.9443, policy_loss: 0.8559, value_loss: 0.5155
2024-07-11 17:25:21,349 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:25:21,733 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:25:21,786 [INFO    ] __main__: train step 18071: loss: 0.9443, policy_loss: 0.8559, value_loss: 0.5154
2024-07-11 17:25:21,957 [INFO    ] __main__: train step 18072: loss: 0.9443, policy_loss: 0.8558, value_loss: 0.5154
2024-07-11 17:25:22,165 [INFO    ] __main__: train step 18073: loss: 0.9442, policy_loss: 0.8558, value_loss: 0.5154
2024-07-11 17:25:22,372 [INFO    ] __main__: train step 18074: loss: 0.9442, policy_loss: 0.8558, value_loss: 0.5154
2024-07-11 17:25:22,571 [INFO    ] __main__: train step 18075: loss: 0.9442, policy_loss: 0.8558, value_loss: 0.5154
2024-07-11 17:25:22,768 [INFO    ] __main__: train step 18076: loss: 0.9442, policy_loss: 0.8557, value_loss: 0.5153
2024-07-11 17:25:22,968 [INFO    ] __main__: train step 18077: loss: 0.9442, policy_loss: 0.8557, value_loss: 0.5153
2024-07-11 17:25:23,175 [INFO    ] __main__: train step 18078: loss: 0.9441, policy_loss: 0.8557, value_loss: 0.5153
2024-07-11 17:25:23,377 [INFO    ] __main__: train step 18079: loss: 0.9441, policy_loss: 0.8557, value_loss: 0.5153
2024-07-11 17:25:23,584 [INFO    ] __main__: train step 18080: loss: 0.9441, policy_loss: 0.8556, value_loss: 0.5153
2024-07-11 17:25:23,791 [INFO    ] __main__: train step 18081: loss: 0.9441, policy_loss: 0.8556, value_loss: 0.5152
2024-07-11 17:25:23,992 [INFO    ] __main__: train step 18082: loss: 0.9440, policy_loss: 0.8556, value_loss: 0.5152
2024-07-11 17:25:24,202 [INFO    ] __main__: train step 18083: loss: 0.9440, policy_loss: 0.8556, value_loss: 0.5152
2024-07-11 17:25:24,406 [INFO    ] __main__: train step 18084: loss: 0.9440, policy_loss: 0.8555, value_loss: 0.5152
2024-07-11 17:25:24,660 [INFO    ] __main__: train step 18085: loss: 0.9440, policy_loss: 0.8555, value_loss: 0.5151
2024-07-11 17:25:24,891 [INFO    ] __main__: train step 18086: loss: 0.9439, policy_loss: 0.8555, value_loss: 0.5151
2024-07-11 17:25:25,095 [INFO    ] __main__: train step 18087: loss: 0.9439, policy_loss: 0.8555, value_loss: 0.5151
2024-07-11 17:25:26,535 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:25:26,972 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:25:27,034 [INFO    ] __main__: train step 18088: loss: 0.9439, policy_loss: 0.8554, value_loss: 0.5151
2024-07-11 17:25:27,226 [INFO    ] __main__: train step 18089: loss: 0.9439, policy_loss: 0.8554, value_loss: 0.5151
2024-07-11 17:25:27,444 [INFO    ] __main__: train step 18090: loss: 0.9438, policy_loss: 0.8554, value_loss: 0.5150
2024-07-11 17:25:27,641 [INFO    ] __main__: train step 18091: loss: 0.9438, policy_loss: 0.8554, value_loss: 0.5150
2024-07-11 17:25:27,842 [INFO    ] __main__: train step 18092: loss: 0.9438, policy_loss: 0.8553, value_loss: 0.5150
2024-07-11 17:25:28,051 [INFO    ] __main__: train step 18093: loss: 0.9438, policy_loss: 0.8553, value_loss: 0.5150
2024-07-11 17:25:28,248 [INFO    ] __main__: train step 18094: loss: 0.9438, policy_loss: 0.8553, value_loss: 0.5150
2024-07-11 17:25:28,452 [INFO    ] __main__: train step 18095: loss: 0.9437, policy_loss: 0.8553, value_loss: 0.5149
2024-07-11 17:25:28,660 [INFO    ] __main__: train step 18096: loss: 0.9437, policy_loss: 0.8552, value_loss: 0.5149
2024-07-11 17:25:28,852 [INFO    ] __main__: train step 18097: loss: 0.9437, policy_loss: 0.8552, value_loss: 0.5149
2024-07-11 17:25:30,833 [INFO    ] __main__: train step 18098: loss: 0.9437, policy_loss: 0.8552, value_loss: 0.5149
2024-07-11 17:25:31,031 [INFO    ] __main__: train step 18099: loss: 0.9436, policy_loss: 0.8552, value_loss: 0.5148
2024-07-11 17:25:31,250 [INFO    ] __main__: train step 18100: loss: 0.9436, policy_loss: 0.8551, value_loss: 0.5148
2024-07-11 17:25:31,481 [INFO    ] __main__: train step 18101: loss: 0.9436, policy_loss: 0.8551, value_loss: 0.5148
2024-07-11 17:25:31,693 [INFO    ] __main__: train step 18102: loss: 0.9436, policy_loss: 0.8551, value_loss: 0.5148
2024-07-11 17:25:31,905 [INFO    ] __main__: train step 18103: loss: 0.9435, policy_loss: 0.8551, value_loss: 0.5148
2024-07-11 17:25:32,110 [INFO    ] __main__: train step 18104: loss: 0.9435, policy_loss: 0.8550, value_loss: 0.5147
2024-07-11 17:25:33,548 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:25:33,961 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:25:34,020 [INFO    ] __main__: train step 18105: loss: 0.9435, policy_loss: 0.8550, value_loss: 0.5147
2024-07-11 17:25:34,194 [INFO    ] __main__: train step 18106: loss: 0.9435, policy_loss: 0.8550, value_loss: 0.5147
2024-07-11 17:25:34,404 [INFO    ] __main__: train step 18107: loss: 0.9435, policy_loss: 0.8550, value_loss: 0.5147
2024-07-11 17:25:34,617 [INFO    ] __main__: train step 18108: loss: 0.9434, policy_loss: 0.8549, value_loss: 0.5147
2024-07-11 17:25:34,825 [INFO    ] __main__: train step 18109: loss: 0.9434, policy_loss: 0.8549, value_loss: 0.5146
2024-07-11 17:25:35,031 [INFO    ] __main__: train step 18110: loss: 0.9434, policy_loss: 0.8549, value_loss: 0.5146
2024-07-11 17:25:35,277 [INFO    ] __main__: train step 18111: loss: 0.9434, policy_loss: 0.8549, value_loss: 0.5146
2024-07-11 17:25:35,476 [INFO    ] __main__: train step 18112: loss: 0.9433, policy_loss: 0.8548, value_loss: 0.5146
2024-07-11 17:25:35,677 [INFO    ] __main__: train step 18113: loss: 0.9433, policy_loss: 0.8548, value_loss: 0.5145
2024-07-11 17:25:35,903 [INFO    ] __main__: train step 18114: loss: 0.9433, policy_loss: 0.8548, value_loss: 0.5145
2024-07-11 17:25:36,113 [INFO    ] __main__: train step 18115: loss: 0.9433, policy_loss: 0.8548, value_loss: 0.5145
2024-07-11 17:25:36,316 [INFO    ] __main__: train step 18116: loss: 0.9432, policy_loss: 0.8547, value_loss: 0.5145
2024-07-11 17:25:36,518 [INFO    ] __main__: train step 18117: loss: 0.9432, policy_loss: 0.8547, value_loss: 0.5145
2024-07-11 17:25:36,733 [INFO    ] __main__: train step 18118: loss: 0.9432, policy_loss: 0.8547, value_loss: 0.5144
2024-07-11 17:25:36,947 [INFO    ] __main__: train step 18119: loss: 0.9432, policy_loss: 0.8547, value_loss: 0.5144
2024-07-11 17:25:37,169 [INFO    ] __main__: train step 18120: loss: 0.9432, policy_loss: 0.8546, value_loss: 0.5144
2024-07-11 17:25:37,369 [INFO    ] __main__: train step 18121: loss: 0.9431, policy_loss: 0.8546, value_loss: 0.5144
2024-07-11 17:25:38,818 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:25:39,217 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:25:39,272 [INFO    ] __main__: train step 18122: loss: 0.9431, policy_loss: 0.8546, value_loss: 0.5143
2024-07-11 17:25:39,453 [INFO    ] __main__: train step 18123: loss: 0.9431, policy_loss: 0.8546, value_loss: 0.5143
2024-07-11 17:25:39,660 [INFO    ] __main__: train step 18124: loss: 0.9431, policy_loss: 0.8545, value_loss: 0.5143
2024-07-11 17:25:39,871 [INFO    ] __main__: train step 18125: loss: 0.9430, policy_loss: 0.8545, value_loss: 0.5143
2024-07-11 17:25:40,067 [INFO    ] __main__: train step 18126: loss: 0.9430, policy_loss: 0.8545, value_loss: 0.5143
2024-07-11 17:25:40,274 [INFO    ] __main__: train step 18127: loss: 0.9430, policy_loss: 0.8545, value_loss: 0.5142
2024-07-11 17:25:40,472 [INFO    ] __main__: train step 18128: loss: 0.9430, policy_loss: 0.8544, value_loss: 0.5142
2024-07-11 17:25:40,678 [INFO    ] __main__: train step 18129: loss: 0.9429, policy_loss: 0.8544, value_loss: 0.5142
2024-07-11 17:25:40,880 [INFO    ] __main__: train step 18130: loss: 0.9429, policy_loss: 0.8544, value_loss: 0.5142
2024-07-11 17:25:41,077 [INFO    ] __main__: train step 18131: loss: 0.9429, policy_loss: 0.8544, value_loss: 0.5141
2024-07-11 17:25:41,277 [INFO    ] __main__: train step 18132: loss: 0.9429, policy_loss: 0.8543, value_loss: 0.5141
2024-07-11 17:25:41,490 [INFO    ] __main__: train step 18133: loss: 0.9429, policy_loss: 0.8543, value_loss: 0.5141
2024-07-11 17:25:41,716 [INFO    ] __main__: train step 18134: loss: 0.9428, policy_loss: 0.8543, value_loss: 0.5141
2024-07-11 17:25:41,965 [INFO    ] __main__: train step 18135: loss: 0.9428, policy_loss: 0.8543, value_loss: 0.5141
2024-07-11 17:25:42,172 [INFO    ] __main__: train step 18136: loss: 0.9428, policy_loss: 0.8542, value_loss: 0.5140
2024-07-11 17:25:42,369 [INFO    ] __main__: train step 18137: loss: 0.9428, policy_loss: 0.8542, value_loss: 0.5140
2024-07-11 17:25:42,570 [INFO    ] __main__: train step 18138: loss: 0.9427, policy_loss: 0.8542, value_loss: 0.5140
2024-07-11 17:25:44,020 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:25:44,428 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:25:44,484 [INFO    ] __main__: train step 18139: loss: 0.9427, policy_loss: 0.8542, value_loss: 0.5140
2024-07-11 17:25:44,663 [INFO    ] __main__: train step 18140: loss: 0.9427, policy_loss: 0.8541, value_loss: 0.5140
2024-07-11 17:25:44,880 [INFO    ] __main__: train step 18141: loss: 0.9427, policy_loss: 0.8541, value_loss: 0.5139
2024-07-11 17:25:45,089 [INFO    ] __main__: train step 18142: loss: 0.9426, policy_loss: 0.8541, value_loss: 0.5139
2024-07-11 17:25:45,298 [INFO    ] __main__: train step 18143: loss: 0.9426, policy_loss: 0.8541, value_loss: 0.5139
2024-07-11 17:25:45,505 [INFO    ] __main__: train step 18144: loss: 0.9426, policy_loss: 0.8540, value_loss: 0.5139
2024-07-11 17:25:45,712 [INFO    ] __main__: train step 18145: loss: 0.9426, policy_loss: 0.8540, value_loss: 0.5138
2024-07-11 17:25:45,923 [INFO    ] __main__: train step 18146: loss: 0.9426, policy_loss: 0.8540, value_loss: 0.5138
2024-07-11 17:25:46,166 [INFO    ] __main__: train step 18147: loss: 0.9425, policy_loss: 0.8540, value_loss: 0.5138
2024-07-11 17:25:46,370 [INFO    ] __main__: train step 18148: loss: 0.9425, policy_loss: 0.8539, value_loss: 0.5138
2024-07-11 17:25:46,581 [INFO    ] __main__: train step 18149: loss: 0.9425, policy_loss: 0.8539, value_loss: 0.5138
2024-07-11 17:25:46,788 [INFO    ] __main__: train step 18150: loss: 0.9425, policy_loss: 0.8539, value_loss: 0.5137
2024-07-11 17:25:47,002 [INFO    ] __main__: train step 18151: loss: 0.9424, policy_loss: 0.8539, value_loss: 0.5137
2024-07-11 17:25:47,204 [INFO    ] __main__: train step 18152: loss: 0.9424, policy_loss: 0.8538, value_loss: 0.5137
2024-07-11 17:25:47,410 [INFO    ] __main__: train step 18153: loss: 0.9424, policy_loss: 0.8538, value_loss: 0.5137
2024-07-11 17:25:47,612 [INFO    ] __main__: train step 18154: loss: 0.9424, policy_loss: 0.8538, value_loss: 0.5136
2024-07-11 17:25:47,837 [INFO    ] __main__: train step 18155: loss: 0.9423, policy_loss: 0.8538, value_loss: 0.5136
2024-07-11 17:25:49,312 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:25:49,718 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:25:49,773 [INFO    ] __main__: train step 18156: loss: 0.9423, policy_loss: 0.8537, value_loss: 0.5136
2024-07-11 17:25:49,952 [INFO    ] __main__: train step 18157: loss: 0.9423, policy_loss: 0.8537, value_loss: 0.5136
2024-07-11 17:25:50,155 [INFO    ] __main__: train step 18158: loss: 0.9423, policy_loss: 0.8537, value_loss: 0.5136
2024-07-11 17:25:50,363 [INFO    ] __main__: train step 18159: loss: 0.9423, policy_loss: 0.8537, value_loss: 0.5135
2024-07-11 17:25:50,573 [INFO    ] __main__: train step 18160: loss: 0.9422, policy_loss: 0.8536, value_loss: 0.5135
2024-07-11 17:25:50,789 [INFO    ] __main__: train step 18161: loss: 0.9422, policy_loss: 0.8536, value_loss: 0.5135
2024-07-11 17:25:50,992 [INFO    ] __main__: train step 18162: loss: 0.9422, policy_loss: 0.8536, value_loss: 0.5135
2024-07-11 17:25:51,228 [INFO    ] __main__: train step 18163: loss: 0.9422, policy_loss: 0.8536, value_loss: 0.5134
2024-07-11 17:25:51,466 [INFO    ] __main__: train step 18164: loss: 0.9421, policy_loss: 0.8535, value_loss: 0.5134
2024-07-11 17:25:51,700 [INFO    ] __main__: train step 18165: loss: 0.9421, policy_loss: 0.8535, value_loss: 0.5134
2024-07-11 17:25:51,953 [INFO    ] __main__: train step 18166: loss: 0.9421, policy_loss: 0.8535, value_loss: 0.5134
2024-07-11 17:25:52,193 [INFO    ] __main__: train step 18167: loss: 0.9421, policy_loss: 0.8535, value_loss: 0.5134
2024-07-11 17:25:52,421 [INFO    ] __main__: train step 18168: loss: 0.9420, policy_loss: 0.8534, value_loss: 0.5133
2024-07-11 17:25:52,631 [INFO    ] __main__: train step 18169: loss: 0.9420, policy_loss: 0.8534, value_loss: 0.5133
2024-07-11 17:25:52,843 [INFO    ] __main__: train step 18170: loss: 0.9420, policy_loss: 0.8534, value_loss: 0.5133
2024-07-11 17:25:53,073 [INFO    ] __main__: train step 18171: loss: 0.9420, policy_loss: 0.8534, value_loss: 0.5133
2024-07-11 17:25:53,303 [INFO    ] __main__: train step 18172: loss: 0.9420, policy_loss: 0.8534, value_loss: 0.5133
2024-07-11 17:25:54,738 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:25:55,118 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:25:55,174 [INFO    ] __main__: train step 18173: loss: 0.9419, policy_loss: 0.8533, value_loss: 0.5132
2024-07-11 17:25:55,351 [INFO    ] __main__: train step 18174: loss: 0.9419, policy_loss: 0.8533, value_loss: 0.5132
2024-07-11 17:25:55,540 [INFO    ] __main__: train step 18175: loss: 0.9419, policy_loss: 0.8533, value_loss: 0.5132
2024-07-11 17:25:55,754 [INFO    ] __main__: train step 18176: loss: 0.9419, policy_loss: 0.8533, value_loss: 0.5132
2024-07-11 17:25:55,954 [INFO    ] __main__: train step 18177: loss: 0.9418, policy_loss: 0.8532, value_loss: 0.5131
2024-07-11 17:25:56,160 [INFO    ] __main__: train step 18178: loss: 0.9418, policy_loss: 0.8532, value_loss: 0.5131
2024-07-11 17:25:56,366 [INFO    ] __main__: train step 18179: loss: 0.9418, policy_loss: 0.8532, value_loss: 0.5131
2024-07-11 17:25:56,562 [INFO    ] __main__: train step 18180: loss: 0.9418, policy_loss: 0.8532, value_loss: 0.5131
2024-07-11 17:25:56,774 [INFO    ] __main__: train step 18181: loss: 0.9418, policy_loss: 0.8531, value_loss: 0.5131
2024-07-11 17:25:56,969 [INFO    ] __main__: train step 18182: loss: 0.9417, policy_loss: 0.8531, value_loss: 0.5130
2024-07-11 17:25:57,187 [INFO    ] __main__: train step 18183: loss: 0.9417, policy_loss: 0.8531, value_loss: 0.5130
2024-07-11 17:25:57,413 [INFO    ] __main__: train step 18184: loss: 0.9417, policy_loss: 0.8531, value_loss: 0.5130
2024-07-11 17:25:57,607 [INFO    ] __main__: train step 18185: loss: 0.9417, policy_loss: 0.8530, value_loss: 0.5130
2024-07-11 17:25:57,804 [INFO    ] __main__: train step 18186: loss: 0.9416, policy_loss: 0.8530, value_loss: 0.5129
2024-07-11 17:25:58,009 [INFO    ] __main__: train step 18187: loss: 0.9416, policy_loss: 0.8530, value_loss: 0.5129
2024-07-11 17:25:58,211 [INFO    ] __main__: train step 18188: loss: 0.9416, policy_loss: 0.8530, value_loss: 0.5129
2024-07-11 17:25:58,415 [INFO    ] __main__: train step 18189: loss: 0.9416, policy_loss: 0.8529, value_loss: 0.5129
2024-07-11 17:25:59,876 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:26:00,295 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:26:00,351 [INFO    ] __main__: train step 18190: loss: 0.9416, policy_loss: 0.8529, value_loss: 0.5129
2024-07-11 17:26:00,535 [INFO    ] __main__: train step 18191: loss: 0.9415, policy_loss: 0.8529, value_loss: 0.5128
2024-07-11 17:26:00,770 [INFO    ] __main__: train step 18192: loss: 0.9415, policy_loss: 0.8529, value_loss: 0.5128
2024-07-11 17:26:00,964 [INFO    ] __main__: train step 18193: loss: 0.9415, policy_loss: 0.8528, value_loss: 0.5128
2024-07-11 17:26:01,173 [INFO    ] __main__: train step 18194: loss: 0.9415, policy_loss: 0.8528, value_loss: 0.5128
2024-07-11 17:26:01,411 [INFO    ] __main__: train step 18195: loss: 0.9414, policy_loss: 0.8528, value_loss: 0.5128
2024-07-11 17:26:01,644 [INFO    ] __main__: train step 18196: loss: 0.9414, policy_loss: 0.8528, value_loss: 0.5127
2024-07-11 17:26:01,855 [INFO    ] __main__: train step 18197: loss: 0.9414, policy_loss: 0.8527, value_loss: 0.5127
2024-07-11 17:26:02,058 [INFO    ] __main__: train step 18198: loss: 0.9414, policy_loss: 0.8527, value_loss: 0.5127
2024-07-11 17:26:02,269 [INFO    ] __main__: train step 18199: loss: 0.9413, policy_loss: 0.8527, value_loss: 0.5127
2024-07-11 17:26:02,481 [INFO    ] __main__: train step 18200: loss: 0.9413, policy_loss: 0.8527, value_loss: 0.5126
2024-07-11 17:26:02,679 [INFO    ] __main__: train step 18201: loss: 0.9413, policy_loss: 0.8527, value_loss: 0.5126
2024-07-11 17:26:02,883 [INFO    ] __main__: train step 18202: loss: 0.9413, policy_loss: 0.8526, value_loss: 0.5126
2024-07-11 17:26:03,100 [INFO    ] __main__: train step 18203: loss: 0.9413, policy_loss: 0.8526, value_loss: 0.5126
2024-07-11 17:26:03,302 [INFO    ] __main__: train step 18204: loss: 0.9412, policy_loss: 0.8526, value_loss: 0.5126
2024-07-11 17:26:03,521 [INFO    ] __main__: train step 18205: loss: 0.9412, policy_loss: 0.8526, value_loss: 0.5125
2024-07-11 17:26:03,728 [INFO    ] __main__: train step 18206: loss: 0.9412, policy_loss: 0.8525, value_loss: 0.5125
2024-07-11 17:26:05,206 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:26:05,556 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:26:05,614 [INFO    ] __main__: train step 18207: loss: 0.9412, policy_loss: 0.8525, value_loss: 0.5125
2024-07-11 17:26:05,793 [INFO    ] __main__: train step 18208: loss: 0.9411, policy_loss: 0.8525, value_loss: 0.5125
2024-07-11 17:26:05,999 [INFO    ] __main__: train step 18209: loss: 0.9411, policy_loss: 0.8525, value_loss: 0.5124
2024-07-11 17:26:06,213 [INFO    ] __main__: train step 18210: loss: 0.9411, policy_loss: 0.8524, value_loss: 0.5124
2024-07-11 17:26:06,416 [INFO    ] __main__: train step 18211: loss: 0.9411, policy_loss: 0.8524, value_loss: 0.5124
2024-07-11 17:26:06,619 [INFO    ] __main__: train step 18212: loss: 0.9410, policy_loss: 0.8524, value_loss: 0.5124
2024-07-11 17:26:06,829 [INFO    ] __main__: train step 18213: loss: 0.9410, policy_loss: 0.8524, value_loss: 0.5124
2024-07-11 17:26:07,034 [INFO    ] __main__: train step 18214: loss: 0.9410, policy_loss: 0.8523, value_loss: 0.5123
2024-07-11 17:26:08,924 [INFO    ] __main__: train step 18215: loss: 0.9410, policy_loss: 0.8523, value_loss: 0.5123
2024-07-11 17:26:09,169 [INFO    ] __main__: train step 18216: loss: 0.9410, policy_loss: 0.8523, value_loss: 0.5123
2024-07-11 17:26:09,376 [INFO    ] __main__: train step 18217: loss: 0.9409, policy_loss: 0.8523, value_loss: 0.5123
2024-07-11 17:26:09,606 [INFO    ] __main__: train step 18218: loss: 0.9409, policy_loss: 0.8522, value_loss: 0.5122
2024-07-11 17:26:09,823 [INFO    ] __main__: train step 18219: loss: 0.9409, policy_loss: 0.8522, value_loss: 0.5122
2024-07-11 17:26:10,062 [INFO    ] __main__: train step 18220: loss: 0.9409, policy_loss: 0.8522, value_loss: 0.5122
2024-07-11 17:26:10,299 [INFO    ] __main__: train step 18221: loss: 0.9408, policy_loss: 0.8522, value_loss: 0.5122
2024-07-11 17:26:10,509 [INFO    ] __main__: train step 18222: loss: 0.9408, policy_loss: 0.8522, value_loss: 0.5122
2024-07-11 17:26:10,740 [INFO    ] __main__: train step 18223: loss: 0.9408, policy_loss: 0.8521, value_loss: 0.5121
2024-07-11 17:26:12,201 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:26:12,619 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:26:12,678 [INFO    ] __main__: train step 18224: loss: 0.9408, policy_loss: 0.8521, value_loss: 0.5121
2024-07-11 17:26:12,852 [INFO    ] __main__: train step 18225: loss: 0.9408, policy_loss: 0.8521, value_loss: 0.5121
2024-07-11 17:26:13,063 [INFO    ] __main__: train step 18226: loss: 0.9407, policy_loss: 0.8521, value_loss: 0.5121
2024-07-11 17:26:13,275 [INFO    ] __main__: train step 18227: loss: 0.9407, policy_loss: 0.8520, value_loss: 0.5120
2024-07-11 17:26:13,492 [INFO    ] __main__: train step 18228: loss: 0.9407, policy_loss: 0.8520, value_loss: 0.5120
2024-07-11 17:26:13,719 [INFO    ] __main__: train step 18229: loss: 0.9407, policy_loss: 0.8520, value_loss: 0.5120
2024-07-11 17:26:13,931 [INFO    ] __main__: train step 18230: loss: 0.9406, policy_loss: 0.8520, value_loss: 0.5120
2024-07-11 17:26:14,137 [INFO    ] __main__: train step 18231: loss: 0.9406, policy_loss: 0.8519, value_loss: 0.5120
2024-07-11 17:26:14,342 [INFO    ] __main__: train step 18232: loss: 0.9406, policy_loss: 0.8519, value_loss: 0.5119
2024-07-11 17:26:14,558 [INFO    ] __main__: train step 18233: loss: 0.9406, policy_loss: 0.8519, value_loss: 0.5119
2024-07-11 17:26:14,803 [INFO    ] __main__: train step 18234: loss: 0.9406, policy_loss: 0.8519, value_loss: 0.5119
2024-07-11 17:26:15,007 [INFO    ] __main__: train step 18235: loss: 0.9405, policy_loss: 0.8518, value_loss: 0.5119
2024-07-11 17:26:15,253 [INFO    ] __main__: train step 18236: loss: 0.9405, policy_loss: 0.8518, value_loss: 0.5119
2024-07-11 17:26:15,480 [INFO    ] __main__: train step 18237: loss: 0.9405, policy_loss: 0.8518, value_loss: 0.5118
2024-07-11 17:26:15,681 [INFO    ] __main__: train step 18238: loss: 0.9405, policy_loss: 0.8518, value_loss: 0.5118
2024-07-11 17:26:15,901 [INFO    ] __main__: train step 18239: loss: 0.9404, policy_loss: 0.8517, value_loss: 0.5118
2024-07-11 17:26:16,101 [INFO    ] __main__: train step 18240: loss: 0.9404, policy_loss: 0.8517, value_loss: 0.5118
2024-07-11 17:26:17,543 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:26:17,935 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:26:17,991 [INFO    ] __main__: train step 18241: loss: 0.9404, policy_loss: 0.8517, value_loss: 0.5117
2024-07-11 17:26:18,167 [INFO    ] __main__: train step 18242: loss: 0.9404, policy_loss: 0.8517, value_loss: 0.5117
2024-07-11 17:26:18,372 [INFO    ] __main__: train step 18243: loss: 0.9403, policy_loss: 0.8516, value_loss: 0.5117
2024-07-11 17:26:18,589 [INFO    ] __main__: train step 18244: loss: 0.9403, policy_loss: 0.8516, value_loss: 0.5117
2024-07-11 17:26:18,803 [INFO    ] __main__: train step 18245: loss: 0.9403, policy_loss: 0.8516, value_loss: 0.5117
2024-07-11 17:26:19,004 [INFO    ] __main__: train step 18246: loss: 0.9403, policy_loss: 0.8516, value_loss: 0.5116
2024-07-11 17:26:19,246 [INFO    ] __main__: train step 18247: loss: 0.9403, policy_loss: 0.8516, value_loss: 0.5116
2024-07-11 17:26:19,444 [INFO    ] __main__: train step 18248: loss: 0.9402, policy_loss: 0.8515, value_loss: 0.5116
2024-07-11 17:26:19,658 [INFO    ] __main__: train step 18249: loss: 0.9402, policy_loss: 0.8515, value_loss: 0.5116
2024-07-11 17:26:19,857 [INFO    ] __main__: train step 18250: loss: 0.9402, policy_loss: 0.8515, value_loss: 0.5115
2024-07-11 17:26:20,052 [INFO    ] __main__: train step 18251: loss: 0.9402, policy_loss: 0.8515, value_loss: 0.5115
2024-07-11 17:26:20,265 [INFO    ] __main__: train step 18252: loss: 0.9402, policy_loss: 0.8514, value_loss: 0.5115
2024-07-11 17:26:20,474 [INFO    ] __main__: train step 18253: loss: 0.9401, policy_loss: 0.8514, value_loss: 0.5115
2024-07-11 17:26:20,686 [INFO    ] __main__: train step 18254: loss: 0.9401, policy_loss: 0.8514, value_loss: 0.5115
2024-07-11 17:26:20,914 [INFO    ] __main__: train step 18255: loss: 0.9401, policy_loss: 0.8514, value_loss: 0.5114
2024-07-11 17:26:21,146 [INFO    ] __main__: train step 18256: loss: 0.9401, policy_loss: 0.8513, value_loss: 0.5114
2024-07-11 17:26:21,353 [INFO    ] __main__: train step 18257: loss: 0.9400, policy_loss: 0.8513, value_loss: 0.5114
2024-07-11 17:26:22,833 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:26:23,252 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:26:23,307 [INFO    ] __main__: train step 18258: loss: 0.9400, policy_loss: 0.8513, value_loss: 0.5114
2024-07-11 17:26:23,490 [INFO    ] __main__: train step 18259: loss: 0.9400, policy_loss: 0.8513, value_loss: 0.5113
2024-07-11 17:26:23,715 [INFO    ] __main__: train step 18260: loss: 0.9400, policy_loss: 0.8512, value_loss: 0.5113
2024-07-11 17:26:23,944 [INFO    ] __main__: train step 18261: loss: 0.9399, policy_loss: 0.8512, value_loss: 0.5113
2024-07-11 17:26:24,150 [INFO    ] __main__: train step 18262: loss: 0.9399, policy_loss: 0.8512, value_loss: 0.5113
2024-07-11 17:26:24,370 [INFO    ] __main__: train step 18263: loss: 0.9399, policy_loss: 0.8512, value_loss: 0.5113
2024-07-11 17:26:24,604 [INFO    ] __main__: train step 18264: loss: 0.9399, policy_loss: 0.8512, value_loss: 0.5112
2024-07-11 17:26:24,809 [INFO    ] __main__: train step 18265: loss: 0.9399, policy_loss: 0.8511, value_loss: 0.5112
2024-07-11 17:26:25,009 [INFO    ] __main__: train step 18266: loss: 0.9398, policy_loss: 0.8511, value_loss: 0.5112
2024-07-11 17:26:25,214 [INFO    ] __main__: train step 18267: loss: 0.9398, policy_loss: 0.8511, value_loss: 0.5112
2024-07-11 17:26:25,426 [INFO    ] __main__: train step 18268: loss: 0.9398, policy_loss: 0.8511, value_loss: 0.5111
2024-07-11 17:26:25,632 [INFO    ] __main__: train step 18269: loss: 0.9398, policy_loss: 0.8510, value_loss: 0.5111
2024-07-11 17:26:25,834 [INFO    ] __main__: train step 18270: loss: 0.9397, policy_loss: 0.8510, value_loss: 0.5111
2024-07-11 17:26:26,042 [INFO    ] __main__: train step 18271: loss: 0.9397, policy_loss: 0.8510, value_loss: 0.5111
2024-07-11 17:26:26,246 [INFO    ] __main__: train step 18272: loss: 0.9397, policy_loss: 0.8510, value_loss: 0.5111
2024-07-11 17:26:26,446 [INFO    ] __main__: train step 18273: loss: 0.9397, policy_loss: 0.8509, value_loss: 0.5110
2024-07-11 17:26:26,658 [INFO    ] __main__: train step 18274: loss: 0.9397, policy_loss: 0.8509, value_loss: 0.5110
2024-07-11 17:26:28,120 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:26:28,496 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:26:28,550 [INFO    ] __main__: train step 18275: loss: 0.9396, policy_loss: 0.8509, value_loss: 0.5110
2024-07-11 17:26:28,738 [INFO    ] __main__: train step 18276: loss: 0.9396, policy_loss: 0.8509, value_loss: 0.5110
2024-07-11 17:26:28,963 [INFO    ] __main__: train step 18277: loss: 0.9396, policy_loss: 0.8509, value_loss: 0.5109
2024-07-11 17:26:29,177 [INFO    ] __main__: train step 18278: loss: 0.9396, policy_loss: 0.8508, value_loss: 0.5109
2024-07-11 17:26:29,417 [INFO    ] __main__: train step 18279: loss: 0.9395, policy_loss: 0.8508, value_loss: 0.5109
2024-07-11 17:26:29,649 [INFO    ] __main__: train step 18280: loss: 0.9395, policy_loss: 0.8508, value_loss: 0.5109
2024-07-11 17:26:29,851 [INFO    ] __main__: train step 18281: loss: 0.9395, policy_loss: 0.8508, value_loss: 0.5109
2024-07-11 17:26:30,055 [INFO    ] __main__: train step 18282: loss: 0.9395, policy_loss: 0.8507, value_loss: 0.5108
2024-07-11 17:26:30,266 [INFO    ] __main__: train step 18283: loss: 0.9395, policy_loss: 0.8507, value_loss: 0.5108
2024-07-11 17:26:30,475 [INFO    ] __main__: train step 18284: loss: 0.9394, policy_loss: 0.8507, value_loss: 0.5108
2024-07-11 17:26:30,686 [INFO    ] __main__: train step 18285: loss: 0.9394, policy_loss: 0.8507, value_loss: 0.5108
2024-07-11 17:26:30,881 [INFO    ] __main__: train step 18286: loss: 0.9394, policy_loss: 0.8506, value_loss: 0.5107
2024-07-11 17:26:31,091 [INFO    ] __main__: train step 18287: loss: 0.9394, policy_loss: 0.8506, value_loss: 0.5107
2024-07-11 17:26:31,293 [INFO    ] __main__: train step 18288: loss: 0.9393, policy_loss: 0.8506, value_loss: 0.5107
2024-07-11 17:26:31,494 [INFO    ] __main__: train step 18289: loss: 0.9393, policy_loss: 0.8506, value_loss: 0.5107
2024-07-11 17:26:31,695 [INFO    ] __main__: train step 18290: loss: 0.9393, policy_loss: 0.8505, value_loss: 0.5107
2024-07-11 17:26:31,896 [INFO    ] __main__: train step 18291: loss: 0.9393, policy_loss: 0.8505, value_loss: 0.5106
2024-07-11 17:26:33,340 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:26:33,718 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:26:33,773 [INFO    ] __main__: train step 18292: loss: 0.9393, policy_loss: 0.8505, value_loss: 0.5106
2024-07-11 17:26:33,953 [INFO    ] __main__: train step 18293: loss: 0.9392, policy_loss: 0.8505, value_loss: 0.5106
2024-07-11 17:26:34,150 [INFO    ] __main__: train step 18294: loss: 0.9392, policy_loss: 0.8505, value_loss: 0.5106
2024-07-11 17:26:34,359 [INFO    ] __main__: train step 18295: loss: 0.9392, policy_loss: 0.8504, value_loss: 0.5106
2024-07-11 17:26:34,583 [INFO    ] __main__: train step 18296: loss: 0.9392, policy_loss: 0.8504, value_loss: 0.5105
2024-07-11 17:26:34,804 [INFO    ] __main__: train step 18297: loss: 0.9391, policy_loss: 0.8504, value_loss: 0.5105
2024-07-11 17:26:35,017 [INFO    ] __main__: train step 18298: loss: 0.9391, policy_loss: 0.8504, value_loss: 0.5105
2024-07-11 17:26:35,244 [INFO    ] __main__: train step 18299: loss: 0.9391, policy_loss: 0.8503, value_loss: 0.5105
2024-07-11 17:26:35,458 [INFO    ] __main__: train step 18300: loss: 0.9391, policy_loss: 0.8503, value_loss: 0.5104
2024-07-11 17:26:35,697 [INFO    ] __main__: train step 18301: loss: 0.9391, policy_loss: 0.8503, value_loss: 0.5104
2024-07-11 17:26:35,929 [INFO    ] __main__: train step 18302: loss: 0.9390, policy_loss: 0.8503, value_loss: 0.5104
2024-07-11 17:26:36,148 [INFO    ] __main__: train step 18303: loss: 0.9390, policy_loss: 0.8503, value_loss: 0.5104
2024-07-11 17:26:36,398 [INFO    ] __main__: train step 18304: loss: 0.9390, policy_loss: 0.8502, value_loss: 0.5104
2024-07-11 17:26:36,634 [INFO    ] __main__: train step 18305: loss: 0.9390, policy_loss: 0.8502, value_loss: 0.5103
2024-07-11 17:26:36,868 [INFO    ] __main__: train step 18306: loss: 0.9390, policy_loss: 0.8502, value_loss: 0.5103
2024-07-11 17:26:37,074 [INFO    ] __main__: train step 18307: loss: 0.9389, policy_loss: 0.8502, value_loss: 0.5103
2024-07-11 17:26:37,272 [INFO    ] __main__: train step 18308: loss: 0.9389, policy_loss: 0.8501, value_loss: 0.5103
2024-07-11 17:26:38,716 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:26:39,137 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:26:39,200 [INFO    ] __main__: train step 18309: loss: 0.9389, policy_loss: 0.8501, value_loss: 0.5102
2024-07-11 17:26:39,380 [INFO    ] __main__: train step 18310: loss: 0.9389, policy_loss: 0.8501, value_loss: 0.5102
2024-07-11 17:26:39,622 [INFO    ] __main__: train step 18311: loss: 0.9388, policy_loss: 0.8501, value_loss: 0.5102
2024-07-11 17:26:39,831 [INFO    ] __main__: train step 18312: loss: 0.9388, policy_loss: 0.8500, value_loss: 0.5102
2024-07-11 17:26:40,026 [INFO    ] __main__: train step 18313: loss: 0.9388, policy_loss: 0.8500, value_loss: 0.5102
2024-07-11 17:26:40,235 [INFO    ] __main__: train step 18314: loss: 0.9388, policy_loss: 0.8500, value_loss: 0.5101
2024-07-11 17:26:40,453 [INFO    ] __main__: train step 18315: loss: 0.9388, policy_loss: 0.8500, value_loss: 0.5101
2024-07-11 17:26:40,649 [INFO    ] __main__: train step 18316: loss: 0.9387, policy_loss: 0.8500, value_loss: 0.5101
2024-07-11 17:26:40,852 [INFO    ] __main__: train step 18317: loss: 0.9387, policy_loss: 0.8499, value_loss: 0.5101
2024-07-11 17:26:41,056 [INFO    ] __main__: train step 18318: loss: 0.9387, policy_loss: 0.8499, value_loss: 0.5101
2024-07-11 17:26:41,256 [INFO    ] __main__: train step 18319: loss: 0.9387, policy_loss: 0.8499, value_loss: 0.5100
2024-07-11 17:26:41,458 [INFO    ] __main__: train step 18320: loss: 0.9387, policy_loss: 0.8499, value_loss: 0.5100
2024-07-11 17:26:41,674 [INFO    ] __main__: train step 18321: loss: 0.9386, policy_loss: 0.8498, value_loss: 0.5100
2024-07-11 17:26:41,907 [INFO    ] __main__: train step 18322: loss: 0.9386, policy_loss: 0.8498, value_loss: 0.5100
2024-07-11 17:26:42,133 [INFO    ] __main__: train step 18323: loss: 0.9386, policy_loss: 0.8498, value_loss: 0.5099
2024-07-11 17:26:42,337 [INFO    ] __main__: train step 18324: loss: 0.9386, policy_loss: 0.8498, value_loss: 0.5099
2024-07-11 17:26:42,553 [INFO    ] __main__: train step 18325: loss: 0.9385, policy_loss: 0.8498, value_loss: 0.5099
2024-07-11 17:26:44,042 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:26:44,453 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:26:44,519 [INFO    ] __main__: train step 18326: loss: 0.9385, policy_loss: 0.8497, value_loss: 0.5099
2024-07-11 17:26:44,710 [INFO    ] __main__: train step 18327: loss: 0.9385, policy_loss: 0.8497, value_loss: 0.5099
2024-07-11 17:26:46,631 [INFO    ] __main__: train step 18328: loss: 0.9385, policy_loss: 0.8497, value_loss: 0.5098
2024-07-11 17:26:46,855 [INFO    ] __main__: train step 18329: loss: 0.9385, policy_loss: 0.8497, value_loss: 0.5098
2024-07-11 17:26:47,062 [INFO    ] __main__: train step 18330: loss: 0.9384, policy_loss: 0.8496, value_loss: 0.5098
2024-07-11 17:26:47,275 [INFO    ] __main__: train step 18331: loss: 0.9384, policy_loss: 0.8496, value_loss: 0.5098
2024-07-11 17:26:47,476 [INFO    ] __main__: train step 18332: loss: 0.9384, policy_loss: 0.8496, value_loss: 0.5097
2024-07-11 17:26:47,689 [INFO    ] __main__: train step 18333: loss: 0.9384, policy_loss: 0.8496, value_loss: 0.5097
2024-07-11 17:26:47,894 [INFO    ] __main__: train step 18334: loss: 0.9384, policy_loss: 0.8495, value_loss: 0.5097
2024-07-11 17:26:48,093 [INFO    ] __main__: train step 18335: loss: 0.9383, policy_loss: 0.8495, value_loss: 0.5097
2024-07-11 17:26:48,326 [INFO    ] __main__: train step 18336: loss: 0.9383, policy_loss: 0.8495, value_loss: 0.5097
2024-07-11 17:26:48,554 [INFO    ] __main__: train step 18337: loss: 0.9383, policy_loss: 0.8495, value_loss: 0.5096
2024-07-11 17:26:48,801 [INFO    ] __main__: train step 18338: loss: 0.9383, policy_loss: 0.8495, value_loss: 0.5096
2024-07-11 17:26:49,010 [INFO    ] __main__: train step 18339: loss: 0.9383, policy_loss: 0.8494, value_loss: 0.5096
2024-07-11 17:26:49,219 [INFO    ] __main__: train step 18340: loss: 0.9382, policy_loss: 0.8494, value_loss: 0.5096
2024-07-11 17:26:49,428 [INFO    ] __main__: train step 18341: loss: 0.9382, policy_loss: 0.8494, value_loss: 0.5096
2024-07-11 17:26:49,643 [INFO    ] __main__: train step 18342: loss: 0.9382, policy_loss: 0.8494, value_loss: 0.5095
2024-07-11 17:26:51,089 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:26:51,539 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:26:51,600 [INFO    ] __main__: train step 18343: loss: 0.9382, policy_loss: 0.8493, value_loss: 0.5095
2024-07-11 17:26:51,779 [INFO    ] __main__: train step 18344: loss: 0.9381, policy_loss: 0.8493, value_loss: 0.5095
2024-07-11 17:26:51,989 [INFO    ] __main__: train step 18345: loss: 0.9381, policy_loss: 0.8493, value_loss: 0.5095
2024-07-11 17:26:52,187 [INFO    ] __main__: train step 18346: loss: 0.9381, policy_loss: 0.8493, value_loss: 0.5094
2024-07-11 17:26:52,394 [INFO    ] __main__: train step 18347: loss: 0.9381, policy_loss: 0.8493, value_loss: 0.5094
2024-07-11 17:26:52,600 [INFO    ] __main__: train step 18348: loss: 0.9381, policy_loss: 0.8492, value_loss: 0.5094
2024-07-11 17:26:52,811 [INFO    ] __main__: train step 18349: loss: 0.9380, policy_loss: 0.8492, value_loss: 0.5094
2024-07-11 17:26:53,012 [INFO    ] __main__: train step 18350: loss: 0.9380, policy_loss: 0.8492, value_loss: 0.5094
2024-07-11 17:26:53,220 [INFO    ] __main__: train step 18351: loss: 0.9380, policy_loss: 0.8492, value_loss: 0.5093
2024-07-11 17:26:53,419 [INFO    ] __main__: train step 18352: loss: 0.9380, policy_loss: 0.8491, value_loss: 0.5093
2024-07-11 17:26:53,627 [INFO    ] __main__: train step 18353: loss: 0.9380, policy_loss: 0.8491, value_loss: 0.5093
2024-07-11 17:26:53,835 [INFO    ] __main__: train step 18354: loss: 0.9379, policy_loss: 0.8491, value_loss: 0.5093
2024-07-11 17:26:54,056 [INFO    ] __main__: train step 18355: loss: 0.9379, policy_loss: 0.8491, value_loss: 0.5092
2024-07-11 17:26:54,269 [INFO    ] __main__: train step 18356: loss: 0.9379, policy_loss: 0.8491, value_loss: 0.5092
2024-07-11 17:26:54,510 [INFO    ] __main__: train step 18357: loss: 0.9379, policy_loss: 0.8490, value_loss: 0.5092
2024-07-11 17:26:54,741 [INFO    ] __main__: train step 18358: loss: 0.9378, policy_loss: 0.8490, value_loss: 0.5092
2024-07-11 17:26:54,985 [INFO    ] __main__: train step 18359: loss: 0.9378, policy_loss: 0.8490, value_loss: 0.5092
2024-07-11 17:26:56,458 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:26:56,855 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:26:56,915 [INFO    ] __main__: train step 18360: loss: 0.9378, policy_loss: 0.8490, value_loss: 0.5091
2024-07-11 17:26:57,094 [INFO    ] __main__: train step 18361: loss: 0.9378, policy_loss: 0.8489, value_loss: 0.5091
2024-07-11 17:26:57,313 [INFO    ] __main__: train step 18362: loss: 0.9378, policy_loss: 0.8489, value_loss: 0.5091
2024-07-11 17:26:57,556 [INFO    ] __main__: train step 18363: loss: 0.9377, policy_loss: 0.8489, value_loss: 0.5091
2024-07-11 17:26:57,761 [INFO    ] __main__: train step 18364: loss: 0.9377, policy_loss: 0.8489, value_loss: 0.5091
2024-07-11 17:26:57,973 [INFO    ] __main__: train step 18365: loss: 0.9377, policy_loss: 0.8489, value_loss: 0.5090
2024-07-11 17:26:58,202 [INFO    ] __main__: train step 18366: loss: 0.9377, policy_loss: 0.8488, value_loss: 0.5090
2024-07-11 17:26:58,403 [INFO    ] __main__: train step 18367: loss: 0.9377, policy_loss: 0.8488, value_loss: 0.5090
2024-07-11 17:26:58,599 [INFO    ] __main__: train step 18368: loss: 0.9376, policy_loss: 0.8488, value_loss: 0.5090
2024-07-11 17:26:58,798 [INFO    ] __main__: train step 18369: loss: 0.9376, policy_loss: 0.8488, value_loss: 0.5089
2024-07-11 17:26:59,003 [INFO    ] __main__: train step 18370: loss: 0.9376, policy_loss: 0.8487, value_loss: 0.5089
2024-07-11 17:26:59,200 [INFO    ] __main__: train step 18371: loss: 0.9376, policy_loss: 0.8487, value_loss: 0.5089
2024-07-11 17:26:59,410 [INFO    ] __main__: train step 18372: loss: 0.9376, policy_loss: 0.8487, value_loss: 0.5089
2024-07-11 17:26:59,629 [INFO    ] __main__: train step 18373: loss: 0.9375, policy_loss: 0.8487, value_loss: 0.5089
2024-07-11 17:26:59,832 [INFO    ] __main__: train step 18374: loss: 0.9375, policy_loss: 0.8487, value_loss: 0.5088
2024-07-11 17:27:00,043 [INFO    ] __main__: train step 18375: loss: 0.9375, policy_loss: 0.8486, value_loss: 0.5088
2024-07-11 17:27:00,249 [INFO    ] __main__: train step 18376: loss: 0.9375, policy_loss: 0.8486, value_loss: 0.5088
2024-07-11 17:27:01,690 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:27:02,004 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:27:02,061 [INFO    ] __main__: train step 18377: loss: 0.9375, policy_loss: 0.8486, value_loss: 0.5088
2024-07-11 17:27:02,248 [INFO    ] __main__: train step 18378: loss: 0.9374, policy_loss: 0.8486, value_loss: 0.5088
2024-07-11 17:27:02,454 [INFO    ] __main__: train step 18379: loss: 0.9374, policy_loss: 0.8485, value_loss: 0.5087
2024-07-11 17:27:02,657 [INFO    ] __main__: train step 18380: loss: 0.9374, policy_loss: 0.8485, value_loss: 0.5087
2024-07-11 17:27:02,871 [INFO    ] __main__: train step 18381: loss: 0.9374, policy_loss: 0.8485, value_loss: 0.5087
2024-07-11 17:27:03,107 [INFO    ] __main__: train step 18382: loss: 0.9373, policy_loss: 0.8485, value_loss: 0.5087
2024-07-11 17:27:03,321 [INFO    ] __main__: train step 18383: loss: 0.9373, policy_loss: 0.8485, value_loss: 0.5086
2024-07-11 17:27:03,562 [INFO    ] __main__: train step 18384: loss: 0.9373, policy_loss: 0.8484, value_loss: 0.5086
2024-07-11 17:27:03,766 [INFO    ] __main__: train step 18385: loss: 0.9373, policy_loss: 0.8484, value_loss: 0.5086
2024-07-11 17:27:03,961 [INFO    ] __main__: train step 18386: loss: 0.9373, policy_loss: 0.8484, value_loss: 0.5086
2024-07-11 17:27:04,164 [INFO    ] __main__: train step 18387: loss: 0.9372, policy_loss: 0.8484, value_loss: 0.5086
2024-07-11 17:27:04,361 [INFO    ] __main__: train step 18388: loss: 0.9372, policy_loss: 0.8483, value_loss: 0.5085
2024-07-11 17:27:04,561 [INFO    ] __main__: train step 18389: loss: 0.9372, policy_loss: 0.8483, value_loss: 0.5085
2024-07-11 17:27:04,777 [INFO    ] __main__: train step 18390: loss: 0.9372, policy_loss: 0.8483, value_loss: 0.5085
2024-07-11 17:27:04,989 [INFO    ] __main__: train step 18391: loss: 0.9372, policy_loss: 0.8483, value_loss: 0.5085
2024-07-11 17:27:05,225 [INFO    ] __main__: train step 18392: loss: 0.9371, policy_loss: 0.8483, value_loss: 0.5084
2024-07-11 17:27:05,425 [INFO    ] __main__: train step 18393: loss: 0.9371, policy_loss: 0.8482, value_loss: 0.5084
2024-07-11 17:27:06,872 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:27:07,253 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:27:07,311 [INFO    ] __main__: train step 18394: loss: 0.9371, policy_loss: 0.8482, value_loss: 0.5084
2024-07-11 17:27:07,485 [INFO    ] __main__: train step 18395: loss: 0.9371, policy_loss: 0.8482, value_loss: 0.5084
2024-07-11 17:27:07,709 [INFO    ] __main__: train step 18396: loss: 0.9371, policy_loss: 0.8482, value_loss: 0.5084
2024-07-11 17:27:07,910 [INFO    ] __main__: train step 18397: loss: 0.9370, policy_loss: 0.8481, value_loss: 0.5083
2024-07-11 17:27:08,117 [INFO    ] __main__: train step 18398: loss: 0.9370, policy_loss: 0.8481, value_loss: 0.5083
2024-07-11 17:27:08,331 [INFO    ] __main__: train step 18399: loss: 0.9370, policy_loss: 0.8481, value_loss: 0.5083
2024-07-11 17:27:08,545 [INFO    ] __main__: train step 18400: loss: 0.9370, policy_loss: 0.8481, value_loss: 0.5083
2024-07-11 17:27:08,757 [INFO    ] __main__: train step 18401: loss: 0.9370, policy_loss: 0.8481, value_loss: 0.5083
2024-07-11 17:27:08,957 [INFO    ] __main__: train step 18402: loss: 0.9369, policy_loss: 0.8480, value_loss: 0.5082
2024-07-11 17:27:09,183 [INFO    ] __main__: train step 18403: loss: 0.9369, policy_loss: 0.8480, value_loss: 0.5082
2024-07-11 17:27:09,387 [INFO    ] __main__: train step 18404: loss: 0.9369, policy_loss: 0.8480, value_loss: 0.5082
2024-07-11 17:27:09,592 [INFO    ] __main__: train step 18405: loss: 0.9369, policy_loss: 0.8480, value_loss: 0.5082
2024-07-11 17:27:09,800 [INFO    ] __main__: train step 18406: loss: 0.9368, policy_loss: 0.8480, value_loss: 0.5081
2024-07-11 17:27:10,001 [INFO    ] __main__: train step 18407: loss: 0.9368, policy_loss: 0.8479, value_loss: 0.5081
2024-07-11 17:27:10,212 [INFO    ] __main__: train step 18408: loss: 0.9368, policy_loss: 0.8479, value_loss: 0.5081
2024-07-11 17:27:10,419 [INFO    ] __main__: train step 18409: loss: 0.9368, policy_loss: 0.8479, value_loss: 0.5081
2024-07-11 17:27:10,632 [INFO    ] __main__: train step 18410: loss: 0.9368, policy_loss: 0.8479, value_loss: 0.5081
2024-07-11 17:27:12,089 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:27:12,430 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:27:12,489 [INFO    ] __main__: train step 18411: loss: 0.9367, policy_loss: 0.8478, value_loss: 0.5080
2024-07-11 17:27:12,665 [INFO    ] __main__: train step 18412: loss: 0.9367, policy_loss: 0.8478, value_loss: 0.5080
2024-07-11 17:27:12,870 [INFO    ] __main__: train step 18413: loss: 0.9367, policy_loss: 0.8478, value_loss: 0.5080
2024-07-11 17:27:13,069 [INFO    ] __main__: train step 18414: loss: 0.9367, policy_loss: 0.8478, value_loss: 0.5080
2024-07-11 17:27:13,265 [INFO    ] __main__: train step 18415: loss: 0.9367, policy_loss: 0.8478, value_loss: 0.5080
2024-07-11 17:27:13,471 [INFO    ] __main__: train step 18416: loss: 0.9366, policy_loss: 0.8477, value_loss: 0.5079
2024-07-11 17:27:13,675 [INFO    ] __main__: train step 18417: loss: 0.9366, policy_loss: 0.8477, value_loss: 0.5079
2024-07-11 17:27:13,876 [INFO    ] __main__: train step 18418: loss: 0.9366, policy_loss: 0.8477, value_loss: 0.5079
2024-07-11 17:27:14,088 [INFO    ] __main__: train step 18419: loss: 0.9366, policy_loss: 0.8477, value_loss: 0.5079
2024-07-11 17:27:14,284 [INFO    ] __main__: train step 18420: loss: 0.9366, policy_loss: 0.8476, value_loss: 0.5078
2024-07-11 17:27:14,497 [INFO    ] __main__: train step 18421: loss: 0.9365, policy_loss: 0.8476, value_loss: 0.5078
2024-07-11 17:27:14,742 [INFO    ] __main__: train step 18422: loss: 0.9365, policy_loss: 0.8476, value_loss: 0.5078
2024-07-11 17:27:14,944 [INFO    ] __main__: train step 18423: loss: 0.9365, policy_loss: 0.8476, value_loss: 0.5078
2024-07-11 17:27:15,152 [INFO    ] __main__: train step 18424: loss: 0.9365, policy_loss: 0.8476, value_loss: 0.5078
2024-07-11 17:27:15,362 [INFO    ] __main__: train step 18425: loss: 0.9365, policy_loss: 0.8475, value_loss: 0.5077
2024-07-11 17:27:15,576 [INFO    ] __main__: train step 18426: loss: 0.9364, policy_loss: 0.8475, value_loss: 0.5077
2024-07-11 17:27:15,779 [INFO    ] __main__: train step 18427: loss: 0.9364, policy_loss: 0.8475, value_loss: 0.5077
2024-07-11 17:27:17,228 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:27:17,598 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:27:17,653 [INFO    ] __main__: train step 18428: loss: 0.9364, policy_loss: 0.8475, value_loss: 0.5077
2024-07-11 17:27:17,844 [INFO    ] __main__: train step 18429: loss: 0.9364, policy_loss: 0.8475, value_loss: 0.5076
2024-07-11 17:27:18,075 [INFO    ] __main__: train step 18430: loss: 0.9364, policy_loss: 0.8474, value_loss: 0.5076
2024-07-11 17:27:18,285 [INFO    ] __main__: train step 18431: loss: 0.9363, policy_loss: 0.8474, value_loss: 0.5076
2024-07-11 17:27:18,489 [INFO    ] __main__: train step 18432: loss: 0.9363, policy_loss: 0.8474, value_loss: 0.5076
2024-07-11 17:27:18,706 [INFO    ] __main__: train step 18433: loss: 0.9363, policy_loss: 0.8474, value_loss: 0.5076
2024-07-11 17:27:18,945 [INFO    ] __main__: train step 18434: loss: 0.9363, policy_loss: 0.8473, value_loss: 0.5075
2024-07-11 17:27:19,185 [INFO    ] __main__: train step 18435: loss: 0.9363, policy_loss: 0.8473, value_loss: 0.5075
2024-07-11 17:27:19,391 [INFO    ] __main__: train step 18436: loss: 0.9362, policy_loss: 0.8473, value_loss: 0.5075
2024-07-11 17:27:19,624 [INFO    ] __main__: train step 18437: loss: 0.9362, policy_loss: 0.8473, value_loss: 0.5075
2024-07-11 17:27:19,820 [INFO    ] __main__: train step 18438: loss: 0.9362, policy_loss: 0.8473, value_loss: 0.5075
2024-07-11 17:27:20,020 [INFO    ] __main__: train step 18439: loss: 0.9362, policy_loss: 0.8472, value_loss: 0.5074
2024-07-11 17:27:20,226 [INFO    ] __main__: train step 18440: loss: 0.9362, policy_loss: 0.8472, value_loss: 0.5074
2024-07-11 17:27:20,459 [INFO    ] __main__: train step 18441: loss: 0.9361, policy_loss: 0.8472, value_loss: 0.5074
2024-07-11 17:27:22,564 [INFO    ] __main__: train step 18442: loss: 0.9361, policy_loss: 0.8472, value_loss: 0.5074
2024-07-11 17:27:22,771 [INFO    ] __main__: train step 18443: loss: 0.9361, policy_loss: 0.8472, value_loss: 0.5073
2024-07-11 17:27:23,012 [INFO    ] __main__: train step 18444: loss: 0.9361, policy_loss: 0.8471, value_loss: 0.5073
2024-07-11 17:27:24,539 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:27:24,910 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:27:24,970 [INFO    ] __main__: train step 18445: loss: 0.9361, policy_loss: 0.8471, value_loss: 0.5073
2024-07-11 17:27:25,144 [INFO    ] __main__: train step 18446: loss: 0.9360, policy_loss: 0.8471, value_loss: 0.5073
2024-07-11 17:27:25,358 [INFO    ] __main__: train step 18447: loss: 0.9360, policy_loss: 0.8471, value_loss: 0.5073
2024-07-11 17:27:25,553 [INFO    ] __main__: train step 18448: loss: 0.9360, policy_loss: 0.8470, value_loss: 0.5072
2024-07-11 17:27:25,751 [INFO    ] __main__: train step 18449: loss: 0.9360, policy_loss: 0.8470, value_loss: 0.5072
2024-07-11 17:27:25,953 [INFO    ] __main__: train step 18450: loss: 0.9359, policy_loss: 0.8470, value_loss: 0.5072
2024-07-11 17:27:26,164 [INFO    ] __main__: train step 18451: loss: 0.9359, policy_loss: 0.8470, value_loss: 0.5072
2024-07-11 17:27:26,406 [INFO    ] __main__: train step 18452: loss: 0.9359, policy_loss: 0.8470, value_loss: 0.5072
2024-07-11 17:27:26,617 [INFO    ] __main__: train step 18453: loss: 0.9359, policy_loss: 0.8469, value_loss: 0.5071
2024-07-11 17:27:26,825 [INFO    ] __main__: train step 18454: loss: 0.9359, policy_loss: 0.8469, value_loss: 0.5071
2024-07-11 17:27:27,030 [INFO    ] __main__: train step 18455: loss: 0.9358, policy_loss: 0.8469, value_loss: 0.5071
2024-07-11 17:27:27,240 [INFO    ] __main__: train step 18456: loss: 0.9358, policy_loss: 0.8469, value_loss: 0.5071
2024-07-11 17:27:27,456 [INFO    ] __main__: train step 18457: loss: 0.9358, policy_loss: 0.8468, value_loss: 0.5070
2024-07-11 17:27:27,661 [INFO    ] __main__: train step 18458: loss: 0.9358, policy_loss: 0.8468, value_loss: 0.5070
2024-07-11 17:27:27,860 [INFO    ] __main__: train step 18459: loss: 0.9358, policy_loss: 0.8468, value_loss: 0.5070
2024-07-11 17:27:28,061 [INFO    ] __main__: train step 18460: loss: 0.9357, policy_loss: 0.8468, value_loss: 0.5070
2024-07-11 17:27:28,267 [INFO    ] __main__: train step 18461: loss: 0.9357, policy_loss: 0.8468, value_loss: 0.5070
2024-07-11 17:27:29,709 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:27:30,093 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:27:30,153 [INFO    ] __main__: train step 18462: loss: 0.9357, policy_loss: 0.8467, value_loss: 0.5069
2024-07-11 17:27:30,337 [INFO    ] __main__: train step 18463: loss: 0.9357, policy_loss: 0.8467, value_loss: 0.5069
2024-07-11 17:27:30,553 [INFO    ] __main__: train step 18464: loss: 0.9357, policy_loss: 0.8467, value_loss: 0.5069
2024-07-11 17:27:30,767 [INFO    ] __main__: train step 18465: loss: 0.9356, policy_loss: 0.8467, value_loss: 0.5069
2024-07-11 17:27:30,959 [INFO    ] __main__: train step 18466: loss: 0.9356, policy_loss: 0.8467, value_loss: 0.5069
2024-07-11 17:27:31,157 [INFO    ] __main__: train step 18467: loss: 0.9356, policy_loss: 0.8466, value_loss: 0.5068
2024-07-11 17:27:31,388 [INFO    ] __main__: train step 18468: loss: 0.9356, policy_loss: 0.8466, value_loss: 0.5068
2024-07-11 17:27:31,593 [INFO    ] __main__: train step 18469: loss: 0.9356, policy_loss: 0.8466, value_loss: 0.5068
2024-07-11 17:27:31,809 [INFO    ] __main__: train step 18470: loss: 0.9355, policy_loss: 0.8466, value_loss: 0.5068
2024-07-11 17:27:32,001 [INFO    ] __main__: train step 18471: loss: 0.9355, policy_loss: 0.8466, value_loss: 0.5067
2024-07-11 17:27:32,201 [INFO    ] __main__: train step 18472: loss: 0.9355, policy_loss: 0.8465, value_loss: 0.5067
2024-07-11 17:27:32,417 [INFO    ] __main__: train step 18473: loss: 0.9355, policy_loss: 0.8465, value_loss: 0.5067
2024-07-11 17:27:32,648 [INFO    ] __main__: train step 18474: loss: 0.9355, policy_loss: 0.8465, value_loss: 0.5067
2024-07-11 17:27:32,856 [INFO    ] __main__: train step 18475: loss: 0.9354, policy_loss: 0.8465, value_loss: 0.5067
2024-07-11 17:27:33,061 [INFO    ] __main__: train step 18476: loss: 0.9354, policy_loss: 0.8464, value_loss: 0.5066
2024-07-11 17:27:33,285 [INFO    ] __main__: train step 18477: loss: 0.9354, policy_loss: 0.8464, value_loss: 0.5066
2024-07-11 17:27:33,497 [INFO    ] __main__: train step 18478: loss: 0.9354, policy_loss: 0.8464, value_loss: 0.5066
2024-07-11 17:27:34,939 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:27:35,299 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:27:35,353 [INFO    ] __main__: train step 18479: loss: 0.9354, policy_loss: 0.8464, value_loss: 0.5066
2024-07-11 17:27:35,550 [INFO    ] __main__: train step 18480: loss: 0.9353, policy_loss: 0.8464, value_loss: 0.5065
2024-07-11 17:27:35,762 [INFO    ] __main__: train step 18481: loss: 0.9353, policy_loss: 0.8463, value_loss: 0.5065
2024-07-11 17:27:35,996 [INFO    ] __main__: train step 18482: loss: 0.9353, policy_loss: 0.8463, value_loss: 0.5065
2024-07-11 17:27:36,233 [INFO    ] __main__: train step 18483: loss: 0.9353, policy_loss: 0.8463, value_loss: 0.5065
2024-07-11 17:27:36,452 [INFO    ] __main__: train step 18484: loss: 0.9353, policy_loss: 0.8463, value_loss: 0.5065
2024-07-11 17:27:36,677 [INFO    ] __main__: train step 18485: loss: 0.9352, policy_loss: 0.8463, value_loss: 0.5064
2024-07-11 17:27:36,881 [INFO    ] __main__: train step 18486: loss: 0.9352, policy_loss: 0.8462, value_loss: 0.5064
2024-07-11 17:27:37,089 [INFO    ] __main__: train step 18487: loss: 0.9352, policy_loss: 0.8462, value_loss: 0.5064
2024-07-11 17:27:37,293 [INFO    ] __main__: train step 18488: loss: 0.9352, policy_loss: 0.8462, value_loss: 0.5064
2024-07-11 17:27:37,491 [INFO    ] __main__: train step 18489: loss: 0.9352, policy_loss: 0.8462, value_loss: 0.5064
2024-07-11 17:27:37,704 [INFO    ] __main__: train step 18490: loss: 0.9351, policy_loss: 0.8461, value_loss: 0.5063
2024-07-11 17:27:37,931 [INFO    ] __main__: train step 18491: loss: 0.9351, policy_loss: 0.8461, value_loss: 0.5063
2024-07-11 17:27:38,142 [INFO    ] __main__: train step 18492: loss: 0.9351, policy_loss: 0.8461, value_loss: 0.5063
2024-07-11 17:27:38,343 [INFO    ] __main__: train step 18493: loss: 0.9351, policy_loss: 0.8461, value_loss: 0.5063
2024-07-11 17:27:38,548 [INFO    ] __main__: train step 18494: loss: 0.9351, policy_loss: 0.8461, value_loss: 0.5062
2024-07-11 17:27:38,764 [INFO    ] __main__: train step 18495: loss: 0.9350, policy_loss: 0.8460, value_loss: 0.5062
2024-07-11 17:27:40,216 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:27:40,606 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:27:40,668 [INFO    ] __main__: train step 18496: loss: 0.9350, policy_loss: 0.8460, value_loss: 0.5062
2024-07-11 17:27:40,849 [INFO    ] __main__: train step 18497: loss: 0.9350, policy_loss: 0.8460, value_loss: 0.5062
2024-07-11 17:27:41,047 [INFO    ] __main__: train step 18498: loss: 0.9350, policy_loss: 0.8460, value_loss: 0.5062
2024-07-11 17:27:41,262 [INFO    ] __main__: train step 18499: loss: 0.9350, policy_loss: 0.8460, value_loss: 0.5061
2024-07-11 17:27:41,503 [INFO    ] __main__: train step 18500: loss: 0.9349, policy_loss: 0.8459, value_loss: 0.5061
2024-07-11 17:27:41,755 [INFO    ] __main__: train step 18501: loss: 0.9349, policy_loss: 0.8459, value_loss: 0.5061
2024-07-11 17:27:42,003 [INFO    ] __main__: train step 18502: loss: 0.9349, policy_loss: 0.8459, value_loss: 0.5061
2024-07-11 17:27:42,241 [INFO    ] __main__: train step 18503: loss: 0.9349, policy_loss: 0.8459, value_loss: 0.5061
2024-07-11 17:27:42,472 [INFO    ] __main__: train step 18504: loss: 0.9349, policy_loss: 0.8459, value_loss: 0.5060
2024-07-11 17:27:42,679 [INFO    ] __main__: train step 18505: loss: 0.9348, policy_loss: 0.8458, value_loss: 0.5060
2024-07-11 17:27:42,895 [INFO    ] __main__: train step 18506: loss: 0.9348, policy_loss: 0.8458, value_loss: 0.5060
2024-07-11 17:27:43,129 [INFO    ] __main__: train step 18507: loss: 0.9348, policy_loss: 0.8458, value_loss: 0.5060
2024-07-11 17:27:43,342 [INFO    ] __main__: train step 18508: loss: 0.9348, policy_loss: 0.8458, value_loss: 0.5059
2024-07-11 17:27:43,550 [INFO    ] __main__: train step 18509: loss: 0.9348, policy_loss: 0.8458, value_loss: 0.5059
2024-07-11 17:27:43,796 [INFO    ] __main__: train step 18510: loss: 0.9347, policy_loss: 0.8457, value_loss: 0.5059
2024-07-11 17:27:44,010 [INFO    ] __main__: train step 18511: loss: 0.9347, policy_loss: 0.8457, value_loss: 0.5059
2024-07-11 17:27:44,214 [INFO    ] __main__: train step 18512: loss: 0.9347, policy_loss: 0.8457, value_loss: 0.5059
2024-07-11 17:27:45,678 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:27:46,063 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:27:46,122 [INFO    ] __main__: train step 18513: loss: 0.9347, policy_loss: 0.8457, value_loss: 0.5058
2024-07-11 17:27:46,311 [INFO    ] __main__: train step 18514: loss: 0.9347, policy_loss: 0.8457, value_loss: 0.5058
2024-07-11 17:27:46,514 [INFO    ] __main__: train step 18515: loss: 0.9346, policy_loss: 0.8456, value_loss: 0.5058
2024-07-11 17:27:46,752 [INFO    ] __main__: train step 18516: loss: 0.9346, policy_loss: 0.8456, value_loss: 0.5058
2024-07-11 17:27:46,975 [INFO    ] __main__: train step 18517: loss: 0.9346, policy_loss: 0.8456, value_loss: 0.5058
2024-07-11 17:27:47,204 [INFO    ] __main__: train step 18518: loss: 0.9346, policy_loss: 0.8456, value_loss: 0.5057
2024-07-11 17:27:47,454 [INFO    ] __main__: train step 18519: loss: 0.9346, policy_loss: 0.8455, value_loss: 0.5057
2024-07-11 17:27:47,685 [INFO    ] __main__: train step 18520: loss: 0.9345, policy_loss: 0.8455, value_loss: 0.5057
2024-07-11 17:27:47,956 [INFO    ] __main__: train step 18521: loss: 0.9345, policy_loss: 0.8455, value_loss: 0.5057
2024-07-11 17:27:48,206 [INFO    ] __main__: train step 18522: loss: 0.9345, policy_loss: 0.8455, value_loss: 0.5056
2024-07-11 17:27:48,439 [INFO    ] __main__: train step 18523: loss: 0.9345, policy_loss: 0.8455, value_loss: 0.5056
2024-07-11 17:27:48,647 [INFO    ] __main__: train step 18524: loss: 0.9345, policy_loss: 0.8454, value_loss: 0.5056
2024-07-11 17:27:48,872 [INFO    ] __main__: train step 18525: loss: 0.9345, policy_loss: 0.8454, value_loss: 0.5056
2024-07-11 17:27:49,114 [INFO    ] __main__: train step 18526: loss: 0.9344, policy_loss: 0.8454, value_loss: 0.5056
2024-07-11 17:27:49,324 [INFO    ] __main__: train step 18527: loss: 0.9344, policy_loss: 0.8454, value_loss: 0.5055
2024-07-11 17:27:49,534 [INFO    ] __main__: train step 18528: loss: 0.9344, policy_loss: 0.8454, value_loss: 0.5055
2024-07-11 17:27:49,735 [INFO    ] __main__: train step 18529: loss: 0.9344, policy_loss: 0.8453, value_loss: 0.5055
2024-07-11 17:27:51,185 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:27:51,566 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:27:51,621 [INFO    ] __main__: train step 18530: loss: 0.9344, policy_loss: 0.8453, value_loss: 0.5055
2024-07-11 17:27:51,792 [INFO    ] __main__: train step 18531: loss: 0.9343, policy_loss: 0.8453, value_loss: 0.5055
2024-07-11 17:27:51,994 [INFO    ] __main__: train step 18532: loss: 0.9343, policy_loss: 0.8453, value_loss: 0.5054
2024-07-11 17:27:52,192 [INFO    ] __main__: train step 18533: loss: 0.9343, policy_loss: 0.8453, value_loss: 0.5054
2024-07-11 17:27:52,401 [INFO    ] __main__: train step 18534: loss: 0.9343, policy_loss: 0.8452, value_loss: 0.5054
2024-07-11 17:27:52,613 [INFO    ] __main__: train step 18535: loss: 0.9343, policy_loss: 0.8452, value_loss: 0.5054
2024-07-11 17:27:52,811 [INFO    ] __main__: train step 18536: loss: 0.9342, policy_loss: 0.8452, value_loss: 0.5053
2024-07-11 17:27:53,017 [INFO    ] __main__: train step 18537: loss: 0.9342, policy_loss: 0.8452, value_loss: 0.5053
2024-07-11 17:27:53,223 [INFO    ] __main__: train step 18538: loss: 0.9342, policy_loss: 0.8452, value_loss: 0.5053
2024-07-11 17:27:53,429 [INFO    ] __main__: train step 18539: loss: 0.9342, policy_loss: 0.8451, value_loss: 0.5053
2024-07-11 17:27:53,661 [INFO    ] __main__: train step 18540: loss: 0.9342, policy_loss: 0.8451, value_loss: 0.5053
2024-07-11 17:27:53,880 [INFO    ] __main__: train step 18541: loss: 0.9341, policy_loss: 0.8451, value_loss: 0.5052
2024-07-11 17:27:54,091 [INFO    ] __main__: train step 18542: loss: 0.9341, policy_loss: 0.8451, value_loss: 0.5052
2024-07-11 17:27:54,303 [INFO    ] __main__: train step 18543: loss: 0.9341, policy_loss: 0.8451, value_loss: 0.5052
2024-07-11 17:27:54,550 [INFO    ] __main__: train step 18544: loss: 0.9341, policy_loss: 0.8450, value_loss: 0.5052
2024-07-11 17:27:54,778 [INFO    ] __main__: train step 18545: loss: 0.9341, policy_loss: 0.8450, value_loss: 0.5052
2024-07-11 17:27:54,973 [INFO    ] __main__: train step 18546: loss: 0.9340, policy_loss: 0.8450, value_loss: 0.5051
2024-07-11 17:27:56,415 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:27:56,778 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:27:56,839 [INFO    ] __main__: train step 18547: loss: 0.9340, policy_loss: 0.8450, value_loss: 0.5051
2024-07-11 17:27:57,022 [INFO    ] __main__: train step 18548: loss: 0.9340, policy_loss: 0.8450, value_loss: 0.5051
2024-07-11 17:27:57,221 [INFO    ] __main__: train step 18549: loss: 0.9340, policy_loss: 0.8449, value_loss: 0.5051
2024-07-11 17:27:57,431 [INFO    ] __main__: train step 18550: loss: 0.9340, policy_loss: 0.8449, value_loss: 0.5050
2024-07-11 17:27:57,632 [INFO    ] __main__: train step 18551: loss: 0.9339, policy_loss: 0.8449, value_loss: 0.5050
2024-07-11 17:27:57,833 [INFO    ] __main__: train step 18552: loss: 0.9339, policy_loss: 0.8449, value_loss: 0.5050
2024-07-11 17:27:58,032 [INFO    ] __main__: train step 18553: loss: 0.9339, policy_loss: 0.8449, value_loss: 0.5050
2024-07-11 17:27:58,233 [INFO    ] __main__: train step 18554: loss: 0.9339, policy_loss: 0.8448, value_loss: 0.5050
2024-07-11 17:27:58,442 [INFO    ] __main__: train step 18555: loss: 0.9339, policy_loss: 0.8448, value_loss: 0.5049
2024-07-11 17:27:58,642 [INFO    ] __main__: train step 18556: loss: 0.9338, policy_loss: 0.8448, value_loss: 0.5049
2024-07-11 17:28:00,715 [INFO    ] __main__: train step 18557: loss: 0.9338, policy_loss: 0.8448, value_loss: 0.5049
2024-07-11 17:28:00,958 [INFO    ] __main__: train step 18558: loss: 0.9338, policy_loss: 0.8448, value_loss: 0.5049
2024-07-11 17:28:01,221 [INFO    ] __main__: train step 18559: loss: 0.9338, policy_loss: 0.8447, value_loss: 0.5049
2024-07-11 17:28:01,439 [INFO    ] __main__: train step 18560: loss: 0.9338, policy_loss: 0.8447, value_loss: 0.5048
2024-07-11 17:28:01,656 [INFO    ] __main__: train step 18561: loss: 0.9337, policy_loss: 0.8447, value_loss: 0.5048
2024-07-11 17:28:01,874 [INFO    ] __main__: train step 18562: loss: 0.9337, policy_loss: 0.8447, value_loss: 0.5048
2024-07-11 17:28:02,074 [INFO    ] __main__: train step 18563: loss: 0.9337, policy_loss: 0.8446, value_loss: 0.5048
2024-07-11 17:28:03,516 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:28:03,828 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:28:03,888 [INFO    ] __main__: train step 18564: loss: 0.9337, policy_loss: 0.8446, value_loss: 0.5047
2024-07-11 17:28:04,063 [INFO    ] __main__: train step 18565: loss: 0.9337, policy_loss: 0.8446, value_loss: 0.5047
2024-07-11 17:28:04,269 [INFO    ] __main__: train step 18566: loss: 0.9337, policy_loss: 0.8446, value_loss: 0.5047
2024-07-11 17:28:04,470 [INFO    ] __main__: train step 18567: loss: 0.9336, policy_loss: 0.8446, value_loss: 0.5047
2024-07-11 17:28:04,671 [INFO    ] __main__: train step 18568: loss: 0.9336, policy_loss: 0.8446, value_loss: 0.5047
2024-07-11 17:28:04,873 [INFO    ] __main__: train step 18569: loss: 0.9336, policy_loss: 0.8445, value_loss: 0.5046
2024-07-11 17:28:05,078 [INFO    ] __main__: train step 18570: loss: 0.9336, policy_loss: 0.8445, value_loss: 0.5046
2024-07-11 17:28:05,282 [INFO    ] __main__: train step 18571: loss: 0.9336, policy_loss: 0.8445, value_loss: 0.5046
2024-07-11 17:28:05,503 [INFO    ] __main__: train step 18572: loss: 0.9335, policy_loss: 0.8445, value_loss: 0.5046
2024-07-11 17:28:05,705 [INFO    ] __main__: train step 18573: loss: 0.9335, policy_loss: 0.8445, value_loss: 0.5046
2024-07-11 17:28:05,917 [INFO    ] __main__: train step 18574: loss: 0.9335, policy_loss: 0.8444, value_loss: 0.5045
2024-07-11 17:28:06,112 [INFO    ] __main__: train step 18575: loss: 0.9335, policy_loss: 0.8444, value_loss: 0.5045
2024-07-11 17:28:06,328 [INFO    ] __main__: train step 18576: loss: 0.9335, policy_loss: 0.8444, value_loss: 0.5045
2024-07-11 17:28:06,535 [INFO    ] __main__: train step 18577: loss: 0.9334, policy_loss: 0.8444, value_loss: 0.5045
2024-07-11 17:28:06,740 [INFO    ] __main__: train step 18578: loss: 0.9334, policy_loss: 0.8444, value_loss: 0.5044
2024-07-11 17:28:06,947 [INFO    ] __main__: train step 18579: loss: 0.9334, policy_loss: 0.8443, value_loss: 0.5044
2024-07-11 17:28:07,162 [INFO    ] __main__: train step 18580: loss: 0.9334, policy_loss: 0.8443, value_loss: 0.5044
2024-07-11 17:28:08,605 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:28:08,935 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:28:08,990 [INFO    ] __main__: train step 18581: loss: 0.9334, policy_loss: 0.8443, value_loss: 0.5044
2024-07-11 17:28:09,181 [INFO    ] __main__: train step 18582: loss: 0.9333, policy_loss: 0.8443, value_loss: 0.5044
2024-07-11 17:28:09,387 [INFO    ] __main__: train step 18583: loss: 0.9333, policy_loss: 0.8443, value_loss: 0.5043
2024-07-11 17:28:09,594 [INFO    ] __main__: train step 18584: loss: 0.9333, policy_loss: 0.8442, value_loss: 0.5043
2024-07-11 17:28:09,808 [INFO    ] __main__: train step 18585: loss: 0.9333, policy_loss: 0.8442, value_loss: 0.5043
2024-07-11 17:28:10,008 [INFO    ] __main__: train step 18586: loss: 0.9333, policy_loss: 0.8442, value_loss: 0.5043
2024-07-11 17:28:10,234 [INFO    ] __main__: train step 18587: loss: 0.9333, policy_loss: 0.8442, value_loss: 0.5042
2024-07-11 17:28:10,509 [INFO    ] __main__: train step 18588: loss: 0.9332, policy_loss: 0.8442, value_loss: 0.5042
2024-07-11 17:28:10,757 [INFO    ] __main__: train step 18589: loss: 0.9332, policy_loss: 0.8441, value_loss: 0.5042
2024-07-11 17:28:10,993 [INFO    ] __main__: train step 18590: loss: 0.9332, policy_loss: 0.8441, value_loss: 0.5042
2024-07-11 17:28:11,210 [INFO    ] __main__: train step 18591: loss: 0.9332, policy_loss: 0.8441, value_loss: 0.5042
2024-07-11 17:28:11,453 [INFO    ] __main__: train step 18592: loss: 0.9332, policy_loss: 0.8441, value_loss: 0.5041
2024-07-11 17:28:11,692 [INFO    ] __main__: train step 18593: loss: 0.9331, policy_loss: 0.8441, value_loss: 0.5041
2024-07-11 17:28:11,931 [INFO    ] __main__: train step 18594: loss: 0.9331, policy_loss: 0.8440, value_loss: 0.5041
2024-07-11 17:28:12,181 [INFO    ] __main__: train step 18595: loss: 0.9331, policy_loss: 0.8440, value_loss: 0.5041
2024-07-11 17:28:12,420 [INFO    ] __main__: train step 18596: loss: 0.9331, policy_loss: 0.8440, value_loss: 0.5041
2024-07-11 17:28:12,627 [INFO    ] __main__: train step 18597: loss: 0.9331, policy_loss: 0.8440, value_loss: 0.5040
2024-07-11 17:28:14,068 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:28:14,439 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:28:14,494 [INFO    ] __main__: train step 18598: loss: 0.9330, policy_loss: 0.8440, value_loss: 0.5040
2024-07-11 17:28:14,690 [INFO    ] __main__: train step 18599: loss: 0.9330, policy_loss: 0.8439, value_loss: 0.5040
2024-07-11 17:28:14,898 [INFO    ] __main__: train step 18600: loss: 0.9330, policy_loss: 0.8439, value_loss: 0.5040
2024-07-11 17:28:15,136 [INFO    ] __main__: train step 18601: loss: 0.9330, policy_loss: 0.8439, value_loss: 0.5039
2024-07-11 17:28:15,356 [INFO    ] __main__: train step 18602: loss: 0.9330, policy_loss: 0.8439, value_loss: 0.5039
2024-07-11 17:28:15,550 [INFO    ] __main__: train step 18603: loss: 0.9329, policy_loss: 0.8439, value_loss: 0.5039
2024-07-11 17:28:15,769 [INFO    ] __main__: train step 18604: loss: 0.9329, policy_loss: 0.8438, value_loss: 0.5039
2024-07-11 17:28:15,977 [INFO    ] __main__: train step 18605: loss: 0.9329, policy_loss: 0.8438, value_loss: 0.5039
2024-07-11 17:28:16,186 [INFO    ] __main__: train step 18606: loss: 0.9329, policy_loss: 0.8438, value_loss: 0.5038
2024-07-11 17:28:16,388 [INFO    ] __main__: train step 18607: loss: 0.9329, policy_loss: 0.8438, value_loss: 0.5038
2024-07-11 17:28:16,592 [INFO    ] __main__: train step 18608: loss: 0.9329, policy_loss: 0.8438, value_loss: 0.5038
2024-07-11 17:28:16,794 [INFO    ] __main__: train step 18609: loss: 0.9328, policy_loss: 0.8437, value_loss: 0.5038
2024-07-11 17:28:17,003 [INFO    ] __main__: train step 18610: loss: 0.9328, policy_loss: 0.8437, value_loss: 0.5038
2024-07-11 17:28:17,203 [INFO    ] __main__: train step 18611: loss: 0.9328, policy_loss: 0.8437, value_loss: 0.5037
2024-07-11 17:28:17,409 [INFO    ] __main__: train step 18612: loss: 0.9328, policy_loss: 0.8437, value_loss: 0.5037
2024-07-11 17:28:17,621 [INFO    ] __main__: train step 18613: loss: 0.9328, policy_loss: 0.8437, value_loss: 0.5037
2024-07-11 17:28:17,842 [INFO    ] __main__: train step 18614: loss: 0.9327, policy_loss: 0.8436, value_loss: 0.5037
2024-07-11 17:28:19,316 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:28:19,711 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:28:19,777 [INFO    ] __main__: train step 18615: loss: 0.9327, policy_loss: 0.8436, value_loss: 0.5036
2024-07-11 17:28:19,951 [INFO    ] __main__: train step 18616: loss: 0.9327, policy_loss: 0.8436, value_loss: 0.5036
2024-07-11 17:28:20,159 [INFO    ] __main__: train step 18617: loss: 0.9327, policy_loss: 0.8436, value_loss: 0.5036
2024-07-11 17:28:20,370 [INFO    ] __main__: train step 18618: loss: 0.9327, policy_loss: 0.8436, value_loss: 0.5036
2024-07-11 17:28:20,587 [INFO    ] __main__: train step 18619: loss: 0.9326, policy_loss: 0.8435, value_loss: 0.5036
2024-07-11 17:28:20,787 [INFO    ] __main__: train step 18620: loss: 0.9326, policy_loss: 0.8435, value_loss: 0.5035
2024-07-11 17:28:20,996 [INFO    ] __main__: train step 18621: loss: 0.9326, policy_loss: 0.8435, value_loss: 0.5035
2024-07-11 17:28:21,199 [INFO    ] __main__: train step 18622: loss: 0.9326, policy_loss: 0.8435, value_loss: 0.5035
2024-07-11 17:28:21,419 [INFO    ] __main__: train step 18623: loss: 0.9326, policy_loss: 0.8435, value_loss: 0.5035
2024-07-11 17:28:21,626 [INFO    ] __main__: train step 18624: loss: 0.9326, policy_loss: 0.8434, value_loss: 0.5035
2024-07-11 17:28:21,832 [INFO    ] __main__: train step 18625: loss: 0.9325, policy_loss: 0.8434, value_loss: 0.5034
2024-07-11 17:28:22,055 [INFO    ] __main__: train step 18626: loss: 0.9325, policy_loss: 0.8434, value_loss: 0.5034
2024-07-11 17:28:22,261 [INFO    ] __main__: train step 18627: loss: 0.9325, policy_loss: 0.8434, value_loss: 0.5034
2024-07-11 17:28:22,458 [INFO    ] __main__: train step 18628: loss: 0.9325, policy_loss: 0.8434, value_loss: 0.5034
2024-07-11 17:28:22,662 [INFO    ] __main__: train step 18629: loss: 0.9325, policy_loss: 0.8434, value_loss: 0.5033
2024-07-11 17:28:22,863 [INFO    ] __main__: train step 18630: loss: 0.9324, policy_loss: 0.8433, value_loss: 0.5033
2024-07-11 17:28:23,060 [INFO    ] __main__: train step 18631: loss: 0.9324, policy_loss: 0.8433, value_loss: 0.5033
2024-07-11 17:28:24,508 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:28:24,861 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:28:24,916 [INFO    ] __main__: train step 18632: loss: 0.9324, policy_loss: 0.8433, value_loss: 0.5033
2024-07-11 17:28:25,097 [INFO    ] __main__: train step 18633: loss: 0.9324, policy_loss: 0.8433, value_loss: 0.5033
2024-07-11 17:28:25,304 [INFO    ] __main__: train step 18634: loss: 0.9324, policy_loss: 0.8433, value_loss: 0.5032
2024-07-11 17:28:25,510 [INFO    ] __main__: train step 18635: loss: 0.9323, policy_loss: 0.8432, value_loss: 0.5032
2024-07-11 17:28:25,712 [INFO    ] __main__: train step 18636: loss: 0.9323, policy_loss: 0.8432, value_loss: 0.5032
2024-07-11 17:28:25,920 [INFO    ] __main__: train step 18637: loss: 0.9323, policy_loss: 0.8432, value_loss: 0.5032
2024-07-11 17:28:26,120 [INFO    ] __main__: train step 18638: loss: 0.9323, policy_loss: 0.8432, value_loss: 0.5031
2024-07-11 17:28:26,328 [INFO    ] __main__: train step 18639: loss: 0.9323, policy_loss: 0.8432, value_loss: 0.5031
2024-07-11 17:28:26,534 [INFO    ] __main__: train step 18640: loss: 0.9323, policy_loss: 0.8431, value_loss: 0.5031
2024-07-11 17:28:26,739 [INFO    ] __main__: train step 18641: loss: 0.9322, policy_loss: 0.8431, value_loss: 0.5031
2024-07-11 17:28:26,965 [INFO    ] __main__: train step 18642: loss: 0.9322, policy_loss: 0.8431, value_loss: 0.5031
2024-07-11 17:28:27,205 [INFO    ] __main__: train step 18643: loss: 0.9322, policy_loss: 0.8431, value_loss: 0.5030
2024-07-11 17:28:27,421 [INFO    ] __main__: train step 18644: loss: 0.9322, policy_loss: 0.8431, value_loss: 0.5030
2024-07-11 17:28:27,625 [INFO    ] __main__: train step 18645: loss: 0.9322, policy_loss: 0.8430, value_loss: 0.5030
2024-07-11 17:28:27,835 [INFO    ] __main__: train step 18646: loss: 0.9321, policy_loss: 0.8430, value_loss: 0.5030
2024-07-11 17:28:28,040 [INFO    ] __main__: train step 18647: loss: 0.9321, policy_loss: 0.8430, value_loss: 0.5030
2024-07-11 17:28:28,281 [INFO    ] __main__: train step 18648: loss: 0.9321, policy_loss: 0.8430, value_loss: 0.5029
2024-07-11 17:28:29,716 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:28:30,067 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:28:30,126 [INFO    ] __main__: train step 18649: loss: 0.9321, policy_loss: 0.8430, value_loss: 0.5029
2024-07-11 17:28:30,309 [INFO    ] __main__: train step 18650: loss: 0.9321, policy_loss: 0.8429, value_loss: 0.5029
2024-07-11 17:28:30,523 [INFO    ] __main__: train step 18651: loss: 0.9321, policy_loss: 0.8429, value_loss: 0.5029
2024-07-11 17:28:30,726 [INFO    ] __main__: train step 18652: loss: 0.9320, policy_loss: 0.8429, value_loss: 0.5028
2024-07-11 17:28:30,933 [INFO    ] __main__: train step 18653: loss: 0.9320, policy_loss: 0.8429, value_loss: 0.5028
2024-07-11 17:28:31,133 [INFO    ] __main__: train step 18654: loss: 0.9320, policy_loss: 0.8429, value_loss: 0.5028
2024-07-11 17:28:31,344 [INFO    ] __main__: train step 18655: loss: 0.9320, policy_loss: 0.8429, value_loss: 0.5028
2024-07-11 17:28:31,553 [INFO    ] __main__: train step 18656: loss: 0.9320, policy_loss: 0.8428, value_loss: 0.5028
2024-07-11 17:28:31,752 [INFO    ] __main__: train step 18657: loss: 0.9319, policy_loss: 0.8428, value_loss: 0.5027
2024-07-11 17:28:31,958 [INFO    ] __main__: train step 18658: loss: 0.9319, policy_loss: 0.8428, value_loss: 0.5027
2024-07-11 17:28:32,153 [INFO    ] __main__: train step 18659: loss: 0.9319, policy_loss: 0.8428, value_loss: 0.5027
2024-07-11 17:28:32,349 [INFO    ] __main__: train step 18660: loss: 0.9319, policy_loss: 0.8428, value_loss: 0.5027
2024-07-11 17:28:32,567 [INFO    ] __main__: train step 18661: loss: 0.9319, policy_loss: 0.8427, value_loss: 0.5026
2024-07-11 17:28:32,800 [INFO    ] __main__: train step 18662: loss: 0.9319, policy_loss: 0.8427, value_loss: 0.5026
2024-07-11 17:28:33,006 [INFO    ] __main__: train step 18663: loss: 0.9318, policy_loss: 0.8427, value_loss: 0.5026
2024-07-11 17:28:33,222 [INFO    ] __main__: train step 18664: loss: 0.9318, policy_loss: 0.8427, value_loss: 0.5026
2024-07-11 17:28:33,415 [INFO    ] __main__: train step 18665: loss: 0.9318, policy_loss: 0.8427, value_loss: 0.5026
2024-07-11 17:28:34,861 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:28:35,240 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:28:35,302 [INFO    ] __main__: train step 18666: loss: 0.9318, policy_loss: 0.8426, value_loss: 0.5025
2024-07-11 17:28:35,478 [INFO    ] __main__: train step 18667: loss: 0.9318, policy_loss: 0.8426, value_loss: 0.5025
2024-07-11 17:28:35,688 [INFO    ] __main__: train step 18668: loss: 0.9317, policy_loss: 0.8426, value_loss: 0.5025
2024-07-11 17:28:35,916 [INFO    ] __main__: train step 18669: loss: 0.9317, policy_loss: 0.8426, value_loss: 0.5025
2024-07-11 17:28:36,112 [INFO    ] __main__: train step 18670: loss: 0.9317, policy_loss: 0.8426, value_loss: 0.5025
2024-07-11 17:28:36,331 [INFO    ] __main__: train step 18671: loss: 0.9317, policy_loss: 0.8426, value_loss: 0.5024
2024-07-11 17:28:36,531 [INFO    ] __main__: train step 18672: loss: 0.9317, policy_loss: 0.8425, value_loss: 0.5024
2024-07-11 17:28:38,425 [INFO    ] __main__: train step 18673: loss: 0.9316, policy_loss: 0.8425, value_loss: 0.5024
2024-07-11 17:28:38,669 [INFO    ] __main__: train step 18674: loss: 0.9316, policy_loss: 0.8425, value_loss: 0.5024
2024-07-11 17:28:38,889 [INFO    ] __main__: train step 18675: loss: 0.9316, policy_loss: 0.8425, value_loss: 0.5023
2024-07-11 17:28:39,106 [INFO    ] __main__: train step 18676: loss: 0.9316, policy_loss: 0.8425, value_loss: 0.5023
2024-07-11 17:28:39,312 [INFO    ] __main__: train step 18677: loss: 0.9316, policy_loss: 0.8424, value_loss: 0.5023
2024-07-11 17:28:39,513 [INFO    ] __main__: train step 18678: loss: 0.9316, policy_loss: 0.8424, value_loss: 0.5023
2024-07-11 17:28:39,716 [INFO    ] __main__: train step 18679: loss: 0.9315, policy_loss: 0.8424, value_loss: 0.5023
2024-07-11 17:28:39,924 [INFO    ] __main__: train step 18680: loss: 0.9315, policy_loss: 0.8424, value_loss: 0.5022
2024-07-11 17:28:40,125 [INFO    ] __main__: train step 18681: loss: 0.9315, policy_loss: 0.8424, value_loss: 0.5022
2024-07-11 17:28:40,327 [INFO    ] __main__: train step 18682: loss: 0.9315, policy_loss: 0.8423, value_loss: 0.5022
2024-07-11 17:28:41,778 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:28:42,124 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:28:42,182 [INFO    ] __main__: train step 18683: loss: 0.9315, policy_loss: 0.8423, value_loss: 0.5022
2024-07-11 17:28:42,367 [INFO    ] __main__: train step 18684: loss: 0.9314, policy_loss: 0.8423, value_loss: 0.5022
2024-07-11 17:28:42,570 [INFO    ] __main__: train step 18685: loss: 0.9314, policy_loss: 0.8423, value_loss: 0.5021
2024-07-11 17:28:42,776 [INFO    ] __main__: train step 18686: loss: 0.9314, policy_loss: 0.8423, value_loss: 0.5021
2024-07-11 17:28:42,971 [INFO    ] __main__: train step 18687: loss: 0.9314, policy_loss: 0.8423, value_loss: 0.5021
2024-07-11 17:28:43,177 [INFO    ] __main__: train step 18688: loss: 0.9314, policy_loss: 0.8422, value_loss: 0.5021
2024-07-11 17:28:43,380 [INFO    ] __main__: train step 18689: loss: 0.9314, policy_loss: 0.8422, value_loss: 0.5020
2024-07-11 17:28:43,579 [INFO    ] __main__: train step 18690: loss: 0.9313, policy_loss: 0.8422, value_loss: 0.5020
2024-07-11 17:28:43,787 [INFO    ] __main__: train step 18691: loss: 0.9313, policy_loss: 0.8422, value_loss: 0.5020
2024-07-11 17:28:43,992 [INFO    ] __main__: train step 18692: loss: 0.9313, policy_loss: 0.8422, value_loss: 0.5020
2024-07-11 17:28:44,187 [INFO    ] __main__: train step 18693: loss: 0.9313, policy_loss: 0.8421, value_loss: 0.5020
2024-07-11 17:28:44,403 [INFO    ] __main__: train step 18694: loss: 0.9313, policy_loss: 0.8421, value_loss: 0.5019
2024-07-11 17:28:44,632 [INFO    ] __main__: train step 18695: loss: 0.9313, policy_loss: 0.8421, value_loss: 0.5019
2024-07-11 17:28:44,841 [INFO    ] __main__: train step 18696: loss: 0.9312, policy_loss: 0.8421, value_loss: 0.5019
2024-07-11 17:28:45,078 [INFO    ] __main__: train step 18697: loss: 0.9312, policy_loss: 0.8421, value_loss: 0.5019
2024-07-11 17:28:45,288 [INFO    ] __main__: train step 18698: loss: 0.9312, policy_loss: 0.8420, value_loss: 0.5019
2024-07-11 17:28:45,488 [INFO    ] __main__: train step 18699: loss: 0.9312, policy_loss: 0.8420, value_loss: 0.5018
2024-07-11 17:28:46,929 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:28:47,317 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:28:47,377 [INFO    ] __main__: train step 18700: loss: 0.9312, policy_loss: 0.8420, value_loss: 0.5018
2024-07-11 17:28:47,565 [INFO    ] __main__: train step 18701: loss: 0.9311, policy_loss: 0.8420, value_loss: 0.5018
2024-07-11 17:28:47,768 [INFO    ] __main__: train step 18702: loss: 0.9311, policy_loss: 0.8420, value_loss: 0.5018
2024-07-11 17:28:47,979 [INFO    ] __main__: train step 18703: loss: 0.9311, policy_loss: 0.8420, value_loss: 0.5017
2024-07-11 17:28:48,189 [INFO    ] __main__: train step 18704: loss: 0.9311, policy_loss: 0.8419, value_loss: 0.5017
2024-07-11 17:28:48,402 [INFO    ] __main__: train step 18705: loss: 0.9311, policy_loss: 0.8419, value_loss: 0.5017
2024-07-11 17:28:48,607 [INFO    ] __main__: train step 18706: loss: 0.9311, policy_loss: 0.8419, value_loss: 0.5017
2024-07-11 17:28:48,807 [INFO    ] __main__: train step 18707: loss: 0.9310, policy_loss: 0.8419, value_loss: 0.5017
2024-07-11 17:28:49,018 [INFO    ] __main__: train step 18708: loss: 0.9310, policy_loss: 0.8419, value_loss: 0.5016
2024-07-11 17:28:49,214 [INFO    ] __main__: train step 18709: loss: 0.9310, policy_loss: 0.8419, value_loss: 0.5016
2024-07-11 17:28:49,419 [INFO    ] __main__: train step 18710: loss: 0.9310, policy_loss: 0.8418, value_loss: 0.5016
2024-07-11 17:28:49,619 [INFO    ] __main__: train step 18711: loss: 0.9310, policy_loss: 0.8418, value_loss: 0.5016
2024-07-11 17:28:49,827 [INFO    ] __main__: train step 18712: loss: 0.9310, policy_loss: 0.8418, value_loss: 0.5016
2024-07-11 17:28:50,029 [INFO    ] __main__: train step 18713: loss: 0.9309, policy_loss: 0.8418, value_loss: 0.5015
2024-07-11 17:28:50,229 [INFO    ] __main__: train step 18714: loss: 0.9309, policy_loss: 0.8418, value_loss: 0.5015
2024-07-11 17:28:50,439 [INFO    ] __main__: train step 18715: loss: 0.9309, policy_loss: 0.8417, value_loss: 0.5015
2024-07-11 17:28:50,658 [INFO    ] __main__: train step 18716: loss: 0.9309, policy_loss: 0.8417, value_loss: 0.5015
2024-07-11 17:28:52,099 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:28:52,457 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:28:52,516 [INFO    ] __main__: train step 18717: loss: 0.9309, policy_loss: 0.8417, value_loss: 0.5014
2024-07-11 17:28:52,704 [INFO    ] __main__: train step 18718: loss: 0.9308, policy_loss: 0.8417, value_loss: 0.5014
2024-07-11 17:28:52,921 [INFO    ] __main__: train step 18719: loss: 0.9308, policy_loss: 0.8417, value_loss: 0.5014
2024-07-11 17:28:53,127 [INFO    ] __main__: train step 18720: loss: 0.9308, policy_loss: 0.8416, value_loss: 0.5014
2024-07-11 17:28:53,332 [INFO    ] __main__: train step 18721: loss: 0.9308, policy_loss: 0.8416, value_loss: 0.5014
2024-07-11 17:28:53,537 [INFO    ] __main__: train step 18722: loss: 0.9308, policy_loss: 0.8416, value_loss: 0.5013
2024-07-11 17:28:53,753 [INFO    ] __main__: train step 18723: loss: 0.9308, policy_loss: 0.8416, value_loss: 0.5013
2024-07-11 17:28:53,988 [INFO    ] __main__: train step 18724: loss: 0.9307, policy_loss: 0.8416, value_loss: 0.5013
2024-07-11 17:28:54,204 [INFO    ] __main__: train step 18725: loss: 0.9307, policy_loss: 0.8416, value_loss: 0.5013
2024-07-11 17:28:54,428 [INFO    ] __main__: train step 18726: loss: 0.9307, policy_loss: 0.8415, value_loss: 0.5012
2024-07-11 17:28:54,660 [INFO    ] __main__: train step 18727: loss: 0.9307, policy_loss: 0.8415, value_loss: 0.5012
2024-07-11 17:28:54,862 [INFO    ] __main__: train step 18728: loss: 0.9307, policy_loss: 0.8415, value_loss: 0.5012
2024-07-11 17:28:55,061 [INFO    ] __main__: train step 18729: loss: 0.9307, policy_loss: 0.8415, value_loss: 0.5012
2024-07-11 17:28:55,267 [INFO    ] __main__: train step 18730: loss: 0.9306, policy_loss: 0.8415, value_loss: 0.5012
2024-07-11 17:28:55,469 [INFO    ] __main__: train step 18731: loss: 0.9306, policy_loss: 0.8415, value_loss: 0.5011
2024-07-11 17:28:55,672 [INFO    ] __main__: train step 18732: loss: 0.9306, policy_loss: 0.8414, value_loss: 0.5011
2024-07-11 17:28:55,872 [INFO    ] __main__: train step 18733: loss: 0.9306, policy_loss: 0.8414, value_loss: 0.5011
2024-07-11 17:28:57,314 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:28:57,670 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:28:57,725 [INFO    ] __main__: train step 18734: loss: 0.9306, policy_loss: 0.8414, value_loss: 0.5011
2024-07-11 17:28:57,898 [INFO    ] __main__: train step 18735: loss: 0.9305, policy_loss: 0.8414, value_loss: 0.5011
2024-07-11 17:28:58,107 [INFO    ] __main__: train step 18736: loss: 0.9305, policy_loss: 0.8414, value_loss: 0.5010
2024-07-11 17:28:58,307 [INFO    ] __main__: train step 18737: loss: 0.9305, policy_loss: 0.8413, value_loss: 0.5010
2024-07-11 17:28:58,513 [INFO    ] __main__: train step 18738: loss: 0.9305, policy_loss: 0.8413, value_loss: 0.5010
2024-07-11 17:28:58,708 [INFO    ] __main__: train step 18739: loss: 0.9305, policy_loss: 0.8413, value_loss: 0.5010
2024-07-11 17:28:58,914 [INFO    ] __main__: train step 18740: loss: 0.9305, policy_loss: 0.8413, value_loss: 0.5009
2024-07-11 17:28:59,129 [INFO    ] __main__: train step 18741: loss: 0.9304, policy_loss: 0.8413, value_loss: 0.5009
2024-07-11 17:28:59,347 [INFO    ] __main__: train step 18742: loss: 0.9304, policy_loss: 0.8413, value_loss: 0.5009
2024-07-11 17:28:59,539 [INFO    ] __main__: train step 18743: loss: 0.9304, policy_loss: 0.8412, value_loss: 0.5009
2024-07-11 17:28:59,750 [INFO    ] __main__: train step 18744: loss: 0.9304, policy_loss: 0.8412, value_loss: 0.5009
2024-07-11 17:28:59,963 [INFO    ] __main__: train step 18745: loss: 0.9304, policy_loss: 0.8412, value_loss: 0.5008
2024-07-11 17:29:00,208 [INFO    ] __main__: train step 18746: loss: 0.9304, policy_loss: 0.8412, value_loss: 0.5008
2024-07-11 17:29:00,431 [INFO    ] __main__: train step 18747: loss: 0.9303, policy_loss: 0.8412, value_loss: 0.5008
2024-07-11 17:29:00,675 [INFO    ] __main__: train step 18748: loss: 0.9303, policy_loss: 0.8411, value_loss: 0.5008
2024-07-11 17:29:00,907 [INFO    ] __main__: train step 18749: loss: 0.9303, policy_loss: 0.8411, value_loss: 0.5008
2024-07-11 17:29:01,119 [INFO    ] __main__: train step 18750: loss: 0.9303, policy_loss: 0.8411, value_loss: 0.5007
2024-07-11 17:29:02,584 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:29:02,964 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:29:03,019 [INFO    ] __main__: train step 18751: loss: 0.9303, policy_loss: 0.8411, value_loss: 0.5007
2024-07-11 17:29:03,212 [INFO    ] __main__: train step 18752: loss: 0.9303, policy_loss: 0.8411, value_loss: 0.5007
2024-07-11 17:29:03,461 [INFO    ] __main__: train step 18753: loss: 0.9302, policy_loss: 0.8411, value_loss: 0.5007
2024-07-11 17:29:03,658 [INFO    ] __main__: train step 18754: loss: 0.9302, policy_loss: 0.8410, value_loss: 0.5006
2024-07-11 17:29:03,859 [INFO    ] __main__: train step 18755: loss: 0.9302, policy_loss: 0.8410, value_loss: 0.5006
2024-07-11 17:29:04,058 [INFO    ] __main__: train step 18756: loss: 0.9302, policy_loss: 0.8410, value_loss: 0.5006
2024-07-11 17:29:04,267 [INFO    ] __main__: train step 18757: loss: 0.9302, policy_loss: 0.8410, value_loss: 0.5006
2024-07-11 17:29:04,468 [INFO    ] __main__: train step 18758: loss: 0.9302, policy_loss: 0.8410, value_loss: 0.5006
2024-07-11 17:29:04,669 [INFO    ] __main__: train step 18759: loss: 0.9301, policy_loss: 0.8410, value_loss: 0.5005
2024-07-11 17:29:04,878 [INFO    ] __main__: train step 18760: loss: 0.9301, policy_loss: 0.8409, value_loss: 0.5005
2024-07-11 17:29:05,093 [INFO    ] __main__: train step 18761: loss: 0.9301, policy_loss: 0.8409, value_loss: 0.5005
2024-07-11 17:29:05,290 [INFO    ] __main__: train step 18762: loss: 0.9301, policy_loss: 0.8409, value_loss: 0.5005
2024-07-11 17:29:05,500 [INFO    ] __main__: train step 18763: loss: 0.9301, policy_loss: 0.8409, value_loss: 0.5005
2024-07-11 17:29:05,717 [INFO    ] __main__: train step 18764: loss: 0.9300, policy_loss: 0.8409, value_loss: 0.5004
2024-07-11 17:29:05,932 [INFO    ] __main__: train step 18765: loss: 0.9300, policy_loss: 0.8408, value_loss: 0.5004
2024-07-11 17:29:06,175 [INFO    ] __main__: train step 18766: loss: 0.9300, policy_loss: 0.8408, value_loss: 0.5004
2024-07-11 17:29:06,400 [INFO    ] __main__: train step 18767: loss: 0.9300, policy_loss: 0.8408, value_loss: 0.5004
2024-07-11 17:29:07,856 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:29:08,212 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:29:08,267 [INFO    ] __main__: train step 18768: loss: 0.9300, policy_loss: 0.8408, value_loss: 0.5003
2024-07-11 17:29:08,446 [INFO    ] __main__: train step 18769: loss: 0.9300, policy_loss: 0.8408, value_loss: 0.5003
2024-07-11 17:29:08,664 [INFO    ] __main__: train step 18770: loss: 0.9299, policy_loss: 0.8408, value_loss: 0.5003
2024-07-11 17:29:08,875 [INFO    ] __main__: train step 18771: loss: 0.9299, policy_loss: 0.8407, value_loss: 0.5003
2024-07-11 17:29:09,110 [INFO    ] __main__: train step 18772: loss: 0.9299, policy_loss: 0.8407, value_loss: 0.5003
2024-07-11 17:29:09,323 [INFO    ] __main__: train step 18773: loss: 0.9299, policy_loss: 0.8407, value_loss: 0.5002
2024-07-11 17:29:09,526 [INFO    ] __main__: train step 18774: loss: 0.9299, policy_loss: 0.8407, value_loss: 0.5002
2024-07-11 17:29:09,736 [INFO    ] __main__: train step 18775: loss: 0.9299, policy_loss: 0.8407, value_loss: 0.5002
2024-07-11 17:29:09,950 [INFO    ] __main__: train step 18776: loss: 0.9298, policy_loss: 0.8407, value_loss: 0.5002
2024-07-11 17:29:10,155 [INFO    ] __main__: train step 18777: loss: 0.9298, policy_loss: 0.8406, value_loss: 0.5002
2024-07-11 17:29:10,363 [INFO    ] __main__: train step 18778: loss: 0.9298, policy_loss: 0.8406, value_loss: 0.5001
2024-07-11 17:29:10,566 [INFO    ] __main__: train step 18779: loss: 0.9298, policy_loss: 0.8406, value_loss: 0.5001
2024-07-11 17:29:10,774 [INFO    ] __main__: train step 18780: loss: 0.9298, policy_loss: 0.8406, value_loss: 0.5001
2024-07-11 17:29:10,995 [INFO    ] __main__: train step 18781: loss: 0.9298, policy_loss: 0.8406, value_loss: 0.5001
2024-07-11 17:29:11,213 [INFO    ] __main__: train step 18782: loss: 0.9297, policy_loss: 0.8406, value_loss: 0.5000
2024-07-11 17:29:11,433 [INFO    ] __main__: train step 18783: loss: 0.9297, policy_loss: 0.8405, value_loss: 0.5000
2024-07-11 17:29:11,676 [INFO    ] __main__: train step 18784: loss: 0.9297, policy_loss: 0.8405, value_loss: 0.5000
2024-07-11 17:29:13,149 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:29:13,511 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:29:13,565 [INFO    ] __main__: train step 18785: loss: 0.9297, policy_loss: 0.8405, value_loss: 0.5000
2024-07-11 17:29:13,741 [INFO    ] __main__: train step 18786: loss: 0.9297, policy_loss: 0.8405, value_loss: 0.5000
2024-07-11 17:29:13,938 [INFO    ] __main__: train step 18787: loss: 0.9297, policy_loss: 0.8405, value_loss: 0.4999
2024-07-11 17:29:15,899 [INFO    ] __main__: train step 18788: loss: 0.9296, policy_loss: 0.8405, value_loss: 0.4999
2024-07-11 17:29:16,105 [INFO    ] __main__: train step 18789: loss: 0.9296, policy_loss: 0.8404, value_loss: 0.4999
2024-07-11 17:29:16,307 [INFO    ] __main__: train step 18790: loss: 0.9296, policy_loss: 0.8404, value_loss: 0.4999
2024-07-11 17:29:16,507 [INFO    ] __main__: train step 18791: loss: 0.9296, policy_loss: 0.8404, value_loss: 0.4999
2024-07-11 17:29:16,709 [INFO    ] __main__: train step 18792: loss: 0.9296, policy_loss: 0.8404, value_loss: 0.4998
2024-07-11 17:29:16,910 [INFO    ] __main__: train step 18793: loss: 0.9296, policy_loss: 0.8404, value_loss: 0.4998
2024-07-11 17:29:17,114 [INFO    ] __main__: train step 18794: loss: 0.9295, policy_loss: 0.8403, value_loss: 0.4998
2024-07-11 17:29:17,317 [INFO    ] __main__: train step 18795: loss: 0.9295, policy_loss: 0.8403, value_loss: 0.4998
2024-07-11 17:29:17,523 [INFO    ] __main__: train step 18796: loss: 0.9295, policy_loss: 0.8403, value_loss: 0.4997
2024-07-11 17:29:17,728 [INFO    ] __main__: train step 18797: loss: 0.9295, policy_loss: 0.8403, value_loss: 0.4997
2024-07-11 17:29:17,935 [INFO    ] __main__: train step 18798: loss: 0.9295, policy_loss: 0.8403, value_loss: 0.4997
2024-07-11 17:29:18,133 [INFO    ] __main__: train step 18799: loss: 0.9295, policy_loss: 0.8403, value_loss: 0.4997
2024-07-11 17:29:18,350 [INFO    ] __main__: train step 18800: loss: 0.9294, policy_loss: 0.8402, value_loss: 0.4997
2024-07-11 17:29:18,588 [INFO    ] __main__: train step 18801: loss: 0.9294, policy_loss: 0.8402, value_loss: 0.4996
2024-07-11 17:29:20,059 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:29:20,429 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:29:20,485 [INFO    ] __main__: train step 18802: loss: 0.9294, policy_loss: 0.8402, value_loss: 0.4996
2024-07-11 17:29:20,690 [INFO    ] __main__: train step 18803: loss: 0.9294, policy_loss: 0.8402, value_loss: 0.4996
2024-07-11 17:29:20,929 [INFO    ] __main__: train step 18804: loss: 0.9294, policy_loss: 0.8402, value_loss: 0.4996
2024-07-11 17:29:21,170 [INFO    ] __main__: train step 18805: loss: 0.9294, policy_loss: 0.8402, value_loss: 0.4996
2024-07-11 17:29:21,407 [INFO    ] __main__: train step 18806: loss: 0.9293, policy_loss: 0.8401, value_loss: 0.4995
2024-07-11 17:29:21,608 [INFO    ] __main__: train step 18807: loss: 0.9293, policy_loss: 0.8401, value_loss: 0.4995
2024-07-11 17:29:21,819 [INFO    ] __main__: train step 18808: loss: 0.9293, policy_loss: 0.8401, value_loss: 0.4995
2024-07-11 17:29:22,022 [INFO    ] __main__: train step 18809: loss: 0.9293, policy_loss: 0.8401, value_loss: 0.4995
2024-07-11 17:29:22,234 [INFO    ] __main__: train step 18810: loss: 0.9293, policy_loss: 0.8401, value_loss: 0.4994
2024-07-11 17:29:22,429 [INFO    ] __main__: train step 18811: loss: 0.9293, policy_loss: 0.8401, value_loss: 0.4994
2024-07-11 17:29:22,629 [INFO    ] __main__: train step 18812: loss: 0.9292, policy_loss: 0.8400, value_loss: 0.4994
2024-07-11 17:29:22,830 [INFO    ] __main__: train step 18813: loss: 0.9292, policy_loss: 0.8400, value_loss: 0.4994
2024-07-11 17:29:23,031 [INFO    ] __main__: train step 18814: loss: 0.9292, policy_loss: 0.8400, value_loss: 0.4994
2024-07-11 17:29:23,230 [INFO    ] __main__: train step 18815: loss: 0.9292, policy_loss: 0.8400, value_loss: 0.4993
2024-07-11 17:29:23,433 [INFO    ] __main__: train step 18816: loss: 0.9292, policy_loss: 0.8400, value_loss: 0.4993
2024-07-11 17:29:23,644 [INFO    ] __main__: train step 18817: loss: 0.9292, policy_loss: 0.8400, value_loss: 0.4993
2024-07-11 17:29:23,856 [INFO    ] __main__: train step 18818: loss: 0.9291, policy_loss: 0.8399, value_loss: 0.4993
2024-07-11 17:29:25,331 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:29:25,754 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:29:25,814 [INFO    ] __main__: train step 18819: loss: 0.9291, policy_loss: 0.8399, value_loss: 0.4993
2024-07-11 17:29:25,990 [INFO    ] __main__: train step 18820: loss: 0.9291, policy_loss: 0.8399, value_loss: 0.4992
2024-07-11 17:29:26,196 [INFO    ] __main__: train step 18821: loss: 0.9291, policy_loss: 0.8399, value_loss: 0.4992
2024-07-11 17:29:26,390 [INFO    ] __main__: train step 18822: loss: 0.9291, policy_loss: 0.8399, value_loss: 0.4992
2024-07-11 17:29:26,615 [INFO    ] __main__: train step 18823: loss: 0.9291, policy_loss: 0.8399, value_loss: 0.4992
2024-07-11 17:29:26,836 [INFO    ] __main__: train step 18824: loss: 0.9291, policy_loss: 0.8398, value_loss: 0.4992
2024-07-11 17:29:27,061 [INFO    ] __main__: train step 18825: loss: 0.9290, policy_loss: 0.8398, value_loss: 0.4991
2024-07-11 17:29:27,269 [INFO    ] __main__: train step 18826: loss: 0.9290, policy_loss: 0.8398, value_loss: 0.4991
2024-07-11 17:29:27,520 [INFO    ] __main__: train step 18827: loss: 0.9290, policy_loss: 0.8398, value_loss: 0.4991
2024-07-11 17:29:27,752 [INFO    ] __main__: train step 18828: loss: 0.9290, policy_loss: 0.8398, value_loss: 0.4991
2024-07-11 17:29:28,000 [INFO    ] __main__: train step 18829: loss: 0.9290, policy_loss: 0.8398, value_loss: 0.4990
2024-07-11 17:29:28,235 [INFO    ] __main__: train step 18830: loss: 0.9290, policy_loss: 0.8397, value_loss: 0.4990
2024-07-11 17:29:28,446 [INFO    ] __main__: train step 18831: loss: 0.9289, policy_loss: 0.8397, value_loss: 0.4990
2024-07-11 17:29:28,645 [INFO    ] __main__: train step 18832: loss: 0.9289, policy_loss: 0.8397, value_loss: 0.4990
2024-07-11 17:29:28,843 [INFO    ] __main__: train step 18833: loss: 0.9289, policy_loss: 0.8397, value_loss: 0.4990
2024-07-11 17:29:29,062 [INFO    ] __main__: train step 18834: loss: 0.9289, policy_loss: 0.8397, value_loss: 0.4989
2024-07-11 17:29:29,294 [INFO    ] __main__: train step 18835: loss: 0.9289, policy_loss: 0.8397, value_loss: 0.4989
2024-07-11 17:29:30,741 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:29:31,113 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:29:31,170 [INFO    ] __main__: train step 18836: loss: 0.9289, policy_loss: 0.8396, value_loss: 0.4989
2024-07-11 17:29:31,351 [INFO    ] __main__: train step 18837: loss: 0.9288, policy_loss: 0.8396, value_loss: 0.4989
2024-07-11 17:29:31,549 [INFO    ] __main__: train step 18838: loss: 0.9288, policy_loss: 0.8396, value_loss: 0.4989
2024-07-11 17:29:31,766 [INFO    ] __main__: train step 18839: loss: 0.9288, policy_loss: 0.8396, value_loss: 0.4988
2024-07-11 17:29:31,982 [INFO    ] __main__: train step 18840: loss: 0.9288, policy_loss: 0.8396, value_loss: 0.4988
2024-07-11 17:29:32,185 [INFO    ] __main__: train step 18841: loss: 0.9288, policy_loss: 0.8396, value_loss: 0.4988
2024-07-11 17:29:32,383 [INFO    ] __main__: train step 18842: loss: 0.9288, policy_loss: 0.8395, value_loss: 0.4988
2024-07-11 17:29:32,613 [INFO    ] __main__: train step 18843: loss: 0.9287, policy_loss: 0.8395, value_loss: 0.4987
2024-07-11 17:29:32,839 [INFO    ] __main__: train step 18844: loss: 0.9287, policy_loss: 0.8395, value_loss: 0.4987
2024-07-11 17:29:33,080 [INFO    ] __main__: train step 18845: loss: 0.9287, policy_loss: 0.8395, value_loss: 0.4987
2024-07-11 17:29:33,284 [INFO    ] __main__: train step 18846: loss: 0.9287, policy_loss: 0.8395, value_loss: 0.4987
2024-07-11 17:29:33,492 [INFO    ] __main__: train step 18847: loss: 0.9287, policy_loss: 0.8395, value_loss: 0.4987
2024-07-11 17:29:33,696 [INFO    ] __main__: train step 18848: loss: 0.9287, policy_loss: 0.8394, value_loss: 0.4986
2024-07-11 17:29:33,912 [INFO    ] __main__: train step 18849: loss: 0.9287, policy_loss: 0.8394, value_loss: 0.4986
2024-07-11 17:29:34,117 [INFO    ] __main__: train step 18850: loss: 0.9286, policy_loss: 0.8394, value_loss: 0.4986
2024-07-11 17:29:34,324 [INFO    ] __main__: train step 18851: loss: 0.9286, policy_loss: 0.8394, value_loss: 0.4986
2024-07-11 17:29:34,539 [INFO    ] __main__: train step 18852: loss: 0.9286, policy_loss: 0.8394, value_loss: 0.4986
2024-07-11 17:29:36,003 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:29:36,433 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:29:36,492 [INFO    ] __main__: train step 18853: loss: 0.9286, policy_loss: 0.8394, value_loss: 0.4985
2024-07-11 17:29:36,681 [INFO    ] __main__: train step 18854: loss: 0.9286, policy_loss: 0.8393, value_loss: 0.4985
2024-07-11 17:29:36,917 [INFO    ] __main__: train step 18855: loss: 0.9286, policy_loss: 0.8393, value_loss: 0.4985
2024-07-11 17:29:37,118 [INFO    ] __main__: train step 18856: loss: 0.9285, policy_loss: 0.8393, value_loss: 0.4985
2024-07-11 17:29:37,325 [INFO    ] __main__: train step 18857: loss: 0.9285, policy_loss: 0.8393, value_loss: 0.4985
2024-07-11 17:29:37,533 [INFO    ] __main__: train step 18858: loss: 0.9285, policy_loss: 0.8393, value_loss: 0.4984
2024-07-11 17:29:37,744 [INFO    ] __main__: train step 18859: loss: 0.9285, policy_loss: 0.8393, value_loss: 0.4984
2024-07-11 17:29:37,953 [INFO    ] __main__: train step 18860: loss: 0.9285, policy_loss: 0.8392, value_loss: 0.4984
2024-07-11 17:29:38,150 [INFO    ] __main__: train step 18861: loss: 0.9285, policy_loss: 0.8392, value_loss: 0.4984
2024-07-11 17:29:38,362 [INFO    ] __main__: train step 18862: loss: 0.9284, policy_loss: 0.8392, value_loss: 0.4983
2024-07-11 17:29:38,574 [INFO    ] __main__: train step 18863: loss: 0.9284, policy_loss: 0.8392, value_loss: 0.4983
2024-07-11 17:29:38,784 [INFO    ] __main__: train step 18864: loss: 0.9284, policy_loss: 0.8392, value_loss: 0.4983
2024-07-11 17:29:39,022 [INFO    ] __main__: train step 18865: loss: 0.9284, policy_loss: 0.8392, value_loss: 0.4983
2024-07-11 17:29:39,233 [INFO    ] __main__: train step 18866: loss: 0.9284, policy_loss: 0.8391, value_loss: 0.4983
2024-07-11 17:29:39,472 [INFO    ] __main__: train step 18867: loss: 0.9284, policy_loss: 0.8391, value_loss: 0.4982
2024-07-11 17:29:39,683 [INFO    ] __main__: train step 18868: loss: 0.9284, policy_loss: 0.8391, value_loss: 0.4982
2024-07-11 17:29:39,926 [INFO    ] __main__: train step 18869: loss: 0.9283, policy_loss: 0.8391, value_loss: 0.4982
2024-07-11 17:29:41,408 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:29:41,851 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:29:41,911 [INFO    ] __main__: train step 18870: loss: 0.9283, policy_loss: 0.8391, value_loss: 0.4982
2024-07-11 17:29:42,091 [INFO    ] __main__: train step 18871: loss: 0.9283, policy_loss: 0.8391, value_loss: 0.4982
2024-07-11 17:29:42,309 [INFO    ] __main__: train step 18872: loss: 0.9283, policy_loss: 0.8391, value_loss: 0.4981
2024-07-11 17:29:42,529 [INFO    ] __main__: train step 18873: loss: 0.9283, policy_loss: 0.8390, value_loss: 0.4981
2024-07-11 17:29:42,728 [INFO    ] __main__: train step 18874: loss: 0.9283, policy_loss: 0.8390, value_loss: 0.4981
2024-07-11 17:29:42,934 [INFO    ] __main__: train step 18875: loss: 0.9282, policy_loss: 0.8390, value_loss: 0.4981
2024-07-11 17:29:43,138 [INFO    ] __main__: train step 18876: loss: 0.9282, policy_loss: 0.8390, value_loss: 0.4981
2024-07-11 17:29:43,338 [INFO    ] __main__: train step 18877: loss: 0.9282, policy_loss: 0.8390, value_loss: 0.4980
2024-07-11 17:29:43,543 [INFO    ] __main__: train step 18878: loss: 0.9282, policy_loss: 0.8390, value_loss: 0.4980
2024-07-11 17:29:43,741 [INFO    ] __main__: train step 18879: loss: 0.9282, policy_loss: 0.8389, value_loss: 0.4980
2024-07-11 17:29:43,953 [INFO    ] __main__: train step 18880: loss: 0.9282, policy_loss: 0.8389, value_loss: 0.4980
2024-07-11 17:29:44,155 [INFO    ] __main__: train step 18881: loss: 0.9281, policy_loss: 0.8389, value_loss: 0.4979
2024-07-11 17:29:44,363 [INFO    ] __main__: train step 18882: loss: 0.9281, policy_loss: 0.8389, value_loss: 0.4979
2024-07-11 17:29:44,588 [INFO    ] __main__: train step 18883: loss: 0.9281, policy_loss: 0.8389, value_loss: 0.4979
2024-07-11 17:29:44,824 [INFO    ] __main__: train step 18884: loss: 0.9281, policy_loss: 0.8389, value_loss: 0.4979
2024-07-11 17:29:45,065 [INFO    ] __main__: train step 18885: loss: 0.9281, policy_loss: 0.8388, value_loss: 0.4979
2024-07-11 17:29:45,293 [INFO    ] __main__: train step 18886: loss: 0.9281, policy_loss: 0.8388, value_loss: 0.4978
2024-07-11 17:29:46,742 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:29:47,170 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:29:47,234 [INFO    ] __main__: train step 18887: loss: 0.9281, policy_loss: 0.8388, value_loss: 0.4978
2024-07-11 17:29:47,405 [INFO    ] __main__: train step 18888: loss: 0.9280, policy_loss: 0.8388, value_loss: 0.4978
2024-07-11 17:29:47,622 [INFO    ] __main__: train step 18889: loss: 0.9280, policy_loss: 0.8388, value_loss: 0.4978
2024-07-11 17:29:47,821 [INFO    ] __main__: train step 18890: loss: 0.9280, policy_loss: 0.8388, value_loss: 0.4978
2024-07-11 17:29:48,024 [INFO    ] __main__: train step 18891: loss: 0.9280, policy_loss: 0.8388, value_loss: 0.4977
2024-07-11 17:29:48,237 [INFO    ] __main__: train step 18892: loss: 0.9280, policy_loss: 0.8387, value_loss: 0.4977
2024-07-11 17:29:48,443 [INFO    ] __main__: train step 18893: loss: 0.9280, policy_loss: 0.8387, value_loss: 0.4977
2024-07-11 17:29:48,646 [INFO    ] __main__: train step 18894: loss: 0.9280, policy_loss: 0.8387, value_loss: 0.4977
2024-07-11 17:29:48,861 [INFO    ] __main__: train step 18895: loss: 0.9279, policy_loss: 0.8387, value_loss: 0.4977
2024-07-11 17:29:49,064 [INFO    ] __main__: train step 18896: loss: 0.9279, policy_loss: 0.8387, value_loss: 0.4976
2024-07-11 17:29:49,274 [INFO    ] __main__: train step 18897: loss: 0.9279, policy_loss: 0.8387, value_loss: 0.4976
2024-07-11 17:29:49,482 [INFO    ] __main__: train step 18898: loss: 0.9279, policy_loss: 0.8386, value_loss: 0.4976
2024-07-11 17:29:49,682 [INFO    ] __main__: train step 18899: loss: 0.9279, policy_loss: 0.8386, value_loss: 0.4976
2024-07-11 17:29:49,896 [INFO    ] __main__: train step 18900: loss: 0.9279, policy_loss: 0.8386, value_loss: 0.4975
2024-07-11 17:29:50,101 [INFO    ] __main__: train step 18901: loss: 0.9279, policy_loss: 0.8386, value_loss: 0.4975
2024-07-11 17:29:50,352 [INFO    ] __main__: train step 18902: loss: 0.9278, policy_loss: 0.8386, value_loss: 0.4975
2024-07-11 17:29:50,564 [INFO    ] __main__: train step 18903: loss: 0.9278, policy_loss: 0.8386, value_loss: 0.4975
2024-07-11 17:29:53,768 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:29:54,235 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:29:54,302 [INFO    ] __main__: train step 18904: loss: 0.9278, policy_loss: 0.8385, value_loss: 0.4975
2024-07-11 17:29:54,497 [INFO    ] __main__: train step 18905: loss: 0.9278, policy_loss: 0.8385, value_loss: 0.4974
2024-07-11 17:29:54,732 [INFO    ] __main__: train step 18906: loss: 0.9278, policy_loss: 0.8385, value_loss: 0.4974
2024-07-11 17:29:54,925 [INFO    ] __main__: train step 18907: loss: 0.9278, policy_loss: 0.8385, value_loss: 0.4974
2024-07-11 17:29:55,125 [INFO    ] __main__: train step 18908: loss: 0.9277, policy_loss: 0.8385, value_loss: 0.4974
2024-07-11 17:29:55,332 [INFO    ] __main__: train step 18909: loss: 0.9277, policy_loss: 0.8385, value_loss: 0.4974
2024-07-11 17:29:55,553 [INFO    ] __main__: train step 18910: loss: 0.9277, policy_loss: 0.8385, value_loss: 0.4973
2024-07-11 17:29:55,778 [INFO    ] __main__: train step 18911: loss: 0.9277, policy_loss: 0.8384, value_loss: 0.4973
2024-07-11 17:29:56,012 [INFO    ] __main__: train step 18912: loss: 0.9277, policy_loss: 0.8384, value_loss: 0.4973
2024-07-11 17:29:56,224 [INFO    ] __main__: train step 18913: loss: 0.9277, policy_loss: 0.8384, value_loss: 0.4973
2024-07-11 17:29:56,427 [INFO    ] __main__: train step 18914: loss: 0.9277, policy_loss: 0.8384, value_loss: 0.4973
2024-07-11 17:29:56,632 [INFO    ] __main__: train step 18915: loss: 0.9276, policy_loss: 0.8384, value_loss: 0.4972
2024-07-11 17:29:56,845 [INFO    ] __main__: train step 18916: loss: 0.9276, policy_loss: 0.8384, value_loss: 0.4972
2024-07-11 17:29:57,062 [INFO    ] __main__: train step 18917: loss: 0.9276, policy_loss: 0.8383, value_loss: 0.4972
2024-07-11 17:29:57,266 [INFO    ] __main__: train step 18918: loss: 0.9276, policy_loss: 0.8383, value_loss: 0.4972
2024-07-11 17:29:57,478 [INFO    ] __main__: train step 18919: loss: 0.9276, policy_loss: 0.8383, value_loss: 0.4972
2024-07-11 17:29:57,679 [INFO    ] __main__: train step 18920: loss: 0.9276, policy_loss: 0.8383, value_loss: 0.4971
2024-07-11 17:29:59,131 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:29:59,559 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:29:59,620 [INFO    ] __main__: train step 18921: loss: 0.9276, policy_loss: 0.8383, value_loss: 0.4971
2024-07-11 17:29:59,810 [INFO    ] __main__: train step 18922: loss: 0.9275, policy_loss: 0.8383, value_loss: 0.4971
2024-07-11 17:30:00,044 [INFO    ] __main__: train step 18923: loss: 0.9275, policy_loss: 0.8382, value_loss: 0.4971
2024-07-11 17:30:00,246 [INFO    ] __main__: train step 18924: loss: 0.9275, policy_loss: 0.8382, value_loss: 0.4970
2024-07-11 17:30:00,456 [INFO    ] __main__: train step 18925: loss: 0.9275, policy_loss: 0.8382, value_loss: 0.4970
2024-07-11 17:30:00,684 [INFO    ] __main__: train step 18926: loss: 0.9275, policy_loss: 0.8382, value_loss: 0.4970
2024-07-11 17:30:00,887 [INFO    ] __main__: train step 18927: loss: 0.9275, policy_loss: 0.8382, value_loss: 0.4970
2024-07-11 17:30:01,086 [INFO    ] __main__: train step 18928: loss: 0.9275, policy_loss: 0.8382, value_loss: 0.4970
2024-07-11 17:30:01,299 [INFO    ] __main__: train step 18929: loss: 0.9274, policy_loss: 0.8382, value_loss: 0.4969
2024-07-11 17:30:01,497 [INFO    ] __main__: train step 18930: loss: 0.9274, policy_loss: 0.8381, value_loss: 0.4969
2024-07-11 17:30:01,710 [INFO    ] __main__: train step 18931: loss: 0.9274, policy_loss: 0.8381, value_loss: 0.4969
2024-07-11 17:30:01,905 [INFO    ] __main__: train step 18932: loss: 0.9274, policy_loss: 0.8381, value_loss: 0.4969
2024-07-11 17:30:02,099 [INFO    ] __main__: train step 18933: loss: 0.9274, policy_loss: 0.8381, value_loss: 0.4969
2024-07-11 17:30:02,314 [INFO    ] __main__: train step 18934: loss: 0.9274, policy_loss: 0.8381, value_loss: 0.4968
2024-07-11 17:30:02,512 [INFO    ] __main__: train step 18935: loss: 0.9273, policy_loss: 0.8381, value_loss: 0.4968
2024-07-11 17:30:02,728 [INFO    ] __main__: train step 18936: loss: 0.9273, policy_loss: 0.8380, value_loss: 0.4968
2024-07-11 17:30:02,958 [INFO    ] __main__: train step 18937: loss: 0.9273, policy_loss: 0.8380, value_loss: 0.4968
2024-07-11 17:30:04,429 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:30:04,865 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:30:04,928 [INFO    ] __main__: train step 18938: loss: 0.9273, policy_loss: 0.8380, value_loss: 0.4968
2024-07-11 17:30:05,102 [INFO    ] __main__: train step 18939: loss: 0.9273, policy_loss: 0.8380, value_loss: 0.4967
2024-07-11 17:30:05,301 [INFO    ] __main__: train step 18940: loss: 0.9273, policy_loss: 0.8380, value_loss: 0.4967
2024-07-11 17:30:05,513 [INFO    ] __main__: train step 18941: loss: 0.9273, policy_loss: 0.8380, value_loss: 0.4967
2024-07-11 17:30:05,735 [INFO    ] __main__: train step 18942: loss: 0.9272, policy_loss: 0.8380, value_loss: 0.4967
2024-07-11 17:30:05,959 [INFO    ] __main__: train step 18943: loss: 0.9272, policy_loss: 0.8379, value_loss: 0.4967
2024-07-11 17:30:06,168 [INFO    ] __main__: train step 18944: loss: 0.9272, policy_loss: 0.8379, value_loss: 0.4966
2024-07-11 17:30:06,377 [INFO    ] __main__: train step 18945: loss: 0.9272, policy_loss: 0.8379, value_loss: 0.4966
2024-07-11 17:30:06,580 [INFO    ] __main__: train step 18946: loss: 0.9272, policy_loss: 0.8379, value_loss: 0.4966
2024-07-11 17:30:06,781 [INFO    ] __main__: train step 18947: loss: 0.9272, policy_loss: 0.8379, value_loss: 0.4966
2024-07-11 17:30:06,985 [INFO    ] __main__: train step 18948: loss: 0.9272, policy_loss: 0.8379, value_loss: 0.4966
2024-07-11 17:30:07,191 [INFO    ] __main__: train step 18949: loss: 0.9271, policy_loss: 0.8378, value_loss: 0.4965
2024-07-11 17:30:07,385 [INFO    ] __main__: train step 18950: loss: 0.9271, policy_loss: 0.8378, value_loss: 0.4965
2024-07-11 17:30:07,593 [INFO    ] __main__: train step 18951: loss: 0.9271, policy_loss: 0.8378, value_loss: 0.4965
2024-07-11 17:30:07,783 [INFO    ] __main__: train step 18952: loss: 0.9271, policy_loss: 0.8378, value_loss: 0.4965
2024-07-11 17:30:07,984 [INFO    ] __main__: train step 18953: loss: 0.9271, policy_loss: 0.8378, value_loss: 0.4964
2024-07-11 17:30:08,174 [INFO    ] __main__: train step 18954: loss: 0.9271, policy_loss: 0.8378, value_loss: 0.4964
2024-07-11 17:30:09,610 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:30:10,025 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:30:10,084 [INFO    ] __main__: train step 18955: loss: 0.9271, policy_loss: 0.8378, value_loss: 0.4964
2024-07-11 17:30:10,262 [INFO    ] __main__: train step 18956: loss: 0.9270, policy_loss: 0.8377, value_loss: 0.4964
2024-07-11 17:30:10,463 [INFO    ] __main__: train step 18957: loss: 0.9270, policy_loss: 0.8377, value_loss: 0.4964
2024-07-11 17:30:10,661 [INFO    ] __main__: train step 18958: loss: 0.9270, policy_loss: 0.8377, value_loss: 0.4963
2024-07-11 17:30:10,856 [INFO    ] __main__: train step 18959: loss: 0.9270, policy_loss: 0.8377, value_loss: 0.4963
2024-07-11 17:30:11,054 [INFO    ] __main__: train step 18960: loss: 0.9270, policy_loss: 0.8377, value_loss: 0.4963
2024-07-11 17:30:11,260 [INFO    ] __main__: train step 18961: loss: 0.9270, policy_loss: 0.8377, value_loss: 0.4963
2024-07-11 17:30:11,472 [INFO    ] __main__: train step 18962: loss: 0.9270, policy_loss: 0.8376, value_loss: 0.4963
2024-07-11 17:30:11,706 [INFO    ] __main__: train step 18963: loss: 0.9269, policy_loss: 0.8376, value_loss: 0.4962
2024-07-11 17:30:11,940 [INFO    ] __main__: train step 18964: loss: 0.9269, policy_loss: 0.8376, value_loss: 0.4962
2024-07-11 17:30:12,167 [INFO    ] __main__: train step 18965: loss: 0.9269, policy_loss: 0.8376, value_loss: 0.4962
2024-07-11 17:30:12,372 [INFO    ] __main__: train step 18966: loss: 0.9269, policy_loss: 0.8376, value_loss: 0.4962
2024-07-11 17:30:12,584 [INFO    ] __main__: train step 18967: loss: 0.9269, policy_loss: 0.8376, value_loss: 0.4962
2024-07-11 17:30:12,829 [INFO    ] __main__: train step 18968: loss: 0.9269, policy_loss: 0.8376, value_loss: 0.4961
2024-07-11 17:30:13,060 [INFO    ] __main__: train step 18969: loss: 0.9269, policy_loss: 0.8375, value_loss: 0.4961
2024-07-11 17:30:13,294 [INFO    ] __main__: train step 18970: loss: 0.9268, policy_loss: 0.8375, value_loss: 0.4961
2024-07-11 17:30:13,502 [INFO    ] __main__: train step 18971: loss: 0.9268, policy_loss: 0.8375, value_loss: 0.4961
2024-07-11 17:30:14,948 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:30:15,388 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:30:15,451 [INFO    ] __main__: train step 18972: loss: 0.9268, policy_loss: 0.8375, value_loss: 0.4961
2024-07-11 17:30:15,623 [INFO    ] __main__: train step 18973: loss: 0.9268, policy_loss: 0.8375, value_loss: 0.4960
2024-07-11 17:30:15,855 [INFO    ] __main__: train step 18974: loss: 0.9268, policy_loss: 0.8375, value_loss: 0.4960
2024-07-11 17:30:16,095 [INFO    ] __main__: train step 18975: loss: 0.9268, policy_loss: 0.8375, value_loss: 0.4960
2024-07-11 17:30:16,297 [INFO    ] __main__: train step 18976: loss: 0.9268, policy_loss: 0.8374, value_loss: 0.4960
2024-07-11 17:30:16,498 [INFO    ] __main__: train step 18977: loss: 0.9267, policy_loss: 0.8374, value_loss: 0.4960
2024-07-11 17:30:16,706 [INFO    ] __main__: train step 18978: loss: 0.9267, policy_loss: 0.8374, value_loss: 0.4959
2024-07-11 17:30:16,914 [INFO    ] __main__: train step 18979: loss: 0.9267, policy_loss: 0.8374, value_loss: 0.4959
2024-07-11 17:30:17,126 [INFO    ] __main__: train step 18980: loss: 0.9267, policy_loss: 0.8374, value_loss: 0.4959
2024-07-11 17:30:17,327 [INFO    ] __main__: train step 18981: loss: 0.9267, policy_loss: 0.8374, value_loss: 0.4959
2024-07-11 17:30:17,538 [INFO    ] __main__: train step 18982: loss: 0.9267, policy_loss: 0.8373, value_loss: 0.4959
2024-07-11 17:30:17,740 [INFO    ] __main__: train step 18983: loss: 0.9267, policy_loss: 0.8373, value_loss: 0.4958
2024-07-11 17:30:17,969 [INFO    ] __main__: train step 18984: loss: 0.9266, policy_loss: 0.8373, value_loss: 0.4958
2024-07-11 17:30:18,197 [INFO    ] __main__: train step 18985: loss: 0.9266, policy_loss: 0.8373, value_loss: 0.4958
2024-07-11 17:30:18,405 [INFO    ] __main__: train step 18986: loss: 0.9266, policy_loss: 0.8373, value_loss: 0.4958
2024-07-11 17:30:18,610 [INFO    ] __main__: train step 18987: loss: 0.9266, policy_loss: 0.8373, value_loss: 0.4957
2024-07-11 17:30:18,812 [INFO    ] __main__: train step 18988: loss: 0.9266, policy_loss: 0.8373, value_loss: 0.4957
2024-07-11 17:30:20,252 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:30:20,665 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:30:20,722 [INFO    ] __main__: train step 18989: loss: 0.9266, policy_loss: 0.8372, value_loss: 0.4957
2024-07-11 17:30:20,920 [INFO    ] __main__: train step 18990: loss: 0.9266, policy_loss: 0.8372, value_loss: 0.4957
2024-07-11 17:30:21,137 [INFO    ] __main__: train step 18991: loss: 0.9265, policy_loss: 0.8372, value_loss: 0.4957
2024-07-11 17:30:21,343 [INFO    ] __main__: train step 18992: loss: 0.9265, policy_loss: 0.8372, value_loss: 0.4956
2024-07-11 17:30:21,546 [INFO    ] __main__: train step 18993: loss: 0.9265, policy_loss: 0.8372, value_loss: 0.4956
2024-07-11 17:30:21,753 [INFO    ] __main__: train step 18994: loss: 0.9265, policy_loss: 0.8372, value_loss: 0.4956
2024-07-11 17:30:21,957 [INFO    ] __main__: train step 18995: loss: 0.9265, policy_loss: 0.8372, value_loss: 0.4956
2024-07-11 17:30:22,154 [INFO    ] __main__: train step 18996: loss: 0.9265, policy_loss: 0.8371, value_loss: 0.4956
2024-07-11 17:30:22,359 [INFO    ] __main__: train step 18997: loss: 0.9265, policy_loss: 0.8371, value_loss: 0.4955
2024-07-11 17:30:22,560 [INFO    ] __main__: train step 18998: loss: 0.9264, policy_loss: 0.8371, value_loss: 0.4955
2024-07-11 17:30:22,765 [INFO    ] __main__: train step 18999: loss: 0.9264, policy_loss: 0.8371, value_loss: 0.4955
2024-07-11 17:30:23,010 [INFO    ] __main__: train step 19000: loss: 0.9264, policy_loss: 0.8371, value_loss: 0.4955
2024-07-11 17:30:23,118 [INFO    ] __main__: restored step 18000 for evaluation
2024-07-11 17:30:30,594 [INFO    ] __main__: later network ELO difference from earlier network: +82 (+8/-8) ELO from 32000 self-played games
2024-07-11 17:30:30,594 [INFO    ] __main__: game outcomes: W: 18794, D: 588, L: 12618
2024-07-11 17:30:30,597 [INFO    ] __main__: validation_elo_delta: 82, validation_elo: 2696
2024-07-11 17:30:31,100 [INFO    ] __main__: train step 19001: loss: 0.9264, policy_loss: 0.8371, value_loss: 0.4955
2024-07-11 17:30:31,295 [INFO    ] __main__: train step 19002: loss: 0.9264, policy_loss: 0.8371, value_loss: 0.4954
2024-07-11 17:30:31,505 [INFO    ] __main__: train step 19003: loss: 0.9264, policy_loss: 0.8370, value_loss: 0.4954
2024-07-11 17:30:31,699 [INFO    ] __main__: train step 19004: loss: 0.9264, policy_loss: 0.8370, value_loss: 0.4954
2024-07-11 17:30:31,908 [INFO    ] __main__: train step 19005: loss: 0.9264, policy_loss: 0.8370, value_loss: 0.4954
2024-07-11 17:30:33,377 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:30:33,767 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:30:33,822 [INFO    ] __main__: train step 19006: loss: 0.9263, policy_loss: 0.8370, value_loss: 0.4954
2024-07-11 17:30:33,998 [INFO    ] __main__: train step 19007: loss: 0.9263, policy_loss: 0.8370, value_loss: 0.4953
2024-07-11 17:30:34,205 [INFO    ] __main__: train step 19008: loss: 0.9263, policy_loss: 0.8370, value_loss: 0.4953
2024-07-11 17:30:34,408 [INFO    ] __main__: train step 19009: loss: 0.9263, policy_loss: 0.8369, value_loss: 0.4953
2024-07-11 17:30:34,604 [INFO    ] __main__: train step 19010: loss: 0.9263, policy_loss: 0.8369, value_loss: 0.4953
2024-07-11 17:30:34,813 [INFO    ] __main__: train step 19011: loss: 0.9263, policy_loss: 0.8369, value_loss: 0.4953
2024-07-11 17:30:35,022 [INFO    ] __main__: train step 19012: loss: 0.9263, policy_loss: 0.8369, value_loss: 0.4952
2024-07-11 17:30:35,219 [INFO    ] __main__: train step 19013: loss: 0.9262, policy_loss: 0.8369, value_loss: 0.4952
2024-07-11 17:30:35,430 [INFO    ] __main__: train step 19014: loss: 0.9262, policy_loss: 0.8369, value_loss: 0.4952
2024-07-11 17:30:35,647 [INFO    ] __main__: train step 19015: loss: 0.9262, policy_loss: 0.8369, value_loss: 0.4952
2024-07-11 17:30:35,887 [INFO    ] __main__: train step 19016: loss: 0.9262, policy_loss: 0.8368, value_loss: 0.4952
2024-07-11 17:30:36,122 [INFO    ] __main__: train step 19017: loss: 0.9262, policy_loss: 0.8368, value_loss: 0.4951
2024-07-11 17:30:38,010 [INFO    ] __main__: train step 19018: loss: 0.9262, policy_loss: 0.8368, value_loss: 0.4951
2024-07-11 17:30:38,233 [INFO    ] __main__: train step 19019: loss: 0.9262, policy_loss: 0.8368, value_loss: 0.4951
2024-07-11 17:30:38,430 [INFO    ] __main__: train step 19020: loss: 0.9262, policy_loss: 0.8368, value_loss: 0.4951
2024-07-11 17:30:38,655 [INFO    ] __main__: train step 19021: loss: 0.9261, policy_loss: 0.8368, value_loss: 0.4951
2024-07-11 17:30:38,877 [INFO    ] __main__: train step 19022: loss: 0.9261, policy_loss: 0.8368, value_loss: 0.4950
2024-07-11 17:30:40,321 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:30:40,734 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:30:40,789 [INFO    ] __main__: train step 19023: loss: 0.9261, policy_loss: 0.8367, value_loss: 0.4950
2024-07-11 17:30:40,959 [INFO    ] __main__: train step 19024: loss: 0.9261, policy_loss: 0.8367, value_loss: 0.4950
2024-07-11 17:30:41,167 [INFO    ] __main__: train step 19025: loss: 0.9261, policy_loss: 0.8367, value_loss: 0.4950
2024-07-11 17:30:41,369 [INFO    ] __main__: train step 19026: loss: 0.9261, policy_loss: 0.8367, value_loss: 0.4950
2024-07-11 17:30:41,587 [INFO    ] __main__: train step 19027: loss: 0.9261, policy_loss: 0.8367, value_loss: 0.4949
2024-07-11 17:30:41,792 [INFO    ] __main__: train step 19028: loss: 0.9260, policy_loss: 0.8367, value_loss: 0.4949
2024-07-11 17:30:42,043 [INFO    ] __main__: train step 19029: loss: 0.9260, policy_loss: 0.8367, value_loss: 0.4949
2024-07-11 17:30:42,252 [INFO    ] __main__: train step 19030: loss: 0.9260, policy_loss: 0.8366, value_loss: 0.4949
2024-07-11 17:30:42,455 [INFO    ] __main__: train step 19031: loss: 0.9260, policy_loss: 0.8366, value_loss: 0.4949
2024-07-11 17:30:42,663 [INFO    ] __main__: train step 19032: loss: 0.9260, policy_loss: 0.8366, value_loss: 0.4948
2024-07-11 17:30:42,870 [INFO    ] __main__: train step 19033: loss: 0.9260, policy_loss: 0.8366, value_loss: 0.4948
2024-07-11 17:30:43,075 [INFO    ] __main__: train step 19034: loss: 0.9260, policy_loss: 0.8366, value_loss: 0.4948
2024-07-11 17:30:43,289 [INFO    ] __main__: train step 19035: loss: 0.9260, policy_loss: 0.8366, value_loss: 0.4948
2024-07-11 17:30:43,497 [INFO    ] __main__: train step 19036: loss: 0.9259, policy_loss: 0.8366, value_loss: 0.4948
2024-07-11 17:30:43,698 [INFO    ] __main__: train step 19037: loss: 0.9259, policy_loss: 0.8365, value_loss: 0.4947
2024-07-11 17:30:43,900 [INFO    ] __main__: train step 19038: loss: 0.9259, policy_loss: 0.8365, value_loss: 0.4947
2024-07-11 17:30:44,098 [INFO    ] __main__: train step 19039: loss: 0.9259, policy_loss: 0.8365, value_loss: 0.4947
2024-07-11 17:30:45,555 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:30:45,988 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:30:46,049 [INFO    ] __main__: train step 19040: loss: 0.9259, policy_loss: 0.8365, value_loss: 0.4947
2024-07-11 17:30:46,223 [INFO    ] __main__: train step 19041: loss: 0.9259, policy_loss: 0.8365, value_loss: 0.4947
2024-07-11 17:30:46,420 [INFO    ] __main__: train step 19042: loss: 0.9259, policy_loss: 0.8365, value_loss: 0.4946
2024-07-11 17:30:46,625 [INFO    ] __main__: train step 19043: loss: 0.9258, policy_loss: 0.8365, value_loss: 0.4946
2024-07-11 17:30:46,828 [INFO    ] __main__: train step 19044: loss: 0.9258, policy_loss: 0.8364, value_loss: 0.4946
2024-07-11 17:30:47,039 [INFO    ] __main__: train step 19045: loss: 0.9258, policy_loss: 0.8364, value_loss: 0.4946
2024-07-11 17:30:47,238 [INFO    ] __main__: train step 19046: loss: 0.9258, policy_loss: 0.8364, value_loss: 0.4946
2024-07-11 17:30:47,449 [INFO    ] __main__: train step 19047: loss: 0.9258, policy_loss: 0.8364, value_loss: 0.4945
2024-07-11 17:30:47,648 [INFO    ] __main__: train step 19048: loss: 0.9258, policy_loss: 0.8364, value_loss: 0.4945
2024-07-11 17:30:47,854 [INFO    ] __main__: train step 19049: loss: 0.9258, policy_loss: 0.8364, value_loss: 0.4945
2024-07-11 17:30:48,053 [INFO    ] __main__: train step 19050: loss: 0.9258, policy_loss: 0.8364, value_loss: 0.4945
2024-07-11 17:30:48,269 [INFO    ] __main__: train step 19051: loss: 0.9257, policy_loss: 0.8363, value_loss: 0.4945
2024-07-11 17:30:48,506 [INFO    ] __main__: train step 19052: loss: 0.9257, policy_loss: 0.8363, value_loss: 0.4944
2024-07-11 17:30:48,700 [INFO    ] __main__: train step 19053: loss: 0.9257, policy_loss: 0.8363, value_loss: 0.4944
2024-07-11 17:30:48,902 [INFO    ] __main__: train step 19054: loss: 0.9257, policy_loss: 0.8363, value_loss: 0.4944
2024-07-11 17:30:49,141 [INFO    ] __main__: train step 19055: loss: 0.9257, policy_loss: 0.8363, value_loss: 0.4944
2024-07-11 17:30:49,349 [INFO    ] __main__: train step 19056: loss: 0.9257, policy_loss: 0.8363, value_loss: 0.4944
2024-07-11 17:30:50,790 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:30:51,214 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:30:51,271 [INFO    ] __main__: train step 19057: loss: 0.9257, policy_loss: 0.8363, value_loss: 0.4943
2024-07-11 17:30:51,465 [INFO    ] __main__: train step 19058: loss: 0.9256, policy_loss: 0.8362, value_loss: 0.4943
2024-07-11 17:30:51,699 [INFO    ] __main__: train step 19059: loss: 0.9256, policy_loss: 0.8362, value_loss: 0.4943
2024-07-11 17:30:51,903 [INFO    ] __main__: train step 19060: loss: 0.9256, policy_loss: 0.8362, value_loss: 0.4943
2024-07-11 17:30:52,109 [INFO    ] __main__: train step 19061: loss: 0.9256, policy_loss: 0.8362, value_loss: 0.4943
2024-07-11 17:30:52,317 [INFO    ] __main__: train step 19062: loss: 0.9256, policy_loss: 0.8362, value_loss: 0.4942
2024-07-11 17:30:52,511 [INFO    ] __main__: train step 19063: loss: 0.9256, policy_loss: 0.8362, value_loss: 0.4942
2024-07-11 17:30:52,712 [INFO    ] __main__: train step 19064: loss: 0.9256, policy_loss: 0.8362, value_loss: 0.4942
2024-07-11 17:30:52,919 [INFO    ] __main__: train step 19065: loss: 0.9256, policy_loss: 0.8361, value_loss: 0.4942
2024-07-11 17:30:53,126 [INFO    ] __main__: train step 19066: loss: 0.9255, policy_loss: 0.8361, value_loss: 0.4942
2024-07-11 17:30:53,362 [INFO    ] __main__: train step 19067: loss: 0.9255, policy_loss: 0.8361, value_loss: 0.4941
2024-07-11 17:30:53,597 [INFO    ] __main__: train step 19068: loss: 0.9255, policy_loss: 0.8361, value_loss: 0.4941
2024-07-11 17:30:53,804 [INFO    ] __main__: train step 19069: loss: 0.9255, policy_loss: 0.8361, value_loss: 0.4941
2024-07-11 17:30:54,024 [INFO    ] __main__: train step 19070: loss: 0.9255, policy_loss: 0.8361, value_loss: 0.4941
2024-07-11 17:30:54,258 [INFO    ] __main__: train step 19071: loss: 0.9255, policy_loss: 0.8361, value_loss: 0.4940
2024-07-11 17:30:54,467 [INFO    ] __main__: train step 19072: loss: 0.9255, policy_loss: 0.8360, value_loss: 0.4940
2024-07-11 17:30:54,679 [INFO    ] __main__: train step 19073: loss: 0.9255, policy_loss: 0.8360, value_loss: 0.4940
2024-07-11 17:30:56,132 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:30:56,570 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:30:56,636 [INFO    ] __main__: train step 19074: loss: 0.9254, policy_loss: 0.8360, value_loss: 0.4940
2024-07-11 17:30:56,827 [INFO    ] __main__: train step 19075: loss: 0.9254, policy_loss: 0.8360, value_loss: 0.4940
2024-07-11 17:30:57,062 [INFO    ] __main__: train step 19076: loss: 0.9254, policy_loss: 0.8360, value_loss: 0.4939
2024-07-11 17:30:57,261 [INFO    ] __main__: train step 19077: loss: 0.9254, policy_loss: 0.8360, value_loss: 0.4939
2024-07-11 17:30:57,493 [INFO    ] __main__: train step 19078: loss: 0.9254, policy_loss: 0.8360, value_loss: 0.4939
2024-07-11 17:30:57,690 [INFO    ] __main__: train step 19079: loss: 0.9254, policy_loss: 0.8359, value_loss: 0.4939
2024-07-11 17:30:57,894 [INFO    ] __main__: train step 19080: loss: 0.9254, policy_loss: 0.8359, value_loss: 0.4939
2024-07-11 17:30:58,097 [INFO    ] __main__: train step 19081: loss: 0.9253, policy_loss: 0.8359, value_loss: 0.4938
2024-07-11 17:30:58,301 [INFO    ] __main__: train step 19082: loss: 0.9253, policy_loss: 0.8359, value_loss: 0.4938
2024-07-11 17:30:58,501 [INFO    ] __main__: train step 19083: loss: 0.9253, policy_loss: 0.8359, value_loss: 0.4938
2024-07-11 17:30:58,712 [INFO    ] __main__: train step 19084: loss: 0.9253, policy_loss: 0.8359, value_loss: 0.4938
2024-07-11 17:30:58,916 [INFO    ] __main__: train step 19085: loss: 0.9253, policy_loss: 0.8359, value_loss: 0.4938
2024-07-11 17:30:59,117 [INFO    ] __main__: train step 19086: loss: 0.9253, policy_loss: 0.8358, value_loss: 0.4938
2024-07-11 17:30:59,322 [INFO    ] __main__: train step 19087: loss: 0.9253, policy_loss: 0.8358, value_loss: 0.4937
2024-07-11 17:30:59,527 [INFO    ] __main__: train step 19088: loss: 0.9253, policy_loss: 0.8358, value_loss: 0.4937
2024-07-11 17:30:59,747 [INFO    ] __main__: train step 19089: loss: 0.9253, policy_loss: 0.8358, value_loss: 0.4937
2024-07-11 17:30:59,978 [INFO    ] __main__: train step 19090: loss: 0.9252, policy_loss: 0.8358, value_loss: 0.4937
2024-07-11 17:31:01,418 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:31:01,835 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:31:01,892 [INFO    ] __main__: train step 19091: loss: 0.9252, policy_loss: 0.8358, value_loss: 0.4937
2024-07-11 17:31:02,075 [INFO    ] __main__: train step 19092: loss: 0.9252, policy_loss: 0.8358, value_loss: 0.4936
2024-07-11 17:31:02,283 [INFO    ] __main__: train step 19093: loss: 0.9252, policy_loss: 0.8358, value_loss: 0.4936
2024-07-11 17:31:02,491 [INFO    ] __main__: train step 19094: loss: 0.9252, policy_loss: 0.8357, value_loss: 0.4936
2024-07-11 17:31:02,701 [INFO    ] __main__: train step 19095: loss: 0.9252, policy_loss: 0.8357, value_loss: 0.4936
2024-07-11 17:31:02,926 [INFO    ] __main__: train step 19096: loss: 0.9252, policy_loss: 0.8357, value_loss: 0.4935
2024-07-11 17:31:03,132 [INFO    ] __main__: train step 19097: loss: 0.9252, policy_loss: 0.8357, value_loss: 0.4935
2024-07-11 17:31:03,362 [INFO    ] __main__: train step 19098: loss: 0.9251, policy_loss: 0.8357, value_loss: 0.4935
2024-07-11 17:31:03,576 [INFO    ] __main__: train step 19099: loss: 0.9251, policy_loss: 0.8357, value_loss: 0.4935
2024-07-11 17:31:03,769 [INFO    ] __main__: train step 19100: loss: 0.9251, policy_loss: 0.8357, value_loss: 0.4935
2024-07-11 17:31:03,968 [INFO    ] __main__: train step 19101: loss: 0.9251, policy_loss: 0.8356, value_loss: 0.4934
2024-07-11 17:31:04,183 [INFO    ] __main__: train step 19102: loss: 0.9251, policy_loss: 0.8356, value_loss: 0.4934
2024-07-11 17:31:04,497 [INFO    ] __main__: train step 19103: loss: 0.9251, policy_loss: 0.8356, value_loss: 0.4934
2024-07-11 17:31:04,726 [INFO    ] __main__: train step 19104: loss: 0.9251, policy_loss: 0.8356, value_loss: 0.4934
2024-07-11 17:31:04,925 [INFO    ] __main__: train step 19105: loss: 0.9251, policy_loss: 0.8356, value_loss: 0.4934
2024-07-11 17:31:05,157 [INFO    ] __main__: train step 19106: loss: 0.9250, policy_loss: 0.8356, value_loss: 0.4933
2024-07-11 17:31:05,370 [INFO    ] __main__: train step 19107: loss: 0.9250, policy_loss: 0.8356, value_loss: 0.4933
2024-07-11 17:31:06,809 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:31:07,243 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:31:07,297 [INFO    ] __main__: train step 19108: loss: 0.9250, policy_loss: 0.8356, value_loss: 0.4933
2024-07-11 17:31:07,473 [INFO    ] __main__: train step 19109: loss: 0.9250, policy_loss: 0.8355, value_loss: 0.4933
2024-07-11 17:31:07,671 [INFO    ] __main__: train step 19110: loss: 0.9250, policy_loss: 0.8355, value_loss: 0.4933
2024-07-11 17:31:07,880 [INFO    ] __main__: train step 19111: loss: 0.9250, policy_loss: 0.8355, value_loss: 0.4933
2024-07-11 17:31:08,071 [INFO    ] __main__: train step 19112: loss: 0.9250, policy_loss: 0.8355, value_loss: 0.4932
2024-07-11 17:31:08,285 [INFO    ] __main__: train step 19113: loss: 0.9250, policy_loss: 0.8355, value_loss: 0.4932
2024-07-11 17:31:08,481 [INFO    ] __main__: train step 19114: loss: 0.9249, policy_loss: 0.8355, value_loss: 0.4932
2024-07-11 17:31:08,696 [INFO    ] __main__: train step 19115: loss: 0.9249, policy_loss: 0.8355, value_loss: 0.4932
2024-07-11 17:31:08,933 [INFO    ] __main__: train step 19116: loss: 0.9249, policy_loss: 0.8354, value_loss: 0.4932
2024-07-11 17:31:09,147 [INFO    ] __main__: train step 19117: loss: 0.9249, policy_loss: 0.8354, value_loss: 0.4931
2024-07-11 17:31:09,345 [INFO    ] __main__: train step 19118: loss: 0.9249, policy_loss: 0.8354, value_loss: 0.4931
2024-07-11 17:31:09,555 [INFO    ] __main__: train step 19119: loss: 0.9249, policy_loss: 0.8354, value_loss: 0.4931
2024-07-11 17:31:09,757 [INFO    ] __main__: train step 19120: loss: 0.9249, policy_loss: 0.8354, value_loss: 0.4931
2024-07-11 17:31:09,955 [INFO    ] __main__: train step 19121: loss: 0.9249, policy_loss: 0.8354, value_loss: 0.4931
2024-07-11 17:31:10,156 [INFO    ] __main__: train step 19122: loss: 0.9248, policy_loss: 0.8354, value_loss: 0.4930
2024-07-11 17:31:10,362 [INFO    ] __main__: train step 19123: loss: 0.9248, policy_loss: 0.8353, value_loss: 0.4930
2024-07-11 17:31:10,562 [INFO    ] __main__: train step 19124: loss: 0.9248, policy_loss: 0.8353, value_loss: 0.4930
2024-07-11 17:31:11,998 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:31:12,427 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:31:12,485 [INFO    ] __main__: train step 19125: loss: 0.9248, policy_loss: 0.8353, value_loss: 0.4930
2024-07-11 17:31:12,662 [INFO    ] __main__: train step 19126: loss: 0.9248, policy_loss: 0.8353, value_loss: 0.4930
2024-07-11 17:31:12,867 [INFO    ] __main__: train step 19127: loss: 0.9248, policy_loss: 0.8353, value_loss: 0.4929
2024-07-11 17:31:13,070 [INFO    ] __main__: train step 19128: loss: 0.9248, policy_loss: 0.8353, value_loss: 0.4929
2024-07-11 17:31:13,281 [INFO    ] __main__: train step 19129: loss: 0.9248, policy_loss: 0.8353, value_loss: 0.4929
2024-07-11 17:31:13,514 [INFO    ] __main__: train step 19130: loss: 0.9247, policy_loss: 0.8353, value_loss: 0.4929
2024-07-11 17:31:13,725 [INFO    ] __main__: train step 19131: loss: 0.9247, policy_loss: 0.8352, value_loss: 0.4929
2024-07-11 17:31:15,671 [INFO    ] __main__: train step 19132: loss: 0.9247, policy_loss: 0.8352, value_loss: 0.4928
2024-07-11 17:31:15,882 [INFO    ] __main__: train step 19133: loss: 0.9247, policy_loss: 0.8352, value_loss: 0.4928
2024-07-11 17:31:16,098 [INFO    ] __main__: train step 19134: loss: 0.9247, policy_loss: 0.8352, value_loss: 0.4928
2024-07-11 17:31:16,341 [INFO    ] __main__: train step 19135: loss: 0.9247, policy_loss: 0.8352, value_loss: 0.4928
2024-07-11 17:31:16,550 [INFO    ] __main__: train step 19136: loss: 0.9247, policy_loss: 0.8352, value_loss: 0.4928
2024-07-11 17:31:16,761 [INFO    ] __main__: train step 19137: loss: 0.9247, policy_loss: 0.8352, value_loss: 0.4927
2024-07-11 17:31:16,963 [INFO    ] __main__: train step 19138: loss: 0.9246, policy_loss: 0.8351, value_loss: 0.4927
2024-07-11 17:31:17,160 [INFO    ] __main__: train step 19139: loss: 0.9246, policy_loss: 0.8351, value_loss: 0.4927
2024-07-11 17:31:17,376 [INFO    ] __main__: train step 19140: loss: 0.9246, policy_loss: 0.8351, value_loss: 0.4927
2024-07-11 17:31:17,583 [INFO    ] __main__: train step 19141: loss: 0.9246, policy_loss: 0.8351, value_loss: 0.4927
2024-07-11 17:31:19,057 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:31:19,482 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:31:19,539 [INFO    ] __main__: train step 19142: loss: 0.9246, policy_loss: 0.8351, value_loss: 0.4926
2024-07-11 17:31:19,714 [INFO    ] __main__: train step 19143: loss: 0.9246, policy_loss: 0.8351, value_loss: 0.4926
2024-07-11 17:31:19,921 [INFO    ] __main__: train step 19144: loss: 0.9246, policy_loss: 0.8351, value_loss: 0.4926
2024-07-11 17:31:20,125 [INFO    ] __main__: train step 19145: loss: 0.9246, policy_loss: 0.8351, value_loss: 0.4926
2024-07-11 17:31:20,325 [INFO    ] __main__: train step 19146: loss: 0.9245, policy_loss: 0.8350, value_loss: 0.4926
2024-07-11 17:31:20,533 [INFO    ] __main__: train step 19147: loss: 0.9245, policy_loss: 0.8350, value_loss: 0.4925
2024-07-11 17:31:20,734 [INFO    ] __main__: train step 19148: loss: 0.9245, policy_loss: 0.8350, value_loss: 0.4925
2024-07-11 17:31:20,944 [INFO    ] __main__: train step 19149: loss: 0.9245, policy_loss: 0.8350, value_loss: 0.4925
2024-07-11 17:31:21,146 [INFO    ] __main__: train step 19150: loss: 0.9245, policy_loss: 0.8350, value_loss: 0.4925
2024-07-11 17:31:21,349 [INFO    ] __main__: train step 19151: loss: 0.9245, policy_loss: 0.8350, value_loss: 0.4925
2024-07-11 17:31:21,560 [INFO    ] __main__: train step 19152: loss: 0.9245, policy_loss: 0.8350, value_loss: 0.4924
2024-07-11 17:31:21,765 [INFO    ] __main__: train step 19153: loss: 0.9245, policy_loss: 0.8349, value_loss: 0.4924
2024-07-11 17:31:21,971 [INFO    ] __main__: train step 19154: loss: 0.9245, policy_loss: 0.8349, value_loss: 0.4924
2024-07-11 17:31:22,171 [INFO    ] __main__: train step 19155: loss: 0.9244, policy_loss: 0.8349, value_loss: 0.4924
2024-07-11 17:31:22,382 [INFO    ] __main__: train step 19156: loss: 0.9244, policy_loss: 0.8349, value_loss: 0.4924
2024-07-11 17:31:22,585 [INFO    ] __main__: train step 19157: loss: 0.9244, policy_loss: 0.8349, value_loss: 0.4923
2024-07-11 17:31:22,794 [INFO    ] __main__: train step 19158: loss: 0.9244, policy_loss: 0.8349, value_loss: 0.4923
2024-07-11 17:31:24,238 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:31:24,663 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:31:24,718 [INFO    ] __main__: train step 19159: loss: 0.9244, policy_loss: 0.8349, value_loss: 0.4923
2024-07-11 17:31:24,895 [INFO    ] __main__: train step 19160: loss: 0.9244, policy_loss: 0.8349, value_loss: 0.4923
2024-07-11 17:31:25,101 [INFO    ] __main__: train step 19161: loss: 0.9244, policy_loss: 0.8348, value_loss: 0.4923
2024-07-11 17:31:25,306 [INFO    ] __main__: train step 19162: loss: 0.9244, policy_loss: 0.8348, value_loss: 0.4922
2024-07-11 17:31:25,510 [INFO    ] __main__: train step 19163: loss: 0.9243, policy_loss: 0.8348, value_loss: 0.4922
2024-07-11 17:31:25,715 [INFO    ] __main__: train step 19164: loss: 0.9243, policy_loss: 0.8348, value_loss: 0.4922
2024-07-11 17:31:25,920 [INFO    ] __main__: train step 19165: loss: 0.9243, policy_loss: 0.8348, value_loss: 0.4922
2024-07-11 17:31:26,116 [INFO    ] __main__: train step 19166: loss: 0.9243, policy_loss: 0.8348, value_loss: 0.4922
2024-07-11 17:31:26,320 [INFO    ] __main__: train step 19167: loss: 0.9243, policy_loss: 0.8348, value_loss: 0.4921
2024-07-11 17:31:26,534 [INFO    ] __main__: train step 19168: loss: 0.9243, policy_loss: 0.8348, value_loss: 0.4921
2024-07-11 17:31:26,745 [INFO    ] __main__: train step 19169: loss: 0.9243, policy_loss: 0.8347, value_loss: 0.4921
2024-07-11 17:31:26,953 [INFO    ] __main__: train step 19170: loss: 0.9243, policy_loss: 0.8347, value_loss: 0.4921
2024-07-11 17:31:27,153 [INFO    ] __main__: train step 19171: loss: 0.9243, policy_loss: 0.8347, value_loss: 0.4921
2024-07-11 17:31:27,365 [INFO    ] __main__: train step 19172: loss: 0.9242, policy_loss: 0.8347, value_loss: 0.4920
2024-07-11 17:31:27,581 [INFO    ] __main__: train step 19173: loss: 0.9242, policy_loss: 0.8347, value_loss: 0.4920
2024-07-11 17:31:27,807 [INFO    ] __main__: train step 19174: loss: 0.9242, policy_loss: 0.8347, value_loss: 0.4920
2024-07-11 17:31:28,024 [INFO    ] __main__: train step 19175: loss: 0.9242, policy_loss: 0.8347, value_loss: 0.4920
2024-07-11 17:31:29,459 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:31:29,880 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:31:29,943 [INFO    ] __main__: train step 19176: loss: 0.9242, policy_loss: 0.8346, value_loss: 0.4920
2024-07-11 17:31:30,122 [INFO    ] __main__: train step 19177: loss: 0.9242, policy_loss: 0.8346, value_loss: 0.4919
2024-07-11 17:31:30,333 [INFO    ] __main__: train step 19178: loss: 0.9242, policy_loss: 0.8346, value_loss: 0.4919
2024-07-11 17:31:30,530 [INFO    ] __main__: train step 19179: loss: 0.9242, policy_loss: 0.8346, value_loss: 0.4919
2024-07-11 17:31:30,736 [INFO    ] __main__: train step 19180: loss: 0.9241, policy_loss: 0.8346, value_loss: 0.4919
2024-07-11 17:31:30,931 [INFO    ] __main__: train step 19181: loss: 0.9241, policy_loss: 0.8346, value_loss: 0.4919
2024-07-11 17:31:31,128 [INFO    ] __main__: train step 19182: loss: 0.9241, policy_loss: 0.8346, value_loss: 0.4918
2024-07-11 17:31:31,335 [INFO    ] __main__: train step 19183: loss: 0.9241, policy_loss: 0.8346, value_loss: 0.4918
2024-07-11 17:31:31,546 [INFO    ] __main__: train step 19184: loss: 0.9241, policy_loss: 0.8345, value_loss: 0.4918
2024-07-11 17:31:31,787 [INFO    ] __main__: train step 19185: loss: 0.9241, policy_loss: 0.8345, value_loss: 0.4918
2024-07-11 17:31:31,980 [INFO    ] __main__: train step 19186: loss: 0.9241, policy_loss: 0.8345, value_loss: 0.4918
2024-07-11 17:31:32,183 [INFO    ] __main__: train step 19187: loss: 0.9241, policy_loss: 0.8345, value_loss: 0.4917
2024-07-11 17:31:32,384 [INFO    ] __main__: train step 19188: loss: 0.9241, policy_loss: 0.8345, value_loss: 0.4917
2024-07-11 17:31:32,593 [INFO    ] __main__: train step 19189: loss: 0.9240, policy_loss: 0.8345, value_loss: 0.4917
2024-07-11 17:31:32,841 [INFO    ] __main__: train step 19190: loss: 0.9240, policy_loss: 0.8345, value_loss: 0.4917
2024-07-11 17:31:33,030 [INFO    ] __main__: train step 19191: loss: 0.9240, policy_loss: 0.8345, value_loss: 0.4917
2024-07-11 17:31:33,230 [INFO    ] __main__: train step 19192: loss: 0.9240, policy_loss: 0.8344, value_loss: 0.4916
2024-07-11 17:31:34,697 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:31:35,078 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:31:35,137 [INFO    ] __main__: train step 19193: loss: 0.9240, policy_loss: 0.8344, value_loss: 0.4916
2024-07-11 17:31:35,320 [INFO    ] __main__: train step 19194: loss: 0.9240, policy_loss: 0.8344, value_loss: 0.4916
2024-07-11 17:31:35,557 [INFO    ] __main__: train step 19195: loss: 0.9240, policy_loss: 0.8344, value_loss: 0.4916
2024-07-11 17:31:35,768 [INFO    ] __main__: train step 19196: loss: 0.9240, policy_loss: 0.8344, value_loss: 0.4916
2024-07-11 17:31:35,987 [INFO    ] __main__: train step 19197: loss: 0.9240, policy_loss: 0.8344, value_loss: 0.4915
2024-07-11 17:31:36,207 [INFO    ] __main__: train step 19198: loss: 0.9239, policy_loss: 0.8344, value_loss: 0.4915
2024-07-11 17:31:36,435 [INFO    ] __main__: train step 19199: loss: 0.9239, policy_loss: 0.8344, value_loss: 0.4915
2024-07-11 17:31:36,655 [INFO    ] __main__: train step 19200: loss: 0.9239, policy_loss: 0.8343, value_loss: 0.4915
2024-07-11 17:31:36,858 [INFO    ] __main__: train step 19201: loss: 0.9239, policy_loss: 0.8343, value_loss: 0.4915
2024-07-11 17:31:37,067 [INFO    ] __main__: train step 19202: loss: 0.9239, policy_loss: 0.8343, value_loss: 0.4915
2024-07-11 17:31:37,269 [INFO    ] __main__: train step 19203: loss: 0.9239, policy_loss: 0.8343, value_loss: 0.4914
2024-07-11 17:31:37,465 [INFO    ] __main__: train step 19204: loss: 0.9239, policy_loss: 0.8343, value_loss: 0.4914
2024-07-11 17:31:37,661 [INFO    ] __main__: train step 19205: loss: 0.9239, policy_loss: 0.8343, value_loss: 0.4914
2024-07-11 17:31:37,862 [INFO    ] __main__: train step 19206: loss: 0.9239, policy_loss: 0.8343, value_loss: 0.4914
2024-07-11 17:31:38,056 [INFO    ] __main__: train step 19207: loss: 0.9238, policy_loss: 0.8343, value_loss: 0.4914
2024-07-11 17:31:38,253 [INFO    ] __main__: train step 19208: loss: 0.9238, policy_loss: 0.8342, value_loss: 0.4913
2024-07-11 17:31:38,461 [INFO    ] __main__: train step 19209: loss: 0.9238, policy_loss: 0.8342, value_loss: 0.4913
2024-07-11 17:31:39,914 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:31:40,340 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:31:40,394 [INFO    ] __main__: train step 19210: loss: 0.9238, policy_loss: 0.8342, value_loss: 0.4913
2024-07-11 17:31:40,575 [INFO    ] __main__: train step 19211: loss: 0.9238, policy_loss: 0.8342, value_loss: 0.4913
2024-07-11 17:31:40,780 [INFO    ] __main__: train step 19212: loss: 0.9238, policy_loss: 0.8342, value_loss: 0.4913
2024-07-11 17:31:40,988 [INFO    ] __main__: train step 19213: loss: 0.9238, policy_loss: 0.8342, value_loss: 0.4912
2024-07-11 17:31:41,186 [INFO    ] __main__: train step 19214: loss: 0.9238, policy_loss: 0.8342, value_loss: 0.4912
2024-07-11 17:31:41,389 [INFO    ] __main__: train step 19215: loss: 0.9238, policy_loss: 0.8342, value_loss: 0.4912
2024-07-11 17:31:41,596 [INFO    ] __main__: train step 19216: loss: 0.9237, policy_loss: 0.8341, value_loss: 0.4912
2024-07-11 17:31:41,810 [INFO    ] __main__: train step 19217: loss: 0.9237, policy_loss: 0.8341, value_loss: 0.4912
2024-07-11 17:31:42,019 [INFO    ] __main__: train step 19218: loss: 0.9237, policy_loss: 0.8341, value_loss: 0.4911
2024-07-11 17:31:42,224 [INFO    ] __main__: train step 19219: loss: 0.9237, policy_loss: 0.8341, value_loss: 0.4911
2024-07-11 17:31:42,441 [INFO    ] __main__: train step 19220: loss: 0.9237, policy_loss: 0.8341, value_loss: 0.4911
2024-07-11 17:31:42,658 [INFO    ] __main__: train step 19221: loss: 0.9237, policy_loss: 0.8341, value_loss: 0.4911
2024-07-11 17:31:42,895 [INFO    ] __main__: train step 19222: loss: 0.9237, policy_loss: 0.8341, value_loss: 0.4911
2024-07-11 17:31:43,096 [INFO    ] __main__: train step 19223: loss: 0.9237, policy_loss: 0.8341, value_loss: 0.4910
2024-07-11 17:31:43,301 [INFO    ] __main__: train step 19224: loss: 0.9237, policy_loss: 0.8340, value_loss: 0.4910
2024-07-11 17:31:43,520 [INFO    ] __main__: train step 19225: loss: 0.9236, policy_loss: 0.8340, value_loss: 0.4910
2024-07-11 17:31:43,718 [INFO    ] __main__: train step 19226: loss: 0.9236, policy_loss: 0.8340, value_loss: 0.4910
2024-07-11 17:31:45,166 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:31:45,579 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:31:45,634 [INFO    ] __main__: train step 19227: loss: 0.9236, policy_loss: 0.8340, value_loss: 0.4910
2024-07-11 17:31:45,809 [INFO    ] __main__: train step 19228: loss: 0.9236, policy_loss: 0.8340, value_loss: 0.4909
2024-07-11 17:31:46,030 [INFO    ] __main__: train step 19229: loss: 0.9236, policy_loss: 0.8340, value_loss: 0.4909
2024-07-11 17:31:46,225 [INFO    ] __main__: train step 19230: loss: 0.9236, policy_loss: 0.8340, value_loss: 0.4909
2024-07-11 17:31:46,431 [INFO    ] __main__: train step 19231: loss: 0.9236, policy_loss: 0.8340, value_loss: 0.4909
2024-07-11 17:31:46,627 [INFO    ] __main__: train step 19232: loss: 0.9236, policy_loss: 0.8339, value_loss: 0.4909
2024-07-11 17:31:46,822 [INFO    ] __main__: train step 19233: loss: 0.9236, policy_loss: 0.8339, value_loss: 0.4908
2024-07-11 17:31:47,025 [INFO    ] __main__: train step 19234: loss: 0.9235, policy_loss: 0.8339, value_loss: 0.4908
2024-07-11 17:31:47,236 [INFO    ] __main__: train step 19235: loss: 0.9235, policy_loss: 0.8339, value_loss: 0.4908
2024-07-11 17:31:47,435 [INFO    ] __main__: train step 19236: loss: 0.9235, policy_loss: 0.8339, value_loss: 0.4908
2024-07-11 17:31:47,643 [INFO    ] __main__: train step 19237: loss: 0.9235, policy_loss: 0.8339, value_loss: 0.4908
2024-07-11 17:31:47,847 [INFO    ] __main__: train step 19238: loss: 0.9235, policy_loss: 0.8339, value_loss: 0.4907
2024-07-11 17:31:48,059 [INFO    ] __main__: train step 19239: loss: 0.9235, policy_loss: 0.8339, value_loss: 0.4907
2024-07-11 17:31:48,275 [INFO    ] __main__: train step 19240: loss: 0.9235, policy_loss: 0.8338, value_loss: 0.4907
2024-07-11 17:31:48,506 [INFO    ] __main__: train step 19241: loss: 0.9235, policy_loss: 0.8338, value_loss: 0.4907
2024-07-11 17:31:48,733 [INFO    ] __main__: train step 19242: loss: 0.9235, policy_loss: 0.8338, value_loss: 0.4907
2024-07-11 17:31:48,931 [INFO    ] __main__: train step 19243: loss: 0.9234, policy_loss: 0.8338, value_loss: 0.4907
2024-07-11 17:31:50,375 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:31:50,787 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:31:50,845 [INFO    ] __main__: train step 19244: loss: 0.9234, policy_loss: 0.8338, value_loss: 0.4906
2024-07-11 17:31:52,752 [INFO    ] __main__: train step 19245: loss: 0.9234, policy_loss: 0.8338, value_loss: 0.4906
2024-07-11 17:31:52,969 [INFO    ] __main__: train step 19246: loss: 0.9234, policy_loss: 0.8338, value_loss: 0.4906
2024-07-11 17:31:53,185 [INFO    ] __main__: train step 19247: loss: 0.9234, policy_loss: 0.8338, value_loss: 0.4906
2024-07-11 17:31:53,395 [INFO    ] __main__: train step 19248: loss: 0.9234, policy_loss: 0.8337, value_loss: 0.4906
2024-07-11 17:31:53,622 [INFO    ] __main__: train step 19249: loss: 0.9234, policy_loss: 0.8337, value_loss: 0.4905
2024-07-11 17:31:53,840 [INFO    ] __main__: train step 19250: loss: 0.9234, policy_loss: 0.8337, value_loss: 0.4905
2024-07-11 17:31:54,051 [INFO    ] __main__: train step 19251: loss: 0.9234, policy_loss: 0.8337, value_loss: 0.4905
2024-07-11 17:31:54,260 [INFO    ] __main__: train step 19252: loss: 0.9234, policy_loss: 0.8337, value_loss: 0.4905
2024-07-11 17:31:54,467 [INFO    ] __main__: train step 19253: loss: 0.9233, policy_loss: 0.8337, value_loss: 0.4905
2024-07-11 17:31:54,675 [INFO    ] __main__: train step 19254: loss: 0.9233, policy_loss: 0.8337, value_loss: 0.4904
2024-07-11 17:31:54,886 [INFO    ] __main__: train step 19255: loss: 0.9233, policy_loss: 0.8337, value_loss: 0.4904
2024-07-11 17:31:55,078 [INFO    ] __main__: train step 19256: loss: 0.9233, policy_loss: 0.8337, value_loss: 0.4904
2024-07-11 17:31:55,292 [INFO    ] __main__: train step 19257: loss: 0.9233, policy_loss: 0.8336, value_loss: 0.4904
2024-07-11 17:31:55,490 [INFO    ] __main__: train step 19258: loss: 0.9233, policy_loss: 0.8336, value_loss: 0.4904
2024-07-11 17:31:55,694 [INFO    ] __main__: train step 19259: loss: 0.9233, policy_loss: 0.8336, value_loss: 0.4903
2024-07-11 17:31:55,894 [INFO    ] __main__: train step 19260: loss: 0.9233, policy_loss: 0.8336, value_loss: 0.4903
2024-07-11 17:31:57,341 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:31:57,738 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:31:57,793 [INFO    ] __main__: train step 19261: loss: 0.9233, policy_loss: 0.8336, value_loss: 0.4903
2024-07-11 17:31:57,966 [INFO    ] __main__: train step 19262: loss: 0.9233, policy_loss: 0.8336, value_loss: 0.4903
2024-07-11 17:31:58,167 [INFO    ] __main__: train step 19263: loss: 0.9232, policy_loss: 0.8336, value_loss: 0.4903
2024-07-11 17:31:58,369 [INFO    ] __main__: train step 19264: loss: 0.9232, policy_loss: 0.8336, value_loss: 0.4902
2024-07-11 17:31:58,574 [INFO    ] __main__: train step 19265: loss: 0.9232, policy_loss: 0.8335, value_loss: 0.4902
2024-07-11 17:31:58,771 [INFO    ] __main__: train step 19266: loss: 0.9232, policy_loss: 0.8335, value_loss: 0.4902
2024-07-11 17:31:58,981 [INFO    ] __main__: train step 19267: loss: 0.9232, policy_loss: 0.8335, value_loss: 0.4902
2024-07-11 17:31:59,191 [INFO    ] __main__: train step 19268: loss: 0.9232, policy_loss: 0.8335, value_loss: 0.4902
2024-07-11 17:31:59,399 [INFO    ] __main__: train step 19269: loss: 0.9232, policy_loss: 0.8335, value_loss: 0.4901
2024-07-11 17:31:59,601 [INFO    ] __main__: train step 19270: loss: 0.9232, policy_loss: 0.8335, value_loss: 0.4901
2024-07-11 17:31:59,815 [INFO    ] __main__: train step 19271: loss: 0.9232, policy_loss: 0.8335, value_loss: 0.4901
2024-07-11 17:32:00,024 [INFO    ] __main__: train step 19272: loss: 0.9231, policy_loss: 0.8335, value_loss: 0.4901
2024-07-11 17:32:00,239 [INFO    ] __main__: train step 19273: loss: 0.9231, policy_loss: 0.8335, value_loss: 0.4901
2024-07-11 17:32:00,488 [INFO    ] __main__: train step 19274: loss: 0.9231, policy_loss: 0.8334, value_loss: 0.4901
2024-07-11 17:32:00,719 [INFO    ] __main__: train step 19275: loss: 0.9231, policy_loss: 0.8334, value_loss: 0.4900
2024-07-11 17:32:00,920 [INFO    ] __main__: train step 19276: loss: 0.9231, policy_loss: 0.8334, value_loss: 0.4900
2024-07-11 17:32:01,134 [INFO    ] __main__: train step 19277: loss: 0.9231, policy_loss: 0.8334, value_loss: 0.4900
2024-07-11 17:32:02,580 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:32:03,002 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:32:03,066 [INFO    ] __main__: train step 19278: loss: 0.9231, policy_loss: 0.8334, value_loss: 0.4900
2024-07-11 17:32:03,246 [INFO    ] __main__: train step 19279: loss: 0.9231, policy_loss: 0.8334, value_loss: 0.4900
2024-07-11 17:32:03,455 [INFO    ] __main__: train step 19280: loss: 0.9231, policy_loss: 0.8334, value_loss: 0.4899
2024-07-11 17:32:03,681 [INFO    ] __main__: train step 19281: loss: 0.9231, policy_loss: 0.8334, value_loss: 0.4899
2024-07-11 17:32:03,889 [INFO    ] __main__: train step 19282: loss: 0.9230, policy_loss: 0.8333, value_loss: 0.4899
2024-07-11 17:32:04,090 [INFO    ] __main__: train step 19283: loss: 0.9230, policy_loss: 0.8333, value_loss: 0.4899
2024-07-11 17:32:04,299 [INFO    ] __main__: train step 19284: loss: 0.9230, policy_loss: 0.8333, value_loss: 0.4899
2024-07-11 17:32:04,510 [INFO    ] __main__: train step 19285: loss: 0.9230, policy_loss: 0.8333, value_loss: 0.4898
2024-07-11 17:32:04,725 [INFO    ] __main__: train step 19286: loss: 0.9230, policy_loss: 0.8333, value_loss: 0.4898
2024-07-11 17:32:04,952 [INFO    ] __main__: train step 19287: loss: 0.9230, policy_loss: 0.8333, value_loss: 0.4898
2024-07-11 17:32:05,166 [INFO    ] __main__: train step 19288: loss: 0.9230, policy_loss: 0.8333, value_loss: 0.4898
2024-07-11 17:32:05,374 [INFO    ] __main__: train step 19289: loss: 0.9230, policy_loss: 0.8333, value_loss: 0.4898
2024-07-11 17:32:05,588 [INFO    ] __main__: train step 19290: loss: 0.9230, policy_loss: 0.8333, value_loss: 0.4897
2024-07-11 17:32:05,804 [INFO    ] __main__: train step 19291: loss: 0.9230, policy_loss: 0.8332, value_loss: 0.4897
2024-07-11 17:32:06,040 [INFO    ] __main__: train step 19292: loss: 0.9229, policy_loss: 0.8332, value_loss: 0.4897
2024-07-11 17:32:06,250 [INFO    ] __main__: train step 19293: loss: 0.9229, policy_loss: 0.8332, value_loss: 0.4897
2024-07-11 17:32:06,505 [INFO    ] __main__: train step 19294: loss: 0.9229, policy_loss: 0.8332, value_loss: 0.4897
2024-07-11 17:32:07,947 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:32:08,379 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:32:08,442 [INFO    ] __main__: train step 19295: loss: 0.9229, policy_loss: 0.8332, value_loss: 0.4896
2024-07-11 17:32:08,621 [INFO    ] __main__: train step 19296: loss: 0.9229, policy_loss: 0.8332, value_loss: 0.4896
2024-07-11 17:32:08,834 [INFO    ] __main__: train step 19297: loss: 0.9229, policy_loss: 0.8332, value_loss: 0.4896
2024-07-11 17:32:09,032 [INFO    ] __main__: train step 19298: loss: 0.9229, policy_loss: 0.8332, value_loss: 0.4896
2024-07-11 17:32:09,242 [INFO    ] __main__: train step 19299: loss: 0.9229, policy_loss: 0.8332, value_loss: 0.4896
2024-07-11 17:32:09,467 [INFO    ] __main__: train step 19300: loss: 0.9229, policy_loss: 0.8331, value_loss: 0.4896
2024-07-11 17:32:09,682 [INFO    ] __main__: train step 19301: loss: 0.9229, policy_loss: 0.8331, value_loss: 0.4895
2024-07-11 17:32:09,899 [INFO    ] __main__: train step 19302: loss: 0.9228, policy_loss: 0.8331, value_loss: 0.4895
2024-07-11 17:32:10,104 [INFO    ] __main__: train step 19303: loss: 0.9228, policy_loss: 0.8331, value_loss: 0.4895
2024-07-11 17:32:10,346 [INFO    ] __main__: train step 19304: loss: 0.9228, policy_loss: 0.8331, value_loss: 0.4895
2024-07-11 17:32:10,573 [INFO    ] __main__: train step 19305: loss: 0.9228, policy_loss: 0.8331, value_loss: 0.4895
2024-07-11 17:32:10,768 [INFO    ] __main__: train step 19306: loss: 0.9228, policy_loss: 0.8331, value_loss: 0.4894
2024-07-11 17:32:10,977 [INFO    ] __main__: train step 19307: loss: 0.9228, policy_loss: 0.8331, value_loss: 0.4894
2024-07-11 17:32:11,174 [INFO    ] __main__: train step 19308: loss: 0.9228, policy_loss: 0.8330, value_loss: 0.4894
2024-07-11 17:32:11,385 [INFO    ] __main__: train step 19309: loss: 0.9228, policy_loss: 0.8330, value_loss: 0.4894
2024-07-11 17:32:11,602 [INFO    ] __main__: train step 19310: loss: 0.9228, policy_loss: 0.8330, value_loss: 0.4894
2024-07-11 17:32:11,826 [INFO    ] __main__: train step 19311: loss: 0.9228, policy_loss: 0.8330, value_loss: 0.4893
2024-07-11 17:32:13,287 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:32:13,696 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:32:13,751 [INFO    ] __main__: train step 19312: loss: 0.9227, policy_loss: 0.8330, value_loss: 0.4893
2024-07-11 17:32:13,946 [INFO    ] __main__: train step 19313: loss: 0.9227, policy_loss: 0.8330, value_loss: 0.4893
2024-07-11 17:32:14,143 [INFO    ] __main__: train step 19314: loss: 0.9227, policy_loss: 0.8330, value_loss: 0.4893
2024-07-11 17:32:14,360 [INFO    ] __main__: train step 19315: loss: 0.9227, policy_loss: 0.8330, value_loss: 0.4893
2024-07-11 17:32:14,599 [INFO    ] __main__: train step 19316: loss: 0.9227, policy_loss: 0.8330, value_loss: 0.4892
2024-07-11 17:32:14,843 [INFO    ] __main__: train step 19317: loss: 0.9227, policy_loss: 0.8330, value_loss: 0.4892
2024-07-11 17:32:15,060 [INFO    ] __main__: train step 19318: loss: 0.9227, policy_loss: 0.8329, value_loss: 0.4892
2024-07-11 17:32:15,284 [INFO    ] __main__: train step 19319: loss: 0.9227, policy_loss: 0.8329, value_loss: 0.4892
2024-07-11 17:32:15,512 [INFO    ] __main__: train step 19320: loss: 0.9227, policy_loss: 0.8329, value_loss: 0.4892
2024-07-11 17:32:15,708 [INFO    ] __main__: train step 19321: loss: 0.9227, policy_loss: 0.8329, value_loss: 0.4891
2024-07-11 17:32:15,906 [INFO    ] __main__: train step 19322: loss: 0.9227, policy_loss: 0.8329, value_loss: 0.4891
2024-07-11 17:32:16,105 [INFO    ] __main__: train step 19323: loss: 0.9226, policy_loss: 0.8329, value_loss: 0.4891
2024-07-11 17:32:16,310 [INFO    ] __main__: train step 19324: loss: 0.9226, policy_loss: 0.8329, value_loss: 0.4891
2024-07-11 17:32:16,516 [INFO    ] __main__: train step 19325: loss: 0.9226, policy_loss: 0.8329, value_loss: 0.4891
2024-07-11 17:32:16,720 [INFO    ] __main__: train step 19326: loss: 0.9226, policy_loss: 0.8328, value_loss: 0.4891
2024-07-11 17:32:16,926 [INFO    ] __main__: train step 19327: loss: 0.9226, policy_loss: 0.8328, value_loss: 0.4890
2024-07-11 17:32:17,127 [INFO    ] __main__: train step 19328: loss: 0.9226, policy_loss: 0.8328, value_loss: 0.4890
2024-07-11 17:32:18,572 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:32:19,002 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:32:19,060 [INFO    ] __main__: train step 19329: loss: 0.9226, policy_loss: 0.8328, value_loss: 0.4890
2024-07-11 17:32:19,251 [INFO    ] __main__: train step 19330: loss: 0.9226, policy_loss: 0.8328, value_loss: 0.4890
2024-07-11 17:32:19,473 [INFO    ] __main__: train step 19331: loss: 0.9226, policy_loss: 0.8328, value_loss: 0.4890
2024-07-11 17:32:19,681 [INFO    ] __main__: train step 19332: loss: 0.9226, policy_loss: 0.8328, value_loss: 0.4889
2024-07-11 17:32:19,910 [INFO    ] __main__: train step 19333: loss: 0.9225, policy_loss: 0.8328, value_loss: 0.4889
2024-07-11 17:32:20,128 [INFO    ] __main__: train step 19334: loss: 0.9225, policy_loss: 0.8328, value_loss: 0.4889
2024-07-11 17:32:20,370 [INFO    ] __main__: train step 19335: loss: 0.9225, policy_loss: 0.8328, value_loss: 0.4889
2024-07-11 17:32:20,599 [INFO    ] __main__: train step 19336: loss: 0.9225, policy_loss: 0.8327, value_loss: 0.4889
2024-07-11 17:32:20,827 [INFO    ] __main__: train step 19337: loss: 0.9225, policy_loss: 0.8327, value_loss: 0.4888
2024-07-11 17:32:21,031 [INFO    ] __main__: train step 19338: loss: 0.9225, policy_loss: 0.8327, value_loss: 0.4888
2024-07-11 17:32:21,248 [INFO    ] __main__: train step 19339: loss: 0.9225, policy_loss: 0.8327, value_loss: 0.4888
2024-07-11 17:32:21,484 [INFO    ] __main__: train step 19340: loss: 0.9225, policy_loss: 0.8327, value_loss: 0.4888
2024-07-11 17:32:21,682 [INFO    ] __main__: train step 19341: loss: 0.9225, policy_loss: 0.8327, value_loss: 0.4888
2024-07-11 17:32:21,896 [INFO    ] __main__: train step 19342: loss: 0.9225, policy_loss: 0.8327, value_loss: 0.4887
2024-07-11 17:32:22,129 [INFO    ] __main__: train step 19343: loss: 0.9225, policy_loss: 0.8327, value_loss: 0.4887
2024-07-11 17:32:22,332 [INFO    ] __main__: train step 19344: loss: 0.9224, policy_loss: 0.8327, value_loss: 0.4887
2024-07-11 17:32:22,574 [INFO    ] __main__: train step 19345: loss: 0.9224, policy_loss: 0.8326, value_loss: 0.4887
2024-07-11 17:32:24,016 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:32:24,420 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:32:24,475 [INFO    ] __main__: train step 19346: loss: 0.9224, policy_loss: 0.8326, value_loss: 0.4887
2024-07-11 17:32:24,660 [INFO    ] __main__: train step 19347: loss: 0.9224, policy_loss: 0.8326, value_loss: 0.4886
2024-07-11 17:32:24,883 [INFO    ] __main__: train step 19348: loss: 0.9224, policy_loss: 0.8326, value_loss: 0.4886
2024-07-11 17:32:25,078 [INFO    ] __main__: train step 19349: loss: 0.9224, policy_loss: 0.8326, value_loss: 0.4886
2024-07-11 17:32:25,361 [INFO    ] __main__: train step 19350: loss: 0.9224, policy_loss: 0.8326, value_loss: 0.4886
2024-07-11 17:32:25,592 [INFO    ] __main__: train step 19351: loss: 0.9224, policy_loss: 0.8326, value_loss: 0.4886
2024-07-11 17:32:25,809 [INFO    ] __main__: train step 19352: loss: 0.9224, policy_loss: 0.8326, value_loss: 0.4886
2024-07-11 17:32:26,013 [INFO    ] __main__: train step 19353: loss: 0.9224, policy_loss: 0.8326, value_loss: 0.4885
2024-07-11 17:32:26,219 [INFO    ] __main__: train step 19354: loss: 0.9223, policy_loss: 0.8325, value_loss: 0.4885
2024-07-11 17:32:26,416 [INFO    ] __main__: train step 19355: loss: 0.9223, policy_loss: 0.8325, value_loss: 0.4885
2024-07-11 17:32:26,624 [INFO    ] __main__: train step 19356: loss: 0.9223, policy_loss: 0.8325, value_loss: 0.4885
2024-07-11 17:32:26,841 [INFO    ] __main__: train step 19357: loss: 0.9223, policy_loss: 0.8325, value_loss: 0.4885
2024-07-11 17:32:28,812 [INFO    ] __main__: train step 19358: loss: 0.9223, policy_loss: 0.8325, value_loss: 0.4884
2024-07-11 17:32:29,010 [INFO    ] __main__: train step 19359: loss: 0.9223, policy_loss: 0.8325, value_loss: 0.4884
2024-07-11 17:32:29,214 [INFO    ] __main__: train step 19360: loss: 0.9223, policy_loss: 0.8325, value_loss: 0.4884
2024-07-11 17:32:29,423 [INFO    ] __main__: train step 19361: loss: 0.9223, policy_loss: 0.8325, value_loss: 0.4884
2024-07-11 17:32:29,643 [INFO    ] __main__: train step 19362: loss: 0.9223, policy_loss: 0.8325, value_loss: 0.4884
2024-07-11 17:32:31,087 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:32:31,491 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:32:31,546 [INFO    ] __main__: train step 19363: loss: 0.9223, policy_loss: 0.8325, value_loss: 0.4883
2024-07-11 17:32:31,718 [INFO    ] __main__: train step 19364: loss: 0.9223, policy_loss: 0.8324, value_loss: 0.4883
2024-07-11 17:32:31,924 [INFO    ] __main__: train step 19365: loss: 0.9223, policy_loss: 0.8324, value_loss: 0.4883
2024-07-11 17:32:32,122 [INFO    ] __main__: train step 19366: loss: 0.9222, policy_loss: 0.8324, value_loss: 0.4883
2024-07-11 17:32:32,325 [INFO    ] __main__: train step 19367: loss: 0.9222, policy_loss: 0.8324, value_loss: 0.4883
2024-07-11 17:32:32,535 [INFO    ] __main__: train step 19368: loss: 0.9222, policy_loss: 0.8324, value_loss: 0.4882
2024-07-11 17:32:32,754 [INFO    ] __main__: train step 19369: loss: 0.9222, policy_loss: 0.8324, value_loss: 0.4882
2024-07-11 17:32:33,006 [INFO    ] __main__: train step 19370: loss: 0.9222, policy_loss: 0.8324, value_loss: 0.4882
2024-07-11 17:32:33,226 [INFO    ] __main__: train step 19371: loss: 0.9222, policy_loss: 0.8324, value_loss: 0.4882
2024-07-11 17:32:33,435 [INFO    ] __main__: train step 19372: loss: 0.9222, policy_loss: 0.8324, value_loss: 0.4882
2024-07-11 17:32:33,636 [INFO    ] __main__: train step 19373: loss: 0.9222, policy_loss: 0.8323, value_loss: 0.4882
2024-07-11 17:32:33,844 [INFO    ] __main__: train step 19374: loss: 0.9222, policy_loss: 0.8323, value_loss: 0.4881
2024-07-11 17:32:34,048 [INFO    ] __main__: train step 19375: loss: 0.9222, policy_loss: 0.8323, value_loss: 0.4881
2024-07-11 17:32:34,255 [INFO    ] __main__: train step 19376: loss: 0.9222, policy_loss: 0.8323, value_loss: 0.4881
2024-07-11 17:32:34,459 [INFO    ] __main__: train step 19377: loss: 0.9221, policy_loss: 0.8323, value_loss: 0.4881
2024-07-11 17:32:34,663 [INFO    ] __main__: train step 19378: loss: 0.9221, policy_loss: 0.8323, value_loss: 0.4881
2024-07-11 17:32:34,868 [INFO    ] __main__: train step 19379: loss: 0.9221, policy_loss: 0.8323, value_loss: 0.4880
2024-07-11 17:32:36,323 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:32:36,698 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:32:36,753 [INFO    ] __main__: train step 19380: loss: 0.9221, policy_loss: 0.8323, value_loss: 0.4880
2024-07-11 17:32:36,945 [INFO    ] __main__: train step 19381: loss: 0.9221, policy_loss: 0.8323, value_loss: 0.4880
2024-07-11 17:32:37,183 [INFO    ] __main__: train step 19382: loss: 0.9221, policy_loss: 0.8323, value_loss: 0.4880
2024-07-11 17:32:37,384 [INFO    ] __main__: train step 19383: loss: 0.9221, policy_loss: 0.8322, value_loss: 0.4880
2024-07-11 17:32:37,589 [INFO    ] __main__: train step 19384: loss: 0.9221, policy_loss: 0.8322, value_loss: 0.4879
2024-07-11 17:32:37,795 [INFO    ] __main__: train step 19385: loss: 0.9221, policy_loss: 0.8322, value_loss: 0.4879
2024-07-11 17:32:38,015 [INFO    ] __main__: train step 19386: loss: 0.9221, policy_loss: 0.8322, value_loss: 0.4879
2024-07-11 17:32:38,217 [INFO    ] __main__: train step 19387: loss: 0.9221, policy_loss: 0.8322, value_loss: 0.4879
2024-07-11 17:32:38,426 [INFO    ] __main__: train step 19388: loss: 0.9220, policy_loss: 0.8322, value_loss: 0.4879
2024-07-11 17:32:38,644 [INFO    ] __main__: train step 19389: loss: 0.9220, policy_loss: 0.8322, value_loss: 0.4879
2024-07-11 17:32:38,877 [INFO    ] __main__: train step 19390: loss: 0.9220, policy_loss: 0.8322, value_loss: 0.4878
2024-07-11 17:32:39,126 [INFO    ] __main__: train step 19391: loss: 0.9220, policy_loss: 0.8322, value_loss: 0.4878
2024-07-11 17:32:39,337 [INFO    ] __main__: train step 19392: loss: 0.9220, policy_loss: 0.8322, value_loss: 0.4878
2024-07-11 17:32:39,573 [INFO    ] __main__: train step 19393: loss: 0.9220, policy_loss: 0.8321, value_loss: 0.4878
2024-07-11 17:32:39,780 [INFO    ] __main__: train step 19394: loss: 0.9220, policy_loss: 0.8321, value_loss: 0.4878
2024-07-11 17:32:39,982 [INFO    ] __main__: train step 19395: loss: 0.9220, policy_loss: 0.8321, value_loss: 0.4877
2024-07-11 17:32:40,200 [INFO    ] __main__: train step 19396: loss: 0.9220, policy_loss: 0.8321, value_loss: 0.4877
2024-07-11 17:32:41,633 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:32:42,094 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:32:42,156 [INFO    ] __main__: train step 19397: loss: 0.9220, policy_loss: 0.8321, value_loss: 0.4877
2024-07-11 17:32:42,333 [INFO    ] __main__: train step 19398: loss: 0.9220, policy_loss: 0.8321, value_loss: 0.4877
2024-07-11 17:32:42,539 [INFO    ] __main__: train step 19399: loss: 0.9220, policy_loss: 0.8321, value_loss: 0.4877
2024-07-11 17:32:42,744 [INFO    ] __main__: train step 19400: loss: 0.9219, policy_loss: 0.8321, value_loss: 0.4876
2024-07-11 17:32:42,955 [INFO    ] __main__: train step 19401: loss: 0.9219, policy_loss: 0.8321, value_loss: 0.4876
2024-07-11 17:32:43,169 [INFO    ] __main__: train step 19402: loss: 0.9219, policy_loss: 0.8321, value_loss: 0.4876
2024-07-11 17:32:43,367 [INFO    ] __main__: train step 19403: loss: 0.9219, policy_loss: 0.8320, value_loss: 0.4876
2024-07-11 17:32:43,578 [INFO    ] __main__: train step 19404: loss: 0.9219, policy_loss: 0.8320, value_loss: 0.4876
2024-07-11 17:32:43,792 [INFO    ] __main__: train step 19405: loss: 0.9219, policy_loss: 0.8320, value_loss: 0.4875
2024-07-11 17:32:44,000 [INFO    ] __main__: train step 19406: loss: 0.9219, policy_loss: 0.8320, value_loss: 0.4875
2024-07-11 17:32:44,209 [INFO    ] __main__: train step 19407: loss: 0.9219, policy_loss: 0.8320, value_loss: 0.4875
2024-07-11 17:32:44,417 [INFO    ] __main__: train step 19408: loss: 0.9219, policy_loss: 0.8320, value_loss: 0.4875
2024-07-11 17:32:44,624 [INFO    ] __main__: train step 19409: loss: 0.9219, policy_loss: 0.8320, value_loss: 0.4875
2024-07-11 17:32:44,845 [INFO    ] __main__: train step 19410: loss: 0.9219, policy_loss: 0.8320, value_loss: 0.4875
2024-07-11 17:32:45,051 [INFO    ] __main__: train step 19411: loss: 0.9219, policy_loss: 0.8320, value_loss: 0.4874
2024-07-11 17:32:45,266 [INFO    ] __main__: train step 19412: loss: 0.9218, policy_loss: 0.8320, value_loss: 0.4874
2024-07-11 17:32:45,470 [INFO    ] __main__: train step 19413: loss: 0.9218, policy_loss: 0.8319, value_loss: 0.4874
2024-07-11 17:32:46,921 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:32:47,343 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:32:47,399 [INFO    ] __main__: train step 19414: loss: 0.9218, policy_loss: 0.8319, value_loss: 0.4874
2024-07-11 17:32:47,578 [INFO    ] __main__: train step 19415: loss: 0.9218, policy_loss: 0.8319, value_loss: 0.4874
2024-07-11 17:32:47,779 [INFO    ] __main__: train step 19416: loss: 0.9218, policy_loss: 0.8319, value_loss: 0.4873
2024-07-11 17:32:47,994 [INFO    ] __main__: train step 19417: loss: 0.9218, policy_loss: 0.8319, value_loss: 0.4873
2024-07-11 17:32:48,234 [INFO    ] __main__: train step 19418: loss: 0.9218, policy_loss: 0.8319, value_loss: 0.4873
2024-07-11 17:32:48,434 [INFO    ] __main__: train step 19419: loss: 0.9218, policy_loss: 0.8319, value_loss: 0.4873
2024-07-11 17:32:48,650 [INFO    ] __main__: train step 19420: loss: 0.9218, policy_loss: 0.8319, value_loss: 0.4873
2024-07-11 17:32:48,882 [INFO    ] __main__: train step 19421: loss: 0.9218, policy_loss: 0.8319, value_loss: 0.4872
2024-07-11 17:32:49,110 [INFO    ] __main__: train step 19422: loss: 0.9218, policy_loss: 0.8319, value_loss: 0.4872
2024-07-11 17:32:49,330 [INFO    ] __main__: train step 19423: loss: 0.9218, policy_loss: 0.8318, value_loss: 0.4872
2024-07-11 17:32:49,557 [INFO    ] __main__: train step 19424: loss: 0.9217, policy_loss: 0.8318, value_loss: 0.4872
2024-07-11 17:32:49,767 [INFO    ] __main__: train step 19425: loss: 0.9217, policy_loss: 0.8318, value_loss: 0.4872
2024-07-11 17:32:49,969 [INFO    ] __main__: train step 19426: loss: 0.9217, policy_loss: 0.8318, value_loss: 0.4871
2024-07-11 17:32:50,170 [INFO    ] __main__: train step 19427: loss: 0.9217, policy_loss: 0.8318, value_loss: 0.4871
2024-07-11 17:32:50,378 [INFO    ] __main__: train step 19428: loss: 0.9217, policy_loss: 0.8318, value_loss: 0.4871
2024-07-11 17:32:50,581 [INFO    ] __main__: train step 19429: loss: 0.9217, policy_loss: 0.8318, value_loss: 0.4871
2024-07-11 17:32:50,787 [INFO    ] __main__: train step 19430: loss: 0.9217, policy_loss: 0.8318, value_loss: 0.4871
2024-07-11 17:32:52,219 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:32:52,644 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:32:52,705 [INFO    ] __main__: train step 19431: loss: 0.9217, policy_loss: 0.8318, value_loss: 0.4871
2024-07-11 17:32:52,878 [INFO    ] __main__: train step 19432: loss: 0.9217, policy_loss: 0.8317, value_loss: 0.4870
2024-07-11 17:32:53,070 [INFO    ] __main__: train step 19433: loss: 0.9217, policy_loss: 0.8317, value_loss: 0.4870
2024-07-11 17:32:53,285 [INFO    ] __main__: train step 19434: loss: 0.9217, policy_loss: 0.8317, value_loss: 0.4870
2024-07-11 17:32:53,483 [INFO    ] __main__: train step 19435: loss: 0.9216, policy_loss: 0.8317, value_loss: 0.4870
2024-07-11 17:32:53,694 [INFO    ] __main__: train step 19436: loss: 0.9216, policy_loss: 0.8317, value_loss: 0.4870
2024-07-11 17:32:53,910 [INFO    ] __main__: train step 19437: loss: 0.9216, policy_loss: 0.8317, value_loss: 0.4869
2024-07-11 17:32:54,136 [INFO    ] __main__: train step 19438: loss: 0.9216, policy_loss: 0.8317, value_loss: 0.4869
2024-07-11 17:32:54,361 [INFO    ] __main__: train step 19439: loss: 0.9216, policy_loss: 0.8317, value_loss: 0.4869
2024-07-11 17:32:54,589 [INFO    ] __main__: train step 19440: loss: 0.9216, policy_loss: 0.8317, value_loss: 0.4869
2024-07-11 17:32:54,809 [INFO    ] __main__: train step 19441: loss: 0.9216, policy_loss: 0.8317, value_loss: 0.4869
2024-07-11 17:32:55,009 [INFO    ] __main__: train step 19442: loss: 0.9216, policy_loss: 0.8317, value_loss: 0.4868
2024-07-11 17:32:55,216 [INFO    ] __main__: train step 19443: loss: 0.9216, policy_loss: 0.8316, value_loss: 0.4868
2024-07-11 17:32:55,422 [INFO    ] __main__: train step 19444: loss: 0.9216, policy_loss: 0.8316, value_loss: 0.4868
2024-07-11 17:32:55,633 [INFO    ] __main__: train step 19445: loss: 0.9216, policy_loss: 0.8316, value_loss: 0.4868
2024-07-11 17:32:55,871 [INFO    ] __main__: train step 19446: loss: 0.9216, policy_loss: 0.8316, value_loss: 0.4868
2024-07-11 17:32:56,072 [INFO    ] __main__: train step 19447: loss: 0.9216, policy_loss: 0.8316, value_loss: 0.4868
2024-07-11 17:32:57,533 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:32:57,958 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:32:58,023 [INFO    ] __main__: train step 19448: loss: 0.9215, policy_loss: 0.8316, value_loss: 0.4867
2024-07-11 17:32:58,209 [INFO    ] __main__: train step 19449: loss: 0.9215, policy_loss: 0.8316, value_loss: 0.4867
2024-07-11 17:32:58,414 [INFO    ] __main__: train step 19450: loss: 0.9215, policy_loss: 0.8316, value_loss: 0.4867
2024-07-11 17:32:58,616 [INFO    ] __main__: train step 19451: loss: 0.9215, policy_loss: 0.8316, value_loss: 0.4867
2024-07-11 17:32:58,812 [INFO    ] __main__: train step 19452: loss: 0.9215, policy_loss: 0.8316, value_loss: 0.4867
2024-07-11 17:32:59,012 [INFO    ] __main__: train step 19453: loss: 0.9215, policy_loss: 0.8316, value_loss: 0.4866
2024-07-11 17:32:59,221 [INFO    ] __main__: train step 19454: loss: 0.9215, policy_loss: 0.8315, value_loss: 0.4866
2024-07-11 17:32:59,421 [INFO    ] __main__: train step 19455: loss: 0.9215, policy_loss: 0.8315, value_loss: 0.4866
2024-07-11 17:32:59,635 [INFO    ] __main__: train step 19456: loss: 0.9215, policy_loss: 0.8315, value_loss: 0.4866
2024-07-11 17:32:59,853 [INFO    ] __main__: train step 19457: loss: 0.9215, policy_loss: 0.8315, value_loss: 0.4866
2024-07-11 17:33:00,069 [INFO    ] __main__: train step 19458: loss: 0.9215, policy_loss: 0.8315, value_loss: 0.4865
2024-07-11 17:33:00,276 [INFO    ] __main__: train step 19459: loss: 0.9215, policy_loss: 0.8315, value_loss: 0.4865
2024-07-11 17:33:00,489 [INFO    ] __main__: train step 19460: loss: 0.9215, policy_loss: 0.8315, value_loss: 0.4865
2024-07-11 17:33:00,692 [INFO    ] __main__: train step 19461: loss: 0.9214, policy_loss: 0.8315, value_loss: 0.4865
2024-07-11 17:33:00,891 [INFO    ] __main__: train step 19462: loss: 0.9214, policy_loss: 0.8315, value_loss: 0.4865
2024-07-11 17:33:01,103 [INFO    ] __main__: train step 19463: loss: 0.9214, policy_loss: 0.8315, value_loss: 0.4865
2024-07-11 17:33:01,307 [INFO    ] __main__: train step 19464: loss: 0.9214, policy_loss: 0.8314, value_loss: 0.4864
2024-07-11 17:33:02,753 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:33:03,163 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:33:03,218 [INFO    ] __main__: train step 19465: loss: 0.9214, policy_loss: 0.8314, value_loss: 0.4864
2024-07-11 17:33:03,397 [INFO    ] __main__: train step 19466: loss: 0.9214, policy_loss: 0.8314, value_loss: 0.4864
2024-07-11 17:33:03,602 [INFO    ] __main__: train step 19467: loss: 0.9214, policy_loss: 0.8314, value_loss: 0.4864
2024-07-11 17:33:03,805 [INFO    ] __main__: train step 19468: loss: 0.9214, policy_loss: 0.8314, value_loss: 0.4864
2024-07-11 17:33:04,003 [INFO    ] __main__: train step 19469: loss: 0.9214, policy_loss: 0.8314, value_loss: 0.4863
2024-07-11 17:33:04,213 [INFO    ] __main__: train step 19470: loss: 0.9214, policy_loss: 0.8314, value_loss: 0.4863
2024-07-11 17:33:04,434 [INFO    ] __main__: train step 19471: loss: 0.9214, policy_loss: 0.8314, value_loss: 0.4863
2024-07-11 17:33:04,644 [INFO    ] __main__: train step 19472: loss: 0.9214, policy_loss: 0.8314, value_loss: 0.4863
2024-07-11 17:33:06,623 [INFO    ] __main__: train step 19473: loss: 0.9214, policy_loss: 0.8314, value_loss: 0.4863
2024-07-11 17:33:06,844 [INFO    ] __main__: train step 19474: loss: 0.9214, policy_loss: 0.8314, value_loss: 0.4863
2024-07-11 17:33:07,052 [INFO    ] __main__: train step 19475: loss: 0.9213, policy_loss: 0.8313, value_loss: 0.4862
2024-07-11 17:33:07,267 [INFO    ] __main__: train step 19476: loss: 0.9213, policy_loss: 0.8313, value_loss: 0.4862
2024-07-11 17:33:07,480 [INFO    ] __main__: train step 19477: loss: 0.9213, policy_loss: 0.8313, value_loss: 0.4862
2024-07-11 17:33:07,683 [INFO    ] __main__: train step 19478: loss: 0.9213, policy_loss: 0.8313, value_loss: 0.4862
2024-07-11 17:33:07,888 [INFO    ] __main__: train step 19479: loss: 0.9213, policy_loss: 0.8313, value_loss: 0.4862
2024-07-11 17:33:08,107 [INFO    ] __main__: train step 19480: loss: 0.9213, policy_loss: 0.8313, value_loss: 0.4861
2024-07-11 17:33:08,316 [INFO    ] __main__: train step 19481: loss: 0.9213, policy_loss: 0.8313, value_loss: 0.4861
2024-07-11 17:33:09,761 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:33:10,258 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:33:10,313 [INFO    ] __main__: train step 19482: loss: 0.9213, policy_loss: 0.8313, value_loss: 0.4861
2024-07-11 17:33:10,503 [INFO    ] __main__: train step 19483: loss: 0.9213, policy_loss: 0.8313, value_loss: 0.4861
2024-07-11 17:33:10,734 [INFO    ] __main__: train step 19484: loss: 0.9213, policy_loss: 0.8313, value_loss: 0.4861
2024-07-11 17:33:10,933 [INFO    ] __main__: train step 19485: loss: 0.9213, policy_loss: 0.8313, value_loss: 0.4860
2024-07-11 17:33:11,137 [INFO    ] __main__: train step 19486: loss: 0.9213, policy_loss: 0.8312, value_loss: 0.4860
2024-07-11 17:33:11,353 [INFO    ] __main__: train step 19487: loss: 0.9213, policy_loss: 0.8312, value_loss: 0.4860
2024-07-11 17:33:11,565 [INFO    ] __main__: train step 19488: loss: 0.9212, policy_loss: 0.8312, value_loss: 0.4860
2024-07-11 17:33:11,785 [INFO    ] __main__: train step 19489: loss: 0.9212, policy_loss: 0.8312, value_loss: 0.4860
2024-07-11 17:33:12,004 [INFO    ] __main__: train step 19490: loss: 0.9212, policy_loss: 0.8312, value_loss: 0.4860
2024-07-11 17:33:12,207 [INFO    ] __main__: train step 19491: loss: 0.9212, policy_loss: 0.8312, value_loss: 0.4859
2024-07-11 17:33:12,415 [INFO    ] __main__: train step 19492: loss: 0.9212, policy_loss: 0.8312, value_loss: 0.4859
2024-07-11 17:33:12,612 [INFO    ] __main__: train step 19493: loss: 0.9212, policy_loss: 0.8312, value_loss: 0.4859
2024-07-11 17:33:12,822 [INFO    ] __main__: train step 19494: loss: 0.9212, policy_loss: 0.8312, value_loss: 0.4859
2024-07-11 17:33:13,057 [INFO    ] __main__: train step 19495: loss: 0.9212, policy_loss: 0.8312, value_loss: 0.4859
2024-07-11 17:33:13,269 [INFO    ] __main__: train step 19496: loss: 0.9212, policy_loss: 0.8311, value_loss: 0.4858
2024-07-11 17:33:13,493 [INFO    ] __main__: train step 19497: loss: 0.9212, policy_loss: 0.8311, value_loss: 0.4858
2024-07-11 17:33:13,698 [INFO    ] __main__: train step 19498: loss: 0.9212, policy_loss: 0.8311, value_loss: 0.4858
2024-07-11 17:33:15,130 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:33:15,532 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:33:15,587 [INFO    ] __main__: train step 19499: loss: 0.9212, policy_loss: 0.8311, value_loss: 0.4858
2024-07-11 17:33:15,766 [INFO    ] __main__: train step 19500: loss: 0.9211, policy_loss: 0.8311, value_loss: 0.4858
2024-07-11 17:33:15,972 [INFO    ] __main__: train step 19501: loss: 0.9211, policy_loss: 0.8311, value_loss: 0.4857
2024-07-11 17:33:16,170 [INFO    ] __main__: train step 19502: loss: 0.9211, policy_loss: 0.8311, value_loss: 0.4857
2024-07-11 17:33:16,377 [INFO    ] __main__: train step 19503: loss: 0.9211, policy_loss: 0.8311, value_loss: 0.4857
2024-07-11 17:33:16,583 [INFO    ] __main__: train step 19504: loss: 0.9211, policy_loss: 0.8311, value_loss: 0.4857
2024-07-11 17:33:16,786 [INFO    ] __main__: train step 19505: loss: 0.9211, policy_loss: 0.8311, value_loss: 0.4857
2024-07-11 17:33:16,990 [INFO    ] __main__: train step 19506: loss: 0.9211, policy_loss: 0.8311, value_loss: 0.4857
2024-07-11 17:33:17,198 [INFO    ] __main__: train step 19507: loss: 0.9211, policy_loss: 0.8310, value_loss: 0.4856
2024-07-11 17:33:17,408 [INFO    ] __main__: train step 19508: loss: 0.9211, policy_loss: 0.8310, value_loss: 0.4856
2024-07-11 17:33:17,635 [INFO    ] __main__: train step 19509: loss: 0.9211, policy_loss: 0.8310, value_loss: 0.4856
2024-07-11 17:33:17,868 [INFO    ] __main__: train step 19510: loss: 0.9211, policy_loss: 0.8310, value_loss: 0.4856
2024-07-11 17:33:18,080 [INFO    ] __main__: train step 19511: loss: 0.9211, policy_loss: 0.8310, value_loss: 0.4856
2024-07-11 17:33:18,319 [INFO    ] __main__: train step 19512: loss: 0.9211, policy_loss: 0.8310, value_loss: 0.4855
2024-07-11 17:33:18,524 [INFO    ] __main__: train step 19513: loss: 0.9211, policy_loss: 0.8310, value_loss: 0.4855
2024-07-11 17:33:18,733 [INFO    ] __main__: train step 19514: loss: 0.9210, policy_loss: 0.8310, value_loss: 0.4855
2024-07-11 17:33:18,944 [INFO    ] __main__: train step 19515: loss: 0.9210, policy_loss: 0.8310, value_loss: 0.4855
2024-07-11 17:33:20,383 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:33:20,795 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:33:20,850 [INFO    ] __main__: train step 19516: loss: 0.9210, policy_loss: 0.8310, value_loss: 0.4855
2024-07-11 17:33:21,026 [INFO    ] __main__: train step 19517: loss: 0.9210, policy_loss: 0.8310, value_loss: 0.4855
2024-07-11 17:33:21,244 [INFO    ] __main__: train step 19518: loss: 0.9210, policy_loss: 0.8310, value_loss: 0.4854
2024-07-11 17:33:21,449 [INFO    ] __main__: train step 19519: loss: 0.9210, policy_loss: 0.8309, value_loss: 0.4854
2024-07-11 17:33:21,647 [INFO    ] __main__: train step 19520: loss: 0.9210, policy_loss: 0.8309, value_loss: 0.4854
2024-07-11 17:33:21,851 [INFO    ] __main__: train step 19521: loss: 0.9210, policy_loss: 0.8309, value_loss: 0.4854
2024-07-11 17:33:22,061 [INFO    ] __main__: train step 19522: loss: 0.9210, policy_loss: 0.8309, value_loss: 0.4854
2024-07-11 17:33:22,269 [INFO    ] __main__: train step 19523: loss: 0.9210, policy_loss: 0.8309, value_loss: 0.4853
2024-07-11 17:33:22,468 [INFO    ] __main__: train step 19524: loss: 0.9210, policy_loss: 0.8309, value_loss: 0.4853
2024-07-11 17:33:22,675 [INFO    ] __main__: train step 19525: loss: 0.9210, policy_loss: 0.8309, value_loss: 0.4853
2024-07-11 17:33:22,886 [INFO    ] __main__: train step 19526: loss: 0.9210, policy_loss: 0.8309, value_loss: 0.4853
2024-07-11 17:33:23,083 [INFO    ] __main__: train step 19527: loss: 0.9210, policy_loss: 0.8309, value_loss: 0.4853
2024-07-11 17:33:23,282 [INFO    ] __main__: train step 19528: loss: 0.9210, policy_loss: 0.8309, value_loss: 0.4852
2024-07-11 17:33:23,485 [INFO    ] __main__: train step 19529: loss: 0.9209, policy_loss: 0.8309, value_loss: 0.4852
2024-07-11 17:33:23,710 [INFO    ] __main__: train step 19530: loss: 0.9209, policy_loss: 0.8308, value_loss: 0.4852
2024-07-11 17:33:23,950 [INFO    ] __main__: train step 19531: loss: 0.9209, policy_loss: 0.8308, value_loss: 0.4852
2024-07-11 17:33:24,152 [INFO    ] __main__: train step 19532: loss: 0.9209, policy_loss: 0.8308, value_loss: 0.4852
2024-07-11 17:33:25,599 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:33:26,003 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:33:26,058 [INFO    ] __main__: train step 19533: loss: 0.9209, policy_loss: 0.8308, value_loss: 0.4852
2024-07-11 17:33:26,228 [INFO    ] __main__: train step 19534: loss: 0.9209, policy_loss: 0.8308, value_loss: 0.4851
2024-07-11 17:33:26,450 [INFO    ] __main__: train step 19535: loss: 0.9209, policy_loss: 0.8308, value_loss: 0.4851
2024-07-11 17:33:26,668 [INFO    ] __main__: train step 19536: loss: 0.9209, policy_loss: 0.8308, value_loss: 0.4851
2024-07-11 17:33:26,928 [INFO    ] __main__: train step 19537: loss: 0.9209, policy_loss: 0.8308, value_loss: 0.4851
2024-07-11 17:33:27,182 [INFO    ] __main__: train step 19538: loss: 0.9209, policy_loss: 0.8308, value_loss: 0.4851
2024-07-11 17:33:27,392 [INFO    ] __main__: train step 19539: loss: 0.9209, policy_loss: 0.8308, value_loss: 0.4850
2024-07-11 17:33:27,634 [INFO    ] __main__: train step 19540: loss: 0.9209, policy_loss: 0.8308, value_loss: 0.4850
2024-07-11 17:33:27,842 [INFO    ] __main__: train step 19541: loss: 0.9209, policy_loss: 0.8308, value_loss: 0.4850
2024-07-11 17:33:28,045 [INFO    ] __main__: train step 19542: loss: 0.9209, policy_loss: 0.8307, value_loss: 0.4850
2024-07-11 17:33:28,259 [INFO    ] __main__: train step 19543: loss: 0.9208, policy_loss: 0.8307, value_loss: 0.4850
2024-07-11 17:33:28,491 [INFO    ] __main__: train step 19544: loss: 0.9208, policy_loss: 0.8307, value_loss: 0.4850
2024-07-11 17:33:28,689 [INFO    ] __main__: train step 19545: loss: 0.9208, policy_loss: 0.8307, value_loss: 0.4849
2024-07-11 17:33:28,886 [INFO    ] __main__: train step 19546: loss: 0.9208, policy_loss: 0.8307, value_loss: 0.4849
2024-07-11 17:33:29,099 [INFO    ] __main__: train step 19547: loss: 0.9208, policy_loss: 0.8307, value_loss: 0.4849
2024-07-11 17:33:29,301 [INFO    ] __main__: train step 19548: loss: 0.9208, policy_loss: 0.8307, value_loss: 0.4849
2024-07-11 17:33:29,513 [INFO    ] __main__: train step 19549: loss: 0.9208, policy_loss: 0.8307, value_loss: 0.4849
2024-07-11 17:33:30,959 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:33:31,382 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:33:31,449 [INFO    ] __main__: train step 19550: loss: 0.9208, policy_loss: 0.8307, value_loss: 0.4848
2024-07-11 17:33:31,627 [INFO    ] __main__: train step 19551: loss: 0.9208, policy_loss: 0.8307, value_loss: 0.4848
2024-07-11 17:33:31,826 [INFO    ] __main__: train step 19552: loss: 0.9208, policy_loss: 0.8307, value_loss: 0.4848
2024-07-11 17:33:32,029 [INFO    ] __main__: train step 19553: loss: 0.9208, policy_loss: 0.8307, value_loss: 0.4848
2024-07-11 17:33:32,232 [INFO    ] __main__: train step 19554: loss: 0.9208, policy_loss: 0.8306, value_loss: 0.4848
2024-07-11 17:33:32,451 [INFO    ] __main__: train step 19555: loss: 0.9208, policy_loss: 0.8306, value_loss: 0.4847
2024-07-11 17:33:32,641 [INFO    ] __main__: train step 19556: loss: 0.9208, policy_loss: 0.8306, value_loss: 0.4847
2024-07-11 17:33:32,862 [INFO    ] __main__: train step 19557: loss: 0.9208, policy_loss: 0.8306, value_loss: 0.4847
2024-07-11 17:33:33,062 [INFO    ] __main__: train step 19558: loss: 0.9207, policy_loss: 0.8306, value_loss: 0.4847
2024-07-11 17:33:33,273 [INFO    ] __main__: train step 19559: loss: 0.9207, policy_loss: 0.8306, value_loss: 0.4847
2024-07-11 17:33:33,472 [INFO    ] __main__: train step 19560: loss: 0.9207, policy_loss: 0.8306, value_loss: 0.4847
2024-07-11 17:33:33,678 [INFO    ] __main__: train step 19561: loss: 0.9207, policy_loss: 0.8306, value_loss: 0.4846
2024-07-11 17:33:33,882 [INFO    ] __main__: train step 19562: loss: 0.9207, policy_loss: 0.8306, value_loss: 0.4846
2024-07-11 17:33:34,085 [INFO    ] __main__: train step 19563: loss: 0.9207, policy_loss: 0.8306, value_loss: 0.4846
2024-07-11 17:33:34,280 [INFO    ] __main__: train step 19564: loss: 0.9207, policy_loss: 0.8306, value_loss: 0.4846
2024-07-11 17:33:34,484 [INFO    ] __main__: train step 19565: loss: 0.9207, policy_loss: 0.8305, value_loss: 0.4846
2024-07-11 17:33:34,689 [INFO    ] __main__: train step 19566: loss: 0.9207, policy_loss: 0.8305, value_loss: 0.4845
2024-07-11 17:33:36,129 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:33:36,518 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:33:36,577 [INFO    ] __main__: train step 19567: loss: 0.9207, policy_loss: 0.8305, value_loss: 0.4845
2024-07-11 17:33:36,753 [INFO    ] __main__: train step 19568: loss: 0.9207, policy_loss: 0.8305, value_loss: 0.4845
2024-07-11 17:33:36,960 [INFO    ] __main__: train step 19569: loss: 0.9207, policy_loss: 0.8305, value_loss: 0.4845
2024-07-11 17:33:37,167 [INFO    ] __main__: train step 19570: loss: 0.9207, policy_loss: 0.8305, value_loss: 0.4845
2024-07-11 17:33:37,364 [INFO    ] __main__: train step 19571: loss: 0.9207, policy_loss: 0.8305, value_loss: 0.4845
2024-07-11 17:33:37,567 [INFO    ] __main__: train step 19572: loss: 0.9206, policy_loss: 0.8305, value_loss: 0.4844
2024-07-11 17:33:37,776 [INFO    ] __main__: train step 19573: loss: 0.9206, policy_loss: 0.8305, value_loss: 0.4844
2024-07-11 17:33:37,969 [INFO    ] __main__: train step 19574: loss: 0.9206, policy_loss: 0.8305, value_loss: 0.4844
2024-07-11 17:33:38,185 [INFO    ] __main__: train step 19575: loss: 0.9206, policy_loss: 0.8305, value_loss: 0.4844
2024-07-11 17:33:38,379 [INFO    ] __main__: train step 19576: loss: 0.9206, policy_loss: 0.8305, value_loss: 0.4844
2024-07-11 17:33:38,588 [INFO    ] __main__: train step 19577: loss: 0.9206, policy_loss: 0.8304, value_loss: 0.4843
2024-07-11 17:33:38,798 [INFO    ] __main__: train step 19578: loss: 0.9206, policy_loss: 0.8304, value_loss: 0.4843
2024-07-11 17:33:38,997 [INFO    ] __main__: train step 19579: loss: 0.9206, policy_loss: 0.8304, value_loss: 0.4843
2024-07-11 17:33:39,210 [INFO    ] __main__: train step 19580: loss: 0.9206, policy_loss: 0.8304, value_loss: 0.4843
2024-07-11 17:33:39,425 [INFO    ] __main__: train step 19581: loss: 0.9206, policy_loss: 0.8304, value_loss: 0.4843
2024-07-11 17:33:39,655 [INFO    ] __main__: train step 19582: loss: 0.9206, policy_loss: 0.8304, value_loss: 0.4843
2024-07-11 17:33:39,862 [INFO    ] __main__: train step 19583: loss: 0.9206, policy_loss: 0.8304, value_loss: 0.4842
2024-07-11 17:33:41,316 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:33:41,715 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:33:41,769 [INFO    ] __main__: train step 19584: loss: 0.9206, policy_loss: 0.8304, value_loss: 0.4842
2024-07-11 17:33:41,950 [INFO    ] __main__: train step 19585: loss: 0.9206, policy_loss: 0.8304, value_loss: 0.4842
2024-07-11 17:33:42,142 [INFO    ] __main__: train step 19586: loss: 0.9206, policy_loss: 0.8304, value_loss: 0.4842
2024-07-11 17:33:44,047 [INFO    ] __main__: train step 19587: loss: 0.9206, policy_loss: 0.8304, value_loss: 0.4842
2024-07-11 17:33:44,260 [INFO    ] __main__: train step 19588: loss: 0.9205, policy_loss: 0.8304, value_loss: 0.4841
2024-07-11 17:33:44,470 [INFO    ] __main__: train step 19589: loss: 0.9205, policy_loss: 0.8303, value_loss: 0.4841
2024-07-11 17:33:44,687 [INFO    ] __main__: train step 19590: loss: 0.9205, policy_loss: 0.8303, value_loss: 0.4841
2024-07-11 17:33:44,937 [INFO    ] __main__: train step 19591: loss: 0.9205, policy_loss: 0.8303, value_loss: 0.4841
2024-07-11 17:33:45,169 [INFO    ] __main__: train step 19592: loss: 0.9205, policy_loss: 0.8303, value_loss: 0.4841
2024-07-11 17:33:45,403 [INFO    ] __main__: train step 19593: loss: 0.9205, policy_loss: 0.8303, value_loss: 0.4841
2024-07-11 17:33:45,622 [INFO    ] __main__: train step 19594: loss: 0.9205, policy_loss: 0.8303, value_loss: 0.4840
2024-07-11 17:33:45,855 [INFO    ] __main__: train step 19595: loss: 0.9205, policy_loss: 0.8303, value_loss: 0.4840
2024-07-11 17:33:46,097 [INFO    ] __main__: train step 19596: loss: 0.9205, policy_loss: 0.8303, value_loss: 0.4840
2024-07-11 17:33:46,309 [INFO    ] __main__: train step 19597: loss: 0.9205, policy_loss: 0.8303, value_loss: 0.4840
2024-07-11 17:33:46,529 [INFO    ] __main__: train step 19598: loss: 0.9205, policy_loss: 0.8303, value_loss: 0.4840
2024-07-11 17:33:46,732 [INFO    ] __main__: train step 19599: loss: 0.9205, policy_loss: 0.8303, value_loss: 0.4839
2024-07-11 17:33:46,933 [INFO    ] __main__: train step 19600: loss: 0.9205, policy_loss: 0.8303, value_loss: 0.4839
2024-07-11 17:33:48,374 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:33:48,779 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:33:48,834 [INFO    ] __main__: train step 19601: loss: 0.9205, policy_loss: 0.8303, value_loss: 0.4839
2024-07-11 17:33:49,017 [INFO    ] __main__: train step 19602: loss: 0.9205, policy_loss: 0.8302, value_loss: 0.4839
2024-07-11 17:33:49,217 [INFO    ] __main__: train step 19603: loss: 0.9205, policy_loss: 0.8302, value_loss: 0.4839
2024-07-11 17:33:49,423 [INFO    ] __main__: train step 19604: loss: 0.9204, policy_loss: 0.8302, value_loss: 0.4838
2024-07-11 17:33:49,658 [INFO    ] __main__: train step 19605: loss: 0.9204, policy_loss: 0.8302, value_loss: 0.4838
2024-07-11 17:33:49,875 [INFO    ] __main__: train step 19606: loss: 0.9204, policy_loss: 0.8302, value_loss: 0.4838
2024-07-11 17:33:50,075 [INFO    ] __main__: train step 19607: loss: 0.9204, policy_loss: 0.8302, value_loss: 0.4838
2024-07-11 17:33:50,279 [INFO    ] __main__: train step 19608: loss: 0.9204, policy_loss: 0.8302, value_loss: 0.4838
2024-07-11 17:33:50,493 [INFO    ] __main__: train step 19609: loss: 0.9204, policy_loss: 0.8302, value_loss: 0.4838
2024-07-11 17:33:50,698 [INFO    ] __main__: train step 19610: loss: 0.9204, policy_loss: 0.8302, value_loss: 0.4837
2024-07-11 17:33:50,906 [INFO    ] __main__: train step 19611: loss: 0.9204, policy_loss: 0.8302, value_loss: 0.4837
2024-07-11 17:33:51,119 [INFO    ] __main__: train step 19612: loss: 0.9204, policy_loss: 0.8302, value_loss: 0.4837
2024-07-11 17:33:51,331 [INFO    ] __main__: train step 19613: loss: 0.9204, policy_loss: 0.8302, value_loss: 0.4837
2024-07-11 17:33:51,567 [INFO    ] __main__: train step 19614: loss: 0.9204, policy_loss: 0.8302, value_loss: 0.4837
2024-07-11 17:33:51,768 [INFO    ] __main__: train step 19615: loss: 0.9204, policy_loss: 0.8301, value_loss: 0.4836
2024-07-11 17:33:51,973 [INFO    ] __main__: train step 19616: loss: 0.9204, policy_loss: 0.8301, value_loss: 0.4836
2024-07-11 17:33:52,180 [INFO    ] __main__: train step 19617: loss: 0.9204, policy_loss: 0.8301, value_loss: 0.4836
2024-07-11 17:33:53,609 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:33:54,004 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:33:54,059 [INFO    ] __main__: train step 19618: loss: 0.9204, policy_loss: 0.8301, value_loss: 0.4836
2024-07-11 17:33:54,239 [INFO    ] __main__: train step 19619: loss: 0.9204, policy_loss: 0.8301, value_loss: 0.4836
2024-07-11 17:33:54,456 [INFO    ] __main__: train step 19620: loss: 0.9204, policy_loss: 0.8301, value_loss: 0.4836
2024-07-11 17:33:54,682 [INFO    ] __main__: train step 19621: loss: 0.9203, policy_loss: 0.8301, value_loss: 0.4835
2024-07-11 17:33:54,889 [INFO    ] __main__: train step 19622: loss: 0.9203, policy_loss: 0.8301, value_loss: 0.4835
2024-07-11 17:33:55,097 [INFO    ] __main__: train step 19623: loss: 0.9203, policy_loss: 0.8301, value_loss: 0.4835
2024-07-11 17:33:55,319 [INFO    ] __main__: train step 19624: loss: 0.9203, policy_loss: 0.8301, value_loss: 0.4835
2024-07-11 17:33:55,543 [INFO    ] __main__: train step 19625: loss: 0.9203, policy_loss: 0.8301, value_loss: 0.4835
2024-07-11 17:33:55,745 [INFO    ] __main__: train step 19626: loss: 0.9203, policy_loss: 0.8301, value_loss: 0.4834
2024-07-11 17:33:55,955 [INFO    ] __main__: train step 19627: loss: 0.9203, policy_loss: 0.8301, value_loss: 0.4834
2024-07-11 17:33:56,187 [INFO    ] __main__: train step 19628: loss: 0.9203, policy_loss: 0.8300, value_loss: 0.4834
2024-07-11 17:33:56,392 [INFO    ] __main__: train step 19629: loss: 0.9203, policy_loss: 0.8300, value_loss: 0.4834
2024-07-11 17:33:56,610 [INFO    ] __main__: train step 19630: loss: 0.9203, policy_loss: 0.8300, value_loss: 0.4834
2024-07-11 17:33:56,849 [INFO    ] __main__: train step 19631: loss: 0.9203, policy_loss: 0.8300, value_loss: 0.4834
2024-07-11 17:33:57,099 [INFO    ] __main__: train step 19632: loss: 0.9203, policy_loss: 0.8300, value_loss: 0.4833
2024-07-11 17:33:57,341 [INFO    ] __main__: train step 19633: loss: 0.9203, policy_loss: 0.8300, value_loss: 0.4833
2024-07-11 17:33:57,547 [INFO    ] __main__: train step 19634: loss: 0.9203, policy_loss: 0.8300, value_loss: 0.4833
2024-07-11 17:33:58,979 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:33:59,398 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:33:59,463 [INFO    ] __main__: train step 19635: loss: 0.9203, policy_loss: 0.8300, value_loss: 0.4833
2024-07-11 17:33:59,657 [INFO    ] __main__: train step 19636: loss: 0.9203, policy_loss: 0.8300, value_loss: 0.4833
2024-07-11 17:33:59,889 [INFO    ] __main__: train step 19637: loss: 0.9203, policy_loss: 0.8300, value_loss: 0.4832
2024-07-11 17:34:00,095 [INFO    ] __main__: train step 19638: loss: 0.9202, policy_loss: 0.8300, value_loss: 0.4832
2024-07-11 17:34:00,318 [INFO    ] __main__: train step 19639: loss: 0.9202, policy_loss: 0.8300, value_loss: 0.4832
2024-07-11 17:34:00,545 [INFO    ] __main__: train step 19640: loss: 0.9202, policy_loss: 0.8300, value_loss: 0.4832
2024-07-11 17:34:00,748 [INFO    ] __main__: train step 19641: loss: 0.9202, policy_loss: 0.8299, value_loss: 0.4832
2024-07-11 17:34:00,956 [INFO    ] __main__: train step 19642: loss: 0.9202, policy_loss: 0.8299, value_loss: 0.4832
2024-07-11 17:34:01,166 [INFO    ] __main__: train step 19643: loss: 0.9202, policy_loss: 0.8299, value_loss: 0.4831
2024-07-11 17:34:01,376 [INFO    ] __main__: train step 19644: loss: 0.9202, policy_loss: 0.8299, value_loss: 0.4831
2024-07-11 17:34:01,599 [INFO    ] __main__: train step 19645: loss: 0.9202, policy_loss: 0.8299, value_loss: 0.4831
2024-07-11 17:34:01,799 [INFO    ] __main__: train step 19646: loss: 0.9202, policy_loss: 0.8299, value_loss: 0.4831
2024-07-11 17:34:02,011 [INFO    ] __main__: train step 19647: loss: 0.9202, policy_loss: 0.8299, value_loss: 0.4831
2024-07-11 17:34:02,208 [INFO    ] __main__: train step 19648: loss: 0.9202, policy_loss: 0.8299, value_loss: 0.4830
2024-07-11 17:34:02,421 [INFO    ] __main__: train step 19649: loss: 0.9202, policy_loss: 0.8299, value_loss: 0.4830
2024-07-11 17:34:02,643 [INFO    ] __main__: train step 19650: loss: 0.9202, policy_loss: 0.8299, value_loss: 0.4830
2024-07-11 17:34:02,891 [INFO    ] __main__: train step 19651: loss: 0.9202, policy_loss: 0.8299, value_loss: 0.4830
2024-07-11 17:34:04,359 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:34:04,747 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:34:04,808 [INFO    ] __main__: train step 19652: loss: 0.9202, policy_loss: 0.8299, value_loss: 0.4830
2024-07-11 17:34:04,993 [INFO    ] __main__: train step 19653: loss: 0.9202, policy_loss: 0.8299, value_loss: 0.4830
2024-07-11 17:34:05,211 [INFO    ] __main__: train step 19654: loss: 0.9202, policy_loss: 0.8299, value_loss: 0.4829
2024-07-11 17:34:05,410 [INFO    ] __main__: train step 19655: loss: 0.9202, policy_loss: 0.8298, value_loss: 0.4829
2024-07-11 17:34:05,638 [INFO    ] __main__: train step 19656: loss: 0.9201, policy_loss: 0.8298, value_loss: 0.4829
2024-07-11 17:34:05,881 [INFO    ] __main__: train step 19657: loss: 0.9201, policy_loss: 0.8298, value_loss: 0.4829
2024-07-11 17:34:06,093 [INFO    ] __main__: train step 19658: loss: 0.9201, policy_loss: 0.8298, value_loss: 0.4829
2024-07-11 17:34:06,337 [INFO    ] __main__: train step 19659: loss: 0.9201, policy_loss: 0.8298, value_loss: 0.4828
2024-07-11 17:34:06,555 [INFO    ] __main__: train step 19660: loss: 0.9201, policy_loss: 0.8298, value_loss: 0.4828
2024-07-11 17:34:06,751 [INFO    ] __main__: train step 19661: loss: 0.9201, policy_loss: 0.8298, value_loss: 0.4828
2024-07-11 17:34:06,954 [INFO    ] __main__: train step 19662: loss: 0.9201, policy_loss: 0.8298, value_loss: 0.4828
2024-07-11 17:34:07,155 [INFO    ] __main__: train step 19663: loss: 0.9201, policy_loss: 0.8298, value_loss: 0.4828
2024-07-11 17:34:07,362 [INFO    ] __main__: train step 19664: loss: 0.9201, policy_loss: 0.8298, value_loss: 0.4828
2024-07-11 17:34:07,582 [INFO    ] __main__: train step 19665: loss: 0.9201, policy_loss: 0.8298, value_loss: 0.4827
2024-07-11 17:34:07,775 [INFO    ] __main__: train step 19666: loss: 0.9201, policy_loss: 0.8298, value_loss: 0.4827
2024-07-11 17:34:07,992 [INFO    ] __main__: train step 19667: loss: 0.9201, policy_loss: 0.8298, value_loss: 0.4827
2024-07-11 17:34:08,202 [INFO    ] __main__: train step 19668: loss: 0.9201, policy_loss: 0.8298, value_loss: 0.4827
2024-07-11 17:34:09,644 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:34:10,028 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:34:10,084 [INFO    ] __main__: train step 19669: loss: 0.9201, policy_loss: 0.8297, value_loss: 0.4827
2024-07-11 17:34:10,265 [INFO    ] __main__: train step 19670: loss: 0.9201, policy_loss: 0.8297, value_loss: 0.4826
2024-07-11 17:34:10,456 [INFO    ] __main__: train step 19671: loss: 0.9201, policy_loss: 0.8297, value_loss: 0.4826
2024-07-11 17:34:10,654 [INFO    ] __main__: train step 19672: loss: 0.9201, policy_loss: 0.8297, value_loss: 0.4826
2024-07-11 17:34:10,871 [INFO    ] __main__: train step 19673: loss: 0.9201, policy_loss: 0.8297, value_loss: 0.4826
2024-07-11 17:34:11,078 [INFO    ] __main__: train step 19674: loss: 0.9201, policy_loss: 0.8297, value_loss: 0.4826
2024-07-11 17:34:11,278 [INFO    ] __main__: train step 19675: loss: 0.9201, policy_loss: 0.8297, value_loss: 0.4826
2024-07-11 17:34:11,494 [INFO    ] __main__: train step 19676: loss: 0.9200, policy_loss: 0.8297, value_loss: 0.4825
2024-07-11 17:34:11,726 [INFO    ] __main__: train step 19677: loss: 0.9200, policy_loss: 0.8297, value_loss: 0.4825
2024-07-11 17:34:11,932 [INFO    ] __main__: train step 19678: loss: 0.9200, policy_loss: 0.8297, value_loss: 0.4825
2024-07-11 17:34:12,140 [INFO    ] __main__: train step 19679: loss: 0.9200, policy_loss: 0.8297, value_loss: 0.4825
2024-07-11 17:34:12,354 [INFO    ] __main__: train step 19680: loss: 0.9200, policy_loss: 0.8297, value_loss: 0.4825
2024-07-11 17:34:12,583 [INFO    ] __main__: train step 19681: loss: 0.9200, policy_loss: 0.8297, value_loss: 0.4824
2024-07-11 17:34:12,783 [INFO    ] __main__: train step 19682: loss: 0.9200, policy_loss: 0.8297, value_loss: 0.4824
2024-07-11 17:34:12,978 [INFO    ] __main__: train step 19683: loss: 0.9200, policy_loss: 0.8296, value_loss: 0.4824
2024-07-11 17:34:13,183 [INFO    ] __main__: train step 19684: loss: 0.9200, policy_loss: 0.8296, value_loss: 0.4824
2024-07-11 17:34:13,383 [INFO    ] __main__: train step 19685: loss: 0.9200, policy_loss: 0.8296, value_loss: 0.4824
2024-07-11 17:34:14,808 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:34:15,223 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:34:15,285 [INFO    ] __main__: train step 19686: loss: 0.9200, policy_loss: 0.8296, value_loss: 0.4824
2024-07-11 17:34:15,461 [INFO    ] __main__: train step 19687: loss: 0.9200, policy_loss: 0.8296, value_loss: 0.4823
2024-07-11 17:34:15,674 [INFO    ] __main__: train step 19688: loss: 0.9200, policy_loss: 0.8296, value_loss: 0.4823
2024-07-11 17:34:15,880 [INFO    ] __main__: train step 19689: loss: 0.9200, policy_loss: 0.8296, value_loss: 0.4823
2024-07-11 17:34:16,083 [INFO    ] __main__: train step 19690: loss: 0.9200, policy_loss: 0.8296, value_loss: 0.4823
2024-07-11 17:34:16,293 [INFO    ] __main__: train step 19691: loss: 0.9200, policy_loss: 0.8296, value_loss: 0.4823
2024-07-11 17:34:16,498 [INFO    ] __main__: train step 19692: loss: 0.9200, policy_loss: 0.8296, value_loss: 0.4823
2024-07-11 17:34:16,697 [INFO    ] __main__: train step 19693: loss: 0.9200, policy_loss: 0.8296, value_loss: 0.4822
2024-07-11 17:34:16,904 [INFO    ] __main__: train step 19694: loss: 0.9199, policy_loss: 0.8296, value_loss: 0.4822
2024-07-11 17:34:17,119 [INFO    ] __main__: train step 19695: loss: 0.9199, policy_loss: 0.8296, value_loss: 0.4822
2024-07-11 17:34:17,330 [INFO    ] __main__: train step 19696: loss: 0.9199, policy_loss: 0.8296, value_loss: 0.4822
2024-07-11 17:34:17,550 [INFO    ] __main__: train step 19697: loss: 0.9199, policy_loss: 0.8295, value_loss: 0.4822
2024-07-11 17:34:17,748 [INFO    ] __main__: train step 19698: loss: 0.9199, policy_loss: 0.8295, value_loss: 0.4821
2024-07-11 17:34:17,961 [INFO    ] __main__: train step 19699: loss: 0.9199, policy_loss: 0.8295, value_loss: 0.4821
2024-07-11 17:34:18,177 [INFO    ] __main__: train step 19700: loss: 0.9199, policy_loss: 0.8295, value_loss: 0.4821
2024-07-11 17:34:18,425 [INFO    ] __main__: train step 19701: loss: 0.9199, policy_loss: 0.8295, value_loss: 0.4821
2024-07-11 17:34:18,659 [INFO    ] __main__: train step 19702: loss: 0.9199, policy_loss: 0.8295, value_loss: 0.4821
2024-07-11 17:34:20,087 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:34:20,470 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:34:20,526 [INFO    ] __main__: train step 19703: loss: 0.9199, policy_loss: 0.8295, value_loss: 0.4820
2024-07-11 17:34:22,461 [INFO    ] __main__: train step 19704: loss: 0.9199, policy_loss: 0.8295, value_loss: 0.4820
2024-07-11 17:34:22,695 [INFO    ] __main__: train step 19705: loss: 0.9199, policy_loss: 0.8295, value_loss: 0.4820
2024-07-11 17:34:22,900 [INFO    ] __main__: train step 19706: loss: 0.9199, policy_loss: 0.8295, value_loss: 0.4820
2024-07-11 17:34:23,104 [INFO    ] __main__: train step 19707: loss: 0.9199, policy_loss: 0.8295, value_loss: 0.4820
2024-07-11 17:34:23,309 [INFO    ] __main__: train step 19708: loss: 0.9199, policy_loss: 0.8295, value_loss: 0.4820
2024-07-11 17:34:23,512 [INFO    ] __main__: train step 19709: loss: 0.9199, policy_loss: 0.8295, value_loss: 0.4819
2024-07-11 17:34:23,734 [INFO    ] __main__: train step 19710: loss: 0.9199, policy_loss: 0.8295, value_loss: 0.4819
2024-07-11 17:34:23,968 [INFO    ] __main__: train step 19711: loss: 0.9199, policy_loss: 0.8294, value_loss: 0.4819
2024-07-11 17:34:24,184 [INFO    ] __main__: train step 19712: loss: 0.9199, policy_loss: 0.8294, value_loss: 0.4819
2024-07-11 17:34:24,428 [INFO    ] __main__: train step 19713: loss: 0.9199, policy_loss: 0.8294, value_loss: 0.4819
2024-07-11 17:34:24,653 [INFO    ] __main__: train step 19714: loss: 0.9198, policy_loss: 0.8294, value_loss: 0.4819
2024-07-11 17:34:24,858 [INFO    ] __main__: train step 19715: loss: 0.9198, policy_loss: 0.8294, value_loss: 0.4818
2024-07-11 17:34:25,078 [INFO    ] __main__: train step 19716: loss: 0.9198, policy_loss: 0.8294, value_loss: 0.4818
2024-07-11 17:34:25,285 [INFO    ] __main__: train step 19717: loss: 0.9198, policy_loss: 0.8294, value_loss: 0.4818
2024-07-11 17:34:25,485 [INFO    ] __main__: train step 19718: loss: 0.9198, policy_loss: 0.8294, value_loss: 0.4818
2024-07-11 17:34:25,690 [INFO    ] __main__: train step 19719: loss: 0.9198, policy_loss: 0.8294, value_loss: 0.4818
2024-07-11 17:34:27,145 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:34:27,528 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:34:27,583 [INFO    ] __main__: train step 19720: loss: 0.9198, policy_loss: 0.8294, value_loss: 0.4817
2024-07-11 17:34:27,769 [INFO    ] __main__: train step 19721: loss: 0.9198, policy_loss: 0.8294, value_loss: 0.4817
2024-07-11 17:34:27,973 [INFO    ] __main__: train step 19722: loss: 0.9198, policy_loss: 0.8294, value_loss: 0.4817
2024-07-11 17:34:28,178 [INFO    ] __main__: train step 19723: loss: 0.9198, policy_loss: 0.8294, value_loss: 0.4817
2024-07-11 17:34:28,393 [INFO    ] __main__: train step 19724: loss: 0.9198, policy_loss: 0.8294, value_loss: 0.4817
2024-07-11 17:34:28,602 [INFO    ] __main__: train step 19725: loss: 0.9198, policy_loss: 0.8294, value_loss: 0.4817
2024-07-11 17:34:28,809 [INFO    ] __main__: train step 19726: loss: 0.9198, policy_loss: 0.8294, value_loss: 0.4816
2024-07-11 17:34:29,010 [INFO    ] __main__: train step 19727: loss: 0.9198, policy_loss: 0.8293, value_loss: 0.4816
2024-07-11 17:34:29,224 [INFO    ] __main__: train step 19728: loss: 0.9198, policy_loss: 0.8293, value_loss: 0.4816
2024-07-11 17:34:29,430 [INFO    ] __main__: train step 19729: loss: 0.9198, policy_loss: 0.8293, value_loss: 0.4816
2024-07-11 17:34:29,647 [INFO    ] __main__: train step 19730: loss: 0.9198, policy_loss: 0.8293, value_loss: 0.4816
2024-07-11 17:34:29,864 [INFO    ] __main__: train step 19731: loss: 0.9198, policy_loss: 0.8293, value_loss: 0.4815
2024-07-11 17:34:30,065 [INFO    ] __main__: train step 19732: loss: 0.9198, policy_loss: 0.8293, value_loss: 0.4815
2024-07-11 17:34:30,277 [INFO    ] __main__: train step 19733: loss: 0.9198, policy_loss: 0.8293, value_loss: 0.4815
2024-07-11 17:34:30,489 [INFO    ] __main__: train step 19734: loss: 0.9198, policy_loss: 0.8293, value_loss: 0.4815
2024-07-11 17:34:30,689 [INFO    ] __main__: train step 19735: loss: 0.9198, policy_loss: 0.8293, value_loss: 0.4815
2024-07-11 17:34:30,910 [INFO    ] __main__: train step 19736: loss: 0.9197, policy_loss: 0.8293, value_loss: 0.4815
2024-07-11 17:34:32,337 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:34:32,771 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:34:32,827 [INFO    ] __main__: train step 19737: loss: 0.9197, policy_loss: 0.8293, value_loss: 0.4814
2024-07-11 17:34:33,010 [INFO    ] __main__: train step 19738: loss: 0.9197, policy_loss: 0.8293, value_loss: 0.4814
2024-07-11 17:34:33,216 [INFO    ] __main__: train step 19739: loss: 0.9197, policy_loss: 0.8293, value_loss: 0.4814
2024-07-11 17:34:33,419 [INFO    ] __main__: train step 19740: loss: 0.9197, policy_loss: 0.8293, value_loss: 0.4814
2024-07-11 17:34:33,622 [INFO    ] __main__: train step 19741: loss: 0.9197, policy_loss: 0.8293, value_loss: 0.4814
2024-07-11 17:34:33,823 [INFO    ] __main__: train step 19742: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4814
2024-07-11 17:34:34,037 [INFO    ] __main__: train step 19743: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4813
2024-07-11 17:34:34,235 [INFO    ] __main__: train step 19744: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4813
2024-07-11 17:34:34,454 [INFO    ] __main__: train step 19745: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4813
2024-07-11 17:34:34,683 [INFO    ] __main__: train step 19746: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4813
2024-07-11 17:34:34,888 [INFO    ] __main__: train step 19747: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4813
2024-07-11 17:34:35,097 [INFO    ] __main__: train step 19748: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4812
2024-07-11 17:34:35,311 [INFO    ] __main__: train step 19749: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4812
2024-07-11 17:34:35,544 [INFO    ] __main__: train step 19750: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4812
2024-07-11 17:34:35,752 [INFO    ] __main__: train step 19751: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4812
2024-07-11 17:34:35,958 [INFO    ] __main__: train step 19752: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4812
2024-07-11 17:34:36,172 [INFO    ] __main__: train step 19753: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4812
2024-07-11 17:34:37,624 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:34:38,042 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:34:38,104 [INFO    ] __main__: train step 19754: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4811
2024-07-11 17:34:38,277 [INFO    ] __main__: train step 19755: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4811
2024-07-11 17:34:38,484 [INFO    ] __main__: train step 19756: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4811
2024-07-11 17:34:38,687 [INFO    ] __main__: train step 19757: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4811
2024-07-11 17:34:38,906 [INFO    ] __main__: train step 19758: loss: 0.9197, policy_loss: 0.8292, value_loss: 0.4811
2024-07-11 17:34:39,102 [INFO    ] __main__: train step 19759: loss: 0.9197, policy_loss: 0.8291, value_loss: 0.4810
2024-07-11 17:34:39,349 [INFO    ] __main__: train step 19760: loss: 0.9197, policy_loss: 0.8291, value_loss: 0.4810
2024-07-11 17:34:39,572 [INFO    ] __main__: train step 19761: loss: 0.9196, policy_loss: 0.8291, value_loss: 0.4810
2024-07-11 17:34:39,786 [INFO    ] __main__: train step 19762: loss: 0.9196, policy_loss: 0.8291, value_loss: 0.4810
2024-07-11 17:34:40,003 [INFO    ] __main__: train step 19763: loss: 0.9196, policy_loss: 0.8291, value_loss: 0.4810
2024-07-11 17:34:40,205 [INFO    ] __main__: train step 19764: loss: 0.9196, policy_loss: 0.8291, value_loss: 0.4810
2024-07-11 17:34:40,435 [INFO    ] __main__: train step 19765: loss: 0.9196, policy_loss: 0.8291, value_loss: 0.4809
2024-07-11 17:34:40,647 [INFO    ] __main__: train step 19766: loss: 0.9196, policy_loss: 0.8291, value_loss: 0.4809
2024-07-11 17:34:40,855 [INFO    ] __main__: train step 19767: loss: 0.9196, policy_loss: 0.8291, value_loss: 0.4809
2024-07-11 17:34:41,087 [INFO    ] __main__: train step 19768: loss: 0.9196, policy_loss: 0.8291, value_loss: 0.4809
2024-07-11 17:34:41,294 [INFO    ] __main__: train step 19769: loss: 0.9196, policy_loss: 0.8291, value_loss: 0.4809
2024-07-11 17:34:41,500 [INFO    ] __main__: train step 19770: loss: 0.9196, policy_loss: 0.8291, value_loss: 0.4809
2024-07-11 17:34:42,934 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:34:43,286 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:34:43,341 [INFO    ] __main__: train step 19771: loss: 0.9196, policy_loss: 0.8291, value_loss: 0.4808
2024-07-11 17:34:43,525 [INFO    ] __main__: train step 19772: loss: 0.9196, policy_loss: 0.8291, value_loss: 0.4808
2024-07-11 17:34:43,733 [INFO    ] __main__: train step 19773: loss: 0.9196, policy_loss: 0.8291, value_loss: 0.4808
2024-07-11 17:34:43,944 [INFO    ] __main__: train step 19774: loss: 0.9196, policy_loss: 0.8291, value_loss: 0.4808
2024-07-11 17:34:44,142 [INFO    ] __main__: train step 19775: loss: 0.9196, policy_loss: 0.8291, value_loss: 0.4808
2024-07-11 17:34:44,354 [INFO    ] __main__: train step 19776: loss: 0.9196, policy_loss: 0.8290, value_loss: 0.4807
2024-07-11 17:34:44,554 [INFO    ] __main__: train step 19777: loss: 0.9196, policy_loss: 0.8290, value_loss: 0.4807
2024-07-11 17:34:44,766 [INFO    ] __main__: train step 19778: loss: 0.9196, policy_loss: 0.8290, value_loss: 0.4807
2024-07-11 17:34:44,972 [INFO    ] __main__: train step 19779: loss: 0.9196, policy_loss: 0.8290, value_loss: 0.4807
2024-07-11 17:34:45,172 [INFO    ] __main__: train step 19780: loss: 0.9196, policy_loss: 0.8290, value_loss: 0.4807
2024-07-11 17:34:45,383 [INFO    ] __main__: train step 19781: loss: 0.9196, policy_loss: 0.8290, value_loss: 0.4807
2024-07-11 17:34:45,635 [INFO    ] __main__: train step 19782: loss: 0.9196, policy_loss: 0.8290, value_loss: 0.4806
2024-07-11 17:34:45,839 [INFO    ] __main__: train step 19783: loss: 0.9196, policy_loss: 0.8290, value_loss: 0.4806
2024-07-11 17:34:46,061 [INFO    ] __main__: train step 19784: loss: 0.9196, policy_loss: 0.8290, value_loss: 0.4806
2024-07-11 17:34:46,259 [INFO    ] __main__: train step 19785: loss: 0.9196, policy_loss: 0.8290, value_loss: 0.4806
2024-07-11 17:34:46,452 [INFO    ] __main__: train step 19786: loss: 0.9195, policy_loss: 0.8290, value_loss: 0.4806
2024-07-11 17:34:46,666 [INFO    ] __main__: train step 19787: loss: 0.9195, policy_loss: 0.8290, value_loss: 0.4806
2024-07-11 17:34:48,105 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:34:48,506 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:34:48,561 [INFO    ] __main__: train step 19788: loss: 0.9195, policy_loss: 0.8290, value_loss: 0.4805
2024-07-11 17:34:48,748 [INFO    ] __main__: train step 19789: loss: 0.9195, policy_loss: 0.8290, value_loss: 0.4805
2024-07-11 17:34:48,954 [INFO    ] __main__: train step 19790: loss: 0.9195, policy_loss: 0.8290, value_loss: 0.4805
2024-07-11 17:34:49,166 [INFO    ] __main__: train step 19791: loss: 0.9195, policy_loss: 0.8290, value_loss: 0.4805
2024-07-11 17:34:49,386 [INFO    ] __main__: train step 19792: loss: 0.9195, policy_loss: 0.8290, value_loss: 0.4805
2024-07-11 17:34:49,630 [INFO    ] __main__: train step 19793: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4804
2024-07-11 17:34:49,830 [INFO    ] __main__: train step 19794: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4804
2024-07-11 17:34:50,030 [INFO    ] __main__: train step 19795: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4804
2024-07-11 17:34:50,239 [INFO    ] __main__: train step 19796: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4804
2024-07-11 17:34:50,473 [INFO    ] __main__: train step 19797: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4804
2024-07-11 17:34:50,677 [INFO    ] __main__: train step 19798: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4804
2024-07-11 17:34:50,883 [INFO    ] __main__: train step 19799: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4803
2024-07-11 17:34:51,087 [INFO    ] __main__: train step 19800: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4803
2024-07-11 17:34:51,306 [INFO    ] __main__: train step 19801: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4803
2024-07-11 17:34:51,523 [INFO    ] __main__: train step 19802: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4803
2024-07-11 17:34:51,746 [INFO    ] __main__: train step 19803: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4803
2024-07-11 17:34:51,947 [INFO    ] __main__: train step 19804: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4803
2024-07-11 17:34:53,375 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:34:53,778 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:34:53,837 [INFO    ] __main__: train step 19805: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4802
2024-07-11 17:34:54,015 [INFO    ] __main__: train step 19806: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4802
2024-07-11 17:34:54,224 [INFO    ] __main__: train step 19807: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4802
2024-07-11 17:34:54,450 [INFO    ] __main__: train step 19808: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4802
2024-07-11 17:34:54,642 [INFO    ] __main__: train step 19809: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4802
2024-07-11 17:34:54,849 [INFO    ] __main__: train step 19810: loss: 0.9195, policy_loss: 0.8289, value_loss: 0.4801
2024-07-11 17:34:55,054 [INFO    ] __main__: train step 19811: loss: 0.9195, policy_loss: 0.8288, value_loss: 0.4801
2024-07-11 17:34:55,278 [INFO    ] __main__: train step 19812: loss: 0.9195, policy_loss: 0.8288, value_loss: 0.4801
2024-07-11 17:34:55,493 [INFO    ] __main__: train step 19813: loss: 0.9195, policy_loss: 0.8288, value_loss: 0.4801
2024-07-11 17:34:55,682 [INFO    ] __main__: train step 19814: loss: 0.9195, policy_loss: 0.8288, value_loss: 0.4801
2024-07-11 17:34:55,885 [INFO    ] __main__: train step 19815: loss: 0.9194, policy_loss: 0.8288, value_loss: 0.4801
2024-07-11 17:34:56,090 [INFO    ] __main__: train step 19816: loss: 0.9194, policy_loss: 0.8288, value_loss: 0.4800
2024-07-11 17:34:56,292 [INFO    ] __main__: train step 19817: loss: 0.9194, policy_loss: 0.8288, value_loss: 0.4800
2024-07-11 17:34:56,496 [INFO    ] __main__: train step 19818: loss: 0.9194, policy_loss: 0.8288, value_loss: 0.4800
2024-07-11 17:34:58,404 [INFO    ] __main__: train step 19819: loss: 0.9194, policy_loss: 0.8288, value_loss: 0.4800
2024-07-11 17:34:58,583 [INFO    ] __main__: train step 19820: loss: 0.9194, policy_loss: 0.8288, value_loss: 0.4800
2024-07-11 17:34:58,782 [INFO    ] __main__: train step 19821: loss: 0.9194, policy_loss: 0.8288, value_loss: 0.4800
2024-07-11 17:35:00,237 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:35:00,600 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:35:00,657 [INFO    ] __main__: train step 19822: loss: 0.9194, policy_loss: 0.8288, value_loss: 0.4799
2024-07-11 17:35:00,844 [INFO    ] __main__: train step 19823: loss: 0.9194, policy_loss: 0.8288, value_loss: 0.4799
2024-07-11 17:35:01,050 [INFO    ] __main__: train step 19824: loss: 0.9194, policy_loss: 0.8288, value_loss: 0.4799
2024-07-11 17:35:01,247 [INFO    ] __main__: train step 19825: loss: 0.9194, policy_loss: 0.8288, value_loss: 0.4799
2024-07-11 17:35:01,458 [INFO    ] __main__: train step 19826: loss: 0.9194, policy_loss: 0.8288, value_loss: 0.4799
2024-07-11 17:35:01,671 [INFO    ] __main__: train step 19827: loss: 0.9194, policy_loss: 0.8288, value_loss: 0.4798
2024-07-11 17:35:01,875 [INFO    ] __main__: train step 19828: loss: 0.9194, policy_loss: 0.8288, value_loss: 0.4798
2024-07-11 17:35:02,078 [INFO    ] __main__: train step 19829: loss: 0.9194, policy_loss: 0.8287, value_loss: 0.4798
2024-07-11 17:35:02,286 [INFO    ] __main__: train step 19830: loss: 0.9194, policy_loss: 0.8287, value_loss: 0.4798
2024-07-11 17:35:02,518 [INFO    ] __main__: train step 19831: loss: 0.9194, policy_loss: 0.8287, value_loss: 0.4798
2024-07-11 17:35:02,732 [INFO    ] __main__: train step 19832: loss: 0.9194, policy_loss: 0.8287, value_loss: 0.4798
2024-07-11 17:35:02,939 [INFO    ] __main__: train step 19833: loss: 0.9194, policy_loss: 0.8287, value_loss: 0.4797
2024-07-11 17:35:03,140 [INFO    ] __main__: train step 19834: loss: 0.9194, policy_loss: 0.8287, value_loss: 0.4797
2024-07-11 17:35:03,336 [INFO    ] __main__: train step 19835: loss: 0.9194, policy_loss: 0.8287, value_loss: 0.4797
2024-07-11 17:35:03,558 [INFO    ] __main__: train step 19836: loss: 0.9194, policy_loss: 0.8287, value_loss: 0.4797
2024-07-11 17:35:03,759 [INFO    ] __main__: train step 19837: loss: 0.9194, policy_loss: 0.8287, value_loss: 0.4797
2024-07-11 17:35:03,971 [INFO    ] __main__: train step 19838: loss: 0.9194, policy_loss: 0.8287, value_loss: 0.4797
2024-07-11 17:35:05,419 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:35:05,802 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:35:05,861 [INFO    ] __main__: train step 19839: loss: 0.9194, policy_loss: 0.8287, value_loss: 0.4796
2024-07-11 17:35:06,050 [INFO    ] __main__: train step 19840: loss: 0.9194, policy_loss: 0.8287, value_loss: 0.4796
2024-07-11 17:35:06,256 [INFO    ] __main__: train step 19841: loss: 0.9194, policy_loss: 0.8287, value_loss: 0.4796
2024-07-11 17:35:06,459 [INFO    ] __main__: train step 19842: loss: 0.9194, policy_loss: 0.8287, value_loss: 0.4796
2024-07-11 17:35:06,675 [INFO    ] __main__: train step 19843: loss: 0.9193, policy_loss: 0.8287, value_loss: 0.4796
2024-07-11 17:35:06,886 [INFO    ] __main__: train step 19844: loss: 0.9193, policy_loss: 0.8287, value_loss: 0.4795
2024-07-11 17:35:07,095 [INFO    ] __main__: train step 19845: loss: 0.9193, policy_loss: 0.8287, value_loss: 0.4795
2024-07-11 17:35:07,346 [INFO    ] __main__: train step 19846: loss: 0.9193, policy_loss: 0.8287, value_loss: 0.4795
2024-07-11 17:35:07,577 [INFO    ] __main__: train step 19847: loss: 0.9193, policy_loss: 0.8287, value_loss: 0.4795
2024-07-11 17:35:07,827 [INFO    ] __main__: train step 19848: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4795
2024-07-11 17:35:08,022 [INFO    ] __main__: train step 19849: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4795
2024-07-11 17:35:08,223 [INFO    ] __main__: train step 19850: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4794
2024-07-11 17:35:08,423 [INFO    ] __main__: train step 19851: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4794
2024-07-11 17:35:08,640 [INFO    ] __main__: train step 19852: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4794
2024-07-11 17:35:08,844 [INFO    ] __main__: train step 19853: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4794
2024-07-11 17:35:09,066 [INFO    ] __main__: train step 19854: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4794
2024-07-11 17:35:09,300 [INFO    ] __main__: train step 19855: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4794
2024-07-11 17:35:10,745 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:35:11,110 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:35:11,169 [INFO    ] __main__: train step 19856: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4793
2024-07-11 17:35:11,361 [INFO    ] __main__: train step 19857: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4793
2024-07-11 17:35:11,604 [INFO    ] __main__: train step 19858: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4793
2024-07-11 17:35:11,818 [INFO    ] __main__: train step 19859: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4793
2024-07-11 17:35:12,031 [INFO    ] __main__: train step 19860: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4793
2024-07-11 17:35:12,272 [INFO    ] __main__: train step 19861: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4792
2024-07-11 17:35:12,498 [INFO    ] __main__: train step 19862: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4792
2024-07-11 17:35:12,702 [INFO    ] __main__: train step 19863: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4792
2024-07-11 17:35:12,901 [INFO    ] __main__: train step 19864: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4792
2024-07-11 17:35:13,111 [INFO    ] __main__: train step 19865: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4792
2024-07-11 17:35:13,310 [INFO    ] __main__: train step 19866: loss: 0.9193, policy_loss: 0.8286, value_loss: 0.4792
2024-07-11 17:35:13,515 [INFO    ] __main__: train step 19867: loss: 0.9193, policy_loss: 0.8285, value_loss: 0.4791
2024-07-11 17:35:13,729 [INFO    ] __main__: train step 19868: loss: 0.9193, policy_loss: 0.8285, value_loss: 0.4791
2024-07-11 17:35:13,932 [INFO    ] __main__: train step 19869: loss: 0.9193, policy_loss: 0.8285, value_loss: 0.4791
2024-07-11 17:35:14,132 [INFO    ] __main__: train step 19870: loss: 0.9193, policy_loss: 0.8285, value_loss: 0.4791
2024-07-11 17:35:14,335 [INFO    ] __main__: train step 19871: loss: 0.9193, policy_loss: 0.8285, value_loss: 0.4791
2024-07-11 17:35:14,542 [INFO    ] __main__: train step 19872: loss: 0.9193, policy_loss: 0.8285, value_loss: 0.4791
2024-07-11 17:35:15,977 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:35:16,392 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:35:16,453 [INFO    ] __main__: train step 19873: loss: 0.9193, policy_loss: 0.8285, value_loss: 0.4790
2024-07-11 17:35:16,625 [INFO    ] __main__: train step 19874: loss: 0.9192, policy_loss: 0.8285, value_loss: 0.4790
2024-07-11 17:35:16,825 [INFO    ] __main__: train step 19875: loss: 0.9192, policy_loss: 0.8285, value_loss: 0.4790
2024-07-11 17:35:17,029 [INFO    ] __main__: train step 19876: loss: 0.9192, policy_loss: 0.8285, value_loss: 0.4790
2024-07-11 17:35:17,242 [INFO    ] __main__: train step 19877: loss: 0.9192, policy_loss: 0.8285, value_loss: 0.4790
2024-07-11 17:35:17,450 [INFO    ] __main__: train step 19878: loss: 0.9192, policy_loss: 0.8285, value_loss: 0.4789
2024-07-11 17:35:17,693 [INFO    ] __main__: train step 19879: loss: 0.9192, policy_loss: 0.8285, value_loss: 0.4789
2024-07-11 17:35:17,915 [INFO    ] __main__: train step 19880: loss: 0.9192, policy_loss: 0.8285, value_loss: 0.4789
2024-07-11 17:35:18,147 [INFO    ] __main__: train step 19881: loss: 0.9192, policy_loss: 0.8285, value_loss: 0.4789
2024-07-11 17:35:18,350 [INFO    ] __main__: train step 19882: loss: 0.9192, policy_loss: 0.8285, value_loss: 0.4789
2024-07-11 17:35:18,555 [INFO    ] __main__: train step 19883: loss: 0.9192, policy_loss: 0.8285, value_loss: 0.4789
2024-07-11 17:35:18,772 [INFO    ] __main__: train step 19884: loss: 0.9192, policy_loss: 0.8285, value_loss: 0.4788
2024-07-11 17:35:19,003 [INFO    ] __main__: train step 19885: loss: 0.9192, policy_loss: 0.8285, value_loss: 0.4788
2024-07-11 17:35:19,204 [INFO    ] __main__: train step 19886: loss: 0.9192, policy_loss: 0.8285, value_loss: 0.4788
2024-07-11 17:35:19,408 [INFO    ] __main__: train step 19887: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4788
2024-07-11 17:35:19,614 [INFO    ] __main__: train step 19888: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4788
2024-07-11 17:35:19,821 [INFO    ] __main__: train step 19889: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4788
2024-07-11 17:35:21,257 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:35:21,621 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:35:21,675 [INFO    ] __main__: train step 19890: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4787
2024-07-11 17:35:21,862 [INFO    ] __main__: train step 19891: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4787
2024-07-11 17:35:22,073 [INFO    ] __main__: train step 19892: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4787
2024-07-11 17:35:22,291 [INFO    ] __main__: train step 19893: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4787
2024-07-11 17:35:22,490 [INFO    ] __main__: train step 19894: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4787
2024-07-11 17:35:22,694 [INFO    ] __main__: train step 19895: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4786
2024-07-11 17:35:22,905 [INFO    ] __main__: train step 19896: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4786
2024-07-11 17:35:23,117 [INFO    ] __main__: train step 19897: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4786
2024-07-11 17:35:23,322 [INFO    ] __main__: train step 19898: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4786
2024-07-11 17:35:23,545 [INFO    ] __main__: train step 19899: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4786
2024-07-11 17:35:23,748 [INFO    ] __main__: train step 19900: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4786
2024-07-11 17:35:23,957 [INFO    ] __main__: train step 19901: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4785
2024-07-11 17:35:24,172 [INFO    ] __main__: train step 19902: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4785
2024-07-11 17:35:24,388 [INFO    ] __main__: train step 19903: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4785
2024-07-11 17:35:24,590 [INFO    ] __main__: train step 19904: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4785
2024-07-11 17:35:24,810 [INFO    ] __main__: train step 19905: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4785
2024-07-11 17:35:25,004 [INFO    ] __main__: train step 19906: loss: 0.9192, policy_loss: 0.8284, value_loss: 0.4785
2024-07-11 17:35:26,447 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:35:26,836 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:35:26,892 [INFO    ] __main__: train step 19907: loss: 0.9191, policy_loss: 0.8284, value_loss: 0.4784
2024-07-11 17:35:27,075 [INFO    ] __main__: train step 19908: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4784
2024-07-11 17:35:27,292 [INFO    ] __main__: train step 19909: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4784
2024-07-11 17:35:27,502 [INFO    ] __main__: train step 19910: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4784
2024-07-11 17:35:27,711 [INFO    ] __main__: train step 19911: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4784
2024-07-11 17:35:27,913 [INFO    ] __main__: train step 19912: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4783
2024-07-11 17:35:28,111 [INFO    ] __main__: train step 19913: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4783
2024-07-11 17:35:28,321 [INFO    ] __main__: train step 19914: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4783
2024-07-11 17:35:28,521 [INFO    ] __main__: train step 19915: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4783
2024-07-11 17:35:28,719 [INFO    ] __main__: train step 19916: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4783
2024-07-11 17:35:28,928 [INFO    ] __main__: train step 19917: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4783
2024-07-11 17:35:29,121 [INFO    ] __main__: train step 19918: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4782
2024-07-11 17:35:29,328 [INFO    ] __main__: train step 19919: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4782
2024-07-11 17:35:29,550 [INFO    ] __main__: train step 19920: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4782
2024-07-11 17:35:29,792 [INFO    ] __main__: train step 19921: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4782
2024-07-11 17:35:29,996 [INFO    ] __main__: train step 19922: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4782
2024-07-11 17:35:30,217 [INFO    ] __main__: train step 19923: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4782
2024-07-11 17:35:31,668 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:35:32,038 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:35:32,096 [INFO    ] __main__: train step 19924: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4781
2024-07-11 17:35:32,279 [INFO    ] __main__: train step 19925: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4781
2024-07-11 17:35:32,518 [INFO    ] __main__: train step 19926: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4781
2024-07-11 17:35:32,725 [INFO    ] __main__: train step 19927: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4781
2024-07-11 17:35:32,965 [INFO    ] __main__: train step 19928: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4781
2024-07-11 17:35:33,168 [INFO    ] __main__: train step 19929: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4780
2024-07-11 17:35:33,407 [INFO    ] __main__: train step 19930: loss: 0.9191, policy_loss: 0.8283, value_loss: 0.4780
2024-07-11 17:35:33,616 [INFO    ] __main__: train step 19931: loss: 0.9191, policy_loss: 0.8282, value_loss: 0.4780
2024-07-11 17:35:33,849 [INFO    ] __main__: train step 19932: loss: 0.9191, policy_loss: 0.8282, value_loss: 0.4780
2024-07-11 17:35:34,063 [INFO    ] __main__: train step 19933: loss: 0.9191, policy_loss: 0.8282, value_loss: 0.4780
2024-07-11 17:35:34,262 [INFO    ] __main__: train step 19934: loss: 0.9191, policy_loss: 0.8282, value_loss: 0.4780
2024-07-11 17:35:34,469 [INFO    ] __main__: train step 19935: loss: 0.9191, policy_loss: 0.8282, value_loss: 0.4779
2024-07-11 17:35:34,701 [INFO    ] __main__: train step 19936: loss: 0.9191, policy_loss: 0.8282, value_loss: 0.4779
2024-07-11 17:35:36,624 [INFO    ] __main__: train step 19937: loss: 0.9191, policy_loss: 0.8282, value_loss: 0.4779
2024-07-11 17:35:36,840 [INFO    ] __main__: train step 19938: loss: 0.9191, policy_loss: 0.8282, value_loss: 0.4779
2024-07-11 17:35:37,040 [INFO    ] __main__: train step 19939: loss: 0.9191, policy_loss: 0.8282, value_loss: 0.4779
2024-07-11 17:35:37,237 [INFO    ] __main__: train step 19940: loss: 0.9191, policy_loss: 0.8282, value_loss: 0.4779
2024-07-11 17:35:38,681 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:35:39,051 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:35:39,108 [INFO    ] __main__: train step 19941: loss: 0.9191, policy_loss: 0.8282, value_loss: 0.4778
2024-07-11 17:35:39,285 [INFO    ] __main__: train step 19942: loss: 0.9191, policy_loss: 0.8282, value_loss: 0.4778
2024-07-11 17:35:39,504 [INFO    ] __main__: train step 19943: loss: 0.9191, policy_loss: 0.8282, value_loss: 0.4778
2024-07-11 17:35:39,714 [INFO    ] __main__: train step 19944: loss: 0.9191, policy_loss: 0.8282, value_loss: 0.4778
2024-07-11 17:35:39,913 [INFO    ] __main__: train step 19945: loss: 0.9191, policy_loss: 0.8282, value_loss: 0.4778
2024-07-11 17:35:40,116 [INFO    ] __main__: train step 19946: loss: 0.9190, policy_loss: 0.8282, value_loss: 0.4777
2024-07-11 17:35:40,326 [INFO    ] __main__: train step 19947: loss: 0.9190, policy_loss: 0.8282, value_loss: 0.4777
2024-07-11 17:35:40,541 [INFO    ] __main__: train step 19948: loss: 0.9190, policy_loss: 0.8282, value_loss: 0.4777
2024-07-11 17:35:40,774 [INFO    ] __main__: train step 19949: loss: 0.9190, policy_loss: 0.8282, value_loss: 0.4777
2024-07-11 17:35:40,972 [INFO    ] __main__: train step 19950: loss: 0.9190, policy_loss: 0.8282, value_loss: 0.4777
2024-07-11 17:35:41,193 [INFO    ] __main__: train step 19951: loss: 0.9190, policy_loss: 0.8282, value_loss: 0.4777
2024-07-11 17:35:41,392 [INFO    ] __main__: train step 19952: loss: 0.9190, policy_loss: 0.8282, value_loss: 0.4776
2024-07-11 17:35:41,603 [INFO    ] __main__: train step 19953: loss: 0.9190, policy_loss: 0.8282, value_loss: 0.4776
2024-07-11 17:35:41,811 [INFO    ] __main__: train step 19954: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4776
2024-07-11 17:35:42,024 [INFO    ] __main__: train step 19955: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4776
2024-07-11 17:35:42,232 [INFO    ] __main__: train step 19956: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4776
2024-07-11 17:35:42,441 [INFO    ] __main__: train step 19957: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4776
2024-07-11 17:35:43,890 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:35:44,261 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:35:44,316 [INFO    ] __main__: train step 19958: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4775
2024-07-11 17:35:44,488 [INFO    ] __main__: train step 19959: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4775
2024-07-11 17:35:44,691 [INFO    ] __main__: train step 19960: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4775
2024-07-11 17:35:44,918 [INFO    ] __main__: train step 19961: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4775
2024-07-11 17:35:45,128 [INFO    ] __main__: train step 19962: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4775
2024-07-11 17:35:45,368 [INFO    ] __main__: train step 19963: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4774
2024-07-11 17:35:45,610 [INFO    ] __main__: train step 19964: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4774
2024-07-11 17:35:45,842 [INFO    ] __main__: train step 19965: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4774
2024-07-11 17:35:46,048 [INFO    ] __main__: train step 19966: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4774
2024-07-11 17:35:46,254 [INFO    ] __main__: train step 19967: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4774
2024-07-11 17:35:46,459 [INFO    ] __main__: train step 19968: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4774
2024-07-11 17:35:46,684 [INFO    ] __main__: train step 19969: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4773
2024-07-11 17:35:46,893 [INFO    ] __main__: train step 19970: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4773
2024-07-11 17:35:47,111 [INFO    ] __main__: train step 19971: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4773
2024-07-11 17:35:47,306 [INFO    ] __main__: train step 19972: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4773
2024-07-11 17:35:47,504 [INFO    ] __main__: train step 19973: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4773
2024-07-11 17:35:47,712 [INFO    ] __main__: train step 19974: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4773
2024-07-11 17:35:49,160 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:35:49,557 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:35:49,621 [INFO    ] __main__: train step 19975: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4772
2024-07-11 17:35:49,792 [INFO    ] __main__: train step 19976: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4772
2024-07-11 17:35:50,007 [INFO    ] __main__: train step 19977: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4772
2024-07-11 17:35:50,210 [INFO    ] __main__: train step 19978: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4772
2024-07-11 17:35:50,416 [INFO    ] __main__: train step 19979: loss: 0.9190, policy_loss: 0.8281, value_loss: 0.4772
2024-07-11 17:35:50,633 [INFO    ] __main__: train step 19980: loss: 0.9190, policy_loss: 0.8280, value_loss: 0.4771
2024-07-11 17:35:50,879 [INFO    ] __main__: train step 19981: loss: 0.9190, policy_loss: 0.8280, value_loss: 0.4771
2024-07-11 17:35:51,087 [INFO    ] __main__: train step 19982: loss: 0.9190, policy_loss: 0.8280, value_loss: 0.4771
2024-07-11 17:35:51,283 [INFO    ] __main__: train step 19983: loss: 0.9190, policy_loss: 0.8280, value_loss: 0.4771
2024-07-11 17:35:51,489 [INFO    ] __main__: train step 19984: loss: 0.9190, policy_loss: 0.8280, value_loss: 0.4771
2024-07-11 17:35:51,705 [INFO    ] __main__: train step 19985: loss: 0.9190, policy_loss: 0.8280, value_loss: 0.4771
2024-07-11 17:35:51,916 [INFO    ] __main__: train step 19986: loss: 0.9190, policy_loss: 0.8280, value_loss: 0.4770
2024-07-11 17:35:52,115 [INFO    ] __main__: train step 19987: loss: 0.9190, policy_loss: 0.8280, value_loss: 0.4770
2024-07-11 17:35:52,348 [INFO    ] __main__: train step 19988: loss: 0.9190, policy_loss: 0.8280, value_loss: 0.4770
2024-07-11 17:35:52,625 [INFO    ] __main__: train step 19989: loss: 0.9190, policy_loss: 0.8280, value_loss: 0.4770
2024-07-11 17:35:52,841 [INFO    ] __main__: train step 19990: loss: 0.9190, policy_loss: 0.8280, value_loss: 0.4770
2024-07-11 17:35:53,029 [INFO    ] __main__: train step 19991: loss: 0.9189, policy_loss: 0.8280, value_loss: 0.4770
2024-07-11 17:35:54,502 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:35:54,816 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:35:54,876 [INFO    ] __main__: train step 19992: loss: 0.9189, policy_loss: 0.8280, value_loss: 0.4769
2024-07-11 17:35:55,054 [INFO    ] __main__: train step 19993: loss: 0.9189, policy_loss: 0.8280, value_loss: 0.4769
2024-07-11 17:35:55,262 [INFO    ] __main__: train step 19994: loss: 0.9189, policy_loss: 0.8280, value_loss: 0.4769
2024-07-11 17:35:55,458 [INFO    ] __main__: train step 19995: loss: 0.9189, policy_loss: 0.8280, value_loss: 0.4769
2024-07-11 17:35:55,662 [INFO    ] __main__: train step 19996: loss: 0.9189, policy_loss: 0.8280, value_loss: 0.4769
2024-07-11 17:35:55,859 [INFO    ] __main__: train step 19997: loss: 0.9189, policy_loss: 0.8280, value_loss: 0.4768
2024-07-11 17:35:56,080 [INFO    ] __main__: train step 19998: loss: 0.9189, policy_loss: 0.8280, value_loss: 0.4768
2024-07-11 17:35:56,281 [INFO    ] __main__: train step 19999: loss: 0.9189, policy_loss: 0.8280, value_loss: 0.4768
2024-07-11 17:35:56,492 [INFO    ] __main__: train step 20000: loss: 0.9189, policy_loss: 0.8280, value_loss: 0.4768
2024-07-11 17:35:56,603 [INFO    ] __main__: restored step 19000 for evaluation
2024-07-11 17:36:04,361 [INFO    ] __main__: later network ELO difference from earlier network: +44 (+8/-8) ELO from 32000 self-played games
2024-07-11 17:36:04,361 [INFO    ] __main__: game outcomes: W: 17464, D: 368, L: 14168
2024-07-11 17:36:04,363 [INFO    ] __main__: validation_elo_delta: 44, validation_elo: 2740
2024-07-11 17:36:04,690 [INFO    ] __main__: running self-play game for SVG generation
2024-07-11 17:38:23,586 [INFO    ] __main__: saved self-play game in animations/run1_baseline/20000.svg
2024-07-11 17:38:23,769 [INFO    ] __main__: train step 20001: loss: 0.9189, policy_loss: 0.8280, value_loss: 0.4768
2024-07-11 17:38:23,987 [INFO    ] __main__: train step 20002: loss: 0.9189, policy_loss: 0.8280, value_loss: 0.4768
2024-07-11 17:38:24,206 [INFO    ] __main__: train step 20003: loss: 0.9189, policy_loss: 0.8280, value_loss: 0.4767
2024-07-11 17:38:24,419 [INFO    ] __main__: train step 20004: loss: 0.9189, policy_loss: 0.8280, value_loss: 0.4767
2024-07-11 17:38:24,634 [INFO    ] __main__: train step 20005: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4767
2024-07-11 17:38:24,852 [INFO    ] __main__: train step 20006: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4767
2024-07-11 17:38:25,071 [INFO    ] __main__: train step 20007: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4767
2024-07-11 17:38:25,271 [INFO    ] __main__: train step 20008: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4767
2024-07-11 17:38:26,703 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:38:27,130 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:38:27,196 [INFO    ] __main__: train step 20009: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4766
2024-07-11 17:38:27,383 [INFO    ] __main__: train step 20010: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4766
2024-07-11 17:38:27,635 [INFO    ] __main__: train step 20011: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4766
2024-07-11 17:38:27,828 [INFO    ] __main__: train step 20012: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4766
2024-07-11 17:38:28,041 [INFO    ] __main__: train step 20013: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4766
2024-07-11 17:38:28,265 [INFO    ] __main__: train step 20014: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4765
2024-07-11 17:38:28,467 [INFO    ] __main__: train step 20015: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4765
2024-07-11 17:38:28,669 [INFO    ] __main__: train step 20016: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4765
2024-07-11 17:38:28,864 [INFO    ] __main__: train step 20017: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4765
2024-07-11 17:38:29,074 [INFO    ] __main__: train step 20018: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4765
2024-07-11 17:38:29,273 [INFO    ] __main__: train step 20019: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4765
2024-07-11 17:38:29,474 [INFO    ] __main__: train step 20020: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4764
2024-07-11 17:38:29,685 [INFO    ] __main__: train step 20021: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4764
2024-07-11 17:38:29,889 [INFO    ] __main__: train step 20022: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4764
2024-07-11 17:38:30,099 [INFO    ] __main__: train step 20023: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4764
2024-07-11 17:38:30,315 [INFO    ] __main__: train step 20024: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4764
2024-07-11 17:38:30,554 [INFO    ] __main__: train step 20025: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4764
2024-07-11 17:38:32,002 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:38:32,376 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:38:32,433 [INFO    ] __main__: train step 20026: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4763
2024-07-11 17:38:32,619 [INFO    ] __main__: train step 20027: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4763
2024-07-11 17:38:32,829 [INFO    ] __main__: train step 20028: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4763
2024-07-11 17:38:33,035 [INFO    ] __main__: train step 20029: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4763
2024-07-11 17:38:33,240 [INFO    ] __main__: train step 20030: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4763
2024-07-11 17:38:33,453 [INFO    ] __main__: train step 20031: loss: 0.9189, policy_loss: 0.8279, value_loss: 0.4762
2024-07-11 17:38:33,650 [INFO    ] __main__: train step 20032: loss: 0.9189, policy_loss: 0.8278, value_loss: 0.4762
2024-07-11 17:38:33,861 [INFO    ] __main__: train step 20033: loss: 0.9189, policy_loss: 0.8278, value_loss: 0.4762
2024-07-11 17:38:34,080 [INFO    ] __main__: train step 20034: loss: 0.9189, policy_loss: 0.8278, value_loss: 0.4762
2024-07-11 17:38:34,285 [INFO    ] __main__: train step 20035: loss: 0.9189, policy_loss: 0.8278, value_loss: 0.4762
2024-07-11 17:38:34,512 [INFO    ] __main__: train step 20036: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4762
2024-07-11 17:38:34,732 [INFO    ] __main__: train step 20037: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4761
2024-07-11 17:38:34,931 [INFO    ] __main__: train step 20038: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4761
2024-07-11 17:38:35,143 [INFO    ] __main__: train step 20039: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4761
2024-07-11 17:38:35,350 [INFO    ] __main__: train step 20040: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4761
2024-07-11 17:38:35,550 [INFO    ] __main__: train step 20041: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4761
2024-07-11 17:38:35,772 [INFO    ] __main__: train step 20042: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4761
2024-07-11 17:38:37,253 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:38:37,671 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:38:37,735 [INFO    ] __main__: train step 20043: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4760
2024-07-11 17:38:37,908 [INFO    ] __main__: train step 20044: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4760
2024-07-11 17:38:38,110 [INFO    ] __main__: train step 20045: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4760
2024-07-11 17:38:38,312 [INFO    ] __main__: train step 20046: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4760
2024-07-11 17:38:38,514 [INFO    ] __main__: train step 20047: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4760
2024-07-11 17:38:38,721 [INFO    ] __main__: train step 20048: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4759
2024-07-11 17:38:38,934 [INFO    ] __main__: train step 20049: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4759
2024-07-11 17:38:39,163 [INFO    ] __main__: train step 20050: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4759
2024-07-11 17:38:39,378 [INFO    ] __main__: train step 20051: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4759
2024-07-11 17:38:39,615 [INFO    ] __main__: train step 20052: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4759
2024-07-11 17:38:39,814 [INFO    ] __main__: train step 20053: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4759
2024-07-11 17:38:40,021 [INFO    ] __main__: train step 20054: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4758
2024-07-11 17:38:40,247 [INFO    ] __main__: train step 20055: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4758
2024-07-11 17:38:40,447 [INFO    ] __main__: train step 20056: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4758
2024-07-11 17:38:40,650 [INFO    ] __main__: train step 20057: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4758
2024-07-11 17:38:40,861 [INFO    ] __main__: train step 20058: loss: 0.9188, policy_loss: 0.8278, value_loss: 0.4758
2024-07-11 17:38:41,054 [INFO    ] __main__: train step 20059: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4758
2024-07-11 17:38:42,484 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:38:42,880 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:38:42,939 [INFO    ] __main__: train step 20060: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4757
2024-07-11 17:38:43,110 [INFO    ] __main__: train step 20061: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4757
2024-07-11 17:38:43,312 [INFO    ] __main__: train step 20062: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4757
2024-07-11 17:38:43,524 [INFO    ] __main__: train step 20063: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4757
2024-07-11 17:38:43,726 [INFO    ] __main__: train step 20064: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4757
2024-07-11 17:38:43,928 [INFO    ] __main__: train step 20065: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4757
2024-07-11 17:38:44,130 [INFO    ] __main__: train step 20066: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4756
2024-07-11 17:38:44,340 [INFO    ] __main__: train step 20067: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4756
2024-07-11 17:38:44,537 [INFO    ] __main__: train step 20068: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4756
2024-07-11 17:38:44,742 [INFO    ] __main__: train step 20069: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4756
2024-07-11 17:38:44,938 [INFO    ] __main__: train step 20070: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4756
2024-07-11 17:38:45,157 [INFO    ] __main__: train step 20071: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4755
2024-07-11 17:38:45,360 [INFO    ] __main__: train step 20072: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4755
2024-07-11 17:38:45,565 [INFO    ] __main__: train step 20073: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4755
2024-07-11 17:38:45,768 [INFO    ] __main__: train step 20074: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4755
2024-07-11 17:38:45,974 [INFO    ] __main__: train step 20075: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4755
2024-07-11 17:38:46,170 [INFO    ] __main__: train step 20076: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4755
2024-07-11 17:38:47,614 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:38:47,988 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:38:48,044 [INFO    ] __main__: train step 20077: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4754
2024-07-11 17:38:48,225 [INFO    ] __main__: train step 20078: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4754
2024-07-11 17:38:48,437 [INFO    ] __main__: train step 20079: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4754
2024-07-11 17:38:48,678 [INFO    ] __main__: train step 20080: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4754
2024-07-11 17:38:48,884 [INFO    ] __main__: train step 20081: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4754
2024-07-11 17:38:49,081 [INFO    ] __main__: train step 20082: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4754
2024-07-11 17:38:49,272 [INFO    ] __main__: train step 20083: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4753
2024-07-11 17:38:49,478 [INFO    ] __main__: train step 20084: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4753
2024-07-11 17:38:49,682 [INFO    ] __main__: train step 20085: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4753
2024-07-11 17:38:49,888 [INFO    ] __main__: train step 20086: loss: 0.9188, policy_loss: 0.8277, value_loss: 0.4753
2024-07-11 17:38:50,090 [INFO    ] __main__: train step 20087: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4753
2024-07-11 17:38:50,289 [INFO    ] __main__: train step 20088: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4752
2024-07-11 17:38:50,498 [INFO    ] __main__: train step 20089: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4752
2024-07-11 17:38:50,741 [INFO    ] __main__: train step 20090: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4752
2024-07-11 17:38:50,990 [INFO    ] __main__: train step 20091: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4752
2024-07-11 17:38:51,214 [INFO    ] __main__: train step 20092: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4752
2024-07-11 17:38:51,413 [INFO    ] __main__: train step 20093: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4752
2024-07-11 17:38:52,862 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:38:53,223 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:38:53,276 [INFO    ] __main__: train step 20094: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4751
2024-07-11 17:38:53,462 [INFO    ] __main__: train step 20095: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4751
2024-07-11 17:38:53,682 [INFO    ] __main__: train step 20096: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4751
2024-07-11 17:38:53,885 [INFO    ] __main__: train step 20097: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4751
2024-07-11 17:38:54,091 [INFO    ] __main__: train step 20098: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4751
2024-07-11 17:38:54,305 [INFO    ] __main__: train step 20099: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4751
2024-07-11 17:38:54,522 [INFO    ] __main__: train step 20100: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4750
2024-07-11 17:38:54,741 [INFO    ] __main__: train step 20101: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4750
2024-07-11 17:38:54,952 [INFO    ] __main__: train step 20102: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4750
2024-07-11 17:38:55,155 [INFO    ] __main__: train step 20103: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4750
2024-07-11 17:38:55,362 [INFO    ] __main__: train step 20104: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4750
2024-07-11 17:38:55,572 [INFO    ] __main__: train step 20105: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4750
2024-07-11 17:38:55,764 [INFO    ] __main__: train step 20106: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4749
2024-07-11 17:38:55,974 [INFO    ] __main__: train step 20107: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4749
2024-07-11 17:38:56,187 [INFO    ] __main__: train step 20108: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4749
2024-07-11 17:38:56,403 [INFO    ] __main__: train step 20109: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4749
2024-07-11 17:38:56,616 [INFO    ] __main__: train step 20110: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4749
2024-07-11 17:38:58,070 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:38:58,498 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:38:58,557 [INFO    ] __main__: train step 20111: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4748
2024-07-11 17:38:58,728 [INFO    ] __main__: train step 20112: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4748
2024-07-11 17:38:58,931 [INFO    ] __main__: train step 20113: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4748
2024-07-11 17:38:59,127 [INFO    ] __main__: train step 20114: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4748
2024-07-11 17:38:59,336 [INFO    ] __main__: train step 20115: loss: 0.9187, policy_loss: 0.8276, value_loss: 0.4748
2024-07-11 17:38:59,546 [INFO    ] __main__: train step 20116: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4748
2024-07-11 17:38:59,749 [INFO    ] __main__: train step 20117: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4747
2024-07-11 17:38:59,965 [INFO    ] __main__: train step 20118: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4747
2024-07-11 17:39:00,211 [INFO    ] __main__: train step 20119: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4747
2024-07-11 17:39:00,437 [INFO    ] __main__: train step 20120: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4747
2024-07-11 17:39:00,647 [INFO    ] __main__: train step 20121: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4747
2024-07-11 17:39:00,846 [INFO    ] __main__: train step 20122: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4747
2024-07-11 17:39:01,053 [INFO    ] __main__: train step 20123: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4746
2024-07-11 17:39:01,256 [INFO    ] __main__: train step 20124: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4746
2024-07-11 17:39:01,464 [INFO    ] __main__: train step 20125: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4746
2024-07-11 17:39:01,687 [INFO    ] __main__: train step 20126: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4746
2024-07-11 17:39:01,890 [INFO    ] __main__: train step 20127: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4746
2024-07-11 17:39:03,339 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:39:03,726 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:39:03,781 [INFO    ] __main__: train step 20128: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4746
2024-07-11 17:39:03,962 [INFO    ] __main__: train step 20129: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4745
2024-07-11 17:39:04,164 [INFO    ] __main__: train step 20130: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4745
2024-07-11 17:39:04,366 [INFO    ] __main__: train step 20131: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4745
2024-07-11 17:39:04,564 [INFO    ] __main__: train step 20132: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4745
2024-07-11 17:39:04,766 [INFO    ] __main__: train step 20133: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4745
2024-07-11 17:39:04,973 [INFO    ] __main__: train step 20134: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4744
2024-07-11 17:39:05,184 [INFO    ] __main__: train step 20135: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4744
2024-07-11 17:39:07,661 [INFO    ] __main__: train step 20136: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4744
2024-07-11 17:39:07,878 [INFO    ] __main__: train step 20137: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4744
2024-07-11 17:39:08,075 [INFO    ] __main__: train step 20138: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4744
2024-07-11 17:39:08,275 [INFO    ] __main__: train step 20139: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4744
2024-07-11 17:39:08,475 [INFO    ] __main__: train step 20140: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4743
2024-07-11 17:39:08,687 [INFO    ] __main__: train step 20141: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4743
2024-07-11 17:39:08,883 [INFO    ] __main__: train step 20142: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4743
2024-07-11 17:39:09,098 [INFO    ] __main__: train step 20143: loss: 0.9187, policy_loss: 0.8275, value_loss: 0.4743
2024-07-11 17:39:09,312 [INFO    ] __main__: train step 20144: loss: 0.9186, policy_loss: 0.8275, value_loss: 0.4743
2024-07-11 17:39:10,802 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:39:11,212 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:39:11,274 [INFO    ] __main__: train step 20145: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4743
2024-07-11 17:39:11,461 [INFO    ] __main__: train step 20146: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4742
2024-07-11 17:39:11,680 [INFO    ] __main__: train step 20147: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4742
2024-07-11 17:39:11,903 [INFO    ] __main__: train step 20148: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4742
2024-07-11 17:39:12,098 [INFO    ] __main__: train step 20149: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4742
2024-07-11 17:39:12,310 [INFO    ] __main__: train step 20150: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4742
2024-07-11 17:39:12,519 [INFO    ] __main__: train step 20151: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4742
2024-07-11 17:39:12,741 [INFO    ] __main__: train step 20152: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4741
2024-07-11 17:39:12,953 [INFO    ] __main__: train step 20153: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4741
2024-07-11 17:39:13,157 [INFO    ] __main__: train step 20154: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4741
2024-07-11 17:39:13,367 [INFO    ] __main__: train step 20155: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4741
2024-07-11 17:39:13,569 [INFO    ] __main__: train step 20156: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4741
2024-07-11 17:39:13,767 [INFO    ] __main__: train step 20157: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4741
2024-07-11 17:39:13,987 [INFO    ] __main__: train step 20158: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4740
2024-07-11 17:39:14,201 [INFO    ] __main__: train step 20159: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4740
2024-07-11 17:39:14,405 [INFO    ] __main__: train step 20160: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4740
2024-07-11 17:39:14,611 [INFO    ] __main__: train step 20161: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4740
2024-07-11 17:39:16,054 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:39:16,450 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:39:16,505 [INFO    ] __main__: train step 20162: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4740
2024-07-11 17:39:16,689 [INFO    ] __main__: train step 20163: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4739
2024-07-11 17:39:16,886 [INFO    ] __main__: train step 20164: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4739
2024-07-11 17:39:17,097 [INFO    ] __main__: train step 20165: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4739
2024-07-11 17:39:17,311 [INFO    ] __main__: train step 20166: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4739
2024-07-11 17:39:17,517 [INFO    ] __main__: train step 20167: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4739
2024-07-11 17:39:17,718 [INFO    ] __main__: train step 20168: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4739
2024-07-11 17:39:17,927 [INFO    ] __main__: train step 20169: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4738
2024-07-11 17:39:18,145 [INFO    ] __main__: train step 20170: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4738
2024-07-11 17:39:18,339 [INFO    ] __main__: train step 20171: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4738
2024-07-11 17:39:18,557 [INFO    ] __main__: train step 20172: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4738
2024-07-11 17:39:18,757 [INFO    ] __main__: train step 20173: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4738
2024-07-11 17:39:18,977 [INFO    ] __main__: train step 20174: loss: 0.9186, policy_loss: 0.8274, value_loss: 0.4738
2024-07-11 17:39:19,167 [INFO    ] __main__: train step 20175: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4737
2024-07-11 17:39:19,375 [INFO    ] __main__: train step 20176: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4737
2024-07-11 17:39:19,572 [INFO    ] __main__: train step 20177: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4737
2024-07-11 17:39:19,776 [INFO    ] __main__: train step 20178: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4737
2024-07-11 17:39:21,217 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:39:21,632 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:39:21,693 [INFO    ] __main__: train step 20179: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4737
2024-07-11 17:39:21,877 [INFO    ] __main__: train step 20180: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4736
2024-07-11 17:39:22,082 [INFO    ] __main__: train step 20181: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4736
2024-07-11 17:39:22,276 [INFO    ] __main__: train step 20182: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4736
2024-07-11 17:39:22,477 [INFO    ] __main__: train step 20183: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4736
2024-07-11 17:39:22,682 [INFO    ] __main__: train step 20184: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4736
2024-07-11 17:39:22,893 [INFO    ] __main__: train step 20185: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4736
2024-07-11 17:39:23,098 [INFO    ] __main__: train step 20186: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4735
2024-07-11 17:39:23,294 [INFO    ] __main__: train step 20187: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4735
2024-07-11 17:39:23,499 [INFO    ] __main__: train step 20188: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4735
2024-07-11 17:39:23,709 [INFO    ] __main__: train step 20189: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4735
2024-07-11 17:39:23,932 [INFO    ] __main__: train step 20190: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4735
2024-07-11 17:39:24,141 [INFO    ] __main__: train step 20191: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4735
2024-07-11 17:39:24,354 [INFO    ] __main__: train step 20192: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4734
2024-07-11 17:39:24,553 [INFO    ] __main__: train step 20193: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4734
2024-07-11 17:39:24,749 [INFO    ] __main__: train step 20194: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4734
2024-07-11 17:39:24,939 [INFO    ] __main__: train step 20195: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4734
2024-07-11 17:39:26,380 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:39:26,762 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:39:26,820 [INFO    ] __main__: train step 20196: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4734
2024-07-11 17:39:27,021 [INFO    ] __main__: train step 20197: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4734
2024-07-11 17:39:27,269 [INFO    ] __main__: train step 20198: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4733
2024-07-11 17:39:27,494 [INFO    ] __main__: train step 20199: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4733
2024-07-11 17:39:27,728 [INFO    ] __main__: train step 20200: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4733
2024-07-11 17:39:27,924 [INFO    ] __main__: train step 20201: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4733
2024-07-11 17:39:28,120 [INFO    ] __main__: train step 20202: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4733
2024-07-11 17:39:28,320 [INFO    ] __main__: train step 20203: loss: 0.9186, policy_loss: 0.8273, value_loss: 0.4732
2024-07-11 17:39:28,523 [INFO    ] __main__: train step 20204: loss: 0.9185, policy_loss: 0.8273, value_loss: 0.4732
2024-07-11 17:39:28,724 [INFO    ] __main__: train step 20205: loss: 0.9185, policy_loss: 0.8273, value_loss: 0.4732
2024-07-11 17:39:28,932 [INFO    ] __main__: train step 20206: loss: 0.9185, policy_loss: 0.8273, value_loss: 0.4732
2024-07-11 17:39:29,148 [INFO    ] __main__: train step 20207: loss: 0.9185, policy_loss: 0.8273, value_loss: 0.4732
2024-07-11 17:39:29,340 [INFO    ] __main__: train step 20208: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4732
2024-07-11 17:39:29,548 [INFO    ] __main__: train step 20209: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4731
2024-07-11 17:39:29,766 [INFO    ] __main__: train step 20210: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4731
2024-07-11 17:39:30,013 [INFO    ] __main__: train step 20211: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4731
2024-07-11 17:39:30,243 [INFO    ] __main__: train step 20212: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4731
2024-07-11 17:39:31,681 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:39:32,062 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:39:32,116 [INFO    ] __main__: train step 20213: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4731
2024-07-11 17:39:32,293 [INFO    ] __main__: train step 20214: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4731
2024-07-11 17:39:32,504 [INFO    ] __main__: train step 20215: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4730
2024-07-11 17:39:32,724 [INFO    ] __main__: train step 20216: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4730
2024-07-11 17:39:32,932 [INFO    ] __main__: train step 20217: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4730
2024-07-11 17:39:33,142 [INFO    ] __main__: train step 20218: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4730
2024-07-11 17:39:33,375 [INFO    ] __main__: train step 20219: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4730
2024-07-11 17:39:33,581 [INFO    ] __main__: train step 20220: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4730
2024-07-11 17:39:33,796 [INFO    ] __main__: train step 20221: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4729
2024-07-11 17:39:34,024 [INFO    ] __main__: train step 20222: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4729
2024-07-11 17:39:34,224 [INFO    ] __main__: train step 20223: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4729
2024-07-11 17:39:34,424 [INFO    ] __main__: train step 20224: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4729
2024-07-11 17:39:34,631 [INFO    ] __main__: train step 20225: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4729
2024-07-11 17:39:34,826 [INFO    ] __main__: train step 20226: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4728
2024-07-11 17:39:35,025 [INFO    ] __main__: train step 20227: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4728
2024-07-11 17:39:35,232 [INFO    ] __main__: train step 20228: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4728
2024-07-11 17:39:35,431 [INFO    ] __main__: train step 20229: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4728
2024-07-11 17:39:36,872 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:39:37,273 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:39:37,327 [INFO    ] __main__: train step 20230: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4728
2024-07-11 17:39:37,506 [INFO    ] __main__: train step 20231: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4728
2024-07-11 17:39:37,717 [INFO    ] __main__: train step 20232: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4727
2024-07-11 17:39:37,917 [INFO    ] __main__: train step 20233: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4727
2024-07-11 17:39:38,132 [INFO    ] __main__: train step 20234: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4727
2024-07-11 17:39:38,342 [INFO    ] __main__: train step 20235: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4727
2024-07-11 17:39:38,538 [INFO    ] __main__: train step 20236: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4727
2024-07-11 17:39:38,747 [INFO    ] __main__: train step 20237: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4727
2024-07-11 17:39:38,953 [INFO    ] __main__: train step 20238: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4726
2024-07-11 17:39:39,168 [INFO    ] __main__: train step 20239: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4726
2024-07-11 17:39:39,369 [INFO    ] __main__: train step 20240: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4726
2024-07-11 17:39:39,577 [INFO    ] __main__: train step 20241: loss: 0.9185, policy_loss: 0.8272, value_loss: 0.4726
2024-07-11 17:39:39,783 [INFO    ] __main__: train step 20242: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4726
2024-07-11 17:39:39,996 [INFO    ] __main__: train step 20243: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4725
2024-07-11 17:39:40,201 [INFO    ] __main__: train step 20244: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4725
2024-07-11 17:39:40,400 [INFO    ] __main__: train step 20245: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4725
2024-07-11 17:39:40,605 [INFO    ] __main__: train step 20246: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4725
2024-07-11 17:39:42,051 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:39:42,473 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:39:42,536 [INFO    ] __main__: train step 20247: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4725
2024-07-11 17:39:42,709 [INFO    ] __main__: train step 20248: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4725
2024-07-11 17:39:42,913 [INFO    ] __main__: train step 20249: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4724
2024-07-11 17:39:43,119 [INFO    ] __main__: train step 20250: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4724
2024-07-11 17:39:43,314 [INFO    ] __main__: train step 20251: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4724
2024-07-11 17:39:43,520 [INFO    ] __main__: train step 20252: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4724
2024-07-11 17:39:43,717 [INFO    ] __main__: train step 20253: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4724
2024-07-11 17:39:43,911 [INFO    ] __main__: train step 20254: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4724
2024-07-11 17:39:44,125 [INFO    ] __main__: train step 20255: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4723
2024-07-11 17:39:44,315 [INFO    ] __main__: train step 20256: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4723
2024-07-11 17:39:44,518 [INFO    ] __main__: train step 20257: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4723
2024-07-11 17:39:44,741 [INFO    ] __main__: train step 20258: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4723
2024-07-11 17:39:44,987 [INFO    ] __main__: train step 20259: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4723
2024-07-11 17:39:45,214 [INFO    ] __main__: train step 20260: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4723
2024-07-11 17:39:45,416 [INFO    ] __main__: train step 20261: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4722
2024-07-11 17:39:45,606 [INFO    ] __main__: train step 20262: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4722
2024-07-11 17:39:45,823 [INFO    ] __main__: train step 20263: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4722
2024-07-11 17:39:47,259 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:39:47,667 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:39:47,727 [INFO    ] __main__: train step 20264: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4722
2024-07-11 17:39:47,916 [INFO    ] __main__: train step 20265: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4722
2024-07-11 17:39:48,151 [INFO    ] __main__: train step 20266: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4722
2024-07-11 17:39:48,383 [INFO    ] __main__: train step 20267: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4721
2024-07-11 17:39:48,614 [INFO    ] __main__: train step 20268: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4721
2024-07-11 17:39:48,830 [INFO    ] __main__: train step 20269: loss: 0.9185, policy_loss: 0.8271, value_loss: 0.4721
2024-07-11 17:39:49,034 [INFO    ] __main__: train step 20270: loss: 0.9184, policy_loss: 0.8271, value_loss: 0.4721
2024-07-11 17:39:49,238 [INFO    ] __main__: train step 20271: loss: 0.9184, policy_loss: 0.8271, value_loss: 0.4721
2024-07-11 17:39:49,445 [INFO    ] __main__: train step 20272: loss: 0.9184, policy_loss: 0.8271, value_loss: 0.4720
2024-07-11 17:39:49,658 [INFO    ] __main__: train step 20273: loss: 0.9184, policy_loss: 0.8271, value_loss: 0.4720
2024-07-11 17:39:49,866 [INFO    ] __main__: train step 20274: loss: 0.9184, policy_loss: 0.8271, value_loss: 0.4720
2024-07-11 17:39:50,070 [INFO    ] __main__: train step 20275: loss: 0.9184, policy_loss: 0.8271, value_loss: 0.4720
2024-07-11 17:39:50,282 [INFO    ] __main__: train step 20276: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4720
2024-07-11 17:39:50,489 [INFO    ] __main__: train step 20277: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4720
2024-07-11 17:39:52,935 [INFO    ] __main__: train step 20278: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4719
2024-07-11 17:39:53,151 [INFO    ] __main__: train step 20279: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4719
2024-07-11 17:39:53,359 [INFO    ] __main__: train step 20280: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4719
2024-07-11 17:39:54,818 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:39:55,216 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:39:55,272 [INFO    ] __main__: train step 20281: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4719
2024-07-11 17:39:55,449 [INFO    ] __main__: train step 20282: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4719
2024-07-11 17:39:55,673 [INFO    ] __main__: train step 20283: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4719
2024-07-11 17:39:55,886 [INFO    ] __main__: train step 20284: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4718
2024-07-11 17:39:56,094 [INFO    ] __main__: train step 20285: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4718
2024-07-11 17:39:56,309 [INFO    ] __main__: train step 20286: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4718
2024-07-11 17:39:56,513 [INFO    ] __main__: train step 20287: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4718
2024-07-11 17:39:56,746 [INFO    ] __main__: train step 20288: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4718
2024-07-11 17:39:56,952 [INFO    ] __main__: train step 20289: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4717
2024-07-11 17:39:57,163 [INFO    ] __main__: train step 20290: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4717
2024-07-11 17:39:57,365 [INFO    ] __main__: train step 20291: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4717
2024-07-11 17:39:57,581 [INFO    ] __main__: train step 20292: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4717
2024-07-11 17:39:57,792 [INFO    ] __main__: train step 20293: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4717
2024-07-11 17:39:57,986 [INFO    ] __main__: train step 20294: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4717
2024-07-11 17:39:58,191 [INFO    ] __main__: train step 20295: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4716
2024-07-11 17:39:58,403 [INFO    ] __main__: train step 20296: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4716
2024-07-11 17:39:58,600 [INFO    ] __main__: train step 20297: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4716
2024-07-11 17:40:00,053 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:40:00,484 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:40:00,540 [INFO    ] __main__: train step 20298: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4716
2024-07-11 17:40:00,727 [INFO    ] __main__: train step 20299: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4716
2024-07-11 17:40:00,928 [INFO    ] __main__: train step 20300: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4716
2024-07-11 17:40:01,164 [INFO    ] __main__: train step 20301: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4715
2024-07-11 17:40:01,368 [INFO    ] __main__: train step 20302: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4715
2024-07-11 17:40:01,568 [INFO    ] __main__: train step 20303: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4715
2024-07-11 17:40:01,780 [INFO    ] __main__: train step 20304: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4715
2024-07-11 17:40:01,990 [INFO    ] __main__: train step 20305: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4715
2024-07-11 17:40:02,231 [INFO    ] __main__: train step 20306: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4715
2024-07-11 17:40:02,428 [INFO    ] __main__: train step 20307: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4714
2024-07-11 17:40:02,639 [INFO    ] __main__: train step 20308: loss: 0.9184, policy_loss: 0.8270, value_loss: 0.4714
2024-07-11 17:40:02,839 [INFO    ] __main__: train step 20309: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4714
2024-07-11 17:40:03,049 [INFO    ] __main__: train step 20310: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4714
2024-07-11 17:40:03,259 [INFO    ] __main__: train step 20311: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4714
2024-07-11 17:40:03,460 [INFO    ] __main__: train step 20312: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4713
2024-07-11 17:40:03,651 [INFO    ] __main__: train step 20313: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4713
2024-07-11 17:40:03,851 [INFO    ] __main__: train step 20314: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4713
2024-07-11 17:40:05,277 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:40:05,689 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:40:05,745 [INFO    ] __main__: train step 20315: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4713
2024-07-11 17:40:05,925 [INFO    ] __main__: train step 20316: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4713
2024-07-11 17:40:06,132 [INFO    ] __main__: train step 20317: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4713
2024-07-11 17:40:06,359 [INFO    ] __main__: train step 20318: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4712
2024-07-11 17:40:06,592 [INFO    ] __main__: train step 20319: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4712
2024-07-11 17:40:06,802 [INFO    ] __main__: train step 20320: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4712
2024-07-11 17:40:07,040 [INFO    ] __main__: train step 20321: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4712
2024-07-11 17:40:07,235 [INFO    ] __main__: train step 20322: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4712
2024-07-11 17:40:07,450 [INFO    ] __main__: train step 20323: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4712
2024-07-11 17:40:07,646 [INFO    ] __main__: train step 20324: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4711
2024-07-11 17:40:07,865 [INFO    ] __main__: train step 20325: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4711
2024-07-11 17:40:08,064 [INFO    ] __main__: train step 20326: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4711
2024-07-11 17:40:08,266 [INFO    ] __main__: train step 20327: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4711
2024-07-11 17:40:08,463 [INFO    ] __main__: train step 20328: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4711
2024-07-11 17:40:08,696 [INFO    ] __main__: train step 20329: loss: 0.9184, policy_loss: 0.8269, value_loss: 0.4711
2024-07-11 17:40:08,933 [INFO    ] __main__: train step 20330: loss: 0.9183, policy_loss: 0.8269, value_loss: 0.4710
2024-07-11 17:40:09,169 [INFO    ] __main__: train step 20331: loss: 0.9183, policy_loss: 0.8269, value_loss: 0.4710
2024-07-11 17:40:10,616 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:40:11,018 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:40:11,074 [INFO    ] __main__: train step 20332: loss: 0.9183, policy_loss: 0.8269, value_loss: 0.4710
2024-07-11 17:40:11,255 [INFO    ] __main__: train step 20333: loss: 0.9183, policy_loss: 0.8269, value_loss: 0.4710
2024-07-11 17:40:11,491 [INFO    ] __main__: train step 20334: loss: 0.9183, policy_loss: 0.8269, value_loss: 0.4710
2024-07-11 17:40:11,703 [INFO    ] __main__: train step 20335: loss: 0.9183, policy_loss: 0.8269, value_loss: 0.4709
2024-07-11 17:40:11,903 [INFO    ] __main__: train step 20336: loss: 0.9183, policy_loss: 0.8269, value_loss: 0.4709
2024-07-11 17:40:12,121 [INFO    ] __main__: train step 20337: loss: 0.9183, policy_loss: 0.8269, value_loss: 0.4709
2024-07-11 17:40:12,326 [INFO    ] __main__: train step 20338: loss: 0.9183, policy_loss: 0.8269, value_loss: 0.4709
2024-07-11 17:40:12,540 [INFO    ] __main__: train step 20339: loss: 0.9183, policy_loss: 0.8269, value_loss: 0.4709
2024-07-11 17:40:12,750 [INFO    ] __main__: train step 20340: loss: 0.9183, policy_loss: 0.8269, value_loss: 0.4709
2024-07-11 17:40:12,956 [INFO    ] __main__: train step 20341: loss: 0.9183, policy_loss: 0.8269, value_loss: 0.4708
2024-07-11 17:40:13,159 [INFO    ] __main__: train step 20342: loss: 0.9183, policy_loss: 0.8269, value_loss: 0.4708
2024-07-11 17:40:13,362 [INFO    ] __main__: train step 20343: loss: 0.9183, policy_loss: 0.8269, value_loss: 0.4708
2024-07-11 17:40:13,563 [INFO    ] __main__: train step 20344: loss: 0.9183, policy_loss: 0.8269, value_loss: 0.4708
2024-07-11 17:40:13,759 [INFO    ] __main__: train step 20345: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4708
2024-07-11 17:40:13,973 [INFO    ] __main__: train step 20346: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4708
2024-07-11 17:40:14,178 [INFO    ] __main__: train step 20347: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4707
2024-07-11 17:40:14,377 [INFO    ] __main__: train step 20348: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4707
2024-07-11 17:40:15,812 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:40:16,223 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:40:16,278 [INFO    ] __main__: train step 20349: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4707
2024-07-11 17:40:16,457 [INFO    ] __main__: train step 20350: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4707
2024-07-11 17:40:16,669 [INFO    ] __main__: train step 20351: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4707
2024-07-11 17:40:16,880 [INFO    ] __main__: train step 20352: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4707
2024-07-11 17:40:17,107 [INFO    ] __main__: train step 20353: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4706
2024-07-11 17:40:17,347 [INFO    ] __main__: train step 20354: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4706
2024-07-11 17:40:17,559 [INFO    ] __main__: train step 20355: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4706
2024-07-11 17:40:17,779 [INFO    ] __main__: train step 20356: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4706
2024-07-11 17:40:17,999 [INFO    ] __main__: train step 20357: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4706
2024-07-11 17:40:18,247 [INFO    ] __main__: train step 20358: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4705
2024-07-11 17:40:18,463 [INFO    ] __main__: train step 20359: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4705
2024-07-11 17:40:18,672 [INFO    ] __main__: train step 20360: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4705
2024-07-11 17:40:18,874 [INFO    ] __main__: train step 20361: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4705
2024-07-11 17:40:19,075 [INFO    ] __main__: train step 20362: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4705
2024-07-11 17:40:19,300 [INFO    ] __main__: train step 20363: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4705
2024-07-11 17:40:19,542 [INFO    ] __main__: train step 20364: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4704
2024-07-11 17:40:19,740 [INFO    ] __main__: train step 20365: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4704
2024-07-11 17:40:21,209 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:40:21,646 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:40:21,700 [INFO    ] __main__: train step 20366: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4704
2024-07-11 17:40:21,880 [INFO    ] __main__: train step 20367: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4704
2024-07-11 17:40:22,096 [INFO    ] __main__: train step 20368: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4704
2024-07-11 17:40:22,297 [INFO    ] __main__: train step 20369: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4704
2024-07-11 17:40:22,493 [INFO    ] __main__: train step 20370: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4703
2024-07-11 17:40:22,703 [INFO    ] __main__: train step 20371: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4703
2024-07-11 17:40:22,903 [INFO    ] __main__: train step 20372: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4703
2024-07-11 17:40:23,107 [INFO    ] __main__: train step 20373: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4703
2024-07-11 17:40:23,305 [INFO    ] __main__: train step 20374: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4703
2024-07-11 17:40:23,512 [INFO    ] __main__: train step 20375: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4703
2024-07-11 17:40:23,766 [INFO    ] __main__: train step 20376: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4702
2024-07-11 17:40:24,007 [INFO    ] __main__: train step 20377: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4702
2024-07-11 17:40:24,216 [INFO    ] __main__: train step 20378: loss: 0.9183, policy_loss: 0.8268, value_loss: 0.4702
2024-07-11 17:40:24,421 [INFO    ] __main__: train step 20379: loss: 0.9183, policy_loss: 0.8267, value_loss: 0.4702
2024-07-11 17:40:24,628 [INFO    ] __main__: train step 20380: loss: 0.9183, policy_loss: 0.8267, value_loss: 0.4702
2024-07-11 17:40:24,833 [INFO    ] __main__: train step 20381: loss: 0.9183, policy_loss: 0.8267, value_loss: 0.4701
2024-07-11 17:40:25,036 [INFO    ] __main__: train step 20382: loss: 0.9183, policy_loss: 0.8267, value_loss: 0.4701
2024-07-11 17:40:26,474 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:40:26,862 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:40:26,921 [INFO    ] __main__: train step 20383: loss: 0.9183, policy_loss: 0.8267, value_loss: 0.4701
2024-07-11 17:40:27,106 [INFO    ] __main__: train step 20384: loss: 0.9183, policy_loss: 0.8267, value_loss: 0.4701
2024-07-11 17:40:27,319 [INFO    ] __main__: train step 20385: loss: 0.9183, policy_loss: 0.8267, value_loss: 0.4701
2024-07-11 17:40:27,547 [INFO    ] __main__: train step 20386: loss: 0.9183, policy_loss: 0.8267, value_loss: 0.4701
2024-07-11 17:40:27,738 [INFO    ] __main__: train step 20387: loss: 0.9183, policy_loss: 0.8267, value_loss: 0.4700
2024-07-11 17:40:27,945 [INFO    ] __main__: train step 20388: loss: 0.9183, policy_loss: 0.8267, value_loss: 0.4700
2024-07-11 17:40:28,141 [INFO    ] __main__: train step 20389: loss: 0.9183, policy_loss: 0.8267, value_loss: 0.4700
2024-07-11 17:40:28,361 [INFO    ] __main__: train step 20390: loss: 0.9183, policy_loss: 0.8267, value_loss: 0.4700
2024-07-11 17:40:28,561 [INFO    ] __main__: train step 20391: loss: 0.9183, policy_loss: 0.8267, value_loss: 0.4700
2024-07-11 17:40:28,769 [INFO    ] __main__: train step 20392: loss: 0.9183, policy_loss: 0.8267, value_loss: 0.4700
2024-07-11 17:40:28,966 [INFO    ] __main__: train step 20393: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4699
2024-07-11 17:40:29,168 [INFO    ] __main__: train step 20394: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4699
2024-07-11 17:40:29,361 [INFO    ] __main__: train step 20395: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4699
2024-07-11 17:40:29,577 [INFO    ] __main__: train step 20396: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4699
2024-07-11 17:40:29,775 [INFO    ] __main__: train step 20397: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4699
2024-07-11 17:40:29,983 [INFO    ] __main__: train step 20398: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4699
2024-07-11 17:40:30,224 [INFO    ] __main__: train step 20399: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4698
2024-07-11 17:40:31,663 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:40:32,052 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:40:32,108 [INFO    ] __main__: train step 20400: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4698
2024-07-11 17:40:32,292 [INFO    ] __main__: train step 20401: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4698
2024-07-11 17:40:32,489 [INFO    ] __main__: train step 20402: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4698
2024-07-11 17:40:32,703 [INFO    ] __main__: train step 20403: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4698
2024-07-11 17:40:32,921 [INFO    ] __main__: train step 20404: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4697
2024-07-11 17:40:33,121 [INFO    ] __main__: train step 20405: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4697
2024-07-11 17:40:33,326 [INFO    ] __main__: train step 20406: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4697
2024-07-11 17:40:33,539 [INFO    ] __main__: train step 20407: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4697
2024-07-11 17:40:33,730 [INFO    ] __main__: train step 20408: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4697
2024-07-11 17:40:33,938 [INFO    ] __main__: train step 20409: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4697
2024-07-11 17:40:34,145 [INFO    ] __main__: train step 20410: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4696
2024-07-11 17:40:34,356 [INFO    ] __main__: train step 20411: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4696
2024-07-11 17:40:34,551 [INFO    ] __main__: train step 20412: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4696
2024-07-11 17:40:34,755 [INFO    ] __main__: train step 20413: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4696
2024-07-11 17:40:34,949 [INFO    ] __main__: train step 20414: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4696
2024-07-11 17:40:35,159 [INFO    ] __main__: train step 20415: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4696
2024-07-11 17:40:35,360 [INFO    ] __main__: train step 20416: loss: 0.9182, policy_loss: 0.8267, value_loss: 0.4695
2024-07-11 17:40:39,151 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:40:39,585 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:40:39,645 [INFO    ] __main__: train step 20417: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4695
2024-07-11 17:40:39,817 [INFO    ] __main__: train step 20418: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4695
2024-07-11 17:40:40,024 [INFO    ] __main__: train step 20419: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4695
2024-07-11 17:40:40,229 [INFO    ] __main__: train step 20420: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4695
2024-07-11 17:40:40,442 [INFO    ] __main__: train step 20421: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4695
2024-07-11 17:40:40,644 [INFO    ] __main__: train step 20422: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4694
2024-07-11 17:40:40,854 [INFO    ] __main__: train step 20423: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4694
2024-07-11 17:40:41,062 [INFO    ] __main__: train step 20424: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4694
2024-07-11 17:40:41,265 [INFO    ] __main__: train step 20425: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4694
2024-07-11 17:40:41,467 [INFO    ] __main__: train step 20426: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4694
2024-07-11 17:40:41,673 [INFO    ] __main__: train step 20427: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4693
2024-07-11 17:40:41,881 [INFO    ] __main__: train step 20428: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4693
2024-07-11 17:40:42,089 [INFO    ] __main__: train step 20429: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4693
2024-07-11 17:40:42,305 [INFO    ] __main__: train step 20430: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4693
2024-07-11 17:40:42,539 [INFO    ] __main__: train step 20431: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4693
2024-07-11 17:40:42,753 [INFO    ] __main__: train step 20432: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4693
2024-07-11 17:40:42,949 [INFO    ] __main__: train step 20433: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4692
2024-07-11 17:40:44,389 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:40:44,778 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:40:44,833 [INFO    ] __main__: train step 20434: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4692
2024-07-11 17:40:45,027 [INFO    ] __main__: train step 20435: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4692
2024-07-11 17:40:45,252 [INFO    ] __main__: train step 20436: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4692
2024-07-11 17:40:45,471 [INFO    ] __main__: train step 20437: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4692
2024-07-11 17:40:45,665 [INFO    ] __main__: train step 20438: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4692
2024-07-11 17:40:45,893 [INFO    ] __main__: train step 20439: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4691
2024-07-11 17:40:46,104 [INFO    ] __main__: train step 20440: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4691
2024-07-11 17:40:46,331 [INFO    ] __main__: train step 20441: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4691
2024-07-11 17:40:46,538 [INFO    ] __main__: train step 20442: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4691
2024-07-11 17:40:46,736 [INFO    ] __main__: train step 20443: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4691
2024-07-11 17:40:46,943 [INFO    ] __main__: train step 20444: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4690
2024-07-11 17:40:47,136 [INFO    ] __main__: train step 20445: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4690
2024-07-11 17:40:47,347 [INFO    ] __main__: train step 20446: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4690
2024-07-11 17:40:47,557 [INFO    ] __main__: train step 20447: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4690
2024-07-11 17:40:47,781 [INFO    ] __main__: train step 20448: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4690
2024-07-11 17:40:48,013 [INFO    ] __main__: train step 20449: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4690
2024-07-11 17:40:48,251 [INFO    ] __main__: train step 20450: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4689
2024-07-11 17:40:49,747 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:40:50,127 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:40:50,184 [INFO    ] __main__: train step 20451: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4689
2024-07-11 17:40:50,367 [INFO    ] __main__: train step 20452: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4689
2024-07-11 17:40:50,568 [INFO    ] __main__: train step 20453: loss: 0.9182, policy_loss: 0.8266, value_loss: 0.4689
2024-07-11 17:40:50,792 [INFO    ] __main__: train step 20454: loss: 0.9182, policy_loss: 0.8265, value_loss: 0.4689
2024-07-11 17:40:51,033 [INFO    ] __main__: train step 20455: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4689
2024-07-11 17:40:51,237 [INFO    ] __main__: train step 20456: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4688
2024-07-11 17:40:51,445 [INFO    ] __main__: train step 20457: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4688
2024-07-11 17:40:51,656 [INFO    ] __main__: train step 20458: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4688
2024-07-11 17:40:51,856 [INFO    ] __main__: train step 20459: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4688
2024-07-11 17:40:52,062 [INFO    ] __main__: train step 20460: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4688
2024-07-11 17:40:52,273 [INFO    ] __main__: train step 20461: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4688
2024-07-11 17:40:52,487 [INFO    ] __main__: train step 20462: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4687
2024-07-11 17:40:52,684 [INFO    ] __main__: train step 20463: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4687
2024-07-11 17:40:52,891 [INFO    ] __main__: train step 20464: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4687
2024-07-11 17:40:53,089 [INFO    ] __main__: train step 20465: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4687
2024-07-11 17:40:53,288 [INFO    ] __main__: train step 20466: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4687
2024-07-11 17:40:53,492 [INFO    ] __main__: train step 20467: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4686
2024-07-11 17:40:54,946 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:40:55,330 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:40:55,385 [INFO    ] __main__: train step 20468: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4686
2024-07-11 17:40:55,558 [INFO    ] __main__: train step 20469: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4686
2024-07-11 17:40:55,765 [INFO    ] __main__: train step 20470: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4686
2024-07-11 17:40:55,967 [INFO    ] __main__: train step 20471: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4686
2024-07-11 17:40:56,159 [INFO    ] __main__: train step 20472: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4686
2024-07-11 17:40:56,360 [INFO    ] __main__: train step 20473: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4685
2024-07-11 17:40:56,567 [INFO    ] __main__: train step 20474: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4685
2024-07-11 17:40:56,767 [INFO    ] __main__: train step 20475: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4685
2024-07-11 17:40:56,976 [INFO    ] __main__: train step 20476: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4685
2024-07-11 17:40:57,176 [INFO    ] __main__: train step 20477: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4685
2024-07-11 17:40:57,398 [INFO    ] __main__: train step 20478: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4685
2024-07-11 17:40:57,636 [INFO    ] __main__: train step 20479: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4684
2024-07-11 17:40:57,841 [INFO    ] __main__: train step 20480: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4684
2024-07-11 17:40:58,046 [INFO    ] __main__: train step 20481: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4684
2024-07-11 17:40:58,247 [INFO    ] __main__: train step 20482: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4684
2024-07-11 17:40:58,456 [INFO    ] __main__: train step 20483: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4684
2024-07-11 17:40:58,657 [INFO    ] __main__: train step 20484: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4683
2024-07-11 17:41:00,107 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:41:00,553 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:41:00,611 [INFO    ] __main__: train step 20485: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4683
2024-07-11 17:41:00,786 [INFO    ] __main__: train step 20486: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4683
2024-07-11 17:41:00,994 [INFO    ] __main__: train step 20487: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4683
2024-07-11 17:41:01,211 [INFO    ] __main__: train step 20488: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4683
2024-07-11 17:41:01,410 [INFO    ] __main__: train step 20489: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4683
2024-07-11 17:41:01,612 [INFO    ] __main__: train step 20490: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4682
2024-07-11 17:41:01,817 [INFO    ] __main__: train step 20491: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4682
2024-07-11 17:41:02,024 [INFO    ] __main__: train step 20492: loss: 0.9181, policy_loss: 0.8265, value_loss: 0.4682
2024-07-11 17:41:02,229 [INFO    ] __main__: train step 20493: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4682
2024-07-11 17:41:02,437 [INFO    ] __main__: train step 20494: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4682
2024-07-11 17:41:02,655 [INFO    ] __main__: train step 20495: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4682
2024-07-11 17:41:02,867 [INFO    ] __main__: train step 20496: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4681
2024-07-11 17:41:03,113 [INFO    ] __main__: train step 20497: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4681
2024-07-11 17:41:03,342 [INFO    ] __main__: train step 20498: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4681
2024-07-11 17:41:03,540 [INFO    ] __main__: train step 20499: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4681
2024-07-11 17:41:03,763 [INFO    ] __main__: train step 20500: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4681
2024-07-11 17:41:03,979 [INFO    ] __main__: train step 20501: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4681
2024-07-11 17:41:05,440 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:41:05,835 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:41:05,895 [INFO    ] __main__: train step 20502: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4680
2024-07-11 17:41:06,086 [INFO    ] __main__: train step 20503: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4680
2024-07-11 17:41:06,283 [INFO    ] __main__: train step 20504: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4680
2024-07-11 17:41:06,487 [INFO    ] __main__: train step 20505: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4680
2024-07-11 17:41:06,691 [INFO    ] __main__: train step 20506: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4680
2024-07-11 17:41:06,887 [INFO    ] __main__: train step 20507: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4679
2024-07-11 17:41:07,093 [INFO    ] __main__: train step 20508: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4679
2024-07-11 17:41:07,292 [INFO    ] __main__: train step 20509: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4679
2024-07-11 17:41:07,494 [INFO    ] __main__: train step 20510: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4679
2024-07-11 17:41:07,700 [INFO    ] __main__: train step 20511: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4679
2024-07-11 17:41:07,904 [INFO    ] __main__: train step 20512: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4679
2024-07-11 17:41:08,113 [INFO    ] __main__: train step 20513: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4678
2024-07-11 17:41:08,312 [INFO    ] __main__: train step 20514: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4678
2024-07-11 17:41:08,520 [INFO    ] __main__: train step 20515: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4678
2024-07-11 17:41:08,781 [INFO    ] __main__: train step 20516: loss: 0.9181, policy_loss: 0.8264, value_loss: 0.4678
2024-07-11 17:41:09,010 [INFO    ] __main__: train step 20517: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4678
2024-07-11 17:41:09,226 [INFO    ] __main__: train step 20518: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4678
2024-07-11 17:41:10,705 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:41:11,074 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:41:11,133 [INFO    ] __main__: train step 20519: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4677
2024-07-11 17:41:11,317 [INFO    ] __main__: train step 20520: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4677
2024-07-11 17:41:11,515 [INFO    ] __main__: train step 20521: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4677
2024-07-11 17:41:11,740 [INFO    ] __main__: train step 20522: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4677
2024-07-11 17:41:11,989 [INFO    ] __main__: train step 20523: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4677
2024-07-11 17:41:12,197 [INFO    ] __main__: train step 20524: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4677
2024-07-11 17:41:12,406 [INFO    ] __main__: train step 20525: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4676
2024-07-11 17:41:12,612 [INFO    ] __main__: train step 20526: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4676
2024-07-11 17:41:12,827 [INFO    ] __main__: train step 20527: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4676
2024-07-11 17:41:13,031 [INFO    ] __main__: train step 20528: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4676
2024-07-11 17:41:13,245 [INFO    ] __main__: train step 20529: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4676
2024-07-11 17:41:13,458 [INFO    ] __main__: train step 20530: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4675
2024-07-11 17:41:13,657 [INFO    ] __main__: train step 20531: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4675
2024-07-11 17:41:13,869 [INFO    ] __main__: train step 20532: loss: 0.9180, policy_loss: 0.8264, value_loss: 0.4675
2024-07-11 17:41:14,070 [INFO    ] __main__: train step 20533: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4675
2024-07-11 17:41:14,281 [INFO    ] __main__: train step 20534: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4675
2024-07-11 17:41:14,513 [INFO    ] __main__: train step 20535: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4675
2024-07-11 17:41:15,964 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:41:16,359 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:41:16,414 [INFO    ] __main__: train step 20536: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4674
2024-07-11 17:41:16,584 [INFO    ] __main__: train step 20537: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4674
2024-07-11 17:41:16,800 [INFO    ] __main__: train step 20538: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4674
2024-07-11 17:41:17,016 [INFO    ] __main__: train step 20539: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4674
2024-07-11 17:41:17,222 [INFO    ] __main__: train step 20540: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4674
2024-07-11 17:41:17,427 [INFO    ] __main__: train step 20541: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4674
2024-07-11 17:41:17,646 [INFO    ] __main__: train step 20542: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4673
2024-07-11 17:41:17,859 [INFO    ] __main__: train step 20543: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4673
2024-07-11 17:41:18,066 [INFO    ] __main__: train step 20544: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4673
2024-07-11 17:41:18,273 [INFO    ] __main__: train step 20545: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4673
2024-07-11 17:41:18,480 [INFO    ] __main__: train step 20546: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4673
2024-07-11 17:41:18,692 [INFO    ] __main__: train step 20547: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4673
2024-07-11 17:41:18,897 [INFO    ] __main__: train step 20548: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4672
2024-07-11 17:41:19,105 [INFO    ] __main__: train step 20549: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4672
2024-07-11 17:41:19,314 [INFO    ] __main__: train step 20550: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4672
2024-07-11 17:41:19,520 [INFO    ] __main__: train step 20551: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4672
2024-07-11 17:41:19,735 [INFO    ] __main__: train step 20552: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4672
2024-07-11 17:41:21,177 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:41:21,578 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:41:21,633 [INFO    ] __main__: train step 20553: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4672
2024-07-11 17:41:21,812 [INFO    ] __main__: train step 20554: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4671
2024-07-11 17:41:22,017 [INFO    ] __main__: train step 20555: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4671
2024-07-11 17:41:22,216 [INFO    ] __main__: train step 20556: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4671
2024-07-11 17:41:24,733 [INFO    ] __main__: train step 20557: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4671
2024-07-11 17:41:24,941 [INFO    ] __main__: train step 20558: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4671
2024-07-11 17:41:25,152 [INFO    ] __main__: train step 20559: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4670
2024-07-11 17:41:25,347 [INFO    ] __main__: train step 20560: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4670
2024-07-11 17:41:25,555 [INFO    ] __main__: train step 20561: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4670
2024-07-11 17:41:25,755 [INFO    ] __main__: train step 20562: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4670
2024-07-11 17:41:25,956 [INFO    ] __main__: train step 20563: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4670
2024-07-11 17:41:26,162 [INFO    ] __main__: train step 20564: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4670
2024-07-11 17:41:26,371 [INFO    ] __main__: train step 20565: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4669
2024-07-11 17:41:26,565 [INFO    ] __main__: train step 20566: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4669
2024-07-11 17:41:26,778 [INFO    ] __main__: train step 20567: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4669
2024-07-11 17:41:26,982 [INFO    ] __main__: train step 20568: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4669
2024-07-11 17:41:27,186 [INFO    ] __main__: train step 20569: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4669
2024-07-11 17:41:28,627 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:41:28,986 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:41:29,042 [INFO    ] __main__: train step 20570: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4669
2024-07-11 17:41:29,218 [INFO    ] __main__: train step 20571: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4668
2024-07-11 17:41:29,432 [INFO    ] __main__: train step 20572: loss: 0.9180, policy_loss: 0.8263, value_loss: 0.4668
2024-07-11 17:41:29,629 [INFO    ] __main__: train step 20573: loss: 0.9180, policy_loss: 0.8262, value_loss: 0.4668
2024-07-11 17:41:29,834 [INFO    ] __main__: train step 20574: loss: 0.9180, policy_loss: 0.8262, value_loss: 0.4668
2024-07-11 17:41:30,045 [INFO    ] __main__: train step 20575: loss: 0.9180, policy_loss: 0.8262, value_loss: 0.4668
2024-07-11 17:41:30,279 [INFO    ] __main__: train step 20576: loss: 0.9180, policy_loss: 0.8262, value_loss: 0.4668
2024-07-11 17:41:30,492 [INFO    ] __main__: train step 20577: loss: 0.9180, policy_loss: 0.8262, value_loss: 0.4667
2024-07-11 17:41:30,692 [INFO    ] __main__: train step 20578: loss: 0.9180, policy_loss: 0.8262, value_loss: 0.4667
2024-07-11 17:41:30,894 [INFO    ] __main__: train step 20579: loss: 0.9180, policy_loss: 0.8262, value_loss: 0.4667
2024-07-11 17:41:31,102 [INFO    ] __main__: train step 20580: loss: 0.9180, policy_loss: 0.8262, value_loss: 0.4667
2024-07-11 17:41:31,308 [INFO    ] __main__: train step 20581: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4667
2024-07-11 17:41:31,512 [INFO    ] __main__: train step 20582: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4666
2024-07-11 17:41:31,724 [INFO    ] __main__: train step 20583: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4666
2024-07-11 17:41:31,935 [INFO    ] __main__: train step 20584: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4666
2024-07-11 17:41:32,140 [INFO    ] __main__: train step 20585: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4666
2024-07-11 17:41:32,370 [INFO    ] __main__: train step 20586: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4666
2024-07-11 17:41:33,808 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:41:34,162 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:41:34,217 [INFO    ] __main__: train step 20587: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4666
2024-07-11 17:41:34,391 [INFO    ] __main__: train step 20588: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4665
2024-07-11 17:41:34,605 [INFO    ] __main__: train step 20589: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4665
2024-07-11 17:41:34,811 [INFO    ] __main__: train step 20590: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4665
2024-07-11 17:41:35,012 [INFO    ] __main__: train step 20591: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4665
2024-07-11 17:41:35,207 [INFO    ] __main__: train step 20592: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4665
2024-07-11 17:41:35,410 [INFO    ] __main__: train step 20593: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4665
2024-07-11 17:41:35,626 [INFO    ] __main__: train step 20594: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4664
2024-07-11 17:41:35,849 [INFO    ] __main__: train step 20595: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4664
2024-07-11 17:41:36,082 [INFO    ] __main__: train step 20596: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4664
2024-07-11 17:41:36,290 [INFO    ] __main__: train step 20597: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4664
2024-07-11 17:41:36,498 [INFO    ] __main__: train step 20598: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4664
2024-07-11 17:41:36,738 [INFO    ] __main__: train step 20599: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4664
2024-07-11 17:41:36,976 [INFO    ] __main__: train step 20600: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4663
2024-07-11 17:41:37,175 [INFO    ] __main__: train step 20601: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4663
2024-07-11 17:41:37,378 [INFO    ] __main__: train step 20602: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4663
2024-07-11 17:41:37,576 [INFO    ] __main__: train step 20603: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4663
2024-07-11 17:41:39,013 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:41:39,379 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:41:39,435 [INFO    ] __main__: train step 20604: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4663
2024-07-11 17:41:39,628 [INFO    ] __main__: train step 20605: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4662
2024-07-11 17:41:39,863 [INFO    ] __main__: train step 20606: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4662
2024-07-11 17:41:40,083 [INFO    ] __main__: train step 20607: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4662
2024-07-11 17:41:40,296 [INFO    ] __main__: train step 20608: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4662
2024-07-11 17:41:40,511 [INFO    ] __main__: train step 20609: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4662
2024-07-11 17:41:40,716 [INFO    ] __main__: train step 20610: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4662
2024-07-11 17:41:40,927 [INFO    ] __main__: train step 20611: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4661
2024-07-11 17:41:41,127 [INFO    ] __main__: train step 20612: loss: 0.9179, policy_loss: 0.8262, value_loss: 0.4661
2024-07-11 17:41:41,336 [INFO    ] __main__: train step 20613: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4661
2024-07-11 17:41:41,547 [INFO    ] __main__: train step 20614: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4661
2024-07-11 17:41:41,755 [INFO    ] __main__: train step 20615: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4661
2024-07-11 17:41:41,986 [INFO    ] __main__: train step 20616: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4661
2024-07-11 17:41:42,221 [INFO    ] __main__: train step 20617: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4660
2024-07-11 17:41:42,417 [INFO    ] __main__: train step 20618: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4660
2024-07-11 17:41:42,610 [INFO    ] __main__: train step 20619: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4660
2024-07-11 17:41:42,837 [INFO    ] __main__: train step 20620: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4660
2024-07-11 17:41:44,297 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:41:44,710 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:41:44,765 [INFO    ] __main__: train step 20621: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4660
2024-07-11 17:41:44,946 [INFO    ] __main__: train step 20622: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4660
2024-07-11 17:41:45,152 [INFO    ] __main__: train step 20623: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4659
2024-07-11 17:41:45,363 [INFO    ] __main__: train step 20624: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4659
2024-07-11 17:41:45,576 [INFO    ] __main__: train step 20625: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4659
2024-07-11 17:41:45,815 [INFO    ] __main__: train step 20626: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4659
2024-07-11 17:41:46,015 [INFO    ] __main__: train step 20627: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4659
2024-07-11 17:41:46,217 [INFO    ] __main__: train step 20628: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4658
2024-07-11 17:41:46,417 [INFO    ] __main__: train step 20629: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4658
2024-07-11 17:41:46,625 [INFO    ] __main__: train step 20630: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4658
2024-07-11 17:41:46,830 [INFO    ] __main__: train step 20631: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4658
2024-07-11 17:41:47,043 [INFO    ] __main__: train step 20632: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4658
2024-07-11 17:41:47,274 [INFO    ] __main__: train step 20633: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4658
2024-07-11 17:41:47,473 [INFO    ] __main__: train step 20634: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4657
2024-07-11 17:41:47,685 [INFO    ] __main__: train step 20635: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4657
2024-07-11 17:41:47,901 [INFO    ] __main__: train step 20636: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4657
2024-07-11 17:41:48,109 [INFO    ] __main__: train step 20637: loss: 0.9179, policy_loss: 0.8261, value_loss: 0.4657
2024-07-11 17:41:49,586 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:41:49,976 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:41:50,039 [INFO    ] __main__: train step 20638: loss: 0.9178, policy_loss: 0.8261, value_loss: 0.4657
2024-07-11 17:41:50,222 [INFO    ] __main__: train step 20639: loss: 0.9178, policy_loss: 0.8261, value_loss: 0.4657
2024-07-11 17:41:50,457 [INFO    ] __main__: train step 20640: loss: 0.9178, policy_loss: 0.8261, value_loss: 0.4656
2024-07-11 17:41:50,671 [INFO    ] __main__: train step 20641: loss: 0.9178, policy_loss: 0.8261, value_loss: 0.4656
2024-07-11 17:41:50,901 [INFO    ] __main__: train step 20642: loss: 0.9178, policy_loss: 0.8261, value_loss: 0.4656
2024-07-11 17:41:51,154 [INFO    ] __main__: train step 20643: loss: 0.9178, policy_loss: 0.8261, value_loss: 0.4656
2024-07-11 17:41:51,413 [INFO    ] __main__: train step 20644: loss: 0.9178, policy_loss: 0.8261, value_loss: 0.4656
2024-07-11 17:41:51,645 [INFO    ] __main__: train step 20645: loss: 0.9178, policy_loss: 0.8261, value_loss: 0.4656
2024-07-11 17:41:51,857 [INFO    ] __main__: train step 20646: loss: 0.9178, policy_loss: 0.8261, value_loss: 0.4655
2024-07-11 17:41:52,057 [INFO    ] __main__: train step 20647: loss: 0.9178, policy_loss: 0.8261, value_loss: 0.4655
2024-07-11 17:41:52,267 [INFO    ] __main__: train step 20648: loss: 0.9178, policy_loss: 0.8261, value_loss: 0.4655
2024-07-11 17:41:52,471 [INFO    ] __main__: train step 20649: loss: 0.9178, policy_loss: 0.8261, value_loss: 0.4655
2024-07-11 17:41:52,666 [INFO    ] __main__: train step 20650: loss: 0.9178, policy_loss: 0.8261, value_loss: 0.4655
2024-07-11 17:41:52,867 [INFO    ] __main__: train step 20651: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4655
2024-07-11 17:41:53,069 [INFO    ] __main__: train step 20652: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4654
2024-07-11 17:41:53,265 [INFO    ] __main__: train step 20653: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4654
2024-07-11 17:41:53,470 [INFO    ] __main__: train step 20654: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4654
2024-07-11 17:41:54,930 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:41:55,181 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:41:55,235 [INFO    ] __main__: train step 20655: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4654
2024-07-11 17:41:55,407 [INFO    ] __main__: train step 20656: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4654
2024-07-11 17:41:55,628 [INFO    ] __main__: train step 20657: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4653
2024-07-11 17:41:55,837 [INFO    ] __main__: train step 20658: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4653
2024-07-11 17:41:56,040 [INFO    ] __main__: train step 20659: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4653
2024-07-11 17:41:56,246 [INFO    ] __main__: train step 20660: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4653
2024-07-11 17:41:56,448 [INFO    ] __main__: train step 20661: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4653
2024-07-11 17:41:56,653 [INFO    ] __main__: train step 20662: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4653
2024-07-11 17:41:56,865 [INFO    ] __main__: train step 20663: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4652
2024-07-11 17:41:57,076 [INFO    ] __main__: train step 20664: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4652
2024-07-11 17:41:57,281 [INFO    ] __main__: train step 20665: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4652
2024-07-11 17:41:57,485 [INFO    ] __main__: train step 20666: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4652
2024-07-11 17:41:57,681 [INFO    ] __main__: train step 20667: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4652
2024-07-11 17:41:57,884 [INFO    ] __main__: train step 20668: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4652
2024-07-11 17:41:58,096 [INFO    ] __main__: train step 20669: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4651
2024-07-11 17:41:58,335 [INFO    ] __main__: train step 20670: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4651
2024-07-11 17:41:58,528 [INFO    ] __main__: train step 20671: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4651
2024-07-11 17:41:59,977 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:42:00,388 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:42:00,449 [INFO    ] __main__: train step 20672: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4651
2024-07-11 17:42:00,649 [INFO    ] __main__: train step 20673: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4651
2024-07-11 17:42:00,862 [INFO    ] __main__: train step 20674: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4651
2024-07-11 17:42:01,067 [INFO    ] __main__: train step 20675: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4650
2024-07-11 17:42:01,268 [INFO    ] __main__: train step 20676: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4650
2024-07-11 17:42:01,472 [INFO    ] __main__: train step 20677: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4650
2024-07-11 17:42:01,672 [INFO    ] __main__: train step 20678: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4650
2024-07-11 17:42:01,882 [INFO    ] __main__: train step 20679: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4650
2024-07-11 17:42:02,091 [INFO    ] __main__: train step 20680: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4649
2024-07-11 17:42:02,296 [INFO    ] __main__: train step 20681: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4649
2024-07-11 17:42:02,509 [INFO    ] __main__: train step 20682: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4649
2024-07-11 17:42:02,726 [INFO    ] __main__: train step 20683: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4649
2024-07-11 17:42:02,941 [INFO    ] __main__: train step 20684: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4649
2024-07-11 17:42:03,177 [INFO    ] __main__: train step 20685: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4649
2024-07-11 17:42:03,405 [INFO    ] __main__: train step 20686: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4648
2024-07-11 17:42:03,623 [INFO    ] __main__: train step 20687: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4648
2024-07-11 17:42:03,865 [INFO    ] __main__: train step 20688: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4648
2024-07-11 17:42:05,285 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:42:05,693 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:42:05,754 [INFO    ] __main__: train step 20689: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4648
2024-07-11 17:42:05,940 [INFO    ] __main__: train step 20690: loss: 0.9178, policy_loss: 0.8260, value_loss: 0.4648
2024-07-11 17:42:06,146 [INFO    ] __main__: train step 20691: loss: 0.9178, policy_loss: 0.8259, value_loss: 0.4648
2024-07-11 17:42:06,361 [INFO    ] __main__: train step 20692: loss: 0.9178, policy_loss: 0.8259, value_loss: 0.4647
2024-07-11 17:42:06,588 [INFO    ] __main__: train step 20693: loss: 0.9178, policy_loss: 0.8259, value_loss: 0.4647
2024-07-11 17:42:06,797 [INFO    ] __main__: train step 20694: loss: 0.9178, policy_loss: 0.8259, value_loss: 0.4647
2024-07-11 17:42:09,268 [INFO    ] __main__: train step 20695: loss: 0.9178, policy_loss: 0.8259, value_loss: 0.4647
2024-07-11 17:42:09,493 [INFO    ] __main__: train step 20696: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4647
2024-07-11 17:42:09,692 [INFO    ] __main__: train step 20697: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4647
2024-07-11 17:42:09,899 [INFO    ] __main__: train step 20698: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4646
2024-07-11 17:42:10,102 [INFO    ] __main__: train step 20699: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4646
2024-07-11 17:42:10,303 [INFO    ] __main__: train step 20700: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4646
2024-07-11 17:42:10,509 [INFO    ] __main__: train step 20701: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4646
2024-07-11 17:42:10,715 [INFO    ] __main__: train step 20702: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4646
2024-07-11 17:42:10,920 [INFO    ] __main__: train step 20703: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4645
2024-07-11 17:42:11,121 [INFO    ] __main__: train step 20704: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4645
2024-07-11 17:42:11,339 [INFO    ] __main__: train step 20705: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4645
2024-07-11 17:42:12,781 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:42:13,149 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:42:13,208 [INFO    ] __main__: train step 20706: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4645
2024-07-11 17:42:13,383 [INFO    ] __main__: train step 20707: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4645
2024-07-11 17:42:13,601 [INFO    ] __main__: train step 20708: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4645
2024-07-11 17:42:13,822 [INFO    ] __main__: train step 20709: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4644
2024-07-11 17:42:14,025 [INFO    ] __main__: train step 20710: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4644
2024-07-11 17:42:14,248 [INFO    ] __main__: train step 20711: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4644
2024-07-11 17:42:14,453 [INFO    ] __main__: train step 20712: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4644
2024-07-11 17:42:14,659 [INFO    ] __main__: train step 20713: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4644
2024-07-11 17:42:14,880 [INFO    ] __main__: train step 20714: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4644
2024-07-11 17:42:15,088 [INFO    ] __main__: train step 20715: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4643
2024-07-11 17:42:15,310 [INFO    ] __main__: train step 20716: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4643
2024-07-11 17:42:15,549 [INFO    ] __main__: train step 20717: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4643
2024-07-11 17:42:15,752 [INFO    ] __main__: train step 20718: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4643
2024-07-11 17:42:15,950 [INFO    ] __main__: train step 20719: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4643
2024-07-11 17:42:16,154 [INFO    ] __main__: train step 20720: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4643
2024-07-11 17:42:16,352 [INFO    ] __main__: train step 20721: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4642
2024-07-11 17:42:16,571 [INFO    ] __main__: train step 20722: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4642
2024-07-11 17:42:18,009 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:42:18,372 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:42:18,428 [INFO    ] __main__: train step 20723: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4642
2024-07-11 17:42:18,611 [INFO    ] __main__: train step 20724: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4642
2024-07-11 17:42:18,813 [INFO    ] __main__: train step 20725: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4642
2024-07-11 17:42:19,026 [INFO    ] __main__: train step 20726: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4641
2024-07-11 17:42:19,224 [INFO    ] __main__: train step 20727: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4641
2024-07-11 17:42:19,418 [INFO    ] __main__: train step 20728: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4641
2024-07-11 17:42:19,621 [INFO    ] __main__: train step 20729: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4641
2024-07-11 17:42:19,829 [INFO    ] __main__: train step 20730: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4641
2024-07-11 17:42:20,040 [INFO    ] __main__: train step 20731: loss: 0.9177, policy_loss: 0.8259, value_loss: 0.4641
2024-07-11 17:42:20,250 [INFO    ] __main__: train step 20732: loss: 0.9177, policy_loss: 0.8258, value_loss: 0.4640
2024-07-11 17:42:20,449 [INFO    ] __main__: train step 20733: loss: 0.9177, policy_loss: 0.8258, value_loss: 0.4640
2024-07-11 17:42:20,661 [INFO    ] __main__: train step 20734: loss: 0.9177, policy_loss: 0.8258, value_loss: 0.4640
2024-07-11 17:42:20,884 [INFO    ] __main__: train step 20735: loss: 0.9177, policy_loss: 0.8258, value_loss: 0.4640
2024-07-11 17:42:21,114 [INFO    ] __main__: train step 20736: loss: 0.9177, policy_loss: 0.8258, value_loss: 0.4640
2024-07-11 17:42:21,319 [INFO    ] __main__: train step 20737: loss: 0.9177, policy_loss: 0.8258, value_loss: 0.4640
2024-07-11 17:42:21,525 [INFO    ] __main__: train step 20738: loss: 0.9177, policy_loss: 0.8258, value_loss: 0.4639
2024-07-11 17:42:21,755 [INFO    ] __main__: train step 20739: loss: 0.9177, policy_loss: 0.8258, value_loss: 0.4639
2024-07-11 17:42:23,193 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:42:23,577 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:42:23,639 [INFO    ] __main__: train step 20740: loss: 0.9177, policy_loss: 0.8258, value_loss: 0.4639
2024-07-11 17:42:23,821 [INFO    ] __main__: train step 20741: loss: 0.9177, policy_loss: 0.8258, value_loss: 0.4639
2024-07-11 17:42:24,036 [INFO    ] __main__: train step 20742: loss: 0.9177, policy_loss: 0.8258, value_loss: 0.4639
2024-07-11 17:42:24,247 [INFO    ] __main__: train step 20743: loss: 0.9177, policy_loss: 0.8258, value_loss: 0.4639
2024-07-11 17:42:24,461 [INFO    ] __main__: train step 20744: loss: 0.9177, policy_loss: 0.8258, value_loss: 0.4638
2024-07-11 17:42:24,670 [INFO    ] __main__: train step 20745: loss: 0.9177, policy_loss: 0.8258, value_loss: 0.4638
2024-07-11 17:42:24,865 [INFO    ] __main__: train step 20746: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4638
2024-07-11 17:42:25,073 [INFO    ] __main__: train step 20747: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4638
2024-07-11 17:42:25,291 [INFO    ] __main__: train step 20748: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4638
2024-07-11 17:42:25,489 [INFO    ] __main__: train step 20749: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4637
2024-07-11 17:42:25,710 [INFO    ] __main__: train step 20750: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4637
2024-07-11 17:42:25,942 [INFO    ] __main__: train step 20751: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4637
2024-07-11 17:42:26,150 [INFO    ] __main__: train step 20752: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4637
2024-07-11 17:42:26,358 [INFO    ] __main__: train step 20753: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4637
2024-07-11 17:42:26,569 [INFO    ] __main__: train step 20754: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4637
2024-07-11 17:42:26,774 [INFO    ] __main__: train step 20755: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4636
2024-07-11 17:42:26,995 [INFO    ] __main__: train step 20756: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4636
2024-07-11 17:42:28,419 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:42:28,832 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:42:28,889 [INFO    ] __main__: train step 20757: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4636
2024-07-11 17:42:29,081 [INFO    ] __main__: train step 20758: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4636
2024-07-11 17:42:29,278 [INFO    ] __main__: train step 20759: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4636
2024-07-11 17:42:29,500 [INFO    ] __main__: train step 20760: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4636
2024-07-11 17:42:29,703 [INFO    ] __main__: train step 20761: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4635
2024-07-11 17:42:29,916 [INFO    ] __main__: train step 20762: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4635
2024-07-11 17:42:30,114 [INFO    ] __main__: train step 20763: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4635
2024-07-11 17:42:30,312 [INFO    ] __main__: train step 20764: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4635
2024-07-11 17:42:30,528 [INFO    ] __main__: train step 20765: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4635
2024-07-11 17:42:30,732 [INFO    ] __main__: train step 20766: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4635
2024-07-11 17:42:30,932 [INFO    ] __main__: train step 20767: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4634
2024-07-11 17:42:31,139 [INFO    ] __main__: train step 20768: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4634
2024-07-11 17:42:31,351 [INFO    ] __main__: train step 20769: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4634
2024-07-11 17:42:31,562 [INFO    ] __main__: train step 20770: loss: 0.9176, policy_loss: 0.8258, value_loss: 0.4634
2024-07-11 17:42:31,767 [INFO    ] __main__: train step 20771: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4634
2024-07-11 17:42:31,982 [INFO    ] __main__: train step 20772: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4634
2024-07-11 17:42:32,209 [INFO    ] __main__: train step 20773: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4633
2024-07-11 17:42:33,645 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:42:34,025 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:42:34,081 [INFO    ] __main__: train step 20774: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4633
2024-07-11 17:42:34,274 [INFO    ] __main__: train step 20775: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4633
2024-07-11 17:42:34,475 [INFO    ] __main__: train step 20776: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4633
2024-07-11 17:42:34,673 [INFO    ] __main__: train step 20777: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4633
2024-07-11 17:42:34,885 [INFO    ] __main__: train step 20778: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4632
2024-07-11 17:42:35,083 [INFO    ] __main__: train step 20779: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4632
2024-07-11 17:42:35,283 [INFO    ] __main__: train step 20780: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4632
2024-07-11 17:42:35,487 [INFO    ] __main__: train step 20781: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4632
2024-07-11 17:42:35,704 [INFO    ] __main__: train step 20782: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4632
2024-07-11 17:42:35,914 [INFO    ] __main__: train step 20783: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4632
2024-07-11 17:42:36,109 [INFO    ] __main__: train step 20784: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4631
2024-07-11 17:42:36,317 [INFO    ] __main__: train step 20785: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4631
2024-07-11 17:42:36,518 [INFO    ] __main__: train step 20786: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4631
2024-07-11 17:42:36,716 [INFO    ] __main__: train step 20787: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4631
2024-07-11 17:42:36,923 [INFO    ] __main__: train step 20788: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4631
2024-07-11 17:42:37,121 [INFO    ] __main__: train step 20789: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4631
2024-07-11 17:42:37,327 [INFO    ] __main__: train step 20790: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4630
2024-07-11 17:42:38,762 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:42:39,135 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:42:39,191 [INFO    ] __main__: train step 20791: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4630
2024-07-11 17:42:39,378 [INFO    ] __main__: train step 20792: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4630
2024-07-11 17:42:39,590 [INFO    ] __main__: train step 20793: loss: 0.9176, policy_loss: 0.8257, value_loss: 0.4630
2024-07-11 17:42:39,822 [INFO    ] __main__: train step 20794: loss: 0.9175, policy_loss: 0.8257, value_loss: 0.4630
2024-07-11 17:42:40,019 [INFO    ] __main__: train step 20795: loss: 0.9175, policy_loss: 0.8257, value_loss: 0.4630
2024-07-11 17:42:40,229 [INFO    ] __main__: train step 20796: loss: 0.9175, policy_loss: 0.8257, value_loss: 0.4629
2024-07-11 17:42:40,434 [INFO    ] __main__: train step 20797: loss: 0.9175, policy_loss: 0.8257, value_loss: 0.4629
2024-07-11 17:42:40,644 [INFO    ] __main__: train step 20798: loss: 0.9175, policy_loss: 0.8257, value_loss: 0.4629
2024-07-11 17:42:40,853 [INFO    ] __main__: train step 20799: loss: 0.9175, policy_loss: 0.8257, value_loss: 0.4629
2024-07-11 17:42:41,060 [INFO    ] __main__: train step 20800: loss: 0.9175, policy_loss: 0.8257, value_loss: 0.4629
2024-07-11 17:42:41,259 [INFO    ] __main__: train step 20801: loss: 0.9175, policy_loss: 0.8257, value_loss: 0.4628
2024-07-11 17:42:41,458 [INFO    ] __main__: train step 20802: loss: 0.9175, policy_loss: 0.8257, value_loss: 0.4628
2024-07-11 17:42:41,672 [INFO    ] __main__: train step 20803: loss: 0.9175, policy_loss: 0.8257, value_loss: 0.4628
2024-07-11 17:42:41,883 [INFO    ] __main__: train step 20804: loss: 0.9175, policy_loss: 0.8257, value_loss: 0.4628
2024-07-11 17:42:42,103 [INFO    ] __main__: train step 20805: loss: 0.9175, policy_loss: 0.8257, value_loss: 0.4628
2024-07-11 17:42:42,342 [INFO    ] __main__: train step 20806: loss: 0.9175, policy_loss: 0.8257, value_loss: 0.4628
2024-07-11 17:42:42,541 [INFO    ] __main__: train step 20807: loss: 0.9175, policy_loss: 0.8257, value_loss: 0.4627
2024-07-11 17:42:43,980 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:42:44,346 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:42:44,402 [INFO    ] __main__: train step 20808: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4627
2024-07-11 17:42:44,578 [INFO    ] __main__: train step 20809: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4627
2024-07-11 17:42:44,801 [INFO    ] __main__: train step 20810: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4627
2024-07-11 17:42:45,002 [INFO    ] __main__: train step 20811: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4627
2024-07-11 17:42:45,211 [INFO    ] __main__: train step 20812: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4627
2024-07-11 17:42:45,427 [INFO    ] __main__: train step 20813: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4626
2024-07-11 17:42:45,627 [INFO    ] __main__: train step 20814: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4626
2024-07-11 17:42:45,832 [INFO    ] __main__: train step 20815: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4626
2024-07-11 17:42:46,032 [INFO    ] __main__: train step 20816: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4626
2024-07-11 17:42:46,245 [INFO    ] __main__: train step 20817: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4626
2024-07-11 17:42:46,444 [INFO    ] __main__: train step 20818: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4625
2024-07-11 17:42:46,643 [INFO    ] __main__: train step 20819: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4625
2024-07-11 17:42:46,845 [INFO    ] __main__: train step 20820: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4625
2024-07-11 17:42:47,038 [INFO    ] __main__: train step 20821: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4625
2024-07-11 17:42:47,243 [INFO    ] __main__: train step 20822: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4625
2024-07-11 17:42:47,450 [INFO    ] __main__: train step 20823: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4625
2024-07-11 17:42:47,654 [INFO    ] __main__: train step 20824: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4624
2024-07-11 17:42:49,088 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:42:49,454 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:42:49,509 [INFO    ] __main__: train step 20825: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4624
2024-07-11 17:42:49,681 [INFO    ] __main__: train step 20826: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4624
2024-07-11 17:42:49,887 [INFO    ] __main__: train step 20827: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4624
2024-07-11 17:42:50,087 [INFO    ] __main__: train step 20828: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4624
2024-07-11 17:42:50,294 [INFO    ] __main__: train step 20829: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4624
2024-07-11 17:42:50,491 [INFO    ] __main__: train step 20830: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4623
2024-07-11 17:42:50,702 [INFO    ] __main__: train step 20831: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4623
2024-07-11 17:42:50,916 [INFO    ] __main__: train step 20832: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4623
2024-07-11 17:42:51,158 [INFO    ] __main__: train step 20833: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4623
2024-07-11 17:42:51,405 [INFO    ] __main__: train step 20834: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4623
2024-07-11 17:42:51,634 [INFO    ] __main__: train step 20835: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4623
2024-07-11 17:42:54,050 [INFO    ] __main__: train step 20836: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4622
2024-07-11 17:42:54,277 [INFO    ] __main__: train step 20837: loss: 0.9175, policy_loss: 0.8256, value_loss: 0.4622
2024-07-11 17:42:54,477 [INFO    ] __main__: train step 20838: loss: 0.9174, policy_loss: 0.8256, value_loss: 0.4622
2024-07-11 17:42:54,671 [INFO    ] __main__: train step 20839: loss: 0.9174, policy_loss: 0.8256, value_loss: 0.4622
2024-07-11 17:42:54,881 [INFO    ] __main__: train step 20840: loss: 0.9174, policy_loss: 0.8256, value_loss: 0.4622
2024-07-11 17:42:55,089 [INFO    ] __main__: train step 20841: loss: 0.9174, policy_loss: 0.8256, value_loss: 0.4621
2024-07-11 17:42:56,562 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:42:56,944 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:42:57,002 [INFO    ] __main__: train step 20842: loss: 0.9174, policy_loss: 0.8256, value_loss: 0.4621
2024-07-11 17:42:57,183 [INFO    ] __main__: train step 20843: loss: 0.9174, policy_loss: 0.8256, value_loss: 0.4621
2024-07-11 17:42:57,389 [INFO    ] __main__: train step 20844: loss: 0.9174, policy_loss: 0.8256, value_loss: 0.4621
2024-07-11 17:42:57,599 [INFO    ] __main__: train step 20845: loss: 0.9174, policy_loss: 0.8256, value_loss: 0.4621
2024-07-11 17:42:57,817 [INFO    ] __main__: train step 20846: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4621
2024-07-11 17:42:58,047 [INFO    ] __main__: train step 20847: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4620
2024-07-11 17:42:58,264 [INFO    ] __main__: train step 20848: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4620
2024-07-11 17:42:58,477 [INFO    ] __main__: train step 20849: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4620
2024-07-11 17:42:58,680 [INFO    ] __main__: train step 20850: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4620
2024-07-11 17:42:58,881 [INFO    ] __main__: train step 20851: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4620
2024-07-11 17:42:59,082 [INFO    ] __main__: train step 20852: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4620
2024-07-11 17:42:59,284 [INFO    ] __main__: train step 20853: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4619
2024-07-11 17:42:59,478 [INFO    ] __main__: train step 20854: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4619
2024-07-11 17:42:59,693 [INFO    ] __main__: train step 20855: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4619
2024-07-11 17:42:59,918 [INFO    ] __main__: train step 20856: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4619
2024-07-11 17:43:00,131 [INFO    ] __main__: train step 20857: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4619
2024-07-11 17:43:00,339 [INFO    ] __main__: train step 20858: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4618
2024-07-11 17:43:01,798 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:43:02,177 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:43:02,236 [INFO    ] __main__: train step 20859: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4618
2024-07-11 17:43:02,411 [INFO    ] __main__: train step 20860: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4618
2024-07-11 17:43:02,623 [INFO    ] __main__: train step 20861: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4618
2024-07-11 17:43:02,834 [INFO    ] __main__: train step 20862: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4618
2024-07-11 17:43:03,045 [INFO    ] __main__: train step 20863: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4618
2024-07-11 17:43:03,254 [INFO    ] __main__: train step 20864: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4617
2024-07-11 17:43:03,493 [INFO    ] __main__: train step 20865: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4617
2024-07-11 17:43:03,692 [INFO    ] __main__: train step 20866: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4617
2024-07-11 17:43:03,898 [INFO    ] __main__: train step 20867: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4617
2024-07-11 17:43:04,093 [INFO    ] __main__: train step 20868: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4617
2024-07-11 17:43:04,304 [INFO    ] __main__: train step 20869: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4617
2024-07-11 17:43:04,501 [INFO    ] __main__: train step 20870: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4616
2024-07-11 17:43:04,701 [INFO    ] __main__: train step 20871: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4616
2024-07-11 17:43:04,900 [INFO    ] __main__: train step 20872: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4616
2024-07-11 17:43:05,106 [INFO    ] __main__: train step 20873: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4616
2024-07-11 17:43:05,306 [INFO    ] __main__: train step 20874: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4616
2024-07-11 17:43:05,515 [INFO    ] __main__: train step 20875: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4616
2024-07-11 17:43:06,997 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:43:07,381 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:43:07,437 [INFO    ] __main__: train step 20876: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4615
2024-07-11 17:43:07,616 [INFO    ] __main__: train step 20877: loss: 0.9174, policy_loss: 0.8255, value_loss: 0.4615
2024-07-11 17:43:07,854 [INFO    ] __main__: train step 20878: loss: 0.9173, policy_loss: 0.8255, value_loss: 0.4615
2024-07-11 17:43:08,086 [INFO    ] __main__: train step 20879: loss: 0.9173, policy_loss: 0.8255, value_loss: 0.4615
2024-07-11 17:43:08,285 [INFO    ] __main__: train step 20880: loss: 0.9173, policy_loss: 0.8255, value_loss: 0.4615
2024-07-11 17:43:08,484 [INFO    ] __main__: train step 20881: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4615
2024-07-11 17:43:08,692 [INFO    ] __main__: train step 20882: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4614
2024-07-11 17:43:08,907 [INFO    ] __main__: train step 20883: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4614
2024-07-11 17:43:09,115 [INFO    ] __main__: train step 20884: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4614
2024-07-11 17:43:09,322 [INFO    ] __main__: train step 20885: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4614
2024-07-11 17:43:09,573 [INFO    ] __main__: train step 20886: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4614
2024-07-11 17:43:09,803 [INFO    ] __main__: train step 20887: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4614
2024-07-11 17:43:10,014 [INFO    ] __main__: train step 20888: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4613
2024-07-11 17:43:10,208 [INFO    ] __main__: train step 20889: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4613
2024-07-11 17:43:10,420 [INFO    ] __main__: train step 20890: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4613
2024-07-11 17:43:10,619 [INFO    ] __main__: train step 20891: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4613
2024-07-11 17:43:10,817 [INFO    ] __main__: train step 20892: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4613
2024-07-11 17:43:12,269 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:43:12,629 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:43:12,686 [INFO    ] __main__: train step 20893: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4612
2024-07-11 17:43:12,866 [INFO    ] __main__: train step 20894: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4612
2024-07-11 17:43:13,068 [INFO    ] __main__: train step 20895: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4612
2024-07-11 17:43:13,277 [INFO    ] __main__: train step 20896: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4612
2024-07-11 17:43:13,484 [INFO    ] __main__: train step 20897: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4612
2024-07-11 17:43:13,684 [INFO    ] __main__: train step 20898: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4612
2024-07-11 17:43:13,886 [INFO    ] __main__: train step 20899: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4611
2024-07-11 17:43:14,088 [INFO    ] __main__: train step 20900: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4611
2024-07-11 17:43:14,300 [INFO    ] __main__: train step 20901: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4611
2024-07-11 17:43:14,498 [INFO    ] __main__: train step 20902: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4611
2024-07-11 17:43:14,723 [INFO    ] __main__: train step 20903: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4611
2024-07-11 17:43:14,951 [INFO    ] __main__: train step 20904: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4611
2024-07-11 17:43:15,158 [INFO    ] __main__: train step 20905: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4610
2024-07-11 17:43:15,375 [INFO    ] __main__: train step 20906: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4610
2024-07-11 17:43:15,617 [INFO    ] __main__: train step 20907: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4610
2024-07-11 17:43:15,809 [INFO    ] __main__: train step 20908: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4610
2024-07-11 17:43:16,006 [INFO    ] __main__: train step 20909: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4610
2024-07-11 17:43:17,445 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:43:17,828 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:43:17,886 [INFO    ] __main__: train step 20910: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4609
2024-07-11 17:43:18,081 [INFO    ] __main__: train step 20911: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4609
2024-07-11 17:43:18,317 [INFO    ] __main__: train step 20912: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4609
2024-07-11 17:43:18,525 [INFO    ] __main__: train step 20913: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4609
2024-07-11 17:43:18,734 [INFO    ] __main__: train step 20914: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4609
2024-07-11 17:43:18,966 [INFO    ] __main__: train step 20915: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4609
2024-07-11 17:43:19,182 [INFO    ] __main__: train step 20916: loss: 0.9173, policy_loss: 0.8254, value_loss: 0.4608
2024-07-11 17:43:19,424 [INFO    ] __main__: train step 20917: loss: 0.9173, policy_loss: 0.8253, value_loss: 0.4608
2024-07-11 17:43:19,626 [INFO    ] __main__: train step 20918: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4608
2024-07-11 17:43:19,835 [INFO    ] __main__: train step 20919: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4608
2024-07-11 17:43:20,030 [INFO    ] __main__: train step 20920: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4608
2024-07-11 17:43:20,238 [INFO    ] __main__: train step 20921: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4608
2024-07-11 17:43:20,444 [INFO    ] __main__: train step 20922: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4607
2024-07-11 17:43:20,653 [INFO    ] __main__: train step 20923: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4607
2024-07-11 17:43:20,874 [INFO    ] __main__: train step 20924: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4607
2024-07-11 17:43:21,094 [INFO    ] __main__: train step 20925: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4607
2024-07-11 17:43:21,325 [INFO    ] __main__: train step 20926: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4607
2024-07-11 17:43:22,800 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:43:23,164 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:43:23,219 [INFO    ] __main__: train step 20927: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4607
2024-07-11 17:43:23,403 [INFO    ] __main__: train step 20928: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4606
2024-07-11 17:43:23,610 [INFO    ] __main__: train step 20929: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4606
2024-07-11 17:43:23,820 [INFO    ] __main__: train step 20930: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4606
2024-07-11 17:43:24,049 [INFO    ] __main__: train step 20931: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4606
2024-07-11 17:43:24,251 [INFO    ] __main__: train step 20932: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4606
2024-07-11 17:43:24,462 [INFO    ] __main__: train step 20933: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4606
2024-07-11 17:43:24,662 [INFO    ] __main__: train step 20934: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4605
2024-07-11 17:43:24,888 [INFO    ] __main__: train step 20935: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4605
2024-07-11 17:43:25,087 [INFO    ] __main__: train step 20936: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4605
2024-07-11 17:43:25,290 [INFO    ] __main__: train step 20937: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4605
2024-07-11 17:43:25,500 [INFO    ] __main__: train step 20938: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4605
2024-07-11 17:43:25,698 [INFO    ] __main__: train step 20939: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4604
2024-07-11 17:43:25,892 [INFO    ] __main__: train step 20940: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4604
2024-07-11 17:43:26,098 [INFO    ] __main__: train step 20941: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4604
2024-07-11 17:43:26,308 [INFO    ] __main__: train step 20942: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4604
2024-07-11 17:43:26,525 [INFO    ] __main__: train step 20943: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4604
2024-07-11 17:43:28,004 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:43:28,363 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:43:28,421 [INFO    ] __main__: train step 20944: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4604
2024-07-11 17:43:28,592 [INFO    ] __main__: train step 20945: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4603
2024-07-11 17:43:28,792 [INFO    ] __main__: train step 20946: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4603
2024-07-11 17:43:28,989 [INFO    ] __main__: train step 20947: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4603
2024-07-11 17:43:29,185 [INFO    ] __main__: train step 20948: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4603
2024-07-11 17:43:29,385 [INFO    ] __main__: train step 20949: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4603
2024-07-11 17:43:29,582 [INFO    ] __main__: train step 20950: loss: 0.9172, policy_loss: 0.8253, value_loss: 0.4603
2024-07-11 17:43:29,799 [INFO    ] __main__: train step 20951: loss: 0.9172, policy_loss: 0.8252, value_loss: 0.4602
2024-07-11 17:43:30,053 [INFO    ] __main__: train step 20952: loss: 0.9172, policy_loss: 0.8252, value_loss: 0.4602
2024-07-11 17:43:30,292 [INFO    ] __main__: train step 20953: loss: 0.9172, policy_loss: 0.8252, value_loss: 0.4602
2024-07-11 17:43:30,491 [INFO    ] __main__: train step 20954: loss: 0.9172, policy_loss: 0.8252, value_loss: 0.4602
2024-07-11 17:43:30,700 [INFO    ] __main__: train step 20955: loss: 0.9172, policy_loss: 0.8252, value_loss: 0.4602
2024-07-11 17:43:30,902 [INFO    ] __main__: train step 20956: loss: 0.9172, policy_loss: 0.8252, value_loss: 0.4602
2024-07-11 17:43:31,105 [INFO    ] __main__: train step 20957: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4601
2024-07-11 17:43:31,314 [INFO    ] __main__: train step 20958: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4601
2024-07-11 17:43:31,533 [INFO    ] __main__: train step 20959: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4601
2024-07-11 17:43:31,740 [INFO    ] __main__: train step 20960: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4601
2024-07-11 17:43:33,170 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:43:33,594 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:43:33,657 [INFO    ] __main__: train step 20961: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4601
2024-07-11 17:43:33,832 [INFO    ] __main__: train step 20962: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4601
2024-07-11 17:43:34,033 [INFO    ] __main__: train step 20963: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4600
2024-07-11 17:43:34,235 [INFO    ] __main__: train step 20964: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4600
2024-07-11 17:43:34,433 [INFO    ] __main__: train step 20965: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4600
2024-07-11 17:43:34,651 [INFO    ] __main__: train step 20966: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4600
2024-07-11 17:43:34,880 [INFO    ] __main__: train step 20967: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4600
2024-07-11 17:43:35,094 [INFO    ] __main__: train step 20968: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4599
2024-07-11 17:43:35,296 [INFO    ] __main__: train step 20969: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4599
2024-07-11 17:43:35,501 [INFO    ] __main__: train step 20970: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4599
2024-07-11 17:43:35,726 [INFO    ] __main__: train step 20971: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4599
2024-07-11 17:43:35,960 [INFO    ] __main__: train step 20972: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4599
2024-07-11 17:43:36,179 [INFO    ] __main__: train step 20973: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4599
2024-07-11 17:43:38,593 [INFO    ] __main__: train step 20974: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4598
2024-07-11 17:43:38,821 [INFO    ] __main__: train step 20975: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4598
2024-07-11 17:43:39,027 [INFO    ] __main__: train step 20976: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4598
2024-07-11 17:43:39,227 [INFO    ] __main__: train step 20977: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4598
2024-07-11 17:43:40,685 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:43:41,093 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:43:41,148 [INFO    ] __main__: train step 20978: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4598
2024-07-11 17:43:41,328 [INFO    ] __main__: train step 20979: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4598
2024-07-11 17:43:41,526 [INFO    ] __main__: train step 20980: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4597
2024-07-11 17:43:41,738 [INFO    ] __main__: train step 20981: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4597
2024-07-11 17:43:41,951 [INFO    ] __main__: train step 20982: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4597
2024-07-11 17:43:42,168 [INFO    ] __main__: train step 20983: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4597
2024-07-11 17:43:42,398 [INFO    ] __main__: train step 20984: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4597
2024-07-11 17:43:42,611 [INFO    ] __main__: train step 20985: loss: 0.9171, policy_loss: 0.8252, value_loss: 0.4597
2024-07-11 17:43:42,809 [INFO    ] __main__: train step 20986: loss: 0.9171, policy_loss: 0.8251, value_loss: 0.4596
2024-07-11 17:43:43,021 [INFO    ] __main__: train step 20987: loss: 0.9171, policy_loss: 0.8251, value_loss: 0.4596
2024-07-11 17:43:43,217 [INFO    ] __main__: train step 20988: loss: 0.9171, policy_loss: 0.8251, value_loss: 0.4596
2024-07-11 17:43:43,416 [INFO    ] __main__: train step 20989: loss: 0.9171, policy_loss: 0.8251, value_loss: 0.4596
2024-07-11 17:43:43,611 [INFO    ] __main__: train step 20990: loss: 0.9171, policy_loss: 0.8251, value_loss: 0.4596
2024-07-11 17:43:43,812 [INFO    ] __main__: train step 20991: loss: 0.9171, policy_loss: 0.8251, value_loss: 0.4595
2024-07-11 17:43:44,016 [INFO    ] __main__: train step 20992: loss: 0.9171, policy_loss: 0.8251, value_loss: 0.4595
2024-07-11 17:43:44,218 [INFO    ] __main__: train step 20993: loss: 0.9171, policy_loss: 0.8251, value_loss: 0.4595
2024-07-11 17:43:44,422 [INFO    ] __main__: train step 20994: loss: 0.9171, policy_loss: 0.8251, value_loss: 0.4595
2024-07-11 17:43:45,872 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:43:46,295 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:43:46,350 [INFO    ] __main__: train step 20995: loss: 0.9171, policy_loss: 0.8251, value_loss: 0.4595
2024-07-11 17:43:46,535 [INFO    ] __main__: train step 20996: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4595
2024-07-11 17:43:46,729 [INFO    ] __main__: train step 20997: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4594
2024-07-11 17:43:46,943 [INFO    ] __main__: train step 20998: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4594
2024-07-11 17:43:47,153 [INFO    ] __main__: train step 20999: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4594
2024-07-11 17:43:47,367 [INFO    ] __main__: train step 21000: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4594
2024-07-11 17:43:47,480 [INFO    ] __main__: restored step 20000 for evaluation
2024-07-11 17:43:55,351 [INFO    ] __main__: later network ELO difference from earlier network: +46 (+8/-8) ELO from 32000 self-played games
2024-07-11 17:43:55,351 [INFO    ] __main__: game outcomes: W: 17618, D: 188, L: 14194
2024-07-11 17:43:55,354 [INFO    ] __main__: validation_elo_delta: 46, validation_elo: 2786
2024-07-11 17:43:55,880 [INFO    ] __main__: train step 21001: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4594
2024-07-11 17:43:56,090 [INFO    ] __main__: train step 21002: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4594
2024-07-11 17:43:56,300 [INFO    ] __main__: train step 21003: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4593
2024-07-11 17:43:56,508 [INFO    ] __main__: train step 21004: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4593
2024-07-11 17:43:56,728 [INFO    ] __main__: train step 21005: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4593
2024-07-11 17:43:56,941 [INFO    ] __main__: train step 21006: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4593
2024-07-11 17:43:57,159 [INFO    ] __main__: train step 21007: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4593
2024-07-11 17:43:57,369 [INFO    ] __main__: train step 21008: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4593
2024-07-11 17:43:57,589 [INFO    ] __main__: train step 21009: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4592
2024-07-11 17:43:57,796 [INFO    ] __main__: train step 21010: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4592
2024-07-11 17:43:57,984 [INFO    ] __main__: train step 21011: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4592
2024-07-11 17:43:59,406 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:43:59,949 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:44:00,004 [INFO    ] __main__: train step 21012: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4592
2024-07-11 17:44:00,185 [INFO    ] __main__: train step 21013: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4592
2024-07-11 17:44:00,392 [INFO    ] __main__: train step 21014: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4591
2024-07-11 17:44:00,602 [INFO    ] __main__: train step 21015: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4591
2024-07-11 17:44:00,805 [INFO    ] __main__: train step 21016: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4591
2024-07-11 17:44:01,015 [INFO    ] __main__: train step 21017: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4591
2024-07-11 17:44:01,212 [INFO    ] __main__: train step 21018: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4591
2024-07-11 17:44:01,422 [INFO    ] __main__: train step 21019: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4591
2024-07-11 17:44:01,620 [INFO    ] __main__: train step 21020: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4590
2024-07-11 17:44:01,823 [INFO    ] __main__: train step 21021: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4590
2024-07-11 17:44:02,027 [INFO    ] __main__: train step 21022: loss: 0.9170, policy_loss: 0.8251, value_loss: 0.4590
2024-07-11 17:44:02,224 [INFO    ] __main__: train step 21023: loss: 0.9170, policy_loss: 0.8250, value_loss: 0.4590
2024-07-11 17:44:02,425 [INFO    ] __main__: train step 21024: loss: 0.9170, policy_loss: 0.8250, value_loss: 0.4590
2024-07-11 17:44:02,641 [INFO    ] __main__: train step 21025: loss: 0.9170, policy_loss: 0.8250, value_loss: 0.4590
2024-07-11 17:44:02,854 [INFO    ] __main__: train step 21026: loss: 0.9170, policy_loss: 0.8250, value_loss: 0.4589
2024-07-11 17:44:03,064 [INFO    ] __main__: train step 21027: loss: 0.9170, policy_loss: 0.8250, value_loss: 0.4589
2024-07-11 17:44:03,262 [INFO    ] __main__: train step 21028: loss: 0.9170, policy_loss: 0.8250, value_loss: 0.4589
2024-07-11 17:44:04,718 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:44:05,167 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:44:05,233 [INFO    ] __main__: train step 21029: loss: 0.9170, policy_loss: 0.8250, value_loss: 0.4589
2024-07-11 17:44:05,403 [INFO    ] __main__: train step 21030: loss: 0.9170, policy_loss: 0.8250, value_loss: 0.4589
2024-07-11 17:44:05,605 [INFO    ] __main__: train step 21031: loss: 0.9170, policy_loss: 0.8250, value_loss: 0.4589
2024-07-11 17:44:05,814 [INFO    ] __main__: train step 21032: loss: 0.9170, policy_loss: 0.8250, value_loss: 0.4588
2024-07-11 17:44:06,026 [INFO    ] __main__: train step 21033: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4588
2024-07-11 17:44:06,223 [INFO    ] __main__: train step 21034: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4588
2024-07-11 17:44:06,435 [INFO    ] __main__: train step 21035: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4588
2024-07-11 17:44:06,644 [INFO    ] __main__: train step 21036: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4588
2024-07-11 17:44:06,848 [INFO    ] __main__: train step 21037: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4587
2024-07-11 17:44:07,045 [INFO    ] __main__: train step 21038: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4587
2024-07-11 17:44:07,254 [INFO    ] __main__: train step 21039: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4587
2024-07-11 17:44:07,459 [INFO    ] __main__: train step 21040: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4587
2024-07-11 17:44:07,662 [INFO    ] __main__: train step 21041: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4587
2024-07-11 17:44:07,868 [INFO    ] __main__: train step 21042: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4587
2024-07-11 17:44:08,074 [INFO    ] __main__: train step 21043: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4586
2024-07-11 17:44:08,279 [INFO    ] __main__: train step 21044: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4586
2024-07-11 17:44:08,484 [INFO    ] __main__: train step 21045: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4586
2024-07-11 17:44:09,929 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:44:10,365 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:44:10,424 [INFO    ] __main__: train step 21046: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4586
2024-07-11 17:44:10,606 [INFO    ] __main__: train step 21047: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4586
2024-07-11 17:44:10,813 [INFO    ] __main__: train step 21048: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4586
2024-07-11 17:44:11,022 [INFO    ] __main__: train step 21049: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4585
2024-07-11 17:44:11,229 [INFO    ] __main__: train step 21050: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4585
2024-07-11 17:44:11,431 [INFO    ] __main__: train step 21051: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4585
2024-07-11 17:44:11,651 [INFO    ] __main__: train step 21052: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4585
2024-07-11 17:44:11,886 [INFO    ] __main__: train step 21053: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4585
2024-07-11 17:44:12,115 [INFO    ] __main__: train step 21054: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4585
2024-07-11 17:44:12,351 [INFO    ] __main__: train step 21055: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4584
2024-07-11 17:44:12,601 [INFO    ] __main__: train step 21056: loss: 0.9169, policy_loss: 0.8250, value_loss: 0.4584
2024-07-11 17:44:12,837 [INFO    ] __main__: train step 21057: loss: 0.9169, policy_loss: 0.8249, value_loss: 0.4584
2024-07-11 17:44:13,074 [INFO    ] __main__: train step 21058: loss: 0.9169, policy_loss: 0.8249, value_loss: 0.4584
2024-07-11 17:44:13,277 [INFO    ] __main__: train step 21059: loss: 0.9169, policy_loss: 0.8249, value_loss: 0.4584
2024-07-11 17:44:13,482 [INFO    ] __main__: train step 21060: loss: 0.9169, policy_loss: 0.8249, value_loss: 0.4584
2024-07-11 17:44:13,685 [INFO    ] __main__: train step 21061: loss: 0.9169, policy_loss: 0.8249, value_loss: 0.4583
2024-07-11 17:44:13,895 [INFO    ] __main__: train step 21062: loss: 0.9169, policy_loss: 0.8249, value_loss: 0.4583
2024-07-11 17:44:15,337 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:44:15,783 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:44:15,840 [INFO    ] __main__: train step 21063: loss: 0.9169, policy_loss: 0.8249, value_loss: 0.4583
2024-07-11 17:44:16,014 [INFO    ] __main__: train step 21064: loss: 0.9169, policy_loss: 0.8249, value_loss: 0.4583
2024-07-11 17:44:16,223 [INFO    ] __main__: train step 21065: loss: 0.9169, policy_loss: 0.8249, value_loss: 0.4583
2024-07-11 17:44:16,420 [INFO    ] __main__: train step 21066: loss: 0.9169, policy_loss: 0.8249, value_loss: 0.4582
2024-07-11 17:44:16,628 [INFO    ] __main__: train step 21067: loss: 0.9169, policy_loss: 0.8249, value_loss: 0.4582
2024-07-11 17:44:16,833 [INFO    ] __main__: train step 21068: loss: 0.9169, policy_loss: 0.8249, value_loss: 0.4582
2024-07-11 17:44:17,032 [INFO    ] __main__: train step 21069: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4582
2024-07-11 17:44:17,231 [INFO    ] __main__: train step 21070: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4582
2024-07-11 17:44:17,433 [INFO    ] __main__: train step 21071: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4582
2024-07-11 17:44:17,650 [INFO    ] __main__: train step 21072: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4581
2024-07-11 17:44:17,857 [INFO    ] __main__: train step 21073: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4581
2024-07-11 17:44:18,061 [INFO    ] __main__: train step 21074: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4581
2024-07-11 17:44:18,262 [INFO    ] __main__: train step 21075: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4581
2024-07-11 17:44:18,464 [INFO    ] __main__: train step 21076: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4581
2024-07-11 17:44:18,666 [INFO    ] __main__: train step 21077: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4581
2024-07-11 17:44:18,866 [INFO    ] __main__: train step 21078: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4580
2024-07-11 17:44:19,066 [INFO    ] __main__: train step 21079: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4580
2024-07-11 17:44:20,510 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:44:20,932 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:44:20,987 [INFO    ] __main__: train step 21080: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4580
2024-07-11 17:44:21,163 [INFO    ] __main__: train step 21081: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4580
2024-07-11 17:44:21,382 [INFO    ] __main__: train step 21082: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4580
2024-07-11 17:44:21,583 [INFO    ] __main__: train step 21083: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4580
2024-07-11 17:44:21,785 [INFO    ] __main__: train step 21084: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4579
2024-07-11 17:44:21,989 [INFO    ] __main__: train step 21085: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4579
2024-07-11 17:44:22,187 [INFO    ] __main__: train step 21086: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4579
2024-07-11 17:44:22,390 [INFO    ] __main__: train step 21087: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4579
2024-07-11 17:44:22,591 [INFO    ] __main__: train step 21088: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4579
2024-07-11 17:44:22,794 [INFO    ] __main__: train step 21089: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4578
2024-07-11 17:44:22,997 [INFO    ] __main__: train step 21090: loss: 0.9168, policy_loss: 0.8249, value_loss: 0.4578
2024-07-11 17:44:23,194 [INFO    ] __main__: train step 21091: loss: 0.9168, policy_loss: 0.8248, value_loss: 0.4578
2024-07-11 17:44:23,389 [INFO    ] __main__: train step 21092: loss: 0.9168, policy_loss: 0.8248, value_loss: 0.4578
2024-07-11 17:44:23,601 [INFO    ] __main__: train step 21093: loss: 0.9168, policy_loss: 0.8248, value_loss: 0.4578
2024-07-11 17:44:23,810 [INFO    ] __main__: train step 21094: loss: 0.9168, policy_loss: 0.8248, value_loss: 0.4578
2024-07-11 17:44:24,054 [INFO    ] __main__: train step 21095: loss: 0.9168, policy_loss: 0.8248, value_loss: 0.4577
2024-07-11 17:44:24,272 [INFO    ] __main__: train step 21096: loss: 0.9168, policy_loss: 0.8248, value_loss: 0.4577
2024-07-11 17:44:25,739 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:44:26,147 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:44:26,207 [INFO    ] __main__: train step 21097: loss: 0.9168, policy_loss: 0.8248, value_loss: 0.4577
2024-07-11 17:44:26,382 [INFO    ] __main__: train step 21098: loss: 0.9168, policy_loss: 0.8248, value_loss: 0.4577
2024-07-11 17:44:26,585 [INFO    ] __main__: train step 21099: loss: 0.9168, policy_loss: 0.8248, value_loss: 0.4577
2024-07-11 17:44:26,794 [INFO    ] __main__: train step 21100: loss: 0.9168, policy_loss: 0.8248, value_loss: 0.4577
2024-07-11 17:44:26,985 [INFO    ] __main__: train step 21101: loss: 0.9168, policy_loss: 0.8248, value_loss: 0.4576
2024-07-11 17:44:27,190 [INFO    ] __main__: train step 21102: loss: 0.9168, policy_loss: 0.8248, value_loss: 0.4576
2024-07-11 17:44:27,406 [INFO    ] __main__: train step 21103: loss: 0.9168, policy_loss: 0.8248, value_loss: 0.4576
2024-07-11 17:44:27,658 [INFO    ] __main__: train step 21104: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4576
2024-07-11 17:44:27,874 [INFO    ] __main__: train step 21105: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4576
2024-07-11 17:44:28,093 [INFO    ] __main__: train step 21106: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4576
2024-07-11 17:44:28,326 [INFO    ] __main__: train step 21107: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4575
2024-07-11 17:44:28,547 [INFO    ] __main__: train step 21108: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4575
2024-07-11 17:44:31,005 [INFO    ] __main__: train step 21109: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4575
2024-07-11 17:44:31,212 [INFO    ] __main__: train step 21110: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4575
2024-07-11 17:44:31,427 [INFO    ] __main__: train step 21111: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4575
2024-07-11 17:44:31,659 [INFO    ] __main__: train step 21112: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4575
2024-07-11 17:44:31,861 [INFO    ] __main__: train step 21113: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4574
2024-07-11 17:44:33,308 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:44:33,739 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:44:33,797 [INFO    ] __main__: train step 21114: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4574
2024-07-11 17:44:33,988 [INFO    ] __main__: train step 21115: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4574
2024-07-11 17:44:34,235 [INFO    ] __main__: train step 21116: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4574
2024-07-11 17:44:34,465 [INFO    ] __main__: train step 21117: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4574
2024-07-11 17:44:34,672 [INFO    ] __main__: train step 21118: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4573
2024-07-11 17:44:34,873 [INFO    ] __main__: train step 21119: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4573
2024-07-11 17:44:35,079 [INFO    ] __main__: train step 21120: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4573
2024-07-11 17:44:35,273 [INFO    ] __main__: train step 21121: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4573
2024-07-11 17:44:35,483 [INFO    ] __main__: train step 21122: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4573
2024-07-11 17:44:35,691 [INFO    ] __main__: train step 21123: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4573
2024-07-11 17:44:35,913 [INFO    ] __main__: train step 21124: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4572
2024-07-11 17:44:36,145 [INFO    ] __main__: train step 21125: loss: 0.9167, policy_loss: 0.8248, value_loss: 0.4572
2024-07-11 17:44:36,360 [INFO    ] __main__: train step 21126: loss: 0.9167, policy_loss: 0.8247, value_loss: 0.4572
2024-07-11 17:44:36,605 [INFO    ] __main__: train step 21127: loss: 0.9167, policy_loss: 0.8247, value_loss: 0.4572
2024-07-11 17:44:36,798 [INFO    ] __main__: train step 21128: loss: 0.9167, policy_loss: 0.8247, value_loss: 0.4572
2024-07-11 17:44:37,007 [INFO    ] __main__: train step 21129: loss: 0.9167, policy_loss: 0.8247, value_loss: 0.4572
2024-07-11 17:44:37,241 [INFO    ] __main__: train step 21130: loss: 0.9167, policy_loss: 0.8247, value_loss: 0.4571
2024-07-11 17:44:38,675 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:44:39,110 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:44:39,166 [INFO    ] __main__: train step 21131: loss: 0.9167, policy_loss: 0.8247, value_loss: 0.4571
2024-07-11 17:44:39,359 [INFO    ] __main__: train step 21132: loss: 0.9167, policy_loss: 0.8247, value_loss: 0.4571
2024-07-11 17:44:39,597 [INFO    ] __main__: train step 21133: loss: 0.9167, policy_loss: 0.8247, value_loss: 0.4571
2024-07-11 17:44:39,834 [INFO    ] __main__: train step 21134: loss: 0.9167, policy_loss: 0.8247, value_loss: 0.4571
2024-07-11 17:44:40,037 [INFO    ] __main__: train step 21135: loss: 0.9167, policy_loss: 0.8247, value_loss: 0.4570
2024-07-11 17:44:40,240 [INFO    ] __main__: train step 21136: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4570
2024-07-11 17:44:40,446 [INFO    ] __main__: train step 21137: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4570
2024-07-11 17:44:40,653 [INFO    ] __main__: train step 21138: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4570
2024-07-11 17:44:40,856 [INFO    ] __main__: train step 21139: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4570
2024-07-11 17:44:41,052 [INFO    ] __main__: train step 21140: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4570
2024-07-11 17:44:41,254 [INFO    ] __main__: train step 21141: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4569
2024-07-11 17:44:41,454 [INFO    ] __main__: train step 21142: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4569
2024-07-11 17:44:41,656 [INFO    ] __main__: train step 21143: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4569
2024-07-11 17:44:41,871 [INFO    ] __main__: train step 21144: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4569
2024-07-11 17:44:42,107 [INFO    ] __main__: train step 21145: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4569
2024-07-11 17:44:42,352 [INFO    ] __main__: train step 21146: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4569
2024-07-11 17:44:42,588 [INFO    ] __main__: train step 21147: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4568
2024-07-11 17:44:44,041 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:44:44,336 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:44:44,390 [INFO    ] __main__: train step 21148: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4568
2024-07-11 17:44:44,572 [INFO    ] __main__: train step 21149: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4568
2024-07-11 17:44:44,806 [INFO    ] __main__: train step 21150: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4568
2024-07-11 17:44:45,046 [INFO    ] __main__: train step 21151: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4568
2024-07-11 17:44:45,278 [INFO    ] __main__: train step 21152: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4568
2024-07-11 17:44:45,491 [INFO    ] __main__: train step 21153: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4567
2024-07-11 17:44:45,687 [INFO    ] __main__: train step 21154: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4567
2024-07-11 17:44:45,894 [INFO    ] __main__: train step 21155: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4567
2024-07-11 17:44:46,098 [INFO    ] __main__: train step 21156: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4567
2024-07-11 17:44:46,294 [INFO    ] __main__: train step 21157: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4567
2024-07-11 17:44:46,492 [INFO    ] __main__: train step 21158: loss: 0.9166, policy_loss: 0.8247, value_loss: 0.4566
2024-07-11 17:44:46,692 [INFO    ] __main__: train step 21159: loss: 0.9166, policy_loss: 0.8246, value_loss: 0.4566
2024-07-11 17:44:46,899 [INFO    ] __main__: train step 21160: loss: 0.9166, policy_loss: 0.8246, value_loss: 0.4566
2024-07-11 17:44:47,101 [INFO    ] __main__: train step 21161: loss: 0.9166, policy_loss: 0.8246, value_loss: 0.4566
2024-07-11 17:44:47,302 [INFO    ] __main__: train step 21162: loss: 0.9166, policy_loss: 0.8246, value_loss: 0.4566
2024-07-11 17:44:47,521 [INFO    ] __main__: train step 21163: loss: 0.9166, policy_loss: 0.8246, value_loss: 0.4566
2024-07-11 17:44:47,739 [INFO    ] __main__: train step 21164: loss: 0.9166, policy_loss: 0.8246, value_loss: 0.4565
2024-07-11 17:44:49,205 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:44:49,591 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:44:49,647 [INFO    ] __main__: train step 21165: loss: 0.9166, policy_loss: 0.8246, value_loss: 0.4565
2024-07-11 17:44:49,838 [INFO    ] __main__: train step 21166: loss: 0.9166, policy_loss: 0.8246, value_loss: 0.4565
2024-07-11 17:44:50,037 [INFO    ] __main__: train step 21167: loss: 0.9166, policy_loss: 0.8246, value_loss: 0.4565
2024-07-11 17:44:50,250 [INFO    ] __main__: train step 21168: loss: 0.9166, policy_loss: 0.8246, value_loss: 0.4565
2024-07-11 17:44:50,445 [INFO    ] __main__: train step 21169: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4565
2024-07-11 17:44:50,648 [INFO    ] __main__: train step 21170: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4564
2024-07-11 17:44:50,860 [INFO    ] __main__: train step 21171: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4564
2024-07-11 17:44:51,098 [INFO    ] __main__: train step 21172: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4564
2024-07-11 17:44:51,335 [INFO    ] __main__: train step 21173: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4564
2024-07-11 17:44:51,537 [INFO    ] __main__: train step 21174: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4564
2024-07-11 17:44:51,738 [INFO    ] __main__: train step 21175: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4564
2024-07-11 17:44:51,949 [INFO    ] __main__: train step 21176: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4563
2024-07-11 17:44:52,154 [INFO    ] __main__: train step 21177: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4563
2024-07-11 17:44:52,359 [INFO    ] __main__: train step 21178: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4563
2024-07-11 17:44:52,558 [INFO    ] __main__: train step 21179: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4563
2024-07-11 17:44:52,758 [INFO    ] __main__: train step 21180: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4563
2024-07-11 17:44:52,964 [INFO    ] __main__: train step 21181: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4562
2024-07-11 17:44:54,400 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:44:54,829 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:44:54,884 [INFO    ] __main__: train step 21182: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4562
2024-07-11 17:44:55,060 [INFO    ] __main__: train step 21183: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4562
2024-07-11 17:44:55,259 [INFO    ] __main__: train step 21184: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4562
2024-07-11 17:44:55,470 [INFO    ] __main__: train step 21185: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4562
2024-07-11 17:44:55,667 [INFO    ] __main__: train step 21186: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4562
2024-07-11 17:44:55,875 [INFO    ] __main__: train step 21187: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4561
2024-07-11 17:44:56,086 [INFO    ] __main__: train step 21188: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4561
2024-07-11 17:44:56,284 [INFO    ] __main__: train step 21189: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4561
2024-07-11 17:44:56,495 [INFO    ] __main__: train step 21190: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4561
2024-07-11 17:44:56,702 [INFO    ] __main__: train step 21191: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4561
2024-07-11 17:44:56,901 [INFO    ] __main__: train step 21192: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4561
2024-07-11 17:44:57,118 [INFO    ] __main__: train step 21193: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4560
2024-07-11 17:44:57,318 [INFO    ] __main__: train step 21194: loss: 0.9165, policy_loss: 0.8246, value_loss: 0.4560
2024-07-11 17:44:57,527 [INFO    ] __main__: train step 21195: loss: 0.9165, policy_loss: 0.8245, value_loss: 0.4560
2024-07-11 17:44:57,765 [INFO    ] __main__: train step 21196: loss: 0.9165, policy_loss: 0.8245, value_loss: 0.4560
2024-07-11 17:44:57,972 [INFO    ] __main__: train step 21197: loss: 0.9165, policy_loss: 0.8245, value_loss: 0.4560
2024-07-11 17:44:58,169 [INFO    ] __main__: train step 21198: loss: 0.9165, policy_loss: 0.8245, value_loss: 0.4560
2024-07-11 17:44:59,597 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:45:00,038 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:45:00,094 [INFO    ] __main__: train step 21199: loss: 0.9165, policy_loss: 0.8245, value_loss: 0.4559
2024-07-11 17:45:00,277 [INFO    ] __main__: train step 21200: loss: 0.9165, policy_loss: 0.8245, value_loss: 0.4559
2024-07-11 17:45:00,484 [INFO    ] __main__: train step 21201: loss: 0.9165, policy_loss: 0.8245, value_loss: 0.4559
2024-07-11 17:45:00,699 [INFO    ] __main__: train step 21202: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4559
2024-07-11 17:45:00,908 [INFO    ] __main__: train step 21203: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4559
2024-07-11 17:45:01,115 [INFO    ] __main__: train step 21204: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4559
2024-07-11 17:45:01,322 [INFO    ] __main__: train step 21205: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4558
2024-07-11 17:45:01,518 [INFO    ] __main__: train step 21206: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4558
2024-07-11 17:45:01,730 [INFO    ] __main__: train step 21207: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4558
2024-07-11 17:45:01,939 [INFO    ] __main__: train step 21208: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4558
2024-07-11 17:45:02,163 [INFO    ] __main__: train step 21209: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4558
2024-07-11 17:45:02,400 [INFO    ] __main__: train step 21210: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4557
2024-07-11 17:45:02,606 [INFO    ] __main__: train step 21211: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4557
2024-07-11 17:45:02,829 [INFO    ] __main__: train step 21212: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4557
2024-07-11 17:45:03,061 [INFO    ] __main__: train step 21213: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4557
2024-07-11 17:45:03,270 [INFO    ] __main__: train step 21214: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4557
2024-07-11 17:45:03,478 [INFO    ] __main__: train step 21215: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4557
2024-07-11 17:45:04,918 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:45:05,340 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:45:05,399 [INFO    ] __main__: train step 21216: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4556
2024-07-11 17:45:05,576 [INFO    ] __main__: train step 21217: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4556
2024-07-11 17:45:05,781 [INFO    ] __main__: train step 21218: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4556
2024-07-11 17:45:06,003 [INFO    ] __main__: train step 21219: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4556
2024-07-11 17:45:06,225 [INFO    ] __main__: train step 21220: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4556
2024-07-11 17:45:06,437 [INFO    ] __main__: train step 21221: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4556
2024-07-11 17:45:06,674 [INFO    ] __main__: train step 21222: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4555
2024-07-11 17:45:06,884 [INFO    ] __main__: train step 21223: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4555
2024-07-11 17:45:07,081 [INFO    ] __main__: train step 21224: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4555
2024-07-11 17:45:07,287 [INFO    ] __main__: train step 21225: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4555
2024-07-11 17:45:07,486 [INFO    ] __main__: train step 21226: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4555
2024-07-11 17:45:07,691 [INFO    ] __main__: train step 21227: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4555
2024-07-11 17:45:07,890 [INFO    ] __main__: train step 21228: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4554
2024-07-11 17:45:08,093 [INFO    ] __main__: train step 21229: loss: 0.9164, policy_loss: 0.8245, value_loss: 0.4554
2024-07-11 17:45:08,305 [INFO    ] __main__: train step 21230: loss: 0.9164, policy_loss: 0.8244, value_loss: 0.4554
2024-07-11 17:45:08,502 [INFO    ] __main__: train step 21231: loss: 0.9164, policy_loss: 0.8244, value_loss: 0.4554
2024-07-11 17:45:08,710 [INFO    ] __main__: train step 21232: loss: 0.9164, policy_loss: 0.8244, value_loss: 0.4554
2024-07-11 17:45:10,166 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:45:10,610 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:45:10,669 [INFO    ] __main__: train step 21233: loss: 0.9164, policy_loss: 0.8244, value_loss: 0.4553
2024-07-11 17:45:10,846 [INFO    ] __main__: train step 21234: loss: 0.9164, policy_loss: 0.8244, value_loss: 0.4553
2024-07-11 17:45:11,048 [INFO    ] __main__: train step 21235: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4553
2024-07-11 17:45:11,253 [INFO    ] __main__: train step 21236: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4553
2024-07-11 17:45:11,452 [INFO    ] __main__: train step 21237: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4553
2024-07-11 17:45:11,670 [INFO    ] __main__: train step 21238: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4553
2024-07-11 17:45:11,876 [INFO    ] __main__: train step 21239: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4552
2024-07-11 17:45:12,084 [INFO    ] __main__: train step 21240: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4552
2024-07-11 17:45:12,291 [INFO    ] __main__: train step 21241: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4552
2024-07-11 17:45:12,498 [INFO    ] __main__: train step 21242: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4552
2024-07-11 17:45:12,700 [INFO    ] __main__: train step 21243: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4552
2024-07-11 17:45:12,902 [INFO    ] __main__: train step 21244: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4552
2024-07-11 17:45:13,108 [INFO    ] __main__: train step 21245: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4551
2024-07-11 17:45:13,317 [INFO    ] __main__: train step 21246: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4551
2024-07-11 17:45:13,518 [INFO    ] __main__: train step 21247: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4551
2024-07-11 17:45:13,726 [INFO    ] __main__: train step 21248: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4551
2024-07-11 17:45:13,926 [INFO    ] __main__: train step 21249: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4551
2024-07-11 17:45:17,591 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:45:18,014 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:45:18,070 [INFO    ] __main__: train step 21250: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4551
2024-07-11 17:45:18,258 [INFO    ] __main__: train step 21251: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4550
2024-07-11 17:45:18,463 [INFO    ] __main__: train step 21252: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4550
2024-07-11 17:45:18,675 [INFO    ] __main__: train step 21253: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4550
2024-07-11 17:45:18,867 [INFO    ] __main__: train step 21254: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4550
2024-07-11 17:45:19,074 [INFO    ] __main__: train step 21255: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4550
2024-07-11 17:45:19,286 [INFO    ] __main__: train step 21256: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4549
2024-07-11 17:45:19,496 [INFO    ] __main__: train step 21257: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4549
2024-07-11 17:45:19,699 [INFO    ] __main__: train step 21258: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4549
2024-07-11 17:45:19,901 [INFO    ] __main__: train step 21259: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4549
2024-07-11 17:45:20,107 [INFO    ] __main__: train step 21260: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4549
2024-07-11 17:45:20,316 [INFO    ] __main__: train step 21261: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4549
2024-07-11 17:45:20,519 [INFO    ] __main__: train step 21262: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4548
2024-07-11 17:45:20,751 [INFO    ] __main__: train step 21263: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4548
2024-07-11 17:45:20,994 [INFO    ] __main__: train step 21264: loss: 0.9163, policy_loss: 0.8244, value_loss: 0.4548
2024-07-11 17:45:21,208 [INFO    ] __main__: train step 21265: loss: 0.9163, policy_loss: 0.8243, value_loss: 0.4548
2024-07-11 17:45:21,424 [INFO    ] __main__: train step 21266: loss: 0.9163, policy_loss: 0.8243, value_loss: 0.4548
2024-07-11 17:45:22,872 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:45:23,280 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:45:23,339 [INFO    ] __main__: train step 21267: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4548
2024-07-11 17:45:23,516 [INFO    ] __main__: train step 21268: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4547
2024-07-11 17:45:23,763 [INFO    ] __main__: train step 21269: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4547
2024-07-11 17:45:24,011 [INFO    ] __main__: train step 21270: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4547
2024-07-11 17:45:24,247 [INFO    ] __main__: train step 21271: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4547
2024-07-11 17:45:24,456 [INFO    ] __main__: train step 21272: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4547
2024-07-11 17:45:24,666 [INFO    ] __main__: train step 21273: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4547
2024-07-11 17:45:24,873 [INFO    ] __main__: train step 21274: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4546
2024-07-11 17:45:25,073 [INFO    ] __main__: train step 21275: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4546
2024-07-11 17:45:25,286 [INFO    ] __main__: train step 21276: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4546
2024-07-11 17:45:25,489 [INFO    ] __main__: train step 21277: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4546
2024-07-11 17:45:25,689 [INFO    ] __main__: train step 21278: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4546
2024-07-11 17:45:25,887 [INFO    ] __main__: train step 21279: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4546
2024-07-11 17:45:26,097 [INFO    ] __main__: train step 21280: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4545
2024-07-11 17:45:26,304 [INFO    ] __main__: train step 21281: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4545
2024-07-11 17:45:26,508 [INFO    ] __main__: train step 21282: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4545
2024-07-11 17:45:26,727 [INFO    ] __main__: train step 21283: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4545
2024-07-11 17:45:28,155 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:45:28,569 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:45:28,624 [INFO    ] __main__: train step 21284: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4545
2024-07-11 17:45:28,800 [INFO    ] __main__: train step 21285: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4544
2024-07-11 17:45:28,999 [INFO    ] __main__: train step 21286: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4544
2024-07-11 17:45:29,209 [INFO    ] __main__: train step 21287: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4544
2024-07-11 17:45:29,415 [INFO    ] __main__: train step 21288: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4544
2024-07-11 17:45:29,620 [INFO    ] __main__: train step 21289: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4544
2024-07-11 17:45:29,827 [INFO    ] __main__: train step 21290: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4544
2024-07-11 17:45:30,042 [INFO    ] __main__: train step 21291: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4543
2024-07-11 17:45:30,268 [INFO    ] __main__: train step 21292: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4543
2024-07-11 17:45:30,478 [INFO    ] __main__: train step 21293: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4543
2024-07-11 17:45:30,686 [INFO    ] __main__: train step 21294: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4543
2024-07-11 17:45:30,887 [INFO    ] __main__: train step 21295: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4543
2024-07-11 17:45:31,104 [INFO    ] __main__: train step 21296: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4543
2024-07-11 17:45:31,347 [INFO    ] __main__: train step 21297: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4542
2024-07-11 17:45:31,553 [INFO    ] __main__: train step 21298: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4542
2024-07-11 17:45:31,785 [INFO    ] __main__: train step 21299: loss: 0.9162, policy_loss: 0.8243, value_loss: 0.4542
2024-07-11 17:45:31,984 [INFO    ] __main__: train step 21300: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4542
2024-07-11 17:45:33,432 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:45:33,878 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:45:33,940 [INFO    ] __main__: train step 21301: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4542
2024-07-11 17:45:34,114 [INFO    ] __main__: train step 21302: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4542
2024-07-11 17:45:34,320 [INFO    ] __main__: train step 21303: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4541
2024-07-11 17:45:34,527 [INFO    ] __main__: train step 21304: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4541
2024-07-11 17:45:34,738 [INFO    ] __main__: train step 21305: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4541
2024-07-11 17:45:34,940 [INFO    ] __main__: train step 21306: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4541
2024-07-11 17:45:35,160 [INFO    ] __main__: train step 21307: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4541
2024-07-11 17:45:35,364 [INFO    ] __main__: train step 21308: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4540
2024-07-11 17:45:35,570 [INFO    ] __main__: train step 21309: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4540
2024-07-11 17:45:35,784 [INFO    ] __main__: train step 21310: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4540
2024-07-11 17:45:36,012 [INFO    ] __main__: train step 21311: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4540
2024-07-11 17:45:36,253 [INFO    ] __main__: train step 21312: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4540
2024-07-11 17:45:36,476 [INFO    ] __main__: train step 21313: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4540
2024-07-11 17:45:36,717 [INFO    ] __main__: train step 21314: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4539
2024-07-11 17:45:36,955 [INFO    ] __main__: train step 21315: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4539
2024-07-11 17:45:37,153 [INFO    ] __main__: train step 21316: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4539
2024-07-11 17:45:37,363 [INFO    ] __main__: train step 21317: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4539
2024-07-11 17:45:38,820 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:45:39,262 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:45:39,324 [INFO    ] __main__: train step 21318: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4539
2024-07-11 17:45:39,501 [INFO    ] __main__: train step 21319: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4539
2024-07-11 17:45:39,710 [INFO    ] __main__: train step 21320: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4538
2024-07-11 17:45:39,909 [INFO    ] __main__: train step 21321: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4538
2024-07-11 17:45:40,112 [INFO    ] __main__: train step 21322: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4538
2024-07-11 17:45:40,314 [INFO    ] __main__: train step 21323: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4538
2024-07-11 17:45:40,523 [INFO    ] __main__: train step 21324: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4538
2024-07-11 17:45:40,747 [INFO    ] __main__: train step 21325: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4538
2024-07-11 17:45:40,982 [INFO    ] __main__: train step 21326: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4537
2024-07-11 17:45:41,188 [INFO    ] __main__: train step 21327: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4537
2024-07-11 17:45:41,400 [INFO    ] __main__: train step 21328: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4537
2024-07-11 17:45:41,598 [INFO    ] __main__: train step 21329: loss: 0.9161, policy_loss: 0.8242, value_loss: 0.4537
2024-07-11 17:45:41,826 [INFO    ] __main__: train step 21330: loss: 0.9160, policy_loss: 0.8242, value_loss: 0.4537
2024-07-11 17:45:42,042 [INFO    ] __main__: train step 21331: loss: 0.9160, policy_loss: 0.8242, value_loss: 0.4537
2024-07-11 17:45:42,276 [INFO    ] __main__: train step 21332: loss: 0.9160, policy_loss: 0.8242, value_loss: 0.4536
2024-07-11 17:45:42,485 [INFO    ] __main__: train step 21333: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4536
2024-07-11 17:45:42,688 [INFO    ] __main__: train step 21334: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4536
2024-07-11 17:45:44,131 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:45:44,562 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:45:44,619 [INFO    ] __main__: train step 21335: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4536
2024-07-11 17:45:44,804 [INFO    ] __main__: train step 21336: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4536
2024-07-11 17:45:45,049 [INFO    ] __main__: train step 21337: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4535
2024-07-11 17:45:45,243 [INFO    ] __main__: train step 21338: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4535
2024-07-11 17:45:45,452 [INFO    ] __main__: train step 21339: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4535
2024-07-11 17:45:45,669 [INFO    ] __main__: train step 21340: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4535
2024-07-11 17:45:45,885 [INFO    ] __main__: train step 21341: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4535
2024-07-11 17:45:46,090 [INFO    ] __main__: train step 21342: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4535
2024-07-11 17:45:46,294 [INFO    ] __main__: train step 21343: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4534
2024-07-11 17:45:46,495 [INFO    ] __main__: train step 21344: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4534
2024-07-11 17:45:46,700 [INFO    ] __main__: train step 21345: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4534
2024-07-11 17:45:46,903 [INFO    ] __main__: train step 21346: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4534
2024-07-11 17:45:47,111 [INFO    ] __main__: train step 21347: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4534
2024-07-11 17:45:47,349 [INFO    ] __main__: train step 21348: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4534
2024-07-11 17:45:47,560 [INFO    ] __main__: train step 21349: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4533
2024-07-11 17:45:47,758 [INFO    ] __main__: train step 21350: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4533
2024-07-11 17:45:47,980 [INFO    ] __main__: train step 21351: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4533
2024-07-11 17:45:49,424 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:45:49,820 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:45:49,876 [INFO    ] __main__: train step 21352: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4533
2024-07-11 17:45:50,050 [INFO    ] __main__: train step 21353: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4533
2024-07-11 17:45:50,259 [INFO    ] __main__: train step 21354: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4533
2024-07-11 17:45:50,468 [INFO    ] __main__: train step 21355: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4532
2024-07-11 17:45:50,703 [INFO    ] __main__: train step 21356: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4532
2024-07-11 17:45:50,912 [INFO    ] __main__: train step 21357: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4532
2024-07-11 17:45:51,117 [INFO    ] __main__: train step 21358: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4532
2024-07-11 17:45:51,335 [INFO    ] __main__: train step 21359: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4532
2024-07-11 17:45:51,578 [INFO    ] __main__: train step 21360: loss: 0.9160, policy_loss: 0.8241, value_loss: 0.4532
2024-07-11 17:45:51,799 [INFO    ] __main__: train step 21361: loss: 0.9159, policy_loss: 0.8241, value_loss: 0.4531
2024-07-11 17:45:51,997 [INFO    ] __main__: train step 21362: loss: 0.9159, policy_loss: 0.8241, value_loss: 0.4531
2024-07-11 17:45:52,203 [INFO    ] __main__: train step 21363: loss: 0.9159, policy_loss: 0.8241, value_loss: 0.4531
2024-07-11 17:45:52,405 [INFO    ] __main__: train step 21364: loss: 0.9159, policy_loss: 0.8241, value_loss: 0.4531
2024-07-11 17:45:52,610 [INFO    ] __main__: train step 21365: loss: 0.9159, policy_loss: 0.8241, value_loss: 0.4531
2024-07-11 17:45:52,808 [INFO    ] __main__: train step 21366: loss: 0.9159, policy_loss: 0.8241, value_loss: 0.4531
2024-07-11 17:45:53,006 [INFO    ] __main__: train step 21367: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4530
2024-07-11 17:45:53,213 [INFO    ] __main__: train step 21368: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4530
2024-07-11 17:45:54,667 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:45:55,082 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:45:55,141 [INFO    ] __main__: train step 21369: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4530
2024-07-11 17:45:55,322 [INFO    ] __main__: train step 21370: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4530
2024-07-11 17:45:55,546 [INFO    ] __main__: train step 21371: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4530
2024-07-11 17:45:55,753 [INFO    ] __main__: train step 21372: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4529
2024-07-11 17:45:55,960 [INFO    ] __main__: train step 21373: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4529
2024-07-11 17:45:56,201 [INFO    ] __main__: train step 21374: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4529
2024-07-11 17:45:56,423 [INFO    ] __main__: train step 21375: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4529
2024-07-11 17:45:56,629 [INFO    ] __main__: train step 21376: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4529
2024-07-11 17:45:56,845 [INFO    ] __main__: train step 21377: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4529
2024-07-11 17:45:57,052 [INFO    ] __main__: train step 21378: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4528
2024-07-11 17:45:57,295 [INFO    ] __main__: train step 21379: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4528
2024-07-11 17:45:57,514 [INFO    ] __main__: train step 21380: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4528
2024-07-11 17:45:57,740 [INFO    ] __main__: train step 21381: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4528
2024-07-11 17:45:57,946 [INFO    ] __main__: train step 21382: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4528
2024-07-11 17:45:58,150 [INFO    ] __main__: train step 21383: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4528
2024-07-11 17:45:58,355 [INFO    ] __main__: train step 21384: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4527
2024-07-11 17:45:58,559 [INFO    ] __main__: train step 21385: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4527
2024-07-11 17:46:00,014 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:46:00,435 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:46:00,493 [INFO    ] __main__: train step 21386: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4527
2024-07-11 17:46:02,951 [INFO    ] __main__: train step 21387: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4527
2024-07-11 17:46:03,164 [INFO    ] __main__: train step 21388: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4527
2024-07-11 17:46:03,375 [INFO    ] __main__: train step 21389: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4527
2024-07-11 17:46:03,589 [INFO    ] __main__: train step 21390: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4526
2024-07-11 17:46:03,796 [INFO    ] __main__: train step 21391: loss: 0.9159, policy_loss: 0.8240, value_loss: 0.4526
2024-07-11 17:46:04,002 [INFO    ] __main__: train step 21392: loss: 0.9158, policy_loss: 0.8240, value_loss: 0.4526
2024-07-11 17:46:04,222 [INFO    ] __main__: train step 21393: loss: 0.9158, policy_loss: 0.8240, value_loss: 0.4526
2024-07-11 17:46:04,439 [INFO    ] __main__: train step 21394: loss: 0.9158, policy_loss: 0.8240, value_loss: 0.4526
2024-07-11 17:46:04,643 [INFO    ] __main__: train step 21395: loss: 0.9158, policy_loss: 0.8240, value_loss: 0.4526
2024-07-11 17:46:04,843 [INFO    ] __main__: train step 21396: loss: 0.9158, policy_loss: 0.8240, value_loss: 0.4525
2024-07-11 17:46:05,047 [INFO    ] __main__: train step 21397: loss: 0.9158, policy_loss: 0.8240, value_loss: 0.4525
2024-07-11 17:46:05,251 [INFO    ] __main__: train step 21398: loss: 0.9158, policy_loss: 0.8240, value_loss: 0.4525
2024-07-11 17:46:05,462 [INFO    ] __main__: train step 21399: loss: 0.9158, policy_loss: 0.8240, value_loss: 0.4525
2024-07-11 17:46:05,672 [INFO    ] __main__: train step 21400: loss: 0.9158, policy_loss: 0.8240, value_loss: 0.4525
2024-07-11 17:46:05,875 [INFO    ] __main__: train step 21401: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4524
2024-07-11 17:46:06,101 [INFO    ] __main__: train step 21402: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4524
2024-07-11 17:46:07,527 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:46:07,956 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:46:08,013 [INFO    ] __main__: train step 21403: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4524
2024-07-11 17:46:08,199 [INFO    ] __main__: train step 21404: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4524
2024-07-11 17:46:08,409 [INFO    ] __main__: train step 21405: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4524
2024-07-11 17:46:08,611 [INFO    ] __main__: train step 21406: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4524
2024-07-11 17:46:08,825 [INFO    ] __main__: train step 21407: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4523
2024-07-11 17:46:09,037 [INFO    ] __main__: train step 21408: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4523
2024-07-11 17:46:09,261 [INFO    ] __main__: train step 21409: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4523
2024-07-11 17:46:09,471 [INFO    ] __main__: train step 21410: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4523
2024-07-11 17:46:09,678 [INFO    ] __main__: train step 21411: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4523
2024-07-11 17:46:09,887 [INFO    ] __main__: train step 21412: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4523
2024-07-11 17:46:10,094 [INFO    ] __main__: train step 21413: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4522
2024-07-11 17:46:10,300 [INFO    ] __main__: train step 21414: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4522
2024-07-11 17:46:10,501 [INFO    ] __main__: train step 21415: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4522
2024-07-11 17:46:10,709 [INFO    ] __main__: train step 21416: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4522
2024-07-11 17:46:10,908 [INFO    ] __main__: train step 21417: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4522
2024-07-11 17:46:11,113 [INFO    ] __main__: train step 21418: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4522
2024-07-11 17:46:11,317 [INFO    ] __main__: train step 21419: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4521
2024-07-11 17:46:12,756 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:46:13,153 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:46:13,208 [INFO    ] __main__: train step 21420: loss: 0.9158, policy_loss: 0.8239, value_loss: 0.4521
2024-07-11 17:46:13,385 [INFO    ] __main__: train step 21421: loss: 0.9157, policy_loss: 0.8239, value_loss: 0.4521
2024-07-11 17:46:13,584 [INFO    ] __main__: train step 21422: loss: 0.9157, policy_loss: 0.8239, value_loss: 0.4521
2024-07-11 17:46:13,787 [INFO    ] __main__: train step 21423: loss: 0.9157, policy_loss: 0.8239, value_loss: 0.4521
2024-07-11 17:46:14,000 [INFO    ] __main__: train step 21424: loss: 0.9157, policy_loss: 0.8239, value_loss: 0.4521
2024-07-11 17:46:14,206 [INFO    ] __main__: train step 21425: loss: 0.9157, policy_loss: 0.8239, value_loss: 0.4520
2024-07-11 17:46:14,441 [INFO    ] __main__: train step 21426: loss: 0.9157, policy_loss: 0.8239, value_loss: 0.4520
2024-07-11 17:46:14,659 [INFO    ] __main__: train step 21427: loss: 0.9157, policy_loss: 0.8239, value_loss: 0.4520
2024-07-11 17:46:14,904 [INFO    ] __main__: train step 21428: loss: 0.9157, policy_loss: 0.8239, value_loss: 0.4520
2024-07-11 17:46:15,139 [INFO    ] __main__: train step 21429: loss: 0.9157, policy_loss: 0.8239, value_loss: 0.4520
2024-07-11 17:46:15,344 [INFO    ] __main__: train step 21430: loss: 0.9157, policy_loss: 0.8239, value_loss: 0.4520
2024-07-11 17:46:15,562 [INFO    ] __main__: train step 21431: loss: 0.9157, policy_loss: 0.8239, value_loss: 0.4519
2024-07-11 17:46:15,791 [INFO    ] __main__: train step 21432: loss: 0.9157, policy_loss: 0.8239, value_loss: 0.4519
2024-07-11 17:46:16,005 [INFO    ] __main__: train step 21433: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4519
2024-07-11 17:46:16,201 [INFO    ] __main__: train step 21434: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4519
2024-07-11 17:46:16,409 [INFO    ] __main__: train step 21435: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4519
2024-07-11 17:46:16,619 [INFO    ] __main__: train step 21436: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4519
2024-07-11 17:46:18,067 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:46:18,475 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:46:18,537 [INFO    ] __main__: train step 21437: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4518
2024-07-11 17:46:18,721 [INFO    ] __main__: train step 21438: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4518
2024-07-11 17:46:18,921 [INFO    ] __main__: train step 21439: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4518
2024-07-11 17:46:19,128 [INFO    ] __main__: train step 21440: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4518
2024-07-11 17:46:19,343 [INFO    ] __main__: train step 21441: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4518
2024-07-11 17:46:19,547 [INFO    ] __main__: train step 21442: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4517
2024-07-11 17:46:19,745 [INFO    ] __main__: train step 21443: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4517
2024-07-11 17:46:19,955 [INFO    ] __main__: train step 21444: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4517
2024-07-11 17:46:20,166 [INFO    ] __main__: train step 21445: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4517
2024-07-11 17:46:20,409 [INFO    ] __main__: train step 21446: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4517
2024-07-11 17:46:20,654 [INFO    ] __main__: train step 21447: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4517
2024-07-11 17:46:20,869 [INFO    ] __main__: train step 21448: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4516
2024-07-11 17:46:21,086 [INFO    ] __main__: train step 21449: loss: 0.9157, policy_loss: 0.8238, value_loss: 0.4516
2024-07-11 17:46:21,323 [INFO    ] __main__: train step 21450: loss: 0.9156, policy_loss: 0.8238, value_loss: 0.4516
2024-07-11 17:46:21,538 [INFO    ] __main__: train step 21451: loss: 0.9156, policy_loss: 0.8238, value_loss: 0.4516
2024-07-11 17:46:21,766 [INFO    ] __main__: train step 21452: loss: 0.9156, policy_loss: 0.8238, value_loss: 0.4516
2024-07-11 17:46:21,978 [INFO    ] __main__: train step 21453: loss: 0.9156, policy_loss: 0.8238, value_loss: 0.4516
2024-07-11 17:46:23,445 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:46:23,878 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:46:23,937 [INFO    ] __main__: train step 21454: loss: 0.9156, policy_loss: 0.8238, value_loss: 0.4515
2024-07-11 17:46:24,125 [INFO    ] __main__: train step 21455: loss: 0.9156, policy_loss: 0.8238, value_loss: 0.4515
2024-07-11 17:46:24,366 [INFO    ] __main__: train step 21456: loss: 0.9156, policy_loss: 0.8238, value_loss: 0.4515
2024-07-11 17:46:24,589 [INFO    ] __main__: train step 21457: loss: 0.9156, policy_loss: 0.8238, value_loss: 0.4515
2024-07-11 17:46:24,820 [INFO    ] __main__: train step 21458: loss: 0.9156, policy_loss: 0.8238, value_loss: 0.4515
2024-07-11 17:46:25,029 [INFO    ] __main__: train step 21459: loss: 0.9156, policy_loss: 0.8238, value_loss: 0.4515
2024-07-11 17:46:25,222 [INFO    ] __main__: train step 21460: loss: 0.9156, policy_loss: 0.8238, value_loss: 0.4514
2024-07-11 17:46:25,421 [INFO    ] __main__: train step 21461: loss: 0.9156, policy_loss: 0.8238, value_loss: 0.4514
2024-07-11 17:46:25,629 [INFO    ] __main__: train step 21462: loss: 0.9156, policy_loss: 0.8238, value_loss: 0.4514
2024-07-11 17:46:25,847 [INFO    ] __main__: train step 21463: loss: 0.9156, policy_loss: 0.8238, value_loss: 0.4514
2024-07-11 17:46:26,043 [INFO    ] __main__: train step 21464: loss: 0.9156, policy_loss: 0.8238, value_loss: 0.4514
2024-07-11 17:46:26,241 [INFO    ] __main__: train step 21465: loss: 0.9156, policy_loss: 0.8237, value_loss: 0.4514
2024-07-11 17:46:26,439 [INFO    ] __main__: train step 21466: loss: 0.9156, policy_loss: 0.8237, value_loss: 0.4513
2024-07-11 17:46:26,653 [INFO    ] __main__: train step 21467: loss: 0.9156, policy_loss: 0.8237, value_loss: 0.4513
2024-07-11 17:46:26,859 [INFO    ] __main__: train step 21468: loss: 0.9156, policy_loss: 0.8237, value_loss: 0.4513
2024-07-11 17:46:27,094 [INFO    ] __main__: train step 21469: loss: 0.9156, policy_loss: 0.8237, value_loss: 0.4513
2024-07-11 17:46:27,297 [INFO    ] __main__: train step 21470: loss: 0.9156, policy_loss: 0.8237, value_loss: 0.4513
2024-07-11 17:46:28,734 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:46:29,153 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:46:29,213 [INFO    ] __main__: train step 21471: loss: 0.9156, policy_loss: 0.8237, value_loss: 0.4513
2024-07-11 17:46:29,392 [INFO    ] __main__: train step 21472: loss: 0.9156, policy_loss: 0.8237, value_loss: 0.4512
2024-07-11 17:46:29,627 [INFO    ] __main__: train step 21473: loss: 0.9156, policy_loss: 0.8237, value_loss: 0.4512
2024-07-11 17:46:29,845 [INFO    ] __main__: train step 21474: loss: 0.9156, policy_loss: 0.8237, value_loss: 0.4512
2024-07-11 17:46:30,092 [INFO    ] __main__: train step 21475: loss: 0.9156, policy_loss: 0.8237, value_loss: 0.4512
2024-07-11 17:46:30,330 [INFO    ] __main__: train step 21476: loss: 0.9156, policy_loss: 0.8237, value_loss: 0.4512
2024-07-11 17:46:30,566 [INFO    ] __main__: train step 21477: loss: 0.9156, policy_loss: 0.8237, value_loss: 0.4512
2024-07-11 17:46:30,796 [INFO    ] __main__: train step 21478: loss: 0.9156, policy_loss: 0.8237, value_loss: 0.4511
2024-07-11 17:46:31,001 [INFO    ] __main__: train step 21479: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4511
2024-07-11 17:46:31,198 [INFO    ] __main__: train step 21480: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4511
2024-07-11 17:46:31,405 [INFO    ] __main__: train step 21481: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4511
2024-07-11 17:46:31,601 [INFO    ] __main__: train step 21482: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4511
2024-07-11 17:46:31,803 [INFO    ] __main__: train step 21483: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4511
2024-07-11 17:46:32,017 [INFO    ] __main__: train step 21484: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4510
2024-07-11 17:46:32,219 [INFO    ] __main__: train step 21485: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4510
2024-07-11 17:46:32,412 [INFO    ] __main__: train step 21486: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4510
2024-07-11 17:46:32,619 [INFO    ] __main__: train step 21487: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4510
2024-07-11 17:46:34,062 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:46:34,465 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:46:34,525 [INFO    ] __main__: train step 21488: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4510
2024-07-11 17:46:34,705 [INFO    ] __main__: train step 21489: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4509
2024-07-11 17:46:34,913 [INFO    ] __main__: train step 21490: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4509
2024-07-11 17:46:35,142 [INFO    ] __main__: train step 21491: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4509
2024-07-11 17:46:35,337 [INFO    ] __main__: train step 21492: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4509
2024-07-11 17:46:35,548 [INFO    ] __main__: train step 21493: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4509
2024-07-11 17:46:35,765 [INFO    ] __main__: train step 21494: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4509
2024-07-11 17:46:36,009 [INFO    ] __main__: train step 21495: loss: 0.9155, policy_loss: 0.8237, value_loss: 0.4508
2024-07-11 17:46:36,213 [INFO    ] __main__: train step 21496: loss: 0.9155, policy_loss: 0.8236, value_loss: 0.4508
2024-07-11 17:46:36,418 [INFO    ] __main__: train step 21497: loss: 0.9155, policy_loss: 0.8236, value_loss: 0.4508
2024-07-11 17:46:36,620 [INFO    ] __main__: train step 21498: loss: 0.9155, policy_loss: 0.8236, value_loss: 0.4508
2024-07-11 17:46:36,825 [INFO    ] __main__: train step 21499: loss: 0.9155, policy_loss: 0.8236, value_loss: 0.4508
2024-07-11 17:46:37,026 [INFO    ] __main__: train step 21500: loss: 0.9155, policy_loss: 0.8236, value_loss: 0.4508
2024-07-11 17:46:37,229 [INFO    ] __main__: train step 21501: loss: 0.9155, policy_loss: 0.8236, value_loss: 0.4507
2024-07-11 17:46:37,442 [INFO    ] __main__: train step 21502: loss: 0.9155, policy_loss: 0.8236, value_loss: 0.4507
2024-07-11 17:46:37,642 [INFO    ] __main__: train step 21503: loss: 0.9155, policy_loss: 0.8236, value_loss: 0.4507
2024-07-11 17:46:37,839 [INFO    ] __main__: train step 21504: loss: 0.9155, policy_loss: 0.8236, value_loss: 0.4507
2024-07-11 17:46:39,284 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:46:39,718 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:46:39,779 [INFO    ] __main__: train step 21505: loss: 0.9155, policy_loss: 0.8236, value_loss: 0.4507
2024-07-11 17:46:39,953 [INFO    ] __main__: train step 21506: loss: 0.9155, policy_loss: 0.8236, value_loss: 0.4507
2024-07-11 17:46:40,162 [INFO    ] __main__: train step 21507: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4506
2024-07-11 17:46:40,368 [INFO    ] __main__: train step 21508: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4506
2024-07-11 17:46:40,574 [INFO    ] __main__: train step 21509: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4506
2024-07-11 17:46:40,777 [INFO    ] __main__: train step 21510: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4506
2024-07-11 17:46:40,986 [INFO    ] __main__: train step 21511: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4506
2024-07-11 17:46:41,197 [INFO    ] __main__: train step 21512: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4506
2024-07-11 17:46:41,396 [INFO    ] __main__: train step 21513: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4505
2024-07-11 17:46:41,604 [INFO    ] __main__: train step 21514: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4505
2024-07-11 17:46:41,836 [INFO    ] __main__: train step 21515: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4505
2024-07-11 17:46:42,094 [INFO    ] __main__: train step 21516: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4505
2024-07-11 17:46:42,343 [INFO    ] __main__: train step 21517: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4505
2024-07-11 17:46:42,562 [INFO    ] __main__: train step 21518: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4505
2024-07-11 17:46:42,765 [INFO    ] __main__: train step 21519: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4504
2024-07-11 17:46:42,971 [INFO    ] __main__: train step 21520: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4504
2024-07-11 17:46:43,188 [INFO    ] __main__: train step 21521: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4504
2024-07-11 17:46:44,614 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:46:45,133 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:46:45,188 [INFO    ] __main__: train step 21522: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4504
2024-07-11 17:46:47,624 [INFO    ] __main__: train step 21523: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4504
2024-07-11 17:46:47,840 [INFO    ] __main__: train step 21524: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4504
2024-07-11 17:46:48,062 [INFO    ] __main__: train step 21525: loss: 0.9154, policy_loss: 0.8236, value_loss: 0.4503
2024-07-11 17:46:48,287 [INFO    ] __main__: train step 21526: loss: 0.9154, policy_loss: 0.8235, value_loss: 0.4503
2024-07-11 17:46:48,502 [INFO    ] __main__: train step 21527: loss: 0.9154, policy_loss: 0.8235, value_loss: 0.4503
2024-07-11 17:46:48,701 [INFO    ] __main__: train step 21528: loss: 0.9154, policy_loss: 0.8235, value_loss: 0.4503
2024-07-11 17:46:48,905 [INFO    ] __main__: train step 21529: loss: 0.9154, policy_loss: 0.8235, value_loss: 0.4503
2024-07-11 17:46:49,111 [INFO    ] __main__: train step 21530: loss: 0.9154, policy_loss: 0.8235, value_loss: 0.4502
2024-07-11 17:46:49,320 [INFO    ] __main__: train step 21531: loss: 0.9154, policy_loss: 0.8235, value_loss: 0.4502
2024-07-11 17:46:49,529 [INFO    ] __main__: train step 21532: loss: 0.9154, policy_loss: 0.8235, value_loss: 0.4502
2024-07-11 17:46:49,756 [INFO    ] __main__: train step 21533: loss: 0.9154, policy_loss: 0.8235, value_loss: 0.4502
2024-07-11 17:46:49,953 [INFO    ] __main__: train step 21534: loss: 0.9154, policy_loss: 0.8235, value_loss: 0.4502
2024-07-11 17:46:50,166 [INFO    ] __main__: train step 21535: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4502
2024-07-11 17:46:50,393 [INFO    ] __main__: train step 21536: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4501
2024-07-11 17:46:50,594 [INFO    ] __main__: train step 21537: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4501
2024-07-11 17:46:50,821 [INFO    ] __main__: train step 21538: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4501
2024-07-11 17:46:52,265 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:46:52,654 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:46:52,709 [INFO    ] __main__: train step 21539: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4501
2024-07-11 17:46:52,894 [INFO    ] __main__: train step 21540: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4501
2024-07-11 17:46:53,092 [INFO    ] __main__: train step 21541: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4501
2024-07-11 17:46:53,301 [INFO    ] __main__: train step 21542: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4500
2024-07-11 17:46:53,507 [INFO    ] __main__: train step 21543: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4500
2024-07-11 17:46:53,720 [INFO    ] __main__: train step 21544: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4500
2024-07-11 17:46:53,943 [INFO    ] __main__: train step 21545: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4500
2024-07-11 17:46:54,187 [INFO    ] __main__: train step 21546: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4500
2024-07-11 17:46:54,405 [INFO    ] __main__: train step 21547: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4500
2024-07-11 17:46:54,620 [INFO    ] __main__: train step 21548: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4499
2024-07-11 17:46:54,818 [INFO    ] __main__: train step 21549: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4499
2024-07-11 17:46:55,028 [INFO    ] __main__: train step 21550: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4499
2024-07-11 17:46:55,243 [INFO    ] __main__: train step 21551: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4499
2024-07-11 17:46:55,442 [INFO    ] __main__: train step 21552: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4499
2024-07-11 17:46:55,647 [INFO    ] __main__: train step 21553: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4499
2024-07-11 17:46:55,855 [INFO    ] __main__: train step 21554: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4498
2024-07-11 17:46:56,066 [INFO    ] __main__: train step 21555: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4498
2024-07-11 17:46:57,495 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:46:57,938 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:46:57,998 [INFO    ] __main__: train step 21556: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4498
2024-07-11 17:46:58,178 [INFO    ] __main__: train step 21557: loss: 0.9153, policy_loss: 0.8235, value_loss: 0.4498
2024-07-11 17:46:58,384 [INFO    ] __main__: train step 21558: loss: 0.9153, policy_loss: 0.8234, value_loss: 0.4498
2024-07-11 17:46:58,589 [INFO    ] __main__: train step 21559: loss: 0.9153, policy_loss: 0.8234, value_loss: 0.4498
2024-07-11 17:46:58,791 [INFO    ] __main__: train step 21560: loss: 0.9153, policy_loss: 0.8234, value_loss: 0.4497
2024-07-11 17:46:58,994 [INFO    ] __main__: train step 21561: loss: 0.9153, policy_loss: 0.8234, value_loss: 0.4497
2024-07-11 17:46:59,195 [INFO    ] __main__: train step 21562: loss: 0.9153, policy_loss: 0.8234, value_loss: 0.4497
2024-07-11 17:46:59,396 [INFO    ] __main__: train step 21563: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4497
2024-07-11 17:46:59,607 [INFO    ] __main__: train step 21564: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4497
2024-07-11 17:46:59,811 [INFO    ] __main__: train step 21565: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4497
2024-07-11 17:47:00,018 [INFO    ] __main__: train step 21566: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4496
2024-07-11 17:47:00,241 [INFO    ] __main__: train step 21567: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4496
2024-07-11 17:47:00,447 [INFO    ] __main__: train step 21568: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4496
2024-07-11 17:47:00,647 [INFO    ] __main__: train step 21569: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4496
2024-07-11 17:47:00,852 [INFO    ] __main__: train step 21570: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4496
2024-07-11 17:47:01,061 [INFO    ] __main__: train step 21571: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4496
2024-07-11 17:47:01,270 [INFO    ] __main__: train step 21572: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4495
2024-07-11 17:47:02,705 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:47:03,145 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:47:03,208 [INFO    ] __main__: train step 21573: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4495
2024-07-11 17:47:03,401 [INFO    ] __main__: train step 21574: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4495
2024-07-11 17:47:03,647 [INFO    ] __main__: train step 21575: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4495
2024-07-11 17:47:03,881 [INFO    ] __main__: train step 21576: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4495
2024-07-11 17:47:04,082 [INFO    ] __main__: train step 21577: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4495
2024-07-11 17:47:04,288 [INFO    ] __main__: train step 21578: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4494
2024-07-11 17:47:04,503 [INFO    ] __main__: train step 21579: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4494
2024-07-11 17:47:04,703 [INFO    ] __main__: train step 21580: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4494
2024-07-11 17:47:04,913 [INFO    ] __main__: train step 21581: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4494
2024-07-11 17:47:05,117 [INFO    ] __main__: train step 21582: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4494
2024-07-11 17:47:05,332 [INFO    ] __main__: train step 21583: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4494
2024-07-11 17:47:05,538 [INFO    ] __main__: train step 21584: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4493
2024-07-11 17:47:05,755 [INFO    ] __main__: train step 21585: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4493
2024-07-11 17:47:05,954 [INFO    ] __main__: train step 21586: loss: 0.9152, policy_loss: 0.8234, value_loss: 0.4493
2024-07-11 17:47:06,174 [INFO    ] __main__: train step 21587: loss: 0.9152, policy_loss: 0.8233, value_loss: 0.4493
2024-07-11 17:47:06,395 [INFO    ] __main__: train step 21588: loss: 0.9152, policy_loss: 0.8233, value_loss: 0.4493
2024-07-11 17:47:06,610 [INFO    ] __main__: train step 21589: loss: 0.9152, policy_loss: 0.8233, value_loss: 0.4493
2024-07-11 17:47:08,077 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:47:08,472 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:47:08,528 [INFO    ] __main__: train step 21590: loss: 0.9152, policy_loss: 0.8233, value_loss: 0.4492
2024-07-11 17:47:08,717 [INFO    ] __main__: train step 21591: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4492
2024-07-11 17:47:08,914 [INFO    ] __main__: train step 21592: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4492
2024-07-11 17:47:09,136 [INFO    ] __main__: train step 21593: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4492
2024-07-11 17:47:09,362 [INFO    ] __main__: train step 21594: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4492
2024-07-11 17:47:09,573 [INFO    ] __main__: train step 21595: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4492
2024-07-11 17:47:09,771 [INFO    ] __main__: train step 21596: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4491
2024-07-11 17:47:09,989 [INFO    ] __main__: train step 21597: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4491
2024-07-11 17:47:10,233 [INFO    ] __main__: train step 21598: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4491
2024-07-11 17:47:10,461 [INFO    ] __main__: train step 21599: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4491
2024-07-11 17:47:10,668 [INFO    ] __main__: train step 21600: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4491
2024-07-11 17:47:10,890 [INFO    ] __main__: train step 21601: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4491
2024-07-11 17:47:11,122 [INFO    ] __main__: train step 21602: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4490
2024-07-11 17:47:11,351 [INFO    ] __main__: train step 21603: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4490
2024-07-11 17:47:11,594 [INFO    ] __main__: train step 21604: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4490
2024-07-11 17:47:11,831 [INFO    ] __main__: train step 21605: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4490
2024-07-11 17:47:12,024 [INFO    ] __main__: train step 21606: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4490
2024-07-11 17:47:13,464 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:47:13,879 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:47:13,939 [INFO    ] __main__: train step 21607: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4490
2024-07-11 17:47:14,117 [INFO    ] __main__: train step 21608: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4489
2024-07-11 17:47:14,321 [INFO    ] __main__: train step 21609: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4489
2024-07-11 17:47:14,520 [INFO    ] __main__: train step 21610: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4489
2024-07-11 17:47:14,734 [INFO    ] __main__: train step 21611: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4489
2024-07-11 17:47:14,943 [INFO    ] __main__: train step 21612: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4489
2024-07-11 17:47:15,153 [INFO    ] __main__: train step 21613: loss: 0.9151, policy_loss: 0.8233, value_loss: 0.4489
2024-07-11 17:47:15,362 [INFO    ] __main__: train step 21614: loss: 0.9151, policy_loss: 0.8232, value_loss: 0.4488
2024-07-11 17:47:15,576 [INFO    ] __main__: train step 21615: loss: 0.9151, policy_loss: 0.8232, value_loss: 0.4488
2024-07-11 17:47:15,777 [INFO    ] __main__: train step 21616: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4488
2024-07-11 17:47:15,982 [INFO    ] __main__: train step 21617: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4488
2024-07-11 17:47:16,179 [INFO    ] __main__: train step 21618: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4488
2024-07-11 17:47:16,379 [INFO    ] __main__: train step 21619: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4488
2024-07-11 17:47:16,577 [INFO    ] __main__: train step 21620: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4487
2024-07-11 17:47:16,780 [INFO    ] __main__: train step 21621: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4487
2024-07-11 17:47:16,975 [INFO    ] __main__: train step 21622: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4487
2024-07-11 17:47:17,173 [INFO    ] __main__: train step 21623: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4487
2024-07-11 17:47:18,626 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:47:19,063 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:47:19,128 [INFO    ] __main__: train step 21624: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4487
2024-07-11 17:47:19,321 [INFO    ] __main__: train step 21625: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4487
2024-07-11 17:47:19,561 [INFO    ] __main__: train step 21626: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4486
2024-07-11 17:47:19,787 [INFO    ] __main__: train step 21627: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4486
2024-07-11 17:47:19,996 [INFO    ] __main__: train step 21628: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4486
2024-07-11 17:47:20,237 [INFO    ] __main__: train step 21629: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4486
2024-07-11 17:47:20,463 [INFO    ] __main__: train step 21630: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4486
2024-07-11 17:47:20,668 [INFO    ] __main__: train step 21631: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4486
2024-07-11 17:47:20,888 [INFO    ] __main__: train step 21632: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4485
2024-07-11 17:47:21,135 [INFO    ] __main__: train step 21633: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4485
2024-07-11 17:47:21,358 [INFO    ] __main__: train step 21634: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4485
2024-07-11 17:47:21,576 [INFO    ] __main__: train step 21635: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4485
2024-07-11 17:47:21,826 [INFO    ] __main__: train step 21636: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4485
2024-07-11 17:47:22,059 [INFO    ] __main__: train step 21637: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4484
2024-07-11 17:47:22,258 [INFO    ] __main__: train step 21638: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4484
2024-07-11 17:47:22,460 [INFO    ] __main__: train step 21639: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4484
2024-07-11 17:47:22,668 [INFO    ] __main__: train step 21640: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4484
2024-07-11 17:47:24,104 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:47:24,522 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:47:24,583 [INFO    ] __main__: train step 21641: loss: 0.9150, policy_loss: 0.8232, value_loss: 0.4484
2024-07-11 17:47:24,803 [INFO    ] __main__: train step 21642: loss: 0.9149, policy_loss: 0.8232, value_loss: 0.4484
2024-07-11 17:47:25,059 [INFO    ] __main__: train step 21643: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4483
2024-07-11 17:47:25,300 [INFO    ] __main__: train step 21644: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4483
2024-07-11 17:47:25,519 [INFO    ] __main__: train step 21645: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4483
2024-07-11 17:47:25,720 [INFO    ] __main__: train step 21646: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4483
2024-07-11 17:47:25,932 [INFO    ] __main__: train step 21647: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4483
2024-07-11 17:47:26,143 [INFO    ] __main__: train step 21648: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4483
2024-07-11 17:47:26,336 [INFO    ] __main__: train step 21649: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4482
2024-07-11 17:47:26,560 [INFO    ] __main__: train step 21650: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4482
2024-07-11 17:47:26,788 [INFO    ] __main__: train step 21651: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4482
2024-07-11 17:47:27,014 [INFO    ] __main__: train step 21652: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4482
2024-07-11 17:47:27,259 [INFO    ] __main__: train step 21653: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4482
2024-07-11 17:47:27,476 [INFO    ] __main__: train step 21654: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4482
2024-07-11 17:47:27,771 [INFO    ] __main__: train step 21655: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4481
2024-07-11 17:47:28,004 [INFO    ] __main__: train step 21656: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4481
2024-07-11 17:47:28,218 [INFO    ] __main__: train step 21657: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4481
2024-07-11 17:47:29,657 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:47:30,069 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:47:30,126 [INFO    ] __main__: train step 21658: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4481
2024-07-11 17:47:30,308 [INFO    ] __main__: train step 21659: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4481
2024-07-11 17:47:30,537 [INFO    ] __main__: train step 21660: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4481
2024-07-11 17:47:33,054 [INFO    ] __main__: train step 21661: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4480
2024-07-11 17:47:33,277 [INFO    ] __main__: train step 21662: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4480
2024-07-11 17:47:33,482 [INFO    ] __main__: train step 21663: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4480
2024-07-11 17:47:33,690 [INFO    ] __main__: train step 21664: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4480
2024-07-11 17:47:33,940 [INFO    ] __main__: train step 21665: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4480
2024-07-11 17:47:34,181 [INFO    ] __main__: train step 21666: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4480
2024-07-11 17:47:34,388 [INFO    ] __main__: train step 21667: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4479
2024-07-11 17:47:34,608 [INFO    ] __main__: train step 21668: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4479
2024-07-11 17:47:34,844 [INFO    ] __main__: train step 21669: loss: 0.9149, policy_loss: 0.8231, value_loss: 0.4479
2024-07-11 17:47:35,057 [INFO    ] __main__: train step 21670: loss: 0.9148, policy_loss: 0.8231, value_loss: 0.4479
2024-07-11 17:47:35,286 [INFO    ] __main__: train step 21671: loss: 0.9148, policy_loss: 0.8231, value_loss: 0.4479
2024-07-11 17:47:35,488 [INFO    ] __main__: train step 21672: loss: 0.9148, policy_loss: 0.8231, value_loss: 0.4479
2024-07-11 17:47:35,682 [INFO    ] __main__: train step 21673: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4478
2024-07-11 17:47:35,899 [INFO    ] __main__: train step 21674: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4478
2024-07-11 17:47:37,344 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:47:37,758 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:47:37,814 [INFO    ] __main__: train step 21675: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4478
2024-07-11 17:47:37,995 [INFO    ] __main__: train step 21676: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4478
2024-07-11 17:47:38,191 [INFO    ] __main__: train step 21677: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4478
2024-07-11 17:47:38,393 [INFO    ] __main__: train step 21678: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4478
2024-07-11 17:47:38,600 [INFO    ] __main__: train step 21679: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4477
2024-07-11 17:47:38,809 [INFO    ] __main__: train step 21680: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4477
2024-07-11 17:47:39,017 [INFO    ] __main__: train step 21681: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4477
2024-07-11 17:47:39,220 [INFO    ] __main__: train step 21682: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4477
2024-07-11 17:47:39,424 [INFO    ] __main__: train step 21683: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4477
2024-07-11 17:47:39,643 [INFO    ] __main__: train step 21684: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4477
2024-07-11 17:47:39,849 [INFO    ] __main__: train step 21685: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4476
2024-07-11 17:47:40,082 [INFO    ] __main__: train step 21686: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4476
2024-07-11 17:47:40,287 [INFO    ] __main__: train step 21687: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4476
2024-07-11 17:47:40,503 [INFO    ] __main__: train step 21688: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4476
2024-07-11 17:47:40,737 [INFO    ] __main__: train step 21689: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4476
2024-07-11 17:47:40,942 [INFO    ] __main__: train step 21690: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4476
2024-07-11 17:47:41,145 [INFO    ] __main__: train step 21691: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4475
2024-07-11 17:47:42,612 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:47:43,001 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:47:43,057 [INFO    ] __main__: train step 21692: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4475
2024-07-11 17:47:43,249 [INFO    ] __main__: train step 21693: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4475
2024-07-11 17:47:43,453 [INFO    ] __main__: train step 21694: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4475
2024-07-11 17:47:43,662 [INFO    ] __main__: train step 21695: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4475
2024-07-11 17:47:43,863 [INFO    ] __main__: train step 21696: loss: 0.9148, policy_loss: 0.8230, value_loss: 0.4475
2024-07-11 17:47:44,067 [INFO    ] __main__: train step 21697: loss: 0.9147, policy_loss: 0.8230, value_loss: 0.4474
2024-07-11 17:47:44,271 [INFO    ] __main__: train step 21698: loss: 0.9147, policy_loss: 0.8230, value_loss: 0.4474
2024-07-11 17:47:44,487 [INFO    ] __main__: train step 21699: loss: 0.9147, policy_loss: 0.8230, value_loss: 0.4474
2024-07-11 17:47:44,689 [INFO    ] __main__: train step 21700: loss: 0.9147, policy_loss: 0.8230, value_loss: 0.4474
2024-07-11 17:47:44,909 [INFO    ] __main__: train step 21701: loss: 0.9147, policy_loss: 0.8230, value_loss: 0.4474
2024-07-11 17:47:45,128 [INFO    ] __main__: train step 21702: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4474
2024-07-11 17:47:45,348 [INFO    ] __main__: train step 21703: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4473
2024-07-11 17:47:45,583 [INFO    ] __main__: train step 21704: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4473
2024-07-11 17:47:45,775 [INFO    ] __main__: train step 21705: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4473
2024-07-11 17:47:45,991 [INFO    ] __main__: train step 21706: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4473
2024-07-11 17:47:46,187 [INFO    ] __main__: train step 21707: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4473
2024-07-11 17:47:46,403 [INFO    ] __main__: train step 21708: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4473
2024-07-11 17:47:47,877 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:47:48,296 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:47:48,355 [INFO    ] __main__: train step 21709: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4472
2024-07-11 17:47:48,540 [INFO    ] __main__: train step 21710: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4472
2024-07-11 17:47:48,743 [INFO    ] __main__: train step 21711: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4472
2024-07-11 17:47:48,942 [INFO    ] __main__: train step 21712: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4472
2024-07-11 17:47:49,145 [INFO    ] __main__: train step 21713: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4472
2024-07-11 17:47:49,360 [INFO    ] __main__: train step 21714: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4472
2024-07-11 17:47:49,561 [INFO    ] __main__: train step 21715: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4471
2024-07-11 17:47:49,770 [INFO    ] __main__: train step 21716: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4471
2024-07-11 17:47:50,019 [INFO    ] __main__: train step 21717: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4471
2024-07-11 17:47:50,240 [INFO    ] __main__: train step 21718: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4471
2024-07-11 17:47:50,449 [INFO    ] __main__: train step 21719: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4471
2024-07-11 17:47:50,645 [INFO    ] __main__: train step 21720: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4471
2024-07-11 17:47:50,870 [INFO    ] __main__: train step 21721: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4470
2024-07-11 17:47:51,109 [INFO    ] __main__: train step 21722: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4470
2024-07-11 17:47:51,345 [INFO    ] __main__: train step 21723: loss: 0.9147, policy_loss: 0.8229, value_loss: 0.4470
2024-07-11 17:47:51,552 [INFO    ] __main__: train step 21724: loss: 0.9146, policy_loss: 0.8229, value_loss: 0.4470
2024-07-11 17:47:51,804 [INFO    ] __main__: train step 21725: loss: 0.9146, policy_loss: 0.8229, value_loss: 0.4470
2024-07-11 17:47:53,321 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:47:53,706 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:47:53,762 [INFO    ] __main__: train step 21726: loss: 0.9146, policy_loss: 0.8229, value_loss: 0.4470
2024-07-11 17:47:53,939 [INFO    ] __main__: train step 21727: loss: 0.9146, policy_loss: 0.8229, value_loss: 0.4469
2024-07-11 17:47:54,138 [INFO    ] __main__: train step 21728: loss: 0.9146, policy_loss: 0.8229, value_loss: 0.4469
2024-07-11 17:47:54,343 [INFO    ] __main__: train step 21729: loss: 0.9146, policy_loss: 0.8229, value_loss: 0.4469
2024-07-11 17:47:54,549 [INFO    ] __main__: train step 21730: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4469
2024-07-11 17:47:54,753 [INFO    ] __main__: train step 21731: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4469
2024-07-11 17:47:54,958 [INFO    ] __main__: train step 21732: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4469
2024-07-11 17:47:55,156 [INFO    ] __main__: train step 21733: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4468
2024-07-11 17:47:55,371 [INFO    ] __main__: train step 21734: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4468
2024-07-11 17:47:55,573 [INFO    ] __main__: train step 21735: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4468
2024-07-11 17:47:55,778 [INFO    ] __main__: train step 21736: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4468
2024-07-11 17:47:55,985 [INFO    ] __main__: train step 21737: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4468
2024-07-11 17:47:56,189 [INFO    ] __main__: train step 21738: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4468
2024-07-11 17:47:56,391 [INFO    ] __main__: train step 21739: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4467
2024-07-11 17:47:56,601 [INFO    ] __main__: train step 21740: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4467
2024-07-11 17:47:56,826 [INFO    ] __main__: train step 21741: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4467
2024-07-11 17:47:57,026 [INFO    ] __main__: train step 21742: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4467
2024-07-11 17:47:58,467 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:47:58,848 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:47:58,905 [INFO    ] __main__: train step 21743: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4467
2024-07-11 17:47:59,081 [INFO    ] __main__: train step 21744: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4467
2024-07-11 17:47:59,311 [INFO    ] __main__: train step 21745: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4466
2024-07-11 17:47:59,512 [INFO    ] __main__: train step 21746: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4466
2024-07-11 17:47:59,729 [INFO    ] __main__: train step 21747: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4466
2024-07-11 17:47:59,968 [INFO    ] __main__: train step 21748: loss: 0.9146, policy_loss: 0.8228, value_loss: 0.4466
2024-07-11 17:48:00,203 [INFO    ] __main__: train step 21749: loss: 0.9145, policy_loss: 0.8228, value_loss: 0.4466
2024-07-11 17:48:00,431 [INFO    ] __main__: train step 21750: loss: 0.9145, policy_loss: 0.8228, value_loss: 0.4466
2024-07-11 17:48:00,663 [INFO    ] __main__: train step 21751: loss: 0.9145, policy_loss: 0.8228, value_loss: 0.4465
2024-07-11 17:48:00,887 [INFO    ] __main__: train step 21752: loss: 0.9145, policy_loss: 0.8228, value_loss: 0.4465
2024-07-11 17:48:01,089 [INFO    ] __main__: train step 21753: loss: 0.9145, policy_loss: 0.8228, value_loss: 0.4465
2024-07-11 17:48:01,337 [INFO    ] __main__: train step 21754: loss: 0.9145, policy_loss: 0.8228, value_loss: 0.4465
2024-07-11 17:48:01,557 [INFO    ] __main__: train step 21755: loss: 0.9145, policy_loss: 0.8228, value_loss: 0.4465
2024-07-11 17:48:01,783 [INFO    ] __main__: train step 21756: loss: 0.9145, policy_loss: 0.8228, value_loss: 0.4465
2024-07-11 17:48:01,986 [INFO    ] __main__: train step 21757: loss: 0.9145, policy_loss: 0.8228, value_loss: 0.4464
2024-07-11 17:48:02,217 [INFO    ] __main__: train step 21758: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4464
2024-07-11 17:48:02,420 [INFO    ] __main__: train step 21759: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4464
2024-07-11 17:48:03,897 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:48:04,303 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:48:04,358 [INFO    ] __main__: train step 21760: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4464
2024-07-11 17:48:04,543 [INFO    ] __main__: train step 21761: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4464
2024-07-11 17:48:04,751 [INFO    ] __main__: train step 21762: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4464
2024-07-11 17:48:04,961 [INFO    ] __main__: train step 21763: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4463
2024-07-11 17:48:05,161 [INFO    ] __main__: train step 21764: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4463
2024-07-11 17:48:05,372 [INFO    ] __main__: train step 21765: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4463
2024-07-11 17:48:05,580 [INFO    ] __main__: train step 21766: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4463
2024-07-11 17:48:05,791 [INFO    ] __main__: train step 21767: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4463
2024-07-11 17:48:06,033 [INFO    ] __main__: train step 21768: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4463
2024-07-11 17:48:06,237 [INFO    ] __main__: train step 21769: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4462
2024-07-11 17:48:06,453 [INFO    ] __main__: train step 21770: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4462
2024-07-11 17:48:06,660 [INFO    ] __main__: train step 21771: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4462
2024-07-11 17:48:06,867 [INFO    ] __main__: train step 21772: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4462
2024-07-11 17:48:07,079 [INFO    ] __main__: train step 21773: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4462
2024-07-11 17:48:07,291 [INFO    ] __main__: train step 21774: loss: 0.9145, policy_loss: 0.8227, value_loss: 0.4462
2024-07-11 17:48:07,488 [INFO    ] __main__: train step 21775: loss: 0.9144, policy_loss: 0.8227, value_loss: 0.4461
2024-07-11 17:48:07,695 [INFO    ] __main__: train step 21776: loss: 0.9144, policy_loss: 0.8227, value_loss: 0.4461
2024-07-11 17:48:09,142 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:48:09,690 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:48:09,750 [INFO    ] __main__: train step 21777: loss: 0.9144, policy_loss: 0.8227, value_loss: 0.4461
2024-07-11 17:48:09,936 [INFO    ] __main__: train step 21778: loss: 0.9144, policy_loss: 0.8227, value_loss: 0.4461
2024-07-11 17:48:10,168 [INFO    ] __main__: train step 21779: loss: 0.9144, policy_loss: 0.8227, value_loss: 0.4461
2024-07-11 17:48:10,362 [INFO    ] __main__: train step 21780: loss: 0.9144, policy_loss: 0.8227, value_loss: 0.4461
2024-07-11 17:48:10,572 [INFO    ] __main__: train step 21781: loss: 0.9144, policy_loss: 0.8227, value_loss: 0.4460
2024-07-11 17:48:10,769 [INFO    ] __main__: train step 21782: loss: 0.9144, policy_loss: 0.8227, value_loss: 0.4460
2024-07-11 17:48:10,970 [INFO    ] __main__: train step 21783: loss: 0.9144, policy_loss: 0.8227, value_loss: 0.4460
2024-07-11 17:48:11,175 [INFO    ] __main__: train step 21784: loss: 0.9144, policy_loss: 0.8227, value_loss: 0.4460
2024-07-11 17:48:11,380 [INFO    ] __main__: train step 21785: loss: 0.9144, policy_loss: 0.8227, value_loss: 0.4460
2024-07-11 17:48:11,586 [INFO    ] __main__: train step 21786: loss: 0.9144, policy_loss: 0.8227, value_loss: 0.4460
2024-07-11 17:48:11,798 [INFO    ] __main__: train step 21787: loss: 0.9144, policy_loss: 0.8226, value_loss: 0.4459
2024-07-11 17:48:12,019 [INFO    ] __main__: train step 21788: loss: 0.9144, policy_loss: 0.8226, value_loss: 0.4459
2024-07-11 17:48:12,258 [INFO    ] __main__: train step 21789: loss: 0.9144, policy_loss: 0.8226, value_loss: 0.4459
2024-07-11 17:48:12,456 [INFO    ] __main__: train step 21790: loss: 0.9144, policy_loss: 0.8226, value_loss: 0.4459
2024-07-11 17:48:12,665 [INFO    ] __main__: train step 21791: loss: 0.9144, policy_loss: 0.8226, value_loss: 0.4459
2024-07-11 17:48:12,873 [INFO    ] __main__: train step 21792: loss: 0.9144, policy_loss: 0.8226, value_loss: 0.4459
2024-07-11 17:48:13,078 [INFO    ] __main__: train step 21793: loss: 0.9144, policy_loss: 0.8226, value_loss: 0.4458
2024-07-11 17:48:14,518 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:48:14,909 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:48:14,966 [INFO    ] __main__: train step 21794: loss: 0.9144, policy_loss: 0.8226, value_loss: 0.4458
2024-07-11 17:48:15,158 [INFO    ] __main__: train step 21795: loss: 0.9144, policy_loss: 0.8226, value_loss: 0.4458
2024-07-11 17:48:15,392 [INFO    ] __main__: train step 21796: loss: 0.9144, policy_loss: 0.8226, value_loss: 0.4458
2024-07-11 17:48:15,600 [INFO    ] __main__: train step 21797: loss: 0.9144, policy_loss: 0.8226, value_loss: 0.4458
2024-07-11 17:48:15,811 [INFO    ] __main__: train step 21798: loss: 0.9144, policy_loss: 0.8226, value_loss: 0.4458
2024-07-11 17:48:18,278 [INFO    ] __main__: train step 21799: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4457
2024-07-11 17:48:18,517 [INFO    ] __main__: train step 21800: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4457
2024-07-11 17:48:18,726 [INFO    ] __main__: train step 21801: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4457
2024-07-11 17:48:18,930 [INFO    ] __main__: train step 21802: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4457
2024-07-11 17:48:19,134 [INFO    ] __main__: train step 21803: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4457
2024-07-11 17:48:19,340 [INFO    ] __main__: train step 21804: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4457
2024-07-11 17:48:19,537 [INFO    ] __main__: train step 21805: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4456
2024-07-11 17:48:19,744 [INFO    ] __main__: train step 21806: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4456
2024-07-11 17:48:19,950 [INFO    ] __main__: train step 21807: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4456
2024-07-11 17:48:20,157 [INFO    ] __main__: train step 21808: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4456
2024-07-11 17:48:20,358 [INFO    ] __main__: train step 21809: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4456
2024-07-11 17:48:20,577 [INFO    ] __main__: train step 21810: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4456
2024-07-11 17:48:22,062 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:48:22,481 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:48:22,547 [INFO    ] __main__: train step 21811: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4455
2024-07-11 17:48:22,724 [INFO    ] __main__: train step 21812: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4455
2024-07-11 17:48:22,939 [INFO    ] __main__: train step 21813: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4455
2024-07-11 17:48:23,149 [INFO    ] __main__: train step 21814: loss: 0.9143, policy_loss: 0.8226, value_loss: 0.4455
2024-07-11 17:48:23,354 [INFO    ] __main__: train step 21815: loss: 0.9143, policy_loss: 0.8225, value_loss: 0.4455
2024-07-11 17:48:23,576 [INFO    ] __main__: train step 21816: loss: 0.9143, policy_loss: 0.8225, value_loss: 0.4455
2024-07-11 17:48:23,800 [INFO    ] __main__: train step 21817: loss: 0.9143, policy_loss: 0.8225, value_loss: 0.4454
2024-07-11 17:48:24,038 [INFO    ] __main__: train step 21818: loss: 0.9143, policy_loss: 0.8225, value_loss: 0.4454
2024-07-11 17:48:24,239 [INFO    ] __main__: train step 21819: loss: 0.9143, policy_loss: 0.8225, value_loss: 0.4454
2024-07-11 17:48:24,448 [INFO    ] __main__: train step 21820: loss: 0.9143, policy_loss: 0.8225, value_loss: 0.4454
2024-07-11 17:48:24,658 [INFO    ] __main__: train step 21821: loss: 0.9143, policy_loss: 0.8225, value_loss: 0.4454
2024-07-11 17:48:24,899 [INFO    ] __main__: train step 21822: loss: 0.9143, policy_loss: 0.8225, value_loss: 0.4454
2024-07-11 17:48:25,108 [INFO    ] __main__: train step 21823: loss: 0.9143, policy_loss: 0.8225, value_loss: 0.4453
2024-07-11 17:48:25,316 [INFO    ] __main__: train step 21824: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4453
2024-07-11 17:48:25,514 [INFO    ] __main__: train step 21825: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4453
2024-07-11 17:48:25,726 [INFO    ] __main__: train step 21826: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4453
2024-07-11 17:48:25,935 [INFO    ] __main__: train step 21827: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4453
2024-07-11 17:48:27,396 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:48:27,791 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:48:27,845 [INFO    ] __main__: train step 21828: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4453
2024-07-11 17:48:28,025 [INFO    ] __main__: train step 21829: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4452
2024-07-11 17:48:28,223 [INFO    ] __main__: train step 21830: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4452
2024-07-11 17:48:28,435 [INFO    ] __main__: train step 21831: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4452
2024-07-11 17:48:28,638 [INFO    ] __main__: train step 21832: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4452
2024-07-11 17:48:28,841 [INFO    ] __main__: train step 21833: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4452
2024-07-11 17:48:29,049 [INFO    ] __main__: train step 21834: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4452
2024-07-11 17:48:29,249 [INFO    ] __main__: train step 21835: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4451
2024-07-11 17:48:29,451 [INFO    ] __main__: train step 21836: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4451
2024-07-11 17:48:29,659 [INFO    ] __main__: train step 21837: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4451
2024-07-11 17:48:29,874 [INFO    ] __main__: train step 21838: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4451
2024-07-11 17:48:30,084 [INFO    ] __main__: train step 21839: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4451
2024-07-11 17:48:30,304 [INFO    ] __main__: train step 21840: loss: 0.9142, policy_loss: 0.8225, value_loss: 0.4451
2024-07-11 17:48:30,508 [INFO    ] __main__: train step 21841: loss: 0.9142, policy_loss: 0.8224, value_loss: 0.4450
2024-07-11 17:48:30,720 [INFO    ] __main__: train step 21842: loss: 0.9142, policy_loss: 0.8224, value_loss: 0.4450
2024-07-11 17:48:30,928 [INFO    ] __main__: train step 21843: loss: 0.9142, policy_loss: 0.8224, value_loss: 0.4450
2024-07-11 17:48:31,134 [INFO    ] __main__: train step 21844: loss: 0.9142, policy_loss: 0.8224, value_loss: 0.4450
2024-07-11 17:48:32,586 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:48:33,012 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:48:33,072 [INFO    ] __main__: train step 21845: loss: 0.9142, policy_loss: 0.8224, value_loss: 0.4450
2024-07-11 17:48:33,252 [INFO    ] __main__: train step 21846: loss: 0.9142, policy_loss: 0.8224, value_loss: 0.4450
2024-07-11 17:48:33,453 [INFO    ] __main__: train step 21847: loss: 0.9142, policy_loss: 0.8224, value_loss: 0.4449
2024-07-11 17:48:33,660 [INFO    ] __main__: train step 21848: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4449
2024-07-11 17:48:33,861 [INFO    ] __main__: train step 21849: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4449
2024-07-11 17:48:34,055 [INFO    ] __main__: train step 21850: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4449
2024-07-11 17:48:34,256 [INFO    ] __main__: train step 21851: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4449
2024-07-11 17:48:34,453 [INFO    ] __main__: train step 21852: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4449
2024-07-11 17:48:34,664 [INFO    ] __main__: train step 21853: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4448
2024-07-11 17:48:34,869 [INFO    ] __main__: train step 21854: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4448
2024-07-11 17:48:35,069 [INFO    ] __main__: train step 21855: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4448
2024-07-11 17:48:35,275 [INFO    ] __main__: train step 21856: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4448
2024-07-11 17:48:35,472 [INFO    ] __main__: train step 21857: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4448
2024-07-11 17:48:35,675 [INFO    ] __main__: train step 21858: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4448
2024-07-11 17:48:35,895 [INFO    ] __main__: train step 21859: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4447
2024-07-11 17:48:36,136 [INFO    ] __main__: train step 21860: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4447
2024-07-11 17:48:36,375 [INFO    ] __main__: train step 21861: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4447
2024-07-11 17:48:37,834 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:48:38,232 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:48:38,293 [INFO    ] __main__: train step 21862: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4447
2024-07-11 17:48:38,468 [INFO    ] __main__: train step 21863: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4447
2024-07-11 17:48:38,674 [INFO    ] __main__: train step 21864: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4447
2024-07-11 17:48:38,899 [INFO    ] __main__: train step 21865: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4446
2024-07-11 17:48:39,120 [INFO    ] __main__: train step 21866: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4446
2024-07-11 17:48:39,327 [INFO    ] __main__: train step 21867: loss: 0.9141, policy_loss: 0.8224, value_loss: 0.4446
2024-07-11 17:48:39,533 [INFO    ] __main__: train step 21868: loss: 0.9141, policy_loss: 0.8223, value_loss: 0.4446
2024-07-11 17:48:39,739 [INFO    ] __main__: train step 21869: loss: 0.9141, policy_loss: 0.8223, value_loss: 0.4446
2024-07-11 17:48:39,943 [INFO    ] __main__: train step 21870: loss: 0.9141, policy_loss: 0.8223, value_loss: 0.4446
2024-07-11 17:48:40,144 [INFO    ] __main__: train step 21871: loss: 0.9141, policy_loss: 0.8223, value_loss: 0.4445
2024-07-11 17:48:40,353 [INFO    ] __main__: train step 21872: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4445
2024-07-11 17:48:40,564 [INFO    ] __main__: train step 21873: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4445
2024-07-11 17:48:40,810 [INFO    ] __main__: train step 21874: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4445
2024-07-11 17:48:41,009 [INFO    ] __main__: train step 21875: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4445
2024-07-11 17:48:41,226 [INFO    ] __main__: train step 21876: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4445
2024-07-11 17:48:41,423 [INFO    ] __main__: train step 21877: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4444
2024-07-11 17:48:41,622 [INFO    ] __main__: train step 21878: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4444
2024-07-11 17:48:43,058 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:48:43,435 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:48:43,493 [INFO    ] __main__: train step 21879: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4444
2024-07-11 17:48:43,670 [INFO    ] __main__: train step 21880: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4444
2024-07-11 17:48:43,877 [INFO    ] __main__: train step 21881: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4444
2024-07-11 17:48:44,080 [INFO    ] __main__: train step 21882: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4444
2024-07-11 17:48:44,280 [INFO    ] __main__: train step 21883: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4444
2024-07-11 17:48:44,485 [INFO    ] __main__: train step 21884: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4443
2024-07-11 17:48:44,700 [INFO    ] __main__: train step 21885: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4443
2024-07-11 17:48:44,944 [INFO    ] __main__: train step 21886: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4443
2024-07-11 17:48:45,164 [INFO    ] __main__: train step 21887: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4443
2024-07-11 17:48:45,392 [INFO    ] __main__: train step 21888: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4443
2024-07-11 17:48:45,596 [INFO    ] __main__: train step 21889: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4443
2024-07-11 17:48:45,799 [INFO    ] __main__: train step 21890: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4442
2024-07-11 17:48:45,996 [INFO    ] __main__: train step 21891: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4442
2024-07-11 17:48:46,202 [INFO    ] __main__: train step 21892: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4442
2024-07-11 17:48:46,404 [INFO    ] __main__: train step 21893: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4442
2024-07-11 17:48:46,616 [INFO    ] __main__: train step 21894: loss: 0.9140, policy_loss: 0.8223, value_loss: 0.4442
2024-07-11 17:48:46,812 [INFO    ] __main__: train step 21895: loss: 0.9140, policy_loss: 0.8222, value_loss: 0.4442
2024-07-11 17:48:48,245 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:48:48,647 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:48:48,708 [INFO    ] __main__: train step 21896: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4441
2024-07-11 17:48:48,887 [INFO    ] __main__: train step 21897: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4441
2024-07-11 17:48:49,087 [INFO    ] __main__: train step 21898: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4441
2024-07-11 17:48:49,307 [INFO    ] __main__: train step 21899: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4441
2024-07-11 17:48:49,530 [INFO    ] __main__: train step 21900: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4441
2024-07-11 17:48:49,747 [INFO    ] __main__: train step 21901: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4441
2024-07-11 17:48:49,959 [INFO    ] __main__: train step 21902: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4440
2024-07-11 17:48:50,153 [INFO    ] __main__: train step 21903: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4440
2024-07-11 17:48:50,459 [INFO    ] __main__: train step 21904: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4440
2024-07-11 17:48:50,662 [INFO    ] __main__: train step 21905: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4440
2024-07-11 17:48:50,869 [INFO    ] __main__: train step 21906: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4440
2024-07-11 17:48:51,105 [INFO    ] __main__: train step 21907: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4440
2024-07-11 17:48:51,331 [INFO    ] __main__: train step 21908: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4439
2024-07-11 17:48:51,533 [INFO    ] __main__: train step 21909: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4439
2024-07-11 17:48:51,743 [INFO    ] __main__: train step 21910: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4439
2024-07-11 17:48:51,942 [INFO    ] __main__: train step 21911: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4439
2024-07-11 17:48:52,149 [INFO    ] __main__: train step 21912: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4439
2024-07-11 17:48:53,594 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:48:53,981 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:48:54,039 [INFO    ] __main__: train step 21913: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4439
2024-07-11 17:48:54,226 [INFO    ] __main__: train step 21914: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4438
2024-07-11 17:48:54,421 [INFO    ] __main__: train step 21915: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4438
2024-07-11 17:48:54,640 [INFO    ] __main__: train step 21916: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4438
2024-07-11 17:48:54,845 [INFO    ] __main__: train step 21917: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4438
2024-07-11 17:48:55,052 [INFO    ] __main__: train step 21918: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4438
2024-07-11 17:48:55,248 [INFO    ] __main__: train step 21919: loss: 0.9139, policy_loss: 0.8222, value_loss: 0.4438
2024-07-11 17:48:55,449 [INFO    ] __main__: train step 21920: loss: 0.9138, policy_loss: 0.8222, value_loss: 0.4437
2024-07-11 17:48:55,647 [INFO    ] __main__: train step 21921: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4437
2024-07-11 17:48:55,852 [INFO    ] __main__: train step 21922: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4437
2024-07-11 17:48:56,059 [INFO    ] __main__: train step 21923: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4437
2024-07-11 17:48:56,259 [INFO    ] __main__: train step 21924: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4437
2024-07-11 17:48:56,467 [INFO    ] __main__: train step 21925: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4437
2024-07-11 17:48:56,674 [INFO    ] __main__: train step 21926: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4436
2024-07-11 17:48:56,875 [INFO    ] __main__: train step 21927: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4436
2024-07-11 17:48:57,088 [INFO    ] __main__: train step 21928: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4436
2024-07-11 17:48:57,293 [INFO    ] __main__: train step 21929: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4436
2024-07-11 17:48:58,729 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:48:59,089 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:48:59,144 [INFO    ] __main__: train step 21930: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4436
2024-07-11 17:48:59,333 [INFO    ] __main__: train step 21931: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4436
2024-07-11 17:48:59,532 [INFO    ] __main__: train step 21932: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4435
2024-07-11 17:48:59,736 [INFO    ] __main__: train step 21933: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4435
2024-07-11 17:48:59,942 [INFO    ] __main__: train step 21934: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4435
2024-07-11 17:49:00,157 [INFO    ] __main__: train step 21935: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4435
2024-07-11 17:49:00,362 [INFO    ] __main__: train step 21936: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4435
2024-07-11 17:49:02,866 [INFO    ] __main__: train step 21937: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4435
2024-07-11 17:49:03,100 [INFO    ] __main__: train step 21938: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4434
2024-07-11 17:49:03,290 [INFO    ] __main__: train step 21939: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4434
2024-07-11 17:49:03,501 [INFO    ] __main__: train step 21940: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4434
2024-07-11 17:49:03,713 [INFO    ] __main__: train step 21941: loss: 0.9138, policy_loss: 0.8221, value_loss: 0.4434
2024-07-11 17:49:03,922 [INFO    ] __main__: train step 21942: loss: 0.9137, policy_loss: 0.8221, value_loss: 0.4434
2024-07-11 17:49:04,117 [INFO    ] __main__: train step 21943: loss: 0.9137, policy_loss: 0.8221, value_loss: 0.4434
2024-07-11 17:49:04,328 [INFO    ] __main__: train step 21944: loss: 0.9137, policy_loss: 0.8221, value_loss: 0.4433
2024-07-11 17:49:04,542 [INFO    ] __main__: train step 21945: loss: 0.9137, policy_loss: 0.8221, value_loss: 0.4433
2024-07-11 17:49:04,740 [INFO    ] __main__: train step 21946: loss: 0.9137, policy_loss: 0.8221, value_loss: 0.4433
2024-07-11 17:49:06,195 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:49:06,583 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:49:06,639 [INFO    ] __main__: train step 21947: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4433
2024-07-11 17:49:06,826 [INFO    ] __main__: train step 21948: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4433
2024-07-11 17:49:07,032 [INFO    ] __main__: train step 21949: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4433
2024-07-11 17:49:07,228 [INFO    ] __main__: train step 21950: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4432
2024-07-11 17:49:07,424 [INFO    ] __main__: train step 21951: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4432
2024-07-11 17:49:07,627 [INFO    ] __main__: train step 21952: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4432
2024-07-11 17:49:07,829 [INFO    ] __main__: train step 21953: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4432
2024-07-11 17:49:08,039 [INFO    ] __main__: train step 21954: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4432
2024-07-11 17:49:08,254 [INFO    ] __main__: train step 21955: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4432
2024-07-11 17:49:08,449 [INFO    ] __main__: train step 21956: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4431
2024-07-11 17:49:08,651 [INFO    ] __main__: train step 21957: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4431
2024-07-11 17:49:08,870 [INFO    ] __main__: train step 21958: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4431
2024-07-11 17:49:09,086 [INFO    ] __main__: train step 21959: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4431
2024-07-11 17:49:09,338 [INFO    ] __main__: train step 21960: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4431
2024-07-11 17:49:09,575 [INFO    ] __main__: train step 21961: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4431
2024-07-11 17:49:09,780 [INFO    ] __main__: train step 21962: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4430
2024-07-11 17:49:09,985 [INFO    ] __main__: train step 21963: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4430
2024-07-11 17:49:11,432 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:49:11,811 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:49:11,866 [INFO    ] __main__: train step 21964: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4430
2024-07-11 17:49:12,055 [INFO    ] __main__: train step 21965: loss: 0.9137, policy_loss: 0.8220, value_loss: 0.4430
2024-07-11 17:49:12,270 [INFO    ] __main__: train step 21966: loss: 0.9136, policy_loss: 0.8220, value_loss: 0.4430
2024-07-11 17:49:12,494 [INFO    ] __main__: train step 21967: loss: 0.9136, policy_loss: 0.8220, value_loss: 0.4430
2024-07-11 17:49:12,706 [INFO    ] __main__: train step 21968: loss: 0.9136, policy_loss: 0.8220, value_loss: 0.4429
2024-07-11 17:49:12,910 [INFO    ] __main__: train step 21969: loss: 0.9136, policy_loss: 0.8220, value_loss: 0.4429
2024-07-11 17:49:13,117 [INFO    ] __main__: train step 21970: loss: 0.9136, policy_loss: 0.8220, value_loss: 0.4429
2024-07-11 17:49:13,321 [INFO    ] __main__: train step 21971: loss: 0.9136, policy_loss: 0.8220, value_loss: 0.4429
2024-07-11 17:49:13,527 [INFO    ] __main__: train step 21972: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4429
2024-07-11 17:49:13,735 [INFO    ] __main__: train step 21973: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4429
2024-07-11 17:49:13,941 [INFO    ] __main__: train step 21974: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4429
2024-07-11 17:49:14,148 [INFO    ] __main__: train step 21975: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4428
2024-07-11 17:49:14,350 [INFO    ] __main__: train step 21976: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4428
2024-07-11 17:49:14,586 [INFO    ] __main__: train step 21977: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4428
2024-07-11 17:49:14,791 [INFO    ] __main__: train step 21978: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4428
2024-07-11 17:49:15,011 [INFO    ] __main__: train step 21979: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4428
2024-07-11 17:49:15,210 [INFO    ] __main__: train step 21980: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4428
2024-07-11 17:49:16,647 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:49:17,015 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:49:17,078 [INFO    ] __main__: train step 21981: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4427
2024-07-11 17:49:17,262 [INFO    ] __main__: train step 21982: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4427
2024-07-11 17:49:17,461 [INFO    ] __main__: train step 21983: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4427
2024-07-11 17:49:17,671 [INFO    ] __main__: train step 21984: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4427
2024-07-11 17:49:17,901 [INFO    ] __main__: train step 21985: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4427
2024-07-11 17:49:18,114 [INFO    ] __main__: train step 21986: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4427
2024-07-11 17:49:18,315 [INFO    ] __main__: train step 21987: loss: 0.9136, policy_loss: 0.8219, value_loss: 0.4426
2024-07-11 17:49:18,526 [INFO    ] __main__: train step 21988: loss: 0.9135, policy_loss: 0.8219, value_loss: 0.4426
2024-07-11 17:49:18,729 [INFO    ] __main__: train step 21989: loss: 0.9135, policy_loss: 0.8219, value_loss: 0.4426
2024-07-11 17:49:18,924 [INFO    ] __main__: train step 21990: loss: 0.9135, policy_loss: 0.8219, value_loss: 0.4426
2024-07-11 17:49:19,128 [INFO    ] __main__: train step 21991: loss: 0.9135, policy_loss: 0.8219, value_loss: 0.4426
2024-07-11 17:49:19,332 [INFO    ] __main__: train step 21992: loss: 0.9135, policy_loss: 0.8219, value_loss: 0.4426
2024-07-11 17:49:19,526 [INFO    ] __main__: train step 21993: loss: 0.9135, policy_loss: 0.8219, value_loss: 0.4425
2024-07-11 17:49:19,728 [INFO    ] __main__: train step 21994: loss: 0.9135, policy_loss: 0.8219, value_loss: 0.4425
2024-07-11 17:49:19,931 [INFO    ] __main__: train step 21995: loss: 0.9135, policy_loss: 0.8219, value_loss: 0.4425
2024-07-11 17:49:20,133 [INFO    ] __main__: train step 21996: loss: 0.9135, policy_loss: 0.8219, value_loss: 0.4425
2024-07-11 17:49:20,339 [INFO    ] __main__: train step 21997: loss: 0.9135, policy_loss: 0.8218, value_loss: 0.4425
2024-07-11 17:49:21,784 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:49:22,188 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:49:22,252 [INFO    ] __main__: train step 21998: loss: 0.9135, policy_loss: 0.8218, value_loss: 0.4425
2024-07-11 17:49:22,426 [INFO    ] __main__: train step 21999: loss: 0.9135, policy_loss: 0.8218, value_loss: 0.4424
2024-07-11 17:49:22,633 [INFO    ] __main__: train step 22000: loss: 0.9135, policy_loss: 0.8218, value_loss: 0.4424
2024-07-11 17:49:22,752 [INFO    ] __main__: restored step 21000 for evaluation
2024-07-11 17:49:30,773 [INFO    ] __main__: later network ELO difference from earlier network: +62 (+8/-8) ELO from 32000 self-played games
2024-07-11 17:49:30,773 [INFO    ] __main__: game outcomes: W: 18181, D: 314, L: 13505
2024-07-11 17:49:30,774 [INFO    ] __main__: validation_elo_delta: 62, validation_elo: 2848
2024-07-11 17:49:31,267 [INFO    ] __main__: train step 22001: loss: 0.9135, policy_loss: 0.8218, value_loss: 0.4424
2024-07-11 17:49:31,464 [INFO    ] __main__: train step 22002: loss: 0.9135, policy_loss: 0.8218, value_loss: 0.4424
2024-07-11 17:49:31,667 [INFO    ] __main__: train step 22003: loss: 0.9135, policy_loss: 0.8218, value_loss: 0.4424
2024-07-11 17:49:31,871 [INFO    ] __main__: train step 22004: loss: 0.9135, policy_loss: 0.8218, value_loss: 0.4424
2024-07-11 17:49:32,077 [INFO    ] __main__: train step 22005: loss: 0.9135, policy_loss: 0.8218, value_loss: 0.4423
2024-07-11 17:49:32,305 [INFO    ] __main__: train step 22006: loss: 0.9135, policy_loss: 0.8218, value_loss: 0.4423
2024-07-11 17:49:32,509 [INFO    ] __main__: train step 22007: loss: 0.9135, policy_loss: 0.8218, value_loss: 0.4423
2024-07-11 17:49:32,720 [INFO    ] __main__: train step 22008: loss: 0.9135, policy_loss: 0.8218, value_loss: 0.4423
2024-07-11 17:49:32,921 [INFO    ] __main__: train step 22009: loss: 0.9135, policy_loss: 0.8218, value_loss: 0.4423
2024-07-11 17:49:33,146 [INFO    ] __main__: train step 22010: loss: 0.9134, policy_loss: 0.8218, value_loss: 0.4423
2024-07-11 17:49:33,383 [INFO    ] __main__: train step 22011: loss: 0.9134, policy_loss: 0.8218, value_loss: 0.4422
2024-07-11 17:49:33,583 [INFO    ] __main__: train step 22012: loss: 0.9134, policy_loss: 0.8218, value_loss: 0.4422
2024-07-11 17:49:33,782 [INFO    ] __main__: train step 22013: loss: 0.9134, policy_loss: 0.8218, value_loss: 0.4422
2024-07-11 17:49:33,996 [INFO    ] __main__: train step 22014: loss: 0.9134, policy_loss: 0.8218, value_loss: 0.4422
2024-07-11 17:49:35,439 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:49:35,798 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:49:35,853 [INFO    ] __main__: train step 22015: loss: 0.9134, policy_loss: 0.8218, value_loss: 0.4422
2024-07-11 17:49:36,029 [INFO    ] __main__: train step 22016: loss: 0.9134, policy_loss: 0.8218, value_loss: 0.4422
2024-07-11 17:49:36,268 [INFO    ] __main__: train step 22017: loss: 0.9134, policy_loss: 0.8218, value_loss: 0.4421
2024-07-11 17:49:36,489 [INFO    ] __main__: train step 22018: loss: 0.9134, policy_loss: 0.8218, value_loss: 0.4421
2024-07-11 17:49:36,712 [INFO    ] __main__: train step 22019: loss: 0.9134, policy_loss: 0.8218, value_loss: 0.4421
2024-07-11 17:49:36,913 [INFO    ] __main__: train step 22020: loss: 0.9134, policy_loss: 0.8218, value_loss: 0.4421
2024-07-11 17:49:37,124 [INFO    ] __main__: train step 22021: loss: 0.9134, policy_loss: 0.8218, value_loss: 0.4421
2024-07-11 17:49:37,325 [INFO    ] __main__: train step 22022: loss: 0.9134, policy_loss: 0.8217, value_loss: 0.4421
2024-07-11 17:49:37,532 [INFO    ] __main__: train step 22023: loss: 0.9134, policy_loss: 0.8217, value_loss: 0.4420
2024-07-11 17:49:37,745 [INFO    ] __main__: train step 22024: loss: 0.9134, policy_loss: 0.8217, value_loss: 0.4420
2024-07-11 17:49:37,944 [INFO    ] __main__: train step 22025: loss: 0.9134, policy_loss: 0.8217, value_loss: 0.4420
2024-07-11 17:49:38,156 [INFO    ] __main__: train step 22026: loss: 0.9134, policy_loss: 0.8217, value_loss: 0.4420
2024-07-11 17:49:38,398 [INFO    ] __main__: train step 22027: loss: 0.9134, policy_loss: 0.8217, value_loss: 0.4420
2024-07-11 17:49:38,609 [INFO    ] __main__: train step 22028: loss: 0.9134, policy_loss: 0.8217, value_loss: 0.4420
2024-07-11 17:49:38,830 [INFO    ] __main__: train step 22029: loss: 0.9134, policy_loss: 0.8217, value_loss: 0.4419
2024-07-11 17:49:39,075 [INFO    ] __main__: train step 22030: loss: 0.9134, policy_loss: 0.8217, value_loss: 0.4419
2024-07-11 17:49:39,319 [INFO    ] __main__: train step 22031: loss: 0.9134, policy_loss: 0.8217, value_loss: 0.4419
2024-07-11 17:49:40,798 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:49:41,150 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:49:41,205 [INFO    ] __main__: train step 22032: loss: 0.9133, policy_loss: 0.8217, value_loss: 0.4419
2024-07-11 17:49:41,375 [INFO    ] __main__: train step 22033: loss: 0.9133, policy_loss: 0.8217, value_loss: 0.4419
2024-07-11 17:49:41,619 [INFO    ] __main__: train step 22034: loss: 0.9133, policy_loss: 0.8217, value_loss: 0.4419
2024-07-11 17:49:41,824 [INFO    ] __main__: train step 22035: loss: 0.9133, policy_loss: 0.8217, value_loss: 0.4419
2024-07-11 17:49:42,020 [INFO    ] __main__: train step 22036: loss: 0.9133, policy_loss: 0.8217, value_loss: 0.4418
2024-07-11 17:49:42,233 [INFO    ] __main__: train step 22037: loss: 0.9133, policy_loss: 0.8217, value_loss: 0.4418
2024-07-11 17:49:42,449 [INFO    ] __main__: train step 22038: loss: 0.9133, policy_loss: 0.8217, value_loss: 0.4418
2024-07-11 17:49:42,658 [INFO    ] __main__: train step 22039: loss: 0.9133, policy_loss: 0.8217, value_loss: 0.4418
2024-07-11 17:49:42,876 [INFO    ] __main__: train step 22040: loss: 0.9133, policy_loss: 0.8217, value_loss: 0.4418
2024-07-11 17:49:43,095 [INFO    ] __main__: train step 22041: loss: 0.9133, policy_loss: 0.8217, value_loss: 0.4418
2024-07-11 17:49:43,323 [INFO    ] __main__: train step 22042: loss: 0.9133, policy_loss: 0.8217, value_loss: 0.4417
2024-07-11 17:49:43,529 [INFO    ] __main__: train step 22043: loss: 0.9133, policy_loss: 0.8217, value_loss: 0.4417
2024-07-11 17:49:43,730 [INFO    ] __main__: train step 22044: loss: 0.9133, policy_loss: 0.8217, value_loss: 0.4417
2024-07-11 17:49:43,947 [INFO    ] __main__: train step 22045: loss: 0.9133, policy_loss: 0.8217, value_loss: 0.4417
2024-07-11 17:49:44,169 [INFO    ] __main__: train step 22046: loss: 0.9133, policy_loss: 0.8216, value_loss: 0.4417
2024-07-11 17:49:44,378 [INFO    ] __main__: train step 22047: loss: 0.9133, policy_loss: 0.8216, value_loss: 0.4417
2024-07-11 17:49:44,594 [INFO    ] __main__: train step 22048: loss: 0.9133, policy_loss: 0.8216, value_loss: 0.4416
2024-07-11 17:49:46,039 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:49:46,412 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:49:46,470 [INFO    ] __main__: train step 22049: loss: 0.9133, policy_loss: 0.8216, value_loss: 0.4416
2024-07-11 17:49:46,651 [INFO    ] __main__: train step 22050: loss: 0.9133, policy_loss: 0.8216, value_loss: 0.4416
2024-07-11 17:49:46,862 [INFO    ] __main__: train step 22051: loss: 0.9133, policy_loss: 0.8216, value_loss: 0.4416
2024-07-11 17:49:47,075 [INFO    ] __main__: train step 22052: loss: 0.9133, policy_loss: 0.8216, value_loss: 0.4416
2024-07-11 17:49:47,276 [INFO    ] __main__: train step 22053: loss: 0.9133, policy_loss: 0.8216, value_loss: 0.4416
2024-07-11 17:49:47,472 [INFO    ] __main__: train step 22054: loss: 0.9132, policy_loss: 0.8216, value_loss: 0.4415
2024-07-11 17:49:47,676 [INFO    ] __main__: train step 22055: loss: 0.9132, policy_loss: 0.8216, value_loss: 0.4415
2024-07-11 17:49:47,887 [INFO    ] __main__: train step 22056: loss: 0.9132, policy_loss: 0.8216, value_loss: 0.4415
2024-07-11 17:49:48,089 [INFO    ] __main__: train step 22057: loss: 0.9132, policy_loss: 0.8216, value_loss: 0.4415
2024-07-11 17:49:48,296 [INFO    ] __main__: train step 22058: loss: 0.9132, policy_loss: 0.8216, value_loss: 0.4415
2024-07-11 17:49:48,506 [INFO    ] __main__: train step 22059: loss: 0.9132, policy_loss: 0.8216, value_loss: 0.4415
2024-07-11 17:49:48,736 [INFO    ] __main__: train step 22060: loss: 0.9132, policy_loss: 0.8216, value_loss: 0.4414
2024-07-11 17:49:48,932 [INFO    ] __main__: train step 22061: loss: 0.9132, policy_loss: 0.8216, value_loss: 0.4414
2024-07-11 17:49:49,130 [INFO    ] __main__: train step 22062: loss: 0.9132, policy_loss: 0.8216, value_loss: 0.4414
2024-07-11 17:49:49,341 [INFO    ] __main__: train step 22063: loss: 0.9132, policy_loss: 0.8216, value_loss: 0.4414
2024-07-11 17:49:49,536 [INFO    ] __main__: train step 22064: loss: 0.9132, policy_loss: 0.8216, value_loss: 0.4414
2024-07-11 17:49:49,737 [INFO    ] __main__: train step 22065: loss: 0.9132, policy_loss: 0.8216, value_loss: 0.4414
2024-07-11 17:49:51,185 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:49:51,442 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:49:51,500 [INFO    ] __main__: train step 22066: loss: 0.9132, policy_loss: 0.8216, value_loss: 0.4413
2024-07-11 17:49:51,676 [INFO    ] __main__: train step 22067: loss: 0.9132, policy_loss: 0.8216, value_loss: 0.4413
2024-07-11 17:49:51,884 [INFO    ] __main__: train step 22068: loss: 0.9132, policy_loss: 0.8216, value_loss: 0.4413
2024-07-11 17:49:52,089 [INFO    ] __main__: train step 22069: loss: 0.9132, policy_loss: 0.8215, value_loss: 0.4413
2024-07-11 17:49:52,289 [INFO    ] __main__: train step 22070: loss: 0.9132, policy_loss: 0.8215, value_loss: 0.4413
2024-07-11 17:49:52,506 [INFO    ] __main__: train step 22071: loss: 0.9132, policy_loss: 0.8215, value_loss: 0.4413
2024-07-11 17:49:52,708 [INFO    ] __main__: train step 22072: loss: 0.9132, policy_loss: 0.8215, value_loss: 0.4412
2024-07-11 17:49:52,910 [INFO    ] __main__: train step 22073: loss: 0.9132, policy_loss: 0.8215, value_loss: 0.4412
2024-07-11 17:49:53,127 [INFO    ] __main__: train step 22074: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4412
2024-07-11 17:49:53,342 [INFO    ] __main__: train step 22075: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4412
2024-07-11 17:49:53,573 [INFO    ] __main__: train step 22076: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4412
2024-07-11 17:49:56,082 [INFO    ] __main__: train step 22077: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4412
2024-07-11 17:49:56,286 [INFO    ] __main__: train step 22078: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4411
2024-07-11 17:49:56,484 [INFO    ] __main__: train step 22079: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4411
2024-07-11 17:49:56,700 [INFO    ] __main__: train step 22080: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4411
2024-07-11 17:49:56,946 [INFO    ] __main__: train step 22081: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4411
2024-07-11 17:49:57,163 [INFO    ] __main__: train step 22082: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4411
2024-07-11 17:49:58,632 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:49:59,054 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:49:59,114 [INFO    ] __main__: train step 22083: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4411
2024-07-11 17:49:59,300 [INFO    ] __main__: train step 22084: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4411
2024-07-11 17:49:59,502 [INFO    ] __main__: train step 22085: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4410
2024-07-11 17:49:59,712 [INFO    ] __main__: train step 22086: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4410
2024-07-11 17:49:59,912 [INFO    ] __main__: train step 22087: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4410
2024-07-11 17:50:00,132 [INFO    ] __main__: train step 22088: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4410
2024-07-11 17:50:00,348 [INFO    ] __main__: train step 22089: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4410
2024-07-11 17:50:00,589 [INFO    ] __main__: train step 22090: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4410
2024-07-11 17:50:00,797 [INFO    ] __main__: train step 22091: loss: 0.9131, policy_loss: 0.8215, value_loss: 0.4409
2024-07-11 17:50:01,033 [INFO    ] __main__: train step 22092: loss: 0.9131, policy_loss: 0.8214, value_loss: 0.4409
2024-07-11 17:50:01,243 [INFO    ] __main__: train step 22093: loss: 0.9131, policy_loss: 0.8214, value_loss: 0.4409
2024-07-11 17:50:01,440 [INFO    ] __main__: train step 22094: loss: 0.9131, policy_loss: 0.8214, value_loss: 0.4409
2024-07-11 17:50:01,646 [INFO    ] __main__: train step 22095: loss: 0.9131, policy_loss: 0.8214, value_loss: 0.4409
2024-07-11 17:50:01,854 [INFO    ] __main__: train step 22096: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4409
2024-07-11 17:50:02,065 [INFO    ] __main__: train step 22097: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4408
2024-07-11 17:50:02,276 [INFO    ] __main__: train step 22098: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4408
2024-07-11 17:50:02,514 [INFO    ] __main__: train step 22099: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4408
2024-07-11 17:50:03,957 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:50:04,338 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:50:04,393 [INFO    ] __main__: train step 22100: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4408
2024-07-11 17:50:04,568 [INFO    ] __main__: train step 22101: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4408
2024-07-11 17:50:04,771 [INFO    ] __main__: train step 22102: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4408
2024-07-11 17:50:04,973 [INFO    ] __main__: train step 22103: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4407
2024-07-11 17:50:05,179 [INFO    ] __main__: train step 22104: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4407
2024-07-11 17:50:05,382 [INFO    ] __main__: train step 22105: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4407
2024-07-11 17:50:05,584 [INFO    ] __main__: train step 22106: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4407
2024-07-11 17:50:05,809 [INFO    ] __main__: train step 22107: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4407
2024-07-11 17:50:06,044 [INFO    ] __main__: train step 22108: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4407
2024-07-11 17:50:06,238 [INFO    ] __main__: train step 22109: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4406
2024-07-11 17:50:06,469 [INFO    ] __main__: train step 22110: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4406
2024-07-11 17:50:06,687 [INFO    ] __main__: train step 22111: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4406
2024-07-11 17:50:06,897 [INFO    ] __main__: train step 22112: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4406
2024-07-11 17:50:07,098 [INFO    ] __main__: train step 22113: loss: 0.9130, policy_loss: 0.8214, value_loss: 0.4406
2024-07-11 17:50:07,320 [INFO    ] __main__: train step 22114: loss: 0.9130, policy_loss: 0.8213, value_loss: 0.4406
2024-07-11 17:50:07,543 [INFO    ] __main__: train step 22115: loss: 0.9130, policy_loss: 0.8213, value_loss: 0.4406
2024-07-11 17:50:07,744 [INFO    ] __main__: train step 22116: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4405
2024-07-11 17:50:09,185 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:50:09,545 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:50:09,600 [INFO    ] __main__: train step 22117: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4405
2024-07-11 17:50:09,780 [INFO    ] __main__: train step 22118: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4405
2024-07-11 17:50:09,982 [INFO    ] __main__: train step 22119: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4405
2024-07-11 17:50:10,186 [INFO    ] __main__: train step 22120: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4405
2024-07-11 17:50:10,383 [INFO    ] __main__: train step 22121: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4405
2024-07-11 17:50:10,596 [INFO    ] __main__: train step 22122: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4404
2024-07-11 17:50:10,834 [INFO    ] __main__: train step 22123: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4404
2024-07-11 17:50:11,041 [INFO    ] __main__: train step 22124: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4404
2024-07-11 17:50:11,243 [INFO    ] __main__: train step 22125: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4404
2024-07-11 17:50:11,445 [INFO    ] __main__: train step 22126: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4404
2024-07-11 17:50:11,656 [INFO    ] __main__: train step 22127: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4404
2024-07-11 17:50:11,864 [INFO    ] __main__: train step 22128: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4403
2024-07-11 17:50:12,105 [INFO    ] __main__: train step 22129: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4403
2024-07-11 17:50:12,304 [INFO    ] __main__: train step 22130: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4403
2024-07-11 17:50:12,527 [INFO    ] __main__: train step 22131: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4403
2024-07-11 17:50:12,748 [INFO    ] __main__: train step 22132: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4403
2024-07-11 17:50:12,951 [INFO    ] __main__: train step 22133: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4403
2024-07-11 17:50:14,402 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:50:14,772 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:50:14,836 [INFO    ] __main__: train step 22134: loss: 0.9129, policy_loss: 0.8213, value_loss: 0.4402
2024-07-11 17:50:15,021 [INFO    ] __main__: train step 22135: loss: 0.9129, policy_loss: 0.8212, value_loss: 0.4402
2024-07-11 17:50:15,226 [INFO    ] __main__: train step 22136: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4402
2024-07-11 17:50:15,443 [INFO    ] __main__: train step 22137: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4402
2024-07-11 17:50:15,684 [INFO    ] __main__: train step 22138: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4402
2024-07-11 17:50:15,907 [INFO    ] __main__: train step 22139: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4402
2024-07-11 17:50:16,132 [INFO    ] __main__: train step 22140: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4402
2024-07-11 17:50:16,346 [INFO    ] __main__: train step 22141: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4401
2024-07-11 17:50:16,593 [INFO    ] __main__: train step 22142: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4401
2024-07-11 17:50:16,809 [INFO    ] __main__: train step 22143: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4401
2024-07-11 17:50:17,021 [INFO    ] __main__: train step 22144: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4401
2024-07-11 17:50:17,222 [INFO    ] __main__: train step 22145: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4401
2024-07-11 17:50:17,431 [INFO    ] __main__: train step 22146: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4401
2024-07-11 17:50:17,637 [INFO    ] __main__: train step 22147: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4400
2024-07-11 17:50:17,862 [INFO    ] __main__: train step 22148: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4400
2024-07-11 17:50:18,094 [INFO    ] __main__: train step 22149: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4400
2024-07-11 17:50:18,300 [INFO    ] __main__: train step 22150: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4400
2024-07-11 17:50:19,759 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:50:20,158 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:50:20,218 [INFO    ] __main__: train step 22151: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4400
2024-07-11 17:50:20,397 [INFO    ] __main__: train step 22152: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4400
2024-07-11 17:50:20,601 [INFO    ] __main__: train step 22153: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4399
2024-07-11 17:50:20,811 [INFO    ] __main__: train step 22154: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4399
2024-07-11 17:50:21,061 [INFO    ] __main__: train step 22155: loss: 0.9128, policy_loss: 0.8212, value_loss: 0.4399
2024-07-11 17:50:21,284 [INFO    ] __main__: train step 22156: loss: 0.9127, policy_loss: 0.8212, value_loss: 0.4399
2024-07-11 17:50:21,510 [INFO    ] __main__: train step 22157: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4399
2024-07-11 17:50:21,716 [INFO    ] __main__: train step 22158: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4399
2024-07-11 17:50:21,931 [INFO    ] __main__: train step 22159: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4398
2024-07-11 17:50:22,152 [INFO    ] __main__: train step 22160: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4398
2024-07-11 17:50:22,360 [INFO    ] __main__: train step 22161: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4398
2024-07-11 17:50:22,561 [INFO    ] __main__: train step 22162: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4398
2024-07-11 17:50:22,773 [INFO    ] __main__: train step 22163: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4398
2024-07-11 17:50:22,968 [INFO    ] __main__: train step 22164: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4398
2024-07-11 17:50:23,171 [INFO    ] __main__: train step 22165: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4397
2024-07-11 17:50:23,381 [INFO    ] __main__: train step 22166: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4397
2024-07-11 17:50:23,585 [INFO    ] __main__: train step 22167: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4397
2024-07-11 17:50:25,056 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:50:25,491 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:50:25,549 [INFO    ] __main__: train step 22168: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4397
2024-07-11 17:50:25,729 [INFO    ] __main__: train step 22169: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4397
2024-07-11 17:50:25,939 [INFO    ] __main__: train step 22170: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4397
2024-07-11 17:50:26,145 [INFO    ] __main__: train step 22171: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4397
2024-07-11 17:50:26,347 [INFO    ] __main__: train step 22172: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4396
2024-07-11 17:50:26,545 [INFO    ] __main__: train step 22173: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4396
2024-07-11 17:50:26,751 [INFO    ] __main__: train step 22174: loss: 0.9127, policy_loss: 0.8211, value_loss: 0.4396
2024-07-11 17:50:26,963 [INFO    ] __main__: train step 22175: loss: 0.9126, policy_loss: 0.8211, value_loss: 0.4396
2024-07-11 17:50:27,165 [INFO    ] __main__: train step 22176: loss: 0.9126, policy_loss: 0.8211, value_loss: 0.4396
2024-07-11 17:50:27,377 [INFO    ] __main__: train step 22177: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4396
2024-07-11 17:50:27,606 [INFO    ] __main__: train step 22178: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4395
2024-07-11 17:50:27,848 [INFO    ] __main__: train step 22179: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4395
2024-07-11 17:50:28,047 [INFO    ] __main__: train step 22180: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4395
2024-07-11 17:50:28,261 [INFO    ] __main__: train step 22181: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4395
2024-07-11 17:50:28,460 [INFO    ] __main__: train step 22182: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4395
2024-07-11 17:50:28,675 [INFO    ] __main__: train step 22183: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4395
2024-07-11 17:50:28,875 [INFO    ] __main__: train step 22184: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4394
2024-07-11 17:50:30,317 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:50:30,702 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:50:30,758 [INFO    ] __main__: train step 22185: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4394
2024-07-11 17:50:30,935 [INFO    ] __main__: train step 22186: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4394
2024-07-11 17:50:31,142 [INFO    ] __main__: train step 22187: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4394
2024-07-11 17:50:31,354 [INFO    ] __main__: train step 22188: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4394
2024-07-11 17:50:31,596 [INFO    ] __main__: train step 22189: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4394
2024-07-11 17:50:31,795 [INFO    ] __main__: train step 22190: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4393
2024-07-11 17:50:32,003 [INFO    ] __main__: train step 22191: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4393
2024-07-11 17:50:32,210 [INFO    ] __main__: train step 22192: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4393
2024-07-11 17:50:32,412 [INFO    ] __main__: train step 22193: loss: 0.9126, policy_loss: 0.8210, value_loss: 0.4393
2024-07-11 17:50:32,617 [INFO    ] __main__: train step 22194: loss: 0.9125, policy_loss: 0.8210, value_loss: 0.4393
2024-07-11 17:50:32,821 [INFO    ] __main__: train step 22195: loss: 0.9125, policy_loss: 0.8210, value_loss: 0.4393
2024-07-11 17:50:33,047 [INFO    ] __main__: train step 22196: loss: 0.9125, policy_loss: 0.8210, value_loss: 0.4392
2024-07-11 17:50:33,265 [INFO    ] __main__: train step 22197: loss: 0.9125, policy_loss: 0.8210, value_loss: 0.4392
2024-07-11 17:50:33,472 [INFO    ] __main__: train step 22198: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4392
2024-07-11 17:50:33,682 [INFO    ] __main__: train step 22199: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4392
2024-07-11 17:50:33,885 [INFO    ] __main__: train step 22200: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4392
2024-07-11 17:50:34,083 [INFO    ] __main__: train step 22201: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4392
2024-07-11 17:50:35,540 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:50:35,923 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:50:35,979 [INFO    ] __main__: train step 22202: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4392
2024-07-11 17:50:36,174 [INFO    ] __main__: train step 22203: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4391
2024-07-11 17:50:36,413 [INFO    ] __main__: train step 22204: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4391
2024-07-11 17:50:36,659 [INFO    ] __main__: train step 22205: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4391
2024-07-11 17:50:36,867 [INFO    ] __main__: train step 22206: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4391
2024-07-11 17:50:37,068 [INFO    ] __main__: train step 22207: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4391
2024-07-11 17:50:37,272 [INFO    ] __main__: train step 22208: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4391
2024-07-11 17:50:37,483 [INFO    ] __main__: train step 22209: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4390
2024-07-11 17:50:37,686 [INFO    ] __main__: train step 22210: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4390
2024-07-11 17:50:37,899 [INFO    ] __main__: train step 22211: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4390
2024-07-11 17:50:38,122 [INFO    ] __main__: train step 22212: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4390
2024-07-11 17:50:38,321 [INFO    ] __main__: train step 22213: loss: 0.9125, policy_loss: 0.8209, value_loss: 0.4390
2024-07-11 17:50:38,524 [INFO    ] __main__: train step 22214: loss: 0.9124, policy_loss: 0.8209, value_loss: 0.4390
2024-07-11 17:50:41,010 [INFO    ] __main__: train step 22215: loss: 0.9124, policy_loss: 0.8209, value_loss: 0.4389
2024-07-11 17:50:41,220 [INFO    ] __main__: train step 22216: loss: 0.9124, policy_loss: 0.8209, value_loss: 0.4389
2024-07-11 17:50:41,431 [INFO    ] __main__: train step 22217: loss: 0.9124, policy_loss: 0.8209, value_loss: 0.4389
2024-07-11 17:50:41,638 [INFO    ] __main__: train step 22218: loss: 0.9124, policy_loss: 0.8209, value_loss: 0.4389
2024-07-11 17:50:43,100 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:50:43,504 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:50:43,559 [INFO    ] __main__: train step 22219: loss: 0.9124, policy_loss: 0.8208, value_loss: 0.4389
2024-07-11 17:50:43,738 [INFO    ] __main__: train step 22220: loss: 0.9124, policy_loss: 0.8208, value_loss: 0.4389
2024-07-11 17:50:43,947 [INFO    ] __main__: train step 22221: loss: 0.9124, policy_loss: 0.8208, value_loss: 0.4388
2024-07-11 17:50:44,152 [INFO    ] __main__: train step 22222: loss: 0.9124, policy_loss: 0.8208, value_loss: 0.4388
2024-07-11 17:50:44,353 [INFO    ] __main__: train step 22223: loss: 0.9124, policy_loss: 0.8208, value_loss: 0.4388
2024-07-11 17:50:44,556 [INFO    ] __main__: train step 22224: loss: 0.9124, policy_loss: 0.8208, value_loss: 0.4388
2024-07-11 17:50:44,778 [INFO    ] __main__: train step 22225: loss: 0.9124, policy_loss: 0.8208, value_loss: 0.4388
2024-07-11 17:50:44,986 [INFO    ] __main__: train step 22226: loss: 0.9124, policy_loss: 0.8208, value_loss: 0.4388
2024-07-11 17:50:45,203 [INFO    ] __main__: train step 22227: loss: 0.9124, policy_loss: 0.8208, value_loss: 0.4388
2024-07-11 17:50:45,409 [INFO    ] __main__: train step 22228: loss: 0.9124, policy_loss: 0.8208, value_loss: 0.4387
2024-07-11 17:50:45,624 [INFO    ] __main__: train step 22229: loss: 0.9124, policy_loss: 0.8208, value_loss: 0.4387
2024-07-11 17:50:45,859 [INFO    ] __main__: train step 22230: loss: 0.9124, policy_loss: 0.8208, value_loss: 0.4387
2024-07-11 17:50:46,056 [INFO    ] __main__: train step 22231: loss: 0.9124, policy_loss: 0.8208, value_loss: 0.4387
2024-07-11 17:50:46,264 [INFO    ] __main__: train step 22232: loss: 0.9124, policy_loss: 0.8208, value_loss: 0.4387
2024-07-11 17:50:46,475 [INFO    ] __main__: train step 22233: loss: 0.9123, policy_loss: 0.8208, value_loss: 0.4387
2024-07-11 17:50:46,675 [INFO    ] __main__: train step 22234: loss: 0.9123, policy_loss: 0.8208, value_loss: 0.4386
2024-07-11 17:50:46,883 [INFO    ] __main__: train step 22235: loss: 0.9123, policy_loss: 0.8208, value_loss: 0.4386
2024-07-11 17:50:48,337 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:50:48,776 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:50:48,836 [INFO    ] __main__: train step 22236: loss: 0.9123, policy_loss: 0.8208, value_loss: 0.4386
2024-07-11 17:50:49,026 [INFO    ] __main__: train step 22237: loss: 0.9123, policy_loss: 0.8208, value_loss: 0.4386
2024-07-11 17:50:49,222 [INFO    ] __main__: train step 22238: loss: 0.9123, policy_loss: 0.8208, value_loss: 0.4386
2024-07-11 17:50:49,424 [INFO    ] __main__: train step 22239: loss: 0.9123, policy_loss: 0.8208, value_loss: 0.4386
2024-07-11 17:50:49,636 [INFO    ] __main__: train step 22240: loss: 0.9123, policy_loss: 0.8207, value_loss: 0.4385
2024-07-11 17:50:49,838 [INFO    ] __main__: train step 22241: loss: 0.9123, policy_loss: 0.8207, value_loss: 0.4385
2024-07-11 17:50:50,040 [INFO    ] __main__: train step 22242: loss: 0.9123, policy_loss: 0.8207, value_loss: 0.4385
2024-07-11 17:50:50,244 [INFO    ] __main__: train step 22243: loss: 0.9123, policy_loss: 0.8207, value_loss: 0.4385
2024-07-11 17:50:50,461 [INFO    ] __main__: train step 22244: loss: 0.9123, policy_loss: 0.8207, value_loss: 0.4385
2024-07-11 17:50:50,663 [INFO    ] __main__: train step 22245: loss: 0.9123, policy_loss: 0.8207, value_loss: 0.4385
2024-07-11 17:50:50,887 [INFO    ] __main__: train step 22246: loss: 0.9123, policy_loss: 0.8207, value_loss: 0.4384
2024-07-11 17:50:51,135 [INFO    ] __main__: train step 22247: loss: 0.9123, policy_loss: 0.8207, value_loss: 0.4384
2024-07-11 17:50:51,341 [INFO    ] __main__: train step 22248: loss: 0.9123, policy_loss: 0.8207, value_loss: 0.4384
2024-07-11 17:50:51,546 [INFO    ] __main__: train step 22249: loss: 0.9123, policy_loss: 0.8207, value_loss: 0.4384
2024-07-11 17:50:51,759 [INFO    ] __main__: train step 22250: loss: 0.9123, policy_loss: 0.8207, value_loss: 0.4384
2024-07-11 17:50:52,000 [INFO    ] __main__: train step 22251: loss: 0.9123, policy_loss: 0.8207, value_loss: 0.4384
2024-07-11 17:50:52,186 [INFO    ] __main__: train step 22252: loss: 0.9122, policy_loss: 0.8207, value_loss: 0.4384
2024-07-11 17:50:53,626 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:50:54,023 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:50:54,083 [INFO    ] __main__: train step 22253: loss: 0.9122, policy_loss: 0.8207, value_loss: 0.4383
2024-07-11 17:50:54,269 [INFO    ] __main__: train step 22254: loss: 0.9122, policy_loss: 0.8207, value_loss: 0.4383
2024-07-11 17:50:54,483 [INFO    ] __main__: train step 22255: loss: 0.9122, policy_loss: 0.8207, value_loss: 0.4383
2024-07-11 17:50:54,699 [INFO    ] __main__: train step 22256: loss: 0.9122, policy_loss: 0.8207, value_loss: 0.4383
2024-07-11 17:50:54,932 [INFO    ] __main__: train step 22257: loss: 0.9122, policy_loss: 0.8207, value_loss: 0.4383
2024-07-11 17:50:55,144 [INFO    ] __main__: train step 22258: loss: 0.9122, policy_loss: 0.8207, value_loss: 0.4383
2024-07-11 17:50:55,352 [INFO    ] __main__: train step 22259: loss: 0.9122, policy_loss: 0.8207, value_loss: 0.4382
2024-07-11 17:50:55,566 [INFO    ] __main__: train step 22260: loss: 0.9122, policy_loss: 0.8206, value_loss: 0.4382
2024-07-11 17:50:55,780 [INFO    ] __main__: train step 22261: loss: 0.9122, policy_loss: 0.8206, value_loss: 0.4382
2024-07-11 17:50:55,980 [INFO    ] __main__: train step 22262: loss: 0.9122, policy_loss: 0.8206, value_loss: 0.4382
2024-07-11 17:50:56,205 [INFO    ] __main__: train step 22263: loss: 0.9122, policy_loss: 0.8206, value_loss: 0.4382
2024-07-11 17:50:56,447 [INFO    ] __main__: train step 22264: loss: 0.9122, policy_loss: 0.8206, value_loss: 0.4382
2024-07-11 17:50:56,667 [INFO    ] __main__: train step 22265: loss: 0.9122, policy_loss: 0.8206, value_loss: 0.4381
2024-07-11 17:50:56,874 [INFO    ] __main__: train step 22266: loss: 0.9122, policy_loss: 0.8206, value_loss: 0.4381
2024-07-11 17:50:57,090 [INFO    ] __main__: train step 22267: loss: 0.9122, policy_loss: 0.8206, value_loss: 0.4381
2024-07-11 17:50:57,289 [INFO    ] __main__: train step 22268: loss: 0.9122, policy_loss: 0.8206, value_loss: 0.4381
2024-07-11 17:50:57,503 [INFO    ] __main__: train step 22269: loss: 0.9122, policy_loss: 0.8206, value_loss: 0.4381
2024-07-11 17:50:58,947 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:50:59,336 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:50:59,391 [INFO    ] __main__: train step 22270: loss: 0.9122, policy_loss: 0.8206, value_loss: 0.4381
2024-07-11 17:50:59,566 [INFO    ] __main__: train step 22271: loss: 0.9121, policy_loss: 0.8206, value_loss: 0.4381
2024-07-11 17:50:59,770 [INFO    ] __main__: train step 22272: loss: 0.9121, policy_loss: 0.8206, value_loss: 0.4380
2024-07-11 17:50:59,968 [INFO    ] __main__: train step 22273: loss: 0.9121, policy_loss: 0.8206, value_loss: 0.4380
2024-07-11 17:51:00,203 [INFO    ] __main__: train step 22274: loss: 0.9121, policy_loss: 0.8206, value_loss: 0.4380
2024-07-11 17:51:00,409 [INFO    ] __main__: train step 22275: loss: 0.9121, policy_loss: 0.8206, value_loss: 0.4380
2024-07-11 17:51:00,618 [INFO    ] __main__: train step 22276: loss: 0.9121, policy_loss: 0.8206, value_loss: 0.4380
2024-07-11 17:51:00,864 [INFO    ] __main__: train step 22277: loss: 0.9121, policy_loss: 0.8206, value_loss: 0.4380
2024-07-11 17:51:01,057 [INFO    ] __main__: train step 22278: loss: 0.9121, policy_loss: 0.8206, value_loss: 0.4379
2024-07-11 17:51:01,264 [INFO    ] __main__: train step 22279: loss: 0.9121, policy_loss: 0.8206, value_loss: 0.4379
2024-07-11 17:51:01,465 [INFO    ] __main__: train step 22280: loss: 0.9121, policy_loss: 0.8205, value_loss: 0.4379
2024-07-11 17:51:01,671 [INFO    ] __main__: train step 22281: loss: 0.9121, policy_loss: 0.8205, value_loss: 0.4379
2024-07-11 17:51:01,878 [INFO    ] __main__: train step 22282: loss: 0.9121, policy_loss: 0.8205, value_loss: 0.4379
2024-07-11 17:51:02,080 [INFO    ] __main__: train step 22283: loss: 0.9121, policy_loss: 0.8205, value_loss: 0.4379
2024-07-11 17:51:02,277 [INFO    ] __main__: train step 22284: loss: 0.9121, policy_loss: 0.8205, value_loss: 0.4378
2024-07-11 17:51:02,482 [INFO    ] __main__: train step 22285: loss: 0.9121, policy_loss: 0.8205, value_loss: 0.4378
2024-07-11 17:51:02,678 [INFO    ] __main__: train step 22286: loss: 0.9121, policy_loss: 0.8205, value_loss: 0.4378
2024-07-11 17:51:04,143 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:51:04,550 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:51:04,608 [INFO    ] __main__: train step 22287: loss: 0.9121, policy_loss: 0.8205, value_loss: 0.4378
2024-07-11 17:51:04,786 [INFO    ] __main__: train step 22288: loss: 0.9121, policy_loss: 0.8205, value_loss: 0.4378
2024-07-11 17:51:04,989 [INFO    ] __main__: train step 22289: loss: 0.9121, policy_loss: 0.8205, value_loss: 0.4378
2024-07-11 17:51:05,218 [INFO    ] __main__: train step 22290: loss: 0.9120, policy_loss: 0.8205, value_loss: 0.4377
2024-07-11 17:51:05,432 [INFO    ] __main__: train step 22291: loss: 0.9120, policy_loss: 0.8205, value_loss: 0.4377
2024-07-11 17:51:05,628 [INFO    ] __main__: train step 22292: loss: 0.9120, policy_loss: 0.8205, value_loss: 0.4377
2024-07-11 17:51:05,836 [INFO    ] __main__: train step 22293: loss: 0.9120, policy_loss: 0.8205, value_loss: 0.4377
2024-07-11 17:51:06,045 [INFO    ] __main__: train step 22294: loss: 0.9120, policy_loss: 0.8205, value_loss: 0.4377
2024-07-11 17:51:06,249 [INFO    ] __main__: train step 22295: loss: 0.9120, policy_loss: 0.8205, value_loss: 0.4377
2024-07-11 17:51:06,479 [INFO    ] __main__: train step 22296: loss: 0.9120, policy_loss: 0.8205, value_loss: 0.4377
2024-07-11 17:51:06,676 [INFO    ] __main__: train step 22297: loss: 0.9120, policy_loss: 0.8205, value_loss: 0.4376
2024-07-11 17:51:06,906 [INFO    ] __main__: train step 22298: loss: 0.9120, policy_loss: 0.8205, value_loss: 0.4376
2024-07-11 17:51:07,117 [INFO    ] __main__: train step 22299: loss: 0.9120, policy_loss: 0.8205, value_loss: 0.4376
2024-07-11 17:51:07,315 [INFO    ] __main__: train step 22300: loss: 0.9120, policy_loss: 0.8205, value_loss: 0.4376
2024-07-11 17:51:07,524 [INFO    ] __main__: train step 22301: loss: 0.9120, policy_loss: 0.8204, value_loss: 0.4376
2024-07-11 17:51:07,730 [INFO    ] __main__: train step 22302: loss: 0.9120, policy_loss: 0.8204, value_loss: 0.4376
2024-07-11 17:51:07,933 [INFO    ] __main__: train step 22303: loss: 0.9120, policy_loss: 0.8204, value_loss: 0.4375
2024-07-11 17:51:09,371 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:51:09,761 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:51:09,814 [INFO    ] __main__: train step 22304: loss: 0.9120, policy_loss: 0.8204, value_loss: 0.4375
2024-07-11 17:51:09,998 [INFO    ] __main__: train step 22305: loss: 0.9120, policy_loss: 0.8204, value_loss: 0.4375
2024-07-11 17:51:10,201 [INFO    ] __main__: train step 22306: loss: 0.9120, policy_loss: 0.8204, value_loss: 0.4375
2024-07-11 17:51:10,405 [INFO    ] __main__: train step 22307: loss: 0.9120, policy_loss: 0.8204, value_loss: 0.4375
2024-07-11 17:51:10,654 [INFO    ] __main__: train step 22308: loss: 0.9119, policy_loss: 0.8204, value_loss: 0.4375
2024-07-11 17:51:10,880 [INFO    ] __main__: train step 22309: loss: 0.9119, policy_loss: 0.8204, value_loss: 0.4374
2024-07-11 17:51:11,078 [INFO    ] __main__: train step 22310: loss: 0.9119, policy_loss: 0.8204, value_loss: 0.4374
2024-07-11 17:51:11,289 [INFO    ] __main__: train step 22311: loss: 0.9119, policy_loss: 0.8204, value_loss: 0.4374
2024-07-11 17:51:11,500 [INFO    ] __main__: train step 22312: loss: 0.9119, policy_loss: 0.8204, value_loss: 0.4374
2024-07-11 17:51:11,741 [INFO    ] __main__: train step 22313: loss: 0.9119, policy_loss: 0.8204, value_loss: 0.4374
2024-07-11 17:51:11,982 [INFO    ] __main__: train step 22314: loss: 0.9119, policy_loss: 0.8204, value_loss: 0.4374
2024-07-11 17:51:12,184 [INFO    ] __main__: train step 22315: loss: 0.9119, policy_loss: 0.8204, value_loss: 0.4374
2024-07-11 17:51:12,399 [INFO    ] __main__: train step 22316: loss: 0.9119, policy_loss: 0.8204, value_loss: 0.4373
2024-07-11 17:51:12,606 [INFO    ] __main__: train step 22317: loss: 0.9119, policy_loss: 0.8204, value_loss: 0.4373
2024-07-11 17:51:12,805 [INFO    ] __main__: train step 22318: loss: 0.9119, policy_loss: 0.8204, value_loss: 0.4373
2024-07-11 17:51:13,012 [INFO    ] __main__: train step 22319: loss: 0.9119, policy_loss: 0.8204, value_loss: 0.4373
2024-07-11 17:51:13,225 [INFO    ] __main__: train step 22320: loss: 0.9119, policy_loss: 0.8203, value_loss: 0.4373
2024-07-11 17:51:14,660 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:51:15,073 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:51:15,129 [INFO    ] __main__: train step 22321: loss: 0.9119, policy_loss: 0.8203, value_loss: 0.4373
2024-07-11 17:51:15,317 [INFO    ] __main__: train step 22322: loss: 0.9119, policy_loss: 0.8203, value_loss: 0.4372
2024-07-11 17:51:15,518 [INFO    ] __main__: train step 22323: loss: 0.9119, policy_loss: 0.8203, value_loss: 0.4372
2024-07-11 17:51:15,726 [INFO    ] __main__: train step 22324: loss: 0.9119, policy_loss: 0.8203, value_loss: 0.4372
2024-07-11 17:51:15,937 [INFO    ] __main__: train step 22325: loss: 0.9119, policy_loss: 0.8203, value_loss: 0.4372
2024-07-11 17:51:16,142 [INFO    ] __main__: train step 22326: loss: 0.9118, policy_loss: 0.8203, value_loss: 0.4372
2024-07-11 17:51:16,346 [INFO    ] __main__: train step 22327: loss: 0.9118, policy_loss: 0.8203, value_loss: 0.4372
2024-07-11 17:51:16,555 [INFO    ] __main__: train step 22328: loss: 0.9118, policy_loss: 0.8203, value_loss: 0.4371
2024-07-11 17:51:16,754 [INFO    ] __main__: train step 22329: loss: 0.9118, policy_loss: 0.8203, value_loss: 0.4371
2024-07-11 17:51:16,965 [INFO    ] __main__: train step 22330: loss: 0.9118, policy_loss: 0.8203, value_loss: 0.4371
2024-07-11 17:51:17,157 [INFO    ] __main__: train step 22331: loss: 0.9118, policy_loss: 0.8203, value_loss: 0.4371
2024-07-11 17:51:17,361 [INFO    ] __main__: train step 22332: loss: 0.9118, policy_loss: 0.8203, value_loss: 0.4371
2024-07-11 17:51:17,571 [INFO    ] __main__: train step 22333: loss: 0.9118, policy_loss: 0.8203, value_loss: 0.4371
2024-07-11 17:51:17,792 [INFO    ] __main__: train step 22334: loss: 0.9118, policy_loss: 0.8203, value_loss: 0.4371
2024-07-11 17:51:17,997 [INFO    ] __main__: train step 22335: loss: 0.9118, policy_loss: 0.8203, value_loss: 0.4370
2024-07-11 17:51:18,239 [INFO    ] __main__: train step 22336: loss: 0.9118, policy_loss: 0.8203, value_loss: 0.4370
2024-07-11 17:51:18,476 [INFO    ] __main__: train step 22337: loss: 0.9118, policy_loss: 0.8203, value_loss: 0.4370
2024-07-11 17:51:19,921 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:51:20,309 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:51:20,365 [INFO    ] __main__: train step 22338: loss: 0.9118, policy_loss: 0.8202, value_loss: 0.4370
2024-07-11 17:51:20,543 [INFO    ] __main__: train step 22339: loss: 0.9118, policy_loss: 0.8202, value_loss: 0.4370
2024-07-11 17:51:20,740 [INFO    ] __main__: train step 22340: loss: 0.9118, policy_loss: 0.8202, value_loss: 0.4370
2024-07-11 17:51:20,940 [INFO    ] __main__: train step 22341: loss: 0.9118, policy_loss: 0.8202, value_loss: 0.4369
2024-07-11 17:51:21,155 [INFO    ] __main__: train step 22342: loss: 0.9118, policy_loss: 0.8202, value_loss: 0.4369
2024-07-11 17:51:21,361 [INFO    ] __main__: train step 22343: loss: 0.9117, policy_loss: 0.8202, value_loss: 0.4369
2024-07-11 17:51:21,563 [INFO    ] __main__: train step 22344: loss: 0.9117, policy_loss: 0.8202, value_loss: 0.4369
2024-07-11 17:51:21,772 [INFO    ] __main__: train step 22345: loss: 0.9117, policy_loss: 0.8202, value_loss: 0.4369
2024-07-11 17:51:21,982 [INFO    ] __main__: train step 22346: loss: 0.9117, policy_loss: 0.8202, value_loss: 0.4369
2024-07-11 17:51:22,186 [INFO    ] __main__: train step 22347: loss: 0.9117, policy_loss: 0.8202, value_loss: 0.4368
2024-07-11 17:51:22,383 [INFO    ] __main__: train step 22348: loss: 0.9117, policy_loss: 0.8202, value_loss: 0.4368
2024-07-11 17:51:22,592 [INFO    ] __main__: train step 22349: loss: 0.9117, policy_loss: 0.8202, value_loss: 0.4368
2024-07-11 17:51:22,801 [INFO    ] __main__: train step 22350: loss: 0.9117, policy_loss: 0.8202, value_loss: 0.4368
2024-07-11 17:51:23,016 [INFO    ] __main__: train step 22351: loss: 0.9117, policy_loss: 0.8202, value_loss: 0.4368
2024-07-11 17:51:25,505 [INFO    ] __main__: train step 22352: loss: 0.9117, policy_loss: 0.8202, value_loss: 0.4368
2024-07-11 17:51:25,733 [INFO    ] __main__: train step 22353: loss: 0.9117, policy_loss: 0.8202, value_loss: 0.4368
2024-07-11 17:51:25,965 [INFO    ] __main__: train step 22354: loss: 0.9117, policy_loss: 0.8202, value_loss: 0.4367
2024-07-11 17:51:27,413 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:51:27,816 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:51:27,873 [INFO    ] __main__: train step 22355: loss: 0.9117, policy_loss: 0.8202, value_loss: 0.4367
2024-07-11 17:51:28,062 [INFO    ] __main__: train step 22356: loss: 0.9117, policy_loss: 0.8202, value_loss: 0.4367
2024-07-11 17:51:28,260 [INFO    ] __main__: train step 22357: loss: 0.9117, policy_loss: 0.8201, value_loss: 0.4367
2024-07-11 17:51:28,468 [INFO    ] __main__: train step 22358: loss: 0.9117, policy_loss: 0.8201, value_loss: 0.4367
2024-07-11 17:51:28,668 [INFO    ] __main__: train step 22359: loss: 0.9117, policy_loss: 0.8201, value_loss: 0.4367
2024-07-11 17:51:28,872 [INFO    ] __main__: train step 22360: loss: 0.9117, policy_loss: 0.8201, value_loss: 0.4366
2024-07-11 17:51:29,090 [INFO    ] __main__: train step 22361: loss: 0.9117, policy_loss: 0.8201, value_loss: 0.4366
2024-07-11 17:51:29,316 [INFO    ] __main__: train step 22362: loss: 0.9116, policy_loss: 0.8201, value_loss: 0.4366
2024-07-11 17:51:29,520 [INFO    ] __main__: train step 22363: loss: 0.9116, policy_loss: 0.8201, value_loss: 0.4366
2024-07-11 17:51:29,723 [INFO    ] __main__: train step 22364: loss: 0.9116, policy_loss: 0.8201, value_loss: 0.4366
2024-07-11 17:51:29,942 [INFO    ] __main__: train step 22365: loss: 0.9116, policy_loss: 0.8201, value_loss: 0.4366
2024-07-11 17:51:30,162 [INFO    ] __main__: train step 22366: loss: 0.9116, policy_loss: 0.8201, value_loss: 0.4365
2024-07-11 17:51:30,365 [INFO    ] __main__: train step 22367: loss: 0.9116, policy_loss: 0.8201, value_loss: 0.4365
2024-07-11 17:51:30,597 [INFO    ] __main__: train step 22368: loss: 0.9116, policy_loss: 0.8201, value_loss: 0.4365
2024-07-11 17:51:30,809 [INFO    ] __main__: train step 22369: loss: 0.9116, policy_loss: 0.8201, value_loss: 0.4365
2024-07-11 17:51:31,039 [INFO    ] __main__: train step 22370: loss: 0.9116, policy_loss: 0.8201, value_loss: 0.4365
2024-07-11 17:51:31,240 [INFO    ] __main__: train step 22371: loss: 0.9116, policy_loss: 0.8201, value_loss: 0.4365
2024-07-11 17:51:32,670 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:51:33,038 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:51:33,093 [INFO    ] __main__: train step 22372: loss: 0.9116, policy_loss: 0.8201, value_loss: 0.4365
2024-07-11 17:51:33,283 [INFO    ] __main__: train step 22373: loss: 0.9116, policy_loss: 0.8201, value_loss: 0.4364
2024-07-11 17:51:33,511 [INFO    ] __main__: train step 22374: loss: 0.9116, policy_loss: 0.8201, value_loss: 0.4364
2024-07-11 17:51:33,746 [INFO    ] __main__: train step 22375: loss: 0.9116, policy_loss: 0.8201, value_loss: 0.4364
2024-07-11 17:51:33,939 [INFO    ] __main__: train step 22376: loss: 0.9116, policy_loss: 0.8200, value_loss: 0.4364
2024-07-11 17:51:34,147 [INFO    ] __main__: train step 22377: loss: 0.9116, policy_loss: 0.8200, value_loss: 0.4364
2024-07-11 17:51:34,355 [INFO    ] __main__: train step 22378: loss: 0.9116, policy_loss: 0.8200, value_loss: 0.4364
2024-07-11 17:51:34,564 [INFO    ] __main__: train step 22379: loss: 0.9116, policy_loss: 0.8200, value_loss: 0.4363
2024-07-11 17:51:34,767 [INFO    ] __main__: train step 22380: loss: 0.9115, policy_loss: 0.8200, value_loss: 0.4363
2024-07-11 17:51:34,967 [INFO    ] __main__: train step 22381: loss: 0.9115, policy_loss: 0.8200, value_loss: 0.4363
2024-07-11 17:51:35,176 [INFO    ] __main__: train step 22382: loss: 0.9115, policy_loss: 0.8200, value_loss: 0.4363
2024-07-11 17:51:35,391 [INFO    ] __main__: train step 22383: loss: 0.9115, policy_loss: 0.8200, value_loss: 0.4363
2024-07-11 17:51:35,610 [INFO    ] __main__: train step 22384: loss: 0.9115, policy_loss: 0.8200, value_loss: 0.4363
2024-07-11 17:51:35,825 [INFO    ] __main__: train step 22385: loss: 0.9115, policy_loss: 0.8200, value_loss: 0.4363
2024-07-11 17:51:36,070 [INFO    ] __main__: train step 22386: loss: 0.9115, policy_loss: 0.8200, value_loss: 0.4362
2024-07-11 17:51:36,303 [INFO    ] __main__: train step 22387: loss: 0.9115, policy_loss: 0.8200, value_loss: 0.4362
2024-07-11 17:51:36,535 [INFO    ] __main__: train step 22388: loss: 0.9115, policy_loss: 0.8200, value_loss: 0.4362
2024-07-11 17:51:37,973 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:51:38,362 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:51:38,421 [INFO    ] __main__: train step 22389: loss: 0.9115, policy_loss: 0.8200, value_loss: 0.4362
2024-07-11 17:51:38,607 [INFO    ] __main__: train step 22390: loss: 0.9115, policy_loss: 0.8200, value_loss: 0.4362
2024-07-11 17:51:38,823 [INFO    ] __main__: train step 22391: loss: 0.9115, policy_loss: 0.8200, value_loss: 0.4362
2024-07-11 17:51:39,026 [INFO    ] __main__: train step 22392: loss: 0.9115, policy_loss: 0.8200, value_loss: 0.4361
2024-07-11 17:51:39,238 [INFO    ] __main__: train step 22393: loss: 0.9115, policy_loss: 0.8200, value_loss: 0.4361
2024-07-11 17:51:39,442 [INFO    ] __main__: train step 22394: loss: 0.9115, policy_loss: 0.8199, value_loss: 0.4361
2024-07-11 17:51:39,652 [INFO    ] __main__: train step 22395: loss: 0.9115, policy_loss: 0.8199, value_loss: 0.4361
2024-07-11 17:51:39,850 [INFO    ] __main__: train step 22396: loss: 0.9115, policy_loss: 0.8199, value_loss: 0.4361
2024-07-11 17:51:40,062 [INFO    ] __main__: train step 22397: loss: 0.9115, policy_loss: 0.8199, value_loss: 0.4361
2024-07-11 17:51:40,272 [INFO    ] __main__: train step 22398: loss: 0.9114, policy_loss: 0.8199, value_loss: 0.4361
2024-07-11 17:51:40,467 [INFO    ] __main__: train step 22399: loss: 0.9114, policy_loss: 0.8199, value_loss: 0.4360
2024-07-11 17:51:40,676 [INFO    ] __main__: train step 22400: loss: 0.9114, policy_loss: 0.8199, value_loss: 0.4360
2024-07-11 17:51:40,878 [INFO    ] __main__: train step 22401: loss: 0.9114, policy_loss: 0.8199, value_loss: 0.4360
2024-07-11 17:51:41,086 [INFO    ] __main__: train step 22402: loss: 0.9114, policy_loss: 0.8199, value_loss: 0.4360
2024-07-11 17:51:41,286 [INFO    ] __main__: train step 22403: loss: 0.9114, policy_loss: 0.8199, value_loss: 0.4360
2024-07-11 17:51:41,488 [INFO    ] __main__: train step 22404: loss: 0.9114, policy_loss: 0.8199, value_loss: 0.4360
2024-07-11 17:51:41,700 [INFO    ] __main__: train step 22405: loss: 0.9114, policy_loss: 0.8199, value_loss: 0.4359
2024-07-11 17:51:43,167 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:51:43,550 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:51:43,605 [INFO    ] __main__: train step 22406: loss: 0.9114, policy_loss: 0.8199, value_loss: 0.4359
2024-07-11 17:51:43,791 [INFO    ] __main__: train step 22407: loss: 0.9114, policy_loss: 0.8199, value_loss: 0.4359
2024-07-11 17:51:44,002 [INFO    ] __main__: train step 22408: loss: 0.9114, policy_loss: 0.8199, value_loss: 0.4359
2024-07-11 17:51:44,215 [INFO    ] __main__: train step 22409: loss: 0.9114, policy_loss: 0.8199, value_loss: 0.4359
2024-07-11 17:51:44,447 [INFO    ] __main__: train step 22410: loss: 0.9114, policy_loss: 0.8199, value_loss: 0.4359
2024-07-11 17:51:44,684 [INFO    ] __main__: train step 22411: loss: 0.9114, policy_loss: 0.8199, value_loss: 0.4359
2024-07-11 17:51:44,911 [INFO    ] __main__: train step 22412: loss: 0.9114, policy_loss: 0.8198, value_loss: 0.4358
2024-07-11 17:51:45,165 [INFO    ] __main__: train step 22413: loss: 0.9114, policy_loss: 0.8198, value_loss: 0.4358
2024-07-11 17:51:45,401 [INFO    ] __main__: train step 22414: loss: 0.9114, policy_loss: 0.8198, value_loss: 0.4358
2024-07-11 17:51:45,608 [INFO    ] __main__: train step 22415: loss: 0.9113, policy_loss: 0.8198, value_loss: 0.4358
2024-07-11 17:51:45,824 [INFO    ] __main__: train step 22416: loss: 0.9113, policy_loss: 0.8198, value_loss: 0.4358
2024-07-11 17:51:46,031 [INFO    ] __main__: train step 22417: loss: 0.9113, policy_loss: 0.8198, value_loss: 0.4358
2024-07-11 17:51:46,243 [INFO    ] __main__: train step 22418: loss: 0.9113, policy_loss: 0.8198, value_loss: 0.4357
2024-07-11 17:51:46,450 [INFO    ] __main__: train step 22419: loss: 0.9113, policy_loss: 0.8198, value_loss: 0.4357
2024-07-11 17:51:46,660 [INFO    ] __main__: train step 22420: loss: 0.9113, policy_loss: 0.8198, value_loss: 0.4357
2024-07-11 17:51:46,869 [INFO    ] __main__: train step 22421: loss: 0.9113, policy_loss: 0.8198, value_loss: 0.4357
2024-07-11 17:51:47,078 [INFO    ] __main__: train step 22422: loss: 0.9113, policy_loss: 0.8198, value_loss: 0.4357
2024-07-11 17:51:48,532 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:51:48,964 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:51:49,021 [INFO    ] __main__: train step 22423: loss: 0.9113, policy_loss: 0.8198, value_loss: 0.4357
2024-07-11 17:51:49,201 [INFO    ] __main__: train step 22424: loss: 0.9113, policy_loss: 0.8198, value_loss: 0.4356
2024-07-11 17:51:49,413 [INFO    ] __main__: train step 22425: loss: 0.9113, policy_loss: 0.8198, value_loss: 0.4356
2024-07-11 17:51:49,625 [INFO    ] __main__: train step 22426: loss: 0.9113, policy_loss: 0.8198, value_loss: 0.4356
2024-07-11 17:51:49,876 [INFO    ] __main__: train step 22427: loss: 0.9113, policy_loss: 0.8198, value_loss: 0.4356
2024-07-11 17:51:50,103 [INFO    ] __main__: train step 22428: loss: 0.9113, policy_loss: 0.8198, value_loss: 0.4356
2024-07-11 17:51:50,319 [INFO    ] __main__: train step 22429: loss: 0.9113, policy_loss: 0.8197, value_loss: 0.4356
2024-07-11 17:51:50,528 [INFO    ] __main__: train step 22430: loss: 0.9113, policy_loss: 0.8197, value_loss: 0.4356
2024-07-11 17:51:50,724 [INFO    ] __main__: train step 22431: loss: 0.9113, policy_loss: 0.8197, value_loss: 0.4355
2024-07-11 17:51:50,937 [INFO    ] __main__: train step 22432: loss: 0.9112, policy_loss: 0.8197, value_loss: 0.4355
2024-07-11 17:51:51,154 [INFO    ] __main__: train step 22433: loss: 0.9112, policy_loss: 0.8197, value_loss: 0.4355
2024-07-11 17:51:51,393 [INFO    ] __main__: train step 22434: loss: 0.9112, policy_loss: 0.8197, value_loss: 0.4355
2024-07-11 17:51:51,634 [INFO    ] __main__: train step 22435: loss: 0.9112, policy_loss: 0.8197, value_loss: 0.4355
2024-07-11 17:51:51,857 [INFO    ] __main__: train step 22436: loss: 0.9112, policy_loss: 0.8197, value_loss: 0.4355
2024-07-11 17:51:52,063 [INFO    ] __main__: train step 22437: loss: 0.9112, policy_loss: 0.8197, value_loss: 0.4354
2024-07-11 17:51:52,271 [INFO    ] __main__: train step 22438: loss: 0.9112, policy_loss: 0.8197, value_loss: 0.4354
2024-07-11 17:51:52,475 [INFO    ] __main__: train step 22439: loss: 0.9112, policy_loss: 0.8197, value_loss: 0.4354
2024-07-11 17:51:53,935 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:51:54,367 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:51:54,427 [INFO    ] __main__: train step 22440: loss: 0.9112, policy_loss: 0.8197, value_loss: 0.4354
2024-07-11 17:51:54,604 [INFO    ] __main__: train step 22441: loss: 0.9112, policy_loss: 0.8197, value_loss: 0.4354
2024-07-11 17:51:54,829 [INFO    ] __main__: train step 22442: loss: 0.9112, policy_loss: 0.8197, value_loss: 0.4354
2024-07-11 17:51:55,068 [INFO    ] __main__: train step 22443: loss: 0.9112, policy_loss: 0.8197, value_loss: 0.4354
2024-07-11 17:51:55,273 [INFO    ] __main__: train step 22444: loss: 0.9112, policy_loss: 0.8197, value_loss: 0.4353
2024-07-11 17:51:55,487 [INFO    ] __main__: train step 22445: loss: 0.9112, policy_loss: 0.8197, value_loss: 0.4353
2024-07-11 17:51:55,719 [INFO    ] __main__: train step 22446: loss: 0.9112, policy_loss: 0.8197, value_loss: 0.4353
2024-07-11 17:51:55,923 [INFO    ] __main__: train step 22447: loss: 0.9112, policy_loss: 0.8196, value_loss: 0.4353
2024-07-11 17:51:56,137 [INFO    ] __main__: train step 22448: loss: 0.9112, policy_loss: 0.8196, value_loss: 0.4353
2024-07-11 17:51:56,344 [INFO    ] __main__: train step 22449: loss: 0.9111, policy_loss: 0.8196, value_loss: 0.4353
2024-07-11 17:51:56,584 [INFO    ] __main__: train step 22450: loss: 0.9111, policy_loss: 0.8196, value_loss: 0.4352
2024-07-11 17:51:56,793 [INFO    ] __main__: train step 22451: loss: 0.9111, policy_loss: 0.8196, value_loss: 0.4352
2024-07-11 17:51:57,035 [INFO    ] __main__: train step 22452: loss: 0.9111, policy_loss: 0.8196, value_loss: 0.4352
2024-07-11 17:51:57,286 [INFO    ] __main__: train step 22453: loss: 0.9111, policy_loss: 0.8196, value_loss: 0.4352
2024-07-11 17:51:57,474 [INFO    ] __main__: train step 22454: loss: 0.9111, policy_loss: 0.8196, value_loss: 0.4352
2024-07-11 17:51:57,685 [INFO    ] __main__: train step 22455: loss: 0.9111, policy_loss: 0.8196, value_loss: 0.4352
2024-07-11 17:51:57,892 [INFO    ] __main__: train step 22456: loss: 0.9111, policy_loss: 0.8196, value_loss: 0.4352
2024-07-11 17:51:59,335 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:51:59,709 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:51:59,772 [INFO    ] __main__: train step 22457: loss: 0.9111, policy_loss: 0.8196, value_loss: 0.4351
2024-07-11 17:51:59,958 [INFO    ] __main__: train step 22458: loss: 0.9111, policy_loss: 0.8196, value_loss: 0.4351
2024-07-11 17:52:00,173 [INFO    ] __main__: train step 22459: loss: 0.9111, policy_loss: 0.8196, value_loss: 0.4351
2024-07-11 17:52:00,405 [INFO    ] __main__: train step 22460: loss: 0.9111, policy_loss: 0.8196, value_loss: 0.4351
2024-07-11 17:52:00,628 [INFO    ] __main__: train step 22461: loss: 0.9111, policy_loss: 0.8196, value_loss: 0.4351
2024-07-11 17:52:00,831 [INFO    ] __main__: train step 22462: loss: 0.9111, policy_loss: 0.8196, value_loss: 0.4351
2024-07-11 17:52:01,033 [INFO    ] __main__: train step 22463: loss: 0.9111, policy_loss: 0.8195, value_loss: 0.4350
2024-07-11 17:52:01,243 [INFO    ] __main__: train step 22464: loss: 0.9111, policy_loss: 0.8195, value_loss: 0.4350
2024-07-11 17:52:01,445 [INFO    ] __main__: train step 22465: loss: 0.9110, policy_loss: 0.8195, value_loss: 0.4350
2024-07-11 17:52:01,654 [INFO    ] __main__: train step 22466: loss: 0.9110, policy_loss: 0.8195, value_loss: 0.4350
2024-07-11 17:52:01,854 [INFO    ] __main__: train step 22467: loss: 0.9110, policy_loss: 0.8195, value_loss: 0.4350
2024-07-11 17:52:02,066 [INFO    ] __main__: train step 22468: loss: 0.9110, policy_loss: 0.8195, value_loss: 0.4350
2024-07-11 17:52:02,269 [INFO    ] __main__: train step 22469: loss: 0.9110, policy_loss: 0.8195, value_loss: 0.4350
2024-07-11 17:52:02,476 [INFO    ] __main__: train step 22470: loss: 0.9110, policy_loss: 0.8195, value_loss: 0.4349
2024-07-11 17:52:02,682 [INFO    ] __main__: train step 22471: loss: 0.9110, policy_loss: 0.8195, value_loss: 0.4349
2024-07-11 17:52:02,893 [INFO    ] __main__: train step 22472: loss: 0.9110, policy_loss: 0.8195, value_loss: 0.4349
2024-07-11 17:52:03,105 [INFO    ] __main__: train step 22473: loss: 0.9110, policy_loss: 0.8195, value_loss: 0.4349
2024-07-11 17:52:04,543 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:52:04,915 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:52:04,975 [INFO    ] __main__: train step 22474: loss: 0.9110, policy_loss: 0.8195, value_loss: 0.4349
2024-07-11 17:52:05,154 [INFO    ] __main__: train step 22475: loss: 0.9110, policy_loss: 0.8195, value_loss: 0.4349
2024-07-11 17:52:05,386 [INFO    ] __main__: train step 22476: loss: 0.9110, policy_loss: 0.8195, value_loss: 0.4348
2024-07-11 17:52:05,585 [INFO    ] __main__: train step 22477: loss: 0.9110, policy_loss: 0.8195, value_loss: 0.4348
2024-07-11 17:52:05,797 [INFO    ] __main__: train step 22478: loss: 0.9110, policy_loss: 0.8195, value_loss: 0.4348
2024-07-11 17:52:05,997 [INFO    ] __main__: train step 22479: loss: 0.9110, policy_loss: 0.8195, value_loss: 0.4348
2024-07-11 17:52:06,212 [INFO    ] __main__: train step 22480: loss: 0.9110, policy_loss: 0.8194, value_loss: 0.4348
2024-07-11 17:52:06,427 [INFO    ] __main__: train step 22481: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4348
2024-07-11 17:52:06,645 [INFO    ] __main__: train step 22482: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4347
2024-07-11 17:52:06,896 [INFO    ] __main__: train step 22483: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4347
2024-07-11 17:52:07,096 [INFO    ] __main__: train step 22484: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4347
2024-07-11 17:52:07,309 [INFO    ] __main__: train step 22485: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4347
2024-07-11 17:52:07,518 [INFO    ] __main__: train step 22486: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4347
2024-07-11 17:52:07,721 [INFO    ] __main__: train step 22487: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4347
2024-07-11 17:52:07,934 [INFO    ] __main__: train step 22488: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4347
2024-07-11 17:52:08,138 [INFO    ] __main__: train step 22489: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4346
2024-07-11 17:52:08,343 [INFO    ] __main__: train step 22490: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4346
2024-07-11 17:52:09,774 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:52:10,152 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:52:10,206 [INFO    ] __main__: train step 22491: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4346
2024-07-11 17:52:12,594 [INFO    ] __main__: train step 22492: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4346
2024-07-11 17:52:12,807 [INFO    ] __main__: train step 22493: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4346
2024-07-11 17:52:13,005 [INFO    ] __main__: train step 22494: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4346
2024-07-11 17:52:13,207 [INFO    ] __main__: train step 22495: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4345
2024-07-11 17:52:13,413 [INFO    ] __main__: train step 22496: loss: 0.9109, policy_loss: 0.8194, value_loss: 0.4345
2024-07-11 17:52:13,619 [INFO    ] __main__: train step 22497: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4345
2024-07-11 17:52:13,823 [INFO    ] __main__: train step 22498: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4345
2024-07-11 17:52:14,033 [INFO    ] __main__: train step 22499: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4345
2024-07-11 17:52:14,255 [INFO    ] __main__: train step 22500: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4345
2024-07-11 17:52:14,457 [INFO    ] __main__: train step 22501: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4345
2024-07-11 17:52:14,660 [INFO    ] __main__: train step 22502: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4344
2024-07-11 17:52:14,885 [INFO    ] __main__: train step 22503: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4344
2024-07-11 17:52:15,114 [INFO    ] __main__: train step 22504: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4344
2024-07-11 17:52:15,354 [INFO    ] __main__: train step 22505: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4344
2024-07-11 17:52:15,598 [INFO    ] __main__: train step 22506: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4344
2024-07-11 17:52:15,832 [INFO    ] __main__: train step 22507: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4344
2024-07-11 17:52:17,295 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:52:17,702 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:52:17,763 [INFO    ] __main__: train step 22508: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4343
2024-07-11 17:52:17,942 [INFO    ] __main__: train step 22509: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4343
2024-07-11 17:52:18,141 [INFO    ] __main__: train step 22510: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4343
2024-07-11 17:52:18,356 [INFO    ] __main__: train step 22511: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4343
2024-07-11 17:52:18,549 [INFO    ] __main__: train step 22512: loss: 0.9108, policy_loss: 0.8193, value_loss: 0.4343
2024-07-11 17:52:18,753 [INFO    ] __main__: train step 22513: loss: 0.9107, policy_loss: 0.8192, value_loss: 0.4343
2024-07-11 17:52:18,959 [INFO    ] __main__: train step 22514: loss: 0.9107, policy_loss: 0.8192, value_loss: 0.4343
2024-07-11 17:52:19,168 [INFO    ] __main__: train step 22515: loss: 0.9107, policy_loss: 0.8192, value_loss: 0.4342
2024-07-11 17:52:19,370 [INFO    ] __main__: train step 22516: loss: 0.9107, policy_loss: 0.8192, value_loss: 0.4342
2024-07-11 17:52:19,583 [INFO    ] __main__: train step 22517: loss: 0.9107, policy_loss: 0.8192, value_loss: 0.4342
2024-07-11 17:52:19,784 [INFO    ] __main__: train step 22518: loss: 0.9107, policy_loss: 0.8192, value_loss: 0.4342
2024-07-11 17:52:19,999 [INFO    ] __main__: train step 22519: loss: 0.9107, policy_loss: 0.8192, value_loss: 0.4342
2024-07-11 17:52:20,207 [INFO    ] __main__: train step 22520: loss: 0.9107, policy_loss: 0.8192, value_loss: 0.4342
2024-07-11 17:52:20,403 [INFO    ] __main__: train step 22521: loss: 0.9107, policy_loss: 0.8192, value_loss: 0.4342
2024-07-11 17:52:20,616 [INFO    ] __main__: train step 22522: loss: 0.9107, policy_loss: 0.8192, value_loss: 0.4341
2024-07-11 17:52:20,828 [INFO    ] __main__: train step 22523: loss: 0.9107, policy_loss: 0.8192, value_loss: 0.4341
2024-07-11 17:52:21,056 [INFO    ] __main__: train step 22524: loss: 0.9107, policy_loss: 0.8192, value_loss: 0.4341
2024-07-11 17:52:22,514 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:52:22,914 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:52:22,982 [INFO    ] __main__: train step 22525: loss: 0.9107, policy_loss: 0.8192, value_loss: 0.4341
2024-07-11 17:52:23,159 [INFO    ] __main__: train step 22526: loss: 0.9107, policy_loss: 0.8192, value_loss: 0.4341
2024-07-11 17:52:23,360 [INFO    ] __main__: train step 22527: loss: 0.9107, policy_loss: 0.8192, value_loss: 0.4341
2024-07-11 17:52:23,573 [INFO    ] __main__: train step 22528: loss: 0.9106, policy_loss: 0.8192, value_loss: 0.4340
2024-07-11 17:52:23,780 [INFO    ] __main__: train step 22529: loss: 0.9106, policy_loss: 0.8191, value_loss: 0.4340
2024-07-11 17:52:23,980 [INFO    ] __main__: train step 22530: loss: 0.9106, policy_loss: 0.8191, value_loss: 0.4340
2024-07-11 17:52:24,200 [INFO    ] __main__: train step 22531: loss: 0.9106, policy_loss: 0.8191, value_loss: 0.4340
2024-07-11 17:52:24,407 [INFO    ] __main__: train step 22532: loss: 0.9106, policy_loss: 0.8191, value_loss: 0.4340
2024-07-11 17:52:24,625 [INFO    ] __main__: train step 22533: loss: 0.9106, policy_loss: 0.8191, value_loss: 0.4340
2024-07-11 17:52:24,863 [INFO    ] __main__: train step 22534: loss: 0.9106, policy_loss: 0.8191, value_loss: 0.4339
2024-07-11 17:52:25,106 [INFO    ] __main__: train step 22535: loss: 0.9106, policy_loss: 0.8191, value_loss: 0.4339
2024-07-11 17:52:25,312 [INFO    ] __main__: train step 22536: loss: 0.9106, policy_loss: 0.8191, value_loss: 0.4339
2024-07-11 17:52:25,512 [INFO    ] __main__: train step 22537: loss: 0.9106, policy_loss: 0.8191, value_loss: 0.4339
2024-07-11 17:52:25,714 [INFO    ] __main__: train step 22538: loss: 0.9106, policy_loss: 0.8191, value_loss: 0.4339
2024-07-11 17:52:25,914 [INFO    ] __main__: train step 22539: loss: 0.9106, policy_loss: 0.8191, value_loss: 0.4339
2024-07-11 17:52:26,119 [INFO    ] __main__: train step 22540: loss: 0.9106, policy_loss: 0.8191, value_loss: 0.4339
2024-07-11 17:52:26,317 [INFO    ] __main__: train step 22541: loss: 0.9106, policy_loss: 0.8191, value_loss: 0.4338
2024-07-11 17:52:27,760 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:52:28,134 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:52:28,192 [INFO    ] __main__: train step 22542: loss: 0.9106, policy_loss: 0.8191, value_loss: 0.4338
2024-07-11 17:52:28,369 [INFO    ] __main__: train step 22543: loss: 0.9105, policy_loss: 0.8191, value_loss: 0.4338
2024-07-11 17:52:28,677 [INFO    ] __main__: train step 22544: loss: 0.9105, policy_loss: 0.8190, value_loss: 0.4338
2024-07-11 17:52:28,910 [INFO    ] __main__: train step 22545: loss: 0.9105, policy_loss: 0.8190, value_loss: 0.4338
2024-07-11 17:52:29,099 [INFO    ] __main__: train step 22546: loss: 0.9105, policy_loss: 0.8190, value_loss: 0.4338
2024-07-11 17:52:29,353 [INFO    ] __main__: train step 22547: loss: 0.9105, policy_loss: 0.8190, value_loss: 0.4337
2024-07-11 17:52:29,551 [INFO    ] __main__: train step 22548: loss: 0.9105, policy_loss: 0.8190, value_loss: 0.4337
2024-07-11 17:52:29,763 [INFO    ] __main__: train step 22549: loss: 0.9105, policy_loss: 0.8190, value_loss: 0.4337
2024-07-11 17:52:29,974 [INFO    ] __main__: train step 22550: loss: 0.9105, policy_loss: 0.8190, value_loss: 0.4337
2024-07-11 17:52:30,188 [INFO    ] __main__: train step 22551: loss: 0.9105, policy_loss: 0.8190, value_loss: 0.4337
2024-07-11 17:52:30,429 [INFO    ] __main__: train step 22552: loss: 0.9105, policy_loss: 0.8190, value_loss: 0.4337
2024-07-11 17:52:30,681 [INFO    ] __main__: train step 22553: loss: 0.9105, policy_loss: 0.8190, value_loss: 0.4337
2024-07-11 17:52:30,909 [INFO    ] __main__: train step 22554: loss: 0.9105, policy_loss: 0.8190, value_loss: 0.4336
2024-07-11 17:52:31,110 [INFO    ] __main__: train step 22555: loss: 0.9105, policy_loss: 0.8190, value_loss: 0.4336
2024-07-11 17:52:31,316 [INFO    ] __main__: train step 22556: loss: 0.9105, policy_loss: 0.8190, value_loss: 0.4336
2024-07-11 17:52:31,521 [INFO    ] __main__: train step 22557: loss: 0.9105, policy_loss: 0.8190, value_loss: 0.4336
2024-07-11 17:52:31,723 [INFO    ] __main__: train step 22558: loss: 0.9104, policy_loss: 0.8190, value_loss: 0.4336
2024-07-11 17:52:33,177 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:52:33,565 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:52:33,619 [INFO    ] __main__: train step 22559: loss: 0.9104, policy_loss: 0.8189, value_loss: 0.4336
2024-07-11 17:52:33,806 [INFO    ] __main__: train step 22560: loss: 0.9104, policy_loss: 0.8189, value_loss: 0.4335
2024-07-11 17:52:34,041 [INFO    ] __main__: train step 22561: loss: 0.9104, policy_loss: 0.8189, value_loss: 0.4335
2024-07-11 17:52:34,243 [INFO    ] __main__: train step 22562: loss: 0.9104, policy_loss: 0.8189, value_loss: 0.4335
2024-07-11 17:52:34,474 [INFO    ] __main__: train step 22563: loss: 0.9104, policy_loss: 0.8189, value_loss: 0.4335
2024-07-11 17:52:34,689 [INFO    ] __main__: train step 22564: loss: 0.9104, policy_loss: 0.8189, value_loss: 0.4335
2024-07-11 17:52:34,892 [INFO    ] __main__: train step 22565: loss: 0.9104, policy_loss: 0.8189, value_loss: 0.4335
2024-07-11 17:52:35,104 [INFO    ] __main__: train step 22566: loss: 0.9104, policy_loss: 0.8189, value_loss: 0.4335
2024-07-11 17:52:35,312 [INFO    ] __main__: train step 22567: loss: 0.9104, policy_loss: 0.8189, value_loss: 0.4334
2024-07-11 17:52:35,511 [INFO    ] __main__: train step 22568: loss: 0.9104, policy_loss: 0.8189, value_loss: 0.4334
2024-07-11 17:52:35,719 [INFO    ] __main__: train step 22569: loss: 0.9104, policy_loss: 0.8189, value_loss: 0.4334
2024-07-11 17:52:35,942 [INFO    ] __main__: train step 22570: loss: 0.9104, policy_loss: 0.8189, value_loss: 0.4334
2024-07-11 17:52:36,194 [INFO    ] __main__: train step 22571: loss: 0.9104, policy_loss: 0.8189, value_loss: 0.4334
2024-07-11 17:52:36,431 [INFO    ] __main__: train step 22572: loss: 0.9103, policy_loss: 0.8189, value_loss: 0.4334
2024-07-11 17:52:36,648 [INFO    ] __main__: train step 22573: loss: 0.9103, policy_loss: 0.8189, value_loss: 0.4333
2024-07-11 17:52:36,866 [INFO    ] __main__: train step 22574: loss: 0.9103, policy_loss: 0.8188, value_loss: 0.4333
2024-07-11 17:52:37,058 [INFO    ] __main__: train step 22575: loss: 0.9103, policy_loss: 0.8188, value_loss: 0.4333
2024-07-11 17:52:38,512 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:52:38,884 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:52:38,940 [INFO    ] __main__: train step 22576: loss: 0.9103, policy_loss: 0.8188, value_loss: 0.4333
2024-07-11 17:52:39,120 [INFO    ] __main__: train step 22577: loss: 0.9103, policy_loss: 0.8188, value_loss: 0.4333
2024-07-11 17:52:39,340 [INFO    ] __main__: train step 22578: loss: 0.9103, policy_loss: 0.8188, value_loss: 0.4333
2024-07-11 17:52:39,573 [INFO    ] __main__: train step 22579: loss: 0.9103, policy_loss: 0.8188, value_loss: 0.4333
2024-07-11 17:52:39,770 [INFO    ] __main__: train step 22580: loss: 0.9103, policy_loss: 0.8188, value_loss: 0.4332
2024-07-11 17:52:39,971 [INFO    ] __main__: train step 22581: loss: 0.9103, policy_loss: 0.8188, value_loss: 0.4332
2024-07-11 17:52:40,179 [INFO    ] __main__: train step 22582: loss: 0.9103, policy_loss: 0.8188, value_loss: 0.4332
2024-07-11 17:52:40,383 [INFO    ] __main__: train step 22583: loss: 0.9103, policy_loss: 0.8188, value_loss: 0.4332
2024-07-11 17:52:40,579 [INFO    ] __main__: train step 22584: loss: 0.9103, policy_loss: 0.8188, value_loss: 0.4332
2024-07-11 17:52:40,786 [INFO    ] __main__: train step 22585: loss: 0.9103, policy_loss: 0.8188, value_loss: 0.4332
2024-07-11 17:52:40,986 [INFO    ] __main__: train step 22586: loss: 0.9103, policy_loss: 0.8188, value_loss: 0.4331
2024-07-11 17:52:41,193 [INFO    ] __main__: train step 22587: loss: 0.9102, policy_loss: 0.8188, value_loss: 0.4331
2024-07-11 17:52:41,390 [INFO    ] __main__: train step 22588: loss: 0.9102, policy_loss: 0.8188, value_loss: 0.4331
2024-07-11 17:52:41,601 [INFO    ] __main__: train step 22589: loss: 0.9102, policy_loss: 0.8187, value_loss: 0.4331
2024-07-11 17:52:41,811 [INFO    ] __main__: train step 22590: loss: 0.9102, policy_loss: 0.8187, value_loss: 0.4331
2024-07-11 17:52:42,027 [INFO    ] __main__: train step 22591: loss: 0.9102, policy_loss: 0.8187, value_loss: 0.4331
2024-07-11 17:52:42,229 [INFO    ] __main__: train step 22592: loss: 0.9102, policy_loss: 0.8187, value_loss: 0.4331
2024-07-11 17:52:43,682 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:52:44,091 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:52:44,156 [INFO    ] __main__: train step 22593: loss: 0.9102, policy_loss: 0.8187, value_loss: 0.4330
2024-07-11 17:52:44,334 [INFO    ] __main__: train step 22594: loss: 0.9102, policy_loss: 0.8187, value_loss: 0.4330
2024-07-11 17:52:44,540 [INFO    ] __main__: train step 22595: loss: 0.9102, policy_loss: 0.8187, value_loss: 0.4330
2024-07-11 17:52:44,752 [INFO    ] __main__: train step 22596: loss: 0.9102, policy_loss: 0.8187, value_loss: 0.4330
2024-07-11 17:52:44,956 [INFO    ] __main__: train step 22597: loss: 0.9102, policy_loss: 0.8187, value_loss: 0.4330
2024-07-11 17:52:45,172 [INFO    ] __main__: train step 22598: loss: 0.9102, policy_loss: 0.8187, value_loss: 0.4330
2024-07-11 17:52:45,419 [INFO    ] __main__: train step 22599: loss: 0.9102, policy_loss: 0.8187, value_loss: 0.4329
2024-07-11 17:52:45,637 [INFO    ] __main__: train step 22600: loss: 0.9102, policy_loss: 0.8187, value_loss: 0.4329
2024-07-11 17:52:45,840 [INFO    ] __main__: train step 22601: loss: 0.9101, policy_loss: 0.8187, value_loss: 0.4329
2024-07-11 17:52:46,044 [INFO    ] __main__: train step 22602: loss: 0.9101, policy_loss: 0.8187, value_loss: 0.4329
2024-07-11 17:52:46,251 [INFO    ] __main__: train step 22603: loss: 0.9101, policy_loss: 0.8187, value_loss: 0.4329
2024-07-11 17:52:46,454 [INFO    ] __main__: train step 22604: loss: 0.9101, policy_loss: 0.8186, value_loss: 0.4329
2024-07-11 17:52:46,650 [INFO    ] __main__: train step 22605: loss: 0.9101, policy_loss: 0.8186, value_loss: 0.4329
2024-07-11 17:52:46,857 [INFO    ] __main__: train step 22606: loss: 0.9101, policy_loss: 0.8186, value_loss: 0.4328
2024-07-11 17:52:47,082 [INFO    ] __main__: train step 22607: loss: 0.9101, policy_loss: 0.8186, value_loss: 0.4328
2024-07-11 17:52:47,318 [INFO    ] __main__: train step 22608: loss: 0.9101, policy_loss: 0.8186, value_loss: 0.4328
2024-07-11 17:52:47,527 [INFO    ] __main__: train step 22609: loss: 0.9101, policy_loss: 0.8186, value_loss: 0.4328
2024-07-11 17:52:48,975 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:52:49,335 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:52:49,395 [INFO    ] __main__: train step 22610: loss: 0.9101, policy_loss: 0.8186, value_loss: 0.4328
2024-07-11 17:52:49,579 [INFO    ] __main__: train step 22611: loss: 0.9101, policy_loss: 0.8186, value_loss: 0.4328
2024-07-11 17:52:49,778 [INFO    ] __main__: train step 22612: loss: 0.9101, policy_loss: 0.8186, value_loss: 0.4328
2024-07-11 17:52:49,984 [INFO    ] __main__: train step 22613: loss: 0.9101, policy_loss: 0.8186, value_loss: 0.4327
2024-07-11 17:52:50,191 [INFO    ] __main__: train step 22614: loss: 0.9101, policy_loss: 0.8186, value_loss: 0.4327
2024-07-11 17:52:50,397 [INFO    ] __main__: train step 22615: loss: 0.9100, policy_loss: 0.8186, value_loss: 0.4327
2024-07-11 17:52:50,606 [INFO    ] __main__: train step 22616: loss: 0.9100, policy_loss: 0.8186, value_loss: 0.4327
2024-07-11 17:52:50,816 [INFO    ] __main__: train step 22617: loss: 0.9100, policy_loss: 0.8186, value_loss: 0.4327
2024-07-11 17:52:51,026 [INFO    ] __main__: train step 22618: loss: 0.9100, policy_loss: 0.8185, value_loss: 0.4327
2024-07-11 17:52:51,225 [INFO    ] __main__: train step 22619: loss: 0.9100, policy_loss: 0.8185, value_loss: 0.4326
2024-07-11 17:52:51,441 [INFO    ] __main__: train step 22620: loss: 0.9100, policy_loss: 0.8185, value_loss: 0.4326
2024-07-11 17:52:51,655 [INFO    ] __main__: train step 22621: loss: 0.9100, policy_loss: 0.8185, value_loss: 0.4326
2024-07-11 17:52:51,868 [INFO    ] __main__: train step 22622: loss: 0.9100, policy_loss: 0.8185, value_loss: 0.4326
2024-07-11 17:52:52,068 [INFO    ] __main__: train step 22623: loss: 0.9100, policy_loss: 0.8185, value_loss: 0.4326
2024-07-11 17:52:52,273 [INFO    ] __main__: train step 22624: loss: 0.9100, policy_loss: 0.8185, value_loss: 0.4326
2024-07-11 17:52:52,488 [INFO    ] __main__: train step 22625: loss: 0.9100, policy_loss: 0.8185, value_loss: 0.4326
2024-07-11 17:52:52,725 [INFO    ] __main__: train step 22626: loss: 0.9100, policy_loss: 0.8185, value_loss: 0.4325
2024-07-11 17:52:54,164 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:52:54,522 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:52:54,582 [INFO    ] __main__: train step 22627: loss: 0.9100, policy_loss: 0.8185, value_loss: 0.4325
2024-07-11 17:52:54,765 [INFO    ] __main__: train step 22628: loss: 0.9100, policy_loss: 0.8185, value_loss: 0.4325
2024-07-11 17:52:54,964 [INFO    ] __main__: train step 22629: loss: 0.9100, policy_loss: 0.8185, value_loss: 0.4325
2024-07-11 17:52:55,169 [INFO    ] __main__: train step 22630: loss: 0.9099, policy_loss: 0.8185, value_loss: 0.4325
2024-07-11 17:52:55,376 [INFO    ] __main__: train step 22631: loss: 0.9099, policy_loss: 0.8185, value_loss: 0.4325
2024-07-11 17:52:57,854 [INFO    ] __main__: train step 22632: loss: 0.9099, policy_loss: 0.8185, value_loss: 0.4324
2024-07-11 17:52:58,061 [INFO    ] __main__: train step 22633: loss: 0.9099, policy_loss: 0.8184, value_loss: 0.4324
2024-07-11 17:52:58,273 [INFO    ] __main__: train step 22634: loss: 0.9099, policy_loss: 0.8184, value_loss: 0.4324
2024-07-11 17:52:58,497 [INFO    ] __main__: train step 22635: loss: 0.9099, policy_loss: 0.8184, value_loss: 0.4324
2024-07-11 17:52:58,706 [INFO    ] __main__: train step 22636: loss: 0.9099, policy_loss: 0.8184, value_loss: 0.4324
2024-07-11 17:52:58,906 [INFO    ] __main__: train step 22637: loss: 0.9099, policy_loss: 0.8184, value_loss: 0.4324
2024-07-11 17:52:59,114 [INFO    ] __main__: train step 22638: loss: 0.9099, policy_loss: 0.8184, value_loss: 0.4324
2024-07-11 17:52:59,331 [INFO    ] __main__: train step 22639: loss: 0.9099, policy_loss: 0.8184, value_loss: 0.4323
2024-07-11 17:52:59,538 [INFO    ] __main__: train step 22640: loss: 0.9099, policy_loss: 0.8184, value_loss: 0.4323
2024-07-11 17:52:59,771 [INFO    ] __main__: train step 22641: loss: 0.9099, policy_loss: 0.8184, value_loss: 0.4323
2024-07-11 17:52:59,982 [INFO    ] __main__: train step 22642: loss: 0.9099, policy_loss: 0.8184, value_loss: 0.4323
2024-07-11 17:53:00,190 [INFO    ] __main__: train step 22643: loss: 0.9099, policy_loss: 0.8184, value_loss: 0.4323
2024-07-11 17:53:01,624 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:53:02,002 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:53:02,066 [INFO    ] __main__: train step 22644: loss: 0.9098, policy_loss: 0.8184, value_loss: 0.4323
2024-07-11 17:53:02,242 [INFO    ] __main__: train step 22645: loss: 0.9098, policy_loss: 0.8184, value_loss: 0.4323
2024-07-11 17:53:02,443 [INFO    ] __main__: train step 22646: loss: 0.9098, policy_loss: 0.8184, value_loss: 0.4322
2024-07-11 17:53:02,642 [INFO    ] __main__: train step 22647: loss: 0.9098, policy_loss: 0.8183, value_loss: 0.4322
2024-07-11 17:53:02,856 [INFO    ] __main__: train step 22648: loss: 0.9098, policy_loss: 0.8183, value_loss: 0.4322
2024-07-11 17:53:03,092 [INFO    ] __main__: train step 22649: loss: 0.9098, policy_loss: 0.8183, value_loss: 0.4322
2024-07-11 17:53:03,298 [INFO    ] __main__: train step 22650: loss: 0.9098, policy_loss: 0.8183, value_loss: 0.4322
2024-07-11 17:53:03,511 [INFO    ] __main__: train step 22651: loss: 0.9098, policy_loss: 0.8183, value_loss: 0.4322
2024-07-11 17:53:03,720 [INFO    ] __main__: train step 22652: loss: 0.9098, policy_loss: 0.8183, value_loss: 0.4321
2024-07-11 17:53:03,944 [INFO    ] __main__: train step 22653: loss: 0.9098, policy_loss: 0.8183, value_loss: 0.4321
2024-07-11 17:53:04,153 [INFO    ] __main__: train step 22654: loss: 0.9098, policy_loss: 0.8183, value_loss: 0.4321
2024-07-11 17:53:04,390 [INFO    ] __main__: train step 22655: loss: 0.9098, policy_loss: 0.8183, value_loss: 0.4321
2024-07-11 17:53:04,590 [INFO    ] __main__: train step 22656: loss: 0.9098, policy_loss: 0.8183, value_loss: 0.4321
2024-07-11 17:53:04,806 [INFO    ] __main__: train step 22657: loss: 0.9097, policy_loss: 0.8183, value_loss: 0.4321
2024-07-11 17:53:05,013 [INFO    ] __main__: train step 22658: loss: 0.9097, policy_loss: 0.8183, value_loss: 0.4321
2024-07-11 17:53:05,236 [INFO    ] __main__: train step 22659: loss: 0.9097, policy_loss: 0.8183, value_loss: 0.4320
2024-07-11 17:53:05,438 [INFO    ] __main__: train step 22660: loss: 0.9097, policy_loss: 0.8183, value_loss: 0.4320
2024-07-11 17:53:06,887 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:53:07,249 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:53:07,305 [INFO    ] __main__: train step 22661: loss: 0.9097, policy_loss: 0.8182, value_loss: 0.4320
2024-07-11 17:53:07,494 [INFO    ] __main__: train step 22662: loss: 0.9097, policy_loss: 0.8182, value_loss: 0.4320
2024-07-11 17:53:07,698 [INFO    ] __main__: train step 22663: loss: 0.9097, policy_loss: 0.8182, value_loss: 0.4320
2024-07-11 17:53:07,913 [INFO    ] __main__: train step 22664: loss: 0.9097, policy_loss: 0.8182, value_loss: 0.4320
2024-07-11 17:53:08,116 [INFO    ] __main__: train step 22665: loss: 0.9097, policy_loss: 0.8182, value_loss: 0.4319
2024-07-11 17:53:08,330 [INFO    ] __main__: train step 22666: loss: 0.9097, policy_loss: 0.8182, value_loss: 0.4319
2024-07-11 17:53:08,531 [INFO    ] __main__: train step 22667: loss: 0.9097, policy_loss: 0.8182, value_loss: 0.4319
2024-07-11 17:53:08,740 [INFO    ] __main__: train step 22668: loss: 0.9097, policy_loss: 0.8182, value_loss: 0.4319
2024-07-11 17:53:08,965 [INFO    ] __main__: train step 22669: loss: 0.9097, policy_loss: 0.8182, value_loss: 0.4319
2024-07-11 17:53:09,185 [INFO    ] __main__: train step 22670: loss: 0.9096, policy_loss: 0.8182, value_loss: 0.4319
2024-07-11 17:53:09,434 [INFO    ] __main__: train step 22671: loss: 0.9096, policy_loss: 0.8182, value_loss: 0.4319
2024-07-11 17:53:09,656 [INFO    ] __main__: train step 22672: loss: 0.9096, policy_loss: 0.8182, value_loss: 0.4318
2024-07-11 17:53:09,888 [INFO    ] __main__: train step 22673: loss: 0.9096, policy_loss: 0.8182, value_loss: 0.4318
2024-07-11 17:53:10,093 [INFO    ] __main__: train step 22674: loss: 0.9096, policy_loss: 0.8181, value_loss: 0.4318
2024-07-11 17:53:10,309 [INFO    ] __main__: train step 22675: loss: 0.9096, policy_loss: 0.8181, value_loss: 0.4318
2024-07-11 17:53:10,521 [INFO    ] __main__: train step 22676: loss: 0.9096, policy_loss: 0.8181, value_loss: 0.4318
2024-07-11 17:53:10,730 [INFO    ] __main__: train step 22677: loss: 0.9096, policy_loss: 0.8181, value_loss: 0.4318
2024-07-11 17:53:12,164 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:53:12,551 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:53:12,606 [INFO    ] __main__: train step 22678: loss: 0.9096, policy_loss: 0.8181, value_loss: 0.4317
2024-07-11 17:53:12,783 [INFO    ] __main__: train step 22679: loss: 0.9096, policy_loss: 0.8181, value_loss: 0.4317
2024-07-11 17:53:12,987 [INFO    ] __main__: train step 22680: loss: 0.9096, policy_loss: 0.8181, value_loss: 0.4317
2024-07-11 17:53:13,187 [INFO    ] __main__: train step 22681: loss: 0.9096, policy_loss: 0.8181, value_loss: 0.4317
2024-07-11 17:53:13,383 [INFO    ] __main__: train step 22682: loss: 0.9096, policy_loss: 0.8181, value_loss: 0.4317
2024-07-11 17:53:13,583 [INFO    ] __main__: train step 22683: loss: 0.9095, policy_loss: 0.8181, value_loss: 0.4317
2024-07-11 17:53:13,792 [INFO    ] __main__: train step 22684: loss: 0.9095, policy_loss: 0.8181, value_loss: 0.4317
2024-07-11 17:53:13,994 [INFO    ] __main__: train step 22685: loss: 0.9095, policy_loss: 0.8181, value_loss: 0.4316
2024-07-11 17:53:14,193 [INFO    ] __main__: train step 22686: loss: 0.9095, policy_loss: 0.8181, value_loss: 0.4316
2024-07-11 17:53:14,406 [INFO    ] __main__: train step 22687: loss: 0.9095, policy_loss: 0.8181, value_loss: 0.4316
2024-07-11 17:53:14,605 [INFO    ] __main__: train step 22688: loss: 0.9095, policy_loss: 0.8180, value_loss: 0.4316
2024-07-11 17:53:14,825 [INFO    ] __main__: train step 22689: loss: 0.9095, policy_loss: 0.8180, value_loss: 0.4316
2024-07-11 17:53:15,057 [INFO    ] __main__: train step 22690: loss: 0.9095, policy_loss: 0.8180, value_loss: 0.4316
2024-07-11 17:53:15,264 [INFO    ] __main__: train step 22691: loss: 0.9095, policy_loss: 0.8180, value_loss: 0.4315
2024-07-11 17:53:15,469 [INFO    ] __main__: train step 22692: loss: 0.9095, policy_loss: 0.8180, value_loss: 0.4315
2024-07-11 17:53:15,675 [INFO    ] __main__: train step 22693: loss: 0.9095, policy_loss: 0.8180, value_loss: 0.4315
2024-07-11 17:53:15,873 [INFO    ] __main__: train step 22694: loss: 0.9095, policy_loss: 0.8180, value_loss: 0.4315
2024-07-11 17:53:17,315 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:53:17,665 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:53:17,722 [INFO    ] __main__: train step 22695: loss: 0.9095, policy_loss: 0.8180, value_loss: 0.4315
2024-07-11 17:53:17,926 [INFO    ] __main__: train step 22696: loss: 0.9094, policy_loss: 0.8180, value_loss: 0.4315
2024-07-11 17:53:18,155 [INFO    ] __main__: train step 22697: loss: 0.9094, policy_loss: 0.8180, value_loss: 0.4315
2024-07-11 17:53:18,354 [INFO    ] __main__: train step 22698: loss: 0.9094, policy_loss: 0.8180, value_loss: 0.4314
2024-07-11 17:53:18,572 [INFO    ] __main__: train step 22699: loss: 0.9094, policy_loss: 0.8180, value_loss: 0.4314
2024-07-11 17:53:18,771 [INFO    ] __main__: train step 22700: loss: 0.9094, policy_loss: 0.8180, value_loss: 0.4314
2024-07-11 17:53:18,978 [INFO    ] __main__: train step 22701: loss: 0.9094, policy_loss: 0.8179, value_loss: 0.4314
2024-07-11 17:53:19,190 [INFO    ] __main__: train step 22702: loss: 0.9094, policy_loss: 0.8179, value_loss: 0.4314
2024-07-11 17:53:19,393 [INFO    ] __main__: train step 22703: loss: 0.9094, policy_loss: 0.8179, value_loss: 0.4314
2024-07-11 17:53:19,592 [INFO    ] __main__: train step 22704: loss: 0.9094, policy_loss: 0.8179, value_loss: 0.4313
2024-07-11 17:53:19,805 [INFO    ] __main__: train step 22705: loss: 0.9094, policy_loss: 0.8179, value_loss: 0.4313
2024-07-11 17:53:20,015 [INFO    ] __main__: train step 22706: loss: 0.9094, policy_loss: 0.8179, value_loss: 0.4313
2024-07-11 17:53:20,229 [INFO    ] __main__: train step 22707: loss: 0.9094, policy_loss: 0.8179, value_loss: 0.4313
2024-07-11 17:53:20,453 [INFO    ] __main__: train step 22708: loss: 0.9094, policy_loss: 0.8179, value_loss: 0.4313
2024-07-11 17:53:20,662 [INFO    ] __main__: train step 22709: loss: 0.9093, policy_loss: 0.8179, value_loss: 0.4313
2024-07-11 17:53:20,869 [INFO    ] __main__: train step 22710: loss: 0.9093, policy_loss: 0.8179, value_loss: 0.4313
2024-07-11 17:53:21,074 [INFO    ] __main__: train step 22711: loss: 0.9093, policy_loss: 0.8179, value_loss: 0.4312
2024-07-11 17:53:22,526 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:53:22,877 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:53:22,940 [INFO    ] __main__: train step 22712: loss: 0.9093, policy_loss: 0.8179, value_loss: 0.4312
2024-07-11 17:53:23,127 [INFO    ] __main__: train step 22713: loss: 0.9093, policy_loss: 0.8179, value_loss: 0.4312
2024-07-11 17:53:23,371 [INFO    ] __main__: train step 22714: loss: 0.9093, policy_loss: 0.8178, value_loss: 0.4312
2024-07-11 17:53:23,571 [INFO    ] __main__: train step 22715: loss: 0.9093, policy_loss: 0.8178, value_loss: 0.4312
2024-07-11 17:53:23,805 [INFO    ] __main__: train step 22716: loss: 0.9093, policy_loss: 0.8178, value_loss: 0.4312
2024-07-11 17:53:24,039 [INFO    ] __main__: train step 22717: loss: 0.9093, policy_loss: 0.8178, value_loss: 0.4311
2024-07-11 17:53:24,271 [INFO    ] __main__: train step 22718: loss: 0.9093, policy_loss: 0.8178, value_loss: 0.4311
2024-07-11 17:53:24,475 [INFO    ] __main__: train step 22719: loss: 0.9093, policy_loss: 0.8178, value_loss: 0.4311
2024-07-11 17:53:24,693 [INFO    ] __main__: train step 22720: loss: 0.9093, policy_loss: 0.8178, value_loss: 0.4311
2024-07-11 17:53:24,934 [INFO    ] __main__: train step 22721: loss: 0.9092, policy_loss: 0.8178, value_loss: 0.4311
2024-07-11 17:53:25,165 [INFO    ] __main__: train step 22722: loss: 0.9092, policy_loss: 0.8178, value_loss: 0.4311
2024-07-11 17:53:25,376 [INFO    ] __main__: train step 22723: loss: 0.9092, policy_loss: 0.8178, value_loss: 0.4311
2024-07-11 17:53:25,577 [INFO    ] __main__: train step 22724: loss: 0.9092, policy_loss: 0.8178, value_loss: 0.4310
2024-07-11 17:53:25,778 [INFO    ] __main__: train step 22725: loss: 0.9092, policy_loss: 0.8178, value_loss: 0.4310
2024-07-11 17:53:25,991 [INFO    ] __main__: train step 22726: loss: 0.9092, policy_loss: 0.8178, value_loss: 0.4310
2024-07-11 17:53:26,192 [INFO    ] __main__: train step 22727: loss: 0.9092, policy_loss: 0.8177, value_loss: 0.4310
2024-07-11 17:53:26,388 [INFO    ] __main__: train step 22728: loss: 0.9092, policy_loss: 0.8177, value_loss: 0.4310
2024-07-11 17:53:27,822 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:53:28,181 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:53:28,241 [INFO    ] __main__: train step 22729: loss: 0.9092, policy_loss: 0.8177, value_loss: 0.4310
2024-07-11 17:53:28,423 [INFO    ] __main__: train step 22730: loss: 0.9092, policy_loss: 0.8177, value_loss: 0.4309
2024-07-11 17:53:28,636 [INFO    ] __main__: train step 22731: loss: 0.9092, policy_loss: 0.8177, value_loss: 0.4309
2024-07-11 17:53:28,839 [INFO    ] __main__: train step 22732: loss: 0.9092, policy_loss: 0.8177, value_loss: 0.4309
2024-07-11 17:53:29,049 [INFO    ] __main__: train step 22733: loss: 0.9091, policy_loss: 0.8177, value_loss: 0.4309
2024-07-11 17:53:29,249 [INFO    ] __main__: train step 22734: loss: 0.9091, policy_loss: 0.8177, value_loss: 0.4309
2024-07-11 17:53:29,464 [INFO    ] __main__: train step 22735: loss: 0.9091, policy_loss: 0.8177, value_loss: 0.4309
2024-07-11 17:53:29,664 [INFO    ] __main__: train step 22736: loss: 0.9091, policy_loss: 0.8177, value_loss: 0.4309
2024-07-11 17:53:29,873 [INFO    ] __main__: train step 22737: loss: 0.9091, policy_loss: 0.8177, value_loss: 0.4308
2024-07-11 17:53:30,099 [INFO    ] __main__: train step 22738: loss: 0.9091, policy_loss: 0.8177, value_loss: 0.4308
2024-07-11 17:53:30,319 [INFO    ] __main__: train step 22739: loss: 0.9091, policy_loss: 0.8177, value_loss: 0.4308
2024-07-11 17:53:30,547 [INFO    ] __main__: train step 22740: loss: 0.9091, policy_loss: 0.8176, value_loss: 0.4308
2024-07-11 17:53:30,769 [INFO    ] __main__: train step 22741: loss: 0.9091, policy_loss: 0.8176, value_loss: 0.4308
2024-07-11 17:53:30,996 [INFO    ] __main__: train step 22742: loss: 0.9091, policy_loss: 0.8176, value_loss: 0.4308
2024-07-11 17:53:31,189 [INFO    ] __main__: train step 22743: loss: 0.9091, policy_loss: 0.8176, value_loss: 0.4308
2024-07-11 17:53:31,399 [INFO    ] __main__: train step 22744: loss: 0.9091, policy_loss: 0.8176, value_loss: 0.4307
2024-07-11 17:53:31,598 [INFO    ] __main__: train step 22745: loss: 0.9091, policy_loss: 0.8176, value_loss: 0.4307
2024-07-11 17:53:33,022 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:53:33,380 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:53:33,439 [INFO    ] __main__: train step 22746: loss: 0.9090, policy_loss: 0.8176, value_loss: 0.4307
2024-07-11 17:53:33,621 [INFO    ] __main__: train step 22747: loss: 0.9090, policy_loss: 0.8176, value_loss: 0.4307
2024-07-11 17:53:33,820 [INFO    ] __main__: train step 22748: loss: 0.9090, policy_loss: 0.8176, value_loss: 0.4307
2024-07-11 17:53:34,018 [INFO    ] __main__: train step 22749: loss: 0.9090, policy_loss: 0.8176, value_loss: 0.4307
2024-07-11 17:53:34,230 [INFO    ] __main__: train step 22750: loss: 0.9090, policy_loss: 0.8176, value_loss: 0.4306
2024-07-11 17:53:34,426 [INFO    ] __main__: train step 22751: loss: 0.9090, policy_loss: 0.8176, value_loss: 0.4306
2024-07-11 17:53:34,633 [INFO    ] __main__: train step 22752: loss: 0.9090, policy_loss: 0.8176, value_loss: 0.4306
2024-07-11 17:53:34,840 [INFO    ] __main__: train step 22753: loss: 0.9090, policy_loss: 0.8175, value_loss: 0.4306
2024-07-11 17:53:35,039 [INFO    ] __main__: train step 22754: loss: 0.9090, policy_loss: 0.8175, value_loss: 0.4306
2024-07-11 17:53:35,236 [INFO    ] __main__: train step 22755: loss: 0.9090, policy_loss: 0.8175, value_loss: 0.4306
2024-07-11 17:53:35,440 [INFO    ] __main__: train step 22756: loss: 0.9090, policy_loss: 0.8175, value_loss: 0.4306
2024-07-11 17:53:35,640 [INFO    ] __main__: train step 22757: loss: 0.9090, policy_loss: 0.8175, value_loss: 0.4305
2024-07-11 17:53:35,861 [INFO    ] __main__: train step 22758: loss: 0.9089, policy_loss: 0.8175, value_loss: 0.4305
2024-07-11 17:53:36,089 [INFO    ] __main__: train step 22759: loss: 0.9089, policy_loss: 0.8175, value_loss: 0.4305
2024-07-11 17:53:36,298 [INFO    ] __main__: train step 22760: loss: 0.9089, policy_loss: 0.8175, value_loss: 0.4305
2024-07-11 17:53:36,505 [INFO    ] __main__: train step 22761: loss: 0.9089, policy_loss: 0.8175, value_loss: 0.4305
2024-07-11 17:53:36,739 [INFO    ] __main__: train step 22762: loss: 0.9089, policy_loss: 0.8175, value_loss: 0.4305
2024-07-11 17:53:38,175 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:53:38,587 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:53:38,641 [INFO    ] __main__: train step 22763: loss: 0.9089, policy_loss: 0.8175, value_loss: 0.4304
2024-07-11 17:53:38,823 [INFO    ] __main__: train step 22764: loss: 0.9089, policy_loss: 0.8175, value_loss: 0.4304
2024-07-11 17:53:39,036 [INFO    ] __main__: train step 22765: loss: 0.9089, policy_loss: 0.8175, value_loss: 0.4304
2024-07-11 17:53:39,245 [INFO    ] __main__: train step 22766: loss: 0.9089, policy_loss: 0.8174, value_loss: 0.4304
2024-07-11 17:53:41,660 [INFO    ] __main__: train step 22767: loss: 0.9089, policy_loss: 0.8174, value_loss: 0.4304
2024-07-11 17:53:41,894 [INFO    ] __main__: train step 22768: loss: 0.9089, policy_loss: 0.8174, value_loss: 0.4304
2024-07-11 17:53:42,135 [INFO    ] __main__: train step 22769: loss: 0.9089, policy_loss: 0.8174, value_loss: 0.4304
2024-07-11 17:53:42,374 [INFO    ] __main__: train step 22770: loss: 0.9088, policy_loss: 0.8174, value_loss: 0.4303
2024-07-11 17:53:42,624 [INFO    ] __main__: train step 22771: loss: 0.9088, policy_loss: 0.8174, value_loss: 0.4303
2024-07-11 17:53:42,860 [INFO    ] __main__: train step 22772: loss: 0.9088, policy_loss: 0.8174, value_loss: 0.4303
2024-07-11 17:53:43,067 [INFO    ] __main__: train step 22773: loss: 0.9088, policy_loss: 0.8174, value_loss: 0.4303
2024-07-11 17:53:43,285 [INFO    ] __main__: train step 22774: loss: 0.9088, policy_loss: 0.8174, value_loss: 0.4303
2024-07-11 17:53:43,516 [INFO    ] __main__: train step 22775: loss: 0.9088, policy_loss: 0.8174, value_loss: 0.4303
2024-07-11 17:53:43,720 [INFO    ] __main__: train step 22776: loss: 0.9088, policy_loss: 0.8174, value_loss: 0.4302
2024-07-11 17:53:43,921 [INFO    ] __main__: train step 22777: loss: 0.9088, policy_loss: 0.8174, value_loss: 0.4302
2024-07-11 17:53:44,121 [INFO    ] __main__: train step 22778: loss: 0.9088, policy_loss: 0.8173, value_loss: 0.4302
2024-07-11 17:53:44,330 [INFO    ] __main__: train step 22779: loss: 0.9088, policy_loss: 0.8173, value_loss: 0.4302
2024-07-11 17:53:45,760 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:53:46,162 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:53:46,216 [INFO    ] __main__: train step 22780: loss: 0.9088, policy_loss: 0.8173, value_loss: 0.4302
2024-07-11 17:53:46,387 [INFO    ] __main__: train step 22781: loss: 0.9088, policy_loss: 0.8173, value_loss: 0.4302
2024-07-11 17:53:46,587 [INFO    ] __main__: train step 22782: loss: 0.9087, policy_loss: 0.8173, value_loss: 0.4302
2024-07-11 17:53:46,785 [INFO    ] __main__: train step 22783: loss: 0.9087, policy_loss: 0.8173, value_loss: 0.4301
2024-07-11 17:53:46,995 [INFO    ] __main__: train step 22784: loss: 0.9087, policy_loss: 0.8173, value_loss: 0.4301
2024-07-11 17:53:47,206 [INFO    ] __main__: train step 22785: loss: 0.9087, policy_loss: 0.8173, value_loss: 0.4301
2024-07-11 17:53:47,442 [INFO    ] __main__: train step 22786: loss: 0.9087, policy_loss: 0.8173, value_loss: 0.4301
2024-07-11 17:53:47,648 [INFO    ] __main__: train step 22787: loss: 0.9087, policy_loss: 0.8173, value_loss: 0.4301
2024-07-11 17:53:47,868 [INFO    ] __main__: train step 22788: loss: 0.9087, policy_loss: 0.8173, value_loss: 0.4301
2024-07-11 17:53:48,098 [INFO    ] __main__: train step 22789: loss: 0.9087, policy_loss: 0.8173, value_loss: 0.4301
2024-07-11 17:53:48,318 [INFO    ] __main__: train step 22790: loss: 0.9087, policy_loss: 0.8172, value_loss: 0.4300
2024-07-11 17:53:48,554 [INFO    ] __main__: train step 22791: loss: 0.9087, policy_loss: 0.8172, value_loss: 0.4300
2024-07-11 17:53:48,764 [INFO    ] __main__: train step 22792: loss: 0.9087, policy_loss: 0.8172, value_loss: 0.4300
2024-07-11 17:53:48,969 [INFO    ] __main__: train step 22793: loss: 0.9087, policy_loss: 0.8172, value_loss: 0.4300
2024-07-11 17:53:49,174 [INFO    ] __main__: train step 22794: loss: 0.9086, policy_loss: 0.8172, value_loss: 0.4300
2024-07-11 17:53:49,372 [INFO    ] __main__: train step 22795: loss: 0.9086, policy_loss: 0.8172, value_loss: 0.4300
2024-07-11 17:53:49,594 [INFO    ] __main__: train step 22796: loss: 0.9086, policy_loss: 0.8172, value_loss: 0.4299
2024-07-11 17:53:51,031 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:53:51,501 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:53:51,557 [INFO    ] __main__: train step 22797: loss: 0.9086, policy_loss: 0.8172, value_loss: 0.4299
2024-07-11 17:53:51,737 [INFO    ] __main__: train step 22798: loss: 0.9086, policy_loss: 0.8172, value_loss: 0.4299
2024-07-11 17:53:51,956 [INFO    ] __main__: train step 22799: loss: 0.9086, policy_loss: 0.8172, value_loss: 0.4299
2024-07-11 17:53:52,157 [INFO    ] __main__: train step 22800: loss: 0.9086, policy_loss: 0.8172, value_loss: 0.4299
2024-07-11 17:53:52,383 [INFO    ] __main__: train step 22801: loss: 0.9086, policy_loss: 0.8172, value_loss: 0.4299
2024-07-11 17:53:52,578 [INFO    ] __main__: train step 22802: loss: 0.9086, policy_loss: 0.8171, value_loss: 0.4299
2024-07-11 17:53:52,798 [INFO    ] __main__: train step 22803: loss: 0.9086, policy_loss: 0.8171, value_loss: 0.4298
2024-07-11 17:53:53,039 [INFO    ] __main__: train step 22804: loss: 0.9086, policy_loss: 0.8171, value_loss: 0.4298
2024-07-11 17:53:53,236 [INFO    ] __main__: train step 22805: loss: 0.9085, policy_loss: 0.8171, value_loss: 0.4298
2024-07-11 17:53:53,444 [INFO    ] __main__: train step 22806: loss: 0.9085, policy_loss: 0.8171, value_loss: 0.4298
2024-07-11 17:53:53,668 [INFO    ] __main__: train step 22807: loss: 0.9085, policy_loss: 0.8171, value_loss: 0.4298
2024-07-11 17:53:53,916 [INFO    ] __main__: train step 22808: loss: 0.9085, policy_loss: 0.8171, value_loss: 0.4298
2024-07-11 17:53:54,166 [INFO    ] __main__: train step 22809: loss: 0.9085, policy_loss: 0.8171, value_loss: 0.4297
2024-07-11 17:53:54,411 [INFO    ] __main__: train step 22810: loss: 0.9085, policy_loss: 0.8171, value_loss: 0.4297
2024-07-11 17:53:54,613 [INFO    ] __main__: train step 22811: loss: 0.9085, policy_loss: 0.8171, value_loss: 0.4297
2024-07-11 17:53:54,820 [INFO    ] __main__: train step 22812: loss: 0.9085, policy_loss: 0.8171, value_loss: 0.4297
2024-07-11 17:53:55,031 [INFO    ] __main__: train step 22813: loss: 0.9085, policy_loss: 0.8171, value_loss: 0.4297
2024-07-11 17:53:56,487 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:53:56,884 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:53:56,939 [INFO    ] __main__: train step 22814: loss: 0.9085, policy_loss: 0.8170, value_loss: 0.4297
2024-07-11 17:53:57,124 [INFO    ] __main__: train step 22815: loss: 0.9085, policy_loss: 0.8170, value_loss: 0.4297
2024-07-11 17:53:57,338 [INFO    ] __main__: train step 22816: loss: 0.9085, policy_loss: 0.8170, value_loss: 0.4296
2024-07-11 17:53:57,575 [INFO    ] __main__: train step 22817: loss: 0.9084, policy_loss: 0.8170, value_loss: 0.4296
2024-07-11 17:53:57,776 [INFO    ] __main__: train step 22818: loss: 0.9084, policy_loss: 0.8170, value_loss: 0.4296
2024-07-11 17:53:57,986 [INFO    ] __main__: train step 22819: loss: 0.9084, policy_loss: 0.8170, value_loss: 0.4296
2024-07-11 17:53:58,191 [INFO    ] __main__: train step 22820: loss: 0.9084, policy_loss: 0.8170, value_loss: 0.4296
2024-07-11 17:53:58,403 [INFO    ] __main__: train step 22821: loss: 0.9084, policy_loss: 0.8170, value_loss: 0.4296
2024-07-11 17:53:58,615 [INFO    ] __main__: train step 22822: loss: 0.9084, policy_loss: 0.8170, value_loss: 0.4296
2024-07-11 17:53:58,856 [INFO    ] __main__: train step 22823: loss: 0.9084, policy_loss: 0.8170, value_loss: 0.4295
2024-07-11 17:53:59,068 [INFO    ] __main__: train step 22824: loss: 0.9084, policy_loss: 0.8170, value_loss: 0.4295
2024-07-11 17:53:59,262 [INFO    ] __main__: train step 22825: loss: 0.9084, policy_loss: 0.8170, value_loss: 0.4295
2024-07-11 17:53:59,471 [INFO    ] __main__: train step 22826: loss: 0.9084, policy_loss: 0.8170, value_loss: 0.4295
2024-07-11 17:53:59,678 [INFO    ] __main__: train step 22827: loss: 0.9084, policy_loss: 0.8169, value_loss: 0.4295
2024-07-11 17:53:59,895 [INFO    ] __main__: train step 22828: loss: 0.9083, policy_loss: 0.8169, value_loss: 0.4295
2024-07-11 17:54:00,133 [INFO    ] __main__: train step 22829: loss: 0.9083, policy_loss: 0.8169, value_loss: 0.4294
2024-07-11 17:54:00,351 [INFO    ] __main__: train step 22830: loss: 0.9083, policy_loss: 0.8169, value_loss: 0.4294
2024-07-11 17:54:01,772 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:54:02,209 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:54:02,275 [INFO    ] __main__: train step 22831: loss: 0.9083, policy_loss: 0.8169, value_loss: 0.4294
2024-07-11 17:54:02,451 [INFO    ] __main__: train step 22832: loss: 0.9083, policy_loss: 0.8169, value_loss: 0.4294
2024-07-11 17:54:02,665 [INFO    ] __main__: train step 22833: loss: 0.9083, policy_loss: 0.8169, value_loss: 0.4294
2024-07-11 17:54:02,876 [INFO    ] __main__: train step 22834: loss: 0.9083, policy_loss: 0.8169, value_loss: 0.4294
2024-07-11 17:54:03,076 [INFO    ] __main__: train step 22835: loss: 0.9083, policy_loss: 0.8169, value_loss: 0.4294
2024-07-11 17:54:03,288 [INFO    ] __main__: train step 22836: loss: 0.9083, policy_loss: 0.8169, value_loss: 0.4293
2024-07-11 17:54:03,484 [INFO    ] __main__: train step 22837: loss: 0.9083, policy_loss: 0.8169, value_loss: 0.4293
2024-07-11 17:54:03,697 [INFO    ] __main__: train step 22838: loss: 0.9083, policy_loss: 0.8168, value_loss: 0.4293
2024-07-11 17:54:03,906 [INFO    ] __main__: train step 22839: loss: 0.9083, policy_loss: 0.8168, value_loss: 0.4293
2024-07-11 17:54:04,108 [INFO    ] __main__: train step 22840: loss: 0.9082, policy_loss: 0.8168, value_loss: 0.4293
2024-07-11 17:54:04,316 [INFO    ] __main__: train step 22841: loss: 0.9082, policy_loss: 0.8168, value_loss: 0.4293
2024-07-11 17:54:04,523 [INFO    ] __main__: train step 22842: loss: 0.9082, policy_loss: 0.8168, value_loss: 0.4292
2024-07-11 17:54:04,733 [INFO    ] __main__: train step 22843: loss: 0.9082, policy_loss: 0.8168, value_loss: 0.4292
2024-07-11 17:54:04,953 [INFO    ] __main__: train step 22844: loss: 0.9082, policy_loss: 0.8168, value_loss: 0.4292
2024-07-11 17:54:05,193 [INFO    ] __main__: train step 22845: loss: 0.9082, policy_loss: 0.8168, value_loss: 0.4292
2024-07-11 17:54:05,441 [INFO    ] __main__: train step 22846: loss: 0.9082, policy_loss: 0.8168, value_loss: 0.4292
2024-07-11 17:54:05,643 [INFO    ] __main__: train step 22847: loss: 0.9082, policy_loss: 0.8168, value_loss: 0.4292
2024-07-11 17:54:07,100 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:54:07,524 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:54:07,583 [INFO    ] __main__: train step 22848: loss: 0.9082, policy_loss: 0.8168, value_loss: 0.4292
2024-07-11 17:54:07,769 [INFO    ] __main__: train step 22849: loss: 0.9082, policy_loss: 0.8168, value_loss: 0.4291
2024-07-11 17:54:07,973 [INFO    ] __main__: train step 22850: loss: 0.9082, policy_loss: 0.8167, value_loss: 0.4291
2024-07-11 17:54:08,179 [INFO    ] __main__: train step 22851: loss: 0.9081, policy_loss: 0.8167, value_loss: 0.4291
2024-07-11 17:54:08,382 [INFO    ] __main__: train step 22852: loss: 0.9081, policy_loss: 0.8167, value_loss: 0.4291
2024-07-11 17:54:08,598 [INFO    ] __main__: train step 22853: loss: 0.9081, policy_loss: 0.8167, value_loss: 0.4291
2024-07-11 17:54:08,810 [INFO    ] __main__: train step 22854: loss: 0.9081, policy_loss: 0.8167, value_loss: 0.4291
2024-07-11 17:54:09,011 [INFO    ] __main__: train step 22855: loss: 0.9081, policy_loss: 0.8167, value_loss: 0.4291
2024-07-11 17:54:09,228 [INFO    ] __main__: train step 22856: loss: 0.9081, policy_loss: 0.8167, value_loss: 0.4290
2024-07-11 17:54:09,466 [INFO    ] __main__: train step 22857: loss: 0.9081, policy_loss: 0.8167, value_loss: 0.4290
2024-07-11 17:54:09,676 [INFO    ] __main__: train step 22858: loss: 0.9081, policy_loss: 0.8167, value_loss: 0.4290
2024-07-11 17:54:09,893 [INFO    ] __main__: train step 22859: loss: 0.9081, policy_loss: 0.8167, value_loss: 0.4290
2024-07-11 17:54:10,098 [INFO    ] __main__: train step 22860: loss: 0.9081, policy_loss: 0.8167, value_loss: 0.4290
2024-07-11 17:54:10,302 [INFO    ] __main__: train step 22861: loss: 0.9081, policy_loss: 0.8167, value_loss: 0.4290
2024-07-11 17:54:10,529 [INFO    ] __main__: train step 22862: loss: 0.9080, policy_loss: 0.8166, value_loss: 0.4289
2024-07-11 17:54:10,730 [INFO    ] __main__: train step 22863: loss: 0.9080, policy_loss: 0.8166, value_loss: 0.4289
2024-07-11 17:54:10,930 [INFO    ] __main__: train step 22864: loss: 0.9080, policy_loss: 0.8166, value_loss: 0.4289
2024-07-11 17:54:12,375 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:54:12,769 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:54:12,825 [INFO    ] __main__: train step 22865: loss: 0.9080, policy_loss: 0.8166, value_loss: 0.4289
2024-07-11 17:54:12,999 [INFO    ] __main__: train step 22866: loss: 0.9080, policy_loss: 0.8166, value_loss: 0.4289
2024-07-11 17:54:13,197 [INFO    ] __main__: train step 22867: loss: 0.9080, policy_loss: 0.8166, value_loss: 0.4289
2024-07-11 17:54:13,394 [INFO    ] __main__: train step 22868: loss: 0.9080, policy_loss: 0.8166, value_loss: 0.4289
2024-07-11 17:54:13,598 [INFO    ] __main__: train step 22869: loss: 0.9080, policy_loss: 0.8166, value_loss: 0.4288
2024-07-11 17:54:13,807 [INFO    ] __main__: train step 22870: loss: 0.9080, policy_loss: 0.8166, value_loss: 0.4288
2024-07-11 17:54:14,003 [INFO    ] __main__: train step 22871: loss: 0.9080, policy_loss: 0.8166, value_loss: 0.4288
2024-07-11 17:54:14,202 [INFO    ] __main__: train step 22872: loss: 0.9080, policy_loss: 0.8166, value_loss: 0.4288
2024-07-11 17:54:14,412 [INFO    ] __main__: train step 22873: loss: 0.9079, policy_loss: 0.8165, value_loss: 0.4288
2024-07-11 17:54:14,614 [INFO    ] __main__: train step 22874: loss: 0.9079, policy_loss: 0.8165, value_loss: 0.4288
2024-07-11 17:54:14,833 [INFO    ] __main__: train step 22875: loss: 0.9079, policy_loss: 0.8165, value_loss: 0.4287
2024-07-11 17:54:15,070 [INFO    ] __main__: train step 22876: loss: 0.9079, policy_loss: 0.8165, value_loss: 0.4287
2024-07-11 17:54:15,266 [INFO    ] __main__: train step 22877: loss: 0.9079, policy_loss: 0.8165, value_loss: 0.4287
2024-07-11 17:54:15,468 [INFO    ] __main__: train step 22878: loss: 0.9079, policy_loss: 0.8165, value_loss: 0.4287
2024-07-11 17:54:15,692 [INFO    ] __main__: train step 22879: loss: 0.9079, policy_loss: 0.8165, value_loss: 0.4287
2024-07-11 17:54:15,892 [INFO    ] __main__: train step 22880: loss: 0.9079, policy_loss: 0.8165, value_loss: 0.4287
2024-07-11 17:54:16,089 [INFO    ] __main__: train step 22881: loss: 0.9079, policy_loss: 0.8165, value_loss: 0.4287
2024-07-11 17:54:17,532 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:54:17,886 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:54:17,942 [INFO    ] __main__: train step 22882: loss: 0.9079, policy_loss: 0.8165, value_loss: 0.4286
2024-07-11 17:54:18,130 [INFO    ] __main__: train step 22883: loss: 0.9079, policy_loss: 0.8165, value_loss: 0.4286
2024-07-11 17:54:18,351 [INFO    ] __main__: train step 22884: loss: 0.9078, policy_loss: 0.8164, value_loss: 0.4286
2024-07-11 17:54:18,588 [INFO    ] __main__: train step 22885: loss: 0.9078, policy_loss: 0.8164, value_loss: 0.4286
2024-07-11 17:54:18,820 [INFO    ] __main__: train step 22886: loss: 0.9078, policy_loss: 0.8164, value_loss: 0.4286
2024-07-11 17:54:19,018 [INFO    ] __main__: train step 22887: loss: 0.9078, policy_loss: 0.8164, value_loss: 0.4286
2024-07-11 17:54:19,233 [INFO    ] __main__: train step 22888: loss: 0.9078, policy_loss: 0.8164, value_loss: 0.4286
2024-07-11 17:54:19,467 [INFO    ] __main__: train step 22889: loss: 0.9078, policy_loss: 0.8164, value_loss: 0.4285
2024-07-11 17:54:19,673 [INFO    ] __main__: train step 22890: loss: 0.9078, policy_loss: 0.8164, value_loss: 0.4285
2024-07-11 17:54:19,893 [INFO    ] __main__: train step 22891: loss: 0.9078, policy_loss: 0.8164, value_loss: 0.4285
2024-07-11 17:54:20,088 [INFO    ] __main__: train step 22892: loss: 0.9078, policy_loss: 0.8164, value_loss: 0.4285
2024-07-11 17:54:20,291 [INFO    ] __main__: train step 22893: loss: 0.9078, policy_loss: 0.8164, value_loss: 0.4285
2024-07-11 17:54:20,508 [INFO    ] __main__: train step 22894: loss: 0.9077, policy_loss: 0.8164, value_loss: 0.4285
2024-07-11 17:54:20,745 [INFO    ] __main__: train step 22895: loss: 0.9077, policy_loss: 0.8163, value_loss: 0.4284
2024-07-11 17:54:20,950 [INFO    ] __main__: train step 22896: loss: 0.9077, policy_loss: 0.8163, value_loss: 0.4284
2024-07-11 17:54:21,162 [INFO    ] __main__: train step 22897: loss: 0.9077, policy_loss: 0.8163, value_loss: 0.4284
2024-07-11 17:54:21,363 [INFO    ] __main__: train step 22898: loss: 0.9077, policy_loss: 0.8163, value_loss: 0.4284
2024-07-11 17:54:22,827 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:54:23,210 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:54:23,267 [INFO    ] __main__: train step 22899: loss: 0.9077, policy_loss: 0.8163, value_loss: 0.4284
2024-07-11 17:54:23,446 [INFO    ] __main__: train step 22900: loss: 0.9077, policy_loss: 0.8163, value_loss: 0.4284
2024-07-11 17:54:23,648 [INFO    ] __main__: train step 22901: loss: 0.9077, policy_loss: 0.8163, value_loss: 0.4284
2024-07-11 17:54:23,853 [INFO    ] __main__: train step 22902: loss: 0.9077, policy_loss: 0.8163, value_loss: 0.4283
2024-07-11 17:54:24,068 [INFO    ] __main__: train step 22903: loss: 0.9077, policy_loss: 0.8163, value_loss: 0.4283
2024-07-11 17:54:24,269 [INFO    ] __main__: train step 22904: loss: 0.9077, policy_loss: 0.8163, value_loss: 0.4283
2024-07-11 17:54:24,484 [INFO    ] __main__: train step 22905: loss: 0.9076, policy_loss: 0.8163, value_loss: 0.4283
2024-07-11 17:54:24,696 [INFO    ] __main__: train step 22906: loss: 0.9076, policy_loss: 0.8162, value_loss: 0.4283
2024-07-11 17:54:24,898 [INFO    ] __main__: train step 22907: loss: 0.9076, policy_loss: 0.8162, value_loss: 0.4283
2024-07-11 17:54:27,313 [INFO    ] __main__: train step 22908: loss: 0.9076, policy_loss: 0.8162, value_loss: 0.4282
2024-07-11 17:54:27,528 [INFO    ] __main__: train step 22909: loss: 0.9076, policy_loss: 0.8162, value_loss: 0.4282
2024-07-11 17:54:27,736 [INFO    ] __main__: train step 22910: loss: 0.9076, policy_loss: 0.8162, value_loss: 0.4282
2024-07-11 17:54:27,952 [INFO    ] __main__: train step 22911: loss: 0.9076, policy_loss: 0.8162, value_loss: 0.4282
2024-07-11 17:54:28,183 [INFO    ] __main__: train step 22912: loss: 0.9076, policy_loss: 0.8162, value_loss: 0.4282
2024-07-11 17:54:28,414 [INFO    ] __main__: train step 22913: loss: 0.9076, policy_loss: 0.8162, value_loss: 0.4282
2024-07-11 17:54:28,624 [INFO    ] __main__: train step 22914: loss: 0.9076, policy_loss: 0.8162, value_loss: 0.4282
2024-07-11 17:54:28,819 [INFO    ] __main__: train step 22915: loss: 0.9075, policy_loss: 0.8162, value_loss: 0.4281
2024-07-11 17:54:30,276 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:54:30,670 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:54:30,725 [INFO    ] __main__: train step 22916: loss: 0.9075, policy_loss: 0.8162, value_loss: 0.4281
2024-07-11 17:54:30,905 [INFO    ] __main__: train step 22917: loss: 0.9075, policy_loss: 0.8161, value_loss: 0.4281
2024-07-11 17:54:31,124 [INFO    ] __main__: train step 22918: loss: 0.9075, policy_loss: 0.8161, value_loss: 0.4281
2024-07-11 17:54:31,333 [INFO    ] __main__: train step 22919: loss: 0.9075, policy_loss: 0.8161, value_loss: 0.4281
2024-07-11 17:54:31,550 [INFO    ] __main__: train step 22920: loss: 0.9075, policy_loss: 0.8161, value_loss: 0.4281
2024-07-11 17:54:31,772 [INFO    ] __main__: train step 22921: loss: 0.9075, policy_loss: 0.8161, value_loss: 0.4280
2024-07-11 17:54:32,012 [INFO    ] __main__: train step 22922: loss: 0.9075, policy_loss: 0.8161, value_loss: 0.4280
2024-07-11 17:54:32,231 [INFO    ] __main__: train step 22923: loss: 0.9075, policy_loss: 0.8161, value_loss: 0.4280
2024-07-11 17:54:32,433 [INFO    ] __main__: train step 22924: loss: 0.9075, policy_loss: 0.8161, value_loss: 0.4280
2024-07-11 17:54:32,644 [INFO    ] __main__: train step 22925: loss: 0.9075, policy_loss: 0.8161, value_loss: 0.4280
2024-07-11 17:54:32,858 [INFO    ] __main__: train step 22926: loss: 0.9074, policy_loss: 0.8161, value_loss: 0.4280
2024-07-11 17:54:33,065 [INFO    ] __main__: train step 22927: loss: 0.9074, policy_loss: 0.8161, value_loss: 0.4280
2024-07-11 17:54:33,276 [INFO    ] __main__: train step 22928: loss: 0.9074, policy_loss: 0.8160, value_loss: 0.4279
2024-07-11 17:54:33,476 [INFO    ] __main__: train step 22929: loss: 0.9074, policy_loss: 0.8160, value_loss: 0.4279
2024-07-11 17:54:33,696 [INFO    ] __main__: train step 22930: loss: 0.9074, policy_loss: 0.8160, value_loss: 0.4279
2024-07-11 17:54:33,915 [INFO    ] __main__: train step 22931: loss: 0.9074, policy_loss: 0.8160, value_loss: 0.4279
2024-07-11 17:54:34,118 [INFO    ] __main__: train step 22932: loss: 0.9074, policy_loss: 0.8160, value_loss: 0.4279
2024-07-11 17:54:35,552 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:54:35,992 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:54:36,048 [INFO    ] __main__: train step 22933: loss: 0.9074, policy_loss: 0.8160, value_loss: 0.4279
2024-07-11 17:54:36,247 [INFO    ] __main__: train step 22934: loss: 0.9074, policy_loss: 0.8160, value_loss: 0.4279
2024-07-11 17:54:36,448 [INFO    ] __main__: train step 22935: loss: 0.9074, policy_loss: 0.8160, value_loss: 0.4278
2024-07-11 17:54:36,647 [INFO    ] __main__: train step 22936: loss: 0.9073, policy_loss: 0.8160, value_loss: 0.4278
2024-07-11 17:54:36,850 [INFO    ] __main__: train step 22937: loss: 0.9073, policy_loss: 0.8160, value_loss: 0.4278
2024-07-11 17:54:37,060 [INFO    ] __main__: train step 22938: loss: 0.9073, policy_loss: 0.8160, value_loss: 0.4278
2024-07-11 17:54:37,264 [INFO    ] __main__: train step 22939: loss: 0.9073, policy_loss: 0.8159, value_loss: 0.4278
2024-07-11 17:54:37,483 [INFO    ] __main__: train step 22940: loss: 0.9073, policy_loss: 0.8159, value_loss: 0.4278
2024-07-11 17:54:37,706 [INFO    ] __main__: train step 22941: loss: 0.9073, policy_loss: 0.8159, value_loss: 0.4277
2024-07-11 17:54:37,940 [INFO    ] __main__: train step 22942: loss: 0.9073, policy_loss: 0.8159, value_loss: 0.4277
2024-07-11 17:54:38,145 [INFO    ] __main__: train step 22943: loss: 0.9073, policy_loss: 0.8159, value_loss: 0.4277
2024-07-11 17:54:38,347 [INFO    ] __main__: train step 22944: loss: 0.9073, policy_loss: 0.8159, value_loss: 0.4277
2024-07-11 17:54:38,555 [INFO    ] __main__: train step 22945: loss: 0.9073, policy_loss: 0.8159, value_loss: 0.4277
2024-07-11 17:54:38,785 [INFO    ] __main__: train step 22946: loss: 0.9072, policy_loss: 0.8159, value_loss: 0.4277
2024-07-11 17:54:38,986 [INFO    ] __main__: train step 22947: loss: 0.9072, policy_loss: 0.8159, value_loss: 0.4277
2024-07-11 17:54:39,198 [INFO    ] __main__: train step 22948: loss: 0.9072, policy_loss: 0.8159, value_loss: 0.4276
2024-07-11 17:54:39,409 [INFO    ] __main__: train step 22949: loss: 0.9072, policy_loss: 0.8159, value_loss: 0.4276
2024-07-11 17:54:40,884 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:54:41,305 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:54:41,369 [INFO    ] __main__: train step 22950: loss: 0.9072, policy_loss: 0.8158, value_loss: 0.4276
2024-07-11 17:54:41,554 [INFO    ] __main__: train step 22951: loss: 0.9072, policy_loss: 0.8158, value_loss: 0.4276
2024-07-11 17:54:41,792 [INFO    ] __main__: train step 22952: loss: 0.9072, policy_loss: 0.8158, value_loss: 0.4276
2024-07-11 17:54:41,999 [INFO    ] __main__: train step 22953: loss: 0.9072, policy_loss: 0.8158, value_loss: 0.4276
2024-07-11 17:54:42,230 [INFO    ] __main__: train step 22954: loss: 0.9072, policy_loss: 0.8158, value_loss: 0.4275
2024-07-11 17:54:42,435 [INFO    ] __main__: train step 22955: loss: 0.9072, policy_loss: 0.8158, value_loss: 0.4275
2024-07-11 17:54:42,647 [INFO    ] __main__: train step 22956: loss: 0.9071, policy_loss: 0.8158, value_loss: 0.4275
2024-07-11 17:54:42,856 [INFO    ] __main__: train step 22957: loss: 0.9071, policy_loss: 0.8158, value_loss: 0.4275
2024-07-11 17:54:43,067 [INFO    ] __main__: train step 22958: loss: 0.9071, policy_loss: 0.8158, value_loss: 0.4275
2024-07-11 17:54:43,308 [INFO    ] __main__: train step 22959: loss: 0.9071, policy_loss: 0.8158, value_loss: 0.4275
2024-07-11 17:54:43,506 [INFO    ] __main__: train step 22960: loss: 0.9071, policy_loss: 0.8158, value_loss: 0.4275
2024-07-11 17:54:43,718 [INFO    ] __main__: train step 22961: loss: 0.9071, policy_loss: 0.8157, value_loss: 0.4274
2024-07-11 17:54:43,918 [INFO    ] __main__: train step 22962: loss: 0.9071, policy_loss: 0.8157, value_loss: 0.4274
2024-07-11 17:54:44,132 [INFO    ] __main__: train step 22963: loss: 0.9071, policy_loss: 0.8157, value_loss: 0.4274
2024-07-11 17:54:44,356 [INFO    ] __main__: train step 22964: loss: 0.9071, policy_loss: 0.8157, value_loss: 0.4274
2024-07-11 17:54:44,561 [INFO    ] __main__: train step 22965: loss: 0.9071, policy_loss: 0.8157, value_loss: 0.4274
2024-07-11 17:54:44,770 [INFO    ] __main__: train step 22966: loss: 0.9071, policy_loss: 0.8157, value_loss: 0.4274
2024-07-11 17:54:46,213 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:54:46,620 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:54:46,675 [INFO    ] __main__: train step 22967: loss: 0.9070, policy_loss: 0.8157, value_loss: 0.4274
2024-07-11 17:54:46,851 [INFO    ] __main__: train step 22968: loss: 0.9070, policy_loss: 0.8157, value_loss: 0.4273
2024-07-11 17:54:47,064 [INFO    ] __main__: train step 22969: loss: 0.9070, policy_loss: 0.8157, value_loss: 0.4273
2024-07-11 17:54:47,271 [INFO    ] __main__: train step 22970: loss: 0.9070, policy_loss: 0.8157, value_loss: 0.4273
2024-07-11 17:54:47,473 [INFO    ] __main__: train step 22971: loss: 0.9070, policy_loss: 0.8156, value_loss: 0.4273
2024-07-11 17:54:47,682 [INFO    ] __main__: train step 22972: loss: 0.9070, policy_loss: 0.8156, value_loss: 0.4273
2024-07-11 17:54:47,882 [INFO    ] __main__: train step 22973: loss: 0.9070, policy_loss: 0.8156, value_loss: 0.4273
2024-07-11 17:54:48,108 [INFO    ] __main__: train step 22974: loss: 0.9070, policy_loss: 0.8156, value_loss: 0.4272
2024-07-11 17:54:48,348 [INFO    ] __main__: train step 22975: loss: 0.9070, policy_loss: 0.8156, value_loss: 0.4272
2024-07-11 17:54:48,580 [INFO    ] __main__: train step 22976: loss: 0.9070, policy_loss: 0.8156, value_loss: 0.4272
2024-07-11 17:54:48,781 [INFO    ] __main__: train step 22977: loss: 0.9069, policy_loss: 0.8156, value_loss: 0.4272
2024-07-11 17:54:48,979 [INFO    ] __main__: train step 22978: loss: 0.9069, policy_loss: 0.8156, value_loss: 0.4272
2024-07-11 17:54:49,195 [INFO    ] __main__: train step 22979: loss: 0.9069, policy_loss: 0.8156, value_loss: 0.4272
2024-07-11 17:54:49,430 [INFO    ] __main__: train step 22980: loss: 0.9069, policy_loss: 0.8156, value_loss: 0.4272
2024-07-11 17:54:49,639 [INFO    ] __main__: train step 22981: loss: 0.9069, policy_loss: 0.8156, value_loss: 0.4271
2024-07-11 17:54:49,835 [INFO    ] __main__: train step 22982: loss: 0.9069, policy_loss: 0.8155, value_loss: 0.4271
2024-07-11 17:54:50,033 [INFO    ] __main__: train step 22983: loss: 0.9069, policy_loss: 0.8155, value_loss: 0.4271
2024-07-11 17:54:51,465 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:54:51,853 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:54:51,913 [INFO    ] __main__: train step 22984: loss: 0.9069, policy_loss: 0.8155, value_loss: 0.4271
2024-07-11 17:54:52,090 [INFO    ] __main__: train step 22985: loss: 0.9069, policy_loss: 0.8155, value_loss: 0.4271
2024-07-11 17:54:52,304 [INFO    ] __main__: train step 22986: loss: 0.9068, policy_loss: 0.8155, value_loss: 0.4271
2024-07-11 17:54:52,501 [INFO    ] __main__: train step 22987: loss: 0.9068, policy_loss: 0.8155, value_loss: 0.4271
2024-07-11 17:54:52,713 [INFO    ] __main__: train step 22988: loss: 0.9068, policy_loss: 0.8155, value_loss: 0.4270
2024-07-11 17:54:52,918 [INFO    ] __main__: train step 22989: loss: 0.9068, policy_loss: 0.8155, value_loss: 0.4270
2024-07-11 17:54:53,117 [INFO    ] __main__: train step 22990: loss: 0.9068, policy_loss: 0.8155, value_loss: 0.4270
2024-07-11 17:54:53,333 [INFO    ] __main__: train step 22991: loss: 0.9068, policy_loss: 0.8155, value_loss: 0.4270
2024-07-11 17:54:53,560 [INFO    ] __main__: train step 22992: loss: 0.9068, policy_loss: 0.8154, value_loss: 0.4270
2024-07-11 17:54:53,771 [INFO    ] __main__: train step 22993: loss: 0.9068, policy_loss: 0.8154, value_loss: 0.4270
2024-07-11 17:54:53,972 [INFO    ] __main__: train step 22994: loss: 0.9068, policy_loss: 0.8154, value_loss: 0.4269
2024-07-11 17:54:54,187 [INFO    ] __main__: train step 22995: loss: 0.9068, policy_loss: 0.8154, value_loss: 0.4269
2024-07-11 17:54:54,400 [INFO    ] __main__: train step 22996: loss: 0.9068, policy_loss: 0.8154, value_loss: 0.4269
2024-07-11 17:54:54,640 [INFO    ] __main__: train step 22997: loss: 0.9067, policy_loss: 0.8154, value_loss: 0.4269
2024-07-11 17:54:54,839 [INFO    ] __main__: train step 22998: loss: 0.9067, policy_loss: 0.8154, value_loss: 0.4269
2024-07-11 17:54:55,039 [INFO    ] __main__: train step 22999: loss: 0.9067, policy_loss: 0.8154, value_loss: 0.4269
2024-07-11 17:54:55,244 [INFO    ] __main__: train step 23000: loss: 0.9067, policy_loss: 0.8154, value_loss: 0.4269
2024-07-11 17:54:55,362 [INFO    ] __main__: restored step 22000 for evaluation
2024-07-11 17:55:02,905 [INFO    ] __main__: later network ELO difference from earlier network: +248 (+8/-8) ELO from 32000 self-played games
2024-07-11 17:55:02,906 [INFO    ] __main__: game outcomes: W: 24467, D: 309, L: 7224
2024-07-11 17:55:02,907 [INFO    ] __main__: validation_elo_delta: 248, validation_elo: 3096
2024-07-11 17:55:04,699 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:55:05,094 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:55:05,153 [INFO    ] __main__: train step 23001: loss: 0.9067, policy_loss: 0.8154, value_loss: 0.4268
2024-07-11 17:55:05,335 [INFO    ] __main__: train step 23002: loss: 0.9067, policy_loss: 0.8154, value_loss: 0.4268
2024-07-11 17:55:05,528 [INFO    ] __main__: train step 23003: loss: 0.9067, policy_loss: 0.8153, value_loss: 0.4268
2024-07-11 17:55:05,738 [INFO    ] __main__: train step 23004: loss: 0.9067, policy_loss: 0.8153, value_loss: 0.4268
2024-07-11 17:55:05,956 [INFO    ] __main__: train step 23005: loss: 0.9067, policy_loss: 0.8153, value_loss: 0.4268
2024-07-11 17:55:06,178 [INFO    ] __main__: train step 23006: loss: 0.9066, policy_loss: 0.8153, value_loss: 0.4268
2024-07-11 17:55:06,399 [INFO    ] __main__: train step 23007: loss: 0.9066, policy_loss: 0.8153, value_loss: 0.4267
2024-07-11 17:55:06,624 [INFO    ] __main__: train step 23008: loss: 0.9066, policy_loss: 0.8153, value_loss: 0.4267
2024-07-11 17:55:06,824 [INFO    ] __main__: train step 23009: loss: 0.9066, policy_loss: 0.8153, value_loss: 0.4267
2024-07-11 17:55:07,023 [INFO    ] __main__: train step 23010: loss: 0.9066, policy_loss: 0.8153, value_loss: 0.4267
2024-07-11 17:55:07,224 [INFO    ] __main__: train step 23011: loss: 0.9066, policy_loss: 0.8153, value_loss: 0.4267
2024-07-11 17:55:07,425 [INFO    ] __main__: train step 23012: loss: 0.9066, policy_loss: 0.8153, value_loss: 0.4267
2024-07-11 17:55:07,631 [INFO    ] __main__: train step 23013: loss: 0.9066, policy_loss: 0.8152, value_loss: 0.4267
2024-07-11 17:55:07,839 [INFO    ] __main__: train step 23014: loss: 0.9066, policy_loss: 0.8152, value_loss: 0.4266
2024-07-11 17:55:08,045 [INFO    ] __main__: train step 23015: loss: 0.9066, policy_loss: 0.8152, value_loss: 0.4266
2024-07-11 17:55:08,270 [INFO    ] __main__: train step 23016: loss: 0.9065, policy_loss: 0.8152, value_loss: 0.4266
2024-07-11 17:55:08,509 [INFO    ] __main__: train step 23017: loss: 0.9065, policy_loss: 0.8152, value_loss: 0.4266
2024-07-11 17:55:09,933 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:55:10,307 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:55:10,364 [INFO    ] __main__: train step 23018: loss: 0.9065, policy_loss: 0.8152, value_loss: 0.4266
2024-07-11 17:55:10,540 [INFO    ] __main__: train step 23019: loss: 0.9065, policy_loss: 0.8152, value_loss: 0.4266
2024-07-11 17:55:10,748 [INFO    ] __main__: train step 23020: loss: 0.9065, policy_loss: 0.8152, value_loss: 0.4265
2024-07-11 17:55:10,974 [INFO    ] __main__: train step 23021: loss: 0.9065, policy_loss: 0.8152, value_loss: 0.4265
2024-07-11 17:55:11,182 [INFO    ] __main__: train step 23022: loss: 0.9065, policy_loss: 0.8152, value_loss: 0.4265
2024-07-11 17:55:11,389 [INFO    ] __main__: train step 23023: loss: 0.9065, policy_loss: 0.8151, value_loss: 0.4265
2024-07-11 17:55:11,606 [INFO    ] __main__: train step 23024: loss: 0.9065, policy_loss: 0.8151, value_loss: 0.4265
2024-07-11 17:55:11,850 [INFO    ] __main__: train step 23025: loss: 0.9065, policy_loss: 0.8151, value_loss: 0.4265
2024-07-11 17:55:12,101 [INFO    ] __main__: train step 23026: loss: 0.9064, policy_loss: 0.8151, value_loss: 0.4265
2024-07-11 17:55:12,321 [INFO    ] __main__: train step 23027: loss: 0.9064, policy_loss: 0.8151, value_loss: 0.4264
2024-07-11 17:55:12,553 [INFO    ] __main__: train step 23028: loss: 0.9064, policy_loss: 0.8151, value_loss: 0.4264
2024-07-11 17:55:12,777 [INFO    ] __main__: train step 23029: loss: 0.9064, policy_loss: 0.8151, value_loss: 0.4264
2024-07-11 17:55:13,001 [INFO    ] __main__: train step 23030: loss: 0.9064, policy_loss: 0.8151, value_loss: 0.4264
2024-07-11 17:55:13,216 [INFO    ] __main__: train step 23031: loss: 0.9064, policy_loss: 0.8151, value_loss: 0.4264
2024-07-11 17:55:13,423 [INFO    ] __main__: train step 23032: loss: 0.9064, policy_loss: 0.8151, value_loss: 0.4264
2024-07-11 17:55:13,625 [INFO    ] __main__: train step 23033: loss: 0.9064, policy_loss: 0.8150, value_loss: 0.4264
2024-07-11 17:55:13,832 [INFO    ] __main__: train step 23034: loss: 0.9064, policy_loss: 0.8150, value_loss: 0.4263
2024-07-11 17:55:15,284 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:55:15,647 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:55:15,711 [INFO    ] __main__: train step 23035: loss: 0.9063, policy_loss: 0.8150, value_loss: 0.4263
2024-07-11 17:55:15,882 [INFO    ] __main__: train step 23036: loss: 0.9063, policy_loss: 0.8150, value_loss: 0.4263
2024-07-11 17:55:16,083 [INFO    ] __main__: train step 23037: loss: 0.9063, policy_loss: 0.8150, value_loss: 0.4263
2024-07-11 17:55:16,298 [INFO    ] __main__: train step 23038: loss: 0.9063, policy_loss: 0.8150, value_loss: 0.4263
2024-07-11 17:55:16,502 [INFO    ] __main__: train step 23039: loss: 0.9063, policy_loss: 0.8150, value_loss: 0.4263
2024-07-11 17:55:16,706 [INFO    ] __main__: train step 23040: loss: 0.9063, policy_loss: 0.8150, value_loss: 0.4262
2024-07-11 17:55:16,905 [INFO    ] __main__: train step 23041: loss: 0.9063, policy_loss: 0.8150, value_loss: 0.4262
2024-07-11 17:55:17,106 [INFO    ] __main__: train step 23042: loss: 0.9063, policy_loss: 0.8150, value_loss: 0.4262
2024-07-11 17:55:17,309 [INFO    ] __main__: train step 23043: loss: 0.9063, policy_loss: 0.8150, value_loss: 0.4262
2024-07-11 17:55:17,520 [INFO    ] __main__: train step 23044: loss: 0.9063, policy_loss: 0.8149, value_loss: 0.4262
2024-07-11 17:55:19,980 [INFO    ] __main__: train step 23045: loss: 0.9062, policy_loss: 0.8149, value_loss: 0.4262
2024-07-11 17:55:20,232 [INFO    ] __main__: train step 23046: loss: 0.9062, policy_loss: 0.8149, value_loss: 0.4262
2024-07-11 17:55:20,474 [INFO    ] __main__: train step 23047: loss: 0.9062, policy_loss: 0.8149, value_loss: 0.4261
2024-07-11 17:55:20,687 [INFO    ] __main__: train step 23048: loss: 0.9062, policy_loss: 0.8149, value_loss: 0.4261
2024-07-11 17:55:20,934 [INFO    ] __main__: train step 23049: loss: 0.9062, policy_loss: 0.8149, value_loss: 0.4261
2024-07-11 17:55:21,145 [INFO    ] __main__: train step 23050: loss: 0.9062, policy_loss: 0.8149, value_loss: 0.4261
2024-07-11 17:55:21,375 [INFO    ] __main__: train step 23051: loss: 0.9062, policy_loss: 0.8149, value_loss: 0.4261
2024-07-11 17:55:22,822 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:55:23,241 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:55:23,298 [INFO    ] __main__: train step 23052: loss: 0.9062, policy_loss: 0.8149, value_loss: 0.4261
2024-07-11 17:55:23,489 [INFO    ] __main__: train step 23053: loss: 0.9062, policy_loss: 0.8148, value_loss: 0.4261
2024-07-11 17:55:23,723 [INFO    ] __main__: train step 23054: loss: 0.9061, policy_loss: 0.8148, value_loss: 0.4260
2024-07-11 17:55:23,930 [INFO    ] __main__: train step 23055: loss: 0.9061, policy_loss: 0.8148, value_loss: 0.4260
2024-07-11 17:55:24,139 [INFO    ] __main__: train step 23056: loss: 0.9061, policy_loss: 0.8148, value_loss: 0.4260
2024-07-11 17:55:24,365 [INFO    ] __main__: train step 23057: loss: 0.9061, policy_loss: 0.8148, value_loss: 0.4260
2024-07-11 17:55:24,579 [INFO    ] __main__: train step 23058: loss: 0.9061, policy_loss: 0.8148, value_loss: 0.4260
2024-07-11 17:55:24,817 [INFO    ] __main__: train step 23059: loss: 0.9061, policy_loss: 0.8148, value_loss: 0.4260
2024-07-11 17:55:25,023 [INFO    ] __main__: train step 23060: loss: 0.9061, policy_loss: 0.8148, value_loss: 0.4259
2024-07-11 17:55:25,226 [INFO    ] __main__: train step 23061: loss: 0.9061, policy_loss: 0.8148, value_loss: 0.4259
2024-07-11 17:55:25,439 [INFO    ] __main__: train step 23062: loss: 0.9061, policy_loss: 0.8148, value_loss: 0.4259
2024-07-11 17:55:25,640 [INFO    ] __main__: train step 23063: loss: 0.9061, policy_loss: 0.8148, value_loss: 0.4259
2024-07-11 17:55:25,838 [INFO    ] __main__: train step 23064: loss: 0.9060, policy_loss: 0.8147, value_loss: 0.4259
2024-07-11 17:55:26,044 [INFO    ] __main__: train step 23065: loss: 0.9060, policy_loss: 0.8147, value_loss: 0.4259
2024-07-11 17:55:26,243 [INFO    ] __main__: train step 23066: loss: 0.9060, policy_loss: 0.8147, value_loss: 0.4259
2024-07-11 17:55:26,451 [INFO    ] __main__: train step 23067: loss: 0.9060, policy_loss: 0.8147, value_loss: 0.4258
2024-07-11 17:55:26,665 [INFO    ] __main__: train step 23068: loss: 0.9060, policy_loss: 0.8147, value_loss: 0.4258
2024-07-11 17:55:28,127 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:55:28,527 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:55:28,590 [INFO    ] __main__: train step 23069: loss: 0.9060, policy_loss: 0.8147, value_loss: 0.4258
2024-07-11 17:55:28,766 [INFO    ] __main__: train step 23070: loss: 0.9060, policy_loss: 0.8147, value_loss: 0.4258
2024-07-11 17:55:28,977 [INFO    ] __main__: train step 23071: loss: 0.9060, policy_loss: 0.8147, value_loss: 0.4258
2024-07-11 17:55:29,187 [INFO    ] __main__: train step 23072: loss: 0.9060, policy_loss: 0.8147, value_loss: 0.4258
2024-07-11 17:55:29,386 [INFO    ] __main__: train step 23073: loss: 0.9059, policy_loss: 0.8146, value_loss: 0.4258
2024-07-11 17:55:29,590 [INFO    ] __main__: train step 23074: loss: 0.9059, policy_loss: 0.8146, value_loss: 0.4257
2024-07-11 17:55:29,802 [INFO    ] __main__: train step 23075: loss: 0.9059, policy_loss: 0.8146, value_loss: 0.4257
2024-07-11 17:55:30,015 [INFO    ] __main__: train step 23076: loss: 0.9059, policy_loss: 0.8146, value_loss: 0.4257
2024-07-11 17:55:30,233 [INFO    ] __main__: train step 23077: loss: 0.9059, policy_loss: 0.8146, value_loss: 0.4257
2024-07-11 17:55:30,436 [INFO    ] __main__: train step 23078: loss: 0.9059, policy_loss: 0.8146, value_loss: 0.4257
2024-07-11 17:55:30,667 [INFO    ] __main__: train step 23079: loss: 0.9059, policy_loss: 0.8146, value_loss: 0.4257
2024-07-11 17:55:30,899 [INFO    ] __main__: train step 23080: loss: 0.9059, policy_loss: 0.8146, value_loss: 0.4256
2024-07-11 17:55:31,101 [INFO    ] __main__: train step 23081: loss: 0.9059, policy_loss: 0.8146, value_loss: 0.4256
2024-07-11 17:55:31,305 [INFO    ] __main__: train step 23082: loss: 0.9058, policy_loss: 0.8146, value_loss: 0.4256
2024-07-11 17:55:31,516 [INFO    ] __main__: train step 23083: loss: 0.9058, policy_loss: 0.8145, value_loss: 0.4256
2024-07-11 17:55:31,728 [INFO    ] __main__: train step 23084: loss: 0.9058, policy_loss: 0.8145, value_loss: 0.4256
2024-07-11 17:55:31,936 [INFO    ] __main__: train step 23085: loss: 0.9058, policy_loss: 0.8145, value_loss: 0.4256
2024-07-11 17:55:33,381 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:55:33,752 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:55:33,806 [INFO    ] __main__: train step 23086: loss: 0.9058, policy_loss: 0.8145, value_loss: 0.4256
2024-07-11 17:55:33,992 [INFO    ] __main__: train step 23087: loss: 0.9058, policy_loss: 0.8145, value_loss: 0.4255
2024-07-11 17:55:34,186 [INFO    ] __main__: train step 23088: loss: 0.9058, policy_loss: 0.8145, value_loss: 0.4255
2024-07-11 17:55:34,398 [INFO    ] __main__: train step 23089: loss: 0.9058, policy_loss: 0.8145, value_loss: 0.4255
2024-07-11 17:55:34,605 [INFO    ] __main__: train step 23090: loss: 0.9058, policy_loss: 0.8145, value_loss: 0.4255
2024-07-11 17:55:34,816 [INFO    ] __main__: train step 23091: loss: 0.9057, policy_loss: 0.8145, value_loss: 0.4255
2024-07-11 17:55:35,016 [INFO    ] __main__: train step 23092: loss: 0.9057, policy_loss: 0.8145, value_loss: 0.4255
2024-07-11 17:55:35,211 [INFO    ] __main__: train step 23093: loss: 0.9057, policy_loss: 0.8144, value_loss: 0.4254
2024-07-11 17:55:35,423 [INFO    ] __main__: train step 23094: loss: 0.9057, policy_loss: 0.8144, value_loss: 0.4254
2024-07-11 17:55:35,638 [INFO    ] __main__: train step 23095: loss: 0.9057, policy_loss: 0.8144, value_loss: 0.4254
2024-07-11 17:55:35,844 [INFO    ] __main__: train step 23096: loss: 0.9057, policy_loss: 0.8144, value_loss: 0.4254
2024-07-11 17:55:36,045 [INFO    ] __main__: train step 23097: loss: 0.9057, policy_loss: 0.8144, value_loss: 0.4254
2024-07-11 17:55:36,252 [INFO    ] __main__: train step 23098: loss: 0.9057, policy_loss: 0.8144, value_loss: 0.4254
2024-07-11 17:55:36,462 [INFO    ] __main__: train step 23099: loss: 0.9057, policy_loss: 0.8144, value_loss: 0.4254
2024-07-11 17:55:36,687 [INFO    ] __main__: train step 23100: loss: 0.9057, policy_loss: 0.8144, value_loss: 0.4253
2024-07-11 17:55:36,917 [INFO    ] __main__: train step 23101: loss: 0.9056, policy_loss: 0.8144, value_loss: 0.4253
2024-07-11 17:55:37,123 [INFO    ] __main__: train step 23102: loss: 0.9056, policy_loss: 0.8143, value_loss: 0.4253
2024-07-11 17:55:38,543 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:55:38,910 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:55:38,971 [INFO    ] __main__: train step 23103: loss: 0.9056, policy_loss: 0.8143, value_loss: 0.4253
2024-07-11 17:55:39,154 [INFO    ] __main__: train step 23104: loss: 0.9056, policy_loss: 0.8143, value_loss: 0.4253
2024-07-11 17:55:39,415 [INFO    ] __main__: train step 23105: loss: 0.9056, policy_loss: 0.8143, value_loss: 0.4253
2024-07-11 17:55:39,654 [INFO    ] __main__: train step 23106: loss: 0.9056, policy_loss: 0.8143, value_loss: 0.4253
2024-07-11 17:55:39,883 [INFO    ] __main__: train step 23107: loss: 0.9056, policy_loss: 0.8143, value_loss: 0.4252
2024-07-11 17:55:40,083 [INFO    ] __main__: train step 23108: loss: 0.9056, policy_loss: 0.8143, value_loss: 0.4252
2024-07-11 17:55:40,289 [INFO    ] __main__: train step 23109: loss: 0.9055, policy_loss: 0.8143, value_loss: 0.4252
2024-07-11 17:55:40,495 [INFO    ] __main__: train step 23110: loss: 0.9055, policy_loss: 0.8143, value_loss: 0.4252
2024-07-11 17:55:40,711 [INFO    ] __main__: train step 23111: loss: 0.9055, policy_loss: 0.8143, value_loss: 0.4252
2024-07-11 17:55:40,915 [INFO    ] __main__: train step 23112: loss: 0.9055, policy_loss: 0.8142, value_loss: 0.4252
2024-07-11 17:55:41,120 [INFO    ] __main__: train step 23113: loss: 0.9055, policy_loss: 0.8142, value_loss: 0.4251
2024-07-11 17:55:41,330 [INFO    ] __main__: train step 23114: loss: 0.9055, policy_loss: 0.8142, value_loss: 0.4251
2024-07-11 17:55:41,548 [INFO    ] __main__: train step 23115: loss: 0.9055, policy_loss: 0.8142, value_loss: 0.4251
2024-07-11 17:55:41,786 [INFO    ] __main__: train step 23116: loss: 0.9055, policy_loss: 0.8142, value_loss: 0.4251
2024-07-11 17:55:41,999 [INFO    ] __main__: train step 23117: loss: 0.9055, policy_loss: 0.8142, value_loss: 0.4251
2024-07-11 17:55:42,214 [INFO    ] __main__: train step 23118: loss: 0.9054, policy_loss: 0.8142, value_loss: 0.4251
2024-07-11 17:55:42,420 [INFO    ] __main__: train step 23119: loss: 0.9054, policy_loss: 0.8142, value_loss: 0.4251
2024-07-11 17:55:43,868 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:55:44,262 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:55:44,324 [INFO    ] __main__: train step 23120: loss: 0.9054, policy_loss: 0.8142, value_loss: 0.4250
2024-07-11 17:55:44,501 [INFO    ] __main__: train step 23121: loss: 0.9054, policy_loss: 0.8141, value_loss: 0.4250
2024-07-11 17:55:44,714 [INFO    ] __main__: train step 23122: loss: 0.9054, policy_loss: 0.8141, value_loss: 0.4250
2024-07-11 17:55:44,950 [INFO    ] __main__: train step 23123: loss: 0.9054, policy_loss: 0.8141, value_loss: 0.4250
2024-07-11 17:55:45,172 [INFO    ] __main__: train step 23124: loss: 0.9054, policy_loss: 0.8141, value_loss: 0.4250
2024-07-11 17:55:45,401 [INFO    ] __main__: train step 23125: loss: 0.9054, policy_loss: 0.8141, value_loss: 0.4250
2024-07-11 17:55:45,648 [INFO    ] __main__: train step 23126: loss: 0.9054, policy_loss: 0.8141, value_loss: 0.4249
2024-07-11 17:55:45,886 [INFO    ] __main__: train step 23127: loss: 0.9053, policy_loss: 0.8141, value_loss: 0.4249
2024-07-11 17:55:46,119 [INFO    ] __main__: train step 23128: loss: 0.9053, policy_loss: 0.8141, value_loss: 0.4249
2024-07-11 17:55:46,332 [INFO    ] __main__: train step 23129: loss: 0.9053, policy_loss: 0.8141, value_loss: 0.4249
2024-07-11 17:55:46,559 [INFO    ] __main__: train step 23130: loss: 0.9053, policy_loss: 0.8141, value_loss: 0.4249
2024-07-11 17:55:46,771 [INFO    ] __main__: train step 23131: loss: 0.9053, policy_loss: 0.8140, value_loss: 0.4249
2024-07-11 17:55:46,973 [INFO    ] __main__: train step 23132: loss: 0.9053, policy_loss: 0.8140, value_loss: 0.4249
2024-07-11 17:55:47,207 [INFO    ] __main__: train step 23133: loss: 0.9053, policy_loss: 0.8140, value_loss: 0.4248
2024-07-11 17:55:47,419 [INFO    ] __main__: train step 23134: loss: 0.9053, policy_loss: 0.8140, value_loss: 0.4248
2024-07-11 17:55:47,652 [INFO    ] __main__: train step 23135: loss: 0.9053, policy_loss: 0.8140, value_loss: 0.4248
2024-07-11 17:55:47,860 [INFO    ] __main__: train step 23136: loss: 0.9052, policy_loss: 0.8140, value_loss: 0.4248
2024-07-11 17:55:49,337 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:55:49,687 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:55:49,742 [INFO    ] __main__: train step 23137: loss: 0.9052, policy_loss: 0.8140, value_loss: 0.4248
2024-07-11 17:55:49,914 [INFO    ] __main__: train step 23138: loss: 0.9052, policy_loss: 0.8140, value_loss: 0.4248
2024-07-11 17:55:50,124 [INFO    ] __main__: train step 23139: loss: 0.9052, policy_loss: 0.8140, value_loss: 0.4248
2024-07-11 17:55:50,334 [INFO    ] __main__: train step 23140: loss: 0.9052, policy_loss: 0.8140, value_loss: 0.4247
2024-07-11 17:55:50,563 [INFO    ] __main__: train step 23141: loss: 0.9052, policy_loss: 0.8139, value_loss: 0.4247
2024-07-11 17:55:50,782 [INFO    ] __main__: train step 23142: loss: 0.9052, policy_loss: 0.8139, value_loss: 0.4247
2024-07-11 17:55:50,988 [INFO    ] __main__: train step 23143: loss: 0.9052, policy_loss: 0.8139, value_loss: 0.4247
2024-07-11 17:55:51,211 [INFO    ] __main__: train step 23144: loss: 0.9052, policy_loss: 0.8139, value_loss: 0.4247
2024-07-11 17:55:51,424 [INFO    ] __main__: train step 23145: loss: 0.9051, policy_loss: 0.8139, value_loss: 0.4247
2024-07-11 17:55:51,639 [INFO    ] __main__: train step 23146: loss: 0.9051, policy_loss: 0.8139, value_loss: 0.4246
2024-07-11 17:55:51,839 [INFO    ] __main__: train step 23147: loss: 0.9051, policy_loss: 0.8139, value_loss: 0.4246
2024-07-11 17:55:52,066 [INFO    ] __main__: train step 23148: loss: 0.9051, policy_loss: 0.8139, value_loss: 0.4246
2024-07-11 17:55:52,291 [INFO    ] __main__: train step 23149: loss: 0.9051, policy_loss: 0.8139, value_loss: 0.4246
2024-07-11 17:55:52,495 [INFO    ] __main__: train step 23150: loss: 0.9051, policy_loss: 0.8138, value_loss: 0.4246
2024-07-11 17:55:52,703 [INFO    ] __main__: train step 23151: loss: 0.9051, policy_loss: 0.8138, value_loss: 0.4246
2024-07-11 17:55:52,907 [INFO    ] __main__: train step 23152: loss: 0.9051, policy_loss: 0.8138, value_loss: 0.4246
2024-07-11 17:55:53,115 [INFO    ] __main__: train step 23153: loss: 0.9051, policy_loss: 0.8138, value_loss: 0.4245
2024-07-11 17:55:54,552 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:55:54,887 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:55:54,944 [INFO    ] __main__: train step 23154: loss: 0.9050, policy_loss: 0.8138, value_loss: 0.4245
2024-07-11 17:55:55,138 [INFO    ] __main__: train step 23155: loss: 0.9050, policy_loss: 0.8138, value_loss: 0.4245
2024-07-11 17:55:55,365 [INFO    ] __main__: train step 23156: loss: 0.9050, policy_loss: 0.8138, value_loss: 0.4245
2024-07-11 17:55:55,572 [INFO    ] __main__: train step 23157: loss: 0.9050, policy_loss: 0.8138, value_loss: 0.4245
2024-07-11 17:55:55,773 [INFO    ] __main__: train step 23158: loss: 0.9050, policy_loss: 0.8138, value_loss: 0.4245
2024-07-11 17:55:55,978 [INFO    ] __main__: train step 23159: loss: 0.9050, policy_loss: 0.8137, value_loss: 0.4244
2024-07-11 17:55:56,182 [INFO    ] __main__: train step 23160: loss: 0.9050, policy_loss: 0.8137, value_loss: 0.4244
2024-07-11 17:55:56,388 [INFO    ] __main__: train step 23161: loss: 0.9050, policy_loss: 0.8137, value_loss: 0.4244
2024-07-11 17:55:56,589 [INFO    ] __main__: train step 23162: loss: 0.9050, policy_loss: 0.8137, value_loss: 0.4244
2024-07-11 17:55:56,802 [INFO    ] __main__: train step 23163: loss: 0.9049, policy_loss: 0.8137, value_loss: 0.4244
2024-07-11 17:55:57,014 [INFO    ] __main__: train step 23164: loss: 0.9049, policy_loss: 0.8137, value_loss: 0.4244
2024-07-11 17:55:57,232 [INFO    ] __main__: train step 23165: loss: 0.9049, policy_loss: 0.8137, value_loss: 0.4244
2024-07-11 17:55:57,455 [INFO    ] __main__: train step 23166: loss: 0.9049, policy_loss: 0.8137, value_loss: 0.4243
2024-07-11 17:55:57,672 [INFO    ] __main__: train step 23167: loss: 0.9049, policy_loss: 0.8137, value_loss: 0.4243
2024-07-11 17:55:57,906 [INFO    ] __main__: train step 23168: loss: 0.9049, policy_loss: 0.8137, value_loss: 0.4243
2024-07-11 17:55:58,110 [INFO    ] __main__: train step 23169: loss: 0.9049, policy_loss: 0.8136, value_loss: 0.4243
2024-07-11 17:55:58,313 [INFO    ] __main__: train step 23170: loss: 0.9049, policy_loss: 0.8136, value_loss: 0.4243
2024-07-11 17:55:59,752 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:56:00,118 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:56:00,173 [INFO    ] __main__: train step 23171: loss: 0.9048, policy_loss: 0.8136, value_loss: 0.4243
2024-07-11 17:56:00,361 [INFO    ] __main__: train step 23172: loss: 0.9048, policy_loss: 0.8136, value_loss: 0.4243
2024-07-11 17:56:00,573 [INFO    ] __main__: train step 23173: loss: 0.9048, policy_loss: 0.8136, value_loss: 0.4242
2024-07-11 17:56:00,794 [INFO    ] __main__: train step 23174: loss: 0.9048, policy_loss: 0.8136, value_loss: 0.4242
2024-07-11 17:56:01,001 [INFO    ] __main__: train step 23175: loss: 0.9048, policy_loss: 0.8136, value_loss: 0.4242
2024-07-11 17:56:01,208 [INFO    ] __main__: train step 23176: loss: 0.9048, policy_loss: 0.8136, value_loss: 0.4242
2024-07-11 17:56:01,413 [INFO    ] __main__: train step 23177: loss: 0.9048, policy_loss: 0.8136, value_loss: 0.4242
2024-07-11 17:56:01,620 [INFO    ] __main__: train step 23178: loss: 0.9048, policy_loss: 0.8135, value_loss: 0.4242
2024-07-11 17:56:01,846 [INFO    ] __main__: train step 23179: loss: 0.9048, policy_loss: 0.8135, value_loss: 0.4241
2024-07-11 17:56:02,062 [INFO    ] __main__: train step 23180: loss: 0.9047, policy_loss: 0.8135, value_loss: 0.4241
2024-07-11 17:56:02,293 [INFO    ] __main__: train step 23181: loss: 0.9047, policy_loss: 0.8135, value_loss: 0.4241
2024-07-11 17:56:02,507 [INFO    ] __main__: train step 23182: loss: 0.9047, policy_loss: 0.8135, value_loss: 0.4241
2024-07-11 17:56:02,704 [INFO    ] __main__: train step 23183: loss: 0.9047, policy_loss: 0.8135, value_loss: 0.4241
2024-07-11 17:56:02,936 [INFO    ] __main__: train step 23184: loss: 0.9047, policy_loss: 0.8135, value_loss: 0.4241
2024-07-11 17:56:05,407 [INFO    ] __main__: train step 23185: loss: 0.9047, policy_loss: 0.8135, value_loss: 0.4241
2024-07-11 17:56:05,604 [INFO    ] __main__: train step 23186: loss: 0.9047, policy_loss: 0.8135, value_loss: 0.4240
2024-07-11 17:56:05,832 [INFO    ] __main__: train step 23187: loss: 0.9047, policy_loss: 0.8134, value_loss: 0.4240
2024-07-11 17:56:07,300 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:56:07,657 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:56:07,712 [INFO    ] __main__: train step 23188: loss: 0.9047, policy_loss: 0.8134, value_loss: 0.4240
2024-07-11 17:56:07,895 [INFO    ] __main__: train step 23189: loss: 0.9046, policy_loss: 0.8134, value_loss: 0.4240
2024-07-11 17:56:08,096 [INFO    ] __main__: train step 23190: loss: 0.9046, policy_loss: 0.8134, value_loss: 0.4240
2024-07-11 17:56:08,302 [INFO    ] __main__: train step 23191: loss: 0.9046, policy_loss: 0.8134, value_loss: 0.4240
2024-07-11 17:56:08,504 [INFO    ] __main__: train step 23192: loss: 0.9046, policy_loss: 0.8134, value_loss: 0.4240
2024-07-11 17:56:08,718 [INFO    ] __main__: train step 23193: loss: 0.9046, policy_loss: 0.8134, value_loss: 0.4239
2024-07-11 17:56:08,966 [INFO    ] __main__: train step 23194: loss: 0.9046, policy_loss: 0.8134, value_loss: 0.4239
2024-07-11 17:56:09,215 [INFO    ] __main__: train step 23195: loss: 0.9046, policy_loss: 0.8134, value_loss: 0.4239
2024-07-11 17:56:09,442 [INFO    ] __main__: train step 23196: loss: 0.9046, policy_loss: 0.8133, value_loss: 0.4239
2024-07-11 17:56:09,650 [INFO    ] __main__: train step 23197: loss: 0.9045, policy_loss: 0.8133, value_loss: 0.4239
2024-07-11 17:56:09,855 [INFO    ] __main__: train step 23198: loss: 0.9045, policy_loss: 0.8133, value_loss: 0.4239
2024-07-11 17:56:10,063 [INFO    ] __main__: train step 23199: loss: 0.9045, policy_loss: 0.8133, value_loss: 0.4238
2024-07-11 17:56:10,270 [INFO    ] __main__: train step 23200: loss: 0.9045, policy_loss: 0.8133, value_loss: 0.4238
2024-07-11 17:56:10,473 [INFO    ] __main__: train step 23201: loss: 0.9045, policy_loss: 0.8133, value_loss: 0.4238
2024-07-11 17:56:10,680 [INFO    ] __main__: train step 23202: loss: 0.9045, policy_loss: 0.8133, value_loss: 0.4238
2024-07-11 17:56:10,878 [INFO    ] __main__: train step 23203: loss: 0.9045, policy_loss: 0.8133, value_loss: 0.4238
2024-07-11 17:56:11,088 [INFO    ] __main__: train step 23204: loss: 0.9045, policy_loss: 0.8133, value_loss: 0.4238
2024-07-11 17:56:12,524 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:56:12,870 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:56:12,926 [INFO    ] __main__: train step 23205: loss: 0.9045, policy_loss: 0.8132, value_loss: 0.4238
2024-07-11 17:56:13,115 [INFO    ] __main__: train step 23206: loss: 0.9044, policy_loss: 0.8132, value_loss: 0.4237
2024-07-11 17:56:13,325 [INFO    ] __main__: train step 23207: loss: 0.9044, policy_loss: 0.8132, value_loss: 0.4237
2024-07-11 17:56:13,532 [INFO    ] __main__: train step 23208: loss: 0.9044, policy_loss: 0.8132, value_loss: 0.4237
2024-07-11 17:56:13,740 [INFO    ] __main__: train step 23209: loss: 0.9044, policy_loss: 0.8132, value_loss: 0.4237
2024-07-11 17:56:13,950 [INFO    ] __main__: train step 23210: loss: 0.9044, policy_loss: 0.8132, value_loss: 0.4237
2024-07-11 17:56:14,158 [INFO    ] __main__: train step 23211: loss: 0.9044, policy_loss: 0.8132, value_loss: 0.4237
2024-07-11 17:56:14,368 [INFO    ] __main__: train step 23212: loss: 0.9044, policy_loss: 0.8132, value_loss: 0.4237
2024-07-11 17:56:14,580 [INFO    ] __main__: train step 23213: loss: 0.9044, policy_loss: 0.8132, value_loss: 0.4236
2024-07-11 17:56:14,793 [INFO    ] __main__: train step 23214: loss: 0.9043, policy_loss: 0.8131, value_loss: 0.4236
2024-07-11 17:56:15,005 [INFO    ] __main__: train step 23215: loss: 0.9043, policy_loss: 0.8131, value_loss: 0.4236
2024-07-11 17:56:15,212 [INFO    ] __main__: train step 23216: loss: 0.9043, policy_loss: 0.8131, value_loss: 0.4236
2024-07-11 17:56:15,456 [INFO    ] __main__: train step 23217: loss: 0.9043, policy_loss: 0.8131, value_loss: 0.4236
2024-07-11 17:56:15,688 [INFO    ] __main__: train step 23218: loss: 0.9043, policy_loss: 0.8131, value_loss: 0.4236
2024-07-11 17:56:15,889 [INFO    ] __main__: train step 23219: loss: 0.9043, policy_loss: 0.8131, value_loss: 0.4236
2024-07-11 17:56:16,093 [INFO    ] __main__: train step 23220: loss: 0.9043, policy_loss: 0.8131, value_loss: 0.4235
2024-07-11 17:56:16,284 [INFO    ] __main__: train step 23221: loss: 0.9043, policy_loss: 0.8131, value_loss: 0.4235
2024-07-11 17:56:17,730 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:56:18,149 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:56:18,208 [INFO    ] __main__: train step 23222: loss: 0.9043, policy_loss: 0.8131, value_loss: 0.4235
2024-07-11 17:56:18,389 [INFO    ] __main__: train step 23223: loss: 0.9042, policy_loss: 0.8131, value_loss: 0.4235
2024-07-11 17:56:18,604 [INFO    ] __main__: train step 23224: loss: 0.9042, policy_loss: 0.8130, value_loss: 0.4235
2024-07-11 17:56:18,814 [INFO    ] __main__: train step 23225: loss: 0.9042, policy_loss: 0.8130, value_loss: 0.4235
2024-07-11 17:56:19,021 [INFO    ] __main__: train step 23226: loss: 0.9042, policy_loss: 0.8130, value_loss: 0.4234
2024-07-11 17:56:19,219 [INFO    ] __main__: train step 23227: loss: 0.9042, policy_loss: 0.8130, value_loss: 0.4234
2024-07-11 17:56:19,426 [INFO    ] __main__: train step 23228: loss: 0.9042, policy_loss: 0.8130, value_loss: 0.4234
2024-07-11 17:56:19,632 [INFO    ] __main__: train step 23229: loss: 0.9042, policy_loss: 0.8130, value_loss: 0.4234
2024-07-11 17:56:19,844 [INFO    ] __main__: train step 23230: loss: 0.9042, policy_loss: 0.8130, value_loss: 0.4234
2024-07-11 17:56:20,044 [INFO    ] __main__: train step 23231: loss: 0.9042, policy_loss: 0.8130, value_loss: 0.4234
2024-07-11 17:56:20,267 [INFO    ] __main__: train step 23232: loss: 0.9041, policy_loss: 0.8130, value_loss: 0.4234
2024-07-11 17:56:20,499 [INFO    ] __main__: train step 23233: loss: 0.9041, policy_loss: 0.8129, value_loss: 0.4233
2024-07-11 17:56:20,705 [INFO    ] __main__: train step 23234: loss: 0.9041, policy_loss: 0.8129, value_loss: 0.4233
2024-07-11 17:56:20,920 [INFO    ] __main__: train step 23235: loss: 0.9041, policy_loss: 0.8129, value_loss: 0.4233
2024-07-11 17:56:21,123 [INFO    ] __main__: train step 23236: loss: 0.9041, policy_loss: 0.8129, value_loss: 0.4233
2024-07-11 17:56:21,339 [INFO    ] __main__: train step 23237: loss: 0.9041, policy_loss: 0.8129, value_loss: 0.4233
2024-07-11 17:56:21,539 [INFO    ] __main__: train step 23238: loss: 0.9041, policy_loss: 0.8129, value_loss: 0.4233
2024-07-11 17:56:22,987 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:56:23,359 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:56:23,414 [INFO    ] __main__: train step 23239: loss: 0.9041, policy_loss: 0.8129, value_loss: 0.4232
2024-07-11 17:56:23,593 [INFO    ] __main__: train step 23240: loss: 0.9040, policy_loss: 0.8129, value_loss: 0.4232
2024-07-11 17:56:23,797 [INFO    ] __main__: train step 23241: loss: 0.9040, policy_loss: 0.8129, value_loss: 0.4232
2024-07-11 17:56:24,009 [INFO    ] __main__: train step 23242: loss: 0.9040, policy_loss: 0.8128, value_loss: 0.4232
2024-07-11 17:56:24,220 [INFO    ] __main__: train step 23243: loss: 0.9040, policy_loss: 0.8128, value_loss: 0.4232
2024-07-11 17:56:24,429 [INFO    ] __main__: train step 23244: loss: 0.9040, policy_loss: 0.8128, value_loss: 0.4232
2024-07-11 17:56:24,638 [INFO    ] __main__: train step 23245: loss: 0.9040, policy_loss: 0.8128, value_loss: 0.4232
2024-07-11 17:56:24,869 [INFO    ] __main__: train step 23246: loss: 0.9040, policy_loss: 0.8128, value_loss: 0.4231
2024-07-11 17:56:25,069 [INFO    ] __main__: train step 23247: loss: 0.9040, policy_loss: 0.8128, value_loss: 0.4231
2024-07-11 17:56:25,288 [INFO    ] __main__: train step 23248: loss: 0.9039, policy_loss: 0.8128, value_loss: 0.4231
2024-07-11 17:56:25,482 [INFO    ] __main__: train step 23249: loss: 0.9039, policy_loss: 0.8128, value_loss: 0.4231
2024-07-11 17:56:25,691 [INFO    ] __main__: train step 23250: loss: 0.9039, policy_loss: 0.8127, value_loss: 0.4231
2024-07-11 17:56:25,900 [INFO    ] __main__: train step 23251: loss: 0.9039, policy_loss: 0.8127, value_loss: 0.4231
2024-07-11 17:56:26,117 [INFO    ] __main__: train step 23252: loss: 0.9039, policy_loss: 0.8127, value_loss: 0.4231
2024-07-11 17:56:26,368 [INFO    ] __main__: train step 23253: loss: 0.9039, policy_loss: 0.8127, value_loss: 0.4230
2024-07-11 17:56:26,600 [INFO    ] __main__: train step 23254: loss: 0.9039, policy_loss: 0.8127, value_loss: 0.4230
2024-07-11 17:56:26,810 [INFO    ] __main__: train step 23255: loss: 0.9039, policy_loss: 0.8127, value_loss: 0.4230
2024-07-11 17:56:28,254 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:56:28,603 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:56:28,661 [INFO    ] __main__: train step 23256: loss: 0.9038, policy_loss: 0.8127, value_loss: 0.4230
2024-07-11 17:56:28,837 [INFO    ] __main__: train step 23257: loss: 0.9038, policy_loss: 0.8127, value_loss: 0.4230
2024-07-11 17:56:29,041 [INFO    ] __main__: train step 23258: loss: 0.9038, policy_loss: 0.8127, value_loss: 0.4230
2024-07-11 17:56:29,238 [INFO    ] __main__: train step 23259: loss: 0.9038, policy_loss: 0.8126, value_loss: 0.4229
2024-07-11 17:56:29,451 [INFO    ] __main__: train step 23260: loss: 0.9038, policy_loss: 0.8126, value_loss: 0.4229
2024-07-11 17:56:29,678 [INFO    ] __main__: train step 23261: loss: 0.9038, policy_loss: 0.8126, value_loss: 0.4229
2024-07-11 17:56:29,917 [INFO    ] __main__: train step 23262: loss: 0.9038, policy_loss: 0.8126, value_loss: 0.4229
2024-07-11 17:56:30,118 [INFO    ] __main__: train step 23263: loss: 0.9038, policy_loss: 0.8126, value_loss: 0.4229
2024-07-11 17:56:30,326 [INFO    ] __main__: train step 23264: loss: 0.9038, policy_loss: 0.8126, value_loss: 0.4229
2024-07-11 17:56:30,528 [INFO    ] __main__: train step 23265: loss: 0.9037, policy_loss: 0.8126, value_loss: 0.4229
2024-07-11 17:56:30,746 [INFO    ] __main__: train step 23266: loss: 0.9037, policy_loss: 0.8126, value_loss: 0.4228
2024-07-11 17:56:30,983 [INFO    ] __main__: train step 23267: loss: 0.9037, policy_loss: 0.8126, value_loss: 0.4228
2024-07-11 17:56:31,190 [INFO    ] __main__: train step 23268: loss: 0.9037, policy_loss: 0.8125, value_loss: 0.4228
2024-07-11 17:56:31,389 [INFO    ] __main__: train step 23269: loss: 0.9037, policy_loss: 0.8125, value_loss: 0.4228
2024-07-11 17:56:31,593 [INFO    ] __main__: train step 23270: loss: 0.9037, policy_loss: 0.8125, value_loss: 0.4228
2024-07-11 17:56:31,786 [INFO    ] __main__: train step 23271: loss: 0.9037, policy_loss: 0.8125, value_loss: 0.4228
2024-07-11 17:56:31,987 [INFO    ] __main__: train step 23272: loss: 0.9037, policy_loss: 0.8125, value_loss: 0.4228
2024-07-11 17:56:33,433 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:56:33,792 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:56:33,849 [INFO    ] __main__: train step 23273: loss: 0.9036, policy_loss: 0.8125, value_loss: 0.4227
2024-07-11 17:56:34,035 [INFO    ] __main__: train step 23274: loss: 0.9036, policy_loss: 0.8125, value_loss: 0.4227
2024-07-11 17:56:34,241 [INFO    ] __main__: train step 23275: loss: 0.9036, policy_loss: 0.8125, value_loss: 0.4227
2024-07-11 17:56:34,452 [INFO    ] __main__: train step 23276: loss: 0.9036, policy_loss: 0.8124, value_loss: 0.4227
2024-07-11 17:56:34,677 [INFO    ] __main__: train step 23277: loss: 0.9036, policy_loss: 0.8124, value_loss: 0.4227
2024-07-11 17:56:34,888 [INFO    ] __main__: train step 23278: loss: 0.9036, policy_loss: 0.8124, value_loss: 0.4227
2024-07-11 17:56:35,086 [INFO    ] __main__: train step 23279: loss: 0.9036, policy_loss: 0.8124, value_loss: 0.4226
2024-07-11 17:56:35,292 [INFO    ] __main__: train step 23280: loss: 0.9036, policy_loss: 0.8124, value_loss: 0.4226
2024-07-11 17:56:35,495 [INFO    ] __main__: train step 23281: loss: 0.9035, policy_loss: 0.8124, value_loss: 0.4226
2024-07-11 17:56:35,698 [INFO    ] __main__: train step 23282: loss: 0.9035, policy_loss: 0.8124, value_loss: 0.4226
2024-07-11 17:56:35,927 [INFO    ] __main__: train step 23283: loss: 0.9035, policy_loss: 0.8124, value_loss: 0.4226
2024-07-11 17:56:36,129 [INFO    ] __main__: train step 23284: loss: 0.9035, policy_loss: 0.8124, value_loss: 0.4226
2024-07-11 17:56:36,346 [INFO    ] __main__: train step 23285: loss: 0.9035, policy_loss: 0.8123, value_loss: 0.4226
2024-07-11 17:56:36,575 [INFO    ] __main__: train step 23286: loss: 0.9035, policy_loss: 0.8123, value_loss: 0.4225
2024-07-11 17:56:36,797 [INFO    ] __main__: train step 23287: loss: 0.9035, policy_loss: 0.8123, value_loss: 0.4225
2024-07-11 17:56:37,027 [INFO    ] __main__: train step 23288: loss: 0.9035, policy_loss: 0.8123, value_loss: 0.4225
2024-07-11 17:56:37,230 [INFO    ] __main__: train step 23289: loss: 0.9034, policy_loss: 0.8123, value_loss: 0.4225
2024-07-11 17:56:38,662 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:56:39,025 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:56:39,092 [INFO    ] __main__: train step 23290: loss: 0.9034, policy_loss: 0.8123, value_loss: 0.4225
2024-07-11 17:56:39,270 [INFO    ] __main__: train step 23291: loss: 0.9034, policy_loss: 0.8123, value_loss: 0.4225
2024-07-11 17:56:39,478 [INFO    ] __main__: train step 23292: loss: 0.9034, policy_loss: 0.8123, value_loss: 0.4225
2024-07-11 17:56:39,697 [INFO    ] __main__: train step 23293: loss: 0.9034, policy_loss: 0.8123, value_loss: 0.4224
2024-07-11 17:56:39,938 [INFO    ] __main__: train step 23294: loss: 0.9034, policy_loss: 0.8122, value_loss: 0.4224
2024-07-11 17:56:40,187 [INFO    ] __main__: train step 23295: loss: 0.9034, policy_loss: 0.8122, value_loss: 0.4224
2024-07-11 17:56:40,425 [INFO    ] __main__: train step 23296: loss: 0.9034, policy_loss: 0.8122, value_loss: 0.4224
2024-07-11 17:56:40,616 [INFO    ] __main__: train step 23297: loss: 0.9033, policy_loss: 0.8122, value_loss: 0.4224
2024-07-11 17:56:40,835 [INFO    ] __main__: train step 23298: loss: 0.9033, policy_loss: 0.8122, value_loss: 0.4224
2024-07-11 17:56:41,046 [INFO    ] __main__: train step 23299: loss: 0.9033, policy_loss: 0.8122, value_loss: 0.4223
2024-07-11 17:56:41,243 [INFO    ] __main__: train step 23300: loss: 0.9033, policy_loss: 0.8122, value_loss: 0.4223
2024-07-11 17:56:41,448 [INFO    ] __main__: train step 23301: loss: 0.9033, policy_loss: 0.8122, value_loss: 0.4223
2024-07-11 17:56:41,653 [INFO    ] __main__: train step 23302: loss: 0.9033, policy_loss: 0.8122, value_loss: 0.4223
2024-07-11 17:56:41,871 [INFO    ] __main__: train step 23303: loss: 0.9033, policy_loss: 0.8121, value_loss: 0.4223
2024-07-11 17:56:42,108 [INFO    ] __main__: train step 23304: loss: 0.9033, policy_loss: 0.8121, value_loss: 0.4223
2024-07-11 17:56:42,319 [INFO    ] __main__: train step 23305: loss: 0.9032, policy_loss: 0.8121, value_loss: 0.4223
2024-07-11 17:56:42,574 [INFO    ] __main__: train step 23306: loss: 0.9032, policy_loss: 0.8121, value_loss: 0.4222
2024-07-11 17:56:44,047 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:56:44,442 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:56:44,501 [INFO    ] __main__: train step 23307: loss: 0.9032, policy_loss: 0.8121, value_loss: 0.4222
2024-07-11 17:56:44,685 [INFO    ] __main__: train step 23308: loss: 0.9032, policy_loss: 0.8121, value_loss: 0.4222
2024-07-11 17:56:44,923 [INFO    ] __main__: train step 23309: loss: 0.9032, policy_loss: 0.8121, value_loss: 0.4222
2024-07-11 17:56:45,164 [INFO    ] __main__: train step 23310: loss: 0.9032, policy_loss: 0.8121, value_loss: 0.4222
2024-07-11 17:56:45,375 [INFO    ] __main__: train step 23311: loss: 0.9032, policy_loss: 0.8120, value_loss: 0.4222
2024-07-11 17:56:45,576 [INFO    ] __main__: train step 23312: loss: 0.9032, policy_loss: 0.8120, value_loss: 0.4221
2024-07-11 17:56:45,790 [INFO    ] __main__: train step 23313: loss: 0.9031, policy_loss: 0.8120, value_loss: 0.4221
2024-07-11 17:56:45,993 [INFO    ] __main__: train step 23314: loss: 0.9031, policy_loss: 0.8120, value_loss: 0.4221
2024-07-11 17:56:46,197 [INFO    ] __main__: train step 23315: loss: 0.9031, policy_loss: 0.8120, value_loss: 0.4221
2024-07-11 17:56:46,402 [INFO    ] __main__: train step 23316: loss: 0.9031, policy_loss: 0.8120, value_loss: 0.4221
2024-07-11 17:56:46,607 [INFO    ] __main__: train step 23317: loss: 0.9031, policy_loss: 0.8120, value_loss: 0.4221
2024-07-11 17:56:46,824 [INFO    ] __main__: train step 23318: loss: 0.9031, policy_loss: 0.8120, value_loss: 0.4221
2024-07-11 17:56:47,049 [INFO    ] __main__: train step 23319: loss: 0.9031, policy_loss: 0.8120, value_loss: 0.4220
2024-07-11 17:56:47,250 [INFO    ] __main__: train step 23320: loss: 0.9031, policy_loss: 0.8119, value_loss: 0.4220
2024-07-11 17:56:47,458 [INFO    ] __main__: train step 23321: loss: 0.9030, policy_loss: 0.8119, value_loss: 0.4220
2024-07-11 17:56:49,932 [INFO    ] __main__: train step 23322: loss: 0.9030, policy_loss: 0.8119, value_loss: 0.4220
2024-07-11 17:56:50,126 [INFO    ] __main__: train step 23323: loss: 0.9030, policy_loss: 0.8119, value_loss: 0.4220
2024-07-11 17:56:51,609 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:56:51,966 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:56:52,022 [INFO    ] __main__: train step 23324: loss: 0.9030, policy_loss: 0.8119, value_loss: 0.4220
2024-07-11 17:56:52,204 [INFO    ] __main__: train step 23325: loss: 0.9030, policy_loss: 0.8119, value_loss: 0.4220
2024-07-11 17:56:52,413 [INFO    ] __main__: train step 23326: loss: 0.9030, policy_loss: 0.8119, value_loss: 0.4219
2024-07-11 17:56:52,616 [INFO    ] __main__: train step 23327: loss: 0.9030, policy_loss: 0.8119, value_loss: 0.4219
2024-07-11 17:56:52,817 [INFO    ] __main__: train step 23328: loss: 0.9030, policy_loss: 0.8118, value_loss: 0.4219
2024-07-11 17:56:53,027 [INFO    ] __main__: train step 23329: loss: 0.9029, policy_loss: 0.8118, value_loss: 0.4219
2024-07-11 17:56:53,231 [INFO    ] __main__: train step 23330: loss: 0.9029, policy_loss: 0.8118, value_loss: 0.4219
2024-07-11 17:56:53,434 [INFO    ] __main__: train step 23331: loss: 0.9029, policy_loss: 0.8118, value_loss: 0.4219
2024-07-11 17:56:53,637 [INFO    ] __main__: train step 23332: loss: 0.9029, policy_loss: 0.8118, value_loss: 0.4218
2024-07-11 17:56:53,856 [INFO    ] __main__: train step 23333: loss: 0.9029, policy_loss: 0.8118, value_loss: 0.4218
2024-07-11 17:56:54,077 [INFO    ] __main__: train step 23334: loss: 0.9029, policy_loss: 0.8118, value_loss: 0.4218
2024-07-11 17:56:54,294 [INFO    ] __main__: train step 23335: loss: 0.9029, policy_loss: 0.8118, value_loss: 0.4218
2024-07-11 17:56:54,516 [INFO    ] __main__: train step 23336: loss: 0.9029, policy_loss: 0.8118, value_loss: 0.4218
2024-07-11 17:56:54,715 [INFO    ] __main__: train step 23337: loss: 0.9028, policy_loss: 0.8117, value_loss: 0.4218
2024-07-11 17:56:54,933 [INFO    ] __main__: train step 23338: loss: 0.9028, policy_loss: 0.8117, value_loss: 0.4218
2024-07-11 17:56:55,131 [INFO    ] __main__: train step 23339: loss: 0.9028, policy_loss: 0.8117, value_loss: 0.4217
2024-07-11 17:56:55,335 [INFO    ] __main__: train step 23340: loss: 0.9028, policy_loss: 0.8117, value_loss: 0.4217
2024-07-11 17:56:56,772 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:56:57,179 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:56:57,241 [INFO    ] __main__: train step 23341: loss: 0.9028, policy_loss: 0.8117, value_loss: 0.4217
2024-07-11 17:56:57,416 [INFO    ] __main__: train step 23342: loss: 0.9028, policy_loss: 0.8117, value_loss: 0.4217
2024-07-11 17:56:57,626 [INFO    ] __main__: train step 23343: loss: 0.9028, policy_loss: 0.8117, value_loss: 0.4217
2024-07-11 17:56:57,829 [INFO    ] __main__: train step 23344: loss: 0.9028, policy_loss: 0.8117, value_loss: 0.4217
2024-07-11 17:56:58,046 [INFO    ] __main__: train step 23345: loss: 0.9027, policy_loss: 0.8116, value_loss: 0.4216
2024-07-11 17:56:58,249 [INFO    ] __main__: train step 23346: loss: 0.9027, policy_loss: 0.8116, value_loss: 0.4216
2024-07-11 17:56:58,464 [INFO    ] __main__: train step 23347: loss: 0.9027, policy_loss: 0.8116, value_loss: 0.4216
2024-07-11 17:56:58,671 [INFO    ] __main__: train step 23348: loss: 0.9027, policy_loss: 0.8116, value_loss: 0.4216
2024-07-11 17:56:58,885 [INFO    ] __main__: train step 23349: loss: 0.9027, policy_loss: 0.8116, value_loss: 0.4216
2024-07-11 17:56:59,116 [INFO    ] __main__: train step 23350: loss: 0.9027, policy_loss: 0.8116, value_loss: 0.4216
2024-07-11 17:56:59,326 [INFO    ] __main__: train step 23351: loss: 0.9027, policy_loss: 0.8116, value_loss: 0.4216
2024-07-11 17:56:59,531 [INFO    ] __main__: train step 23352: loss: 0.9026, policy_loss: 0.8116, value_loss: 0.4215
2024-07-11 17:56:59,747 [INFO    ] __main__: train step 23353: loss: 0.9026, policy_loss: 0.8116, value_loss: 0.4215
2024-07-11 17:57:00,001 [INFO    ] __main__: train step 23354: loss: 0.9026, policy_loss: 0.8115, value_loss: 0.4215
2024-07-11 17:57:00,239 [INFO    ] __main__: train step 23355: loss: 0.9026, policy_loss: 0.8115, value_loss: 0.4215
2024-07-11 17:57:00,472 [INFO    ] __main__: train step 23356: loss: 0.9026, policy_loss: 0.8115, value_loss: 0.4215
2024-07-11 17:57:00,676 [INFO    ] __main__: train step 23357: loss: 0.9026, policy_loss: 0.8115, value_loss: 0.4215
2024-07-11 17:57:02,119 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:57:02,468 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:57:02,521 [INFO    ] __main__: train step 23358: loss: 0.9026, policy_loss: 0.8115, value_loss: 0.4215
2024-07-11 17:57:02,704 [INFO    ] __main__: train step 23359: loss: 0.9026, policy_loss: 0.8115, value_loss: 0.4214
2024-07-11 17:57:02,928 [INFO    ] __main__: train step 23360: loss: 0.9025, policy_loss: 0.8115, value_loss: 0.4214
2024-07-11 17:57:03,164 [INFO    ] __main__: train step 23361: loss: 0.9025, policy_loss: 0.8115, value_loss: 0.4214
2024-07-11 17:57:03,363 [INFO    ] __main__: train step 23362: loss: 0.9025, policy_loss: 0.8114, value_loss: 0.4214
2024-07-11 17:57:03,576 [INFO    ] __main__: train step 23363: loss: 0.9025, policy_loss: 0.8114, value_loss: 0.4214
2024-07-11 17:57:03,783 [INFO    ] __main__: train step 23364: loss: 0.9025, policy_loss: 0.8114, value_loss: 0.4214
2024-07-11 17:57:03,994 [INFO    ] __main__: train step 23365: loss: 0.9025, policy_loss: 0.8114, value_loss: 0.4213
2024-07-11 17:57:04,211 [INFO    ] __main__: train step 23366: loss: 0.9025, policy_loss: 0.8114, value_loss: 0.4213
2024-07-11 17:57:04,456 [INFO    ] __main__: train step 23367: loss: 0.9025, policy_loss: 0.8114, value_loss: 0.4213
2024-07-11 17:57:04,655 [INFO    ] __main__: train step 23368: loss: 0.9024, policy_loss: 0.8114, value_loss: 0.4213
2024-07-11 17:57:04,866 [INFO    ] __main__: train step 23369: loss: 0.9024, policy_loss: 0.8114, value_loss: 0.4213
2024-07-11 17:57:05,073 [INFO    ] __main__: train step 23370: loss: 0.9024, policy_loss: 0.8114, value_loss: 0.4213
2024-07-11 17:57:05,280 [INFO    ] __main__: train step 23371: loss: 0.9024, policy_loss: 0.8113, value_loss: 0.4213
2024-07-11 17:57:05,498 [INFO    ] __main__: train step 23372: loss: 0.9024, policy_loss: 0.8113, value_loss: 0.4212
2024-07-11 17:57:05,747 [INFO    ] __main__: train step 23373: loss: 0.9024, policy_loss: 0.8113, value_loss: 0.4212
2024-07-11 17:57:06,006 [INFO    ] __main__: train step 23374: loss: 0.9024, policy_loss: 0.8113, value_loss: 0.4212
2024-07-11 17:57:07,487 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:57:07,875 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:57:07,938 [INFO    ] __main__: train step 23375: loss: 0.9024, policy_loss: 0.8113, value_loss: 0.4212
2024-07-11 17:57:08,131 [INFO    ] __main__: train step 23376: loss: 0.9023, policy_loss: 0.8113, value_loss: 0.4212
2024-07-11 17:57:08,337 [INFO    ] __main__: train step 23377: loss: 0.9023, policy_loss: 0.8113, value_loss: 0.4212
2024-07-11 17:57:08,552 [INFO    ] __main__: train step 23378: loss: 0.9023, policy_loss: 0.8113, value_loss: 0.4212
2024-07-11 17:57:08,770 [INFO    ] __main__: train step 23379: loss: 0.9023, policy_loss: 0.8112, value_loss: 0.4211
2024-07-11 17:57:09,000 [INFO    ] __main__: train step 23380: loss: 0.9023, policy_loss: 0.8112, value_loss: 0.4211
2024-07-11 17:57:09,212 [INFO    ] __main__: train step 23381: loss: 0.9023, policy_loss: 0.8112, value_loss: 0.4211
2024-07-11 17:57:09,418 [INFO    ] __main__: train step 23382: loss: 0.9023, policy_loss: 0.8112, value_loss: 0.4211
2024-07-11 17:57:09,631 [INFO    ] __main__: train step 23383: loss: 0.9022, policy_loss: 0.8112, value_loss: 0.4211
2024-07-11 17:57:09,839 [INFO    ] __main__: train step 23384: loss: 0.9022, policy_loss: 0.8112, value_loss: 0.4211
2024-07-11 17:57:10,064 [INFO    ] __main__: train step 23385: loss: 0.9022, policy_loss: 0.8112, value_loss: 0.4210
2024-07-11 17:57:10,268 [INFO    ] __main__: train step 23386: loss: 0.9022, policy_loss: 0.8112, value_loss: 0.4210
2024-07-11 17:57:10,467 [INFO    ] __main__: train step 23387: loss: 0.9022, policy_loss: 0.8111, value_loss: 0.4210
2024-07-11 17:57:10,669 [INFO    ] __main__: train step 23388: loss: 0.9022, policy_loss: 0.8111, value_loss: 0.4210
2024-07-11 17:57:10,865 [INFO    ] __main__: train step 23389: loss: 0.9022, policy_loss: 0.8111, value_loss: 0.4210
2024-07-11 17:57:11,072 [INFO    ] __main__: train step 23390: loss: 0.9022, policy_loss: 0.8111, value_loss: 0.4210
2024-07-11 17:57:11,270 [INFO    ] __main__: train step 23391: loss: 0.9021, policy_loss: 0.8111, value_loss: 0.4210
2024-07-11 17:57:12,706 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:57:13,094 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:57:13,160 [INFO    ] __main__: train step 23392: loss: 0.9021, policy_loss: 0.8111, value_loss: 0.4209
2024-07-11 17:57:13,339 [INFO    ] __main__: train step 23393: loss: 0.9021, policy_loss: 0.8111, value_loss: 0.4209
2024-07-11 17:57:13,535 [INFO    ] __main__: train step 23394: loss: 0.9021, policy_loss: 0.8111, value_loss: 0.4209
2024-07-11 17:57:13,740 [INFO    ] __main__: train step 23395: loss: 0.9021, policy_loss: 0.8110, value_loss: 0.4209
2024-07-11 17:57:13,943 [INFO    ] __main__: train step 23396: loss: 0.9021, policy_loss: 0.8110, value_loss: 0.4209
2024-07-11 17:57:14,150 [INFO    ] __main__: train step 23397: loss: 0.9021, policy_loss: 0.8110, value_loss: 0.4209
2024-07-11 17:57:14,348 [INFO    ] __main__: train step 23398: loss: 0.9021, policy_loss: 0.8110, value_loss: 0.4209
2024-07-11 17:57:14,546 [INFO    ] __main__: train step 23399: loss: 0.9020, policy_loss: 0.8110, value_loss: 0.4208
2024-07-11 17:57:14,751 [INFO    ] __main__: train step 23400: loss: 0.9020, policy_loss: 0.8110, value_loss: 0.4208
2024-07-11 17:57:14,979 [INFO    ] __main__: train step 23401: loss: 0.9020, policy_loss: 0.8110, value_loss: 0.4208
2024-07-11 17:57:15,193 [INFO    ] __main__: train step 23402: loss: 0.9020, policy_loss: 0.8110, value_loss: 0.4208
2024-07-11 17:57:15,422 [INFO    ] __main__: train step 23403: loss: 0.9020, policy_loss: 0.8109, value_loss: 0.4208
2024-07-11 17:57:15,663 [INFO    ] __main__: train step 23404: loss: 0.9020, policy_loss: 0.8109, value_loss: 0.4208
2024-07-11 17:57:15,864 [INFO    ] __main__: train step 23405: loss: 0.9020, policy_loss: 0.8109, value_loss: 0.4207
2024-07-11 17:57:16,081 [INFO    ] __main__: train step 23406: loss: 0.9019, policy_loss: 0.8109, value_loss: 0.4207
2024-07-11 17:57:16,276 [INFO    ] __main__: train step 23407: loss: 0.9019, policy_loss: 0.8109, value_loss: 0.4207
2024-07-11 17:57:16,487 [INFO    ] __main__: train step 23408: loss: 0.9019, policy_loss: 0.8109, value_loss: 0.4207
2024-07-11 17:57:17,934 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:57:18,307 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:57:18,362 [INFO    ] __main__: train step 23409: loss: 0.9019, policy_loss: 0.8109, value_loss: 0.4207
2024-07-11 17:57:18,535 [INFO    ] __main__: train step 23410: loss: 0.9019, policy_loss: 0.8109, value_loss: 0.4207
2024-07-11 17:57:18,742 [INFO    ] __main__: train step 23411: loss: 0.9019, policy_loss: 0.8108, value_loss: 0.4207
2024-07-11 17:57:18,940 [INFO    ] __main__: train step 23412: loss: 0.9019, policy_loss: 0.8108, value_loss: 0.4206
2024-07-11 17:57:19,154 [INFO    ] __main__: train step 23413: loss: 0.9019, policy_loss: 0.8108, value_loss: 0.4206
2024-07-11 17:57:19,345 [INFO    ] __main__: train step 23414: loss: 0.9018, policy_loss: 0.8108, value_loss: 0.4206
2024-07-11 17:57:19,542 [INFO    ] __main__: train step 23415: loss: 0.9018, policy_loss: 0.8108, value_loss: 0.4206
2024-07-11 17:57:19,748 [INFO    ] __main__: train step 23416: loss: 0.9018, policy_loss: 0.8108, value_loss: 0.4206
2024-07-11 17:57:19,955 [INFO    ] __main__: train step 23417: loss: 0.9018, policy_loss: 0.8108, value_loss: 0.4206
2024-07-11 17:57:20,159 [INFO    ] __main__: train step 23418: loss: 0.9018, policy_loss: 0.8108, value_loss: 0.4206
2024-07-11 17:57:20,357 [INFO    ] __main__: train step 23419: loss: 0.9018, policy_loss: 0.8107, value_loss: 0.4205
2024-07-11 17:57:20,557 [INFO    ] __main__: train step 23420: loss: 0.9018, policy_loss: 0.8107, value_loss: 0.4205
2024-07-11 17:57:20,767 [INFO    ] __main__: train step 23421: loss: 0.9017, policy_loss: 0.8107, value_loss: 0.4205
2024-07-11 17:57:20,984 [INFO    ] __main__: train step 23422: loss: 0.9017, policy_loss: 0.8107, value_loss: 0.4205
2024-07-11 17:57:21,220 [INFO    ] __main__: train step 23423: loss: 0.9017, policy_loss: 0.8107, value_loss: 0.4205
2024-07-11 17:57:21,438 [INFO    ] __main__: train step 23424: loss: 0.9017, policy_loss: 0.8107, value_loss: 0.4205
2024-07-11 17:57:21,634 [INFO    ] __main__: train step 23425: loss: 0.9017, policy_loss: 0.8107, value_loss: 0.4205
2024-07-11 17:57:23,078 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:57:23,530 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:57:23,594 [INFO    ] __main__: train step 23426: loss: 0.9017, policy_loss: 0.8107, value_loss: 0.4204
2024-07-11 17:57:23,783 [INFO    ] __main__: train step 23427: loss: 0.9017, policy_loss: 0.8106, value_loss: 0.4204
2024-07-11 17:57:23,999 [INFO    ] __main__: train step 23428: loss: 0.9017, policy_loss: 0.8106, value_loss: 0.4204
2024-07-11 17:57:24,218 [INFO    ] __main__: train step 23429: loss: 0.9016, policy_loss: 0.8106, value_loss: 0.4204
2024-07-11 17:57:24,415 [INFO    ] __main__: train step 23430: loss: 0.9016, policy_loss: 0.8106, value_loss: 0.4204
2024-07-11 17:57:24,636 [INFO    ] __main__: train step 23431: loss: 0.9016, policy_loss: 0.8106, value_loss: 0.4204
2024-07-11 17:57:24,847 [INFO    ] __main__: train step 23432: loss: 0.9016, policy_loss: 0.8106, value_loss: 0.4203
2024-07-11 17:57:25,049 [INFO    ] __main__: train step 23433: loss: 0.9016, policy_loss: 0.8106, value_loss: 0.4203
2024-07-11 17:57:25,252 [INFO    ] __main__: train step 23434: loss: 0.9016, policy_loss: 0.8106, value_loss: 0.4203
2024-07-11 17:57:25,654 [INFO    ] __main__: train step 23435: loss: 0.9016, policy_loss: 0.8106, value_loss: 0.4203
2024-07-11 17:57:25,882 [INFO    ] __main__: train step 23436: loss: 0.9015, policy_loss: 0.8105, value_loss: 0.4203
2024-07-11 17:57:26,083 [INFO    ] __main__: train step 23437: loss: 0.9015, policy_loss: 0.8105, value_loss: 0.4203
2024-07-11 17:57:26,288 [INFO    ] __main__: train step 23438: loss: 0.9015, policy_loss: 0.8105, value_loss: 0.4203
2024-07-11 17:57:26,517 [INFO    ] __main__: train step 23439: loss: 0.9015, policy_loss: 0.8105, value_loss: 0.4202
2024-07-11 17:57:26,724 [INFO    ] __main__: train step 23440: loss: 0.9015, policy_loss: 0.8105, value_loss: 0.4202
2024-07-11 17:57:26,968 [INFO    ] __main__: train step 23441: loss: 0.9015, policy_loss: 0.8105, value_loss: 0.4202
2024-07-11 17:57:27,209 [INFO    ] __main__: train step 23442: loss: 0.9015, policy_loss: 0.8105, value_loss: 0.4202
2024-07-11 17:57:28,679 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:57:29,083 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:57:29,138 [INFO    ] __main__: train step 23443: loss: 0.9015, policy_loss: 0.8104, value_loss: 0.4202
2024-07-11 17:57:29,319 [INFO    ] __main__: train step 23444: loss: 0.9014, policy_loss: 0.8104, value_loss: 0.4202
2024-07-11 17:57:29,518 [INFO    ] __main__: train step 23445: loss: 0.9014, policy_loss: 0.8104, value_loss: 0.4202
2024-07-11 17:57:29,728 [INFO    ] __main__: train step 23446: loss: 0.9014, policy_loss: 0.8104, value_loss: 0.4201
2024-07-11 17:57:29,943 [INFO    ] __main__: train step 23447: loss: 0.9014, policy_loss: 0.8104, value_loss: 0.4201
2024-07-11 17:57:30,157 [INFO    ] __main__: train step 23448: loss: 0.9014, policy_loss: 0.8104, value_loss: 0.4201
2024-07-11 17:57:30,367 [INFO    ] __main__: train step 23449: loss: 0.9014, policy_loss: 0.8104, value_loss: 0.4201
2024-07-11 17:57:30,590 [INFO    ] __main__: train step 23450: loss: 0.9014, policy_loss: 0.8104, value_loss: 0.4201
2024-07-11 17:57:30,796 [INFO    ] __main__: train step 23451: loss: 0.9013, policy_loss: 0.8103, value_loss: 0.4201
2024-07-11 17:57:30,995 [INFO    ] __main__: train step 23452: loss: 0.9013, policy_loss: 0.8103, value_loss: 0.4200
2024-07-11 17:57:31,197 [INFO    ] __main__: train step 23453: loss: 0.9013, policy_loss: 0.8103, value_loss: 0.4200
2024-07-11 17:57:31,402 [INFO    ] __main__: train step 23454: loss: 0.9013, policy_loss: 0.8103, value_loss: 0.4200
2024-07-11 17:57:31,598 [INFO    ] __main__: train step 23455: loss: 0.9013, policy_loss: 0.8103, value_loss: 0.4200
2024-07-11 17:57:31,798 [INFO    ] __main__: train step 23456: loss: 0.9013, policy_loss: 0.8103, value_loss: 0.4200
2024-07-11 17:57:31,995 [INFO    ] __main__: train step 23457: loss: 0.9013, policy_loss: 0.8103, value_loss: 0.4200
2024-07-11 17:57:32,207 [INFO    ] __main__: train step 23458: loss: 0.9013, policy_loss: 0.8103, value_loss: 0.4200
2024-07-11 17:57:32,413 [INFO    ] __main__: train step 23459: loss: 0.9012, policy_loss: 0.8102, value_loss: 0.4199
2024-07-11 17:57:33,851 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:57:34,250 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:57:34,305 [INFO    ] __main__: train step 23460: loss: 0.9012, policy_loss: 0.8102, value_loss: 0.4199
2024-07-11 17:57:34,486 [INFO    ] __main__: train step 23461: loss: 0.9012, policy_loss: 0.8102, value_loss: 0.4199
2024-07-11 17:57:34,694 [INFO    ] __main__: train step 23462: loss: 0.9012, policy_loss: 0.8102, value_loss: 0.4199
2024-07-11 17:57:34,895 [INFO    ] __main__: train step 23463: loss: 0.9012, policy_loss: 0.8102, value_loss: 0.4199
2024-07-11 17:57:37,391 [INFO    ] __main__: train step 23464: loss: 0.9012, policy_loss: 0.8102, value_loss: 0.4199
2024-07-11 17:57:37,618 [INFO    ] __main__: train step 23465: loss: 0.9012, policy_loss: 0.8102, value_loss: 0.4199
2024-07-11 17:57:37,830 [INFO    ] __main__: train step 23466: loss: 0.9011, policy_loss: 0.8102, value_loss: 0.4198
2024-07-11 17:57:38,034 [INFO    ] __main__: train step 23467: loss: 0.9011, policy_loss: 0.8101, value_loss: 0.4198
2024-07-11 17:57:38,238 [INFO    ] __main__: train step 23468: loss: 0.9011, policy_loss: 0.8101, value_loss: 0.4198
2024-07-11 17:57:38,445 [INFO    ] __main__: train step 23469: loss: 0.9011, policy_loss: 0.8101, value_loss: 0.4198
2024-07-11 17:57:38,643 [INFO    ] __main__: train step 23470: loss: 0.9011, policy_loss: 0.8101, value_loss: 0.4198
2024-07-11 17:57:38,859 [INFO    ] __main__: train step 23471: loss: 0.9011, policy_loss: 0.8101, value_loss: 0.4198
2024-07-11 17:57:39,063 [INFO    ] __main__: train step 23472: loss: 0.9011, policy_loss: 0.8101, value_loss: 0.4197
2024-07-11 17:57:39,267 [INFO    ] __main__: train step 23473: loss: 0.9010, policy_loss: 0.8101, value_loss: 0.4197
2024-07-11 17:57:39,479 [INFO    ] __main__: train step 23474: loss: 0.9010, policy_loss: 0.8101, value_loss: 0.4197
2024-07-11 17:57:39,692 [INFO    ] __main__: train step 23475: loss: 0.9010, policy_loss: 0.8100, value_loss: 0.4197
2024-07-11 17:57:39,890 [INFO    ] __main__: train step 23476: loss: 0.9010, policy_loss: 0.8100, value_loss: 0.4197
2024-07-11 17:57:41,329 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:57:41,684 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:57:41,742 [INFO    ] __main__: train step 23477: loss: 0.9010, policy_loss: 0.8100, value_loss: 0.4197
2024-07-11 17:57:41,935 [INFO    ] __main__: train step 23478: loss: 0.9010, policy_loss: 0.8100, value_loss: 0.4197
2024-07-11 17:57:42,170 [INFO    ] __main__: train step 23479: loss: 0.9010, policy_loss: 0.8100, value_loss: 0.4196
2024-07-11 17:57:42,424 [INFO    ] __main__: train step 23480: loss: 0.9010, policy_loss: 0.8100, value_loss: 0.4196
2024-07-11 17:57:42,622 [INFO    ] __main__: train step 23481: loss: 0.9009, policy_loss: 0.8100, value_loss: 0.4196
2024-07-11 17:57:42,829 [INFO    ] __main__: train step 23482: loss: 0.9009, policy_loss: 0.8100, value_loss: 0.4196
2024-07-11 17:57:43,029 [INFO    ] __main__: train step 23483: loss: 0.9009, policy_loss: 0.8099, value_loss: 0.4196
2024-07-11 17:57:43,237 [INFO    ] __main__: train step 23484: loss: 0.9009, policy_loss: 0.8099, value_loss: 0.4196
2024-07-11 17:57:43,445 [INFO    ] __main__: train step 23485: loss: 0.9009, policy_loss: 0.8099, value_loss: 0.4196
2024-07-11 17:57:43,664 [INFO    ] __main__: train step 23486: loss: 0.9009, policy_loss: 0.8099, value_loss: 0.4195
2024-07-11 17:57:43,858 [INFO    ] __main__: train step 23487: loss: 0.9009, policy_loss: 0.8099, value_loss: 0.4195
2024-07-11 17:57:44,059 [INFO    ] __main__: train step 23488: loss: 0.9008, policy_loss: 0.8099, value_loss: 0.4195
2024-07-11 17:57:44,259 [INFO    ] __main__: train step 23489: loss: 0.9008, policy_loss: 0.8099, value_loss: 0.4195
2024-07-11 17:57:44,474 [INFO    ] __main__: train step 23490: loss: 0.9008, policy_loss: 0.8099, value_loss: 0.4195
2024-07-11 17:57:44,687 [INFO    ] __main__: train step 23491: loss: 0.9008, policy_loss: 0.8098, value_loss: 0.4195
2024-07-11 17:57:44,906 [INFO    ] __main__: train step 23492: loss: 0.9008, policy_loss: 0.8098, value_loss: 0.4194
2024-07-11 17:57:45,114 [INFO    ] __main__: train step 23493: loss: 0.9008, policy_loss: 0.8098, value_loss: 0.4194
2024-07-11 17:57:46,551 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:57:46,986 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:57:47,044 [INFO    ] __main__: train step 23494: loss: 0.9008, policy_loss: 0.8098, value_loss: 0.4194
2024-07-11 17:57:47,219 [INFO    ] __main__: train step 23495: loss: 0.9007, policy_loss: 0.8098, value_loss: 0.4194
2024-07-11 17:57:47,426 [INFO    ] __main__: train step 23496: loss: 0.9007, policy_loss: 0.8098, value_loss: 0.4194
2024-07-11 17:57:47,625 [INFO    ] __main__: train step 23497: loss: 0.9007, policy_loss: 0.8098, value_loss: 0.4194
2024-07-11 17:57:47,830 [INFO    ] __main__: train step 23498: loss: 0.9007, policy_loss: 0.8098, value_loss: 0.4194
2024-07-11 17:57:48,035 [INFO    ] __main__: train step 23499: loss: 0.9007, policy_loss: 0.8097, value_loss: 0.4193
2024-07-11 17:57:48,253 [INFO    ] __main__: train step 23500: loss: 0.9007, policy_loss: 0.8097, value_loss: 0.4193
2024-07-11 17:57:48,459 [INFO    ] __main__: train step 23501: loss: 0.9007, policy_loss: 0.8097, value_loss: 0.4193
2024-07-11 17:57:48,658 [INFO    ] __main__: train step 23502: loss: 0.9006, policy_loss: 0.8097, value_loss: 0.4193
2024-07-11 17:57:48,862 [INFO    ] __main__: train step 23503: loss: 0.9006, policy_loss: 0.8097, value_loss: 0.4193
2024-07-11 17:57:49,069 [INFO    ] __main__: train step 23504: loss: 0.9006, policy_loss: 0.8097, value_loss: 0.4193
2024-07-11 17:57:49,284 [INFO    ] __main__: train step 23505: loss: 0.9006, policy_loss: 0.8097, value_loss: 0.4193
2024-07-11 17:57:49,480 [INFO    ] __main__: train step 23506: loss: 0.9006, policy_loss: 0.8096, value_loss: 0.4192
2024-07-11 17:57:49,696 [INFO    ] __main__: train step 23507: loss: 0.9006, policy_loss: 0.8096, value_loss: 0.4192
2024-07-11 17:57:49,918 [INFO    ] __main__: train step 23508: loss: 0.9006, policy_loss: 0.8096, value_loss: 0.4192
2024-07-11 17:57:50,119 [INFO    ] __main__: train step 23509: loss: 0.9005, policy_loss: 0.8096, value_loss: 0.4192
2024-07-11 17:57:50,326 [INFO    ] __main__: train step 23510: loss: 0.9005, policy_loss: 0.8096, value_loss: 0.4192
2024-07-11 17:57:51,781 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:57:52,184 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:57:52,238 [INFO    ] __main__: train step 23511: loss: 0.9005, policy_loss: 0.8096, value_loss: 0.4192
2024-07-11 17:57:52,411 [INFO    ] __main__: train step 23512: loss: 0.9005, policy_loss: 0.8096, value_loss: 0.4191
2024-07-11 17:57:52,633 [INFO    ] __main__: train step 23513: loss: 0.9005, policy_loss: 0.8096, value_loss: 0.4191
2024-07-11 17:57:52,857 [INFO    ] __main__: train step 23514: loss: 0.9005, policy_loss: 0.8095, value_loss: 0.4191
2024-07-11 17:57:53,132 [INFO    ] __main__: train step 23515: loss: 0.9005, policy_loss: 0.8095, value_loss: 0.4191
2024-07-11 17:57:53,332 [INFO    ] __main__: train step 23516: loss: 0.9005, policy_loss: 0.8095, value_loss: 0.4191
2024-07-11 17:57:53,556 [INFO    ] __main__: train step 23517: loss: 0.9004, policy_loss: 0.8095, value_loss: 0.4191
2024-07-11 17:57:53,798 [INFO    ] __main__: train step 23518: loss: 0.9004, policy_loss: 0.8095, value_loss: 0.4191
2024-07-11 17:57:54,006 [INFO    ] __main__: train step 23519: loss: 0.9004, policy_loss: 0.8095, value_loss: 0.4190
2024-07-11 17:57:54,229 [INFO    ] __main__: train step 23520: loss: 0.9004, policy_loss: 0.8095, value_loss: 0.4190
2024-07-11 17:57:54,461 [INFO    ] __main__: train step 23521: loss: 0.9004, policy_loss: 0.8095, value_loss: 0.4190
2024-07-11 17:57:54,693 [INFO    ] __main__: train step 23522: loss: 0.9004, policy_loss: 0.8094, value_loss: 0.4190
2024-07-11 17:57:54,909 [INFO    ] __main__: train step 23523: loss: 0.9004, policy_loss: 0.8094, value_loss: 0.4190
2024-07-11 17:57:55,122 [INFO    ] __main__: train step 23524: loss: 0.9003, policy_loss: 0.8094, value_loss: 0.4190
2024-07-11 17:57:55,356 [INFO    ] __main__: train step 23525: loss: 0.9003, policy_loss: 0.8094, value_loss: 0.4190
2024-07-11 17:57:55,550 [INFO    ] __main__: train step 23526: loss: 0.9003, policy_loss: 0.8094, value_loss: 0.4189
2024-07-11 17:57:55,771 [INFO    ] __main__: train step 23527: loss: 0.9003, policy_loss: 0.8094, value_loss: 0.4189
2024-07-11 17:57:57,233 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:57:57,662 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:57:57,717 [INFO    ] __main__: train step 23528: loss: 0.9003, policy_loss: 0.8094, value_loss: 0.4189
2024-07-11 17:57:57,898 [INFO    ] __main__: train step 23529: loss: 0.9003, policy_loss: 0.8094, value_loss: 0.4189
2024-07-11 17:57:58,100 [INFO    ] __main__: train step 23530: loss: 0.9003, policy_loss: 0.8093, value_loss: 0.4189
2024-07-11 17:57:58,303 [INFO    ] __main__: train step 23531: loss: 0.9002, policy_loss: 0.8093, value_loss: 0.4189
2024-07-11 17:57:58,509 [INFO    ] __main__: train step 23532: loss: 0.9002, policy_loss: 0.8093, value_loss: 0.4188
2024-07-11 17:57:58,715 [INFO    ] __main__: train step 23533: loss: 0.9002, policy_loss: 0.8093, value_loss: 0.4188
2024-07-11 17:57:58,920 [INFO    ] __main__: train step 23534: loss: 0.9002, policy_loss: 0.8093, value_loss: 0.4188
2024-07-11 17:57:59,135 [INFO    ] __main__: train step 23535: loss: 0.9002, policy_loss: 0.8093, value_loss: 0.4188
2024-07-11 17:57:59,332 [INFO    ] __main__: train step 23536: loss: 0.9002, policy_loss: 0.8093, value_loss: 0.4188
2024-07-11 17:57:59,532 [INFO    ] __main__: train step 23537: loss: 0.9002, policy_loss: 0.8092, value_loss: 0.4188
2024-07-11 17:57:59,735 [INFO    ] __main__: train step 23538: loss: 0.9001, policy_loss: 0.8092, value_loss: 0.4188
2024-07-11 17:57:59,984 [INFO    ] __main__: train step 23539: loss: 0.9001, policy_loss: 0.8092, value_loss: 0.4187
2024-07-11 17:58:00,222 [INFO    ] __main__: train step 23540: loss: 0.9001, policy_loss: 0.8092, value_loss: 0.4187
2024-07-11 17:58:00,423 [INFO    ] __main__: train step 23541: loss: 0.9001, policy_loss: 0.8092, value_loss: 0.4187
2024-07-11 17:58:00,634 [INFO    ] __main__: train step 23542: loss: 0.9001, policy_loss: 0.8092, value_loss: 0.4187
2024-07-11 17:58:00,834 [INFO    ] __main__: train step 23543: loss: 0.9001, policy_loss: 0.8092, value_loss: 0.4187
2024-07-11 17:58:01,037 [INFO    ] __main__: train step 23544: loss: 0.9001, policy_loss: 0.8092, value_loss: 0.4187
2024-07-11 17:58:02,492 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:58:02,917 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:58:02,973 [INFO    ] __main__: train step 23545: loss: 0.9000, policy_loss: 0.8091, value_loss: 0.4187
2024-07-11 17:58:03,162 [INFO    ] __main__: train step 23546: loss: 0.9000, policy_loss: 0.8091, value_loss: 0.4186
2024-07-11 17:58:03,375 [INFO    ] __main__: train step 23547: loss: 0.9000, policy_loss: 0.8091, value_loss: 0.4186
2024-07-11 17:58:03,573 [INFO    ] __main__: train step 23548: loss: 0.9000, policy_loss: 0.8091, value_loss: 0.4186
2024-07-11 17:58:03,821 [INFO    ] __main__: train step 23549: loss: 0.9000, policy_loss: 0.8091, value_loss: 0.4186
2024-07-11 17:58:04,035 [INFO    ] __main__: train step 23550: loss: 0.9000, policy_loss: 0.8091, value_loss: 0.4186
2024-07-11 17:58:04,260 [INFO    ] __main__: train step 23551: loss: 0.9000, policy_loss: 0.8091, value_loss: 0.4186
2024-07-11 17:58:04,479 [INFO    ] __main__: train step 23552: loss: 0.8999, policy_loss: 0.8090, value_loss: 0.4185
2024-07-11 17:58:04,726 [INFO    ] __main__: train step 23553: loss: 0.8999, policy_loss: 0.8090, value_loss: 0.4185
2024-07-11 17:58:04,945 [INFO    ] __main__: train step 23554: loss: 0.8999, policy_loss: 0.8090, value_loss: 0.4185
2024-07-11 17:58:05,153 [INFO    ] __main__: train step 23555: loss: 0.8999, policy_loss: 0.8090, value_loss: 0.4185
2024-07-11 17:58:05,363 [INFO    ] __main__: train step 23556: loss: 0.8999, policy_loss: 0.8090, value_loss: 0.4185
2024-07-11 17:58:05,579 [INFO    ] __main__: train step 23557: loss: 0.8999, policy_loss: 0.8090, value_loss: 0.4185
2024-07-11 17:58:05,789 [INFO    ] __main__: train step 23558: loss: 0.8999, policy_loss: 0.8090, value_loss: 0.4185
2024-07-11 17:58:06,017 [INFO    ] __main__: train step 23559: loss: 0.8998, policy_loss: 0.8090, value_loss: 0.4184
2024-07-11 17:58:06,253 [INFO    ] __main__: train step 23560: loss: 0.8998, policy_loss: 0.8089, value_loss: 0.4184
2024-07-11 17:58:06,477 [INFO    ] __main__: train step 23561: loss: 0.8998, policy_loss: 0.8089, value_loss: 0.4184
2024-07-11 17:58:07,917 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:58:08,339 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:58:08,395 [INFO    ] __main__: train step 23562: loss: 0.8998, policy_loss: 0.8089, value_loss: 0.4184
2024-07-11 17:58:08,579 [INFO    ] __main__: train step 23563: loss: 0.8998, policy_loss: 0.8089, value_loss: 0.4184
2024-07-11 17:58:08,823 [INFO    ] __main__: train step 23564: loss: 0.8998, policy_loss: 0.8089, value_loss: 0.4184
2024-07-11 17:58:09,032 [INFO    ] __main__: train step 23565: loss: 0.8998, policy_loss: 0.8089, value_loss: 0.4184
2024-07-11 17:58:09,252 [INFO    ] __main__: train step 23566: loss: 0.8997, policy_loss: 0.8089, value_loss: 0.4183
2024-07-11 17:58:09,475 [INFO    ] __main__: train step 23567: loss: 0.8997, policy_loss: 0.8088, value_loss: 0.4183
2024-07-11 17:58:09,683 [INFO    ] __main__: train step 23568: loss: 0.8997, policy_loss: 0.8088, value_loss: 0.4183
2024-07-11 17:58:09,894 [INFO    ] __main__: train step 23569: loss: 0.8997, policy_loss: 0.8088, value_loss: 0.4183
2024-07-11 17:58:10,109 [INFO    ] __main__: train step 23570: loss: 0.8997, policy_loss: 0.8088, value_loss: 0.4183
2024-07-11 17:58:10,311 [INFO    ] __main__: train step 23571: loss: 0.8997, policy_loss: 0.8088, value_loss: 0.4183
2024-07-11 17:58:10,516 [INFO    ] __main__: train step 23572: loss: 0.8997, policy_loss: 0.8088, value_loss: 0.4182
2024-07-11 17:58:10,717 [INFO    ] __main__: train step 23573: loss: 0.8996, policy_loss: 0.8088, value_loss: 0.4182
2024-07-11 17:58:10,938 [INFO    ] __main__: train step 23574: loss: 0.8996, policy_loss: 0.8088, value_loss: 0.4182
2024-07-11 17:58:11,136 [INFO    ] __main__: train step 23575: loss: 0.8996, policy_loss: 0.8087, value_loss: 0.4182
2024-07-11 17:58:11,342 [INFO    ] __main__: train step 23576: loss: 0.8996, policy_loss: 0.8087, value_loss: 0.4182
2024-07-11 17:58:11,546 [INFO    ] __main__: train step 23577: loss: 0.8996, policy_loss: 0.8087, value_loss: 0.4182
2024-07-11 17:58:11,771 [INFO    ] __main__: train step 23578: loss: 0.8996, policy_loss: 0.8087, value_loss: 0.4182
2024-07-11 17:58:13,254 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:58:13,630 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:58:13,686 [INFO    ] __main__: train step 23579: loss: 0.8995, policy_loss: 0.8087, value_loss: 0.4181
2024-07-11 17:58:13,867 [INFO    ] __main__: train step 23580: loss: 0.8995, policy_loss: 0.8087, value_loss: 0.4181
2024-07-11 17:58:14,114 [INFO    ] __main__: train step 23581: loss: 0.8995, policy_loss: 0.8087, value_loss: 0.4181
2024-07-11 17:58:14,315 [INFO    ] __main__: train step 23582: loss: 0.8995, policy_loss: 0.8086, value_loss: 0.4181
2024-07-11 17:58:14,516 [INFO    ] __main__: train step 23583: loss: 0.8995, policy_loss: 0.8086, value_loss: 0.4181
2024-07-11 17:58:14,732 [INFO    ] __main__: train step 23584: loss: 0.8995, policy_loss: 0.8086, value_loss: 0.4181
2024-07-11 17:58:14,984 [INFO    ] __main__: train step 23585: loss: 0.8995, policy_loss: 0.8086, value_loss: 0.4181
2024-07-11 17:58:15,233 [INFO    ] __main__: train step 23586: loss: 0.8994, policy_loss: 0.8086, value_loss: 0.4180
2024-07-11 17:58:15,454 [INFO    ] __main__: train step 23587: loss: 0.8994, policy_loss: 0.8086, value_loss: 0.4180
2024-07-11 17:58:15,693 [INFO    ] __main__: train step 23588: loss: 0.8994, policy_loss: 0.8086, value_loss: 0.4180
2024-07-11 17:58:15,903 [INFO    ] __main__: train step 23589: loss: 0.8994, policy_loss: 0.8085, value_loss: 0.4180
2024-07-11 17:58:16,103 [INFO    ] __main__: train step 23590: loss: 0.8994, policy_loss: 0.8085, value_loss: 0.4180
2024-07-11 17:58:16,307 [INFO    ] __main__: train step 23591: loss: 0.8994, policy_loss: 0.8085, value_loss: 0.4180
2024-07-11 17:58:16,511 [INFO    ] __main__: train step 23592: loss: 0.8994, policy_loss: 0.8085, value_loss: 0.4179
2024-07-11 17:58:16,718 [INFO    ] __main__: train step 23593: loss: 0.8993, policy_loss: 0.8085, value_loss: 0.4179
2024-07-11 17:58:16,923 [INFO    ] __main__: train step 23594: loss: 0.8993, policy_loss: 0.8085, value_loss: 0.4179
2024-07-11 17:58:17,156 [INFO    ] __main__: train step 23595: loss: 0.8993, policy_loss: 0.8085, value_loss: 0.4179
2024-07-11 17:58:18,606 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:58:19,037 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:58:19,096 [INFO    ] __main__: train step 23596: loss: 0.8993, policy_loss: 0.8085, value_loss: 0.4179
2024-07-11 17:58:19,273 [INFO    ] __main__: train step 23597: loss: 0.8993, policy_loss: 0.8084, value_loss: 0.4179
2024-07-11 17:58:19,491 [INFO    ] __main__: train step 23598: loss: 0.8993, policy_loss: 0.8084, value_loss: 0.4179
2024-07-11 17:58:19,699 [INFO    ] __main__: train step 23599: loss: 0.8993, policy_loss: 0.8084, value_loss: 0.4178
2024-07-11 17:58:19,929 [INFO    ] __main__: train step 23600: loss: 0.8992, policy_loss: 0.8084, value_loss: 0.4178
2024-07-11 17:58:20,141 [INFO    ] __main__: train step 23601: loss: 0.8992, policy_loss: 0.8084, value_loss: 0.4178
2024-07-11 17:58:22,593 [INFO    ] __main__: train step 23602: loss: 0.8992, policy_loss: 0.8084, value_loss: 0.4178
2024-07-11 17:58:22,773 [INFO    ] __main__: train step 23603: loss: 0.8992, policy_loss: 0.8084, value_loss: 0.4178
2024-07-11 17:58:22,973 [INFO    ] __main__: train step 23604: loss: 0.8992, policy_loss: 0.8083, value_loss: 0.4178
2024-07-11 17:58:23,167 [INFO    ] __main__: train step 23605: loss: 0.8992, policy_loss: 0.8083, value_loss: 0.4178
2024-07-11 17:58:23,382 [INFO    ] __main__: train step 23606: loss: 0.8992, policy_loss: 0.8083, value_loss: 0.4177
2024-07-11 17:58:23,607 [INFO    ] __main__: train step 23607: loss: 0.8991, policy_loss: 0.8083, value_loss: 0.4177
2024-07-11 17:58:23,847 [INFO    ] __main__: train step 23608: loss: 0.8991, policy_loss: 0.8083, value_loss: 0.4177
2024-07-11 17:58:24,053 [INFO    ] __main__: train step 23609: loss: 0.8991, policy_loss: 0.8083, value_loss: 0.4177
2024-07-11 17:58:24,280 [INFO    ] __main__: train step 23610: loss: 0.8991, policy_loss: 0.8083, value_loss: 0.4177
2024-07-11 17:58:24,488 [INFO    ] __main__: train step 23611: loss: 0.8991, policy_loss: 0.8083, value_loss: 0.4177
2024-07-11 17:58:24,713 [INFO    ] __main__: train step 23612: loss: 0.8991, policy_loss: 0.8082, value_loss: 0.4176
2024-07-11 17:58:26,161 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:58:26,562 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:58:26,619 [INFO    ] __main__: train step 23613: loss: 0.8990, policy_loss: 0.8082, value_loss: 0.4176
2024-07-11 17:58:26,789 [INFO    ] __main__: train step 23614: loss: 0.8990, policy_loss: 0.8082, value_loss: 0.4176
2024-07-11 17:58:27,017 [INFO    ] __main__: train step 23615: loss: 0.8990, policy_loss: 0.8082, value_loss: 0.4176
2024-07-11 17:58:27,226 [INFO    ] __main__: train step 23616: loss: 0.8990, policy_loss: 0.8082, value_loss: 0.4176
2024-07-11 17:58:27,435 [INFO    ] __main__: train step 23617: loss: 0.8990, policy_loss: 0.8082, value_loss: 0.4176
2024-07-11 17:58:27,651 [INFO    ] __main__: train step 23618: loss: 0.8990, policy_loss: 0.8082, value_loss: 0.4176
2024-07-11 17:58:27,858 [INFO    ] __main__: train step 23619: loss: 0.8990, policy_loss: 0.8081, value_loss: 0.4175
2024-07-11 17:58:28,070 [INFO    ] __main__: train step 23620: loss: 0.8989, policy_loss: 0.8081, value_loss: 0.4175
2024-07-11 17:58:28,286 [INFO    ] __main__: train step 23621: loss: 0.8989, policy_loss: 0.8081, value_loss: 0.4175
2024-07-11 17:58:28,497 [INFO    ] __main__: train step 23622: loss: 0.8989, policy_loss: 0.8081, value_loss: 0.4175
2024-07-11 17:58:28,709 [INFO    ] __main__: train step 23623: loss: 0.8989, policy_loss: 0.8081, value_loss: 0.4175
2024-07-11 17:58:28,913 [INFO    ] __main__: train step 23624: loss: 0.8989, policy_loss: 0.8081, value_loss: 0.4175
2024-07-11 17:58:29,129 [INFO    ] __main__: train step 23625: loss: 0.8989, policy_loss: 0.8081, value_loss: 0.4175
2024-07-11 17:58:29,329 [INFO    ] __main__: train step 23626: loss: 0.8989, policy_loss: 0.8080, value_loss: 0.4174
2024-07-11 17:58:29,549 [INFO    ] __main__: train step 23627: loss: 0.8988, policy_loss: 0.8080, value_loss: 0.4174
2024-07-11 17:58:29,758 [INFO    ] __main__: train step 23628: loss: 0.8988, policy_loss: 0.8080, value_loss: 0.4174
2024-07-11 17:58:29,981 [INFO    ] __main__: train step 23629: loss: 0.8988, policy_loss: 0.8080, value_loss: 0.4174
2024-07-11 17:58:31,454 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:58:31,837 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:58:31,893 [INFO    ] __main__: train step 23630: loss: 0.8988, policy_loss: 0.8080, value_loss: 0.4174
2024-07-11 17:58:32,070 [INFO    ] __main__: train step 23631: loss: 0.8988, policy_loss: 0.8080, value_loss: 0.4174
2024-07-11 17:58:32,266 [INFO    ] __main__: train step 23632: loss: 0.8988, policy_loss: 0.8080, value_loss: 0.4173
2024-07-11 17:58:32,470 [INFO    ] __main__: train step 23633: loss: 0.8988, policy_loss: 0.8080, value_loss: 0.4173
2024-07-11 17:58:32,680 [INFO    ] __main__: train step 23634: loss: 0.8987, policy_loss: 0.8079, value_loss: 0.4173
2024-07-11 17:58:32,893 [INFO    ] __main__: train step 23635: loss: 0.8987, policy_loss: 0.8079, value_loss: 0.4173
2024-07-11 17:58:33,142 [INFO    ] __main__: train step 23636: loss: 0.8987, policy_loss: 0.8079, value_loss: 0.4173
2024-07-11 17:58:33,402 [INFO    ] __main__: train step 23637: loss: 0.8987, policy_loss: 0.8079, value_loss: 0.4173
2024-07-11 17:58:33,637 [INFO    ] __main__: train step 23638: loss: 0.8987, policy_loss: 0.8079, value_loss: 0.4173
2024-07-11 17:58:33,841 [INFO    ] __main__: train step 23639: loss: 0.8987, policy_loss: 0.8079, value_loss: 0.4172
2024-07-11 17:58:34,047 [INFO    ] __main__: train step 23640: loss: 0.8987, policy_loss: 0.8079, value_loss: 0.4172
2024-07-11 17:58:34,260 [INFO    ] __main__: train step 23641: loss: 0.8986, policy_loss: 0.8078, value_loss: 0.4172
2024-07-11 17:58:34,469 [INFO    ] __main__: train step 23642: loss: 0.8986, policy_loss: 0.8078, value_loss: 0.4172
2024-07-11 17:58:34,685 [INFO    ] __main__: train step 23643: loss: 0.8986, policy_loss: 0.8078, value_loss: 0.4172
2024-07-11 17:58:34,892 [INFO    ] __main__: train step 23644: loss: 0.8986, policy_loss: 0.8078, value_loss: 0.4172
2024-07-11 17:58:35,123 [INFO    ] __main__: train step 23645: loss: 0.8986, policy_loss: 0.8078, value_loss: 0.4172
2024-07-11 17:58:35,334 [INFO    ] __main__: train step 23646: loss: 0.8986, policy_loss: 0.8078, value_loss: 0.4171
2024-07-11 17:58:36,792 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:58:37,180 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:58:37,236 [INFO    ] __main__: train step 23647: loss: 0.8985, policy_loss: 0.8078, value_loss: 0.4171
2024-07-11 17:58:37,415 [INFO    ] __main__: train step 23648: loss: 0.8985, policy_loss: 0.8077, value_loss: 0.4171
2024-07-11 17:58:37,619 [INFO    ] __main__: train step 23649: loss: 0.8985, policy_loss: 0.8077, value_loss: 0.4171
2024-07-11 17:58:37,823 [INFO    ] __main__: train step 23650: loss: 0.8985, policy_loss: 0.8077, value_loss: 0.4171
2024-07-11 17:58:38,027 [INFO    ] __main__: train step 23651: loss: 0.8985, policy_loss: 0.8077, value_loss: 0.4171
2024-07-11 17:58:38,229 [INFO    ] __main__: train step 23652: loss: 0.8985, policy_loss: 0.8077, value_loss: 0.4170
2024-07-11 17:58:38,447 [INFO    ] __main__: train step 23653: loss: 0.8985, policy_loss: 0.8077, value_loss: 0.4170
2024-07-11 17:58:38,682 [INFO    ] __main__: train step 23654: loss: 0.8984, policy_loss: 0.8077, value_loss: 0.4170
2024-07-11 17:58:38,890 [INFO    ] __main__: train step 23655: loss: 0.8984, policy_loss: 0.8076, value_loss: 0.4170
2024-07-11 17:58:39,136 [INFO    ] __main__: train step 23656: loss: 0.8984, policy_loss: 0.8076, value_loss: 0.4170
2024-07-11 17:58:39,359 [INFO    ] __main__: train step 23657: loss: 0.8984, policy_loss: 0.8076, value_loss: 0.4170
2024-07-11 17:58:39,561 [INFO    ] __main__: train step 23658: loss: 0.8984, policy_loss: 0.8076, value_loss: 0.4170
2024-07-11 17:58:39,776 [INFO    ] __main__: train step 23659: loss: 0.8984, policy_loss: 0.8076, value_loss: 0.4169
2024-07-11 17:58:40,021 [INFO    ] __main__: train step 23660: loss: 0.8983, policy_loss: 0.8076, value_loss: 0.4169
2024-07-11 17:58:40,248 [INFO    ] __main__: train step 23661: loss: 0.8983, policy_loss: 0.8076, value_loss: 0.4169
2024-07-11 17:58:40,448 [INFO    ] __main__: train step 23662: loss: 0.8983, policy_loss: 0.8075, value_loss: 0.4169
2024-07-11 17:58:40,651 [INFO    ] __main__: train step 23663: loss: 0.8983, policy_loss: 0.8075, value_loss: 0.4169
2024-07-11 17:58:42,092 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:58:42,489 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:58:42,544 [INFO    ] __main__: train step 23664: loss: 0.8983, policy_loss: 0.8075, value_loss: 0.4169
2024-07-11 17:58:42,733 [INFO    ] __main__: train step 23665: loss: 0.8983, policy_loss: 0.8075, value_loss: 0.4169
2024-07-11 17:58:42,932 [INFO    ] __main__: train step 23666: loss: 0.8983, policy_loss: 0.8075, value_loss: 0.4168
2024-07-11 17:58:43,137 [INFO    ] __main__: train step 23667: loss: 0.8982, policy_loss: 0.8075, value_loss: 0.4168
2024-07-11 17:58:43,351 [INFO    ] __main__: train step 23668: loss: 0.8982, policy_loss: 0.8075, value_loss: 0.4168
2024-07-11 17:58:43,548 [INFO    ] __main__: train step 23669: loss: 0.8982, policy_loss: 0.8075, value_loss: 0.4168
2024-07-11 17:58:43,745 [INFO    ] __main__: train step 23670: loss: 0.8982, policy_loss: 0.8074, value_loss: 0.4168
2024-07-11 17:58:43,960 [INFO    ] __main__: train step 23671: loss: 0.8982, policy_loss: 0.8074, value_loss: 0.4168
2024-07-11 17:58:44,160 [INFO    ] __main__: train step 23672: loss: 0.8982, policy_loss: 0.8074, value_loss: 0.4167
2024-07-11 17:58:44,365 [INFO    ] __main__: train step 23673: loss: 0.8982, policy_loss: 0.8074, value_loss: 0.4167
2024-07-11 17:58:44,588 [INFO    ] __main__: train step 23674: loss: 0.8981, policy_loss: 0.8074, value_loss: 0.4167
2024-07-11 17:58:44,826 [INFO    ] __main__: train step 23675: loss: 0.8981, policy_loss: 0.8074, value_loss: 0.4167
2024-07-11 17:58:45,035 [INFO    ] __main__: train step 23676: loss: 0.8981, policy_loss: 0.8074, value_loss: 0.4167
2024-07-11 17:58:45,255 [INFO    ] __main__: train step 23677: loss: 0.8981, policy_loss: 0.8073, value_loss: 0.4167
2024-07-11 17:58:45,485 [INFO    ] __main__: train step 23678: loss: 0.8981, policy_loss: 0.8073, value_loss: 0.4167
2024-07-11 17:58:45,702 [INFO    ] __main__: train step 23679: loss: 0.8981, policy_loss: 0.8073, value_loss: 0.4166
2024-07-11 17:58:45,923 [INFO    ] __main__: train step 23680: loss: 0.8980, policy_loss: 0.8073, value_loss: 0.4166
2024-07-11 17:58:47,373 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:58:47,787 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:58:47,846 [INFO    ] __main__: train step 23681: loss: 0.8980, policy_loss: 0.8073, value_loss: 0.4166
2024-07-11 17:58:48,037 [INFO    ] __main__: train step 23682: loss: 0.8980, policy_loss: 0.8073, value_loss: 0.4166
2024-07-11 17:58:48,256 [INFO    ] __main__: train step 23683: loss: 0.8980, policy_loss: 0.8073, value_loss: 0.4166
2024-07-11 17:58:48,459 [INFO    ] __main__: train step 23684: loss: 0.8980, policy_loss: 0.8072, value_loss: 0.4166
2024-07-11 17:58:48,672 [INFO    ] __main__: train step 23685: loss: 0.8980, policy_loss: 0.8072, value_loss: 0.4166
2024-07-11 17:58:48,881 [INFO    ] __main__: train step 23686: loss: 0.8980, policy_loss: 0.8072, value_loss: 0.4165
2024-07-11 17:58:49,092 [INFO    ] __main__: train step 23687: loss: 0.8979, policy_loss: 0.8072, value_loss: 0.4165
2024-07-11 17:58:49,303 [INFO    ] __main__: train step 23688: loss: 0.8979, policy_loss: 0.8072, value_loss: 0.4165
2024-07-11 17:58:49,547 [INFO    ] __main__: train step 23689: loss: 0.8979, policy_loss: 0.8072, value_loss: 0.4165
2024-07-11 17:58:49,784 [INFO    ] __main__: train step 23690: loss: 0.8979, policy_loss: 0.8072, value_loss: 0.4165
2024-07-11 17:58:49,992 [INFO    ] __main__: train step 23691: loss: 0.8979, policy_loss: 0.8071, value_loss: 0.4165
2024-07-11 17:58:50,198 [INFO    ] __main__: train step 23692: loss: 0.8979, policy_loss: 0.8071, value_loss: 0.4164
2024-07-11 17:58:50,410 [INFO    ] __main__: train step 23693: loss: 0.8978, policy_loss: 0.8071, value_loss: 0.4164
2024-07-11 17:58:50,603 [INFO    ] __main__: train step 23694: loss: 0.8978, policy_loss: 0.8071, value_loss: 0.4164
2024-07-11 17:58:50,807 [INFO    ] __main__: train step 23695: loss: 0.8978, policy_loss: 0.8071, value_loss: 0.4164
2024-07-11 17:58:51,019 [INFO    ] __main__: train step 23696: loss: 0.8978, policy_loss: 0.8071, value_loss: 0.4164
2024-07-11 17:58:51,226 [INFO    ] __main__: train step 23697: loss: 0.8978, policy_loss: 0.8071, value_loss: 0.4164
2024-07-11 17:58:52,668 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:58:53,078 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:58:53,135 [INFO    ] __main__: train step 23698: loss: 0.8978, policy_loss: 0.8070, value_loss: 0.4164
2024-07-11 17:58:53,321 [INFO    ] __main__: train step 23699: loss: 0.8978, policy_loss: 0.8070, value_loss: 0.4163
2024-07-11 17:58:53,557 [INFO    ] __main__: train step 23700: loss: 0.8977, policy_loss: 0.8070, value_loss: 0.4163
2024-07-11 17:58:53,791 [INFO    ] __main__: train step 23701: loss: 0.8977, policy_loss: 0.8070, value_loss: 0.4163
2024-07-11 17:58:54,021 [INFO    ] __main__: train step 23702: loss: 0.8977, policy_loss: 0.8070, value_loss: 0.4163
2024-07-11 17:58:54,253 [INFO    ] __main__: train step 23703: loss: 0.8977, policy_loss: 0.8070, value_loss: 0.4163
2024-07-11 17:58:54,490 [INFO    ] __main__: train step 23704: loss: 0.8977, policy_loss: 0.8070, value_loss: 0.4163
2024-07-11 17:58:54,701 [INFO    ] __main__: train step 23705: loss: 0.8977, policy_loss: 0.8069, value_loss: 0.4163
2024-07-11 17:58:54,919 [INFO    ] __main__: train step 23706: loss: 0.8976, policy_loss: 0.8069, value_loss: 0.4162
2024-07-11 17:58:55,118 [INFO    ] __main__: train step 23707: loss: 0.8976, policy_loss: 0.8069, value_loss: 0.4162
2024-07-11 17:58:55,324 [INFO    ] __main__: train step 23708: loss: 0.8976, policy_loss: 0.8069, value_loss: 0.4162
2024-07-11 17:58:55,526 [INFO    ] __main__: train step 23709: loss: 0.8976, policy_loss: 0.8069, value_loss: 0.4162
2024-07-11 17:58:55,733 [INFO    ] __main__: train step 23710: loss: 0.8976, policy_loss: 0.8069, value_loss: 0.4162
2024-07-11 17:58:55,945 [INFO    ] __main__: train step 23711: loss: 0.8976, policy_loss: 0.8069, value_loss: 0.4162
2024-07-11 17:58:56,144 [INFO    ] __main__: train step 23712: loss: 0.8976, policy_loss: 0.8068, value_loss: 0.4161
2024-07-11 17:58:56,353 [INFO    ] __main__: train step 23713: loss: 0.8975, policy_loss: 0.8068, value_loss: 0.4161
2024-07-11 17:58:56,547 [INFO    ] __main__: train step 23714: loss: 0.8975, policy_loss: 0.8068, value_loss: 0.4161
2024-07-11 17:58:58,006 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:58:58,395 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:58:58,450 [INFO    ] __main__: train step 23715: loss: 0.8975, policy_loss: 0.8068, value_loss: 0.4161
2024-07-11 17:58:58,634 [INFO    ] __main__: train step 23716: loss: 0.8975, policy_loss: 0.8068, value_loss: 0.4161
2024-07-11 17:58:58,841 [INFO    ] __main__: train step 23717: loss: 0.8975, policy_loss: 0.8068, value_loss: 0.4161
2024-07-11 17:58:59,052 [INFO    ] __main__: train step 23718: loss: 0.8975, policy_loss: 0.8068, value_loss: 0.4161
2024-07-11 17:58:59,258 [INFO    ] __main__: train step 23719: loss: 0.8974, policy_loss: 0.8067, value_loss: 0.4160
2024-07-11 17:58:59,489 [INFO    ] __main__: train step 23720: loss: 0.8974, policy_loss: 0.8067, value_loss: 0.4160
2024-07-11 17:58:59,693 [INFO    ] __main__: train step 23721: loss: 0.8974, policy_loss: 0.8067, value_loss: 0.4160
2024-07-11 17:58:59,917 [INFO    ] __main__: train step 23722: loss: 0.8974, policy_loss: 0.8067, value_loss: 0.4160
2024-07-11 17:59:00,116 [INFO    ] __main__: train step 23723: loss: 0.8974, policy_loss: 0.8067, value_loss: 0.4160
2024-07-11 17:59:00,318 [INFO    ] __main__: train step 23724: loss: 0.8974, policy_loss: 0.8067, value_loss: 0.4160
2024-07-11 17:59:00,535 [INFO    ] __main__: train step 23725: loss: 0.8974, policy_loss: 0.8067, value_loss: 0.4160
2024-07-11 17:59:00,777 [INFO    ] __main__: train step 23726: loss: 0.8973, policy_loss: 0.8067, value_loss: 0.4159
2024-07-11 17:59:00,982 [INFO    ] __main__: train step 23727: loss: 0.8973, policy_loss: 0.8066, value_loss: 0.4159
2024-07-11 17:59:01,190 [INFO    ] __main__: train step 23728: loss: 0.8973, policy_loss: 0.8066, value_loss: 0.4159
2024-07-11 17:59:01,413 [INFO    ] __main__: train step 23729: loss: 0.8973, policy_loss: 0.8066, value_loss: 0.4159
2024-07-11 17:59:01,615 [INFO    ] __main__: train step 23730: loss: 0.8973, policy_loss: 0.8066, value_loss: 0.4159
2024-07-11 17:59:01,828 [INFO    ] __main__: train step 23731: loss: 0.8973, policy_loss: 0.8066, value_loss: 0.4159
2024-07-11 17:59:03,267 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:59:03,698 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:59:03,762 [INFO    ] __main__: train step 23732: loss: 0.8972, policy_loss: 0.8066, value_loss: 0.4158
2024-07-11 17:59:03,940 [INFO    ] __main__: train step 23733: loss: 0.8972, policy_loss: 0.8066, value_loss: 0.4158
2024-07-11 17:59:04,150 [INFO    ] __main__: train step 23734: loss: 0.8972, policy_loss: 0.8065, value_loss: 0.4158
2024-07-11 17:59:04,358 [INFO    ] __main__: train step 23735: loss: 0.8972, policy_loss: 0.8065, value_loss: 0.4158
2024-07-11 17:59:04,568 [INFO    ] __main__: train step 23736: loss: 0.8972, policy_loss: 0.8065, value_loss: 0.4158
2024-07-11 17:59:04,793 [INFO    ] __main__: train step 23737: loss: 0.8972, policy_loss: 0.8065, value_loss: 0.4158
2024-07-11 17:59:04,990 [INFO    ] __main__: train step 23738: loss: 0.8972, policy_loss: 0.8065, value_loss: 0.4158
2024-07-11 17:59:05,209 [INFO    ] __main__: train step 23739: loss: 0.8971, policy_loss: 0.8065, value_loss: 0.4157
2024-07-11 17:59:05,422 [INFO    ] __main__: train step 23740: loss: 0.8971, policy_loss: 0.8065, value_loss: 0.4157
2024-07-11 17:59:05,637 [INFO    ] __main__: train step 23741: loss: 0.8971, policy_loss: 0.8064, value_loss: 0.4157
2024-07-11 17:59:05,850 [INFO    ] __main__: train step 23742: loss: 0.8971, policy_loss: 0.8064, value_loss: 0.4157
2024-07-11 17:59:06,062 [INFO    ] __main__: train step 23743: loss: 0.8971, policy_loss: 0.8064, value_loss: 0.4157
2024-07-11 17:59:08,445 [INFO    ] __main__: train step 23744: loss: 0.8971, policy_loss: 0.8064, value_loss: 0.4157
2024-07-11 17:59:08,651 [INFO    ] __main__: train step 23745: loss: 0.8970, policy_loss: 0.8064, value_loss: 0.4157
2024-07-11 17:59:08,878 [INFO    ] __main__: train step 23746: loss: 0.8970, policy_loss: 0.8064, value_loss: 0.4156
2024-07-11 17:59:09,092 [INFO    ] __main__: train step 23747: loss: 0.8970, policy_loss: 0.8063, value_loss: 0.4156
2024-07-11 17:59:09,334 [INFO    ] __main__: train step 23748: loss: 0.8970, policy_loss: 0.8063, value_loss: 0.4156
2024-07-11 17:59:10,795 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:59:11,206 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:59:11,269 [INFO    ] __main__: train step 23749: loss: 0.8970, policy_loss: 0.8063, value_loss: 0.4156
2024-07-11 17:59:11,450 [INFO    ] __main__: train step 23750: loss: 0.8970, policy_loss: 0.8063, value_loss: 0.4156
2024-07-11 17:59:11,659 [INFO    ] __main__: train step 23751: loss: 0.8969, policy_loss: 0.8063, value_loss: 0.4156
2024-07-11 17:59:11,857 [INFO    ] __main__: train step 23752: loss: 0.8969, policy_loss: 0.8063, value_loss: 0.4155
2024-07-11 17:59:12,070 [INFO    ] __main__: train step 23753: loss: 0.8969, policy_loss: 0.8063, value_loss: 0.4155
2024-07-11 17:59:12,290 [INFO    ] __main__: train step 23754: loss: 0.8969, policy_loss: 0.8062, value_loss: 0.4155
2024-07-11 17:59:12,499 [INFO    ] __main__: train step 23755: loss: 0.8969, policy_loss: 0.8062, value_loss: 0.4155
2024-07-11 17:59:12,697 [INFO    ] __main__: train step 23756: loss: 0.8969, policy_loss: 0.8062, value_loss: 0.4155
2024-07-11 17:59:12,903 [INFO    ] __main__: train step 23757: loss: 0.8969, policy_loss: 0.8062, value_loss: 0.4155
2024-07-11 17:59:13,112 [INFO    ] __main__: train step 23758: loss: 0.8968, policy_loss: 0.8062, value_loss: 0.4155
2024-07-11 17:59:13,312 [INFO    ] __main__: train step 23759: loss: 0.8968, policy_loss: 0.8062, value_loss: 0.4154
2024-07-11 17:59:13,511 [INFO    ] __main__: train step 23760: loss: 0.8968, policy_loss: 0.8062, value_loss: 0.4154
2024-07-11 17:59:13,719 [INFO    ] __main__: train step 23761: loss: 0.8968, policy_loss: 0.8061, value_loss: 0.4154
2024-07-11 17:59:13,921 [INFO    ] __main__: train step 23762: loss: 0.8968, policy_loss: 0.8061, value_loss: 0.4154
2024-07-11 17:59:14,126 [INFO    ] __main__: train step 23763: loss: 0.8968, policy_loss: 0.8061, value_loss: 0.4154
2024-07-11 17:59:14,337 [INFO    ] __main__: train step 23764: loss: 0.8967, policy_loss: 0.8061, value_loss: 0.4154
2024-07-11 17:59:14,572 [INFO    ] __main__: train step 23765: loss: 0.8967, policy_loss: 0.8061, value_loss: 0.4153
2024-07-11 17:59:16,017 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:59:16,424 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:59:16,485 [INFO    ] __main__: train step 23766: loss: 0.8967, policy_loss: 0.8061, value_loss: 0.4153
2024-07-11 17:59:16,659 [INFO    ] __main__: train step 23767: loss: 0.8967, policy_loss: 0.8061, value_loss: 0.4153
2024-07-11 17:59:16,869 [INFO    ] __main__: train step 23768: loss: 0.8967, policy_loss: 0.8060, value_loss: 0.4153
2024-07-11 17:59:17,079 [INFO    ] __main__: train step 23769: loss: 0.8967, policy_loss: 0.8060, value_loss: 0.4153
2024-07-11 17:59:17,316 [INFO    ] __main__: train step 23770: loss: 0.8966, policy_loss: 0.8060, value_loss: 0.4153
2024-07-11 17:59:17,517 [INFO    ] __main__: train step 23771: loss: 0.8966, policy_loss: 0.8060, value_loss: 0.4153
2024-07-11 17:59:17,725 [INFO    ] __main__: train step 23772: loss: 0.8966, policy_loss: 0.8060, value_loss: 0.4152
2024-07-11 17:59:17,966 [INFO    ] __main__: train step 23773: loss: 0.8966, policy_loss: 0.8060, value_loss: 0.4152
2024-07-11 17:59:18,188 [INFO    ] __main__: train step 23774: loss: 0.8966, policy_loss: 0.8060, value_loss: 0.4152
2024-07-11 17:59:18,424 [INFO    ] __main__: train step 23775: loss: 0.8966, policy_loss: 0.8059, value_loss: 0.4152
2024-07-11 17:59:18,627 [INFO    ] __main__: train step 23776: loss: 0.8965, policy_loss: 0.8059, value_loss: 0.4152
2024-07-11 17:59:18,842 [INFO    ] __main__: train step 23777: loss: 0.8965, policy_loss: 0.8059, value_loss: 0.4152
2024-07-11 17:59:19,064 [INFO    ] __main__: train step 23778: loss: 0.8965, policy_loss: 0.8059, value_loss: 0.4152
2024-07-11 17:59:19,270 [INFO    ] __main__: train step 23779: loss: 0.8965, policy_loss: 0.8059, value_loss: 0.4151
2024-07-11 17:59:19,465 [INFO    ] __main__: train step 23780: loss: 0.8965, policy_loss: 0.8059, value_loss: 0.4151
2024-07-11 17:59:19,670 [INFO    ] __main__: train step 23781: loss: 0.8965, policy_loss: 0.8059, value_loss: 0.4151
2024-07-11 17:59:19,893 [INFO    ] __main__: train step 23782: loss: 0.8965, policy_loss: 0.8058, value_loss: 0.4151
2024-07-11 17:59:21,340 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:59:21,751 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:59:21,815 [INFO    ] __main__: train step 23783: loss: 0.8964, policy_loss: 0.8058, value_loss: 0.4151
2024-07-11 17:59:21,993 [INFO    ] __main__: train step 23784: loss: 0.8964, policy_loss: 0.8058, value_loss: 0.4151
2024-07-11 17:59:22,209 [INFO    ] __main__: train step 23785: loss: 0.8964, policy_loss: 0.8058, value_loss: 0.4150
2024-07-11 17:59:22,444 [INFO    ] __main__: train step 23786: loss: 0.8964, policy_loss: 0.8058, value_loss: 0.4150
2024-07-11 17:59:22,670 [INFO    ] __main__: train step 23787: loss: 0.8964, policy_loss: 0.8058, value_loss: 0.4150
2024-07-11 17:59:22,879 [INFO    ] __main__: train step 23788: loss: 0.8964, policy_loss: 0.8058, value_loss: 0.4150
2024-07-11 17:59:23,085 [INFO    ] __main__: train step 23789: loss: 0.8963, policy_loss: 0.8057, value_loss: 0.4150
2024-07-11 17:59:23,280 [INFO    ] __main__: train step 23790: loss: 0.8963, policy_loss: 0.8057, value_loss: 0.4150
2024-07-11 17:59:23,475 [INFO    ] __main__: train step 23791: loss: 0.8963, policy_loss: 0.8057, value_loss: 0.4150
2024-07-11 17:59:23,684 [INFO    ] __main__: train step 23792: loss: 0.8963, policy_loss: 0.8057, value_loss: 0.4149
2024-07-11 17:59:23,902 [INFO    ] __main__: train step 23793: loss: 0.8963, policy_loss: 0.8057, value_loss: 0.4149
2024-07-11 17:59:24,143 [INFO    ] __main__: train step 23794: loss: 0.8963, policy_loss: 0.8057, value_loss: 0.4149
2024-07-11 17:59:24,362 [INFO    ] __main__: train step 23795: loss: 0.8962, policy_loss: 0.8057, value_loss: 0.4149
2024-07-11 17:59:24,565 [INFO    ] __main__: train step 23796: loss: 0.8962, policy_loss: 0.8056, value_loss: 0.4149
2024-07-11 17:59:24,775 [INFO    ] __main__: train step 23797: loss: 0.8962, policy_loss: 0.8056, value_loss: 0.4149
2024-07-11 17:59:24,988 [INFO    ] __main__: train step 23798: loss: 0.8962, policy_loss: 0.8056, value_loss: 0.4149
2024-07-11 17:59:25,205 [INFO    ] __main__: train step 23799: loss: 0.8962, policy_loss: 0.8056, value_loss: 0.4148
2024-07-11 17:59:26,647 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:59:27,059 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:59:27,118 [INFO    ] __main__: train step 23800: loss: 0.8962, policy_loss: 0.8056, value_loss: 0.4148
2024-07-11 17:59:27,296 [INFO    ] __main__: train step 23801: loss: 0.8961, policy_loss: 0.8056, value_loss: 0.4148
2024-07-11 17:59:27,499 [INFO    ] __main__: train step 23802: loss: 0.8961, policy_loss: 0.8055, value_loss: 0.4148
2024-07-11 17:59:27,716 [INFO    ] __main__: train step 23803: loss: 0.8961, policy_loss: 0.8055, value_loss: 0.4148
2024-07-11 17:59:27,921 [INFO    ] __main__: train step 23804: loss: 0.8961, policy_loss: 0.8055, value_loss: 0.4148
2024-07-11 17:59:28,133 [INFO    ] __main__: train step 23805: loss: 0.8961, policy_loss: 0.8055, value_loss: 0.4147
2024-07-11 17:59:28,338 [INFO    ] __main__: train step 23806: loss: 0.8961, policy_loss: 0.8055, value_loss: 0.4147
2024-07-11 17:59:28,542 [INFO    ] __main__: train step 23807: loss: 0.8960, policy_loss: 0.8055, value_loss: 0.4147
2024-07-11 17:59:28,757 [INFO    ] __main__: train step 23808: loss: 0.8960, policy_loss: 0.8055, value_loss: 0.4147
2024-07-11 17:59:28,968 [INFO    ] __main__: train step 23809: loss: 0.8960, policy_loss: 0.8054, value_loss: 0.4147
2024-07-11 17:59:29,176 [INFO    ] __main__: train step 23810: loss: 0.8960, policy_loss: 0.8054, value_loss: 0.4147
2024-07-11 17:59:29,400 [INFO    ] __main__: train step 23811: loss: 0.8960, policy_loss: 0.8054, value_loss: 0.4147
2024-07-11 17:59:29,595 [INFO    ] __main__: train step 23812: loss: 0.8960, policy_loss: 0.8054, value_loss: 0.4146
2024-07-11 17:59:29,828 [INFO    ] __main__: train step 23813: loss: 0.8960, policy_loss: 0.8054, value_loss: 0.4146
2024-07-11 17:59:30,047 [INFO    ] __main__: train step 23814: loss: 0.8959, policy_loss: 0.8054, value_loss: 0.4146
2024-07-11 17:59:30,300 [INFO    ] __main__: train step 23815: loss: 0.8959, policy_loss: 0.8054, value_loss: 0.4146
2024-07-11 17:59:30,534 [INFO    ] __main__: train step 23816: loss: 0.8959, policy_loss: 0.8053, value_loss: 0.4146
2024-07-11 17:59:32,002 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:59:32,419 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:59:32,474 [INFO    ] __main__: train step 23817: loss: 0.8959, policy_loss: 0.8053, value_loss: 0.4146
2024-07-11 17:59:32,653 [INFO    ] __main__: train step 23818: loss: 0.8959, policy_loss: 0.8053, value_loss: 0.4146
2024-07-11 17:59:32,889 [INFO    ] __main__: train step 23819: loss: 0.8959, policy_loss: 0.8053, value_loss: 0.4145
2024-07-11 17:59:33,131 [INFO    ] __main__: train step 23820: loss: 0.8958, policy_loss: 0.8053, value_loss: 0.4145
2024-07-11 17:59:33,347 [INFO    ] __main__: train step 23821: loss: 0.8958, policy_loss: 0.8053, value_loss: 0.4145
2024-07-11 17:59:33,556 [INFO    ] __main__: train step 23822: loss: 0.8958, policy_loss: 0.8053, value_loss: 0.4145
2024-07-11 17:59:33,765 [INFO    ] __main__: train step 23823: loss: 0.8958, policy_loss: 0.8052, value_loss: 0.4145
2024-07-11 17:59:33,970 [INFO    ] __main__: train step 23824: loss: 0.8958, policy_loss: 0.8052, value_loss: 0.4145
2024-07-11 17:59:34,178 [INFO    ] __main__: train step 23825: loss: 0.8958, policy_loss: 0.8052, value_loss: 0.4144
2024-07-11 17:59:34,391 [INFO    ] __main__: train step 23826: loss: 0.8957, policy_loss: 0.8052, value_loss: 0.4144
2024-07-11 17:59:34,592 [INFO    ] __main__: train step 23827: loss: 0.8957, policy_loss: 0.8052, value_loss: 0.4144
2024-07-11 17:59:34,803 [INFO    ] __main__: train step 23828: loss: 0.8957, policy_loss: 0.8052, value_loss: 0.4144
2024-07-11 17:59:35,009 [INFO    ] __main__: train step 23829: loss: 0.8957, policy_loss: 0.8051, value_loss: 0.4144
2024-07-11 17:59:35,214 [INFO    ] __main__: train step 23830: loss: 0.8957, policy_loss: 0.8051, value_loss: 0.4144
2024-07-11 17:59:35,420 [INFO    ] __main__: train step 23831: loss: 0.8957, policy_loss: 0.8051, value_loss: 0.4144
2024-07-11 17:59:35,623 [INFO    ] __main__: train step 23832: loss: 0.8956, policy_loss: 0.8051, value_loss: 0.4143
2024-07-11 17:59:35,835 [INFO    ] __main__: train step 23833: loss: 0.8956, policy_loss: 0.8051, value_loss: 0.4143
2024-07-11 17:59:37,257 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:59:37,614 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:59:37,672 [INFO    ] __main__: train step 23834: loss: 0.8956, policy_loss: 0.8051, value_loss: 0.4143
2024-07-11 17:59:37,850 [INFO    ] __main__: train step 23835: loss: 0.8956, policy_loss: 0.8051, value_loss: 0.4143
2024-07-11 17:59:38,066 [INFO    ] __main__: train step 23836: loss: 0.8956, policy_loss: 0.8050, value_loss: 0.4143
2024-07-11 17:59:38,274 [INFO    ] __main__: train step 23837: loss: 0.8956, policy_loss: 0.8050, value_loss: 0.4143
2024-07-11 17:59:38,464 [INFO    ] __main__: train step 23838: loss: 0.8955, policy_loss: 0.8050, value_loss: 0.4143
2024-07-11 17:59:38,672 [INFO    ] __main__: train step 23839: loss: 0.8955, policy_loss: 0.8050, value_loss: 0.4142
2024-07-11 17:59:38,894 [INFO    ] __main__: train step 23840: loss: 0.8955, policy_loss: 0.8050, value_loss: 0.4142
2024-07-11 17:59:39,126 [INFO    ] __main__: train step 23841: loss: 0.8955, policy_loss: 0.8050, value_loss: 0.4142
2024-07-11 17:59:39,349 [INFO    ] __main__: train step 23842: loss: 0.8955, policy_loss: 0.8050, value_loss: 0.4142
2024-07-11 17:59:39,543 [INFO    ] __main__: train step 23843: loss: 0.8955, policy_loss: 0.8049, value_loss: 0.4142
2024-07-11 17:59:39,756 [INFO    ] __main__: train step 23844: loss: 0.8954, policy_loss: 0.8049, value_loss: 0.4142
2024-07-11 17:59:39,978 [INFO    ] __main__: train step 23845: loss: 0.8954, policy_loss: 0.8049, value_loss: 0.4141
2024-07-11 17:59:40,185 [INFO    ] __main__: train step 23846: loss: 0.8954, policy_loss: 0.8049, value_loss: 0.4141
2024-07-11 17:59:40,392 [INFO    ] __main__: train step 23847: loss: 0.8954, policy_loss: 0.8049, value_loss: 0.4141
2024-07-11 17:59:40,607 [INFO    ] __main__: train step 23848: loss: 0.8954, policy_loss: 0.8049, value_loss: 0.4141
2024-07-11 17:59:40,839 [INFO    ] __main__: train step 23849: loss: 0.8954, policy_loss: 0.8048, value_loss: 0.4141
2024-07-11 17:59:41,036 [INFO    ] __main__: train step 23850: loss: 0.8953, policy_loss: 0.8048, value_loss: 0.4141
2024-07-11 17:59:42,474 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:59:42,893 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:59:42,956 [INFO    ] __main__: train step 23851: loss: 0.8953, policy_loss: 0.8048, value_loss: 0.4141
2024-07-11 17:59:43,132 [INFO    ] __main__: train step 23852: loss: 0.8953, policy_loss: 0.8048, value_loss: 0.4140
2024-07-11 17:59:43,337 [INFO    ] __main__: train step 23853: loss: 0.8953, policy_loss: 0.8048, value_loss: 0.4140
2024-07-11 17:59:43,539 [INFO    ] __main__: train step 23854: loss: 0.8953, policy_loss: 0.8048, value_loss: 0.4140
2024-07-11 17:59:43,746 [INFO    ] __main__: train step 23855: loss: 0.8953, policy_loss: 0.8048, value_loss: 0.4140
2024-07-11 17:59:43,959 [INFO    ] __main__: train step 23856: loss: 0.8952, policy_loss: 0.8047, value_loss: 0.4140
2024-07-11 17:59:44,158 [INFO    ] __main__: train step 23857: loss: 0.8952, policy_loss: 0.8047, value_loss: 0.4140
2024-07-11 17:59:44,377 [INFO    ] __main__: train step 23858: loss: 0.8952, policy_loss: 0.8047, value_loss: 0.4140
2024-07-11 17:59:44,607 [INFO    ] __main__: train step 23859: loss: 0.8952, policy_loss: 0.8047, value_loss: 0.4139
2024-07-11 17:59:44,824 [INFO    ] __main__: train step 23860: loss: 0.8952, policy_loss: 0.8047, value_loss: 0.4139
2024-07-11 17:59:45,027 [INFO    ] __main__: train step 23861: loss: 0.8952, policy_loss: 0.8047, value_loss: 0.4139
2024-07-11 17:59:45,254 [INFO    ] __main__: train step 23862: loss: 0.8951, policy_loss: 0.8047, value_loss: 0.4139
2024-07-11 17:59:45,462 [INFO    ] __main__: train step 23863: loss: 0.8951, policy_loss: 0.8046, value_loss: 0.4139
2024-07-11 17:59:45,675 [INFO    ] __main__: train step 23864: loss: 0.8951, policy_loss: 0.8046, value_loss: 0.4139
2024-07-11 17:59:45,885 [INFO    ] __main__: train step 23865: loss: 0.8951, policy_loss: 0.8046, value_loss: 0.4138
2024-07-11 17:59:46,098 [INFO    ] __main__: train step 23866: loss: 0.8951, policy_loss: 0.8046, value_loss: 0.4138
2024-07-11 17:59:46,326 [INFO    ] __main__: train step 23867: loss: 0.8951, policy_loss: 0.8046, value_loss: 0.4138
2024-07-11 17:59:47,772 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:59:48,139 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:59:48,199 [INFO    ] __main__: train step 23868: loss: 0.8950, policy_loss: 0.8046, value_loss: 0.4138
2024-07-11 17:59:48,407 [INFO    ] __main__: train step 23869: loss: 0.8950, policy_loss: 0.8045, value_loss: 0.4138
2024-07-11 17:59:48,651 [INFO    ] __main__: train step 23870: loss: 0.8950, policy_loss: 0.8045, value_loss: 0.4138
2024-07-11 17:59:48,862 [INFO    ] __main__: train step 23871: loss: 0.8950, policy_loss: 0.8045, value_loss: 0.4138
2024-07-11 17:59:49,101 [INFO    ] __main__: train step 23872: loss: 0.8950, policy_loss: 0.8045, value_loss: 0.4137
2024-07-11 17:59:49,306 [INFO    ] __main__: train step 23873: loss: 0.8950, policy_loss: 0.8045, value_loss: 0.4137
2024-07-11 17:59:49,516 [INFO    ] __main__: train step 23874: loss: 0.8949, policy_loss: 0.8045, value_loss: 0.4137
2024-07-11 17:59:49,728 [INFO    ] __main__: train step 23875: loss: 0.8949, policy_loss: 0.8045, value_loss: 0.4137
2024-07-11 17:59:49,943 [INFO    ] __main__: train step 23876: loss: 0.8949, policy_loss: 0.8044, value_loss: 0.4137
2024-07-11 17:59:50,166 [INFO    ] __main__: train step 23877: loss: 0.8949, policy_loss: 0.8044, value_loss: 0.4137
2024-07-11 17:59:50,378 [INFO    ] __main__: train step 23878: loss: 0.8949, policy_loss: 0.8044, value_loss: 0.4137
2024-07-11 17:59:50,583 [INFO    ] __main__: train step 23879: loss: 0.8949, policy_loss: 0.8044, value_loss: 0.4136
2024-07-11 17:59:53,058 [INFO    ] __main__: train step 23880: loss: 0.8949, policy_loss: 0.8044, value_loss: 0.4136
2024-07-11 17:59:53,290 [INFO    ] __main__: train step 23881: loss: 0.8948, policy_loss: 0.8044, value_loss: 0.4136
2024-07-11 17:59:53,527 [INFO    ] __main__: train step 23882: loss: 0.8948, policy_loss: 0.8044, value_loss: 0.4136
2024-07-11 17:59:53,731 [INFO    ] __main__: train step 23883: loss: 0.8948, policy_loss: 0.8043, value_loss: 0.4136
2024-07-11 17:59:53,958 [INFO    ] __main__: train step 23884: loss: 0.8948, policy_loss: 0.8043, value_loss: 0.4136
2024-07-11 17:59:55,430 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 17:59:55,756 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 17:59:55,812 [INFO    ] __main__: train step 23885: loss: 0.8948, policy_loss: 0.8043, value_loss: 0.4135
2024-07-11 17:59:56,000 [INFO    ] __main__: train step 23886: loss: 0.8948, policy_loss: 0.8043, value_loss: 0.4135
2024-07-11 17:59:56,213 [INFO    ] __main__: train step 23887: loss: 0.8947, policy_loss: 0.8043, value_loss: 0.4135
2024-07-11 17:59:56,445 [INFO    ] __main__: train step 23888: loss: 0.8947, policy_loss: 0.8043, value_loss: 0.4135
2024-07-11 17:59:56,649 [INFO    ] __main__: train step 23889: loss: 0.8947, policy_loss: 0.8042, value_loss: 0.4135
2024-07-11 17:59:56,859 [INFO    ] __main__: train step 23890: loss: 0.8947, policy_loss: 0.8042, value_loss: 0.4135
2024-07-11 17:59:57,072 [INFO    ] __main__: train step 23891: loss: 0.8947, policy_loss: 0.8042, value_loss: 0.4135
2024-07-11 17:59:57,306 [INFO    ] __main__: train step 23892: loss: 0.8946, policy_loss: 0.8042, value_loss: 0.4134
2024-07-11 17:59:57,537 [INFO    ] __main__: train step 23893: loss: 0.8946, policy_loss: 0.8042, value_loss: 0.4134
2024-07-11 17:59:57,753 [INFO    ] __main__: train step 23894: loss: 0.8946, policy_loss: 0.8042, value_loss: 0.4134
2024-07-11 17:59:57,948 [INFO    ] __main__: train step 23895: loss: 0.8946, policy_loss: 0.8042, value_loss: 0.4134
2024-07-11 17:59:58,146 [INFO    ] __main__: train step 23896: loss: 0.8946, policy_loss: 0.8041, value_loss: 0.4134
2024-07-11 17:59:58,350 [INFO    ] __main__: train step 23897: loss: 0.8946, policy_loss: 0.8041, value_loss: 0.4134
2024-07-11 17:59:58,558 [INFO    ] __main__: train step 23898: loss: 0.8945, policy_loss: 0.8041, value_loss: 0.4134
2024-07-11 17:59:58,762 [INFO    ] __main__: train step 23899: loss: 0.8945, policy_loss: 0.8041, value_loss: 0.4133
2024-07-11 17:59:58,960 [INFO    ] __main__: train step 23900: loss: 0.8945, policy_loss: 0.8041, value_loss: 0.4133
2024-07-11 17:59:59,164 [INFO    ] __main__: train step 23901: loss: 0.8945, policy_loss: 0.8041, value_loss: 0.4133
2024-07-11 18:00:00,613 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:00:00,950 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:00:01,006 [INFO    ] __main__: train step 23902: loss: 0.8945, policy_loss: 0.8040, value_loss: 0.4133
2024-07-11 18:00:01,202 [INFO    ] __main__: train step 23903: loss: 0.8945, policy_loss: 0.8040, value_loss: 0.4133
2024-07-11 18:00:01,442 [INFO    ] __main__: train step 23904: loss: 0.8944, policy_loss: 0.8040, value_loss: 0.4133
2024-07-11 18:00:01,653 [INFO    ] __main__: train step 23905: loss: 0.8944, policy_loss: 0.8040, value_loss: 0.4132
2024-07-11 18:00:01,856 [INFO    ] __main__: train step 23906: loss: 0.8944, policy_loss: 0.8040, value_loss: 0.4132
2024-07-11 18:00:02,063 [INFO    ] __main__: train step 23907: loss: 0.8944, policy_loss: 0.8040, value_loss: 0.4132
2024-07-11 18:00:02,271 [INFO    ] __main__: train step 23908: loss: 0.8944, policy_loss: 0.8040, value_loss: 0.4132
2024-07-11 18:00:02,474 [INFO    ] __main__: train step 23909: loss: 0.8944, policy_loss: 0.8039, value_loss: 0.4132
2024-07-11 18:00:02,672 [INFO    ] __main__: train step 23910: loss: 0.8943, policy_loss: 0.8039, value_loss: 0.4132
2024-07-11 18:00:02,885 [INFO    ] __main__: train step 23911: loss: 0.8943, policy_loss: 0.8039, value_loss: 0.4132
2024-07-11 18:00:03,104 [INFO    ] __main__: train step 23912: loss: 0.8943, policy_loss: 0.8039, value_loss: 0.4131
2024-07-11 18:00:03,326 [INFO    ] __main__: train step 23913: loss: 0.8943, policy_loss: 0.8039, value_loss: 0.4131
2024-07-11 18:00:03,539 [INFO    ] __main__: train step 23914: loss: 0.8943, policy_loss: 0.8039, value_loss: 0.4131
2024-07-11 18:00:03,785 [INFO    ] __main__: train step 23915: loss: 0.8943, policy_loss: 0.8038, value_loss: 0.4131
2024-07-11 18:00:04,014 [INFO    ] __main__: train step 23916: loss: 0.8942, policy_loss: 0.8038, value_loss: 0.4131
2024-07-11 18:00:04,215 [INFO    ] __main__: train step 23917: loss: 0.8942, policy_loss: 0.8038, value_loss: 0.4131
2024-07-11 18:00:04,420 [INFO    ] __main__: train step 23918: loss: 0.8942, policy_loss: 0.8038, value_loss: 0.4131
2024-07-11 18:00:05,839 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:00:06,215 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:00:06,275 [INFO    ] __main__: train step 23919: loss: 0.8942, policy_loss: 0.8038, value_loss: 0.4130
2024-07-11 18:00:06,459 [INFO    ] __main__: train step 23920: loss: 0.8942, policy_loss: 0.8038, value_loss: 0.4130
2024-07-11 18:00:06,657 [INFO    ] __main__: train step 23921: loss: 0.8942, policy_loss: 0.8038, value_loss: 0.4130
2024-07-11 18:00:06,856 [INFO    ] __main__: train step 23922: loss: 0.8941, policy_loss: 0.8037, value_loss: 0.4130
2024-07-11 18:00:07,053 [INFO    ] __main__: train step 23923: loss: 0.8941, policy_loss: 0.8037, value_loss: 0.4130
2024-07-11 18:00:07,244 [INFO    ] __main__: train step 23924: loss: 0.8941, policy_loss: 0.8037, value_loss: 0.4130
2024-07-11 18:00:07,452 [INFO    ] __main__: train step 23925: loss: 0.8941, policy_loss: 0.8037, value_loss: 0.4129
2024-07-11 18:00:07,659 [INFO    ] __main__: train step 23926: loss: 0.8941, policy_loss: 0.8037, value_loss: 0.4129
2024-07-11 18:00:07,865 [INFO    ] __main__: train step 23927: loss: 0.8941, policy_loss: 0.8037, value_loss: 0.4129
2024-07-11 18:00:08,079 [INFO    ] __main__: train step 23928: loss: 0.8940, policy_loss: 0.8036, value_loss: 0.4129
2024-07-11 18:00:08,283 [INFO    ] __main__: train step 23929: loss: 0.8940, policy_loss: 0.8036, value_loss: 0.4129
2024-07-11 18:00:08,494 [INFO    ] __main__: train step 23930: loss: 0.8940, policy_loss: 0.8036, value_loss: 0.4129
2024-07-11 18:00:08,693 [INFO    ] __main__: train step 23931: loss: 0.8940, policy_loss: 0.8036, value_loss: 0.4129
2024-07-11 18:00:08,912 [INFO    ] __main__: train step 23932: loss: 0.8940, policy_loss: 0.8036, value_loss: 0.4128
2024-07-11 18:00:09,143 [INFO    ] __main__: train step 23933: loss: 0.8940, policy_loss: 0.8036, value_loss: 0.4128
2024-07-11 18:00:09,345 [INFO    ] __main__: train step 23934: loss: 0.8939, policy_loss: 0.8036, value_loss: 0.4128
2024-07-11 18:00:09,558 [INFO    ] __main__: train step 23935: loss: 0.8939, policy_loss: 0.8035, value_loss: 0.4128
2024-07-11 18:00:11,001 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:00:11,379 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:00:11,439 [INFO    ] __main__: train step 23936: loss: 0.8939, policy_loss: 0.8035, value_loss: 0.4128
2024-07-11 18:00:11,628 [INFO    ] __main__: train step 23937: loss: 0.8939, policy_loss: 0.8035, value_loss: 0.4128
2024-07-11 18:00:11,833 [INFO    ] __main__: train step 23938: loss: 0.8939, policy_loss: 0.8035, value_loss: 0.4128
2024-07-11 18:00:12,059 [INFO    ] __main__: train step 23939: loss: 0.8939, policy_loss: 0.8035, value_loss: 0.4127
2024-07-11 18:00:12,299 [INFO    ] __main__: train step 23940: loss: 0.8938, policy_loss: 0.8035, value_loss: 0.4127
2024-07-11 18:00:12,502 [INFO    ] __main__: train step 23941: loss: 0.8938, policy_loss: 0.8034, value_loss: 0.4127
2024-07-11 18:00:12,710 [INFO    ] __main__: train step 23942: loss: 0.8938, policy_loss: 0.8034, value_loss: 0.4127
2024-07-11 18:00:12,920 [INFO    ] __main__: train step 23943: loss: 0.8938, policy_loss: 0.8034, value_loss: 0.4127
2024-07-11 18:00:13,130 [INFO    ] __main__: train step 23944: loss: 0.8938, policy_loss: 0.8034, value_loss: 0.4127
2024-07-11 18:00:13,342 [INFO    ] __main__: train step 23945: loss: 0.8938, policy_loss: 0.8034, value_loss: 0.4126
2024-07-11 18:00:13,563 [INFO    ] __main__: train step 23946: loss: 0.8937, policy_loss: 0.8034, value_loss: 0.4126
2024-07-11 18:00:13,788 [INFO    ] __main__: train step 23947: loss: 0.8937, policy_loss: 0.8034, value_loss: 0.4126
2024-07-11 18:00:14,006 [INFO    ] __main__: train step 23948: loss: 0.8937, policy_loss: 0.8033, value_loss: 0.4126
2024-07-11 18:00:14,231 [INFO    ] __main__: train step 23949: loss: 0.8937, policy_loss: 0.8033, value_loss: 0.4126
2024-07-11 18:00:14,436 [INFO    ] __main__: train step 23950: loss: 0.8937, policy_loss: 0.8033, value_loss: 0.4126
2024-07-11 18:00:14,645 [INFO    ] __main__: train step 23951: loss: 0.8937, policy_loss: 0.8033, value_loss: 0.4126
2024-07-11 18:00:14,851 [INFO    ] __main__: train step 23952: loss: 0.8936, policy_loss: 0.8033, value_loss: 0.4125
2024-07-11 18:00:16,283 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:00:16,592 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:00:16,648 [INFO    ] __main__: train step 23953: loss: 0.8936, policy_loss: 0.8033, value_loss: 0.4125
2024-07-11 18:00:16,841 [INFO    ] __main__: train step 23954: loss: 0.8936, policy_loss: 0.8032, value_loss: 0.4125
2024-07-11 18:00:17,049 [INFO    ] __main__: train step 23955: loss: 0.8936, policy_loss: 0.8032, value_loss: 0.4125
2024-07-11 18:00:17,259 [INFO    ] __main__: train step 23956: loss: 0.8936, policy_loss: 0.8032, value_loss: 0.4125
2024-07-11 18:00:17,464 [INFO    ] __main__: train step 23957: loss: 0.8936, policy_loss: 0.8032, value_loss: 0.4125
2024-07-11 18:00:17,654 [INFO    ] __main__: train step 23958: loss: 0.8935, policy_loss: 0.8032, value_loss: 0.4125
2024-07-11 18:00:17,871 [INFO    ] __main__: train step 23959: loss: 0.8935, policy_loss: 0.8032, value_loss: 0.4124
2024-07-11 18:00:18,105 [INFO    ] __main__: train step 23960: loss: 0.8935, policy_loss: 0.8032, value_loss: 0.4124
2024-07-11 18:00:18,350 [INFO    ] __main__: train step 23961: loss: 0.8935, policy_loss: 0.8031, value_loss: 0.4124
2024-07-11 18:00:18,559 [INFO    ] __main__: train step 23962: loss: 0.8935, policy_loss: 0.8031, value_loss: 0.4124
2024-07-11 18:00:18,798 [INFO    ] __main__: train step 23963: loss: 0.8934, policy_loss: 0.8031, value_loss: 0.4124
2024-07-11 18:00:19,000 [INFO    ] __main__: train step 23964: loss: 0.8934, policy_loss: 0.8031, value_loss: 0.4124
2024-07-11 18:00:19,202 [INFO    ] __main__: train step 23965: loss: 0.8934, policy_loss: 0.8031, value_loss: 0.4123
2024-07-11 18:00:19,408 [INFO    ] __main__: train step 23966: loss: 0.8934, policy_loss: 0.8031, value_loss: 0.4123
2024-07-11 18:00:19,637 [INFO    ] __main__: train step 23967: loss: 0.8934, policy_loss: 0.8030, value_loss: 0.4123
2024-07-11 18:00:19,839 [INFO    ] __main__: train step 23968: loss: 0.8934, policy_loss: 0.8030, value_loss: 0.4123
2024-07-11 18:00:20,057 [INFO    ] __main__: train step 23969: loss: 0.8933, policy_loss: 0.8030, value_loss: 0.4123
2024-07-11 18:00:21,471 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:00:21,860 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:00:21,916 [INFO    ] __main__: train step 23970: loss: 0.8933, policy_loss: 0.8030, value_loss: 0.4123
2024-07-11 18:00:22,095 [INFO    ] __main__: train step 23971: loss: 0.8933, policy_loss: 0.8030, value_loss: 0.4123
2024-07-11 18:00:22,303 [INFO    ] __main__: train step 23972: loss: 0.8933, policy_loss: 0.8030, value_loss: 0.4122
2024-07-11 18:00:22,509 [INFO    ] __main__: train step 23973: loss: 0.8933, policy_loss: 0.8029, value_loss: 0.4122
2024-07-11 18:00:22,709 [INFO    ] __main__: train step 23974: loss: 0.8933, policy_loss: 0.8029, value_loss: 0.4122
2024-07-11 18:00:22,910 [INFO    ] __main__: train step 23975: loss: 0.8932, policy_loss: 0.8029, value_loss: 0.4122
2024-07-11 18:00:23,126 [INFO    ] __main__: train step 23976: loss: 0.8932, policy_loss: 0.8029, value_loss: 0.4122
2024-07-11 18:00:23,330 [INFO    ] __main__: train step 23977: loss: 0.8932, policy_loss: 0.8029, value_loss: 0.4122
2024-07-11 18:00:23,531 [INFO    ] __main__: train step 23978: loss: 0.8932, policy_loss: 0.8029, value_loss: 0.4122
2024-07-11 18:00:23,746 [INFO    ] __main__: train step 23979: loss: 0.8932, policy_loss: 0.8029, value_loss: 0.4121
2024-07-11 18:00:23,994 [INFO    ] __main__: train step 23980: loss: 0.8932, policy_loss: 0.8028, value_loss: 0.4121
2024-07-11 18:00:24,198 [INFO    ] __main__: train step 23981: loss: 0.8931, policy_loss: 0.8028, value_loss: 0.4121
2024-07-11 18:00:24,439 [INFO    ] __main__: train step 23982: loss: 0.8931, policy_loss: 0.8028, value_loss: 0.4121
2024-07-11 18:00:24,666 [INFO    ] __main__: train step 23983: loss: 0.8931, policy_loss: 0.8028, value_loss: 0.4121
2024-07-11 18:00:24,877 [INFO    ] __main__: train step 23984: loss: 0.8931, policy_loss: 0.8028, value_loss: 0.4121
2024-07-11 18:00:25,081 [INFO    ] __main__: train step 23985: loss: 0.8931, policy_loss: 0.8028, value_loss: 0.4120
2024-07-11 18:00:25,277 [INFO    ] __main__: train step 23986: loss: 0.8931, policy_loss: 0.8027, value_loss: 0.4120
2024-07-11 18:00:26,695 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:00:27,077 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:00:27,133 [INFO    ] __main__: train step 23987: loss: 0.8930, policy_loss: 0.8027, value_loss: 0.4120
2024-07-11 18:00:27,328 [INFO    ] __main__: train step 23988: loss: 0.8930, policy_loss: 0.8027, value_loss: 0.4120
2024-07-11 18:00:27,571 [INFO    ] __main__: train step 23989: loss: 0.8930, policy_loss: 0.8027, value_loss: 0.4120
2024-07-11 18:00:27,773 [INFO    ] __main__: train step 23990: loss: 0.8930, policy_loss: 0.8027, value_loss: 0.4120
2024-07-11 18:00:27,977 [INFO    ] __main__: train step 23991: loss: 0.8930, policy_loss: 0.8027, value_loss: 0.4120
2024-07-11 18:00:28,186 [INFO    ] __main__: train step 23992: loss: 0.8930, policy_loss: 0.8027, value_loss: 0.4119
2024-07-11 18:00:28,402 [INFO    ] __main__: train step 23993: loss: 0.8929, policy_loss: 0.8026, value_loss: 0.4119
2024-07-11 18:00:28,616 [INFO    ] __main__: train step 23994: loss: 0.8929, policy_loss: 0.8026, value_loss: 0.4119
2024-07-11 18:00:28,848 [INFO    ] __main__: train step 23995: loss: 0.8929, policy_loss: 0.8026, value_loss: 0.4119
2024-07-11 18:00:29,049 [INFO    ] __main__: train step 23996: loss: 0.8929, policy_loss: 0.8026, value_loss: 0.4119
2024-07-11 18:00:29,254 [INFO    ] __main__: train step 23997: loss: 0.8929, policy_loss: 0.8026, value_loss: 0.4119
2024-07-11 18:00:29,457 [INFO    ] __main__: train step 23998: loss: 0.8928, policy_loss: 0.8026, value_loss: 0.4119
2024-07-11 18:00:29,659 [INFO    ] __main__: train step 23999: loss: 0.8928, policy_loss: 0.8025, value_loss: 0.4118
2024-07-11 18:00:29,874 [INFO    ] __main__: train step 24000: loss: 0.8928, policy_loss: 0.8025, value_loss: 0.4118
2024-07-11 18:00:29,985 [INFO    ] __main__: restored step 23000 for evaluation
2024-07-11 18:00:37,253 [INFO    ] __main__: later network ELO difference from earlier network: +88 (+8/-8) ELO from 32000 self-played games
2024-07-11 18:00:37,253 [INFO    ] __main__: game outcomes: W: 19204, D: 137, L: 12659
2024-07-11 18:00:37,255 [INFO    ] __main__: validation_elo_delta: 88, validation_elo: 3184
2024-07-11 18:00:37,771 [INFO    ] __main__: train step 24001: loss: 0.8928, policy_loss: 0.8025, value_loss: 0.4118
2024-07-11 18:00:37,979 [INFO    ] __main__: train step 24002: loss: 0.8928, policy_loss: 0.8025, value_loss: 0.4118
2024-07-11 18:00:38,179 [INFO    ] __main__: train step 24003: loss: 0.8928, policy_loss: 0.8025, value_loss: 0.4118
2024-07-11 18:00:39,628 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:00:39,991 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:00:40,052 [INFO    ] __main__: train step 24004: loss: 0.8927, policy_loss: 0.8025, value_loss: 0.4118
2024-07-11 18:00:40,233 [INFO    ] __main__: train step 24005: loss: 0.8927, policy_loss: 0.8025, value_loss: 0.4117
2024-07-11 18:00:40,461 [INFO    ] __main__: train step 24006: loss: 0.8927, policy_loss: 0.8024, value_loss: 0.4117
2024-07-11 18:00:40,665 [INFO    ] __main__: train step 24007: loss: 0.8927, policy_loss: 0.8024, value_loss: 0.4117
2024-07-11 18:00:40,868 [INFO    ] __main__: train step 24008: loss: 0.8927, policy_loss: 0.8024, value_loss: 0.4117
2024-07-11 18:00:41,077 [INFO    ] __main__: train step 24009: loss: 0.8927, policy_loss: 0.8024, value_loss: 0.4117
2024-07-11 18:00:41,274 [INFO    ] __main__: train step 24010: loss: 0.8926, policy_loss: 0.8024, value_loss: 0.4117
2024-07-11 18:00:41,485 [INFO    ] __main__: train step 24011: loss: 0.8926, policy_loss: 0.8024, value_loss: 0.4117
2024-07-11 18:00:41,690 [INFO    ] __main__: train step 24012: loss: 0.8926, policy_loss: 0.8023, value_loss: 0.4116
2024-07-11 18:00:41,898 [INFO    ] __main__: train step 24013: loss: 0.8926, policy_loss: 0.8023, value_loss: 0.4116
2024-07-11 18:00:42,127 [INFO    ] __main__: train step 24014: loss: 0.8926, policy_loss: 0.8023, value_loss: 0.4116
2024-07-11 18:00:42,331 [INFO    ] __main__: train step 24015: loss: 0.8926, policy_loss: 0.8023, value_loss: 0.4116
2024-07-11 18:00:42,536 [INFO    ] __main__: train step 24016: loss: 0.8925, policy_loss: 0.8023, value_loss: 0.4116
2024-07-11 18:00:42,740 [INFO    ] __main__: train step 24017: loss: 0.8925, policy_loss: 0.8023, value_loss: 0.4116
2024-07-11 18:00:42,982 [INFO    ] __main__: train step 24018: loss: 0.8925, policy_loss: 0.8022, value_loss: 0.4116
2024-07-11 18:00:45,473 [INFO    ] __main__: train step 24019: loss: 0.8925, policy_loss: 0.8022, value_loss: 0.4115
2024-07-11 18:00:45,682 [INFO    ] __main__: train step 24020: loss: 0.8925, policy_loss: 0.8022, value_loss: 0.4115
2024-07-11 18:00:47,148 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:00:47,498 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:00:47,553 [INFO    ] __main__: train step 24021: loss: 0.8924, policy_loss: 0.8022, value_loss: 0.4115
2024-07-11 18:00:47,738 [INFO    ] __main__: train step 24022: loss: 0.8924, policy_loss: 0.8022, value_loss: 0.4115
2024-07-11 18:00:47,952 [INFO    ] __main__: train step 24023: loss: 0.8924, policy_loss: 0.8022, value_loss: 0.4115
2024-07-11 18:00:48,161 [INFO    ] __main__: train step 24024: loss: 0.8924, policy_loss: 0.8022, value_loss: 0.4115
2024-07-11 18:00:48,415 [INFO    ] __main__: train step 24025: loss: 0.8924, policy_loss: 0.8021, value_loss: 0.4114
2024-07-11 18:00:48,644 [INFO    ] __main__: train step 24026: loss: 0.8924, policy_loss: 0.8021, value_loss: 0.4114
2024-07-11 18:00:48,853 [INFO    ] __main__: train step 24027: loss: 0.8923, policy_loss: 0.8021, value_loss: 0.4114
2024-07-11 18:00:49,067 [INFO    ] __main__: train step 24028: loss: 0.8923, policy_loss: 0.8021, value_loss: 0.4114
2024-07-11 18:00:49,310 [INFO    ] __main__: train step 24029: loss: 0.8923, policy_loss: 0.8021, value_loss: 0.4114
2024-07-11 18:00:49,534 [INFO    ] __main__: train step 24030: loss: 0.8923, policy_loss: 0.8021, value_loss: 0.4114
2024-07-11 18:00:49,739 [INFO    ] __main__: train step 24031: loss: 0.8923, policy_loss: 0.8020, value_loss: 0.4114
2024-07-11 18:00:49,948 [INFO    ] __main__: train step 24032: loss: 0.8923, policy_loss: 0.8020, value_loss: 0.4113
2024-07-11 18:00:50,150 [INFO    ] __main__: train step 24033: loss: 0.8922, policy_loss: 0.8020, value_loss: 0.4113
2024-07-11 18:00:50,360 [INFO    ] __main__: train step 24034: loss: 0.8922, policy_loss: 0.8020, value_loss: 0.4113
2024-07-11 18:00:50,568 [INFO    ] __main__: train step 24035: loss: 0.8922, policy_loss: 0.8020, value_loss: 0.4113
2024-07-11 18:00:50,773 [INFO    ] __main__: train step 24036: loss: 0.8922, policy_loss: 0.8020, value_loss: 0.4113
2024-07-11 18:00:50,985 [INFO    ] __main__: train step 24037: loss: 0.8922, policy_loss: 0.8019, value_loss: 0.4113
2024-07-11 18:00:52,474 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:00:52,821 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:00:52,880 [INFO    ] __main__: train step 24038: loss: 0.8922, policy_loss: 0.8019, value_loss: 0.4113
2024-07-11 18:00:53,064 [INFO    ] __main__: train step 24039: loss: 0.8921, policy_loss: 0.8019, value_loss: 0.4112
2024-07-11 18:00:53,268 [INFO    ] __main__: train step 24040: loss: 0.8921, policy_loss: 0.8019, value_loss: 0.4112
2024-07-11 18:00:53,477 [INFO    ] __main__: train step 24041: loss: 0.8921, policy_loss: 0.8019, value_loss: 0.4112
2024-07-11 18:00:53,722 [INFO    ] __main__: train step 24042: loss: 0.8921, policy_loss: 0.8019, value_loss: 0.4112
2024-07-11 18:00:53,925 [INFO    ] __main__: train step 24043: loss: 0.8921, policy_loss: 0.8019, value_loss: 0.4112
2024-07-11 18:00:54,173 [INFO    ] __main__: train step 24044: loss: 0.8921, policy_loss: 0.8018, value_loss: 0.4112
2024-07-11 18:00:54,402 [INFO    ] __main__: train step 24045: loss: 0.8920, policy_loss: 0.8018, value_loss: 0.4111
2024-07-11 18:00:54,609 [INFO    ] __main__: train step 24046: loss: 0.8920, policy_loss: 0.8018, value_loss: 0.4111
2024-07-11 18:00:54,812 [INFO    ] __main__: train step 24047: loss: 0.8920, policy_loss: 0.8018, value_loss: 0.4111
2024-07-11 18:00:55,018 [INFO    ] __main__: train step 24048: loss: 0.8920, policy_loss: 0.8018, value_loss: 0.4111
2024-07-11 18:00:55,234 [INFO    ] __main__: train step 24049: loss: 0.8920, policy_loss: 0.8018, value_loss: 0.4111
2024-07-11 18:00:55,424 [INFO    ] __main__: train step 24050: loss: 0.8919, policy_loss: 0.8017, value_loss: 0.4111
2024-07-11 18:00:55,630 [INFO    ] __main__: train step 24051: loss: 0.8919, policy_loss: 0.8017, value_loss: 0.4111
2024-07-11 18:00:55,840 [INFO    ] __main__: train step 24052: loss: 0.8919, policy_loss: 0.8017, value_loss: 0.4110
2024-07-11 18:00:56,051 [INFO    ] __main__: train step 24053: loss: 0.8919, policy_loss: 0.8017, value_loss: 0.4110
2024-07-11 18:00:56,245 [INFO    ] __main__: train step 24054: loss: 0.8919, policy_loss: 0.8017, value_loss: 0.4110
2024-07-11 18:00:57,673 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:00:58,034 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:00:58,093 [INFO    ] __main__: train step 24055: loss: 0.8919, policy_loss: 0.8017, value_loss: 0.4110
2024-07-11 18:00:58,276 [INFO    ] __main__: train step 24056: loss: 0.8918, policy_loss: 0.8016, value_loss: 0.4110
2024-07-11 18:00:58,480 [INFO    ] __main__: train step 24057: loss: 0.8918, policy_loss: 0.8016, value_loss: 0.4110
2024-07-11 18:00:58,683 [INFO    ] __main__: train step 24058: loss: 0.8918, policy_loss: 0.8016, value_loss: 0.4110
2024-07-11 18:00:58,900 [INFO    ] __main__: train step 24059: loss: 0.8918, policy_loss: 0.8016, value_loss: 0.4109
2024-07-11 18:00:59,094 [INFO    ] __main__: train step 24060: loss: 0.8918, policy_loss: 0.8016, value_loss: 0.4109
2024-07-11 18:00:59,303 [INFO    ] __main__: train step 24061: loss: 0.8917, policy_loss: 0.8016, value_loss: 0.4109
2024-07-11 18:00:59,513 [INFO    ] __main__: train step 24062: loss: 0.8917, policy_loss: 0.8015, value_loss: 0.4109
2024-07-11 18:00:59,722 [INFO    ] __main__: train step 24063: loss: 0.8917, policy_loss: 0.8015, value_loss: 0.4109
2024-07-11 18:00:59,945 [INFO    ] __main__: train step 24064: loss: 0.8917, policy_loss: 0.8015, value_loss: 0.4109
2024-07-11 18:01:00,158 [INFO    ] __main__: train step 24065: loss: 0.8917, policy_loss: 0.8015, value_loss: 0.4108
2024-07-11 18:01:00,383 [INFO    ] __main__: train step 24066: loss: 0.8917, policy_loss: 0.8015, value_loss: 0.4108
2024-07-11 18:01:00,599 [INFO    ] __main__: train step 24067: loss: 0.8916, policy_loss: 0.8015, value_loss: 0.4108
2024-07-11 18:01:00,828 [INFO    ] __main__: train step 24068: loss: 0.8916, policy_loss: 0.8015, value_loss: 0.4108
2024-07-11 18:01:01,040 [INFO    ] __main__: train step 24069: loss: 0.8916, policy_loss: 0.8014, value_loss: 0.4108
2024-07-11 18:01:01,233 [INFO    ] __main__: train step 24070: loss: 0.8916, policy_loss: 0.8014, value_loss: 0.4108
2024-07-11 18:01:01,533 [INFO    ] __main__: train step 24071: loss: 0.8916, policy_loss: 0.8014, value_loss: 0.4108
2024-07-11 18:01:02,977 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:01:03,337 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:01:03,393 [INFO    ] __main__: train step 24072: loss: 0.8916, policy_loss: 0.8014, value_loss: 0.4107
2024-07-11 18:01:03,572 [INFO    ] __main__: train step 24073: loss: 0.8915, policy_loss: 0.8014, value_loss: 0.4107
2024-07-11 18:01:03,782 [INFO    ] __main__: train step 24074: loss: 0.8915, policy_loss: 0.8014, value_loss: 0.4107
2024-07-11 18:01:03,988 [INFO    ] __main__: train step 24075: loss: 0.8915, policy_loss: 0.8013, value_loss: 0.4107
2024-07-11 18:01:04,195 [INFO    ] __main__: train step 24076: loss: 0.8915, policy_loss: 0.8013, value_loss: 0.4107
2024-07-11 18:01:04,412 [INFO    ] __main__: train step 24077: loss: 0.8915, policy_loss: 0.8013, value_loss: 0.4107
2024-07-11 18:01:04,624 [INFO    ] __main__: train step 24078: loss: 0.8914, policy_loss: 0.8013, value_loss: 0.4107
2024-07-11 18:01:04,868 [INFO    ] __main__: train step 24079: loss: 0.8914, policy_loss: 0.8013, value_loss: 0.4106
2024-07-11 18:01:05,076 [INFO    ] __main__: train step 24080: loss: 0.8914, policy_loss: 0.8013, value_loss: 0.4106
2024-07-11 18:01:05,311 [INFO    ] __main__: train step 24081: loss: 0.8914, policy_loss: 0.8012, value_loss: 0.4106
2024-07-11 18:01:05,521 [INFO    ] __main__: train step 24082: loss: 0.8914, policy_loss: 0.8012, value_loss: 0.4106
2024-07-11 18:01:05,728 [INFO    ] __main__: train step 24083: loss: 0.8914, policy_loss: 0.8012, value_loss: 0.4106
2024-07-11 18:01:05,934 [INFO    ] __main__: train step 24084: loss: 0.8913, policy_loss: 0.8012, value_loss: 0.4106
2024-07-11 18:01:06,152 [INFO    ] __main__: train step 24085: loss: 0.8913, policy_loss: 0.8012, value_loss: 0.4105
2024-07-11 18:01:06,356 [INFO    ] __main__: train step 24086: loss: 0.8913, policy_loss: 0.8012, value_loss: 0.4105
2024-07-11 18:01:06,568 [INFO    ] __main__: train step 24087: loss: 0.8913, policy_loss: 0.8011, value_loss: 0.4105
2024-07-11 18:01:06,785 [INFO    ] __main__: train step 24088: loss: 0.8913, policy_loss: 0.8011, value_loss: 0.4105
2024-07-11 18:01:08,258 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:01:08,682 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:01:08,747 [INFO    ] __main__: train step 24089: loss: 0.8913, policy_loss: 0.8011, value_loss: 0.4105
2024-07-11 18:01:08,928 [INFO    ] __main__: train step 24090: loss: 0.8912, policy_loss: 0.8011, value_loss: 0.4105
2024-07-11 18:01:09,155 [INFO    ] __main__: train step 24091: loss: 0.8912, policy_loss: 0.8011, value_loss: 0.4105
2024-07-11 18:01:09,374 [INFO    ] __main__: train step 24092: loss: 0.8912, policy_loss: 0.8011, value_loss: 0.4104
2024-07-11 18:01:09,583 [INFO    ] __main__: train step 24093: loss: 0.8912, policy_loss: 0.8010, value_loss: 0.4104
2024-07-11 18:01:09,782 [INFO    ] __main__: train step 24094: loss: 0.8912, policy_loss: 0.8010, value_loss: 0.4104
2024-07-11 18:01:10,000 [INFO    ] __main__: train step 24095: loss: 0.8911, policy_loss: 0.8010, value_loss: 0.4104
2024-07-11 18:01:10,201 [INFO    ] __main__: train step 24096: loss: 0.8911, policy_loss: 0.8010, value_loss: 0.4104
2024-07-11 18:01:10,408 [INFO    ] __main__: train step 24097: loss: 0.8911, policy_loss: 0.8010, value_loss: 0.4104
2024-07-11 18:01:10,604 [INFO    ] __main__: train step 24098: loss: 0.8911, policy_loss: 0.8010, value_loss: 0.4104
2024-07-11 18:01:10,815 [INFO    ] __main__: train step 24099: loss: 0.8911, policy_loss: 0.8010, value_loss: 0.4103
2024-07-11 18:01:11,020 [INFO    ] __main__: train step 24100: loss: 0.8911, policy_loss: 0.8009, value_loss: 0.4103
2024-07-11 18:01:11,236 [INFO    ] __main__: train step 24101: loss: 0.8910, policy_loss: 0.8009, value_loss: 0.4103
2024-07-11 18:01:11,429 [INFO    ] __main__: train step 24102: loss: 0.8910, policy_loss: 0.8009, value_loss: 0.4103
2024-07-11 18:01:11,625 [INFO    ] __main__: train step 24103: loss: 0.8910, policy_loss: 0.8009, value_loss: 0.4103
2024-07-11 18:01:11,829 [INFO    ] __main__: train step 24104: loss: 0.8910, policy_loss: 0.8009, value_loss: 0.4103
2024-07-11 18:01:12,063 [INFO    ] __main__: train step 24105: loss: 0.8910, policy_loss: 0.8009, value_loss: 0.4103
2024-07-11 18:01:13,513 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:01:13,951 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:01:14,016 [INFO    ] __main__: train step 24106: loss: 0.8909, policy_loss: 0.8008, value_loss: 0.4102
2024-07-11 18:01:14,199 [INFO    ] __main__: train step 24107: loss: 0.8909, policy_loss: 0.8008, value_loss: 0.4102
2024-07-11 18:01:14,405 [INFO    ] __main__: train step 24108: loss: 0.8909, policy_loss: 0.8008, value_loss: 0.4102
2024-07-11 18:01:14,607 [INFO    ] __main__: train step 24109: loss: 0.8909, policy_loss: 0.8008, value_loss: 0.4102
2024-07-11 18:01:14,818 [INFO    ] __main__: train step 24110: loss: 0.8909, policy_loss: 0.8008, value_loss: 0.4102
2024-07-11 18:01:15,045 [INFO    ] __main__: train step 24111: loss: 0.8909, policy_loss: 0.8008, value_loss: 0.4102
2024-07-11 18:01:15,285 [INFO    ] __main__: train step 24112: loss: 0.8908, policy_loss: 0.8007, value_loss: 0.4101
2024-07-11 18:01:15,488 [INFO    ] __main__: train step 24113: loss: 0.8908, policy_loss: 0.8007, value_loss: 0.4101
2024-07-11 18:01:15,696 [INFO    ] __main__: train step 24114: loss: 0.8908, policy_loss: 0.8007, value_loss: 0.4101
2024-07-11 18:01:15,910 [INFO    ] __main__: train step 24115: loss: 0.8908, policy_loss: 0.8007, value_loss: 0.4101
2024-07-11 18:01:16,118 [INFO    ] __main__: train step 24116: loss: 0.8908, policy_loss: 0.8007, value_loss: 0.4101
2024-07-11 18:01:16,336 [INFO    ] __main__: train step 24117: loss: 0.8908, policy_loss: 0.8007, value_loss: 0.4101
2024-07-11 18:01:16,569 [INFO    ] __main__: train step 24118: loss: 0.8907, policy_loss: 0.8006, value_loss: 0.4101
2024-07-11 18:01:16,759 [INFO    ] __main__: train step 24119: loss: 0.8907, policy_loss: 0.8006, value_loss: 0.4100
2024-07-11 18:01:16,964 [INFO    ] __main__: train step 24120: loss: 0.8907, policy_loss: 0.8006, value_loss: 0.4100
2024-07-11 18:01:17,185 [INFO    ] __main__: train step 24121: loss: 0.8907, policy_loss: 0.8006, value_loss: 0.4100
2024-07-11 18:01:17,417 [INFO    ] __main__: train step 24122: loss: 0.8907, policy_loss: 0.8006, value_loss: 0.4100
2024-07-11 18:01:18,858 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:01:19,275 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:01:19,331 [INFO    ] __main__: train step 24123: loss: 0.8906, policy_loss: 0.8006, value_loss: 0.4100
2024-07-11 18:01:19,512 [INFO    ] __main__: train step 24124: loss: 0.8906, policy_loss: 0.8005, value_loss: 0.4100
2024-07-11 18:01:19,727 [INFO    ] __main__: train step 24125: loss: 0.8906, policy_loss: 0.8005, value_loss: 0.4100
2024-07-11 18:01:19,951 [INFO    ] __main__: train step 24126: loss: 0.8906, policy_loss: 0.8005, value_loss: 0.4099
2024-07-11 18:01:20,163 [INFO    ] __main__: train step 24127: loss: 0.8906, policy_loss: 0.8005, value_loss: 0.4099
2024-07-11 18:01:20,397 [INFO    ] __main__: train step 24128: loss: 0.8906, policy_loss: 0.8005, value_loss: 0.4099
2024-07-11 18:01:20,603 [INFO    ] __main__: train step 24129: loss: 0.8905, policy_loss: 0.8005, value_loss: 0.4099
2024-07-11 18:01:20,820 [INFO    ] __main__: train step 24130: loss: 0.8905, policy_loss: 0.8005, value_loss: 0.4099
2024-07-11 18:01:21,022 [INFO    ] __main__: train step 24131: loss: 0.8905, policy_loss: 0.8004, value_loss: 0.4099
2024-07-11 18:01:21,231 [INFO    ] __main__: train step 24132: loss: 0.8905, policy_loss: 0.8004, value_loss: 0.4098
2024-07-11 18:01:21,456 [INFO    ] __main__: train step 24133: loss: 0.8905, policy_loss: 0.8004, value_loss: 0.4098
2024-07-11 18:01:21,677 [INFO    ] __main__: train step 24134: loss: 0.8905, policy_loss: 0.8004, value_loss: 0.4098
2024-07-11 18:01:21,877 [INFO    ] __main__: train step 24135: loss: 0.8904, policy_loss: 0.8004, value_loss: 0.4098
2024-07-11 18:01:22,094 [INFO    ] __main__: train step 24136: loss: 0.8904, policy_loss: 0.8004, value_loss: 0.4098
2024-07-11 18:01:22,330 [INFO    ] __main__: train step 24137: loss: 0.8904, policy_loss: 0.8003, value_loss: 0.4098
2024-07-11 18:01:22,528 [INFO    ] __main__: train step 24138: loss: 0.8904, policy_loss: 0.8003, value_loss: 0.4098
2024-07-11 18:01:22,734 [INFO    ] __main__: train step 24139: loss: 0.8904, policy_loss: 0.8003, value_loss: 0.4097
2024-07-11 18:01:24,196 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:01:24,573 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:01:24,630 [INFO    ] __main__: train step 24140: loss: 0.8903, policy_loss: 0.8003, value_loss: 0.4097
2024-07-11 18:01:24,813 [INFO    ] __main__: train step 24141: loss: 0.8903, policy_loss: 0.8003, value_loss: 0.4097
2024-07-11 18:01:25,023 [INFO    ] __main__: train step 24142: loss: 0.8903, policy_loss: 0.8003, value_loss: 0.4097
2024-07-11 18:01:25,220 [INFO    ] __main__: train step 24143: loss: 0.8903, policy_loss: 0.8002, value_loss: 0.4097
2024-07-11 18:01:25,421 [INFO    ] __main__: train step 24144: loss: 0.8903, policy_loss: 0.8002, value_loss: 0.4097
2024-07-11 18:01:25,627 [INFO    ] __main__: train step 24145: loss: 0.8903, policy_loss: 0.8002, value_loss: 0.4097
2024-07-11 18:01:25,835 [INFO    ] __main__: train step 24146: loss: 0.8902, policy_loss: 0.8002, value_loss: 0.4096
2024-07-11 18:01:26,035 [INFO    ] __main__: train step 24147: loss: 0.8902, policy_loss: 0.8002, value_loss: 0.4096
2024-07-11 18:01:26,247 [INFO    ] __main__: train step 24148: loss: 0.8902, policy_loss: 0.8002, value_loss: 0.4096
2024-07-11 18:01:26,444 [INFO    ] __main__: train step 24149: loss: 0.8902, policy_loss: 0.8001, value_loss: 0.4096
2024-07-11 18:01:26,650 [INFO    ] __main__: train step 24150: loss: 0.8902, policy_loss: 0.8001, value_loss: 0.4096
2024-07-11 18:01:26,861 [INFO    ] __main__: train step 24151: loss: 0.8901, policy_loss: 0.8001, value_loss: 0.4096
2024-07-11 18:01:27,060 [INFO    ] __main__: train step 24152: loss: 0.8901, policy_loss: 0.8001, value_loss: 0.4095
2024-07-11 18:01:27,259 [INFO    ] __main__: train step 24153: loss: 0.8901, policy_loss: 0.8001, value_loss: 0.4095
2024-07-11 18:01:27,462 [INFO    ] __main__: train step 24154: loss: 0.8901, policy_loss: 0.8001, value_loss: 0.4095
2024-07-11 18:01:27,662 [INFO    ] __main__: train step 24155: loss: 0.8901, policy_loss: 0.8000, value_loss: 0.4095
2024-07-11 18:01:27,869 [INFO    ] __main__: train step 24156: loss: 0.8901, policy_loss: 0.8000, value_loss: 0.4095
2024-07-11 18:01:29,319 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:01:29,718 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:01:29,776 [INFO    ] __main__: train step 24157: loss: 0.8900, policy_loss: 0.8000, value_loss: 0.4095
2024-07-11 18:01:29,957 [INFO    ] __main__: train step 24158: loss: 0.8900, policy_loss: 0.8000, value_loss: 0.4095
2024-07-11 18:01:32,419 [INFO    ] __main__: train step 24159: loss: 0.8900, policy_loss: 0.8000, value_loss: 0.4094
2024-07-11 18:01:32,658 [INFO    ] __main__: train step 24160: loss: 0.8900, policy_loss: 0.8000, value_loss: 0.4094
2024-07-11 18:01:32,896 [INFO    ] __main__: train step 24161: loss: 0.8900, policy_loss: 0.8000, value_loss: 0.4094
2024-07-11 18:01:33,120 [INFO    ] __main__: train step 24162: loss: 0.8899, policy_loss: 0.7999, value_loss: 0.4094
2024-07-11 18:01:33,337 [INFO    ] __main__: train step 24163: loss: 0.8899, policy_loss: 0.7999, value_loss: 0.4094
2024-07-11 18:01:33,585 [INFO    ] __main__: train step 24164: loss: 0.8899, policy_loss: 0.7999, value_loss: 0.4094
2024-07-11 18:01:33,831 [INFO    ] __main__: train step 24165: loss: 0.8899, policy_loss: 0.7999, value_loss: 0.4094
2024-07-11 18:01:34,029 [INFO    ] __main__: train step 24166: loss: 0.8899, policy_loss: 0.7999, value_loss: 0.4093
2024-07-11 18:01:34,250 [INFO    ] __main__: train step 24167: loss: 0.8899, policy_loss: 0.7999, value_loss: 0.4093
2024-07-11 18:01:34,455 [INFO    ] __main__: train step 24168: loss: 0.8898, policy_loss: 0.7998, value_loss: 0.4093
2024-07-11 18:01:34,656 [INFO    ] __main__: train step 24169: loss: 0.8898, policy_loss: 0.7998, value_loss: 0.4093
2024-07-11 18:01:34,861 [INFO    ] __main__: train step 24170: loss: 0.8898, policy_loss: 0.7998, value_loss: 0.4093
2024-07-11 18:01:35,068 [INFO    ] __main__: train step 24171: loss: 0.8898, policy_loss: 0.7998, value_loss: 0.4093
2024-07-11 18:01:35,281 [INFO    ] __main__: train step 24172: loss: 0.8898, policy_loss: 0.7998, value_loss: 0.4092
2024-07-11 18:01:35,479 [INFO    ] __main__: train step 24173: loss: 0.8898, policy_loss: 0.7998, value_loss: 0.4092
2024-07-11 18:01:36,921 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:01:37,317 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:01:37,378 [INFO    ] __main__: train step 24174: loss: 0.8897, policy_loss: 0.7997, value_loss: 0.4092
2024-07-11 18:01:37,551 [INFO    ] __main__: train step 24175: loss: 0.8897, policy_loss: 0.7997, value_loss: 0.4092
2024-07-11 18:01:37,762 [INFO    ] __main__: train step 24176: loss: 0.8897, policy_loss: 0.7997, value_loss: 0.4092
2024-07-11 18:01:37,972 [INFO    ] __main__: train step 24177: loss: 0.8897, policy_loss: 0.7997, value_loss: 0.4092
2024-07-11 18:01:38,170 [INFO    ] __main__: train step 24178: loss: 0.8897, policy_loss: 0.7997, value_loss: 0.4092
2024-07-11 18:01:38,378 [INFO    ] __main__: train step 24179: loss: 0.8896, policy_loss: 0.7997, value_loss: 0.4091
2024-07-11 18:01:38,590 [INFO    ] __main__: train step 24180: loss: 0.8896, policy_loss: 0.7996, value_loss: 0.4091
2024-07-11 18:01:38,828 [INFO    ] __main__: train step 24181: loss: 0.8896, policy_loss: 0.7996, value_loss: 0.4091
2024-07-11 18:01:39,048 [INFO    ] __main__: train step 24182: loss: 0.8896, policy_loss: 0.7996, value_loss: 0.4091
2024-07-11 18:01:39,250 [INFO    ] __main__: train step 24183: loss: 0.8896, policy_loss: 0.7996, value_loss: 0.4091
2024-07-11 18:01:39,475 [INFO    ] __main__: train step 24184: loss: 0.8896, policy_loss: 0.7996, value_loss: 0.4091
2024-07-11 18:01:39,701 [INFO    ] __main__: train step 24185: loss: 0.8895, policy_loss: 0.7996, value_loss: 0.4091
2024-07-11 18:01:39,908 [INFO    ] __main__: train step 24186: loss: 0.8895, policy_loss: 0.7995, value_loss: 0.4090
2024-07-11 18:01:40,119 [INFO    ] __main__: train step 24187: loss: 0.8895, policy_loss: 0.7995, value_loss: 0.4090
2024-07-11 18:01:40,330 [INFO    ] __main__: train step 24188: loss: 0.8895, policy_loss: 0.7995, value_loss: 0.4090
2024-07-11 18:01:40,539 [INFO    ] __main__: train step 24189: loss: 0.8895, policy_loss: 0.7995, value_loss: 0.4090
2024-07-11 18:01:40,749 [INFO    ] __main__: train step 24190: loss: 0.8894, policy_loss: 0.7995, value_loss: 0.4090
2024-07-11 18:01:42,185 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:01:42,621 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:01:42,679 [INFO    ] __main__: train step 24191: loss: 0.8894, policy_loss: 0.7995, value_loss: 0.4090
2024-07-11 18:01:42,854 [INFO    ] __main__: train step 24192: loss: 0.8894, policy_loss: 0.7994, value_loss: 0.4089
2024-07-11 18:01:43,062 [INFO    ] __main__: train step 24193: loss: 0.8894, policy_loss: 0.7994, value_loss: 0.4089
2024-07-11 18:01:43,272 [INFO    ] __main__: train step 24194: loss: 0.8894, policy_loss: 0.7994, value_loss: 0.4089
2024-07-11 18:01:43,469 [INFO    ] __main__: train step 24195: loss: 0.8894, policy_loss: 0.7994, value_loss: 0.4089
2024-07-11 18:01:43,671 [INFO    ] __main__: train step 24196: loss: 0.8893, policy_loss: 0.7994, value_loss: 0.4089
2024-07-11 18:01:43,871 [INFO    ] __main__: train step 24197: loss: 0.8893, policy_loss: 0.7994, value_loss: 0.4089
2024-07-11 18:01:44,078 [INFO    ] __main__: train step 24198: loss: 0.8893, policy_loss: 0.7994, value_loss: 0.4089
2024-07-11 18:01:44,286 [INFO    ] __main__: train step 24199: loss: 0.8893, policy_loss: 0.7993, value_loss: 0.4088
2024-07-11 18:01:44,490 [INFO    ] __main__: train step 24200: loss: 0.8893, policy_loss: 0.7993, value_loss: 0.4088
2024-07-11 18:01:44,695 [INFO    ] __main__: train step 24201: loss: 0.8892, policy_loss: 0.7993, value_loss: 0.4088
2024-07-11 18:01:44,917 [INFO    ] __main__: train step 24202: loss: 0.8892, policy_loss: 0.7993, value_loss: 0.4088
2024-07-11 18:01:45,154 [INFO    ] __main__: train step 24203: loss: 0.8892, policy_loss: 0.7993, value_loss: 0.4088
2024-07-11 18:01:45,400 [INFO    ] __main__: train step 24204: loss: 0.8892, policy_loss: 0.7993, value_loss: 0.4088
2024-07-11 18:01:45,644 [INFO    ] __main__: train step 24205: loss: 0.8892, policy_loss: 0.7992, value_loss: 0.4088
2024-07-11 18:01:45,874 [INFO    ] __main__: train step 24206: loss: 0.8892, policy_loss: 0.7992, value_loss: 0.4087
2024-07-11 18:01:46,084 [INFO    ] __main__: train step 24207: loss: 0.8891, policy_loss: 0.7992, value_loss: 0.4087
2024-07-11 18:01:47,525 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:01:47,952 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:01:48,013 [INFO    ] __main__: train step 24208: loss: 0.8891, policy_loss: 0.7992, value_loss: 0.4087
2024-07-11 18:01:48,200 [INFO    ] __main__: train step 24209: loss: 0.8891, policy_loss: 0.7992, value_loss: 0.4087
2024-07-11 18:01:48,442 [INFO    ] __main__: train step 24210: loss: 0.8891, policy_loss: 0.7992, value_loss: 0.4087
2024-07-11 18:01:48,644 [INFO    ] __main__: train step 24211: loss: 0.8891, policy_loss: 0.7991, value_loss: 0.4087
2024-07-11 18:01:48,860 [INFO    ] __main__: train step 24212: loss: 0.8891, policy_loss: 0.7991, value_loss: 0.4086
2024-07-11 18:01:49,064 [INFO    ] __main__: train step 24213: loss: 0.8890, policy_loss: 0.7991, value_loss: 0.4086
2024-07-11 18:01:49,266 [INFO    ] __main__: train step 24214: loss: 0.8890, policy_loss: 0.7991, value_loss: 0.4086
2024-07-11 18:01:49,470 [INFO    ] __main__: train step 24215: loss: 0.8890, policy_loss: 0.7991, value_loss: 0.4086
2024-07-11 18:01:49,685 [INFO    ] __main__: train step 24216: loss: 0.8890, policy_loss: 0.7991, value_loss: 0.4086
2024-07-11 18:01:49,896 [INFO    ] __main__: train step 24217: loss: 0.8890, policy_loss: 0.7990, value_loss: 0.4086
2024-07-11 18:01:50,109 [INFO    ] __main__: train step 24218: loss: 0.8889, policy_loss: 0.7990, value_loss: 0.4086
2024-07-11 18:01:50,337 [INFO    ] __main__: train step 24219: loss: 0.8889, policy_loss: 0.7990, value_loss: 0.4085
2024-07-11 18:01:50,543 [INFO    ] __main__: train step 24220: loss: 0.8889, policy_loss: 0.7990, value_loss: 0.4085
2024-07-11 18:01:50,752 [INFO    ] __main__: train step 24221: loss: 0.8889, policy_loss: 0.7990, value_loss: 0.4085
2024-07-11 18:01:50,970 [INFO    ] __main__: train step 24222: loss: 0.8889, policy_loss: 0.7990, value_loss: 0.4085
2024-07-11 18:01:51,208 [INFO    ] __main__: train step 24223: loss: 0.8889, policy_loss: 0.7989, value_loss: 0.4085
2024-07-11 18:01:51,435 [INFO    ] __main__: train step 24224: loss: 0.8888, policy_loss: 0.7989, value_loss: 0.4085
2024-07-11 18:01:52,872 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:01:53,255 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:01:53,309 [INFO    ] __main__: train step 24225: loss: 0.8888, policy_loss: 0.7989, value_loss: 0.4085
2024-07-11 18:01:53,494 [INFO    ] __main__: train step 24226: loss: 0.8888, policy_loss: 0.7989, value_loss: 0.4084
2024-07-11 18:01:53,699 [INFO    ] __main__: train step 24227: loss: 0.8888, policy_loss: 0.7989, value_loss: 0.4084
2024-07-11 18:01:53,914 [INFO    ] __main__: train step 24228: loss: 0.8888, policy_loss: 0.7989, value_loss: 0.4084
2024-07-11 18:01:54,113 [INFO    ] __main__: train step 24229: loss: 0.8887, policy_loss: 0.7988, value_loss: 0.4084
2024-07-11 18:01:54,325 [INFO    ] __main__: train step 24230: loss: 0.8887, policy_loss: 0.7988, value_loss: 0.4084
2024-07-11 18:01:54,531 [INFO    ] __main__: train step 24231: loss: 0.8887, policy_loss: 0.7988, value_loss: 0.4084
2024-07-11 18:01:54,743 [INFO    ] __main__: train step 24232: loss: 0.8887, policy_loss: 0.7988, value_loss: 0.4083
2024-07-11 18:01:54,942 [INFO    ] __main__: train step 24233: loss: 0.8887, policy_loss: 0.7988, value_loss: 0.4083
2024-07-11 18:01:55,154 [INFO    ] __main__: train step 24234: loss: 0.8887, policy_loss: 0.7988, value_loss: 0.4083
2024-07-11 18:01:55,351 [INFO    ] __main__: train step 24235: loss: 0.8886, policy_loss: 0.7987, value_loss: 0.4083
2024-07-11 18:01:55,554 [INFO    ] __main__: train step 24236: loss: 0.8886, policy_loss: 0.7987, value_loss: 0.4083
2024-07-11 18:01:55,753 [INFO    ] __main__: train step 24237: loss: 0.8886, policy_loss: 0.7987, value_loss: 0.4083
2024-07-11 18:01:55,956 [INFO    ] __main__: train step 24238: loss: 0.8886, policy_loss: 0.7987, value_loss: 0.4083
2024-07-11 18:01:56,158 [INFO    ] __main__: train step 24239: loss: 0.8886, policy_loss: 0.7987, value_loss: 0.4082
2024-07-11 18:01:56,361 [INFO    ] __main__: train step 24240: loss: 0.8885, policy_loss: 0.7987, value_loss: 0.4082
2024-07-11 18:01:56,580 [INFO    ] __main__: train step 24241: loss: 0.8885, policy_loss: 0.7987, value_loss: 0.4082
2024-07-11 18:01:58,024 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:01:58,437 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:01:58,497 [INFO    ] __main__: train step 24242: loss: 0.8885, policy_loss: 0.7986, value_loss: 0.4082
2024-07-11 18:01:58,670 [INFO    ] __main__: train step 24243: loss: 0.8885, policy_loss: 0.7986, value_loss: 0.4082
2024-07-11 18:01:58,880 [INFO    ] __main__: train step 24244: loss: 0.8885, policy_loss: 0.7986, value_loss: 0.4082
2024-07-11 18:01:59,096 [INFO    ] __main__: train step 24245: loss: 0.8885, policy_loss: 0.7986, value_loss: 0.4082
2024-07-11 18:01:59,303 [INFO    ] __main__: train step 24246: loss: 0.8884, policy_loss: 0.7986, value_loss: 0.4081
2024-07-11 18:01:59,512 [INFO    ] __main__: train step 24247: loss: 0.8884, policy_loss: 0.7986, value_loss: 0.4081
2024-07-11 18:01:59,721 [INFO    ] __main__: train step 24248: loss: 0.8884, policy_loss: 0.7985, value_loss: 0.4081
2024-07-11 18:01:59,943 [INFO    ] __main__: train step 24249: loss: 0.8884, policy_loss: 0.7985, value_loss: 0.4081
2024-07-11 18:02:00,192 [INFO    ] __main__: train step 24250: loss: 0.8884, policy_loss: 0.7985, value_loss: 0.4081
2024-07-11 18:02:00,398 [INFO    ] __main__: train step 24251: loss: 0.8883, policy_loss: 0.7985, value_loss: 0.4081
2024-07-11 18:02:00,604 [INFO    ] __main__: train step 24252: loss: 0.8883, policy_loss: 0.7985, value_loss: 0.4081
2024-07-11 18:02:00,816 [INFO    ] __main__: train step 24253: loss: 0.8883, policy_loss: 0.7985, value_loss: 0.4080
2024-07-11 18:02:01,029 [INFO    ] __main__: train step 24254: loss: 0.8883, policy_loss: 0.7984, value_loss: 0.4080
2024-07-11 18:02:01,239 [INFO    ] __main__: train step 24255: loss: 0.8883, policy_loss: 0.7984, value_loss: 0.4080
2024-07-11 18:02:01,453 [INFO    ] __main__: train step 24256: loss: 0.8883, policy_loss: 0.7984, value_loss: 0.4080
2024-07-11 18:02:01,661 [INFO    ] __main__: train step 24257: loss: 0.8882, policy_loss: 0.7984, value_loss: 0.4080
2024-07-11 18:02:01,865 [INFO    ] __main__: train step 24258: loss: 0.8882, policy_loss: 0.7984, value_loss: 0.4080
2024-07-11 18:02:03,319 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:02:03,586 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:02:03,639 [INFO    ] __main__: train step 24259: loss: 0.8882, policy_loss: 0.7984, value_loss: 0.4079
2024-07-11 18:02:03,816 [INFO    ] __main__: train step 24260: loss: 0.8882, policy_loss: 0.7983, value_loss: 0.4079
2024-07-11 18:02:04,037 [INFO    ] __main__: train step 24261: loss: 0.8882, policy_loss: 0.7983, value_loss: 0.4079
2024-07-11 18:02:04,238 [INFO    ] __main__: train step 24262: loss: 0.8881, policy_loss: 0.7983, value_loss: 0.4079
2024-07-11 18:02:04,446 [INFO    ] __main__: train step 24263: loss: 0.8881, policy_loss: 0.7983, value_loss: 0.4079
2024-07-11 18:02:04,653 [INFO    ] __main__: train step 24264: loss: 0.8881, policy_loss: 0.7983, value_loss: 0.4079
2024-07-11 18:02:04,857 [INFO    ] __main__: train step 24265: loss: 0.8881, policy_loss: 0.7983, value_loss: 0.4079
2024-07-11 18:02:05,068 [INFO    ] __main__: train step 24266: loss: 0.8881, policy_loss: 0.7982, value_loss: 0.4078
2024-07-11 18:02:05,270 [INFO    ] __main__: train step 24267: loss: 0.8880, policy_loss: 0.7982, value_loss: 0.4078
2024-07-11 18:02:05,474 [INFO    ] __main__: train step 24268: loss: 0.8880, policy_loss: 0.7982, value_loss: 0.4078
2024-07-11 18:02:05,677 [INFO    ] __main__: train step 24269: loss: 0.8880, policy_loss: 0.7982, value_loss: 0.4078
2024-07-11 18:02:05,887 [INFO    ] __main__: train step 24270: loss: 0.8880, policy_loss: 0.7982, value_loss: 0.4078
2024-07-11 18:02:06,094 [INFO    ] __main__: train step 24271: loss: 0.8880, policy_loss: 0.7982, value_loss: 0.4078
2024-07-11 18:02:06,294 [INFO    ] __main__: train step 24272: loss: 0.8880, policy_loss: 0.7981, value_loss: 0.4078
2024-07-11 18:02:06,498 [INFO    ] __main__: train step 24273: loss: 0.8879, policy_loss: 0.7981, value_loss: 0.4077
2024-07-11 18:02:06,706 [INFO    ] __main__: train step 24274: loss: 0.8879, policy_loss: 0.7981, value_loss: 0.4077
2024-07-11 18:02:06,904 [INFO    ] __main__: train step 24275: loss: 0.8879, policy_loss: 0.7981, value_loss: 0.4077
2024-07-11 18:02:08,338 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:02:08,733 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:02:08,788 [INFO    ] __main__: train step 24276: loss: 0.8879, policy_loss: 0.7981, value_loss: 0.4077
2024-07-11 18:02:08,978 [INFO    ] __main__: train step 24277: loss: 0.8879, policy_loss: 0.7981, value_loss: 0.4077
2024-07-11 18:02:09,193 [INFO    ] __main__: train step 24278: loss: 0.8878, policy_loss: 0.7980, value_loss: 0.4077
2024-07-11 18:02:09,444 [INFO    ] __main__: train step 24279: loss: 0.8878, policy_loss: 0.7980, value_loss: 0.4076
2024-07-11 18:02:09,675 [INFO    ] __main__: train step 24280: loss: 0.8878, policy_loss: 0.7980, value_loss: 0.4076
2024-07-11 18:02:09,890 [INFO    ] __main__: train step 24281: loss: 0.8878, policy_loss: 0.7980, value_loss: 0.4076
2024-07-11 18:02:10,119 [INFO    ] __main__: train step 24282: loss: 0.8878, policy_loss: 0.7980, value_loss: 0.4076
2024-07-11 18:02:10,323 [INFO    ] __main__: train step 24283: loss: 0.8878, policy_loss: 0.7980, value_loss: 0.4076
2024-07-11 18:02:10,521 [INFO    ] __main__: train step 24284: loss: 0.8877, policy_loss: 0.7979, value_loss: 0.4076
2024-07-11 18:02:10,725 [INFO    ] __main__: train step 24285: loss: 0.8877, policy_loss: 0.7979, value_loss: 0.4076
2024-07-11 18:02:10,937 [INFO    ] __main__: train step 24286: loss: 0.8877, policy_loss: 0.7979, value_loss: 0.4075
2024-07-11 18:02:11,144 [INFO    ] __main__: train step 24287: loss: 0.8877, policy_loss: 0.7979, value_loss: 0.4075
2024-07-11 18:02:11,335 [INFO    ] __main__: train step 24288: loss: 0.8877, policy_loss: 0.7979, value_loss: 0.4075
2024-07-11 18:02:11,532 [INFO    ] __main__: train step 24289: loss: 0.8876, policy_loss: 0.7979, value_loss: 0.4075
2024-07-11 18:02:11,737 [INFO    ] __main__: train step 24290: loss: 0.8876, policy_loss: 0.7978, value_loss: 0.4075
2024-07-11 18:02:11,946 [INFO    ] __main__: train step 24291: loss: 0.8876, policy_loss: 0.7978, value_loss: 0.4075
2024-07-11 18:02:12,197 [INFO    ] __main__: train step 24292: loss: 0.8876, policy_loss: 0.7978, value_loss: 0.4074
2024-07-11 18:02:13,663 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:02:14,074 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:02:14,133 [INFO    ] __main__: train step 24293: loss: 0.8876, policy_loss: 0.7978, value_loss: 0.4074
2024-07-11 18:02:14,322 [INFO    ] __main__: train step 24294: loss: 0.8876, policy_loss: 0.7978, value_loss: 0.4074
2024-07-11 18:02:14,531 [INFO    ] __main__: train step 24295: loss: 0.8875, policy_loss: 0.7978, value_loss: 0.4074
2024-07-11 18:02:14,735 [INFO    ] __main__: train step 24296: loss: 0.8875, policy_loss: 0.7977, value_loss: 0.4074
2024-07-11 18:02:14,968 [INFO    ] __main__: train step 24297: loss: 0.8875, policy_loss: 0.7977, value_loss: 0.4074
2024-07-11 18:02:15,176 [INFO    ] __main__: train step 24298: loss: 0.8875, policy_loss: 0.7977, value_loss: 0.4074
2024-07-11 18:02:15,374 [INFO    ] __main__: train step 24299: loss: 0.8875, policy_loss: 0.7977, value_loss: 0.4073
2024-07-11 18:02:15,572 [INFO    ] __main__: train step 24300: loss: 0.8874, policy_loss: 0.7977, value_loss: 0.4073
2024-07-11 18:02:15,778 [INFO    ] __main__: train step 24301: loss: 0.8874, policy_loss: 0.7977, value_loss: 0.4073
2024-07-11 18:02:18,216 [INFO    ] __main__: train step 24302: loss: 0.8874, policy_loss: 0.7977, value_loss: 0.4073
2024-07-11 18:02:18,434 [INFO    ] __main__: train step 24303: loss: 0.8874, policy_loss: 0.7976, value_loss: 0.4073
2024-07-11 18:02:18,658 [INFO    ] __main__: train step 24304: loss: 0.8874, policy_loss: 0.7976, value_loss: 0.4073
2024-07-11 18:02:18,864 [INFO    ] __main__: train step 24305: loss: 0.8874, policy_loss: 0.7976, value_loss: 0.4073
2024-07-11 18:02:19,074 [INFO    ] __main__: train step 24306: loss: 0.8873, policy_loss: 0.7976, value_loss: 0.4072
2024-07-11 18:02:19,280 [INFO    ] __main__: train step 24307: loss: 0.8873, policy_loss: 0.7976, value_loss: 0.4072
2024-07-11 18:02:19,480 [INFO    ] __main__: train step 24308: loss: 0.8873, policy_loss: 0.7976, value_loss: 0.4072
2024-07-11 18:02:19,686 [INFO    ] __main__: train step 24309: loss: 0.8873, policy_loss: 0.7975, value_loss: 0.4072
2024-07-11 18:02:21,140 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:02:21,503 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:02:21,563 [INFO    ] __main__: train step 24310: loss: 0.8873, policy_loss: 0.7975, value_loss: 0.4072
2024-07-11 18:02:21,746 [INFO    ] __main__: train step 24311: loss: 0.8872, policy_loss: 0.7975, value_loss: 0.4072
2024-07-11 18:02:21,959 [INFO    ] __main__: train step 24312: loss: 0.8872, policy_loss: 0.7975, value_loss: 0.4071
2024-07-11 18:02:22,163 [INFO    ] __main__: train step 24313: loss: 0.8872, policy_loss: 0.7975, value_loss: 0.4071
2024-07-11 18:02:22,370 [INFO    ] __main__: train step 24314: loss: 0.8872, policy_loss: 0.7975, value_loss: 0.4071
2024-07-11 18:02:22,570 [INFO    ] __main__: train step 24315: loss: 0.8872, policy_loss: 0.7974, value_loss: 0.4071
2024-07-11 18:02:22,783 [INFO    ] __main__: train step 24316: loss: 0.8872, policy_loss: 0.7974, value_loss: 0.4071
2024-07-11 18:02:22,987 [INFO    ] __main__: train step 24317: loss: 0.8871, policy_loss: 0.7974, value_loss: 0.4071
2024-07-11 18:02:23,199 [INFO    ] __main__: train step 24318: loss: 0.8871, policy_loss: 0.7974, value_loss: 0.4071
2024-07-11 18:02:23,401 [INFO    ] __main__: train step 24319: loss: 0.8871, policy_loss: 0.7974, value_loss: 0.4070
2024-07-11 18:02:23,605 [INFO    ] __main__: train step 24320: loss: 0.8871, policy_loss: 0.7974, value_loss: 0.4070
2024-07-11 18:02:23,813 [INFO    ] __main__: train step 24321: loss: 0.8871, policy_loss: 0.7973, value_loss: 0.4070
2024-07-11 18:02:24,020 [INFO    ] __main__: train step 24322: loss: 0.8870, policy_loss: 0.7973, value_loss: 0.4070
2024-07-11 18:02:24,230 [INFO    ] __main__: train step 24323: loss: 0.8870, policy_loss: 0.7973, value_loss: 0.4070
2024-07-11 18:02:24,458 [INFO    ] __main__: train step 24324: loss: 0.8870, policy_loss: 0.7973, value_loss: 0.4070
2024-07-11 18:02:24,697 [INFO    ] __main__: train step 24325: loss: 0.8870, policy_loss: 0.7973, value_loss: 0.4070
2024-07-11 18:02:24,927 [INFO    ] __main__: train step 24326: loss: 0.8870, policy_loss: 0.7973, value_loss: 0.4069
2024-07-11 18:02:26,381 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:02:26,815 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:02:26,875 [INFO    ] __main__: train step 24327: loss: 0.8869, policy_loss: 0.7972, value_loss: 0.4069
2024-07-11 18:02:27,062 [INFO    ] __main__: train step 24328: loss: 0.8869, policy_loss: 0.7972, value_loss: 0.4069
2024-07-11 18:02:27,283 [INFO    ] __main__: train step 24329: loss: 0.8869, policy_loss: 0.7972, value_loss: 0.4069
2024-07-11 18:02:27,489 [INFO    ] __main__: train step 24330: loss: 0.8869, policy_loss: 0.7972, value_loss: 0.4069
2024-07-11 18:02:27,693 [INFO    ] __main__: train step 24331: loss: 0.8869, policy_loss: 0.7972, value_loss: 0.4069
2024-07-11 18:02:27,890 [INFO    ] __main__: train step 24332: loss: 0.8869, policy_loss: 0.7972, value_loss: 0.4069
2024-07-11 18:02:28,091 [INFO    ] __main__: train step 24333: loss: 0.8868, policy_loss: 0.7971, value_loss: 0.4068
2024-07-11 18:02:28,295 [INFO    ] __main__: train step 24334: loss: 0.8868, policy_loss: 0.7971, value_loss: 0.4068
2024-07-11 18:02:28,505 [INFO    ] __main__: train step 24335: loss: 0.8868, policy_loss: 0.7971, value_loss: 0.4068
2024-07-11 18:02:28,708 [INFO    ] __main__: train step 24336: loss: 0.8868, policy_loss: 0.7971, value_loss: 0.4068
2024-07-11 18:02:28,916 [INFO    ] __main__: train step 24337: loss: 0.8868, policy_loss: 0.7971, value_loss: 0.4068
2024-07-11 18:02:29,128 [INFO    ] __main__: train step 24338: loss: 0.8867, policy_loss: 0.7971, value_loss: 0.4068
2024-07-11 18:02:29,334 [INFO    ] __main__: train step 24339: loss: 0.8867, policy_loss: 0.7970, value_loss: 0.4067
2024-07-11 18:02:29,541 [INFO    ] __main__: train step 24340: loss: 0.8867, policy_loss: 0.7970, value_loss: 0.4067
2024-07-11 18:02:29,739 [INFO    ] __main__: train step 24341: loss: 0.8867, policy_loss: 0.7970, value_loss: 0.4067
2024-07-11 18:02:29,943 [INFO    ] __main__: train step 24342: loss: 0.8867, policy_loss: 0.7970, value_loss: 0.4067
2024-07-11 18:02:30,154 [INFO    ] __main__: train step 24343: loss: 0.8867, policy_loss: 0.7970, value_loss: 0.4067
2024-07-11 18:02:31,606 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:02:31,984 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:02:32,039 [INFO    ] __main__: train step 24344: loss: 0.8866, policy_loss: 0.7970, value_loss: 0.4067
2024-07-11 18:02:32,218 [INFO    ] __main__: train step 24345: loss: 0.8866, policy_loss: 0.7969, value_loss: 0.4067
2024-07-11 18:02:32,424 [INFO    ] __main__: train step 24346: loss: 0.8866, policy_loss: 0.7969, value_loss: 0.4066
2024-07-11 18:02:32,628 [INFO    ] __main__: train step 24347: loss: 0.8866, policy_loss: 0.7969, value_loss: 0.4066
2024-07-11 18:02:32,839 [INFO    ] __main__: train step 24348: loss: 0.8866, policy_loss: 0.7969, value_loss: 0.4066
2024-07-11 18:02:33,050 [INFO    ] __main__: train step 24349: loss: 0.8865, policy_loss: 0.7969, value_loss: 0.4066
2024-07-11 18:02:33,253 [INFO    ] __main__: train step 24350: loss: 0.8865, policy_loss: 0.7969, value_loss: 0.4066
2024-07-11 18:02:33,475 [INFO    ] __main__: train step 24351: loss: 0.8865, policy_loss: 0.7968, value_loss: 0.4066
2024-07-11 18:02:33,715 [INFO    ] __main__: train step 24352: loss: 0.8865, policy_loss: 0.7968, value_loss: 0.4066
2024-07-11 18:02:33,926 [INFO    ] __main__: train step 24353: loss: 0.8865, policy_loss: 0.7968, value_loss: 0.4065
2024-07-11 18:02:34,130 [INFO    ] __main__: train step 24354: loss: 0.8864, policy_loss: 0.7968, value_loss: 0.4065
2024-07-11 18:02:34,340 [INFO    ] __main__: train step 24355: loss: 0.8864, policy_loss: 0.7968, value_loss: 0.4065
2024-07-11 18:02:34,556 [INFO    ] __main__: train step 24356: loss: 0.8864, policy_loss: 0.7968, value_loss: 0.4065
2024-07-11 18:02:34,802 [INFO    ] __main__: train step 24357: loss: 0.8864, policy_loss: 0.7967, value_loss: 0.4065
2024-07-11 18:02:35,031 [INFO    ] __main__: train step 24358: loss: 0.8864, policy_loss: 0.7967, value_loss: 0.4065
2024-07-11 18:02:35,236 [INFO    ] __main__: train step 24359: loss: 0.8864, policy_loss: 0.7967, value_loss: 0.4064
2024-07-11 18:02:35,436 [INFO    ] __main__: train step 24360: loss: 0.8863, policy_loss: 0.7967, value_loss: 0.4064
2024-07-11 18:02:36,902 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:02:37,302 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:02:37,364 [INFO    ] __main__: train step 24361: loss: 0.8863, policy_loss: 0.7967, value_loss: 0.4064
2024-07-11 18:02:37,539 [INFO    ] __main__: train step 24362: loss: 0.8863, policy_loss: 0.7967, value_loss: 0.4064
2024-07-11 18:02:37,747 [INFO    ] __main__: train step 24363: loss: 0.8863, policy_loss: 0.7966, value_loss: 0.4064
2024-07-11 18:02:37,953 [INFO    ] __main__: train step 24364: loss: 0.8863, policy_loss: 0.7966, value_loss: 0.4064
2024-07-11 18:02:38,153 [INFO    ] __main__: train step 24365: loss: 0.8862, policy_loss: 0.7966, value_loss: 0.4064
2024-07-11 18:02:38,353 [INFO    ] __main__: train step 24366: loss: 0.8862, policy_loss: 0.7966, value_loss: 0.4063
2024-07-11 18:02:38,556 [INFO    ] __main__: train step 24367: loss: 0.8862, policy_loss: 0.7966, value_loss: 0.4063
2024-07-11 18:02:38,765 [INFO    ] __main__: train step 24368: loss: 0.8862, policy_loss: 0.7966, value_loss: 0.4063
2024-07-11 18:02:38,980 [INFO    ] __main__: train step 24369: loss: 0.8862, policy_loss: 0.7965, value_loss: 0.4063
2024-07-11 18:02:39,194 [INFO    ] __main__: train step 24370: loss: 0.8862, policy_loss: 0.7965, value_loss: 0.4063
2024-07-11 18:02:39,423 [INFO    ] __main__: train step 24371: loss: 0.8861, policy_loss: 0.7965, value_loss: 0.4063
2024-07-11 18:02:39,651 [INFO    ] __main__: train step 24372: loss: 0.8861, policy_loss: 0.7965, value_loss: 0.4062
2024-07-11 18:02:39,864 [INFO    ] __main__: train step 24373: loss: 0.8861, policy_loss: 0.7965, value_loss: 0.4062
2024-07-11 18:02:40,076 [INFO    ] __main__: train step 24374: loss: 0.8861, policy_loss: 0.7965, value_loss: 0.4062
2024-07-11 18:02:40,277 [INFO    ] __main__: train step 24375: loss: 0.8861, policy_loss: 0.7964, value_loss: 0.4062
2024-07-11 18:02:40,488 [INFO    ] __main__: train step 24376: loss: 0.8860, policy_loss: 0.7964, value_loss: 0.4062
2024-07-11 18:02:40,693 [INFO    ] __main__: train step 24377: loss: 0.8860, policy_loss: 0.7964, value_loss: 0.4062
2024-07-11 18:02:42,145 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:02:42,516 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:02:42,573 [INFO    ] __main__: train step 24378: loss: 0.8860, policy_loss: 0.7964, value_loss: 0.4062
2024-07-11 18:02:42,765 [INFO    ] __main__: train step 24379: loss: 0.8860, policy_loss: 0.7964, value_loss: 0.4061
2024-07-11 18:02:42,967 [INFO    ] __main__: train step 24380: loss: 0.8860, policy_loss: 0.7964, value_loss: 0.4061
2024-07-11 18:02:43,172 [INFO    ] __main__: train step 24381: loss: 0.8859, policy_loss: 0.7963, value_loss: 0.4061
2024-07-11 18:02:43,380 [INFO    ] __main__: train step 24382: loss: 0.8859, policy_loss: 0.7963, value_loss: 0.4061
2024-07-11 18:02:43,594 [INFO    ] __main__: train step 24383: loss: 0.8859, policy_loss: 0.7963, value_loss: 0.4061
2024-07-11 18:02:43,797 [INFO    ] __main__: train step 24384: loss: 0.8859, policy_loss: 0.7963, value_loss: 0.4061
2024-07-11 18:02:43,998 [INFO    ] __main__: train step 24385: loss: 0.8859, policy_loss: 0.7963, value_loss: 0.4061
2024-07-11 18:02:44,219 [INFO    ] __main__: train step 24386: loss: 0.8859, policy_loss: 0.7963, value_loss: 0.4060
2024-07-11 18:02:44,424 [INFO    ] __main__: train step 24387: loss: 0.8858, policy_loss: 0.7962, value_loss: 0.4060
2024-07-11 18:02:44,626 [INFO    ] __main__: train step 24388: loss: 0.8858, policy_loss: 0.7962, value_loss: 0.4060
2024-07-11 18:02:44,831 [INFO    ] __main__: train step 24389: loss: 0.8858, policy_loss: 0.7962, value_loss: 0.4060
2024-07-11 18:02:45,039 [INFO    ] __main__: train step 24390: loss: 0.8858, policy_loss: 0.7962, value_loss: 0.4060
2024-07-11 18:02:45,262 [INFO    ] __main__: train step 24391: loss: 0.8858, policy_loss: 0.7962, value_loss: 0.4060
2024-07-11 18:02:45,468 [INFO    ] __main__: train step 24392: loss: 0.8857, policy_loss: 0.7962, value_loss: 0.4060
2024-07-11 18:02:45,673 [INFO    ] __main__: train step 24393: loss: 0.8857, policy_loss: 0.7962, value_loss: 0.4059
2024-07-11 18:02:45,876 [INFO    ] __main__: train step 24394: loss: 0.8857, policy_loss: 0.7961, value_loss: 0.4059
2024-07-11 18:02:47,334 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:02:47,715 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:02:47,770 [INFO    ] __main__: train step 24395: loss: 0.8857, policy_loss: 0.7961, value_loss: 0.4059
2024-07-11 18:02:47,965 [INFO    ] __main__: train step 24396: loss: 0.8857, policy_loss: 0.7961, value_loss: 0.4059
2024-07-11 18:02:48,202 [INFO    ] __main__: train step 24397: loss: 0.8857, policy_loss: 0.7961, value_loss: 0.4059
2024-07-11 18:02:48,429 [INFO    ] __main__: train step 24398: loss: 0.8856, policy_loss: 0.7961, value_loss: 0.4059
2024-07-11 18:02:48,633 [INFO    ] __main__: train step 24399: loss: 0.8856, policy_loss: 0.7961, value_loss: 0.4058
2024-07-11 18:02:48,841 [INFO    ] __main__: train step 24400: loss: 0.8856, policy_loss: 0.7960, value_loss: 0.4058
2024-07-11 18:02:49,048 [INFO    ] __main__: train step 24401: loss: 0.8856, policy_loss: 0.7960, value_loss: 0.4058
2024-07-11 18:02:49,255 [INFO    ] __main__: train step 24402: loss: 0.8856, policy_loss: 0.7960, value_loss: 0.4058
2024-07-11 18:02:49,467 [INFO    ] __main__: train step 24403: loss: 0.8855, policy_loss: 0.7960, value_loss: 0.4058
2024-07-11 18:02:49,664 [INFO    ] __main__: train step 24404: loss: 0.8855, policy_loss: 0.7960, value_loss: 0.4058
2024-07-11 18:02:49,872 [INFO    ] __main__: train step 24405: loss: 0.8855, policy_loss: 0.7960, value_loss: 0.4058
2024-07-11 18:02:50,071 [INFO    ] __main__: train step 24406: loss: 0.8855, policy_loss: 0.7959, value_loss: 0.4057
2024-07-11 18:02:50,272 [INFO    ] __main__: train step 24407: loss: 0.8855, policy_loss: 0.7959, value_loss: 0.4057
2024-07-11 18:02:50,479 [INFO    ] __main__: train step 24408: loss: 0.8855, policy_loss: 0.7959, value_loss: 0.4057
2024-07-11 18:02:50,676 [INFO    ] __main__: train step 24409: loss: 0.8854, policy_loss: 0.7959, value_loss: 0.4057
2024-07-11 18:02:50,898 [INFO    ] __main__: train step 24410: loss: 0.8854, policy_loss: 0.7959, value_loss: 0.4057
2024-07-11 18:02:51,105 [INFO    ] __main__: train step 24411: loss: 0.8854, policy_loss: 0.7959, value_loss: 0.4057
2024-07-11 18:02:52,582 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:02:52,926 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:02:52,982 [INFO    ] __main__: train step 24412: loss: 0.8854, policy_loss: 0.7958, value_loss: 0.4057
2024-07-11 18:02:53,161 [INFO    ] __main__: train step 24413: loss: 0.8854, policy_loss: 0.7958, value_loss: 0.4056
2024-07-11 18:02:53,364 [INFO    ] __main__: train step 24414: loss: 0.8853, policy_loss: 0.7958, value_loss: 0.4056
2024-07-11 18:02:53,570 [INFO    ] __main__: train step 24415: loss: 0.8853, policy_loss: 0.7958, value_loss: 0.4056
2024-07-11 18:02:53,774 [INFO    ] __main__: train step 24416: loss: 0.8853, policy_loss: 0.7958, value_loss: 0.4056
2024-07-11 18:02:53,986 [INFO    ] __main__: train step 24417: loss: 0.8853, policy_loss: 0.7958, value_loss: 0.4056
2024-07-11 18:02:54,217 [INFO    ] __main__: train step 24418: loss: 0.8853, policy_loss: 0.7957, value_loss: 0.4056
2024-07-11 18:02:54,429 [INFO    ] __main__: train step 24419: loss: 0.8852, policy_loss: 0.7957, value_loss: 0.4055
2024-07-11 18:02:54,628 [INFO    ] __main__: train step 24420: loss: 0.8852, policy_loss: 0.7957, value_loss: 0.4055
2024-07-11 18:02:54,850 [INFO    ] __main__: train step 24421: loss: 0.8852, policy_loss: 0.7957, value_loss: 0.4055
2024-07-11 18:02:55,052 [INFO    ] __main__: train step 24422: loss: 0.8852, policy_loss: 0.7957, value_loss: 0.4055
2024-07-11 18:02:55,255 [INFO    ] __main__: train step 24423: loss: 0.8852, policy_loss: 0.7957, value_loss: 0.4055
2024-07-11 18:02:55,455 [INFO    ] __main__: train step 24424: loss: 0.8852, policy_loss: 0.7956, value_loss: 0.4055
2024-07-11 18:02:55,658 [INFO    ] __main__: train step 24425: loss: 0.8851, policy_loss: 0.7956, value_loss: 0.4055
2024-07-11 18:02:55,877 [INFO    ] __main__: train step 24426: loss: 0.8851, policy_loss: 0.7956, value_loss: 0.4054
2024-07-11 18:02:56,076 [INFO    ] __main__: train step 24427: loss: 0.8851, policy_loss: 0.7956, value_loss: 0.4054
2024-07-11 18:02:56,281 [INFO    ] __main__: train step 24428: loss: 0.8851, policy_loss: 0.7956, value_loss: 0.4054
2024-07-11 18:02:57,751 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:02:58,125 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:02:58,184 [INFO    ] __main__: train step 24429: loss: 0.8851, policy_loss: 0.7956, value_loss: 0.4054
2024-07-11 18:02:58,359 [INFO    ] __main__: train step 24430: loss: 0.8850, policy_loss: 0.7955, value_loss: 0.4054
2024-07-11 18:02:58,570 [INFO    ] __main__: train step 24431: loss: 0.8850, policy_loss: 0.7955, value_loss: 0.4054
2024-07-11 18:02:58,784 [INFO    ] __main__: train step 24432: loss: 0.8850, policy_loss: 0.7955, value_loss: 0.4054
2024-07-11 18:02:58,992 [INFO    ] __main__: train step 24433: loss: 0.8850, policy_loss: 0.7955, value_loss: 0.4053
2024-07-11 18:02:59,185 [INFO    ] __main__: train step 24434: loss: 0.8850, policy_loss: 0.7955, value_loss: 0.4053
2024-07-11 18:02:59,388 [INFO    ] __main__: train step 24435: loss: 0.8849, policy_loss: 0.7955, value_loss: 0.4053
2024-07-11 18:02:59,601 [INFO    ] __main__: train step 24436: loss: 0.8849, policy_loss: 0.7954, value_loss: 0.4053
2024-07-11 18:02:59,807 [INFO    ] __main__: train step 24437: loss: 0.8849, policy_loss: 0.7954, value_loss: 0.4053
2024-07-11 18:03:00,036 [INFO    ] __main__: train step 24438: loss: 0.8849, policy_loss: 0.7954, value_loss: 0.4053
2024-07-11 18:03:02,535 [INFO    ] __main__: train step 24439: loss: 0.8849, policy_loss: 0.7954, value_loss: 0.4052
2024-07-11 18:03:02,766 [INFO    ] __main__: train step 24440: loss: 0.8849, policy_loss: 0.7954, value_loss: 0.4052
2024-07-11 18:03:02,984 [INFO    ] __main__: train step 24441: loss: 0.8848, policy_loss: 0.7954, value_loss: 0.4052
2024-07-11 18:03:03,230 [INFO    ] __main__: train step 24442: loss: 0.8848, policy_loss: 0.7953, value_loss: 0.4052
2024-07-11 18:03:03,429 [INFO    ] __main__: train step 24443: loss: 0.8848, policy_loss: 0.7953, value_loss: 0.4052
2024-07-11 18:03:03,640 [INFO    ] __main__: train step 24444: loss: 0.8848, policy_loss: 0.7953, value_loss: 0.4052
2024-07-11 18:03:03,861 [INFO    ] __main__: train step 24445: loss: 0.8848, policy_loss: 0.7953, value_loss: 0.4052
2024-07-11 18:03:05,322 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:03:05,732 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:03:05,791 [INFO    ] __main__: train step 24446: loss: 0.8847, policy_loss: 0.7953, value_loss: 0.4051
2024-07-11 18:03:05,979 [INFO    ] __main__: train step 24447: loss: 0.8847, policy_loss: 0.7953, value_loss: 0.4051
2024-07-11 18:03:06,203 [INFO    ] __main__: train step 24448: loss: 0.8847, policy_loss: 0.7952, value_loss: 0.4051
2024-07-11 18:03:06,398 [INFO    ] __main__: train step 24449: loss: 0.8847, policy_loss: 0.7952, value_loss: 0.4051
2024-07-11 18:03:06,611 [INFO    ] __main__: train step 24450: loss: 0.8847, policy_loss: 0.7952, value_loss: 0.4051
2024-07-11 18:03:06,840 [INFO    ] __main__: train step 24451: loss: 0.8846, policy_loss: 0.7952, value_loss: 0.4051
2024-07-11 18:03:07,069 [INFO    ] __main__: train step 24452: loss: 0.8846, policy_loss: 0.7952, value_loss: 0.4050
2024-07-11 18:03:07,282 [INFO    ] __main__: train step 24453: loss: 0.8846, policy_loss: 0.7952, value_loss: 0.4050
2024-07-11 18:03:07,501 [INFO    ] __main__: train step 24454: loss: 0.8846, policy_loss: 0.7951, value_loss: 0.4050
2024-07-11 18:03:07,737 [INFO    ] __main__: train step 24455: loss: 0.8846, policy_loss: 0.7951, value_loss: 0.4050
2024-07-11 18:03:07,952 [INFO    ] __main__: train step 24456: loss: 0.8846, policy_loss: 0.7951, value_loss: 0.4050
2024-07-11 18:03:08,193 [INFO    ] __main__: train step 24457: loss: 0.8845, policy_loss: 0.7951, value_loss: 0.4050
2024-07-11 18:03:08,397 [INFO    ] __main__: train step 24458: loss: 0.8845, policy_loss: 0.7951, value_loss: 0.4050
2024-07-11 18:03:08,599 [INFO    ] __main__: train step 24459: loss: 0.8845, policy_loss: 0.7951, value_loss: 0.4049
2024-07-11 18:03:08,802 [INFO    ] __main__: train step 24460: loss: 0.8845, policy_loss: 0.7950, value_loss: 0.4049
2024-07-11 18:03:09,032 [INFO    ] __main__: train step 24461: loss: 0.8845, policy_loss: 0.7950, value_loss: 0.4049
2024-07-11 18:03:09,263 [INFO    ] __main__: train step 24462: loss: 0.8844, policy_loss: 0.7950, value_loss: 0.4049
2024-07-11 18:03:10,725 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:03:11,143 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:03:11,204 [INFO    ] __main__: train step 24463: loss: 0.8844, policy_loss: 0.7950, value_loss: 0.4049
2024-07-11 18:03:11,398 [INFO    ] __main__: train step 24464: loss: 0.8844, policy_loss: 0.7950, value_loss: 0.4049
2024-07-11 18:03:11,586 [INFO    ] __main__: train step 24465: loss: 0.8844, policy_loss: 0.7950, value_loss: 0.4049
2024-07-11 18:03:11,799 [INFO    ] __main__: train step 24466: loss: 0.8844, policy_loss: 0.7949, value_loss: 0.4048
2024-07-11 18:03:12,015 [INFO    ] __main__: train step 24467: loss: 0.8843, policy_loss: 0.7949, value_loss: 0.4048
2024-07-11 18:03:12,256 [INFO    ] __main__: train step 24468: loss: 0.8843, policy_loss: 0.7949, value_loss: 0.4048
2024-07-11 18:03:12,452 [INFO    ] __main__: train step 24469: loss: 0.8843, policy_loss: 0.7949, value_loss: 0.4048
2024-07-11 18:03:12,657 [INFO    ] __main__: train step 24470: loss: 0.8843, policy_loss: 0.7949, value_loss: 0.4048
2024-07-11 18:03:12,860 [INFO    ] __main__: train step 24471: loss: 0.8843, policy_loss: 0.7949, value_loss: 0.4048
2024-07-11 18:03:13,068 [INFO    ] __main__: train step 24472: loss: 0.8842, policy_loss: 0.7948, value_loss: 0.4047
2024-07-11 18:03:13,282 [INFO    ] __main__: train step 24473: loss: 0.8842, policy_loss: 0.7948, value_loss: 0.4047
2024-07-11 18:03:13,490 [INFO    ] __main__: train step 24474: loss: 0.8842, policy_loss: 0.7948, value_loss: 0.4047
2024-07-11 18:03:13,702 [INFO    ] __main__: train step 24475: loss: 0.8842, policy_loss: 0.7948, value_loss: 0.4047
2024-07-11 18:03:13,941 [INFO    ] __main__: train step 24476: loss: 0.8842, policy_loss: 0.7948, value_loss: 0.4047
2024-07-11 18:03:14,174 [INFO    ] __main__: train step 24477: loss: 0.8842, policy_loss: 0.7948, value_loss: 0.4047
2024-07-11 18:03:14,387 [INFO    ] __main__: train step 24478: loss: 0.8841, policy_loss: 0.7947, value_loss: 0.4047
2024-07-11 18:03:14,582 [INFO    ] __main__: train step 24479: loss: 0.8841, policy_loss: 0.7947, value_loss: 0.4046
2024-07-11 18:03:16,020 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:03:16,359 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:03:16,415 [INFO    ] __main__: train step 24480: loss: 0.8841, policy_loss: 0.7947, value_loss: 0.4046
2024-07-11 18:03:16,597 [INFO    ] __main__: train step 24481: loss: 0.8841, policy_loss: 0.7947, value_loss: 0.4046
2024-07-11 18:03:16,803 [INFO    ] __main__: train step 24482: loss: 0.8841, policy_loss: 0.7947, value_loss: 0.4046
2024-07-11 18:03:17,009 [INFO    ] __main__: train step 24483: loss: 0.8840, policy_loss: 0.7947, value_loss: 0.4046
2024-07-11 18:03:17,224 [INFO    ] __main__: train step 24484: loss: 0.8840, policy_loss: 0.7946, value_loss: 0.4046
2024-07-11 18:03:17,435 [INFO    ] __main__: train step 24485: loss: 0.8840, policy_loss: 0.7946, value_loss: 0.4045
2024-07-11 18:03:17,637 [INFO    ] __main__: train step 24486: loss: 0.8840, policy_loss: 0.7946, value_loss: 0.4045
2024-07-11 18:03:17,858 [INFO    ] __main__: train step 24487: loss: 0.8840, policy_loss: 0.7946, value_loss: 0.4045
2024-07-11 18:03:18,070 [INFO    ] __main__: train step 24488: loss: 0.8839, policy_loss: 0.7946, value_loss: 0.4045
2024-07-11 18:03:18,268 [INFO    ] __main__: train step 24489: loss: 0.8839, policy_loss: 0.7946, value_loss: 0.4045
2024-07-11 18:03:18,488 [INFO    ] __main__: train step 24490: loss: 0.8839, policy_loss: 0.7945, value_loss: 0.4045
2024-07-11 18:03:18,729 [INFO    ] __main__: train step 24491: loss: 0.8839, policy_loss: 0.7945, value_loss: 0.4045
2024-07-11 18:03:18,932 [INFO    ] __main__: train step 24492: loss: 0.8839, policy_loss: 0.7945, value_loss: 0.4044
2024-07-11 18:03:19,137 [INFO    ] __main__: train step 24493: loss: 0.8839, policy_loss: 0.7945, value_loss: 0.4044
2024-07-11 18:03:19,340 [INFO    ] __main__: train step 24494: loss: 0.8838, policy_loss: 0.7945, value_loss: 0.4044
2024-07-11 18:03:19,548 [INFO    ] __main__: train step 24495: loss: 0.8838, policy_loss: 0.7945, value_loss: 0.4044
2024-07-11 18:03:19,760 [INFO    ] __main__: train step 24496: loss: 0.8838, policy_loss: 0.7944, value_loss: 0.4044
2024-07-11 18:03:21,207 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:03:21,566 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:03:21,626 [INFO    ] __main__: train step 24497: loss: 0.8838, policy_loss: 0.7944, value_loss: 0.4044
2024-07-11 18:03:21,818 [INFO    ] __main__: train step 24498: loss: 0.8838, policy_loss: 0.7944, value_loss: 0.4044
2024-07-11 18:03:22,053 [INFO    ] __main__: train step 24499: loss: 0.8837, policy_loss: 0.7944, value_loss: 0.4043
2024-07-11 18:03:22,251 [INFO    ] __main__: train step 24500: loss: 0.8837, policy_loss: 0.7944, value_loss: 0.4043
2024-07-11 18:03:22,464 [INFO    ] __main__: train step 24501: loss: 0.8837, policy_loss: 0.7944, value_loss: 0.4043
2024-07-11 18:03:22,663 [INFO    ] __main__: train step 24502: loss: 0.8837, policy_loss: 0.7943, value_loss: 0.4043
2024-07-11 18:03:22,866 [INFO    ] __main__: train step 24503: loss: 0.8837, policy_loss: 0.7943, value_loss: 0.4043
2024-07-11 18:03:23,071 [INFO    ] __main__: train step 24504: loss: 0.8836, policy_loss: 0.7943, value_loss: 0.4043
2024-07-11 18:03:23,278 [INFO    ] __main__: train step 24505: loss: 0.8836, policy_loss: 0.7943, value_loss: 0.4042
2024-07-11 18:03:23,485 [INFO    ] __main__: train step 24506: loss: 0.8836, policy_loss: 0.7943, value_loss: 0.4042
2024-07-11 18:03:23,690 [INFO    ] __main__: train step 24507: loss: 0.8836, policy_loss: 0.7943, value_loss: 0.4042
2024-07-11 18:03:23,905 [INFO    ] __main__: train step 24508: loss: 0.8836, policy_loss: 0.7942, value_loss: 0.4042
2024-07-11 18:03:24,129 [INFO    ] __main__: train step 24509: loss: 0.8835, policy_loss: 0.7942, value_loss: 0.4042
2024-07-11 18:03:24,341 [INFO    ] __main__: train step 24510: loss: 0.8835, policy_loss: 0.7942, value_loss: 0.4042
2024-07-11 18:03:24,592 [INFO    ] __main__: train step 24511: loss: 0.8835, policy_loss: 0.7942, value_loss: 0.4042
2024-07-11 18:03:24,793 [INFO    ] __main__: train step 24512: loss: 0.8835, policy_loss: 0.7942, value_loss: 0.4041
2024-07-11 18:03:25,002 [INFO    ] __main__: train step 24513: loss: 0.8835, policy_loss: 0.7942, value_loss: 0.4041
2024-07-11 18:03:26,429 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:03:26,798 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:03:26,853 [INFO    ] __main__: train step 24514: loss: 0.8835, policy_loss: 0.7941, value_loss: 0.4041
2024-07-11 18:03:27,043 [INFO    ] __main__: train step 24515: loss: 0.8834, policy_loss: 0.7941, value_loss: 0.4041
2024-07-11 18:03:27,253 [INFO    ] __main__: train step 24516: loss: 0.8834, policy_loss: 0.7941, value_loss: 0.4041
2024-07-11 18:03:27,471 [INFO    ] __main__: train step 24517: loss: 0.8834, policy_loss: 0.7941, value_loss: 0.4041
2024-07-11 18:03:27,670 [INFO    ] __main__: train step 24518: loss: 0.8834, policy_loss: 0.7941, value_loss: 0.4040
2024-07-11 18:03:27,892 [INFO    ] __main__: train step 24519: loss: 0.8834, policy_loss: 0.7941, value_loss: 0.4040
2024-07-11 18:03:28,101 [INFO    ] __main__: train step 24520: loss: 0.8833, policy_loss: 0.7940, value_loss: 0.4040
2024-07-11 18:03:28,303 [INFO    ] __main__: train step 24521: loss: 0.8833, policy_loss: 0.7940, value_loss: 0.4040
2024-07-11 18:03:28,511 [INFO    ] __main__: train step 24522: loss: 0.8833, policy_loss: 0.7940, value_loss: 0.4040
2024-07-11 18:03:28,716 [INFO    ] __main__: train step 24523: loss: 0.8833, policy_loss: 0.7940, value_loss: 0.4040
2024-07-11 18:03:28,918 [INFO    ] __main__: train step 24524: loss: 0.8833, policy_loss: 0.7940, value_loss: 0.4040
2024-07-11 18:03:29,129 [INFO    ] __main__: train step 24525: loss: 0.8832, policy_loss: 0.7940, value_loss: 0.4039
2024-07-11 18:03:29,330 [INFO    ] __main__: train step 24526: loss: 0.8832, policy_loss: 0.7939, value_loss: 0.4039
2024-07-11 18:03:29,535 [INFO    ] __main__: train step 24527: loss: 0.8832, policy_loss: 0.7939, value_loss: 0.4039
2024-07-11 18:03:29,735 [INFO    ] __main__: train step 24528: loss: 0.8832, policy_loss: 0.7939, value_loss: 0.4039
2024-07-11 18:03:29,967 [INFO    ] __main__: train step 24529: loss: 0.8832, policy_loss: 0.7939, value_loss: 0.4039
2024-07-11 18:03:30,197 [INFO    ] __main__: train step 24530: loss: 0.8831, policy_loss: 0.7939, value_loss: 0.4039
2024-07-11 18:03:31,647 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:03:32,001 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:03:32,057 [INFO    ] __main__: train step 24531: loss: 0.8831, policy_loss: 0.7939, value_loss: 0.4039
2024-07-11 18:03:32,232 [INFO    ] __main__: train step 24532: loss: 0.8831, policy_loss: 0.7938, value_loss: 0.4038
2024-07-11 18:03:32,452 [INFO    ] __main__: train step 24533: loss: 0.8831, policy_loss: 0.7938, value_loss: 0.4038
2024-07-11 18:03:32,664 [INFO    ] __main__: train step 24534: loss: 0.8831, policy_loss: 0.7938, value_loss: 0.4038
2024-07-11 18:03:32,888 [INFO    ] __main__: train step 24535: loss: 0.8831, policy_loss: 0.7938, value_loss: 0.4038
2024-07-11 18:03:33,113 [INFO    ] __main__: train step 24536: loss: 0.8830, policy_loss: 0.7938, value_loss: 0.4038
2024-07-11 18:03:33,348 [INFO    ] __main__: train step 24537: loss: 0.8830, policy_loss: 0.7938, value_loss: 0.4038
2024-07-11 18:03:33,594 [INFO    ] __main__: train step 24538: loss: 0.8830, policy_loss: 0.7937, value_loss: 0.4037
2024-07-11 18:03:33,839 [INFO    ] __main__: train step 24539: loss: 0.8830, policy_loss: 0.7937, value_loss: 0.4037
2024-07-11 18:03:34,079 [INFO    ] __main__: train step 24540: loss: 0.8830, policy_loss: 0.7937, value_loss: 0.4037
2024-07-11 18:03:34,282 [INFO    ] __main__: train step 24541: loss: 0.8829, policy_loss: 0.7937, value_loss: 0.4037
2024-07-11 18:03:34,483 [INFO    ] __main__: train step 24542: loss: 0.8829, policy_loss: 0.7937, value_loss: 0.4037
2024-07-11 18:03:34,692 [INFO    ] __main__: train step 24543: loss: 0.8829, policy_loss: 0.7937, value_loss: 0.4037
2024-07-11 18:03:34,893 [INFO    ] __main__: train step 24544: loss: 0.8829, policy_loss: 0.7936, value_loss: 0.4037
2024-07-11 18:03:35,093 [INFO    ] __main__: train step 24545: loss: 0.8829, policy_loss: 0.7936, value_loss: 0.4036
2024-07-11 18:03:35,294 [INFO    ] __main__: train step 24546: loss: 0.8828, policy_loss: 0.7936, value_loss: 0.4036
2024-07-11 18:03:35,502 [INFO    ] __main__: train step 24547: loss: 0.8828, policy_loss: 0.7936, value_loss: 0.4036
2024-07-11 18:03:36,942 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:03:37,306 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:03:37,361 [INFO    ] __main__: train step 24548: loss: 0.8828, policy_loss: 0.7936, value_loss: 0.4036
2024-07-11 18:03:37,542 [INFO    ] __main__: train step 24549: loss: 0.8828, policy_loss: 0.7936, value_loss: 0.4036
2024-07-11 18:03:37,749 [INFO    ] __main__: train step 24550: loss: 0.8828, policy_loss: 0.7935, value_loss: 0.4036
2024-07-11 18:03:37,963 [INFO    ] __main__: train step 24551: loss: 0.8828, policy_loss: 0.7935, value_loss: 0.4035
2024-07-11 18:03:38,169 [INFO    ] __main__: train step 24552: loss: 0.8827, policy_loss: 0.7935, value_loss: 0.4035
2024-07-11 18:03:38,375 [INFO    ] __main__: train step 24553: loss: 0.8827, policy_loss: 0.7935, value_loss: 0.4035
2024-07-11 18:03:38,576 [INFO    ] __main__: train step 24554: loss: 0.8827, policy_loss: 0.7935, value_loss: 0.4035
2024-07-11 18:03:38,787 [INFO    ] __main__: train step 24555: loss: 0.8827, policy_loss: 0.7935, value_loss: 0.4035
2024-07-11 18:03:38,994 [INFO    ] __main__: train step 24556: loss: 0.8827, policy_loss: 0.7934, value_loss: 0.4035
2024-07-11 18:03:39,213 [INFO    ] __main__: train step 24557: loss: 0.8826, policy_loss: 0.7934, value_loss: 0.4035
2024-07-11 18:03:39,456 [INFO    ] __main__: train step 24558: loss: 0.8826, policy_loss: 0.7934, value_loss: 0.4034
2024-07-11 18:03:39,683 [INFO    ] __main__: train step 24559: loss: 0.8826, policy_loss: 0.7934, value_loss: 0.4034
2024-07-11 18:03:39,893 [INFO    ] __main__: train step 24560: loss: 0.8826, policy_loss: 0.7934, value_loss: 0.4034
2024-07-11 18:03:40,132 [INFO    ] __main__: train step 24561: loss: 0.8826, policy_loss: 0.7934, value_loss: 0.4034
2024-07-11 18:03:40,333 [INFO    ] __main__: train step 24562: loss: 0.8825, policy_loss: 0.7933, value_loss: 0.4034
2024-07-11 18:03:40,545 [INFO    ] __main__: train step 24563: loss: 0.8825, policy_loss: 0.7933, value_loss: 0.4034
2024-07-11 18:03:40,777 [INFO    ] __main__: train step 24564: loss: 0.8825, policy_loss: 0.7933, value_loss: 0.4034
2024-07-11 18:03:42,225 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:03:42,618 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:03:42,683 [INFO    ] __main__: train step 24565: loss: 0.8825, policy_loss: 0.7933, value_loss: 0.4033
2024-07-11 18:03:42,869 [INFO    ] __main__: train step 24566: loss: 0.8825, policy_loss: 0.7933, value_loss: 0.4033
2024-07-11 18:03:43,070 [INFO    ] __main__: train step 24567: loss: 0.8824, policy_loss: 0.7933, value_loss: 0.4033
2024-07-11 18:03:43,286 [INFO    ] __main__: train step 24568: loss: 0.8824, policy_loss: 0.7932, value_loss: 0.4033
2024-07-11 18:03:43,488 [INFO    ] __main__: train step 24569: loss: 0.8824, policy_loss: 0.7932, value_loss: 0.4033
2024-07-11 18:03:43,693 [INFO    ] __main__: train step 24570: loss: 0.8824, policy_loss: 0.7932, value_loss: 0.4033
2024-07-11 18:03:43,896 [INFO    ] __main__: train step 24571: loss: 0.8824, policy_loss: 0.7932, value_loss: 0.4032
2024-07-11 18:03:44,108 [INFO    ] __main__: train step 24572: loss: 0.8824, policy_loss: 0.7932, value_loss: 0.4032
2024-07-11 18:03:44,307 [INFO    ] __main__: train step 24573: loss: 0.8823, policy_loss: 0.7932, value_loss: 0.4032
2024-07-11 18:03:44,506 [INFO    ] __main__: train step 24574: loss: 0.8823, policy_loss: 0.7931, value_loss: 0.4032
2024-07-11 18:03:44,714 [INFO    ] __main__: train step 24575: loss: 0.8823, policy_loss: 0.7931, value_loss: 0.4032
2024-07-11 18:03:44,931 [INFO    ] __main__: train step 24576: loss: 0.8823, policy_loss: 0.7931, value_loss: 0.4032
2024-07-11 18:03:45,175 [INFO    ] __main__: train step 24577: loss: 0.8823, policy_loss: 0.7931, value_loss: 0.4032
2024-07-11 18:03:45,388 [INFO    ] __main__: train step 24578: loss: 0.8822, policy_loss: 0.7931, value_loss: 0.4031
2024-07-11 18:03:45,591 [INFO    ] __main__: train step 24579: loss: 0.8822, policy_loss: 0.7931, value_loss: 0.4031
2024-07-11 18:03:48,036 [INFO    ] __main__: train step 24580: loss: 0.8822, policy_loss: 0.7930, value_loss: 0.4031
2024-07-11 18:03:48,266 [INFO    ] __main__: train step 24581: loss: 0.8822, policy_loss: 0.7930, value_loss: 0.4031
2024-07-11 18:03:49,752 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:03:50,247 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:03:50,310 [INFO    ] __main__: train step 24582: loss: 0.8822, policy_loss: 0.7930, value_loss: 0.4031
2024-07-11 18:03:50,489 [INFO    ] __main__: train step 24583: loss: 0.8821, policy_loss: 0.7930, value_loss: 0.4031
2024-07-11 18:03:50,701 [INFO    ] __main__: train step 24584: loss: 0.8821, policy_loss: 0.7930, value_loss: 0.4031
2024-07-11 18:03:50,909 [INFO    ] __main__: train step 24585: loss: 0.8821, policy_loss: 0.7930, value_loss: 0.4030
2024-07-11 18:03:51,175 [INFO    ] __main__: train step 24586: loss: 0.8821, policy_loss: 0.7929, value_loss: 0.4030
2024-07-11 18:03:51,407 [INFO    ] __main__: train step 24587: loss: 0.8821, policy_loss: 0.7929, value_loss: 0.4030
2024-07-11 18:03:51,624 [INFO    ] __main__: train step 24588: loss: 0.8821, policy_loss: 0.7929, value_loss: 0.4030
2024-07-11 18:03:51,839 [INFO    ] __main__: train step 24589: loss: 0.8820, policy_loss: 0.7929, value_loss: 0.4030
2024-07-11 18:03:52,055 [INFO    ] __main__: train step 24590: loss: 0.8820, policy_loss: 0.7929, value_loss: 0.4030
2024-07-11 18:03:52,250 [INFO    ] __main__: train step 24591: loss: 0.8820, policy_loss: 0.7929, value_loss: 0.4029
2024-07-11 18:03:52,459 [INFO    ] __main__: train step 24592: loss: 0.8820, policy_loss: 0.7928, value_loss: 0.4029
2024-07-11 18:03:52,679 [INFO    ] __main__: train step 24593: loss: 0.8820, policy_loss: 0.7928, value_loss: 0.4029
2024-07-11 18:03:52,890 [INFO    ] __main__: train step 24594: loss: 0.8819, policy_loss: 0.7928, value_loss: 0.4029
2024-07-11 18:03:53,094 [INFO    ] __main__: train step 24595: loss: 0.8819, policy_loss: 0.7928, value_loss: 0.4029
2024-07-11 18:03:53,299 [INFO    ] __main__: train step 24596: loss: 0.8819, policy_loss: 0.7928, value_loss: 0.4029
2024-07-11 18:03:53,497 [INFO    ] __main__: train step 24597: loss: 0.8819, policy_loss: 0.7928, value_loss: 0.4029
2024-07-11 18:03:53,697 [INFO    ] __main__: train step 24598: loss: 0.8819, policy_loss: 0.7927, value_loss: 0.4028
2024-07-11 18:03:55,148 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:03:55,528 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:03:55,590 [INFO    ] __main__: train step 24599: loss: 0.8819, policy_loss: 0.7927, value_loss: 0.4028
2024-07-11 18:03:55,773 [INFO    ] __main__: train step 24600: loss: 0.8818, policy_loss: 0.7927, value_loss: 0.4028
2024-07-11 18:03:55,973 [INFO    ] __main__: train step 24601: loss: 0.8818, policy_loss: 0.7927, value_loss: 0.4028
2024-07-11 18:03:56,186 [INFO    ] __main__: train step 24602: loss: 0.8818, policy_loss: 0.7927, value_loss: 0.4028
2024-07-11 18:03:56,388 [INFO    ] __main__: train step 24603: loss: 0.8818, policy_loss: 0.7927, value_loss: 0.4028
2024-07-11 18:03:56,586 [INFO    ] __main__: train step 24604: loss: 0.8818, policy_loss: 0.7927, value_loss: 0.4028
2024-07-11 18:03:56,793 [INFO    ] __main__: train step 24605: loss: 0.8817, policy_loss: 0.7926, value_loss: 0.4027
2024-07-11 18:03:56,999 [INFO    ] __main__: train step 24606: loss: 0.8817, policy_loss: 0.7926, value_loss: 0.4027
2024-07-11 18:03:57,214 [INFO    ] __main__: train step 24607: loss: 0.8817, policy_loss: 0.7926, value_loss: 0.4027
2024-07-11 18:03:57,460 [INFO    ] __main__: train step 24608: loss: 0.8817, policy_loss: 0.7926, value_loss: 0.4027
2024-07-11 18:03:57,697 [INFO    ] __main__: train step 24609: loss: 0.8817, policy_loss: 0.7926, value_loss: 0.4027
2024-07-11 18:03:57,903 [INFO    ] __main__: train step 24610: loss: 0.8816, policy_loss: 0.7926, value_loss: 0.4027
2024-07-11 18:03:58,112 [INFO    ] __main__: train step 24611: loss: 0.8816, policy_loss: 0.7925, value_loss: 0.4026
2024-07-11 18:03:58,315 [INFO    ] __main__: train step 24612: loss: 0.8816, policy_loss: 0.7925, value_loss: 0.4026
2024-07-11 18:03:58,517 [INFO    ] __main__: train step 24613: loss: 0.8816, policy_loss: 0.7925, value_loss: 0.4026
2024-07-11 18:03:58,722 [INFO    ] __main__: train step 24614: loss: 0.8816, policy_loss: 0.7925, value_loss: 0.4026
2024-07-11 18:03:58,929 [INFO    ] __main__: train step 24615: loss: 0.8816, policy_loss: 0.7925, value_loss: 0.4026
2024-07-11 18:04:00,372 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:04:00,737 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:04:00,791 [INFO    ] __main__: train step 24616: loss: 0.8815, policy_loss: 0.7925, value_loss: 0.4026
2024-07-11 18:04:00,967 [INFO    ] __main__: train step 24617: loss: 0.8815, policy_loss: 0.7924, value_loss: 0.4026
2024-07-11 18:04:01,189 [INFO    ] __main__: train step 24618: loss: 0.8815, policy_loss: 0.7924, value_loss: 0.4025
2024-07-11 18:04:01,397 [INFO    ] __main__: train step 24619: loss: 0.8815, policy_loss: 0.7924, value_loss: 0.4025
2024-07-11 18:04:01,596 [INFO    ] __main__: train step 24620: loss: 0.8815, policy_loss: 0.7924, value_loss: 0.4025
2024-07-11 18:04:01,795 [INFO    ] __main__: train step 24621: loss: 0.8814, policy_loss: 0.7924, value_loss: 0.4025
2024-07-11 18:04:01,991 [INFO    ] __main__: train step 24622: loss: 0.8814, policy_loss: 0.7924, value_loss: 0.4025
2024-07-11 18:04:02,204 [INFO    ] __main__: train step 24623: loss: 0.8814, policy_loss: 0.7923, value_loss: 0.4025
2024-07-11 18:04:02,412 [INFO    ] __main__: train step 24624: loss: 0.8814, policy_loss: 0.7923, value_loss: 0.4025
2024-07-11 18:04:02,613 [INFO    ] __main__: train step 24625: loss: 0.8814, policy_loss: 0.7923, value_loss: 0.4024
2024-07-11 18:04:02,828 [INFO    ] __main__: train step 24626: loss: 0.8814, policy_loss: 0.7923, value_loss: 0.4024
2024-07-11 18:04:03,032 [INFO    ] __main__: train step 24627: loss: 0.8813, policy_loss: 0.7923, value_loss: 0.4024
2024-07-11 18:04:03,253 [INFO    ] __main__: train step 24628: loss: 0.8813, policy_loss: 0.7923, value_loss: 0.4024
2024-07-11 18:04:03,482 [INFO    ] __main__: train step 24629: loss: 0.8813, policy_loss: 0.7922, value_loss: 0.4024
2024-07-11 18:04:03,692 [INFO    ] __main__: train step 24630: loss: 0.8813, policy_loss: 0.7922, value_loss: 0.4024
2024-07-11 18:04:03,909 [INFO    ] __main__: train step 24631: loss: 0.8813, policy_loss: 0.7922, value_loss: 0.4023
2024-07-11 18:04:04,135 [INFO    ] __main__: train step 24632: loss: 0.8812, policy_loss: 0.7922, value_loss: 0.4023
2024-07-11 18:04:05,580 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:04:05,963 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:04:06,023 [INFO    ] __main__: train step 24633: loss: 0.8812, policy_loss: 0.7922, value_loss: 0.4023
2024-07-11 18:04:06,213 [INFO    ] __main__: train step 24634: loss: 0.8812, policy_loss: 0.7922, value_loss: 0.4023
2024-07-11 18:04:06,451 [INFO    ] __main__: train step 24635: loss: 0.8812, policy_loss: 0.7921, value_loss: 0.4023
2024-07-11 18:04:06,656 [INFO    ] __main__: train step 24636: loss: 0.8812, policy_loss: 0.7921, value_loss: 0.4023
2024-07-11 18:04:06,867 [INFO    ] __main__: train step 24637: loss: 0.8811, policy_loss: 0.7921, value_loss: 0.4023
2024-07-11 18:04:07,072 [INFO    ] __main__: train step 24638: loss: 0.8811, policy_loss: 0.7921, value_loss: 0.4022
2024-07-11 18:04:07,278 [INFO    ] __main__: train step 24639: loss: 0.8811, policy_loss: 0.7921, value_loss: 0.4022
2024-07-11 18:04:07,491 [INFO    ] __main__: train step 24640: loss: 0.8811, policy_loss: 0.7921, value_loss: 0.4022
2024-07-11 18:04:07,697 [INFO    ] __main__: train step 24641: loss: 0.8811, policy_loss: 0.7921, value_loss: 0.4022
2024-07-11 18:04:07,916 [INFO    ] __main__: train step 24642: loss: 0.8811, policy_loss: 0.7920, value_loss: 0.4022
2024-07-11 18:04:08,153 [INFO    ] __main__: train step 24643: loss: 0.8810, policy_loss: 0.7920, value_loss: 0.4022
2024-07-11 18:04:08,371 [INFO    ] __main__: train step 24644: loss: 0.8810, policy_loss: 0.7920, value_loss: 0.4022
2024-07-11 18:04:08,572 [INFO    ] __main__: train step 24645: loss: 0.8810, policy_loss: 0.7920, value_loss: 0.4021
2024-07-11 18:04:08,781 [INFO    ] __main__: train step 24646: loss: 0.8810, policy_loss: 0.7920, value_loss: 0.4021
2024-07-11 18:04:08,997 [INFO    ] __main__: train step 24647: loss: 0.8810, policy_loss: 0.7920, value_loss: 0.4021
2024-07-11 18:04:09,235 [INFO    ] __main__: train step 24648: loss: 0.8809, policy_loss: 0.7919, value_loss: 0.4021
2024-07-11 18:04:09,461 [INFO    ] __main__: train step 24649: loss: 0.8809, policy_loss: 0.7919, value_loss: 0.4021
2024-07-11 18:04:10,935 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:04:11,301 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:04:11,361 [INFO    ] __main__: train step 24650: loss: 0.8809, policy_loss: 0.7919, value_loss: 0.4021
2024-07-11 18:04:11,538 [INFO    ] __main__: train step 24651: loss: 0.8809, policy_loss: 0.7919, value_loss: 0.4020
2024-07-11 18:04:11,744 [INFO    ] __main__: train step 24652: loss: 0.8809, policy_loss: 0.7919, value_loss: 0.4020
2024-07-11 18:04:11,950 [INFO    ] __main__: train step 24653: loss: 0.8809, policy_loss: 0.7919, value_loss: 0.4020
2024-07-11 18:04:12,163 [INFO    ] __main__: train step 24654: loss: 0.8808, policy_loss: 0.7918, value_loss: 0.4020
2024-07-11 18:04:12,398 [INFO    ] __main__: train step 24655: loss: 0.8808, policy_loss: 0.7918, value_loss: 0.4020
2024-07-11 18:04:12,600 [INFO    ] __main__: train step 24656: loss: 0.8808, policy_loss: 0.7918, value_loss: 0.4020
2024-07-11 18:04:12,820 [INFO    ] __main__: train step 24657: loss: 0.8808, policy_loss: 0.7918, value_loss: 0.4020
2024-07-11 18:04:13,060 [INFO    ] __main__: train step 24658: loss: 0.8808, policy_loss: 0.7918, value_loss: 0.4019
2024-07-11 18:04:13,298 [INFO    ] __main__: train step 24659: loss: 0.8807, policy_loss: 0.7918, value_loss: 0.4019
2024-07-11 18:04:13,504 [INFO    ] __main__: train step 24660: loss: 0.8807, policy_loss: 0.7917, value_loss: 0.4019
2024-07-11 18:04:13,703 [INFO    ] __main__: train step 24661: loss: 0.8807, policy_loss: 0.7917, value_loss: 0.4019
2024-07-11 18:04:13,917 [INFO    ] __main__: train step 24662: loss: 0.8807, policy_loss: 0.7917, value_loss: 0.4019
2024-07-11 18:04:14,151 [INFO    ] __main__: train step 24663: loss: 0.8807, policy_loss: 0.7917, value_loss: 0.4019
2024-07-11 18:04:14,384 [INFO    ] __main__: train step 24664: loss: 0.8807, policy_loss: 0.7917, value_loss: 0.4019
2024-07-11 18:04:14,612 [INFO    ] __main__: train step 24665: loss: 0.8806, policy_loss: 0.7917, value_loss: 0.4018
2024-07-11 18:04:14,817 [INFO    ] __main__: train step 24666: loss: 0.8806, policy_loss: 0.7916, value_loss: 0.4018
2024-07-11 18:04:16,281 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:04:16,618 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:04:16,682 [INFO    ] __main__: train step 24667: loss: 0.8806, policy_loss: 0.7916, value_loss: 0.4018
2024-07-11 18:04:16,873 [INFO    ] __main__: train step 24668: loss: 0.8806, policy_loss: 0.7916, value_loss: 0.4018
2024-07-11 18:04:17,103 [INFO    ] __main__: train step 24669: loss: 0.8806, policy_loss: 0.7916, value_loss: 0.4018
2024-07-11 18:04:17,301 [INFO    ] __main__: train step 24670: loss: 0.8805, policy_loss: 0.7916, value_loss: 0.4018
2024-07-11 18:04:17,511 [INFO    ] __main__: train step 24671: loss: 0.8805, policy_loss: 0.7916, value_loss: 0.4017
2024-07-11 18:04:17,709 [INFO    ] __main__: train step 24672: loss: 0.8805, policy_loss: 0.7915, value_loss: 0.4017
2024-07-11 18:04:17,935 [INFO    ] __main__: train step 24673: loss: 0.8805, policy_loss: 0.7915, value_loss: 0.4017
2024-07-11 18:04:18,150 [INFO    ] __main__: train step 24674: loss: 0.8805, policy_loss: 0.7915, value_loss: 0.4017
2024-07-11 18:04:18,379 [INFO    ] __main__: train step 24675: loss: 0.8804, policy_loss: 0.7915, value_loss: 0.4017
2024-07-11 18:04:18,593 [INFO    ] __main__: train step 24676: loss: 0.8804, policy_loss: 0.7915, value_loss: 0.4017
2024-07-11 18:04:18,802 [INFO    ] __main__: train step 24677: loss: 0.8804, policy_loss: 0.7915, value_loss: 0.4017
2024-07-11 18:04:19,004 [INFO    ] __main__: train step 24678: loss: 0.8804, policy_loss: 0.7915, value_loss: 0.4016
2024-07-11 18:04:19,206 [INFO    ] __main__: train step 24679: loss: 0.8804, policy_loss: 0.7914, value_loss: 0.4016
2024-07-11 18:04:19,414 [INFO    ] __main__: train step 24680: loss: 0.8804, policy_loss: 0.7914, value_loss: 0.4016
2024-07-11 18:04:19,622 [INFO    ] __main__: train step 24681: loss: 0.8803, policy_loss: 0.7914, value_loss: 0.4016
2024-07-11 18:04:19,824 [INFO    ] __main__: train step 24682: loss: 0.8803, policy_loss: 0.7914, value_loss: 0.4016
2024-07-11 18:04:20,025 [INFO    ] __main__: train step 24683: loss: 0.8803, policy_loss: 0.7914, value_loss: 0.4016
2024-07-11 18:04:21,483 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:04:21,726 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:04:21,781 [INFO    ] __main__: train step 24684: loss: 0.8803, policy_loss: 0.7914, value_loss: 0.4016
2024-07-11 18:04:21,957 [INFO    ] __main__: train step 24685: loss: 0.8803, policy_loss: 0.7913, value_loss: 0.4015
2024-07-11 18:04:22,174 [INFO    ] __main__: train step 24686: loss: 0.8802, policy_loss: 0.7913, value_loss: 0.4015
2024-07-11 18:04:22,371 [INFO    ] __main__: train step 24687: loss: 0.8802, policy_loss: 0.7913, value_loss: 0.4015
2024-07-11 18:04:22,575 [INFO    ] __main__: train step 24688: loss: 0.8802, policy_loss: 0.7913, value_loss: 0.4015
2024-07-11 18:04:22,787 [INFO    ] __main__: train step 24689: loss: 0.8802, policy_loss: 0.7913, value_loss: 0.4015
2024-07-11 18:04:22,995 [INFO    ] __main__: train step 24690: loss: 0.8802, policy_loss: 0.7913, value_loss: 0.4015
2024-07-11 18:04:23,214 [INFO    ] __main__: train step 24691: loss: 0.8802, policy_loss: 0.7912, value_loss: 0.4014
2024-07-11 18:04:23,464 [INFO    ] __main__: train step 24692: loss: 0.8801, policy_loss: 0.7912, value_loss: 0.4014
2024-07-11 18:04:23,709 [INFO    ] __main__: train step 24693: loss: 0.8801, policy_loss: 0.7912, value_loss: 0.4014
2024-07-11 18:04:23,948 [INFO    ] __main__: train step 24694: loss: 0.8801, policy_loss: 0.7912, value_loss: 0.4014
2024-07-11 18:04:24,190 [INFO    ] __main__: train step 24695: loss: 0.8801, policy_loss: 0.7912, value_loss: 0.4014
2024-07-11 18:04:24,421 [INFO    ] __main__: train step 24696: loss: 0.8801, policy_loss: 0.7912, value_loss: 0.4014
2024-07-11 18:04:24,626 [INFO    ] __main__: train step 24697: loss: 0.8800, policy_loss: 0.7911, value_loss: 0.4014
2024-07-11 18:04:24,867 [INFO    ] __main__: train step 24698: loss: 0.8800, policy_loss: 0.7911, value_loss: 0.4013
2024-07-11 18:04:25,099 [INFO    ] __main__: train step 24699: loss: 0.8800, policy_loss: 0.7911, value_loss: 0.4013
2024-07-11 18:04:25,301 [INFO    ] __main__: train step 24700: loss: 0.8800, policy_loss: 0.7911, value_loss: 0.4013
2024-07-11 18:04:26,750 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:04:27,120 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:04:27,183 [INFO    ] __main__: train step 24701: loss: 0.8800, policy_loss: 0.7911, value_loss: 0.4013
2024-07-11 18:04:27,364 [INFO    ] __main__: train step 24702: loss: 0.8800, policy_loss: 0.7911, value_loss: 0.4013
2024-07-11 18:04:27,594 [INFO    ] __main__: train step 24703: loss: 0.8799, policy_loss: 0.7911, value_loss: 0.4013
2024-07-11 18:04:27,815 [INFO    ] __main__: train step 24704: loss: 0.8799, policy_loss: 0.7910, value_loss: 0.4013
2024-07-11 18:04:28,015 [INFO    ] __main__: train step 24705: loss: 0.8799, policy_loss: 0.7910, value_loss: 0.4012
2024-07-11 18:04:28,225 [INFO    ] __main__: train step 24706: loss: 0.8799, policy_loss: 0.7910, value_loss: 0.4012
2024-07-11 18:04:28,428 [INFO    ] __main__: train step 24707: loss: 0.8799, policy_loss: 0.7910, value_loss: 0.4012
2024-07-11 18:04:28,635 [INFO    ] __main__: train step 24708: loss: 0.8798, policy_loss: 0.7910, value_loss: 0.4012
2024-07-11 18:04:28,846 [INFO    ] __main__: train step 24709: loss: 0.8798, policy_loss: 0.7910, value_loss: 0.4012
2024-07-11 18:04:29,061 [INFO    ] __main__: train step 24710: loss: 0.8798, policy_loss: 0.7909, value_loss: 0.4012
2024-07-11 18:04:29,262 [INFO    ] __main__: train step 24711: loss: 0.8798, policy_loss: 0.7909, value_loss: 0.4011
2024-07-11 18:04:29,466 [INFO    ] __main__: train step 24712: loss: 0.8798, policy_loss: 0.7909, value_loss: 0.4011
2024-07-11 18:04:29,664 [INFO    ] __main__: train step 24713: loss: 0.8798, policy_loss: 0.7909, value_loss: 0.4011
2024-07-11 18:04:29,874 [INFO    ] __main__: train step 24714: loss: 0.8797, policy_loss: 0.7909, value_loss: 0.4011
2024-07-11 18:04:30,077 [INFO    ] __main__: train step 24715: loss: 0.8797, policy_loss: 0.7909, value_loss: 0.4011
2024-07-11 18:04:32,555 [INFO    ] __main__: train step 24716: loss: 0.8797, policy_loss: 0.7908, value_loss: 0.4011
2024-07-11 18:04:32,768 [INFO    ] __main__: train step 24717: loss: 0.8797, policy_loss: 0.7908, value_loss: 0.4011
2024-07-11 18:04:34,207 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:04:34,594 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:04:34,651 [INFO    ] __main__: train step 24718: loss: 0.8797, policy_loss: 0.7908, value_loss: 0.4010
2024-07-11 18:04:34,829 [INFO    ] __main__: train step 24719: loss: 0.8796, policy_loss: 0.7908, value_loss: 0.4010
2024-07-11 18:04:35,048 [INFO    ] __main__: train step 24720: loss: 0.8796, policy_loss: 0.7908, value_loss: 0.4010
2024-07-11 18:04:35,255 [INFO    ] __main__: train step 24721: loss: 0.8796, policy_loss: 0.7908, value_loss: 0.4010
2024-07-11 18:04:35,453 [INFO    ] __main__: train step 24722: loss: 0.8796, policy_loss: 0.7908, value_loss: 0.4010
2024-07-11 18:04:35,660 [INFO    ] __main__: train step 24723: loss: 0.8796, policy_loss: 0.7907, value_loss: 0.4010
2024-07-11 18:04:35,873 [INFO    ] __main__: train step 24724: loss: 0.8796, policy_loss: 0.7907, value_loss: 0.4010
2024-07-11 18:04:36,082 [INFO    ] __main__: train step 24725: loss: 0.8795, policy_loss: 0.7907, value_loss: 0.4009
2024-07-11 18:04:36,300 [INFO    ] __main__: train step 24726: loss: 0.8795, policy_loss: 0.7907, value_loss: 0.4009
2024-07-11 18:04:36,549 [INFO    ] __main__: train step 24727: loss: 0.8795, policy_loss: 0.7907, value_loss: 0.4009
2024-07-11 18:04:36,757 [INFO    ] __main__: train step 24728: loss: 0.8795, policy_loss: 0.7907, value_loss: 0.4009
2024-07-11 18:04:36,977 [INFO    ] __main__: train step 24729: loss: 0.8795, policy_loss: 0.7906, value_loss: 0.4009
2024-07-11 18:04:37,209 [INFO    ] __main__: train step 24730: loss: 0.8794, policy_loss: 0.7906, value_loss: 0.4009
2024-07-11 18:04:37,419 [INFO    ] __main__: train step 24731: loss: 0.8794, policy_loss: 0.7906, value_loss: 0.4009
2024-07-11 18:04:37,624 [INFO    ] __main__: train step 24732: loss: 0.8794, policy_loss: 0.7906, value_loss: 0.4008
2024-07-11 18:04:37,831 [INFO    ] __main__: train step 24733: loss: 0.8794, policy_loss: 0.7906, value_loss: 0.4008
2024-07-11 18:04:38,029 [INFO    ] __main__: train step 24734: loss: 0.8794, policy_loss: 0.7906, value_loss: 0.4008
2024-07-11 18:04:39,472 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:04:39,825 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:04:39,885 [INFO    ] __main__: train step 24735: loss: 0.8794, policy_loss: 0.7905, value_loss: 0.4008
2024-07-11 18:04:40,061 [INFO    ] __main__: train step 24736: loss: 0.8793, policy_loss: 0.7905, value_loss: 0.4008
2024-07-11 18:04:40,269 [INFO    ] __main__: train step 24737: loss: 0.8793, policy_loss: 0.7905, value_loss: 0.4008
2024-07-11 18:04:40,486 [INFO    ] __main__: train step 24738: loss: 0.8793, policy_loss: 0.7905, value_loss: 0.4007
2024-07-11 18:04:40,690 [INFO    ] __main__: train step 24739: loss: 0.8793, policy_loss: 0.7905, value_loss: 0.4007
2024-07-11 18:04:40,916 [INFO    ] __main__: train step 24740: loss: 0.8793, policy_loss: 0.7905, value_loss: 0.4007
2024-07-11 18:04:41,115 [INFO    ] __main__: train step 24741: loss: 0.8792, policy_loss: 0.7905, value_loss: 0.4007
2024-07-11 18:04:41,321 [INFO    ] __main__: train step 24742: loss: 0.8792, policy_loss: 0.7904, value_loss: 0.4007
2024-07-11 18:04:41,519 [INFO    ] __main__: train step 24743: loss: 0.8792, policy_loss: 0.7904, value_loss: 0.4007
2024-07-11 18:04:41,730 [INFO    ] __main__: train step 24744: loss: 0.8792, policy_loss: 0.7904, value_loss: 0.4007
2024-07-11 18:04:41,941 [INFO    ] __main__: train step 24745: loss: 0.8792, policy_loss: 0.7904, value_loss: 0.4006
2024-07-11 18:04:42,151 [INFO    ] __main__: train step 24746: loss: 0.8792, policy_loss: 0.7904, value_loss: 0.4006
2024-07-11 18:04:42,367 [INFO    ] __main__: train step 24747: loss: 0.8791, policy_loss: 0.7904, value_loss: 0.4006
2024-07-11 18:04:42,605 [INFO    ] __main__: train step 24748: loss: 0.8791, policy_loss: 0.7903, value_loss: 0.4006
2024-07-11 18:04:42,803 [INFO    ] __main__: train step 24749: loss: 0.8791, policy_loss: 0.7903, value_loss: 0.4006
2024-07-11 18:04:43,015 [INFO    ] __main__: train step 24750: loss: 0.8791, policy_loss: 0.7903, value_loss: 0.4006
2024-07-11 18:04:43,219 [INFO    ] __main__: train step 24751: loss: 0.8791, policy_loss: 0.7903, value_loss: 0.4006
2024-07-11 18:04:44,675 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:04:45,033 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:04:45,091 [INFO    ] __main__: train step 24752: loss: 0.8791, policy_loss: 0.7903, value_loss: 0.4005
2024-07-11 18:04:45,274 [INFO    ] __main__: train step 24753: loss: 0.8790, policy_loss: 0.7903, value_loss: 0.4005
2024-07-11 18:04:45,482 [INFO    ] __main__: train step 24754: loss: 0.8790, policy_loss: 0.7902, value_loss: 0.4005
2024-07-11 18:04:45,715 [INFO    ] __main__: train step 24755: loss: 0.8790, policy_loss: 0.7902, value_loss: 0.4005
2024-07-11 18:04:45,926 [INFO    ] __main__: train step 24756: loss: 0.8790, policy_loss: 0.7902, value_loss: 0.4005
2024-07-11 18:04:46,125 [INFO    ] __main__: train step 24757: loss: 0.8790, policy_loss: 0.7902, value_loss: 0.4005
2024-07-11 18:04:46,337 [INFO    ] __main__: train step 24758: loss: 0.8789, policy_loss: 0.7902, value_loss: 0.4005
2024-07-11 18:04:46,547 [INFO    ] __main__: train step 24759: loss: 0.8789, policy_loss: 0.7902, value_loss: 0.4004
2024-07-11 18:04:46,754 [INFO    ] __main__: train step 24760: loss: 0.8789, policy_loss: 0.7902, value_loss: 0.4004
2024-07-11 18:04:46,971 [INFO    ] __main__: train step 24761: loss: 0.8789, policy_loss: 0.7901, value_loss: 0.4004
2024-07-11 18:04:47,174 [INFO    ] __main__: train step 24762: loss: 0.8789, policy_loss: 0.7901, value_loss: 0.4004
2024-07-11 18:04:47,383 [INFO    ] __main__: train step 24763: loss: 0.8789, policy_loss: 0.7901, value_loss: 0.4004
2024-07-11 18:04:47,584 [INFO    ] __main__: train step 24764: loss: 0.8788, policy_loss: 0.7901, value_loss: 0.4004
2024-07-11 18:04:47,790 [INFO    ] __main__: train step 24765: loss: 0.8788, policy_loss: 0.7901, value_loss: 0.4003
2024-07-11 18:04:48,003 [INFO    ] __main__: train step 24766: loss: 0.8788, policy_loss: 0.7901, value_loss: 0.4003
2024-07-11 18:04:48,233 [INFO    ] __main__: train step 24767: loss: 0.8788, policy_loss: 0.7900, value_loss: 0.4003
2024-07-11 18:04:48,470 [INFO    ] __main__: train step 24768: loss: 0.8788, policy_loss: 0.7900, value_loss: 0.4003
2024-07-11 18:04:49,952 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:04:50,301 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:04:50,356 [INFO    ] __main__: train step 24769: loss: 0.8787, policy_loss: 0.7900, value_loss: 0.4003
2024-07-11 18:04:50,535 [INFO    ] __main__: train step 24770: loss: 0.8787, policy_loss: 0.7900, value_loss: 0.4003
2024-07-11 18:04:50,745 [INFO    ] __main__: train step 24771: loss: 0.8787, policy_loss: 0.7900, value_loss: 0.4003
2024-07-11 18:04:50,955 [INFO    ] __main__: train step 24772: loss: 0.8787, policy_loss: 0.7900, value_loss: 0.4002
2024-07-11 18:04:51,166 [INFO    ] __main__: train step 24773: loss: 0.8787, policy_loss: 0.7899, value_loss: 0.4002
2024-07-11 18:04:51,379 [INFO    ] __main__: train step 24774: loss: 0.8787, policy_loss: 0.7899, value_loss: 0.4002
2024-07-11 18:04:51,585 [INFO    ] __main__: train step 24775: loss: 0.8786, policy_loss: 0.7899, value_loss: 0.4002
2024-07-11 18:04:51,841 [INFO    ] __main__: train step 24776: loss: 0.8786, policy_loss: 0.7899, value_loss: 0.4002
2024-07-11 18:04:52,091 [INFO    ] __main__: train step 24777: loss: 0.8786, policy_loss: 0.7899, value_loss: 0.4002
2024-07-11 18:04:52,298 [INFO    ] __main__: train step 24778: loss: 0.8786, policy_loss: 0.7899, value_loss: 0.4002
2024-07-11 18:04:52,508 [INFO    ] __main__: train step 24779: loss: 0.8786, policy_loss: 0.7899, value_loss: 0.4001
2024-07-11 18:04:52,714 [INFO    ] __main__: train step 24780: loss: 0.8785, policy_loss: 0.7898, value_loss: 0.4001
2024-07-11 18:04:52,919 [INFO    ] __main__: train step 24781: loss: 0.8785, policy_loss: 0.7898, value_loss: 0.4001
2024-07-11 18:04:53,125 [INFO    ] __main__: train step 24782: loss: 0.8785, policy_loss: 0.7898, value_loss: 0.4001
2024-07-11 18:04:53,337 [INFO    ] __main__: train step 24783: loss: 0.8785, policy_loss: 0.7898, value_loss: 0.4001
2024-07-11 18:04:53,536 [INFO    ] __main__: train step 24784: loss: 0.8785, policy_loss: 0.7898, value_loss: 0.4001
2024-07-11 18:04:53,754 [INFO    ] __main__: train step 24785: loss: 0.8785, policy_loss: 0.7898, value_loss: 0.4000
2024-07-11 18:04:55,195 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:04:55,545 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:04:55,601 [INFO    ] __main__: train step 24786: loss: 0.8784, policy_loss: 0.7897, value_loss: 0.4000
2024-07-11 18:04:55,782 [INFO    ] __main__: train step 24787: loss: 0.8784, policy_loss: 0.7897, value_loss: 0.4000
2024-07-11 18:04:55,990 [INFO    ] __main__: train step 24788: loss: 0.8784, policy_loss: 0.7897, value_loss: 0.4000
2024-07-11 18:04:56,190 [INFO    ] __main__: train step 24789: loss: 0.8784, policy_loss: 0.7897, value_loss: 0.4000
2024-07-11 18:04:56,399 [INFO    ] __main__: train step 24790: loss: 0.8784, policy_loss: 0.7897, value_loss: 0.4000
2024-07-11 18:04:56,600 [INFO    ] __main__: train step 24791: loss: 0.8784, policy_loss: 0.7897, value_loss: 0.4000
2024-07-11 18:04:56,797 [INFO    ] __main__: train step 24792: loss: 0.8783, policy_loss: 0.7897, value_loss: 0.3999
2024-07-11 18:04:56,996 [INFO    ] __main__: train step 24793: loss: 0.8783, policy_loss: 0.7896, value_loss: 0.3999
2024-07-11 18:04:57,225 [INFO    ] __main__: train step 24794: loss: 0.8783, policy_loss: 0.7896, value_loss: 0.3999
2024-07-11 18:04:57,456 [INFO    ] __main__: train step 24795: loss: 0.8783, policy_loss: 0.7896, value_loss: 0.3999
2024-07-11 18:04:57,655 [INFO    ] __main__: train step 24796: loss: 0.8783, policy_loss: 0.7896, value_loss: 0.3999
2024-07-11 18:04:57,865 [INFO    ] __main__: train step 24797: loss: 0.8782, policy_loss: 0.7896, value_loss: 0.3999
2024-07-11 18:04:58,063 [INFO    ] __main__: train step 24798: loss: 0.8782, policy_loss: 0.7896, value_loss: 0.3999
2024-07-11 18:04:58,266 [INFO    ] __main__: train step 24799: loss: 0.8782, policy_loss: 0.7895, value_loss: 0.3998
2024-07-11 18:04:58,476 [INFO    ] __main__: train step 24800: loss: 0.8782, policy_loss: 0.7895, value_loss: 0.3998
2024-07-11 18:04:58,712 [INFO    ] __main__: train step 24801: loss: 0.8782, policy_loss: 0.7895, value_loss: 0.3998
2024-07-11 18:04:58,915 [INFO    ] __main__: train step 24802: loss: 0.8782, policy_loss: 0.7895, value_loss: 0.3998
2024-07-11 18:05:00,347 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:05:00,714 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:05:00,771 [INFO    ] __main__: train step 24803: loss: 0.8781, policy_loss: 0.7895, value_loss: 0.3998
2024-07-11 18:05:00,955 [INFO    ] __main__: train step 24804: loss: 0.8781, policy_loss: 0.7895, value_loss: 0.3998
2024-07-11 18:05:01,165 [INFO    ] __main__: train step 24805: loss: 0.8781, policy_loss: 0.7894, value_loss: 0.3998
2024-07-11 18:05:01,371 [INFO    ] __main__: train step 24806: loss: 0.8781, policy_loss: 0.7894, value_loss: 0.3997
2024-07-11 18:05:01,573 [INFO    ] __main__: train step 24807: loss: 0.8781, policy_loss: 0.7894, value_loss: 0.3997
2024-07-11 18:05:01,781 [INFO    ] __main__: train step 24808: loss: 0.8780, policy_loss: 0.7894, value_loss: 0.3997
2024-07-11 18:05:01,995 [INFO    ] __main__: train step 24809: loss: 0.8780, policy_loss: 0.7894, value_loss: 0.3997
2024-07-11 18:05:02,227 [INFO    ] __main__: train step 24810: loss: 0.8780, policy_loss: 0.7894, value_loss: 0.3997
2024-07-11 18:05:02,440 [INFO    ] __main__: train step 24811: loss: 0.8780, policy_loss: 0.7894, value_loss: 0.3997
2024-07-11 18:05:02,640 [INFO    ] __main__: train step 24812: loss: 0.8780, policy_loss: 0.7893, value_loss: 0.3997
2024-07-11 18:05:02,849 [INFO    ] __main__: train step 24813: loss: 0.8780, policy_loss: 0.7893, value_loss: 0.3996
2024-07-11 18:05:03,066 [INFO    ] __main__: train step 24814: loss: 0.8779, policy_loss: 0.7893, value_loss: 0.3996
2024-07-11 18:05:03,323 [INFO    ] __main__: train step 24815: loss: 0.8779, policy_loss: 0.7893, value_loss: 0.3996
2024-07-11 18:05:03,553 [INFO    ] __main__: train step 24816: loss: 0.8779, policy_loss: 0.7893, value_loss: 0.3996
2024-07-11 18:05:03,761 [INFO    ] __main__: train step 24817: loss: 0.8779, policy_loss: 0.7893, value_loss: 0.3996
2024-07-11 18:05:03,967 [INFO    ] __main__: train step 24818: loss: 0.8779, policy_loss: 0.7893, value_loss: 0.3996
2024-07-11 18:05:04,205 [INFO    ] __main__: train step 24819: loss: 0.8779, policy_loss: 0.7892, value_loss: 0.3995
2024-07-11 18:05:05,651 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:05:06,052 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:05:06,107 [INFO    ] __main__: train step 24820: loss: 0.8778, policy_loss: 0.7892, value_loss: 0.3995
2024-07-11 18:05:06,305 [INFO    ] __main__: train step 24821: loss: 0.8778, policy_loss: 0.7892, value_loss: 0.3995
2024-07-11 18:05:06,545 [INFO    ] __main__: train step 24822: loss: 0.8778, policy_loss: 0.7892, value_loss: 0.3995
2024-07-11 18:05:06,756 [INFO    ] __main__: train step 24823: loss: 0.8778, policy_loss: 0.7892, value_loss: 0.3995
2024-07-11 18:05:06,964 [INFO    ] __main__: train step 24824: loss: 0.8778, policy_loss: 0.7892, value_loss: 0.3995
2024-07-11 18:05:07,160 [INFO    ] __main__: train step 24825: loss: 0.8778, policy_loss: 0.7891, value_loss: 0.3995
2024-07-11 18:05:07,373 [INFO    ] __main__: train step 24826: loss: 0.8777, policy_loss: 0.7891, value_loss: 0.3994
2024-07-11 18:05:07,575 [INFO    ] __main__: train step 24827: loss: 0.8777, policy_loss: 0.7891, value_loss: 0.3994
2024-07-11 18:05:07,780 [INFO    ] __main__: train step 24828: loss: 0.8777, policy_loss: 0.7891, value_loss: 0.3994
2024-07-11 18:05:07,982 [INFO    ] __main__: train step 24829: loss: 0.8777, policy_loss: 0.7891, value_loss: 0.3994
2024-07-11 18:05:08,187 [INFO    ] __main__: train step 24830: loss: 0.8777, policy_loss: 0.7891, value_loss: 0.3994
2024-07-11 18:05:08,391 [INFO    ] __main__: train step 24831: loss: 0.8776, policy_loss: 0.7891, value_loss: 0.3994
2024-07-11 18:05:08,596 [INFO    ] __main__: train step 24832: loss: 0.8776, policy_loss: 0.7890, value_loss: 0.3994
2024-07-11 18:05:08,795 [INFO    ] __main__: train step 24833: loss: 0.8776, policy_loss: 0.7890, value_loss: 0.3993
2024-07-11 18:05:09,021 [INFO    ] __main__: train step 24834: loss: 0.8776, policy_loss: 0.7890, value_loss: 0.3993
2024-07-11 18:05:09,254 [INFO    ] __main__: train step 24835: loss: 0.8776, policy_loss: 0.7890, value_loss: 0.3993
2024-07-11 18:05:09,502 [INFO    ] __main__: train step 24836: loss: 0.8776, policy_loss: 0.7890, value_loss: 0.3993
2024-07-11 18:05:10,966 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:05:11,356 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:05:11,414 [INFO    ] __main__: train step 24837: loss: 0.8775, policy_loss: 0.7890, value_loss: 0.3993
2024-07-11 18:05:11,600 [INFO    ] __main__: train step 24838: loss: 0.8775, policy_loss: 0.7889, value_loss: 0.3993
2024-07-11 18:05:11,821 [INFO    ] __main__: train step 24839: loss: 0.8775, policy_loss: 0.7889, value_loss: 0.3993
2024-07-11 18:05:12,046 [INFO    ] __main__: train step 24840: loss: 0.8775, policy_loss: 0.7889, value_loss: 0.3992
2024-07-11 18:05:12,297 [INFO    ] __main__: train step 24841: loss: 0.8775, policy_loss: 0.7889, value_loss: 0.3992
2024-07-11 18:05:12,514 [INFO    ] __main__: train step 24842: loss: 0.8775, policy_loss: 0.7889, value_loss: 0.3992
2024-07-11 18:05:12,757 [INFO    ] __main__: train step 24843: loss: 0.8774, policy_loss: 0.7889, value_loss: 0.3992
2024-07-11 18:05:12,968 [INFO    ] __main__: train step 24844: loss: 0.8774, policy_loss: 0.7889, value_loss: 0.3992
2024-07-11 18:05:13,175 [INFO    ] __main__: train step 24845: loss: 0.8774, policy_loss: 0.7888, value_loss: 0.3992
2024-07-11 18:05:13,382 [INFO    ] __main__: train step 24846: loss: 0.8774, policy_loss: 0.7888, value_loss: 0.3992
2024-07-11 18:05:13,591 [INFO    ] __main__: train step 24847: loss: 0.8774, policy_loss: 0.7888, value_loss: 0.3991
2024-07-11 18:05:13,793 [INFO    ] __main__: train step 24848: loss: 0.8773, policy_loss: 0.7888, value_loss: 0.3991
2024-07-11 18:05:14,007 [INFO    ] __main__: train step 24849: loss: 0.8773, policy_loss: 0.7888, value_loss: 0.3991
2024-07-11 18:05:14,216 [INFO    ] __main__: train step 24850: loss: 0.8773, policy_loss: 0.7888, value_loss: 0.3991
2024-07-11 18:05:14,448 [INFO    ] __main__: train step 24851: loss: 0.8773, policy_loss: 0.7887, value_loss: 0.3991
2024-07-11 18:05:14,662 [INFO    ] __main__: train step 24852: loss: 0.8773, policy_loss: 0.7887, value_loss: 0.3991
2024-07-11 18:05:14,890 [INFO    ] __main__: train step 24853: loss: 0.8773, policy_loss: 0.7887, value_loss: 0.3990
2024-07-11 18:05:18,644 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:05:19,167 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:05:19,228 [INFO    ] __main__: train step 24854: loss: 0.8772, policy_loss: 0.7887, value_loss: 0.3990
2024-07-11 18:05:19,416 [INFO    ] __main__: train step 24855: loss: 0.8772, policy_loss: 0.7887, value_loss: 0.3990
2024-07-11 18:05:19,639 [INFO    ] __main__: train step 24856: loss: 0.8772, policy_loss: 0.7887, value_loss: 0.3990
2024-07-11 18:05:19,847 [INFO    ] __main__: train step 24857: loss: 0.8772, policy_loss: 0.7887, value_loss: 0.3990
2024-07-11 18:05:20,068 [INFO    ] __main__: train step 24858: loss: 0.8772, policy_loss: 0.7886, value_loss: 0.3990
2024-07-11 18:05:20,311 [INFO    ] __main__: train step 24859: loss: 0.8772, policy_loss: 0.7886, value_loss: 0.3990
2024-07-11 18:05:20,531 [INFO    ] __main__: train step 24860: loss: 0.8771, policy_loss: 0.7886, value_loss: 0.3989
2024-07-11 18:05:20,735 [INFO    ] __main__: train step 24861: loss: 0.8771, policy_loss: 0.7886, value_loss: 0.3989
2024-07-11 18:05:20,961 [INFO    ] __main__: train step 24862: loss: 0.8771, policy_loss: 0.7886, value_loss: 0.3989
2024-07-11 18:05:21,203 [INFO    ] __main__: train step 24863: loss: 0.8771, policy_loss: 0.7886, value_loss: 0.3989
2024-07-11 18:05:21,405 [INFO    ] __main__: train step 24864: loss: 0.8771, policy_loss: 0.7885, value_loss: 0.3989
2024-07-11 18:05:21,621 [INFO    ] __main__: train step 24865: loss: 0.8771, policy_loss: 0.7885, value_loss: 0.3989
2024-07-11 18:05:21,825 [INFO    ] __main__: train step 24866: loss: 0.8770, policy_loss: 0.7885, value_loss: 0.3989
2024-07-11 18:05:22,027 [INFO    ] __main__: train step 24867: loss: 0.8770, policy_loss: 0.7885, value_loss: 0.3988
2024-07-11 18:05:22,237 [INFO    ] __main__: train step 24868: loss: 0.8770, policy_loss: 0.7885, value_loss: 0.3988
2024-07-11 18:05:22,469 [INFO    ] __main__: train step 24869: loss: 0.8770, policy_loss: 0.7885, value_loss: 0.3988
2024-07-11 18:05:22,674 [INFO    ] __main__: train step 24870: loss: 0.8770, policy_loss: 0.7885, value_loss: 0.3988
2024-07-11 18:05:24,126 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:05:24,510 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:05:24,566 [INFO    ] __main__: train step 24871: loss: 0.8769, policy_loss: 0.7884, value_loss: 0.3988
2024-07-11 18:05:24,743 [INFO    ] __main__: train step 24872: loss: 0.8769, policy_loss: 0.7884, value_loss: 0.3988
2024-07-11 18:05:24,952 [INFO    ] __main__: train step 24873: loss: 0.8769, policy_loss: 0.7884, value_loss: 0.3988
2024-07-11 18:05:25,156 [INFO    ] __main__: train step 24874: loss: 0.8769, policy_loss: 0.7884, value_loss: 0.3987
2024-07-11 18:05:25,369 [INFO    ] __main__: train step 24875: loss: 0.8769, policy_loss: 0.7884, value_loss: 0.3987
2024-07-11 18:05:25,574 [INFO    ] __main__: train step 24876: loss: 0.8769, policy_loss: 0.7884, value_loss: 0.3987
2024-07-11 18:05:25,780 [INFO    ] __main__: train step 24877: loss: 0.8768, policy_loss: 0.7884, value_loss: 0.3987
2024-07-11 18:05:25,986 [INFO    ] __main__: train step 24878: loss: 0.8768, policy_loss: 0.7883, value_loss: 0.3987
2024-07-11 18:05:26,194 [INFO    ] __main__: train step 24879: loss: 0.8768, policy_loss: 0.7883, value_loss: 0.3987
2024-07-11 18:05:26,398 [INFO    ] __main__: train step 24880: loss: 0.8768, policy_loss: 0.7883, value_loss: 0.3986
2024-07-11 18:05:26,605 [INFO    ] __main__: train step 24881: loss: 0.8768, policy_loss: 0.7883, value_loss: 0.3986
2024-07-11 18:05:26,806 [INFO    ] __main__: train step 24882: loss: 0.8768, policy_loss: 0.7883, value_loss: 0.3986
2024-07-11 18:05:27,023 [INFO    ] __main__: train step 24883: loss: 0.8767, policy_loss: 0.7883, value_loss: 0.3986
2024-07-11 18:05:27,270 [INFO    ] __main__: train step 24884: loss: 0.8767, policy_loss: 0.7882, value_loss: 0.3986
2024-07-11 18:05:27,512 [INFO    ] __main__: train step 24885: loss: 0.8767, policy_loss: 0.7882, value_loss: 0.3986
2024-07-11 18:05:27,735 [INFO    ] __main__: train step 24886: loss: 0.8767, policy_loss: 0.7882, value_loss: 0.3986
2024-07-11 18:05:27,945 [INFO    ] __main__: train step 24887: loss: 0.8767, policy_loss: 0.7882, value_loss: 0.3985
2024-07-11 18:05:29,388 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:05:29,796 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:05:29,850 [INFO    ] __main__: train step 24888: loss: 0.8767, policy_loss: 0.7882, value_loss: 0.3985
2024-07-11 18:05:30,051 [INFO    ] __main__: train step 24889: loss: 0.8766, policy_loss: 0.7882, value_loss: 0.3985
2024-07-11 18:05:30,278 [INFO    ] __main__: train step 24890: loss: 0.8766, policy_loss: 0.7882, value_loss: 0.3985
2024-07-11 18:05:30,494 [INFO    ] __main__: train step 24891: loss: 0.8766, policy_loss: 0.7881, value_loss: 0.3985
2024-07-11 18:05:30,733 [INFO    ] __main__: train step 24892: loss: 0.8766, policy_loss: 0.7881, value_loss: 0.3985
2024-07-11 18:05:30,935 [INFO    ] __main__: train step 24893: loss: 0.8766, policy_loss: 0.7881, value_loss: 0.3985
2024-07-11 18:05:31,139 [INFO    ] __main__: train step 24894: loss: 0.8766, policy_loss: 0.7881, value_loss: 0.3984
2024-07-11 18:05:31,355 [INFO    ] __main__: train step 24895: loss: 0.8765, policy_loss: 0.7881, value_loss: 0.3984
2024-07-11 18:05:31,593 [INFO    ] __main__: train step 24896: loss: 0.8765, policy_loss: 0.7881, value_loss: 0.3984
2024-07-11 18:05:31,797 [INFO    ] __main__: train step 24897: loss: 0.8765, policy_loss: 0.7881, value_loss: 0.3984
2024-07-11 18:05:32,011 [INFO    ] __main__: train step 24898: loss: 0.8765, policy_loss: 0.7880, value_loss: 0.3984
2024-07-11 18:05:32,216 [INFO    ] __main__: train step 24899: loss: 0.8765, policy_loss: 0.7880, value_loss: 0.3984
2024-07-11 18:05:32,426 [INFO    ] __main__: train step 24900: loss: 0.8764, policy_loss: 0.7880, value_loss: 0.3984
2024-07-11 18:05:32,635 [INFO    ] __main__: train step 24901: loss: 0.8764, policy_loss: 0.7880, value_loss: 0.3983
2024-07-11 18:05:32,848 [INFO    ] __main__: train step 24902: loss: 0.8764, policy_loss: 0.7880, value_loss: 0.3983
2024-07-11 18:05:33,054 [INFO    ] __main__: train step 24903: loss: 0.8764, policy_loss: 0.7880, value_loss: 0.3983
2024-07-11 18:05:33,276 [INFO    ] __main__: train step 24904: loss: 0.8764, policy_loss: 0.7879, value_loss: 0.3983
2024-07-11 18:05:34,746 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:05:35,129 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:05:35,183 [INFO    ] __main__: train step 24905: loss: 0.8764, policy_loss: 0.7879, value_loss: 0.3983
2024-07-11 18:05:35,364 [INFO    ] __main__: train step 24906: loss: 0.8763, policy_loss: 0.7879, value_loss: 0.3983
2024-07-11 18:05:35,583 [INFO    ] __main__: train step 24907: loss: 0.8763, policy_loss: 0.7879, value_loss: 0.3983
2024-07-11 18:05:35,796 [INFO    ] __main__: train step 24908: loss: 0.8763, policy_loss: 0.7879, value_loss: 0.3982
2024-07-11 18:05:36,045 [INFO    ] __main__: train step 24909: loss: 0.8763, policy_loss: 0.7879, value_loss: 0.3982
2024-07-11 18:05:36,281 [INFO    ] __main__: train step 24910: loss: 0.8763, policy_loss: 0.7879, value_loss: 0.3982
2024-07-11 18:05:36,499 [INFO    ] __main__: train step 24911: loss: 0.8763, policy_loss: 0.7878, value_loss: 0.3982
2024-07-11 18:05:36,692 [INFO    ] __main__: train step 24912: loss: 0.8762, policy_loss: 0.7878, value_loss: 0.3982
2024-07-11 18:05:36,900 [INFO    ] __main__: train step 24913: loss: 0.8762, policy_loss: 0.7878, value_loss: 0.3982
2024-07-11 18:05:37,111 [INFO    ] __main__: train step 24914: loss: 0.8762, policy_loss: 0.7878, value_loss: 0.3982
2024-07-11 18:05:37,315 [INFO    ] __main__: train step 24915: loss: 0.8762, policy_loss: 0.7878, value_loss: 0.3981
2024-07-11 18:05:37,521 [INFO    ] __main__: train step 24916: loss: 0.8762, policy_loss: 0.7878, value_loss: 0.3981
2024-07-11 18:05:37,737 [INFO    ] __main__: train step 24917: loss: 0.8762, policy_loss: 0.7878, value_loss: 0.3981
2024-07-11 18:05:37,933 [INFO    ] __main__: train step 24918: loss: 0.8761, policy_loss: 0.7877, value_loss: 0.3981
2024-07-11 18:05:38,139 [INFO    ] __main__: train step 24919: loss: 0.8761, policy_loss: 0.7877, value_loss: 0.3981
2024-07-11 18:05:38,352 [INFO    ] __main__: train step 24920: loss: 0.8761, policy_loss: 0.7877, value_loss: 0.3981
2024-07-11 18:05:38,545 [INFO    ] __main__: train step 24921: loss: 0.8761, policy_loss: 0.7877, value_loss: 0.3981
2024-07-11 18:05:39,989 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:05:40,350 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:05:40,409 [INFO    ] __main__: train step 24922: loss: 0.8761, policy_loss: 0.7877, value_loss: 0.3980
2024-07-11 18:05:40,585 [INFO    ] __main__: train step 24923: loss: 0.8761, policy_loss: 0.7877, value_loss: 0.3980
2024-07-11 18:05:40,798 [INFO    ] __main__: train step 24924: loss: 0.8760, policy_loss: 0.7876, value_loss: 0.3980
2024-07-11 18:05:40,998 [INFO    ] __main__: train step 24925: loss: 0.8760, policy_loss: 0.7876, value_loss: 0.3980
2024-07-11 18:05:41,205 [INFO    ] __main__: train step 24926: loss: 0.8760, policy_loss: 0.7876, value_loss: 0.3980
2024-07-11 18:05:41,411 [INFO    ] __main__: train step 24927: loss: 0.8760, policy_loss: 0.7876, value_loss: 0.3980
2024-07-11 18:05:41,617 [INFO    ] __main__: train step 24928: loss: 0.8760, policy_loss: 0.7876, value_loss: 0.3979
2024-07-11 18:05:41,824 [INFO    ] __main__: train step 24929: loss: 0.8760, policy_loss: 0.7876, value_loss: 0.3979
2024-07-11 18:05:42,028 [INFO    ] __main__: train step 24930: loss: 0.8759, policy_loss: 0.7876, value_loss: 0.3979
2024-07-11 18:05:42,245 [INFO    ] __main__: train step 24931: loss: 0.8759, policy_loss: 0.7875, value_loss: 0.3979
2024-07-11 18:05:42,471 [INFO    ] __main__: train step 24932: loss: 0.8759, policy_loss: 0.7875, value_loss: 0.3979
2024-07-11 18:05:42,683 [INFO    ] __main__: train step 24933: loss: 0.8759, policy_loss: 0.7875, value_loss: 0.3979
2024-07-11 18:05:42,903 [INFO    ] __main__: train step 24934: loss: 0.8759, policy_loss: 0.7875, value_loss: 0.3979
2024-07-11 18:05:43,137 [INFO    ] __main__: train step 24935: loss: 0.8758, policy_loss: 0.7875, value_loss: 0.3978
2024-07-11 18:05:43,337 [INFO    ] __main__: train step 24936: loss: 0.8758, policy_loss: 0.7875, value_loss: 0.3978
2024-07-11 18:05:43,544 [INFO    ] __main__: train step 24937: loss: 0.8758, policy_loss: 0.7875, value_loss: 0.3978
2024-07-11 18:05:43,749 [INFO    ] __main__: train step 24938: loss: 0.8758, policy_loss: 0.7874, value_loss: 0.3978
2024-07-11 18:05:45,182 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:05:45,610 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:05:45,671 [INFO    ] __main__: train step 24939: loss: 0.8758, policy_loss: 0.7874, value_loss: 0.3978
2024-07-11 18:05:45,850 [INFO    ] __main__: train step 24940: loss: 0.8758, policy_loss: 0.7874, value_loss: 0.3978
2024-07-11 18:05:46,060 [INFO    ] __main__: train step 24941: loss: 0.8757, policy_loss: 0.7874, value_loss: 0.3978
2024-07-11 18:05:46,273 [INFO    ] __main__: train step 24942: loss: 0.8757, policy_loss: 0.7874, value_loss: 0.3977
2024-07-11 18:05:46,476 [INFO    ] __main__: train step 24943: loss: 0.8757, policy_loss: 0.7874, value_loss: 0.3977
2024-07-11 18:05:46,676 [INFO    ] __main__: train step 24944: loss: 0.8757, policy_loss: 0.7874, value_loss: 0.3977
2024-07-11 18:05:46,893 [INFO    ] __main__: train step 24945: loss: 0.8757, policy_loss: 0.7873, value_loss: 0.3977
2024-07-11 18:05:47,094 [INFO    ] __main__: train step 24946: loss: 0.8757, policy_loss: 0.7873, value_loss: 0.3977
2024-07-11 18:05:47,299 [INFO    ] __main__: train step 24947: loss: 0.8756, policy_loss: 0.7873, value_loss: 0.3977
2024-07-11 18:05:47,504 [INFO    ] __main__: train step 24948: loss: 0.8756, policy_loss: 0.7873, value_loss: 0.3977
2024-07-11 18:05:47,707 [INFO    ] __main__: train step 24949: loss: 0.8756, policy_loss: 0.7873, value_loss: 0.3976
2024-07-11 18:05:47,925 [INFO    ] __main__: train step 24950: loss: 0.8756, policy_loss: 0.7873, value_loss: 0.3976
2024-07-11 18:05:48,136 [INFO    ] __main__: train step 24951: loss: 0.8756, policy_loss: 0.7872, value_loss: 0.3976
2024-07-11 18:05:48,375 [INFO    ] __main__: train step 24952: loss: 0.8756, policy_loss: 0.7872, value_loss: 0.3976
2024-07-11 18:05:48,595 [INFO    ] __main__: train step 24953: loss: 0.8755, policy_loss: 0.7872, value_loss: 0.3976
2024-07-11 18:05:48,795 [INFO    ] __main__: train step 24954: loss: 0.8755, policy_loss: 0.7872, value_loss: 0.3976
2024-07-11 18:05:48,994 [INFO    ] __main__: train step 24955: loss: 0.8755, policy_loss: 0.7872, value_loss: 0.3976
2024-07-11 18:05:50,432 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:05:50,835 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:05:50,894 [INFO    ] __main__: train step 24956: loss: 0.8755, policy_loss: 0.7872, value_loss: 0.3975
2024-07-11 18:05:51,074 [INFO    ] __main__: train step 24957: loss: 0.8755, policy_loss: 0.7872, value_loss: 0.3975
2024-07-11 18:05:51,296 [INFO    ] __main__: train step 24958: loss: 0.8755, policy_loss: 0.7871, value_loss: 0.3975
2024-07-11 18:05:51,538 [INFO    ] __main__: train step 24959: loss: 0.8754, policy_loss: 0.7871, value_loss: 0.3975
2024-07-11 18:05:51,773 [INFO    ] __main__: train step 24960: loss: 0.8754, policy_loss: 0.7871, value_loss: 0.3975
2024-07-11 18:05:51,978 [INFO    ] __main__: train step 24961: loss: 0.8754, policy_loss: 0.7871, value_loss: 0.3975
2024-07-11 18:05:52,184 [INFO    ] __main__: train step 24962: loss: 0.8754, policy_loss: 0.7871, value_loss: 0.3975
2024-07-11 18:05:52,393 [INFO    ] __main__: train step 24963: loss: 0.8754, policy_loss: 0.7871, value_loss: 0.3974
2024-07-11 18:05:52,602 [INFO    ] __main__: train step 24964: loss: 0.8754, policy_loss: 0.7871, value_loss: 0.3974
2024-07-11 18:05:52,813 [INFO    ] __main__: train step 24965: loss: 0.8753, policy_loss: 0.7870, value_loss: 0.3974
2024-07-11 18:05:53,046 [INFO    ] __main__: train step 24966: loss: 0.8753, policy_loss: 0.7870, value_loss: 0.3974
2024-07-11 18:05:53,242 [INFO    ] __main__: train step 24967: loss: 0.8753, policy_loss: 0.7870, value_loss: 0.3974
2024-07-11 18:05:53,434 [INFO    ] __main__: train step 24968: loss: 0.8753, policy_loss: 0.7870, value_loss: 0.3974
2024-07-11 18:05:53,639 [INFO    ] __main__: train step 24969: loss: 0.8753, policy_loss: 0.7870, value_loss: 0.3974
2024-07-11 18:05:53,844 [INFO    ] __main__: train step 24970: loss: 0.8753, policy_loss: 0.7870, value_loss: 0.3973
2024-07-11 18:05:54,053 [INFO    ] __main__: train step 24971: loss: 0.8752, policy_loss: 0.7870, value_loss: 0.3973
2024-07-11 18:05:54,260 [INFO    ] __main__: train step 24972: loss: 0.8752, policy_loss: 0.7869, value_loss: 0.3973
2024-07-11 18:05:55,690 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:05:56,099 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:05:56,154 [INFO    ] __main__: train step 24973: loss: 0.8752, policy_loss: 0.7869, value_loss: 0.3973
2024-07-11 18:05:56,333 [INFO    ] __main__: train step 24974: loss: 0.8752, policy_loss: 0.7869, value_loss: 0.3973
2024-07-11 18:05:56,534 [INFO    ] __main__: train step 24975: loss: 0.8752, policy_loss: 0.7869, value_loss: 0.3973
2024-07-11 18:05:56,746 [INFO    ] __main__: train step 24976: loss: 0.8752, policy_loss: 0.7869, value_loss: 0.3972
2024-07-11 18:05:56,949 [INFO    ] __main__: train step 24977: loss: 0.8751, policy_loss: 0.7869, value_loss: 0.3972
2024-07-11 18:05:57,170 [INFO    ] __main__: train step 24978: loss: 0.8751, policy_loss: 0.7869, value_loss: 0.3972
2024-07-11 18:05:57,397 [INFO    ] __main__: train step 24979: loss: 0.8751, policy_loss: 0.7868, value_loss: 0.3972
2024-07-11 18:05:57,599 [INFO    ] __main__: train step 24980: loss: 0.8751, policy_loss: 0.7868, value_loss: 0.3972
2024-07-11 18:05:57,803 [INFO    ] __main__: train step 24981: loss: 0.8751, policy_loss: 0.7868, value_loss: 0.3972
2024-07-11 18:05:58,007 [INFO    ] __main__: train step 24982: loss: 0.8751, policy_loss: 0.7868, value_loss: 0.3972
2024-07-11 18:05:58,218 [INFO    ] __main__: train step 24983: loss: 0.8750, policy_loss: 0.7868, value_loss: 0.3971
2024-07-11 18:05:58,454 [INFO    ] __main__: train step 24984: loss: 0.8750, policy_loss: 0.7868, value_loss: 0.3971
2024-07-11 18:05:58,651 [INFO    ] __main__: train step 24985: loss: 0.8750, policy_loss: 0.7868, value_loss: 0.3971
2024-07-11 18:05:58,854 [INFO    ] __main__: train step 24986: loss: 0.8750, policy_loss: 0.7867, value_loss: 0.3971
2024-07-11 18:05:59,058 [INFO    ] __main__: train step 24987: loss: 0.8750, policy_loss: 0.7867, value_loss: 0.3971
2024-07-11 18:05:59,271 [INFO    ] __main__: train step 24988: loss: 0.8750, policy_loss: 0.7867, value_loss: 0.3971
2024-07-11 18:05:59,468 [INFO    ] __main__: train step 24989: loss: 0.8749, policy_loss: 0.7867, value_loss: 0.3971
2024-07-11 18:06:00,895 [INFO    ] __main__: replay_buffer size = 62500
2024-07-11 18:06:01,271 [INFO    ] __main__: saved replay_buffer to storage
2024-07-11 18:06:01,326 [INFO    ] __main__: train step 24990: loss: 0.8749, policy_loss: 0.7867, value_loss: 0.3970
2024-07-11 18:06:01,503 [INFO    ] __main__: train step 24991: loss: 0.8749, policy_loss: 0.7867, value_loss: 0.3970
2024-07-11 18:06:04,001 [INFO    ] __main__: train step 24992: loss: 0.8749, policy_loss: 0.7867, value_loss: 0.3970
2024-07-11 18:06:04,212 [INFO    ] __main__: train step 24993: loss: 0.8749, policy_loss: 0.7866, value_loss: 0.3970
2024-07-11 18:06:04,412 [INFO    ] __main__: train step 24994: loss: 0.8749, policy_loss: 0.7866, value_loss: 0.3970
2024-07-11 18:06:04,623 [INFO    ] __main__: train step 24995: loss: 0.8748, policy_loss: 0.7866, value_loss: 0.3970
2024-07-11 18:06:04,827 [INFO    ] __main__: train step 24996: loss: 0.8748, policy_loss: 0.7866, value_loss: 0.3970
2024-07-11 18:06:05,035 [INFO    ] __main__: train step 24997: loss: 0.8748, policy_loss: 0.7866, value_loss: 0.3969
2024-07-11 18:06:05,241 [INFO    ] __main__: train step 24998: loss: 0.8748, policy_loss: 0.7866, value_loss: 0.3969
2024-07-11 18:06:05,446 [INFO    ] __main__: train step 24999: loss: 0.8748, policy_loss: 0.7866, value_loss: 0.3969
2024-07-11 18:06:05,647 [INFO    ] __main__: train step 25000: loss: 0.8748, policy_loss: 0.7865, value_loss: 0.3969
2024-07-11 18:06:05,757 [INFO    ] __main__: restored step 24000 for evaluation
2024-07-11 18:06:13,492 [INFO    ] __main__: later network ELO difference from earlier network: -2 (+8/-8) ELO from 32000 self-played games
2024-07-11 18:06:13,493 [INFO    ] __main__: game outcomes: W: 15879, D: 34, L: 16087
2024-07-11 18:06:13,494 [INFO    ] __main__: validation_elo_delta: -2, validation_elo: 3182
2024-07-11 18:06:13,805 [INFO    ] __main__: running self-play game for SVG generation
2024-07-11 18:08:30,270 [INFO    ] __main__: saved self-play game in animations/run1_baseline/25000.svg
2024-07-11 18:08:30,447 [INFO    ] __main__: train step 25001: loss: 0.8747, policy_loss: 0.7865, value_loss: 0.3969
2024-07-11 18:08:30,657 [INFO    ] __main__: train step 25002: loss: 0.8747, policy_loss: 0.7865, value_loss: 0.3969
2024-07-11 18:08:30,852 [INFO    ] __main__: train step 25003: loss: 0.8747, policy_loss: 0.7865, value_loss: 0.3969
2024-07-11 18:08:31,064 [INFO    ] __main__: train step 25004: loss: 0.8747, policy_loss: 0.7865, value_loss: 0.3968
2024-07-11 18:08:31,275 [INFO    ] __main__: train step 25005: loss: 0.8747, policy_loss: 0.7865, value_loss: 0.3968
2024-07-11 18:08:31,511 [INFO    ] __main__: train step 25006: loss: 0.8747, policy_loss: 0.7864, value_loss: 0.3968
2024-07-11 18:08:31,772 [INFO    ] __main__: training has completed!
